INFO:root:Using device cuda
wandb: Currently logged in as: mathildepapillon (use `wandb login --relogin` to force relogin)
TORCH
1.11.0
wandb: wandb version 0.12.15 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.14
wandb: Run data is saved locally in /home/papillon/move/move/wandb/run-20220422_203716-3dzw8hg1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-wave-14
wandb: ⭐️ View project at https://wandb.ai/bioshape-lab/move
wandb: 🚀 View run at https://wandb.ai/bioshape-lab/move/runs/3dzw8hg1
INFO:root:Config: {config}
INFO:root:Run server specific commands
INFO:root:Initialize model
INFO:root:Loading raw datasets:
INFO:root:- data/mariel_betternot_and_retrograde.npy of shape (9925, 53, 3)
INFO:root:- data/mariel_beyond.npy of shape (5803, 53, 3)
INFO:root:- data/mariel_chunli.npy of shape (3866, 53, 3)
INFO:root:- data/mariel_honey.npy of shape (5309, 53, 3)
INFO:root:- data/mariel_knownbetter.npy of shape (6649, 53, 3)
INFO:root:- data/mariel_penelope.npy of shape (6757, 53, 3)
INFO:root:Preprocessing: Load seq_data of shape (38181, 128, 159)
INFO:root:>> Train ds has shape (34363, 128, 159)
INFO:root:>> Valid ds has shape (1909, 128, 159)
INFO:root:>> Test ds has shape (1909, 128, 159)
INFO:root:Preprocessing: Convert into torch dataloader
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 0): Loss/seq after 00000 batchs: 3904.376953125
INFO:root:Train (Epoch 0): Loss/seq after 00050 batchs: 6863.46533203125
INFO:root:Train (Epoch 0): Loss/seq after 00100 batchs: 4926.52099609375
INFO:root:Train (Epoch 0): Loss/seq after 00150 batchs: 3813.03515625
INFO:root:Train (Epoch 0): Loss/seq after 00200 batchs: 3528.123779296875
INFO:root:Train (Epoch 0): Loss/seq after 00250 batchs: 3363.0478515625
INFO:root:Train (Epoch 0): Loss/seq after 00300 batchs: 3053.3056640625
INFO:root:Train (Epoch 0): Loss/seq after 00350 batchs: 2770.774658203125
INFO:root:Train (Epoch 0): Loss/seq after 00400 batchs: 2903.33154296875
INFO:root:Train (Epoch 0): Loss/seq after 00450 batchs: 2738.34375
INFO:root:Train (Epoch 0): Loss/seq after 00500 batchs: 2733.058349609375
INFO:root:Train (Epoch 0): Loss/seq after 00550 batchs: 2612.62060546875
INFO:root:Train (Epoch 0): Loss/seq after 00600 batchs: 2523.23388671875
INFO:root:Train (Epoch 0): Loss/seq after 00650 batchs: 2612.03466796875
INFO:root:Train (Epoch 0): Loss/seq after 00700 batchs: 2639.426513671875
INFO:root:Train (Epoch 0): Loss/seq after 00750 batchs: 2620.837158203125
INFO:root:Train (Epoch 0): Loss/seq after 00800 batchs: 2635.265869140625
INFO:root:Train (Epoch 0): Loss/seq after 00850 batchs: 2548.89794921875
INFO:root:Train (Epoch 0): Loss/seq after 00900 batchs: 2516.35595703125
INFO:root:Train (Epoch 0): Loss/seq after 00950 batchs: 2647.841552734375
INFO:root:Train (Epoch 0): Loss/seq after 01000 batchs: 2649.234619140625
INFO:root:Train (Epoch 0): Loss/seq after 01050 batchs: 2621.47412109375
INFO:root:Train (Epoch 0): Loss/seq after 01100 batchs: 2584.34423828125
INFO:root:Train (Epoch 0): Loss/seq after 01150 batchs: 2526.692626953125
INFO:root:Train (Epoch 0): Loss/seq after 01200 batchs: 2475.939453125
INFO:root:Train (Epoch 0): Loss/seq after 01250 batchs: 2465.196533203125
INFO:root:Train (Epoch 0): Loss/seq after 01300 batchs: 2479.9052734375
INFO:root:Train (Epoch 0): Loss/seq after 01350 batchs: 2454.626953125
INFO:root:Train (Epoch 0): Loss/seq after 01400 batchs: 2486.163818359375
INFO:root:Train (Epoch 0): Loss/seq after 01450 batchs: 2514.415283203125
INFO:root:Train (Epoch 0): Loss/seq after 01500 batchs: 2488.66748046875
INFO:root:Train (Epoch 0): Loss/seq after 01550 batchs: 2466.64208984375
INFO:root:Train (Epoch 0): Loss/seq after 01600 batchs: 2420.186279296875
INFO:root:Train (Epoch 0): Loss/seq after 01650 batchs: 2389.647216796875
INFO:root:Train (Epoch 0): Loss/seq after 01700 batchs: 2352.703857421875
INFO:root:Train (Epoch 0): Loss/seq after 01750 batchs: 2314.25732421875
INFO:root:Train (Epoch 0): Loss/seq after 01800 batchs: 2275.114501953125
INFO:root:Train (Epoch 0): Loss/seq after 01850 batchs: 2236.883056640625
INFO:root:Train (Epoch 0): Loss/seq after 01900 batchs: 2212.87841796875
INFO:root:Train (Epoch 0): Loss/seq after 01950 batchs: 2185.841064453125
INFO:root:Train (Epoch 0): Loss/seq after 02000 batchs: 2155.42138671875
INFO:root:Train (Epoch 0): Loss/seq after 02050 batchs: 2127.295654296875
INFO:root:Train (Epoch 0): Loss/seq after 02100 batchs: 2096.884033203125
INFO:root:Train (Epoch 0): Loss/seq after 02150 batchs: 2068.61669921875
INFO:root:Train (Epoch 0): Loss/seq after 02200 batchs: 2039.7506103515625
INFO:root:Train (Epoch 0): Loss/seq after 02250 batchs: 2034.7352294921875
INFO:root:Train (Epoch 0): Loss/seq after 02300 batchs: 2042.387451171875
INFO:root:Train (Epoch 0): Loss/seq after 02350 batchs: 2021.957275390625
INFO:root:Train (Epoch 0): Loss/seq after 02400 batchs: 2003.9052734375
INFO:root:Train (Epoch 0): Loss/seq after 02450 batchs: 1977.9134521484375
INFO:root:Train (Epoch 0): Loss/seq after 02500 batchs: 1946.4517822265625
INFO:root:Train (Epoch 0): Loss/seq after 02550 batchs: 1927.0413818359375
INFO:root:Train (Epoch 0): Loss/seq after 02600 batchs: 1915.753173828125
INFO:root:Train (Epoch 0): Loss/seq after 02650 batchs: 1900.8302001953125
INFO:root:Train (Epoch 0): Loss/seq after 02700 batchs: 1891.7098388671875
INFO:root:Train (Epoch 0): Loss/seq after 02750 batchs: 1916.6029052734375
INFO:root:Train (Epoch 0): Loss/seq after 02800 batchs: 1922.8231201171875
INFO:root:Train (Epoch 0): Loss/seq after 02850 batchs: 1915.2132568359375
INFO:root:Train (Epoch 0): Loss/seq after 02900 batchs: 1906.8905029296875
INFO:root:Train (Epoch 0): Loss/seq after 02950 batchs: 1889.166259765625
INFO:root:Train (Epoch 0): Loss/seq after 03000 batchs: 1876.3330078125
INFO:root:Train (Epoch 0): Loss/seq after 03050 batchs: 1868.82666015625
INFO:root:Train (Epoch 0): Loss/seq after 03100 batchs: 1893.765380859375
INFO:root:Train (Epoch 0): Loss/seq after 03150 batchs: 1909.397216796875
INFO:root:Train (Epoch 0): Loss/seq after 03200 batchs: 1915.0791015625
INFO:root:Train (Epoch 0): Loss/seq after 03250 batchs: 1920.3671875
INFO:root:Train (Epoch 0): Loss/seq after 03300 batchs: 1913.6719970703125
INFO:root:Train (Epoch 0): Loss/seq after 03350 batchs: 1906.938720703125
INFO:root:Train (Epoch 0): Loss/seq after 03400 batchs: 1889.2581787109375
INFO:root:Train (Epoch 0): Loss/seq after 03450 batchs: 1876.909423828125
INFO:root:Train (Epoch 0): Loss/seq after 03500 batchs: 1874.674072265625
INFO:root:Train (Epoch 0): Loss/seq after 03550 batchs: 1864.284912109375
INFO:root:Train (Epoch 0): Loss/seq after 03600 batchs: 1863.5924072265625
INFO:root:Train (Epoch 0): Loss/seq after 03650 batchs: 1852.8853759765625
INFO:root:Train (Epoch 0): Loss/seq after 03700 batchs: 1845.333984375
INFO:root:Train (Epoch 0): Loss/seq after 03750 batchs: 1837.578857421875
INFO:root:Train (Epoch 0): Loss/seq after 03800 batchs: 1823.306640625
INFO:root:Train (Epoch 0): Loss/seq after 03850 batchs: 1812.0172119140625
INFO:root:Train (Epoch 0): Loss/seq after 03900 batchs: 1816.52587890625
INFO:root:Train (Epoch 0): Loss/seq after 03950 batchs: 1820.123046875
INFO:root:Train (Epoch 0): Loss/seq after 04000 batchs: 1804.2177734375
INFO:root:Train (Epoch 0): Loss/seq after 04050 batchs: 1789.2879638671875
INFO:root:Train (Epoch 0): Loss/seq after 04100 batchs: 1779.916259765625
INFO:root:Train (Epoch 0): Loss/seq after 04150 batchs: 1768.6314697265625
INFO:root:Train (Epoch 0): Loss/seq after 04200 batchs: 1759.2537841796875
INFO:root:Train (Epoch 0): Loss/seq after 04250 batchs: 1749.2818603515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 0): Loss/seq after 00000 batches: 999.7996215820312
INFO:root:# Valid (Epoch 0): Loss/seq after 00050 batches: 1174.171875
INFO:root:# Valid (Epoch 0): Loss/seq after 00100 batches: 1566.760498046875
INFO:root:# Valid (Epoch 0): Loss/seq after 00150 batches: 1302.3619384765625
INFO:root:# Valid (Epoch 0): Loss/seq after 00200 batches: 1176.08837890625
INFO:root:Artifacts: Make stick videos for epoch 0
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_0_on_20220422_204205.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_0_index_12_on_20220422_204205.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 1): Loss/seq after 00000 batchs: 4165.3642578125
INFO:root:Train (Epoch 1): Loss/seq after 00050 batchs: 2309.370849609375
INFO:root:Train (Epoch 1): Loss/seq after 00100 batchs: 2193.591552734375
INFO:root:Train (Epoch 1): Loss/seq after 00150 batchs: 1905.80126953125
INFO:root:Train (Epoch 1): Loss/seq after 00200 batchs: 1983.965576171875
INFO:root:Train (Epoch 1): Loss/seq after 00250 batchs: 2085.239501953125
INFO:root:Train (Epoch 1): Loss/seq after 00300 batchs: 1956.3863525390625
INFO:root:Train (Epoch 1): Loss/seq after 00350 batchs: 1814.92626953125
INFO:root:Train (Epoch 1): Loss/seq after 00400 batchs: 1903.3594970703125
INFO:root:Train (Epoch 1): Loss/seq after 00450 batchs: 1796.798583984375
INFO:root:Train (Epoch 1): Loss/seq after 00500 batchs: 1875.2100830078125
INFO:root:Train (Epoch 1): Loss/seq after 00550 batchs: 1792.615478515625
INFO:root:Train (Epoch 1): Loss/seq after 00600 batchs: 1739.6014404296875
INFO:root:Train (Epoch 1): Loss/seq after 00650 batchs: 1785.7060546875
INFO:root:Train (Epoch 1): Loss/seq after 00700 batchs: 1853.1253662109375
INFO:root:Train (Epoch 1): Loss/seq after 00750 batchs: 1883.6513671875
INFO:root:Train (Epoch 1): Loss/seq after 00800 batchs: 1856.1856689453125
INFO:root:Train (Epoch 1): Loss/seq after 00850 batchs: 1806.221435546875
INFO:root:Train (Epoch 1): Loss/seq after 00900 batchs: 1813.4630126953125
INFO:root:Train (Epoch 1): Loss/seq after 00950 batchs: 1911.009765625
INFO:root:Train (Epoch 1): Loss/seq after 01000 batchs: 1913.2568359375
INFO:root:Train (Epoch 1): Loss/seq after 01050 batchs: 1889.4813232421875
INFO:root:Train (Epoch 1): Loss/seq after 01100 batchs: 1885.6357421875
INFO:root:Train (Epoch 1): Loss/seq after 01150 batchs: 1850.9481201171875
INFO:root:Train (Epoch 1): Loss/seq after 01200 batchs: 1824.5347900390625
INFO:root:Train (Epoch 1): Loss/seq after 01250 batchs: 1812.5069580078125
INFO:root:Train (Epoch 1): Loss/seq after 01300 batchs: 1814.2166748046875
INFO:root:Train (Epoch 1): Loss/seq after 01350 batchs: 1805.2735595703125
INFO:root:Train (Epoch 1): Loss/seq after 01400 batchs: 1857.2952880859375
INFO:root:Train (Epoch 1): Loss/seq after 01450 batchs: 1839.587890625
INFO:root:Train (Epoch 1): Loss/seq after 01500 batchs: 1815.0733642578125
INFO:root:Train (Epoch 1): Loss/seq after 01550 batchs: 1812.0264892578125
INFO:root:Train (Epoch 1): Loss/seq after 01600 batchs: 1781.956787109375
INFO:root:Train (Epoch 1): Loss/seq after 01650 batchs: 1769.3424072265625
INFO:root:Train (Epoch 1): Loss/seq after 01700 batchs: 1749.7215576171875
INFO:root:Train (Epoch 1): Loss/seq after 01750 batchs: 1727.004638671875
INFO:root:Train (Epoch 1): Loss/seq after 01800 batchs: 1702.796875
INFO:root:Train (Epoch 1): Loss/seq after 01850 batchs: 1678.772216796875
INFO:root:Train (Epoch 1): Loss/seq after 01900 batchs: 1668.331787109375
INFO:root:Train (Epoch 1): Loss/seq after 01950 batchs: 1654.3291015625
INFO:root:Train (Epoch 1): Loss/seq after 02000 batchs: 1636.1593017578125
INFO:root:Train (Epoch 1): Loss/seq after 02050 batchs: 1619.9840087890625
INFO:root:Train (Epoch 1): Loss/seq after 02100 batchs: 1600.787109375
INFO:root:Train (Epoch 1): Loss/seq after 02150 batchs: 1583.26025390625
INFO:root:Train (Epoch 1): Loss/seq after 02200 batchs: 1564.69189453125
INFO:root:Train (Epoch 1): Loss/seq after 02250 batchs: 1570.26513671875
INFO:root:Train (Epoch 1): Loss/seq after 02300 batchs: 1573.6739501953125
INFO:root:Train (Epoch 1): Loss/seq after 02350 batchs: 1560.14794921875
INFO:root:Train (Epoch 1): Loss/seq after 02400 batchs: 1550.897705078125
INFO:root:Train (Epoch 1): Loss/seq after 02450 batchs: 1533.59326171875
INFO:root:Train (Epoch 1): Loss/seq after 02500 batchs: 1510.3721923828125
INFO:root:Train (Epoch 1): Loss/seq after 02550 batchs: 1498.62109375
INFO:root:Train (Epoch 1): Loss/seq after 02600 batchs: 1494.5526123046875
INFO:root:Train (Epoch 1): Loss/seq after 02650 batchs: 1487.0662841796875
INFO:root:Train (Epoch 1): Loss/seq after 02700 batchs: 1484.4639892578125
INFO:root:Train (Epoch 1): Loss/seq after 02750 batchs: 1514.081787109375
INFO:root:Train (Epoch 1): Loss/seq after 02800 batchs: 1523.3350830078125
INFO:root:Train (Epoch 1): Loss/seq after 02850 batchs: 1520.885986328125
INFO:root:Train (Epoch 1): Loss/seq after 02900 batchs: 1518.7200927734375
INFO:root:Train (Epoch 1): Loss/seq after 02950 batchs: 1508.452880859375
INFO:root:Train (Epoch 1): Loss/seq after 03000 batchs: 1501.7059326171875
INFO:root:Train (Epoch 1): Loss/seq after 03050 batchs: 1499.8787841796875
INFO:root:Train (Epoch 1): Loss/seq after 03100 batchs: 1521.4971923828125
INFO:root:Train (Epoch 1): Loss/seq after 03150 batchs: 1540.18310546875
INFO:root:Train (Epoch 1): Loss/seq after 03200 batchs: 1550.9176025390625
INFO:root:Train (Epoch 1): Loss/seq after 03250 batchs: 1562.061767578125
INFO:root:Train (Epoch 1): Loss/seq after 03300 batchs: 1562.4285888671875
INFO:root:Train (Epoch 1): Loss/seq after 03350 batchs: 1559.937255859375
INFO:root:Train (Epoch 1): Loss/seq after 03400 batchs: 1547.1510009765625
INFO:root:Train (Epoch 1): Loss/seq after 03450 batchs: 1538.8995361328125
INFO:root:Train (Epoch 1): Loss/seq after 03500 batchs: 1537.657470703125
INFO:root:Train (Epoch 1): Loss/seq after 03550 batchs: 1530.2928466796875
INFO:root:Train (Epoch 1): Loss/seq after 03600 batchs: 1533.45166015625
INFO:root:Train (Epoch 1): Loss/seq after 03650 batchs: 1526.8843994140625
INFO:root:Train (Epoch 1): Loss/seq after 03700 batchs: 1523.312255859375
INFO:root:Train (Epoch 1): Loss/seq after 03750 batchs: 1519.56396484375
INFO:root:Train (Epoch 1): Loss/seq after 03800 batchs: 1509.165283203125
INFO:root:Train (Epoch 1): Loss/seq after 03850 batchs: 1501.6663818359375
INFO:root:Train (Epoch 1): Loss/seq after 03900 batchs: 1511.2125244140625
INFO:root:Train (Epoch 1): Loss/seq after 03950 batchs: 1519.058837890625
INFO:root:Train (Epoch 1): Loss/seq after 04000 batchs: 1506.7313232421875
INFO:root:Train (Epoch 1): Loss/seq after 04050 batchs: 1495.2796630859375
INFO:root:Train (Epoch 1): Loss/seq after 04100 batchs: 1489.2744140625
INFO:root:Train (Epoch 1): Loss/seq after 04150 batchs: 1481.202880859375
INFO:root:Train (Epoch 1): Loss/seq after 04200 batchs: 1475.0281982421875
INFO:root:Train (Epoch 1): Loss/seq after 04250 batchs: 1468.1922607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 1): Loss/seq after 00000 batches: 1010.4625854492188
INFO:root:# Valid (Epoch 1): Loss/seq after 00050 batches: 1162.1549072265625
INFO:root:# Valid (Epoch 1): Loss/seq after 00100 batches: 1547.9132080078125
INFO:root:# Valid (Epoch 1): Loss/seq after 00150 batches: 1277.07568359375
INFO:root:# Valid (Epoch 1): Loss/seq after 00200 batches: 1149.3023681640625
INFO:root:Artifacts: Make stick videos for epoch 1
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_1_on_20220422_204655.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_1_index_1303_on_20220422_204655.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 2): Loss/seq after 00000 batchs: 2579.30517578125
INFO:root:Train (Epoch 2): Loss/seq after 00050 batchs: 2060.56201171875
INFO:root:Train (Epoch 2): Loss/seq after 00100 batchs: 1959.36474609375
INFO:root:Train (Epoch 2): Loss/seq after 00150 batchs: 1717.6444091796875
INFO:root:Train (Epoch 2): Loss/seq after 00200 batchs: 1820.083251953125
INFO:root:Train (Epoch 2): Loss/seq after 00250 batchs: 1933.1094970703125
INFO:root:Train (Epoch 2): Loss/seq after 00300 batchs: 1806.6185302734375
INFO:root:Train (Epoch 2): Loss/seq after 00350 batchs: 1676.963623046875
INFO:root:Train (Epoch 2): Loss/seq after 00400 batchs: 1763.451904296875
INFO:root:Train (Epoch 2): Loss/seq after 00450 batchs: 1669.052001953125
INFO:root:Train (Epoch 2): Loss/seq after 00500 batchs: 1728.035888671875
INFO:root:Train (Epoch 2): Loss/seq after 00550 batchs: 1657.2174072265625
INFO:root:Train (Epoch 2): Loss/seq after 00600 batchs: 1617.465576171875
INFO:root:Train (Epoch 2): Loss/seq after 00650 batchs: 1674.3199462890625
INFO:root:Train (Epoch 2): Loss/seq after 00700 batchs: 1750.446044921875
INFO:root:Train (Epoch 2): Loss/seq after 00750 batchs: 1787.373779296875
INFO:root:Train (Epoch 2): Loss/seq after 00800 batchs: 1763.6448974609375
INFO:root:Train (Epoch 2): Loss/seq after 00850 batchs: 1718.03076171875
INFO:root:Train (Epoch 2): Loss/seq after 00900 batchs: 1739.292236328125
INFO:root:Train (Epoch 2): Loss/seq after 00950 batchs: 1886.6546630859375
INFO:root:Train (Epoch 2): Loss/seq after 01000 batchs: 1885.7933349609375
INFO:root:Train (Epoch 2): Loss/seq after 01050 batchs: 1861.3341064453125
INFO:root:Train (Epoch 2): Loss/seq after 01100 batchs: 1861.25390625
INFO:root:Train (Epoch 2): Loss/seq after 01150 batchs: 1826.5748291015625
INFO:root:Train (Epoch 2): Loss/seq after 01200 batchs: 1800.5118408203125
INFO:root:Train (Epoch 2): Loss/seq after 01250 batchs: 1789.4324951171875
INFO:root:Train (Epoch 2): Loss/seq after 01300 batchs: 1794.739990234375
INFO:root:Train (Epoch 2): Loss/seq after 01350 batchs: 1786.4593505859375
INFO:root:Train (Epoch 2): Loss/seq after 01400 batchs: 1835.01171875
INFO:root:Train (Epoch 2): Loss/seq after 01450 batchs: 1813.5050048828125
INFO:root:Train (Epoch 2): Loss/seq after 01500 batchs: 1789.0948486328125
INFO:root:Train (Epoch 2): Loss/seq after 01550 batchs: 1789.140869140625
INFO:root:Train (Epoch 2): Loss/seq after 01600 batchs: 1759.5523681640625
INFO:root:Train (Epoch 2): Loss/seq after 01650 batchs: 1747.242919921875
INFO:root:Train (Epoch 2): Loss/seq after 01700 batchs: 1727.76171875
INFO:root:Train (Epoch 2): Loss/seq after 01750 batchs: 1705.3411865234375
INFO:root:Train (Epoch 2): Loss/seq after 01800 batchs: 1681.39794921875
INFO:root:Train (Epoch 2): Loss/seq after 01850 batchs: 1657.6339111328125
INFO:root:Train (Epoch 2): Loss/seq after 01900 batchs: 1647.4091796875
INFO:root:Train (Epoch 2): Loss/seq after 01950 batchs: 1633.68505859375
INFO:root:Train (Epoch 2): Loss/seq after 02000 batchs: 1615.7314453125
INFO:root:Train (Epoch 2): Loss/seq after 02050 batchs: 1599.8048095703125
INFO:root:Train (Epoch 2): Loss/seq after 02100 batchs: 1580.818359375
INFO:root:Train (Epoch 2): Loss/seq after 02150 batchs: 1563.5379638671875
INFO:root:Train (Epoch 2): Loss/seq after 02200 batchs: 1545.2066650390625
INFO:root:Train (Epoch 2): Loss/seq after 02250 batchs: 1551.0313720703125
INFO:root:Train (Epoch 2): Loss/seq after 02300 batchs: 1554.5050048828125
INFO:root:Train (Epoch 2): Loss/seq after 02350 batchs: 1540.9322509765625
INFO:root:Train (Epoch 2): Loss/seq after 02400 batchs: 1531.870361328125
INFO:root:Train (Epoch 2): Loss/seq after 02450 batchs: 1514.7999267578125
INFO:root:Train (Epoch 2): Loss/seq after 02500 batchs: 1491.8037109375
INFO:root:Train (Epoch 2): Loss/seq after 02550 batchs: 1480.919677734375
INFO:root:Train (Epoch 2): Loss/seq after 02600 batchs: 1477.1246337890625
INFO:root:Train (Epoch 2): Loss/seq after 02650 batchs: 1469.8887939453125
INFO:root:Train (Epoch 2): Loss/seq after 02700 batchs: 1467.5408935546875
INFO:root:Train (Epoch 2): Loss/seq after 02750 batchs: 1496.5001220703125
INFO:root:Train (Epoch 2): Loss/seq after 02800 batchs: 1504.90185546875
INFO:root:Train (Epoch 2): Loss/seq after 02850 batchs: 1501.827392578125
INFO:root:Train (Epoch 2): Loss/seq after 02900 batchs: 1499.7093505859375
INFO:root:Train (Epoch 2): Loss/seq after 02950 batchs: 1489.4354248046875
INFO:root:Train (Epoch 2): Loss/seq after 03000 batchs: 1482.918212890625
INFO:root:Train (Epoch 2): Loss/seq after 03050 batchs: 1481.28662109375
INFO:root:Train (Epoch 2): Loss/seq after 03100 batchs: 1503.78662109375
INFO:root:Train (Epoch 2): Loss/seq after 03150 batchs: 1527.84375
INFO:root:Train (Epoch 2): Loss/seq after 03200 batchs: 1539.2874755859375
INFO:root:Train (Epoch 2): Loss/seq after 03250 batchs: 1549.87060546875
INFO:root:Train (Epoch 2): Loss/seq after 03300 batchs: 1550.9583740234375
INFO:root:Train (Epoch 2): Loss/seq after 03350 batchs: 1549.12939453125
INFO:root:Train (Epoch 2): Loss/seq after 03400 batchs: 1536.35107421875
INFO:root:Train (Epoch 2): Loss/seq after 03450 batchs: 1528.613037109375
INFO:root:Train (Epoch 2): Loss/seq after 03500 batchs: 1530.6109619140625
INFO:root:Train (Epoch 2): Loss/seq after 03550 batchs: 1524.4637451171875
INFO:root:Train (Epoch 2): Loss/seq after 03600 batchs: 1528.2900390625
INFO:root:Train (Epoch 2): Loss/seq after 03650 batchs: 1521.755126953125
INFO:root:Train (Epoch 2): Loss/seq after 03700 batchs: 1518.25732421875
INFO:root:Train (Epoch 2): Loss/seq after 03750 batchs: 1514.5263671875
INFO:root:Train (Epoch 2): Loss/seq after 03800 batchs: 1504.1304931640625
INFO:root:Train (Epoch 2): Loss/seq after 03850 batchs: 1496.5997314453125
INFO:root:Train (Epoch 2): Loss/seq after 03900 batchs: 1510.5042724609375
INFO:root:Train (Epoch 2): Loss/seq after 03950 batchs: 1518.001220703125
INFO:root:Train (Epoch 2): Loss/seq after 04000 batchs: 1506.5439453125
INFO:root:Train (Epoch 2): Loss/seq after 04050 batchs: 1495.1656494140625
INFO:root:Train (Epoch 2): Loss/seq after 04100 batchs: 1489.4093017578125
INFO:root:Train (Epoch 2): Loss/seq after 04150 batchs: 1481.22216796875
INFO:root:Train (Epoch 2): Loss/seq after 04200 batchs: 1474.8953857421875
INFO:root:Train (Epoch 2): Loss/seq after 04250 batchs: 1467.9793701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 2): Loss/seq after 00000 batches: 1024.0478515625
INFO:root:# Valid (Epoch 2): Loss/seq after 00050 batches: 1161.7889404296875
INFO:root:# Valid (Epoch 2): Loss/seq after 00100 batches: 1539.67138671875
INFO:root:# Valid (Epoch 2): Loss/seq after 00150 batches: 1264.41650390625
INFO:root:# Valid (Epoch 2): Loss/seq after 00200 batches: 1135.6922607421875
INFO:root:Artifacts: Make stick videos for epoch 2
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_2_on_20220422_205141.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_2_index_173_on_20220422_205141.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 3): Loss/seq after 00000 batchs: 2597.631103515625
INFO:root:Train (Epoch 3): Loss/seq after 00050 batchs: 2010.012451171875
INFO:root:Train (Epoch 3): Loss/seq after 00100 batchs: 1993.3631591796875
INFO:root:Train (Epoch 3): Loss/seq after 00150 batchs: 1737.1490478515625
INFO:root:Train (Epoch 3): Loss/seq after 00200 batchs: 1870.24072265625
INFO:root:Train (Epoch 3): Loss/seq after 00250 batchs: 2021.30029296875
INFO:root:Train (Epoch 3): Loss/seq after 00300 batchs: 1900.6781005859375
INFO:root:Train (Epoch 3): Loss/seq after 00350 batchs: 1763.224365234375
INFO:root:Train (Epoch 3): Loss/seq after 00400 batchs: 2029.823974609375
INFO:root:Train (Epoch 3): Loss/seq after 00450 batchs: 1944.0977783203125
INFO:root:Train (Epoch 3): Loss/seq after 00500 batchs: 2016.6744384765625
INFO:root:Train (Epoch 3): Loss/seq after 00550 batchs: 1933.516845703125
INFO:root:Train (Epoch 3): Loss/seq after 00600 batchs: 1890.9862060546875
INFO:root:Train (Epoch 3): Loss/seq after 00650 batchs: 2119.639892578125
INFO:root:Train (Epoch 3): Loss/seq after 00700 batchs: 2287.346435546875
INFO:root:Train (Epoch 3): Loss/seq after 00750 batchs: 2289.724853515625
INFO:root:Train (Epoch 3): Loss/seq after 00800 batchs: 2376.461181640625
INFO:root:Train (Epoch 3): Loss/seq after 00850 batchs: 2340.15478515625
INFO:root:Train (Epoch 3): Loss/seq after 00900 batchs: 2311.599365234375
INFO:root:Train (Epoch 3): Loss/seq after 00950 batchs: 2492.19921875
INFO:root:Train (Epoch 3): Loss/seq after 01000 batchs: 2518.00830078125
INFO:root:Train (Epoch 3): Loss/seq after 01050 batchs: 2516.4443359375
INFO:root:Train (Epoch 3): Loss/seq after 01100 batchs: 2469.015625
INFO:root:Train (Epoch 3): Loss/seq after 01150 batchs: 2421.040283203125
INFO:root:Train (Epoch 3): Loss/seq after 01200 batchs: 2382.50830078125
INFO:root:Train (Epoch 3): Loss/seq after 01250 batchs: 2369.302978515625
INFO:root:Train (Epoch 3): Loss/seq after 01300 batchs: 2411.458740234375
INFO:root:Train (Epoch 3): Loss/seq after 01350 batchs: 2411.264892578125
INFO:root:Train (Epoch 3): Loss/seq after 01400 batchs: 2466.119384765625
INFO:root:Train (Epoch 3): Loss/seq after 01450 batchs: 2483.30859375
INFO:root:Train (Epoch 3): Loss/seq after 01500 batchs: 2477.04443359375
INFO:root:Train (Epoch 3): Loss/seq after 01550 batchs: 2458.087646484375
INFO:root:Train (Epoch 3): Loss/seq after 01600 batchs: 2419.41552734375
INFO:root:Train (Epoch 3): Loss/seq after 01650 batchs: 2388.0517578125
INFO:root:Train (Epoch 3): Loss/seq after 01700 batchs: 2351.732177734375
INFO:root:Train (Epoch 3): Loss/seq after 01750 batchs: 2313.019287109375
INFO:root:Train (Epoch 3): Loss/seq after 01800 batchs: 2272.939208984375
INFO:root:Train (Epoch 3): Loss/seq after 01850 batchs: 2233.190185546875
INFO:root:Train (Epoch 3): Loss/seq after 01900 batchs: 2207.83349609375
INFO:root:Train (Epoch 3): Loss/seq after 01950 batchs: 2179.6953125
INFO:root:Train (Epoch 3): Loss/seq after 02000 batchs: 2148.13330078125
INFO:root:Train (Epoch 3): Loss/seq after 02050 batchs: 2119.111572265625
INFO:root:Train (Epoch 3): Loss/seq after 02100 batchs: 2087.731689453125
INFO:root:Train (Epoch 3): Loss/seq after 02150 batchs: 2058.602294921875
INFO:root:Train (Epoch 3): Loss/seq after 02200 batchs: 2029.0079345703125
INFO:root:Train (Epoch 3): Loss/seq after 02250 batchs: 2024.922119140625
INFO:root:Train (Epoch 3): Loss/seq after 02300 batchs: 2040.4537353515625
INFO:root:Train (Epoch 3): Loss/seq after 02350 batchs: 2019.27587890625
INFO:root:Train (Epoch 3): Loss/seq after 02400 batchs: 2001.843017578125
INFO:root:Train (Epoch 3): Loss/seq after 02450 batchs: 1976.4647216796875
INFO:root:Train (Epoch 3): Loss/seq after 02500 batchs: 1944.7918701171875
INFO:root:Train (Epoch 3): Loss/seq after 02550 batchs: 1924.4180908203125
INFO:root:Train (Epoch 3): Loss/seq after 02600 batchs: 1911.9525146484375
INFO:root:Train (Epoch 3): Loss/seq after 02650 batchs: 1896.3409423828125
INFO:root:Train (Epoch 3): Loss/seq after 02700 batchs: 1891.792236328125
INFO:root:Train (Epoch 3): Loss/seq after 02750 batchs: 1922.497314453125
INFO:root:Train (Epoch 3): Loss/seq after 02800 batchs: 1942.265380859375
INFO:root:Train (Epoch 3): Loss/seq after 02850 batchs: 1938.2799072265625
INFO:root:Train (Epoch 3): Loss/seq after 02900 batchs: 1931.026611328125
INFO:root:Train (Epoch 3): Loss/seq after 02950 batchs: 1918.6822509765625
INFO:root:Train (Epoch 3): Loss/seq after 03000 batchs: 1907.59716796875
INFO:root:Train (Epoch 3): Loss/seq after 03050 batchs: 1899.510498046875
INFO:root:Train (Epoch 3): Loss/seq after 03100 batchs: 1931.72021484375
INFO:root:Train (Epoch 3): Loss/seq after 03150 batchs: 1987.379150390625
INFO:root:Train (Epoch 3): Loss/seq after 03200 batchs: 1996.321533203125
INFO:root:Train (Epoch 3): Loss/seq after 03250 batchs: 2000.9744873046875
INFO:root:Train (Epoch 3): Loss/seq after 03300 batchs: 2000.622802734375
INFO:root:Train (Epoch 3): Loss/seq after 03350 batchs: 1999.373291015625
INFO:root:Train (Epoch 3): Loss/seq after 03400 batchs: 1984.7489013671875
INFO:root:Train (Epoch 3): Loss/seq after 03450 batchs: 1971.09423828125
INFO:root:Train (Epoch 3): Loss/seq after 03500 batchs: 1967.0126953125
INFO:root:Train (Epoch 3): Loss/seq after 03550 batchs: 1956.01513671875
INFO:root:Train (Epoch 3): Loss/seq after 03600 batchs: 1954.3316650390625
INFO:root:Train (Epoch 3): Loss/seq after 03650 batchs: 1942.016845703125
INFO:root:Train (Epoch 3): Loss/seq after 03700 batchs: 1933.027587890625
INFO:root:Train (Epoch 3): Loss/seq after 03750 batchs: 1923.8360595703125
INFO:root:Train (Epoch 3): Loss/seq after 03800 batchs: 1908.1279296875
INFO:root:Train (Epoch 3): Loss/seq after 03850 batchs: 1895.4432373046875
INFO:root:Train (Epoch 3): Loss/seq after 03900 batchs: 1925.08642578125
INFO:root:Train (Epoch 3): Loss/seq after 03950 batchs: 1938.9683837890625
INFO:root:Train (Epoch 3): Loss/seq after 04000 batchs: 1934.365966796875
INFO:root:Train (Epoch 3): Loss/seq after 04050 batchs: 1919.397216796875
INFO:root:Train (Epoch 3): Loss/seq after 04100 batchs: 1906.85546875
INFO:root:Train (Epoch 3): Loss/seq after 04150 batchs: 1893.79931640625
INFO:root:Train (Epoch 3): Loss/seq after 04200 batchs: 1882.9393310546875
INFO:root:Train (Epoch 3): Loss/seq after 04250 batchs: 1871.5435791015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 3): Loss/seq after 00000 batches: 975.9070434570312
INFO:root:# Valid (Epoch 3): Loss/seq after 00050 batches: 1144.60595703125
INFO:root:# Valid (Epoch 3): Loss/seq after 00100 batches: 1560.772705078125
INFO:root:# Valid (Epoch 3): Loss/seq after 00150 batches: 1308.6168212890625
INFO:root:# Valid (Epoch 3): Loss/seq after 00200 batches: 1184.77294921875
INFO:root:Artifacts: Make stick videos for epoch 3
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_3_on_20220422_205628.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_3_index_922_on_20220422_205628.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 4): Loss/seq after 00000 batchs: 5843.93212890625
INFO:root:Train (Epoch 4): Loss/seq after 00050 batchs: 2592.801513671875
INFO:root:Train (Epoch 4): Loss/seq after 00100 batchs: 2603.87939453125
INFO:root:Train (Epoch 4): Loss/seq after 00150 batchs: 2194.829833984375
INFO:root:Train (Epoch 4): Loss/seq after 00200 batchs: 2484.940673828125
INFO:root:Train (Epoch 4): Loss/seq after 00250 batchs: 2494.228515625
INFO:root:Train (Epoch 4): Loss/seq after 00300 batchs: 2412.65869140625
INFO:root:Train (Epoch 4): Loss/seq after 00350 batchs: 2239.729248046875
INFO:root:Train (Epoch 4): Loss/seq after 00400 batchs: 2398.631591796875
INFO:root:Train (Epoch 4): Loss/seq after 00450 batchs: 2280.607666015625
INFO:root:Train (Epoch 4): Loss/seq after 00500 batchs: 2313.502197265625
INFO:root:Train (Epoch 4): Loss/seq after 00550 batchs: 2206.65869140625
INFO:root:Train (Epoch 4): Loss/seq after 00600 batchs: 2140.745361328125
INFO:root:Train (Epoch 4): Loss/seq after 00650 batchs: 2350.1103515625
INFO:root:Train (Epoch 4): Loss/seq after 00700 batchs: 2526.901123046875
INFO:root:Train (Epoch 4): Loss/seq after 00750 batchs: 2521.112060546875
INFO:root:Train (Epoch 4): Loss/seq after 00800 batchs: 2569.878662109375
INFO:root:Train (Epoch 4): Loss/seq after 00850 batchs: 2520.881591796875
INFO:root:Train (Epoch 4): Loss/seq after 00900 batchs: 2482.13427734375
INFO:root:Train (Epoch 4): Loss/seq after 00950 batchs: 2651.43017578125
INFO:root:Train (Epoch 4): Loss/seq after 01000 batchs: 2673.382080078125
INFO:root:Train (Epoch 4): Loss/seq after 01050 batchs: 2661.9765625
INFO:root:Train (Epoch 4): Loss/seq after 01100 batchs: 2608.339111328125
INFO:root:Train (Epoch 4): Loss/seq after 01150 batchs: 2554.21435546875
INFO:root:Train (Epoch 4): Loss/seq after 01200 batchs: 2509.677001953125
INFO:root:Train (Epoch 4): Loss/seq after 01250 batchs: 2492.720703125
INFO:root:Train (Epoch 4): Loss/seq after 01300 batchs: 2527.805419921875
INFO:root:Train (Epoch 4): Loss/seq after 01350 batchs: 2522.934326171875
INFO:root:Train (Epoch 4): Loss/seq after 01400 batchs: 2574.449951171875
INFO:root:Train (Epoch 4): Loss/seq after 01450 batchs: 2586.744384765625
INFO:root:Train (Epoch 4): Loss/seq after 01500 batchs: 2577.990234375
INFO:root:Train (Epoch 4): Loss/seq after 01550 batchs: 2556.704833984375
INFO:root:Train (Epoch 4): Loss/seq after 01600 batchs: 2516.587158203125
INFO:root:Train (Epoch 4): Loss/seq after 01650 batchs: 2483.037841796875
INFO:root:Train (Epoch 4): Loss/seq after 01700 batchs: 2445.067138671875
INFO:root:Train (Epoch 4): Loss/seq after 01750 batchs: 2404.87744140625
INFO:root:Train (Epoch 4): Loss/seq after 01800 batchs: 2363.699462890625
INFO:root:Train (Epoch 4): Loss/seq after 01850 batchs: 2322.10205078125
INFO:root:Train (Epoch 4): Loss/seq after 01900 batchs: 2294.49853515625
INFO:root:Train (Epoch 4): Loss/seq after 01950 batchs: 2264.131591796875
INFO:root:Train (Epoch 4): Loss/seq after 02000 batchs: 2230.45703125
INFO:root:Train (Epoch 4): Loss/seq after 02050 batchs: 2199.395263671875
INFO:root:Train (Epoch 4): Loss/seq after 02100 batchs: 2166.11328125
INFO:root:Train (Epoch 4): Loss/seq after 02150 batchs: 2135.15966796875
INFO:root:Train (Epoch 4): Loss/seq after 02200 batchs: 2103.872802734375
INFO:root:Train (Epoch 4): Loss/seq after 02250 batchs: 2098.75927734375
INFO:root:Train (Epoch 4): Loss/seq after 02300 batchs: 2113.793212890625
INFO:root:Train (Epoch 4): Loss/seq after 02350 batchs: 2090.792724609375
INFO:root:Train (Epoch 4): Loss/seq after 02400 batchs: 2071.699951171875
INFO:root:Train (Epoch 4): Loss/seq after 02450 batchs: 2044.8145751953125
INFO:root:Train (Epoch 4): Loss/seq after 02500 batchs: 2011.8438720703125
INFO:root:Train (Epoch 4): Loss/seq after 02550 batchs: 1990.13525390625
INFO:root:Train (Epoch 4): Loss/seq after 02600 batchs: 1976.41064453125
INFO:root:Train (Epoch 4): Loss/seq after 02650 batchs: 1959.587158203125
INFO:root:Train (Epoch 4): Loss/seq after 02700 batchs: 1953.8428955078125
INFO:root:Train (Epoch 4): Loss/seq after 02750 batchs: 1983.5101318359375
INFO:root:Train (Epoch 4): Loss/seq after 02800 batchs: 2002.531982421875
INFO:root:Train (Epoch 4): Loss/seq after 02850 batchs: 1997.3538818359375
INFO:root:Train (Epoch 4): Loss/seq after 02900 batchs: 1989.066650390625
INFO:root:Train (Epoch 4): Loss/seq after 02950 batchs: 1975.751220703125
INFO:root:Train (Epoch 4): Loss/seq after 03000 batchs: 1963.8865966796875
INFO:root:Train (Epoch 4): Loss/seq after 03050 batchs: 1955.2222900390625
INFO:root:Train (Epoch 4): Loss/seq after 03100 batchs: 1986.15185546875
INFO:root:Train (Epoch 4): Loss/seq after 03150 batchs: 2044.837890625
INFO:root:Train (Epoch 4): Loss/seq after 03200 batchs: 2070.356689453125
INFO:root:Train (Epoch 4): Loss/seq after 03250 batchs: 2084.203369140625
INFO:root:Train (Epoch 4): Loss/seq after 03300 batchs: 2084.656494140625
INFO:root:Train (Epoch 4): Loss/seq after 03350 batchs: 2085.004638671875
INFO:root:Train (Epoch 4): Loss/seq after 03400 batchs: 2071.4228515625
INFO:root:Train (Epoch 4): Loss/seq after 03450 batchs: 2056.858154296875
INFO:root:Train (Epoch 4): Loss/seq after 03500 batchs: 2051.512939453125
INFO:root:Train (Epoch 4): Loss/seq after 03550 batchs: 2039.431640625
INFO:root:Train (Epoch 4): Loss/seq after 03600 batchs: 2036.3134765625
INFO:root:Train (Epoch 4): Loss/seq after 03650 batchs: 2022.748291015625
INFO:root:Train (Epoch 4): Loss/seq after 03700 batchs: 2013.0616455078125
INFO:root:Train (Epoch 4): Loss/seq after 03750 batchs: 2002.764404296875
INFO:root:Train (Epoch 4): Loss/seq after 03800 batchs: 1986.0380859375
INFO:root:Train (Epoch 4): Loss/seq after 03850 batchs: 1972.3626708984375
INFO:root:Train (Epoch 4): Loss/seq after 03900 batchs: 2000.890380859375
INFO:root:Train (Epoch 4): Loss/seq after 03950 batchs: 2013.2176513671875
INFO:root:Train (Epoch 4): Loss/seq after 04000 batchs: 2008.9659423828125
INFO:root:Train (Epoch 4): Loss/seq after 04050 batchs: 1997.81689453125
INFO:root:Train (Epoch 4): Loss/seq after 04100 batchs: 1990.90966796875
INFO:root:Train (Epoch 4): Loss/seq after 04150 batchs: 1977.4884033203125
INFO:root:Train (Epoch 4): Loss/seq after 04200 batchs: 1965.019775390625
INFO:root:Train (Epoch 4): Loss/seq after 04250 batchs: 1952.4256591796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 4): Loss/seq after 00000 batches: 1016.9431762695312
INFO:root:# Valid (Epoch 4): Loss/seq after 00050 batches: 1156.38427734375
INFO:root:# Valid (Epoch 4): Loss/seq after 00100 batches: 1541.496826171875
INFO:root:# Valid (Epoch 4): Loss/seq after 00150 batches: 1267.195556640625
INFO:root:# Valid (Epoch 4): Loss/seq after 00200 batches: 1138.7789306640625
INFO:root:Artifacts: Make stick videos for epoch 4
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_4_on_20220422_210119.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_4_index_1440_on_20220422_210119.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 5): Loss/seq after 00000 batchs: 5647.32666015625
INFO:root:Train (Epoch 5): Loss/seq after 00050 batchs: 2572.45556640625
INFO:root:Train (Epoch 5): Loss/seq after 00100 batchs: 2639.125244140625
INFO:root:Train (Epoch 5): Loss/seq after 00150 batchs: 2197.4755859375
INFO:root:Train (Epoch 5): Loss/seq after 00200 batchs: 2531.553955078125
INFO:root:Train (Epoch 5): Loss/seq after 00250 batchs: 2526.563232421875
INFO:root:Train (Epoch 5): Loss/seq after 00300 batchs: 2429.615478515625
INFO:root:Train (Epoch 5): Loss/seq after 00350 batchs: 2255.231201171875
INFO:root:Train (Epoch 5): Loss/seq after 00400 batchs: 2408.33251953125
INFO:root:Train (Epoch 5): Loss/seq after 00450 batchs: 2288.181640625
INFO:root:Train (Epoch 5): Loss/seq after 00500 batchs: 2319.428466796875
INFO:root:Train (Epoch 5): Loss/seq after 00550 batchs: 2211.379638671875
INFO:root:Train (Epoch 5): Loss/seq after 00600 batchs: 2144.889404296875
INFO:root:Train (Epoch 5): Loss/seq after 00650 batchs: 2356.535400390625
INFO:root:Train (Epoch 5): Loss/seq after 00700 batchs: 2543.96240234375
INFO:root:Train (Epoch 5): Loss/seq after 00750 batchs: 2542.54443359375
INFO:root:Train (Epoch 5): Loss/seq after 00800 batchs: 2583.462890625
INFO:root:Train (Epoch 5): Loss/seq after 00850 batchs: 2535.228271484375
INFO:root:Train (Epoch 5): Loss/seq after 00900 batchs: 2496.79052734375
INFO:root:Train (Epoch 5): Loss/seq after 00950 batchs: 2663.28759765625
INFO:root:Train (Epoch 5): Loss/seq after 01000 batchs: 2679.59619140625
INFO:root:Train (Epoch 5): Loss/seq after 01050 batchs: 2668.70947265625
INFO:root:Train (Epoch 5): Loss/seq after 01100 batchs: 2614.25341796875
INFO:root:Train (Epoch 5): Loss/seq after 01150 batchs: 2560.908203125
INFO:root:Train (Epoch 5): Loss/seq after 01200 batchs: 2519.246337890625
INFO:root:Train (Epoch 5): Loss/seq after 01250 batchs: 2499.351806640625
INFO:root:Train (Epoch 5): Loss/seq after 01300 batchs: 2535.111572265625
INFO:root:Train (Epoch 5): Loss/seq after 01350 batchs: 2531.778564453125
INFO:root:Train (Epoch 5): Loss/seq after 01400 batchs: 2585.088134765625
INFO:root:Train (Epoch 5): Loss/seq after 01450 batchs: 2594.232177734375
INFO:root:Train (Epoch 5): Loss/seq after 01500 batchs: 2584.6796875
INFO:root:Train (Epoch 5): Loss/seq after 01550 batchs: 2563.145751953125
INFO:root:Train (Epoch 5): Loss/seq after 01600 batchs: 2522.88330078125
INFO:root:Train (Epoch 5): Loss/seq after 01650 batchs: 2488.924560546875
INFO:root:Train (Epoch 5): Loss/seq after 01700 batchs: 2450.866455078125
INFO:root:Train (Epoch 5): Loss/seq after 01750 batchs: 2410.17578125
INFO:root:Train (Epoch 5): Loss/seq after 01800 batchs: 2368.463623046875
INFO:root:Train (Epoch 5): Loss/seq after 01850 batchs: 2326.39794921875
INFO:root:Train (Epoch 5): Loss/seq after 01900 batchs: 2298.630615234375
INFO:root:Train (Epoch 5): Loss/seq after 01950 batchs: 2268.17236328125
INFO:root:Train (Epoch 5): Loss/seq after 02000 batchs: 2234.3876953125
INFO:root:Train (Epoch 5): Loss/seq after 02050 batchs: 2203.262939453125
INFO:root:Train (Epoch 5): Loss/seq after 02100 batchs: 2169.868408203125
INFO:root:Train (Epoch 5): Loss/seq after 02150 batchs: 2138.82470703125
INFO:root:Train (Epoch 5): Loss/seq after 02200 batchs: 2107.40869140625
INFO:root:Train (Epoch 5): Loss/seq after 02250 batchs: 2101.55859375
INFO:root:Train (Epoch 5): Loss/seq after 02300 batchs: 2115.486572265625
INFO:root:Train (Epoch 5): Loss/seq after 02350 batchs: 2092.667236328125
INFO:root:Train (Epoch 5): Loss/seq after 02400 batchs: 2073.556640625
INFO:root:Train (Epoch 5): Loss/seq after 02450 batchs: 2046.67822265625
INFO:root:Train (Epoch 5): Loss/seq after 02500 batchs: 2013.7978515625
INFO:root:Train (Epoch 5): Loss/seq after 02550 batchs: 1991.9359130859375
INFO:root:Train (Epoch 5): Loss/seq after 02600 batchs: 1978.220703125
INFO:root:Train (Epoch 5): Loss/seq after 02650 batchs: 1961.334228515625
INFO:root:Train (Epoch 5): Loss/seq after 02700 batchs: 1955.5694580078125
INFO:root:Train (Epoch 5): Loss/seq after 02750 batchs: 1984.9835205078125
INFO:root:Train (Epoch 5): Loss/seq after 02800 batchs: 2003.7510986328125
INFO:root:Train (Epoch 5): Loss/seq after 02850 batchs: 1998.6759033203125
INFO:root:Train (Epoch 5): Loss/seq after 02900 batchs: 1990.367919921875
INFO:root:Train (Epoch 5): Loss/seq after 02950 batchs: 1976.9930419921875
INFO:root:Train (Epoch 5): Loss/seq after 03000 batchs: 1965.0401611328125
INFO:root:Train (Epoch 5): Loss/seq after 03050 batchs: 1956.3394775390625
INFO:root:Train (Epoch 5): Loss/seq after 03100 batchs: 1987.2353515625
INFO:root:Train (Epoch 5): Loss/seq after 03150 batchs: 2044.8271484375
INFO:root:Train (Epoch 5): Loss/seq after 03200 batchs: 2063.485595703125
INFO:root:Train (Epoch 5): Loss/seq after 03250 batchs: 2066.71240234375
INFO:root:Train (Epoch 5): Loss/seq after 03300 batchs: 2063.594482421875
INFO:root:Train (Epoch 5): Loss/seq after 03350 batchs: 2061.16015625
INFO:root:Train (Epoch 5): Loss/seq after 03400 batchs: 2046.87255859375
INFO:root:Train (Epoch 5): Loss/seq after 03450 batchs: 2033.71240234375
INFO:root:Train (Epoch 5): Loss/seq after 03500 batchs: 2028.163330078125
INFO:root:Train (Epoch 5): Loss/seq after 03550 batchs: 2016.2403564453125
INFO:root:Train (Epoch 5): Loss/seq after 03600 batchs: 2014.6104736328125
INFO:root:Train (Epoch 5): Loss/seq after 03650 batchs: 2001.4600830078125
INFO:root:Train (Epoch 5): Loss/seq after 03700 batchs: 1991.662109375
INFO:root:Train (Epoch 5): Loss/seq after 03750 batchs: 1981.816650390625
INFO:root:Train (Epoch 5): Loss/seq after 03800 batchs: 1965.50341796875
INFO:root:Train (Epoch 5): Loss/seq after 03850 batchs: 1952.1854248046875
INFO:root:Train (Epoch 5): Loss/seq after 03900 batchs: 1988.1453857421875
INFO:root:Train (Epoch 5): Loss/seq after 03950 batchs: 2005.5599365234375
INFO:root:Train (Epoch 5): Loss/seq after 04000 batchs: 1994.9072265625
INFO:root:Train (Epoch 5): Loss/seq after 04050 batchs: 1981.900146484375
INFO:root:Train (Epoch 5): Loss/seq after 04100 batchs: 1974.7418212890625
INFO:root:Train (Epoch 5): Loss/seq after 04150 batchs: 1962.1600341796875
INFO:root:Train (Epoch 5): Loss/seq after 04200 batchs: 1949.52880859375
INFO:root:Train (Epoch 5): Loss/seq after 04250 batchs: 1937.25048828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 5): Loss/seq after 00000 batches: 1119.6810302734375
INFO:root:# Valid (Epoch 5): Loss/seq after 00050 batches: 1219.0760498046875
INFO:root:# Valid (Epoch 5): Loss/seq after 00100 batches: 1560.772216796875
INFO:root:# Valid (Epoch 5): Loss/seq after 00150 batches: 1261.4193115234375
INFO:root:# Valid (Epoch 5): Loss/seq after 00200 batches: 1126.25732421875
INFO:root:Artifacts: Make stick videos for epoch 5
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_5_on_20220422_210606.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_5_index_586_on_20220422_210606.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 6): Loss/seq after 00000 batchs: 5293.21435546875
INFO:root:Train (Epoch 6): Loss/seq after 00050 batchs: 2512.73779296875
INFO:root:Train (Epoch 6): Loss/seq after 00100 batchs: 2660.890625
INFO:root:Train (Epoch 6): Loss/seq after 00150 batchs: 2198.2021484375
INFO:root:Train (Epoch 6): Loss/seq after 00200 batchs: 2585.934814453125
INFO:root:Train (Epoch 6): Loss/seq after 00250 batchs: 2572.12060546875
INFO:root:Train (Epoch 6): Loss/seq after 00300 batchs: 2448.00927734375
INFO:root:Train (Epoch 6): Loss/seq after 00350 batchs: 2270.572998046875
INFO:root:Train (Epoch 6): Loss/seq after 00400 batchs: 2418.32080078125
INFO:root:Train (Epoch 6): Loss/seq after 00450 batchs: 2295.073486328125
INFO:root:Train (Epoch 6): Loss/seq after 00500 batchs: 2324.668212890625
INFO:root:Train (Epoch 6): Loss/seq after 00550 batchs: 2215.2978515625
INFO:root:Train (Epoch 6): Loss/seq after 00600 batchs: 2148.536865234375
INFO:root:Train (Epoch 6): Loss/seq after 00650 batchs: 2367.435791015625
INFO:root:Train (Epoch 6): Loss/seq after 00700 batchs: 2575.783447265625
INFO:root:Train (Epoch 6): Loss/seq after 00750 batchs: 2585.455322265625
INFO:root:Train (Epoch 6): Loss/seq after 00800 batchs: 2606.404052734375
INFO:root:Train (Epoch 6): Loss/seq after 00850 batchs: 2561.529541015625
INFO:root:Train (Epoch 6): Loss/seq after 00900 batchs: 2522.47021484375
INFO:root:Train (Epoch 6): Loss/seq after 00950 batchs: 2684.578125
INFO:root:Train (Epoch 6): Loss/seq after 01000 batchs: 2697.94775390625
INFO:root:Train (Epoch 6): Loss/seq after 01050 batchs: 2686.064208984375
INFO:root:Train (Epoch 6): Loss/seq after 01100 batchs: 2629.9794921875
INFO:root:Train (Epoch 6): Loss/seq after 01150 batchs: 2576.842529296875
INFO:root:Train (Epoch 6): Loss/seq after 01200 batchs: 2536.2109375
INFO:root:Train (Epoch 6): Loss/seq after 01250 batchs: 2514.897705078125
INFO:root:Train (Epoch 6): Loss/seq after 01300 batchs: 2550.784423828125
INFO:root:Train (Epoch 6): Loss/seq after 01350 batchs: 2549.12548828125
INFO:root:Train (Epoch 6): Loss/seq after 01400 batchs: 2604.534912109375
INFO:root:Train (Epoch 6): Loss/seq after 01450 batchs: 2609.492919921875
INFO:root:Train (Epoch 6): Loss/seq after 01500 batchs: 2599.873046875
INFO:root:Train (Epoch 6): Loss/seq after 01550 batchs: 2578.290771484375
INFO:root:Train (Epoch 6): Loss/seq after 01600 batchs: 2538.549072265625
INFO:root:Train (Epoch 6): Loss/seq after 01650 batchs: 2504.537841796875
INFO:root:Train (Epoch 6): Loss/seq after 01700 batchs: 2466.628662109375
INFO:root:Train (Epoch 6): Loss/seq after 01750 batchs: 2426.453857421875
INFO:root:Train (Epoch 6): Loss/seq after 01800 batchs: 2385.721923828125
INFO:root:Train (Epoch 6): Loss/seq after 01850 batchs: 2344.26318359375
INFO:root:Train (Epoch 6): Loss/seq after 01900 batchs: 2316.604248046875
INFO:root:Train (Epoch 6): Loss/seq after 01950 batchs: 2285.8115234375
INFO:root:Train (Epoch 6): Loss/seq after 02000 batchs: 2251.798583984375
INFO:root:Train (Epoch 6): Loss/seq after 02050 batchs: 2220.25537109375
INFO:root:Train (Epoch 6): Loss/seq after 02100 batchs: 2186.587646484375
INFO:root:Train (Epoch 6): Loss/seq after 02150 batchs: 2155.19580078125
INFO:root:Train (Epoch 6): Loss/seq after 02200 batchs: 2123.53125
INFO:root:Train (Epoch 6): Loss/seq after 02250 batchs: 2118.68359375
INFO:root:Train (Epoch 6): Loss/seq after 02300 batchs: 2134.923095703125
INFO:root:Train (Epoch 6): Loss/seq after 02350 batchs: 2110.591064453125
INFO:root:Train (Epoch 6): Loss/seq after 02400 batchs: 2090.9140625
INFO:root:Train (Epoch 6): Loss/seq after 02450 batchs: 2063.62646484375
INFO:root:Train (Epoch 6): Loss/seq after 02500 batchs: 2030.5595703125
INFO:root:Train (Epoch 6): Loss/seq after 02550 batchs: 2008.224365234375
INFO:root:Train (Epoch 6): Loss/seq after 02600 batchs: 1994.205078125
INFO:root:Train (Epoch 6): Loss/seq after 02650 batchs: 1976.949951171875
INFO:root:Train (Epoch 6): Loss/seq after 02700 batchs: 1970.9381103515625
INFO:root:Train (Epoch 6): Loss/seq after 02750 batchs: 2000.9991455078125
INFO:root:Train (Epoch 6): Loss/seq after 02800 batchs: 2020.523681640625
INFO:root:Train (Epoch 6): Loss/seq after 02850 batchs: 2014.143798828125
INFO:root:Train (Epoch 6): Loss/seq after 02900 batchs: 2005.55419921875
INFO:root:Train (Epoch 6): Loss/seq after 02950 batchs: 1992.0606689453125
INFO:root:Train (Epoch 6): Loss/seq after 03000 batchs: 1980.2076416015625
INFO:root:Train (Epoch 6): Loss/seq after 03050 batchs: 1971.4515380859375
INFO:root:Train (Epoch 6): Loss/seq after 03100 batchs: 2002.1903076171875
INFO:root:Train (Epoch 6): Loss/seq after 03150 batchs: 2063.236083984375
INFO:root:Train (Epoch 6): Loss/seq after 03200 batchs: 2091.141845703125
INFO:root:Train (Epoch 6): Loss/seq after 03250 batchs: 2111.536865234375
INFO:root:Train (Epoch 6): Loss/seq after 03300 batchs: 2107.416748046875
INFO:root:Train (Epoch 6): Loss/seq after 03350 batchs: 2108.0634765625
INFO:root:Train (Epoch 6): Loss/seq after 03400 batchs: 2099.57568359375
INFO:root:Train (Epoch 6): Loss/seq after 03450 batchs: 2088.447265625
INFO:root:Train (Epoch 6): Loss/seq after 03500 batchs: 2082.04150390625
INFO:root:Train (Epoch 6): Loss/seq after 03550 batchs: 2072.14404296875
INFO:root:Train (Epoch 6): Loss/seq after 03600 batchs: 2071.6083984375
INFO:root:Train (Epoch 6): Loss/seq after 03650 batchs: 2057.726806640625
INFO:root:Train (Epoch 6): Loss/seq after 03700 batchs: 2047.4239501953125
INFO:root:Train (Epoch 6): Loss/seq after 03750 batchs: 2036.876708984375
INFO:root:Train (Epoch 6): Loss/seq after 03800 batchs: 2019.817626953125
INFO:root:Train (Epoch 6): Loss/seq after 03850 batchs: 2005.73583984375
INFO:root:Train (Epoch 6): Loss/seq after 03900 batchs: 2040.123291015625
INFO:root:Train (Epoch 6): Loss/seq after 03950 batchs: 2056.44873046875
INFO:root:Train (Epoch 6): Loss/seq after 04000 batchs: 2045.6087646484375
INFO:root:Train (Epoch 6): Loss/seq after 04050 batchs: 2032.1676025390625
INFO:root:Train (Epoch 6): Loss/seq after 04100 batchs: 2024.525634765625
INFO:root:Train (Epoch 6): Loss/seq after 04150 batchs: 2011.384765625
INFO:root:Train (Epoch 6): Loss/seq after 04200 batchs: 1998.131103515625
INFO:root:Train (Epoch 6): Loss/seq after 04250 batchs: 1985.244384765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 6): Loss/seq after 00000 batches: 1100.134521484375
INFO:root:# Valid (Epoch 6): Loss/seq after 00050 batches: 1212.2327880859375
INFO:root:# Valid (Epoch 6): Loss/seq after 00100 batches: 1555.13671875
INFO:root:# Valid (Epoch 6): Loss/seq after 00150 batches: 1257.2742919921875
INFO:root:# Valid (Epoch 6): Loss/seq after 00200 batches: 1122.09716796875
INFO:root:Artifacts: Make stick videos for epoch 6
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_6_on_20220422_211054.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_6_index_298_on_20220422_211054.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 7): Loss/seq after 00000 batchs: 5309.27734375
INFO:root:Train (Epoch 7): Loss/seq after 00050 batchs: 2513.66748046875
INFO:root:Train (Epoch 7): Loss/seq after 00100 batchs: 2655.512451171875
INFO:root:Train (Epoch 7): Loss/seq after 00150 batchs: 2194.74951171875
INFO:root:Train (Epoch 7): Loss/seq after 00200 batchs: 2579.4345703125
INFO:root:Train (Epoch 7): Loss/seq after 00250 batchs: 2566.66162109375
INFO:root:Train (Epoch 7): Loss/seq after 00300 batchs: 2444.276611328125
INFO:root:Train (Epoch 7): Loss/seq after 00350 batchs: 2267.160888671875
INFO:root:Train (Epoch 7): Loss/seq after 00400 batchs: 2415.2314453125
INFO:root:Train (Epoch 7): Loss/seq after 00450 batchs: 2292.32470703125
INFO:root:Train (Epoch 7): Loss/seq after 00500 batchs: 2321.830078125
INFO:root:Train (Epoch 7): Loss/seq after 00550 batchs: 2212.8125
INFO:root:Train (Epoch 7): Loss/seq after 00600 batchs: 2145.950439453125
INFO:root:Train (Epoch 7): Loss/seq after 00650 batchs: 2365.031005859375
INFO:root:Train (Epoch 7): Loss/seq after 00700 batchs: 2572.316162109375
INFO:root:Train (Epoch 7): Loss/seq after 00750 batchs: 2579.25244140625
INFO:root:Train (Epoch 7): Loss/seq after 00800 batchs: 2604.65966796875
INFO:root:Train (Epoch 7): Loss/seq after 00850 batchs: 2558.175048828125
INFO:root:Train (Epoch 7): Loss/seq after 00900 batchs: 2518.75341796875
INFO:root:Train (Epoch 7): Loss/seq after 00950 batchs: 2682.518798828125
INFO:root:Train (Epoch 7): Loss/seq after 01000 batchs: 2696.269287109375
INFO:root:Train (Epoch 7): Loss/seq after 01050 batchs: 2683.568603515625
INFO:root:Train (Epoch 7): Loss/seq after 01100 batchs: 2627.788818359375
INFO:root:Train (Epoch 7): Loss/seq after 01150 batchs: 2574.42236328125
INFO:root:Train (Epoch 7): Loss/seq after 01200 batchs: 2533.653076171875
INFO:root:Train (Epoch 7): Loss/seq after 01250 batchs: 2512.407958984375
INFO:root:Train (Epoch 7): Loss/seq after 01300 batchs: 2548.560546875
INFO:root:Train (Epoch 7): Loss/seq after 01350 batchs: 2547.385009765625
INFO:root:Train (Epoch 7): Loss/seq after 01400 batchs: 2603.095703125
INFO:root:Train (Epoch 7): Loss/seq after 01450 batchs: 2607.52099609375
INFO:root:Train (Epoch 7): Loss/seq after 01500 batchs: 2597.498291015625
INFO:root:Train (Epoch 7): Loss/seq after 01550 batchs: 2575.96484375
INFO:root:Train (Epoch 7): Loss/seq after 01600 batchs: 2536.363525390625
INFO:root:Train (Epoch 7): Loss/seq after 01650 batchs: 2502.413330078125
INFO:root:Train (Epoch 7): Loss/seq after 01700 batchs: 2464.6806640625
INFO:root:Train (Epoch 7): Loss/seq after 01750 batchs: 2424.557861328125
INFO:root:Train (Epoch 7): Loss/seq after 01800 batchs: 2383.788330078125
INFO:root:Train (Epoch 7): Loss/seq after 01850 batchs: 2342.196533203125
INFO:root:Train (Epoch 7): Loss/seq after 01900 batchs: 2314.382080078125
INFO:root:Train (Epoch 7): Loss/seq after 01950 batchs: 2283.56494140625
INFO:root:Train (Epoch 7): Loss/seq after 02000 batchs: 2249.4443359375
INFO:root:Train (Epoch 7): Loss/seq after 02050 batchs: 2217.877197265625
INFO:root:Train (Epoch 7): Loss/seq after 02100 batchs: 2184.12109375
INFO:root:Train (Epoch 7): Loss/seq after 02150 batchs: 2152.7119140625
INFO:root:Train (Epoch 7): Loss/seq after 02200 batchs: 2120.995361328125
INFO:root:Train (Epoch 7): Loss/seq after 02250 batchs: 2115.835693359375
INFO:root:Train (Epoch 7): Loss/seq after 02300 batchs: 2131.54833984375
INFO:root:Train (Epoch 7): Loss/seq after 02350 batchs: 2107.48583984375
INFO:root:Train (Epoch 7): Loss/seq after 02400 batchs: 2087.813720703125
INFO:root:Train (Epoch 7): Loss/seq after 02450 batchs: 2060.543701171875
INFO:root:Train (Epoch 7): Loss/seq after 02500 batchs: 2027.3968505859375
INFO:root:Train (Epoch 7): Loss/seq after 02550 batchs: 2005.1787109375
INFO:root:Train (Epoch 7): Loss/seq after 02600 batchs: 1991.151611328125
INFO:root:Train (Epoch 7): Loss/seq after 02650 batchs: 1973.9459228515625
INFO:root:Train (Epoch 7): Loss/seq after 02700 batchs: 1967.9013671875
INFO:root:Train (Epoch 7): Loss/seq after 02750 batchs: 1997.7188720703125
INFO:root:Train (Epoch 7): Loss/seq after 02800 batchs: 2017.1104736328125
INFO:root:Train (Epoch 7): Loss/seq after 02850 batchs: 2011.0452880859375
INFO:root:Train (Epoch 7): Loss/seq after 02900 batchs: 2002.4613037109375
INFO:root:Train (Epoch 7): Loss/seq after 02950 batchs: 1988.94189453125
INFO:root:Train (Epoch 7): Loss/seq after 03000 batchs: 1977.085205078125
INFO:root:Train (Epoch 7): Loss/seq after 03050 batchs: 1968.3563232421875
INFO:root:Train (Epoch 7): Loss/seq after 03100 batchs: 1999.034912109375
INFO:root:Train (Epoch 7): Loss/seq after 03150 batchs: 2059.24072265625
INFO:root:Train (Epoch 7): Loss/seq after 03200 batchs: 2081.2158203125
INFO:root:Train (Epoch 7): Loss/seq after 03250 batchs: 2083.083984375
INFO:root:Train (Epoch 7): Loss/seq after 03300 batchs: 2077.948486328125
INFO:root:Train (Epoch 7): Loss/seq after 03350 batchs: 2074.72216796875
INFO:root:Train (Epoch 7): Loss/seq after 03400 batchs: 2060.887451171875
INFO:root:Train (Epoch 7): Loss/seq after 03450 batchs: 2047.46044921875
INFO:root:Train (Epoch 7): Loss/seq after 03500 batchs: 2041.39599609375
INFO:root:Train (Epoch 7): Loss/seq after 03550 batchs: 2029.6273193359375
INFO:root:Train (Epoch 7): Loss/seq after 03600 batchs: 2027.4293212890625
INFO:root:Train (Epoch 7): Loss/seq after 03650 batchs: 2013.9869384765625
INFO:root:Train (Epoch 7): Loss/seq after 03700 batchs: 2003.9735107421875
INFO:root:Train (Epoch 7): Loss/seq after 03750 batchs: 1993.7818603515625
INFO:root:Train (Epoch 7): Loss/seq after 03800 batchs: 1977.1177978515625
INFO:root:Train (Epoch 7): Loss/seq after 03850 batchs: 1963.4722900390625
INFO:root:Train (Epoch 7): Loss/seq after 03900 batchs: 1996.1533203125
INFO:root:Train (Epoch 7): Loss/seq after 03950 batchs: 2011.4752197265625
INFO:root:Train (Epoch 7): Loss/seq after 04000 batchs: 2002.899658203125
INFO:root:Train (Epoch 7): Loss/seq after 04050 batchs: 1990.6453857421875
INFO:root:Train (Epoch 7): Loss/seq after 04100 batchs: 1983.727294921875
INFO:root:Train (Epoch 7): Loss/seq after 04150 batchs: 1970.9957275390625
INFO:root:Train (Epoch 7): Loss/seq after 04200 batchs: 1958.259033203125
INFO:root:Train (Epoch 7): Loss/seq after 04250 batchs: 1945.7989501953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 7): Loss/seq after 00000 batches: 1095.6326904296875
INFO:root:# Valid (Epoch 7): Loss/seq after 00050 batches: 1197.3936767578125
INFO:root:# Valid (Epoch 7): Loss/seq after 00100 batches: 1550.0980224609375
INFO:root:# Valid (Epoch 7): Loss/seq after 00150 batches: 1255.459228515625
INFO:root:# Valid (Epoch 7): Loss/seq after 00200 batches: 1121.5714111328125
INFO:root:Artifacts: Make stick videos for epoch 7
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_7_on_20220422_211538.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_7_index_681_on_20220422_211538.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 8): Loss/seq after 00000 batchs: 5390.31103515625
INFO:root:Train (Epoch 8): Loss/seq after 00050 batchs: 2530.09375
INFO:root:Train (Epoch 8): Loss/seq after 00100 batchs: 2652.443115234375
INFO:root:Train (Epoch 8): Loss/seq after 00150 batchs: 2195.728759765625
INFO:root:Train (Epoch 8): Loss/seq after 00200 batchs: 2569.498291015625
INFO:root:Train (Epoch 8): Loss/seq after 00250 batchs: 2557.472412109375
INFO:root:Train (Epoch 8): Loss/seq after 00300 batchs: 2439.96826171875
INFO:root:Train (Epoch 8): Loss/seq after 00350 batchs: 2264.015869140625
INFO:root:Train (Epoch 8): Loss/seq after 00400 batchs: 2412.557373046875
INFO:root:Train (Epoch 8): Loss/seq after 00450 batchs: 2290.3837890625
INFO:root:Train (Epoch 8): Loss/seq after 00500 batchs: 2319.95263671875
INFO:root:Train (Epoch 8): Loss/seq after 00550 batchs: 2211.274169921875
INFO:root:Train (Epoch 8): Loss/seq after 00600 batchs: 2144.54248046875
INFO:root:Train (Epoch 8): Loss/seq after 00650 batchs: 2362.86474609375
INFO:root:Train (Epoch 8): Loss/seq after 00700 batchs: 2569.05859375
INFO:root:Train (Epoch 8): Loss/seq after 00750 batchs: 2573.457763671875
INFO:root:Train (Epoch 8): Loss/seq after 00800 batchs: 2599.03076171875
INFO:root:Train (Epoch 8): Loss/seq after 00850 batchs: 2539.113037109375
INFO:root:Train (Epoch 8): Loss/seq after 00900 batchs: 2498.42138671875
INFO:root:Train (Epoch 8): Loss/seq after 00950 batchs: 2674.334716796875
INFO:root:Train (Epoch 8): Loss/seq after 01000 batchs: 2689.454833984375
INFO:root:Train (Epoch 8): Loss/seq after 01050 batchs: 2679.69287109375
INFO:root:Train (Epoch 8): Loss/seq after 01100 batchs: 2624.314453125
INFO:root:Train (Epoch 8): Loss/seq after 01150 batchs: 2571.37744140625
INFO:root:Train (Epoch 8): Loss/seq after 01200 batchs: 2529.111083984375
INFO:root:Train (Epoch 8): Loss/seq after 01250 batchs: 2509.6064453125
INFO:root:Train (Epoch 8): Loss/seq after 01300 batchs: 2544.442626953125
INFO:root:Train (Epoch 8): Loss/seq after 01350 batchs: 2540.4736328125
INFO:root:Train (Epoch 8): Loss/seq after 01400 batchs: 2592.139404296875
INFO:root:Train (Epoch 8): Loss/seq after 01450 batchs: 2602.116943359375
INFO:root:Train (Epoch 8): Loss/seq after 01500 batchs: 2594.026611328125
INFO:root:Train (Epoch 8): Loss/seq after 01550 batchs: 2572.75634765625
INFO:root:Train (Epoch 8): Loss/seq after 01600 batchs: 2532.308349609375
INFO:root:Train (Epoch 8): Loss/seq after 01650 batchs: 2497.708251953125
INFO:root:Train (Epoch 8): Loss/seq after 01700 batchs: 2458.276611328125
INFO:root:Train (Epoch 8): Loss/seq after 01750 batchs: 2416.111572265625
INFO:root:Train (Epoch 8): Loss/seq after 01800 batchs: 2372.8876953125
INFO:root:Train (Epoch 8): Loss/seq after 01850 batchs: 2330.43603515625
INFO:root:Train (Epoch 8): Loss/seq after 01900 batchs: 2302.489501953125
INFO:root:Train (Epoch 8): Loss/seq after 01950 batchs: 2271.9521484375
INFO:root:Train (Epoch 8): Loss/seq after 02000 batchs: 2238.0546875
INFO:root:Train (Epoch 8): Loss/seq after 02050 batchs: 2206.81787109375
INFO:root:Train (Epoch 8): Loss/seq after 02100 batchs: 2173.326904296875
INFO:root:Train (Epoch 8): Loss/seq after 02150 batchs: 2142.20556640625
INFO:root:Train (Epoch 8): Loss/seq after 02200 batchs: 2110.680419921875
INFO:root:Train (Epoch 8): Loss/seq after 02250 batchs: 2103.49560546875
INFO:root:Train (Epoch 8): Loss/seq after 02300 batchs: 2113.749267578125
INFO:root:Train (Epoch 8): Loss/seq after 02350 batchs: 2092.238525390625
INFO:root:Train (Epoch 8): Loss/seq after 02400 batchs: 2074.1484375
INFO:root:Train (Epoch 8): Loss/seq after 02450 batchs: 2046.93505859375
INFO:root:Train (Epoch 8): Loss/seq after 02500 batchs: 2013.42822265625
INFO:root:Train (Epoch 8): Loss/seq after 02550 batchs: 1992.129150390625
INFO:root:Train (Epoch 8): Loss/seq after 02600 batchs: 1978.5078125
INFO:root:Train (Epoch 8): Loss/seq after 02650 batchs: 1961.6376953125
INFO:root:Train (Epoch 8): Loss/seq after 02700 batchs: 1955.7427978515625
INFO:root:Train (Epoch 8): Loss/seq after 02750 batchs: 1983.6571044921875
INFO:root:Train (Epoch 8): Loss/seq after 02800 batchs: 2000.457275390625
INFO:root:Train (Epoch 8): Loss/seq after 02850 batchs: 1994.540771484375
INFO:root:Train (Epoch 8): Loss/seq after 02900 batchs: 1985.13232421875
INFO:root:Train (Epoch 8): Loss/seq after 02950 batchs: 1969.5308837890625
INFO:root:Train (Epoch 8): Loss/seq after 03000 batchs: 1955.3421630859375
INFO:root:Train (Epoch 8): Loss/seq after 03050 batchs: 1945.8931884765625
INFO:root:Train (Epoch 8): Loss/seq after 03100 batchs: 1964.7755126953125
INFO:root:Train (Epoch 8): Loss/seq after 03150 batchs: 1985.314208984375
INFO:root:Train (Epoch 8): Loss/seq after 03200 batchs: 1988.8642578125
INFO:root:Train (Epoch 8): Loss/seq after 03250 batchs: 1993.05615234375
INFO:root:Train (Epoch 8): Loss/seq after 03300 batchs: 1989.7098388671875
INFO:root:Train (Epoch 8): Loss/seq after 03350 batchs: 1986.5601806640625
INFO:root:Train (Epoch 8): Loss/seq after 03400 batchs: 1970.230224609375
INFO:root:Train (Epoch 8): Loss/seq after 03450 batchs: 1956.604248046875
INFO:root:Train (Epoch 8): Loss/seq after 03500 batchs: 1952.5523681640625
INFO:root:Train (Epoch 8): Loss/seq after 03550 batchs: 1941.0521240234375
INFO:root:Train (Epoch 8): Loss/seq after 03600 batchs: 1939.4317626953125
INFO:root:Train (Epoch 8): Loss/seq after 03650 batchs: 1927.2713623046875
INFO:root:Train (Epoch 8): Loss/seq after 03700 batchs: 1918.3363037109375
INFO:root:Train (Epoch 8): Loss/seq after 03750 batchs: 1909.277099609375
INFO:root:Train (Epoch 8): Loss/seq after 03800 batchs: 1893.751708984375
INFO:root:Train (Epoch 8): Loss/seq after 03850 batchs: 1881.142333984375
INFO:root:Train (Epoch 8): Loss/seq after 03900 batchs: 1914.625732421875
INFO:root:Train (Epoch 8): Loss/seq after 03950 batchs: 1932.564208984375
INFO:root:Train (Epoch 8): Loss/seq after 04000 batchs: 1921.5120849609375
INFO:root:Train (Epoch 8): Loss/seq after 04050 batchs: 1906.306884765625
INFO:root:Train (Epoch 8): Loss/seq after 04100 batchs: 1895.84228515625
INFO:root:Train (Epoch 8): Loss/seq after 04150 batchs: 1882.756591796875
INFO:root:Train (Epoch 8): Loss/seq after 04200 batchs: 1871.578857421875
INFO:root:Train (Epoch 8): Loss/seq after 04250 batchs: 1860.001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 8): Loss/seq after 00000 batches: 1027.9371337890625
INFO:root:# Valid (Epoch 8): Loss/seq after 00050 batches: 1159.53857421875
INFO:root:# Valid (Epoch 8): Loss/seq after 00100 batches: 1528.7398681640625
INFO:root:# Valid (Epoch 8): Loss/seq after 00150 batches: 1248.4593505859375
INFO:root:# Valid (Epoch 8): Loss/seq after 00200 batches: 1119.9791259765625
INFO:root:Artifacts: Make stick videos for epoch 8
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_8_on_20220422_212020.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_8_index_390_on_20220422_212020.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 9): Loss/seq after 00000 batchs: 5630.0009765625
INFO:root:Train (Epoch 9): Loss/seq after 00050 batchs: 2564.749267578125
INFO:root:Train (Epoch 9): Loss/seq after 00100 batchs: 2474.06982421875
INFO:root:Train (Epoch 9): Loss/seq after 00150 batchs: 2161.893310546875
INFO:root:Train (Epoch 9): Loss/seq after 00200 batchs: 2406.42333984375
INFO:root:Train (Epoch 9): Loss/seq after 00250 batchs: 2423.544921875
INFO:root:Train (Epoch 9): Loss/seq after 00300 batchs: 2351.79052734375
INFO:root:Train (Epoch 9): Loss/seq after 00350 batchs: 2193.92626953125
INFO:root:Train (Epoch 9): Loss/seq after 00400 batchs: 2332.181884765625
INFO:root:Train (Epoch 9): Loss/seq after 00450 batchs: 2237.646240234375
INFO:root:Train (Epoch 9): Loss/seq after 00500 batchs: 2270.50244140625
INFO:root:Train (Epoch 9): Loss/seq after 00550 batchs: 2167.3935546875
INFO:root:Train (Epoch 9): Loss/seq after 00600 batchs: 2098.25146484375
INFO:root:Train (Epoch 9): Loss/seq after 00650 batchs: 2279.8798828125
INFO:root:Train (Epoch 9): Loss/seq after 00700 batchs: 2379.38916015625
INFO:root:Train (Epoch 9): Loss/seq after 00750 batchs: 2364.154052734375
INFO:root:Train (Epoch 9): Loss/seq after 00800 batchs: 2317.677490234375
INFO:root:Train (Epoch 9): Loss/seq after 00850 batchs: 2238.51220703125
INFO:root:Train (Epoch 9): Loss/seq after 00900 batchs: 2220.068115234375
INFO:root:Train (Epoch 9): Loss/seq after 00950 batchs: 2302.509033203125
INFO:root:Train (Epoch 9): Loss/seq after 01000 batchs: 2303.24169921875
INFO:root:Train (Epoch 9): Loss/seq after 01050 batchs: 2273.7216796875
INFO:root:Train (Epoch 9): Loss/seq after 01100 batchs: 2258.382080078125
INFO:root:Train (Epoch 9): Loss/seq after 01150 batchs: 2230.96533203125
INFO:root:Train (Epoch 9): Loss/seq after 01200 batchs: 2194.924560546875
INFO:root:Train (Epoch 9): Loss/seq after 01250 batchs: 2179.985107421875
INFO:root:Train (Epoch 9): Loss/seq after 01300 batchs: 2199.533447265625
INFO:root:Train (Epoch 9): Loss/seq after 01350 batchs: 2179.720947265625
INFO:root:Train (Epoch 9): Loss/seq after 01400 batchs: 2220.272705078125
INFO:root:Train (Epoch 9): Loss/seq after 01450 batchs: 2190.85546875
INFO:root:Train (Epoch 9): Loss/seq after 01500 batchs: 2153.9951171875
INFO:root:Train (Epoch 9): Loss/seq after 01550 batchs: 2144.995849609375
INFO:root:Train (Epoch 9): Loss/seq after 01600 batchs: 2103.906005859375
INFO:root:Train (Epoch 9): Loss/seq after 01650 batchs: 2080.91259765625
INFO:root:Train (Epoch 9): Loss/seq after 01700 batchs: 2051.396728515625
INFO:root:Train (Epoch 9): Loss/seq after 01750 batchs: 2019.50048828125
INFO:root:Train (Epoch 9): Loss/seq after 01800 batchs: 1986.7672119140625
INFO:root:Train (Epoch 9): Loss/seq after 01850 batchs: 1954.5638427734375
INFO:root:Train (Epoch 9): Loss/seq after 01900 batchs: 1936.3004150390625
INFO:root:Train (Epoch 9): Loss/seq after 01950 batchs: 1915.089111328125
INFO:root:Train (Epoch 9): Loss/seq after 02000 batchs: 1890.0196533203125
INFO:root:Train (Epoch 9): Loss/seq after 02050 batchs: 1867.21630859375
INFO:root:Train (Epoch 9): Loss/seq after 02100 batchs: 1841.7508544921875
INFO:root:Train (Epoch 9): Loss/seq after 02150 batchs: 1818.292724609375
INFO:root:Train (Epoch 9): Loss/seq after 02200 batchs: 1794.13232421875
INFO:root:Train (Epoch 9): Loss/seq after 02250 batchs: 1794.5531005859375
INFO:root:Train (Epoch 9): Loss/seq after 02300 batchs: 1793.756103515625
INFO:root:Train (Epoch 9): Loss/seq after 02350 batchs: 1775.0947265625
INFO:root:Train (Epoch 9): Loss/seq after 02400 batchs: 1761.0810546875
INFO:root:Train (Epoch 9): Loss/seq after 02450 batchs: 1739.2908935546875
INFO:root:Train (Epoch 9): Loss/seq after 02500 batchs: 1711.8994140625
INFO:root:Train (Epoch 9): Loss/seq after 02550 batchs: 1694.3372802734375
INFO:root:Train (Epoch 9): Loss/seq after 02600 batchs: 1685.986328125
INFO:root:Train (Epoch 9): Loss/seq after 02650 batchs: 1673.466064453125
INFO:root:Train (Epoch 9): Loss/seq after 02700 batchs: 1665.24365234375
INFO:root:Train (Epoch 9): Loss/seq after 02750 batchs: 1695.2816162109375
INFO:root:Train (Epoch 9): Loss/seq after 02800 batchs: 1700.145263671875
INFO:root:Train (Epoch 9): Loss/seq after 02850 batchs: 1693.53125
INFO:root:Train (Epoch 9): Loss/seq after 02900 batchs: 1686.6666259765625
INFO:root:Train (Epoch 9): Loss/seq after 02950 batchs: 1672.5347900390625
INFO:root:Train (Epoch 9): Loss/seq after 03000 batchs: 1662.823486328125
INFO:root:Train (Epoch 9): Loss/seq after 03050 batchs: 1658.1614990234375
INFO:root:Train (Epoch 9): Loss/seq after 03100 batchs: 1673.51416015625
INFO:root:Train (Epoch 9): Loss/seq after 03150 batchs: 1691.732177734375
INFO:root:Train (Epoch 9): Loss/seq after 03200 batchs: 1700.984619140625
INFO:root:Train (Epoch 9): Loss/seq after 03250 batchs: 1709.9322509765625
INFO:root:Train (Epoch 9): Loss/seq after 03300 batchs: 1707.199951171875
INFO:root:Train (Epoch 9): Loss/seq after 03350 batchs: 1703.761962890625
INFO:root:Train (Epoch 9): Loss/seq after 03400 batchs: 1688.593017578125
INFO:root:Train (Epoch 9): Loss/seq after 03450 batchs: 1678.7357177734375
INFO:root:Train (Epoch 9): Loss/seq after 03500 batchs: 1675.93505859375
INFO:root:Train (Epoch 9): Loss/seq after 03550 batchs: 1667.09130859375
INFO:root:Train (Epoch 9): Loss/seq after 03600 batchs: 1668.3330078125
INFO:root:Train (Epoch 9): Loss/seq after 03650 batchs: 1659.981689453125
INFO:root:Train (Epoch 9): Loss/seq after 03700 batchs: 1654.497802734375
INFO:root:Train (Epoch 9): Loss/seq after 03750 batchs: 1648.860595703125
INFO:root:Train (Epoch 9): Loss/seq after 03800 batchs: 1636.694580078125
INFO:root:Train (Epoch 9): Loss/seq after 03850 batchs: 1627.391845703125
INFO:root:Train (Epoch 9): Loss/seq after 03900 batchs: 1635.8966064453125
INFO:root:Train (Epoch 9): Loss/seq after 03950 batchs: 1642.5130615234375
INFO:root:Train (Epoch 9): Loss/seq after 04000 batchs: 1628.815185546875
INFO:root:Train (Epoch 9): Loss/seq after 04050 batchs: 1615.79150390625
INFO:root:Train (Epoch 9): Loss/seq after 04100 batchs: 1608.193603515625
INFO:root:Train (Epoch 9): Loss/seq after 04150 batchs: 1598.6102294921875
INFO:root:Train (Epoch 9): Loss/seq after 04200 batchs: 1590.7440185546875
INFO:root:Train (Epoch 9): Loss/seq after 04250 batchs: 1582.420654296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 9): Loss/seq after 00000 batches: 1005.2175903320312
INFO:root:# Valid (Epoch 9): Loss/seq after 00050 batches: 1147.036376953125
INFO:root:# Valid (Epoch 9): Loss/seq after 00100 batches: 1530.26806640625
INFO:root:# Valid (Epoch 9): Loss/seq after 00150 batches: 1256.485595703125
INFO:root:# Valid (Epoch 9): Loss/seq after 00200 batches: 1129.8692626953125
INFO:root:Artifacts: Make stick videos for epoch 9
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_9_on_20220422_212523.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_9_index_770_on_20220422_212523.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 10): Loss/seq after 00000 batchs: 4504.23828125
INFO:root:Train (Epoch 10): Loss/seq after 00050 batchs: 2294.490234375
INFO:root:Train (Epoch 10): Loss/seq after 00100 batchs: 2045.9246826171875
INFO:root:Train (Epoch 10): Loss/seq after 00150 batchs: 1788.1539306640625
INFO:root:Train (Epoch 10): Loss/seq after 00200 batchs: 1881.0125732421875
INFO:root:Train (Epoch 10): Loss/seq after 00250 batchs: 2019.4593505859375
INFO:root:Train (Epoch 10): Loss/seq after 00300 batchs: 1882.4903564453125
INFO:root:Train (Epoch 10): Loss/seq after 00350 batchs: 1741.1285400390625
INFO:root:Train (Epoch 10): Loss/seq after 00400 batchs: 1862.4822998046875
INFO:root:Train (Epoch 10): Loss/seq after 00450 batchs: 1753.520751953125
INFO:root:Train (Epoch 10): Loss/seq after 00500 batchs: 1783.8074951171875
INFO:root:Train (Epoch 10): Loss/seq after 00550 batchs: 1708.3089599609375
INFO:root:Train (Epoch 10): Loss/seq after 00600 batchs: 1663.2576904296875
INFO:root:Train (Epoch 10): Loss/seq after 00650 batchs: 1745.7705078125
INFO:root:Train (Epoch 10): Loss/seq after 00700 batchs: 1823.05712890625
INFO:root:Train (Epoch 10): Loss/seq after 00750 batchs: 1854.4930419921875
INFO:root:Train (Epoch 10): Loss/seq after 00800 batchs: 1863.7740478515625
INFO:root:Train (Epoch 10): Loss/seq after 00850 batchs: 1821.6026611328125
INFO:root:Train (Epoch 10): Loss/seq after 00900 batchs: 1829.6800537109375
INFO:root:Train (Epoch 10): Loss/seq after 00950 batchs: 1956.3218994140625
INFO:root:Train (Epoch 10): Loss/seq after 01000 batchs: 1969.979248046875
INFO:root:Train (Epoch 10): Loss/seq after 01050 batchs: 1932.6776123046875
INFO:root:Train (Epoch 10): Loss/seq after 01100 batchs: 1910.636962890625
INFO:root:Train (Epoch 10): Loss/seq after 01150 batchs: 1872.40625
INFO:root:Train (Epoch 10): Loss/seq after 01200 batchs: 1844.6888427734375
INFO:root:Train (Epoch 10): Loss/seq after 01250 batchs: 1828.360107421875
INFO:root:Train (Epoch 10): Loss/seq after 01300 batchs: 1831.392333984375
INFO:root:Train (Epoch 10): Loss/seq after 01350 batchs: 1821.1759033203125
INFO:root:Train (Epoch 10): Loss/seq after 01400 batchs: 1871.7984619140625
INFO:root:Train (Epoch 10): Loss/seq after 01450 batchs: 1846.4884033203125
INFO:root:Train (Epoch 10): Loss/seq after 01500 batchs: 1820.773681640625
INFO:root:Train (Epoch 10): Loss/seq after 01550 batchs: 1814.6363525390625
INFO:root:Train (Epoch 10): Loss/seq after 01600 batchs: 1783.95166015625
INFO:root:Train (Epoch 10): Loss/seq after 01650 batchs: 1767.999267578125
INFO:root:Train (Epoch 10): Loss/seq after 01700 batchs: 1747.1903076171875
INFO:root:Train (Epoch 10): Loss/seq after 01750 batchs: 1723.7965087890625
INFO:root:Train (Epoch 10): Loss/seq after 01800 batchs: 1699.1414794921875
INFO:root:Train (Epoch 10): Loss/seq after 01850 batchs: 1674.909423828125
INFO:root:Train (Epoch 10): Loss/seq after 01900 batchs: 1663.987548828125
INFO:root:Train (Epoch 10): Loss/seq after 01950 batchs: 1649.7412109375
INFO:root:Train (Epoch 10): Loss/seq after 02000 batchs: 1631.348876953125
INFO:root:Train (Epoch 10): Loss/seq after 02050 batchs: 1615.004150390625
INFO:root:Train (Epoch 10): Loss/seq after 02100 batchs: 1595.5423583984375
INFO:root:Train (Epoch 10): Loss/seq after 02150 batchs: 1577.815185546875
INFO:root:Train (Epoch 10): Loss/seq after 02200 batchs: 1559.094482421875
INFO:root:Train (Epoch 10): Loss/seq after 02250 batchs: 1559.7882080078125
INFO:root:Train (Epoch 10): Loss/seq after 02300 batchs: 1559.6435546875
INFO:root:Train (Epoch 10): Loss/seq after 02350 batchs: 1545.1290283203125
INFO:root:Train (Epoch 10): Loss/seq after 02400 batchs: 1535.36669921875
INFO:root:Train (Epoch 10): Loss/seq after 02450 batchs: 1517.7213134765625
INFO:root:Train (Epoch 10): Loss/seq after 02500 batchs: 1494.7359619140625
INFO:root:Train (Epoch 10): Loss/seq after 02550 batchs: 1480.099853515625
INFO:root:Train (Epoch 10): Loss/seq after 02600 batchs: 1475.7734375
INFO:root:Train (Epoch 10): Loss/seq after 02650 batchs: 1468.2052001953125
INFO:root:Train (Epoch 10): Loss/seq after 02700 batchs: 1461.46630859375
INFO:root:Train (Epoch 10): Loss/seq after 02750 batchs: 1489.9329833984375
INFO:root:Train (Epoch 10): Loss/seq after 02800 batchs: 1498.8408203125
INFO:root:Train (Epoch 10): Loss/seq after 02850 batchs: 1493.15771484375
INFO:root:Train (Epoch 10): Loss/seq after 02900 batchs: 1489.139404296875
INFO:root:Train (Epoch 10): Loss/seq after 02950 batchs: 1477.893310546875
INFO:root:Train (Epoch 10): Loss/seq after 03000 batchs: 1471.3984375
INFO:root:Train (Epoch 10): Loss/seq after 03050 batchs: 1469.950439453125
INFO:root:Train (Epoch 10): Loss/seq after 03100 batchs: 1486.129150390625
INFO:root:Train (Epoch 10): Loss/seq after 03150 batchs: 1506.48291015625
INFO:root:Train (Epoch 10): Loss/seq after 03200 batchs: 1517.9765625
INFO:root:Train (Epoch 10): Loss/seq after 03250 batchs: 1529.0989990234375
INFO:root:Train (Epoch 10): Loss/seq after 03300 batchs: 1527.56591796875
INFO:root:Train (Epoch 10): Loss/seq after 03350 batchs: 1525.624267578125
INFO:root:Train (Epoch 10): Loss/seq after 03400 batchs: 1512.93603515625
INFO:root:Train (Epoch 10): Loss/seq after 03450 batchs: 1503.6724853515625
INFO:root:Train (Epoch 10): Loss/seq after 03500 batchs: 1501.959716796875
INFO:root:Train (Epoch 10): Loss/seq after 03550 batchs: 1494.6134033203125
INFO:root:Train (Epoch 10): Loss/seq after 03600 batchs: 1497.7314453125
INFO:root:Train (Epoch 10): Loss/seq after 03650 batchs: 1490.744873046875
INFO:root:Train (Epoch 10): Loss/seq after 03700 batchs: 1487.7437744140625
INFO:root:Train (Epoch 10): Loss/seq after 03750 batchs: 1484.3428955078125
INFO:root:Train (Epoch 10): Loss/seq after 03800 batchs: 1474.3831787109375
INFO:root:Train (Epoch 10): Loss/seq after 03850 batchs: 1467.0787353515625
INFO:root:Train (Epoch 10): Loss/seq after 03900 batchs: 1474.6063232421875
INFO:root:Train (Epoch 10): Loss/seq after 03950 batchs: 1483.1212158203125
INFO:root:Train (Epoch 10): Loss/seq after 04000 batchs: 1470.9554443359375
INFO:root:Train (Epoch 10): Loss/seq after 04050 batchs: 1459.846923828125
INFO:root:Train (Epoch 10): Loss/seq after 04100 batchs: 1454.02978515625
INFO:root:Train (Epoch 10): Loss/seq after 04150 batchs: 1446.3414306640625
INFO:root:Train (Epoch 10): Loss/seq after 04200 batchs: 1439.395263671875
INFO:root:Train (Epoch 10): Loss/seq after 04250 batchs: 1432.7894287109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 10): Loss/seq after 00000 batches: 954.0530395507812
INFO:root:# Valid (Epoch 10): Loss/seq after 00050 batches: 1123.4539794921875
INFO:root:# Valid (Epoch 10): Loss/seq after 00100 batches: 1540.20849609375
INFO:root:# Valid (Epoch 10): Loss/seq after 00150 batches: 1276.8179931640625
INFO:root:# Valid (Epoch 10): Loss/seq after 00200 batches: 1155.6707763671875
INFO:root:Artifacts: Make stick videos for epoch 10
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_10_on_20220422_213026.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_10_index_464_on_20220422_213026.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 11): Loss/seq after 00000 batchs: 2575.02001953125
INFO:root:Train (Epoch 11): Loss/seq after 00050 batchs: 1952.5509033203125
INFO:root:Train (Epoch 11): Loss/seq after 00100 batchs: 1850.2171630859375
INFO:root:Train (Epoch 11): Loss/seq after 00150 batchs: 1637.2791748046875
INFO:root:Train (Epoch 11): Loss/seq after 00200 batchs: 1753.948974609375
INFO:root:Train (Epoch 11): Loss/seq after 00250 batchs: 1873.0902099609375
INFO:root:Train (Epoch 11): Loss/seq after 00300 batchs: 1751.8585205078125
INFO:root:Train (Epoch 11): Loss/seq after 00350 batchs: 1628.530029296875
INFO:root:Train (Epoch 11): Loss/seq after 00400 batchs: 1698.97900390625
INFO:root:Train (Epoch 11): Loss/seq after 00450 batchs: 1607.9798583984375
INFO:root:Train (Epoch 11): Loss/seq after 00500 batchs: 1637.8226318359375
INFO:root:Train (Epoch 11): Loss/seq after 00550 batchs: 1565.7637939453125
INFO:root:Train (Epoch 11): Loss/seq after 00600 batchs: 1526.3575439453125
INFO:root:Train (Epoch 11): Loss/seq after 00650 batchs: 1591.88671875
INFO:root:Train (Epoch 11): Loss/seq after 00700 batchs: 1677.6922607421875
INFO:root:Train (Epoch 11): Loss/seq after 00750 batchs: 1716.0675048828125
INFO:root:Train (Epoch 11): Loss/seq after 00800 batchs: 1695.36279296875
INFO:root:Train (Epoch 11): Loss/seq after 00850 batchs: 1655.220458984375
INFO:root:Train (Epoch 11): Loss/seq after 00900 batchs: 1663.8956298828125
INFO:root:Train (Epoch 11): Loss/seq after 00950 batchs: 1767.74951171875
INFO:root:Train (Epoch 11): Loss/seq after 01000 batchs: 1768.1844482421875
INFO:root:Train (Epoch 11): Loss/seq after 01050 batchs: 1741.4500732421875
INFO:root:Train (Epoch 11): Loss/seq after 01100 batchs: 1726.599365234375
INFO:root:Train (Epoch 11): Loss/seq after 01150 batchs: 1696.333251953125
INFO:root:Train (Epoch 11): Loss/seq after 01200 batchs: 1675.563232421875
INFO:root:Train (Epoch 11): Loss/seq after 01250 batchs: 1669.930908203125
INFO:root:Train (Epoch 11): Loss/seq after 01300 batchs: 1676.999755859375
INFO:root:Train (Epoch 11): Loss/seq after 01350 batchs: 1671.7760009765625
INFO:root:Train (Epoch 11): Loss/seq after 01400 batchs: 1725.0654296875
INFO:root:Train (Epoch 11): Loss/seq after 01450 batchs: 1704.0654296875
INFO:root:Train (Epoch 11): Loss/seq after 01500 batchs: 1683.2686767578125
INFO:root:Train (Epoch 11): Loss/seq after 01550 batchs: 1681.2095947265625
INFO:root:Train (Epoch 11): Loss/seq after 01600 batchs: 1654.957763671875
INFO:root:Train (Epoch 11): Loss/seq after 01650 batchs: 1644.807373046875
INFO:root:Train (Epoch 11): Loss/seq after 01700 batchs: 1627.22412109375
INFO:root:Train (Epoch 11): Loss/seq after 01750 batchs: 1607.2728271484375
INFO:root:Train (Epoch 11): Loss/seq after 01800 batchs: 1585.8812255859375
INFO:root:Train (Epoch 11): Loss/seq after 01850 batchs: 1564.62255859375
INFO:root:Train (Epoch 11): Loss/seq after 01900 batchs: 1556.6654052734375
INFO:root:Train (Epoch 11): Loss/seq after 01950 batchs: 1545.14404296875
INFO:root:Train (Epoch 11): Loss/seq after 02000 batchs: 1529.277587890625
INFO:root:Train (Epoch 11): Loss/seq after 02050 batchs: 1515.461669921875
INFO:root:Train (Epoch 11): Loss/seq after 02100 batchs: 1498.3599853515625
INFO:root:Train (Epoch 11): Loss/seq after 02150 batchs: 1482.917724609375
INFO:root:Train (Epoch 11): Loss/seq after 02200 batchs: 1466.35546875
INFO:root:Train (Epoch 11): Loss/seq after 02250 batchs: 1468.8118896484375
INFO:root:Train (Epoch 11): Loss/seq after 02300 batchs: 1470.9598388671875
INFO:root:Train (Epoch 11): Loss/seq after 02350 batchs: 1459.106689453125
INFO:root:Train (Epoch 11): Loss/seq after 02400 batchs: 1451.142822265625
INFO:root:Train (Epoch 11): Loss/seq after 02450 batchs: 1435.2552490234375
INFO:root:Train (Epoch 11): Loss/seq after 02500 batchs: 1413.919921875
INFO:root:Train (Epoch 11): Loss/seq after 02550 batchs: 1400.6392822265625
INFO:root:Train (Epoch 11): Loss/seq after 02600 batchs: 1396.487548828125
INFO:root:Train (Epoch 11): Loss/seq after 02650 batchs: 1388.8939208984375
INFO:root:Train (Epoch 11): Loss/seq after 02700 batchs: 1384.1229248046875
INFO:root:Train (Epoch 11): Loss/seq after 02750 batchs: 1416.6728515625
INFO:root:Train (Epoch 11): Loss/seq after 02800 batchs: 1427.3955078125
INFO:root:Train (Epoch 11): Loss/seq after 02850 batchs: 1425.7813720703125
INFO:root:Train (Epoch 11): Loss/seq after 02900 batchs: 1424.1209716796875
INFO:root:Train (Epoch 11): Loss/seq after 02950 batchs: 1414.171875
INFO:root:Train (Epoch 11): Loss/seq after 03000 batchs: 1408.720947265625
INFO:root:Train (Epoch 11): Loss/seq after 03050 batchs: 1408.2794189453125
INFO:root:Train (Epoch 11): Loss/seq after 03100 batchs: 1428.2764892578125
INFO:root:Train (Epoch 11): Loss/seq after 03150 batchs: 1449.50146484375
INFO:root:Train (Epoch 11): Loss/seq after 03200 batchs: 1461.7095947265625
INFO:root:Train (Epoch 11): Loss/seq after 03250 batchs: 1473.41748046875
INFO:root:Train (Epoch 11): Loss/seq after 03300 batchs: 1471.9029541015625
INFO:root:Train (Epoch 11): Loss/seq after 03350 batchs: 1471.1458740234375
INFO:root:Train (Epoch 11): Loss/seq after 03400 batchs: 1459.2108154296875
INFO:root:Train (Epoch 11): Loss/seq after 03450 batchs: 1451.8927001953125
INFO:root:Train (Epoch 11): Loss/seq after 03500 batchs: 1451.3680419921875
INFO:root:Train (Epoch 11): Loss/seq after 03550 batchs: 1444.5958251953125
INFO:root:Train (Epoch 11): Loss/seq after 03600 batchs: 1448.342529296875
INFO:root:Train (Epoch 11): Loss/seq after 03650 batchs: 1442.2755126953125
INFO:root:Train (Epoch 11): Loss/seq after 03700 batchs: 1440.0118408203125
INFO:root:Train (Epoch 11): Loss/seq after 03750 batchs: 1437.208740234375
INFO:root:Train (Epoch 11): Loss/seq after 03800 batchs: 1427.6815185546875
INFO:root:Train (Epoch 11): Loss/seq after 03850 batchs: 1420.8670654296875
INFO:root:Train (Epoch 11): Loss/seq after 03900 batchs: 1428.4295654296875
INFO:root:Train (Epoch 11): Loss/seq after 03950 batchs: 1436.93798828125
INFO:root:Train (Epoch 11): Loss/seq after 04000 batchs: 1425.3756103515625
INFO:root:Train (Epoch 11): Loss/seq after 04050 batchs: 1414.8509521484375
INFO:root:Train (Epoch 11): Loss/seq after 04100 batchs: 1409.400146484375
INFO:root:Train (Epoch 11): Loss/seq after 04150 batchs: 1402.242919921875
INFO:root:Train (Epoch 11): Loss/seq after 04200 batchs: 1396.0635986328125
INFO:root:Train (Epoch 11): Loss/seq after 04250 batchs: 1389.842041015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 11): Loss/seq after 00000 batches: 949.5154418945312
INFO:root:# Valid (Epoch 11): Loss/seq after 00050 batches: 1120.601806640625
INFO:root:# Valid (Epoch 11): Loss/seq after 00100 batches: 1485.5667724609375
INFO:root:# Valid (Epoch 11): Loss/seq after 00150 batches: 1243.4500732421875
INFO:root:# Valid (Epoch 11): Loss/seq after 00200 batches: 1127.361328125
INFO:root:Artifacts: Make stick videos for epoch 11
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_11_on_20220422_213512.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_11_index_24_on_20220422_213512.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 12): Loss/seq after 00000 batchs: 2634.330322265625
INFO:root:Train (Epoch 12): Loss/seq after 00050 batchs: 2028.359130859375
INFO:root:Train (Epoch 12): Loss/seq after 00100 batchs: 1931.9073486328125
INFO:root:Train (Epoch 12): Loss/seq after 00150 batchs: 1701.06689453125
INFO:root:Train (Epoch 12): Loss/seq after 00200 batchs: 1791.3743896484375
INFO:root:Train (Epoch 12): Loss/seq after 00250 batchs: 1900.482177734375
INFO:root:Train (Epoch 12): Loss/seq after 00300 batchs: 1780.0433349609375
INFO:root:Train (Epoch 12): Loss/seq after 00350 batchs: 1653.4554443359375
INFO:root:Train (Epoch 12): Loss/seq after 00400 batchs: 1721.9560546875
INFO:root:Train (Epoch 12): Loss/seq after 00450 batchs: 1631.0157470703125
INFO:root:Train (Epoch 12): Loss/seq after 00500 batchs: 1664.779296875
INFO:root:Train (Epoch 12): Loss/seq after 00550 batchs: 1590.6025390625
INFO:root:Train (Epoch 12): Loss/seq after 00600 batchs: 1548.6767578125
INFO:root:Train (Epoch 12): Loss/seq after 00650 batchs: 1612.297607421875
INFO:root:Train (Epoch 12): Loss/seq after 00700 batchs: 1698.861328125
INFO:root:Train (Epoch 12): Loss/seq after 00750 batchs: 1734.8116455078125
INFO:root:Train (Epoch 12): Loss/seq after 00800 batchs: 1712.8624267578125
INFO:root:Train (Epoch 12): Loss/seq after 00850 batchs: 1670.0665283203125
INFO:root:Train (Epoch 12): Loss/seq after 00900 batchs: 1687.0491943359375
INFO:root:Train (Epoch 12): Loss/seq after 00950 batchs: 1788.614013671875
INFO:root:Train (Epoch 12): Loss/seq after 01000 batchs: 1786.7843017578125
INFO:root:Train (Epoch 12): Loss/seq after 01050 batchs: 1758.7042236328125
INFO:root:Train (Epoch 12): Loss/seq after 01100 batchs: 1745.46044921875
INFO:root:Train (Epoch 12): Loss/seq after 01150 batchs: 1716.1505126953125
INFO:root:Train (Epoch 12): Loss/seq after 01200 batchs: 1694.1917724609375
INFO:root:Train (Epoch 12): Loss/seq after 01250 batchs: 1683.8521728515625
INFO:root:Train (Epoch 12): Loss/seq after 01300 batchs: 1689.8741455078125
INFO:root:Train (Epoch 12): Loss/seq after 01350 batchs: 1684.363037109375
INFO:root:Train (Epoch 12): Loss/seq after 01400 batchs: 1736.4039306640625
INFO:root:Train (Epoch 12): Loss/seq after 01450 batchs: 1720.624267578125
INFO:root:Train (Epoch 12): Loss/seq after 01500 batchs: 1698.993408203125
INFO:root:Train (Epoch 12): Loss/seq after 01550 batchs: 1696.4698486328125
INFO:root:Train (Epoch 12): Loss/seq after 01600 batchs: 1669.1177978515625
INFO:root:Train (Epoch 12): Loss/seq after 01650 batchs: 1657.4317626953125
INFO:root:Train (Epoch 12): Loss/seq after 01700 batchs: 1639.8428955078125
INFO:root:Train (Epoch 12): Loss/seq after 01750 batchs: 1619.46142578125
INFO:root:Train (Epoch 12): Loss/seq after 01800 batchs: 1597.633544921875
INFO:root:Train (Epoch 12): Loss/seq after 01850 batchs: 1575.9835205078125
INFO:root:Train (Epoch 12): Loss/seq after 01900 batchs: 1567.5919189453125
INFO:root:Train (Epoch 12): Loss/seq after 01950 batchs: 1555.6771240234375
INFO:root:Train (Epoch 12): Loss/seq after 02000 batchs: 1539.5947265625
INFO:root:Train (Epoch 12): Loss/seq after 02050 batchs: 1525.4658203125
INFO:root:Train (Epoch 12): Loss/seq after 02100 batchs: 1508.1099853515625
INFO:root:Train (Epoch 12): Loss/seq after 02150 batchs: 1492.4046630859375
INFO:root:Train (Epoch 12): Loss/seq after 02200 batchs: 1475.63037109375
INFO:root:Train (Epoch 12): Loss/seq after 02250 batchs: 1478.5921630859375
INFO:root:Train (Epoch 12): Loss/seq after 02300 batchs: 1483.3021240234375
INFO:root:Train (Epoch 12): Loss/seq after 02350 batchs: 1470.078369140625
INFO:root:Train (Epoch 12): Loss/seq after 02400 batchs: 1461.857177734375
INFO:root:Train (Epoch 12): Loss/seq after 02450 batchs: 1445.5689697265625
INFO:root:Train (Epoch 12): Loss/seq after 02500 batchs: 1424.0411376953125
INFO:root:Train (Epoch 12): Loss/seq after 02550 batchs: 1410.5672607421875
INFO:root:Train (Epoch 12): Loss/seq after 02600 batchs: 1406.4991455078125
INFO:root:Train (Epoch 12): Loss/seq after 02650 batchs: 1398.6617431640625
INFO:root:Train (Epoch 12): Loss/seq after 02700 batchs: 1393.4041748046875
INFO:root:Train (Epoch 12): Loss/seq after 02750 batchs: 1422.8773193359375
INFO:root:Train (Epoch 12): Loss/seq after 02800 batchs: 1431.0751953125
INFO:root:Train (Epoch 12): Loss/seq after 02850 batchs: 1426.4560546875
INFO:root:Train (Epoch 12): Loss/seq after 02900 batchs: 1422.5078125
INFO:root:Train (Epoch 12): Loss/seq after 02950 batchs: 1412.3323974609375
INFO:root:Train (Epoch 12): Loss/seq after 03000 batchs: 1406.9267578125
INFO:root:Train (Epoch 12): Loss/seq after 03050 batchs: 1406.5396728515625
INFO:root:Train (Epoch 12): Loss/seq after 03100 batchs: 1422.7337646484375
INFO:root:Train (Epoch 12): Loss/seq after 03150 batchs: 1443.4088134765625
INFO:root:Train (Epoch 12): Loss/seq after 03200 batchs: 1455.710693359375
INFO:root:Train (Epoch 12): Loss/seq after 03250 batchs: 1467.3260498046875
INFO:root:Train (Epoch 12): Loss/seq after 03300 batchs: 1469.0648193359375
INFO:root:Train (Epoch 12): Loss/seq after 03350 batchs: 1467.5330810546875
INFO:root:Train (Epoch 12): Loss/seq after 03400 batchs: 1455.6583251953125
INFO:root:Train (Epoch 12): Loss/seq after 03450 batchs: 1448.5875244140625
INFO:root:Train (Epoch 12): Loss/seq after 03500 batchs: 1446.809326171875
INFO:root:Train (Epoch 12): Loss/seq after 03550 batchs: 1440.7340087890625
INFO:root:Train (Epoch 12): Loss/seq after 03600 batchs: 1444.623779296875
INFO:root:Train (Epoch 12): Loss/seq after 03650 batchs: 1438.08935546875
INFO:root:Train (Epoch 12): Loss/seq after 03700 batchs: 1435.3787841796875
INFO:root:Train (Epoch 12): Loss/seq after 03750 batchs: 1432.73486328125
INFO:root:Train (Epoch 12): Loss/seq after 03800 batchs: 1423.434326171875
INFO:root:Train (Epoch 12): Loss/seq after 03850 batchs: 1416.9034423828125
INFO:root:Train (Epoch 12): Loss/seq after 03900 batchs: 1424.12939453125
INFO:root:Train (Epoch 12): Loss/seq after 03950 batchs: 1431.4697265625
INFO:root:Train (Epoch 12): Loss/seq after 04000 batchs: 1419.956787109375
INFO:root:Train (Epoch 12): Loss/seq after 04050 batchs: 1409.481689453125
INFO:root:Train (Epoch 12): Loss/seq after 04100 batchs: 1404.3656005859375
INFO:root:Train (Epoch 12): Loss/seq after 04150 batchs: 1397.2376708984375
INFO:root:Train (Epoch 12): Loss/seq after 04200 batchs: 1390.7008056640625
INFO:root:Train (Epoch 12): Loss/seq after 04250 batchs: 1384.6732177734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 12): Loss/seq after 00000 batches: 984.2757568359375
INFO:root:# Valid (Epoch 12): Loss/seq after 00050 batches: 1135.8759765625
INFO:root:# Valid (Epoch 12): Loss/seq after 00100 batches: 1490.1239013671875
INFO:root:# Valid (Epoch 12): Loss/seq after 00150 batches: 1230.843017578125
INFO:root:# Valid (Epoch 12): Loss/seq after 00200 batches: 1113.6346435546875
INFO:root:Artifacts: Make stick videos for epoch 12
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_12_on_20220422_213958.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_12_index_73_on_20220422_213958.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 13): Loss/seq after 00000 batchs: 2658.329833984375
INFO:root:Train (Epoch 13): Loss/seq after 00050 batchs: 1804.0308837890625
INFO:root:Train (Epoch 13): Loss/seq after 00100 batchs: 1780.1700439453125
INFO:root:Train (Epoch 13): Loss/seq after 00150 batchs: 1583.8548583984375
INFO:root:Train (Epoch 13): Loss/seq after 00200 batchs: 1718.487548828125
INFO:root:Train (Epoch 13): Loss/seq after 00250 batchs: 1867.744873046875
INFO:root:Train (Epoch 13): Loss/seq after 00300 batchs: 1744.06640625
INFO:root:Train (Epoch 13): Loss/seq after 00350 batchs: 1621.0380859375
INFO:root:Train (Epoch 13): Loss/seq after 00400 batchs: 1680.9033203125
INFO:root:Train (Epoch 13): Loss/seq after 00450 batchs: 1591.9327392578125
INFO:root:Train (Epoch 13): Loss/seq after 00500 batchs: 1634.29052734375
INFO:root:Train (Epoch 13): Loss/seq after 00550 batchs: 1560.63916015625
INFO:root:Train (Epoch 13): Loss/seq after 00600 batchs: 1520.9039306640625
INFO:root:Train (Epoch 13): Loss/seq after 00650 batchs: 1586.64111328125
INFO:root:Train (Epoch 13): Loss/seq after 00700 batchs: 1676.7113037109375
INFO:root:Train (Epoch 13): Loss/seq after 00750 batchs: 1712.190673828125
INFO:root:Train (Epoch 13): Loss/seq after 00800 batchs: 1690.7225341796875
INFO:root:Train (Epoch 13): Loss/seq after 00850 batchs: 1649.380859375
INFO:root:Train (Epoch 13): Loss/seq after 00900 batchs: 1671.224853515625
INFO:root:Train (Epoch 13): Loss/seq after 00950 batchs: 1772.3516845703125
INFO:root:Train (Epoch 13): Loss/seq after 01000 batchs: 1770.64794921875
INFO:root:Train (Epoch 13): Loss/seq after 01050 batchs: 1744.03271484375
INFO:root:Train (Epoch 13): Loss/seq after 01100 batchs: 1726.8731689453125
INFO:root:Train (Epoch 13): Loss/seq after 01150 batchs: 1700.6712646484375
INFO:root:Train (Epoch 13): Loss/seq after 01200 batchs: 1680.1895751953125
INFO:root:Train (Epoch 13): Loss/seq after 01250 batchs: 1675.7021484375
INFO:root:Train (Epoch 13): Loss/seq after 01300 batchs: 1682.2864990234375
INFO:root:Train (Epoch 13): Loss/seq after 01350 batchs: 1676.8731689453125
INFO:root:Train (Epoch 13): Loss/seq after 01400 batchs: 1730.284423828125
INFO:root:Train (Epoch 13): Loss/seq after 01450 batchs: 1715.5361328125
INFO:root:Train (Epoch 13): Loss/seq after 01500 batchs: 1694.220703125
INFO:root:Train (Epoch 13): Loss/seq after 01550 batchs: 1695.3302001953125
INFO:root:Train (Epoch 13): Loss/seq after 01600 batchs: 1669.1649169921875
INFO:root:Train (Epoch 13): Loss/seq after 01650 batchs: 1658.8988037109375
INFO:root:Train (Epoch 13): Loss/seq after 01700 batchs: 1641.58837890625
INFO:root:Train (Epoch 13): Loss/seq after 01750 batchs: 1621.302001953125
INFO:root:Train (Epoch 13): Loss/seq after 01800 batchs: 1599.5037841796875
INFO:root:Train (Epoch 13): Loss/seq after 01850 batchs: 1577.7384033203125
INFO:root:Train (Epoch 13): Loss/seq after 01900 batchs: 1569.3873291015625
INFO:root:Train (Epoch 13): Loss/seq after 01950 batchs: 1557.4171142578125
INFO:root:Train (Epoch 13): Loss/seq after 02000 batchs: 1541.293212890625
INFO:root:Train (Epoch 13): Loss/seq after 02050 batchs: 1526.991943359375
INFO:root:Train (Epoch 13): Loss/seq after 02100 batchs: 1509.6195068359375
INFO:root:Train (Epoch 13): Loss/seq after 02150 batchs: 1493.9024658203125
INFO:root:Train (Epoch 13): Loss/seq after 02200 batchs: 1477.10107421875
INFO:root:Train (Epoch 13): Loss/seq after 02250 batchs: 1482.9896240234375
INFO:root:Train (Epoch 13): Loss/seq after 02300 batchs: 1488.159423828125
INFO:root:Train (Epoch 13): Loss/seq after 02350 batchs: 1475.9381103515625
INFO:root:Train (Epoch 13): Loss/seq after 02400 batchs: 1468.099609375
INFO:root:Train (Epoch 13): Loss/seq after 02450 batchs: 1452.2322998046875
INFO:root:Train (Epoch 13): Loss/seq after 02500 batchs: 1430.5987548828125
INFO:root:Train (Epoch 13): Loss/seq after 02550 batchs: 1420.8446044921875
INFO:root:Train (Epoch 13): Loss/seq after 02600 batchs: 1418.486083984375
INFO:root:Train (Epoch 13): Loss/seq after 02650 batchs: 1412.14990234375
INFO:root:Train (Epoch 13): Loss/seq after 02700 batchs: 1412.6490478515625
INFO:root:Train (Epoch 13): Loss/seq after 02750 batchs: 1445.2718505859375
INFO:root:Train (Epoch 13): Loss/seq after 02800 batchs: 1454.452392578125
INFO:root:Train (Epoch 13): Loss/seq after 02850 batchs: 1452.6832275390625
INFO:root:Train (Epoch 13): Loss/seq after 02900 batchs: 1450.4765625
INFO:root:Train (Epoch 13): Loss/seq after 02950 batchs: 1441.2188720703125
INFO:root:Train (Epoch 13): Loss/seq after 03000 batchs: 1435.4979248046875
INFO:root:Train (Epoch 13): Loss/seq after 03050 batchs: 1434.5693359375
INFO:root:Train (Epoch 13): Loss/seq after 03100 batchs: 1456.784423828125
INFO:root:Train (Epoch 13): Loss/seq after 03150 batchs: 1484.004150390625
INFO:root:Train (Epoch 13): Loss/seq after 03200 batchs: 1495.7635498046875
INFO:root:Train (Epoch 13): Loss/seq after 03250 batchs: 1507.1650390625
INFO:root:Train (Epoch 13): Loss/seq after 03300 batchs: 1507.8709716796875
INFO:root:Train (Epoch 13): Loss/seq after 03350 batchs: 1507.127197265625
INFO:root:Train (Epoch 13): Loss/seq after 03400 batchs: 1494.93896484375
INFO:root:Train (Epoch 13): Loss/seq after 03450 batchs: 1487.400390625
INFO:root:Train (Epoch 13): Loss/seq after 03500 batchs: 1491.0545654296875
INFO:root:Train (Epoch 13): Loss/seq after 03550 batchs: 1484.9713134765625
INFO:root:Train (Epoch 13): Loss/seq after 03600 batchs: 1489.00244140625
INFO:root:Train (Epoch 13): Loss/seq after 03650 batchs: 1483.01953125
INFO:root:Train (Epoch 13): Loss/seq after 03700 batchs: 1479.92333984375
INFO:root:Train (Epoch 13): Loss/seq after 03750 batchs: 1476.6363525390625
INFO:root:Train (Epoch 13): Loss/seq after 03800 batchs: 1466.7518310546875
INFO:root:Train (Epoch 13): Loss/seq after 03850 batchs: 1459.6446533203125
INFO:root:Train (Epoch 13): Loss/seq after 03900 batchs: 1477.927978515625
INFO:root:Train (Epoch 13): Loss/seq after 03950 batchs: 1485.4776611328125
INFO:root:Train (Epoch 13): Loss/seq after 04000 batchs: 1474.5595703125
INFO:root:Train (Epoch 13): Loss/seq after 04050 batchs: 1463.675537109375
INFO:root:Train (Epoch 13): Loss/seq after 04100 batchs: 1458.0693359375
INFO:root:Train (Epoch 13): Loss/seq after 04150 batchs: 1450.238037109375
INFO:root:Train (Epoch 13): Loss/seq after 04200 batchs: 1444.7791748046875
INFO:root:Train (Epoch 13): Loss/seq after 04250 batchs: 1438.1314697265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 13): Loss/seq after 00000 batches: 1040.1470947265625
INFO:root:# Valid (Epoch 13): Loss/seq after 00050 batches: 1163.03271484375
INFO:root:# Valid (Epoch 13): Loss/seq after 00100 batches: 1529.59228515625
INFO:root:# Valid (Epoch 13): Loss/seq after 00150 batches: 1244.8609619140625
INFO:root:# Valid (Epoch 13): Loss/seq after 00200 batches: 1115.48974609375
INFO:root:Artifacts: Make stick videos for epoch 13
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_13_on_20220422_214458.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_13_index_442_on_20220422_214458.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 14): Loss/seq after 00000 batchs: 2531.315673828125
INFO:root:Train (Epoch 14): Loss/seq after 00050 batchs: 1968.92529296875
INFO:root:Train (Epoch 14): Loss/seq after 00100 batchs: 2022.7969970703125
INFO:root:Train (Epoch 14): Loss/seq after 00150 batchs: 1766.5247802734375
INFO:root:Train (Epoch 14): Loss/seq after 00200 batchs: 1859.8358154296875
INFO:root:Train (Epoch 14): Loss/seq after 00250 batchs: 1959.138427734375
INFO:root:Train (Epoch 14): Loss/seq after 00300 batchs: 1830.8597412109375
INFO:root:Train (Epoch 14): Loss/seq after 00350 batchs: 1701.986083984375
INFO:root:Train (Epoch 14): Loss/seq after 00400 batchs: 1769.2818603515625
INFO:root:Train (Epoch 14): Loss/seq after 00450 batchs: 1671.8580322265625
INFO:root:Train (Epoch 14): Loss/seq after 00500 batchs: 1704.9359130859375
INFO:root:Train (Epoch 14): Loss/seq after 00550 batchs: 1628.7149658203125
INFO:root:Train (Epoch 14): Loss/seq after 00600 batchs: 1587.0
INFO:root:Train (Epoch 14): Loss/seq after 00650 batchs: 1653.8427734375
INFO:root:Train (Epoch 14): Loss/seq after 00700 batchs: 1743.83935546875
INFO:root:Train (Epoch 14): Loss/seq after 00750 batchs: 1775.18896484375
INFO:root:Train (Epoch 14): Loss/seq after 00800 batchs: 1750.1273193359375
INFO:root:Train (Epoch 14): Loss/seq after 00850 batchs: 1704.2867431640625
INFO:root:Train (Epoch 14): Loss/seq after 00900 batchs: 1709.04833984375
INFO:root:Train (Epoch 14): Loss/seq after 00950 batchs: 1817.125244140625
INFO:root:Train (Epoch 14): Loss/seq after 01000 batchs: 1817.4608154296875
INFO:root:Train (Epoch 14): Loss/seq after 01050 batchs: 1793.20849609375
INFO:root:Train (Epoch 14): Loss/seq after 01100 batchs: 1789.7264404296875
INFO:root:Train (Epoch 14): Loss/seq after 01150 batchs: 1757.2344970703125
INFO:root:Train (Epoch 14): Loss/seq after 01200 batchs: 1733.06005859375
INFO:root:Train (Epoch 14): Loss/seq after 01250 batchs: 1720.679443359375
INFO:root:Train (Epoch 14): Loss/seq after 01300 batchs: 1725.6796875
INFO:root:Train (Epoch 14): Loss/seq after 01350 batchs: 1718.379638671875
INFO:root:Train (Epoch 14): Loss/seq after 01400 batchs: 1771.9498291015625
INFO:root:Train (Epoch 14): Loss/seq after 01450 batchs: 1750.0523681640625
INFO:root:Train (Epoch 14): Loss/seq after 01500 batchs: 1727.5
INFO:root:Train (Epoch 14): Loss/seq after 01550 batchs: 1725.0926513671875
INFO:root:Train (Epoch 14): Loss/seq after 01600 batchs: 1696.849853515625
INFO:root:Train (Epoch 14): Loss/seq after 01650 batchs: 1685.3912353515625
INFO:root:Train (Epoch 14): Loss/seq after 01700 batchs: 1666.628662109375
INFO:root:Train (Epoch 14): Loss/seq after 01750 batchs: 1645.51904296875
INFO:root:Train (Epoch 14): Loss/seq after 01800 batchs: 1623.05126953125
INFO:root:Train (Epoch 14): Loss/seq after 01850 batchs: 1600.63720703125
INFO:root:Train (Epoch 14): Loss/seq after 01900 batchs: 1591.6602783203125
INFO:root:Train (Epoch 14): Loss/seq after 01950 batchs: 1579.2010498046875
INFO:root:Train (Epoch 14): Loss/seq after 02000 batchs: 1562.477783203125
INFO:root:Train (Epoch 14): Loss/seq after 02050 batchs: 1547.663818359375
INFO:root:Train (Epoch 14): Loss/seq after 02100 batchs: 1529.782958984375
INFO:root:Train (Epoch 14): Loss/seq after 02150 batchs: 1513.562255859375
INFO:root:Train (Epoch 14): Loss/seq after 02200 batchs: 1496.3280029296875
INFO:root:Train (Epoch 14): Loss/seq after 02250 batchs: 1499.277587890625
INFO:root:Train (Epoch 14): Loss/seq after 02300 batchs: 1499.0692138671875
INFO:root:Train (Epoch 14): Loss/seq after 02350 batchs: 1485.91455078125
INFO:root:Train (Epoch 14): Loss/seq after 02400 batchs: 1477.740234375
INFO:root:Train (Epoch 14): Loss/seq after 02450 batchs: 1461.3060302734375
INFO:root:Train (Epoch 14): Loss/seq after 02500 batchs: 1439.513671875
INFO:root:Train (Epoch 14): Loss/seq after 02550 batchs: 1427.48828125
INFO:root:Train (Epoch 14): Loss/seq after 02600 batchs: 1424.333984375
INFO:root:Train (Epoch 14): Loss/seq after 02650 batchs: 1417.35546875
INFO:root:Train (Epoch 14): Loss/seq after 02700 batchs: 1413.2496337890625
INFO:root:Train (Epoch 14): Loss/seq after 02750 batchs: 1443.345947265625
INFO:root:Train (Epoch 14): Loss/seq after 02800 batchs: 1451.421142578125
INFO:root:Train (Epoch 14): Loss/seq after 02850 batchs: 1446.3873291015625
INFO:root:Train (Epoch 14): Loss/seq after 02900 batchs: 1442.773193359375
INFO:root:Train (Epoch 14): Loss/seq after 02950 batchs: 1432.3878173828125
INFO:root:Train (Epoch 14): Loss/seq after 03000 batchs: 1426.6983642578125
INFO:root:Train (Epoch 14): Loss/seq after 03050 batchs: 1425.9404296875
INFO:root:Train (Epoch 14): Loss/seq after 03100 batchs: 1441.12109375
INFO:root:Train (Epoch 14): Loss/seq after 03150 batchs: 1461.8680419921875
INFO:root:Train (Epoch 14): Loss/seq after 03200 batchs: 1474.0062255859375
INFO:root:Train (Epoch 14): Loss/seq after 03250 batchs: 1485.50830078125
INFO:root:Train (Epoch 14): Loss/seq after 03300 batchs: 1483.5107421875
INFO:root:Train (Epoch 14): Loss/seq after 03350 batchs: 1481.4466552734375
INFO:root:Train (Epoch 14): Loss/seq after 03400 batchs: 1469.4381103515625
INFO:root:Train (Epoch 14): Loss/seq after 03450 batchs: 1461.5360107421875
INFO:root:Train (Epoch 14): Loss/seq after 03500 batchs: 1461.48486328125
INFO:root:Train (Epoch 14): Loss/seq after 03550 batchs: 1454.453125
INFO:root:Train (Epoch 14): Loss/seq after 03600 batchs: 1457.736328125
INFO:root:Train (Epoch 14): Loss/seq after 03650 batchs: 1450.8436279296875
INFO:root:Train (Epoch 14): Loss/seq after 03700 batchs: 1448.028564453125
INFO:root:Train (Epoch 14): Loss/seq after 03750 batchs: 1445.013671875
INFO:root:Train (Epoch 14): Loss/seq after 03800 batchs: 1435.579345703125
INFO:root:Train (Epoch 14): Loss/seq after 03850 batchs: 1428.778076171875
INFO:root:Train (Epoch 14): Loss/seq after 03900 batchs: 1437.7113037109375
INFO:root:Train (Epoch 14): Loss/seq after 03950 batchs: 1451.9439697265625
INFO:root:Train (Epoch 14): Loss/seq after 04000 batchs: 1440.2784423828125
INFO:root:Train (Epoch 14): Loss/seq after 04050 batchs: 1429.5867919921875
INFO:root:Train (Epoch 14): Loss/seq after 04100 batchs: 1424.1644287109375
INFO:root:Train (Epoch 14): Loss/seq after 04150 batchs: 1416.798583984375
INFO:root:Train (Epoch 14): Loss/seq after 04200 batchs: 1410.689453125
INFO:root:Train (Epoch 14): Loss/seq after 04250 batchs: 1404.5274658203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 14): Loss/seq after 00000 batches: 991.4566040039062
INFO:root:# Valid (Epoch 14): Loss/seq after 00050 batches: 1142.4888916015625
INFO:root:# Valid (Epoch 14): Loss/seq after 00100 batches: 1508.9085693359375
INFO:root:# Valid (Epoch 14): Loss/seq after 00150 batches: 1238.001953125
INFO:root:# Valid (Epoch 14): Loss/seq after 00200 batches: 1115.4344482421875
INFO:root:Artifacts: Make stick videos for epoch 14
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_14_on_20220422_214944.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_14_index_1337_on_20220422_214944.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 15): Loss/seq after 00000 batchs: 2614.448974609375
INFO:root:Train (Epoch 15): Loss/seq after 00050 batchs: 1914.68017578125
INFO:root:Train (Epoch 15): Loss/seq after 00100 batchs: 1807.8189697265625
INFO:root:Train (Epoch 15): Loss/seq after 00150 batchs: 1609.174072265625
INFO:root:Train (Epoch 15): Loss/seq after 00200 batchs: 1728.27978515625
INFO:root:Train (Epoch 15): Loss/seq after 00250 batchs: 1835.1307373046875
INFO:root:Train (Epoch 15): Loss/seq after 00300 batchs: 1716.6934814453125
INFO:root:Train (Epoch 15): Loss/seq after 00350 batchs: 1601.572998046875
INFO:root:Train (Epoch 15): Loss/seq after 00400 batchs: 1666.1103515625
INFO:root:Train (Epoch 15): Loss/seq after 00450 batchs: 1578.9649658203125
INFO:root:Train (Epoch 15): Loss/seq after 00500 batchs: 1611.9874267578125
INFO:root:Train (Epoch 15): Loss/seq after 00550 batchs: 1542.9754638671875
INFO:root:Train (Epoch 15): Loss/seq after 00600 batchs: 1504.4168701171875
INFO:root:Train (Epoch 15): Loss/seq after 00650 batchs: 1568.3182373046875
INFO:root:Train (Epoch 15): Loss/seq after 00700 batchs: 1657.959228515625
INFO:root:Train (Epoch 15): Loss/seq after 00750 batchs: 1694.030517578125
INFO:root:Train (Epoch 15): Loss/seq after 00800 batchs: 1673.9278564453125
INFO:root:Train (Epoch 15): Loss/seq after 00850 batchs: 1633.2208251953125
INFO:root:Train (Epoch 15): Loss/seq after 00900 batchs: 1641.0384521484375
INFO:root:Train (Epoch 15): Loss/seq after 00950 batchs: 1743.3226318359375
INFO:root:Train (Epoch 15): Loss/seq after 01000 batchs: 1744.140869140625
INFO:root:Train (Epoch 15): Loss/seq after 01050 batchs: 1719.28759765625
INFO:root:Train (Epoch 15): Loss/seq after 01100 batchs: 1721.476318359375
INFO:root:Train (Epoch 15): Loss/seq after 01150 batchs: 1696.09765625
INFO:root:Train (Epoch 15): Loss/seq after 01200 batchs: 1674.95703125
INFO:root:Train (Epoch 15): Loss/seq after 01250 batchs: 1676.330078125
INFO:root:Train (Epoch 15): Loss/seq after 01300 batchs: 1684.8243408203125
INFO:root:Train (Epoch 15): Loss/seq after 01350 batchs: 1680.19189453125
INFO:root:Train (Epoch 15): Loss/seq after 01400 batchs: 1731.77490234375
INFO:root:Train (Epoch 15): Loss/seq after 01450 batchs: 1712.7559814453125
INFO:root:Train (Epoch 15): Loss/seq after 01500 batchs: 1691.48193359375
INFO:root:Train (Epoch 15): Loss/seq after 01550 batchs: 1690.1888427734375
INFO:root:Train (Epoch 15): Loss/seq after 01600 batchs: 1663.41357421875
INFO:root:Train (Epoch 15): Loss/seq after 01650 batchs: 1650.6002197265625
INFO:root:Train (Epoch 15): Loss/seq after 01700 batchs: 1632.6385498046875
INFO:root:Train (Epoch 15): Loss/seq after 01750 batchs: 1612.5621337890625
INFO:root:Train (Epoch 15): Loss/seq after 01800 batchs: 1591.0037841796875
INFO:root:Train (Epoch 15): Loss/seq after 01850 batchs: 1569.4293212890625
INFO:root:Train (Epoch 15): Loss/seq after 01900 batchs: 1561.20751953125
INFO:root:Train (Epoch 15): Loss/seq after 01950 batchs: 1549.4609375
INFO:root:Train (Epoch 15): Loss/seq after 02000 batchs: 1533.49609375
INFO:root:Train (Epoch 15): Loss/seq after 02050 batchs: 1519.4371337890625
INFO:root:Train (Epoch 15): Loss/seq after 02100 batchs: 1502.2281494140625
INFO:root:Train (Epoch 15): Loss/seq after 02150 batchs: 1486.6993408203125
INFO:root:Train (Epoch 15): Loss/seq after 02200 batchs: 1470.068359375
INFO:root:Train (Epoch 15): Loss/seq after 02250 batchs: 1470.8238525390625
INFO:root:Train (Epoch 15): Loss/seq after 02300 batchs: 1471.0692138671875
INFO:root:Train (Epoch 15): Loss/seq after 02350 batchs: 1458.2916259765625
INFO:root:Train (Epoch 15): Loss/seq after 02400 batchs: 1450.4019775390625
INFO:root:Train (Epoch 15): Loss/seq after 02450 batchs: 1434.0423583984375
INFO:root:Train (Epoch 15): Loss/seq after 02500 batchs: 1412.822021484375
INFO:root:Train (Epoch 15): Loss/seq after 02550 batchs: 1399.6441650390625
INFO:root:Train (Epoch 15): Loss/seq after 02600 batchs: 1396.823486328125
INFO:root:Train (Epoch 15): Loss/seq after 02650 batchs: 1389.7423095703125
INFO:root:Train (Epoch 15): Loss/seq after 02700 batchs: 1384.83154296875
INFO:root:Train (Epoch 15): Loss/seq after 02750 batchs: 1413.85205078125
INFO:root:Train (Epoch 15): Loss/seq after 02800 batchs: 1421.494384765625
INFO:root:Train (Epoch 15): Loss/seq after 02850 batchs: 1416.5889892578125
INFO:root:Train (Epoch 15): Loss/seq after 02900 batchs: 1412.0802001953125
INFO:root:Train (Epoch 15): Loss/seq after 02950 batchs: 1401.8614501953125
INFO:root:Train (Epoch 15): Loss/seq after 03000 batchs: 1396.6395263671875
INFO:root:Train (Epoch 15): Loss/seq after 03050 batchs: 1396.4151611328125
INFO:root:Train (Epoch 15): Loss/seq after 03100 batchs: 1411.92919921875
INFO:root:Train (Epoch 15): Loss/seq after 03150 batchs: 1431.924072265625
INFO:root:Train (Epoch 15): Loss/seq after 03200 batchs: 1444.543701171875
INFO:root:Train (Epoch 15): Loss/seq after 03250 batchs: 1456.3895263671875
INFO:root:Train (Epoch 15): Loss/seq after 03300 batchs: 1457.4239501953125
INFO:root:Train (Epoch 15): Loss/seq after 03350 batchs: 1457.0731201171875
INFO:root:Train (Epoch 15): Loss/seq after 03400 batchs: 1445.4080810546875
INFO:root:Train (Epoch 15): Loss/seq after 03450 batchs: 1437.768798828125
INFO:root:Train (Epoch 15): Loss/seq after 03500 batchs: 1437.474853515625
INFO:root:Train (Epoch 15): Loss/seq after 03550 batchs: 1430.8919677734375
INFO:root:Train (Epoch 15): Loss/seq after 03600 batchs: 1434.780029296875
INFO:root:Train (Epoch 15): Loss/seq after 03650 batchs: 1428.3499755859375
INFO:root:Train (Epoch 15): Loss/seq after 03700 batchs: 1425.859130859375
INFO:root:Train (Epoch 15): Loss/seq after 03750 batchs: 1423.0975341796875
INFO:root:Train (Epoch 15): Loss/seq after 03800 batchs: 1413.9512939453125
INFO:root:Train (Epoch 15): Loss/seq after 03850 batchs: 1407.3980712890625
INFO:root:Train (Epoch 15): Loss/seq after 03900 batchs: 1416.4464111328125
INFO:root:Train (Epoch 15): Loss/seq after 03950 batchs: 1439.2081298828125
INFO:root:Train (Epoch 15): Loss/seq after 04000 batchs: 1428.21533203125
INFO:root:Train (Epoch 15): Loss/seq after 04050 batchs: 1417.696533203125
INFO:root:Train (Epoch 15): Loss/seq after 04100 batchs: 1412.3455810546875
INFO:root:Train (Epoch 15): Loss/seq after 04150 batchs: 1405.103271484375
INFO:root:Train (Epoch 15): Loss/seq after 04200 batchs: 1399.616455078125
INFO:root:Train (Epoch 15): Loss/seq after 04250 batchs: 1393.572265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 15): Loss/seq after 00000 batches: 1028.950439453125
INFO:root:# Valid (Epoch 15): Loss/seq after 00050 batches: 1160.03564453125
INFO:root:# Valid (Epoch 15): Loss/seq after 00100 batches: 1529.6871337890625
INFO:root:# Valid (Epoch 15): Loss/seq after 00150 batches: 1247.86669921875
INFO:root:# Valid (Epoch 15): Loss/seq after 00200 batches: 1118.7508544921875
INFO:root:Artifacts: Make stick videos for epoch 15
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_15_on_20220422_215452.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_15_index_1457_on_20220422_215452.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 16): Loss/seq after 00000 batchs: 5507.48388671875
INFO:root:Train (Epoch 16): Loss/seq after 00050 batchs: 1879.8350830078125
INFO:root:Train (Epoch 16): Loss/seq after 00100 batchs: 1762.3843994140625
INFO:root:Train (Epoch 16): Loss/seq after 00150 batchs: 1579.068115234375
INFO:root:Train (Epoch 16): Loss/seq after 00200 batchs: 1697.0841064453125
INFO:root:Train (Epoch 16): Loss/seq after 00250 batchs: 1804.6197509765625
INFO:root:Train (Epoch 16): Loss/seq after 00300 batchs: 1693.8515625
INFO:root:Train (Epoch 16): Loss/seq after 00350 batchs: 1578.052001953125
INFO:root:Train (Epoch 16): Loss/seq after 00400 batchs: 1638.3134765625
INFO:root:Train (Epoch 16): Loss/seq after 00450 batchs: 1554.0247802734375
INFO:root:Train (Epoch 16): Loss/seq after 00500 batchs: 1588.8389892578125
INFO:root:Train (Epoch 16): Loss/seq after 00550 batchs: 1520.116943359375
INFO:root:Train (Epoch 16): Loss/seq after 00600 batchs: 1483.0186767578125
INFO:root:Train (Epoch 16): Loss/seq after 00650 batchs: 1549.569580078125
INFO:root:Train (Epoch 16): Loss/seq after 00700 batchs: 1641.568115234375
INFO:root:Train (Epoch 16): Loss/seq after 00750 batchs: 1679.1888427734375
INFO:root:Train (Epoch 16): Loss/seq after 00800 batchs: 1659.642578125
INFO:root:Train (Epoch 16): Loss/seq after 00850 batchs: 1619.76416015625
INFO:root:Train (Epoch 16): Loss/seq after 00900 batchs: 1619.7315673828125
INFO:root:Train (Epoch 16): Loss/seq after 00950 batchs: 1718.3551025390625
INFO:root:Train (Epoch 16): Loss/seq after 01000 batchs: 1718.0335693359375
INFO:root:Train (Epoch 16): Loss/seq after 01050 batchs: 1692.1007080078125
INFO:root:Train (Epoch 16): Loss/seq after 01100 batchs: 1677.646484375
INFO:root:Train (Epoch 16): Loss/seq after 01150 batchs: 1648.4166259765625
INFO:root:Train (Epoch 16): Loss/seq after 01200 batchs: 1629.186279296875
INFO:root:Train (Epoch 16): Loss/seq after 01250 batchs: 1623.357666015625
INFO:root:Train (Epoch 16): Loss/seq after 01300 batchs: 1632.1790771484375
INFO:root:Train (Epoch 16): Loss/seq after 01350 batchs: 1628.978271484375
INFO:root:Train (Epoch 16): Loss/seq after 01400 batchs: 1682.037109375
INFO:root:Train (Epoch 16): Loss/seq after 01450 batchs: 1662.9937744140625
INFO:root:Train (Epoch 16): Loss/seq after 01500 batchs: 1643.344970703125
INFO:root:Train (Epoch 16): Loss/seq after 01550 batchs: 1639.8846435546875
INFO:root:Train (Epoch 16): Loss/seq after 01600 batchs: 1614.5810546875
INFO:root:Train (Epoch 16): Loss/seq after 01650 batchs: 1603.8978271484375
INFO:root:Train (Epoch 16): Loss/seq after 01700 batchs: 1587.2518310546875
INFO:root:Train (Epoch 16): Loss/seq after 01750 batchs: 1568.3170166015625
INFO:root:Train (Epoch 16): Loss/seq after 01800 batchs: 1547.9466552734375
INFO:root:Train (Epoch 16): Loss/seq after 01850 batchs: 1527.589599609375
INFO:root:Train (Epoch 16): Loss/seq after 01900 batchs: 1520.467529296875
INFO:root:Train (Epoch 16): Loss/seq after 01950 batchs: 1509.773193359375
INFO:root:Train (Epoch 16): Loss/seq after 02000 batchs: 1494.736083984375
INFO:root:Train (Epoch 16): Loss/seq after 02050 batchs: 1481.5882568359375
INFO:root:Train (Epoch 16): Loss/seq after 02100 batchs: 1465.29443359375
INFO:root:Train (Epoch 16): Loss/seq after 02150 batchs: 1450.5733642578125
INFO:root:Train (Epoch 16): Loss/seq after 02200 batchs: 1434.7376708984375
INFO:root:Train (Epoch 16): Loss/seq after 02250 batchs: 1435.7662353515625
INFO:root:Train (Epoch 16): Loss/seq after 02300 batchs: 1436.8397216796875
INFO:root:Train (Epoch 16): Loss/seq after 02350 batchs: 1424.1033935546875
INFO:root:Train (Epoch 16): Loss/seq after 02400 batchs: 1416.7957763671875
INFO:root:Train (Epoch 16): Loss/seq after 02450 batchs: 1401.106201171875
INFO:root:Train (Epoch 16): Loss/seq after 02500 batchs: 1380.537109375
INFO:root:Train (Epoch 16): Loss/seq after 02550 batchs: 1366.90771484375
INFO:root:Train (Epoch 16): Loss/seq after 02600 batchs: 1363.94189453125
INFO:root:Train (Epoch 16): Loss/seq after 02650 batchs: 1357.0478515625
INFO:root:Train (Epoch 16): Loss/seq after 02700 batchs: 1352.8690185546875
INFO:root:Train (Epoch 16): Loss/seq after 02750 batchs: 1382.0238037109375
INFO:root:Train (Epoch 16): Loss/seq after 02800 batchs: 1389.7537841796875
INFO:root:Train (Epoch 16): Loss/seq after 02850 batchs: 1385.3072509765625
INFO:root:Train (Epoch 16): Loss/seq after 02900 batchs: 1381.35302734375
INFO:root:Train (Epoch 16): Loss/seq after 02950 batchs: 1371.645263671875
INFO:root:Train (Epoch 16): Loss/seq after 03000 batchs: 1366.9251708984375
INFO:root:Train (Epoch 16): Loss/seq after 03050 batchs: 1367.194091796875
INFO:root:Train (Epoch 16): Loss/seq after 03100 batchs: 1382.9378662109375
INFO:root:Train (Epoch 16): Loss/seq after 03150 batchs: 1402.2396240234375
INFO:root:Train (Epoch 16): Loss/seq after 03200 batchs: 1415.1378173828125
INFO:root:Train (Epoch 16): Loss/seq after 03250 batchs: 1427.4476318359375
INFO:root:Train (Epoch 16): Loss/seq after 03300 batchs: 1426.8043212890625
INFO:root:Train (Epoch 16): Loss/seq after 03350 batchs: 1424.954833984375
INFO:root:Train (Epoch 16): Loss/seq after 03400 batchs: 1413.7540283203125
INFO:root:Train (Epoch 16): Loss/seq after 03450 batchs: 1407.0780029296875
INFO:root:Train (Epoch 16): Loss/seq after 03500 batchs: 1405.6224365234375
INFO:root:Train (Epoch 16): Loss/seq after 03550 batchs: 1399.536865234375
INFO:root:Train (Epoch 16): Loss/seq after 03600 batchs: 1403.5538330078125
INFO:root:Train (Epoch 16): Loss/seq after 03650 batchs: 1397.4031982421875
INFO:root:Train (Epoch 16): Loss/seq after 03700 batchs: 1395.25634765625
INFO:root:Train (Epoch 16): Loss/seq after 03750 batchs: 1393.193115234375
INFO:root:Train (Epoch 16): Loss/seq after 03800 batchs: 1384.49951171875
INFO:root:Train (Epoch 16): Loss/seq after 03850 batchs: 1378.454833984375
INFO:root:Train (Epoch 16): Loss/seq after 03900 batchs: 1385.9830322265625
INFO:root:Train (Epoch 16): Loss/seq after 03950 batchs: 1396.759521484375
INFO:root:Train (Epoch 16): Loss/seq after 04000 batchs: 1385.7064208984375
INFO:root:Train (Epoch 16): Loss/seq after 04050 batchs: 1375.6668701171875
INFO:root:Train (Epoch 16): Loss/seq after 04100 batchs: 1370.60009765625
INFO:root:Train (Epoch 16): Loss/seq after 04150 batchs: 1363.8743896484375
INFO:root:Train (Epoch 16): Loss/seq after 04200 batchs: 1358.9151611328125
INFO:root:Train (Epoch 16): Loss/seq after 04250 batchs: 1353.343994140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 16): Loss/seq after 00000 batches: 1035.5052490234375
INFO:root:# Valid (Epoch 16): Loss/seq after 00050 batches: 1160.0694580078125
INFO:root:# Valid (Epoch 16): Loss/seq after 00100 batches: 1530.001220703125
INFO:root:# Valid (Epoch 16): Loss/seq after 00150 batches: 1248.13232421875
INFO:root:# Valid (Epoch 16): Loss/seq after 00200 batches: 1119.1151123046875
INFO:root:Artifacts: Make stick videos for epoch 16
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_16_on_20220422_215948.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_16_index_551_on_20220422_215948.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 17): Loss/seq after 00000 batchs: 2455.532958984375
INFO:root:Train (Epoch 17): Loss/seq after 00050 batchs: 1810.78076171875
INFO:root:Train (Epoch 17): Loss/seq after 00100 batchs: 1730.6478271484375
INFO:root:Train (Epoch 17): Loss/seq after 00150 batchs: 1538.5465087890625
INFO:root:Train (Epoch 17): Loss/seq after 00200 batchs: 1666.4627685546875
INFO:root:Train (Epoch 17): Loss/seq after 00250 batchs: 1774.595947265625
INFO:root:Train (Epoch 17): Loss/seq after 00300 batchs: 1665.780517578125
INFO:root:Train (Epoch 17): Loss/seq after 00350 batchs: 1554.0469970703125
INFO:root:Train (Epoch 17): Loss/seq after 00400 batchs: 1620.418212890625
INFO:root:Train (Epoch 17): Loss/seq after 00450 batchs: 1538.0325927734375
INFO:root:Train (Epoch 17): Loss/seq after 00500 batchs: 1569.3907470703125
INFO:root:Train (Epoch 17): Loss/seq after 00550 batchs: 1501.8204345703125
INFO:root:Train (Epoch 17): Loss/seq after 00600 batchs: 1466.975830078125
INFO:root:Train (Epoch 17): Loss/seq after 00650 batchs: 1531.8004150390625
INFO:root:Train (Epoch 17): Loss/seq after 00700 batchs: 1617.7542724609375
INFO:root:Train (Epoch 17): Loss/seq after 00750 batchs: 1661.6229248046875
INFO:root:Train (Epoch 17): Loss/seq after 00800 batchs: 1642.868408203125
INFO:root:Train (Epoch 17): Loss/seq after 00850 batchs: 1604.4642333984375
INFO:root:Train (Epoch 17): Loss/seq after 00900 batchs: 1605.2060546875
INFO:root:Train (Epoch 17): Loss/seq after 00950 batchs: 1702.365966796875
INFO:root:Train (Epoch 17): Loss/seq after 01000 batchs: 1702.6641845703125
INFO:root:Train (Epoch 17): Loss/seq after 01050 batchs: 1676.417724609375
INFO:root:Train (Epoch 17): Loss/seq after 01100 batchs: 1659.408203125
INFO:root:Train (Epoch 17): Loss/seq after 01150 batchs: 1631.26171875
INFO:root:Train (Epoch 17): Loss/seq after 01200 batchs: 1610.992919921875
INFO:root:Train (Epoch 17): Loss/seq after 01250 batchs: 1600.141845703125
INFO:root:Train (Epoch 17): Loss/seq after 01300 batchs: 1609.47802734375
INFO:root:Train (Epoch 17): Loss/seq after 01350 batchs: 1606.8719482421875
INFO:root:Train (Epoch 17): Loss/seq after 01400 batchs: 1657.786865234375
INFO:root:Train (Epoch 17): Loss/seq after 01450 batchs: 1639.107177734375
INFO:root:Train (Epoch 17): Loss/seq after 01500 batchs: 1620.3621826171875
INFO:root:Train (Epoch 17): Loss/seq after 01550 batchs: 1617.5458984375
INFO:root:Train (Epoch 17): Loss/seq after 01600 batchs: 1593.0955810546875
INFO:root:Train (Epoch 17): Loss/seq after 01650 batchs: 1584.3248291015625
INFO:root:Train (Epoch 17): Loss/seq after 01700 batchs: 1568.33251953125
INFO:root:Train (Epoch 17): Loss/seq after 01750 batchs: 1549.806884765625
INFO:root:Train (Epoch 17): Loss/seq after 01800 batchs: 1529.98291015625
INFO:root:Train (Epoch 17): Loss/seq after 01850 batchs: 1510.048095703125
INFO:root:Train (Epoch 17): Loss/seq after 01900 batchs: 1503.2489013671875
INFO:root:Train (Epoch 17): Loss/seq after 01950 batchs: 1492.91455078125
INFO:root:Train (Epoch 17): Loss/seq after 02000 batchs: 1478.2010498046875
INFO:root:Train (Epoch 17): Loss/seq after 02050 batchs: 1465.344482421875
INFO:root:Train (Epoch 17): Loss/seq after 02100 batchs: 1449.358154296875
INFO:root:Train (Epoch 17): Loss/seq after 02150 batchs: 1434.99462890625
INFO:root:Train (Epoch 17): Loss/seq after 02200 batchs: 1419.5108642578125
INFO:root:Train (Epoch 17): Loss/seq after 02250 batchs: 1420.8260498046875
INFO:root:Train (Epoch 17): Loss/seq after 02300 batchs: 1422.2393798828125
INFO:root:Train (Epoch 17): Loss/seq after 02350 batchs: 1409.544921875
INFO:root:Train (Epoch 17): Loss/seq after 02400 batchs: 1402.654541015625
INFO:root:Train (Epoch 17): Loss/seq after 02450 batchs: 1387.0123291015625
INFO:root:Train (Epoch 17): Loss/seq after 02500 batchs: 1366.6873779296875
INFO:root:Train (Epoch 17): Loss/seq after 02550 batchs: 1353.9039306640625
INFO:root:Train (Epoch 17): Loss/seq after 02600 batchs: 1350.439697265625
INFO:root:Train (Epoch 17): Loss/seq after 02650 batchs: 1343.3306884765625
INFO:root:Train (Epoch 17): Loss/seq after 02700 batchs: 1338.8446044921875
INFO:root:Train (Epoch 17): Loss/seq after 02750 batchs: 1368.4759521484375
INFO:root:Train (Epoch 17): Loss/seq after 02800 batchs: 1376.4014892578125
INFO:root:Train (Epoch 17): Loss/seq after 02850 batchs: 1372.1065673828125
INFO:root:Train (Epoch 17): Loss/seq after 02900 batchs: 1368.36767578125
INFO:root:Train (Epoch 17): Loss/seq after 02950 batchs: 1358.6920166015625
INFO:root:Train (Epoch 17): Loss/seq after 03000 batchs: 1354.1796875
INFO:root:Train (Epoch 17): Loss/seq after 03050 batchs: 1354.6507568359375
INFO:root:Train (Epoch 17): Loss/seq after 03100 batchs: 1370.13818359375
INFO:root:Train (Epoch 17): Loss/seq after 03150 batchs: 1389.302490234375
INFO:root:Train (Epoch 17): Loss/seq after 03200 batchs: 1402.685791015625
INFO:root:Train (Epoch 17): Loss/seq after 03250 batchs: 1415.08544921875
INFO:root:Train (Epoch 17): Loss/seq after 03300 batchs: 1414.730224609375
INFO:root:Train (Epoch 17): Loss/seq after 03350 batchs: 1412.8968505859375
INFO:root:Train (Epoch 17): Loss/seq after 03400 batchs: 1401.7623291015625
INFO:root:Train (Epoch 17): Loss/seq after 03450 batchs: 1393.3870849609375
INFO:root:Train (Epoch 17): Loss/seq after 03500 batchs: 1392.0198974609375
INFO:root:Train (Epoch 17): Loss/seq after 03550 batchs: 1385.5771484375
INFO:root:Train (Epoch 17): Loss/seq after 03600 batchs: 1389.481201171875
INFO:root:Train (Epoch 17): Loss/seq after 03650 batchs: 1383.645263671875
INFO:root:Train (Epoch 17): Loss/seq after 03700 batchs: 1381.56005859375
INFO:root:Train (Epoch 17): Loss/seq after 03750 batchs: 1379.357421875
INFO:root:Train (Epoch 17): Loss/seq after 03800 batchs: 1370.5146484375
INFO:root:Train (Epoch 17): Loss/seq after 03850 batchs: 1364.41064453125
INFO:root:Train (Epoch 17): Loss/seq after 03900 batchs: 1372.046875
INFO:root:Train (Epoch 17): Loss/seq after 03950 batchs: 1381.612060546875
INFO:root:Train (Epoch 17): Loss/seq after 04000 batchs: 1370.719970703125
INFO:root:Train (Epoch 17): Loss/seq after 04050 batchs: 1360.8648681640625
INFO:root:Train (Epoch 17): Loss/seq after 04100 batchs: 1355.9346923828125
INFO:root:Train (Epoch 17): Loss/seq after 04150 batchs: 1349.3626708984375
INFO:root:Train (Epoch 17): Loss/seq after 04200 batchs: 1344.511962890625
INFO:root:Train (Epoch 17): Loss/seq after 04250 batchs: 1339.204833984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 17): Loss/seq after 00000 batches: 1009.056884765625
INFO:root:# Valid (Epoch 17): Loss/seq after 00050 batches: 1147.3271484375
INFO:root:# Valid (Epoch 17): Loss/seq after 00100 batches: 1495.8505859375
INFO:root:# Valid (Epoch 17): Loss/seq after 00150 batches: 1226.4766845703125
INFO:root:# Valid (Epoch 17): Loss/seq after 00200 batches: 1105.39599609375
INFO:root:Artifacts: Make stick videos for epoch 17
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_17_on_20220422_220441.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_17_index_1173_on_20220422_220441.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 18): Loss/seq after 00000 batchs: 2441.47509765625
INFO:root:Train (Epoch 18): Loss/seq after 00050 batchs: 1780.84228515625
INFO:root:Train (Epoch 18): Loss/seq after 00100 batchs: 1724.363525390625
INFO:root:Train (Epoch 18): Loss/seq after 00150 batchs: 1525.9456787109375
INFO:root:Train (Epoch 18): Loss/seq after 00200 batchs: 1652.68310546875
INFO:root:Train (Epoch 18): Loss/seq after 00250 batchs: 1758.50830078125
INFO:root:Train (Epoch 18): Loss/seq after 00300 batchs: 1651.4093017578125
INFO:root:Train (Epoch 18): Loss/seq after 00350 batchs: 1541.5513916015625
INFO:root:Train (Epoch 18): Loss/seq after 00400 batchs: 1607.8050537109375
INFO:root:Train (Epoch 18): Loss/seq after 00450 batchs: 1526.82763671875
INFO:root:Train (Epoch 18): Loss/seq after 00500 batchs: 1559.557861328125
INFO:root:Train (Epoch 18): Loss/seq after 00550 batchs: 1493.1273193359375
INFO:root:Train (Epoch 18): Loss/seq after 00600 batchs: 1458.4368896484375
INFO:root:Train (Epoch 18): Loss/seq after 00650 batchs: 1523.4224853515625
INFO:root:Train (Epoch 18): Loss/seq after 00700 batchs: 1609.133056640625
INFO:root:Train (Epoch 18): Loss/seq after 00750 batchs: 1655.0462646484375
INFO:root:Train (Epoch 18): Loss/seq after 00800 batchs: 1636.8909912109375
INFO:root:Train (Epoch 18): Loss/seq after 00850 batchs: 1598.4892578125
INFO:root:Train (Epoch 18): Loss/seq after 00900 batchs: 1597.3460693359375
INFO:root:Train (Epoch 18): Loss/seq after 00950 batchs: 1692.5977783203125
INFO:root:Train (Epoch 18): Loss/seq after 01000 batchs: 1692.4053955078125
INFO:root:Train (Epoch 18): Loss/seq after 01050 batchs: 1666.7647705078125
INFO:root:Train (Epoch 18): Loss/seq after 01100 batchs: 1648.923583984375
INFO:root:Train (Epoch 18): Loss/seq after 01150 batchs: 1621.1673583984375
INFO:root:Train (Epoch 18): Loss/seq after 01200 batchs: 1602.8646240234375
INFO:root:Train (Epoch 18): Loss/seq after 01250 batchs: 1591.5732421875
INFO:root:Train (Epoch 18): Loss/seq after 01300 batchs: 1600.94873046875
INFO:root:Train (Epoch 18): Loss/seq after 01350 batchs: 1598.463623046875
INFO:root:Train (Epoch 18): Loss/seq after 01400 batchs: 1649.6673583984375
INFO:root:Train (Epoch 18): Loss/seq after 01450 batchs: 1630.29833984375
INFO:root:Train (Epoch 18): Loss/seq after 01500 batchs: 1611.92138671875
INFO:root:Train (Epoch 18): Loss/seq after 01550 batchs: 1608.621826171875
INFO:root:Train (Epoch 18): Loss/seq after 01600 batchs: 1583.8331298828125
INFO:root:Train (Epoch 18): Loss/seq after 01650 batchs: 1572.745849609375
INFO:root:Train (Epoch 18): Loss/seq after 01700 batchs: 1557.30615234375
INFO:root:Train (Epoch 18): Loss/seq after 01750 batchs: 1539.1966552734375
INFO:root:Train (Epoch 18): Loss/seq after 01800 batchs: 1519.574951171875
INFO:root:Train (Epoch 18): Loss/seq after 01850 batchs: 1499.954833984375
INFO:root:Train (Epoch 18): Loss/seq after 01900 batchs: 1493.4794921875
INFO:root:Train (Epoch 18): Loss/seq after 01950 batchs: 1483.3677978515625
INFO:root:Train (Epoch 18): Loss/seq after 02000 batchs: 1469.0299072265625
INFO:root:Train (Epoch 18): Loss/seq after 02050 batchs: 1456.5091552734375
INFO:root:Train (Epoch 18): Loss/seq after 02100 batchs: 1440.8060302734375
INFO:root:Train (Epoch 18): Loss/seq after 02150 batchs: 1426.7269287109375
INFO:root:Train (Epoch 18): Loss/seq after 02200 batchs: 1411.436767578125
INFO:root:Train (Epoch 18): Loss/seq after 02250 batchs: 1413.102783203125
INFO:root:Train (Epoch 18): Loss/seq after 02300 batchs: 1414.699951171875
INFO:root:Train (Epoch 18): Loss/seq after 02350 batchs: 1402.7645263671875
INFO:root:Train (Epoch 18): Loss/seq after 02400 batchs: 1395.8399658203125
INFO:root:Train (Epoch 18): Loss/seq after 02450 batchs: 1380.3719482421875
INFO:root:Train (Epoch 18): Loss/seq after 02500 batchs: 1360.150390625
INFO:root:Train (Epoch 18): Loss/seq after 02550 batchs: 1346.8724365234375
INFO:root:Train (Epoch 18): Loss/seq after 02600 batchs: 1343.2235107421875
INFO:root:Train (Epoch 18): Loss/seq after 02650 batchs: 1336.1317138671875
INFO:root:Train (Epoch 18): Loss/seq after 02700 batchs: 1331.88818359375
INFO:root:Train (Epoch 18): Loss/seq after 02750 batchs: 1362.0103759765625
INFO:root:Train (Epoch 18): Loss/seq after 02800 batchs: 1370.1497802734375
INFO:root:Train (Epoch 18): Loss/seq after 02850 batchs: 1365.837646484375
INFO:root:Train (Epoch 18): Loss/seq after 02900 batchs: 1361.9849853515625
INFO:root:Train (Epoch 18): Loss/seq after 02950 batchs: 1352.5062255859375
INFO:root:Train (Epoch 18): Loss/seq after 03000 batchs: 1348.098876953125
INFO:root:Train (Epoch 18): Loss/seq after 03050 batchs: 1348.6624755859375
INFO:root:Train (Epoch 18): Loss/seq after 03100 batchs: 1364.4613037109375
INFO:root:Train (Epoch 18): Loss/seq after 03150 batchs: 1383.5050048828125
INFO:root:Train (Epoch 18): Loss/seq after 03200 batchs: 1397.00341796875
INFO:root:Train (Epoch 18): Loss/seq after 03250 batchs: 1409.4857177734375
INFO:root:Train (Epoch 18): Loss/seq after 03300 batchs: 1408.339599609375
INFO:root:Train (Epoch 18): Loss/seq after 03350 batchs: 1406.65185546875
INFO:root:Train (Epoch 18): Loss/seq after 03400 batchs: 1395.6790771484375
INFO:root:Train (Epoch 18): Loss/seq after 03450 batchs: 1388.0323486328125
INFO:root:Train (Epoch 18): Loss/seq after 03500 batchs: 1386.5699462890625
INFO:root:Train (Epoch 18): Loss/seq after 03550 batchs: 1380.2550048828125
INFO:root:Train (Epoch 18): Loss/seq after 03600 batchs: 1384.2071533203125
INFO:root:Train (Epoch 18): Loss/seq after 03650 batchs: 1378.4761962890625
INFO:root:Train (Epoch 18): Loss/seq after 03700 batchs: 1376.347900390625
INFO:root:Train (Epoch 18): Loss/seq after 03750 batchs: 1374.3441162109375
INFO:root:Train (Epoch 18): Loss/seq after 03800 batchs: 1365.766357421875
INFO:root:Train (Epoch 18): Loss/seq after 03850 batchs: 1359.8155517578125
INFO:root:Train (Epoch 18): Loss/seq after 03900 batchs: 1366.5322265625
INFO:root:Train (Epoch 18): Loss/seq after 03950 batchs: 1374.73046875
INFO:root:Train (Epoch 18): Loss/seq after 04000 batchs: 1363.89404296875
INFO:root:Train (Epoch 18): Loss/seq after 04050 batchs: 1354.115234375
INFO:root:Train (Epoch 18): Loss/seq after 04100 batchs: 1349.2806396484375
INFO:root:Train (Epoch 18): Loss/seq after 04150 batchs: 1342.7457275390625
INFO:root:Train (Epoch 18): Loss/seq after 04200 batchs: 1336.5172119140625
INFO:root:Train (Epoch 18): Loss/seq after 04250 batchs: 1330.888916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 18): Loss/seq after 00000 batches: 952.3232421875
INFO:root:# Valid (Epoch 18): Loss/seq after 00050 batches: 1121.496826171875
INFO:root:# Valid (Epoch 18): Loss/seq after 00100 batches: 1452.6885986328125
INFO:root:# Valid (Epoch 18): Loss/seq after 00150 batches: 1211.5078125
INFO:root:# Valid (Epoch 18): Loss/seq after 00200 batches: 1099.689208984375
INFO:root:Artifacts: Make stick videos for epoch 18
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_18_on_20220422_220935.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_18_index_1633_on_20220422_220935.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 19): Loss/seq after 00000 batchs: 2562.017333984375
INFO:root:Train (Epoch 19): Loss/seq after 00050 batchs: 1815.12548828125
INFO:root:Train (Epoch 19): Loss/seq after 00100 batchs: 1752.1771240234375
INFO:root:Train (Epoch 19): Loss/seq after 00150 batchs: 1561.151611328125
INFO:root:Train (Epoch 19): Loss/seq after 00200 batchs: 1675.5579833984375
INFO:root:Train (Epoch 19): Loss/seq after 00250 batchs: 1789.1583251953125
INFO:root:Train (Epoch 19): Loss/seq after 00300 batchs: 1676.7354736328125
INFO:root:Train (Epoch 19): Loss/seq after 00350 batchs: 1564.190185546875
INFO:root:Train (Epoch 19): Loss/seq after 00400 batchs: 1628.2733154296875
INFO:root:Train (Epoch 19): Loss/seq after 00450 batchs: 1545.04150390625
INFO:root:Train (Epoch 19): Loss/seq after 00500 batchs: 1580.5614013671875
INFO:root:Train (Epoch 19): Loss/seq after 00550 batchs: 1514.6407470703125
INFO:root:Train (Epoch 19): Loss/seq after 00600 batchs: 1477.7308349609375
INFO:root:Train (Epoch 19): Loss/seq after 00650 batchs: 1541.28955078125
INFO:root:Train (Epoch 19): Loss/seq after 00700 batchs: 1624.8134765625
INFO:root:Train (Epoch 19): Loss/seq after 00750 batchs: 1664.2083740234375
INFO:root:Train (Epoch 19): Loss/seq after 00800 batchs: 1645.573974609375
INFO:root:Train (Epoch 19): Loss/seq after 00850 batchs: 1606.8197021484375
INFO:root:Train (Epoch 19): Loss/seq after 00900 batchs: 1605.3431396484375
INFO:root:Train (Epoch 19): Loss/seq after 00950 batchs: 1701.92626953125
INFO:root:Train (Epoch 19): Loss/seq after 01000 batchs: 1701.091064453125
INFO:root:Train (Epoch 19): Loss/seq after 01050 batchs: 1675.064453125
INFO:root:Train (Epoch 19): Loss/seq after 01100 batchs: 1656.3248291015625
INFO:root:Train (Epoch 19): Loss/seq after 01150 batchs: 1627.685302734375
INFO:root:Train (Epoch 19): Loss/seq after 01200 batchs: 1607.702880859375
INFO:root:Train (Epoch 19): Loss/seq after 01250 batchs: 1597.408203125
INFO:root:Train (Epoch 19): Loss/seq after 01300 batchs: 1606.6834716796875
INFO:root:Train (Epoch 19): Loss/seq after 01350 batchs: 1604.0450439453125
INFO:root:Train (Epoch 19): Loss/seq after 01400 batchs: 1654.4364013671875
INFO:root:Train (Epoch 19): Loss/seq after 01450 batchs: 1634.8724365234375
INFO:root:Train (Epoch 19): Loss/seq after 01500 batchs: 1616.6309814453125
INFO:root:Train (Epoch 19): Loss/seq after 01550 batchs: 1613.5897216796875
INFO:root:Train (Epoch 19): Loss/seq after 01600 batchs: 1588.67919921875
INFO:root:Train (Epoch 19): Loss/seq after 01650 batchs: 1577.052490234375
INFO:root:Train (Epoch 19): Loss/seq after 01700 batchs: 1561.057373046875
INFO:root:Train (Epoch 19): Loss/seq after 01750 batchs: 1542.450439453125
INFO:root:Train (Epoch 19): Loss/seq after 01800 batchs: 1522.6424560546875
INFO:root:Train (Epoch 19): Loss/seq after 01850 batchs: 1502.9599609375
INFO:root:Train (Epoch 19): Loss/seq after 01900 batchs: 1496.3250732421875
INFO:root:Train (Epoch 19): Loss/seq after 01950 batchs: 1486.1448974609375
INFO:root:Train (Epoch 19): Loss/seq after 02000 batchs: 1471.6221923828125
INFO:root:Train (Epoch 19): Loss/seq after 02050 batchs: 1458.9764404296875
INFO:root:Train (Epoch 19): Loss/seq after 02100 batchs: 1443.10888671875
INFO:root:Train (Epoch 19): Loss/seq after 02150 batchs: 1428.767333984375
INFO:root:Train (Epoch 19): Loss/seq after 02200 batchs: 1413.4483642578125
INFO:root:Train (Epoch 19): Loss/seq after 02250 batchs: 1414.4368896484375
INFO:root:Train (Epoch 19): Loss/seq after 02300 batchs: 1416.1444091796875
INFO:root:Train (Epoch 19): Loss/seq after 02350 batchs: 1403.84814453125
INFO:root:Train (Epoch 19): Loss/seq after 02400 batchs: 1396.8743896484375
INFO:root:Train (Epoch 19): Loss/seq after 02450 batchs: 1381.4654541015625
INFO:root:Train (Epoch 19): Loss/seq after 02500 batchs: 1361.2442626953125
INFO:root:Train (Epoch 19): Loss/seq after 02550 batchs: 1347.8226318359375
INFO:root:Train (Epoch 19): Loss/seq after 02600 batchs: 1343.7027587890625
INFO:root:Train (Epoch 19): Loss/seq after 02650 batchs: 1336.28466796875
INFO:root:Train (Epoch 19): Loss/seq after 02700 batchs: 1331.71142578125
INFO:root:Train (Epoch 19): Loss/seq after 02750 batchs: 1363.0538330078125
INFO:root:Train (Epoch 19): Loss/seq after 02800 batchs: 1372.3836669921875
INFO:root:Train (Epoch 19): Loss/seq after 02850 batchs: 1368.6107177734375
INFO:root:Train (Epoch 19): Loss/seq after 02900 batchs: 1364.7686767578125
INFO:root:Train (Epoch 19): Loss/seq after 02950 batchs: 1355.3553466796875
INFO:root:Train (Epoch 19): Loss/seq after 03000 batchs: 1350.8865966796875
INFO:root:Train (Epoch 19): Loss/seq after 03050 batchs: 1351.341796875
INFO:root:Train (Epoch 19): Loss/seq after 03100 batchs: 1368.72119140625
INFO:root:Train (Epoch 19): Loss/seq after 03150 batchs: 1387.624755859375
INFO:root:Train (Epoch 19): Loss/seq after 03200 batchs: 1401.3463134765625
INFO:root:Train (Epoch 19): Loss/seq after 03250 batchs: 1413.6910400390625
INFO:root:Train (Epoch 19): Loss/seq after 03300 batchs: 1412.7640380859375
INFO:root:Train (Epoch 19): Loss/seq after 03350 batchs: 1410.8653564453125
INFO:root:Train (Epoch 19): Loss/seq after 03400 batchs: 1399.6455078125
INFO:root:Train (Epoch 19): Loss/seq after 03450 batchs: 1390.6156005859375
INFO:root:Train (Epoch 19): Loss/seq after 03500 batchs: 1388.6396484375
INFO:root:Train (Epoch 19): Loss/seq after 03550 batchs: 1381.92431640625
INFO:root:Train (Epoch 19): Loss/seq after 03600 batchs: 1385.6934814453125
INFO:root:Train (Epoch 19): Loss/seq after 03650 batchs: 1380.0015869140625
INFO:root:Train (Epoch 19): Loss/seq after 03700 batchs: 1377.86572265625
INFO:root:Train (Epoch 19): Loss/seq after 03750 batchs: 1375.7816162109375
INFO:root:Train (Epoch 19): Loss/seq after 03800 batchs: 1367.1134033203125
INFO:root:Train (Epoch 19): Loss/seq after 03850 batchs: 1361.0728759765625
INFO:root:Train (Epoch 19): Loss/seq after 03900 batchs: 1367.7181396484375
INFO:root:Train (Epoch 19): Loss/seq after 03950 batchs: 1376.0914306640625
INFO:root:Train (Epoch 19): Loss/seq after 04000 batchs: 1365.22802734375
INFO:root:Train (Epoch 19): Loss/seq after 04050 batchs: 1355.430908203125
INFO:root:Train (Epoch 19): Loss/seq after 04100 batchs: 1350.263671875
INFO:root:Train (Epoch 19): Loss/seq after 04150 batchs: 1343.6478271484375
INFO:root:Train (Epoch 19): Loss/seq after 04200 batchs: 1337.069580078125
INFO:root:Train (Epoch 19): Loss/seq after 04250 batchs: 1331.2874755859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 19): Loss/seq after 00000 batches: 933.6893920898438
INFO:root:# Valid (Epoch 19): Loss/seq after 00050 batches: 1114.6065673828125
INFO:root:# Valid (Epoch 19): Loss/seq after 00100 batches: 1439.4901123046875
INFO:root:# Valid (Epoch 19): Loss/seq after 00150 batches: 1204.62939453125
INFO:root:# Valid (Epoch 19): Loss/seq after 00200 batches: 1094.8763427734375
INFO:root:Artifacts: Make stick videos for epoch 19
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_19_on_20220422_221422.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_19_index_993_on_20220422_221422.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 20): Loss/seq after 00000 batchs: 2662.4267578125
INFO:root:Train (Epoch 20): Loss/seq after 00050 batchs: 1794.6024169921875
INFO:root:Train (Epoch 20): Loss/seq after 00100 batchs: 1736.47119140625
INFO:root:Train (Epoch 20): Loss/seq after 00150 batchs: 1539.1771240234375
INFO:root:Train (Epoch 20): Loss/seq after 00200 batchs: 1662.5499267578125
INFO:root:Train (Epoch 20): Loss/seq after 00250 batchs: 1776.704833984375
INFO:root:Train (Epoch 20): Loss/seq after 00300 batchs: 1666.7991943359375
INFO:root:Train (Epoch 20): Loss/seq after 00350 batchs: 1554.8790283203125
INFO:root:Train (Epoch 20): Loss/seq after 00400 batchs: 1622.535400390625
INFO:root:Train (Epoch 20): Loss/seq after 00450 batchs: 1539.8565673828125
INFO:root:Train (Epoch 20): Loss/seq after 00500 batchs: 1570.7186279296875
INFO:root:Train (Epoch 20): Loss/seq after 00550 batchs: 1503.728271484375
INFO:root:Train (Epoch 20): Loss/seq after 00600 batchs: 1467.649658203125
INFO:root:Train (Epoch 20): Loss/seq after 00650 batchs: 1528.0496826171875
INFO:root:Train (Epoch 20): Loss/seq after 00700 batchs: 1611.4613037109375
INFO:root:Train (Epoch 20): Loss/seq after 00750 batchs: 1649.8184814453125
INFO:root:Train (Epoch 20): Loss/seq after 00800 batchs: 1631.9937744140625
INFO:root:Train (Epoch 20): Loss/seq after 00850 batchs: 1594.0364990234375
INFO:root:Train (Epoch 20): Loss/seq after 00900 batchs: 1592.3905029296875
INFO:root:Train (Epoch 20): Loss/seq after 00950 batchs: 1688.025634765625
INFO:root:Train (Epoch 20): Loss/seq after 01000 batchs: 1685.7677001953125
INFO:root:Train (Epoch 20): Loss/seq after 01050 batchs: 1660.271484375
INFO:root:Train (Epoch 20): Loss/seq after 01100 batchs: 1642.92578125
INFO:root:Train (Epoch 20): Loss/seq after 01150 batchs: 1615.3013916015625
INFO:root:Train (Epoch 20): Loss/seq after 01200 batchs: 1594.9295654296875
INFO:root:Train (Epoch 20): Loss/seq after 01250 batchs: 1583.11572265625
INFO:root:Train (Epoch 20): Loss/seq after 01300 batchs: 1592.4400634765625
INFO:root:Train (Epoch 20): Loss/seq after 01350 batchs: 1590.370361328125
INFO:root:Train (Epoch 20): Loss/seq after 01400 batchs: 1640.9466552734375
INFO:root:Train (Epoch 20): Loss/seq after 01450 batchs: 1622.446533203125
INFO:root:Train (Epoch 20): Loss/seq after 01500 batchs: 1604.306396484375
INFO:root:Train (Epoch 20): Loss/seq after 01550 batchs: 1600.7742919921875
INFO:root:Train (Epoch 20): Loss/seq after 01600 batchs: 1576.5355224609375
INFO:root:Train (Epoch 20): Loss/seq after 01650 batchs: 1565.591064453125
INFO:root:Train (Epoch 20): Loss/seq after 01700 batchs: 1549.9505615234375
INFO:root:Train (Epoch 20): Loss/seq after 01750 batchs: 1531.4261474609375
INFO:root:Train (Epoch 20): Loss/seq after 01800 batchs: 1511.642822265625
INFO:root:Train (Epoch 20): Loss/seq after 01850 batchs: 1492.2493896484375
INFO:root:Train (Epoch 20): Loss/seq after 01900 batchs: 1485.849609375
INFO:root:Train (Epoch 20): Loss/seq after 01950 batchs: 1475.8807373046875
INFO:root:Train (Epoch 20): Loss/seq after 02000 batchs: 1461.3411865234375
INFO:root:Train (Epoch 20): Loss/seq after 02050 batchs: 1448.8206787109375
INFO:root:Train (Epoch 20): Loss/seq after 02100 batchs: 1433.144287109375
INFO:root:Train (Epoch 20): Loss/seq after 02150 batchs: 1418.8717041015625
INFO:root:Train (Epoch 20): Loss/seq after 02200 batchs: 1403.720458984375
INFO:root:Train (Epoch 20): Loss/seq after 02250 batchs: 1404.625244140625
INFO:root:Train (Epoch 20): Loss/seq after 02300 batchs: 1406.4024658203125
INFO:root:Train (Epoch 20): Loss/seq after 02350 batchs: 1394.852783203125
INFO:root:Train (Epoch 20): Loss/seq after 02400 batchs: 1388.122802734375
INFO:root:Train (Epoch 20): Loss/seq after 02450 batchs: 1372.95068359375
INFO:root:Train (Epoch 20): Loss/seq after 02500 batchs: 1352.9080810546875
INFO:root:Train (Epoch 20): Loss/seq after 02550 batchs: 1339.587158203125
INFO:root:Train (Epoch 20): Loss/seq after 02600 batchs: 1335.6719970703125
INFO:root:Train (Epoch 20): Loss/seq after 02650 batchs: 1328.509765625
INFO:root:Train (Epoch 20): Loss/seq after 02700 batchs: 1323.6385498046875
INFO:root:Train (Epoch 20): Loss/seq after 02750 batchs: 1353.8037109375
INFO:root:Train (Epoch 20): Loss/seq after 02800 batchs: 1361.8946533203125
INFO:root:Train (Epoch 20): Loss/seq after 02850 batchs: 1357.6739501953125
INFO:root:Train (Epoch 20): Loss/seq after 02900 batchs: 1353.6878662109375
INFO:root:Train (Epoch 20): Loss/seq after 02950 batchs: 1344.3084716796875
INFO:root:Train (Epoch 20): Loss/seq after 03000 batchs: 1340.0291748046875
INFO:root:Train (Epoch 20): Loss/seq after 03050 batchs: 1340.6820068359375
INFO:root:Train (Epoch 20): Loss/seq after 03100 batchs: 1356.3538818359375
INFO:root:Train (Epoch 20): Loss/seq after 03150 batchs: 1374.903564453125
INFO:root:Train (Epoch 20): Loss/seq after 03200 batchs: 1388.9306640625
INFO:root:Train (Epoch 20): Loss/seq after 03250 batchs: 1401.2342529296875
INFO:root:Train (Epoch 20): Loss/seq after 03300 batchs: 1398.9801025390625
INFO:root:Train (Epoch 20): Loss/seq after 03350 batchs: 1397.39111328125
INFO:root:Train (Epoch 20): Loss/seq after 03400 batchs: 1386.3599853515625
INFO:root:Train (Epoch 20): Loss/seq after 03450 batchs: 1377.7471923828125
INFO:root:Train (Epoch 20): Loss/seq after 03500 batchs: 1376.2025146484375
INFO:root:Train (Epoch 20): Loss/seq after 03550 batchs: 1369.7265625
INFO:root:Train (Epoch 20): Loss/seq after 03600 batchs: 1373.711181640625
INFO:root:Train (Epoch 20): Loss/seq after 03650 batchs: 1367.9283447265625
INFO:root:Train (Epoch 20): Loss/seq after 03700 batchs: 1365.7476806640625
INFO:root:Train (Epoch 20): Loss/seq after 03750 batchs: 1363.8052978515625
INFO:root:Train (Epoch 20): Loss/seq after 03800 batchs: 1355.134521484375
INFO:root:Train (Epoch 20): Loss/seq after 03850 batchs: 1349.080078125
INFO:root:Train (Epoch 20): Loss/seq after 03900 batchs: 1355.5123291015625
INFO:root:Train (Epoch 20): Loss/seq after 03950 batchs: 1364.1116943359375
INFO:root:Train (Epoch 20): Loss/seq after 04000 batchs: 1353.3990478515625
INFO:root:Train (Epoch 20): Loss/seq after 04050 batchs: 1343.744140625
INFO:root:Train (Epoch 20): Loss/seq after 04100 batchs: 1338.5191650390625
INFO:root:Train (Epoch 20): Loss/seq after 04150 batchs: 1331.915283203125
INFO:root:Train (Epoch 20): Loss/seq after 04200 batchs: 1325.5074462890625
INFO:root:Train (Epoch 20): Loss/seq after 04250 batchs: 1319.7886962890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 20): Loss/seq after 00000 batches: 929.22021484375
INFO:root:# Valid (Epoch 20): Loss/seq after 00050 batches: 1112.4654541015625
INFO:root:# Valid (Epoch 20): Loss/seq after 00100 batches: 1429.3248291015625
INFO:root:# Valid (Epoch 20): Loss/seq after 00150 batches: 1198.47021484375
INFO:root:# Valid (Epoch 20): Loss/seq after 00200 batches: 1090.9652099609375
INFO:root:Artifacts: Make stick videos for epoch 20
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_20_on_20220422_221907.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_20_index_1625_on_20220422_221907.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 21): Loss/seq after 00000 batchs: 2442.10986328125
INFO:root:Train (Epoch 21): Loss/seq after 00050 batchs: 1759.015380859375
INFO:root:Train (Epoch 21): Loss/seq after 00100 batchs: 1712.17822265625
INFO:root:Train (Epoch 21): Loss/seq after 00150 batchs: 1528.416748046875
INFO:root:Train (Epoch 21): Loss/seq after 00200 batchs: 1652.27685546875
INFO:root:Train (Epoch 21): Loss/seq after 00250 batchs: 1760.1385498046875
INFO:root:Train (Epoch 21): Loss/seq after 00300 batchs: 1652.38623046875
INFO:root:Train (Epoch 21): Loss/seq after 00350 batchs: 1542.390625
INFO:root:Train (Epoch 21): Loss/seq after 00400 batchs: 1602.0045166015625
INFO:root:Train (Epoch 21): Loss/seq after 00450 batchs: 1521.5789794921875
INFO:root:Train (Epoch 21): Loss/seq after 00500 batchs: 1547.8106689453125
INFO:root:Train (Epoch 21): Loss/seq after 00550 batchs: 1482.1060791015625
INFO:root:Train (Epoch 21): Loss/seq after 00600 batchs: 1446.482421875
INFO:root:Train (Epoch 21): Loss/seq after 00650 batchs: 1509.6993408203125
INFO:root:Train (Epoch 21): Loss/seq after 00700 batchs: 1593.8345947265625
INFO:root:Train (Epoch 21): Loss/seq after 00750 batchs: 1631.4869384765625
INFO:root:Train (Epoch 21): Loss/seq after 00800 batchs: 1614.8671875
INFO:root:Train (Epoch 21): Loss/seq after 00850 batchs: 1577.9384765625
INFO:root:Train (Epoch 21): Loss/seq after 00900 batchs: 1577.2041015625
INFO:root:Train (Epoch 21): Loss/seq after 00950 batchs: 1670.411865234375
INFO:root:Train (Epoch 21): Loss/seq after 01000 batchs: 1669.5081787109375
INFO:root:Train (Epoch 21): Loss/seq after 01050 batchs: 1643.956298828125
INFO:root:Train (Epoch 21): Loss/seq after 01100 batchs: 1625.7537841796875
INFO:root:Train (Epoch 21): Loss/seq after 01150 batchs: 1600.4063720703125
INFO:root:Train (Epoch 21): Loss/seq after 01200 batchs: 1581.3916015625
INFO:root:Train (Epoch 21): Loss/seq after 01250 batchs: 1567.80517578125
INFO:root:Train (Epoch 21): Loss/seq after 01300 batchs: 1578.4129638671875
INFO:root:Train (Epoch 21): Loss/seq after 01350 batchs: 1576.959228515625
INFO:root:Train (Epoch 21): Loss/seq after 01400 batchs: 1627.421142578125
INFO:root:Train (Epoch 21): Loss/seq after 01450 batchs: 1608.759765625
INFO:root:Train (Epoch 21): Loss/seq after 01500 batchs: 1591.457275390625
INFO:root:Train (Epoch 21): Loss/seq after 01550 batchs: 1587.470947265625
INFO:root:Train (Epoch 21): Loss/seq after 01600 batchs: 1563.01416015625
INFO:root:Train (Epoch 21): Loss/seq after 01650 batchs: 1552.31884765625
INFO:root:Train (Epoch 21): Loss/seq after 01700 batchs: 1537.0335693359375
INFO:root:Train (Epoch 21): Loss/seq after 01750 batchs: 1518.99169921875
INFO:root:Train (Epoch 21): Loss/seq after 01800 batchs: 1499.6917724609375
INFO:root:Train (Epoch 21): Loss/seq after 01850 batchs: 1480.6884765625
INFO:root:Train (Epoch 21): Loss/seq after 01900 batchs: 1474.493408203125
INFO:root:Train (Epoch 21): Loss/seq after 01950 batchs: 1464.8931884765625
INFO:root:Train (Epoch 21): Loss/seq after 02000 batchs: 1450.636962890625
INFO:root:Train (Epoch 21): Loss/seq after 02050 batchs: 1438.3895263671875
INFO:root:Train (Epoch 21): Loss/seq after 02100 batchs: 1422.9234619140625
INFO:root:Train (Epoch 21): Loss/seq after 02150 batchs: 1408.9814453125
INFO:root:Train (Epoch 21): Loss/seq after 02200 batchs: 1394.0439453125
INFO:root:Train (Epoch 21): Loss/seq after 02250 batchs: 1394.6392822265625
INFO:root:Train (Epoch 21): Loss/seq after 02300 batchs: 1396.177734375
INFO:root:Train (Epoch 21): Loss/seq after 02350 batchs: 1384.59765625
INFO:root:Train (Epoch 21): Loss/seq after 02400 batchs: 1378.0806884765625
INFO:root:Train (Epoch 21): Loss/seq after 02450 batchs: 1362.8094482421875
INFO:root:Train (Epoch 21): Loss/seq after 02500 batchs: 1342.93115234375
INFO:root:Train (Epoch 21): Loss/seq after 02550 batchs: 1329.7513427734375
INFO:root:Train (Epoch 21): Loss/seq after 02600 batchs: 1325.4083251953125
INFO:root:Train (Epoch 21): Loss/seq after 02650 batchs: 1318.384765625
INFO:root:Train (Epoch 21): Loss/seq after 02700 batchs: 1313.93115234375
INFO:root:Train (Epoch 21): Loss/seq after 02750 batchs: 1344.291259765625
INFO:root:Train (Epoch 21): Loss/seq after 02800 batchs: 1352.9326171875
INFO:root:Train (Epoch 21): Loss/seq after 02850 batchs: 1348.8526611328125
INFO:root:Train (Epoch 21): Loss/seq after 02900 batchs: 1344.9710693359375
INFO:root:Train (Epoch 21): Loss/seq after 02950 batchs: 1335.77734375
INFO:root:Train (Epoch 21): Loss/seq after 03000 batchs: 1331.6270751953125
INFO:root:Train (Epoch 21): Loss/seq after 03050 batchs: 1332.416259765625
INFO:root:Train (Epoch 21): Loss/seq after 03100 batchs: 1348.182373046875
INFO:root:Train (Epoch 21): Loss/seq after 03150 batchs: 1365.95068359375
INFO:root:Train (Epoch 21): Loss/seq after 03200 batchs: 1378.8748779296875
INFO:root:Train (Epoch 21): Loss/seq after 03250 batchs: 1391.9403076171875
INFO:root:Train (Epoch 21): Loss/seq after 03300 batchs: 1391.25390625
INFO:root:Train (Epoch 21): Loss/seq after 03350 batchs: 1389.7191162109375
INFO:root:Train (Epoch 21): Loss/seq after 03400 batchs: 1378.806884765625
INFO:root:Train (Epoch 21): Loss/seq after 03450 batchs: 1370.022705078125
INFO:root:Train (Epoch 21): Loss/seq after 03500 batchs: 1368.50439453125
INFO:root:Train (Epoch 21): Loss/seq after 03550 batchs: 1361.9962158203125
INFO:root:Train (Epoch 21): Loss/seq after 03600 batchs: 1366.078125
INFO:root:Train (Epoch 21): Loss/seq after 03650 batchs: 1360.4368896484375
INFO:root:Train (Epoch 21): Loss/seq after 03700 batchs: 1358.44091796875
INFO:root:Train (Epoch 21): Loss/seq after 03750 batchs: 1356.5394287109375
INFO:root:Train (Epoch 21): Loss/seq after 03800 batchs: 1347.997802734375
INFO:root:Train (Epoch 21): Loss/seq after 03850 batchs: 1342.0504150390625
INFO:root:Train (Epoch 21): Loss/seq after 03900 batchs: 1348.2835693359375
INFO:root:Train (Epoch 21): Loss/seq after 03950 batchs: 1356.5301513671875
INFO:root:Train (Epoch 21): Loss/seq after 04000 batchs: 1345.8985595703125
INFO:root:Train (Epoch 21): Loss/seq after 04050 batchs: 1336.33349609375
INFO:root:Train (Epoch 21): Loss/seq after 04100 batchs: 1331.1746826171875
INFO:root:Train (Epoch 21): Loss/seq after 04150 batchs: 1324.461669921875
INFO:root:Train (Epoch 21): Loss/seq after 04200 batchs: 1318.7186279296875
INFO:root:Train (Epoch 21): Loss/seq after 04250 batchs: 1313.8824462890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 21): Loss/seq after 00000 batches: 985.54296875
INFO:root:# Valid (Epoch 21): Loss/seq after 00050 batches: 1139.714599609375
INFO:root:# Valid (Epoch 21): Loss/seq after 00100 batches: 1512.332763671875
INFO:root:# Valid (Epoch 21): Loss/seq after 00150 batches: 1242.419921875
INFO:root:# Valid (Epoch 21): Loss/seq after 00200 batches: 1120.854248046875
INFO:root:Artifacts: Make stick videos for epoch 21
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_21_on_20220422_222415.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_21_index_209_on_20220422_222415.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 22): Loss/seq after 00000 batchs: 2387.3740234375
INFO:root:Train (Epoch 22): Loss/seq after 00050 batchs: 1771.1685791015625
INFO:root:Train (Epoch 22): Loss/seq after 00100 batchs: 1694.048828125
INFO:root:Train (Epoch 22): Loss/seq after 00150 batchs: 1510.053955078125
INFO:root:Train (Epoch 22): Loss/seq after 00200 batchs: 1628.705078125
INFO:root:Train (Epoch 22): Loss/seq after 00250 batchs: 1738.2645263671875
INFO:root:Train (Epoch 22): Loss/seq after 00300 batchs: 1634.6181640625
INFO:root:Train (Epoch 22): Loss/seq after 00350 batchs: 1527.8685302734375
INFO:root:Train (Epoch 22): Loss/seq after 00400 batchs: 1595.5771484375
INFO:root:Train (Epoch 22): Loss/seq after 00450 batchs: 1515.886962890625
INFO:root:Train (Epoch 22): Loss/seq after 00500 batchs: 1541.835205078125
INFO:root:Train (Epoch 22): Loss/seq after 00550 batchs: 1476.7982177734375
INFO:root:Train (Epoch 22): Loss/seq after 00600 batchs: 1438.8525390625
INFO:root:Train (Epoch 22): Loss/seq after 00650 batchs: 1502.59814453125
INFO:root:Train (Epoch 22): Loss/seq after 00700 batchs: 1587.76416015625
INFO:root:Train (Epoch 22): Loss/seq after 00750 batchs: 1624.0032958984375
INFO:root:Train (Epoch 22): Loss/seq after 00800 batchs: 1608.71533203125
INFO:root:Train (Epoch 22): Loss/seq after 00850 batchs: 1571.9697265625
INFO:root:Train (Epoch 22): Loss/seq after 00900 batchs: 1572.172607421875
INFO:root:Train (Epoch 22): Loss/seq after 00950 batchs: 1665.578369140625
INFO:root:Train (Epoch 22): Loss/seq after 01000 batchs: 1664.2305908203125
INFO:root:Train (Epoch 22): Loss/seq after 01050 batchs: 1638.428466796875
INFO:root:Train (Epoch 22): Loss/seq after 01100 batchs: 1622.5687255859375
INFO:root:Train (Epoch 22): Loss/seq after 01150 batchs: 1595.544677734375
INFO:root:Train (Epoch 22): Loss/seq after 01200 batchs: 1577.0682373046875
INFO:root:Train (Epoch 22): Loss/seq after 01250 batchs: 1570.2252197265625
INFO:root:Train (Epoch 22): Loss/seq after 01300 batchs: 1580.619384765625
INFO:root:Train (Epoch 22): Loss/seq after 01350 batchs: 1579.0743408203125
INFO:root:Train (Epoch 22): Loss/seq after 01400 batchs: 1630.3477783203125
INFO:root:Train (Epoch 22): Loss/seq after 01450 batchs: 1613.8551025390625
INFO:root:Train (Epoch 22): Loss/seq after 01500 batchs: 1596.3568115234375
INFO:root:Train (Epoch 22): Loss/seq after 01550 batchs: 1594.4970703125
INFO:root:Train (Epoch 22): Loss/seq after 01600 batchs: 1570.04541015625
INFO:root:Train (Epoch 22): Loss/seq after 01650 batchs: 1558.5032958984375
INFO:root:Train (Epoch 22): Loss/seq after 01700 batchs: 1543.3414306640625
INFO:root:Train (Epoch 22): Loss/seq after 01750 batchs: 1525.466064453125
INFO:root:Train (Epoch 22): Loss/seq after 01800 batchs: 1506.3597412109375
INFO:root:Train (Epoch 22): Loss/seq after 01850 batchs: 1487.0816650390625
INFO:root:Train (Epoch 22): Loss/seq after 01900 batchs: 1480.7718505859375
INFO:root:Train (Epoch 22): Loss/seq after 01950 batchs: 1470.949951171875
INFO:root:Train (Epoch 22): Loss/seq after 02000 batchs: 1456.8243408203125
INFO:root:Train (Epoch 22): Loss/seq after 02050 batchs: 1444.5548095703125
INFO:root:Train (Epoch 22): Loss/seq after 02100 batchs: 1429.0703125
INFO:root:Train (Epoch 22): Loss/seq after 02150 batchs: 1415.154541015625
INFO:root:Train (Epoch 22): Loss/seq after 02200 batchs: 1400.0823974609375
INFO:root:Train (Epoch 22): Loss/seq after 02250 batchs: 1399.762939453125
INFO:root:Train (Epoch 22): Loss/seq after 02300 batchs: 1401.06103515625
INFO:root:Train (Epoch 22): Loss/seq after 02350 batchs: 1388.869140625
INFO:root:Train (Epoch 22): Loss/seq after 02400 batchs: 1381.7064208984375
INFO:root:Train (Epoch 22): Loss/seq after 02450 batchs: 1366.3094482421875
INFO:root:Train (Epoch 22): Loss/seq after 02500 batchs: 1346.3314208984375
INFO:root:Train (Epoch 22): Loss/seq after 02550 batchs: 1333.1002197265625
INFO:root:Train (Epoch 22): Loss/seq after 02600 batchs: 1329.059814453125
INFO:root:Train (Epoch 22): Loss/seq after 02650 batchs: 1321.876220703125
INFO:root:Train (Epoch 22): Loss/seq after 02700 batchs: 1316.57080078125
INFO:root:Train (Epoch 22): Loss/seq after 02750 batchs: 1346.30615234375
INFO:root:Train (Epoch 22): Loss/seq after 02800 batchs: 1354.457275390625
INFO:root:Train (Epoch 22): Loss/seq after 02850 batchs: 1349.7349853515625
INFO:root:Train (Epoch 22): Loss/seq after 02900 batchs: 1345.5762939453125
INFO:root:Train (Epoch 22): Loss/seq after 02950 batchs: 1336.165283203125
INFO:root:Train (Epoch 22): Loss/seq after 03000 batchs: 1332.04296875
INFO:root:Train (Epoch 22): Loss/seq after 03050 batchs: 1332.8292236328125
INFO:root:Train (Epoch 22): Loss/seq after 03100 batchs: 1347.4307861328125
INFO:root:Train (Epoch 22): Loss/seq after 03150 batchs: 1365.4725341796875
INFO:root:Train (Epoch 22): Loss/seq after 03200 batchs: 1378.4771728515625
INFO:root:Train (Epoch 22): Loss/seq after 03250 batchs: 1390.998291015625
INFO:root:Train (Epoch 22): Loss/seq after 03300 batchs: 1389.3092041015625
INFO:root:Train (Epoch 22): Loss/seq after 03350 batchs: 1387.9337158203125
INFO:root:Train (Epoch 22): Loss/seq after 03400 batchs: 1377.167724609375
INFO:root:Train (Epoch 22): Loss/seq after 03450 batchs: 1368.7099609375
INFO:root:Train (Epoch 22): Loss/seq after 03500 batchs: 1366.75537109375
INFO:root:Train (Epoch 22): Loss/seq after 03550 batchs: 1359.8048095703125
INFO:root:Train (Epoch 22): Loss/seq after 03600 batchs: 1363.5364990234375
INFO:root:Train (Epoch 22): Loss/seq after 03650 batchs: 1357.1519775390625
INFO:root:Train (Epoch 22): Loss/seq after 03700 batchs: 1355.166748046875
INFO:root:Train (Epoch 22): Loss/seq after 03750 batchs: 1353.5296630859375
INFO:root:Train (Epoch 22): Loss/seq after 03800 batchs: 1344.9583740234375
INFO:root:Train (Epoch 22): Loss/seq after 03850 batchs: 1339.1016845703125
INFO:root:Train (Epoch 22): Loss/seq after 03900 batchs: 1345.0216064453125
INFO:root:Train (Epoch 22): Loss/seq after 03950 batchs: 1353.0469970703125
INFO:root:Train (Epoch 22): Loss/seq after 04000 batchs: 1342.4498291015625
INFO:root:Train (Epoch 22): Loss/seq after 04050 batchs: 1332.931396484375
INFO:root:Train (Epoch 22): Loss/seq after 04100 batchs: 1327.6126708984375
INFO:root:Train (Epoch 22): Loss/seq after 04150 batchs: 1320.9541015625
INFO:root:Train (Epoch 22): Loss/seq after 04200 batchs: 1314.2669677734375
INFO:root:Train (Epoch 22): Loss/seq after 04250 batchs: 1308.7197265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 22): Loss/seq after 00000 batches: 908.1135864257812
INFO:root:# Valid (Epoch 22): Loss/seq after 00050 batches: 1106.1357421875
INFO:root:# Valid (Epoch 22): Loss/seq after 00100 batches: 1414.55517578125
INFO:root:# Valid (Epoch 22): Loss/seq after 00150 batches: 1176.9974365234375
INFO:root:# Valid (Epoch 22): Loss/seq after 00200 batches: 1068.102783203125
INFO:root:Artifacts: Make stick videos for epoch 22
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_22_on_20220422_222904.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_22_index_673_on_20220422_222904.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 23): Loss/seq after 00000 batchs: 2356.962646484375
INFO:root:Train (Epoch 23): Loss/seq after 00050 batchs: 1707.154052734375
INFO:root:Train (Epoch 23): Loss/seq after 00100 batchs: 1654.9696044921875
INFO:root:Train (Epoch 23): Loss/seq after 00150 batchs: 1502.62744140625
INFO:root:Train (Epoch 23): Loss/seq after 00200 batchs: 1625.4012451171875
INFO:root:Train (Epoch 23): Loss/seq after 00250 batchs: 1734.591796875
INFO:root:Train (Epoch 23): Loss/seq after 00300 batchs: 1630.9129638671875
INFO:root:Train (Epoch 23): Loss/seq after 00350 batchs: 1524.2908935546875
INFO:root:Train (Epoch 23): Loss/seq after 00400 batchs: 1584.1962890625
INFO:root:Train (Epoch 23): Loss/seq after 00450 batchs: 1505.928955078125
INFO:root:Train (Epoch 23): Loss/seq after 00500 batchs: 1533.212158203125
INFO:root:Train (Epoch 23): Loss/seq after 00550 batchs: 1467.2373046875
INFO:root:Train (Epoch 23): Loss/seq after 00600 batchs: 1430.4013671875
INFO:root:Train (Epoch 23): Loss/seq after 00650 batchs: 1493.0830078125
INFO:root:Train (Epoch 23): Loss/seq after 00700 batchs: 1578.1441650390625
INFO:root:Train (Epoch 23): Loss/seq after 00750 batchs: 1615.7799072265625
INFO:root:Train (Epoch 23): Loss/seq after 00800 batchs: 1599.5045166015625
INFO:root:Train (Epoch 23): Loss/seq after 00850 batchs: 1563.859130859375
INFO:root:Train (Epoch 23): Loss/seq after 00900 batchs: 1565.300537109375
INFO:root:Train (Epoch 23): Loss/seq after 00950 batchs: 1655.0423583984375
INFO:root:Train (Epoch 23): Loss/seq after 01000 batchs: 1651.70166015625
INFO:root:Train (Epoch 23): Loss/seq after 01050 batchs: 1621.6622314453125
INFO:root:Train (Epoch 23): Loss/seq after 01100 batchs: 1604.76611328125
INFO:root:Train (Epoch 23): Loss/seq after 01150 batchs: 1579.1815185546875
INFO:root:Train (Epoch 23): Loss/seq after 01200 batchs: 1559.825927734375
INFO:root:Train (Epoch 23): Loss/seq after 01250 batchs: 1545.507080078125
INFO:root:Train (Epoch 23): Loss/seq after 01300 batchs: 1556.6492919921875
INFO:root:Train (Epoch 23): Loss/seq after 01350 batchs: 1556.0341796875
INFO:root:Train (Epoch 23): Loss/seq after 01400 batchs: 1605.8992919921875
INFO:root:Train (Epoch 23): Loss/seq after 01450 batchs: 1587.7659912109375
INFO:root:Train (Epoch 23): Loss/seq after 01500 batchs: 1571.6239013671875
INFO:root:Train (Epoch 23): Loss/seq after 01550 batchs: 1568.02978515625
INFO:root:Train (Epoch 23): Loss/seq after 01600 batchs: 1543.989013671875
INFO:root:Train (Epoch 23): Loss/seq after 01650 batchs: 1532.387451171875
INFO:root:Train (Epoch 23): Loss/seq after 01700 batchs: 1517.424560546875
INFO:root:Train (Epoch 23): Loss/seq after 01750 batchs: 1499.818359375
INFO:root:Train (Epoch 23): Loss/seq after 01800 batchs: 1480.79345703125
INFO:root:Train (Epoch 23): Loss/seq after 01850 batchs: 1462.4100341796875
INFO:root:Train (Epoch 23): Loss/seq after 01900 batchs: 1456.4056396484375
INFO:root:Train (Epoch 23): Loss/seq after 01950 batchs: 1446.8717041015625
INFO:root:Train (Epoch 23): Loss/seq after 02000 batchs: 1432.9952392578125
INFO:root:Train (Epoch 23): Loss/seq after 02050 batchs: 1420.936767578125
INFO:root:Train (Epoch 23): Loss/seq after 02100 batchs: 1405.7940673828125
INFO:root:Train (Epoch 23): Loss/seq after 02150 batchs: 1391.996826171875
INFO:root:Train (Epoch 23): Loss/seq after 02200 batchs: 1377.340576171875
INFO:root:Train (Epoch 23): Loss/seq after 02250 batchs: 1377.3592529296875
INFO:root:Train (Epoch 23): Loss/seq after 02300 batchs: 1380.5166015625
INFO:root:Train (Epoch 23): Loss/seq after 02350 batchs: 1368.990478515625
INFO:root:Train (Epoch 23): Loss/seq after 02400 batchs: 1362.31201171875
INFO:root:Train (Epoch 23): Loss/seq after 02450 batchs: 1347.051513671875
INFO:root:Train (Epoch 23): Loss/seq after 02500 batchs: 1327.4356689453125
INFO:root:Train (Epoch 23): Loss/seq after 02550 batchs: 1314.38916015625
INFO:root:Train (Epoch 23): Loss/seq after 02600 batchs: 1310.2703857421875
INFO:root:Train (Epoch 23): Loss/seq after 02650 batchs: 1303.6939697265625
INFO:root:Train (Epoch 23): Loss/seq after 02700 batchs: 1298.8963623046875
INFO:root:Train (Epoch 23): Loss/seq after 02750 batchs: 1328.902587890625
INFO:root:Train (Epoch 23): Loss/seq after 02800 batchs: 1337.0289306640625
INFO:root:Train (Epoch 23): Loss/seq after 02850 batchs: 1332.6954345703125
INFO:root:Train (Epoch 23): Loss/seq after 02900 batchs: 1328.919921875
INFO:root:Train (Epoch 23): Loss/seq after 02950 batchs: 1319.89892578125
INFO:root:Train (Epoch 23): Loss/seq after 03000 batchs: 1316.0345458984375
INFO:root:Train (Epoch 23): Loss/seq after 03050 batchs: 1317.016357421875
INFO:root:Train (Epoch 23): Loss/seq after 03100 batchs: 1331.08251953125
INFO:root:Train (Epoch 23): Loss/seq after 03150 batchs: 1349.5723876953125
INFO:root:Train (Epoch 23): Loss/seq after 03200 batchs: 1362.5479736328125
INFO:root:Train (Epoch 23): Loss/seq after 03250 batchs: 1375.0594482421875
INFO:root:Train (Epoch 23): Loss/seq after 03300 batchs: 1372.5531005859375
INFO:root:Train (Epoch 23): Loss/seq after 03350 batchs: 1371.008056640625
INFO:root:Train (Epoch 23): Loss/seq after 03400 batchs: 1360.542724609375
INFO:root:Train (Epoch 23): Loss/seq after 03450 batchs: 1353.597412109375
INFO:root:Train (Epoch 23): Loss/seq after 03500 batchs: 1351.501220703125
INFO:root:Train (Epoch 23): Loss/seq after 03550 batchs: 1344.8336181640625
INFO:root:Train (Epoch 23): Loss/seq after 03600 batchs: 1348.9920654296875
INFO:root:Train (Epoch 23): Loss/seq after 03650 batchs: 1342.8760986328125
INFO:root:Train (Epoch 23): Loss/seq after 03700 batchs: 1340.7222900390625
INFO:root:Train (Epoch 23): Loss/seq after 03750 batchs: 1339.1070556640625
INFO:root:Train (Epoch 23): Loss/seq after 03800 batchs: 1330.8028564453125
INFO:root:Train (Epoch 23): Loss/seq after 03850 batchs: 1325.130859375
INFO:root:Train (Epoch 23): Loss/seq after 03900 batchs: 1331.5684814453125
INFO:root:Train (Epoch 23): Loss/seq after 03950 batchs: 1339.3106689453125
INFO:root:Train (Epoch 23): Loss/seq after 04000 batchs: 1328.952880859375
INFO:root:Train (Epoch 23): Loss/seq after 04050 batchs: 1319.609619140625
INFO:root:Train (Epoch 23): Loss/seq after 04100 batchs: 1314.6058349609375
INFO:root:Train (Epoch 23): Loss/seq after 04150 batchs: 1308.2955322265625
INFO:root:Train (Epoch 23): Loss/seq after 04200 batchs: 1302.4521484375
INFO:root:Train (Epoch 23): Loss/seq after 04250 batchs: 1297.0302734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 23): Loss/seq after 00000 batches: 910.3072509765625
INFO:root:# Valid (Epoch 23): Loss/seq after 00050 batches: 1105.3568115234375
INFO:root:# Valid (Epoch 23): Loss/seq after 00100 batches: 1407.92236328125
INFO:root:# Valid (Epoch 23): Loss/seq after 00150 batches: 1145.6934814453125
INFO:root:# Valid (Epoch 23): Loss/seq after 00200 batches: 1033.81982421875
INFO:root:Artifacts: Make stick videos for epoch 23
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_23_on_20220422_223352.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_23_index_1073_on_20220422_223352.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 24): Loss/seq after 00000 batchs: 2393.9091796875
INFO:root:Train (Epoch 24): Loss/seq after 00050 batchs: 1724.613525390625
INFO:root:Train (Epoch 24): Loss/seq after 00100 batchs: 1619.950439453125
INFO:root:Train (Epoch 24): Loss/seq after 00150 batchs: 1436.117431640625
INFO:root:Train (Epoch 24): Loss/seq after 00200 batchs: 1557.5130615234375
INFO:root:Train (Epoch 24): Loss/seq after 00250 batchs: 1667.20166015625
INFO:root:Train (Epoch 24): Loss/seq after 00300 batchs: 1573.9097900390625
INFO:root:Train (Epoch 24): Loss/seq after 00350 batchs: 1469.146484375
INFO:root:Train (Epoch 24): Loss/seq after 00400 batchs: 1519.7919921875
INFO:root:Train (Epoch 24): Loss/seq after 00450 batchs: 1448.8486328125
INFO:root:Train (Epoch 24): Loss/seq after 00500 batchs: 1470.275390625
INFO:root:Train (Epoch 24): Loss/seq after 00550 batchs: 1410.21142578125
INFO:root:Train (Epoch 24): Loss/seq after 00600 batchs: 1371.8118896484375
INFO:root:Train (Epoch 24): Loss/seq after 00650 batchs: 1441.1427001953125
INFO:root:Train (Epoch 24): Loss/seq after 00700 batchs: 1529.760009765625
INFO:root:Train (Epoch 24): Loss/seq after 00750 batchs: 1567.317138671875
INFO:root:Train (Epoch 24): Loss/seq after 00800 batchs: 1550.8114013671875
INFO:root:Train (Epoch 24): Loss/seq after 00850 batchs: 1516.601806640625
INFO:root:Train (Epoch 24): Loss/seq after 00900 batchs: 1518.226318359375
INFO:root:Train (Epoch 24): Loss/seq after 00950 batchs: 1606.2230224609375
INFO:root:Train (Epoch 24): Loss/seq after 01000 batchs: 1603.8272705078125
INFO:root:Train (Epoch 24): Loss/seq after 01050 batchs: 1576.755615234375
INFO:root:Train (Epoch 24): Loss/seq after 01100 batchs: 1569.2276611328125
INFO:root:Train (Epoch 24): Loss/seq after 01150 batchs: 1544.4173583984375
INFO:root:Train (Epoch 24): Loss/seq after 01200 batchs: 1525.506103515625
INFO:root:Train (Epoch 24): Loss/seq after 01250 batchs: 1513.384765625
INFO:root:Train (Epoch 24): Loss/seq after 01300 batchs: 1526.3756103515625
INFO:root:Train (Epoch 24): Loss/seq after 01350 batchs: 1526.78173828125
INFO:root:Train (Epoch 24): Loss/seq after 01400 batchs: 1576.3868408203125
INFO:root:Train (Epoch 24): Loss/seq after 01450 batchs: 1558.917236328125
INFO:root:Train (Epoch 24): Loss/seq after 01500 batchs: 1543.7110595703125
INFO:root:Train (Epoch 24): Loss/seq after 01550 batchs: 1537.4578857421875
INFO:root:Train (Epoch 24): Loss/seq after 01600 batchs: 1514.8477783203125
INFO:root:Train (Epoch 24): Loss/seq after 01650 batchs: 1500.830078125
INFO:root:Train (Epoch 24): Loss/seq after 01700 batchs: 1485.7239990234375
INFO:root:Train (Epoch 24): Loss/seq after 01750 batchs: 1469.1846923828125
INFO:root:Train (Epoch 24): Loss/seq after 01800 batchs: 1451.1859130859375
INFO:root:Train (Epoch 24): Loss/seq after 01850 batchs: 1433.19140625
INFO:root:Train (Epoch 24): Loss/seq after 01900 batchs: 1427.255615234375
INFO:root:Train (Epoch 24): Loss/seq after 01950 batchs: 1417.0030517578125
INFO:root:Train (Epoch 24): Loss/seq after 02000 batchs: 1403.8507080078125
INFO:root:Train (Epoch 24): Loss/seq after 02050 batchs: 1392.18017578125
INFO:root:Train (Epoch 24): Loss/seq after 02100 batchs: 1377.669189453125
INFO:root:Train (Epoch 24): Loss/seq after 02150 batchs: 1364.493408203125
INFO:root:Train (Epoch 24): Loss/seq after 02200 batchs: 1350.4398193359375
INFO:root:Train (Epoch 24): Loss/seq after 02250 batchs: 1347.8272705078125
INFO:root:Train (Epoch 24): Loss/seq after 02300 batchs: 1347.9974365234375
INFO:root:Train (Epoch 24): Loss/seq after 02350 batchs: 1337.681640625
INFO:root:Train (Epoch 24): Loss/seq after 02400 batchs: 1331.2283935546875
INFO:root:Train (Epoch 24): Loss/seq after 02450 batchs: 1316.312255859375
INFO:root:Train (Epoch 24): Loss/seq after 02500 batchs: 1297.4183349609375
INFO:root:Train (Epoch 24): Loss/seq after 02550 batchs: 1284.4822998046875
INFO:root:Train (Epoch 24): Loss/seq after 02600 batchs: 1281.1351318359375
INFO:root:Train (Epoch 24): Loss/seq after 02650 batchs: 1274.828125
INFO:root:Train (Epoch 24): Loss/seq after 02700 batchs: 1270.1951904296875
INFO:root:Train (Epoch 24): Loss/seq after 02750 batchs: 1300.1634521484375
INFO:root:Train (Epoch 24): Loss/seq after 02800 batchs: 1308.7733154296875
INFO:root:Train (Epoch 24): Loss/seq after 02850 batchs: 1304.77294921875
INFO:root:Train (Epoch 24): Loss/seq after 02900 batchs: 1301.325439453125
INFO:root:Train (Epoch 24): Loss/seq after 02950 batchs: 1292.84521484375
INFO:root:Train (Epoch 24): Loss/seq after 03000 batchs: 1289.4188232421875
INFO:root:Train (Epoch 24): Loss/seq after 03050 batchs: 1290.8719482421875
INFO:root:Train (Epoch 24): Loss/seq after 03100 batchs: 1304.61181640625
INFO:root:Train (Epoch 24): Loss/seq after 03150 batchs: 1327.7037353515625
INFO:root:Train (Epoch 24): Loss/seq after 03200 batchs: 1341.9580078125
INFO:root:Train (Epoch 24): Loss/seq after 03250 batchs: 1355.718994140625
INFO:root:Train (Epoch 24): Loss/seq after 03300 batchs: 1353.056640625
INFO:root:Train (Epoch 24): Loss/seq after 03350 batchs: 1351.7451171875
INFO:root:Train (Epoch 24): Loss/seq after 03400 batchs: 1341.8094482421875
INFO:root:Train (Epoch 24): Loss/seq after 03450 batchs: 1334.565673828125
INFO:root:Train (Epoch 24): Loss/seq after 03500 batchs: 1332.1385498046875
INFO:root:Train (Epoch 24): Loss/seq after 03550 batchs: 1325.2918701171875
INFO:root:Train (Epoch 24): Loss/seq after 03600 batchs: 1329.635009765625
INFO:root:Train (Epoch 24): Loss/seq after 03650 batchs: 1323.558349609375
INFO:root:Train (Epoch 24): Loss/seq after 03700 batchs: 1321.55224609375
INFO:root:Train (Epoch 24): Loss/seq after 03750 batchs: 1320.052978515625
INFO:root:Train (Epoch 24): Loss/seq after 03800 batchs: 1311.8048095703125
INFO:root:Train (Epoch 24): Loss/seq after 03850 batchs: 1306.2025146484375
INFO:root:Train (Epoch 24): Loss/seq after 03900 batchs: 1312.502685546875
INFO:root:Train (Epoch 24): Loss/seq after 03950 batchs: 1320.1663818359375
INFO:root:Train (Epoch 24): Loss/seq after 04000 batchs: 1310.1876220703125
INFO:root:Train (Epoch 24): Loss/seq after 04050 batchs: 1301.078369140625
INFO:root:Train (Epoch 24): Loss/seq after 04100 batchs: 1296.40966796875
INFO:root:Train (Epoch 24): Loss/seq after 04150 batchs: 1289.849609375
INFO:root:Train (Epoch 24): Loss/seq after 04200 batchs: 1283.1390380859375
INFO:root:Train (Epoch 24): Loss/seq after 04250 batchs: 1277.8260498046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 24): Loss/seq after 00000 batches: 905.241455078125
INFO:root:# Valid (Epoch 24): Loss/seq after 00050 batches: 1110.3197021484375
INFO:root:# Valid (Epoch 24): Loss/seq after 00100 batches: 1453.825927734375
INFO:root:# Valid (Epoch 24): Loss/seq after 00150 batches: 1220.781005859375
INFO:root:# Valid (Epoch 24): Loss/seq after 00200 batches: 1115.4140625
INFO:root:Artifacts: Make stick videos for epoch 24
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_24_on_20220422_223838.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_24_index_1152_on_20220422_223838.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 25): Loss/seq after 00000 batchs: 2468.89599609375
INFO:root:Train (Epoch 25): Loss/seq after 00050 batchs: 1695.716552734375
INFO:root:Train (Epoch 25): Loss/seq after 00100 batchs: 1607.7056884765625
INFO:root:Train (Epoch 25): Loss/seq after 00150 batchs: 1465.3922119140625
INFO:root:Train (Epoch 25): Loss/seq after 00200 batchs: 1580.0
INFO:root:Train (Epoch 25): Loss/seq after 00250 batchs: 1692.7847900390625
INFO:root:Train (Epoch 25): Loss/seq after 00300 batchs: 1596.692626953125
INFO:root:Train (Epoch 25): Loss/seq after 00350 batchs: 1490.03369140625
INFO:root:Train (Epoch 25): Loss/seq after 00400 batchs: 1531.6434326171875
INFO:root:Train (Epoch 25): Loss/seq after 00450 batchs: 1458.9959716796875
INFO:root:Train (Epoch 25): Loss/seq after 00500 batchs: 1468.513916015625
INFO:root:Train (Epoch 25): Loss/seq after 00550 batchs: 1403.1658935546875
INFO:root:Train (Epoch 25): Loss/seq after 00600 batchs: 1364.8697509765625
INFO:root:Train (Epoch 25): Loss/seq after 00650 batchs: 1431.052001953125
INFO:root:Train (Epoch 25): Loss/seq after 00700 batchs: 1520.299072265625
INFO:root:Train (Epoch 25): Loss/seq after 00750 batchs: 1557.287109375
INFO:root:Train (Epoch 25): Loss/seq after 00800 batchs: 1539.110595703125
INFO:root:Train (Epoch 25): Loss/seq after 00850 batchs: 1506.2200927734375
INFO:root:Train (Epoch 25): Loss/seq after 00900 batchs: 1506.5648193359375
INFO:root:Train (Epoch 25): Loss/seq after 00950 batchs: 1593.9541015625
INFO:root:Train (Epoch 25): Loss/seq after 01000 batchs: 1591.3714599609375
INFO:root:Train (Epoch 25): Loss/seq after 01050 batchs: 1573.9744873046875
INFO:root:Train (Epoch 25): Loss/seq after 01100 batchs: 1558.470458984375
INFO:root:Train (Epoch 25): Loss/seq after 01150 batchs: 1536.1920166015625
INFO:root:Train (Epoch 25): Loss/seq after 01200 batchs: 1518.7197265625
INFO:root:Train (Epoch 25): Loss/seq after 01250 batchs: 1507.3260498046875
INFO:root:Train (Epoch 25): Loss/seq after 01300 batchs: 1520.176513671875
INFO:root:Train (Epoch 25): Loss/seq after 01350 batchs: 1520.863037109375
INFO:root:Train (Epoch 25): Loss/seq after 01400 batchs: 1569.0146484375
INFO:root:Train (Epoch 25): Loss/seq after 01450 batchs: 1552.7646484375
INFO:root:Train (Epoch 25): Loss/seq after 01500 batchs: 1536.724609375
INFO:root:Train (Epoch 25): Loss/seq after 01550 batchs: 1530.3643798828125
INFO:root:Train (Epoch 25): Loss/seq after 01600 batchs: 1508.471435546875
INFO:root:Train (Epoch 25): Loss/seq after 01650 batchs: 1495.5325927734375
INFO:root:Train (Epoch 25): Loss/seq after 01700 batchs: 1480.5439453125
INFO:root:Train (Epoch 25): Loss/seq after 01750 batchs: 1464.484619140625
INFO:root:Train (Epoch 25): Loss/seq after 01800 batchs: 1446.8668212890625
INFO:root:Train (Epoch 25): Loss/seq after 01850 batchs: 1429.0098876953125
INFO:root:Train (Epoch 25): Loss/seq after 01900 batchs: 1423.33935546875
INFO:root:Train (Epoch 25): Loss/seq after 01950 batchs: 1413.5413818359375
INFO:root:Train (Epoch 25): Loss/seq after 02000 batchs: 1400.792724609375
INFO:root:Train (Epoch 25): Loss/seq after 02050 batchs: 1389.427734375
INFO:root:Train (Epoch 25): Loss/seq after 02100 batchs: 1375.0184326171875
INFO:root:Train (Epoch 25): Loss/seq after 02150 batchs: 1361.8939208984375
INFO:root:Train (Epoch 25): Loss/seq after 02200 batchs: 1347.805908203125
INFO:root:Train (Epoch 25): Loss/seq after 02250 batchs: 1344.23486328125
INFO:root:Train (Epoch 25): Loss/seq after 02300 batchs: 1344.0673828125
INFO:root:Train (Epoch 25): Loss/seq after 02350 batchs: 1333.1085205078125
INFO:root:Train (Epoch 25): Loss/seq after 02400 batchs: 1327.0113525390625
INFO:root:Train (Epoch 25): Loss/seq after 02450 batchs: 1312.653564453125
INFO:root:Train (Epoch 25): Loss/seq after 02500 batchs: 1293.82666015625
INFO:root:Train (Epoch 25): Loss/seq after 02550 batchs: 1281.253173828125
INFO:root:Train (Epoch 25): Loss/seq after 02600 batchs: 1278.5040283203125
INFO:root:Train (Epoch 25): Loss/seq after 02650 batchs: 1272.396240234375
INFO:root:Train (Epoch 25): Loss/seq after 02700 batchs: 1270.249755859375
INFO:root:Train (Epoch 25): Loss/seq after 02750 batchs: 1299.8515625
INFO:root:Train (Epoch 25): Loss/seq after 02800 batchs: 1308.097412109375
INFO:root:Train (Epoch 25): Loss/seq after 02850 batchs: 1303.4454345703125
INFO:root:Train (Epoch 25): Loss/seq after 02900 batchs: 1298.9906005859375
INFO:root:Train (Epoch 25): Loss/seq after 02950 batchs: 1290.3563232421875
INFO:root:Train (Epoch 25): Loss/seq after 03000 batchs: 1286.950439453125
INFO:root:Train (Epoch 25): Loss/seq after 03050 batchs: 1288.351318359375
INFO:root:Train (Epoch 25): Loss/seq after 03100 batchs: 1300.454345703125
INFO:root:Train (Epoch 25): Loss/seq after 03150 batchs: 1316.7596435546875
INFO:root:Train (Epoch 25): Loss/seq after 03200 batchs: 1330.1256103515625
INFO:root:Train (Epoch 25): Loss/seq after 03250 batchs: 1343.42919921875
INFO:root:Train (Epoch 25): Loss/seq after 03300 batchs: 1342.97900390625
INFO:root:Train (Epoch 25): Loss/seq after 03350 batchs: 1342.2017822265625
INFO:root:Train (Epoch 25): Loss/seq after 03400 batchs: 1332.1123046875
INFO:root:Train (Epoch 25): Loss/seq after 03450 batchs: 1324.3048095703125
INFO:root:Train (Epoch 25): Loss/seq after 03500 batchs: 1321.612548828125
INFO:root:Train (Epoch 25): Loss/seq after 03550 batchs: 1314.26953125
INFO:root:Train (Epoch 25): Loss/seq after 03600 batchs: 1318.535888671875
INFO:root:Train (Epoch 25): Loss/seq after 03650 batchs: 1312.1558837890625
INFO:root:Train (Epoch 25): Loss/seq after 03700 batchs: 1310.412353515625
INFO:root:Train (Epoch 25): Loss/seq after 03750 batchs: 1309.01611328125
INFO:root:Train (Epoch 25): Loss/seq after 03800 batchs: 1300.8416748046875
INFO:root:Train (Epoch 25): Loss/seq after 03850 batchs: 1295.3511962890625
INFO:root:Train (Epoch 25): Loss/seq after 03900 batchs: 1301.001708984375
INFO:root:Train (Epoch 25): Loss/seq after 03950 batchs: 1308.2025146484375
INFO:root:Train (Epoch 25): Loss/seq after 04000 batchs: 1298.2178955078125
INFO:root:Train (Epoch 25): Loss/seq after 04050 batchs: 1289.2607421875
INFO:root:Train (Epoch 25): Loss/seq after 04100 batchs: 1284.409423828125
INFO:root:Train (Epoch 25): Loss/seq after 04150 batchs: 1277.8319091796875
INFO:root:Train (Epoch 25): Loss/seq after 04200 batchs: 1271.0780029296875
INFO:root:Train (Epoch 25): Loss/seq after 04250 batchs: 1265.76123046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 25): Loss/seq after 00000 batches: 893.04931640625
INFO:root:# Valid (Epoch 25): Loss/seq after 00050 batches: 1107.532470703125
INFO:root:# Valid (Epoch 25): Loss/seq after 00100 batches: 1409.7059326171875
INFO:root:# Valid (Epoch 25): Loss/seq after 00150 batches: 1149.7091064453125
INFO:root:# Valid (Epoch 25): Loss/seq after 00200 batches: 1044.5224609375
INFO:root:Artifacts: Make stick videos for epoch 25
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_25_on_20220422_224322.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_25_index_1363_on_20220422_224322.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 26): Loss/seq after 00000 batchs: 2450.770263671875
INFO:root:Train (Epoch 26): Loss/seq after 00050 batchs: 1612.0628662109375
INFO:root:Train (Epoch 26): Loss/seq after 00100 batchs: 1517.9852294921875
INFO:root:Train (Epoch 26): Loss/seq after 00150 batchs: 1353.9521484375
INFO:root:Train (Epoch 26): Loss/seq after 00200 batchs: 1479.572265625
INFO:root:Train (Epoch 26): Loss/seq after 00250 batchs: 1605.841796875
INFO:root:Train (Epoch 26): Loss/seq after 00300 batchs: 1521.7137451171875
INFO:root:Train (Epoch 26): Loss/seq after 00350 batchs: 1423.4981689453125
INFO:root:Train (Epoch 26): Loss/seq after 00400 batchs: 1472.05908203125
INFO:root:Train (Epoch 26): Loss/seq after 00450 batchs: 1406.0860595703125
INFO:root:Train (Epoch 26): Loss/seq after 00500 batchs: 1425.761962890625
INFO:root:Train (Epoch 26): Loss/seq after 00550 batchs: 1366.318115234375
INFO:root:Train (Epoch 26): Loss/seq after 00600 batchs: 1336.1240234375
INFO:root:Train (Epoch 26): Loss/seq after 00650 batchs: 1404.28857421875
INFO:root:Train (Epoch 26): Loss/seq after 00700 batchs: 1495.7252197265625
INFO:root:Train (Epoch 26): Loss/seq after 00750 batchs: 1534.343017578125
INFO:root:Train (Epoch 26): Loss/seq after 00800 batchs: 1516.68994140625
INFO:root:Train (Epoch 26): Loss/seq after 00850 batchs: 1486.3341064453125
INFO:root:Train (Epoch 26): Loss/seq after 00900 batchs: 1491.3857421875
INFO:root:Train (Epoch 26): Loss/seq after 00950 batchs: 1580.2386474609375
INFO:root:Train (Epoch 26): Loss/seq after 01000 batchs: 1577.2080078125
INFO:root:Train (Epoch 26): Loss/seq after 01050 batchs: 1549.971923828125
INFO:root:Train (Epoch 26): Loss/seq after 01100 batchs: 1536.4710693359375
INFO:root:Train (Epoch 26): Loss/seq after 01150 batchs: 1513.18798828125
INFO:root:Train (Epoch 26): Loss/seq after 01200 batchs: 1496.1160888671875
INFO:root:Train (Epoch 26): Loss/seq after 01250 batchs: 1483.841796875
INFO:root:Train (Epoch 26): Loss/seq after 01300 batchs: 1497.414794921875
INFO:root:Train (Epoch 26): Loss/seq after 01350 batchs: 1499.0
INFO:root:Train (Epoch 26): Loss/seq after 01400 batchs: 1547.4189453125
INFO:root:Train (Epoch 26): Loss/seq after 01450 batchs: 1530.533935546875
INFO:root:Train (Epoch 26): Loss/seq after 01500 batchs: 1514.900390625
INFO:root:Train (Epoch 26): Loss/seq after 01550 batchs: 1507.918212890625
INFO:root:Train (Epoch 26): Loss/seq after 01600 batchs: 1485.7984619140625
INFO:root:Train (Epoch 26): Loss/seq after 01650 batchs: 1473.7529296875
INFO:root:Train (Epoch 26): Loss/seq after 01700 batchs: 1458.853759765625
INFO:root:Train (Epoch 26): Loss/seq after 01750 batchs: 1442.9888916015625
INFO:root:Train (Epoch 26): Loss/seq after 01800 batchs: 1425.0745849609375
INFO:root:Train (Epoch 26): Loss/seq after 01850 batchs: 1407.50244140625
INFO:root:Train (Epoch 26): Loss/seq after 01900 batchs: 1401.697021484375
INFO:root:Train (Epoch 26): Loss/seq after 01950 batchs: 1391.3404541015625
INFO:root:Train (Epoch 26): Loss/seq after 02000 batchs: 1378.6805419921875
INFO:root:Train (Epoch 26): Loss/seq after 02050 batchs: 1367.260009765625
INFO:root:Train (Epoch 26): Loss/seq after 02100 batchs: 1353.1383056640625
INFO:root:Train (Epoch 26): Loss/seq after 02150 batchs: 1340.1932373046875
INFO:root:Train (Epoch 26): Loss/seq after 02200 batchs: 1326.572998046875
INFO:root:Train (Epoch 26): Loss/seq after 02250 batchs: 1323.730712890625
INFO:root:Train (Epoch 26): Loss/seq after 02300 batchs: 1324.3846435546875
INFO:root:Train (Epoch 26): Loss/seq after 02350 batchs: 1312.0889892578125
INFO:root:Train (Epoch 26): Loss/seq after 02400 batchs: 1305.5164794921875
INFO:root:Train (Epoch 26): Loss/seq after 02450 batchs: 1290.71484375
INFO:root:Train (Epoch 26): Loss/seq after 02500 batchs: 1272.1533203125
INFO:root:Train (Epoch 26): Loss/seq after 02550 batchs: 1259.6181640625
INFO:root:Train (Epoch 26): Loss/seq after 02600 batchs: 1256.1226806640625
INFO:root:Train (Epoch 26): Loss/seq after 02650 batchs: 1250.299072265625
INFO:root:Train (Epoch 26): Loss/seq after 02700 batchs: 1246.389892578125
INFO:root:Train (Epoch 26): Loss/seq after 02750 batchs: 1276.0244140625
INFO:root:Train (Epoch 26): Loss/seq after 02800 batchs: 1284.25830078125
INFO:root:Train (Epoch 26): Loss/seq after 02850 batchs: 1280.961181640625
INFO:root:Train (Epoch 26): Loss/seq after 02900 batchs: 1277.4337158203125
INFO:root:Train (Epoch 26): Loss/seq after 02950 batchs: 1269.337890625
INFO:root:Train (Epoch 26): Loss/seq after 03000 batchs: 1266.2911376953125
INFO:root:Train (Epoch 26): Loss/seq after 03050 batchs: 1268.1107177734375
INFO:root:Train (Epoch 26): Loss/seq after 03100 batchs: 1282.4979248046875
INFO:root:Train (Epoch 26): Loss/seq after 03150 batchs: 1301.27490234375
INFO:root:Train (Epoch 26): Loss/seq after 03200 batchs: 1314.89697265625
INFO:root:Train (Epoch 26): Loss/seq after 03250 batchs: 1327.8878173828125
INFO:root:Train (Epoch 26): Loss/seq after 03300 batchs: 1324.869140625
INFO:root:Train (Epoch 26): Loss/seq after 03350 batchs: 1323.31494140625
INFO:root:Train (Epoch 26): Loss/seq after 03400 batchs: 1313.587646484375
INFO:root:Train (Epoch 26): Loss/seq after 03450 batchs: 1305.8199462890625
INFO:root:Train (Epoch 26): Loss/seq after 03500 batchs: 1304.433837890625
INFO:root:Train (Epoch 26): Loss/seq after 03550 batchs: 1297.344970703125
INFO:root:Train (Epoch 26): Loss/seq after 03600 batchs: 1301.68017578125
INFO:root:Train (Epoch 26): Loss/seq after 03650 batchs: 1295.3846435546875
INFO:root:Train (Epoch 26): Loss/seq after 03700 batchs: 1293.534423828125
INFO:root:Train (Epoch 26): Loss/seq after 03750 batchs: 1292.407470703125
INFO:root:Train (Epoch 26): Loss/seq after 03800 batchs: 1284.4512939453125
INFO:root:Train (Epoch 26): Loss/seq after 03850 batchs: 1279.1732177734375
INFO:root:Train (Epoch 26): Loss/seq after 03900 batchs: 1285.3553466796875
INFO:root:Train (Epoch 26): Loss/seq after 03950 batchs: 1292.6343994140625
INFO:root:Train (Epoch 26): Loss/seq after 04000 batchs: 1282.8192138671875
INFO:root:Train (Epoch 26): Loss/seq after 04050 batchs: 1274.040283203125
INFO:root:Train (Epoch 26): Loss/seq after 04100 batchs: 1269.0286865234375
INFO:root:Train (Epoch 26): Loss/seq after 04150 batchs: 1262.57275390625
INFO:root:Train (Epoch 26): Loss/seq after 04200 batchs: 1256.31787109375
INFO:root:Train (Epoch 26): Loss/seq after 04250 batchs: 1251.41064453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 26): Loss/seq after 00000 batches: 899.5084838867188
INFO:root:# Valid (Epoch 26): Loss/seq after 00050 batches: 1106.254150390625
INFO:root:# Valid (Epoch 26): Loss/seq after 00100 batches: 1412.367919921875
INFO:root:# Valid (Epoch 26): Loss/seq after 00150 batches: 1146.837646484375
INFO:root:# Valid (Epoch 26): Loss/seq after 00200 batches: 1043.1029052734375
INFO:root:Artifacts: Make stick videos for epoch 26
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_26_on_20220422_224811.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_26_index_898_on_20220422_224811.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 27): Loss/seq after 00000 batchs: 2400.511962890625
INFO:root:Train (Epoch 27): Loss/seq after 00050 batchs: 1609.3331298828125
INFO:root:Train (Epoch 27): Loss/seq after 00100 batchs: 1550.5179443359375
INFO:root:Train (Epoch 27): Loss/seq after 00150 batchs: 1380.73046875
INFO:root:Train (Epoch 27): Loss/seq after 00200 batchs: 1505.233642578125
INFO:root:Train (Epoch 27): Loss/seq after 00250 batchs: 1619.534912109375
INFO:root:Train (Epoch 27): Loss/seq after 00300 batchs: 1532.9739990234375
INFO:root:Train (Epoch 27): Loss/seq after 00350 batchs: 1430.6602783203125
INFO:root:Train (Epoch 27): Loss/seq after 00400 batchs: 1474.0343017578125
INFO:root:Train (Epoch 27): Loss/seq after 00450 batchs: 1408.354736328125
INFO:root:Train (Epoch 27): Loss/seq after 00500 batchs: 1417.90234375
INFO:root:Train (Epoch 27): Loss/seq after 00550 batchs: 1356.6654052734375
INFO:root:Train (Epoch 27): Loss/seq after 00600 batchs: 1318.120849609375
INFO:root:Train (Epoch 27): Loss/seq after 00650 batchs: 1387.6181640625
INFO:root:Train (Epoch 27): Loss/seq after 00700 batchs: 1479.967041015625
INFO:root:Train (Epoch 27): Loss/seq after 00750 batchs: 1518.7564697265625
INFO:root:Train (Epoch 27): Loss/seq after 00800 batchs: 1499.998046875
INFO:root:Train (Epoch 27): Loss/seq after 00850 batchs: 1466.1324462890625
INFO:root:Train (Epoch 27): Loss/seq after 00900 batchs: 1468.049072265625
INFO:root:Train (Epoch 27): Loss/seq after 00950 batchs: 1554.2208251953125
INFO:root:Train (Epoch 27): Loss/seq after 01000 batchs: 1551.4197998046875
INFO:root:Train (Epoch 27): Loss/seq after 01050 batchs: 1521.774169921875
INFO:root:Train (Epoch 27): Loss/seq after 01100 batchs: 1508.2027587890625
INFO:root:Train (Epoch 27): Loss/seq after 01150 batchs: 1485.7628173828125
INFO:root:Train (Epoch 27): Loss/seq after 01200 batchs: 1469.373779296875
INFO:root:Train (Epoch 27): Loss/seq after 01250 batchs: 1458.6195068359375
INFO:root:Train (Epoch 27): Loss/seq after 01300 batchs: 1473.0826416015625
INFO:root:Train (Epoch 27): Loss/seq after 01350 batchs: 1475.4810791015625
INFO:root:Train (Epoch 27): Loss/seq after 01400 batchs: 1525.103271484375
INFO:root:Train (Epoch 27): Loss/seq after 01450 batchs: 1509.8475341796875
INFO:root:Train (Epoch 27): Loss/seq after 01500 batchs: 1494.6580810546875
INFO:root:Train (Epoch 27): Loss/seq after 01550 batchs: 1487.865234375
INFO:root:Train (Epoch 27): Loss/seq after 01600 batchs: 1466.0667724609375
INFO:root:Train (Epoch 27): Loss/seq after 01650 batchs: 1452.9825439453125
INFO:root:Train (Epoch 27): Loss/seq after 01700 batchs: 1438.659423828125
INFO:root:Train (Epoch 27): Loss/seq after 01750 batchs: 1423.0321044921875
INFO:root:Train (Epoch 27): Loss/seq after 01800 batchs: 1405.3931884765625
INFO:root:Train (Epoch 27): Loss/seq after 01850 batchs: 1388.378662109375
INFO:root:Train (Epoch 27): Loss/seq after 01900 batchs: 1382.778564453125
INFO:root:Train (Epoch 27): Loss/seq after 01950 batchs: 1372.738037109375
INFO:root:Train (Epoch 27): Loss/seq after 02000 batchs: 1360.3941650390625
INFO:root:Train (Epoch 27): Loss/seq after 02050 batchs: 1349.45751953125
INFO:root:Train (Epoch 27): Loss/seq after 02100 batchs: 1335.8272705078125
INFO:root:Train (Epoch 27): Loss/seq after 02150 batchs: 1323.206298828125
INFO:root:Train (Epoch 27): Loss/seq after 02200 batchs: 1309.943603515625
INFO:root:Train (Epoch 27): Loss/seq after 02250 batchs: 1307.2763671875
INFO:root:Train (Epoch 27): Loss/seq after 02300 batchs: 1309.9261474609375
INFO:root:Train (Epoch 27): Loss/seq after 02350 batchs: 1299.743408203125
INFO:root:Train (Epoch 27): Loss/seq after 02400 batchs: 1295.7816162109375
INFO:root:Train (Epoch 27): Loss/seq after 02450 batchs: 1283.33154296875
INFO:root:Train (Epoch 27): Loss/seq after 02500 batchs: 1265.1240234375
INFO:root:Train (Epoch 27): Loss/seq after 02550 batchs: 1255.07275390625
INFO:root:Train (Epoch 27): Loss/seq after 02600 batchs: 1254.17626953125
INFO:root:Train (Epoch 27): Loss/seq after 02650 batchs: 1248.72119140625
INFO:root:Train (Epoch 27): Loss/seq after 02700 batchs: 1244.4140625
INFO:root:Train (Epoch 27): Loss/seq after 02750 batchs: 1274.506103515625
INFO:root:Train (Epoch 27): Loss/seq after 02800 batchs: 1283.0587158203125
INFO:root:Train (Epoch 27): Loss/seq after 02850 batchs: 1279.141357421875
INFO:root:Train (Epoch 27): Loss/seq after 02900 batchs: 1275.083740234375
INFO:root:Train (Epoch 27): Loss/seq after 02950 batchs: 1267.04833984375
INFO:root:Train (Epoch 27): Loss/seq after 03000 batchs: 1264.0389404296875
INFO:root:Train (Epoch 27): Loss/seq after 03050 batchs: 1265.8880615234375
INFO:root:Train (Epoch 27): Loss/seq after 03100 batchs: 1278.1365966796875
INFO:root:Train (Epoch 27): Loss/seq after 03150 batchs: 1296.73974609375
INFO:root:Train (Epoch 27): Loss/seq after 03200 batchs: 1310.381591796875
INFO:root:Train (Epoch 27): Loss/seq after 03250 batchs: 1323.285400390625
INFO:root:Train (Epoch 27): Loss/seq after 03300 batchs: 1319.921142578125
INFO:root:Train (Epoch 27): Loss/seq after 03350 batchs: 1318.7589111328125
INFO:root:Train (Epoch 27): Loss/seq after 03400 batchs: 1309.0
INFO:root:Train (Epoch 27): Loss/seq after 03450 batchs: 1300.9561767578125
INFO:root:Train (Epoch 27): Loss/seq after 03500 batchs: 1298.632080078125
INFO:root:Train (Epoch 27): Loss/seq after 03550 batchs: 1291.219482421875
INFO:root:Train (Epoch 27): Loss/seq after 03600 batchs: 1295.445068359375
INFO:root:Train (Epoch 27): Loss/seq after 03650 batchs: 1288.9984130859375
INFO:root:Train (Epoch 27): Loss/seq after 03700 batchs: 1286.877197265625
INFO:root:Train (Epoch 27): Loss/seq after 03750 batchs: 1285.8680419921875
INFO:root:Train (Epoch 27): Loss/seq after 03800 batchs: 1278.0394287109375
INFO:root:Train (Epoch 27): Loss/seq after 03850 batchs: 1272.8616943359375
INFO:root:Train (Epoch 27): Loss/seq after 03900 batchs: 1278.7567138671875
INFO:root:Train (Epoch 27): Loss/seq after 03950 batchs: 1286.3472900390625
INFO:root:Train (Epoch 27): Loss/seq after 04000 batchs: 1276.6240234375
INFO:root:Train (Epoch 27): Loss/seq after 04050 batchs: 1267.908203125
INFO:root:Train (Epoch 27): Loss/seq after 04100 batchs: 1262.8851318359375
INFO:root:Train (Epoch 27): Loss/seq after 04150 batchs: 1256.47314453125
INFO:root:Train (Epoch 27): Loss/seq after 04200 batchs: 1249.861572265625
INFO:root:Train (Epoch 27): Loss/seq after 04250 batchs: 1244.877197265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 27): Loss/seq after 00000 batches: 882.909912109375
INFO:root:# Valid (Epoch 27): Loss/seq after 00050 batches: 1101.2481689453125
INFO:root:# Valid (Epoch 27): Loss/seq after 00100 batches: 1412.543701171875
INFO:root:# Valid (Epoch 27): Loss/seq after 00150 batches: 1161.3721923828125
INFO:root:# Valid (Epoch 27): Loss/seq after 00200 batches: 1054.0115966796875
INFO:root:Artifacts: Make stick videos for epoch 27
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_27_on_20220422_225255.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_27_index_476_on_20220422_225255.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 28): Loss/seq after 00000 batchs: 2413.50390625
INFO:root:Train (Epoch 28): Loss/seq after 00050 batchs: 1632.0177001953125
INFO:root:Train (Epoch 28): Loss/seq after 00100 batchs: 1603.837890625
INFO:root:Train (Epoch 28): Loss/seq after 00150 batchs: 1455.6016845703125
INFO:root:Train (Epoch 28): Loss/seq after 00200 batchs: 1558.6378173828125
INFO:root:Train (Epoch 28): Loss/seq after 00250 batchs: 1674.8441162109375
INFO:root:Train (Epoch 28): Loss/seq after 00300 batchs: 1580.571533203125
INFO:root:Train (Epoch 28): Loss/seq after 00350 batchs: 1471.285888671875
INFO:root:Train (Epoch 28): Loss/seq after 00400 batchs: 1509.9166259765625
INFO:root:Train (Epoch 28): Loss/seq after 00450 batchs: 1439.9197998046875
INFO:root:Train (Epoch 28): Loss/seq after 00500 batchs: 1450.34521484375
INFO:root:Train (Epoch 28): Loss/seq after 00550 batchs: 1387.858154296875
INFO:root:Train (Epoch 28): Loss/seq after 00600 batchs: 1350.5684814453125
INFO:root:Train (Epoch 28): Loss/seq after 00650 batchs: 1417.3289794921875
INFO:root:Train (Epoch 28): Loss/seq after 00700 batchs: 1506.881591796875
INFO:root:Train (Epoch 28): Loss/seq after 00750 batchs: 1542.3558349609375
INFO:root:Train (Epoch 28): Loss/seq after 00800 batchs: 1523.375
INFO:root:Train (Epoch 28): Loss/seq after 00850 batchs: 1491.73876953125
INFO:root:Train (Epoch 28): Loss/seq after 00900 batchs: 1495.0106201171875
INFO:root:Train (Epoch 28): Loss/seq after 00950 batchs: 1580.333251953125
INFO:root:Train (Epoch 28): Loss/seq after 01000 batchs: 1576.83740234375
INFO:root:Train (Epoch 28): Loss/seq after 01050 batchs: 1554.6015625
INFO:root:Train (Epoch 28): Loss/seq after 01100 batchs: 1540.6767578125
INFO:root:Train (Epoch 28): Loss/seq after 01150 batchs: 1516.793701171875
INFO:root:Train (Epoch 28): Loss/seq after 01200 batchs: 1499.036865234375
INFO:root:Train (Epoch 28): Loss/seq after 01250 batchs: 1488.636962890625
INFO:root:Train (Epoch 28): Loss/seq after 01300 batchs: 1501.9803466796875
INFO:root:Train (Epoch 28): Loss/seq after 01350 batchs: 1503.3319091796875
INFO:root:Train (Epoch 28): Loss/seq after 01400 batchs: 1552.1434326171875
INFO:root:Train (Epoch 28): Loss/seq after 01450 batchs: 1535.2041015625
INFO:root:Train (Epoch 28): Loss/seq after 01500 batchs: 1519.792724609375
INFO:root:Train (Epoch 28): Loss/seq after 01550 batchs: 1513.2528076171875
INFO:root:Train (Epoch 28): Loss/seq after 01600 batchs: 1490.76416015625
INFO:root:Train (Epoch 28): Loss/seq after 01650 batchs: 1478.5177001953125
INFO:root:Train (Epoch 28): Loss/seq after 01700 batchs: 1463.645263671875
INFO:root:Train (Epoch 28): Loss/seq after 01750 batchs: 1447.4342041015625
INFO:root:Train (Epoch 28): Loss/seq after 01800 batchs: 1429.507568359375
INFO:root:Train (Epoch 28): Loss/seq after 01850 batchs: 1412.099853515625
INFO:root:Train (Epoch 28): Loss/seq after 01900 batchs: 1406.378173828125
INFO:root:Train (Epoch 28): Loss/seq after 01950 batchs: 1396.6231689453125
INFO:root:Train (Epoch 28): Loss/seq after 02000 batchs: 1383.89013671875
INFO:root:Train (Epoch 28): Loss/seq after 02050 batchs: 1372.4237060546875
INFO:root:Train (Epoch 28): Loss/seq after 02100 batchs: 1358.13818359375
INFO:root:Train (Epoch 28): Loss/seq after 02150 batchs: 1345.02783203125
INFO:root:Train (Epoch 28): Loss/seq after 02200 batchs: 1331.2464599609375
INFO:root:Train (Epoch 28): Loss/seq after 02250 batchs: 1328.5172119140625
INFO:root:Train (Epoch 28): Loss/seq after 02300 batchs: 1328.9259033203125
INFO:root:Train (Epoch 28): Loss/seq after 02350 batchs: 1316.453369140625
INFO:root:Train (Epoch 28): Loss/seq after 02400 batchs: 1309.9066162109375
INFO:root:Train (Epoch 28): Loss/seq after 02450 batchs: 1294.956787109375
INFO:root:Train (Epoch 28): Loss/seq after 02500 batchs: 1276.246337890625
INFO:root:Train (Epoch 28): Loss/seq after 02550 batchs: 1263.57421875
INFO:root:Train (Epoch 28): Loss/seq after 02600 batchs: 1260.84912109375
INFO:root:Train (Epoch 28): Loss/seq after 02650 batchs: 1255.0028076171875
INFO:root:Train (Epoch 28): Loss/seq after 02700 batchs: 1250.6968994140625
INFO:root:Train (Epoch 28): Loss/seq after 02750 batchs: 1280.5277099609375
INFO:root:Train (Epoch 28): Loss/seq after 02800 batchs: 1288.3751220703125
INFO:root:Train (Epoch 28): Loss/seq after 02850 batchs: 1284.1502685546875
INFO:root:Train (Epoch 28): Loss/seq after 02900 batchs: 1281.776611328125
INFO:root:Train (Epoch 28): Loss/seq after 02950 batchs: 1273.692626953125
INFO:root:Train (Epoch 28): Loss/seq after 03000 batchs: 1270.5458984375
INFO:root:Train (Epoch 28): Loss/seq after 03050 batchs: 1272.216552734375
INFO:root:Train (Epoch 28): Loss/seq after 03100 batchs: 1285.1920166015625
INFO:root:Train (Epoch 28): Loss/seq after 03150 batchs: 1302.432861328125
INFO:root:Train (Epoch 28): Loss/seq after 03200 batchs: 1315.9569091796875
INFO:root:Train (Epoch 28): Loss/seq after 03250 batchs: 1328.873291015625
INFO:root:Train (Epoch 28): Loss/seq after 03300 batchs: 1325.9320068359375
INFO:root:Train (Epoch 28): Loss/seq after 03350 batchs: 1324.3211669921875
INFO:root:Train (Epoch 28): Loss/seq after 03400 batchs: 1314.49951171875
INFO:root:Train (Epoch 28): Loss/seq after 03450 batchs: 1306.8758544921875
INFO:root:Train (Epoch 28): Loss/seq after 03500 batchs: 1304.2879638671875
INFO:root:Train (Epoch 28): Loss/seq after 03550 batchs: 1297.60693359375
INFO:root:Train (Epoch 28): Loss/seq after 03600 batchs: 1302.2030029296875
INFO:root:Train (Epoch 28): Loss/seq after 03650 batchs: 1295.179443359375
INFO:root:Train (Epoch 28): Loss/seq after 03700 batchs: 1293.1424560546875
INFO:root:Train (Epoch 28): Loss/seq after 03750 batchs: 1291.957763671875
INFO:root:Train (Epoch 28): Loss/seq after 03800 batchs: 1283.9822998046875
INFO:root:Train (Epoch 28): Loss/seq after 03850 batchs: 1278.616943359375
INFO:root:Train (Epoch 28): Loss/seq after 03900 batchs: 1284.8375244140625
INFO:root:Train (Epoch 28): Loss/seq after 03950 batchs: 1291.886474609375
INFO:root:Train (Epoch 28): Loss/seq after 04000 batchs: 1282.050537109375
INFO:root:Train (Epoch 28): Loss/seq after 04050 batchs: 1273.2557373046875
INFO:root:Train (Epoch 28): Loss/seq after 04100 batchs: 1267.6741943359375
INFO:root:Train (Epoch 28): Loss/seq after 04150 batchs: 1261.025146484375
INFO:root:Train (Epoch 28): Loss/seq after 04200 batchs: 1255.2640380859375
INFO:root:Train (Epoch 28): Loss/seq after 04250 batchs: 1250.4320068359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 28): Loss/seq after 00000 batches: 899.1617431640625
INFO:root:# Valid (Epoch 28): Loss/seq after 00050 batches: 1105.543701171875
INFO:root:# Valid (Epoch 28): Loss/seq after 00100 batches: 1412.4949951171875
INFO:root:# Valid (Epoch 28): Loss/seq after 00150 batches: 1148.147705078125
INFO:root:# Valid (Epoch 28): Loss/seq after 00200 batches: 1043.4161376953125
INFO:root:Artifacts: Make stick videos for epoch 28
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_28_on_20220422_225746.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_28_index_1184_on_20220422_225746.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 29): Loss/seq after 00000 batchs: 2403.094970703125
INFO:root:Train (Epoch 29): Loss/seq after 00050 batchs: 1601.6207275390625
INFO:root:Train (Epoch 29): Loss/seq after 00100 batchs: 1505.3404541015625
INFO:root:Train (Epoch 29): Loss/seq after 00150 batchs: 1343.88623046875
INFO:root:Train (Epoch 29): Loss/seq after 00200 batchs: 1466.28369140625
INFO:root:Train (Epoch 29): Loss/seq after 00250 batchs: 1591.7115478515625
INFO:root:Train (Epoch 29): Loss/seq after 00300 batchs: 1510.220458984375
INFO:root:Train (Epoch 29): Loss/seq after 00350 batchs: 1410.40673828125
INFO:root:Train (Epoch 29): Loss/seq after 00400 batchs: 1454.93359375
INFO:root:Train (Epoch 29): Loss/seq after 00450 batchs: 1391.759521484375
INFO:root:Train (Epoch 29): Loss/seq after 00500 batchs: 1403.9185791015625
INFO:root:Train (Epoch 29): Loss/seq after 00550 batchs: 1344.4437255859375
INFO:root:Train (Epoch 29): Loss/seq after 00600 batchs: 1308.6563720703125
INFO:root:Train (Epoch 29): Loss/seq after 00650 batchs: 1379.019287109375
INFO:root:Train (Epoch 29): Loss/seq after 00700 batchs: 1471.3858642578125
INFO:root:Train (Epoch 29): Loss/seq after 00750 batchs: 1510.25537109375
INFO:root:Train (Epoch 29): Loss/seq after 00800 batchs: 1491.4879150390625
INFO:root:Train (Epoch 29): Loss/seq after 00850 batchs: 1458.021728515625
INFO:root:Train (Epoch 29): Loss/seq after 00900 batchs: 1461.2747802734375
INFO:root:Train (Epoch 29): Loss/seq after 00950 batchs: 1546.4678955078125
INFO:root:Train (Epoch 29): Loss/seq after 01000 batchs: 1543.91357421875
INFO:root:Train (Epoch 29): Loss/seq after 01050 batchs: 1514.0718994140625
INFO:root:Train (Epoch 29): Loss/seq after 01100 batchs: 1500.717041015625
INFO:root:Train (Epoch 29): Loss/seq after 01150 batchs: 1477.2083740234375
INFO:root:Train (Epoch 29): Loss/seq after 01200 batchs: 1460.013916015625
INFO:root:Train (Epoch 29): Loss/seq after 01250 batchs: 1448.8284912109375
INFO:root:Train (Epoch 29): Loss/seq after 01300 batchs: 1463.9871826171875
INFO:root:Train (Epoch 29): Loss/seq after 01350 batchs: 1466.6986083984375
INFO:root:Train (Epoch 29): Loss/seq after 01400 batchs: 1514.498046875
INFO:root:Train (Epoch 29): Loss/seq after 01450 batchs: 1498.509765625
INFO:root:Train (Epoch 29): Loss/seq after 01500 batchs: 1483.7412109375
INFO:root:Train (Epoch 29): Loss/seq after 01550 batchs: 1476.6849365234375
INFO:root:Train (Epoch 29): Loss/seq after 01600 batchs: 1455.384521484375
INFO:root:Train (Epoch 29): Loss/seq after 01650 batchs: 1441.6298828125
INFO:root:Train (Epoch 29): Loss/seq after 01700 batchs: 1427.98486328125
INFO:root:Train (Epoch 29): Loss/seq after 01750 batchs: 1413.001220703125
INFO:root:Train (Epoch 29): Loss/seq after 01800 batchs: 1395.7158203125
INFO:root:Train (Epoch 29): Loss/seq after 01850 batchs: 1378.82666015625
INFO:root:Train (Epoch 29): Loss/seq after 01900 batchs: 1373.660400390625
INFO:root:Train (Epoch 29): Loss/seq after 01950 batchs: 1364.0726318359375
INFO:root:Train (Epoch 29): Loss/seq after 02000 batchs: 1352.11328125
INFO:root:Train (Epoch 29): Loss/seq after 02050 batchs: 1341.3206787109375
INFO:root:Train (Epoch 29): Loss/seq after 02100 batchs: 1327.649169921875
INFO:root:Train (Epoch 29): Loss/seq after 02150 batchs: 1314.9415283203125
INFO:root:Train (Epoch 29): Loss/seq after 02200 batchs: 1301.728759765625
INFO:root:Train (Epoch 29): Loss/seq after 02250 batchs: 1299.4483642578125
INFO:root:Train (Epoch 29): Loss/seq after 02300 batchs: 1301.0343017578125
INFO:root:Train (Epoch 29): Loss/seq after 02350 batchs: 1290.3031005859375
INFO:root:Train (Epoch 29): Loss/seq after 02400 batchs: 1284.35595703125
INFO:root:Train (Epoch 29): Loss/seq after 02450 batchs: 1269.9442138671875
INFO:root:Train (Epoch 29): Loss/seq after 02500 batchs: 1251.7442626953125
INFO:root:Train (Epoch 29): Loss/seq after 02550 batchs: 1239.09033203125
INFO:root:Train (Epoch 29): Loss/seq after 02600 batchs: 1235.5255126953125
INFO:root:Train (Epoch 29): Loss/seq after 02650 batchs: 1230.037353515625
INFO:root:Train (Epoch 29): Loss/seq after 02700 batchs: 1225.8887939453125
INFO:root:Train (Epoch 29): Loss/seq after 02750 batchs: 1255.9599609375
INFO:root:Train (Epoch 29): Loss/seq after 02800 batchs: 1263.8118896484375
INFO:root:Train (Epoch 29): Loss/seq after 02850 batchs: 1258.8280029296875
INFO:root:Train (Epoch 29): Loss/seq after 02900 batchs: 1254.635498046875
INFO:root:Train (Epoch 29): Loss/seq after 02950 batchs: 1246.2110595703125
INFO:root:Train (Epoch 29): Loss/seq after 03000 batchs: 1243.4873046875
INFO:root:Train (Epoch 29): Loss/seq after 03050 batchs: 1245.3076171875
INFO:root:Train (Epoch 29): Loss/seq after 03100 batchs: 1257.7225341796875
INFO:root:Train (Epoch 29): Loss/seq after 03150 batchs: 1275.2781982421875
INFO:root:Train (Epoch 29): Loss/seq after 03200 batchs: 1289.315673828125
INFO:root:Train (Epoch 29): Loss/seq after 03250 batchs: 1302.6888427734375
INFO:root:Train (Epoch 29): Loss/seq after 03300 batchs: 1299.865478515625
INFO:root:Train (Epoch 29): Loss/seq after 03350 batchs: 1298.55078125
INFO:root:Train (Epoch 29): Loss/seq after 03400 batchs: 1289.201171875
INFO:root:Train (Epoch 29): Loss/seq after 03450 batchs: 1282.4935302734375
INFO:root:Train (Epoch 29): Loss/seq after 03500 batchs: 1280.240966796875
INFO:root:Train (Epoch 29): Loss/seq after 03550 batchs: 1273.4317626953125
INFO:root:Train (Epoch 29): Loss/seq after 03600 batchs: 1277.993408203125
INFO:root:Train (Epoch 29): Loss/seq after 03650 batchs: 1271.12646484375
INFO:root:Train (Epoch 29): Loss/seq after 03700 batchs: 1269.3543701171875
INFO:root:Train (Epoch 29): Loss/seq after 03750 batchs: 1268.625244140625
INFO:root:Train (Epoch 29): Loss/seq after 03800 batchs: 1261.0125732421875
INFO:root:Train (Epoch 29): Loss/seq after 03850 batchs: 1255.8837890625
INFO:root:Train (Epoch 29): Loss/seq after 03900 batchs: 1261.92333984375
INFO:root:Train (Epoch 29): Loss/seq after 03950 batchs: 1269.22900390625
INFO:root:Train (Epoch 29): Loss/seq after 04000 batchs: 1259.628662109375
INFO:root:Train (Epoch 29): Loss/seq after 04050 batchs: 1251.0870361328125
INFO:root:Train (Epoch 29): Loss/seq after 04100 batchs: 1245.277099609375
INFO:root:Train (Epoch 29): Loss/seq after 04150 batchs: 1238.84716796875
INFO:root:Train (Epoch 29): Loss/seq after 04200 batchs: 1232.834228515625
INFO:root:Train (Epoch 29): Loss/seq after 04250 batchs: 1227.9737548828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 29): Loss/seq after 00000 batches: 871.5504150390625
INFO:root:# Valid (Epoch 29): Loss/seq after 00050 batches: 1101.18212890625
INFO:root:# Valid (Epoch 29): Loss/seq after 00100 batches: 1389.92822265625
INFO:root:# Valid (Epoch 29): Loss/seq after 00150 batches: 1121.8170166015625
INFO:root:# Valid (Epoch 29): Loss/seq after 00200 batches: 1012.3484497070312
INFO:root:Artifacts: Make stick videos for epoch 29
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_29_on_20220422_230230.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_29_index_1215_on_20220422_230230.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 30): Loss/seq after 00000 batchs: 2406.954345703125
INFO:root:Train (Epoch 30): Loss/seq after 00050 batchs: 1594.222900390625
INFO:root:Train (Epoch 30): Loss/seq after 00100 batchs: 1535.575439453125
INFO:root:Train (Epoch 30): Loss/seq after 00150 batchs: 1369.4412841796875
INFO:root:Train (Epoch 30): Loss/seq after 00200 batchs: 1483.59912109375
INFO:root:Train (Epoch 30): Loss/seq after 00250 batchs: 1608.643310546875
INFO:root:Train (Epoch 30): Loss/seq after 00300 batchs: 1524.386962890625
INFO:root:Train (Epoch 30): Loss/seq after 00350 batchs: 1422.826171875
INFO:root:Train (Epoch 30): Loss/seq after 00400 batchs: 1466.3585205078125
INFO:root:Train (Epoch 30): Loss/seq after 00450 batchs: 1400.861083984375
INFO:root:Train (Epoch 30): Loss/seq after 00500 batchs: 1406.2410888671875
INFO:root:Train (Epoch 30): Loss/seq after 00550 batchs: 1345.6412353515625
INFO:root:Train (Epoch 30): Loss/seq after 00600 batchs: 1309.7430419921875
INFO:root:Train (Epoch 30): Loss/seq after 00650 batchs: 1379.3607177734375
INFO:root:Train (Epoch 30): Loss/seq after 00700 batchs: 1471.35302734375
INFO:root:Train (Epoch 30): Loss/seq after 00750 batchs: 1508.79638671875
INFO:root:Train (Epoch 30): Loss/seq after 00800 batchs: 1490.35498046875
INFO:root:Train (Epoch 30): Loss/seq after 00850 batchs: 1455.6357421875
INFO:root:Train (Epoch 30): Loss/seq after 00900 batchs: 1456.6431884765625
INFO:root:Train (Epoch 30): Loss/seq after 00950 batchs: 1541.0474853515625
INFO:root:Train (Epoch 30): Loss/seq after 01000 batchs: 1537.39501953125
INFO:root:Train (Epoch 30): Loss/seq after 01050 batchs: 1508.9649658203125
INFO:root:Train (Epoch 30): Loss/seq after 01100 batchs: 1497.7593994140625
INFO:root:Train (Epoch 30): Loss/seq after 01150 batchs: 1474.4521484375
INFO:root:Train (Epoch 30): Loss/seq after 01200 batchs: 1456.967529296875
INFO:root:Train (Epoch 30): Loss/seq after 01250 batchs: 1448.35400390625
INFO:root:Train (Epoch 30): Loss/seq after 01300 batchs: 1463.42724609375
INFO:root:Train (Epoch 30): Loss/seq after 01350 batchs: 1466.2313232421875
INFO:root:Train (Epoch 30): Loss/seq after 01400 batchs: 1513.28759765625
INFO:root:Train (Epoch 30): Loss/seq after 01450 batchs: 1498.4822998046875
INFO:root:Train (Epoch 30): Loss/seq after 01500 batchs: 1484.036376953125
INFO:root:Train (Epoch 30): Loss/seq after 01550 batchs: 1478.923095703125
INFO:root:Train (Epoch 30): Loss/seq after 01600 batchs: 1457.5203857421875
INFO:root:Train (Epoch 30): Loss/seq after 01650 batchs: 1444.259521484375
INFO:root:Train (Epoch 30): Loss/seq after 01700 batchs: 1430.2806396484375
INFO:root:Train (Epoch 30): Loss/seq after 01750 batchs: 1415.180908203125
INFO:root:Train (Epoch 30): Loss/seq after 01800 batchs: 1397.7078857421875
INFO:root:Train (Epoch 30): Loss/seq after 01850 batchs: 1380.744873046875
INFO:root:Train (Epoch 30): Loss/seq after 01900 batchs: 1375.6927490234375
INFO:root:Train (Epoch 30): Loss/seq after 01950 batchs: 1366.0035400390625
INFO:root:Train (Epoch 30): Loss/seq after 02000 batchs: 1353.6690673828125
INFO:root:Train (Epoch 30): Loss/seq after 02050 batchs: 1342.7098388671875
INFO:root:Train (Epoch 30): Loss/seq after 02100 batchs: 1328.9951171875
INFO:root:Train (Epoch 30): Loss/seq after 02150 batchs: 1316.19091796875
INFO:root:Train (Epoch 30): Loss/seq after 02200 batchs: 1302.9696044921875
INFO:root:Train (Epoch 30): Loss/seq after 02250 batchs: 1300.864990234375
INFO:root:Train (Epoch 30): Loss/seq after 02300 batchs: 1301.5333251953125
INFO:root:Train (Epoch 30): Loss/seq after 02350 batchs: 1290.9112548828125
INFO:root:Train (Epoch 30): Loss/seq after 02400 batchs: 1284.89208984375
INFO:root:Train (Epoch 30): Loss/seq after 02450 batchs: 1270.400390625
INFO:root:Train (Epoch 30): Loss/seq after 02500 batchs: 1252.1392822265625
INFO:root:Train (Epoch 30): Loss/seq after 02550 batchs: 1239.1553955078125
INFO:root:Train (Epoch 30): Loss/seq after 02600 batchs: 1235.6673583984375
INFO:root:Train (Epoch 30): Loss/seq after 02650 batchs: 1230.0230712890625
INFO:root:Train (Epoch 30): Loss/seq after 02700 batchs: 1224.9979248046875
INFO:root:Train (Epoch 30): Loss/seq after 02750 batchs: 1255.2403564453125
INFO:root:Train (Epoch 30): Loss/seq after 02800 batchs: 1262.9383544921875
INFO:root:Train (Epoch 30): Loss/seq after 02850 batchs: 1257.91357421875
INFO:root:Train (Epoch 30): Loss/seq after 02900 batchs: 1253.736083984375
INFO:root:Train (Epoch 30): Loss/seq after 02950 batchs: 1245.111083984375
INFO:root:Train (Epoch 30): Loss/seq after 03000 batchs: 1242.3958740234375
INFO:root:Train (Epoch 30): Loss/seq after 03050 batchs: 1244.1002197265625
INFO:root:Train (Epoch 30): Loss/seq after 03100 batchs: 1254.8568115234375
INFO:root:Train (Epoch 30): Loss/seq after 03150 batchs: 1271.2330322265625
INFO:root:Train (Epoch 30): Loss/seq after 03200 batchs: 1285.5986328125
INFO:root:Train (Epoch 30): Loss/seq after 03250 batchs: 1299.2125244140625
INFO:root:Train (Epoch 30): Loss/seq after 03300 batchs: 1296.5736083984375
INFO:root:Train (Epoch 30): Loss/seq after 03350 batchs: 1295.2686767578125
INFO:root:Train (Epoch 30): Loss/seq after 03400 batchs: 1285.7913818359375
INFO:root:Train (Epoch 30): Loss/seq after 03450 batchs: 1277.8614501953125
INFO:root:Train (Epoch 30): Loss/seq after 03500 batchs: 1276.722900390625
INFO:root:Train (Epoch 30): Loss/seq after 03550 batchs: 1269.377685546875
INFO:root:Train (Epoch 30): Loss/seq after 03600 batchs: 1273.697509765625
INFO:root:Train (Epoch 30): Loss/seq after 03650 batchs: 1266.8397216796875
INFO:root:Train (Epoch 30): Loss/seq after 03700 batchs: 1264.9188232421875
INFO:root:Train (Epoch 30): Loss/seq after 03750 batchs: 1264.12451171875
INFO:root:Train (Epoch 30): Loss/seq after 03800 batchs: 1256.500244140625
INFO:root:Train (Epoch 30): Loss/seq after 03850 batchs: 1251.42626953125
INFO:root:Train (Epoch 30): Loss/seq after 03900 batchs: 1256.9713134765625
INFO:root:Train (Epoch 30): Loss/seq after 03950 batchs: 1264.8367919921875
INFO:root:Train (Epoch 30): Loss/seq after 04000 batchs: 1255.2698974609375
INFO:root:Train (Epoch 30): Loss/seq after 04050 batchs: 1246.7769775390625
INFO:root:Train (Epoch 30): Loss/seq after 04100 batchs: 1240.7098388671875
INFO:root:Train (Epoch 30): Loss/seq after 04150 batchs: 1234.5926513671875
INFO:root:Train (Epoch 30): Loss/seq after 04200 batchs: 1228.39208984375
INFO:root:Train (Epoch 30): Loss/seq after 04250 batchs: 1223.5635986328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 30): Loss/seq after 00000 batches: 872.024658203125
INFO:root:# Valid (Epoch 30): Loss/seq after 00050 batches: 1106.6199951171875
INFO:root:# Valid (Epoch 30): Loss/seq after 00100 batches: 1393.0311279296875
INFO:root:# Valid (Epoch 30): Loss/seq after 00150 batches: 1116.0472412109375
INFO:root:# Valid (Epoch 30): Loss/seq after 00200 batches: 1006.4744262695312
INFO:root:Artifacts: Make stick videos for epoch 30
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_30_on_20220422_230733.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_30_index_1696_on_20220422_230733.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 31): Loss/seq after 00000 batchs: 2395.31689453125
INFO:root:Train (Epoch 31): Loss/seq after 00050 batchs: 1615.8392333984375
INFO:root:Train (Epoch 31): Loss/seq after 00100 batchs: 1564.5428466796875
INFO:root:Train (Epoch 31): Loss/seq after 00150 batchs: 1381.0738525390625
INFO:root:Train (Epoch 31): Loss/seq after 00200 batchs: 1483.264404296875
INFO:root:Train (Epoch 31): Loss/seq after 00250 batchs: 1601.837646484375
INFO:root:Train (Epoch 31): Loss/seq after 00300 batchs: 1517.675048828125
INFO:root:Train (Epoch 31): Loss/seq after 00350 batchs: 1414.8045654296875
INFO:root:Train (Epoch 31): Loss/seq after 00400 batchs: 1453.7144775390625
INFO:root:Train (Epoch 31): Loss/seq after 00450 batchs: 1389.6683349609375
INFO:root:Train (Epoch 31): Loss/seq after 00500 batchs: 1399.002197265625
INFO:root:Train (Epoch 31): Loss/seq after 00550 batchs: 1338.99853515625
INFO:root:Train (Epoch 31): Loss/seq after 00600 batchs: 1304.051025390625
INFO:root:Train (Epoch 31): Loss/seq after 00650 batchs: 1373.9061279296875
INFO:root:Train (Epoch 31): Loss/seq after 00700 batchs: 1467.3553466796875
INFO:root:Train (Epoch 31): Loss/seq after 00750 batchs: 1507.621826171875
INFO:root:Train (Epoch 31): Loss/seq after 00800 batchs: 1487.7889404296875
INFO:root:Train (Epoch 31): Loss/seq after 00850 batchs: 1452.3199462890625
INFO:root:Train (Epoch 31): Loss/seq after 00900 batchs: 1450.1611328125
INFO:root:Train (Epoch 31): Loss/seq after 00950 batchs: 1536.05810546875
INFO:root:Train (Epoch 31): Loss/seq after 01000 batchs: 1534.2882080078125
INFO:root:Train (Epoch 31): Loss/seq after 01050 batchs: 1505.9520263671875
INFO:root:Train (Epoch 31): Loss/seq after 01100 batchs: 1496.5987548828125
INFO:root:Train (Epoch 31): Loss/seq after 01150 batchs: 1473.07763671875
INFO:root:Train (Epoch 31): Loss/seq after 01200 batchs: 1457.008056640625
INFO:root:Train (Epoch 31): Loss/seq after 01250 batchs: 1446.6571044921875
INFO:root:Train (Epoch 31): Loss/seq after 01300 batchs: 1461.611572265625
INFO:root:Train (Epoch 31): Loss/seq after 01350 batchs: 1464.2275390625
INFO:root:Train (Epoch 31): Loss/seq after 01400 batchs: 1511.3809814453125
INFO:root:Train (Epoch 31): Loss/seq after 01450 batchs: 1494.9326171875
INFO:root:Train (Epoch 31): Loss/seq after 01500 batchs: 1480.017578125
INFO:root:Train (Epoch 31): Loss/seq after 01550 batchs: 1472.5831298828125
INFO:root:Train (Epoch 31): Loss/seq after 01600 batchs: 1450.6263427734375
INFO:root:Train (Epoch 31): Loss/seq after 01650 batchs: 1435.6993408203125
INFO:root:Train (Epoch 31): Loss/seq after 01700 batchs: 1422.398681640625
INFO:root:Train (Epoch 31): Loss/seq after 01750 batchs: 1407.6644287109375
INFO:root:Train (Epoch 31): Loss/seq after 01800 batchs: 1390.8818359375
INFO:root:Train (Epoch 31): Loss/seq after 01850 batchs: 1374.3123779296875
INFO:root:Train (Epoch 31): Loss/seq after 01900 batchs: 1369.61376953125
INFO:root:Train (Epoch 31): Loss/seq after 01950 batchs: 1360.0360107421875
INFO:root:Train (Epoch 31): Loss/seq after 02000 batchs: 1348.227783203125
INFO:root:Train (Epoch 31): Loss/seq after 02050 batchs: 1337.626953125
INFO:root:Train (Epoch 31): Loss/seq after 02100 batchs: 1324.020751953125
INFO:root:Train (Epoch 31): Loss/seq after 02150 batchs: 1311.3685302734375
INFO:root:Train (Epoch 31): Loss/seq after 02200 batchs: 1298.323486328125
INFO:root:Train (Epoch 31): Loss/seq after 02250 batchs: 1295.813720703125
INFO:root:Train (Epoch 31): Loss/seq after 02300 batchs: 1297.224853515625
INFO:root:Train (Epoch 31): Loss/seq after 02350 batchs: 1286.0555419921875
INFO:root:Train (Epoch 31): Loss/seq after 02400 batchs: 1279.7320556640625
INFO:root:Train (Epoch 31): Loss/seq after 02450 batchs: 1265.3409423828125
INFO:root:Train (Epoch 31): Loss/seq after 02500 batchs: 1247.16455078125
INFO:root:Train (Epoch 31): Loss/seq after 02550 batchs: 1234.2344970703125
INFO:root:Train (Epoch 31): Loss/seq after 02600 batchs: 1230.6934814453125
INFO:root:Train (Epoch 31): Loss/seq after 02650 batchs: 1225.249755859375
INFO:root:Train (Epoch 31): Loss/seq after 02700 batchs: 1220.3499755859375
INFO:root:Train (Epoch 31): Loss/seq after 02750 batchs: 1250.3001708984375
INFO:root:Train (Epoch 31): Loss/seq after 02800 batchs: 1259.7935791015625
INFO:root:Train (Epoch 31): Loss/seq after 02850 batchs: 1254.672119140625
INFO:root:Train (Epoch 31): Loss/seq after 02900 batchs: 1253.0404052734375
INFO:root:Train (Epoch 31): Loss/seq after 02950 batchs: 1244.600341796875
INFO:root:Train (Epoch 31): Loss/seq after 03000 batchs: 1241.93896484375
INFO:root:Train (Epoch 31): Loss/seq after 03050 batchs: 1243.7926025390625
INFO:root:Train (Epoch 31): Loss/seq after 03100 batchs: 1255.3927001953125
INFO:root:Train (Epoch 31): Loss/seq after 03150 batchs: 1272.5703125
INFO:root:Train (Epoch 31): Loss/seq after 03200 batchs: 1286.97314453125
INFO:root:Train (Epoch 31): Loss/seq after 03250 batchs: 1301.1064453125
INFO:root:Train (Epoch 31): Loss/seq after 03300 batchs: 1299.079833984375
INFO:root:Train (Epoch 31): Loss/seq after 03350 batchs: 1297.7769775390625
INFO:root:Train (Epoch 31): Loss/seq after 03400 batchs: 1288.2130126953125
INFO:root:Train (Epoch 31): Loss/seq after 03450 batchs: 1280.654541015625
INFO:root:Train (Epoch 31): Loss/seq after 03500 batchs: 1279.0867919921875
INFO:root:Train (Epoch 31): Loss/seq after 03550 batchs: 1271.528564453125
INFO:root:Train (Epoch 31): Loss/seq after 03600 batchs: 1275.6827392578125
INFO:root:Train (Epoch 31): Loss/seq after 03650 batchs: 1268.6605224609375
INFO:root:Train (Epoch 31): Loss/seq after 03700 batchs: 1266.6591796875
INFO:root:Train (Epoch 31): Loss/seq after 03750 batchs: 1265.8443603515625
INFO:root:Train (Epoch 31): Loss/seq after 03800 batchs: 1258.1025390625
INFO:root:Train (Epoch 31): Loss/seq after 03850 batchs: 1252.87158203125
INFO:root:Train (Epoch 31): Loss/seq after 03900 batchs: 1258.794921875
INFO:root:Train (Epoch 31): Loss/seq after 03950 batchs: 1266.4725341796875
INFO:root:Train (Epoch 31): Loss/seq after 04000 batchs: 1256.90185546875
INFO:root:Train (Epoch 31): Loss/seq after 04050 batchs: 1248.378662109375
INFO:root:Train (Epoch 31): Loss/seq after 04100 batchs: 1242.0535888671875
INFO:root:Train (Epoch 31): Loss/seq after 04150 batchs: 1235.689697265625
INFO:root:Train (Epoch 31): Loss/seq after 04200 batchs: 1229.309814453125
INFO:root:Train (Epoch 31): Loss/seq after 04250 batchs: 1224.53515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 31): Loss/seq after 00000 batches: 881.818115234375
INFO:root:# Valid (Epoch 31): Loss/seq after 00050 batches: 1098.7208251953125
INFO:root:# Valid (Epoch 31): Loss/seq after 00100 batches: 1406.60986328125
INFO:root:# Valid (Epoch 31): Loss/seq after 00150 batches: 1133.844482421875
INFO:root:# Valid (Epoch 31): Loss/seq after 00200 batches: 1018.9859008789062
INFO:root:Artifacts: Make stick videos for epoch 31
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_31_on_20220422_231217.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_31_index_51_on_20220422_231217.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 32): Loss/seq after 00000 batchs: 2431.537841796875
INFO:root:Train (Epoch 32): Loss/seq after 00050 batchs: 1602.453369140625
INFO:root:Train (Epoch 32): Loss/seq after 00100 batchs: 1513.8026123046875
INFO:root:Train (Epoch 32): Loss/seq after 00150 batchs: 1343.6739501953125
INFO:root:Train (Epoch 32): Loss/seq after 00200 batchs: 1470.591552734375
INFO:root:Train (Epoch 32): Loss/seq after 00250 batchs: 1586.2901611328125
INFO:root:Train (Epoch 32): Loss/seq after 00300 batchs: 1505.365234375
INFO:root:Train (Epoch 32): Loss/seq after 00350 batchs: 1403.9683837890625
INFO:root:Train (Epoch 32): Loss/seq after 00400 batchs: 1444.0726318359375
INFO:root:Train (Epoch 32): Loss/seq after 00450 batchs: 1381.5274658203125
INFO:root:Train (Epoch 32): Loss/seq after 00500 batchs: 1404.4793701171875
INFO:root:Train (Epoch 32): Loss/seq after 00550 batchs: 1344.5784912109375
INFO:root:Train (Epoch 32): Loss/seq after 00600 batchs: 1309.234619140625
INFO:root:Train (Epoch 32): Loss/seq after 00650 batchs: 1379.5975341796875
INFO:root:Train (Epoch 32): Loss/seq after 00700 batchs: 1472.2664794921875
INFO:root:Train (Epoch 32): Loss/seq after 00750 batchs: 1510.2821044921875
INFO:root:Train (Epoch 32): Loss/seq after 00800 batchs: 1492.3028564453125
INFO:root:Train (Epoch 32): Loss/seq after 00850 batchs: 1457.654296875
INFO:root:Train (Epoch 32): Loss/seq after 00900 batchs: 1455.2681884765625
INFO:root:Train (Epoch 32): Loss/seq after 00950 batchs: 1539.5543212890625
INFO:root:Train (Epoch 32): Loss/seq after 01000 batchs: 1534.4354248046875
INFO:root:Train (Epoch 32): Loss/seq after 01050 batchs: 1505.818603515625
INFO:root:Train (Epoch 32): Loss/seq after 01100 batchs: 1491.821533203125
INFO:root:Train (Epoch 32): Loss/seq after 01150 batchs: 1468.6947021484375
INFO:root:Train (Epoch 32): Loss/seq after 01200 batchs: 1452.1885986328125
INFO:root:Train (Epoch 32): Loss/seq after 01250 batchs: 1442.00732421875
INFO:root:Train (Epoch 32): Loss/seq after 01300 batchs: 1457.118408203125
INFO:root:Train (Epoch 32): Loss/seq after 01350 batchs: 1459.948486328125
INFO:root:Train (Epoch 32): Loss/seq after 01400 batchs: 1508.7470703125
INFO:root:Train (Epoch 32): Loss/seq after 01450 batchs: 1492.5548095703125
INFO:root:Train (Epoch 32): Loss/seq after 01500 batchs: 1477.6597900390625
INFO:root:Train (Epoch 32): Loss/seq after 01550 batchs: 1471.2913818359375
INFO:root:Train (Epoch 32): Loss/seq after 01600 batchs: 1449.6920166015625
INFO:root:Train (Epoch 32): Loss/seq after 01650 batchs: 1435.7728271484375
INFO:root:Train (Epoch 32): Loss/seq after 01700 batchs: 1421.8551025390625
INFO:root:Train (Epoch 32): Loss/seq after 01750 batchs: 1406.735595703125
INFO:root:Train (Epoch 32): Loss/seq after 01800 batchs: 1389.43359375
INFO:root:Train (Epoch 32): Loss/seq after 01850 batchs: 1372.687255859375
INFO:root:Train (Epoch 32): Loss/seq after 01900 batchs: 1367.6876220703125
INFO:root:Train (Epoch 32): Loss/seq after 01950 batchs: 1358.1190185546875
INFO:root:Train (Epoch 32): Loss/seq after 02000 batchs: 1346.035400390625
INFO:root:Train (Epoch 32): Loss/seq after 02050 batchs: 1335.3504638671875
INFO:root:Train (Epoch 32): Loss/seq after 02100 batchs: 1321.7122802734375
INFO:root:Train (Epoch 32): Loss/seq after 02150 batchs: 1309.15478515625
INFO:root:Train (Epoch 32): Loss/seq after 02200 batchs: 1296.08740234375
INFO:root:Train (Epoch 32): Loss/seq after 02250 batchs: 1293.6435546875
INFO:root:Train (Epoch 32): Loss/seq after 02300 batchs: 1294.302978515625
INFO:root:Train (Epoch 32): Loss/seq after 02350 batchs: 1283.1165771484375
INFO:root:Train (Epoch 32): Loss/seq after 02400 batchs: 1277.0712890625
INFO:root:Train (Epoch 32): Loss/seq after 02450 batchs: 1262.73583984375
INFO:root:Train (Epoch 32): Loss/seq after 02500 batchs: 1244.6029052734375
INFO:root:Train (Epoch 32): Loss/seq after 02550 batchs: 1231.7481689453125
INFO:root:Train (Epoch 32): Loss/seq after 02600 batchs: 1228.0972900390625
INFO:root:Train (Epoch 32): Loss/seq after 02650 batchs: 1222.5262451171875
INFO:root:Train (Epoch 32): Loss/seq after 02700 batchs: 1217.7718505859375
INFO:root:Train (Epoch 32): Loss/seq after 02750 batchs: 1248.9549560546875
INFO:root:Train (Epoch 32): Loss/seq after 02800 batchs: 1256.515625
INFO:root:Train (Epoch 32): Loss/seq after 02850 batchs: 1251.8011474609375
INFO:root:Train (Epoch 32): Loss/seq after 02900 batchs: 1248.0614013671875
INFO:root:Train (Epoch 32): Loss/seq after 02950 batchs: 1240.322021484375
INFO:root:Train (Epoch 32): Loss/seq after 03000 batchs: 1237.7269287109375
INFO:root:Train (Epoch 32): Loss/seq after 03050 batchs: 1239.6256103515625
INFO:root:Train (Epoch 32): Loss/seq after 03100 batchs: 1252.1610107421875
INFO:root:Train (Epoch 32): Loss/seq after 03150 batchs: 1270.068603515625
INFO:root:Train (Epoch 32): Loss/seq after 03200 batchs: 1284.0860595703125
INFO:root:Train (Epoch 32): Loss/seq after 03250 batchs: 1297.41748046875
INFO:root:Train (Epoch 32): Loss/seq after 03300 batchs: 1293.8287353515625
INFO:root:Train (Epoch 32): Loss/seq after 03350 batchs: 1291.86865234375
INFO:root:Train (Epoch 32): Loss/seq after 03400 batchs: 1282.3597412109375
INFO:root:Train (Epoch 32): Loss/seq after 03450 batchs: 1273.8363037109375
INFO:root:Train (Epoch 32): Loss/seq after 03500 batchs: 1271.20703125
INFO:root:Train (Epoch 32): Loss/seq after 03550 batchs: 1263.4703369140625
INFO:root:Train (Epoch 32): Loss/seq after 03600 batchs: 1267.7757568359375
INFO:root:Train (Epoch 32): Loss/seq after 03650 batchs: 1261.056396484375
INFO:root:Train (Epoch 32): Loss/seq after 03700 batchs: 1259.572021484375
INFO:root:Train (Epoch 32): Loss/seq after 03750 batchs: 1258.987060546875
INFO:root:Train (Epoch 32): Loss/seq after 03800 batchs: 1251.611572265625
INFO:root:Train (Epoch 32): Loss/seq after 03850 batchs: 1246.7412109375
INFO:root:Train (Epoch 32): Loss/seq after 03900 batchs: 1253.162841796875
INFO:root:Train (Epoch 32): Loss/seq after 03950 batchs: 1260.7626953125
INFO:root:Train (Epoch 32): Loss/seq after 04000 batchs: 1251.2454833984375
INFO:root:Train (Epoch 32): Loss/seq after 04050 batchs: 1242.80419921875
INFO:root:Train (Epoch 32): Loss/seq after 04100 batchs: 1236.72314453125
INFO:root:Train (Epoch 32): Loss/seq after 04150 batchs: 1230.4783935546875
INFO:root:Train (Epoch 32): Loss/seq after 04200 batchs: 1224.605712890625
INFO:root:Train (Epoch 32): Loss/seq after 04250 batchs: 1219.919921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 32): Loss/seq after 00000 batches: 870.111083984375
INFO:root:# Valid (Epoch 32): Loss/seq after 00050 batches: 1096.2032470703125
INFO:root:# Valid (Epoch 32): Loss/seq after 00100 batches: 1413.9844970703125
INFO:root:# Valid (Epoch 32): Loss/seq after 00150 batches: 1158.4383544921875
INFO:root:# Valid (Epoch 32): Loss/seq after 00200 batches: 1047.704833984375
INFO:root:Artifacts: Make stick videos for epoch 32
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_32_on_20220422_231700.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_32_index_1370_on_20220422_231700.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 33): Loss/seq after 00000 batchs: 2486.838623046875
INFO:root:Train (Epoch 33): Loss/seq after 00050 batchs: 1609.244873046875
INFO:root:Train (Epoch 33): Loss/seq after 00100 batchs: 1520.0772705078125
INFO:root:Train (Epoch 33): Loss/seq after 00150 batchs: 1352.6817626953125
INFO:root:Train (Epoch 33): Loss/seq after 00200 batchs: 1466.22412109375
INFO:root:Train (Epoch 33): Loss/seq after 00250 batchs: 1595.322021484375
INFO:root:Train (Epoch 33): Loss/seq after 00300 batchs: 1513.15380859375
INFO:root:Train (Epoch 33): Loss/seq after 00350 batchs: 1414.9329833984375
INFO:root:Train (Epoch 33): Loss/seq after 00400 batchs: 1455.3507080078125
INFO:root:Train (Epoch 33): Loss/seq after 00450 batchs: 1390.9705810546875
INFO:root:Train (Epoch 33): Loss/seq after 00500 batchs: 1407.361572265625
INFO:root:Train (Epoch 33): Loss/seq after 00550 batchs: 1346.7076416015625
INFO:root:Train (Epoch 33): Loss/seq after 00600 batchs: 1310.7139892578125
INFO:root:Train (Epoch 33): Loss/seq after 00650 batchs: 1381.0439453125
INFO:root:Train (Epoch 33): Loss/seq after 00700 batchs: 1472.9249267578125
INFO:root:Train (Epoch 33): Loss/seq after 00750 batchs: 1510.433837890625
INFO:root:Train (Epoch 33): Loss/seq after 00800 batchs: 1489.462158203125
INFO:root:Train (Epoch 33): Loss/seq after 00850 batchs: 1453.6396484375
INFO:root:Train (Epoch 33): Loss/seq after 00900 batchs: 1450.805908203125
INFO:root:Train (Epoch 33): Loss/seq after 00950 batchs: 1534.1591796875
INFO:root:Train (Epoch 33): Loss/seq after 01000 batchs: 1531.763427734375
INFO:root:Train (Epoch 33): Loss/seq after 01050 batchs: 1504.0888671875
INFO:root:Train (Epoch 33): Loss/seq after 01100 batchs: 1489.0338134765625
INFO:root:Train (Epoch 33): Loss/seq after 01150 batchs: 1465.82861328125
INFO:root:Train (Epoch 33): Loss/seq after 01200 batchs: 1449.7772216796875
INFO:root:Train (Epoch 33): Loss/seq after 01250 batchs: 1440.58447265625
INFO:root:Train (Epoch 33): Loss/seq after 01300 batchs: 1455.7568359375
INFO:root:Train (Epoch 33): Loss/seq after 01350 batchs: 1458.6429443359375
INFO:root:Train (Epoch 33): Loss/seq after 01400 batchs: 1506.6666259765625
INFO:root:Train (Epoch 33): Loss/seq after 01450 batchs: 1492.89990234375
INFO:root:Train (Epoch 33): Loss/seq after 01500 batchs: 1479.435791015625
INFO:root:Train (Epoch 33): Loss/seq after 01550 batchs: 1474.38037109375
INFO:root:Train (Epoch 33): Loss/seq after 01600 batchs: 1453.2816162109375
INFO:root:Train (Epoch 33): Loss/seq after 01650 batchs: 1439.793212890625
INFO:root:Train (Epoch 33): Loss/seq after 01700 batchs: 1426.102294921875
INFO:root:Train (Epoch 33): Loss/seq after 01750 batchs: 1410.7783203125
INFO:root:Train (Epoch 33): Loss/seq after 01800 batchs: 1393.595703125
INFO:root:Train (Epoch 33): Loss/seq after 01850 batchs: 1376.6572265625
INFO:root:Train (Epoch 33): Loss/seq after 01900 batchs: 1371.1749267578125
INFO:root:Train (Epoch 33): Loss/seq after 01950 batchs: 1361.17041015625
INFO:root:Train (Epoch 33): Loss/seq after 02000 batchs: 1348.9808349609375
INFO:root:Train (Epoch 33): Loss/seq after 02050 batchs: 1338.2347412109375
INFO:root:Train (Epoch 33): Loss/seq after 02100 batchs: 1324.504150390625
INFO:root:Train (Epoch 33): Loss/seq after 02150 batchs: 1311.7572021484375
INFO:root:Train (Epoch 33): Loss/seq after 02200 batchs: 1298.6287841796875
INFO:root:Train (Epoch 33): Loss/seq after 02250 batchs: 1296.026611328125
INFO:root:Train (Epoch 33): Loss/seq after 02300 batchs: 1297.02734375
INFO:root:Train (Epoch 33): Loss/seq after 02350 batchs: 1285.6021728515625
INFO:root:Train (Epoch 33): Loss/seq after 02400 batchs: 1279.3931884765625
INFO:root:Train (Epoch 33): Loss/seq after 02450 batchs: 1265.18994140625
INFO:root:Train (Epoch 33): Loss/seq after 02500 batchs: 1247.033203125
INFO:root:Train (Epoch 33): Loss/seq after 02550 batchs: 1234.1199951171875
INFO:root:Train (Epoch 33): Loss/seq after 02600 batchs: 1231.2880859375
INFO:root:Train (Epoch 33): Loss/seq after 02650 batchs: 1225.62353515625
INFO:root:Train (Epoch 33): Loss/seq after 02700 batchs: 1220.914794921875
INFO:root:Train (Epoch 33): Loss/seq after 02750 batchs: 1250.7923583984375
INFO:root:Train (Epoch 33): Loss/seq after 02800 batchs: 1258.82763671875
INFO:root:Train (Epoch 33): Loss/seq after 02850 batchs: 1254.046875
INFO:root:Train (Epoch 33): Loss/seq after 02900 batchs: 1252.1549072265625
INFO:root:Train (Epoch 33): Loss/seq after 02950 batchs: 1243.3642578125
INFO:root:Train (Epoch 33): Loss/seq after 03000 batchs: 1240.6986083984375
INFO:root:Train (Epoch 33): Loss/seq after 03050 batchs: 1242.4364013671875
INFO:root:Train (Epoch 33): Loss/seq after 03100 batchs: 1253.5242919921875
INFO:root:Train (Epoch 33): Loss/seq after 03150 batchs: 1269.4605712890625
INFO:root:Train (Epoch 33): Loss/seq after 03200 batchs: 1284.0615234375
INFO:root:Train (Epoch 33): Loss/seq after 03250 batchs: 1297.3818359375
INFO:root:Train (Epoch 33): Loss/seq after 03300 batchs: 1295.486572265625
INFO:root:Train (Epoch 33): Loss/seq after 03350 batchs: 1294.15625
INFO:root:Train (Epoch 33): Loss/seq after 03400 batchs: 1284.7491455078125
INFO:root:Train (Epoch 33): Loss/seq after 03450 batchs: 1276.705078125
INFO:root:Train (Epoch 33): Loss/seq after 03500 batchs: 1274.3968505859375
INFO:root:Train (Epoch 33): Loss/seq after 03550 batchs: 1266.5325927734375
INFO:root:Train (Epoch 33): Loss/seq after 03600 batchs: 1270.8616943359375
INFO:root:Train (Epoch 33): Loss/seq after 03650 batchs: 1263.589111328125
INFO:root:Train (Epoch 33): Loss/seq after 03700 batchs: 1261.5877685546875
INFO:root:Train (Epoch 33): Loss/seq after 03750 batchs: 1260.9326171875
INFO:root:Train (Epoch 33): Loss/seq after 03800 batchs: 1253.39697265625
INFO:root:Train (Epoch 33): Loss/seq after 03850 batchs: 1248.24853515625
INFO:root:Train (Epoch 33): Loss/seq after 03900 batchs: 1254.4249267578125
INFO:root:Train (Epoch 33): Loss/seq after 03950 batchs: 1261.5850830078125
INFO:root:Train (Epoch 33): Loss/seq after 04000 batchs: 1252.0791015625
INFO:root:Train (Epoch 33): Loss/seq after 04050 batchs: 1243.6090087890625
INFO:root:Train (Epoch 33): Loss/seq after 04100 batchs: 1237.4366455078125
INFO:root:Train (Epoch 33): Loss/seq after 04150 batchs: 1231.2091064453125
INFO:root:Train (Epoch 33): Loss/seq after 04200 batchs: 1224.7772216796875
INFO:root:Train (Epoch 33): Loss/seq after 04250 batchs: 1219.9559326171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 33): Loss/seq after 00000 batches: 889.068603515625
INFO:root:# Valid (Epoch 33): Loss/seq after 00050 batches: 1102.945556640625
INFO:root:# Valid (Epoch 33): Loss/seq after 00100 batches: 1390.5855712890625
INFO:root:# Valid (Epoch 33): Loss/seq after 00150 batches: 1114.8067626953125
INFO:root:# Valid (Epoch 33): Loss/seq after 00200 batches: 1004.6408081054688
INFO:root:Artifacts: Make stick videos for epoch 33
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_33_on_20220422_232143.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_33_index_1822_on_20220422_232143.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 34): Loss/seq after 00000 batchs: 2455.171875
INFO:root:Train (Epoch 34): Loss/seq after 00050 batchs: 1578.4281005859375
INFO:root:Train (Epoch 34): Loss/seq after 00100 batchs: 1491.612548828125
INFO:root:Train (Epoch 34): Loss/seq after 00150 batchs: 1334.933837890625
INFO:root:Train (Epoch 34): Loss/seq after 00200 batchs: 1455.862060546875
INFO:root:Train (Epoch 34): Loss/seq after 00250 batchs: 1573.2271728515625
INFO:root:Train (Epoch 34): Loss/seq after 00300 batchs: 1493.9122314453125
INFO:root:Train (Epoch 34): Loss/seq after 00350 batchs: 1393.8082275390625
INFO:root:Train (Epoch 34): Loss/seq after 00400 batchs: 1430.9996337890625
INFO:root:Train (Epoch 34): Loss/seq after 00450 batchs: 1369.3133544921875
INFO:root:Train (Epoch 34): Loss/seq after 00500 batchs: 1375.2366943359375
INFO:root:Train (Epoch 34): Loss/seq after 00550 batchs: 1317.2630615234375
INFO:root:Train (Epoch 34): Loss/seq after 00600 batchs: 1282.417724609375
INFO:root:Train (Epoch 34): Loss/seq after 00650 batchs: 1354.561767578125
INFO:root:Train (Epoch 34): Loss/seq after 00700 batchs: 1448.640869140625
INFO:root:Train (Epoch 34): Loss/seq after 00750 batchs: 1489.1353759765625
INFO:root:Train (Epoch 34): Loss/seq after 00800 batchs: 1468.966552734375
INFO:root:Train (Epoch 34): Loss/seq after 00850 batchs: 1434.29345703125
INFO:root:Train (Epoch 34): Loss/seq after 00900 batchs: 1431.547119140625
INFO:root:Train (Epoch 34): Loss/seq after 00950 batchs: 1515.82177734375
INFO:root:Train (Epoch 34): Loss/seq after 01000 batchs: 1513.2862548828125
INFO:root:Train (Epoch 34): Loss/seq after 01050 batchs: 1486.4212646484375
INFO:root:Train (Epoch 34): Loss/seq after 01100 batchs: 1471.7696533203125
INFO:root:Train (Epoch 34): Loss/seq after 01150 batchs: 1449.09814453125
INFO:root:Train (Epoch 34): Loss/seq after 01200 batchs: 1432.8865966796875
INFO:root:Train (Epoch 34): Loss/seq after 01250 batchs: 1422.3172607421875
INFO:root:Train (Epoch 34): Loss/seq after 01300 batchs: 1438.33740234375
INFO:root:Train (Epoch 34): Loss/seq after 01350 batchs: 1441.8685302734375
INFO:root:Train (Epoch 34): Loss/seq after 01400 batchs: 1488.5511474609375
INFO:root:Train (Epoch 34): Loss/seq after 01450 batchs: 1472.31396484375
INFO:root:Train (Epoch 34): Loss/seq after 01500 batchs: 1457.9793701171875
INFO:root:Train (Epoch 34): Loss/seq after 01550 batchs: 1451.515380859375
INFO:root:Train (Epoch 34): Loss/seq after 01600 batchs: 1430.886962890625
INFO:root:Train (Epoch 34): Loss/seq after 01650 batchs: 1416.7578125
INFO:root:Train (Epoch 34): Loss/seq after 01700 batchs: 1403.6104736328125
INFO:root:Train (Epoch 34): Loss/seq after 01750 batchs: 1388.945556640625
INFO:root:Train (Epoch 34): Loss/seq after 01800 batchs: 1372.1326904296875
INFO:root:Train (Epoch 34): Loss/seq after 01850 batchs: 1355.8009033203125
INFO:root:Train (Epoch 34): Loss/seq after 01900 batchs: 1350.9560546875
INFO:root:Train (Epoch 34): Loss/seq after 01950 batchs: 1341.075927734375
INFO:root:Train (Epoch 34): Loss/seq after 02000 batchs: 1329.1824951171875
INFO:root:Train (Epoch 34): Loss/seq after 02050 batchs: 1318.5233154296875
INFO:root:Train (Epoch 34): Loss/seq after 02100 batchs: 1305.2762451171875
INFO:root:Train (Epoch 34): Loss/seq after 02150 batchs: 1292.9976806640625
INFO:root:Train (Epoch 34): Loss/seq after 02200 batchs: 1280.273681640625
INFO:root:Train (Epoch 34): Loss/seq after 02250 batchs: 1278.8778076171875
INFO:root:Train (Epoch 34): Loss/seq after 02300 batchs: 1279.8421630859375
INFO:root:Train (Epoch 34): Loss/seq after 02350 batchs: 1268.439208984375
INFO:root:Train (Epoch 34): Loss/seq after 02400 batchs: 1262.6654052734375
INFO:root:Train (Epoch 34): Loss/seq after 02450 batchs: 1248.530517578125
INFO:root:Train (Epoch 34): Loss/seq after 02500 batchs: 1230.720458984375
INFO:root:Train (Epoch 34): Loss/seq after 02550 batchs: 1218.1224365234375
INFO:root:Train (Epoch 34): Loss/seq after 02600 batchs: 1214.685302734375
INFO:root:Train (Epoch 34): Loss/seq after 02650 batchs: 1209.2213134765625
INFO:root:Train (Epoch 34): Loss/seq after 02700 batchs: 1204.4063720703125
INFO:root:Train (Epoch 34): Loss/seq after 02750 batchs: 1233.7691650390625
INFO:root:Train (Epoch 34): Loss/seq after 02800 batchs: 1241.0052490234375
INFO:root:Train (Epoch 34): Loss/seq after 02850 batchs: 1235.955322265625
INFO:root:Train (Epoch 34): Loss/seq after 02900 batchs: 1233.0450439453125
INFO:root:Train (Epoch 34): Loss/seq after 02950 batchs: 1224.7911376953125
INFO:root:Train (Epoch 34): Loss/seq after 03000 batchs: 1222.3974609375
INFO:root:Train (Epoch 34): Loss/seq after 03050 batchs: 1224.3494873046875
INFO:root:Train (Epoch 34): Loss/seq after 03100 batchs: 1235.1201171875
INFO:root:Train (Epoch 34): Loss/seq after 03150 batchs: 1250.8626708984375
INFO:root:Train (Epoch 34): Loss/seq after 03200 batchs: 1265.1202392578125
INFO:root:Train (Epoch 34): Loss/seq after 03250 batchs: 1278.5721435546875
INFO:root:Train (Epoch 34): Loss/seq after 03300 batchs: 1275.2923583984375
INFO:root:Train (Epoch 34): Loss/seq after 03350 batchs: 1273.819091796875
INFO:root:Train (Epoch 34): Loss/seq after 03400 batchs: 1264.5994873046875
INFO:root:Train (Epoch 34): Loss/seq after 03450 batchs: 1256.2060546875
INFO:root:Train (Epoch 34): Loss/seq after 03500 batchs: 1254.104248046875
INFO:root:Train (Epoch 34): Loss/seq after 03550 batchs: 1246.66064453125
INFO:root:Train (Epoch 34): Loss/seq after 03600 batchs: 1251.621826171875
INFO:root:Train (Epoch 34): Loss/seq after 03650 batchs: 1245.08740234375
INFO:root:Train (Epoch 34): Loss/seq after 03700 batchs: 1243.7222900390625
INFO:root:Train (Epoch 34): Loss/seq after 03750 batchs: 1243.2796630859375
INFO:root:Train (Epoch 34): Loss/seq after 03800 batchs: 1235.9493408203125
INFO:root:Train (Epoch 34): Loss/seq after 03850 batchs: 1231.1612548828125
INFO:root:Train (Epoch 34): Loss/seq after 03900 batchs: 1236.9407958984375
INFO:root:Train (Epoch 34): Loss/seq after 03950 batchs: 1244.4884033203125
INFO:root:Train (Epoch 34): Loss/seq after 04000 batchs: 1235.2120361328125
INFO:root:Train (Epoch 34): Loss/seq after 04050 batchs: 1226.9678955078125
INFO:root:Train (Epoch 34): Loss/seq after 04100 batchs: 1220.6329345703125
INFO:root:Train (Epoch 34): Loss/seq after 04150 batchs: 1214.555419921875
INFO:root:Train (Epoch 34): Loss/seq after 04200 batchs: 1208.91162109375
INFO:root:Train (Epoch 34): Loss/seq after 04250 batchs: 1204.1572265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 34): Loss/seq after 00000 batches: 891.4332275390625
INFO:root:# Valid (Epoch 34): Loss/seq after 00050 batches: 1122.5308837890625
INFO:root:# Valid (Epoch 34): Loss/seq after 00100 batches: 1408.873291015625
INFO:root:# Valid (Epoch 34): Loss/seq after 00150 batches: 1137.071044921875
INFO:root:# Valid (Epoch 34): Loss/seq after 00200 batches: 1030.24462890625
INFO:root:Artifacts: Make stick videos for epoch 34
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_34_on_20220422_232636.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_34_index_639_on_20220422_232636.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 35): Loss/seq after 00000 batchs: 2357.440673828125
INFO:root:Train (Epoch 35): Loss/seq after 00050 batchs: 1598.306640625
INFO:root:Train (Epoch 35): Loss/seq after 00100 batchs: 1501.6285400390625
INFO:root:Train (Epoch 35): Loss/seq after 00150 batchs: 1340.7911376953125
INFO:root:Train (Epoch 35): Loss/seq after 00200 batchs: 1459.977294921875
INFO:root:Train (Epoch 35): Loss/seq after 00250 batchs: 1580.51171875
INFO:root:Train (Epoch 35): Loss/seq after 00300 batchs: 1500.3941650390625
INFO:root:Train (Epoch 35): Loss/seq after 00350 batchs: 1400.555908203125
INFO:root:Train (Epoch 35): Loss/seq after 00400 batchs: 1440.1082763671875
INFO:root:Train (Epoch 35): Loss/seq after 00450 batchs: 1377.5218505859375
INFO:root:Train (Epoch 35): Loss/seq after 00500 batchs: 1385.5389404296875
INFO:root:Train (Epoch 35): Loss/seq after 00550 batchs: 1326.62646484375
INFO:root:Train (Epoch 35): Loss/seq after 00600 batchs: 1290.457275390625
INFO:root:Train (Epoch 35): Loss/seq after 00650 batchs: 1361.2061767578125
INFO:root:Train (Epoch 35): Loss/seq after 00700 batchs: 1453.9613037109375
INFO:root:Train (Epoch 35): Loss/seq after 00750 batchs: 1490.7099609375
INFO:root:Train (Epoch 35): Loss/seq after 00800 batchs: 1470.66357421875
INFO:root:Train (Epoch 35): Loss/seq after 00850 batchs: 1436.0469970703125
INFO:root:Train (Epoch 35): Loss/seq after 00900 batchs: 1434.5078125
INFO:root:Train (Epoch 35): Loss/seq after 00950 batchs: 1517.58984375
INFO:root:Train (Epoch 35): Loss/seq after 01000 batchs: 1513.8768310546875
INFO:root:Train (Epoch 35): Loss/seq after 01050 batchs: 1483.3389892578125
INFO:root:Train (Epoch 35): Loss/seq after 01100 batchs: 1470.6385498046875
INFO:root:Train (Epoch 35): Loss/seq after 01150 batchs: 1447.7188720703125
INFO:root:Train (Epoch 35): Loss/seq after 01200 batchs: 1430.8748779296875
INFO:root:Train (Epoch 35): Loss/seq after 01250 batchs: 1421.056396484375
INFO:root:Train (Epoch 35): Loss/seq after 01300 batchs: 1436.840576171875
INFO:root:Train (Epoch 35): Loss/seq after 01350 batchs: 1440.3404541015625
INFO:root:Train (Epoch 35): Loss/seq after 01400 batchs: 1487.45068359375
INFO:root:Train (Epoch 35): Loss/seq after 01450 batchs: 1471.617431640625
INFO:root:Train (Epoch 35): Loss/seq after 01500 batchs: 1457.328369140625
INFO:root:Train (Epoch 35): Loss/seq after 01550 batchs: 1452.3360595703125
INFO:root:Train (Epoch 35): Loss/seq after 01600 batchs: 1432.2054443359375
INFO:root:Train (Epoch 35): Loss/seq after 01650 batchs: 1419.7286376953125
INFO:root:Train (Epoch 35): Loss/seq after 01700 batchs: 1406.63720703125
INFO:root:Train (Epoch 35): Loss/seq after 01750 batchs: 1391.8193359375
INFO:root:Train (Epoch 35): Loss/seq after 01800 batchs: 1374.9100341796875
INFO:root:Train (Epoch 35): Loss/seq after 01850 batchs: 1358.547119140625
INFO:root:Train (Epoch 35): Loss/seq after 01900 batchs: 1353.81298828125
INFO:root:Train (Epoch 35): Loss/seq after 01950 batchs: 1344.3348388671875
INFO:root:Train (Epoch 35): Loss/seq after 02000 batchs: 1332.3902587890625
INFO:root:Train (Epoch 35): Loss/seq after 02050 batchs: 1321.6383056640625
INFO:root:Train (Epoch 35): Loss/seq after 02100 batchs: 1308.1732177734375
INFO:root:Train (Epoch 35): Loss/seq after 02150 batchs: 1295.7086181640625
INFO:root:Train (Epoch 35): Loss/seq after 02200 batchs: 1282.940673828125
INFO:root:Train (Epoch 35): Loss/seq after 02250 batchs: 1281.01025390625
INFO:root:Train (Epoch 35): Loss/seq after 02300 batchs: 1282.639892578125
INFO:root:Train (Epoch 35): Loss/seq after 02350 batchs: 1271.5323486328125
INFO:root:Train (Epoch 35): Loss/seq after 02400 batchs: 1266.0780029296875
INFO:root:Train (Epoch 35): Loss/seq after 02450 batchs: 1252.10791015625
INFO:root:Train (Epoch 35): Loss/seq after 02500 batchs: 1234.298095703125
INFO:root:Train (Epoch 35): Loss/seq after 02550 batchs: 1221.4969482421875
INFO:root:Train (Epoch 35): Loss/seq after 02600 batchs: 1217.8719482421875
INFO:root:Train (Epoch 35): Loss/seq after 02650 batchs: 1212.2542724609375
INFO:root:Train (Epoch 35): Loss/seq after 02700 batchs: 1207.4093017578125
INFO:root:Train (Epoch 35): Loss/seq after 02750 batchs: 1237.0870361328125
INFO:root:Train (Epoch 35): Loss/seq after 02800 batchs: 1244.26220703125
INFO:root:Train (Epoch 35): Loss/seq after 02850 batchs: 1239.3349609375
INFO:root:Train (Epoch 35): Loss/seq after 02900 batchs: 1235.70361328125
INFO:root:Train (Epoch 35): Loss/seq after 02950 batchs: 1227.024169921875
INFO:root:Train (Epoch 35): Loss/seq after 03000 batchs: 1224.58984375
INFO:root:Train (Epoch 35): Loss/seq after 03050 batchs: 1226.3876953125
INFO:root:Train (Epoch 35): Loss/seq after 03100 batchs: 1237.0858154296875
INFO:root:Train (Epoch 35): Loss/seq after 03150 batchs: 1252.81640625
INFO:root:Train (Epoch 35): Loss/seq after 03200 batchs: 1267.2626953125
INFO:root:Train (Epoch 35): Loss/seq after 03250 batchs: 1280.690673828125
INFO:root:Train (Epoch 35): Loss/seq after 03300 batchs: 1277.787353515625
INFO:root:Train (Epoch 35): Loss/seq after 03350 batchs: 1275.9097900390625
INFO:root:Train (Epoch 35): Loss/seq after 03400 batchs: 1266.6678466796875
INFO:root:Train (Epoch 35): Loss/seq after 03450 batchs: 1258.5216064453125
INFO:root:Train (Epoch 35): Loss/seq after 03500 batchs: 1256.0560302734375
INFO:root:Train (Epoch 35): Loss/seq after 03550 batchs: 1248.23779296875
INFO:root:Train (Epoch 35): Loss/seq after 03600 batchs: 1252.606689453125
INFO:root:Train (Epoch 35): Loss/seq after 03650 batchs: 1245.60400390625
INFO:root:Train (Epoch 35): Loss/seq after 03700 batchs: 1243.8155517578125
INFO:root:Train (Epoch 35): Loss/seq after 03750 batchs: 1243.6319580078125
INFO:root:Train (Epoch 35): Loss/seq after 03800 batchs: 1236.7393798828125
INFO:root:Train (Epoch 35): Loss/seq after 03850 batchs: 1232.1302490234375
INFO:root:Train (Epoch 35): Loss/seq after 03900 batchs: 1237.8646240234375
INFO:root:Train (Epoch 35): Loss/seq after 03950 batchs: 1244.9102783203125
INFO:root:Train (Epoch 35): Loss/seq after 04000 batchs: 1235.617919921875
INFO:root:Train (Epoch 35): Loss/seq after 04050 batchs: 1227.3812255859375
INFO:root:Train (Epoch 35): Loss/seq after 04100 batchs: 1220.9825439453125
INFO:root:Train (Epoch 35): Loss/seq after 04150 batchs: 1214.892822265625
INFO:root:Train (Epoch 35): Loss/seq after 04200 batchs: 1209.0220947265625
INFO:root:Train (Epoch 35): Loss/seq after 04250 batchs: 1204.6893310546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 35): Loss/seq after 00000 batches: 878.9791870117188
INFO:root:# Valid (Epoch 35): Loss/seq after 00050 batches: 1096.75390625
INFO:root:# Valid (Epoch 35): Loss/seq after 00100 batches: 1418.5670166015625
INFO:root:# Valid (Epoch 35): Loss/seq after 00150 batches: 1134.7457275390625
INFO:root:# Valid (Epoch 35): Loss/seq after 00200 batches: 1020.1993408203125
INFO:root:Artifacts: Make stick videos for epoch 35
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_35_on_20220422_233120.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_35_index_650_on_20220422_233120.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 36): Loss/seq after 00000 batchs: 2405.391357421875
INFO:root:Train (Epoch 36): Loss/seq after 00050 batchs: 1613.643310546875
INFO:root:Train (Epoch 36): Loss/seq after 00100 batchs: 1529.520751953125
INFO:root:Train (Epoch 36): Loss/seq after 00150 batchs: 1376.572265625
INFO:root:Train (Epoch 36): Loss/seq after 00200 batchs: 1482.633544921875
INFO:root:Train (Epoch 36): Loss/seq after 00250 batchs: 1598.099853515625
INFO:root:Train (Epoch 36): Loss/seq after 00300 batchs: 1514.509033203125
INFO:root:Train (Epoch 36): Loss/seq after 00350 batchs: 1409.8873291015625
INFO:root:Train (Epoch 36): Loss/seq after 00400 batchs: 1446.3316650390625
INFO:root:Train (Epoch 36): Loss/seq after 00450 batchs: 1382.752197265625
INFO:root:Train (Epoch 36): Loss/seq after 00500 batchs: 1384.6085205078125
INFO:root:Train (Epoch 36): Loss/seq after 00550 batchs: 1326.59326171875
INFO:root:Train (Epoch 36): Loss/seq after 00600 batchs: 1289.99267578125
INFO:root:Train (Epoch 36): Loss/seq after 00650 batchs: 1360.4332275390625
INFO:root:Train (Epoch 36): Loss/seq after 00700 batchs: 1453.496337890625
INFO:root:Train (Epoch 36): Loss/seq after 00750 batchs: 1490.334716796875
INFO:root:Train (Epoch 36): Loss/seq after 00800 batchs: 1470.0421142578125
INFO:root:Train (Epoch 36): Loss/seq after 00850 batchs: 1434.859130859375
INFO:root:Train (Epoch 36): Loss/seq after 00900 batchs: 1432.670654296875
INFO:root:Train (Epoch 36): Loss/seq after 00950 batchs: 1521.4970703125
INFO:root:Train (Epoch 36): Loss/seq after 01000 batchs: 1517.1070556640625
INFO:root:Train (Epoch 36): Loss/seq after 01050 batchs: 1489.057373046875
INFO:root:Train (Epoch 36): Loss/seq after 01100 batchs: 1475.4638671875
INFO:root:Train (Epoch 36): Loss/seq after 01150 batchs: 1452.77001953125
INFO:root:Train (Epoch 36): Loss/seq after 01200 batchs: 1437.118408203125
INFO:root:Train (Epoch 36): Loss/seq after 01250 batchs: 1426.5947265625
INFO:root:Train (Epoch 36): Loss/seq after 01300 batchs: 1441.88916015625
INFO:root:Train (Epoch 36): Loss/seq after 01350 batchs: 1445.0587158203125
INFO:root:Train (Epoch 36): Loss/seq after 01400 batchs: 1491.7196044921875
INFO:root:Train (Epoch 36): Loss/seq after 01450 batchs: 1476.638916015625
INFO:root:Train (Epoch 36): Loss/seq after 01500 batchs: 1462.8155517578125
INFO:root:Train (Epoch 36): Loss/seq after 01550 batchs: 1458.24755859375
INFO:root:Train (Epoch 36): Loss/seq after 01600 batchs: 1436.85009765625
INFO:root:Train (Epoch 36): Loss/seq after 01650 batchs: 1422.431396484375
INFO:root:Train (Epoch 36): Loss/seq after 01700 batchs: 1409.1065673828125
INFO:root:Train (Epoch 36): Loss/seq after 01750 batchs: 1394.2078857421875
INFO:root:Train (Epoch 36): Loss/seq after 01800 batchs: 1377.159912109375
INFO:root:Train (Epoch 36): Loss/seq after 01850 batchs: 1360.541748046875
INFO:root:Train (Epoch 36): Loss/seq after 01900 batchs: 1355.2283935546875
INFO:root:Train (Epoch 36): Loss/seq after 01950 batchs: 1345.068603515625
INFO:root:Train (Epoch 36): Loss/seq after 02000 batchs: 1333.231689453125
INFO:root:Train (Epoch 36): Loss/seq after 02050 batchs: 1322.3885498046875
INFO:root:Train (Epoch 36): Loss/seq after 02100 batchs: 1308.9002685546875
INFO:root:Train (Epoch 36): Loss/seq after 02150 batchs: 1296.4923095703125
INFO:root:Train (Epoch 36): Loss/seq after 02200 batchs: 1283.6136474609375
INFO:root:Train (Epoch 36): Loss/seq after 02250 batchs: 1281.18505859375
INFO:root:Train (Epoch 36): Loss/seq after 02300 batchs: 1282.3209228515625
INFO:root:Train (Epoch 36): Loss/seq after 02350 batchs: 1271.455322265625
INFO:root:Train (Epoch 36): Loss/seq after 02400 batchs: 1265.839111328125
INFO:root:Train (Epoch 36): Loss/seq after 02450 batchs: 1251.840087890625
INFO:root:Train (Epoch 36): Loss/seq after 02500 batchs: 1233.954833984375
INFO:root:Train (Epoch 36): Loss/seq after 02550 batchs: 1221.478271484375
INFO:root:Train (Epoch 36): Loss/seq after 02600 batchs: 1218.49658203125
INFO:root:Train (Epoch 36): Loss/seq after 02650 batchs: 1213.4639892578125
INFO:root:Train (Epoch 36): Loss/seq after 02700 batchs: 1208.4896240234375
INFO:root:Train (Epoch 36): Loss/seq after 02750 batchs: 1238.0557861328125
INFO:root:Train (Epoch 36): Loss/seq after 02800 batchs: 1245.115966796875
INFO:root:Train (Epoch 36): Loss/seq after 02850 batchs: 1239.926025390625
INFO:root:Train (Epoch 36): Loss/seq after 02900 batchs: 1236.6334228515625
INFO:root:Train (Epoch 36): Loss/seq after 02950 batchs: 1228.0845947265625
INFO:root:Train (Epoch 36): Loss/seq after 03000 batchs: 1225.6378173828125
INFO:root:Train (Epoch 36): Loss/seq after 03050 batchs: 1227.4525146484375
INFO:root:Train (Epoch 36): Loss/seq after 03100 batchs: 1238.7921142578125
INFO:root:Train (Epoch 36): Loss/seq after 03150 batchs: 1255.4886474609375
INFO:root:Train (Epoch 36): Loss/seq after 03200 batchs: 1269.85400390625
INFO:root:Train (Epoch 36): Loss/seq after 03250 batchs: 1283.0411376953125
INFO:root:Train (Epoch 36): Loss/seq after 03300 batchs: 1280.2222900390625
INFO:root:Train (Epoch 36): Loss/seq after 03350 batchs: 1279.08837890625
INFO:root:Train (Epoch 36): Loss/seq after 03400 batchs: 1269.9227294921875
INFO:root:Train (Epoch 36): Loss/seq after 03450 batchs: 1261.5850830078125
INFO:root:Train (Epoch 36): Loss/seq after 03500 batchs: 1259.1397705078125
INFO:root:Train (Epoch 36): Loss/seq after 03550 batchs: 1251.17626953125
INFO:root:Train (Epoch 36): Loss/seq after 03600 batchs: 1255.758056640625
INFO:root:Train (Epoch 36): Loss/seq after 03650 batchs: 1248.7384033203125
INFO:root:Train (Epoch 36): Loss/seq after 03700 batchs: 1246.9151611328125
INFO:root:Train (Epoch 36): Loss/seq after 03750 batchs: 1246.4520263671875
INFO:root:Train (Epoch 36): Loss/seq after 03800 batchs: 1239.167724609375
INFO:root:Train (Epoch 36): Loss/seq after 03850 batchs: 1234.40380859375
INFO:root:Train (Epoch 36): Loss/seq after 03900 batchs: 1240.4613037109375
INFO:root:Train (Epoch 36): Loss/seq after 03950 batchs: 1247.7823486328125
INFO:root:Train (Epoch 36): Loss/seq after 04000 batchs: 1238.4674072265625
INFO:root:Train (Epoch 36): Loss/seq after 04050 batchs: 1230.1712646484375
INFO:root:Train (Epoch 36): Loss/seq after 04100 batchs: 1223.9417724609375
INFO:root:Train (Epoch 36): Loss/seq after 04150 batchs: 1217.9615478515625
INFO:root:Train (Epoch 36): Loss/seq after 04200 batchs: 1211.815673828125
INFO:root:Train (Epoch 36): Loss/seq after 04250 batchs: 1207.0946044921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 36): Loss/seq after 00000 batches: 900.4356689453125
INFO:root:# Valid (Epoch 36): Loss/seq after 00050 batches: 1108.1236572265625
INFO:root:# Valid (Epoch 36): Loss/seq after 00100 batches: 1399.3511962890625
INFO:root:# Valid (Epoch 36): Loss/seq after 00150 batches: 1119.4097900390625
INFO:root:# Valid (Epoch 36): Loss/seq after 00200 batches: 1007.7816772460938
INFO:root:Artifacts: Make stick videos for epoch 36
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_36_on_20220422_233611.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_36_index_286_on_20220422_233611.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 37): Loss/seq after 00000 batchs: 2397.33154296875
INFO:root:Train (Epoch 37): Loss/seq after 00050 batchs: 1581.1041259765625
INFO:root:Train (Epoch 37): Loss/seq after 00100 batchs: 1487.472412109375
INFO:root:Train (Epoch 37): Loss/seq after 00150 batchs: 1324.6385498046875
INFO:root:Train (Epoch 37): Loss/seq after 00200 batchs: 1441.2716064453125
INFO:root:Train (Epoch 37): Loss/seq after 00250 batchs: 1555.243408203125
INFO:root:Train (Epoch 37): Loss/seq after 00300 batchs: 1478.6231689453125
INFO:root:Train (Epoch 37): Loss/seq after 00350 batchs: 1379.477294921875
INFO:root:Train (Epoch 37): Loss/seq after 00400 batchs: 1416.1585693359375
INFO:root:Train (Epoch 37): Loss/seq after 00450 batchs: 1356.1414794921875
INFO:root:Train (Epoch 37): Loss/seq after 00500 batchs: 1362.732177734375
INFO:root:Train (Epoch 37): Loss/seq after 00550 batchs: 1306.649658203125
INFO:root:Train (Epoch 37): Loss/seq after 00600 batchs: 1275.271240234375
INFO:root:Train (Epoch 37): Loss/seq after 00650 batchs: 1347.031494140625
INFO:root:Train (Epoch 37): Loss/seq after 00700 batchs: 1441.317138671875
INFO:root:Train (Epoch 37): Loss/seq after 00750 batchs: 1480.220703125
INFO:root:Train (Epoch 37): Loss/seq after 00800 batchs: 1461.8870849609375
INFO:root:Train (Epoch 37): Loss/seq after 00850 batchs: 1427.804931640625
INFO:root:Train (Epoch 37): Loss/seq after 00900 batchs: 1426.6080322265625
INFO:root:Train (Epoch 37): Loss/seq after 00950 batchs: 1509.3880615234375
INFO:root:Train (Epoch 37): Loss/seq after 01000 batchs: 1506.486083984375
INFO:root:Train (Epoch 37): Loss/seq after 01050 batchs: 1481.372314453125
INFO:root:Train (Epoch 37): Loss/seq after 01100 batchs: 1469.70166015625
INFO:root:Train (Epoch 37): Loss/seq after 01150 batchs: 1448.1817626953125
INFO:root:Train (Epoch 37): Loss/seq after 01200 batchs: 1432.022216796875
INFO:root:Train (Epoch 37): Loss/seq after 01250 batchs: 1422.1219482421875
INFO:root:Train (Epoch 37): Loss/seq after 01300 batchs: 1437.6192626953125
INFO:root:Train (Epoch 37): Loss/seq after 01350 batchs: 1441.147705078125
INFO:root:Train (Epoch 37): Loss/seq after 01400 batchs: 1487.5428466796875
INFO:root:Train (Epoch 37): Loss/seq after 01450 batchs: 1471.84814453125
INFO:root:Train (Epoch 37): Loss/seq after 01500 batchs: 1457.69921875
INFO:root:Train (Epoch 37): Loss/seq after 01550 batchs: 1450.896484375
INFO:root:Train (Epoch 37): Loss/seq after 01600 batchs: 1429.7706298828125
INFO:root:Train (Epoch 37): Loss/seq after 01650 batchs: 1414.905029296875
INFO:root:Train (Epoch 37): Loss/seq after 01700 batchs: 1401.2999267578125
INFO:root:Train (Epoch 37): Loss/seq after 01750 batchs: 1386.64208984375
INFO:root:Train (Epoch 37): Loss/seq after 01800 batchs: 1369.6646728515625
INFO:root:Train (Epoch 37): Loss/seq after 01850 batchs: 1353.2406005859375
INFO:root:Train (Epoch 37): Loss/seq after 01900 batchs: 1348.3946533203125
INFO:root:Train (Epoch 37): Loss/seq after 01950 batchs: 1338.54833984375
INFO:root:Train (Epoch 37): Loss/seq after 02000 batchs: 1326.922607421875
INFO:root:Train (Epoch 37): Loss/seq after 02050 batchs: 1316.232421875
INFO:root:Train (Epoch 37): Loss/seq after 02100 batchs: 1302.833984375
INFO:root:Train (Epoch 37): Loss/seq after 02150 batchs: 1290.5408935546875
INFO:root:Train (Epoch 37): Loss/seq after 02200 batchs: 1277.791015625
INFO:root:Train (Epoch 37): Loss/seq after 02250 batchs: 1276.120361328125
INFO:root:Train (Epoch 37): Loss/seq after 02300 batchs: 1277.1695556640625
INFO:root:Train (Epoch 37): Loss/seq after 02350 batchs: 1266.68798828125
INFO:root:Train (Epoch 37): Loss/seq after 02400 batchs: 1260.781494140625
INFO:root:Train (Epoch 37): Loss/seq after 02450 batchs: 1246.6649169921875
INFO:root:Train (Epoch 37): Loss/seq after 02500 batchs: 1228.868896484375
INFO:root:Train (Epoch 37): Loss/seq after 02550 batchs: 1216.1776123046875
INFO:root:Train (Epoch 37): Loss/seq after 02600 batchs: 1212.996826171875
INFO:root:Train (Epoch 37): Loss/seq after 02650 batchs: 1207.7000732421875
INFO:root:Train (Epoch 37): Loss/seq after 02700 batchs: 1203.0191650390625
INFO:root:Train (Epoch 37): Loss/seq after 02750 batchs: 1233.6046142578125
INFO:root:Train (Epoch 37): Loss/seq after 02800 batchs: 1240.8392333984375
INFO:root:Train (Epoch 37): Loss/seq after 02850 batchs: 1235.6143798828125
INFO:root:Train (Epoch 37): Loss/seq after 02900 batchs: 1232.5955810546875
INFO:root:Train (Epoch 37): Loss/seq after 02950 batchs: 1224.237548828125
INFO:root:Train (Epoch 37): Loss/seq after 03000 batchs: 1221.885498046875
INFO:root:Train (Epoch 37): Loss/seq after 03050 batchs: 1223.9737548828125
INFO:root:Train (Epoch 37): Loss/seq after 03100 batchs: 1235.6529541015625
INFO:root:Train (Epoch 37): Loss/seq after 03150 batchs: 1251.1209716796875
INFO:root:Train (Epoch 37): Loss/seq after 03200 batchs: 1265.6929931640625
INFO:root:Train (Epoch 37): Loss/seq after 03250 batchs: 1279.081298828125
INFO:root:Train (Epoch 37): Loss/seq after 03300 batchs: 1277.7705078125
INFO:root:Train (Epoch 37): Loss/seq after 03350 batchs: 1277.2857666015625
INFO:root:Train (Epoch 37): Loss/seq after 03400 batchs: 1268.1263427734375
INFO:root:Train (Epoch 37): Loss/seq after 03450 batchs: 1261.14013671875
INFO:root:Train (Epoch 37): Loss/seq after 03500 batchs: 1259.387451171875
INFO:root:Train (Epoch 37): Loss/seq after 03550 batchs: 1252.11669921875
INFO:root:Train (Epoch 37): Loss/seq after 03600 batchs: 1256.8433837890625
INFO:root:Train (Epoch 37): Loss/seq after 03650 batchs: 1249.781982421875
INFO:root:Train (Epoch 37): Loss/seq after 03700 batchs: 1247.951171875
INFO:root:Train (Epoch 37): Loss/seq after 03750 batchs: 1247.3404541015625
INFO:root:Train (Epoch 37): Loss/seq after 03800 batchs: 1239.8419189453125
INFO:root:Train (Epoch 37): Loss/seq after 03850 batchs: 1234.842041015625
INFO:root:Train (Epoch 37): Loss/seq after 03900 batchs: 1240.869140625
INFO:root:Train (Epoch 37): Loss/seq after 03950 batchs: 1248.579833984375
INFO:root:Train (Epoch 37): Loss/seq after 04000 batchs: 1239.2484130859375
INFO:root:Train (Epoch 37): Loss/seq after 04050 batchs: 1230.9268798828125
INFO:root:Train (Epoch 37): Loss/seq after 04100 batchs: 1224.0997314453125
INFO:root:Train (Epoch 37): Loss/seq after 04150 batchs: 1217.9166259765625
INFO:root:Train (Epoch 37): Loss/seq after 04200 batchs: 1211.7314453125
INFO:root:Train (Epoch 37): Loss/seq after 04250 batchs: 1206.834228515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 37): Loss/seq after 00000 batches: 880.56689453125
INFO:root:# Valid (Epoch 37): Loss/seq after 00050 batches: 1108.8173828125
INFO:root:# Valid (Epoch 37): Loss/seq after 00100 batches: 1402.619140625
INFO:root:# Valid (Epoch 37): Loss/seq after 00150 batches: 1122.4952392578125
INFO:root:# Valid (Epoch 37): Loss/seq after 00200 batches: 1010.1632080078125
INFO:root:Artifacts: Make stick videos for epoch 37
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_37_on_20220422_234057.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_37_index_1111_on_20220422_234057.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 38): Loss/seq after 00000 batchs: 2504.93994140625
INFO:root:Train (Epoch 38): Loss/seq after 00050 batchs: 1590.6943359375
INFO:root:Train (Epoch 38): Loss/seq after 00100 batchs: 1518.150390625
INFO:root:Train (Epoch 38): Loss/seq after 00150 batchs: 1355.356689453125
INFO:root:Train (Epoch 38): Loss/seq after 00200 batchs: 1471.5343017578125
INFO:root:Train (Epoch 38): Loss/seq after 00250 batchs: 1583.768310546875
INFO:root:Train (Epoch 38): Loss/seq after 00300 batchs: 1503.5743408203125
INFO:root:Train (Epoch 38): Loss/seq after 00350 batchs: 1403.1583251953125
INFO:root:Train (Epoch 38): Loss/seq after 00400 batchs: 1443.446533203125
INFO:root:Train (Epoch 38): Loss/seq after 00450 batchs: 1380.510986328125
INFO:root:Train (Epoch 38): Loss/seq after 00500 batchs: 1382.7091064453125
INFO:root:Train (Epoch 38): Loss/seq after 00550 batchs: 1324.1173095703125
INFO:root:Train (Epoch 38): Loss/seq after 00600 batchs: 1286.8592529296875
INFO:root:Train (Epoch 38): Loss/seq after 00650 batchs: 1357.0771484375
INFO:root:Train (Epoch 38): Loss/seq after 00700 batchs: 1449.6927490234375
INFO:root:Train (Epoch 38): Loss/seq after 00750 batchs: 1488.04443359375
INFO:root:Train (Epoch 38): Loss/seq after 00800 batchs: 1466.9171142578125
INFO:root:Train (Epoch 38): Loss/seq after 00850 batchs: 1431.1021728515625
INFO:root:Train (Epoch 38): Loss/seq after 00900 batchs: 1427.9761962890625
INFO:root:Train (Epoch 38): Loss/seq after 00950 batchs: 1510.6680908203125
INFO:root:Train (Epoch 38): Loss/seq after 01000 batchs: 1507.21484375
INFO:root:Train (Epoch 38): Loss/seq after 01050 batchs: 1476.1544189453125
INFO:root:Train (Epoch 38): Loss/seq after 01100 batchs: 1463.9022216796875
INFO:root:Train (Epoch 38): Loss/seq after 01150 batchs: 1441.49169921875
INFO:root:Train (Epoch 38): Loss/seq after 01200 batchs: 1425.0999755859375
INFO:root:Train (Epoch 38): Loss/seq after 01250 batchs: 1415.1063232421875
INFO:root:Train (Epoch 38): Loss/seq after 01300 batchs: 1430.892578125
INFO:root:Train (Epoch 38): Loss/seq after 01350 batchs: 1434.6060791015625
INFO:root:Train (Epoch 38): Loss/seq after 01400 batchs: 1481.68896484375
INFO:root:Train (Epoch 38): Loss/seq after 01450 batchs: 1465.6168212890625
INFO:root:Train (Epoch 38): Loss/seq after 01500 batchs: 1451.3883056640625
INFO:root:Train (Epoch 38): Loss/seq after 01550 batchs: 1444.7181396484375
INFO:root:Train (Epoch 38): Loss/seq after 01600 batchs: 1423.6593017578125
INFO:root:Train (Epoch 38): Loss/seq after 01650 batchs: 1408.4298095703125
INFO:root:Train (Epoch 38): Loss/seq after 01700 batchs: 1394.935791015625
INFO:root:Train (Epoch 38): Loss/seq after 01750 batchs: 1380.3408203125
INFO:root:Train (Epoch 38): Loss/seq after 01800 batchs: 1363.4976806640625
INFO:root:Train (Epoch 38): Loss/seq after 01850 batchs: 1347.229736328125
INFO:root:Train (Epoch 38): Loss/seq after 01900 batchs: 1341.8720703125
INFO:root:Train (Epoch 38): Loss/seq after 01950 batchs: 1332.7064208984375
INFO:root:Train (Epoch 38): Loss/seq after 02000 batchs: 1320.97216796875
INFO:root:Train (Epoch 38): Loss/seq after 02050 batchs: 1310.3133544921875
INFO:root:Train (Epoch 38): Loss/seq after 02100 batchs: 1297.028564453125
INFO:root:Train (Epoch 38): Loss/seq after 02150 batchs: 1284.7203369140625
INFO:root:Train (Epoch 38): Loss/seq after 02200 batchs: 1271.9798583984375
INFO:root:Train (Epoch 38): Loss/seq after 02250 batchs: 1269.3131103515625
INFO:root:Train (Epoch 38): Loss/seq after 02300 batchs: 1270.33154296875
INFO:root:Train (Epoch 38): Loss/seq after 02350 batchs: 1259.181640625
INFO:root:Train (Epoch 38): Loss/seq after 02400 batchs: 1253.5421142578125
INFO:root:Train (Epoch 38): Loss/seq after 02450 batchs: 1239.6939697265625
INFO:root:Train (Epoch 38): Loss/seq after 02500 batchs: 1222.0330810546875
INFO:root:Train (Epoch 38): Loss/seq after 02550 batchs: 1209.5052490234375
INFO:root:Train (Epoch 38): Loss/seq after 02600 batchs: 1206.474365234375
INFO:root:Train (Epoch 38): Loss/seq after 02650 batchs: 1201.260498046875
INFO:root:Train (Epoch 38): Loss/seq after 02700 batchs: 1196.57666015625
INFO:root:Train (Epoch 38): Loss/seq after 02750 batchs: 1225.5322265625
INFO:root:Train (Epoch 38): Loss/seq after 02800 batchs: 1232.2799072265625
INFO:root:Train (Epoch 38): Loss/seq after 02850 batchs: 1227.098388671875
INFO:root:Train (Epoch 38): Loss/seq after 02900 batchs: 1223.31005859375
INFO:root:Train (Epoch 38): Loss/seq after 02950 batchs: 1214.548583984375
INFO:root:Train (Epoch 38): Loss/seq after 03000 batchs: 1212.2880859375
INFO:root:Train (Epoch 38): Loss/seq after 03050 batchs: 1214.26904296875
INFO:root:Train (Epoch 38): Loss/seq after 03100 batchs: 1225.4261474609375
INFO:root:Train (Epoch 38): Loss/seq after 03150 batchs: 1241.4796142578125
INFO:root:Train (Epoch 38): Loss/seq after 03200 batchs: 1255.66552734375
INFO:root:Train (Epoch 38): Loss/seq after 03250 batchs: 1269.06005859375
INFO:root:Train (Epoch 38): Loss/seq after 03300 batchs: 1266.241943359375
INFO:root:Train (Epoch 38): Loss/seq after 03350 batchs: 1264.8568115234375
INFO:root:Train (Epoch 38): Loss/seq after 03400 batchs: 1255.93310546875
INFO:root:Train (Epoch 38): Loss/seq after 03450 batchs: 1248.775146484375
INFO:root:Train (Epoch 38): Loss/seq after 03500 batchs: 1246.6351318359375
INFO:root:Train (Epoch 38): Loss/seq after 03550 batchs: 1239.373046875
INFO:root:Train (Epoch 38): Loss/seq after 03600 batchs: 1244.211181640625
INFO:root:Train (Epoch 38): Loss/seq after 03650 batchs: 1237.1141357421875
INFO:root:Train (Epoch 38): Loss/seq after 03700 batchs: 1235.4287109375
INFO:root:Train (Epoch 38): Loss/seq after 03750 batchs: 1235.0797119140625
INFO:root:Train (Epoch 38): Loss/seq after 03800 batchs: 1227.8450927734375
INFO:root:Train (Epoch 38): Loss/seq after 03850 batchs: 1223.0177001953125
INFO:root:Train (Epoch 38): Loss/seq after 03900 batchs: 1229.2574462890625
INFO:root:Train (Epoch 38): Loss/seq after 03950 batchs: 1236.529052734375
INFO:root:Train (Epoch 38): Loss/seq after 04000 batchs: 1227.363525390625
INFO:root:Train (Epoch 38): Loss/seq after 04050 batchs: 1219.215087890625
INFO:root:Train (Epoch 38): Loss/seq after 04100 batchs: 1212.735595703125
INFO:root:Train (Epoch 38): Loss/seq after 04150 batchs: 1206.7236328125
INFO:root:Train (Epoch 38): Loss/seq after 04200 batchs: 1201.357421875
INFO:root:Train (Epoch 38): Loss/seq after 04250 batchs: 1197.046630859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 38): Loss/seq after 00000 batches: 871.6360473632812
INFO:root:# Valid (Epoch 38): Loss/seq after 00050 batches: 1089.3155517578125
INFO:root:# Valid (Epoch 38): Loss/seq after 00100 batches: 1394.85302734375
INFO:root:# Valid (Epoch 38): Loss/seq after 00150 batches: 1117.583251953125
INFO:root:# Valid (Epoch 38): Loss/seq after 00200 batches: 1005.72216796875
INFO:root:Artifacts: Make stick videos for epoch 38
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_38_on_20220422_234549.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_38_index_331_on_20220422_234549.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 39): Loss/seq after 00000 batchs: 2437.75732421875
INFO:root:Train (Epoch 39): Loss/seq after 00050 batchs: 1588.8424072265625
INFO:root:Train (Epoch 39): Loss/seq after 00100 batchs: 1503.9300537109375
INFO:root:Train (Epoch 39): Loss/seq after 00150 batchs: 1345.165283203125
INFO:root:Train (Epoch 39): Loss/seq after 00200 batchs: 1459.5235595703125
INFO:root:Train (Epoch 39): Loss/seq after 00250 batchs: 1574.0172119140625
INFO:root:Train (Epoch 39): Loss/seq after 00300 batchs: 1494.9688720703125
INFO:root:Train (Epoch 39): Loss/seq after 00350 batchs: 1395.2091064453125
INFO:root:Train (Epoch 39): Loss/seq after 00400 batchs: 1434.800048828125
INFO:root:Train (Epoch 39): Loss/seq after 00450 batchs: 1373.857421875
INFO:root:Train (Epoch 39): Loss/seq after 00500 batchs: 1381.3221435546875
INFO:root:Train (Epoch 39): Loss/seq after 00550 batchs: 1322.8099365234375
INFO:root:Train (Epoch 39): Loss/seq after 00600 batchs: 1287.0654296875
INFO:root:Train (Epoch 39): Loss/seq after 00650 batchs: 1357.2169189453125
INFO:root:Train (Epoch 39): Loss/seq after 00700 batchs: 1450.539306640625
INFO:root:Train (Epoch 39): Loss/seq after 00750 batchs: 1488.0511474609375
INFO:root:Train (Epoch 39): Loss/seq after 00800 batchs: 1469.6346435546875
INFO:root:Train (Epoch 39): Loss/seq after 00850 batchs: 1435.16552734375
INFO:root:Train (Epoch 39): Loss/seq after 00900 batchs: 1433.608154296875
INFO:root:Train (Epoch 39): Loss/seq after 00950 batchs: 1516.1077880859375
INFO:root:Train (Epoch 39): Loss/seq after 01000 batchs: 1512.540771484375
INFO:root:Train (Epoch 39): Loss/seq after 01050 batchs: 1483.822021484375
INFO:root:Train (Epoch 39): Loss/seq after 01100 batchs: 1471.216064453125
INFO:root:Train (Epoch 39): Loss/seq after 01150 batchs: 1448.6597900390625
INFO:root:Train (Epoch 39): Loss/seq after 01200 batchs: 1431.912109375
INFO:root:Train (Epoch 39): Loss/seq after 01250 batchs: 1421.37451171875
INFO:root:Train (Epoch 39): Loss/seq after 01300 batchs: 1436.8197021484375
INFO:root:Train (Epoch 39): Loss/seq after 01350 batchs: 1440.14794921875
INFO:root:Train (Epoch 39): Loss/seq after 01400 batchs: 1486.885986328125
INFO:root:Train (Epoch 39): Loss/seq after 01450 batchs: 1470.3577880859375
INFO:root:Train (Epoch 39): Loss/seq after 01500 batchs: 1455.9150390625
INFO:root:Train (Epoch 39): Loss/seq after 01550 batchs: 1448.85009765625
INFO:root:Train (Epoch 39): Loss/seq after 01600 batchs: 1427.46240234375
INFO:root:Train (Epoch 39): Loss/seq after 01650 batchs: 1413.237060546875
INFO:root:Train (Epoch 39): Loss/seq after 01700 batchs: 1400.0623779296875
INFO:root:Train (Epoch 39): Loss/seq after 01750 batchs: 1385.4183349609375
INFO:root:Train (Epoch 39): Loss/seq after 01800 batchs: 1368.375
INFO:root:Train (Epoch 39): Loss/seq after 01850 batchs: 1351.84326171875
INFO:root:Train (Epoch 39): Loss/seq after 01900 batchs: 1346.349853515625
INFO:root:Train (Epoch 39): Loss/seq after 01950 batchs: 1336.1556396484375
INFO:root:Train (Epoch 39): Loss/seq after 02000 batchs: 1324.28271484375
INFO:root:Train (Epoch 39): Loss/seq after 02050 batchs: 1313.4581298828125
INFO:root:Train (Epoch 39): Loss/seq after 02100 batchs: 1299.9947509765625
INFO:root:Train (Epoch 39): Loss/seq after 02150 batchs: 1287.53466796875
INFO:root:Train (Epoch 39): Loss/seq after 02200 batchs: 1274.7574462890625
INFO:root:Train (Epoch 39): Loss/seq after 02250 batchs: 1272.01611328125
INFO:root:Train (Epoch 39): Loss/seq after 02300 batchs: 1272.83447265625
INFO:root:Train (Epoch 39): Loss/seq after 02350 batchs: 1260.8873291015625
INFO:root:Train (Epoch 39): Loss/seq after 02400 batchs: 1255.059814453125
INFO:root:Train (Epoch 39): Loss/seq after 02450 batchs: 1240.9010009765625
INFO:root:Train (Epoch 39): Loss/seq after 02500 batchs: 1223.250732421875
INFO:root:Train (Epoch 39): Loss/seq after 02550 batchs: 1210.695068359375
INFO:root:Train (Epoch 39): Loss/seq after 02600 batchs: 1207.28857421875
INFO:root:Train (Epoch 39): Loss/seq after 02650 batchs: 1201.6871337890625
INFO:root:Train (Epoch 39): Loss/seq after 02700 batchs: 1196.8209228515625
INFO:root:Train (Epoch 39): Loss/seq after 02750 batchs: 1225.74658203125
INFO:root:Train (Epoch 39): Loss/seq after 02800 batchs: 1231.9549560546875
INFO:root:Train (Epoch 39): Loss/seq after 02850 batchs: 1226.6026611328125
INFO:root:Train (Epoch 39): Loss/seq after 02900 batchs: 1223.1126708984375
INFO:root:Train (Epoch 39): Loss/seq after 02950 batchs: 1214.3062744140625
INFO:root:Train (Epoch 39): Loss/seq after 03000 batchs: 1212.0443115234375
INFO:root:Train (Epoch 39): Loss/seq after 03050 batchs: 1213.9512939453125
INFO:root:Train (Epoch 39): Loss/seq after 03100 batchs: 1223.578369140625
INFO:root:Train (Epoch 39): Loss/seq after 03150 batchs: 1240.086181640625
INFO:root:Train (Epoch 39): Loss/seq after 03200 batchs: 1254.7310791015625
INFO:root:Train (Epoch 39): Loss/seq after 03250 batchs: 1268.346923828125
INFO:root:Train (Epoch 39): Loss/seq after 03300 batchs: 1265.12890625
INFO:root:Train (Epoch 39): Loss/seq after 03350 batchs: 1263.828125
INFO:root:Train (Epoch 39): Loss/seq after 03400 batchs: 1254.87744140625
INFO:root:Train (Epoch 39): Loss/seq after 03450 batchs: 1247.1571044921875
INFO:root:Train (Epoch 39): Loss/seq after 03500 batchs: 1244.98681640625
INFO:root:Train (Epoch 39): Loss/seq after 03550 batchs: 1236.85693359375
INFO:root:Train (Epoch 39): Loss/seq after 03600 batchs: 1241.17919921875
INFO:root:Train (Epoch 39): Loss/seq after 03650 batchs: 1233.9256591796875
INFO:root:Train (Epoch 39): Loss/seq after 03700 batchs: 1232.264404296875
INFO:root:Train (Epoch 39): Loss/seq after 03750 batchs: 1231.9173583984375
INFO:root:Train (Epoch 39): Loss/seq after 03800 batchs: 1224.6097412109375
INFO:root:Train (Epoch 39): Loss/seq after 03850 batchs: 1219.741943359375
INFO:root:Train (Epoch 39): Loss/seq after 03900 batchs: 1225.392578125
INFO:root:Train (Epoch 39): Loss/seq after 03950 batchs: 1233.0274658203125
INFO:root:Train (Epoch 39): Loss/seq after 04000 batchs: 1223.8951416015625
INFO:root:Train (Epoch 39): Loss/seq after 04050 batchs: 1215.7587890625
INFO:root:Train (Epoch 39): Loss/seq after 04100 batchs: 1209.1453857421875
INFO:root:Train (Epoch 39): Loss/seq after 04150 batchs: 1203.32080078125
INFO:root:Train (Epoch 39): Loss/seq after 04200 batchs: 1197.330322265625
INFO:root:Train (Epoch 39): Loss/seq after 04250 batchs: 1192.6151123046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 39): Loss/seq after 00000 batches: 873.1889038085938
INFO:root:# Valid (Epoch 39): Loss/seq after 00050 batches: 1097.3284912109375
INFO:root:# Valid (Epoch 39): Loss/seq after 00100 batches: 1400.7664794921875
INFO:root:# Valid (Epoch 39): Loss/seq after 00150 batches: 1137.22607421875
INFO:root:# Valid (Epoch 39): Loss/seq after 00200 batches: 1029.85107421875
INFO:root:Artifacts: Make stick videos for epoch 39
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_39_on_20220422_235042.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_39_index_1118_on_20220422_235042.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 40): Loss/seq after 00000 batchs: 2404.318115234375
INFO:root:Train (Epoch 40): Loss/seq after 00050 batchs: 1557.978759765625
INFO:root:Train (Epoch 40): Loss/seq after 00100 batchs: 1464.4866943359375
INFO:root:Train (Epoch 40): Loss/seq after 00150 batchs: 1313.3292236328125
INFO:root:Train (Epoch 40): Loss/seq after 00200 batchs: 1442.482666015625
INFO:root:Train (Epoch 40): Loss/seq after 00250 batchs: 1556.97509765625
INFO:root:Train (Epoch 40): Loss/seq after 00300 batchs: 1480.4158935546875
INFO:root:Train (Epoch 40): Loss/seq after 00350 batchs: 1387.0552978515625
INFO:root:Train (Epoch 40): Loss/seq after 00400 batchs: 1425.4024658203125
INFO:root:Train (Epoch 40): Loss/seq after 00450 batchs: 1363.9940185546875
INFO:root:Train (Epoch 40): Loss/seq after 00500 batchs: 1375.004150390625
INFO:root:Train (Epoch 40): Loss/seq after 00550 batchs: 1317.08056640625
INFO:root:Train (Epoch 40): Loss/seq after 00600 batchs: 1284.955810546875
INFO:root:Train (Epoch 40): Loss/seq after 00650 batchs: 1355.475830078125
INFO:root:Train (Epoch 40): Loss/seq after 00700 batchs: 1448.7027587890625
INFO:root:Train (Epoch 40): Loss/seq after 00750 batchs: 1487.5555419921875
INFO:root:Train (Epoch 40): Loss/seq after 00800 batchs: 1468.797119140625
INFO:root:Train (Epoch 40): Loss/seq after 00850 batchs: 1432.4957275390625
INFO:root:Train (Epoch 40): Loss/seq after 00900 batchs: 1429.7677001953125
INFO:root:Train (Epoch 40): Loss/seq after 00950 batchs: 1512.16064453125
INFO:root:Train (Epoch 40): Loss/seq after 01000 batchs: 1509.2364501953125
INFO:root:Train (Epoch 40): Loss/seq after 01050 batchs: 1476.299072265625
INFO:root:Train (Epoch 40): Loss/seq after 01100 batchs: 1465.898193359375
INFO:root:Train (Epoch 40): Loss/seq after 01150 batchs: 1443.0877685546875
INFO:root:Train (Epoch 40): Loss/seq after 01200 batchs: 1426.4783935546875
INFO:root:Train (Epoch 40): Loss/seq after 01250 batchs: 1415.1856689453125
INFO:root:Train (Epoch 40): Loss/seq after 01300 batchs: 1430.956787109375
INFO:root:Train (Epoch 40): Loss/seq after 01350 batchs: 1434.6207275390625
INFO:root:Train (Epoch 40): Loss/seq after 01400 batchs: 1482.523681640625
INFO:root:Train (Epoch 40): Loss/seq after 01450 batchs: 1466.120361328125
INFO:root:Train (Epoch 40): Loss/seq after 01500 batchs: 1451.9051513671875
INFO:root:Train (Epoch 40): Loss/seq after 01550 batchs: 1444.53466796875
INFO:root:Train (Epoch 40): Loss/seq after 01600 batchs: 1423.28759765625
INFO:root:Train (Epoch 40): Loss/seq after 01650 batchs: 1407.299560546875
INFO:root:Train (Epoch 40): Loss/seq after 01700 batchs: 1393.9990234375
INFO:root:Train (Epoch 40): Loss/seq after 01750 batchs: 1379.46826171875
INFO:root:Train (Epoch 40): Loss/seq after 01800 batchs: 1362.5260009765625
INFO:root:Train (Epoch 40): Loss/seq after 01850 batchs: 1346.1739501953125
INFO:root:Train (Epoch 40): Loss/seq after 01900 batchs: 1340.290771484375
INFO:root:Train (Epoch 40): Loss/seq after 01950 batchs: 1330.56298828125
INFO:root:Train (Epoch 40): Loss/seq after 02000 batchs: 1318.8897705078125
INFO:root:Train (Epoch 40): Loss/seq after 02050 batchs: 1308.1070556640625
INFO:root:Train (Epoch 40): Loss/seq after 02100 batchs: 1294.656005859375
INFO:root:Train (Epoch 40): Loss/seq after 02150 batchs: 1282.245849609375
INFO:root:Train (Epoch 40): Loss/seq after 02200 batchs: 1269.4720458984375
INFO:root:Train (Epoch 40): Loss/seq after 02250 batchs: 1266.5496826171875
INFO:root:Train (Epoch 40): Loss/seq after 02300 batchs: 1267.5345458984375
INFO:root:Train (Epoch 40): Loss/seq after 02350 batchs: 1255.44921875
INFO:root:Train (Epoch 40): Loss/seq after 02400 batchs: 1249.6334228515625
INFO:root:Train (Epoch 40): Loss/seq after 02450 batchs: 1235.547119140625
INFO:root:Train (Epoch 40): Loss/seq after 02500 batchs: 1217.995361328125
INFO:root:Train (Epoch 40): Loss/seq after 02550 batchs: 1205.3226318359375
INFO:root:Train (Epoch 40): Loss/seq after 02600 batchs: 1202.1796875
INFO:root:Train (Epoch 40): Loss/seq after 02650 batchs: 1196.898193359375
INFO:root:Train (Epoch 40): Loss/seq after 02700 batchs: 1192.09765625
INFO:root:Train (Epoch 40): Loss/seq after 02750 batchs: 1221.1943359375
INFO:root:Train (Epoch 40): Loss/seq after 02800 batchs: 1227.606689453125
INFO:root:Train (Epoch 40): Loss/seq after 02850 batchs: 1222.51611328125
INFO:root:Train (Epoch 40): Loss/seq after 02900 batchs: 1219.4874267578125
INFO:root:Train (Epoch 40): Loss/seq after 02950 batchs: 1211.013671875
INFO:root:Train (Epoch 40): Loss/seq after 03000 batchs: 1208.809814453125
INFO:root:Train (Epoch 40): Loss/seq after 03050 batchs: 1210.82080078125
INFO:root:Train (Epoch 40): Loss/seq after 03100 batchs: 1220.6943359375
INFO:root:Train (Epoch 40): Loss/seq after 03150 batchs: 1239.7857666015625
INFO:root:Train (Epoch 40): Loss/seq after 03200 batchs: 1254.052001953125
INFO:root:Train (Epoch 40): Loss/seq after 03250 batchs: 1267.515625
INFO:root:Train (Epoch 40): Loss/seq after 03300 batchs: 1264.4261474609375
INFO:root:Train (Epoch 40): Loss/seq after 03350 batchs: 1262.762939453125
INFO:root:Train (Epoch 40): Loss/seq after 03400 batchs: 1253.535400390625
INFO:root:Train (Epoch 40): Loss/seq after 03450 batchs: 1245.25537109375
INFO:root:Train (Epoch 40): Loss/seq after 03500 batchs: 1242.6641845703125
INFO:root:Train (Epoch 40): Loss/seq after 03550 batchs: 1234.4573974609375
INFO:root:Train (Epoch 40): Loss/seq after 03600 batchs: 1238.7117919921875
INFO:root:Train (Epoch 40): Loss/seq after 03650 batchs: 1231.9527587890625
INFO:root:Train (Epoch 40): Loss/seq after 03700 batchs: 1230.7630615234375
INFO:root:Train (Epoch 40): Loss/seq after 03750 batchs: 1230.383056640625
INFO:root:Train (Epoch 40): Loss/seq after 03800 batchs: 1223.121337890625
INFO:root:Train (Epoch 40): Loss/seq after 03850 batchs: 1218.27978515625
INFO:root:Train (Epoch 40): Loss/seq after 03900 batchs: 1223.993896484375
INFO:root:Train (Epoch 40): Loss/seq after 03950 batchs: 1232.1932373046875
INFO:root:Train (Epoch 40): Loss/seq after 04000 batchs: 1223.0242919921875
INFO:root:Train (Epoch 40): Loss/seq after 04050 batchs: 1214.8885498046875
INFO:root:Train (Epoch 40): Loss/seq after 04100 batchs: 1208.5140380859375
INFO:root:Train (Epoch 40): Loss/seq after 04150 batchs: 1202.55078125
INFO:root:Train (Epoch 40): Loss/seq after 04200 batchs: 1196.353759765625
INFO:root:Train (Epoch 40): Loss/seq after 04250 batchs: 1191.76123046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 40): Loss/seq after 00000 batches: 870.7992553710938
INFO:root:# Valid (Epoch 40): Loss/seq after 00050 batches: 1088.5521240234375
INFO:root:# Valid (Epoch 40): Loss/seq after 00100 batches: 1379.2823486328125
INFO:root:# Valid (Epoch 40): Loss/seq after 00150 batches: 1102.5054931640625
INFO:root:# Valid (Epoch 40): Loss/seq after 00200 batches: 991.7208862304688
INFO:root:Artifacts: Make stick videos for epoch 40
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_40_on_20220422_235542.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_40_index_1637_on_20220422_235542.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 41): Loss/seq after 00000 batchs: 2430.723388671875
INFO:root:Train (Epoch 41): Loss/seq after 00050 batchs: 1564.0316162109375
INFO:root:Train (Epoch 41): Loss/seq after 00100 batchs: 1463.7679443359375
INFO:root:Train (Epoch 41): Loss/seq after 00150 batchs: 1297.463134765625
INFO:root:Train (Epoch 41): Loss/seq after 00200 batchs: 1421.036376953125
INFO:root:Train (Epoch 41): Loss/seq after 00250 batchs: 1546.552734375
INFO:root:Train (Epoch 41): Loss/seq after 00300 batchs: 1471.227294921875
INFO:root:Train (Epoch 41): Loss/seq after 00350 batchs: 1373.7535400390625
INFO:root:Train (Epoch 41): Loss/seq after 00400 batchs: 1413.275634765625
INFO:root:Train (Epoch 41): Loss/seq after 00450 batchs: 1353.15869140625
INFO:root:Train (Epoch 41): Loss/seq after 00500 batchs: 1359.4189453125
INFO:root:Train (Epoch 41): Loss/seq after 00550 batchs: 1302.80859375
INFO:root:Train (Epoch 41): Loss/seq after 00600 batchs: 1266.537353515625
INFO:root:Train (Epoch 41): Loss/seq after 00650 batchs: 1338.345947265625
INFO:root:Train (Epoch 41): Loss/seq after 00700 batchs: 1432.7705078125
INFO:root:Train (Epoch 41): Loss/seq after 00750 batchs: 1472.7091064453125
INFO:root:Train (Epoch 41): Loss/seq after 00800 batchs: 1450.7945556640625
INFO:root:Train (Epoch 41): Loss/seq after 00850 batchs: 1415.485595703125
INFO:root:Train (Epoch 41): Loss/seq after 00900 batchs: 1413.1680908203125
INFO:root:Train (Epoch 41): Loss/seq after 00950 batchs: 1498.903076171875
INFO:root:Train (Epoch 41): Loss/seq after 01000 batchs: 1495.662353515625
INFO:root:Train (Epoch 41): Loss/seq after 01050 batchs: 1465.2242431640625
INFO:root:Train (Epoch 41): Loss/seq after 01100 batchs: 1452.24658203125
INFO:root:Train (Epoch 41): Loss/seq after 01150 batchs: 1430.4508056640625
INFO:root:Train (Epoch 41): Loss/seq after 01200 batchs: 1414.70458984375
INFO:root:Train (Epoch 41): Loss/seq after 01250 batchs: 1405.10107421875
INFO:root:Train (Epoch 41): Loss/seq after 01300 batchs: 1421.2452392578125
INFO:root:Train (Epoch 41): Loss/seq after 01350 batchs: 1425.293212890625
INFO:root:Train (Epoch 41): Loss/seq after 01400 batchs: 1474.4420166015625
INFO:root:Train (Epoch 41): Loss/seq after 01450 batchs: 1458.7467041015625
INFO:root:Train (Epoch 41): Loss/seq after 01500 batchs: 1444.731689453125
INFO:root:Train (Epoch 41): Loss/seq after 01550 batchs: 1439.3621826171875
INFO:root:Train (Epoch 41): Loss/seq after 01600 batchs: 1418.440673828125
INFO:root:Train (Epoch 41): Loss/seq after 01650 batchs: 1403.71044921875
INFO:root:Train (Epoch 41): Loss/seq after 01700 batchs: 1390.565673828125
INFO:root:Train (Epoch 41): Loss/seq after 01750 batchs: 1376.3201904296875
INFO:root:Train (Epoch 41): Loss/seq after 01800 batchs: 1359.70361328125
INFO:root:Train (Epoch 41): Loss/seq after 01850 batchs: 1343.3409423828125
INFO:root:Train (Epoch 41): Loss/seq after 01900 batchs: 1337.3455810546875
INFO:root:Train (Epoch 41): Loss/seq after 01950 batchs: 1326.8740234375
INFO:root:Train (Epoch 41): Loss/seq after 02000 batchs: 1315.185302734375
INFO:root:Train (Epoch 41): Loss/seq after 02050 batchs: 1304.552978515625
INFO:root:Train (Epoch 41): Loss/seq after 02100 batchs: 1291.316650390625
INFO:root:Train (Epoch 41): Loss/seq after 02150 batchs: 1278.988037109375
INFO:root:Train (Epoch 41): Loss/seq after 02200 batchs: 1266.3238525390625
INFO:root:Train (Epoch 41): Loss/seq after 02250 batchs: 1262.9658203125
INFO:root:Train (Epoch 41): Loss/seq after 02300 batchs: 1264.19482421875
INFO:root:Train (Epoch 41): Loss/seq after 02350 batchs: 1252.6817626953125
INFO:root:Train (Epoch 41): Loss/seq after 02400 batchs: 1246.77294921875
INFO:root:Train (Epoch 41): Loss/seq after 02450 batchs: 1232.68505859375
INFO:root:Train (Epoch 41): Loss/seq after 02500 batchs: 1215.159423828125
INFO:root:Train (Epoch 41): Loss/seq after 02550 batchs: 1202.2906494140625
INFO:root:Train (Epoch 41): Loss/seq after 02600 batchs: 1198.947021484375
INFO:root:Train (Epoch 41): Loss/seq after 02650 batchs: 1193.5096435546875
INFO:root:Train (Epoch 41): Loss/seq after 02700 batchs: 1188.5775146484375
INFO:root:Train (Epoch 41): Loss/seq after 02750 batchs: 1217.76806640625
INFO:root:Train (Epoch 41): Loss/seq after 02800 batchs: 1223.57763671875
INFO:root:Train (Epoch 41): Loss/seq after 02850 batchs: 1218.8028564453125
INFO:root:Train (Epoch 41): Loss/seq after 02900 batchs: 1215.5438232421875
INFO:root:Train (Epoch 41): Loss/seq after 02950 batchs: 1207.211181640625
INFO:root:Train (Epoch 41): Loss/seq after 03000 batchs: 1205.092041015625
INFO:root:Train (Epoch 41): Loss/seq after 03050 batchs: 1207.1478271484375
INFO:root:Train (Epoch 41): Loss/seq after 03100 batchs: 1217.172119140625
INFO:root:Train (Epoch 41): Loss/seq after 03150 batchs: 1232.8458251953125
INFO:root:Train (Epoch 41): Loss/seq after 03200 batchs: 1247.11376953125
INFO:root:Train (Epoch 41): Loss/seq after 03250 batchs: 1260.6695556640625
INFO:root:Train (Epoch 41): Loss/seq after 03300 batchs: 1257.5804443359375
INFO:root:Train (Epoch 41): Loss/seq after 03350 batchs: 1256.3206787109375
INFO:root:Train (Epoch 41): Loss/seq after 03400 batchs: 1247.44873046875
INFO:root:Train (Epoch 41): Loss/seq after 03450 batchs: 1240.137939453125
INFO:root:Train (Epoch 41): Loss/seq after 03500 batchs: 1237.8197021484375
INFO:root:Train (Epoch 41): Loss/seq after 03550 batchs: 1229.893310546875
INFO:root:Train (Epoch 41): Loss/seq after 03600 batchs: 1234.286865234375
INFO:root:Train (Epoch 41): Loss/seq after 03650 batchs: 1227.1798095703125
INFO:root:Train (Epoch 41): Loss/seq after 03700 batchs: 1225.495849609375
INFO:root:Train (Epoch 41): Loss/seq after 03750 batchs: 1225.1634521484375
INFO:root:Train (Epoch 41): Loss/seq after 03800 batchs: 1218.0360107421875
INFO:root:Train (Epoch 41): Loss/seq after 03850 batchs: 1213.2274169921875
INFO:root:Train (Epoch 41): Loss/seq after 03900 batchs: 1218.8895263671875
INFO:root:Train (Epoch 41): Loss/seq after 03950 batchs: 1226.7833251953125
INFO:root:Train (Epoch 41): Loss/seq after 04000 batchs: 1217.71240234375
INFO:root:Train (Epoch 41): Loss/seq after 04050 batchs: 1209.6773681640625
INFO:root:Train (Epoch 41): Loss/seq after 04100 batchs: 1203.2568359375
INFO:root:Train (Epoch 41): Loss/seq after 04150 batchs: 1197.34228515625
INFO:root:Train (Epoch 41): Loss/seq after 04200 batchs: 1191.5233154296875
INFO:root:Train (Epoch 41): Loss/seq after 04250 batchs: 1186.8116455078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 41): Loss/seq after 00000 batches: 897.9322509765625
INFO:root:# Valid (Epoch 41): Loss/seq after 00050 batches: 1112.2464599609375
INFO:root:# Valid (Epoch 41): Loss/seq after 00100 batches: 1405.95556640625
INFO:root:# Valid (Epoch 41): Loss/seq after 00150 batches: 1126.329345703125
INFO:root:# Valid (Epoch 41): Loss/seq after 00200 batches: 1014.2742919921875
INFO:root:Artifacts: Make stick videos for epoch 41
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_41_on_20220423_000051.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_41_index_480_on_20220423_000051.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 42): Loss/seq after 00000 batchs: 2443.0458984375
INFO:root:Train (Epoch 42): Loss/seq after 00050 batchs: 1549.9161376953125
INFO:root:Train (Epoch 42): Loss/seq after 00100 batchs: 1492.29345703125
INFO:root:Train (Epoch 42): Loss/seq after 00150 batchs: 1327.27001953125
INFO:root:Train (Epoch 42): Loss/seq after 00200 batchs: 1441.8172607421875
INFO:root:Train (Epoch 42): Loss/seq after 00250 batchs: 1556.3135986328125
INFO:root:Train (Epoch 42): Loss/seq after 00300 batchs: 1479.5225830078125
INFO:root:Train (Epoch 42): Loss/seq after 00350 batchs: 1379.25390625
INFO:root:Train (Epoch 42): Loss/seq after 00400 batchs: 1417.5841064453125
INFO:root:Train (Epoch 42): Loss/seq after 00450 batchs: 1356.985595703125
INFO:root:Train (Epoch 42): Loss/seq after 00500 batchs: 1361.8865966796875
INFO:root:Train (Epoch 42): Loss/seq after 00550 batchs: 1304.1710205078125
INFO:root:Train (Epoch 42): Loss/seq after 00600 batchs: 1268.1495361328125
INFO:root:Train (Epoch 42): Loss/seq after 00650 batchs: 1340.6309814453125
INFO:root:Train (Epoch 42): Loss/seq after 00700 batchs: 1435.244384765625
INFO:root:Train (Epoch 42): Loss/seq after 00750 batchs: 1475.000732421875
INFO:root:Train (Epoch 42): Loss/seq after 00800 batchs: 1452.4078369140625
INFO:root:Train (Epoch 42): Loss/seq after 00850 batchs: 1417.018798828125
INFO:root:Train (Epoch 42): Loss/seq after 00900 batchs: 1415.19580078125
INFO:root:Train (Epoch 42): Loss/seq after 00950 batchs: 1498.34765625
INFO:root:Train (Epoch 42): Loss/seq after 01000 batchs: 1496.099853515625
INFO:root:Train (Epoch 42): Loss/seq after 01050 batchs: 1464.7012939453125
INFO:root:Train (Epoch 42): Loss/seq after 01100 batchs: 1450.7393798828125
INFO:root:Train (Epoch 42): Loss/seq after 01150 batchs: 1428.6268310546875
INFO:root:Train (Epoch 42): Loss/seq after 01200 batchs: 1411.94873046875
INFO:root:Train (Epoch 42): Loss/seq after 01250 batchs: 1401.8714599609375
INFO:root:Train (Epoch 42): Loss/seq after 01300 batchs: 1418.4608154296875
INFO:root:Train (Epoch 42): Loss/seq after 01350 batchs: 1422.633056640625
INFO:root:Train (Epoch 42): Loss/seq after 01400 batchs: 1470.638916015625
INFO:root:Train (Epoch 42): Loss/seq after 01450 batchs: 1454.62744140625
INFO:root:Train (Epoch 42): Loss/seq after 01500 batchs: 1440.703857421875
INFO:root:Train (Epoch 42): Loss/seq after 01550 batchs: 1434.41748046875
INFO:root:Train (Epoch 42): Loss/seq after 01600 batchs: 1413.60205078125
INFO:root:Train (Epoch 42): Loss/seq after 01650 batchs: 1399.4788818359375
INFO:root:Train (Epoch 42): Loss/seq after 01700 batchs: 1386.334716796875
INFO:root:Train (Epoch 42): Loss/seq after 01750 batchs: 1371.9979248046875
INFO:root:Train (Epoch 42): Loss/seq after 01800 batchs: 1355.408203125
INFO:root:Train (Epoch 42): Loss/seq after 01850 batchs: 1339.1650390625
INFO:root:Train (Epoch 42): Loss/seq after 01900 batchs: 1332.9256591796875
INFO:root:Train (Epoch 42): Loss/seq after 01950 batchs: 1322.31591796875
INFO:root:Train (Epoch 42): Loss/seq after 02000 batchs: 1310.5577392578125
INFO:root:Train (Epoch 42): Loss/seq after 02050 batchs: 1299.8079833984375
INFO:root:Train (Epoch 42): Loss/seq after 02100 batchs: 1286.7257080078125
INFO:root:Train (Epoch 42): Loss/seq after 02150 batchs: 1274.5203857421875
INFO:root:Train (Epoch 42): Loss/seq after 02200 batchs: 1261.871337890625
INFO:root:Train (Epoch 42): Loss/seq after 02250 batchs: 1259.0955810546875
INFO:root:Train (Epoch 42): Loss/seq after 02300 batchs: 1260.2781982421875
INFO:root:Train (Epoch 42): Loss/seq after 02350 batchs: 1248.01416015625
INFO:root:Train (Epoch 42): Loss/seq after 02400 batchs: 1242.127685546875
INFO:root:Train (Epoch 42): Loss/seq after 02450 batchs: 1228.154296875
INFO:root:Train (Epoch 42): Loss/seq after 02500 batchs: 1210.7490234375
INFO:root:Train (Epoch 42): Loss/seq after 02550 batchs: 1198.591064453125
INFO:root:Train (Epoch 42): Loss/seq after 02600 batchs: 1195.55810546875
INFO:root:Train (Epoch 42): Loss/seq after 02650 batchs: 1190.34375
INFO:root:Train (Epoch 42): Loss/seq after 02700 batchs: 1185.55078125
INFO:root:Train (Epoch 42): Loss/seq after 02750 batchs: 1214.6568603515625
INFO:root:Train (Epoch 42): Loss/seq after 02800 batchs: 1219.7906494140625
INFO:root:Train (Epoch 42): Loss/seq after 02850 batchs: 1214.804443359375
INFO:root:Train (Epoch 42): Loss/seq after 02900 batchs: 1211.43896484375
INFO:root:Train (Epoch 42): Loss/seq after 02950 batchs: 1203.0853271484375
INFO:root:Train (Epoch 42): Loss/seq after 03000 batchs: 1200.9918212890625
INFO:root:Train (Epoch 42): Loss/seq after 03050 batchs: 1203.088623046875
INFO:root:Train (Epoch 42): Loss/seq after 03100 batchs: 1213.89697265625
INFO:root:Train (Epoch 42): Loss/seq after 03150 batchs: 1230.380859375
INFO:root:Train (Epoch 42): Loss/seq after 03200 batchs: 1244.625244140625
INFO:root:Train (Epoch 42): Loss/seq after 03250 batchs: 1258.335205078125
INFO:root:Train (Epoch 42): Loss/seq after 03300 batchs: 1255.257568359375
INFO:root:Train (Epoch 42): Loss/seq after 03350 batchs: 1253.5997314453125
INFO:root:Train (Epoch 42): Loss/seq after 03400 batchs: 1244.530029296875
INFO:root:Train (Epoch 42): Loss/seq after 03450 batchs: 1236.7618408203125
INFO:root:Train (Epoch 42): Loss/seq after 03500 batchs: 1234.14306640625
INFO:root:Train (Epoch 42): Loss/seq after 03550 batchs: 1225.7880859375
INFO:root:Train (Epoch 42): Loss/seq after 03600 batchs: 1229.907958984375
INFO:root:Train (Epoch 42): Loss/seq after 03650 batchs: 1222.668212890625
INFO:root:Train (Epoch 42): Loss/seq after 03700 batchs: 1221.1324462890625
INFO:root:Train (Epoch 42): Loss/seq after 03750 batchs: 1220.856689453125
INFO:root:Train (Epoch 42): Loss/seq after 03800 batchs: 1213.815185546875
INFO:root:Train (Epoch 42): Loss/seq after 03850 batchs: 1209.10791015625
INFO:root:Train (Epoch 42): Loss/seq after 03900 batchs: 1214.8531494140625
INFO:root:Train (Epoch 42): Loss/seq after 03950 batchs: 1222.3616943359375
INFO:root:Train (Epoch 42): Loss/seq after 04000 batchs: 1213.35107421875
INFO:root:Train (Epoch 42): Loss/seq after 04050 batchs: 1205.3358154296875
INFO:root:Train (Epoch 42): Loss/seq after 04100 batchs: 1198.73779296875
INFO:root:Train (Epoch 42): Loss/seq after 04150 batchs: 1192.7606201171875
INFO:root:Train (Epoch 42): Loss/seq after 04200 batchs: 1186.670166015625
INFO:root:Train (Epoch 42): Loss/seq after 04250 batchs: 1181.9324951171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 42): Loss/seq after 00000 batches: 871.1254272460938
INFO:root:# Valid (Epoch 42): Loss/seq after 00050 batches: 1092.7376708984375
INFO:root:# Valid (Epoch 42): Loss/seq after 00100 batches: 1380.1256103515625
INFO:root:# Valid (Epoch 42): Loss/seq after 00150 batches: 1099.015380859375
INFO:root:# Valid (Epoch 42): Loss/seq after 00200 batches: 989.3075561523438
INFO:root:Artifacts: Make stick videos for epoch 42
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_42_on_20220423_000547.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_42_index_357_on_20220423_000547.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 43): Loss/seq after 00000 batchs: 2421.822265625
INFO:root:Train (Epoch 43): Loss/seq after 00050 batchs: 1541.461181640625
INFO:root:Train (Epoch 43): Loss/seq after 00100 batchs: 1478.241455078125
INFO:root:Train (Epoch 43): Loss/seq after 00150 batchs: 1306.8707275390625
INFO:root:Train (Epoch 43): Loss/seq after 00200 batchs: 1421.87158203125
INFO:root:Train (Epoch 43): Loss/seq after 00250 batchs: 1535.2802734375
INFO:root:Train (Epoch 43): Loss/seq after 00300 batchs: 1461.1077880859375
INFO:root:Train (Epoch 43): Loss/seq after 00350 batchs: 1369.8016357421875
INFO:root:Train (Epoch 43): Loss/seq after 00400 batchs: 1406.3135986328125
INFO:root:Train (Epoch 43): Loss/seq after 00450 batchs: 1347.5904541015625
INFO:root:Train (Epoch 43): Loss/seq after 00500 batchs: 1353.772705078125
INFO:root:Train (Epoch 43): Loss/seq after 00550 batchs: 1297.041259765625
INFO:root:Train (Epoch 43): Loss/seq after 00600 batchs: 1262.6263427734375
INFO:root:Train (Epoch 43): Loss/seq after 00650 batchs: 1334.5164794921875
INFO:root:Train (Epoch 43): Loss/seq after 00700 batchs: 1428.86328125
INFO:root:Train (Epoch 43): Loss/seq after 00750 batchs: 1466.9212646484375
INFO:root:Train (Epoch 43): Loss/seq after 00800 batchs: 1448.5413818359375
INFO:root:Train (Epoch 43): Loss/seq after 00850 batchs: 1412.6275634765625
INFO:root:Train (Epoch 43): Loss/seq after 00900 batchs: 1410.85302734375
INFO:root:Train (Epoch 43): Loss/seq after 00950 batchs: 1492.987548828125
INFO:root:Train (Epoch 43): Loss/seq after 01000 batchs: 1491.1944580078125
INFO:root:Train (Epoch 43): Loss/seq after 01050 batchs: 1459.44091796875
INFO:root:Train (Epoch 43): Loss/seq after 01100 batchs: 1446.0545654296875
INFO:root:Train (Epoch 43): Loss/seq after 01150 batchs: 1424.0491943359375
INFO:root:Train (Epoch 43): Loss/seq after 01200 batchs: 1407.947265625
INFO:root:Train (Epoch 43): Loss/seq after 01250 batchs: 1397.2154541015625
INFO:root:Train (Epoch 43): Loss/seq after 01300 batchs: 1413.6322021484375
INFO:root:Train (Epoch 43): Loss/seq after 01350 batchs: 1417.907958984375
INFO:root:Train (Epoch 43): Loss/seq after 01400 batchs: 1466.15283203125
INFO:root:Train (Epoch 43): Loss/seq after 01450 batchs: 1450.139892578125
INFO:root:Train (Epoch 43): Loss/seq after 01500 batchs: 1436.261474609375
INFO:root:Train (Epoch 43): Loss/seq after 01550 batchs: 1429.2784423828125
INFO:root:Train (Epoch 43): Loss/seq after 01600 batchs: 1408.5849609375
INFO:root:Train (Epoch 43): Loss/seq after 01650 batchs: 1393.100830078125
INFO:root:Train (Epoch 43): Loss/seq after 01700 batchs: 1379.992431640625
INFO:root:Train (Epoch 43): Loss/seq after 01750 batchs: 1365.718505859375
INFO:root:Train (Epoch 43): Loss/seq after 01800 batchs: 1349.282470703125
INFO:root:Train (Epoch 43): Loss/seq after 01850 batchs: 1332.956787109375
INFO:root:Train (Epoch 43): Loss/seq after 01900 batchs: 1326.8258056640625
INFO:root:Train (Epoch 43): Loss/seq after 01950 batchs: 1316.628173828125
INFO:root:Train (Epoch 43): Loss/seq after 02000 batchs: 1305.2899169921875
INFO:root:Train (Epoch 43): Loss/seq after 02050 batchs: 1294.74658203125
INFO:root:Train (Epoch 43): Loss/seq after 02100 batchs: 1281.6968994140625
INFO:root:Train (Epoch 43): Loss/seq after 02150 batchs: 1269.5264892578125
INFO:root:Train (Epoch 43): Loss/seq after 02200 batchs: 1256.99169921875
INFO:root:Train (Epoch 43): Loss/seq after 02250 batchs: 1254.211669921875
INFO:root:Train (Epoch 43): Loss/seq after 02300 batchs: 1256.200927734375
INFO:root:Train (Epoch 43): Loss/seq after 02350 batchs: 1245.5809326171875
INFO:root:Train (Epoch 43): Loss/seq after 02400 batchs: 1240.49365234375
INFO:root:Train (Epoch 43): Loss/seq after 02450 batchs: 1226.8912353515625
INFO:root:Train (Epoch 43): Loss/seq after 02500 batchs: 1209.4942626953125
INFO:root:Train (Epoch 43): Loss/seq after 02550 batchs: 1197.308349609375
INFO:root:Train (Epoch 43): Loss/seq after 02600 batchs: 1194.2742919921875
INFO:root:Train (Epoch 43): Loss/seq after 02650 batchs: 1189.0338134765625
INFO:root:Train (Epoch 43): Loss/seq after 02700 batchs: 1184.3668212890625
INFO:root:Train (Epoch 43): Loss/seq after 02750 batchs: 1213.1944580078125
INFO:root:Train (Epoch 43): Loss/seq after 02800 batchs: 1218.2239990234375
INFO:root:Train (Epoch 43): Loss/seq after 02850 batchs: 1213.0916748046875
INFO:root:Train (Epoch 43): Loss/seq after 02900 batchs: 1210.387939453125
INFO:root:Train (Epoch 43): Loss/seq after 02950 batchs: 1201.940185546875
INFO:root:Train (Epoch 43): Loss/seq after 03000 batchs: 1199.8597412109375
INFO:root:Train (Epoch 43): Loss/seq after 03050 batchs: 1201.9569091796875
INFO:root:Train (Epoch 43): Loss/seq after 03100 batchs: 1212.2738037109375
INFO:root:Train (Epoch 43): Loss/seq after 03150 batchs: 1229.0245361328125
INFO:root:Train (Epoch 43): Loss/seq after 03200 batchs: 1243.35205078125
INFO:root:Train (Epoch 43): Loss/seq after 03250 batchs: 1257.2845458984375
INFO:root:Train (Epoch 43): Loss/seq after 03300 batchs: 1255.432861328125
INFO:root:Train (Epoch 43): Loss/seq after 03350 batchs: 1254.635986328125
INFO:root:Train (Epoch 43): Loss/seq after 03400 batchs: 1245.9083251953125
INFO:root:Train (Epoch 43): Loss/seq after 03450 batchs: 1238.76806640625
INFO:root:Train (Epoch 43): Loss/seq after 03500 batchs: 1236.6429443359375
INFO:root:Train (Epoch 43): Loss/seq after 03550 batchs: 1228.8138427734375
INFO:root:Train (Epoch 43): Loss/seq after 03600 batchs: 1233.1636962890625
INFO:root:Train (Epoch 43): Loss/seq after 03650 batchs: 1225.767822265625
INFO:root:Train (Epoch 43): Loss/seq after 03700 batchs: 1223.9906005859375
INFO:root:Train (Epoch 43): Loss/seq after 03750 batchs: 1223.7362060546875
INFO:root:Train (Epoch 43): Loss/seq after 03800 batchs: 1216.603271484375
INFO:root:Train (Epoch 43): Loss/seq after 03850 batchs: 1211.7501220703125
INFO:root:Train (Epoch 43): Loss/seq after 03900 batchs: 1217.50390625
INFO:root:Train (Epoch 43): Loss/seq after 03950 batchs: 1224.84130859375
INFO:root:Train (Epoch 43): Loss/seq after 04000 batchs: 1215.7899169921875
INFO:root:Train (Epoch 43): Loss/seq after 04050 batchs: 1207.729248046875
INFO:root:Train (Epoch 43): Loss/seq after 04100 batchs: 1201.307373046875
INFO:root:Train (Epoch 43): Loss/seq after 04150 batchs: 1195.6134033203125
INFO:root:Train (Epoch 43): Loss/seq after 04200 batchs: 1189.45361328125
INFO:root:Train (Epoch 43): Loss/seq after 04250 batchs: 1184.741943359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 43): Loss/seq after 00000 batches: 887.2510986328125
INFO:root:# Valid (Epoch 43): Loss/seq after 00050 batches: 1097.141845703125
INFO:root:# Valid (Epoch 43): Loss/seq after 00100 batches: 1387.225830078125
INFO:root:# Valid (Epoch 43): Loss/seq after 00150 batches: 1108.53125
INFO:root:# Valid (Epoch 43): Loss/seq after 00200 batches: 997.5867919921875
INFO:root:Artifacts: Make stick videos for epoch 43
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_43_on_20220423_001058.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_43_index_1870_on_20220423_001058.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 44): Loss/seq after 00000 batchs: 2429.685546875
INFO:root:Train (Epoch 44): Loss/seq after 00050 batchs: 1548.119873046875
INFO:root:Train (Epoch 44): Loss/seq after 00100 batchs: 1485.1085205078125
INFO:root:Train (Epoch 44): Loss/seq after 00150 batchs: 1317.45703125
INFO:root:Train (Epoch 44): Loss/seq after 00200 batchs: 1430.9886474609375
INFO:root:Train (Epoch 44): Loss/seq after 00250 batchs: 1545.6888427734375
INFO:root:Train (Epoch 44): Loss/seq after 00300 batchs: 1470.6375732421875
INFO:root:Train (Epoch 44): Loss/seq after 00350 batchs: 1375.3504638671875
INFO:root:Train (Epoch 44): Loss/seq after 00400 batchs: 1413.66748046875
INFO:root:Train (Epoch 44): Loss/seq after 00450 batchs: 1354.8392333984375
INFO:root:Train (Epoch 44): Loss/seq after 00500 batchs: 1367.6011962890625
INFO:root:Train (Epoch 44): Loss/seq after 00550 batchs: 1312.0062255859375
INFO:root:Train (Epoch 44): Loss/seq after 00600 batchs: 1278.019775390625
INFO:root:Train (Epoch 44): Loss/seq after 00650 batchs: 1349.221923828125
INFO:root:Train (Epoch 44): Loss/seq after 00700 batchs: 1442.572265625
INFO:root:Train (Epoch 44): Loss/seq after 00750 batchs: 1481.3682861328125
INFO:root:Train (Epoch 44): Loss/seq after 00800 batchs: 1461.66162109375
INFO:root:Train (Epoch 44): Loss/seq after 00850 batchs: 1426.5552978515625
INFO:root:Train (Epoch 44): Loss/seq after 00900 batchs: 1425.7059326171875
INFO:root:Train (Epoch 44): Loss/seq after 00950 batchs: 1508.4896240234375
INFO:root:Train (Epoch 44): Loss/seq after 01000 batchs: 1507.84814453125
INFO:root:Train (Epoch 44): Loss/seq after 01050 batchs: 1477.1778564453125
INFO:root:Train (Epoch 44): Loss/seq after 01100 batchs: 1463.8087158203125
INFO:root:Train (Epoch 44): Loss/seq after 01150 batchs: 1441.4925537109375
INFO:root:Train (Epoch 44): Loss/seq after 01200 batchs: 1424.3095703125
INFO:root:Train (Epoch 44): Loss/seq after 01250 batchs: 1414.2982177734375
INFO:root:Train (Epoch 44): Loss/seq after 01300 batchs: 1429.97607421875
INFO:root:Train (Epoch 44): Loss/seq after 01350 batchs: 1433.6500244140625
INFO:root:Train (Epoch 44): Loss/seq after 01400 batchs: 1481.1126708984375
INFO:root:Train (Epoch 44): Loss/seq after 01450 batchs: 1464.962890625
INFO:root:Train (Epoch 44): Loss/seq after 01500 batchs: 1450.6016845703125
INFO:root:Train (Epoch 44): Loss/seq after 01550 batchs: 1442.572509765625
INFO:root:Train (Epoch 44): Loss/seq after 01600 batchs: 1421.0628662109375
INFO:root:Train (Epoch 44): Loss/seq after 01650 batchs: 1404.2867431640625
INFO:root:Train (Epoch 44): Loss/seq after 01700 batchs: 1390.7711181640625
INFO:root:Train (Epoch 44): Loss/seq after 01750 batchs: 1376.0216064453125
INFO:root:Train (Epoch 44): Loss/seq after 01800 batchs: 1359.25244140625
INFO:root:Train (Epoch 44): Loss/seq after 01850 batchs: 1342.4814453125
INFO:root:Train (Epoch 44): Loss/seq after 01900 batchs: 1335.4527587890625
INFO:root:Train (Epoch 44): Loss/seq after 01950 batchs: 1325.3486328125
INFO:root:Train (Epoch 44): Loss/seq after 02000 batchs: 1313.5372314453125
INFO:root:Train (Epoch 44): Loss/seq after 02050 batchs: 1302.6046142578125
INFO:root:Train (Epoch 44): Loss/seq after 02100 batchs: 1289.3665771484375
INFO:root:Train (Epoch 44): Loss/seq after 02150 batchs: 1276.9219970703125
INFO:root:Train (Epoch 44): Loss/seq after 02200 batchs: 1264.16748046875
INFO:root:Train (Epoch 44): Loss/seq after 02250 batchs: 1261.3126220703125
INFO:root:Train (Epoch 44): Loss/seq after 02300 batchs: 1263.157470703125
INFO:root:Train (Epoch 44): Loss/seq after 02350 batchs: 1251.912353515625
INFO:root:Train (Epoch 44): Loss/seq after 02400 batchs: 1246.819580078125
INFO:root:Train (Epoch 44): Loss/seq after 02450 batchs: 1233.073486328125
INFO:root:Train (Epoch 44): Loss/seq after 02500 batchs: 1215.6376953125
INFO:root:Train (Epoch 44): Loss/seq after 02550 batchs: 1203.4713134765625
INFO:root:Train (Epoch 44): Loss/seq after 02600 batchs: 1200.303955078125
INFO:root:Train (Epoch 44): Loss/seq after 02650 batchs: 1194.9521484375
INFO:root:Train (Epoch 44): Loss/seq after 02700 batchs: 1190.199462890625
INFO:root:Train (Epoch 44): Loss/seq after 02750 batchs: 1219.6746826171875
INFO:root:Train (Epoch 44): Loss/seq after 02800 batchs: 1225.18994140625
INFO:root:Train (Epoch 44): Loss/seq after 02850 batchs: 1220.062744140625
INFO:root:Train (Epoch 44): Loss/seq after 02900 batchs: 1216.7496337890625
INFO:root:Train (Epoch 44): Loss/seq after 02950 batchs: 1208.9515380859375
INFO:root:Train (Epoch 44): Loss/seq after 03000 batchs: 1206.8204345703125
INFO:root:Train (Epoch 44): Loss/seq after 03050 batchs: 1209.029052734375
INFO:root:Train (Epoch 44): Loss/seq after 03100 batchs: 1220.21728515625
INFO:root:Train (Epoch 44): Loss/seq after 03150 batchs: 1235.8360595703125
INFO:root:Train (Epoch 44): Loss/seq after 03200 batchs: 1250.0787353515625
INFO:root:Train (Epoch 44): Loss/seq after 03250 batchs: 1263.5281982421875
INFO:root:Train (Epoch 44): Loss/seq after 03300 batchs: 1261.48291015625
INFO:root:Train (Epoch 44): Loss/seq after 03350 batchs: 1260.9298095703125
INFO:root:Train (Epoch 44): Loss/seq after 03400 batchs: 1251.7471923828125
INFO:root:Train (Epoch 44): Loss/seq after 03450 batchs: 1243.828369140625
INFO:root:Train (Epoch 44): Loss/seq after 03500 batchs: 1241.5401611328125
INFO:root:Train (Epoch 44): Loss/seq after 03550 batchs: 1233.6385498046875
INFO:root:Train (Epoch 44): Loss/seq after 03600 batchs: 1238.1593017578125
INFO:root:Train (Epoch 44): Loss/seq after 03650 batchs: 1231.259765625
INFO:root:Train (Epoch 44): Loss/seq after 03700 batchs: 1229.9539794921875
INFO:root:Train (Epoch 44): Loss/seq after 03750 batchs: 1229.6260986328125
INFO:root:Train (Epoch 44): Loss/seq after 03800 batchs: 1222.4476318359375
INFO:root:Train (Epoch 44): Loss/seq after 03850 batchs: 1217.608154296875
INFO:root:Train (Epoch 44): Loss/seq after 03900 batchs: 1223.010009765625
INFO:root:Train (Epoch 44): Loss/seq after 03950 batchs: 1230.7076416015625
INFO:root:Train (Epoch 44): Loss/seq after 04000 batchs: 1221.577880859375
INFO:root:Train (Epoch 44): Loss/seq after 04050 batchs: 1213.417236328125
INFO:root:Train (Epoch 44): Loss/seq after 04100 batchs: 1206.827880859375
INFO:root:Train (Epoch 44): Loss/seq after 04150 batchs: 1200.7392578125
INFO:root:Train (Epoch 44): Loss/seq after 04200 batchs: 1194.33740234375
INFO:root:Train (Epoch 44): Loss/seq after 04250 batchs: 1189.53662109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 44): Loss/seq after 00000 batches: 886.5609130859375
INFO:root:# Valid (Epoch 44): Loss/seq after 00050 batches: 1091.5074462890625
INFO:root:# Valid (Epoch 44): Loss/seq after 00100 batches: 1389.0469970703125
INFO:root:# Valid (Epoch 44): Loss/seq after 00150 batches: 1103.0753173828125
INFO:root:# Valid (Epoch 44): Loss/seq after 00200 batches: 992.15625
INFO:root:Artifacts: Make stick videos for epoch 44
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_44_on_20220423_001542.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_44_index_257_on_20220423_001542.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 45): Loss/seq after 00000 batchs: 2384.54541015625
INFO:root:Train (Epoch 45): Loss/seq after 00050 batchs: 1582.442626953125
INFO:root:Train (Epoch 45): Loss/seq after 00100 batchs: 1501.1842041015625
INFO:root:Train (Epoch 45): Loss/seq after 00150 batchs: 1325.462646484375
INFO:root:Train (Epoch 45): Loss/seq after 00200 batchs: 1439.82177734375
INFO:root:Train (Epoch 45): Loss/seq after 00250 batchs: 1550.6715087890625
INFO:root:Train (Epoch 45): Loss/seq after 00300 batchs: 1474.3182373046875
INFO:root:Train (Epoch 45): Loss/seq after 00350 batchs: 1373.9742431640625
INFO:root:Train (Epoch 45): Loss/seq after 00400 batchs: 1412.3922119140625
INFO:root:Train (Epoch 45): Loss/seq after 00450 batchs: 1352.0177001953125
INFO:root:Train (Epoch 45): Loss/seq after 00500 batchs: 1350.837646484375
INFO:root:Train (Epoch 45): Loss/seq after 00550 batchs: 1294.3240966796875
INFO:root:Train (Epoch 45): Loss/seq after 00600 batchs: 1259.10302734375
INFO:root:Train (Epoch 45): Loss/seq after 00650 batchs: 1332.24267578125
INFO:root:Train (Epoch 45): Loss/seq after 00700 batchs: 1427.218994140625
INFO:root:Train (Epoch 45): Loss/seq after 00750 batchs: 1466.4132080078125
INFO:root:Train (Epoch 45): Loss/seq after 00800 batchs: 1443.6927490234375
INFO:root:Train (Epoch 45): Loss/seq after 00850 batchs: 1406.9613037109375
INFO:root:Train (Epoch 45): Loss/seq after 00900 batchs: 1404.6817626953125
INFO:root:Train (Epoch 45): Loss/seq after 00950 batchs: 1487.344482421875
INFO:root:Train (Epoch 45): Loss/seq after 01000 batchs: 1484.0841064453125
INFO:root:Train (Epoch 45): Loss/seq after 01050 batchs: 1454.43115234375
INFO:root:Train (Epoch 45): Loss/seq after 01100 batchs: 1443.6712646484375
INFO:root:Train (Epoch 45): Loss/seq after 01150 batchs: 1421.872802734375
INFO:root:Train (Epoch 45): Loss/seq after 01200 batchs: 1405.3232421875
INFO:root:Train (Epoch 45): Loss/seq after 01250 batchs: 1395.3504638671875
INFO:root:Train (Epoch 45): Loss/seq after 01300 batchs: 1411.7822265625
INFO:root:Train (Epoch 45): Loss/seq after 01350 batchs: 1416.0706787109375
INFO:root:Train (Epoch 45): Loss/seq after 01400 batchs: 1463.239990234375
INFO:root:Train (Epoch 45): Loss/seq after 01450 batchs: 1446.890625
INFO:root:Train (Epoch 45): Loss/seq after 01500 batchs: 1433.0198974609375
INFO:root:Train (Epoch 45): Loss/seq after 01550 batchs: 1425.4378662109375
INFO:root:Train (Epoch 45): Loss/seq after 01600 batchs: 1404.482421875
INFO:root:Train (Epoch 45): Loss/seq after 01650 batchs: 1389.3360595703125
INFO:root:Train (Epoch 45): Loss/seq after 01700 batchs: 1376.3388671875
INFO:root:Train (Epoch 45): Loss/seq after 01750 batchs: 1361.96435546875
INFO:root:Train (Epoch 45): Loss/seq after 01800 batchs: 1345.503173828125
INFO:root:Train (Epoch 45): Loss/seq after 01850 batchs: 1329.0947265625
INFO:root:Train (Epoch 45): Loss/seq after 01900 batchs: 1322.5628662109375
INFO:root:Train (Epoch 45): Loss/seq after 01950 batchs: 1312.239501953125
INFO:root:Train (Epoch 45): Loss/seq after 02000 batchs: 1300.9344482421875
INFO:root:Train (Epoch 45): Loss/seq after 02050 batchs: 1290.41162109375
INFO:root:Train (Epoch 45): Loss/seq after 02100 batchs: 1277.3641357421875
INFO:root:Train (Epoch 45): Loss/seq after 02150 batchs: 1265.1500244140625
INFO:root:Train (Epoch 45): Loss/seq after 02200 batchs: 1252.5965576171875
INFO:root:Train (Epoch 45): Loss/seq after 02250 batchs: 1249.0401611328125
INFO:root:Train (Epoch 45): Loss/seq after 02300 batchs: 1250.11962890625
INFO:root:Train (Epoch 45): Loss/seq after 02350 batchs: 1238.56884765625
INFO:root:Train (Epoch 45): Loss/seq after 02400 batchs: 1232.9984130859375
INFO:root:Train (Epoch 45): Loss/seq after 02450 batchs: 1219.2686767578125
INFO:root:Train (Epoch 45): Loss/seq after 02500 batchs: 1202.0118408203125
INFO:root:Train (Epoch 45): Loss/seq after 02550 batchs: 1189.591796875
INFO:root:Train (Epoch 45): Loss/seq after 02600 batchs: 1186.2572021484375
INFO:root:Train (Epoch 45): Loss/seq after 02650 batchs: 1181.036865234375
INFO:root:Train (Epoch 45): Loss/seq after 02700 batchs: 1176.3702392578125
INFO:root:Train (Epoch 45): Loss/seq after 02750 batchs: 1205.205078125
INFO:root:Train (Epoch 45): Loss/seq after 02800 batchs: 1210.1307373046875
INFO:root:Train (Epoch 45): Loss/seq after 02850 batchs: 1205.1622314453125
INFO:root:Train (Epoch 45): Loss/seq after 02900 batchs: 1202.6309814453125
INFO:root:Train (Epoch 45): Loss/seq after 02950 batchs: 1194.9498291015625
INFO:root:Train (Epoch 45): Loss/seq after 03000 batchs: 1192.9979248046875
INFO:root:Train (Epoch 45): Loss/seq after 03050 batchs: 1195.4112548828125
INFO:root:Train (Epoch 45): Loss/seq after 03100 batchs: 1205.4107666015625
INFO:root:Train (Epoch 45): Loss/seq after 03150 batchs: 1221.2547607421875
INFO:root:Train (Epoch 45): Loss/seq after 03200 batchs: 1236.3514404296875
INFO:root:Train (Epoch 45): Loss/seq after 03250 batchs: 1250.4442138671875
INFO:root:Train (Epoch 45): Loss/seq after 03300 batchs: 1247.3118896484375
INFO:root:Train (Epoch 45): Loss/seq after 03350 batchs: 1245.70703125
INFO:root:Train (Epoch 45): Loss/seq after 03400 batchs: 1236.7041015625
INFO:root:Train (Epoch 45): Loss/seq after 03450 batchs: 1228.7520751953125
INFO:root:Train (Epoch 45): Loss/seq after 03500 batchs: 1226.1781005859375
INFO:root:Train (Epoch 45): Loss/seq after 03550 batchs: 1218.174072265625
INFO:root:Train (Epoch 45): Loss/seq after 03600 batchs: 1222.765625
INFO:root:Train (Epoch 45): Loss/seq after 03650 batchs: 1215.958984375
INFO:root:Train (Epoch 45): Loss/seq after 03700 batchs: 1214.95068359375
INFO:root:Train (Epoch 45): Loss/seq after 03750 batchs: 1214.8359375
INFO:root:Train (Epoch 45): Loss/seq after 03800 batchs: 1207.740234375
INFO:root:Train (Epoch 45): Loss/seq after 03850 batchs: 1202.999755859375
INFO:root:Train (Epoch 45): Loss/seq after 03900 batchs: 1208.8726806640625
INFO:root:Train (Epoch 45): Loss/seq after 03950 batchs: 1216.5733642578125
INFO:root:Train (Epoch 45): Loss/seq after 04000 batchs: 1207.62255859375
INFO:root:Train (Epoch 45): Loss/seq after 04050 batchs: 1199.651611328125
INFO:root:Train (Epoch 45): Loss/seq after 04100 batchs: 1193.3577880859375
INFO:root:Train (Epoch 45): Loss/seq after 04150 batchs: 1187.638916015625
INFO:root:Train (Epoch 45): Loss/seq after 04200 batchs: 1181.62109375
INFO:root:Train (Epoch 45): Loss/seq after 04250 batchs: 1176.970703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 45): Loss/seq after 00000 batches: 867.5946655273438
INFO:root:# Valid (Epoch 45): Loss/seq after 00050 batches: 1089.9716796875
INFO:root:# Valid (Epoch 45): Loss/seq after 00100 batches: 1372.564208984375
INFO:root:# Valid (Epoch 45): Loss/seq after 00150 batches: 1101.0230712890625
INFO:root:# Valid (Epoch 45): Loss/seq after 00200 batches: 994.5803833007812
INFO:root:Artifacts: Make stick videos for epoch 45
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_45_on_20220423_002031.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_45_index_179_on_20220423_002031.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 46): Loss/seq after 00000 batchs: 2429.95556640625
INFO:root:Train (Epoch 46): Loss/seq after 00050 batchs: 1538.3382568359375
INFO:root:Train (Epoch 46): Loss/seq after 00100 batchs: 1449.4947509765625
INFO:root:Train (Epoch 46): Loss/seq after 00150 batchs: 1286.6185302734375
INFO:root:Train (Epoch 46): Loss/seq after 00200 batchs: 1411.502197265625
INFO:root:Train (Epoch 46): Loss/seq after 00250 batchs: 1531.8541259765625
INFO:root:Train (Epoch 46): Loss/seq after 00300 batchs: 1457.9617919921875
INFO:root:Train (Epoch 46): Loss/seq after 00350 batchs: 1360.864990234375
INFO:root:Train (Epoch 46): Loss/seq after 00400 batchs: 1399.9202880859375
INFO:root:Train (Epoch 46): Loss/seq after 00450 batchs: 1341.1826171875
INFO:root:Train (Epoch 46): Loss/seq after 00500 batchs: 1338.091552734375
INFO:root:Train (Epoch 46): Loss/seq after 00550 batchs: 1282.4874267578125
INFO:root:Train (Epoch 46): Loss/seq after 00600 batchs: 1248.3607177734375
INFO:root:Train (Epoch 46): Loss/seq after 00650 batchs: 1321.5179443359375
INFO:root:Train (Epoch 46): Loss/seq after 00700 batchs: 1416.401123046875
INFO:root:Train (Epoch 46): Loss/seq after 00750 batchs: 1455.2569580078125
INFO:root:Train (Epoch 46): Loss/seq after 00800 batchs: 1432.918212890625
INFO:root:Train (Epoch 46): Loss/seq after 00850 batchs: 1396.912109375
INFO:root:Train (Epoch 46): Loss/seq after 00900 batchs: 1394.3502197265625
INFO:root:Train (Epoch 46): Loss/seq after 00950 batchs: 1477.964599609375
INFO:root:Train (Epoch 46): Loss/seq after 01000 batchs: 1474.66259765625
INFO:root:Train (Epoch 46): Loss/seq after 01050 batchs: 1447.9337158203125
INFO:root:Train (Epoch 46): Loss/seq after 01100 batchs: 1434.4005126953125
INFO:root:Train (Epoch 46): Loss/seq after 01150 batchs: 1412.62548828125
INFO:root:Train (Epoch 46): Loss/seq after 01200 batchs: 1396.296142578125
INFO:root:Train (Epoch 46): Loss/seq after 01250 batchs: 1386.17041015625
INFO:root:Train (Epoch 46): Loss/seq after 01300 batchs: 1402.89404296875
INFO:root:Train (Epoch 46): Loss/seq after 01350 batchs: 1407.5224609375
INFO:root:Train (Epoch 46): Loss/seq after 01400 batchs: 1454.4278564453125
INFO:root:Train (Epoch 46): Loss/seq after 01450 batchs: 1438.8355712890625
INFO:root:Train (Epoch 46): Loss/seq after 01500 batchs: 1425.3804931640625
INFO:root:Train (Epoch 46): Loss/seq after 01550 batchs: 1418.5780029296875
INFO:root:Train (Epoch 46): Loss/seq after 01600 batchs: 1397.973388671875
INFO:root:Train (Epoch 46): Loss/seq after 01650 batchs: 1381.8060302734375
INFO:root:Train (Epoch 46): Loss/seq after 01700 batchs: 1369.0220947265625
INFO:root:Train (Epoch 46): Loss/seq after 01750 batchs: 1354.9295654296875
INFO:root:Train (Epoch 46): Loss/seq after 01800 batchs: 1338.5955810546875
INFO:root:Train (Epoch 46): Loss/seq after 01850 batchs: 1322.31103515625
INFO:root:Train (Epoch 46): Loss/seq after 01900 batchs: 1316.0975341796875
INFO:root:Train (Epoch 46): Loss/seq after 01950 batchs: 1306.0316162109375
INFO:root:Train (Epoch 46): Loss/seq after 02000 batchs: 1294.693359375
INFO:root:Train (Epoch 46): Loss/seq after 02050 batchs: 1284.0255126953125
INFO:root:Train (Epoch 46): Loss/seq after 02100 batchs: 1271.1241455078125
INFO:root:Train (Epoch 46): Loss/seq after 02150 batchs: 1259.0516357421875
INFO:root:Train (Epoch 46): Loss/seq after 02200 batchs: 1246.7529296875
INFO:root:Train (Epoch 46): Loss/seq after 02250 batchs: 1243.24853515625
INFO:root:Train (Epoch 46): Loss/seq after 02300 batchs: 1244.600341796875
INFO:root:Train (Epoch 46): Loss/seq after 02350 batchs: 1232.475830078125
INFO:root:Train (Epoch 46): Loss/seq after 02400 batchs: 1226.8778076171875
INFO:root:Train (Epoch 46): Loss/seq after 02450 batchs: 1213.222412109375
INFO:root:Train (Epoch 46): Loss/seq after 02500 batchs: 1196.0780029296875
INFO:root:Train (Epoch 46): Loss/seq after 02550 batchs: 1183.7528076171875
INFO:root:Train (Epoch 46): Loss/seq after 02600 batchs: 1180.8170166015625
INFO:root:Train (Epoch 46): Loss/seq after 02650 batchs: 1175.666015625
INFO:root:Train (Epoch 46): Loss/seq after 02700 batchs: 1171.1705322265625
INFO:root:Train (Epoch 46): Loss/seq after 02750 batchs: 1199.9263916015625
INFO:root:Train (Epoch 46): Loss/seq after 02800 batchs: 1205.469970703125
INFO:root:Train (Epoch 46): Loss/seq after 02850 batchs: 1200.3260498046875
INFO:root:Train (Epoch 46): Loss/seq after 02900 batchs: 1197.463134765625
INFO:root:Train (Epoch 46): Loss/seq after 02950 batchs: 1189.5355224609375
INFO:root:Train (Epoch 46): Loss/seq after 03000 batchs: 1187.6444091796875
INFO:root:Train (Epoch 46): Loss/seq after 03050 batchs: 1189.9962158203125
INFO:root:Train (Epoch 46): Loss/seq after 03100 batchs: 1200.8365478515625
INFO:root:Train (Epoch 46): Loss/seq after 03150 batchs: 1220.924072265625
INFO:root:Train (Epoch 46): Loss/seq after 03200 batchs: 1235.2227783203125
INFO:root:Train (Epoch 46): Loss/seq after 03250 batchs: 1248.96240234375
INFO:root:Train (Epoch 46): Loss/seq after 03300 batchs: 1246.4228515625
INFO:root:Train (Epoch 46): Loss/seq after 03350 batchs: 1245.2830810546875
INFO:root:Train (Epoch 46): Loss/seq after 03400 batchs: 1236.26171875
INFO:root:Train (Epoch 46): Loss/seq after 03450 batchs: 1228.2794189453125
INFO:root:Train (Epoch 46): Loss/seq after 03500 batchs: 1226.3955078125
INFO:root:Train (Epoch 46): Loss/seq after 03550 batchs: 1218.380615234375
INFO:root:Train (Epoch 46): Loss/seq after 03600 batchs: 1223.05908203125
INFO:root:Train (Epoch 46): Loss/seq after 03650 batchs: 1216.1622314453125
INFO:root:Train (Epoch 46): Loss/seq after 03700 batchs: 1214.6243896484375
INFO:root:Train (Epoch 46): Loss/seq after 03750 batchs: 1214.4036865234375
INFO:root:Train (Epoch 46): Loss/seq after 03800 batchs: 1207.2327880859375
INFO:root:Train (Epoch 46): Loss/seq after 03850 batchs: 1202.426513671875
INFO:root:Train (Epoch 46): Loss/seq after 03900 batchs: 1208.340576171875
INFO:root:Train (Epoch 46): Loss/seq after 03950 batchs: 1215.8792724609375
INFO:root:Train (Epoch 46): Loss/seq after 04000 batchs: 1206.9473876953125
INFO:root:Train (Epoch 46): Loss/seq after 04050 batchs: 1198.9779052734375
INFO:root:Train (Epoch 46): Loss/seq after 04100 batchs: 1192.681640625
INFO:root:Train (Epoch 46): Loss/seq after 04150 batchs: 1186.9222412109375
INFO:root:Train (Epoch 46): Loss/seq after 04200 batchs: 1180.76904296875
INFO:root:Train (Epoch 46): Loss/seq after 04250 batchs: 1176.086669921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 46): Loss/seq after 00000 batches: 904.7853393554688
INFO:root:# Valid (Epoch 46): Loss/seq after 00050 batches: 1097.802490234375
INFO:root:# Valid (Epoch 46): Loss/seq after 00100 batches: 1375.367431640625
INFO:root:# Valid (Epoch 46): Loss/seq after 00150 batches: 1102.9002685546875
INFO:root:# Valid (Epoch 46): Loss/seq after 00200 batches: 993.0225830078125
INFO:root:Artifacts: Make stick videos for epoch 46
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_46_on_20220423_002515.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_46_index_1633_on_20220423_002515.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 47): Loss/seq after 00000 batchs: 2440.627197265625
INFO:root:Train (Epoch 47): Loss/seq after 00050 batchs: 1528.1180419921875
INFO:root:Train (Epoch 47): Loss/seq after 00100 batchs: 1438.151123046875
INFO:root:Train (Epoch 47): Loss/seq after 00150 batchs: 1280.0611572265625
INFO:root:Train (Epoch 47): Loss/seq after 00200 batchs: 1408.379150390625
INFO:root:Train (Epoch 47): Loss/seq after 00250 batchs: 1527.22607421875
INFO:root:Train (Epoch 47): Loss/seq after 00300 batchs: 1453.998046875
INFO:root:Train (Epoch 47): Loss/seq after 00350 batchs: 1356.421142578125
INFO:root:Train (Epoch 47): Loss/seq after 00400 batchs: 1397.8746337890625
INFO:root:Train (Epoch 47): Loss/seq after 00450 batchs: 1339.5548095703125
INFO:root:Train (Epoch 47): Loss/seq after 00500 batchs: 1338.284423828125
INFO:root:Train (Epoch 47): Loss/seq after 00550 batchs: 1283.095947265625
INFO:root:Train (Epoch 47): Loss/seq after 00600 batchs: 1249.588623046875
INFO:root:Train (Epoch 47): Loss/seq after 00650 batchs: 1322.400390625
INFO:root:Train (Epoch 47): Loss/seq after 00700 batchs: 1418.2266845703125
INFO:root:Train (Epoch 47): Loss/seq after 00750 batchs: 1460.476806640625
INFO:root:Train (Epoch 47): Loss/seq after 00800 batchs: 1439.18505859375
INFO:root:Train (Epoch 47): Loss/seq after 00850 batchs: 1402.403076171875
INFO:root:Train (Epoch 47): Loss/seq after 00900 batchs: 1400.1595458984375
INFO:root:Train (Epoch 47): Loss/seq after 00950 batchs: 1483.4193115234375
INFO:root:Train (Epoch 47): Loss/seq after 01000 batchs: 1480.1109619140625
INFO:root:Train (Epoch 47): Loss/seq after 01050 batchs: 1451.0120849609375
INFO:root:Train (Epoch 47): Loss/seq after 01100 batchs: 1440.704833984375
INFO:root:Train (Epoch 47): Loss/seq after 01150 batchs: 1418.936279296875
INFO:root:Train (Epoch 47): Loss/seq after 01200 batchs: 1402.5628662109375
INFO:root:Train (Epoch 47): Loss/seq after 01250 batchs: 1393.2469482421875
INFO:root:Train (Epoch 47): Loss/seq after 01300 batchs: 1409.8338623046875
INFO:root:Train (Epoch 47): Loss/seq after 01350 batchs: 1414.1578369140625
INFO:root:Train (Epoch 47): Loss/seq after 01400 batchs: 1461.9603271484375
INFO:root:Train (Epoch 47): Loss/seq after 01450 batchs: 1445.7706298828125
INFO:root:Train (Epoch 47): Loss/seq after 01500 batchs: 1432.0516357421875
INFO:root:Train (Epoch 47): Loss/seq after 01550 batchs: 1425.8353271484375
INFO:root:Train (Epoch 47): Loss/seq after 01600 batchs: 1405.22314453125
INFO:root:Train (Epoch 47): Loss/seq after 01650 batchs: 1391.0703125
INFO:root:Train (Epoch 47): Loss/seq after 01700 batchs: 1378.1544189453125
INFO:root:Train (Epoch 47): Loss/seq after 01750 batchs: 1363.7861328125
INFO:root:Train (Epoch 47): Loss/seq after 01800 batchs: 1347.3448486328125
INFO:root:Train (Epoch 47): Loss/seq after 01850 batchs: 1331.191650390625
INFO:root:Train (Epoch 47): Loss/seq after 01900 batchs: 1324.487548828125
INFO:root:Train (Epoch 47): Loss/seq after 01950 batchs: 1313.9520263671875
INFO:root:Train (Epoch 47): Loss/seq after 02000 batchs: 1302.318603515625
INFO:root:Train (Epoch 47): Loss/seq after 02050 batchs: 1291.5133056640625
INFO:root:Train (Epoch 47): Loss/seq after 02100 batchs: 1278.4876708984375
INFO:root:Train (Epoch 47): Loss/seq after 02150 batchs: 1266.32470703125
INFO:root:Train (Epoch 47): Loss/seq after 02200 batchs: 1253.7342529296875
INFO:root:Train (Epoch 47): Loss/seq after 02250 batchs: 1250.6820068359375
INFO:root:Train (Epoch 47): Loss/seq after 02300 batchs: 1251.961669921875
INFO:root:Train (Epoch 47): Loss/seq after 02350 batchs: 1239.81787109375
INFO:root:Train (Epoch 47): Loss/seq after 02400 batchs: 1234.312744140625
INFO:root:Train (Epoch 47): Loss/seq after 02450 batchs: 1220.777587890625
INFO:root:Train (Epoch 47): Loss/seq after 02500 batchs: 1203.5269775390625
INFO:root:Train (Epoch 47): Loss/seq after 02550 batchs: 1190.60546875
INFO:root:Train (Epoch 47): Loss/seq after 02600 batchs: 1187.763671875
INFO:root:Train (Epoch 47): Loss/seq after 02650 batchs: 1182.8392333984375
INFO:root:Train (Epoch 47): Loss/seq after 02700 batchs: 1178.7130126953125
INFO:root:Train (Epoch 47): Loss/seq after 02750 batchs: 1208.5938720703125
INFO:root:Train (Epoch 47): Loss/seq after 02800 batchs: 1213.5718994140625
INFO:root:Train (Epoch 47): Loss/seq after 02850 batchs: 1209.1275634765625
INFO:root:Train (Epoch 47): Loss/seq after 02900 batchs: 1207.0360107421875
INFO:root:Train (Epoch 47): Loss/seq after 02950 batchs: 1198.553466796875
INFO:root:Train (Epoch 47): Loss/seq after 03000 batchs: 1196.50244140625
INFO:root:Train (Epoch 47): Loss/seq after 03050 batchs: 1198.6640625
INFO:root:Train (Epoch 47): Loss/seq after 03100 batchs: 1209.200439453125
INFO:root:Train (Epoch 47): Loss/seq after 03150 batchs: 1226.625244140625
INFO:root:Train (Epoch 47): Loss/seq after 03200 batchs: 1240.9593505859375
INFO:root:Train (Epoch 47): Loss/seq after 03250 batchs: 1254.6234130859375
INFO:root:Train (Epoch 47): Loss/seq after 03300 batchs: 1251.5889892578125
INFO:root:Train (Epoch 47): Loss/seq after 03350 batchs: 1250.111572265625
INFO:root:Train (Epoch 47): Loss/seq after 03400 batchs: 1240.9903564453125
INFO:root:Train (Epoch 47): Loss/seq after 03450 batchs: 1232.9786376953125
INFO:root:Train (Epoch 47): Loss/seq after 03500 batchs: 1230.238037109375
INFO:root:Train (Epoch 47): Loss/seq after 03550 batchs: 1222.2615966796875
INFO:root:Train (Epoch 47): Loss/seq after 03600 batchs: 1226.4921875
INFO:root:Train (Epoch 47): Loss/seq after 03650 batchs: 1219.0928955078125
INFO:root:Train (Epoch 47): Loss/seq after 03700 batchs: 1217.1123046875
INFO:root:Train (Epoch 47): Loss/seq after 03750 batchs: 1216.9432373046875
INFO:root:Train (Epoch 47): Loss/seq after 03800 batchs: 1209.7784423828125
INFO:root:Train (Epoch 47): Loss/seq after 03850 batchs: 1204.88818359375
INFO:root:Train (Epoch 47): Loss/seq after 03900 batchs: 1210.7457275390625
INFO:root:Train (Epoch 47): Loss/seq after 03950 batchs: 1218.6514892578125
INFO:root:Train (Epoch 47): Loss/seq after 04000 batchs: 1209.6707763671875
INFO:root:Train (Epoch 47): Loss/seq after 04050 batchs: 1201.6688232421875
INFO:root:Train (Epoch 47): Loss/seq after 04100 batchs: 1195.159423828125
INFO:root:Train (Epoch 47): Loss/seq after 04150 batchs: 1189.389892578125
INFO:root:Train (Epoch 47): Loss/seq after 04200 batchs: 1183.49365234375
INFO:root:Train (Epoch 47): Loss/seq after 04250 batchs: 1178.8104248046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 47): Loss/seq after 00000 batches: 898.8225708007812
INFO:root:# Valid (Epoch 47): Loss/seq after 00050 batches: 1098.8509521484375
INFO:root:# Valid (Epoch 47): Loss/seq after 00100 batches: 1375.1793212890625
INFO:root:# Valid (Epoch 47): Loss/seq after 00150 batches: 1095.89404296875
INFO:root:# Valid (Epoch 47): Loss/seq after 00200 batches: 986.4589233398438
INFO:root:Artifacts: Make stick videos for epoch 47
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_47_on_20220423_002959.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_47_index_436_on_20220423_002959.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 48): Loss/seq after 00000 batchs: 2453.757568359375
INFO:root:Train (Epoch 48): Loss/seq after 00050 batchs: 1593.5604248046875
INFO:root:Train (Epoch 48): Loss/seq after 00100 batchs: 1506.9468994140625
INFO:root:Train (Epoch 48): Loss/seq after 00150 batchs: 1318.37060546875
INFO:root:Train (Epoch 48): Loss/seq after 00200 batchs: 1432.4080810546875
INFO:root:Train (Epoch 48): Loss/seq after 00250 batchs: 1550.3389892578125
INFO:root:Train (Epoch 48): Loss/seq after 00300 batchs: 1473.76123046875
INFO:root:Train (Epoch 48): Loss/seq after 00350 batchs: 1374.4290771484375
INFO:root:Train (Epoch 48): Loss/seq after 00400 batchs: 1410.7159423828125
INFO:root:Train (Epoch 48): Loss/seq after 00450 batchs: 1350.527587890625
INFO:root:Train (Epoch 48): Loss/seq after 00500 batchs: 1345.75830078125
INFO:root:Train (Epoch 48): Loss/seq after 00550 batchs: 1289.061767578125
INFO:root:Train (Epoch 48): Loss/seq after 00600 batchs: 1254.37158203125
INFO:root:Train (Epoch 48): Loss/seq after 00650 batchs: 1326.4849853515625
INFO:root:Train (Epoch 48): Loss/seq after 00700 batchs: 1421.9583740234375
INFO:root:Train (Epoch 48): Loss/seq after 00750 batchs: 1461.873291015625
INFO:root:Train (Epoch 48): Loss/seq after 00800 batchs: 1439.406982421875
INFO:root:Train (Epoch 48): Loss/seq after 00850 batchs: 1401.9228515625
INFO:root:Train (Epoch 48): Loss/seq after 00900 batchs: 1399.56982421875
INFO:root:Train (Epoch 48): Loss/seq after 00950 batchs: 1484.56884765625
INFO:root:Train (Epoch 48): Loss/seq after 01000 batchs: 1480.5386962890625
INFO:root:Train (Epoch 48): Loss/seq after 01050 batchs: 1452.6309814453125
INFO:root:Train (Epoch 48): Loss/seq after 01100 batchs: 1440.0894775390625
INFO:root:Train (Epoch 48): Loss/seq after 01150 batchs: 1419.098876953125
INFO:root:Train (Epoch 48): Loss/seq after 01200 batchs: 1404.524169921875
INFO:root:Train (Epoch 48): Loss/seq after 01250 batchs: 1395.07373046875
INFO:root:Train (Epoch 48): Loss/seq after 01300 batchs: 1411.672119140625
INFO:root:Train (Epoch 48): Loss/seq after 01350 batchs: 1415.95849609375
INFO:root:Train (Epoch 48): Loss/seq after 01400 batchs: 1463.2725830078125
INFO:root:Train (Epoch 48): Loss/seq after 01450 batchs: 1447.848388671875
INFO:root:Train (Epoch 48): Loss/seq after 01500 batchs: 1434.3673095703125
INFO:root:Train (Epoch 48): Loss/seq after 01550 batchs: 1428.0108642578125
INFO:root:Train (Epoch 48): Loss/seq after 01600 batchs: 1407.0938720703125
INFO:root:Train (Epoch 48): Loss/seq after 01650 batchs: 1391.339599609375
INFO:root:Train (Epoch 48): Loss/seq after 01700 batchs: 1378.9971923828125
INFO:root:Train (Epoch 48): Loss/seq after 01750 batchs: 1364.8922119140625
INFO:root:Train (Epoch 48): Loss/seq after 01800 batchs: 1348.4285888671875
INFO:root:Train (Epoch 48): Loss/seq after 01850 batchs: 1332.1712646484375
INFO:root:Train (Epoch 48): Loss/seq after 01900 batchs: 1325.450927734375
INFO:root:Train (Epoch 48): Loss/seq after 01950 batchs: 1314.72314453125
INFO:root:Train (Epoch 48): Loss/seq after 02000 batchs: 1303.0877685546875
INFO:root:Train (Epoch 48): Loss/seq after 02050 batchs: 1292.1649169921875
INFO:root:Train (Epoch 48): Loss/seq after 02100 batchs: 1278.9852294921875
INFO:root:Train (Epoch 48): Loss/seq after 02150 batchs: 1266.734130859375
INFO:root:Train (Epoch 48): Loss/seq after 02200 batchs: 1254.1671142578125
INFO:root:Train (Epoch 48): Loss/seq after 02250 batchs: 1251.298095703125
INFO:root:Train (Epoch 48): Loss/seq after 02300 batchs: 1252.58935546875
INFO:root:Train (Epoch 48): Loss/seq after 02350 batchs: 1240.6279296875
INFO:root:Train (Epoch 48): Loss/seq after 02400 batchs: 1234.830322265625
INFO:root:Train (Epoch 48): Loss/seq after 02450 batchs: 1220.96484375
INFO:root:Train (Epoch 48): Loss/seq after 02500 batchs: 1203.6729736328125
INFO:root:Train (Epoch 48): Loss/seq after 02550 batchs: 1191.0087890625
INFO:root:Train (Epoch 48): Loss/seq after 02600 batchs: 1187.77001953125
INFO:root:Train (Epoch 48): Loss/seq after 02650 batchs: 1182.284423828125
INFO:root:Train (Epoch 48): Loss/seq after 02700 batchs: 1177.4598388671875
INFO:root:Train (Epoch 48): Loss/seq after 02750 batchs: 1206.55810546875
INFO:root:Train (Epoch 48): Loss/seq after 02800 batchs: 1211.3831787109375
INFO:root:Train (Epoch 48): Loss/seq after 02850 batchs: 1206.08642578125
INFO:root:Train (Epoch 48): Loss/seq after 02900 batchs: 1203.8487548828125
INFO:root:Train (Epoch 48): Loss/seq after 02950 batchs: 1195.8477783203125
INFO:root:Train (Epoch 48): Loss/seq after 03000 batchs: 1193.8861083984375
INFO:root:Train (Epoch 48): Loss/seq after 03050 batchs: 1196.199462890625
INFO:root:Train (Epoch 48): Loss/seq after 03100 batchs: 1205.9554443359375
INFO:root:Train (Epoch 48): Loss/seq after 03150 batchs: 1221.917236328125
INFO:root:Train (Epoch 48): Loss/seq after 03200 batchs: 1236.2637939453125
INFO:root:Train (Epoch 48): Loss/seq after 03250 batchs: 1249.947265625
INFO:root:Train (Epoch 48): Loss/seq after 03300 batchs: 1247.7598876953125
INFO:root:Train (Epoch 48): Loss/seq after 03350 batchs: 1246.256103515625
INFO:root:Train (Epoch 48): Loss/seq after 03400 batchs: 1237.2158203125
INFO:root:Train (Epoch 48): Loss/seq after 03450 batchs: 1229.179443359375
INFO:root:Train (Epoch 48): Loss/seq after 03500 batchs: 1226.5093994140625
INFO:root:Train (Epoch 48): Loss/seq after 03550 batchs: 1218.3292236328125
INFO:root:Train (Epoch 48): Loss/seq after 03600 batchs: 1222.623779296875
INFO:root:Train (Epoch 48): Loss/seq after 03650 batchs: 1215.311279296875
INFO:root:Train (Epoch 48): Loss/seq after 03700 batchs: 1213.6617431640625
INFO:root:Train (Epoch 48): Loss/seq after 03750 batchs: 1213.5296630859375
INFO:root:Train (Epoch 48): Loss/seq after 03800 batchs: 1206.393798828125
INFO:root:Train (Epoch 48): Loss/seq after 03850 batchs: 1201.533935546875
INFO:root:Train (Epoch 48): Loss/seq after 03900 batchs: 1207.137451171875
INFO:root:Train (Epoch 48): Loss/seq after 03950 batchs: 1214.6146240234375
INFO:root:Train (Epoch 48): Loss/seq after 04000 batchs: 1205.6982421875
INFO:root:Train (Epoch 48): Loss/seq after 04050 batchs: 1197.7332763671875
INFO:root:Train (Epoch 48): Loss/seq after 04100 batchs: 1191.2525634765625
INFO:root:Train (Epoch 48): Loss/seq after 04150 batchs: 1185.4307861328125
INFO:root:Train (Epoch 48): Loss/seq after 04200 batchs: 1179.3668212890625
INFO:root:Train (Epoch 48): Loss/seq after 04250 batchs: 1174.7679443359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 48): Loss/seq after 00000 batches: 895.7894897460938
INFO:root:# Valid (Epoch 48): Loss/seq after 00050 batches: 1092.1484375
INFO:root:# Valid (Epoch 48): Loss/seq after 00100 batches: 1372.7442626953125
INFO:root:# Valid (Epoch 48): Loss/seq after 00150 batches: 1093.1246337890625
INFO:root:# Valid (Epoch 48): Loss/seq after 00200 batches: 982.5362548828125
INFO:root:Artifacts: Make stick videos for epoch 48
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_48_on_20220423_003454.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_48_index_113_on_20220423_003454.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 49): Loss/seq after 00000 batchs: 2393.38720703125
INFO:root:Train (Epoch 49): Loss/seq after 00050 batchs: 1535.501708984375
INFO:root:Train (Epoch 49): Loss/seq after 00100 batchs: 1464.4207763671875
INFO:root:Train (Epoch 49): Loss/seq after 00150 batchs: 1292.3134765625
INFO:root:Train (Epoch 49): Loss/seq after 00200 batchs: 1410.239990234375
INFO:root:Train (Epoch 49): Loss/seq after 00250 batchs: 1531.068359375
INFO:root:Train (Epoch 49): Loss/seq after 00300 batchs: 1457.32763671875
INFO:root:Train (Epoch 49): Loss/seq after 00350 batchs: 1364.3232421875
INFO:root:Train (Epoch 49): Loss/seq after 00400 batchs: 1404.623779296875
INFO:root:Train (Epoch 49): Loss/seq after 00450 batchs: 1345.6693115234375
INFO:root:Train (Epoch 49): Loss/seq after 00500 batchs: 1342.228515625
INFO:root:Train (Epoch 49): Loss/seq after 00550 batchs: 1287.01611328125
INFO:root:Train (Epoch 49): Loss/seq after 00600 batchs: 1254.4229736328125
INFO:root:Train (Epoch 49): Loss/seq after 00650 batchs: 1327.57177734375
INFO:root:Train (Epoch 49): Loss/seq after 00700 batchs: 1421.8062744140625
INFO:root:Train (Epoch 49): Loss/seq after 00750 batchs: 1460.1019287109375
INFO:root:Train (Epoch 49): Loss/seq after 00800 batchs: 1441.528564453125
INFO:root:Train (Epoch 49): Loss/seq after 00850 batchs: 1405.718505859375
INFO:root:Train (Epoch 49): Loss/seq after 00900 batchs: 1402.405517578125
INFO:root:Train (Epoch 49): Loss/seq after 00950 batchs: 1487.2464599609375
INFO:root:Train (Epoch 49): Loss/seq after 01000 batchs: 1483.4422607421875
INFO:root:Train (Epoch 49): Loss/seq after 01050 batchs: 1456.0865478515625
INFO:root:Train (Epoch 49): Loss/seq after 01100 batchs: 1442.512939453125
INFO:root:Train (Epoch 49): Loss/seq after 01150 batchs: 1420.176513671875
INFO:root:Train (Epoch 49): Loss/seq after 01200 batchs: 1403.3348388671875
INFO:root:Train (Epoch 49): Loss/seq after 01250 batchs: 1393.307861328125
INFO:root:Train (Epoch 49): Loss/seq after 01300 batchs: 1409.8505859375
INFO:root:Train (Epoch 49): Loss/seq after 01350 batchs: 1414.2176513671875
INFO:root:Train (Epoch 49): Loss/seq after 01400 batchs: 1461.1654052734375
INFO:root:Train (Epoch 49): Loss/seq after 01450 batchs: 1445.4193115234375
INFO:root:Train (Epoch 49): Loss/seq after 01500 batchs: 1431.611328125
INFO:root:Train (Epoch 49): Loss/seq after 01550 batchs: 1424.6600341796875
INFO:root:Train (Epoch 49): Loss/seq after 01600 batchs: 1404.0548095703125
INFO:root:Train (Epoch 49): Loss/seq after 01650 batchs: 1389.1153564453125
INFO:root:Train (Epoch 49): Loss/seq after 01700 batchs: 1376.039794921875
INFO:root:Train (Epoch 49): Loss/seq after 01750 batchs: 1361.7137451171875
INFO:root:Train (Epoch 49): Loss/seq after 01800 batchs: 1345.056396484375
INFO:root:Train (Epoch 49): Loss/seq after 01850 batchs: 1328.768310546875
INFO:root:Train (Epoch 49): Loss/seq after 01900 batchs: 1321.9263916015625
INFO:root:Train (Epoch 49): Loss/seq after 01950 batchs: 1312.219970703125
INFO:root:Train (Epoch 49): Loss/seq after 02000 batchs: 1300.5174560546875
INFO:root:Train (Epoch 49): Loss/seq after 02050 batchs: 1289.6552734375
INFO:root:Train (Epoch 49): Loss/seq after 02100 batchs: 1276.5748291015625
INFO:root:Train (Epoch 49): Loss/seq after 02150 batchs: 1264.3507080078125
INFO:root:Train (Epoch 49): Loss/seq after 02200 batchs: 1251.8170166015625
INFO:root:Train (Epoch 49): Loss/seq after 02250 batchs: 1248.5535888671875
INFO:root:Train (Epoch 49): Loss/seq after 02300 batchs: 1250.015625
INFO:root:Train (Epoch 49): Loss/seq after 02350 batchs: 1239.1806640625
INFO:root:Train (Epoch 49): Loss/seq after 02400 batchs: 1233.7816162109375
INFO:root:Train (Epoch 49): Loss/seq after 02450 batchs: 1220.246337890625
INFO:root:Train (Epoch 49): Loss/seq after 02500 batchs: 1202.9676513671875
INFO:root:Train (Epoch 49): Loss/seq after 02550 batchs: 1190.1868896484375
INFO:root:Train (Epoch 49): Loss/seq after 02600 batchs: 1186.911376953125
INFO:root:Train (Epoch 49): Loss/seq after 02650 batchs: 1181.7657470703125
INFO:root:Train (Epoch 49): Loss/seq after 02700 batchs: 1177.138916015625
INFO:root:Train (Epoch 49): Loss/seq after 02750 batchs: 1206.720458984375
INFO:root:Train (Epoch 49): Loss/seq after 02800 batchs: 1212.58642578125
INFO:root:Train (Epoch 49): Loss/seq after 02850 batchs: 1207.922607421875
INFO:root:Train (Epoch 49): Loss/seq after 02900 batchs: 1206.197021484375
INFO:root:Train (Epoch 49): Loss/seq after 02950 batchs: 1198.6429443359375
INFO:root:Train (Epoch 49): Loss/seq after 03000 batchs: 1196.7122802734375
INFO:root:Train (Epoch 49): Loss/seq after 03050 batchs: 1199.1658935546875
INFO:root:Train (Epoch 49): Loss/seq after 03100 batchs: 1209.0870361328125
INFO:root:Train (Epoch 49): Loss/seq after 03150 batchs: 1224.8658447265625
INFO:root:Train (Epoch 49): Loss/seq after 03200 batchs: 1239.2269287109375
INFO:root:Train (Epoch 49): Loss/seq after 03250 batchs: 1252.7901611328125
INFO:root:Train (Epoch 49): Loss/seq after 03300 batchs: 1250.1617431640625
INFO:root:Train (Epoch 49): Loss/seq after 03350 batchs: 1250.07568359375
INFO:root:Train (Epoch 49): Loss/seq after 03400 batchs: 1241.319580078125
INFO:root:Train (Epoch 49): Loss/seq after 03450 batchs: 1233.769287109375
INFO:root:Train (Epoch 49): Loss/seq after 03500 batchs: 1231.56591796875
INFO:root:Train (Epoch 49): Loss/seq after 03550 batchs: 1223.9229736328125
INFO:root:Train (Epoch 49): Loss/seq after 03600 batchs: 1228.66162109375
INFO:root:Train (Epoch 49): Loss/seq after 03650 batchs: 1221.415283203125
INFO:root:Train (Epoch 49): Loss/seq after 03700 batchs: 1219.690673828125
INFO:root:Train (Epoch 49): Loss/seq after 03750 batchs: 1219.421875
INFO:root:Train (Epoch 49): Loss/seq after 03800 batchs: 1212.190185546875
INFO:root:Train (Epoch 49): Loss/seq after 03850 batchs: 1207.2869873046875
INFO:root:Train (Epoch 49): Loss/seq after 03900 batchs: 1213.299560546875
INFO:root:Train (Epoch 49): Loss/seq after 03950 batchs: 1220.5296630859375
INFO:root:Train (Epoch 49): Loss/seq after 04000 batchs: 1211.5302734375
INFO:root:Train (Epoch 49): Loss/seq after 04050 batchs: 1203.5062255859375
INFO:root:Train (Epoch 49): Loss/seq after 04100 batchs: 1197.14892578125
INFO:root:Train (Epoch 49): Loss/seq after 04150 batchs: 1191.2293701171875
INFO:root:Train (Epoch 49): Loss/seq after 04200 batchs: 1185.1390380859375
INFO:root:Train (Epoch 49): Loss/seq after 04250 batchs: 1180.51220703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 49): Loss/seq after 00000 batches: 880.6754150390625
INFO:root:# Valid (Epoch 49): Loss/seq after 00050 batches: 1094.0738525390625
INFO:root:# Valid (Epoch 49): Loss/seq after 00100 batches: 1382.2303466796875
INFO:root:# Valid (Epoch 49): Loss/seq after 00150 batches: 1100.371337890625
INFO:root:# Valid (Epoch 49): Loss/seq after 00200 batches: 988.7809448242188
INFO:root:Artifacts: Make stick videos for epoch 49
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_49_on_20220423_003948.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_49_index_345_on_20220423_003948.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 50): Loss/seq after 00000 batchs: 2393.218017578125
INFO:root:Train (Epoch 50): Loss/seq after 00050 batchs: 1573.7762451171875
INFO:root:Train (Epoch 50): Loss/seq after 00100 batchs: 1493.8729248046875
INFO:root:Train (Epoch 50): Loss/seq after 00150 batchs: 1313.11279296875
INFO:root:Train (Epoch 50): Loss/seq after 00200 batchs: 1426.527587890625
INFO:root:Train (Epoch 50): Loss/seq after 00250 batchs: 1538.089599609375
INFO:root:Train (Epoch 50): Loss/seq after 00300 batchs: 1463.1949462890625
INFO:root:Train (Epoch 50): Loss/seq after 00350 batchs: 1364.8443603515625
INFO:root:Train (Epoch 50): Loss/seq after 00400 batchs: 1404.5726318359375
INFO:root:Train (Epoch 50): Loss/seq after 00450 batchs: 1346.601318359375
INFO:root:Train (Epoch 50): Loss/seq after 00500 batchs: 1345.2791748046875
INFO:root:Train (Epoch 50): Loss/seq after 00550 batchs: 1289.1119384765625
INFO:root:Train (Epoch 50): Loss/seq after 00600 batchs: 1253.7830810546875
INFO:root:Train (Epoch 50): Loss/seq after 00650 batchs: 1327.1246337890625
INFO:root:Train (Epoch 50): Loss/seq after 00700 batchs: 1421.754150390625
INFO:root:Train (Epoch 50): Loss/seq after 00750 batchs: 1461.367919921875
INFO:root:Train (Epoch 50): Loss/seq after 00800 batchs: 1438.9063720703125
INFO:root:Train (Epoch 50): Loss/seq after 00850 batchs: 1401.664794921875
INFO:root:Train (Epoch 50): Loss/seq after 00900 batchs: 1399.5369873046875
INFO:root:Train (Epoch 50): Loss/seq after 00950 batchs: 1481.78125
INFO:root:Train (Epoch 50): Loss/seq after 01000 batchs: 1478.1312255859375
INFO:root:Train (Epoch 50): Loss/seq after 01050 batchs: 1447.1048583984375
INFO:root:Train (Epoch 50): Loss/seq after 01100 batchs: 1434.278564453125
INFO:root:Train (Epoch 50): Loss/seq after 01150 batchs: 1412.5694580078125
INFO:root:Train (Epoch 50): Loss/seq after 01200 batchs: 1395.7572021484375
INFO:root:Train (Epoch 50): Loss/seq after 01250 batchs: 1386.05322265625
INFO:root:Train (Epoch 50): Loss/seq after 01300 batchs: 1402.927490234375
INFO:root:Train (Epoch 50): Loss/seq after 01350 batchs: 1407.5733642578125
INFO:root:Train (Epoch 50): Loss/seq after 01400 batchs: 1454.363525390625
INFO:root:Train (Epoch 50): Loss/seq after 01450 batchs: 1439.01904296875
INFO:root:Train (Epoch 50): Loss/seq after 01500 batchs: 1425.4820556640625
INFO:root:Train (Epoch 50): Loss/seq after 01550 batchs: 1418.5992431640625
INFO:root:Train (Epoch 50): Loss/seq after 01600 batchs: 1397.9024658203125
INFO:root:Train (Epoch 50): Loss/seq after 01650 batchs: 1381.89111328125
INFO:root:Train (Epoch 50): Loss/seq after 01700 batchs: 1368.952392578125
INFO:root:Train (Epoch 50): Loss/seq after 01750 batchs: 1354.72216796875
INFO:root:Train (Epoch 50): Loss/seq after 01800 batchs: 1338.228271484375
INFO:root:Train (Epoch 50): Loss/seq after 01850 batchs: 1321.8953857421875
INFO:root:Train (Epoch 50): Loss/seq after 01900 batchs: 1315.2664794921875
INFO:root:Train (Epoch 50): Loss/seq after 01950 batchs: 1304.96044921875
INFO:root:Train (Epoch 50): Loss/seq after 02000 batchs: 1293.706298828125
INFO:root:Train (Epoch 50): Loss/seq after 02050 batchs: 1283.2169189453125
INFO:root:Train (Epoch 50): Loss/seq after 02100 batchs: 1270.182373046875
INFO:root:Train (Epoch 50): Loss/seq after 02150 batchs: 1257.99365234375
INFO:root:Train (Epoch 50): Loss/seq after 02200 batchs: 1245.5672607421875
INFO:root:Train (Epoch 50): Loss/seq after 02250 batchs: 1243.9305419921875
INFO:root:Train (Epoch 50): Loss/seq after 02300 batchs: 1245.78759765625
INFO:root:Train (Epoch 50): Loss/seq after 02350 batchs: 1235.4451904296875
INFO:root:Train (Epoch 50): Loss/seq after 02400 batchs: 1229.9085693359375
INFO:root:Train (Epoch 50): Loss/seq after 02450 batchs: 1216.326904296875
INFO:root:Train (Epoch 50): Loss/seq after 02500 batchs: 1199.1402587890625
INFO:root:Train (Epoch 50): Loss/seq after 02550 batchs: 1186.868408203125
INFO:root:Train (Epoch 50): Loss/seq after 02600 batchs: 1183.9617919921875
INFO:root:Train (Epoch 50): Loss/seq after 02650 batchs: 1178.8209228515625
INFO:root:Train (Epoch 50): Loss/seq after 02700 batchs: 1174.147705078125
INFO:root:Train (Epoch 50): Loss/seq after 02750 batchs: 1203.2154541015625
INFO:root:Train (Epoch 50): Loss/seq after 02800 batchs: 1208.359375
INFO:root:Train (Epoch 50): Loss/seq after 02850 batchs: 1203.1126708984375
INFO:root:Train (Epoch 50): Loss/seq after 02900 batchs: 1200.387939453125
INFO:root:Train (Epoch 50): Loss/seq after 02950 batchs: 1192.250732421875
INFO:root:Train (Epoch 50): Loss/seq after 03000 batchs: 1190.3045654296875
INFO:root:Train (Epoch 50): Loss/seq after 03050 batchs: 1192.5643310546875
INFO:root:Train (Epoch 50): Loss/seq after 03100 batchs: 1202.447998046875
INFO:root:Train (Epoch 50): Loss/seq after 03150 batchs: 1218.3294677734375
INFO:root:Train (Epoch 50): Loss/seq after 03200 batchs: 1232.779052734375
INFO:root:Train (Epoch 50): Loss/seq after 03250 batchs: 1246.5638427734375
INFO:root:Train (Epoch 50): Loss/seq after 03300 batchs: 1244.36572265625
INFO:root:Train (Epoch 50): Loss/seq after 03350 batchs: 1243.841552734375
INFO:root:Train (Epoch 50): Loss/seq after 03400 batchs: 1235.178466796875
INFO:root:Train (Epoch 50): Loss/seq after 03450 batchs: 1227.62158203125
INFO:root:Train (Epoch 50): Loss/seq after 03500 batchs: 1225.59814453125
INFO:root:Train (Epoch 50): Loss/seq after 03550 batchs: 1217.7904052734375
INFO:root:Train (Epoch 50): Loss/seq after 03600 batchs: 1222.2152099609375
INFO:root:Train (Epoch 50): Loss/seq after 03650 batchs: 1215.0478515625
INFO:root:Train (Epoch 50): Loss/seq after 03700 batchs: 1213.411376953125
INFO:root:Train (Epoch 50): Loss/seq after 03750 batchs: 1213.2803955078125
INFO:root:Train (Epoch 50): Loss/seq after 03800 batchs: 1206.2142333984375
INFO:root:Train (Epoch 50): Loss/seq after 03850 batchs: 1201.3623046875
INFO:root:Train (Epoch 50): Loss/seq after 03900 batchs: 1207.109619140625
INFO:root:Train (Epoch 50): Loss/seq after 03950 batchs: 1214.8729248046875
INFO:root:Train (Epoch 50): Loss/seq after 04000 batchs: 1205.926513671875
INFO:root:Train (Epoch 50): Loss/seq after 04050 batchs: 1197.9857177734375
INFO:root:Train (Epoch 50): Loss/seq after 04100 batchs: 1191.486328125
INFO:root:Train (Epoch 50): Loss/seq after 04150 batchs: 1185.6275634765625
INFO:root:Train (Epoch 50): Loss/seq after 04200 batchs: 1179.408203125
INFO:root:Train (Epoch 50): Loss/seq after 04250 batchs: 1174.8895263671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 50): Loss/seq after 00000 batches: 905.5505981445312
INFO:root:# Valid (Epoch 50): Loss/seq after 00050 batches: 1105.662353515625
INFO:root:# Valid (Epoch 50): Loss/seq after 00100 batches: 1381.8734130859375
INFO:root:# Valid (Epoch 50): Loss/seq after 00150 batches: 1101.353515625
INFO:root:# Valid (Epoch 50): Loss/seq after 00200 batches: 991.7699584960938
INFO:root:Artifacts: Make stick videos for epoch 50
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_50_on_20220423_004440.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_50_index_539_on_20220423_004440.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 51): Loss/seq after 00000 batchs: 2397.08056640625
INFO:root:Train (Epoch 51): Loss/seq after 00050 batchs: 1609.533935546875
INFO:root:Train (Epoch 51): Loss/seq after 00100 batchs: 1515.1864013671875
INFO:root:Train (Epoch 51): Loss/seq after 00150 batchs: 1334.1053466796875
INFO:root:Train (Epoch 51): Loss/seq after 00200 batchs: 1448.7757568359375
INFO:root:Train (Epoch 51): Loss/seq after 00250 batchs: 1561.1090087890625
INFO:root:Train (Epoch 51): Loss/seq after 00300 batchs: 1482.8939208984375
INFO:root:Train (Epoch 51): Loss/seq after 00350 batchs: 1380.825439453125
INFO:root:Train (Epoch 51): Loss/seq after 00400 batchs: 1417.5037841796875
INFO:root:Train (Epoch 51): Loss/seq after 00450 batchs: 1356.4659423828125
INFO:root:Train (Epoch 51): Loss/seq after 00500 batchs: 1349.8408203125
INFO:root:Train (Epoch 51): Loss/seq after 00550 batchs: 1292.83544921875
INFO:root:Train (Epoch 51): Loss/seq after 00600 batchs: 1257.024658203125
INFO:root:Train (Epoch 51): Loss/seq after 00650 batchs: 1329.8079833984375
INFO:root:Train (Epoch 51): Loss/seq after 00700 batchs: 1424.924560546875
INFO:root:Train (Epoch 51): Loss/seq after 00750 batchs: 1463.7469482421875
INFO:root:Train (Epoch 51): Loss/seq after 00800 batchs: 1440.6064453125
INFO:root:Train (Epoch 51): Loss/seq after 00850 batchs: 1403.5601806640625
INFO:root:Train (Epoch 51): Loss/seq after 00900 batchs: 1400.367919921875
INFO:root:Train (Epoch 51): Loss/seq after 00950 batchs: 1484.4515380859375
INFO:root:Train (Epoch 51): Loss/seq after 01000 batchs: 1481.0594482421875
INFO:root:Train (Epoch 51): Loss/seq after 01050 batchs: 1450.8819580078125
INFO:root:Train (Epoch 51): Loss/seq after 01100 batchs: 1436.73681640625
INFO:root:Train (Epoch 51): Loss/seq after 01150 batchs: 1414.8128662109375
INFO:root:Train (Epoch 51): Loss/seq after 01200 batchs: 1398.1451416015625
INFO:root:Train (Epoch 51): Loss/seq after 01250 batchs: 1387.5625
INFO:root:Train (Epoch 51): Loss/seq after 01300 batchs: 1404.3480224609375
INFO:root:Train (Epoch 51): Loss/seq after 01350 batchs: 1408.8934326171875
INFO:root:Train (Epoch 51): Loss/seq after 01400 batchs: 1455.623779296875
INFO:root:Train (Epoch 51): Loss/seq after 01450 batchs: 1439.605224609375
INFO:root:Train (Epoch 51): Loss/seq after 01500 batchs: 1425.972412109375
INFO:root:Train (Epoch 51): Loss/seq after 01550 batchs: 1418.4276123046875
INFO:root:Train (Epoch 51): Loss/seq after 01600 batchs: 1397.54736328125
INFO:root:Train (Epoch 51): Loss/seq after 01650 batchs: 1380.91845703125
INFO:root:Train (Epoch 51): Loss/seq after 01700 batchs: 1368.0341796875
INFO:root:Train (Epoch 51): Loss/seq after 01750 batchs: 1353.9425048828125
INFO:root:Train (Epoch 51): Loss/seq after 01800 batchs: 1337.5294189453125
INFO:root:Train (Epoch 51): Loss/seq after 01850 batchs: 1321.1710205078125
INFO:root:Train (Epoch 51): Loss/seq after 01900 batchs: 1314.4632568359375
INFO:root:Train (Epoch 51): Loss/seq after 01950 batchs: 1304.1976318359375
INFO:root:Train (Epoch 51): Loss/seq after 02000 batchs: 1292.76220703125
INFO:root:Train (Epoch 51): Loss/seq after 02050 batchs: 1281.981689453125
INFO:root:Train (Epoch 51): Loss/seq after 02100 batchs: 1268.9864501953125
INFO:root:Train (Epoch 51): Loss/seq after 02150 batchs: 1256.850830078125
INFO:root:Train (Epoch 51): Loss/seq after 02200 batchs: 1244.4615478515625
INFO:root:Train (Epoch 51): Loss/seq after 02250 batchs: 1241.38330078125
INFO:root:Train (Epoch 51): Loss/seq after 02300 batchs: 1242.5584716796875
INFO:root:Train (Epoch 51): Loss/seq after 02350 batchs: 1231.9825439453125
INFO:root:Train (Epoch 51): Loss/seq after 02400 batchs: 1226.3680419921875
INFO:root:Train (Epoch 51): Loss/seq after 02450 batchs: 1212.9312744140625
INFO:root:Train (Epoch 51): Loss/seq after 02500 batchs: 1195.8037109375
INFO:root:Train (Epoch 51): Loss/seq after 02550 batchs: 1183.2591552734375
INFO:root:Train (Epoch 51): Loss/seq after 02600 batchs: 1180.2264404296875
INFO:root:Train (Epoch 51): Loss/seq after 02650 batchs: 1174.8931884765625
INFO:root:Train (Epoch 51): Loss/seq after 02700 batchs: 1170.2313232421875
INFO:root:Train (Epoch 51): Loss/seq after 02750 batchs: 1199.150390625
INFO:root:Train (Epoch 51): Loss/seq after 02800 batchs: 1203.91455078125
INFO:root:Train (Epoch 51): Loss/seq after 02850 batchs: 1198.529541015625
INFO:root:Train (Epoch 51): Loss/seq after 02900 batchs: 1195.9210205078125
INFO:root:Train (Epoch 51): Loss/seq after 02950 batchs: 1188.0028076171875
INFO:root:Train (Epoch 51): Loss/seq after 03000 batchs: 1186.0755615234375
INFO:root:Train (Epoch 51): Loss/seq after 03050 batchs: 1188.3033447265625
INFO:root:Train (Epoch 51): Loss/seq after 03100 batchs: 1198.5675048828125
INFO:root:Train (Epoch 51): Loss/seq after 03150 batchs: 1215.8846435546875
INFO:root:Train (Epoch 51): Loss/seq after 03200 batchs: 1230.2205810546875
INFO:root:Train (Epoch 51): Loss/seq after 03250 batchs: 1244.0301513671875
INFO:root:Train (Epoch 51): Loss/seq after 03300 batchs: 1241.1817626953125
INFO:root:Train (Epoch 51): Loss/seq after 03350 batchs: 1239.8828125
INFO:root:Train (Epoch 51): Loss/seq after 03400 batchs: 1231.15576171875
INFO:root:Train (Epoch 51): Loss/seq after 03450 batchs: 1222.964599609375
INFO:root:Train (Epoch 51): Loss/seq after 03500 batchs: 1220.2332763671875
INFO:root:Train (Epoch 51): Loss/seq after 03550 batchs: 1211.910888671875
INFO:root:Train (Epoch 51): Loss/seq after 03600 batchs: 1216.1632080078125
INFO:root:Train (Epoch 51): Loss/seq after 03650 batchs: 1208.91064453125
INFO:root:Train (Epoch 51): Loss/seq after 03700 batchs: 1207.3143310546875
INFO:root:Train (Epoch 51): Loss/seq after 03750 batchs: 1207.273681640625
INFO:root:Train (Epoch 51): Loss/seq after 03800 batchs: 1200.1920166015625
INFO:root:Train (Epoch 51): Loss/seq after 03850 batchs: 1195.3560791015625
INFO:root:Train (Epoch 51): Loss/seq after 03900 batchs: 1200.8800048828125
INFO:root:Train (Epoch 51): Loss/seq after 03950 batchs: 1208.515380859375
INFO:root:Train (Epoch 51): Loss/seq after 04000 batchs: 1199.6326904296875
INFO:root:Train (Epoch 51): Loss/seq after 04050 batchs: 1191.728271484375
INFO:root:Train (Epoch 51): Loss/seq after 04100 batchs: 1185.0355224609375
INFO:root:Train (Epoch 51): Loss/seq after 04150 batchs: 1179.316650390625
INFO:root:Train (Epoch 51): Loss/seq after 04200 batchs: 1173.0413818359375
INFO:root:Train (Epoch 51): Loss/seq after 04250 batchs: 1168.470703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 51): Loss/seq after 00000 batches: 878.4695434570312
INFO:root:# Valid (Epoch 51): Loss/seq after 00050 batches: 1103.2952880859375
INFO:root:# Valid (Epoch 51): Loss/seq after 00100 batches: 1394.7996826171875
INFO:root:# Valid (Epoch 51): Loss/seq after 00150 batches: 1113.310302734375
INFO:root:# Valid (Epoch 51): Loss/seq after 00200 batches: 1003.032470703125
INFO:root:Artifacts: Make stick videos for epoch 51
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_51_on_20220423_004940.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_51_index_390_on_20220423_004940.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 52): Loss/seq after 00000 batchs: 2448.17919921875
INFO:root:Train (Epoch 52): Loss/seq after 00050 batchs: 1584.8104248046875
INFO:root:Train (Epoch 52): Loss/seq after 00100 batchs: 1488.8121337890625
INFO:root:Train (Epoch 52): Loss/seq after 00150 batchs: 1323.0943603515625
INFO:root:Train (Epoch 52): Loss/seq after 00200 batchs: 1437.3099365234375
INFO:root:Train (Epoch 52): Loss/seq after 00250 batchs: 1544.6995849609375
INFO:root:Train (Epoch 52): Loss/seq after 00300 batchs: 1469.08837890625
INFO:root:Train (Epoch 52): Loss/seq after 00350 batchs: 1370.366943359375
INFO:root:Train (Epoch 52): Loss/seq after 00400 batchs: 1407.7142333984375
INFO:root:Train (Epoch 52): Loss/seq after 00450 batchs: 1348.102783203125
INFO:root:Train (Epoch 52): Loss/seq after 00500 batchs: 1344.33056640625
INFO:root:Train (Epoch 52): Loss/seq after 00550 batchs: 1288.25830078125
INFO:root:Train (Epoch 52): Loss/seq after 00600 batchs: 1253.2015380859375
INFO:root:Train (Epoch 52): Loss/seq after 00650 batchs: 1325.8768310546875
INFO:root:Train (Epoch 52): Loss/seq after 00700 batchs: 1420.9791259765625
INFO:root:Train (Epoch 52): Loss/seq after 00750 batchs: 1459.512939453125
INFO:root:Train (Epoch 52): Loss/seq after 00800 batchs: 1436.25537109375
INFO:root:Train (Epoch 52): Loss/seq after 00850 batchs: 1399.489013671875
INFO:root:Train (Epoch 52): Loss/seq after 00900 batchs: 1397.548828125
INFO:root:Train (Epoch 52): Loss/seq after 00950 batchs: 1480.18994140625
INFO:root:Train (Epoch 52): Loss/seq after 01000 batchs: 1477.0040283203125
INFO:root:Train (Epoch 52): Loss/seq after 01050 batchs: 1445.0654296875
INFO:root:Train (Epoch 52): Loss/seq after 01100 batchs: 1430.637451171875
INFO:root:Train (Epoch 52): Loss/seq after 01150 batchs: 1409.194091796875
INFO:root:Train (Epoch 52): Loss/seq after 01200 batchs: 1393.114013671875
INFO:root:Train (Epoch 52): Loss/seq after 01250 batchs: 1383.1622314453125
INFO:root:Train (Epoch 52): Loss/seq after 01300 batchs: 1400.1317138671875
INFO:root:Train (Epoch 52): Loss/seq after 01350 batchs: 1404.7943115234375
INFO:root:Train (Epoch 52): Loss/seq after 01400 batchs: 1451.6951904296875
INFO:root:Train (Epoch 52): Loss/seq after 01450 batchs: 1436.111328125
INFO:root:Train (Epoch 52): Loss/seq after 01500 batchs: 1422.8089599609375
INFO:root:Train (Epoch 52): Loss/seq after 01550 batchs: 1415.6641845703125
INFO:root:Train (Epoch 52): Loss/seq after 01600 batchs: 1394.8074951171875
INFO:root:Train (Epoch 52): Loss/seq after 01650 batchs: 1378.95654296875
INFO:root:Train (Epoch 52): Loss/seq after 01700 batchs: 1366.3572998046875
INFO:root:Train (Epoch 52): Loss/seq after 01750 batchs: 1352.5069580078125
INFO:root:Train (Epoch 52): Loss/seq after 01800 batchs: 1336.089599609375
INFO:root:Train (Epoch 52): Loss/seq after 01850 batchs: 1320.2725830078125
INFO:root:Train (Epoch 52): Loss/seq after 01900 batchs: 1313.1533203125
INFO:root:Train (Epoch 52): Loss/seq after 01950 batchs: 1302.146728515625
INFO:root:Train (Epoch 52): Loss/seq after 02000 batchs: 1290.687255859375
INFO:root:Train (Epoch 52): Loss/seq after 02050 batchs: 1280.15234375
INFO:root:Train (Epoch 52): Loss/seq after 02100 batchs: 1267.3194580078125
INFO:root:Train (Epoch 52): Loss/seq after 02150 batchs: 1255.3251953125
INFO:root:Train (Epoch 52): Loss/seq after 02200 batchs: 1242.9644775390625
INFO:root:Train (Epoch 52): Loss/seq after 02250 batchs: 1239.8367919921875
INFO:root:Train (Epoch 52): Loss/seq after 02300 batchs: 1241.0875244140625
INFO:root:Train (Epoch 52): Loss/seq after 02350 batchs: 1229.68212890625
INFO:root:Train (Epoch 52): Loss/seq after 02400 batchs: 1223.9556884765625
INFO:root:Train (Epoch 52): Loss/seq after 02450 batchs: 1210.383056640625
INFO:root:Train (Epoch 52): Loss/seq after 02500 batchs: 1193.3135986328125
INFO:root:Train (Epoch 52): Loss/seq after 02550 batchs: 1180.800537109375
INFO:root:Train (Epoch 52): Loss/seq after 02600 batchs: 1177.9027099609375
INFO:root:Train (Epoch 52): Loss/seq after 02650 batchs: 1172.645751953125
INFO:root:Train (Epoch 52): Loss/seq after 02700 batchs: 1167.904052734375
INFO:root:Train (Epoch 52): Loss/seq after 02750 batchs: 1195.731201171875
INFO:root:Train (Epoch 52): Loss/seq after 02800 batchs: 1200.0684814453125
INFO:root:Train (Epoch 52): Loss/seq after 02850 batchs: 1194.7938232421875
INFO:root:Train (Epoch 52): Loss/seq after 02900 batchs: 1191.561279296875
INFO:root:Train (Epoch 52): Loss/seq after 02950 batchs: 1183.168701171875
INFO:root:Train (Epoch 52): Loss/seq after 03000 batchs: 1181.3626708984375
INFO:root:Train (Epoch 52): Loss/seq after 03050 batchs: 1183.71240234375
INFO:root:Train (Epoch 52): Loss/seq after 03100 batchs: 1194.046875
INFO:root:Train (Epoch 52): Loss/seq after 03150 batchs: 1210.8331298828125
INFO:root:Train (Epoch 52): Loss/seq after 03200 batchs: 1225.3492431640625
INFO:root:Train (Epoch 52): Loss/seq after 03250 batchs: 1239.18798828125
INFO:root:Train (Epoch 52): Loss/seq after 03300 batchs: 1237.6536865234375
INFO:root:Train (Epoch 52): Loss/seq after 03350 batchs: 1236.9522705078125
INFO:root:Train (Epoch 52): Loss/seq after 03400 batchs: 1228.0430908203125
INFO:root:Train (Epoch 52): Loss/seq after 03450 batchs: 1219.8343505859375
INFO:root:Train (Epoch 52): Loss/seq after 03500 batchs: 1217.7652587890625
INFO:root:Train (Epoch 52): Loss/seq after 03550 batchs: 1210.0494384765625
INFO:root:Train (Epoch 52): Loss/seq after 03600 batchs: 1214.8909912109375
INFO:root:Train (Epoch 52): Loss/seq after 03650 batchs: 1208.123779296875
INFO:root:Train (Epoch 52): Loss/seq after 03700 batchs: 1206.8209228515625
INFO:root:Train (Epoch 52): Loss/seq after 03750 batchs: 1206.6640625
INFO:root:Train (Epoch 52): Loss/seq after 03800 batchs: 1199.604736328125
INFO:root:Train (Epoch 52): Loss/seq after 03850 batchs: 1194.9246826171875
INFO:root:Train (Epoch 52): Loss/seq after 03900 batchs: 1200.95263671875
INFO:root:Train (Epoch 52): Loss/seq after 03950 batchs: 1208.40234375
INFO:root:Train (Epoch 52): Loss/seq after 04000 batchs: 1199.5384521484375
INFO:root:Train (Epoch 52): Loss/seq after 04050 batchs: 1191.65478515625
INFO:root:Train (Epoch 52): Loss/seq after 04100 batchs: 1185.0760498046875
INFO:root:Train (Epoch 52): Loss/seq after 04150 batchs: 1179.4039306640625
INFO:root:Train (Epoch 52): Loss/seq after 04200 batchs: 1173.2083740234375
INFO:root:Train (Epoch 52): Loss/seq after 04250 batchs: 1168.666748046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 52): Loss/seq after 00000 batches: 901.7874755859375
INFO:root:# Valid (Epoch 52): Loss/seq after 00050 batches: 1105.722412109375
INFO:root:# Valid (Epoch 52): Loss/seq after 00100 batches: 1391.883544921875
INFO:root:# Valid (Epoch 52): Loss/seq after 00150 batches: 1109.5179443359375
INFO:root:# Valid (Epoch 52): Loss/seq after 00200 batches: 996.5175170898438
INFO:root:Artifacts: Make stick videos for epoch 52
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_52_on_20220423_005424.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_52_index_1512_on_20220423_005424.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 53): Loss/seq after 00000 batchs: 2430.742431640625
INFO:root:Train (Epoch 53): Loss/seq after 00050 batchs: 1566.7269287109375
INFO:root:Train (Epoch 53): Loss/seq after 00100 batchs: 1473.8607177734375
INFO:root:Train (Epoch 53): Loss/seq after 00150 batchs: 1297.9154052734375
INFO:root:Train (Epoch 53): Loss/seq after 00200 batchs: 1412.969482421875
INFO:root:Train (Epoch 53): Loss/seq after 00250 batchs: 1525.783935546875
INFO:root:Train (Epoch 53): Loss/seq after 00300 batchs: 1452.800537109375
INFO:root:Train (Epoch 53): Loss/seq after 00350 batchs: 1354.90380859375
INFO:root:Train (Epoch 53): Loss/seq after 00400 batchs: 1391.8353271484375
INFO:root:Train (Epoch 53): Loss/seq after 00450 batchs: 1333.6285400390625
INFO:root:Train (Epoch 53): Loss/seq after 00500 batchs: 1328.1756591796875
INFO:root:Train (Epoch 53): Loss/seq after 00550 batchs: 1272.82861328125
INFO:root:Train (Epoch 53): Loss/seq after 00600 batchs: 1238.6146240234375
INFO:root:Train (Epoch 53): Loss/seq after 00650 batchs: 1312.983642578125
INFO:root:Train (Epoch 53): Loss/seq after 00700 batchs: 1409.2462158203125
INFO:root:Train (Epoch 53): Loss/seq after 00750 batchs: 1448.085693359375
INFO:root:Train (Epoch 53): Loss/seq after 00800 batchs: 1425.0125732421875
INFO:root:Train (Epoch 53): Loss/seq after 00850 batchs: 1388.8043212890625
INFO:root:Train (Epoch 53): Loss/seq after 00900 batchs: 1385.92236328125
INFO:root:Train (Epoch 53): Loss/seq after 00950 batchs: 1470.704345703125
INFO:root:Train (Epoch 53): Loss/seq after 01000 batchs: 1467.8585205078125
INFO:root:Train (Epoch 53): Loss/seq after 01050 batchs: 1437.5557861328125
INFO:root:Train (Epoch 53): Loss/seq after 01100 batchs: 1422.9072265625
INFO:root:Train (Epoch 53): Loss/seq after 01150 batchs: 1401.0517578125
INFO:root:Train (Epoch 53): Loss/seq after 01200 batchs: 1384.60693359375
INFO:root:Train (Epoch 53): Loss/seq after 01250 batchs: 1375.060302734375
INFO:root:Train (Epoch 53): Loss/seq after 01300 batchs: 1392.4056396484375
INFO:root:Train (Epoch 53): Loss/seq after 01350 batchs: 1397.4122314453125
INFO:root:Train (Epoch 53): Loss/seq after 01400 batchs: 1444.84423828125
INFO:root:Train (Epoch 53): Loss/seq after 01450 batchs: 1429.575927734375
INFO:root:Train (Epoch 53): Loss/seq after 01500 batchs: 1416.242431640625
INFO:root:Train (Epoch 53): Loss/seq after 01550 batchs: 1409.300537109375
INFO:root:Train (Epoch 53): Loss/seq after 01600 batchs: 1388.79833984375
INFO:root:Train (Epoch 53): Loss/seq after 01650 batchs: 1372.3385009765625
INFO:root:Train (Epoch 53): Loss/seq after 01700 batchs: 1359.6959228515625
INFO:root:Train (Epoch 53): Loss/seq after 01750 batchs: 1345.74609375
INFO:root:Train (Epoch 53): Loss/seq after 01800 batchs: 1329.5712890625
INFO:root:Train (Epoch 53): Loss/seq after 01850 batchs: 1313.36181640625
INFO:root:Train (Epoch 53): Loss/seq after 01900 batchs: 1306.44189453125
INFO:root:Train (Epoch 53): Loss/seq after 01950 batchs: 1296.5623779296875
INFO:root:Train (Epoch 53): Loss/seq after 02000 batchs: 1285.253662109375
INFO:root:Train (Epoch 53): Loss/seq after 02050 batchs: 1274.729736328125
INFO:root:Train (Epoch 53): Loss/seq after 02100 batchs: 1261.7996826171875
INFO:root:Train (Epoch 53): Loss/seq after 02150 batchs: 1249.719482421875
INFO:root:Train (Epoch 53): Loss/seq after 02200 batchs: 1237.4227294921875
INFO:root:Train (Epoch 53): Loss/seq after 02250 batchs: 1234.03515625
INFO:root:Train (Epoch 53): Loss/seq after 02300 batchs: 1235.5528564453125
INFO:root:Train (Epoch 53): Loss/seq after 02350 batchs: 1223.6710205078125
INFO:root:Train (Epoch 53): Loss/seq after 02400 batchs: 1217.909423828125
INFO:root:Train (Epoch 53): Loss/seq after 02450 batchs: 1204.3812255859375
INFO:root:Train (Epoch 53): Loss/seq after 02500 batchs: 1187.419677734375
INFO:root:Train (Epoch 53): Loss/seq after 02550 batchs: 1174.7725830078125
INFO:root:Train (Epoch 53): Loss/seq after 02600 batchs: 1171.8394775390625
INFO:root:Train (Epoch 53): Loss/seq after 02650 batchs: 1166.4991455078125
INFO:root:Train (Epoch 53): Loss/seq after 02700 batchs: 1161.8228759765625
INFO:root:Train (Epoch 53): Loss/seq after 02750 batchs: 1190.2520751953125
INFO:root:Train (Epoch 53): Loss/seq after 02800 batchs: 1194.1329345703125
INFO:root:Train (Epoch 53): Loss/seq after 02850 batchs: 1188.79150390625
INFO:root:Train (Epoch 53): Loss/seq after 02900 batchs: 1186.6278076171875
INFO:root:Train (Epoch 53): Loss/seq after 02950 batchs: 1178.240966796875
INFO:root:Train (Epoch 53): Loss/seq after 03000 batchs: 1176.468017578125
INFO:root:Train (Epoch 53): Loss/seq after 03050 batchs: 1178.8052978515625
INFO:root:Train (Epoch 53): Loss/seq after 03100 batchs: 1188.302490234375
INFO:root:Train (Epoch 53): Loss/seq after 03150 batchs: 1204.40869140625
INFO:root:Train (Epoch 53): Loss/seq after 03200 batchs: 1218.923583984375
INFO:root:Train (Epoch 53): Loss/seq after 03250 batchs: 1232.7232666015625
INFO:root:Train (Epoch 53): Loss/seq after 03300 batchs: 1230.5877685546875
INFO:root:Train (Epoch 53): Loss/seq after 03350 batchs: 1230.35986328125
INFO:root:Train (Epoch 53): Loss/seq after 03400 batchs: 1222.0804443359375
INFO:root:Train (Epoch 53): Loss/seq after 03450 batchs: 1215.38916015625
INFO:root:Train (Epoch 53): Loss/seq after 03500 batchs: 1213.4154052734375
INFO:root:Train (Epoch 53): Loss/seq after 03550 batchs: 1205.4405517578125
INFO:root:Train (Epoch 53): Loss/seq after 03600 batchs: 1210.0
INFO:root:Train (Epoch 53): Loss/seq after 03650 batchs: 1202.8857421875
INFO:root:Train (Epoch 53): Loss/seq after 03700 batchs: 1201.185791015625
INFO:root:Train (Epoch 53): Loss/seq after 03750 batchs: 1201.093505859375
INFO:root:Train (Epoch 53): Loss/seq after 03800 batchs: 1194.08837890625
INFO:root:Train (Epoch 53): Loss/seq after 03850 batchs: 1189.2977294921875
INFO:root:Train (Epoch 53): Loss/seq after 03900 batchs: 1195.1070556640625
INFO:root:Train (Epoch 53): Loss/seq after 03950 batchs: 1202.659423828125
INFO:root:Train (Epoch 53): Loss/seq after 04000 batchs: 1193.859130859375
INFO:root:Train (Epoch 53): Loss/seq after 04050 batchs: 1186.0252685546875
INFO:root:Train (Epoch 53): Loss/seq after 04100 batchs: 1179.389892578125
INFO:root:Train (Epoch 53): Loss/seq after 04150 batchs: 1173.614990234375
INFO:root:Train (Epoch 53): Loss/seq after 04200 batchs: 1167.5201416015625
INFO:root:Train (Epoch 53): Loss/seq after 04250 batchs: 1162.925048828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 53): Loss/seq after 00000 batches: 887.9143676757812
INFO:root:# Valid (Epoch 53): Loss/seq after 00050 batches: 1104.80078125
INFO:root:# Valid (Epoch 53): Loss/seq after 00100 batches: 1390.8262939453125
INFO:root:# Valid (Epoch 53): Loss/seq after 00150 batches: 1107.4493408203125
INFO:root:# Valid (Epoch 53): Loss/seq after 00200 batches: 995.58056640625
INFO:root:Artifacts: Make stick videos for epoch 53
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_53_on_20220423_005925.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_53_index_337_on_20220423_005925.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 54): Loss/seq after 00000 batchs: 2431.734130859375
INFO:root:Train (Epoch 54): Loss/seq after 00050 batchs: 1574.7894287109375
INFO:root:Train (Epoch 54): Loss/seq after 00100 batchs: 1473.77197265625
INFO:root:Train (Epoch 54): Loss/seq after 00150 batchs: 1301.482666015625
INFO:root:Train (Epoch 54): Loss/seq after 00200 batchs: 1421.530029296875
INFO:root:Train (Epoch 54): Loss/seq after 00250 batchs: 1529.94091796875
INFO:root:Train (Epoch 54): Loss/seq after 00300 batchs: 1456.080078125
INFO:root:Train (Epoch 54): Loss/seq after 00350 batchs: 1361.376708984375
INFO:root:Train (Epoch 54): Loss/seq after 00400 batchs: 1397.7452392578125
INFO:root:Train (Epoch 54): Loss/seq after 00450 batchs: 1339.4349365234375
INFO:root:Train (Epoch 54): Loss/seq after 00500 batchs: 1340.3128662109375
INFO:root:Train (Epoch 54): Loss/seq after 00550 batchs: 1284.5465087890625
INFO:root:Train (Epoch 54): Loss/seq after 00600 batchs: 1251.34423828125
INFO:root:Train (Epoch 54): Loss/seq after 00650 batchs: 1324.1221923828125
INFO:root:Train (Epoch 54): Loss/seq after 00700 batchs: 1420.72802734375
INFO:root:Train (Epoch 54): Loss/seq after 00750 batchs: 1459.4405517578125
INFO:root:Train (Epoch 54): Loss/seq after 00800 batchs: 1439.3037109375
INFO:root:Train (Epoch 54): Loss/seq after 00850 batchs: 1402.611572265625
INFO:root:Train (Epoch 54): Loss/seq after 00900 batchs: 1400.706298828125
INFO:root:Train (Epoch 54): Loss/seq after 00950 batchs: 1483.4996337890625
INFO:root:Train (Epoch 54): Loss/seq after 01000 batchs: 1479.4266357421875
INFO:root:Train (Epoch 54): Loss/seq after 01050 batchs: 1448.55615234375
INFO:root:Train (Epoch 54): Loss/seq after 01100 batchs: 1434.27978515625
INFO:root:Train (Epoch 54): Loss/seq after 01150 batchs: 1412.47802734375
INFO:root:Train (Epoch 54): Loss/seq after 01200 batchs: 1395.4609375
INFO:root:Train (Epoch 54): Loss/seq after 01250 batchs: 1385.1593017578125
INFO:root:Train (Epoch 54): Loss/seq after 01300 batchs: 1402.2271728515625
INFO:root:Train (Epoch 54): Loss/seq after 01350 batchs: 1406.8585205078125
INFO:root:Train (Epoch 54): Loss/seq after 01400 batchs: 1454.358642578125
INFO:root:Train (Epoch 54): Loss/seq after 01450 batchs: 1438.547119140625
INFO:root:Train (Epoch 54): Loss/seq after 01500 batchs: 1424.9552001953125
INFO:root:Train (Epoch 54): Loss/seq after 01550 batchs: 1417.0628662109375
INFO:root:Train (Epoch 54): Loss/seq after 01600 batchs: 1396.291748046875
INFO:root:Train (Epoch 54): Loss/seq after 01650 batchs: 1380.08642578125
INFO:root:Train (Epoch 54): Loss/seq after 01700 batchs: 1367.2003173828125
INFO:root:Train (Epoch 54): Loss/seq after 01750 batchs: 1353.0994873046875
INFO:root:Train (Epoch 54): Loss/seq after 01800 batchs: 1336.5052490234375
INFO:root:Train (Epoch 54): Loss/seq after 01850 batchs: 1320.2451171875
INFO:root:Train (Epoch 54): Loss/seq after 01900 batchs: 1313.537353515625
INFO:root:Train (Epoch 54): Loss/seq after 01950 batchs: 1302.5477294921875
INFO:root:Train (Epoch 54): Loss/seq after 02000 batchs: 1291.2159423828125
INFO:root:Train (Epoch 54): Loss/seq after 02050 batchs: 1280.463623046875
INFO:root:Train (Epoch 54): Loss/seq after 02100 batchs: 1267.4954833984375
INFO:root:Train (Epoch 54): Loss/seq after 02150 batchs: 1255.3759765625
INFO:root:Train (Epoch 54): Loss/seq after 02200 batchs: 1242.9508056640625
INFO:root:Train (Epoch 54): Loss/seq after 02250 batchs: 1240.94384765625
INFO:root:Train (Epoch 54): Loss/seq after 02300 batchs: 1242.7965087890625
INFO:root:Train (Epoch 54): Loss/seq after 02350 batchs: 1232.4215087890625
INFO:root:Train (Epoch 54): Loss/seq after 02400 batchs: 1226.67529296875
INFO:root:Train (Epoch 54): Loss/seq after 02450 batchs: 1213.084228515625
INFO:root:Train (Epoch 54): Loss/seq after 02500 batchs: 1195.92578125
INFO:root:Train (Epoch 54): Loss/seq after 02550 batchs: 1183.4228515625
INFO:root:Train (Epoch 54): Loss/seq after 02600 batchs: 1180.2144775390625
INFO:root:Train (Epoch 54): Loss/seq after 02650 batchs: 1174.7127685546875
INFO:root:Train (Epoch 54): Loss/seq after 02700 batchs: 1169.873046875
INFO:root:Train (Epoch 54): Loss/seq after 02750 batchs: 1198.542236328125
INFO:root:Train (Epoch 54): Loss/seq after 02800 batchs: 1203.027099609375
INFO:root:Train (Epoch 54): Loss/seq after 02850 batchs: 1197.7655029296875
INFO:root:Train (Epoch 54): Loss/seq after 02900 batchs: 1195.0899658203125
INFO:root:Train (Epoch 54): Loss/seq after 02950 batchs: 1186.988525390625
INFO:root:Train (Epoch 54): Loss/seq after 03000 batchs: 1185.111083984375
INFO:root:Train (Epoch 54): Loss/seq after 03050 batchs: 1187.3455810546875
INFO:root:Train (Epoch 54): Loss/seq after 03100 batchs: 1197.28662109375
INFO:root:Train (Epoch 54): Loss/seq after 03150 batchs: 1213.164306640625
INFO:root:Train (Epoch 54): Loss/seq after 03200 batchs: 1227.6505126953125
INFO:root:Train (Epoch 54): Loss/seq after 03250 batchs: 1241.4984130859375
INFO:root:Train (Epoch 54): Loss/seq after 03300 batchs: 1238.18115234375
INFO:root:Train (Epoch 54): Loss/seq after 03350 batchs: 1236.4351806640625
INFO:root:Train (Epoch 54): Loss/seq after 03400 batchs: 1227.5472412109375
INFO:root:Train (Epoch 54): Loss/seq after 03450 batchs: 1219.3297119140625
INFO:root:Train (Epoch 54): Loss/seq after 03500 batchs: 1216.646484375
INFO:root:Train (Epoch 54): Loss/seq after 03550 batchs: 1208.2025146484375
INFO:root:Train (Epoch 54): Loss/seq after 03600 batchs: 1212.453369140625
INFO:root:Train (Epoch 54): Loss/seq after 03650 batchs: 1206.16796875
INFO:root:Train (Epoch 54): Loss/seq after 03700 batchs: 1204.845947265625
INFO:root:Train (Epoch 54): Loss/seq after 03750 batchs: 1204.7718505859375
INFO:root:Train (Epoch 54): Loss/seq after 03800 batchs: 1197.6767578125
INFO:root:Train (Epoch 54): Loss/seq after 03850 batchs: 1192.8955078125
INFO:root:Train (Epoch 54): Loss/seq after 03900 batchs: 1198.6663818359375
INFO:root:Train (Epoch 54): Loss/seq after 03950 batchs: 1206.484130859375
INFO:root:Train (Epoch 54): Loss/seq after 04000 batchs: 1197.610107421875
INFO:root:Train (Epoch 54): Loss/seq after 04050 batchs: 1189.7149658203125
INFO:root:Train (Epoch 54): Loss/seq after 04100 batchs: 1183.102294921875
INFO:root:Train (Epoch 54): Loss/seq after 04150 batchs: 1177.3599853515625
INFO:root:Train (Epoch 54): Loss/seq after 04200 batchs: 1171.1741943359375
INFO:root:Train (Epoch 54): Loss/seq after 04250 batchs: 1166.5732421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 54): Loss/seq after 00000 batches: 891.2814331054688
INFO:root:# Valid (Epoch 54): Loss/seq after 00050 batches: 1113.6348876953125
INFO:root:# Valid (Epoch 54): Loss/seq after 00100 batches: 1403.2247314453125
INFO:root:# Valid (Epoch 54): Loss/seq after 00150 batches: 1125.420166015625
INFO:root:# Valid (Epoch 54): Loss/seq after 00200 batches: 1017.0404052734375
INFO:root:Artifacts: Make stick videos for epoch 54
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_54_on_20220423_010418.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_54_index_1010_on_20220423_010418.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 55): Loss/seq after 00000 batchs: 2527.989990234375
INFO:root:Train (Epoch 55): Loss/seq after 00050 batchs: 1560.5762939453125
INFO:root:Train (Epoch 55): Loss/seq after 00100 batchs: 1460.947021484375
INFO:root:Train (Epoch 55): Loss/seq after 00150 batchs: 1286.9512939453125
INFO:root:Train (Epoch 55): Loss/seq after 00200 batchs: 1410.5732421875
INFO:root:Train (Epoch 55): Loss/seq after 00250 batchs: 1527.5791015625
INFO:root:Train (Epoch 55): Loss/seq after 00300 batchs: 1454.0423583984375
INFO:root:Train (Epoch 55): Loss/seq after 00350 batchs: 1361.8046875
INFO:root:Train (Epoch 55): Loss/seq after 00400 batchs: 1402.115966796875
INFO:root:Train (Epoch 55): Loss/seq after 00450 batchs: 1343.5257568359375
INFO:root:Train (Epoch 55): Loss/seq after 00500 batchs: 1343.0477294921875
INFO:root:Train (Epoch 55): Loss/seq after 00550 batchs: 1287.2374267578125
INFO:root:Train (Epoch 55): Loss/seq after 00600 batchs: 1252.9847412109375
INFO:root:Train (Epoch 55): Loss/seq after 00650 batchs: 1325.5875244140625
INFO:root:Train (Epoch 55): Loss/seq after 00700 batchs: 1420.4686279296875
INFO:root:Train (Epoch 55): Loss/seq after 00750 batchs: 1459.30908203125
INFO:root:Train (Epoch 55): Loss/seq after 00800 batchs: 1434.811767578125
INFO:root:Train (Epoch 55): Loss/seq after 00850 batchs: 1397.03564453125
INFO:root:Train (Epoch 55): Loss/seq after 00900 batchs: 1395.3280029296875
INFO:root:Train (Epoch 55): Loss/seq after 00950 batchs: 1478.7535400390625
INFO:root:Train (Epoch 55): Loss/seq after 01000 batchs: 1474.923828125
INFO:root:Train (Epoch 55): Loss/seq after 01050 batchs: 1442.99169921875
INFO:root:Train (Epoch 55): Loss/seq after 01100 batchs: 1428.8037109375
INFO:root:Train (Epoch 55): Loss/seq after 01150 batchs: 1407.742919921875
INFO:root:Train (Epoch 55): Loss/seq after 01200 batchs: 1391.5968017578125
INFO:root:Train (Epoch 55): Loss/seq after 01250 batchs: 1382.0501708984375
INFO:root:Train (Epoch 55): Loss/seq after 01300 batchs: 1399.1640625
INFO:root:Train (Epoch 55): Loss/seq after 01350 batchs: 1403.8902587890625
INFO:root:Train (Epoch 55): Loss/seq after 01400 batchs: 1451.781005859375
INFO:root:Train (Epoch 55): Loss/seq after 01450 batchs: 1435.876220703125
INFO:root:Train (Epoch 55): Loss/seq after 01500 batchs: 1422.4232177734375
INFO:root:Train (Epoch 55): Loss/seq after 01550 batchs: 1416.3138427734375
INFO:root:Train (Epoch 55): Loss/seq after 01600 batchs: 1395.7633056640625
INFO:root:Train (Epoch 55): Loss/seq after 01650 batchs: 1379.7294921875
INFO:root:Train (Epoch 55): Loss/seq after 01700 batchs: 1367.0496826171875
INFO:root:Train (Epoch 55): Loss/seq after 01750 batchs: 1352.925537109375
INFO:root:Train (Epoch 55): Loss/seq after 01800 batchs: 1336.41552734375
INFO:root:Train (Epoch 55): Loss/seq after 01850 batchs: 1320.080078125
INFO:root:Train (Epoch 55): Loss/seq after 01900 batchs: 1312.5072021484375
INFO:root:Train (Epoch 55): Loss/seq after 01950 batchs: 1301.1025390625
INFO:root:Train (Epoch 55): Loss/seq after 02000 batchs: 1289.66552734375
INFO:root:Train (Epoch 55): Loss/seq after 02050 batchs: 1278.783447265625
INFO:root:Train (Epoch 55): Loss/seq after 02100 batchs: 1265.830810546875
INFO:root:Train (Epoch 55): Loss/seq after 02150 batchs: 1253.774169921875
INFO:root:Train (Epoch 55): Loss/seq after 02200 batchs: 1241.353759765625
INFO:root:Train (Epoch 55): Loss/seq after 02250 batchs: 1237.910888671875
INFO:root:Train (Epoch 55): Loss/seq after 02300 batchs: 1238.94970703125
INFO:root:Train (Epoch 55): Loss/seq after 02350 batchs: 1226.744384765625
INFO:root:Train (Epoch 55): Loss/seq after 02400 batchs: 1220.9959716796875
INFO:root:Train (Epoch 55): Loss/seq after 02450 batchs: 1207.4425048828125
INFO:root:Train (Epoch 55): Loss/seq after 02500 batchs: 1190.41015625
INFO:root:Train (Epoch 55): Loss/seq after 02550 batchs: 1177.6329345703125
INFO:root:Train (Epoch 55): Loss/seq after 02600 batchs: 1174.77587890625
INFO:root:Train (Epoch 55): Loss/seq after 02650 batchs: 1169.525390625
INFO:root:Train (Epoch 55): Loss/seq after 02700 batchs: 1164.692626953125
INFO:root:Train (Epoch 55): Loss/seq after 02750 batchs: 1191.8846435546875
INFO:root:Train (Epoch 55): Loss/seq after 02800 batchs: 1196.2724609375
INFO:root:Train (Epoch 55): Loss/seq after 02850 batchs: 1191.3414306640625
INFO:root:Train (Epoch 55): Loss/seq after 02900 batchs: 1188.9195556640625
INFO:root:Train (Epoch 55): Loss/seq after 02950 batchs: 1180.5166015625
INFO:root:Train (Epoch 55): Loss/seq after 03000 batchs: 1178.693115234375
INFO:root:Train (Epoch 55): Loss/seq after 03050 batchs: 1181.0118408203125
INFO:root:Train (Epoch 55): Loss/seq after 03100 batchs: 1191.275634765625
INFO:root:Train (Epoch 55): Loss/seq after 03150 batchs: 1208.017822265625
INFO:root:Train (Epoch 55): Loss/seq after 03200 batchs: 1222.7215576171875
INFO:root:Train (Epoch 55): Loss/seq after 03250 batchs: 1236.7303466796875
INFO:root:Train (Epoch 55): Loss/seq after 03300 batchs: 1234.6322021484375
INFO:root:Train (Epoch 55): Loss/seq after 03350 batchs: 1233.1199951171875
INFO:root:Train (Epoch 55): Loss/seq after 03400 batchs: 1224.32568359375
INFO:root:Train (Epoch 55): Loss/seq after 03450 batchs: 1216.46630859375
INFO:root:Train (Epoch 55): Loss/seq after 03500 batchs: 1214.2193603515625
INFO:root:Train (Epoch 55): Loss/seq after 03550 batchs: 1205.76025390625
INFO:root:Train (Epoch 55): Loss/seq after 03600 batchs: 1209.86669921875
INFO:root:Train (Epoch 55): Loss/seq after 03650 batchs: 1202.7435302734375
INFO:root:Train (Epoch 55): Loss/seq after 03700 batchs: 1201.093017578125
INFO:root:Train (Epoch 55): Loss/seq after 03750 batchs: 1201.0078125
INFO:root:Train (Epoch 55): Loss/seq after 03800 batchs: 1193.9503173828125
INFO:root:Train (Epoch 55): Loss/seq after 03850 batchs: 1189.1927490234375
INFO:root:Train (Epoch 55): Loss/seq after 03900 batchs: 1194.7811279296875
INFO:root:Train (Epoch 55): Loss/seq after 03950 batchs: 1202.6378173828125
INFO:root:Train (Epoch 55): Loss/seq after 04000 batchs: 1193.8203125
INFO:root:Train (Epoch 55): Loss/seq after 04050 batchs: 1185.95751953125
INFO:root:Train (Epoch 55): Loss/seq after 04100 batchs: 1179.345458984375
INFO:root:Train (Epoch 55): Loss/seq after 04150 batchs: 1173.5496826171875
INFO:root:Train (Epoch 55): Loss/seq after 04200 batchs: 1167.6307373046875
INFO:root:Train (Epoch 55): Loss/seq after 04250 batchs: 1163.15673828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 55): Loss/seq after 00000 batches: 881.3818359375
INFO:root:# Valid (Epoch 55): Loss/seq after 00050 batches: 1094.293701171875
INFO:root:# Valid (Epoch 55): Loss/seq after 00100 batches: 1380.641357421875
INFO:root:# Valid (Epoch 55): Loss/seq after 00150 batches: 1099.423095703125
INFO:root:# Valid (Epoch 55): Loss/seq after 00200 batches: 988.4246215820312
INFO:root:Artifacts: Make stick videos for epoch 55
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_55_on_20220423_010902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_55_index_988_on_20220423_010902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 56): Loss/seq after 00000 batchs: 2459.124755859375
INFO:root:Train (Epoch 56): Loss/seq after 00050 batchs: 1557.403564453125
INFO:root:Train (Epoch 56): Loss/seq after 00100 batchs: 1450.24658203125
INFO:root:Train (Epoch 56): Loss/seq after 00150 batchs: 1276.260986328125
INFO:root:Train (Epoch 56): Loss/seq after 00200 batchs: 1396.09326171875
INFO:root:Train (Epoch 56): Loss/seq after 00250 batchs: 1515.6126708984375
INFO:root:Train (Epoch 56): Loss/seq after 00300 batchs: 1443.4632568359375
INFO:root:Train (Epoch 56): Loss/seq after 00350 batchs: 1346.9339599609375
INFO:root:Train (Epoch 56): Loss/seq after 00400 batchs: 1384.68115234375
INFO:root:Train (Epoch 56): Loss/seq after 00450 batchs: 1327.1309814453125
INFO:root:Train (Epoch 56): Loss/seq after 00500 batchs: 1319.86669921875
INFO:root:Train (Epoch 56): Loss/seq after 00550 batchs: 1266.512451171875
INFO:root:Train (Epoch 56): Loss/seq after 00600 batchs: 1232.4310302734375
INFO:root:Train (Epoch 56): Loss/seq after 00650 batchs: 1306.752197265625
INFO:root:Train (Epoch 56): Loss/seq after 00700 batchs: 1403.7701416015625
INFO:root:Train (Epoch 56): Loss/seq after 00750 batchs: 1443.5166015625
INFO:root:Train (Epoch 56): Loss/seq after 00800 batchs: 1421.73388671875
INFO:root:Train (Epoch 56): Loss/seq after 00850 batchs: 1384.88720703125
INFO:root:Train (Epoch 56): Loss/seq after 00900 batchs: 1382.3062744140625
INFO:root:Train (Epoch 56): Loss/seq after 00950 batchs: 1466.7396240234375
INFO:root:Train (Epoch 56): Loss/seq after 01000 batchs: 1465.6129150390625
INFO:root:Train (Epoch 56): Loss/seq after 01050 batchs: 1436.17822265625
INFO:root:Train (Epoch 56): Loss/seq after 01100 batchs: 1421.9149169921875
INFO:root:Train (Epoch 56): Loss/seq after 01150 batchs: 1400.69189453125
INFO:root:Train (Epoch 56): Loss/seq after 01200 batchs: 1384.3140869140625
INFO:root:Train (Epoch 56): Loss/seq after 01250 batchs: 1374.1771240234375
INFO:root:Train (Epoch 56): Loss/seq after 01300 batchs: 1391.4708251953125
INFO:root:Train (Epoch 56): Loss/seq after 01350 batchs: 1396.4354248046875
INFO:root:Train (Epoch 56): Loss/seq after 01400 batchs: 1443.97216796875
INFO:root:Train (Epoch 56): Loss/seq after 01450 batchs: 1429.0931396484375
INFO:root:Train (Epoch 56): Loss/seq after 01500 batchs: 1415.8485107421875
INFO:root:Train (Epoch 56): Loss/seq after 01550 batchs: 1408.542236328125
INFO:root:Train (Epoch 56): Loss/seq after 01600 batchs: 1387.973876953125
INFO:root:Train (Epoch 56): Loss/seq after 01650 batchs: 1371.497802734375
INFO:root:Train (Epoch 56): Loss/seq after 01700 batchs: 1358.923583984375
INFO:root:Train (Epoch 56): Loss/seq after 01750 batchs: 1345.0037841796875
INFO:root:Train (Epoch 56): Loss/seq after 01800 batchs: 1328.6534423828125
INFO:root:Train (Epoch 56): Loss/seq after 01850 batchs: 1312.5897216796875
INFO:root:Train (Epoch 56): Loss/seq after 01900 batchs: 1305.7979736328125
INFO:root:Train (Epoch 56): Loss/seq after 01950 batchs: 1295.38134765625
INFO:root:Train (Epoch 56): Loss/seq after 02000 batchs: 1284.2850341796875
INFO:root:Train (Epoch 56): Loss/seq after 02050 batchs: 1273.647216796875
INFO:root:Train (Epoch 56): Loss/seq after 02100 batchs: 1260.8016357421875
INFO:root:Train (Epoch 56): Loss/seq after 02150 batchs: 1248.74169921875
INFO:root:Train (Epoch 56): Loss/seq after 02200 batchs: 1236.40771484375
INFO:root:Train (Epoch 56): Loss/seq after 02250 batchs: 1233.0972900390625
INFO:root:Train (Epoch 56): Loss/seq after 02300 batchs: 1234.4693603515625
INFO:root:Train (Epoch 56): Loss/seq after 02350 batchs: 1222.402587890625
INFO:root:Train (Epoch 56): Loss/seq after 02400 batchs: 1216.675048828125
INFO:root:Train (Epoch 56): Loss/seq after 02450 batchs: 1203.0811767578125
INFO:root:Train (Epoch 56): Loss/seq after 02500 batchs: 1186.12890625
INFO:root:Train (Epoch 56): Loss/seq after 02550 batchs: 1173.3873291015625
INFO:root:Train (Epoch 56): Loss/seq after 02600 batchs: 1170.2275390625
INFO:root:Train (Epoch 56): Loss/seq after 02650 batchs: 1164.7750244140625
INFO:root:Train (Epoch 56): Loss/seq after 02700 batchs: 1159.9957275390625
INFO:root:Train (Epoch 56): Loss/seq after 02750 batchs: 1186.28662109375
INFO:root:Train (Epoch 56): Loss/seq after 02800 batchs: 1191.1707763671875
INFO:root:Train (Epoch 56): Loss/seq after 02850 batchs: 1185.9346923828125
INFO:root:Train (Epoch 56): Loss/seq after 02900 batchs: 1182.9012451171875
INFO:root:Train (Epoch 56): Loss/seq after 02950 batchs: 1174.5352783203125
INFO:root:Train (Epoch 56): Loss/seq after 03000 batchs: 1172.8350830078125
INFO:root:Train (Epoch 56): Loss/seq after 03050 batchs: 1175.207763671875
INFO:root:Train (Epoch 56): Loss/seq after 03100 batchs: 1185.48681640625
INFO:root:Train (Epoch 56): Loss/seq after 03150 batchs: 1201.7445068359375
INFO:root:Train (Epoch 56): Loss/seq after 03200 batchs: 1216.4517822265625
INFO:root:Train (Epoch 56): Loss/seq after 03250 batchs: 1230.564453125
INFO:root:Train (Epoch 56): Loss/seq after 03300 batchs: 1228.021484375
INFO:root:Train (Epoch 56): Loss/seq after 03350 batchs: 1226.685302734375
INFO:root:Train (Epoch 56): Loss/seq after 03400 batchs: 1218.083984375
INFO:root:Train (Epoch 56): Loss/seq after 03450 batchs: 1210.23193359375
INFO:root:Train (Epoch 56): Loss/seq after 03500 batchs: 1207.693359375
INFO:root:Train (Epoch 56): Loss/seq after 03550 batchs: 1199.299560546875
INFO:root:Train (Epoch 56): Loss/seq after 03600 batchs: 1203.5421142578125
INFO:root:Train (Epoch 56): Loss/seq after 03650 batchs: 1196.359130859375
INFO:root:Train (Epoch 56): Loss/seq after 03700 batchs: 1195.0399169921875
INFO:root:Train (Epoch 56): Loss/seq after 03750 batchs: 1195.0631103515625
INFO:root:Train (Epoch 56): Loss/seq after 03800 batchs: 1188.1353759765625
INFO:root:Train (Epoch 56): Loss/seq after 03850 batchs: 1183.4888916015625
INFO:root:Train (Epoch 56): Loss/seq after 03900 batchs: 1189.0286865234375
INFO:root:Train (Epoch 56): Loss/seq after 03950 batchs: 1196.81298828125
INFO:root:Train (Epoch 56): Loss/seq after 04000 batchs: 1188.0712890625
INFO:root:Train (Epoch 56): Loss/seq after 04050 batchs: 1180.3031005859375
INFO:root:Train (Epoch 56): Loss/seq after 04100 batchs: 1173.5789794921875
INFO:root:Train (Epoch 56): Loss/seq after 04150 batchs: 1167.8140869140625
INFO:root:Train (Epoch 56): Loss/seq after 04200 batchs: 1161.90478515625
INFO:root:Train (Epoch 56): Loss/seq after 04250 batchs: 1157.4615478515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 56): Loss/seq after 00000 batches: 883.6643676757812
INFO:root:# Valid (Epoch 56): Loss/seq after 00050 batches: 1111.7413330078125
INFO:root:# Valid (Epoch 56): Loss/seq after 00100 batches: 1393.6414794921875
INFO:root:# Valid (Epoch 56): Loss/seq after 00150 batches: 1110.303955078125
INFO:root:# Valid (Epoch 56): Loss/seq after 00200 batches: 997.3621215820312
INFO:root:Artifacts: Make stick videos for epoch 56
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_56_on_20220423_011403.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_56_index_394_on_20220423_011403.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 57): Loss/seq after 00000 batchs: 2516.385009765625
INFO:root:Train (Epoch 57): Loss/seq after 00050 batchs: 1563.55126953125
INFO:root:Train (Epoch 57): Loss/seq after 00100 batchs: 1459.2060546875
INFO:root:Train (Epoch 57): Loss/seq after 00150 batchs: 1285.7923583984375
INFO:root:Train (Epoch 57): Loss/seq after 00200 batchs: 1405.505615234375
INFO:root:Train (Epoch 57): Loss/seq after 00250 batchs: 1519.828369140625
INFO:root:Train (Epoch 57): Loss/seq after 00300 batchs: 1446.59619140625
INFO:root:Train (Epoch 57): Loss/seq after 00350 batchs: 1349.3709716796875
INFO:root:Train (Epoch 57): Loss/seq after 00400 batchs: 1386.01611328125
INFO:root:Train (Epoch 57): Loss/seq after 00450 batchs: 1328.4774169921875
INFO:root:Train (Epoch 57): Loss/seq after 00500 batchs: 1323.73486328125
INFO:root:Train (Epoch 57): Loss/seq after 00550 batchs: 1269.402099609375
INFO:root:Train (Epoch 57): Loss/seq after 00600 batchs: 1235.576904296875
INFO:root:Train (Epoch 57): Loss/seq after 00650 batchs: 1309.4400634765625
INFO:root:Train (Epoch 57): Loss/seq after 00700 batchs: 1405.68359375
INFO:root:Train (Epoch 57): Loss/seq after 00750 batchs: 1443.748779296875
INFO:root:Train (Epoch 57): Loss/seq after 00800 batchs: 1419.244384765625
INFO:root:Train (Epoch 57): Loss/seq after 00850 batchs: 1382.806640625
INFO:root:Train (Epoch 57): Loss/seq after 00900 batchs: 1381.69580078125
INFO:root:Train (Epoch 57): Loss/seq after 00950 batchs: 1464.7412109375
INFO:root:Train (Epoch 57): Loss/seq after 01000 batchs: 1463.9254150390625
INFO:root:Train (Epoch 57): Loss/seq after 01050 batchs: 1434.0146484375
INFO:root:Train (Epoch 57): Loss/seq after 01100 batchs: 1420.12451171875
INFO:root:Train (Epoch 57): Loss/seq after 01150 batchs: 1398.4459228515625
INFO:root:Train (Epoch 57): Loss/seq after 01200 batchs: 1381.6451416015625
INFO:root:Train (Epoch 57): Loss/seq after 01250 batchs: 1372.2498779296875
INFO:root:Train (Epoch 57): Loss/seq after 01300 batchs: 1389.728271484375
INFO:root:Train (Epoch 57): Loss/seq after 01350 batchs: 1394.8115234375
INFO:root:Train (Epoch 57): Loss/seq after 01400 batchs: 1442.572021484375
INFO:root:Train (Epoch 57): Loss/seq after 01450 batchs: 1427.4708251953125
INFO:root:Train (Epoch 57): Loss/seq after 01500 batchs: 1414.3193359375
INFO:root:Train (Epoch 57): Loss/seq after 01550 batchs: 1406.8280029296875
INFO:root:Train (Epoch 57): Loss/seq after 01600 batchs: 1386.1910400390625
INFO:root:Train (Epoch 57): Loss/seq after 01650 batchs: 1369.6307373046875
INFO:root:Train (Epoch 57): Loss/seq after 01700 batchs: 1357.1866455078125
INFO:root:Train (Epoch 57): Loss/seq after 01750 batchs: 1343.28173828125
INFO:root:Train (Epoch 57): Loss/seq after 01800 batchs: 1327.037109375
INFO:root:Train (Epoch 57): Loss/seq after 01850 batchs: 1310.8607177734375
INFO:root:Train (Epoch 57): Loss/seq after 01900 batchs: 1304.3541259765625
INFO:root:Train (Epoch 57): Loss/seq after 01950 batchs: 1294.4383544921875
INFO:root:Train (Epoch 57): Loss/seq after 02000 batchs: 1283.3409423828125
INFO:root:Train (Epoch 57): Loss/seq after 02050 batchs: 1272.76220703125
INFO:root:Train (Epoch 57): Loss/seq after 02100 batchs: 1260.047119140625
INFO:root:Train (Epoch 57): Loss/seq after 02150 batchs: 1248.040283203125
INFO:root:Train (Epoch 57): Loss/seq after 02200 batchs: 1235.7222900390625
INFO:root:Train (Epoch 57): Loss/seq after 02250 batchs: 1232.5997314453125
INFO:root:Train (Epoch 57): Loss/seq after 02300 batchs: 1234.2122802734375
INFO:root:Train (Epoch 57): Loss/seq after 02350 batchs: 1222.420166015625
INFO:root:Train (Epoch 57): Loss/seq after 02400 batchs: 1216.6806640625
INFO:root:Train (Epoch 57): Loss/seq after 02450 batchs: 1203.266357421875
INFO:root:Train (Epoch 57): Loss/seq after 02500 batchs: 1186.3095703125
INFO:root:Train (Epoch 57): Loss/seq after 02550 batchs: 1173.5880126953125
INFO:root:Train (Epoch 57): Loss/seq after 02600 batchs: 1170.5316162109375
INFO:root:Train (Epoch 57): Loss/seq after 02650 batchs: 1165.2008056640625
INFO:root:Train (Epoch 57): Loss/seq after 02700 batchs: 1160.3748779296875
INFO:root:Train (Epoch 57): Loss/seq after 02750 batchs: 1186.9588623046875
INFO:root:Train (Epoch 57): Loss/seq after 02800 batchs: 1191.4918212890625
INFO:root:Train (Epoch 57): Loss/seq after 02850 batchs: 1186.1842041015625
INFO:root:Train (Epoch 57): Loss/seq after 02900 batchs: 1182.8338623046875
INFO:root:Train (Epoch 57): Loss/seq after 02950 batchs: 1174.5457763671875
INFO:root:Train (Epoch 57): Loss/seq after 03000 batchs: 1172.8907470703125
INFO:root:Train (Epoch 57): Loss/seq after 03050 batchs: 1175.306884765625
INFO:root:Train (Epoch 57): Loss/seq after 03100 batchs: 1184.49658203125
INFO:root:Train (Epoch 57): Loss/seq after 03150 batchs: 1200.33984375
INFO:root:Train (Epoch 57): Loss/seq after 03200 batchs: 1214.9727783203125
INFO:root:Train (Epoch 57): Loss/seq after 03250 batchs: 1228.869873046875
INFO:root:Train (Epoch 57): Loss/seq after 03300 batchs: 1225.853515625
INFO:root:Train (Epoch 57): Loss/seq after 03350 batchs: 1224.2230224609375
INFO:root:Train (Epoch 57): Loss/seq after 03400 batchs: 1215.5013427734375
INFO:root:Train (Epoch 57): Loss/seq after 03450 batchs: 1207.7637939453125
INFO:root:Train (Epoch 57): Loss/seq after 03500 batchs: 1205.577880859375
INFO:root:Train (Epoch 57): Loss/seq after 03550 batchs: 1197.4129638671875
INFO:root:Train (Epoch 57): Loss/seq after 03600 batchs: 1201.921875
INFO:root:Train (Epoch 57): Loss/seq after 03650 batchs: 1195.4554443359375
INFO:root:Train (Epoch 57): Loss/seq after 03700 batchs: 1194.2459716796875
INFO:root:Train (Epoch 57): Loss/seq after 03750 batchs: 1194.2435302734375
INFO:root:Train (Epoch 57): Loss/seq after 03800 batchs: 1187.3289794921875
INFO:root:Train (Epoch 57): Loss/seq after 03850 batchs: 1182.7071533203125
INFO:root:Train (Epoch 57): Loss/seq after 03900 batchs: 1188.2747802734375
INFO:root:Train (Epoch 57): Loss/seq after 03950 batchs: 1195.68701171875
INFO:root:Train (Epoch 57): Loss/seq after 04000 batchs: 1186.95654296875
INFO:root:Train (Epoch 57): Loss/seq after 04050 batchs: 1179.1922607421875
INFO:root:Train (Epoch 57): Loss/seq after 04100 batchs: 1172.565185546875
INFO:root:Train (Epoch 57): Loss/seq after 04150 batchs: 1166.9515380859375
INFO:root:Train (Epoch 57): Loss/seq after 04200 batchs: 1160.7462158203125
INFO:root:Train (Epoch 57): Loss/seq after 04250 batchs: 1156.16943359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 57): Loss/seq after 00000 batches: 878.6262817382812
INFO:root:# Valid (Epoch 57): Loss/seq after 00050 batches: 1091.62109375
INFO:root:# Valid (Epoch 57): Loss/seq after 00100 batches: 1382.45703125
INFO:root:# Valid (Epoch 57): Loss/seq after 00150 batches: 1100.447509765625
INFO:root:# Valid (Epoch 57): Loss/seq after 00200 batches: 989.8707275390625
INFO:root:Artifacts: Make stick videos for epoch 57
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_57_on_20220423_011846.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_57_index_654_on_20220423_011846.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 58): Loss/seq after 00000 batchs: 2416.788818359375
INFO:root:Train (Epoch 58): Loss/seq after 00050 batchs: 1538.708984375
INFO:root:Train (Epoch 58): Loss/seq after 00100 batchs: 1460.96484375
INFO:root:Train (Epoch 58): Loss/seq after 00150 batchs: 1281.5924072265625
INFO:root:Train (Epoch 58): Loss/seq after 00200 batchs: 1405.375244140625
INFO:root:Train (Epoch 58): Loss/seq after 00250 batchs: 1522.5777587890625
INFO:root:Train (Epoch 58): Loss/seq after 00300 batchs: 1449.3983154296875
INFO:root:Train (Epoch 58): Loss/seq after 00350 batchs: 1352.54931640625
INFO:root:Train (Epoch 58): Loss/seq after 00400 batchs: 1393.314453125
INFO:root:Train (Epoch 58): Loss/seq after 00450 batchs: 1334.856689453125
INFO:root:Train (Epoch 58): Loss/seq after 00500 batchs: 1328.2640380859375
INFO:root:Train (Epoch 58): Loss/seq after 00550 batchs: 1273.15869140625
INFO:root:Train (Epoch 58): Loss/seq after 00600 batchs: 1238.5341796875
INFO:root:Train (Epoch 58): Loss/seq after 00650 batchs: 1312.28173828125
INFO:root:Train (Epoch 58): Loss/seq after 00700 batchs: 1407.937255859375
INFO:root:Train (Epoch 58): Loss/seq after 00750 batchs: 1446.6502685546875
INFO:root:Train (Epoch 58): Loss/seq after 00800 batchs: 1421.266357421875
INFO:root:Train (Epoch 58): Loss/seq after 00850 batchs: 1383.83544921875
INFO:root:Train (Epoch 58): Loss/seq after 00900 batchs: 1381.5380859375
INFO:root:Train (Epoch 58): Loss/seq after 00950 batchs: 1465.9541015625
INFO:root:Train (Epoch 58): Loss/seq after 01000 batchs: 1463.0260009765625
INFO:root:Train (Epoch 58): Loss/seq after 01050 batchs: 1436.921630859375
INFO:root:Train (Epoch 58): Loss/seq after 01100 batchs: 1423.23291015625
INFO:root:Train (Epoch 58): Loss/seq after 01150 batchs: 1401.70703125
INFO:root:Train (Epoch 58): Loss/seq after 01200 batchs: 1385.106201171875
INFO:root:Train (Epoch 58): Loss/seq after 01250 batchs: 1375.4102783203125
INFO:root:Train (Epoch 58): Loss/seq after 01300 batchs: 1392.7271728515625
INFO:root:Train (Epoch 58): Loss/seq after 01350 batchs: 1397.646728515625
INFO:root:Train (Epoch 58): Loss/seq after 01400 batchs: 1445.5029296875
INFO:root:Train (Epoch 58): Loss/seq after 01450 batchs: 1429.7969970703125
INFO:root:Train (Epoch 58): Loss/seq after 01500 batchs: 1416.3984375
INFO:root:Train (Epoch 58): Loss/seq after 01550 batchs: 1408.7763671875
INFO:root:Train (Epoch 58): Loss/seq after 01600 batchs: 1388.0882568359375
INFO:root:Train (Epoch 58): Loss/seq after 01650 batchs: 1371.6142578125
INFO:root:Train (Epoch 58): Loss/seq after 01700 batchs: 1358.94091796875
INFO:root:Train (Epoch 58): Loss/seq after 01750 batchs: 1344.983642578125
INFO:root:Train (Epoch 58): Loss/seq after 01800 batchs: 1328.614013671875
INFO:root:Train (Epoch 58): Loss/seq after 01850 batchs: 1312.2109375
INFO:root:Train (Epoch 58): Loss/seq after 01900 batchs: 1304.917724609375
INFO:root:Train (Epoch 58): Loss/seq after 01950 batchs: 1294.035888671875
INFO:root:Train (Epoch 58): Loss/seq after 02000 batchs: 1283.2039794921875
INFO:root:Train (Epoch 58): Loss/seq after 02050 batchs: 1272.5423583984375
INFO:root:Train (Epoch 58): Loss/seq after 02100 batchs: 1259.6220703125
INFO:root:Train (Epoch 58): Loss/seq after 02150 batchs: 1247.5321044921875
INFO:root:Train (Epoch 58): Loss/seq after 02200 batchs: 1235.1846923828125
INFO:root:Train (Epoch 58): Loss/seq after 02250 batchs: 1231.8841552734375
INFO:root:Train (Epoch 58): Loss/seq after 02300 batchs: 1233.4517822265625
INFO:root:Train (Epoch 58): Loss/seq after 02350 batchs: 1222.696533203125
INFO:root:Train (Epoch 58): Loss/seq after 02400 batchs: 1216.905517578125
INFO:root:Train (Epoch 58): Loss/seq after 02450 batchs: 1203.51611328125
INFO:root:Train (Epoch 58): Loss/seq after 02500 batchs: 1186.54296875
INFO:root:Train (Epoch 58): Loss/seq after 02550 batchs: 1173.8221435546875
INFO:root:Train (Epoch 58): Loss/seq after 02600 batchs: 1170.858154296875
INFO:root:Train (Epoch 58): Loss/seq after 02650 batchs: 1165.5489501953125
INFO:root:Train (Epoch 58): Loss/seq after 02700 batchs: 1160.7523193359375
INFO:root:Train (Epoch 58): Loss/seq after 02750 batchs: 1186.3138427734375
INFO:root:Train (Epoch 58): Loss/seq after 02800 batchs: 1191.2662353515625
INFO:root:Train (Epoch 58): Loss/seq after 02850 batchs: 1185.959716796875
INFO:root:Train (Epoch 58): Loss/seq after 02900 batchs: 1183.815673828125
INFO:root:Train (Epoch 58): Loss/seq after 02950 batchs: 1175.2275390625
INFO:root:Train (Epoch 58): Loss/seq after 03000 batchs: 1173.5052490234375
INFO:root:Train (Epoch 58): Loss/seq after 03050 batchs: 1175.8782958984375
INFO:root:Train (Epoch 58): Loss/seq after 03100 batchs: 1185.431396484375
INFO:root:Train (Epoch 58): Loss/seq after 03150 batchs: 1201.314208984375
INFO:root:Train (Epoch 58): Loss/seq after 03200 batchs: 1216.0179443359375
INFO:root:Train (Epoch 58): Loss/seq after 03250 batchs: 1230.133544921875
INFO:root:Train (Epoch 58): Loss/seq after 03300 batchs: 1227.21044921875
INFO:root:Train (Epoch 58): Loss/seq after 03350 batchs: 1225.9996337890625
INFO:root:Train (Epoch 58): Loss/seq after 03400 batchs: 1217.285400390625
INFO:root:Train (Epoch 58): Loss/seq after 03450 batchs: 1209.4722900390625
INFO:root:Train (Epoch 58): Loss/seq after 03500 batchs: 1206.9327392578125
INFO:root:Train (Epoch 58): Loss/seq after 03550 batchs: 1198.6083984375
INFO:root:Train (Epoch 58): Loss/seq after 03600 batchs: 1203.398193359375
INFO:root:Train (Epoch 58): Loss/seq after 03650 batchs: 1196.2650146484375
INFO:root:Train (Epoch 58): Loss/seq after 03700 batchs: 1194.7379150390625
INFO:root:Train (Epoch 58): Loss/seq after 03750 batchs: 1194.844970703125
INFO:root:Train (Epoch 58): Loss/seq after 03800 batchs: 1187.8316650390625
INFO:root:Train (Epoch 58): Loss/seq after 03850 batchs: 1183.1201171875
INFO:root:Train (Epoch 58): Loss/seq after 03900 batchs: 1188.76025390625
INFO:root:Train (Epoch 58): Loss/seq after 03950 batchs: 1196.5828857421875
INFO:root:Train (Epoch 58): Loss/seq after 04000 batchs: 1187.849365234375
INFO:root:Train (Epoch 58): Loss/seq after 04050 batchs: 1180.05419921875
INFO:root:Train (Epoch 58): Loss/seq after 04100 batchs: 1173.4168701171875
INFO:root:Train (Epoch 58): Loss/seq after 04150 batchs: 1167.64599609375
INFO:root:Train (Epoch 58): Loss/seq after 04200 batchs: 1161.53564453125
INFO:root:Train (Epoch 58): Loss/seq after 04250 batchs: 1157.002197265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 58): Loss/seq after 00000 batches: 866.3173828125
INFO:root:# Valid (Epoch 58): Loss/seq after 00050 batches: 1090.38671875
INFO:root:# Valid (Epoch 58): Loss/seq after 00100 batches: 1373.10498046875
INFO:root:# Valid (Epoch 58): Loss/seq after 00150 batches: 1092.1553955078125
INFO:root:# Valid (Epoch 58): Loss/seq after 00200 batches: 981.7058715820312
INFO:root:Artifacts: Make stick videos for epoch 58
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_58_on_20220423_012330.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_58_index_1459_on_20220423_012330.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 59): Loss/seq after 00000 batchs: 2418.928955078125
INFO:root:Train (Epoch 59): Loss/seq after 00050 batchs: 1532.4166259765625
INFO:root:Train (Epoch 59): Loss/seq after 00100 batchs: 1437.9473876953125
INFO:root:Train (Epoch 59): Loss/seq after 00150 batchs: 1269.996826171875
INFO:root:Train (Epoch 59): Loss/seq after 00200 batchs: 1391.0745849609375
INFO:root:Train (Epoch 59): Loss/seq after 00250 batchs: 1508.6925048828125
INFO:root:Train (Epoch 59): Loss/seq after 00300 batchs: 1437.483642578125
INFO:root:Train (Epoch 59): Loss/seq after 00350 batchs: 1341.4534912109375
INFO:root:Train (Epoch 59): Loss/seq after 00400 batchs: 1379.3077392578125
INFO:root:Train (Epoch 59): Loss/seq after 00450 batchs: 1322.6802978515625
INFO:root:Train (Epoch 59): Loss/seq after 00500 batchs: 1317.4259033203125
INFO:root:Train (Epoch 59): Loss/seq after 00550 batchs: 1263.67529296875
INFO:root:Train (Epoch 59): Loss/seq after 00600 batchs: 1230.7918701171875
INFO:root:Train (Epoch 59): Loss/seq after 00650 batchs: 1305.0029296875
INFO:root:Train (Epoch 59): Loss/seq after 00700 batchs: 1400.9228515625
INFO:root:Train (Epoch 59): Loss/seq after 00750 batchs: 1441.3592529296875
INFO:root:Train (Epoch 59): Loss/seq after 00800 batchs: 1417.7435302734375
INFO:root:Train (Epoch 59): Loss/seq after 00850 batchs: 1380.4149169921875
INFO:root:Train (Epoch 59): Loss/seq after 00900 batchs: 1377.5447998046875
INFO:root:Train (Epoch 59): Loss/seq after 00950 batchs: 1460.7689208984375
INFO:root:Train (Epoch 59): Loss/seq after 01000 batchs: 1457.8310546875
INFO:root:Train (Epoch 59): Loss/seq after 01050 batchs: 1426.910400390625
INFO:root:Train (Epoch 59): Loss/seq after 01100 batchs: 1413.32373046875
INFO:root:Train (Epoch 59): Loss/seq after 01150 batchs: 1391.9486083984375
INFO:root:Train (Epoch 59): Loss/seq after 01200 batchs: 1375.247314453125
INFO:root:Train (Epoch 59): Loss/seq after 01250 batchs: 1366.0531005859375
INFO:root:Train (Epoch 59): Loss/seq after 01300 batchs: 1383.5552978515625
INFO:root:Train (Epoch 59): Loss/seq after 01350 batchs: 1388.8837890625
INFO:root:Train (Epoch 59): Loss/seq after 01400 batchs: 1436.15625
INFO:root:Train (Epoch 59): Loss/seq after 01450 batchs: 1420.9034423828125
INFO:root:Train (Epoch 59): Loss/seq after 01500 batchs: 1407.8092041015625
INFO:root:Train (Epoch 59): Loss/seq after 01550 batchs: 1401.0787353515625
INFO:root:Train (Epoch 59): Loss/seq after 01600 batchs: 1380.64306640625
INFO:root:Train (Epoch 59): Loss/seq after 01650 batchs: 1364.1463623046875
INFO:root:Train (Epoch 59): Loss/seq after 01700 batchs: 1351.71728515625
INFO:root:Train (Epoch 59): Loss/seq after 01750 batchs: 1337.9052734375
INFO:root:Train (Epoch 59): Loss/seq after 01800 batchs: 1321.856201171875
INFO:root:Train (Epoch 59): Loss/seq after 01850 batchs: 1305.722900390625
INFO:root:Train (Epoch 59): Loss/seq after 01900 batchs: 1299.0753173828125
INFO:root:Train (Epoch 59): Loss/seq after 01950 batchs: 1288.58642578125
INFO:root:Train (Epoch 59): Loss/seq after 02000 batchs: 1277.5152587890625
INFO:root:Train (Epoch 59): Loss/seq after 02050 batchs: 1266.908447265625
INFO:root:Train (Epoch 59): Loss/seq after 02100 batchs: 1254.186767578125
INFO:root:Train (Epoch 59): Loss/seq after 02150 batchs: 1242.2451171875
INFO:root:Train (Epoch 59): Loss/seq after 02200 batchs: 1230.0447998046875
INFO:root:Train (Epoch 59): Loss/seq after 02250 batchs: 1227.1939697265625
INFO:root:Train (Epoch 59): Loss/seq after 02300 batchs: 1228.73291015625
INFO:root:Train (Epoch 59): Loss/seq after 02350 batchs: 1217.3406982421875
INFO:root:Train (Epoch 59): Loss/seq after 02400 batchs: 1211.76416015625
INFO:root:Train (Epoch 59): Loss/seq after 02450 batchs: 1198.4310302734375
INFO:root:Train (Epoch 59): Loss/seq after 02500 batchs: 1181.580810546875
INFO:root:Train (Epoch 59): Loss/seq after 02550 batchs: 1169.0074462890625
INFO:root:Train (Epoch 59): Loss/seq after 02600 batchs: 1166.0389404296875
INFO:root:Train (Epoch 59): Loss/seq after 02650 batchs: 1160.7532958984375
INFO:root:Train (Epoch 59): Loss/seq after 02700 batchs: 1155.942138671875
INFO:root:Train (Epoch 59): Loss/seq after 02750 batchs: 1180.4267578125
INFO:root:Train (Epoch 59): Loss/seq after 02800 batchs: 1184.6502685546875
INFO:root:Train (Epoch 59): Loss/seq after 02850 batchs: 1179.563720703125
INFO:root:Train (Epoch 59): Loss/seq after 02900 batchs: 1177.40283203125
INFO:root:Train (Epoch 59): Loss/seq after 02950 batchs: 1169.246826171875
INFO:root:Train (Epoch 59): Loss/seq after 03000 batchs: 1167.6395263671875
INFO:root:Train (Epoch 59): Loss/seq after 03050 batchs: 1170.1605224609375
INFO:root:Train (Epoch 59): Loss/seq after 03100 batchs: 1179.640380859375
INFO:root:Train (Epoch 59): Loss/seq after 03150 batchs: 1195.712890625
INFO:root:Train (Epoch 59): Loss/seq after 03200 batchs: 1210.3392333984375
INFO:root:Train (Epoch 59): Loss/seq after 03250 batchs: 1224.4346923828125
INFO:root:Train (Epoch 59): Loss/seq after 03300 batchs: 1221.2294921875
INFO:root:Train (Epoch 59): Loss/seq after 03350 batchs: 1219.847412109375
INFO:root:Train (Epoch 59): Loss/seq after 03400 batchs: 1211.207763671875
INFO:root:Train (Epoch 59): Loss/seq after 03450 batchs: 1203.0447998046875
INFO:root:Train (Epoch 59): Loss/seq after 03500 batchs: 1200.8372802734375
INFO:root:Train (Epoch 59): Loss/seq after 03550 batchs: 1193.1556396484375
INFO:root:Train (Epoch 59): Loss/seq after 03600 batchs: 1197.8585205078125
INFO:root:Train (Epoch 59): Loss/seq after 03650 batchs: 1190.957275390625
INFO:root:Train (Epoch 59): Loss/seq after 03700 batchs: 1189.5411376953125
INFO:root:Train (Epoch 59): Loss/seq after 03750 batchs: 1189.619384765625
INFO:root:Train (Epoch 59): Loss/seq after 03800 batchs: 1182.761962890625
INFO:root:Train (Epoch 59): Loss/seq after 03850 batchs: 1178.149658203125
INFO:root:Train (Epoch 59): Loss/seq after 03900 batchs: 1183.90283203125
INFO:root:Train (Epoch 59): Loss/seq after 03950 batchs: 1192.2779541015625
INFO:root:Train (Epoch 59): Loss/seq after 04000 batchs: 1183.5875244140625
INFO:root:Train (Epoch 59): Loss/seq after 04050 batchs: 1175.87890625
INFO:root:Train (Epoch 59): Loss/seq after 04100 batchs: 1169.29833984375
INFO:root:Train (Epoch 59): Loss/seq after 04150 batchs: 1163.661376953125
INFO:root:Train (Epoch 59): Loss/seq after 04200 batchs: 1157.642822265625
INFO:root:Train (Epoch 59): Loss/seq after 04250 batchs: 1153.279052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 59): Loss/seq after 00000 batches: 864.4752807617188
INFO:root:# Valid (Epoch 59): Loss/seq after 00050 batches: 1092.083740234375
INFO:root:# Valid (Epoch 59): Loss/seq after 00100 batches: 1386.8499755859375
INFO:root:# Valid (Epoch 59): Loss/seq after 00150 batches: 1103.0162353515625
INFO:root:# Valid (Epoch 59): Loss/seq after 00200 batches: 990.3995361328125
INFO:root:Artifacts: Make stick videos for epoch 59
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_59_on_20220423_012822.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_59_index_823_on_20220423_012822.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 60): Loss/seq after 00000 batchs: 2537.5654296875
INFO:root:Train (Epoch 60): Loss/seq after 00050 batchs: 1576.3009033203125
INFO:root:Train (Epoch 60): Loss/seq after 00100 batchs: 1476.08154296875
INFO:root:Train (Epoch 60): Loss/seq after 00150 batchs: 1296.8594970703125
INFO:root:Train (Epoch 60): Loss/seq after 00200 batchs: 1414.147705078125
INFO:root:Train (Epoch 60): Loss/seq after 00250 batchs: 1522.3695068359375
INFO:root:Train (Epoch 60): Loss/seq after 00300 batchs: 1449.191162109375
INFO:root:Train (Epoch 60): Loss/seq after 00350 batchs: 1353.235595703125
INFO:root:Train (Epoch 60): Loss/seq after 00400 batchs: 1389.0341796875
INFO:root:Train (Epoch 60): Loss/seq after 00450 batchs: 1331.408935546875
INFO:root:Train (Epoch 60): Loss/seq after 00500 batchs: 1324.3455810546875
INFO:root:Train (Epoch 60): Loss/seq after 00550 batchs: 1269.71240234375
INFO:root:Train (Epoch 60): Loss/seq after 00600 batchs: 1235.9031982421875
INFO:root:Train (Epoch 60): Loss/seq after 00650 batchs: 1309.4447021484375
INFO:root:Train (Epoch 60): Loss/seq after 00700 batchs: 1405.201416015625
INFO:root:Train (Epoch 60): Loss/seq after 00750 batchs: 1443.57421875
INFO:root:Train (Epoch 60): Loss/seq after 00800 batchs: 1419.5975341796875
INFO:root:Train (Epoch 60): Loss/seq after 00850 batchs: 1381.7298583984375
INFO:root:Train (Epoch 60): Loss/seq after 00900 batchs: 1378.6885986328125
INFO:root:Train (Epoch 60): Loss/seq after 00950 batchs: 1461.542236328125
INFO:root:Train (Epoch 60): Loss/seq after 01000 batchs: 1458.6290283203125
INFO:root:Train (Epoch 60): Loss/seq after 01050 batchs: 1427.9783935546875
INFO:root:Train (Epoch 60): Loss/seq after 01100 batchs: 1414.2548828125
INFO:root:Train (Epoch 60): Loss/seq after 01150 batchs: 1392.904296875
INFO:root:Train (Epoch 60): Loss/seq after 01200 batchs: 1376.17236328125
INFO:root:Train (Epoch 60): Loss/seq after 01250 batchs: 1366.46923828125
INFO:root:Train (Epoch 60): Loss/seq after 01300 batchs: 1383.7353515625
INFO:root:Train (Epoch 60): Loss/seq after 01350 batchs: 1388.9293212890625
INFO:root:Train (Epoch 60): Loss/seq after 01400 batchs: 1436.0330810546875
INFO:root:Train (Epoch 60): Loss/seq after 01450 batchs: 1420.518310546875
INFO:root:Train (Epoch 60): Loss/seq after 01500 batchs: 1407.4632568359375
INFO:root:Train (Epoch 60): Loss/seq after 01550 batchs: 1399.70947265625
INFO:root:Train (Epoch 60): Loss/seq after 01600 batchs: 1379.210693359375
INFO:root:Train (Epoch 60): Loss/seq after 01650 batchs: 1362.98681640625
INFO:root:Train (Epoch 60): Loss/seq after 01700 batchs: 1350.5611572265625
INFO:root:Train (Epoch 60): Loss/seq after 01750 batchs: 1336.810791015625
INFO:root:Train (Epoch 60): Loss/seq after 01800 batchs: 1320.6448974609375
INFO:root:Train (Epoch 60): Loss/seq after 01850 batchs: 1304.4273681640625
INFO:root:Train (Epoch 60): Loss/seq after 01900 batchs: 1297.45361328125
INFO:root:Train (Epoch 60): Loss/seq after 01950 batchs: 1286.61181640625
INFO:root:Train (Epoch 60): Loss/seq after 02000 batchs: 1275.7210693359375
INFO:root:Train (Epoch 60): Loss/seq after 02050 batchs: 1265.060546875
INFO:root:Train (Epoch 60): Loss/seq after 02100 batchs: 1252.34375
INFO:root:Train (Epoch 60): Loss/seq after 02150 batchs: 1240.4161376953125
INFO:root:Train (Epoch 60): Loss/seq after 02200 batchs: 1228.273681640625
INFO:root:Train (Epoch 60): Loss/seq after 02250 batchs: 1225.618896484375
INFO:root:Train (Epoch 60): Loss/seq after 02300 batchs: 1227.2095947265625
INFO:root:Train (Epoch 60): Loss/seq after 02350 batchs: 1217.008056640625
INFO:root:Train (Epoch 60): Loss/seq after 02400 batchs: 1211.5439453125
INFO:root:Train (Epoch 60): Loss/seq after 02450 batchs: 1198.20068359375
INFO:root:Train (Epoch 60): Loss/seq after 02500 batchs: 1181.3511962890625
INFO:root:Train (Epoch 60): Loss/seq after 02550 batchs: 1168.8421630859375
INFO:root:Train (Epoch 60): Loss/seq after 02600 batchs: 1165.8336181640625
INFO:root:Train (Epoch 60): Loss/seq after 02650 batchs: 1160.5455322265625
INFO:root:Train (Epoch 60): Loss/seq after 02700 batchs: 1155.74462890625
INFO:root:Train (Epoch 60): Loss/seq after 02750 batchs: 1179.520263671875
INFO:root:Train (Epoch 60): Loss/seq after 02800 batchs: 1184.4735107421875
INFO:root:Train (Epoch 60): Loss/seq after 02850 batchs: 1179.1270751953125
INFO:root:Train (Epoch 60): Loss/seq after 02900 batchs: 1176.5010986328125
INFO:root:Train (Epoch 60): Loss/seq after 02950 batchs: 1167.99853515625
INFO:root:Train (Epoch 60): Loss/seq after 03000 batchs: 1166.405029296875
INFO:root:Train (Epoch 60): Loss/seq after 03050 batchs: 1168.953369140625
INFO:root:Train (Epoch 60): Loss/seq after 03100 batchs: 1178.1534423828125
INFO:root:Train (Epoch 60): Loss/seq after 03150 batchs: 1194.1217041015625
INFO:root:Train (Epoch 60): Loss/seq after 03200 batchs: 1208.9481201171875
INFO:root:Train (Epoch 60): Loss/seq after 03250 batchs: 1223.1435546875
INFO:root:Train (Epoch 60): Loss/seq after 03300 batchs: 1220.0657958984375
INFO:root:Train (Epoch 60): Loss/seq after 03350 batchs: 1218.28173828125
INFO:root:Train (Epoch 60): Loss/seq after 03400 batchs: 1209.683837890625
INFO:root:Train (Epoch 60): Loss/seq after 03450 batchs: 1201.4910888671875
INFO:root:Train (Epoch 60): Loss/seq after 03500 batchs: 1199.1767578125
INFO:root:Train (Epoch 60): Loss/seq after 03550 batchs: 1190.91064453125
INFO:root:Train (Epoch 60): Loss/seq after 03600 batchs: 1195.245361328125
INFO:root:Train (Epoch 60): Loss/seq after 03650 batchs: 1188.0101318359375
INFO:root:Train (Epoch 60): Loss/seq after 03700 batchs: 1186.4957275390625
INFO:root:Train (Epoch 60): Loss/seq after 03750 batchs: 1186.6671142578125
INFO:root:Train (Epoch 60): Loss/seq after 03800 batchs: 1179.8165283203125
INFO:root:Train (Epoch 60): Loss/seq after 03850 batchs: 1175.1917724609375
INFO:root:Train (Epoch 60): Loss/seq after 03900 batchs: 1180.830078125
INFO:root:Train (Epoch 60): Loss/seq after 03950 batchs: 1188.9642333984375
INFO:root:Train (Epoch 60): Loss/seq after 04000 batchs: 1180.3089599609375
INFO:root:Train (Epoch 60): Loss/seq after 04050 batchs: 1172.6031494140625
INFO:root:Train (Epoch 60): Loss/seq after 04100 batchs: 1165.939208984375
INFO:root:Train (Epoch 60): Loss/seq after 04150 batchs: 1160.2578125
INFO:root:Train (Epoch 60): Loss/seq after 04200 batchs: 1153.9515380859375
INFO:root:Train (Epoch 60): Loss/seq after 04250 batchs: 1149.447265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 60): Loss/seq after 00000 batches: 866.0607299804688
INFO:root:# Valid (Epoch 60): Loss/seq after 00050 batches: 1092.6312255859375
INFO:root:# Valid (Epoch 60): Loss/seq after 00100 batches: 1377.7646484375
INFO:root:# Valid (Epoch 60): Loss/seq after 00150 batches: 1094.114501953125
INFO:root:# Valid (Epoch 60): Loss/seq after 00200 batches: 983.5795288085938
INFO:root:Artifacts: Make stick videos for epoch 60
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_60_on_20220423_013311.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_60_index_470_on_20220423_013311.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 61): Loss/seq after 00000 batchs: 2396.52197265625
INFO:root:Train (Epoch 61): Loss/seq after 00050 batchs: 1528.537109375
INFO:root:Train (Epoch 61): Loss/seq after 00100 batchs: 1454.5955810546875
INFO:root:Train (Epoch 61): Loss/seq after 00150 batchs: 1275.4681396484375
INFO:root:Train (Epoch 61): Loss/seq after 00200 batchs: 1393.0159912109375
INFO:root:Train (Epoch 61): Loss/seq after 00250 batchs: 1510.760009765625
INFO:root:Train (Epoch 61): Loss/seq after 00300 batchs: 1439.743408203125
INFO:root:Train (Epoch 61): Loss/seq after 00350 batchs: 1348.5360107421875
INFO:root:Train (Epoch 61): Loss/seq after 00400 batchs: 1386.187744140625
INFO:root:Train (Epoch 61): Loss/seq after 00450 batchs: 1329.19091796875
INFO:root:Train (Epoch 61): Loss/seq after 00500 batchs: 1326.141845703125
INFO:root:Train (Epoch 61): Loss/seq after 00550 batchs: 1271.5968017578125
INFO:root:Train (Epoch 61): Loss/seq after 00600 batchs: 1237.8585205078125
INFO:root:Train (Epoch 61): Loss/seq after 00650 batchs: 1311.9676513671875
INFO:root:Train (Epoch 61): Loss/seq after 00700 batchs: 1407.4949951171875
INFO:root:Train (Epoch 61): Loss/seq after 00750 batchs: 1446.7301025390625
INFO:root:Train (Epoch 61): Loss/seq after 00800 batchs: 1422.34912109375
INFO:root:Train (Epoch 61): Loss/seq after 00850 batchs: 1384.4779052734375
INFO:root:Train (Epoch 61): Loss/seq after 00900 batchs: 1382.35498046875
INFO:root:Train (Epoch 61): Loss/seq after 00950 batchs: 1465.4017333984375
INFO:root:Train (Epoch 61): Loss/seq after 01000 batchs: 1462.1552734375
INFO:root:Train (Epoch 61): Loss/seq after 01050 batchs: 1430.1256103515625
INFO:root:Train (Epoch 61): Loss/seq after 01100 batchs: 1416.1065673828125
INFO:root:Train (Epoch 61): Loss/seq after 01150 batchs: 1394.703125
INFO:root:Train (Epoch 61): Loss/seq after 01200 batchs: 1377.9324951171875
INFO:root:Train (Epoch 61): Loss/seq after 01250 batchs: 1368.0928955078125
INFO:root:Train (Epoch 61): Loss/seq after 01300 batchs: 1385.685546875
INFO:root:Train (Epoch 61): Loss/seq after 01350 batchs: 1390.8861083984375
INFO:root:Train (Epoch 61): Loss/seq after 01400 batchs: 1438.244384765625
INFO:root:Train (Epoch 61): Loss/seq after 01450 batchs: 1422.9149169921875
INFO:root:Train (Epoch 61): Loss/seq after 01500 batchs: 1409.7613525390625
INFO:root:Train (Epoch 61): Loss/seq after 01550 batchs: 1401.6868896484375
INFO:root:Train (Epoch 61): Loss/seq after 01600 batchs: 1381.226806640625
INFO:root:Train (Epoch 61): Loss/seq after 01650 batchs: 1364.5218505859375
INFO:root:Train (Epoch 61): Loss/seq after 01700 batchs: 1352.060546875
INFO:root:Train (Epoch 61): Loss/seq after 01750 batchs: 1338.241455078125
INFO:root:Train (Epoch 61): Loss/seq after 01800 batchs: 1322.0399169921875
INFO:root:Train (Epoch 61): Loss/seq after 01850 batchs: 1306.1392822265625
INFO:root:Train (Epoch 61): Loss/seq after 01900 batchs: 1298.801513671875
INFO:root:Train (Epoch 61): Loss/seq after 01950 batchs: 1287.28076171875
INFO:root:Train (Epoch 61): Loss/seq after 02000 batchs: 1276.01123046875
INFO:root:Train (Epoch 61): Loss/seq after 02050 batchs: 1265.6507568359375
INFO:root:Train (Epoch 61): Loss/seq after 02100 batchs: 1252.9891357421875
INFO:root:Train (Epoch 61): Loss/seq after 02150 batchs: 1241.012451171875
INFO:root:Train (Epoch 61): Loss/seq after 02200 batchs: 1228.8302001953125
INFO:root:Train (Epoch 61): Loss/seq after 02250 batchs: 1225.5601806640625
INFO:root:Train (Epoch 61): Loss/seq after 02300 batchs: 1227.125
INFO:root:Train (Epoch 61): Loss/seq after 02350 batchs: 1216.90576171875
INFO:root:Train (Epoch 61): Loss/seq after 02400 batchs: 1211.4764404296875
INFO:root:Train (Epoch 61): Loss/seq after 02450 batchs: 1198.1846923828125
INFO:root:Train (Epoch 61): Loss/seq after 02500 batchs: 1181.33203125
INFO:root:Train (Epoch 61): Loss/seq after 02550 batchs: 1168.9990234375
INFO:root:Train (Epoch 61): Loss/seq after 02600 batchs: 1165.930419921875
INFO:root:Train (Epoch 61): Loss/seq after 02650 batchs: 1160.6728515625
INFO:root:Train (Epoch 61): Loss/seq after 02700 batchs: 1155.88134765625
INFO:root:Train (Epoch 61): Loss/seq after 02750 batchs: 1179.0716552734375
INFO:root:Train (Epoch 61): Loss/seq after 02800 batchs: 1183.0263671875
INFO:root:Train (Epoch 61): Loss/seq after 02850 batchs: 1177.9759521484375
INFO:root:Train (Epoch 61): Loss/seq after 02900 batchs: 1176.263671875
INFO:root:Train (Epoch 61): Loss/seq after 02950 batchs: 1168.5994873046875
INFO:root:Train (Epoch 61): Loss/seq after 03000 batchs: 1167.0390625
INFO:root:Train (Epoch 61): Loss/seq after 03050 batchs: 1169.71533203125
INFO:root:Train (Epoch 61): Loss/seq after 03100 batchs: 1179.601806640625
INFO:root:Train (Epoch 61): Loss/seq after 03150 batchs: 1197.484130859375
INFO:root:Train (Epoch 61): Loss/seq after 03200 batchs: 1212.161865234375
INFO:root:Train (Epoch 61): Loss/seq after 03250 batchs: 1225.9295654296875
INFO:root:Train (Epoch 61): Loss/seq after 03300 batchs: 1222.46728515625
INFO:root:Train (Epoch 61): Loss/seq after 03350 batchs: 1220.8223876953125
INFO:root:Train (Epoch 61): Loss/seq after 03400 batchs: 1212.1871337890625
INFO:root:Train (Epoch 61): Loss/seq after 03450 batchs: 1204.15576171875
INFO:root:Train (Epoch 61): Loss/seq after 03500 batchs: 1201.341552734375
INFO:root:Train (Epoch 61): Loss/seq after 03550 batchs: 1192.8778076171875
INFO:root:Train (Epoch 61): Loss/seq after 03600 batchs: 1197.1475830078125
INFO:root:Train (Epoch 61): Loss/seq after 03650 batchs: 1189.9281005859375
INFO:root:Train (Epoch 61): Loss/seq after 03700 batchs: 1188.30078125
INFO:root:Train (Epoch 61): Loss/seq after 03750 batchs: 1188.404052734375
INFO:root:Train (Epoch 61): Loss/seq after 03800 batchs: 1181.5269775390625
INFO:root:Train (Epoch 61): Loss/seq after 03850 batchs: 1176.9146728515625
INFO:root:Train (Epoch 61): Loss/seq after 03900 batchs: 1182.677734375
INFO:root:Train (Epoch 61): Loss/seq after 03950 batchs: 1190.3121337890625
INFO:root:Train (Epoch 61): Loss/seq after 04000 batchs: 1181.646240234375
INFO:root:Train (Epoch 61): Loss/seq after 04050 batchs: 1173.95703125
INFO:root:Train (Epoch 61): Loss/seq after 04100 batchs: 1167.4232177734375
INFO:root:Train (Epoch 61): Loss/seq after 04150 batchs: 1161.7760009765625
INFO:root:Train (Epoch 61): Loss/seq after 04200 batchs: 1155.40087890625
INFO:root:Train (Epoch 61): Loss/seq after 04250 batchs: 1150.9384765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 61): Loss/seq after 00000 batches: 867.9672241210938
INFO:root:# Valid (Epoch 61): Loss/seq after 00050 batches: 1094.6544189453125
INFO:root:# Valid (Epoch 61): Loss/seq after 00100 batches: 1384.902099609375
INFO:root:# Valid (Epoch 61): Loss/seq after 00150 batches: 1101.283447265625
INFO:root:# Valid (Epoch 61): Loss/seq after 00200 batches: 990.31494140625
INFO:root:Artifacts: Make stick videos for epoch 61
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_61_on_20220423_013759.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_61_index_189_on_20220423_013759.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 62): Loss/seq after 00000 batchs: 2481.137939453125
INFO:root:Train (Epoch 62): Loss/seq after 00050 batchs: 1553.53173828125
INFO:root:Train (Epoch 62): Loss/seq after 00100 batchs: 1463.8017578125
INFO:root:Train (Epoch 62): Loss/seq after 00150 batchs: 1277.6678466796875
INFO:root:Train (Epoch 62): Loss/seq after 00200 batchs: 1399.32275390625
INFO:root:Train (Epoch 62): Loss/seq after 00250 batchs: 1517.5592041015625
INFO:root:Train (Epoch 62): Loss/seq after 00300 batchs: 1445.2659912109375
INFO:root:Train (Epoch 62): Loss/seq after 00350 batchs: 1348.55859375
INFO:root:Train (Epoch 62): Loss/seq after 00400 batchs: 1386.1484375
INFO:root:Train (Epoch 62): Loss/seq after 00450 batchs: 1328.4405517578125
INFO:root:Train (Epoch 62): Loss/seq after 00500 batchs: 1318.59814453125
INFO:root:Train (Epoch 62): Loss/seq after 00550 batchs: 1264.3267822265625
INFO:root:Train (Epoch 62): Loss/seq after 00600 batchs: 1231.26513671875
INFO:root:Train (Epoch 62): Loss/seq after 00650 batchs: 1305.221923828125
INFO:root:Train (Epoch 62): Loss/seq after 00700 batchs: 1401.2989501953125
INFO:root:Train (Epoch 62): Loss/seq after 00750 batchs: 1438.9306640625
INFO:root:Train (Epoch 62): Loss/seq after 00800 batchs: 1414.2562255859375
INFO:root:Train (Epoch 62): Loss/seq after 00850 batchs: 1377.0875244140625
INFO:root:Train (Epoch 62): Loss/seq after 00900 batchs: 1374.6103515625
INFO:root:Train (Epoch 62): Loss/seq after 00950 batchs: 1459.82666015625
INFO:root:Train (Epoch 62): Loss/seq after 01000 batchs: 1457.1702880859375
INFO:root:Train (Epoch 62): Loss/seq after 01050 batchs: 1426.881103515625
INFO:root:Train (Epoch 62): Loss/seq after 01100 batchs: 1413.0
INFO:root:Train (Epoch 62): Loss/seq after 01150 batchs: 1392.3798828125
INFO:root:Train (Epoch 62): Loss/seq after 01200 batchs: 1376.9329833984375
INFO:root:Train (Epoch 62): Loss/seq after 01250 batchs: 1367.8385009765625
INFO:root:Train (Epoch 62): Loss/seq after 01300 batchs: 1385.218505859375
INFO:root:Train (Epoch 62): Loss/seq after 01350 batchs: 1390.4971923828125
INFO:root:Train (Epoch 62): Loss/seq after 01400 batchs: 1438.23779296875
INFO:root:Train (Epoch 62): Loss/seq after 01450 batchs: 1423.1732177734375
INFO:root:Train (Epoch 62): Loss/seq after 01500 batchs: 1410.075927734375
INFO:root:Train (Epoch 62): Loss/seq after 01550 batchs: 1403.381591796875
INFO:root:Train (Epoch 62): Loss/seq after 01600 batchs: 1383.31396484375
INFO:root:Train (Epoch 62): Loss/seq after 01650 batchs: 1368.4427490234375
INFO:root:Train (Epoch 62): Loss/seq after 01700 batchs: 1356.146484375
INFO:root:Train (Epoch 62): Loss/seq after 01750 batchs: 1342.54541015625
INFO:root:Train (Epoch 62): Loss/seq after 01800 batchs: 1326.3963623046875
INFO:root:Train (Epoch 62): Loss/seq after 01850 batchs: 1310.2891845703125
INFO:root:Train (Epoch 62): Loss/seq after 01900 batchs: 1303.196533203125
INFO:root:Train (Epoch 62): Loss/seq after 01950 batchs: 1292.1121826171875
INFO:root:Train (Epoch 62): Loss/seq after 02000 batchs: 1281.0963134765625
INFO:root:Train (Epoch 62): Loss/seq after 02050 batchs: 1270.673583984375
INFO:root:Train (Epoch 62): Loss/seq after 02100 batchs: 1257.7642822265625
INFO:root:Train (Epoch 62): Loss/seq after 02150 batchs: 1245.7333984375
INFO:root:Train (Epoch 62): Loss/seq after 02200 batchs: 1233.4193115234375
INFO:root:Train (Epoch 62): Loss/seq after 02250 batchs: 1230.0997314453125
INFO:root:Train (Epoch 62): Loss/seq after 02300 batchs: 1231.374755859375
INFO:root:Train (Epoch 62): Loss/seq after 02350 batchs: 1219.62060546875
INFO:root:Train (Epoch 62): Loss/seq after 02400 batchs: 1213.9656982421875
INFO:root:Train (Epoch 62): Loss/seq after 02450 batchs: 1200.4754638671875
INFO:root:Train (Epoch 62): Loss/seq after 02500 batchs: 1183.576171875
INFO:root:Train (Epoch 62): Loss/seq after 02550 batchs: 1170.92724609375
INFO:root:Train (Epoch 62): Loss/seq after 02600 batchs: 1167.7935791015625
INFO:root:Train (Epoch 62): Loss/seq after 02650 batchs: 1162.45751953125
INFO:root:Train (Epoch 62): Loss/seq after 02700 batchs: 1157.5792236328125
INFO:root:Train (Epoch 62): Loss/seq after 02750 batchs: 1180.237548828125
INFO:root:Train (Epoch 62): Loss/seq after 02800 batchs: 1185.1339111328125
INFO:root:Train (Epoch 62): Loss/seq after 02850 batchs: 1180.171142578125
INFO:root:Train (Epoch 62): Loss/seq after 02900 batchs: 1177.260498046875
INFO:root:Train (Epoch 62): Loss/seq after 02950 batchs: 1168.7667236328125
INFO:root:Train (Epoch 62): Loss/seq after 03000 batchs: 1167.2247314453125
INFO:root:Train (Epoch 62): Loss/seq after 03050 batchs: 1169.7071533203125
INFO:root:Train (Epoch 62): Loss/seq after 03100 batchs: 1179.8863525390625
INFO:root:Train (Epoch 62): Loss/seq after 03150 batchs: 1195.7672119140625
INFO:root:Train (Epoch 62): Loss/seq after 03200 batchs: 1210.520751953125
INFO:root:Train (Epoch 62): Loss/seq after 03250 batchs: 1224.456298828125
INFO:root:Train (Epoch 62): Loss/seq after 03300 batchs: 1221.2315673828125
INFO:root:Train (Epoch 62): Loss/seq after 03350 batchs: 1219.6763916015625
INFO:root:Train (Epoch 62): Loss/seq after 03400 batchs: 1211.0025634765625
INFO:root:Train (Epoch 62): Loss/seq after 03450 batchs: 1203.0660400390625
INFO:root:Train (Epoch 62): Loss/seq after 03500 batchs: 1200.449951171875
INFO:root:Train (Epoch 62): Loss/seq after 03550 batchs: 1192.0693359375
INFO:root:Train (Epoch 62): Loss/seq after 03600 batchs: 1196.173095703125
INFO:root:Train (Epoch 62): Loss/seq after 03650 batchs: 1188.8013916015625
INFO:root:Train (Epoch 62): Loss/seq after 03700 batchs: 1187.2908935546875
INFO:root:Train (Epoch 62): Loss/seq after 03750 batchs: 1187.4154052734375
INFO:root:Train (Epoch 62): Loss/seq after 03800 batchs: 1180.557373046875
INFO:root:Train (Epoch 62): Loss/seq after 03850 batchs: 1175.99951171875
INFO:root:Train (Epoch 62): Loss/seq after 03900 batchs: 1181.73046875
INFO:root:Train (Epoch 62): Loss/seq after 03950 batchs: 1189.267822265625
INFO:root:Train (Epoch 62): Loss/seq after 04000 batchs: 1180.6011962890625
INFO:root:Train (Epoch 62): Loss/seq after 04050 batchs: 1172.90283203125
INFO:root:Train (Epoch 62): Loss/seq after 04100 batchs: 1166.3082275390625
INFO:root:Train (Epoch 62): Loss/seq after 04150 batchs: 1160.6390380859375
INFO:root:Train (Epoch 62): Loss/seq after 04200 batchs: 1154.3089599609375
INFO:root:Train (Epoch 62): Loss/seq after 04250 batchs: 1149.8232421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 62): Loss/seq after 00000 batches: 871.6423950195312
INFO:root:# Valid (Epoch 62): Loss/seq after 00050 batches: 1091.907958984375
INFO:root:# Valid (Epoch 62): Loss/seq after 00100 batches: 1382.1328125
INFO:root:# Valid (Epoch 62): Loss/seq after 00150 batches: 1099.2586669921875
INFO:root:# Valid (Epoch 62): Loss/seq after 00200 batches: 986.8088989257812
INFO:root:Artifacts: Make stick videos for epoch 62
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_62_on_20220423_014243.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_62_index_165_on_20220423_014243.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 63): Loss/seq after 00000 batchs: 2379.1611328125
INFO:root:Train (Epoch 63): Loss/seq after 00050 batchs: 1529.8203125
INFO:root:Train (Epoch 63): Loss/seq after 00100 batchs: 1444.239501953125
INFO:root:Train (Epoch 63): Loss/seq after 00150 batchs: 1270.692138671875
INFO:root:Train (Epoch 63): Loss/seq after 00200 batchs: 1393.0396728515625
INFO:root:Train (Epoch 63): Loss/seq after 00250 batchs: 1503.5379638671875
INFO:root:Train (Epoch 63): Loss/seq after 00300 batchs: 1433.098388671875
INFO:root:Train (Epoch 63): Loss/seq after 00350 batchs: 1339.671875
INFO:root:Train (Epoch 63): Loss/seq after 00400 batchs: 1376.939208984375
INFO:root:Train (Epoch 63): Loss/seq after 00450 batchs: 1320.6114501953125
INFO:root:Train (Epoch 63): Loss/seq after 00500 batchs: 1315.080078125
INFO:root:Train (Epoch 63): Loss/seq after 00550 batchs: 1261.4239501953125
INFO:root:Train (Epoch 63): Loss/seq after 00600 batchs: 1227.90087890625
INFO:root:Train (Epoch 63): Loss/seq after 00650 batchs: 1302.1346435546875
INFO:root:Train (Epoch 63): Loss/seq after 00700 batchs: 1398.0882568359375
INFO:root:Train (Epoch 63): Loss/seq after 00750 batchs: 1435.2218017578125
INFO:root:Train (Epoch 63): Loss/seq after 00800 batchs: 1411.36572265625
INFO:root:Train (Epoch 63): Loss/seq after 00850 batchs: 1373.9793701171875
INFO:root:Train (Epoch 63): Loss/seq after 00900 batchs: 1371.6468505859375
INFO:root:Train (Epoch 63): Loss/seq after 00950 batchs: 1454.26708984375
INFO:root:Train (Epoch 63): Loss/seq after 01000 batchs: 1451.4259033203125
INFO:root:Train (Epoch 63): Loss/seq after 01050 batchs: 1420.1148681640625
INFO:root:Train (Epoch 63): Loss/seq after 01100 batchs: 1405.5728759765625
INFO:root:Train (Epoch 63): Loss/seq after 01150 batchs: 1384.5555419921875
INFO:root:Train (Epoch 63): Loss/seq after 01200 batchs: 1367.9989013671875
INFO:root:Train (Epoch 63): Loss/seq after 01250 batchs: 1358.3978271484375
INFO:root:Train (Epoch 63): Loss/seq after 01300 batchs: 1376.3363037109375
INFO:root:Train (Epoch 63): Loss/seq after 01350 batchs: 1381.8018798828125
INFO:root:Train (Epoch 63): Loss/seq after 01400 batchs: 1430.970947265625
INFO:root:Train (Epoch 63): Loss/seq after 01450 batchs: 1415.5433349609375
INFO:root:Train (Epoch 63): Loss/seq after 01500 batchs: 1402.6103515625
INFO:root:Train (Epoch 63): Loss/seq after 01550 batchs: 1395.5133056640625
INFO:root:Train (Epoch 63): Loss/seq after 01600 batchs: 1375.6417236328125
INFO:root:Train (Epoch 63): Loss/seq after 01650 batchs: 1359.8697509765625
INFO:root:Train (Epoch 63): Loss/seq after 01700 batchs: 1347.7265625
INFO:root:Train (Epoch 63): Loss/seq after 01750 batchs: 1334.0982666015625
INFO:root:Train (Epoch 63): Loss/seq after 01800 batchs: 1317.9505615234375
INFO:root:Train (Epoch 63): Loss/seq after 01850 batchs: 1302.10302734375
INFO:root:Train (Epoch 63): Loss/seq after 01900 batchs: 1294.62744140625
INFO:root:Train (Epoch 63): Loss/seq after 01950 batchs: 1282.8834228515625
INFO:root:Train (Epoch 63): Loss/seq after 02000 batchs: 1271.9620361328125
INFO:root:Train (Epoch 63): Loss/seq after 02050 batchs: 1261.3372802734375
INFO:root:Train (Epoch 63): Loss/seq after 02100 batchs: 1248.6563720703125
INFO:root:Train (Epoch 63): Loss/seq after 02150 batchs: 1236.738037109375
INFO:root:Train (Epoch 63): Loss/seq after 02200 batchs: 1224.62109375
INFO:root:Train (Epoch 63): Loss/seq after 02250 batchs: 1221.3570556640625
INFO:root:Train (Epoch 63): Loss/seq after 02300 batchs: 1222.6746826171875
INFO:root:Train (Epoch 63): Loss/seq after 02350 batchs: 1211.1376953125
INFO:root:Train (Epoch 63): Loss/seq after 02400 batchs: 1205.4962158203125
INFO:root:Train (Epoch 63): Loss/seq after 02450 batchs: 1192.2093505859375
INFO:root:Train (Epoch 63): Loss/seq after 02500 batchs: 1175.4586181640625
INFO:root:Train (Epoch 63): Loss/seq after 02550 batchs: 1162.9954833984375
INFO:root:Train (Epoch 63): Loss/seq after 02600 batchs: 1160.108642578125
INFO:root:Train (Epoch 63): Loss/seq after 02650 batchs: 1154.9232177734375
INFO:root:Train (Epoch 63): Loss/seq after 02700 batchs: 1150.3062744140625
INFO:root:Train (Epoch 63): Loss/seq after 02750 batchs: 1173.802978515625
INFO:root:Train (Epoch 63): Loss/seq after 02800 batchs: 1177.692626953125
INFO:root:Train (Epoch 63): Loss/seq after 02850 batchs: 1172.6038818359375
INFO:root:Train (Epoch 63): Loss/seq after 02900 batchs: 1171.1402587890625
INFO:root:Train (Epoch 63): Loss/seq after 02950 batchs: 1162.8043212890625
INFO:root:Train (Epoch 63): Loss/seq after 03000 batchs: 1161.2867431640625
INFO:root:Train (Epoch 63): Loss/seq after 03050 batchs: 1163.8486328125
INFO:root:Train (Epoch 63): Loss/seq after 03100 batchs: 1173.6192626953125
INFO:root:Train (Epoch 63): Loss/seq after 03150 batchs: 1190.54638671875
INFO:root:Train (Epoch 63): Loss/seq after 03200 batchs: 1205.240234375
INFO:root:Train (Epoch 63): Loss/seq after 03250 batchs: 1219.1949462890625
INFO:root:Train (Epoch 63): Loss/seq after 03300 batchs: 1215.8333740234375
INFO:root:Train (Epoch 63): Loss/seq after 03350 batchs: 1214.4205322265625
INFO:root:Train (Epoch 63): Loss/seq after 03400 batchs: 1205.84912109375
INFO:root:Train (Epoch 63): Loss/seq after 03450 batchs: 1197.7265625
INFO:root:Train (Epoch 63): Loss/seq after 03500 batchs: 1195.1614990234375
INFO:root:Train (Epoch 63): Loss/seq after 03550 batchs: 1186.898193359375
INFO:root:Train (Epoch 63): Loss/seq after 03600 batchs: 1191.061279296875
INFO:root:Train (Epoch 63): Loss/seq after 03650 batchs: 1183.80517578125
INFO:root:Train (Epoch 63): Loss/seq after 03700 batchs: 1182.25732421875
INFO:root:Train (Epoch 63): Loss/seq after 03750 batchs: 1182.3875732421875
INFO:root:Train (Epoch 63): Loss/seq after 03800 batchs: 1175.65283203125
INFO:root:Train (Epoch 63): Loss/seq after 03850 batchs: 1171.259521484375
INFO:root:Train (Epoch 63): Loss/seq after 03900 batchs: 1176.99951171875
INFO:root:Train (Epoch 63): Loss/seq after 03950 batchs: 1184.48486328125
INFO:root:Train (Epoch 63): Loss/seq after 04000 batchs: 1175.8994140625
INFO:root:Train (Epoch 63): Loss/seq after 04050 batchs: 1168.2706298828125
INFO:root:Train (Epoch 63): Loss/seq after 04100 batchs: 1161.6002197265625
INFO:root:Train (Epoch 63): Loss/seq after 04150 batchs: 1155.98974609375
INFO:root:Train (Epoch 63): Loss/seq after 04200 batchs: 1149.70458984375
INFO:root:Train (Epoch 63): Loss/seq after 04250 batchs: 1145.2293701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 63): Loss/seq after 00000 batches: 880.4443359375
INFO:root:# Valid (Epoch 63): Loss/seq after 00050 batches: 1093.93505859375
INFO:root:# Valid (Epoch 63): Loss/seq after 00100 batches: 1378.27685546875
INFO:root:# Valid (Epoch 63): Loss/seq after 00150 batches: 1094.7635498046875
INFO:root:# Valid (Epoch 63): Loss/seq after 00200 batches: 983.20654296875
INFO:root:Artifacts: Make stick videos for epoch 63
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_63_on_20220423_014733.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_63_index_1162_on_20220423_014733.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 64): Loss/seq after 00000 batchs: 2445.30615234375
INFO:root:Train (Epoch 64): Loss/seq after 00050 batchs: 1530.6121826171875
INFO:root:Train (Epoch 64): Loss/seq after 00100 batchs: 1449.6986083984375
INFO:root:Train (Epoch 64): Loss/seq after 00150 batchs: 1271.3319091796875
INFO:root:Train (Epoch 64): Loss/seq after 00200 batchs: 1402.3028564453125
INFO:root:Train (Epoch 64): Loss/seq after 00250 batchs: 1516.0126953125
INFO:root:Train (Epoch 64): Loss/seq after 00300 batchs: 1443.5216064453125
INFO:root:Train (Epoch 64): Loss/seq after 00350 batchs: 1347.652099609375
INFO:root:Train (Epoch 64): Loss/seq after 00400 batchs: 1387.469970703125
INFO:root:Train (Epoch 64): Loss/seq after 00450 batchs: 1330.0089111328125
INFO:root:Train (Epoch 64): Loss/seq after 00500 batchs: 1324.7176513671875
INFO:root:Train (Epoch 64): Loss/seq after 00550 batchs: 1270.348876953125
INFO:root:Train (Epoch 64): Loss/seq after 00600 batchs: 1235.800537109375
INFO:root:Train (Epoch 64): Loss/seq after 00650 batchs: 1309.656005859375
INFO:root:Train (Epoch 64): Loss/seq after 00700 batchs: 1405.005859375
INFO:root:Train (Epoch 64): Loss/seq after 00750 batchs: 1444.0582275390625
INFO:root:Train (Epoch 64): Loss/seq after 00800 batchs: 1419.2752685546875
INFO:root:Train (Epoch 64): Loss/seq after 00850 batchs: 1381.64013671875
INFO:root:Train (Epoch 64): Loss/seq after 00900 batchs: 1378.673828125
INFO:root:Train (Epoch 64): Loss/seq after 00950 batchs: 1461.8157958984375
INFO:root:Train (Epoch 64): Loss/seq after 01000 batchs: 1459.467529296875
INFO:root:Train (Epoch 64): Loss/seq after 01050 batchs: 1427.5289306640625
INFO:root:Train (Epoch 64): Loss/seq after 01100 batchs: 1413.5108642578125
INFO:root:Train (Epoch 64): Loss/seq after 01150 batchs: 1392.13818359375
INFO:root:Train (Epoch 64): Loss/seq after 01200 batchs: 1375.0172119140625
INFO:root:Train (Epoch 64): Loss/seq after 01250 batchs: 1365.0238037109375
INFO:root:Train (Epoch 64): Loss/seq after 01300 batchs: 1382.2564697265625
INFO:root:Train (Epoch 64): Loss/seq after 01350 batchs: 1387.5390625
INFO:root:Train (Epoch 64): Loss/seq after 01400 batchs: 1434.9993896484375
INFO:root:Train (Epoch 64): Loss/seq after 01450 batchs: 1418.9578857421875
INFO:root:Train (Epoch 64): Loss/seq after 01500 batchs: 1405.888916015625
INFO:root:Train (Epoch 64): Loss/seq after 01550 batchs: 1397.7762451171875
INFO:root:Train (Epoch 64): Loss/seq after 01600 batchs: 1377.1883544921875
INFO:root:Train (Epoch 64): Loss/seq after 01650 batchs: 1360.0892333984375
INFO:root:Train (Epoch 64): Loss/seq after 01700 batchs: 1347.7669677734375
INFO:root:Train (Epoch 64): Loss/seq after 01750 batchs: 1334.02685546875
INFO:root:Train (Epoch 64): Loss/seq after 01800 batchs: 1317.763427734375
INFO:root:Train (Epoch 64): Loss/seq after 01850 batchs: 1301.6380615234375
INFO:root:Train (Epoch 64): Loss/seq after 01900 batchs: 1294.6251220703125
INFO:root:Train (Epoch 64): Loss/seq after 01950 batchs: 1285.25146484375
INFO:root:Train (Epoch 64): Loss/seq after 02000 batchs: 1274.60986328125
INFO:root:Train (Epoch 64): Loss/seq after 02050 batchs: 1264.1505126953125
INFO:root:Train (Epoch 64): Loss/seq after 02100 batchs: 1251.44921875
INFO:root:Train (Epoch 64): Loss/seq after 02150 batchs: 1239.6041259765625
INFO:root:Train (Epoch 64): Loss/seq after 02200 batchs: 1227.455078125
INFO:root:Train (Epoch 64): Loss/seq after 02250 batchs: 1224.867919921875
INFO:root:Train (Epoch 64): Loss/seq after 02300 batchs: 1226.0908203125
INFO:root:Train (Epoch 64): Loss/seq after 02350 batchs: 1215.6793212890625
INFO:root:Train (Epoch 64): Loss/seq after 02400 batchs: 1210.015869140625
INFO:root:Train (Epoch 64): Loss/seq after 02450 batchs: 1196.6080322265625
INFO:root:Train (Epoch 64): Loss/seq after 02500 batchs: 1179.759765625
INFO:root:Train (Epoch 64): Loss/seq after 02550 batchs: 1167.32568359375
INFO:root:Train (Epoch 64): Loss/seq after 02600 batchs: 1164.407470703125
INFO:root:Train (Epoch 64): Loss/seq after 02650 batchs: 1159.1893310546875
INFO:root:Train (Epoch 64): Loss/seq after 02700 batchs: 1154.248046875
INFO:root:Train (Epoch 64): Loss/seq after 02750 batchs: 1177.8948974609375
INFO:root:Train (Epoch 64): Loss/seq after 02800 batchs: 1181.9287109375
INFO:root:Train (Epoch 64): Loss/seq after 02850 batchs: 1176.691650390625
INFO:root:Train (Epoch 64): Loss/seq after 02900 batchs: 1174.3084716796875
INFO:root:Train (Epoch 64): Loss/seq after 02950 batchs: 1165.75244140625
INFO:root:Train (Epoch 64): Loss/seq after 03000 batchs: 1164.1552734375
INFO:root:Train (Epoch 64): Loss/seq after 03050 batchs: 1166.6531982421875
INFO:root:Train (Epoch 64): Loss/seq after 03100 batchs: 1176.3172607421875
INFO:root:Train (Epoch 64): Loss/seq after 03150 batchs: 1192.1363525390625
INFO:root:Train (Epoch 64): Loss/seq after 03200 batchs: 1206.9036865234375
INFO:root:Train (Epoch 64): Loss/seq after 03250 batchs: 1220.9854736328125
INFO:root:Train (Epoch 64): Loss/seq after 03300 batchs: 1218.0670166015625
INFO:root:Train (Epoch 64): Loss/seq after 03350 batchs: 1216.867431640625
INFO:root:Train (Epoch 64): Loss/seq after 03400 batchs: 1208.2635498046875
INFO:root:Train (Epoch 64): Loss/seq after 03450 batchs: 1199.9554443359375
INFO:root:Train (Epoch 64): Loss/seq after 03500 batchs: 1197.2408447265625
INFO:root:Train (Epoch 64): Loss/seq after 03550 batchs: 1188.8499755859375
INFO:root:Train (Epoch 64): Loss/seq after 03600 batchs: 1193.4287109375
INFO:root:Train (Epoch 64): Loss/seq after 03650 batchs: 1186.3662109375
INFO:root:Train (Epoch 64): Loss/seq after 03700 batchs: 1184.8626708984375
INFO:root:Train (Epoch 64): Loss/seq after 03750 batchs: 1184.938232421875
INFO:root:Train (Epoch 64): Loss/seq after 03800 batchs: 1178.086181640625
INFO:root:Train (Epoch 64): Loss/seq after 03850 batchs: 1173.5262451171875
INFO:root:Train (Epoch 64): Loss/seq after 03900 batchs: 1179.0989990234375
INFO:root:Train (Epoch 64): Loss/seq after 03950 batchs: 1186.810546875
INFO:root:Train (Epoch 64): Loss/seq after 04000 batchs: 1178.194580078125
INFO:root:Train (Epoch 64): Loss/seq after 04050 batchs: 1170.5108642578125
INFO:root:Train (Epoch 64): Loss/seq after 04100 batchs: 1163.9560546875
INFO:root:Train (Epoch 64): Loss/seq after 04150 batchs: 1158.2791748046875
INFO:root:Train (Epoch 64): Loss/seq after 04200 batchs: 1152.0830078125
INFO:root:Train (Epoch 64): Loss/seq after 04250 batchs: 1147.677734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 64): Loss/seq after 00000 batches: 868.1437377929688
INFO:root:# Valid (Epoch 64): Loss/seq after 00050 batches: 1088.189453125
INFO:root:# Valid (Epoch 64): Loss/seq after 00100 batches: 1375.2022705078125
INFO:root:# Valid (Epoch 64): Loss/seq after 00150 batches: 1094.32568359375
INFO:root:# Valid (Epoch 64): Loss/seq after 00200 batches: 982.4159545898438
INFO:root:Artifacts: Make stick videos for epoch 64
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_64_on_20220423_015217.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_64_index_139_on_20220423_015217.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 65): Loss/seq after 00000 batchs: 2439.4453125
INFO:root:Train (Epoch 65): Loss/seq after 00050 batchs: 1516.5386962890625
INFO:root:Train (Epoch 65): Loss/seq after 00100 batchs: 1413.285888671875
INFO:root:Train (Epoch 65): Loss/seq after 00150 batchs: 1248.367919921875
INFO:root:Train (Epoch 65): Loss/seq after 00200 batchs: 1378.372802734375
INFO:root:Train (Epoch 65): Loss/seq after 00250 batchs: 1493.1839599609375
INFO:root:Train (Epoch 65): Loss/seq after 00300 batchs: 1424.681884765625
INFO:root:Train (Epoch 65): Loss/seq after 00350 batchs: 1334.0328369140625
INFO:root:Train (Epoch 65): Loss/seq after 00400 batchs: 1375.75830078125
INFO:root:Train (Epoch 65): Loss/seq after 00450 batchs: 1320.0267333984375
INFO:root:Train (Epoch 65): Loss/seq after 00500 batchs: 1312.376953125
INFO:root:Train (Epoch 65): Loss/seq after 00550 batchs: 1258.8519287109375
INFO:root:Train (Epoch 65): Loss/seq after 00600 batchs: 1226.6988525390625
INFO:root:Train (Epoch 65): Loss/seq after 00650 batchs: 1300.895263671875
INFO:root:Train (Epoch 65): Loss/seq after 00700 batchs: 1397.3194580078125
INFO:root:Train (Epoch 65): Loss/seq after 00750 batchs: 1438.073974609375
INFO:root:Train (Epoch 65): Loss/seq after 00800 batchs: 1415.7515869140625
INFO:root:Train (Epoch 65): Loss/seq after 00850 batchs: 1379.1322021484375
INFO:root:Train (Epoch 65): Loss/seq after 00900 batchs: 1377.304443359375
INFO:root:Train (Epoch 65): Loss/seq after 00950 batchs: 1460.1126708984375
INFO:root:Train (Epoch 65): Loss/seq after 01000 batchs: 1458.609375
INFO:root:Train (Epoch 65): Loss/seq after 01050 batchs: 1430.0145263671875
INFO:root:Train (Epoch 65): Loss/seq after 01100 batchs: 1415.98046875
INFO:root:Train (Epoch 65): Loss/seq after 01150 batchs: 1394.95703125
INFO:root:Train (Epoch 65): Loss/seq after 01200 batchs: 1379.3568115234375
INFO:root:Train (Epoch 65): Loss/seq after 01250 batchs: 1369.4263916015625
INFO:root:Train (Epoch 65): Loss/seq after 01300 batchs: 1386.4459228515625
INFO:root:Train (Epoch 65): Loss/seq after 01350 batchs: 1391.46826171875
INFO:root:Train (Epoch 65): Loss/seq after 01400 batchs: 1438.427490234375
INFO:root:Train (Epoch 65): Loss/seq after 01450 batchs: 1423.1573486328125
INFO:root:Train (Epoch 65): Loss/seq after 01500 batchs: 1409.978759765625
INFO:root:Train (Epoch 65): Loss/seq after 01550 batchs: 1402.3487548828125
INFO:root:Train (Epoch 65): Loss/seq after 01600 batchs: 1381.8345947265625
INFO:root:Train (Epoch 65): Loss/seq after 01650 batchs: 1365.072509765625
INFO:root:Train (Epoch 65): Loss/seq after 01700 batchs: 1352.612548828125
INFO:root:Train (Epoch 65): Loss/seq after 01750 batchs: 1338.818603515625
INFO:root:Train (Epoch 65): Loss/seq after 01800 batchs: 1322.6717529296875
INFO:root:Train (Epoch 65): Loss/seq after 01850 batchs: 1306.4219970703125
INFO:root:Train (Epoch 65): Loss/seq after 01900 batchs: 1299.38427734375
INFO:root:Train (Epoch 65): Loss/seq after 01950 batchs: 1288.06298828125
INFO:root:Train (Epoch 65): Loss/seq after 02000 batchs: 1277.32666015625
INFO:root:Train (Epoch 65): Loss/seq after 02050 batchs: 1266.6343994140625
INFO:root:Train (Epoch 65): Loss/seq after 02100 batchs: 1253.7950439453125
INFO:root:Train (Epoch 65): Loss/seq after 02150 batchs: 1241.7681884765625
INFO:root:Train (Epoch 65): Loss/seq after 02200 batchs: 1229.563720703125
INFO:root:Train (Epoch 65): Loss/seq after 02250 batchs: 1226.1910400390625
INFO:root:Train (Epoch 65): Loss/seq after 02300 batchs: 1227.35693359375
INFO:root:Train (Epoch 65): Loss/seq after 02350 batchs: 1215.3438720703125
INFO:root:Train (Epoch 65): Loss/seq after 02400 batchs: 1209.487548828125
INFO:root:Train (Epoch 65): Loss/seq after 02450 batchs: 1196.0703125
INFO:root:Train (Epoch 65): Loss/seq after 02500 batchs: 1179.2408447265625
INFO:root:Train (Epoch 65): Loss/seq after 02550 batchs: 1166.7266845703125
INFO:root:Train (Epoch 65): Loss/seq after 02600 batchs: 1163.705322265625
INFO:root:Train (Epoch 65): Loss/seq after 02650 batchs: 1158.469970703125
INFO:root:Train (Epoch 65): Loss/seq after 02700 batchs: 1153.6568603515625
INFO:root:Train (Epoch 65): Loss/seq after 02750 batchs: 1178.1787109375
INFO:root:Train (Epoch 65): Loss/seq after 02800 batchs: 1182.0435791015625
INFO:root:Train (Epoch 65): Loss/seq after 02850 batchs: 1176.875732421875
INFO:root:Train (Epoch 65): Loss/seq after 02900 batchs: 1174.6976318359375
INFO:root:Train (Epoch 65): Loss/seq after 02950 batchs: 1166.159912109375
INFO:root:Train (Epoch 65): Loss/seq after 03000 batchs: 1164.5787353515625
INFO:root:Train (Epoch 65): Loss/seq after 03050 batchs: 1167.13232421875
INFO:root:Train (Epoch 65): Loss/seq after 03100 batchs: 1176.2364501953125
INFO:root:Train (Epoch 65): Loss/seq after 03150 batchs: 1192.3682861328125
INFO:root:Train (Epoch 65): Loss/seq after 03200 batchs: 1207.0709228515625
INFO:root:Train (Epoch 65): Loss/seq after 03250 batchs: 1221.1065673828125
INFO:root:Train (Epoch 65): Loss/seq after 03300 batchs: 1217.8292236328125
INFO:root:Train (Epoch 65): Loss/seq after 03350 batchs: 1215.9959716796875
INFO:root:Train (Epoch 65): Loss/seq after 03400 batchs: 1207.4385986328125
INFO:root:Train (Epoch 65): Loss/seq after 03450 batchs: 1199.3857421875
INFO:root:Train (Epoch 65): Loss/seq after 03500 batchs: 1196.7091064453125
INFO:root:Train (Epoch 65): Loss/seq after 03550 batchs: 1188.6817626953125
INFO:root:Train (Epoch 65): Loss/seq after 03600 batchs: 1193.7313232421875
INFO:root:Train (Epoch 65): Loss/seq after 03650 batchs: 1186.5533447265625
INFO:root:Train (Epoch 65): Loss/seq after 03700 batchs: 1185.03857421875
INFO:root:Train (Epoch 65): Loss/seq after 03750 batchs: 1185.168212890625
INFO:root:Train (Epoch 65): Loss/seq after 03800 batchs: 1178.293701171875
INFO:root:Train (Epoch 65): Loss/seq after 03850 batchs: 1173.7694091796875
INFO:root:Train (Epoch 65): Loss/seq after 03900 batchs: 1179.4549560546875
INFO:root:Train (Epoch 65): Loss/seq after 03950 batchs: 1187.275146484375
INFO:root:Train (Epoch 65): Loss/seq after 04000 batchs: 1178.6407470703125
INFO:root:Train (Epoch 65): Loss/seq after 04050 batchs: 1170.9560546875
INFO:root:Train (Epoch 65): Loss/seq after 04100 batchs: 1164.388427734375
INFO:root:Train (Epoch 65): Loss/seq after 04150 batchs: 1158.8819580078125
INFO:root:Train (Epoch 65): Loss/seq after 04200 batchs: 1152.591796875
INFO:root:Train (Epoch 65): Loss/seq after 04250 batchs: 1148.0770263671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 65): Loss/seq after 00000 batches: 886.6864013671875
INFO:root:# Valid (Epoch 65): Loss/seq after 00050 batches: 1101.670654296875
INFO:root:# Valid (Epoch 65): Loss/seq after 00100 batches: 1383.8433837890625
INFO:root:# Valid (Epoch 65): Loss/seq after 00150 batches: 1097.2989501953125
INFO:root:# Valid (Epoch 65): Loss/seq after 00200 batches: 984.9456176757812
INFO:root:Artifacts: Make stick videos for epoch 65
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_65_on_20220423_015709.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_65_index_823_on_20220423_015709.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 66): Loss/seq after 00000 batchs: 2465.529296875
INFO:root:Train (Epoch 66): Loss/seq after 00050 batchs: 1531.7431640625
INFO:root:Train (Epoch 66): Loss/seq after 00100 batchs: 1442.64306640625
INFO:root:Train (Epoch 66): Loss/seq after 00150 batchs: 1263.093017578125
INFO:root:Train (Epoch 66): Loss/seq after 00200 batchs: 1386.7921142578125
INFO:root:Train (Epoch 66): Loss/seq after 00250 batchs: 1498.0250244140625
INFO:root:Train (Epoch 66): Loss/seq after 00300 batchs: 1428.5323486328125
INFO:root:Train (Epoch 66): Loss/seq after 00350 batchs: 1335.054443359375
INFO:root:Train (Epoch 66): Loss/seq after 00400 batchs: 1374.022705078125
INFO:root:Train (Epoch 66): Loss/seq after 00450 batchs: 1317.9132080078125
INFO:root:Train (Epoch 66): Loss/seq after 00500 batchs: 1310.5382080078125
INFO:root:Train (Epoch 66): Loss/seq after 00550 batchs: 1257.193359375
INFO:root:Train (Epoch 66): Loss/seq after 00600 batchs: 1224.487060546875
INFO:root:Train (Epoch 66): Loss/seq after 00650 batchs: 1299.1876220703125
INFO:root:Train (Epoch 66): Loss/seq after 00700 batchs: 1395.8287353515625
INFO:root:Train (Epoch 66): Loss/seq after 00750 batchs: 1434.220703125
INFO:root:Train (Epoch 66): Loss/seq after 00800 batchs: 1409.40087890625
INFO:root:Train (Epoch 66): Loss/seq after 00850 batchs: 1371.6884765625
INFO:root:Train (Epoch 66): Loss/seq after 00900 batchs: 1370.185302734375
INFO:root:Train (Epoch 66): Loss/seq after 00950 batchs: 1453.7900390625
INFO:root:Train (Epoch 66): Loss/seq after 01000 batchs: 1452.0010986328125
INFO:root:Train (Epoch 66): Loss/seq after 01050 batchs: 1421.7054443359375
INFO:root:Train (Epoch 66): Loss/seq after 01100 batchs: 1408.5460205078125
INFO:root:Train (Epoch 66): Loss/seq after 01150 batchs: 1388.5841064453125
INFO:root:Train (Epoch 66): Loss/seq after 01200 batchs: 1373.2149658203125
INFO:root:Train (Epoch 66): Loss/seq after 01250 batchs: 1364.1341552734375
INFO:root:Train (Epoch 66): Loss/seq after 01300 batchs: 1381.158935546875
INFO:root:Train (Epoch 66): Loss/seq after 01350 batchs: 1386.49462890625
INFO:root:Train (Epoch 66): Loss/seq after 01400 batchs: 1433.9898681640625
INFO:root:Train (Epoch 66): Loss/seq after 01450 batchs: 1418.3548583984375
INFO:root:Train (Epoch 66): Loss/seq after 01500 batchs: 1405.3807373046875
INFO:root:Train (Epoch 66): Loss/seq after 01550 batchs: 1398.0350341796875
INFO:root:Train (Epoch 66): Loss/seq after 01600 batchs: 1377.668212890625
INFO:root:Train (Epoch 66): Loss/seq after 01650 batchs: 1361.208251953125
INFO:root:Train (Epoch 66): Loss/seq after 01700 batchs: 1348.9334716796875
INFO:root:Train (Epoch 66): Loss/seq after 01750 batchs: 1335.2630615234375
INFO:root:Train (Epoch 66): Loss/seq after 01800 batchs: 1318.9344482421875
INFO:root:Train (Epoch 66): Loss/seq after 01850 batchs: 1302.7772216796875
INFO:root:Train (Epoch 66): Loss/seq after 01900 batchs: 1295.2945556640625
INFO:root:Train (Epoch 66): Loss/seq after 01950 batchs: 1283.557861328125
INFO:root:Train (Epoch 66): Loss/seq after 02000 batchs: 1272.560302734375
INFO:root:Train (Epoch 66): Loss/seq after 02050 batchs: 1262.010009765625
INFO:root:Train (Epoch 66): Loss/seq after 02100 batchs: 1249.326904296875
INFO:root:Train (Epoch 66): Loss/seq after 02150 batchs: 1237.47265625
INFO:root:Train (Epoch 66): Loss/seq after 02200 batchs: 1225.357421875
INFO:root:Train (Epoch 66): Loss/seq after 02250 batchs: 1222.4761962890625
INFO:root:Train (Epoch 66): Loss/seq after 02300 batchs: 1224.069091796875
INFO:root:Train (Epoch 66): Loss/seq after 02350 batchs: 1212.2337646484375
INFO:root:Train (Epoch 66): Loss/seq after 02400 batchs: 1206.672119140625
INFO:root:Train (Epoch 66): Loss/seq after 02450 batchs: 1193.4405517578125
INFO:root:Train (Epoch 66): Loss/seq after 02500 batchs: 1176.6875
INFO:root:Train (Epoch 66): Loss/seq after 02550 batchs: 1164.363525390625
INFO:root:Train (Epoch 66): Loss/seq after 02600 batchs: 1161.4703369140625
INFO:root:Train (Epoch 66): Loss/seq after 02650 batchs: 1156.28955078125
INFO:root:Train (Epoch 66): Loss/seq after 02700 batchs: 1151.642578125
INFO:root:Train (Epoch 66): Loss/seq after 02750 batchs: 1173.7215576171875
INFO:root:Train (Epoch 66): Loss/seq after 02800 batchs: 1177.5078125
INFO:root:Train (Epoch 66): Loss/seq after 02850 batchs: 1172.4188232421875
INFO:root:Train (Epoch 66): Loss/seq after 02900 batchs: 1171.0330810546875
INFO:root:Train (Epoch 66): Loss/seq after 02950 batchs: 1163.3468017578125
INFO:root:Train (Epoch 66): Loss/seq after 03000 batchs: 1161.9173583984375
INFO:root:Train (Epoch 66): Loss/seq after 03050 batchs: 1164.735595703125
INFO:root:Train (Epoch 66): Loss/seq after 03100 batchs: 1174.9012451171875
INFO:root:Train (Epoch 66): Loss/seq after 03150 batchs: 1190.968994140625
INFO:root:Train (Epoch 66): Loss/seq after 03200 batchs: 1205.7091064453125
INFO:root:Train (Epoch 66): Loss/seq after 03250 batchs: 1219.71728515625
INFO:root:Train (Epoch 66): Loss/seq after 03300 batchs: 1217.3106689453125
INFO:root:Train (Epoch 66): Loss/seq after 03350 batchs: 1215.81005859375
INFO:root:Train (Epoch 66): Loss/seq after 03400 batchs: 1207.2105712890625
INFO:root:Train (Epoch 66): Loss/seq after 03450 batchs: 1199.562255859375
INFO:root:Train (Epoch 66): Loss/seq after 03500 batchs: 1196.9681396484375
INFO:root:Train (Epoch 66): Loss/seq after 03550 batchs: 1188.7215576171875
INFO:root:Train (Epoch 66): Loss/seq after 03600 batchs: 1192.96875
INFO:root:Train (Epoch 66): Loss/seq after 03650 batchs: 1185.587158203125
INFO:root:Train (Epoch 66): Loss/seq after 03700 batchs: 1183.9703369140625
INFO:root:Train (Epoch 66): Loss/seq after 03750 batchs: 1184.12890625
INFO:root:Train (Epoch 66): Loss/seq after 03800 batchs: 1177.3656005859375
INFO:root:Train (Epoch 66): Loss/seq after 03850 batchs: 1172.78515625
INFO:root:Train (Epoch 66): Loss/seq after 03900 batchs: 1178.3631591796875
INFO:root:Train (Epoch 66): Loss/seq after 03950 batchs: 1185.8948974609375
INFO:root:Train (Epoch 66): Loss/seq after 04000 batchs: 1177.296630859375
INFO:root:Train (Epoch 66): Loss/seq after 04050 batchs: 1169.62109375
INFO:root:Train (Epoch 66): Loss/seq after 04100 batchs: 1163.025390625
INFO:root:Train (Epoch 66): Loss/seq after 04150 batchs: 1157.5064697265625
INFO:root:Train (Epoch 66): Loss/seq after 04200 batchs: 1151.421630859375
INFO:root:Train (Epoch 66): Loss/seq after 04250 batchs: 1146.99462890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 66): Loss/seq after 00000 batches: 882.4566650390625
INFO:root:# Valid (Epoch 66): Loss/seq after 00050 batches: 1115.706787109375
INFO:root:# Valid (Epoch 66): Loss/seq after 00100 batches: 1406.3046875
INFO:root:# Valid (Epoch 66): Loss/seq after 00150 batches: 1121.632080078125
INFO:root:# Valid (Epoch 66): Loss/seq after 00200 batches: 1009.8458251953125
INFO:root:Artifacts: Make stick videos for epoch 66
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_66_on_20220423_020204.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_66_index_1536_on_20220423_020204.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 67): Loss/seq after 00000 batchs: 2461.580078125
INFO:root:Train (Epoch 67): Loss/seq after 00050 batchs: 1588.5128173828125
INFO:root:Train (Epoch 67): Loss/seq after 00100 batchs: 1464.978271484375
INFO:root:Train (Epoch 67): Loss/seq after 00150 batchs: 1280.17724609375
INFO:root:Train (Epoch 67): Loss/seq after 00200 batchs: 1401.7557373046875
INFO:root:Train (Epoch 67): Loss/seq after 00250 batchs: 1512.1783447265625
INFO:root:Train (Epoch 67): Loss/seq after 00300 batchs: 1440.327392578125
INFO:root:Train (Epoch 67): Loss/seq after 00350 batchs: 1345.14892578125
INFO:root:Train (Epoch 67): Loss/seq after 00400 batchs: 1382.6141357421875
INFO:root:Train (Epoch 67): Loss/seq after 00450 batchs: 1325.54443359375
INFO:root:Train (Epoch 67): Loss/seq after 00500 batchs: 1318.2557373046875
INFO:root:Train (Epoch 67): Loss/seq after 00550 batchs: 1264.6241455078125
INFO:root:Train (Epoch 67): Loss/seq after 00600 batchs: 1230.7491455078125
INFO:root:Train (Epoch 67): Loss/seq after 00650 batchs: 1304.6103515625
INFO:root:Train (Epoch 67): Loss/seq after 00700 batchs: 1399.861572265625
INFO:root:Train (Epoch 67): Loss/seq after 00750 batchs: 1439.72119140625
INFO:root:Train (Epoch 67): Loss/seq after 00800 batchs: 1415.0206298828125
INFO:root:Train (Epoch 67): Loss/seq after 00850 batchs: 1377.249267578125
INFO:root:Train (Epoch 67): Loss/seq after 00900 batchs: 1374.40625
INFO:root:Train (Epoch 67): Loss/seq after 00950 batchs: 1457.0701904296875
INFO:root:Train (Epoch 67): Loss/seq after 01000 batchs: 1455.2498779296875
INFO:root:Train (Epoch 67): Loss/seq after 01050 batchs: 1424.412353515625
INFO:root:Train (Epoch 67): Loss/seq after 01100 batchs: 1411.2684326171875
INFO:root:Train (Epoch 67): Loss/seq after 01150 batchs: 1390.165283203125
INFO:root:Train (Epoch 67): Loss/seq after 01200 batchs: 1373.9144287109375
INFO:root:Train (Epoch 67): Loss/seq after 01250 batchs: 1363.9517822265625
INFO:root:Train (Epoch 67): Loss/seq after 01300 batchs: 1381.1278076171875
INFO:root:Train (Epoch 67): Loss/seq after 01350 batchs: 1386.444580078125
INFO:root:Train (Epoch 67): Loss/seq after 01400 batchs: 1434.0267333984375
INFO:root:Train (Epoch 67): Loss/seq after 01450 batchs: 1418.4873046875
INFO:root:Train (Epoch 67): Loss/seq after 01500 batchs: 1405.3509521484375
INFO:root:Train (Epoch 67): Loss/seq after 01550 batchs: 1397.7386474609375
INFO:root:Train (Epoch 67): Loss/seq after 01600 batchs: 1377.19091796875
INFO:root:Train (Epoch 67): Loss/seq after 01650 batchs: 1360.2208251953125
INFO:root:Train (Epoch 67): Loss/seq after 01700 batchs: 1347.8956298828125
INFO:root:Train (Epoch 67): Loss/seq after 01750 batchs: 1334.181396484375
INFO:root:Train (Epoch 67): Loss/seq after 01800 batchs: 1317.9727783203125
INFO:root:Train (Epoch 67): Loss/seq after 01850 batchs: 1301.8118896484375
INFO:root:Train (Epoch 67): Loss/seq after 01900 batchs: 1294.4697265625
INFO:root:Train (Epoch 67): Loss/seq after 01950 batchs: 1283.8118896484375
INFO:root:Train (Epoch 67): Loss/seq after 02000 batchs: 1273.2252197265625
INFO:root:Train (Epoch 67): Loss/seq after 02050 batchs: 1262.6605224609375
INFO:root:Train (Epoch 67): Loss/seq after 02100 batchs: 1249.910888671875
INFO:root:Train (Epoch 67): Loss/seq after 02150 batchs: 1238.0362548828125
INFO:root:Train (Epoch 67): Loss/seq after 02200 batchs: 1225.8695068359375
INFO:root:Train (Epoch 67): Loss/seq after 02250 batchs: 1223.7109375
INFO:root:Train (Epoch 67): Loss/seq after 02300 batchs: 1225.256591796875
INFO:root:Train (Epoch 67): Loss/seq after 02350 batchs: 1214.9066162109375
INFO:root:Train (Epoch 67): Loss/seq after 02400 batchs: 1209.2088623046875
INFO:root:Train (Epoch 67): Loss/seq after 02450 batchs: 1195.85791015625
INFO:root:Train (Epoch 67): Loss/seq after 02500 batchs: 1179.04443359375
INFO:root:Train (Epoch 67): Loss/seq after 02550 batchs: 1166.7763671875
INFO:root:Train (Epoch 67): Loss/seq after 02600 batchs: 1163.8858642578125
INFO:root:Train (Epoch 67): Loss/seq after 02650 batchs: 1158.7423095703125
INFO:root:Train (Epoch 67): Loss/seq after 02700 batchs: 1153.9464111328125
INFO:root:Train (Epoch 67): Loss/seq after 02750 batchs: 1175.500732421875
INFO:root:Train (Epoch 67): Loss/seq after 02800 batchs: 1179.0511474609375
INFO:root:Train (Epoch 67): Loss/seq after 02850 batchs: 1173.7955322265625
INFO:root:Train (Epoch 67): Loss/seq after 02900 batchs: 1170.8809814453125
INFO:root:Train (Epoch 67): Loss/seq after 02950 batchs: 1162.29248046875
INFO:root:Train (Epoch 67): Loss/seq after 03000 batchs: 1160.7640380859375
INFO:root:Train (Epoch 67): Loss/seq after 03050 batchs: 1163.3577880859375
INFO:root:Train (Epoch 67): Loss/seq after 03100 batchs: 1172.5850830078125
INFO:root:Train (Epoch 67): Loss/seq after 03150 batchs: 1188.5714111328125
INFO:root:Train (Epoch 67): Loss/seq after 03200 batchs: 1203.3092041015625
INFO:root:Train (Epoch 67): Loss/seq after 03250 batchs: 1217.4417724609375
INFO:root:Train (Epoch 67): Loss/seq after 03300 batchs: 1214.39306640625
INFO:root:Train (Epoch 67): Loss/seq after 03350 batchs: 1212.769287109375
INFO:root:Train (Epoch 67): Loss/seq after 03400 batchs: 1204.25390625
INFO:root:Train (Epoch 67): Loss/seq after 03450 batchs: 1196.1326904296875
INFO:root:Train (Epoch 67): Loss/seq after 03500 batchs: 1194.285888671875
INFO:root:Train (Epoch 67): Loss/seq after 03550 batchs: 1185.8441162109375
INFO:root:Train (Epoch 67): Loss/seq after 03600 batchs: 1190.0135498046875
INFO:root:Train (Epoch 67): Loss/seq after 03650 batchs: 1182.7041015625
INFO:root:Train (Epoch 67): Loss/seq after 03700 batchs: 1181.6448974609375
INFO:root:Train (Epoch 67): Loss/seq after 03750 batchs: 1181.8001708984375
INFO:root:Train (Epoch 67): Loss/seq after 03800 batchs: 1174.9979248046875
INFO:root:Train (Epoch 67): Loss/seq after 03850 batchs: 1170.43798828125
INFO:root:Train (Epoch 67): Loss/seq after 03900 batchs: 1176.1844482421875
INFO:root:Train (Epoch 67): Loss/seq after 03950 batchs: 1184.0660400390625
INFO:root:Train (Epoch 67): Loss/seq after 04000 batchs: 1175.487548828125
INFO:root:Train (Epoch 67): Loss/seq after 04050 batchs: 1167.850830078125
INFO:root:Train (Epoch 67): Loss/seq after 04100 batchs: 1161.217529296875
INFO:root:Train (Epoch 67): Loss/seq after 04150 batchs: 1155.611083984375
INFO:root:Train (Epoch 67): Loss/seq after 04200 batchs: 1149.4122314453125
INFO:root:Train (Epoch 67): Loss/seq after 04250 batchs: 1145.0084228515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 67): Loss/seq after 00000 batches: 876.3038940429688
INFO:root:# Valid (Epoch 67): Loss/seq after 00050 batches: 1092.3001708984375
INFO:root:# Valid (Epoch 67): Loss/seq after 00100 batches: 1376.8170166015625
INFO:root:# Valid (Epoch 67): Loss/seq after 00150 batches: 1095.2998046875
INFO:root:# Valid (Epoch 67): Loss/seq after 00200 batches: 983.0299682617188
INFO:root:Artifacts: Make stick videos for epoch 67
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_67_on_20220423_020652.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_67_index_1075_on_20220423_020652.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 68): Loss/seq after 00000 batchs: 2431.121826171875
INFO:root:Train (Epoch 68): Loss/seq after 00050 batchs: 1542.3572998046875
INFO:root:Train (Epoch 68): Loss/seq after 00100 batchs: 1450.6123046875
INFO:root:Train (Epoch 68): Loss/seq after 00150 batchs: 1274.0028076171875
INFO:root:Train (Epoch 68): Loss/seq after 00200 batchs: 1394.8974609375
INFO:root:Train (Epoch 68): Loss/seq after 00250 batchs: 1510.2293701171875
INFO:root:Train (Epoch 68): Loss/seq after 00300 batchs: 1438.8519287109375
INFO:root:Train (Epoch 68): Loss/seq after 00350 batchs: 1343.64453125
INFO:root:Train (Epoch 68): Loss/seq after 00400 batchs: 1382.1287841796875
INFO:root:Train (Epoch 68): Loss/seq after 00450 batchs: 1324.9569091796875
INFO:root:Train (Epoch 68): Loss/seq after 00500 batchs: 1315.98291015625
INFO:root:Train (Epoch 68): Loss/seq after 00550 batchs: 1264.227783203125
INFO:root:Train (Epoch 68): Loss/seq after 00600 batchs: 1230.449951171875
INFO:root:Train (Epoch 68): Loss/seq after 00650 batchs: 1304.213623046875
INFO:root:Train (Epoch 68): Loss/seq after 00700 batchs: 1400.177490234375
INFO:root:Train (Epoch 68): Loss/seq after 00750 batchs: 1438.77197265625
INFO:root:Train (Epoch 68): Loss/seq after 00800 batchs: 1413.4124755859375
INFO:root:Train (Epoch 68): Loss/seq after 00850 batchs: 1375.44189453125
INFO:root:Train (Epoch 68): Loss/seq after 00900 batchs: 1372.6641845703125
INFO:root:Train (Epoch 68): Loss/seq after 00950 batchs: 1456.585693359375
INFO:root:Train (Epoch 68): Loss/seq after 01000 batchs: 1454.495361328125
INFO:root:Train (Epoch 68): Loss/seq after 01050 batchs: 1423.336181640625
INFO:root:Train (Epoch 68): Loss/seq after 01100 batchs: 1409.0589599609375
INFO:root:Train (Epoch 68): Loss/seq after 01150 batchs: 1388.21875
INFO:root:Train (Epoch 68): Loss/seq after 01200 batchs: 1371.739990234375
INFO:root:Train (Epoch 68): Loss/seq after 01250 batchs: 1361.5433349609375
INFO:root:Train (Epoch 68): Loss/seq after 01300 batchs: 1378.6309814453125
INFO:root:Train (Epoch 68): Loss/seq after 01350 batchs: 1384.14306640625
INFO:root:Train (Epoch 68): Loss/seq after 01400 batchs: 1431.5667724609375
INFO:root:Train (Epoch 68): Loss/seq after 01450 batchs: 1415.715087890625
INFO:root:Train (Epoch 68): Loss/seq after 01500 batchs: 1402.7811279296875
INFO:root:Train (Epoch 68): Loss/seq after 01550 batchs: 1395.2001953125
INFO:root:Train (Epoch 68): Loss/seq after 01600 batchs: 1374.7567138671875
INFO:root:Train (Epoch 68): Loss/seq after 01650 batchs: 1357.732421875
INFO:root:Train (Epoch 68): Loss/seq after 01700 batchs: 1345.49853515625
INFO:root:Train (Epoch 68): Loss/seq after 01750 batchs: 1331.8658447265625
INFO:root:Train (Epoch 68): Loss/seq after 01800 batchs: 1315.7808837890625
INFO:root:Train (Epoch 68): Loss/seq after 01850 batchs: 1299.6922607421875
INFO:root:Train (Epoch 68): Loss/seq after 01900 batchs: 1292.409912109375
INFO:root:Train (Epoch 68): Loss/seq after 01950 batchs: 1281.3670654296875
INFO:root:Train (Epoch 68): Loss/seq after 02000 batchs: 1270.6754150390625
INFO:root:Train (Epoch 68): Loss/seq after 02050 batchs: 1259.9598388671875
INFO:root:Train (Epoch 68): Loss/seq after 02100 batchs: 1247.1649169921875
INFO:root:Train (Epoch 68): Loss/seq after 02150 batchs: 1235.2003173828125
INFO:root:Train (Epoch 68): Loss/seq after 02200 batchs: 1223.0482177734375
INFO:root:Train (Epoch 68): Loss/seq after 02250 batchs: 1219.5257568359375
INFO:root:Train (Epoch 68): Loss/seq after 02300 batchs: 1220.97509765625
INFO:root:Train (Epoch 68): Loss/seq after 02350 batchs: 1208.902587890625
INFO:root:Train (Epoch 68): Loss/seq after 02400 batchs: 1203.222412109375
INFO:root:Train (Epoch 68): Loss/seq after 02450 batchs: 1189.9461669921875
INFO:root:Train (Epoch 68): Loss/seq after 02500 batchs: 1173.237548828125
INFO:root:Train (Epoch 68): Loss/seq after 02550 batchs: 1160.8544921875
INFO:root:Train (Epoch 68): Loss/seq after 02600 batchs: 1157.840576171875
INFO:root:Train (Epoch 68): Loss/seq after 02650 batchs: 1152.574462890625
INFO:root:Train (Epoch 68): Loss/seq after 02700 batchs: 1147.8123779296875
INFO:root:Train (Epoch 68): Loss/seq after 02750 batchs: 1169.20166015625
INFO:root:Train (Epoch 68): Loss/seq after 02800 batchs: 1173.554931640625
INFO:root:Train (Epoch 68): Loss/seq after 02850 batchs: 1168.5384521484375
INFO:root:Train (Epoch 68): Loss/seq after 02900 batchs: 1166.57666015625
INFO:root:Train (Epoch 68): Loss/seq after 02950 batchs: 1158.2982177734375
INFO:root:Train (Epoch 68): Loss/seq after 03000 batchs: 1156.8616943359375
INFO:root:Train (Epoch 68): Loss/seq after 03050 batchs: 1159.5640869140625
INFO:root:Train (Epoch 68): Loss/seq after 03100 batchs: 1171.17138671875
INFO:root:Train (Epoch 68): Loss/seq after 03150 batchs: 1188.3201904296875
INFO:root:Train (Epoch 68): Loss/seq after 03200 batchs: 1203.3985595703125
INFO:root:Train (Epoch 68): Loss/seq after 03250 batchs: 1218.0400390625
INFO:root:Train (Epoch 68): Loss/seq after 03300 batchs: 1215.4893798828125
INFO:root:Train (Epoch 68): Loss/seq after 03350 batchs: 1214.507568359375
INFO:root:Train (Epoch 68): Loss/seq after 03400 batchs: 1206.0
INFO:root:Train (Epoch 68): Loss/seq after 03450 batchs: 1197.8902587890625
INFO:root:Train (Epoch 68): Loss/seq after 03500 batchs: 1195.59326171875
INFO:root:Train (Epoch 68): Loss/seq after 03550 batchs: 1187.249267578125
INFO:root:Train (Epoch 68): Loss/seq after 03600 batchs: 1191.73095703125
INFO:root:Train (Epoch 68): Loss/seq after 03650 batchs: 1184.47607421875
INFO:root:Train (Epoch 68): Loss/seq after 03700 batchs: 1182.7230224609375
INFO:root:Train (Epoch 68): Loss/seq after 03750 batchs: 1182.8265380859375
INFO:root:Train (Epoch 68): Loss/seq after 03800 batchs: 1175.96240234375
INFO:root:Train (Epoch 68): Loss/seq after 03850 batchs: 1171.38330078125
INFO:root:Train (Epoch 68): Loss/seq after 03900 batchs: 1177.0389404296875
INFO:root:Train (Epoch 68): Loss/seq after 03950 batchs: 1184.7965087890625
INFO:root:Train (Epoch 68): Loss/seq after 04000 batchs: 1176.199462890625
INFO:root:Train (Epoch 68): Loss/seq after 04050 batchs: 1168.53564453125
INFO:root:Train (Epoch 68): Loss/seq after 04100 batchs: 1161.7415771484375
INFO:root:Train (Epoch 68): Loss/seq after 04150 batchs: 1156.0989990234375
INFO:root:Train (Epoch 68): Loss/seq after 04200 batchs: 1149.75830078125
INFO:root:Train (Epoch 68): Loss/seq after 04250 batchs: 1145.2869873046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 68): Loss/seq after 00000 batches: 863.4461669921875
INFO:root:# Valid (Epoch 68): Loss/seq after 00050 batches: 1085.958251953125
INFO:root:# Valid (Epoch 68): Loss/seq after 00100 batches: 1377.3389892578125
INFO:root:# Valid (Epoch 68): Loss/seq after 00150 batches: 1096.9354248046875
INFO:root:# Valid (Epoch 68): Loss/seq after 00200 batches: 983.9454345703125
INFO:root:Artifacts: Make stick videos for epoch 68
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_68_on_20220423_021135.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_68_index_1352_on_20220423_021135.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 69): Loss/seq after 00000 batchs: 2410.09912109375
INFO:root:Train (Epoch 69): Loss/seq after 00050 batchs: 1531.2808837890625
INFO:root:Train (Epoch 69): Loss/seq after 00100 batchs: 1424.353759765625
INFO:root:Train (Epoch 69): Loss/seq after 00150 batchs: 1249.9119873046875
INFO:root:Train (Epoch 69): Loss/seq after 00200 batchs: 1377.5736083984375
INFO:root:Train (Epoch 69): Loss/seq after 00250 batchs: 1488.362548828125
INFO:root:Train (Epoch 69): Loss/seq after 00300 batchs: 1420.4609375
INFO:root:Train (Epoch 69): Loss/seq after 00350 batchs: 1326.3544921875
INFO:root:Train (Epoch 69): Loss/seq after 00400 batchs: 1366.35693359375
INFO:root:Train (Epoch 69): Loss/seq after 00450 batchs: 1310.8734130859375
INFO:root:Train (Epoch 69): Loss/seq after 00500 batchs: 1303.47412109375
INFO:root:Train (Epoch 69): Loss/seq after 00550 batchs: 1251.3685302734375
INFO:root:Train (Epoch 69): Loss/seq after 00600 batchs: 1218.58984375
INFO:root:Train (Epoch 69): Loss/seq after 00650 batchs: 1293.615478515625
INFO:root:Train (Epoch 69): Loss/seq after 00700 batchs: 1390.1644287109375
INFO:root:Train (Epoch 69): Loss/seq after 00750 batchs: 1427.8939208984375
INFO:root:Train (Epoch 69): Loss/seq after 00800 batchs: 1403.2435302734375
INFO:root:Train (Epoch 69): Loss/seq after 00850 batchs: 1365.9322509765625
INFO:root:Train (Epoch 69): Loss/seq after 00900 batchs: 1363.645751953125
INFO:root:Train (Epoch 69): Loss/seq after 00950 batchs: 1446.8626708984375
INFO:root:Train (Epoch 69): Loss/seq after 01000 batchs: 1444.198974609375
INFO:root:Train (Epoch 69): Loss/seq after 01050 batchs: 1413.2593994140625
INFO:root:Train (Epoch 69): Loss/seq after 01100 batchs: 1399.248046875
INFO:root:Train (Epoch 69): Loss/seq after 01150 batchs: 1378.59228515625
INFO:root:Train (Epoch 69): Loss/seq after 01200 batchs: 1362.6202392578125
INFO:root:Train (Epoch 69): Loss/seq after 01250 batchs: 1353.5433349609375
INFO:root:Train (Epoch 69): Loss/seq after 01300 batchs: 1371.4818115234375
INFO:root:Train (Epoch 69): Loss/seq after 01350 batchs: 1377.10546875
INFO:root:Train (Epoch 69): Loss/seq after 01400 batchs: 1424.4661865234375
INFO:root:Train (Epoch 69): Loss/seq after 01450 batchs: 1408.716552734375
INFO:root:Train (Epoch 69): Loss/seq after 01500 batchs: 1395.878173828125
INFO:root:Train (Epoch 69): Loss/seq after 01550 batchs: 1388.4796142578125
INFO:root:Train (Epoch 69): Loss/seq after 01600 batchs: 1368.6124267578125
INFO:root:Train (Epoch 69): Loss/seq after 01650 batchs: 1351.6566162109375
INFO:root:Train (Epoch 69): Loss/seq after 01700 batchs: 1339.6197509765625
INFO:root:Train (Epoch 69): Loss/seq after 01750 batchs: 1325.94384765625
INFO:root:Train (Epoch 69): Loss/seq after 01800 batchs: 1310.047119140625
INFO:root:Train (Epoch 69): Loss/seq after 01850 batchs: 1293.976806640625
INFO:root:Train (Epoch 69): Loss/seq after 01900 batchs: 1286.7874755859375
INFO:root:Train (Epoch 69): Loss/seq after 01950 batchs: 1275.406494140625
INFO:root:Train (Epoch 69): Loss/seq after 02000 batchs: 1264.62841796875
INFO:root:Train (Epoch 69): Loss/seq after 02050 batchs: 1254.290283203125
INFO:root:Train (Epoch 69): Loss/seq after 02100 batchs: 1241.7259521484375
INFO:root:Train (Epoch 69): Loss/seq after 02150 batchs: 1229.797607421875
INFO:root:Train (Epoch 69): Loss/seq after 02200 batchs: 1217.7774658203125
INFO:root:Train (Epoch 69): Loss/seq after 02250 batchs: 1214.9005126953125
INFO:root:Train (Epoch 69): Loss/seq after 02300 batchs: 1216.749267578125
INFO:root:Train (Epoch 69): Loss/seq after 02350 batchs: 1205.076416015625
INFO:root:Train (Epoch 69): Loss/seq after 02400 batchs: 1199.5555419921875
INFO:root:Train (Epoch 69): Loss/seq after 02450 batchs: 1186.434326171875
INFO:root:Train (Epoch 69): Loss/seq after 02500 batchs: 1169.7977294921875
INFO:root:Train (Epoch 69): Loss/seq after 02550 batchs: 1157.7349853515625
INFO:root:Train (Epoch 69): Loss/seq after 02600 batchs: 1154.9825439453125
INFO:root:Train (Epoch 69): Loss/seq after 02650 batchs: 1149.987548828125
INFO:root:Train (Epoch 69): Loss/seq after 02700 batchs: 1145.690673828125
INFO:root:Train (Epoch 69): Loss/seq after 02750 batchs: 1169.0137939453125
INFO:root:Train (Epoch 69): Loss/seq after 02800 batchs: 1173.4832763671875
INFO:root:Train (Epoch 69): Loss/seq after 02850 batchs: 1168.1292724609375
INFO:root:Train (Epoch 69): Loss/seq after 02900 batchs: 1165.7008056640625
INFO:root:Train (Epoch 69): Loss/seq after 02950 batchs: 1157.2064208984375
INFO:root:Train (Epoch 69): Loss/seq after 03000 batchs: 1155.7618408203125
INFO:root:Train (Epoch 69): Loss/seq after 03050 batchs: 1158.5322265625
INFO:root:Train (Epoch 69): Loss/seq after 03100 batchs: 1168.2080078125
INFO:root:Train (Epoch 69): Loss/seq after 03150 batchs: 1186.1156005859375
INFO:root:Train (Epoch 69): Loss/seq after 03200 batchs: 1200.9178466796875
INFO:root:Train (Epoch 69): Loss/seq after 03250 batchs: 1215.02978515625
INFO:root:Train (Epoch 69): Loss/seq after 03300 batchs: 1211.909423828125
INFO:root:Train (Epoch 69): Loss/seq after 03350 batchs: 1210.7454833984375
INFO:root:Train (Epoch 69): Loss/seq after 03400 batchs: 1202.1947021484375
INFO:root:Train (Epoch 69): Loss/seq after 03450 batchs: 1194.603271484375
INFO:root:Train (Epoch 69): Loss/seq after 03500 batchs: 1192.1475830078125
INFO:root:Train (Epoch 69): Loss/seq after 03550 batchs: 1184.263916015625
INFO:root:Train (Epoch 69): Loss/seq after 03600 batchs: 1188.7818603515625
INFO:root:Train (Epoch 69): Loss/seq after 03650 batchs: 1181.9537353515625
INFO:root:Train (Epoch 69): Loss/seq after 03700 batchs: 1180.4530029296875
INFO:root:Train (Epoch 69): Loss/seq after 03750 batchs: 1180.6043701171875
INFO:root:Train (Epoch 69): Loss/seq after 03800 batchs: 1173.7745361328125
INFO:root:Train (Epoch 69): Loss/seq after 03850 batchs: 1169.2344970703125
INFO:root:Train (Epoch 69): Loss/seq after 03900 batchs: 1175.0260009765625
INFO:root:Train (Epoch 69): Loss/seq after 03950 batchs: 1182.5699462890625
INFO:root:Train (Epoch 69): Loss/seq after 04000 batchs: 1173.998291015625
INFO:root:Train (Epoch 69): Loss/seq after 04050 batchs: 1166.441162109375
INFO:root:Train (Epoch 69): Loss/seq after 04100 batchs: 1159.728759765625
INFO:root:Train (Epoch 69): Loss/seq after 04150 batchs: 1154.25244140625
INFO:root:Train (Epoch 69): Loss/seq after 04200 batchs: 1148.197998046875
INFO:root:Train (Epoch 69): Loss/seq after 04250 batchs: 1143.7550048828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 69): Loss/seq after 00000 batches: 864.9828491210938
INFO:root:# Valid (Epoch 69): Loss/seq after 00050 batches: 1088.4918212890625
INFO:root:# Valid (Epoch 69): Loss/seq after 00100 batches: 1373.602294921875
INFO:root:# Valid (Epoch 69): Loss/seq after 00150 batches: 1091.512451171875
INFO:root:# Valid (Epoch 69): Loss/seq after 00200 batches: 979.9367065429688
INFO:root:Artifacts: Make stick videos for epoch 69
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_69_on_20220423_021637.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_69_index_1456_on_20220423_021637.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 70): Loss/seq after 00000 batchs: 2415.76416015625
INFO:root:Train (Epoch 70): Loss/seq after 00050 batchs: 1527.8292236328125
INFO:root:Train (Epoch 70): Loss/seq after 00100 batchs: 1438.757568359375
INFO:root:Train (Epoch 70): Loss/seq after 00150 batchs: 1262.015380859375
INFO:root:Train (Epoch 70): Loss/seq after 00200 batchs: 1389.52099609375
INFO:root:Train (Epoch 70): Loss/seq after 00250 batchs: 1495.7242431640625
INFO:root:Train (Epoch 70): Loss/seq after 00300 batchs: 1426.7122802734375
INFO:root:Train (Epoch 70): Loss/seq after 00350 batchs: 1333.4071044921875
INFO:root:Train (Epoch 70): Loss/seq after 00400 batchs: 1371.7435302734375
INFO:root:Train (Epoch 70): Loss/seq after 00450 batchs: 1315.7957763671875
INFO:root:Train (Epoch 70): Loss/seq after 00500 batchs: 1305.385009765625
INFO:root:Train (Epoch 70): Loss/seq after 00550 batchs: 1252.4610595703125
INFO:root:Train (Epoch 70): Loss/seq after 00600 batchs: 1219.6151123046875
INFO:root:Train (Epoch 70): Loss/seq after 00650 batchs: 1294.102294921875
INFO:root:Train (Epoch 70): Loss/seq after 00700 batchs: 1389.7628173828125
INFO:root:Train (Epoch 70): Loss/seq after 00750 batchs: 1428.1181640625
INFO:root:Train (Epoch 70): Loss/seq after 00800 batchs: 1403.0196533203125
INFO:root:Train (Epoch 70): Loss/seq after 00850 batchs: 1365.8043212890625
INFO:root:Train (Epoch 70): Loss/seq after 00900 batchs: 1363.1044921875
INFO:root:Train (Epoch 70): Loss/seq after 00950 batchs: 1446.4481201171875
INFO:root:Train (Epoch 70): Loss/seq after 01000 batchs: 1444.086669921875
INFO:root:Train (Epoch 70): Loss/seq after 01050 batchs: 1413.1380615234375
INFO:root:Train (Epoch 70): Loss/seq after 01100 batchs: 1399.38720703125
INFO:root:Train (Epoch 70): Loss/seq after 01150 batchs: 1379.153564453125
INFO:root:Train (Epoch 70): Loss/seq after 01200 batchs: 1363.4659423828125
INFO:root:Train (Epoch 70): Loss/seq after 01250 batchs: 1353.4468994140625
INFO:root:Train (Epoch 70): Loss/seq after 01300 batchs: 1370.873291015625
INFO:root:Train (Epoch 70): Loss/seq after 01350 batchs: 1376.6463623046875
INFO:root:Train (Epoch 70): Loss/seq after 01400 batchs: 1424.388671875
INFO:root:Train (Epoch 70): Loss/seq after 01450 batchs: 1408.798828125
INFO:root:Train (Epoch 70): Loss/seq after 01500 batchs: 1396.17333984375
INFO:root:Train (Epoch 70): Loss/seq after 01550 batchs: 1388.957275390625
INFO:root:Train (Epoch 70): Loss/seq after 01600 batchs: 1369.0740966796875
INFO:root:Train (Epoch 70): Loss/seq after 01650 batchs: 1352.3277587890625
INFO:root:Train (Epoch 70): Loss/seq after 01700 batchs: 1340.1571044921875
INFO:root:Train (Epoch 70): Loss/seq after 01750 batchs: 1326.55712890625
INFO:root:Train (Epoch 70): Loss/seq after 01800 batchs: 1310.4891357421875
INFO:root:Train (Epoch 70): Loss/seq after 01850 batchs: 1294.2215576171875
INFO:root:Train (Epoch 70): Loss/seq after 01900 batchs: 1286.7459716796875
INFO:root:Train (Epoch 70): Loss/seq after 01950 batchs: 1275.2064208984375
INFO:root:Train (Epoch 70): Loss/seq after 02000 batchs: 1264.3291015625
INFO:root:Train (Epoch 70): Loss/seq after 02050 batchs: 1253.6524658203125
INFO:root:Train (Epoch 70): Loss/seq after 02100 batchs: 1241.0543212890625
INFO:root:Train (Epoch 70): Loss/seq after 02150 batchs: 1229.107666015625
INFO:root:Train (Epoch 70): Loss/seq after 02200 batchs: 1217.13671875
INFO:root:Train (Epoch 70): Loss/seq after 02250 batchs: 1213.908447265625
INFO:root:Train (Epoch 70): Loss/seq after 02300 batchs: 1215.4847412109375
INFO:root:Train (Epoch 70): Loss/seq after 02350 batchs: 1203.7950439453125
INFO:root:Train (Epoch 70): Loss/seq after 02400 batchs: 1198.2054443359375
INFO:root:Train (Epoch 70): Loss/seq after 02450 batchs: 1185.08642578125
INFO:root:Train (Epoch 70): Loss/seq after 02500 batchs: 1168.478515625
INFO:root:Train (Epoch 70): Loss/seq after 02550 batchs: 1156.148681640625
INFO:root:Train (Epoch 70): Loss/seq after 02600 batchs: 1153.2513427734375
INFO:root:Train (Epoch 70): Loss/seq after 02650 batchs: 1148.138671875
INFO:root:Train (Epoch 70): Loss/seq after 02700 batchs: 1143.518310546875
INFO:root:Train (Epoch 70): Loss/seq after 02750 batchs: 1165.7308349609375
INFO:root:Train (Epoch 70): Loss/seq after 02800 batchs: 1169.5516357421875
INFO:root:Train (Epoch 70): Loss/seq after 02850 batchs: 1164.1319580078125
INFO:root:Train (Epoch 70): Loss/seq after 02900 batchs: 1162.177001953125
INFO:root:Train (Epoch 70): Loss/seq after 02950 batchs: 1153.7630615234375
INFO:root:Train (Epoch 70): Loss/seq after 03000 batchs: 1152.3388671875
INFO:root:Train (Epoch 70): Loss/seq after 03050 batchs: 1155.0391845703125
INFO:root:Train (Epoch 70): Loss/seq after 03100 batchs: 1164.87548828125
INFO:root:Train (Epoch 70): Loss/seq after 03150 batchs: 1181.1566162109375
INFO:root:Train (Epoch 70): Loss/seq after 03200 batchs: 1196.102783203125
INFO:root:Train (Epoch 70): Loss/seq after 03250 batchs: 1210.4112548828125
INFO:root:Train (Epoch 70): Loss/seq after 03300 batchs: 1208.0028076171875
INFO:root:Train (Epoch 70): Loss/seq after 03350 batchs: 1206.59228515625
INFO:root:Train (Epoch 70): Loss/seq after 03400 batchs: 1198.1878662109375
INFO:root:Train (Epoch 70): Loss/seq after 03450 batchs: 1190.0272216796875
INFO:root:Train (Epoch 70): Loss/seq after 03500 batchs: 1187.7655029296875
INFO:root:Train (Epoch 70): Loss/seq after 03550 batchs: 1179.4039306640625
INFO:root:Train (Epoch 70): Loss/seq after 03600 batchs: 1183.6146240234375
INFO:root:Train (Epoch 70): Loss/seq after 03650 batchs: 1176.4736328125
INFO:root:Train (Epoch 70): Loss/seq after 03700 batchs: 1175.0340576171875
INFO:root:Train (Epoch 70): Loss/seq after 03750 batchs: 1175.3065185546875
INFO:root:Train (Epoch 70): Loss/seq after 03800 batchs: 1168.6134033203125
INFO:root:Train (Epoch 70): Loss/seq after 03850 batchs: 1164.130859375
INFO:root:Train (Epoch 70): Loss/seq after 03900 batchs: 1169.8226318359375
INFO:root:Train (Epoch 70): Loss/seq after 03950 batchs: 1178.0010986328125
INFO:root:Train (Epoch 70): Loss/seq after 04000 batchs: 1169.4840087890625
INFO:root:Train (Epoch 70): Loss/seq after 04050 batchs: 1161.8951416015625
INFO:root:Train (Epoch 70): Loss/seq after 04100 batchs: 1155.3515625
INFO:root:Train (Epoch 70): Loss/seq after 04150 batchs: 1149.83154296875
INFO:root:Train (Epoch 70): Loss/seq after 04200 batchs: 1143.6536865234375
INFO:root:Train (Epoch 70): Loss/seq after 04250 batchs: 1139.2801513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 70): Loss/seq after 00000 batches: 869.146728515625
INFO:root:# Valid (Epoch 70): Loss/seq after 00050 batches: 1103.22021484375
INFO:root:# Valid (Epoch 70): Loss/seq after 00100 batches: 1391.42236328125
INFO:root:# Valid (Epoch 70): Loss/seq after 00150 batches: 1110.773193359375
INFO:root:# Valid (Epoch 70): Loss/seq after 00200 batches: 997.7540893554688
INFO:root:Artifacts: Make stick videos for epoch 70
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_70_on_20220423_022123.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_70_index_271_on_20220423_022123.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 71): Loss/seq after 00000 batchs: 2400.19384765625
INFO:root:Train (Epoch 71): Loss/seq after 00050 batchs: 1531.3671875
INFO:root:Train (Epoch 71): Loss/seq after 00100 batchs: 1424.7403564453125
INFO:root:Train (Epoch 71): Loss/seq after 00150 batchs: 1251.6810302734375
INFO:root:Train (Epoch 71): Loss/seq after 00200 batchs: 1377.4085693359375
INFO:root:Train (Epoch 71): Loss/seq after 00250 batchs: 1487.1455078125
INFO:root:Train (Epoch 71): Loss/seq after 00300 batchs: 1419.2857666015625
INFO:root:Train (Epoch 71): Loss/seq after 00350 batchs: 1325.8662109375
INFO:root:Train (Epoch 71): Loss/seq after 00400 batchs: 1365.1951904296875
INFO:root:Train (Epoch 71): Loss/seq after 00450 batchs: 1309.928955078125
INFO:root:Train (Epoch 71): Loss/seq after 00500 batchs: 1304.90576171875
INFO:root:Train (Epoch 71): Loss/seq after 00550 batchs: 1252.671875
INFO:root:Train (Epoch 71): Loss/seq after 00600 batchs: 1219.808837890625
INFO:root:Train (Epoch 71): Loss/seq after 00650 batchs: 1294.3499755859375
INFO:root:Train (Epoch 71): Loss/seq after 00700 batchs: 1391.143798828125
INFO:root:Train (Epoch 71): Loss/seq after 00750 batchs: 1430.218505859375
INFO:root:Train (Epoch 71): Loss/seq after 00800 batchs: 1405.7108154296875
INFO:root:Train (Epoch 71): Loss/seq after 00850 batchs: 1368.4400634765625
INFO:root:Train (Epoch 71): Loss/seq after 00900 batchs: 1366.4403076171875
INFO:root:Train (Epoch 71): Loss/seq after 00950 batchs: 1449.80224609375
INFO:root:Train (Epoch 71): Loss/seq after 01000 batchs: 1448.82421875
INFO:root:Train (Epoch 71): Loss/seq after 01050 batchs: 1417.2357177734375
INFO:root:Train (Epoch 71): Loss/seq after 01100 batchs: 1403.317626953125
INFO:root:Train (Epoch 71): Loss/seq after 01150 batchs: 1382.505859375
INFO:root:Train (Epoch 71): Loss/seq after 01200 batchs: 1366.1063232421875
INFO:root:Train (Epoch 71): Loss/seq after 01250 batchs: 1356.4373779296875
INFO:root:Train (Epoch 71): Loss/seq after 01300 batchs: 1373.7086181640625
INFO:root:Train (Epoch 71): Loss/seq after 01350 batchs: 1379.259033203125
INFO:root:Train (Epoch 71): Loss/seq after 01400 batchs: 1427.032958984375
INFO:root:Train (Epoch 71): Loss/seq after 01450 batchs: 1411.568359375
INFO:root:Train (Epoch 71): Loss/seq after 01500 batchs: 1398.728515625
INFO:root:Train (Epoch 71): Loss/seq after 01550 batchs: 1390.8758544921875
INFO:root:Train (Epoch 71): Loss/seq after 01600 batchs: 1370.764404296875
INFO:root:Train (Epoch 71): Loss/seq after 01650 batchs: 1354.031494140625
INFO:root:Train (Epoch 71): Loss/seq after 01700 batchs: 1342.1226806640625
INFO:root:Train (Epoch 71): Loss/seq after 01750 batchs: 1328.607666015625
INFO:root:Train (Epoch 71): Loss/seq after 01800 batchs: 1312.8118896484375
INFO:root:Train (Epoch 71): Loss/seq after 01850 batchs: 1296.624267578125
INFO:root:Train (Epoch 71): Loss/seq after 01900 batchs: 1289.5740966796875
INFO:root:Train (Epoch 71): Loss/seq after 01950 batchs: 1278.7413330078125
INFO:root:Train (Epoch 71): Loss/seq after 02000 batchs: 1268.230712890625
INFO:root:Train (Epoch 71): Loss/seq after 02050 batchs: 1257.752197265625
INFO:root:Train (Epoch 71): Loss/seq after 02100 batchs: 1245.142822265625
INFO:root:Train (Epoch 71): Loss/seq after 02150 batchs: 1233.3143310546875
INFO:root:Train (Epoch 71): Loss/seq after 02200 batchs: 1221.1854248046875
INFO:root:Train (Epoch 71): Loss/seq after 02250 batchs: 1219.3194580078125
INFO:root:Train (Epoch 71): Loss/seq after 02300 batchs: 1221.148193359375
INFO:root:Train (Epoch 71): Loss/seq after 02350 batchs: 1210.4495849609375
INFO:root:Train (Epoch 71): Loss/seq after 02400 batchs: 1205.0238037109375
INFO:root:Train (Epoch 71): Loss/seq after 02450 batchs: 1191.7769775390625
INFO:root:Train (Epoch 71): Loss/seq after 02500 batchs: 1175.0413818359375
INFO:root:Train (Epoch 71): Loss/seq after 02550 batchs: 1162.6934814453125
INFO:root:Train (Epoch 71): Loss/seq after 02600 batchs: 1159.7459716796875
INFO:root:Train (Epoch 71): Loss/seq after 02650 batchs: 1154.4873046875
INFO:root:Train (Epoch 71): Loss/seq after 02700 batchs: 1149.712158203125
INFO:root:Train (Epoch 71): Loss/seq after 02750 batchs: 1170.829833984375
INFO:root:Train (Epoch 71): Loss/seq after 02800 batchs: 1174.8759765625
INFO:root:Train (Epoch 71): Loss/seq after 02850 batchs: 1169.419677734375
INFO:root:Train (Epoch 71): Loss/seq after 02900 batchs: 1166.517578125
INFO:root:Train (Epoch 71): Loss/seq after 02950 batchs: 1157.921142578125
INFO:root:Train (Epoch 71): Loss/seq after 03000 batchs: 1156.4091796875
INFO:root:Train (Epoch 71): Loss/seq after 03050 batchs: 1159.119140625
INFO:root:Train (Epoch 71): Loss/seq after 03100 batchs: 1167.948974609375
INFO:root:Train (Epoch 71): Loss/seq after 03150 batchs: 1183.8226318359375
INFO:root:Train (Epoch 71): Loss/seq after 03200 batchs: 1198.6370849609375
INFO:root:Train (Epoch 71): Loss/seq after 03250 batchs: 1212.84130859375
INFO:root:Train (Epoch 71): Loss/seq after 03300 batchs: 1209.723876953125
INFO:root:Train (Epoch 71): Loss/seq after 03350 batchs: 1208.252685546875
INFO:root:Train (Epoch 71): Loss/seq after 03400 batchs: 1199.792236328125
INFO:root:Train (Epoch 71): Loss/seq after 03450 batchs: 1191.838623046875
INFO:root:Train (Epoch 71): Loss/seq after 03500 batchs: 1189.0872802734375
INFO:root:Train (Epoch 71): Loss/seq after 03550 batchs: 1180.72705078125
INFO:root:Train (Epoch 71): Loss/seq after 03600 batchs: 1185.01416015625
INFO:root:Train (Epoch 71): Loss/seq after 03650 batchs: 1178.161376953125
INFO:root:Train (Epoch 71): Loss/seq after 03700 batchs: 1176.639892578125
INFO:root:Train (Epoch 71): Loss/seq after 03750 batchs: 1176.802978515625
INFO:root:Train (Epoch 71): Loss/seq after 03800 batchs: 1170.02587890625
INFO:root:Train (Epoch 71): Loss/seq after 03850 batchs: 1165.521728515625
INFO:root:Train (Epoch 71): Loss/seq after 03900 batchs: 1171.2337646484375
INFO:root:Train (Epoch 71): Loss/seq after 03950 batchs: 1178.80078125
INFO:root:Train (Epoch 71): Loss/seq after 04000 batchs: 1170.2628173828125
INFO:root:Train (Epoch 71): Loss/seq after 04050 batchs: 1162.677978515625
INFO:root:Train (Epoch 71): Loss/seq after 04100 batchs: 1155.86572265625
INFO:root:Train (Epoch 71): Loss/seq after 04150 batchs: 1150.4658203125
INFO:root:Train (Epoch 71): Loss/seq after 04200 batchs: 1144.080322265625
INFO:root:Train (Epoch 71): Loss/seq after 04250 batchs: 1139.6373291015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 71): Loss/seq after 00000 batches: 875.3436279296875
INFO:root:# Valid (Epoch 71): Loss/seq after 00050 batches: 1093.803466796875
INFO:root:# Valid (Epoch 71): Loss/seq after 00100 batches: 1381.2886962890625
INFO:root:# Valid (Epoch 71): Loss/seq after 00150 batches: 1094.9217529296875
INFO:root:# Valid (Epoch 71): Loss/seq after 00200 batches: 982.2075805664062
INFO:root:Artifacts: Make stick videos for epoch 71
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_71_on_20220423_022608.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_71_index_452_on_20220423_022608.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 72): Loss/seq after 00000 batchs: 2410.55322265625
INFO:root:Train (Epoch 72): Loss/seq after 00050 batchs: 1535.517578125
INFO:root:Train (Epoch 72): Loss/seq after 00100 batchs: 1447.014404296875
INFO:root:Train (Epoch 72): Loss/seq after 00150 batchs: 1264.175048828125
INFO:root:Train (Epoch 72): Loss/seq after 00200 batchs: 1391.07666015625
INFO:root:Train (Epoch 72): Loss/seq after 00250 batchs: 1497.9803466796875
INFO:root:Train (Epoch 72): Loss/seq after 00300 batchs: 1428.2830810546875
INFO:root:Train (Epoch 72): Loss/seq after 00350 batchs: 1334.080322265625
INFO:root:Train (Epoch 72): Loss/seq after 00400 batchs: 1376.8538818359375
INFO:root:Train (Epoch 72): Loss/seq after 00450 batchs: 1319.9427490234375
INFO:root:Train (Epoch 72): Loss/seq after 00500 batchs: 1312.1529541015625
INFO:root:Train (Epoch 72): Loss/seq after 00550 batchs: 1259.1685791015625
INFO:root:Train (Epoch 72): Loss/seq after 00600 batchs: 1225.735595703125
INFO:root:Train (Epoch 72): Loss/seq after 00650 batchs: 1299.178955078125
INFO:root:Train (Epoch 72): Loss/seq after 00700 batchs: 1395.99951171875
INFO:root:Train (Epoch 72): Loss/seq after 00750 batchs: 1434.8499755859375
INFO:root:Train (Epoch 72): Loss/seq after 00800 batchs: 1408.050048828125
INFO:root:Train (Epoch 72): Loss/seq after 00850 batchs: 1369.914306640625
INFO:root:Train (Epoch 72): Loss/seq after 00900 batchs: 1367.3905029296875
INFO:root:Train (Epoch 72): Loss/seq after 00950 batchs: 1450.637451171875
INFO:root:Train (Epoch 72): Loss/seq after 01000 batchs: 1448.47802734375
INFO:root:Train (Epoch 72): Loss/seq after 01050 batchs: 1419.2852783203125
INFO:root:Train (Epoch 72): Loss/seq after 01100 batchs: 1405.3663330078125
INFO:root:Train (Epoch 72): Loss/seq after 01150 batchs: 1384.2021484375
INFO:root:Train (Epoch 72): Loss/seq after 01200 batchs: 1367.906982421875
INFO:root:Train (Epoch 72): Loss/seq after 01250 batchs: 1357.7265625
INFO:root:Train (Epoch 72): Loss/seq after 01300 batchs: 1374.6959228515625
INFO:root:Train (Epoch 72): Loss/seq after 01350 batchs: 1380.2896728515625
INFO:root:Train (Epoch 72): Loss/seq after 01400 batchs: 1430.2086181640625
INFO:root:Train (Epoch 72): Loss/seq after 01450 batchs: 1414.6287841796875
INFO:root:Train (Epoch 72): Loss/seq after 01500 batchs: 1401.6773681640625
INFO:root:Train (Epoch 72): Loss/seq after 01550 batchs: 1394.1822509765625
INFO:root:Train (Epoch 72): Loss/seq after 01600 batchs: 1373.7056884765625
INFO:root:Train (Epoch 72): Loss/seq after 01650 batchs: 1357.027099609375
INFO:root:Train (Epoch 72): Loss/seq after 01700 batchs: 1344.8736572265625
INFO:root:Train (Epoch 72): Loss/seq after 01750 batchs: 1331.042236328125
INFO:root:Train (Epoch 72): Loss/seq after 01800 batchs: 1314.701904296875
INFO:root:Train (Epoch 72): Loss/seq after 01850 batchs: 1298.3267822265625
INFO:root:Train (Epoch 72): Loss/seq after 01900 batchs: 1290.6436767578125
INFO:root:Train (Epoch 72): Loss/seq after 01950 batchs: 1278.8203125
INFO:root:Train (Epoch 72): Loss/seq after 02000 batchs: 1267.8250732421875
INFO:root:Train (Epoch 72): Loss/seq after 02050 batchs: 1257.5164794921875
INFO:root:Train (Epoch 72): Loss/seq after 02100 batchs: 1244.862548828125
INFO:root:Train (Epoch 72): Loss/seq after 02150 batchs: 1232.761962890625
INFO:root:Train (Epoch 72): Loss/seq after 02200 batchs: 1220.615234375
INFO:root:Train (Epoch 72): Loss/seq after 02250 batchs: 1217.4317626953125
INFO:root:Train (Epoch 72): Loss/seq after 02300 batchs: 1218.7357177734375
INFO:root:Train (Epoch 72): Loss/seq after 02350 batchs: 1206.9854736328125
INFO:root:Train (Epoch 72): Loss/seq after 02400 batchs: 1201.4283447265625
INFO:root:Train (Epoch 72): Loss/seq after 02450 batchs: 1188.2371826171875
INFO:root:Train (Epoch 72): Loss/seq after 02500 batchs: 1171.5665283203125
INFO:root:Train (Epoch 72): Loss/seq after 02550 batchs: 1159.15576171875
INFO:root:Train (Epoch 72): Loss/seq after 02600 batchs: 1156.25439453125
INFO:root:Train (Epoch 72): Loss/seq after 02650 batchs: 1151.0430908203125
INFO:root:Train (Epoch 72): Loss/seq after 02700 batchs: 1146.4879150390625
INFO:root:Train (Epoch 72): Loss/seq after 02750 batchs: 1166.5372314453125
INFO:root:Train (Epoch 72): Loss/seq after 02800 batchs: 1170.5125732421875
INFO:root:Train (Epoch 72): Loss/seq after 02850 batchs: 1165.098388671875
INFO:root:Train (Epoch 72): Loss/seq after 02900 batchs: 1162.8902587890625
INFO:root:Train (Epoch 72): Loss/seq after 02950 batchs: 1154.3905029296875
INFO:root:Train (Epoch 72): Loss/seq after 03000 batchs: 1152.9188232421875
INFO:root:Train (Epoch 72): Loss/seq after 03050 batchs: 1155.7291259765625
INFO:root:Train (Epoch 72): Loss/seq after 03100 batchs: 1164.7301025390625
INFO:root:Train (Epoch 72): Loss/seq after 03150 batchs: 1180.599609375
INFO:root:Train (Epoch 72): Loss/seq after 03200 batchs: 1195.6024169921875
INFO:root:Train (Epoch 72): Loss/seq after 03250 batchs: 1209.969970703125
INFO:root:Train (Epoch 72): Loss/seq after 03300 batchs: 1206.85205078125
INFO:root:Train (Epoch 72): Loss/seq after 03350 batchs: 1205.3538818359375
INFO:root:Train (Epoch 72): Loss/seq after 03400 batchs: 1196.9635009765625
INFO:root:Train (Epoch 72): Loss/seq after 03450 batchs: 1188.9248046875
INFO:root:Train (Epoch 72): Loss/seq after 03500 batchs: 1186.0838623046875
INFO:root:Train (Epoch 72): Loss/seq after 03550 batchs: 1177.9359130859375
INFO:root:Train (Epoch 72): Loss/seq after 03600 batchs: 1182.3489990234375
INFO:root:Train (Epoch 72): Loss/seq after 03650 batchs: 1175.425537109375
INFO:root:Train (Epoch 72): Loss/seq after 03700 batchs: 1174.135009765625
INFO:root:Train (Epoch 72): Loss/seq after 03750 batchs: 1174.4188232421875
INFO:root:Train (Epoch 72): Loss/seq after 03800 batchs: 1167.6932373046875
INFO:root:Train (Epoch 72): Loss/seq after 03850 batchs: 1163.198486328125
INFO:root:Train (Epoch 72): Loss/seq after 03900 batchs: 1168.7978515625
INFO:root:Train (Epoch 72): Loss/seq after 03950 batchs: 1176.4102783203125
INFO:root:Train (Epoch 72): Loss/seq after 04000 batchs: 1167.90771484375
INFO:root:Train (Epoch 72): Loss/seq after 04050 batchs: 1160.3336181640625
INFO:root:Train (Epoch 72): Loss/seq after 04100 batchs: 1153.715087890625
INFO:root:Train (Epoch 72): Loss/seq after 04150 batchs: 1148.2698974609375
INFO:root:Train (Epoch 72): Loss/seq after 04200 batchs: 1141.9820556640625
INFO:root:Train (Epoch 72): Loss/seq after 04250 batchs: 1137.4923095703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 72): Loss/seq after 00000 batches: 874.6897583007812
INFO:root:# Valid (Epoch 72): Loss/seq after 00050 batches: 1103.665283203125
INFO:root:# Valid (Epoch 72): Loss/seq after 00100 batches: 1385.9681396484375
INFO:root:# Valid (Epoch 72): Loss/seq after 00150 batches: 1100.5784912109375
INFO:root:# Valid (Epoch 72): Loss/seq after 00200 batches: 988.560546875
INFO:root:Artifacts: Make stick videos for epoch 72
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_72_on_20220423_023115.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_72_index_1300_on_20220423_023115.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 73): Loss/seq after 00000 batchs: 2427.7939453125
INFO:root:Train (Epoch 73): Loss/seq after 00050 batchs: 1541.490234375
INFO:root:Train (Epoch 73): Loss/seq after 00100 batchs: 1434.436279296875
INFO:root:Train (Epoch 73): Loss/seq after 00150 batchs: 1255.2374267578125
INFO:root:Train (Epoch 73): Loss/seq after 00200 batchs: 1379.377197265625
INFO:root:Train (Epoch 73): Loss/seq after 00250 batchs: 1486.766357421875
INFO:root:Train (Epoch 73): Loss/seq after 00300 batchs: 1418.929443359375
INFO:root:Train (Epoch 73): Loss/seq after 00350 batchs: 1325.913818359375
INFO:root:Train (Epoch 73): Loss/seq after 00400 batchs: 1364.568115234375
INFO:root:Train (Epoch 73): Loss/seq after 00450 batchs: 1309.43115234375
INFO:root:Train (Epoch 73): Loss/seq after 00500 batchs: 1299.4100341796875
INFO:root:Train (Epoch 73): Loss/seq after 00550 batchs: 1247.954833984375
INFO:root:Train (Epoch 73): Loss/seq after 00600 batchs: 1215.7935791015625
INFO:root:Train (Epoch 73): Loss/seq after 00650 batchs: 1290.4688720703125
INFO:root:Train (Epoch 73): Loss/seq after 00700 batchs: 1386.6829833984375
INFO:root:Train (Epoch 73): Loss/seq after 00750 batchs: 1424.3624267578125
INFO:root:Train (Epoch 73): Loss/seq after 00800 batchs: 1399.3616943359375
INFO:root:Train (Epoch 73): Loss/seq after 00850 batchs: 1361.7835693359375
INFO:root:Train (Epoch 73): Loss/seq after 00900 batchs: 1359.6085205078125
INFO:root:Train (Epoch 73): Loss/seq after 00950 batchs: 1443.15625
INFO:root:Train (Epoch 73): Loss/seq after 01000 batchs: 1440.6378173828125
INFO:root:Train (Epoch 73): Loss/seq after 01050 batchs: 1409.5150146484375
INFO:root:Train (Epoch 73): Loss/seq after 01100 batchs: 1395.3712158203125
INFO:root:Train (Epoch 73): Loss/seq after 01150 batchs: 1374.816650390625
INFO:root:Train (Epoch 73): Loss/seq after 01200 batchs: 1358.6417236328125
INFO:root:Train (Epoch 73): Loss/seq after 01250 batchs: 1349.0455322265625
INFO:root:Train (Epoch 73): Loss/seq after 01300 batchs: 1366.410888671875
INFO:root:Train (Epoch 73): Loss/seq after 01350 batchs: 1372.16015625
INFO:root:Train (Epoch 73): Loss/seq after 01400 batchs: 1420.658935546875
INFO:root:Train (Epoch 73): Loss/seq after 01450 batchs: 1405.0531005859375
INFO:root:Train (Epoch 73): Loss/seq after 01500 batchs: 1392.4984130859375
INFO:root:Train (Epoch 73): Loss/seq after 01550 batchs: 1385.3709716796875
INFO:root:Train (Epoch 73): Loss/seq after 01600 batchs: 1365.418212890625
INFO:root:Train (Epoch 73): Loss/seq after 01650 batchs: 1349.339111328125
INFO:root:Train (Epoch 73): Loss/seq after 01700 batchs: 1337.466552734375
INFO:root:Train (Epoch 73): Loss/seq after 01750 batchs: 1324.2154541015625
INFO:root:Train (Epoch 73): Loss/seq after 01800 batchs: 1308.19970703125
INFO:root:Train (Epoch 73): Loss/seq after 01850 batchs: 1292.0645751953125
INFO:root:Train (Epoch 73): Loss/seq after 01900 batchs: 1284.935791015625
INFO:root:Train (Epoch 73): Loss/seq after 01950 batchs: 1273.635498046875
INFO:root:Train (Epoch 73): Loss/seq after 02000 batchs: 1263.181884765625
INFO:root:Train (Epoch 73): Loss/seq after 02050 batchs: 1252.766357421875
INFO:root:Train (Epoch 73): Loss/seq after 02100 batchs: 1239.9986572265625
INFO:root:Train (Epoch 73): Loss/seq after 02150 batchs: 1227.91943359375
INFO:root:Train (Epoch 73): Loss/seq after 02200 batchs: 1215.843017578125
INFO:root:Train (Epoch 73): Loss/seq after 02250 batchs: 1212.90966796875
INFO:root:Train (Epoch 73): Loss/seq after 02300 batchs: 1214.3359375
INFO:root:Train (Epoch 73): Loss/seq after 02350 batchs: 1202.6912841796875
INFO:root:Train (Epoch 73): Loss/seq after 02400 batchs: 1197.3128662109375
INFO:root:Train (Epoch 73): Loss/seq after 02450 batchs: 1184.1983642578125
INFO:root:Train (Epoch 73): Loss/seq after 02500 batchs: 1167.59912109375
INFO:root:Train (Epoch 73): Loss/seq after 02550 batchs: 1155.254638671875
INFO:root:Train (Epoch 73): Loss/seq after 02600 batchs: 1152.404541015625
INFO:root:Train (Epoch 73): Loss/seq after 02650 batchs: 1147.1942138671875
INFO:root:Train (Epoch 73): Loss/seq after 02700 batchs: 1142.481201171875
INFO:root:Train (Epoch 73): Loss/seq after 02750 batchs: 1163.400390625
INFO:root:Train (Epoch 73): Loss/seq after 02800 batchs: 1167.0311279296875
INFO:root:Train (Epoch 73): Loss/seq after 02850 batchs: 1161.6695556640625
INFO:root:Train (Epoch 73): Loss/seq after 02900 batchs: 1159.2584228515625
INFO:root:Train (Epoch 73): Loss/seq after 02950 batchs: 1150.8128662109375
INFO:root:Train (Epoch 73): Loss/seq after 03000 batchs: 1149.41015625
INFO:root:Train (Epoch 73): Loss/seq after 03050 batchs: 1152.2423095703125
INFO:root:Train (Epoch 73): Loss/seq after 03100 batchs: 1161.3499755859375
INFO:root:Train (Epoch 73): Loss/seq after 03150 batchs: 1177.2347412109375
INFO:root:Train (Epoch 73): Loss/seq after 03200 batchs: 1192.1529541015625
INFO:root:Train (Epoch 73): Loss/seq after 03250 batchs: 1206.6209716796875
INFO:root:Train (Epoch 73): Loss/seq after 03300 batchs: 1204.237060546875
INFO:root:Train (Epoch 73): Loss/seq after 03350 batchs: 1202.6636962890625
INFO:root:Train (Epoch 73): Loss/seq after 03400 batchs: 1194.29541015625
INFO:root:Train (Epoch 73): Loss/seq after 03450 batchs: 1186.3076171875
INFO:root:Train (Epoch 73): Loss/seq after 03500 batchs: 1183.5574951171875
INFO:root:Train (Epoch 73): Loss/seq after 03550 batchs: 1175.236083984375
INFO:root:Train (Epoch 73): Loss/seq after 03600 batchs: 1179.7933349609375
INFO:root:Train (Epoch 73): Loss/seq after 03650 batchs: 1173.072509765625
INFO:root:Train (Epoch 73): Loss/seq after 03700 batchs: 1171.7451171875
INFO:root:Train (Epoch 73): Loss/seq after 03750 batchs: 1171.9862060546875
INFO:root:Train (Epoch 73): Loss/seq after 03800 batchs: 1165.2974853515625
INFO:root:Train (Epoch 73): Loss/seq after 03850 batchs: 1160.8016357421875
INFO:root:Train (Epoch 73): Loss/seq after 03900 batchs: 1166.440185546875
INFO:root:Train (Epoch 73): Loss/seq after 03950 batchs: 1174.1119384765625
INFO:root:Train (Epoch 73): Loss/seq after 04000 batchs: 1165.6326904296875
INFO:root:Train (Epoch 73): Loss/seq after 04050 batchs: 1158.1109619140625
INFO:root:Train (Epoch 73): Loss/seq after 04100 batchs: 1151.431396484375
INFO:root:Train (Epoch 73): Loss/seq after 04150 batchs: 1145.9058837890625
INFO:root:Train (Epoch 73): Loss/seq after 04200 batchs: 1139.6663818359375
INFO:root:Train (Epoch 73): Loss/seq after 04250 batchs: 1135.4755859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 73): Loss/seq after 00000 batches: 871.8743286132812
INFO:root:# Valid (Epoch 73): Loss/seq after 00050 batches: 1097.9874267578125
INFO:root:# Valid (Epoch 73): Loss/seq after 00100 batches: 1389.4227294921875
INFO:root:# Valid (Epoch 73): Loss/seq after 00150 batches: 1104.6490478515625
INFO:root:# Valid (Epoch 73): Loss/seq after 00200 batches: 991.7483520507812
INFO:root:Artifacts: Make stick videos for epoch 73
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_73_on_20220423_023610.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_73_index_1549_on_20220423_023610.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 74): Loss/seq after 00000 batchs: 2412.6416015625
INFO:root:Train (Epoch 74): Loss/seq after 00050 batchs: 1550.744873046875
INFO:root:Train (Epoch 74): Loss/seq after 00100 batchs: 1434.3955078125
INFO:root:Train (Epoch 74): Loss/seq after 00150 batchs: 1253.529052734375
INFO:root:Train (Epoch 74): Loss/seq after 00200 batchs: 1380.4261474609375
INFO:root:Train (Epoch 74): Loss/seq after 00250 batchs: 1485.309814453125
INFO:root:Train (Epoch 74): Loss/seq after 00300 batchs: 1417.4212646484375
INFO:root:Train (Epoch 74): Loss/seq after 00350 batchs: 1325.625
INFO:root:Train (Epoch 74): Loss/seq after 00400 batchs: 1364.2569580078125
INFO:root:Train (Epoch 74): Loss/seq after 00450 batchs: 1309.07421875
INFO:root:Train (Epoch 74): Loss/seq after 00500 batchs: 1300.568115234375
INFO:root:Train (Epoch 74): Loss/seq after 00550 batchs: 1248.27294921875
INFO:root:Train (Epoch 74): Loss/seq after 00600 batchs: 1215.423583984375
INFO:root:Train (Epoch 74): Loss/seq after 00650 batchs: 1289.8768310546875
INFO:root:Train (Epoch 74): Loss/seq after 00700 batchs: 1386.628173828125
INFO:root:Train (Epoch 74): Loss/seq after 00750 batchs: 1424.1365966796875
INFO:root:Train (Epoch 74): Loss/seq after 00800 batchs: 1397.7923583984375
INFO:root:Train (Epoch 74): Loss/seq after 00850 batchs: 1359.8577880859375
INFO:root:Train (Epoch 74): Loss/seq after 00900 batchs: 1358.05419921875
INFO:root:Train (Epoch 74): Loss/seq after 00950 batchs: 1441.6536865234375
INFO:root:Train (Epoch 74): Loss/seq after 01000 batchs: 1439.3424072265625
INFO:root:Train (Epoch 74): Loss/seq after 01050 batchs: 1408.895751953125
INFO:root:Train (Epoch 74): Loss/seq after 01100 batchs: 1397.828369140625
INFO:root:Train (Epoch 74): Loss/seq after 01150 batchs: 1377.3990478515625
INFO:root:Train (Epoch 74): Loss/seq after 01200 batchs: 1361.5430908203125
INFO:root:Train (Epoch 74): Loss/seq after 01250 batchs: 1352.9627685546875
INFO:root:Train (Epoch 74): Loss/seq after 01300 batchs: 1369.9632568359375
INFO:root:Train (Epoch 74): Loss/seq after 01350 batchs: 1375.681640625
INFO:root:Train (Epoch 74): Loss/seq after 01400 batchs: 1424.2513427734375
INFO:root:Train (Epoch 74): Loss/seq after 01450 batchs: 1409.1544189453125
INFO:root:Train (Epoch 74): Loss/seq after 01500 batchs: 1396.668701171875
INFO:root:Train (Epoch 74): Loss/seq after 01550 batchs: 1389.0736083984375
INFO:root:Train (Epoch 74): Loss/seq after 01600 batchs: 1369.3843994140625
INFO:root:Train (Epoch 74): Loss/seq after 01650 batchs: 1352.3692626953125
INFO:root:Train (Epoch 74): Loss/seq after 01700 batchs: 1340.21337890625
INFO:root:Train (Epoch 74): Loss/seq after 01750 batchs: 1326.5045166015625
INFO:root:Train (Epoch 74): Loss/seq after 01800 batchs: 1310.34521484375
INFO:root:Train (Epoch 74): Loss/seq after 01850 batchs: 1293.885009765625
INFO:root:Train (Epoch 74): Loss/seq after 01900 batchs: 1286.04931640625
INFO:root:Train (Epoch 74): Loss/seq after 01950 batchs: 1274.175537109375
INFO:root:Train (Epoch 74): Loss/seq after 02000 batchs: 1263.230712890625
INFO:root:Train (Epoch 74): Loss/seq after 02050 batchs: 1252.36669921875
INFO:root:Train (Epoch 74): Loss/seq after 02100 batchs: 1239.6976318359375
INFO:root:Train (Epoch 74): Loss/seq after 02150 batchs: 1227.607666015625
INFO:root:Train (Epoch 74): Loss/seq after 02200 batchs: 1215.6995849609375
INFO:root:Train (Epoch 74): Loss/seq after 02250 batchs: 1212.36865234375
INFO:root:Train (Epoch 74): Loss/seq after 02300 batchs: 1213.890380859375
INFO:root:Train (Epoch 74): Loss/seq after 02350 batchs: 1202.5042724609375
INFO:root:Train (Epoch 74): Loss/seq after 02400 batchs: 1197.029296875
INFO:root:Train (Epoch 74): Loss/seq after 02450 batchs: 1183.9239501953125
INFO:root:Train (Epoch 74): Loss/seq after 02500 batchs: 1167.3416748046875
INFO:root:Train (Epoch 74): Loss/seq after 02550 batchs: 1154.921142578125
INFO:root:Train (Epoch 74): Loss/seq after 02600 batchs: 1152.1195068359375
INFO:root:Train (Epoch 74): Loss/seq after 02650 batchs: 1146.9154052734375
INFO:root:Train (Epoch 74): Loss/seq after 02700 batchs: 1142.3248291015625
INFO:root:Train (Epoch 74): Loss/seq after 02750 batchs: 1162.733642578125
INFO:root:Train (Epoch 74): Loss/seq after 02800 batchs: 1167.4625244140625
INFO:root:Train (Epoch 74): Loss/seq after 02850 batchs: 1162.1937255859375
INFO:root:Train (Epoch 74): Loss/seq after 02900 batchs: 1160.038330078125
INFO:root:Train (Epoch 74): Loss/seq after 02950 batchs: 1151.547607421875
INFO:root:Train (Epoch 74): Loss/seq after 03000 batchs: 1150.15625
INFO:root:Train (Epoch 74): Loss/seq after 03050 batchs: 1152.9970703125
INFO:root:Train (Epoch 74): Loss/seq after 03100 batchs: 1162.2479248046875
INFO:root:Train (Epoch 74): Loss/seq after 03150 batchs: 1178.452392578125
INFO:root:Train (Epoch 74): Loss/seq after 03200 batchs: 1193.42431640625
INFO:root:Train (Epoch 74): Loss/seq after 03250 batchs: 1207.7294921875
INFO:root:Train (Epoch 74): Loss/seq after 03300 batchs: 1205.0748291015625
INFO:root:Train (Epoch 74): Loss/seq after 03350 batchs: 1203.80712890625
INFO:root:Train (Epoch 74): Loss/seq after 03400 batchs: 1195.4150390625
INFO:root:Train (Epoch 74): Loss/seq after 03450 batchs: 1187.8719482421875
INFO:root:Train (Epoch 74): Loss/seq after 03500 batchs: 1185.657470703125
INFO:root:Train (Epoch 74): Loss/seq after 03550 batchs: 1177.42822265625
INFO:root:Train (Epoch 74): Loss/seq after 03600 batchs: 1181.7696533203125
INFO:root:Train (Epoch 74): Loss/seq after 03650 batchs: 1174.7567138671875
INFO:root:Train (Epoch 74): Loss/seq after 03700 batchs: 1173.2169189453125
INFO:root:Train (Epoch 74): Loss/seq after 03750 batchs: 1173.3956298828125
INFO:root:Train (Epoch 74): Loss/seq after 03800 batchs: 1166.6209716796875
INFO:root:Train (Epoch 74): Loss/seq after 03850 batchs: 1162.1439208984375
INFO:root:Train (Epoch 74): Loss/seq after 03900 batchs: 1167.83447265625
INFO:root:Train (Epoch 74): Loss/seq after 03950 batchs: 1175.417236328125
INFO:root:Train (Epoch 74): Loss/seq after 04000 batchs: 1166.9312744140625
INFO:root:Train (Epoch 74): Loss/seq after 04050 batchs: 1159.378173828125
INFO:root:Train (Epoch 74): Loss/seq after 04100 batchs: 1152.701904296875
INFO:root:Train (Epoch 74): Loss/seq after 04150 batchs: 1147.2393798828125
INFO:root:Train (Epoch 74): Loss/seq after 04200 batchs: 1141.21044921875
INFO:root:Train (Epoch 74): Loss/seq after 04250 batchs: 1136.90625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 74): Loss/seq after 00000 batches: 863.9391479492188
INFO:root:# Valid (Epoch 74): Loss/seq after 00050 batches: 1091.4000244140625
INFO:root:# Valid (Epoch 74): Loss/seq after 00100 batches: 1382.7384033203125
INFO:root:# Valid (Epoch 74): Loss/seq after 00150 batches: 1100.8060302734375
INFO:root:# Valid (Epoch 74): Loss/seq after 00200 batches: 986.996337890625
INFO:root:Artifacts: Make stick videos for epoch 74
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_74_on_20220423_024100.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_74_index_979_on_20220423_024100.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 75): Loss/seq after 00000 batchs: 2408.906005859375
INFO:root:Train (Epoch 75): Loss/seq after 00050 batchs: 1524.3868408203125
INFO:root:Train (Epoch 75): Loss/seq after 00100 batchs: 1431.366455078125
INFO:root:Train (Epoch 75): Loss/seq after 00150 batchs: 1253.718017578125
INFO:root:Train (Epoch 75): Loss/seq after 00200 batchs: 1381.6705322265625
INFO:root:Train (Epoch 75): Loss/seq after 00250 batchs: 1485.5423583984375
INFO:root:Train (Epoch 75): Loss/seq after 00300 batchs: 1417.607666015625
INFO:root:Train (Epoch 75): Loss/seq after 00350 batchs: 1326.9041748046875
INFO:root:Train (Epoch 75): Loss/seq after 00400 batchs: 1366.4498291015625
INFO:root:Train (Epoch 75): Loss/seq after 00450 batchs: 1310.8616943359375
INFO:root:Train (Epoch 75): Loss/seq after 00500 batchs: 1303.345947265625
INFO:root:Train (Epoch 75): Loss/seq after 00550 batchs: 1250.4188232421875
INFO:root:Train (Epoch 75): Loss/seq after 00600 batchs: 1217.9697265625
INFO:root:Train (Epoch 75): Loss/seq after 00650 batchs: 1292.2335205078125
INFO:root:Train (Epoch 75): Loss/seq after 00700 batchs: 1388.1318359375
INFO:root:Train (Epoch 75): Loss/seq after 00750 batchs: 1426.1229248046875
INFO:root:Train (Epoch 75): Loss/seq after 00800 batchs: 1401.891357421875
INFO:root:Train (Epoch 75): Loss/seq after 00850 batchs: 1364.275390625
INFO:root:Train (Epoch 75): Loss/seq after 00900 batchs: 1362.1351318359375
INFO:root:Train (Epoch 75): Loss/seq after 00950 batchs: 1445.446044921875
INFO:root:Train (Epoch 75): Loss/seq after 01000 batchs: 1443.4539794921875
INFO:root:Train (Epoch 75): Loss/seq after 01050 batchs: 1411.7117919921875
INFO:root:Train (Epoch 75): Loss/seq after 01100 batchs: 1397.9510498046875
INFO:root:Train (Epoch 75): Loss/seq after 01150 batchs: 1377.0888671875
INFO:root:Train (Epoch 75): Loss/seq after 01200 batchs: 1360.455078125
INFO:root:Train (Epoch 75): Loss/seq after 01250 batchs: 1350.472412109375
INFO:root:Train (Epoch 75): Loss/seq after 01300 batchs: 1367.755615234375
INFO:root:Train (Epoch 75): Loss/seq after 01350 batchs: 1373.5120849609375
INFO:root:Train (Epoch 75): Loss/seq after 01400 batchs: 1421.6815185546875
INFO:root:Train (Epoch 75): Loss/seq after 01450 batchs: 1405.729736328125
INFO:root:Train (Epoch 75): Loss/seq after 01500 batchs: 1392.91748046875
INFO:root:Train (Epoch 75): Loss/seq after 01550 batchs: 1385.151123046875
INFO:root:Train (Epoch 75): Loss/seq after 01600 batchs: 1364.99365234375
INFO:root:Train (Epoch 75): Loss/seq after 01650 batchs: 1348.019775390625
INFO:root:Train (Epoch 75): Loss/seq after 01700 batchs: 1336.287841796875
INFO:root:Train (Epoch 75): Loss/seq after 01750 batchs: 1322.554931640625
INFO:root:Train (Epoch 75): Loss/seq after 01800 batchs: 1306.3603515625
INFO:root:Train (Epoch 75): Loss/seq after 01850 batchs: 1289.9481201171875
INFO:root:Train (Epoch 75): Loss/seq after 01900 batchs: 1282.1070556640625
INFO:root:Train (Epoch 75): Loss/seq after 01950 batchs: 1270.9039306640625
INFO:root:Train (Epoch 75): Loss/seq after 02000 batchs: 1260.5220947265625
INFO:root:Train (Epoch 75): Loss/seq after 02050 batchs: 1250.0050048828125
INFO:root:Train (Epoch 75): Loss/seq after 02100 batchs: 1237.3917236328125
INFO:root:Train (Epoch 75): Loss/seq after 02150 batchs: 1225.3330078125
INFO:root:Train (Epoch 75): Loss/seq after 02200 batchs: 1213.36767578125
INFO:root:Train (Epoch 75): Loss/seq after 02250 batchs: 1210.178466796875
INFO:root:Train (Epoch 75): Loss/seq after 02300 batchs: 1212.071533203125
INFO:root:Train (Epoch 75): Loss/seq after 02350 batchs: 1200.2471923828125
INFO:root:Train (Epoch 75): Loss/seq after 02400 batchs: 1194.7611083984375
INFO:root:Train (Epoch 75): Loss/seq after 02450 batchs: 1181.72607421875
INFO:root:Train (Epoch 75): Loss/seq after 02500 batchs: 1165.1934814453125
INFO:root:Train (Epoch 75): Loss/seq after 02550 batchs: 1152.8895263671875
INFO:root:Train (Epoch 75): Loss/seq after 02600 batchs: 1149.9912109375
INFO:root:Train (Epoch 75): Loss/seq after 02650 batchs: 1144.9317626953125
INFO:root:Train (Epoch 75): Loss/seq after 02700 batchs: 1140.528076171875
INFO:root:Train (Epoch 75): Loss/seq after 02750 batchs: 1162.3646240234375
INFO:root:Train (Epoch 75): Loss/seq after 02800 batchs: 1166.09912109375
INFO:root:Train (Epoch 75): Loss/seq after 02850 batchs: 1161.02734375
INFO:root:Train (Epoch 75): Loss/seq after 02900 batchs: 1158.6661376953125
INFO:root:Train (Epoch 75): Loss/seq after 02950 batchs: 1150.2822265625
INFO:root:Train (Epoch 75): Loss/seq after 03000 batchs: 1148.8502197265625
INFO:root:Train (Epoch 75): Loss/seq after 03050 batchs: 1151.7591552734375
INFO:root:Train (Epoch 75): Loss/seq after 03100 batchs: 1161.1190185546875
INFO:root:Train (Epoch 75): Loss/seq after 03150 batchs: 1177.9449462890625
INFO:root:Train (Epoch 75): Loss/seq after 03200 batchs: 1192.886962890625
INFO:root:Train (Epoch 75): Loss/seq after 03250 batchs: 1207.2486572265625
INFO:root:Train (Epoch 75): Loss/seq after 03300 batchs: 1204.065673828125
INFO:root:Train (Epoch 75): Loss/seq after 03350 batchs: 1202.4508056640625
INFO:root:Train (Epoch 75): Loss/seq after 03400 batchs: 1194.05419921875
INFO:root:Train (Epoch 75): Loss/seq after 03450 batchs: 1185.9674072265625
INFO:root:Train (Epoch 75): Loss/seq after 03500 batchs: 1183.392333984375
INFO:root:Train (Epoch 75): Loss/seq after 03550 batchs: 1175.12548828125
INFO:root:Train (Epoch 75): Loss/seq after 03600 batchs: 1179.5247802734375
INFO:root:Train (Epoch 75): Loss/seq after 03650 batchs: 1172.6038818359375
INFO:root:Train (Epoch 75): Loss/seq after 03700 batchs: 1171.013916015625
INFO:root:Train (Epoch 75): Loss/seq after 03750 batchs: 1171.2186279296875
INFO:root:Train (Epoch 75): Loss/seq after 03800 batchs: 1164.4710693359375
INFO:root:Train (Epoch 75): Loss/seq after 03850 batchs: 1159.9552001953125
INFO:root:Train (Epoch 75): Loss/seq after 03900 batchs: 1165.7457275390625
INFO:root:Train (Epoch 75): Loss/seq after 03950 batchs: 1173.4329833984375
INFO:root:Train (Epoch 75): Loss/seq after 04000 batchs: 1164.9564208984375
INFO:root:Train (Epoch 75): Loss/seq after 04050 batchs: 1157.4322509765625
INFO:root:Train (Epoch 75): Loss/seq after 04100 batchs: 1150.7291259765625
INFO:root:Train (Epoch 75): Loss/seq after 04150 batchs: 1145.2890625
INFO:root:Train (Epoch 75): Loss/seq after 04200 batchs: 1139.201416015625
INFO:root:Train (Epoch 75): Loss/seq after 04250 batchs: 1134.8739013671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 75): Loss/seq after 00000 batches: 869.5256958007812
INFO:root:# Valid (Epoch 75): Loss/seq after 00050 batches: 1091.2984619140625
INFO:root:# Valid (Epoch 75): Loss/seq after 00100 batches: 1373.9842529296875
INFO:root:# Valid (Epoch 75): Loss/seq after 00150 batches: 1089.85888671875
INFO:root:# Valid (Epoch 75): Loss/seq after 00200 batches: 976.4244995117188
INFO:root:Artifacts: Make stick videos for epoch 75
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_75_on_20220423_024558.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_75_index_967_on_20220423_024558.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 76): Loss/seq after 00000 batchs: 2397.009765625
INFO:root:Train (Epoch 76): Loss/seq after 00050 batchs: 1525.7689208984375
INFO:root:Train (Epoch 76): Loss/seq after 00100 batchs: 1419.97998046875
INFO:root:Train (Epoch 76): Loss/seq after 00150 batchs: 1246.3433837890625
INFO:root:Train (Epoch 76): Loss/seq after 00200 batchs: 1373.9241943359375
INFO:root:Train (Epoch 76): Loss/seq after 00250 batchs: 1480.614013671875
INFO:root:Train (Epoch 76): Loss/seq after 00300 batchs: 1413.3980712890625
INFO:root:Train (Epoch 76): Loss/seq after 00350 batchs: 1320.1312255859375
INFO:root:Train (Epoch 76): Loss/seq after 00400 batchs: 1359.42626953125
INFO:root:Train (Epoch 76): Loss/seq after 00450 batchs: 1304.290283203125
INFO:root:Train (Epoch 76): Loss/seq after 00500 batchs: 1294.778564453125
INFO:root:Train (Epoch 76): Loss/seq after 00550 batchs: 1242.5775146484375
INFO:root:Train (Epoch 76): Loss/seq after 00600 batchs: 1210.8262939453125
INFO:root:Train (Epoch 76): Loss/seq after 00650 batchs: 1286.0618896484375
INFO:root:Train (Epoch 76): Loss/seq after 00700 batchs: 1382.799560546875
INFO:root:Train (Epoch 76): Loss/seq after 00750 batchs: 1421.77294921875
INFO:root:Train (Epoch 76): Loss/seq after 00800 batchs: 1396.4010009765625
INFO:root:Train (Epoch 76): Loss/seq after 00850 batchs: 1358.683837890625
INFO:root:Train (Epoch 76): Loss/seq after 00900 batchs: 1357.219482421875
INFO:root:Train (Epoch 76): Loss/seq after 00950 batchs: 1441.7283935546875
INFO:root:Train (Epoch 76): Loss/seq after 01000 batchs: 1439.8668212890625
INFO:root:Train (Epoch 76): Loss/seq after 01050 batchs: 1409.5491943359375
INFO:root:Train (Epoch 76): Loss/seq after 01100 batchs: 1396.29052734375
INFO:root:Train (Epoch 76): Loss/seq after 01150 batchs: 1376.714599609375
INFO:root:Train (Epoch 76): Loss/seq after 01200 batchs: 1361.653564453125
INFO:root:Train (Epoch 76): Loss/seq after 01250 batchs: 1352.431396484375
INFO:root:Train (Epoch 76): Loss/seq after 01300 batchs: 1369.471435546875
INFO:root:Train (Epoch 76): Loss/seq after 01350 batchs: 1375.09912109375
INFO:root:Train (Epoch 76): Loss/seq after 01400 batchs: 1422.5711669921875
INFO:root:Train (Epoch 76): Loss/seq after 01450 batchs: 1406.893310546875
INFO:root:Train (Epoch 76): Loss/seq after 01500 batchs: 1394.100830078125
INFO:root:Train (Epoch 76): Loss/seq after 01550 batchs: 1386.591064453125
INFO:root:Train (Epoch 76): Loss/seq after 01600 batchs: 1366.198974609375
INFO:root:Train (Epoch 76): Loss/seq after 01650 batchs: 1349.3426513671875
INFO:root:Train (Epoch 76): Loss/seq after 01700 batchs: 1337.3603515625
INFO:root:Train (Epoch 76): Loss/seq after 01750 batchs: 1323.6571044921875
INFO:root:Train (Epoch 76): Loss/seq after 01800 batchs: 1307.634765625
INFO:root:Train (Epoch 76): Loss/seq after 01850 batchs: 1291.2967529296875
INFO:root:Train (Epoch 76): Loss/seq after 01900 batchs: 1283.3482666015625
INFO:root:Train (Epoch 76): Loss/seq after 01950 batchs: 1271.4559326171875
INFO:root:Train (Epoch 76): Loss/seq after 02000 batchs: 1260.5447998046875
INFO:root:Train (Epoch 76): Loss/seq after 02050 batchs: 1249.586181640625
INFO:root:Train (Epoch 76): Loss/seq after 02100 batchs: 1236.870849609375
INFO:root:Train (Epoch 76): Loss/seq after 02150 batchs: 1224.766357421875
INFO:root:Train (Epoch 76): Loss/seq after 02200 batchs: 1212.783447265625
INFO:root:Train (Epoch 76): Loss/seq after 02250 batchs: 1210.314208984375
INFO:root:Train (Epoch 76): Loss/seq after 02300 batchs: 1211.7625732421875
INFO:root:Train (Epoch 76): Loss/seq after 02350 batchs: 1199.7784423828125
INFO:root:Train (Epoch 76): Loss/seq after 02400 batchs: 1194.16259765625
INFO:root:Train (Epoch 76): Loss/seq after 02450 batchs: 1181.0968017578125
INFO:root:Train (Epoch 76): Loss/seq after 02500 batchs: 1164.57666015625
INFO:root:Train (Epoch 76): Loss/seq after 02550 batchs: 1152.2178955078125
INFO:root:Train (Epoch 76): Loss/seq after 02600 batchs: 1149.4345703125
INFO:root:Train (Epoch 76): Loss/seq after 02650 batchs: 1144.27783203125
INFO:root:Train (Epoch 76): Loss/seq after 02700 batchs: 1139.7628173828125
INFO:root:Train (Epoch 76): Loss/seq after 02750 batchs: 1160.875244140625
INFO:root:Train (Epoch 76): Loss/seq after 02800 batchs: 1163.9935302734375
INFO:root:Train (Epoch 76): Loss/seq after 02850 batchs: 1158.5372314453125
INFO:root:Train (Epoch 76): Loss/seq after 02900 batchs: 1155.9556884765625
INFO:root:Train (Epoch 76): Loss/seq after 02950 batchs: 1147.6881103515625
INFO:root:Train (Epoch 76): Loss/seq after 03000 batchs: 1146.2547607421875
INFO:root:Train (Epoch 76): Loss/seq after 03050 batchs: 1149.295166015625
INFO:root:Train (Epoch 76): Loss/seq after 03100 batchs: 1158.2537841796875
INFO:root:Train (Epoch 76): Loss/seq after 03150 batchs: 1174.3184814453125
INFO:root:Train (Epoch 76): Loss/seq after 03200 batchs: 1189.1649169921875
INFO:root:Train (Epoch 76): Loss/seq after 03250 batchs: 1203.56640625
INFO:root:Train (Epoch 76): Loss/seq after 03300 batchs: 1200.5198974609375
INFO:root:Train (Epoch 76): Loss/seq after 03350 batchs: 1199.004638671875
INFO:root:Train (Epoch 76): Loss/seq after 03400 batchs: 1190.6783447265625
INFO:root:Train (Epoch 76): Loss/seq after 03450 batchs: 1182.6197509765625
INFO:root:Train (Epoch 76): Loss/seq after 03500 batchs: 1180.1690673828125
INFO:root:Train (Epoch 76): Loss/seq after 03550 batchs: 1172.3382568359375
INFO:root:Train (Epoch 76): Loss/seq after 03600 batchs: 1177.0799560546875
INFO:root:Train (Epoch 76): Loss/seq after 03650 batchs: 1170.4884033203125
INFO:root:Train (Epoch 76): Loss/seq after 03700 batchs: 1168.982666015625
INFO:root:Train (Epoch 76): Loss/seq after 03750 batchs: 1169.222900390625
INFO:root:Train (Epoch 76): Loss/seq after 03800 batchs: 1162.5404052734375
INFO:root:Train (Epoch 76): Loss/seq after 03850 batchs: 1158.072509765625
INFO:root:Train (Epoch 76): Loss/seq after 03900 batchs: 1163.7081298828125
INFO:root:Train (Epoch 76): Loss/seq after 03950 batchs: 1171.2747802734375
INFO:root:Train (Epoch 76): Loss/seq after 04000 batchs: 1162.8282470703125
INFO:root:Train (Epoch 76): Loss/seq after 04050 batchs: 1155.3138427734375
INFO:root:Train (Epoch 76): Loss/seq after 04100 batchs: 1148.653564453125
INFO:root:Train (Epoch 76): Loss/seq after 04150 batchs: 1143.2823486328125
INFO:root:Train (Epoch 76): Loss/seq after 04200 batchs: 1137.0166015625
INFO:root:Train (Epoch 76): Loss/seq after 04250 batchs: 1132.6546630859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 76): Loss/seq after 00000 batches: 878.3737182617188
INFO:root:# Valid (Epoch 76): Loss/seq after 00050 batches: 1098.5318603515625
INFO:root:# Valid (Epoch 76): Loss/seq after 00100 batches: 1383.2442626953125
INFO:root:# Valid (Epoch 76): Loss/seq after 00150 batches: 1098.181884765625
INFO:root:# Valid (Epoch 76): Loss/seq after 00200 batches: 985.652099609375
INFO:root:Artifacts: Make stick videos for epoch 76
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_76_on_20220423_025053.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_76_index_1308_on_20220423_025053.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 77): Loss/seq after 00000 batchs: 2412.827880859375
INFO:root:Train (Epoch 77): Loss/seq after 00050 batchs: 1529.87939453125
INFO:root:Train (Epoch 77): Loss/seq after 00100 batchs: 1458.0279541015625
INFO:root:Train (Epoch 77): Loss/seq after 00150 batchs: 1268.7552490234375
INFO:root:Train (Epoch 77): Loss/seq after 00200 batchs: 1394.3858642578125
INFO:root:Train (Epoch 77): Loss/seq after 00250 batchs: 1501.8043212890625
INFO:root:Train (Epoch 77): Loss/seq after 00300 batchs: 1431.6876220703125
INFO:root:Train (Epoch 77): Loss/seq after 00350 batchs: 1336.0921630859375
INFO:root:Train (Epoch 77): Loss/seq after 00400 batchs: 1373.921630859375
INFO:root:Train (Epoch 77): Loss/seq after 00450 batchs: 1317.220703125
INFO:root:Train (Epoch 77): Loss/seq after 00500 batchs: 1304.6680908203125
INFO:root:Train (Epoch 77): Loss/seq after 00550 batchs: 1251.2359619140625
INFO:root:Train (Epoch 77): Loss/seq after 00600 batchs: 1217.87548828125
INFO:root:Train (Epoch 77): Loss/seq after 00650 batchs: 1292.99267578125
INFO:root:Train (Epoch 77): Loss/seq after 00700 batchs: 1391.0496826171875
INFO:root:Train (Epoch 77): Loss/seq after 00750 batchs: 1428.9498291015625
INFO:root:Train (Epoch 77): Loss/seq after 00800 batchs: 1402.264892578125
INFO:root:Train (Epoch 77): Loss/seq after 00850 batchs: 1364.1390380859375
INFO:root:Train (Epoch 77): Loss/seq after 00900 batchs: 1361.8824462890625
INFO:root:Train (Epoch 77): Loss/seq after 00950 batchs: 1445.8369140625
INFO:root:Train (Epoch 77): Loss/seq after 01000 batchs: 1442.9013671875
INFO:root:Train (Epoch 77): Loss/seq after 01050 batchs: 1413.33251953125
INFO:root:Train (Epoch 77): Loss/seq after 01100 batchs: 1399.426025390625
INFO:root:Train (Epoch 77): Loss/seq after 01150 batchs: 1378.6129150390625
INFO:root:Train (Epoch 77): Loss/seq after 01200 batchs: 1362.4693603515625
INFO:root:Train (Epoch 77): Loss/seq after 01250 batchs: 1353.2454833984375
INFO:root:Train (Epoch 77): Loss/seq after 01300 batchs: 1370.3876953125
INFO:root:Train (Epoch 77): Loss/seq after 01350 batchs: 1376.04638671875
INFO:root:Train (Epoch 77): Loss/seq after 01400 batchs: 1424.342529296875
INFO:root:Train (Epoch 77): Loss/seq after 01450 batchs: 1408.7470703125
INFO:root:Train (Epoch 77): Loss/seq after 01500 batchs: 1395.84326171875
INFO:root:Train (Epoch 77): Loss/seq after 01550 batchs: 1388.1861572265625
INFO:root:Train (Epoch 77): Loss/seq after 01600 batchs: 1367.7183837890625
INFO:root:Train (Epoch 77): Loss/seq after 01650 batchs: 1350.3477783203125
INFO:root:Train (Epoch 77): Loss/seq after 01700 batchs: 1338.1673583984375
INFO:root:Train (Epoch 77): Loss/seq after 01750 batchs: 1324.3824462890625
INFO:root:Train (Epoch 77): Loss/seq after 01800 batchs: 1308.170654296875
INFO:root:Train (Epoch 77): Loss/seq after 01850 batchs: 1291.5328369140625
INFO:root:Train (Epoch 77): Loss/seq after 01900 batchs: 1283.5860595703125
INFO:root:Train (Epoch 77): Loss/seq after 01950 batchs: 1273.0035400390625
INFO:root:Train (Epoch 77): Loss/seq after 02000 batchs: 1262.113037109375
INFO:root:Train (Epoch 77): Loss/seq after 02050 batchs: 1251.17529296875
INFO:root:Train (Epoch 77): Loss/seq after 02100 batchs: 1238.334228515625
INFO:root:Train (Epoch 77): Loss/seq after 02150 batchs: 1226.136962890625
INFO:root:Train (Epoch 77): Loss/seq after 02200 batchs: 1214.0714111328125
INFO:root:Train (Epoch 77): Loss/seq after 02250 batchs: 1210.79248046875
INFO:root:Train (Epoch 77): Loss/seq after 02300 batchs: 1212.2452392578125
INFO:root:Train (Epoch 77): Loss/seq after 02350 batchs: 1200.47265625
INFO:root:Train (Epoch 77): Loss/seq after 02400 batchs: 1194.99462890625
INFO:root:Train (Epoch 77): Loss/seq after 02450 batchs: 1181.9495849609375
INFO:root:Train (Epoch 77): Loss/seq after 02500 batchs: 1165.40625
INFO:root:Train (Epoch 77): Loss/seq after 02550 batchs: 1153.1881103515625
INFO:root:Train (Epoch 77): Loss/seq after 02600 batchs: 1150.355712890625
INFO:root:Train (Epoch 77): Loss/seq after 02650 batchs: 1145.1220703125
INFO:root:Train (Epoch 77): Loss/seq after 02700 batchs: 1140.45361328125
INFO:root:Train (Epoch 77): Loss/seq after 02750 batchs: 1158.5338134765625
INFO:root:Train (Epoch 77): Loss/seq after 02800 batchs: 1163.613525390625
INFO:root:Train (Epoch 77): Loss/seq after 02850 batchs: 1158.4486083984375
INFO:root:Train (Epoch 77): Loss/seq after 02900 batchs: 1155.882080078125
INFO:root:Train (Epoch 77): Loss/seq after 02950 batchs: 1147.5433349609375
INFO:root:Train (Epoch 77): Loss/seq after 03000 batchs: 1146.2166748046875
INFO:root:Train (Epoch 77): Loss/seq after 03050 batchs: 1149.3111572265625
INFO:root:Train (Epoch 77): Loss/seq after 03100 batchs: 1158.9112548828125
INFO:root:Train (Epoch 77): Loss/seq after 03150 batchs: 1174.8414306640625
INFO:root:Train (Epoch 77): Loss/seq after 03200 batchs: 1189.88818359375
INFO:root:Train (Epoch 77): Loss/seq after 03250 batchs: 1204.14697265625
INFO:root:Train (Epoch 77): Loss/seq after 03300 batchs: 1201.09619140625
INFO:root:Train (Epoch 77): Loss/seq after 03350 batchs: 1199.875732421875
INFO:root:Train (Epoch 77): Loss/seq after 03400 batchs: 1191.510498046875
INFO:root:Train (Epoch 77): Loss/seq after 03450 batchs: 1183.1619873046875
INFO:root:Train (Epoch 77): Loss/seq after 03500 batchs: 1180.6131591796875
INFO:root:Train (Epoch 77): Loss/seq after 03550 batchs: 1172.62060546875
INFO:root:Train (Epoch 77): Loss/seq after 03600 batchs: 1176.9952392578125
INFO:root:Train (Epoch 77): Loss/seq after 03650 batchs: 1170.182373046875
INFO:root:Train (Epoch 77): Loss/seq after 03700 batchs: 1168.6029052734375
INFO:root:Train (Epoch 77): Loss/seq after 03750 batchs: 1168.8414306640625
INFO:root:Train (Epoch 77): Loss/seq after 03800 batchs: 1162.1416015625
INFO:root:Train (Epoch 77): Loss/seq after 03850 batchs: 1157.636474609375
INFO:root:Train (Epoch 77): Loss/seq after 03900 batchs: 1163.31689453125
INFO:root:Train (Epoch 77): Loss/seq after 03950 batchs: 1170.96875
INFO:root:Train (Epoch 77): Loss/seq after 04000 batchs: 1162.521728515625
INFO:root:Train (Epoch 77): Loss/seq after 04050 batchs: 1155.01025390625
INFO:root:Train (Epoch 77): Loss/seq after 04100 batchs: 1148.2779541015625
INFO:root:Train (Epoch 77): Loss/seq after 04150 batchs: 1142.8939208984375
INFO:root:Train (Epoch 77): Loss/seq after 04200 batchs: 1136.9530029296875
INFO:root:Train (Epoch 77): Loss/seq after 04250 batchs: 1132.691162109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 77): Loss/seq after 00000 batches: 886.3621826171875
INFO:root:# Valid (Epoch 77): Loss/seq after 00050 batches: 1114.7823486328125
INFO:root:# Valid (Epoch 77): Loss/seq after 00100 batches: 1400.7913818359375
INFO:root:# Valid (Epoch 77): Loss/seq after 00150 batches: 1116.8814697265625
INFO:root:# Valid (Epoch 77): Loss/seq after 00200 batches: 1006.8403930664062
INFO:root:Artifacts: Make stick videos for epoch 77
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_77_on_20220423_025542.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_77_index_774_on_20220423_025542.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 78): Loss/seq after 00000 batchs: 2392.336669921875
INFO:root:Train (Epoch 78): Loss/seq after 00050 batchs: 1515.4293212890625
INFO:root:Train (Epoch 78): Loss/seq after 00100 batchs: 1409.48388671875
INFO:root:Train (Epoch 78): Loss/seq after 00150 batchs: 1238.56689453125
INFO:root:Train (Epoch 78): Loss/seq after 00200 batchs: 1366.154052734375
INFO:root:Train (Epoch 78): Loss/seq after 00250 batchs: 1471.6390380859375
INFO:root:Train (Epoch 78): Loss/seq after 00300 batchs: 1405.8775634765625
INFO:root:Train (Epoch 78): Loss/seq after 00350 batchs: 1313.81494140625
INFO:root:Train (Epoch 78): Loss/seq after 00400 batchs: 1353.2177734375
INFO:root:Train (Epoch 78): Loss/seq after 00450 batchs: 1298.5963134765625
INFO:root:Train (Epoch 78): Loss/seq after 00500 batchs: 1290.870849609375
INFO:root:Train (Epoch 78): Loss/seq after 00550 batchs: 1238.5628662109375
INFO:root:Train (Epoch 78): Loss/seq after 00600 batchs: 1208.3365478515625
INFO:root:Train (Epoch 78): Loss/seq after 00650 batchs: 1283.2034912109375
INFO:root:Train (Epoch 78): Loss/seq after 00700 batchs: 1379.553955078125
INFO:root:Train (Epoch 78): Loss/seq after 00750 batchs: 1417.721923828125
INFO:root:Train (Epoch 78): Loss/seq after 00800 batchs: 1392.8267822265625
INFO:root:Train (Epoch 78): Loss/seq after 00850 batchs: 1355.4078369140625
INFO:root:Train (Epoch 78): Loss/seq after 00900 batchs: 1354.4140625
INFO:root:Train (Epoch 78): Loss/seq after 00950 batchs: 1438.2257080078125
INFO:root:Train (Epoch 78): Loss/seq after 01000 batchs: 1435.9329833984375
INFO:root:Train (Epoch 78): Loss/seq after 01050 batchs: 1404.7305908203125
INFO:root:Train (Epoch 78): Loss/seq after 01100 batchs: 1391.0867919921875
INFO:root:Train (Epoch 78): Loss/seq after 01150 batchs: 1370.9671630859375
INFO:root:Train (Epoch 78): Loss/seq after 01200 batchs: 1354.810302734375
INFO:root:Train (Epoch 78): Loss/seq after 01250 batchs: 1344.5758056640625
INFO:root:Train (Epoch 78): Loss/seq after 01300 batchs: 1361.8497314453125
INFO:root:Train (Epoch 78): Loss/seq after 01350 batchs: 1367.76025390625
INFO:root:Train (Epoch 78): Loss/seq after 01400 batchs: 1415.79541015625
INFO:root:Train (Epoch 78): Loss/seq after 01450 batchs: 1400.018798828125
INFO:root:Train (Epoch 78): Loss/seq after 01500 batchs: 1387.178466796875
INFO:root:Train (Epoch 78): Loss/seq after 01550 batchs: 1379.9273681640625
INFO:root:Train (Epoch 78): Loss/seq after 01600 batchs: 1359.66015625
INFO:root:Train (Epoch 78): Loss/seq after 01650 batchs: 1343.0703125
INFO:root:Train (Epoch 78): Loss/seq after 01700 batchs: 1331.321044921875
INFO:root:Train (Epoch 78): Loss/seq after 01750 batchs: 1317.6224365234375
INFO:root:Train (Epoch 78): Loss/seq after 01800 batchs: 1301.60107421875
INFO:root:Train (Epoch 78): Loss/seq after 01850 batchs: 1285.2357177734375
INFO:root:Train (Epoch 78): Loss/seq after 01900 batchs: 1277.601806640625
INFO:root:Train (Epoch 78): Loss/seq after 01950 batchs: 1266.0865478515625
INFO:root:Train (Epoch 78): Loss/seq after 02000 batchs: 1255.310791015625
INFO:root:Train (Epoch 78): Loss/seq after 02050 batchs: 1244.334228515625
INFO:root:Train (Epoch 78): Loss/seq after 02100 batchs: 1231.666259765625
INFO:root:Train (Epoch 78): Loss/seq after 02150 batchs: 1219.6717529296875
INFO:root:Train (Epoch 78): Loss/seq after 02200 batchs: 1207.7545166015625
INFO:root:Train (Epoch 78): Loss/seq after 02250 batchs: 1204.71826171875
INFO:root:Train (Epoch 78): Loss/seq after 02300 batchs: 1206.3602294921875
INFO:root:Train (Epoch 78): Loss/seq after 02350 batchs: 1194.789794921875
INFO:root:Train (Epoch 78): Loss/seq after 02400 batchs: 1189.4119873046875
INFO:root:Train (Epoch 78): Loss/seq after 02450 batchs: 1176.4591064453125
INFO:root:Train (Epoch 78): Loss/seq after 02500 batchs: 1160.0233154296875
INFO:root:Train (Epoch 78): Loss/seq after 02550 batchs: 1147.9671630859375
INFO:root:Train (Epoch 78): Loss/seq after 02600 batchs: 1145.2257080078125
INFO:root:Train (Epoch 78): Loss/seq after 02650 batchs: 1140.194580078125
INFO:root:Train (Epoch 78): Loss/seq after 02700 batchs: 1135.6280517578125
INFO:root:Train (Epoch 78): Loss/seq after 02750 batchs: 1152.7261962890625
INFO:root:Train (Epoch 78): Loss/seq after 02800 batchs: 1156.9615478515625
INFO:root:Train (Epoch 78): Loss/seq after 02850 batchs: 1151.849609375
INFO:root:Train (Epoch 78): Loss/seq after 02900 batchs: 1149.758056640625
INFO:root:Train (Epoch 78): Loss/seq after 02950 batchs: 1141.543701171875
INFO:root:Train (Epoch 78): Loss/seq after 03000 batchs: 1140.2408447265625
INFO:root:Train (Epoch 78): Loss/seq after 03050 batchs: 1143.3592529296875
INFO:root:Train (Epoch 78): Loss/seq after 03100 batchs: 1152.7086181640625
INFO:root:Train (Epoch 78): Loss/seq after 03150 batchs: 1170.0615234375
INFO:root:Train (Epoch 78): Loss/seq after 03200 batchs: 1185.1568603515625
INFO:root:Train (Epoch 78): Loss/seq after 03250 batchs: 1199.667724609375
INFO:root:Train (Epoch 78): Loss/seq after 03300 batchs: 1196.7427978515625
INFO:root:Train (Epoch 78): Loss/seq after 03350 batchs: 1195.1236572265625
INFO:root:Train (Epoch 78): Loss/seq after 03400 batchs: 1186.8084716796875
INFO:root:Train (Epoch 78): Loss/seq after 03450 batchs: 1178.841064453125
INFO:root:Train (Epoch 78): Loss/seq after 03500 batchs: 1176.2591552734375
INFO:root:Train (Epoch 78): Loss/seq after 03550 batchs: 1167.9515380859375
INFO:root:Train (Epoch 78): Loss/seq after 03600 batchs: 1172.2655029296875
INFO:root:Train (Epoch 78): Loss/seq after 03650 batchs: 1165.169921875
INFO:root:Train (Epoch 78): Loss/seq after 03700 batchs: 1163.7509765625
INFO:root:Train (Epoch 78): Loss/seq after 03750 batchs: 1164.0205078125
INFO:root:Train (Epoch 78): Loss/seq after 03800 batchs: 1157.350830078125
INFO:root:Train (Epoch 78): Loss/seq after 03850 batchs: 1152.8951416015625
INFO:root:Train (Epoch 78): Loss/seq after 03900 batchs: 1158.5408935546875
INFO:root:Train (Epoch 78): Loss/seq after 03950 batchs: 1166.3812255859375
INFO:root:Train (Epoch 78): Loss/seq after 04000 batchs: 1158.001708984375
INFO:root:Train (Epoch 78): Loss/seq after 04050 batchs: 1150.5484619140625
INFO:root:Train (Epoch 78): Loss/seq after 04100 batchs: 1143.7962646484375
INFO:root:Train (Epoch 78): Loss/seq after 04150 batchs: 1138.3548583984375
INFO:root:Train (Epoch 78): Loss/seq after 04200 batchs: 1132.0311279296875
INFO:root:Train (Epoch 78): Loss/seq after 04250 batchs: 1127.6973876953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 78): Loss/seq after 00000 batches: 908.7192993164062
INFO:root:# Valid (Epoch 78): Loss/seq after 00050 batches: 1108.191650390625
INFO:root:# Valid (Epoch 78): Loss/seq after 00100 batches: 1392.837890625
INFO:root:# Valid (Epoch 78): Loss/seq after 00150 batches: 1102.9674072265625
INFO:root:# Valid (Epoch 78): Loss/seq after 00200 batches: 989.2282104492188
INFO:root:Artifacts: Make stick videos for epoch 78
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_78_on_20220423_030044.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_78_index_1739_on_20220423_030044.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 79): Loss/seq after 00000 batchs: 2450.195068359375
INFO:root:Train (Epoch 79): Loss/seq after 00050 batchs: 1556.1036376953125
INFO:root:Train (Epoch 79): Loss/seq after 00100 batchs: 1428.58642578125
INFO:root:Train (Epoch 79): Loss/seq after 00150 batchs: 1248.931396484375
INFO:root:Train (Epoch 79): Loss/seq after 00200 batchs: 1373.73193359375
INFO:root:Train (Epoch 79): Loss/seq after 00250 batchs: 1482.6561279296875
INFO:root:Train (Epoch 79): Loss/seq after 00300 batchs: 1414.5765380859375
INFO:root:Train (Epoch 79): Loss/seq after 00350 batchs: 1321.208740234375
INFO:root:Train (Epoch 79): Loss/seq after 00400 batchs: 1360.794189453125
INFO:root:Train (Epoch 79): Loss/seq after 00450 batchs: 1305.489013671875
INFO:root:Train (Epoch 79): Loss/seq after 00500 batchs: 1293.8343505859375
INFO:root:Train (Epoch 79): Loss/seq after 00550 batchs: 1241.6812744140625
INFO:root:Train (Epoch 79): Loss/seq after 00600 batchs: 1209.418701171875
INFO:root:Train (Epoch 79): Loss/seq after 00650 batchs: 1284.1864013671875
INFO:root:Train (Epoch 79): Loss/seq after 00700 batchs: 1380.88330078125
INFO:root:Train (Epoch 79): Loss/seq after 00750 batchs: 1419.732666015625
INFO:root:Train (Epoch 79): Loss/seq after 00800 batchs: 1393.4093017578125
INFO:root:Train (Epoch 79): Loss/seq after 00850 batchs: 1355.5753173828125
INFO:root:Train (Epoch 79): Loss/seq after 00900 batchs: 1353.6759033203125
INFO:root:Train (Epoch 79): Loss/seq after 00950 batchs: 1438.1395263671875
INFO:root:Train (Epoch 79): Loss/seq after 01000 batchs: 1436.193115234375
INFO:root:Train (Epoch 79): Loss/seq after 01050 batchs: 1404.6494140625
INFO:root:Train (Epoch 79): Loss/seq after 01100 batchs: 1390.9354248046875
INFO:root:Train (Epoch 79): Loss/seq after 01150 batchs: 1370.5450439453125
INFO:root:Train (Epoch 79): Loss/seq after 01200 batchs: 1354.1376953125
INFO:root:Train (Epoch 79): Loss/seq after 01250 batchs: 1343.888427734375
INFO:root:Train (Epoch 79): Loss/seq after 01300 batchs: 1361.1400146484375
INFO:root:Train (Epoch 79): Loss/seq after 01350 batchs: 1367.0904541015625
INFO:root:Train (Epoch 79): Loss/seq after 01400 batchs: 1414.9840087890625
INFO:root:Train (Epoch 79): Loss/seq after 01450 batchs: 1398.9757080078125
INFO:root:Train (Epoch 79): Loss/seq after 01500 batchs: 1386.2086181640625
INFO:root:Train (Epoch 79): Loss/seq after 01550 batchs: 1378.386962890625
INFO:root:Train (Epoch 79): Loss/seq after 01600 batchs: 1358.193115234375
INFO:root:Train (Epoch 79): Loss/seq after 01650 batchs: 1341.3765869140625
INFO:root:Train (Epoch 79): Loss/seq after 01700 batchs: 1329.41259765625
INFO:root:Train (Epoch 79): Loss/seq after 01750 batchs: 1315.801025390625
INFO:root:Train (Epoch 79): Loss/seq after 01800 batchs: 1299.626953125
INFO:root:Train (Epoch 79): Loss/seq after 01850 batchs: 1283.625244140625
INFO:root:Train (Epoch 79): Loss/seq after 01900 batchs: 1276.089599609375
INFO:root:Train (Epoch 79): Loss/seq after 01950 batchs: 1265.659423828125
INFO:root:Train (Epoch 79): Loss/seq after 02000 batchs: 1255.09130859375
INFO:root:Train (Epoch 79): Loss/seq after 02050 batchs: 1244.2939453125
INFO:root:Train (Epoch 79): Loss/seq after 02100 batchs: 1231.6292724609375
INFO:root:Train (Epoch 79): Loss/seq after 02150 batchs: 1219.5758056640625
INFO:root:Train (Epoch 79): Loss/seq after 02200 batchs: 1207.5740966796875
INFO:root:Train (Epoch 79): Loss/seq after 02250 batchs: 1206.1773681640625
INFO:root:Train (Epoch 79): Loss/seq after 02300 batchs: 1207.8857421875
INFO:root:Train (Epoch 79): Loss/seq after 02350 batchs: 1196.738037109375
INFO:root:Train (Epoch 79): Loss/seq after 02400 batchs: 1191.3280029296875
INFO:root:Train (Epoch 79): Loss/seq after 02450 batchs: 1178.3555908203125
INFO:root:Train (Epoch 79): Loss/seq after 02500 batchs: 1161.865234375
INFO:root:Train (Epoch 79): Loss/seq after 02550 batchs: 1149.6964111328125
INFO:root:Train (Epoch 79): Loss/seq after 02600 batchs: 1146.9337158203125
INFO:root:Train (Epoch 79): Loss/seq after 02650 batchs: 1141.76416015625
INFO:root:Train (Epoch 79): Loss/seq after 02700 batchs: 1137.17431640625
INFO:root:Train (Epoch 79): Loss/seq after 02750 batchs: 1154.122314453125
INFO:root:Train (Epoch 79): Loss/seq after 02800 batchs: 1158.18701171875
INFO:root:Train (Epoch 79): Loss/seq after 02850 batchs: 1153.066650390625
INFO:root:Train (Epoch 79): Loss/seq after 02900 batchs: 1150.655029296875
INFO:root:Train (Epoch 79): Loss/seq after 02950 batchs: 1142.1778564453125
INFO:root:Train (Epoch 79): Loss/seq after 03000 batchs: 1140.85302734375
INFO:root:Train (Epoch 79): Loss/seq after 03050 batchs: 1144.0830078125
INFO:root:Train (Epoch 79): Loss/seq after 03100 batchs: 1153.266845703125
INFO:root:Train (Epoch 79): Loss/seq after 03150 batchs: 1169.4744873046875
INFO:root:Train (Epoch 79): Loss/seq after 03200 batchs: 1184.5067138671875
INFO:root:Train (Epoch 79): Loss/seq after 03250 batchs: 1198.96435546875
INFO:root:Train (Epoch 79): Loss/seq after 03300 batchs: 1196.1016845703125
INFO:root:Train (Epoch 79): Loss/seq after 03350 batchs: 1194.6966552734375
INFO:root:Train (Epoch 79): Loss/seq after 03400 batchs: 1186.408935546875
INFO:root:Train (Epoch 79): Loss/seq after 03450 batchs: 1178.320556640625
INFO:root:Train (Epoch 79): Loss/seq after 03500 batchs: 1175.8658447265625
INFO:root:Train (Epoch 79): Loss/seq after 03550 batchs: 1167.6357421875
INFO:root:Train (Epoch 79): Loss/seq after 03600 batchs: 1172.337646484375
INFO:root:Train (Epoch 79): Loss/seq after 03650 batchs: 1165.60498046875
INFO:root:Train (Epoch 79): Loss/seq after 03700 batchs: 1164.050537109375
INFO:root:Train (Epoch 79): Loss/seq after 03750 batchs: 1164.2760009765625
INFO:root:Train (Epoch 79): Loss/seq after 03800 batchs: 1157.58203125
INFO:root:Train (Epoch 79): Loss/seq after 03850 batchs: 1153.0750732421875
INFO:root:Train (Epoch 79): Loss/seq after 03900 batchs: 1158.8067626953125
INFO:root:Train (Epoch 79): Loss/seq after 03950 batchs: 1166.343505859375
INFO:root:Train (Epoch 79): Loss/seq after 04000 batchs: 1157.953857421875
INFO:root:Train (Epoch 79): Loss/seq after 04050 batchs: 1150.4906005859375
INFO:root:Train (Epoch 79): Loss/seq after 04100 batchs: 1143.7237548828125
INFO:root:Train (Epoch 79): Loss/seq after 04150 batchs: 1138.280517578125
INFO:root:Train (Epoch 79): Loss/seq after 04200 batchs: 1131.91650390625
INFO:root:Train (Epoch 79): Loss/seq after 04250 batchs: 1127.5810546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 79): Loss/seq after 00000 batches: 867.0315551757812
INFO:root:# Valid (Epoch 79): Loss/seq after 00050 batches: 1090.88330078125
INFO:root:# Valid (Epoch 79): Loss/seq after 00100 batches: 1369.742919921875
INFO:root:# Valid (Epoch 79): Loss/seq after 00150 batches: 1088.1439208984375
INFO:root:# Valid (Epoch 79): Loss/seq after 00200 batches: 975.1004638671875
INFO:root:Artifacts: Make stick videos for epoch 79
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_79_on_20220423_030545.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_79_index_1094_on_20220423_030545.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 80): Loss/seq after 00000 batchs: 2422.18359375
INFO:root:Train (Epoch 80): Loss/seq after 00050 batchs: 1507.5643310546875
INFO:root:Train (Epoch 80): Loss/seq after 00100 batchs: 1404.4290771484375
INFO:root:Train (Epoch 80): Loss/seq after 00150 batchs: 1235.2686767578125
INFO:root:Train (Epoch 80): Loss/seq after 00200 batchs: 1364.3154296875
INFO:root:Train (Epoch 80): Loss/seq after 00250 batchs: 1473.880859375
INFO:root:Train (Epoch 80): Loss/seq after 00300 batchs: 1407.2955322265625
INFO:root:Train (Epoch 80): Loss/seq after 00350 batchs: 1315.2215576171875
INFO:root:Train (Epoch 80): Loss/seq after 00400 batchs: 1354.79150390625
INFO:root:Train (Epoch 80): Loss/seq after 00450 batchs: 1300.0562744140625
INFO:root:Train (Epoch 80): Loss/seq after 00500 batchs: 1288.6771240234375
INFO:root:Train (Epoch 80): Loss/seq after 00550 batchs: 1236.481201171875
INFO:root:Train (Epoch 80): Loss/seq after 00600 batchs: 1205.519775390625
INFO:root:Train (Epoch 80): Loss/seq after 00650 batchs: 1280.1204833984375
INFO:root:Train (Epoch 80): Loss/seq after 00700 batchs: 1377.357421875
INFO:root:Train (Epoch 80): Loss/seq after 00750 batchs: 1415.5657958984375
INFO:root:Train (Epoch 80): Loss/seq after 00800 batchs: 1389.1983642578125
INFO:root:Train (Epoch 80): Loss/seq after 00850 batchs: 1351.521240234375
INFO:root:Train (Epoch 80): Loss/seq after 00900 batchs: 1350.1329345703125
INFO:root:Train (Epoch 80): Loss/seq after 00950 batchs: 1433.84619140625
INFO:root:Train (Epoch 80): Loss/seq after 01000 batchs: 1432.7957763671875
INFO:root:Train (Epoch 80): Loss/seq after 01050 batchs: 1401.902099609375
INFO:root:Train (Epoch 80): Loss/seq after 01100 batchs: 1388.8673095703125
INFO:root:Train (Epoch 80): Loss/seq after 01150 batchs: 1368.5614013671875
INFO:root:Train (Epoch 80): Loss/seq after 01200 batchs: 1352.6251220703125
INFO:root:Train (Epoch 80): Loss/seq after 01250 batchs: 1342.677978515625
INFO:root:Train (Epoch 80): Loss/seq after 01300 batchs: 1359.841796875
INFO:root:Train (Epoch 80): Loss/seq after 01350 batchs: 1365.7664794921875
INFO:root:Train (Epoch 80): Loss/seq after 01400 batchs: 1413.8778076171875
INFO:root:Train (Epoch 80): Loss/seq after 01450 batchs: 1398.1536865234375
INFO:root:Train (Epoch 80): Loss/seq after 01500 batchs: 1385.2265625
INFO:root:Train (Epoch 80): Loss/seq after 01550 batchs: 1377.8095703125
INFO:root:Train (Epoch 80): Loss/seq after 01600 batchs: 1357.7423095703125
INFO:root:Train (Epoch 80): Loss/seq after 01650 batchs: 1340.6739501953125
INFO:root:Train (Epoch 80): Loss/seq after 01700 batchs: 1328.881591796875
INFO:root:Train (Epoch 80): Loss/seq after 01750 batchs: 1315.089599609375
INFO:root:Train (Epoch 80): Loss/seq after 01800 batchs: 1298.9371337890625
INFO:root:Train (Epoch 80): Loss/seq after 01850 batchs: 1282.3310546875
INFO:root:Train (Epoch 80): Loss/seq after 01900 batchs: 1274.715576171875
INFO:root:Train (Epoch 80): Loss/seq after 01950 batchs: 1263.6798095703125
INFO:root:Train (Epoch 80): Loss/seq after 02000 batchs: 1253.0579833984375
INFO:root:Train (Epoch 80): Loss/seq after 02050 batchs: 1242.3397216796875
INFO:root:Train (Epoch 80): Loss/seq after 02100 batchs: 1229.646240234375
INFO:root:Train (Epoch 80): Loss/seq after 02150 batchs: 1217.630126953125
INFO:root:Train (Epoch 80): Loss/seq after 02200 batchs: 1205.6187744140625
INFO:root:Train (Epoch 80): Loss/seq after 02250 batchs: 1202.41552734375
INFO:root:Train (Epoch 80): Loss/seq after 02300 batchs: 1203.8797607421875
INFO:root:Train (Epoch 80): Loss/seq after 02350 batchs: 1191.9078369140625
INFO:root:Train (Epoch 80): Loss/seq after 02400 batchs: 1186.5345458984375
INFO:root:Train (Epoch 80): Loss/seq after 02450 batchs: 1173.589111328125
INFO:root:Train (Epoch 80): Loss/seq after 02500 batchs: 1157.1982421875
INFO:root:Train (Epoch 80): Loss/seq after 02550 batchs: 1144.955322265625
INFO:root:Train (Epoch 80): Loss/seq after 02600 batchs: 1142.2193603515625
INFO:root:Train (Epoch 80): Loss/seq after 02650 batchs: 1137.132568359375
INFO:root:Train (Epoch 80): Loss/seq after 02700 batchs: 1132.43017578125
INFO:root:Train (Epoch 80): Loss/seq after 02750 batchs: 1148.6053466796875
INFO:root:Train (Epoch 80): Loss/seq after 02800 batchs: 1152.1961669921875
INFO:root:Train (Epoch 80): Loss/seq after 02850 batchs: 1146.9306640625
INFO:root:Train (Epoch 80): Loss/seq after 02900 batchs: 1144.49365234375
INFO:root:Train (Epoch 80): Loss/seq after 02950 batchs: 1135.98583984375
INFO:root:Train (Epoch 80): Loss/seq after 03000 batchs: 1134.686279296875
INFO:root:Train (Epoch 80): Loss/seq after 03050 batchs: 1137.8817138671875
INFO:root:Train (Epoch 80): Loss/seq after 03100 batchs: 1147.157958984375
INFO:root:Train (Epoch 80): Loss/seq after 03150 batchs: 1163.733642578125
INFO:root:Train (Epoch 80): Loss/seq after 03200 batchs: 1178.8466796875
INFO:root:Train (Epoch 80): Loss/seq after 03250 batchs: 1193.337158203125
INFO:root:Train (Epoch 80): Loss/seq after 03300 batchs: 1190.996337890625
INFO:root:Train (Epoch 80): Loss/seq after 03350 batchs: 1189.83642578125
INFO:root:Train (Epoch 80): Loss/seq after 03400 batchs: 1181.6279296875
INFO:root:Train (Epoch 80): Loss/seq after 03450 batchs: 1173.5750732421875
INFO:root:Train (Epoch 80): Loss/seq after 03500 batchs: 1171.08984375
INFO:root:Train (Epoch 80): Loss/seq after 03550 batchs: 1163.04736328125
INFO:root:Train (Epoch 80): Loss/seq after 03600 batchs: 1167.86572265625
INFO:root:Train (Epoch 80): Loss/seq after 03650 batchs: 1161.85986328125
INFO:root:Train (Epoch 80): Loss/seq after 03700 batchs: 1160.6455078125
INFO:root:Train (Epoch 80): Loss/seq after 03750 batchs: 1160.9949951171875
INFO:root:Train (Epoch 80): Loss/seq after 03800 batchs: 1154.4537353515625
INFO:root:Train (Epoch 80): Loss/seq after 03850 batchs: 1150.130859375
INFO:root:Train (Epoch 80): Loss/seq after 03900 batchs: 1156.037353515625
INFO:root:Train (Epoch 80): Loss/seq after 03950 batchs: 1164.101318359375
INFO:root:Train (Epoch 80): Loss/seq after 04000 batchs: 1155.7445068359375
INFO:root:Train (Epoch 80): Loss/seq after 04050 batchs: 1148.325439453125
INFO:root:Train (Epoch 80): Loss/seq after 04100 batchs: 1141.6058349609375
INFO:root:Train (Epoch 80): Loss/seq after 04150 batchs: 1136.2738037109375
INFO:root:Train (Epoch 80): Loss/seq after 04200 batchs: 1130.1083984375
INFO:root:Train (Epoch 80): Loss/seq after 04250 batchs: 1125.7232666015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 80): Loss/seq after 00000 batches: 874.1207275390625
INFO:root:# Valid (Epoch 80): Loss/seq after 00050 batches: 1092.40478515625
INFO:root:# Valid (Epoch 80): Loss/seq after 00100 batches: 1377.9415283203125
INFO:root:# Valid (Epoch 80): Loss/seq after 00150 batches: 1093.248779296875
INFO:root:# Valid (Epoch 80): Loss/seq after 00200 batches: 979.4285888671875
INFO:root:Artifacts: Make stick videos for epoch 80
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_80_on_20220423_031038.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_80_index_26_on_20220423_031038.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 81): Loss/seq after 00000 batchs: 2411.818115234375
INFO:root:Train (Epoch 81): Loss/seq after 00050 batchs: 1550.3328857421875
INFO:root:Train (Epoch 81): Loss/seq after 00100 batchs: 1433.7276611328125
INFO:root:Train (Epoch 81): Loss/seq after 00150 batchs: 1248.8984375
INFO:root:Train (Epoch 81): Loss/seq after 00200 batchs: 1376.6461181640625
INFO:root:Train (Epoch 81): Loss/seq after 00250 batchs: 1487.503662109375
INFO:root:Train (Epoch 81): Loss/seq after 00300 batchs: 1418.3851318359375
INFO:root:Train (Epoch 81): Loss/seq after 00350 batchs: 1323.965087890625
INFO:root:Train (Epoch 81): Loss/seq after 00400 batchs: 1362.4119873046875
INFO:root:Train (Epoch 81): Loss/seq after 00450 batchs: 1306.536865234375
INFO:root:Train (Epoch 81): Loss/seq after 00500 batchs: 1294.0859375
INFO:root:Train (Epoch 81): Loss/seq after 00550 batchs: 1241.3739013671875
INFO:root:Train (Epoch 81): Loss/seq after 00600 batchs: 1210.0888671875
INFO:root:Train (Epoch 81): Loss/seq after 00650 batchs: 1284.802001953125
INFO:root:Train (Epoch 81): Loss/seq after 00700 batchs: 1381.8980712890625
INFO:root:Train (Epoch 81): Loss/seq after 00750 batchs: 1420.19384765625
INFO:root:Train (Epoch 81): Loss/seq after 00800 batchs: 1392.8248291015625
INFO:root:Train (Epoch 81): Loss/seq after 00850 batchs: 1354.5140380859375
INFO:root:Train (Epoch 81): Loss/seq after 00900 batchs: 1352.12939453125
INFO:root:Train (Epoch 81): Loss/seq after 00950 batchs: 1435.6478271484375
INFO:root:Train (Epoch 81): Loss/seq after 01000 batchs: 1433.5489501953125
INFO:root:Train (Epoch 81): Loss/seq after 01050 batchs: 1404.7552490234375
INFO:root:Train (Epoch 81): Loss/seq after 01100 batchs: 1391.4178466796875
INFO:root:Train (Epoch 81): Loss/seq after 01150 batchs: 1370.8778076171875
INFO:root:Train (Epoch 81): Loss/seq after 01200 batchs: 1354.219970703125
INFO:root:Train (Epoch 81): Loss/seq after 01250 batchs: 1344.3984375
INFO:root:Train (Epoch 81): Loss/seq after 01300 batchs: 1361.438720703125
INFO:root:Train (Epoch 81): Loss/seq after 01350 batchs: 1367.374755859375
INFO:root:Train (Epoch 81): Loss/seq after 01400 batchs: 1415.3330078125
INFO:root:Train (Epoch 81): Loss/seq after 01450 batchs: 1399.3695068359375
INFO:root:Train (Epoch 81): Loss/seq after 01500 batchs: 1386.4554443359375
INFO:root:Train (Epoch 81): Loss/seq after 01550 batchs: 1378.7308349609375
INFO:root:Train (Epoch 81): Loss/seq after 01600 batchs: 1358.4801025390625
INFO:root:Train (Epoch 81): Loss/seq after 01650 batchs: 1341.068359375
INFO:root:Train (Epoch 81): Loss/seq after 01700 batchs: 1329.1724853515625
INFO:root:Train (Epoch 81): Loss/seq after 01750 batchs: 1315.321044921875
INFO:root:Train (Epoch 81): Loss/seq after 01800 batchs: 1299.0771484375
INFO:root:Train (Epoch 81): Loss/seq after 01850 batchs: 1282.4541015625
INFO:root:Train (Epoch 81): Loss/seq after 01900 batchs: 1274.5870361328125
INFO:root:Train (Epoch 81): Loss/seq after 01950 batchs: 1263.08740234375
INFO:root:Train (Epoch 81): Loss/seq after 02000 batchs: 1252.3975830078125
INFO:root:Train (Epoch 81): Loss/seq after 02050 batchs: 1241.4871826171875
INFO:root:Train (Epoch 81): Loss/seq after 02100 batchs: 1228.71484375
INFO:root:Train (Epoch 81): Loss/seq after 02150 batchs: 1216.654541015625
INFO:root:Train (Epoch 81): Loss/seq after 02200 batchs: 1204.72705078125
INFO:root:Train (Epoch 81): Loss/seq after 02250 batchs: 1201.8907470703125
INFO:root:Train (Epoch 81): Loss/seq after 02300 batchs: 1203.4876708984375
INFO:root:Train (Epoch 81): Loss/seq after 02350 batchs: 1192.445556640625
INFO:root:Train (Epoch 81): Loss/seq after 02400 batchs: 1187.13818359375
INFO:root:Train (Epoch 81): Loss/seq after 02450 batchs: 1174.1844482421875
INFO:root:Train (Epoch 81): Loss/seq after 02500 batchs: 1157.77734375
INFO:root:Train (Epoch 81): Loss/seq after 02550 batchs: 1145.653564453125
INFO:root:Train (Epoch 81): Loss/seq after 02600 batchs: 1142.971923828125
INFO:root:Train (Epoch 81): Loss/seq after 02650 batchs: 1137.8553466796875
INFO:root:Train (Epoch 81): Loss/seq after 02700 batchs: 1133.2724609375
INFO:root:Train (Epoch 81): Loss/seq after 02750 batchs: 1152.473876953125
INFO:root:Train (Epoch 81): Loss/seq after 02800 batchs: 1156.227294921875
INFO:root:Train (Epoch 81): Loss/seq after 02850 batchs: 1150.8411865234375
INFO:root:Train (Epoch 81): Loss/seq after 02900 batchs: 1148.531494140625
INFO:root:Train (Epoch 81): Loss/seq after 02950 batchs: 1140.05517578125
INFO:root:Train (Epoch 81): Loss/seq after 03000 batchs: 1138.6944580078125
INFO:root:Train (Epoch 81): Loss/seq after 03050 batchs: 1141.6749267578125
INFO:root:Train (Epoch 81): Loss/seq after 03100 batchs: 1150.703369140625
INFO:root:Train (Epoch 81): Loss/seq after 03150 batchs: 1166.916259765625
INFO:root:Train (Epoch 81): Loss/seq after 03200 batchs: 1181.9249267578125
INFO:root:Train (Epoch 81): Loss/seq after 03250 batchs: 1196.1419677734375
INFO:root:Train (Epoch 81): Loss/seq after 03300 batchs: 1193.13232421875
INFO:root:Train (Epoch 81): Loss/seq after 03350 batchs: 1191.643798828125
INFO:root:Train (Epoch 81): Loss/seq after 03400 batchs: 1183.40478515625
INFO:root:Train (Epoch 81): Loss/seq after 03450 batchs: 1175.20361328125
INFO:root:Train (Epoch 81): Loss/seq after 03500 batchs: 1172.29736328125
INFO:root:Train (Epoch 81): Loss/seq after 03550 batchs: 1164.1055908203125
INFO:root:Train (Epoch 81): Loss/seq after 03600 batchs: 1168.4716796875
INFO:root:Train (Epoch 81): Loss/seq after 03650 batchs: 1161.986083984375
INFO:root:Train (Epoch 81): Loss/seq after 03700 batchs: 1160.43505859375
INFO:root:Train (Epoch 81): Loss/seq after 03750 batchs: 1160.7049560546875
INFO:root:Train (Epoch 81): Loss/seq after 03800 batchs: 1154.0931396484375
INFO:root:Train (Epoch 81): Loss/seq after 03850 batchs: 1149.6046142578125
INFO:root:Train (Epoch 81): Loss/seq after 03900 batchs: 1155.40673828125
INFO:root:Train (Epoch 81): Loss/seq after 03950 batchs: 1162.9559326171875
INFO:root:Train (Epoch 81): Loss/seq after 04000 batchs: 1154.604248046875
INFO:root:Train (Epoch 81): Loss/seq after 04050 batchs: 1147.1884765625
INFO:root:Train (Epoch 81): Loss/seq after 04100 batchs: 1140.4443359375
INFO:root:Train (Epoch 81): Loss/seq after 04150 batchs: 1135.085693359375
INFO:root:Train (Epoch 81): Loss/seq after 04200 batchs: 1128.826416015625
INFO:root:Train (Epoch 81): Loss/seq after 04250 batchs: 1124.3983154296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 81): Loss/seq after 00000 batches: 873.7212524414062
INFO:root:# Valid (Epoch 81): Loss/seq after 00050 batches: 1089.09423828125
INFO:root:# Valid (Epoch 81): Loss/seq after 00100 batches: 1369.2470703125
INFO:root:# Valid (Epoch 81): Loss/seq after 00150 batches: 1086.5322265625
INFO:root:# Valid (Epoch 81): Loss/seq after 00200 batches: 973.6432495117188
INFO:root:Artifacts: Make stick videos for epoch 81
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_81_on_20220423_031522.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_81_index_1407_on_20220423_031522.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 82): Loss/seq after 00000 batchs: 2410.194091796875
INFO:root:Train (Epoch 82): Loss/seq after 00050 batchs: 1529.9769287109375
INFO:root:Train (Epoch 82): Loss/seq after 00100 batchs: 1419.5465087890625
INFO:root:Train (Epoch 82): Loss/seq after 00150 batchs: 1237.9473876953125
INFO:root:Train (Epoch 82): Loss/seq after 00200 batchs: 1370.02734375
INFO:root:Train (Epoch 82): Loss/seq after 00250 batchs: 1480.3018798828125
INFO:root:Train (Epoch 82): Loss/seq after 00300 batchs: 1412.66064453125
INFO:root:Train (Epoch 82): Loss/seq after 00350 batchs: 1320.0601806640625
INFO:root:Train (Epoch 82): Loss/seq after 00400 batchs: 1361.3275146484375
INFO:root:Train (Epoch 82): Loss/seq after 00450 batchs: 1306.498046875
INFO:root:Train (Epoch 82): Loss/seq after 00500 batchs: 1296.619384765625
INFO:root:Train (Epoch 82): Loss/seq after 00550 batchs: 1244.0111083984375
INFO:root:Train (Epoch 82): Loss/seq after 00600 batchs: 1211.22509765625
INFO:root:Train (Epoch 82): Loss/seq after 00650 batchs: 1285.72998046875
INFO:root:Train (Epoch 82): Loss/seq after 00700 batchs: 1382.4520263671875
INFO:root:Train (Epoch 82): Loss/seq after 00750 batchs: 1420.7286376953125
INFO:root:Train (Epoch 82): Loss/seq after 00800 batchs: 1394.0247802734375
INFO:root:Train (Epoch 82): Loss/seq after 00850 batchs: 1355.59716796875
INFO:root:Train (Epoch 82): Loss/seq after 00900 batchs: 1353.720947265625
INFO:root:Train (Epoch 82): Loss/seq after 00950 batchs: 1436.718017578125
INFO:root:Train (Epoch 82): Loss/seq after 01000 batchs: 1434.6190185546875
INFO:root:Train (Epoch 82): Loss/seq after 01050 batchs: 1404.803466796875
INFO:root:Train (Epoch 82): Loss/seq after 01100 batchs: 1390.649169921875
INFO:root:Train (Epoch 82): Loss/seq after 01150 batchs: 1370.20361328125
INFO:root:Train (Epoch 82): Loss/seq after 01200 batchs: 1354.0631103515625
INFO:root:Train (Epoch 82): Loss/seq after 01250 batchs: 1343.590087890625
INFO:root:Train (Epoch 82): Loss/seq after 01300 batchs: 1360.6793212890625
INFO:root:Train (Epoch 82): Loss/seq after 01350 batchs: 1366.5928955078125
INFO:root:Train (Epoch 82): Loss/seq after 01400 batchs: 1414.1107177734375
INFO:root:Train (Epoch 82): Loss/seq after 01450 batchs: 1398.225341796875
INFO:root:Train (Epoch 82): Loss/seq after 01500 batchs: 1385.4256591796875
INFO:root:Train (Epoch 82): Loss/seq after 01550 batchs: 1377.7957763671875
INFO:root:Train (Epoch 82): Loss/seq after 01600 batchs: 1357.6962890625
INFO:root:Train (Epoch 82): Loss/seq after 01650 batchs: 1340.59619140625
INFO:root:Train (Epoch 82): Loss/seq after 01700 batchs: 1328.76123046875
INFO:root:Train (Epoch 82): Loss/seq after 01750 batchs: 1315.150390625
INFO:root:Train (Epoch 82): Loss/seq after 01800 batchs: 1299.1011962890625
INFO:root:Train (Epoch 82): Loss/seq after 01850 batchs: 1282.61474609375
INFO:root:Train (Epoch 82): Loss/seq after 01900 batchs: 1274.8355712890625
INFO:root:Train (Epoch 82): Loss/seq after 01950 batchs: 1263.6475830078125
INFO:root:Train (Epoch 82): Loss/seq after 02000 batchs: 1253.2581787109375
INFO:root:Train (Epoch 82): Loss/seq after 02050 batchs: 1242.46484375
INFO:root:Train (Epoch 82): Loss/seq after 02100 batchs: 1229.7890625
INFO:root:Train (Epoch 82): Loss/seq after 02150 batchs: 1217.785400390625
INFO:root:Train (Epoch 82): Loss/seq after 02200 batchs: 1205.75732421875
INFO:root:Train (Epoch 82): Loss/seq after 02250 batchs: 1203.093017578125
INFO:root:Train (Epoch 82): Loss/seq after 02300 batchs: 1204.6270751953125
INFO:root:Train (Epoch 82): Loss/seq after 02350 batchs: 1192.8807373046875
INFO:root:Train (Epoch 82): Loss/seq after 02400 batchs: 1187.3291015625
INFO:root:Train (Epoch 82): Loss/seq after 02450 batchs: 1174.36962890625
INFO:root:Train (Epoch 82): Loss/seq after 02500 batchs: 1157.96484375
INFO:root:Train (Epoch 82): Loss/seq after 02550 batchs: 1145.65673828125
INFO:root:Train (Epoch 82): Loss/seq after 02600 batchs: 1142.928955078125
INFO:root:Train (Epoch 82): Loss/seq after 02650 batchs: 1137.737548828125
INFO:root:Train (Epoch 82): Loss/seq after 02700 batchs: 1132.8756103515625
INFO:root:Train (Epoch 82): Loss/seq after 02750 batchs: 1149.666748046875
INFO:root:Train (Epoch 82): Loss/seq after 02800 batchs: 1154.507080078125
INFO:root:Train (Epoch 82): Loss/seq after 02850 batchs: 1148.85888671875
INFO:root:Train (Epoch 82): Loss/seq after 02900 batchs: 1146.219970703125
INFO:root:Train (Epoch 82): Loss/seq after 02950 batchs: 1137.6055908203125
INFO:root:Train (Epoch 82): Loss/seq after 03000 batchs: 1136.2669677734375
INFO:root:Train (Epoch 82): Loss/seq after 03050 batchs: 1139.3275146484375
INFO:root:Train (Epoch 82): Loss/seq after 03100 batchs: 1148.517333984375
INFO:root:Train (Epoch 82): Loss/seq after 03150 batchs: 1164.810546875
INFO:root:Train (Epoch 82): Loss/seq after 03200 batchs: 1179.9232177734375
INFO:root:Train (Epoch 82): Loss/seq after 03250 batchs: 1194.2933349609375
INFO:root:Train (Epoch 82): Loss/seq after 03300 batchs: 1191.3797607421875
INFO:root:Train (Epoch 82): Loss/seq after 03350 batchs: 1189.6993408203125
INFO:root:Train (Epoch 82): Loss/seq after 03400 batchs: 1181.49609375
INFO:root:Train (Epoch 82): Loss/seq after 03450 batchs: 1173.5494384765625
INFO:root:Train (Epoch 82): Loss/seq after 03500 batchs: 1170.511962890625
INFO:root:Train (Epoch 82): Loss/seq after 03550 batchs: 1162.4317626953125
INFO:root:Train (Epoch 82): Loss/seq after 03600 batchs: 1166.887939453125
INFO:root:Train (Epoch 82): Loss/seq after 03650 batchs: 1160.416259765625
INFO:root:Train (Epoch 82): Loss/seq after 03700 batchs: 1159.2203369140625
INFO:root:Train (Epoch 82): Loss/seq after 03750 batchs: 1159.5230712890625
INFO:root:Train (Epoch 82): Loss/seq after 03800 batchs: 1152.9117431640625
INFO:root:Train (Epoch 82): Loss/seq after 03850 batchs: 1148.4537353515625
INFO:root:Train (Epoch 82): Loss/seq after 03900 batchs: 1154.2423095703125
INFO:root:Train (Epoch 82): Loss/seq after 03950 batchs: 1161.7557373046875
INFO:root:Train (Epoch 82): Loss/seq after 04000 batchs: 1153.4244384765625
INFO:root:Train (Epoch 82): Loss/seq after 04050 batchs: 1146.0406494140625
INFO:root:Train (Epoch 82): Loss/seq after 04100 batchs: 1139.469482421875
INFO:root:Train (Epoch 82): Loss/seq after 04150 batchs: 1134.042724609375
INFO:root:Train (Epoch 82): Loss/seq after 04200 batchs: 1127.7147216796875
INFO:root:Train (Epoch 82): Loss/seq after 04250 batchs: 1123.2540283203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 82): Loss/seq after 00000 batches: 867.9092407226562
INFO:root:# Valid (Epoch 82): Loss/seq after 00050 batches: 1087.8365478515625
INFO:root:# Valid (Epoch 82): Loss/seq after 00100 batches: 1369.2154541015625
INFO:root:# Valid (Epoch 82): Loss/seq after 00150 batches: 1086.03173828125
INFO:root:# Valid (Epoch 82): Loss/seq after 00200 batches: 972.7809448242188
INFO:root:Artifacts: Make stick videos for epoch 82
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_82_on_20220423_032005.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_82_index_1554_on_20220423_032005.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 83): Loss/seq after 00000 batchs: 2430.9765625
INFO:root:Train (Epoch 83): Loss/seq after 00050 batchs: 1540.2496337890625
INFO:root:Train (Epoch 83): Loss/seq after 00100 batchs: 1443.4989013671875
INFO:root:Train (Epoch 83): Loss/seq after 00150 batchs: 1255.37548828125
INFO:root:Train (Epoch 83): Loss/seq after 00200 batchs: 1382.945068359375
INFO:root:Train (Epoch 83): Loss/seq after 00250 batchs: 1488.097412109375
INFO:root:Train (Epoch 83): Loss/seq after 00300 batchs: 1418.725830078125
INFO:root:Train (Epoch 83): Loss/seq after 00350 batchs: 1323.7371826171875
INFO:root:Train (Epoch 83): Loss/seq after 00400 batchs: 1361.130615234375
INFO:root:Train (Epoch 83): Loss/seq after 00450 batchs: 1305.4896240234375
INFO:root:Train (Epoch 83): Loss/seq after 00500 batchs: 1293.7305908203125
INFO:root:Train (Epoch 83): Loss/seq after 00550 batchs: 1240.6259765625
INFO:root:Train (Epoch 83): Loss/seq after 00600 batchs: 1209.0028076171875
INFO:root:Train (Epoch 83): Loss/seq after 00650 batchs: 1284.3970947265625
INFO:root:Train (Epoch 83): Loss/seq after 00700 batchs: 1381.2843017578125
INFO:root:Train (Epoch 83): Loss/seq after 00750 batchs: 1419.9405517578125
INFO:root:Train (Epoch 83): Loss/seq after 00800 batchs: 1392.4853515625
INFO:root:Train (Epoch 83): Loss/seq after 00850 batchs: 1353.892333984375
INFO:root:Train (Epoch 83): Loss/seq after 00900 batchs: 1351.361083984375
INFO:root:Train (Epoch 83): Loss/seq after 00950 batchs: 1434.631103515625
INFO:root:Train (Epoch 83): Loss/seq after 01000 batchs: 1432.4669189453125
INFO:root:Train (Epoch 83): Loss/seq after 01050 batchs: 1401.63525390625
INFO:root:Train (Epoch 83): Loss/seq after 01100 batchs: 1389.1986083984375
INFO:root:Train (Epoch 83): Loss/seq after 01150 batchs: 1368.73974609375
INFO:root:Train (Epoch 83): Loss/seq after 01200 batchs: 1352.406005859375
INFO:root:Train (Epoch 83): Loss/seq after 01250 batchs: 1341.63037109375
INFO:root:Train (Epoch 83): Loss/seq after 01300 batchs: 1358.6207275390625
INFO:root:Train (Epoch 83): Loss/seq after 01350 batchs: 1364.6466064453125
INFO:root:Train (Epoch 83): Loss/seq after 01400 batchs: 1412.1624755859375
INFO:root:Train (Epoch 83): Loss/seq after 01450 batchs: 1396.4954833984375
INFO:root:Train (Epoch 83): Loss/seq after 01500 batchs: 1383.6666259765625
INFO:root:Train (Epoch 83): Loss/seq after 01550 batchs: 1376.1646728515625
INFO:root:Train (Epoch 83): Loss/seq after 01600 batchs: 1356.4000244140625
INFO:root:Train (Epoch 83): Loss/seq after 01650 batchs: 1339.04931640625
INFO:root:Train (Epoch 83): Loss/seq after 01700 batchs: 1327.16015625
INFO:root:Train (Epoch 83): Loss/seq after 01750 batchs: 1313.3583984375
INFO:root:Train (Epoch 83): Loss/seq after 01800 batchs: 1297.1663818359375
INFO:root:Train (Epoch 83): Loss/seq after 01850 batchs: 1280.532958984375
INFO:root:Train (Epoch 83): Loss/seq after 01900 batchs: 1272.6951904296875
INFO:root:Train (Epoch 83): Loss/seq after 01950 batchs: 1260.9593505859375
INFO:root:Train (Epoch 83): Loss/seq after 02000 batchs: 1250.2095947265625
INFO:root:Train (Epoch 83): Loss/seq after 02050 batchs: 1239.2823486328125
INFO:root:Train (Epoch 83): Loss/seq after 02100 batchs: 1226.75048828125
INFO:root:Train (Epoch 83): Loss/seq after 02150 batchs: 1214.928466796875
INFO:root:Train (Epoch 83): Loss/seq after 02200 batchs: 1203.0714111328125
INFO:root:Train (Epoch 83): Loss/seq after 02250 batchs: 1199.919921875
INFO:root:Train (Epoch 83): Loss/seq after 02300 batchs: 1201.554443359375
INFO:root:Train (Epoch 83): Loss/seq after 02350 batchs: 1189.6602783203125
INFO:root:Train (Epoch 83): Loss/seq after 02400 batchs: 1184.19287109375
INFO:root:Train (Epoch 83): Loss/seq after 02450 batchs: 1171.273193359375
INFO:root:Train (Epoch 83): Loss/seq after 02500 batchs: 1154.9237060546875
INFO:root:Train (Epoch 83): Loss/seq after 02550 batchs: 1142.73779296875
INFO:root:Train (Epoch 83): Loss/seq after 02600 batchs: 1140.0806884765625
INFO:root:Train (Epoch 83): Loss/seq after 02650 batchs: 1134.973876953125
INFO:root:Train (Epoch 83): Loss/seq after 02700 batchs: 1130.1934814453125
INFO:root:Train (Epoch 83): Loss/seq after 02750 batchs: 1145.739013671875
INFO:root:Train (Epoch 83): Loss/seq after 02800 batchs: 1149.449951171875
INFO:root:Train (Epoch 83): Loss/seq after 02850 batchs: 1144.1104736328125
INFO:root:Train (Epoch 83): Loss/seq after 02900 batchs: 1141.8182373046875
INFO:root:Train (Epoch 83): Loss/seq after 02950 batchs: 1133.3690185546875
INFO:root:Train (Epoch 83): Loss/seq after 03000 batchs: 1132.1046142578125
INFO:root:Train (Epoch 83): Loss/seq after 03050 batchs: 1135.3016357421875
INFO:root:Train (Epoch 83): Loss/seq after 03100 batchs: 1144.2972412109375
INFO:root:Train (Epoch 83): Loss/seq after 03150 batchs: 1160.8944091796875
INFO:root:Train (Epoch 83): Loss/seq after 03200 batchs: 1176.029541015625
INFO:root:Train (Epoch 83): Loss/seq after 03250 batchs: 1190.3624267578125
INFO:root:Train (Epoch 83): Loss/seq after 03300 batchs: 1187.34130859375
INFO:root:Train (Epoch 83): Loss/seq after 03350 batchs: 1185.6387939453125
INFO:root:Train (Epoch 83): Loss/seq after 03400 batchs: 1177.4815673828125
INFO:root:Train (Epoch 83): Loss/seq after 03450 batchs: 1169.3756103515625
INFO:root:Train (Epoch 83): Loss/seq after 03500 batchs: 1166.25927734375
INFO:root:Train (Epoch 83): Loss/seq after 03550 batchs: 1157.8740234375
INFO:root:Train (Epoch 83): Loss/seq after 03600 batchs: 1162.22802734375
INFO:root:Train (Epoch 83): Loss/seq after 03650 batchs: 1155.4622802734375
INFO:root:Train (Epoch 83): Loss/seq after 03700 batchs: 1153.96875
INFO:root:Train (Epoch 83): Loss/seq after 03750 batchs: 1154.3048095703125
INFO:root:Train (Epoch 83): Loss/seq after 03800 batchs: 1147.6859130859375
INFO:root:Train (Epoch 83): Loss/seq after 03850 batchs: 1143.2568359375
INFO:root:Train (Epoch 83): Loss/seq after 03900 batchs: 1149.3126220703125
INFO:root:Train (Epoch 83): Loss/seq after 03950 batchs: 1156.9803466796875
INFO:root:Train (Epoch 83): Loss/seq after 04000 batchs: 1148.695068359375
INFO:root:Train (Epoch 83): Loss/seq after 04050 batchs: 1141.326416015625
INFO:root:Train (Epoch 83): Loss/seq after 04100 batchs: 1134.622314453125
INFO:root:Train (Epoch 83): Loss/seq after 04150 batchs: 1129.2347412109375
INFO:root:Train (Epoch 83): Loss/seq after 04200 batchs: 1123.043212890625
INFO:root:Train (Epoch 83): Loss/seq after 04250 batchs: 1118.676025390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 83): Loss/seq after 00000 batches: 879.6243896484375
INFO:root:# Valid (Epoch 83): Loss/seq after 00050 batches: 1123.2496337890625
INFO:root:# Valid (Epoch 83): Loss/seq after 00100 batches: 1411.1923828125
INFO:root:# Valid (Epoch 83): Loss/seq after 00150 batches: 1123.5108642578125
INFO:root:# Valid (Epoch 83): Loss/seq after 00200 batches: 1010.89208984375
INFO:root:Artifacts: Make stick videos for epoch 83
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_83_on_20220423_032451.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_83_index_152_on_20220423_032451.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 84): Loss/seq after 00000 batchs: 2436.45166015625
INFO:root:Train (Epoch 84): Loss/seq after 00050 batchs: 1518.6400146484375
INFO:root:Train (Epoch 84): Loss/seq after 00100 batchs: 1410.599609375
INFO:root:Train (Epoch 84): Loss/seq after 00150 batchs: 1239.5472412109375
INFO:root:Train (Epoch 84): Loss/seq after 00200 batchs: 1368.0074462890625
INFO:root:Train (Epoch 84): Loss/seq after 00250 batchs: 1471.9227294921875
INFO:root:Train (Epoch 84): Loss/seq after 00300 batchs: 1405.072021484375
INFO:root:Train (Epoch 84): Loss/seq after 00350 batchs: 1314.2764892578125
INFO:root:Train (Epoch 84): Loss/seq after 00400 batchs: 1355.3389892578125
INFO:root:Train (Epoch 84): Loss/seq after 00450 batchs: 1300.7203369140625
INFO:root:Train (Epoch 84): Loss/seq after 00500 batchs: 1293.8155517578125
INFO:root:Train (Epoch 84): Loss/seq after 00550 batchs: 1242.30859375
INFO:root:Train (Epoch 84): Loss/seq after 00600 batchs: 1211.5633544921875
INFO:root:Train (Epoch 84): Loss/seq after 00650 batchs: 1285.4432373046875
INFO:root:Train (Epoch 84): Loss/seq after 00700 batchs: 1382.2506103515625
INFO:root:Train (Epoch 84): Loss/seq after 00750 batchs: 1420.1978759765625
INFO:root:Train (Epoch 84): Loss/seq after 00800 batchs: 1395.3734130859375
INFO:root:Train (Epoch 84): Loss/seq after 00850 batchs: 1357.1495361328125
INFO:root:Train (Epoch 84): Loss/seq after 00900 batchs: 1354.89404296875
INFO:root:Train (Epoch 84): Loss/seq after 00950 batchs: 1438.052001953125
INFO:root:Train (Epoch 84): Loss/seq after 01000 batchs: 1436.6884765625
INFO:root:Train (Epoch 84): Loss/seq after 01050 batchs: 1404.6968994140625
INFO:root:Train (Epoch 84): Loss/seq after 01100 batchs: 1391.5797119140625
INFO:root:Train (Epoch 84): Loss/seq after 01150 batchs: 1371.1768798828125
INFO:root:Train (Epoch 84): Loss/seq after 01200 batchs: 1354.5511474609375
INFO:root:Train (Epoch 84): Loss/seq after 01250 batchs: 1344.181640625
INFO:root:Train (Epoch 84): Loss/seq after 01300 batchs: 1360.9383544921875
INFO:root:Train (Epoch 84): Loss/seq after 01350 batchs: 1366.870849609375
INFO:root:Train (Epoch 84): Loss/seq after 01400 batchs: 1414.47705078125
INFO:root:Train (Epoch 84): Loss/seq after 01450 batchs: 1398.3948974609375
INFO:root:Train (Epoch 84): Loss/seq after 01500 batchs: 1385.387939453125
INFO:root:Train (Epoch 84): Loss/seq after 01550 batchs: 1377.7490234375
INFO:root:Train (Epoch 84): Loss/seq after 01600 batchs: 1358.298095703125
INFO:root:Train (Epoch 84): Loss/seq after 01650 batchs: 1341.15185546875
INFO:root:Train (Epoch 84): Loss/seq after 01700 batchs: 1329.16259765625
INFO:root:Train (Epoch 84): Loss/seq after 01750 batchs: 1315.3717041015625
INFO:root:Train (Epoch 84): Loss/seq after 01800 batchs: 1299.1107177734375
INFO:root:Train (Epoch 84): Loss/seq after 01850 batchs: 1282.5811767578125
INFO:root:Train (Epoch 84): Loss/seq after 01900 batchs: 1274.7391357421875
INFO:root:Train (Epoch 84): Loss/seq after 01950 batchs: 1262.8626708984375
INFO:root:Train (Epoch 84): Loss/seq after 02000 batchs: 1252.068359375
INFO:root:Train (Epoch 84): Loss/seq after 02050 batchs: 1240.9921875
INFO:root:Train (Epoch 84): Loss/seq after 02100 batchs: 1228.3199462890625
INFO:root:Train (Epoch 84): Loss/seq after 02150 batchs: 1216.3580322265625
INFO:root:Train (Epoch 84): Loss/seq after 02200 batchs: 1204.397216796875
INFO:root:Train (Epoch 84): Loss/seq after 02250 batchs: 1201.8433837890625
INFO:root:Train (Epoch 84): Loss/seq after 02300 batchs: 1203.7186279296875
INFO:root:Train (Epoch 84): Loss/seq after 02350 batchs: 1192.4263916015625
INFO:root:Train (Epoch 84): Loss/seq after 02400 batchs: 1187.1959228515625
INFO:root:Train (Epoch 84): Loss/seq after 02450 batchs: 1174.2930908203125
INFO:root:Train (Epoch 84): Loss/seq after 02500 batchs: 1157.898193359375
INFO:root:Train (Epoch 84): Loss/seq after 02550 batchs: 1145.6617431640625
INFO:root:Train (Epoch 84): Loss/seq after 02600 batchs: 1142.916259765625
INFO:root:Train (Epoch 84): Loss/seq after 02650 batchs: 1137.6781005859375
INFO:root:Train (Epoch 84): Loss/seq after 02700 batchs: 1132.680419921875
INFO:root:Train (Epoch 84): Loss/seq after 02750 batchs: 1149.983154296875
INFO:root:Train (Epoch 84): Loss/seq after 02800 batchs: 1153.5545654296875
INFO:root:Train (Epoch 84): Loss/seq after 02850 batchs: 1147.873046875
INFO:root:Train (Epoch 84): Loss/seq after 02900 batchs: 1145.3922119140625
INFO:root:Train (Epoch 84): Loss/seq after 02950 batchs: 1136.920654296875
INFO:root:Train (Epoch 84): Loss/seq after 03000 batchs: 1135.5582275390625
INFO:root:Train (Epoch 84): Loss/seq after 03050 batchs: 1138.605712890625
INFO:root:Train (Epoch 84): Loss/seq after 03100 batchs: 1148.3428955078125
INFO:root:Train (Epoch 84): Loss/seq after 03150 batchs: 1164.53076171875
INFO:root:Train (Epoch 84): Loss/seq after 03200 batchs: 1179.5733642578125
INFO:root:Train (Epoch 84): Loss/seq after 03250 batchs: 1194.21240234375
INFO:root:Train (Epoch 84): Loss/seq after 03300 batchs: 1191.540283203125
INFO:root:Train (Epoch 84): Loss/seq after 03350 batchs: 1190.093994140625
INFO:root:Train (Epoch 84): Loss/seq after 03400 batchs: 1181.9605712890625
INFO:root:Train (Epoch 84): Loss/seq after 03450 batchs: 1174.19482421875
INFO:root:Train (Epoch 84): Loss/seq after 03500 batchs: 1171.4676513671875
INFO:root:Train (Epoch 84): Loss/seq after 03550 batchs: 1163.3548583984375
INFO:root:Train (Epoch 84): Loss/seq after 03600 batchs: 1167.85546875
INFO:root:Train (Epoch 84): Loss/seq after 03650 batchs: 1161.0400390625
INFO:root:Train (Epoch 84): Loss/seq after 03700 batchs: 1159.468994140625
INFO:root:Train (Epoch 84): Loss/seq after 03750 batchs: 1159.6993408203125
INFO:root:Train (Epoch 84): Loss/seq after 03800 batchs: 1153.05712890625
INFO:root:Train (Epoch 84): Loss/seq after 03850 batchs: 1148.5360107421875
INFO:root:Train (Epoch 84): Loss/seq after 03900 batchs: 1154.3968505859375
INFO:root:Train (Epoch 84): Loss/seq after 03950 batchs: 1162.158935546875
INFO:root:Train (Epoch 84): Loss/seq after 04000 batchs: 1153.8150634765625
INFO:root:Train (Epoch 84): Loss/seq after 04050 batchs: 1146.4224853515625
INFO:root:Train (Epoch 84): Loss/seq after 04100 batchs: 1139.80810546875
INFO:root:Train (Epoch 84): Loss/seq after 04150 batchs: 1134.4534912109375
INFO:root:Train (Epoch 84): Loss/seq after 04200 batchs: 1128.5869140625
INFO:root:Train (Epoch 84): Loss/seq after 04250 batchs: 1124.2542724609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 84): Loss/seq after 00000 batches: 870.737060546875
INFO:root:# Valid (Epoch 84): Loss/seq after 00050 batches: 1089.570068359375
INFO:root:# Valid (Epoch 84): Loss/seq after 00100 batches: 1377.9486083984375
INFO:root:# Valid (Epoch 84): Loss/seq after 00150 batches: 1097.6273193359375
INFO:root:# Valid (Epoch 84): Loss/seq after 00200 batches: 983.0892333984375
INFO:root:Artifacts: Make stick videos for epoch 84
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_84_on_20220423_032942.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_84_index_1338_on_20220423_032942.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 85): Loss/seq after 00000 batchs: 2426.406005859375
INFO:root:Train (Epoch 85): Loss/seq after 00050 batchs: 1507.84716796875
INFO:root:Train (Epoch 85): Loss/seq after 00100 batchs: 1419.926025390625
INFO:root:Train (Epoch 85): Loss/seq after 00150 batchs: 1239.3892822265625
INFO:root:Train (Epoch 85): Loss/seq after 00200 batchs: 1368.24365234375
INFO:root:Train (Epoch 85): Loss/seq after 00250 batchs: 1476.97998046875
INFO:root:Train (Epoch 85): Loss/seq after 00300 batchs: 1409.2061767578125
INFO:root:Train (Epoch 85): Loss/seq after 00350 batchs: 1315.75048828125
INFO:root:Train (Epoch 85): Loss/seq after 00400 batchs: 1355.0264892578125
INFO:root:Train (Epoch 85): Loss/seq after 00450 batchs: 1299.9610595703125
INFO:root:Train (Epoch 85): Loss/seq after 00500 batchs: 1288.105712890625
INFO:root:Train (Epoch 85): Loss/seq after 00550 batchs: 1235.277099609375
INFO:root:Train (Epoch 85): Loss/seq after 00600 batchs: 1203.6903076171875
INFO:root:Train (Epoch 85): Loss/seq after 00650 batchs: 1277.0068359375
INFO:root:Train (Epoch 85): Loss/seq after 00700 batchs: 1370.286865234375
INFO:root:Train (Epoch 85): Loss/seq after 00750 batchs: 1411.933349609375
INFO:root:Train (Epoch 85): Loss/seq after 00800 batchs: 1385.75341796875
INFO:root:Train (Epoch 85): Loss/seq after 00850 batchs: 1347.851318359375
INFO:root:Train (Epoch 85): Loss/seq after 00900 batchs: 1347.82763671875
INFO:root:Train (Epoch 85): Loss/seq after 00950 batchs: 1427.261474609375
INFO:root:Train (Epoch 85): Loss/seq after 01000 batchs: 1427.005126953125
INFO:root:Train (Epoch 85): Loss/seq after 01050 batchs: 1395.9498291015625
INFO:root:Train (Epoch 85): Loss/seq after 01100 batchs: 1383.4656982421875
INFO:root:Train (Epoch 85): Loss/seq after 01150 batchs: 1363.5726318359375
INFO:root:Train (Epoch 85): Loss/seq after 01200 batchs: 1347.053466796875
INFO:root:Train (Epoch 85): Loss/seq after 01250 batchs: 1336.511962890625
INFO:root:Train (Epoch 85): Loss/seq after 01300 batchs: 1354.2896728515625
INFO:root:Train (Epoch 85): Loss/seq after 01350 batchs: 1360.220947265625
INFO:root:Train (Epoch 85): Loss/seq after 01400 batchs: 1407.7933349609375
INFO:root:Train (Epoch 85): Loss/seq after 01450 batchs: 1391.726318359375
INFO:root:Train (Epoch 85): Loss/seq after 01500 batchs: 1378.939208984375
INFO:root:Train (Epoch 85): Loss/seq after 01550 batchs: 1371.1885986328125
INFO:root:Train (Epoch 85): Loss/seq after 01600 batchs: 1350.940673828125
INFO:root:Train (Epoch 85): Loss/seq after 01650 batchs: 1334.035400390625
INFO:root:Train (Epoch 85): Loss/seq after 01700 batchs: 1322.3367919921875
INFO:root:Train (Epoch 85): Loss/seq after 01750 batchs: 1308.7208251953125
INFO:root:Train (Epoch 85): Loss/seq after 01800 batchs: 1292.5174560546875
INFO:root:Train (Epoch 85): Loss/seq after 01850 batchs: 1276.14404296875
INFO:root:Train (Epoch 85): Loss/seq after 01900 batchs: 1268.298095703125
INFO:root:Train (Epoch 85): Loss/seq after 01950 batchs: 1256.6575927734375
INFO:root:Train (Epoch 85): Loss/seq after 02000 batchs: 1245.912353515625
INFO:root:Train (Epoch 85): Loss/seq after 02050 batchs: 1234.8975830078125
INFO:root:Train (Epoch 85): Loss/seq after 02100 batchs: 1222.2838134765625
INFO:root:Train (Epoch 85): Loss/seq after 02150 batchs: 1210.5640869140625
INFO:root:Train (Epoch 85): Loss/seq after 02200 batchs: 1198.7099609375
INFO:root:Train (Epoch 85): Loss/seq after 02250 batchs: 1195.6727294921875
INFO:root:Train (Epoch 85): Loss/seq after 02300 batchs: 1197.70263671875
INFO:root:Train (Epoch 85): Loss/seq after 02350 batchs: 1185.767822265625
INFO:root:Train (Epoch 85): Loss/seq after 02400 batchs: 1180.3182373046875
INFO:root:Train (Epoch 85): Loss/seq after 02450 batchs: 1167.5106201171875
INFO:root:Train (Epoch 85): Loss/seq after 02500 batchs: 1151.2257080078125
INFO:root:Train (Epoch 85): Loss/seq after 02550 batchs: 1139.3472900390625
INFO:root:Train (Epoch 85): Loss/seq after 02600 batchs: 1136.654296875
INFO:root:Train (Epoch 85): Loss/seq after 02650 batchs: 1131.578125
INFO:root:Train (Epoch 85): Loss/seq after 02700 batchs: 1126.990234375
INFO:root:Train (Epoch 85): Loss/seq after 02750 batchs: 1146.5750732421875
INFO:root:Train (Epoch 85): Loss/seq after 02800 batchs: 1149.9561767578125
INFO:root:Train (Epoch 85): Loss/seq after 02850 batchs: 1144.4249267578125
INFO:root:Train (Epoch 85): Loss/seq after 02900 batchs: 1141.810546875
INFO:root:Train (Epoch 85): Loss/seq after 02950 batchs: 1133.4931640625
INFO:root:Train (Epoch 85): Loss/seq after 03000 batchs: 1132.10009765625
INFO:root:Train (Epoch 85): Loss/seq after 03050 batchs: 1135.1875
INFO:root:Train (Epoch 85): Loss/seq after 03100 batchs: 1144.121337890625
INFO:root:Train (Epoch 85): Loss/seq after 03150 batchs: 1157.0924072265625
INFO:root:Train (Epoch 85): Loss/seq after 03200 batchs: 1170.7174072265625
INFO:root:Train (Epoch 85): Loss/seq after 03250 batchs: 1182.9971923828125
INFO:root:Train (Epoch 85): Loss/seq after 03300 batchs: 1179.8704833984375
INFO:root:Train (Epoch 85): Loss/seq after 03350 batchs: 1178.33251953125
INFO:root:Train (Epoch 85): Loss/seq after 03400 batchs: 1170.3656005859375
INFO:root:Train (Epoch 85): Loss/seq after 03450 batchs: 1162.370849609375
INFO:root:Train (Epoch 85): Loss/seq after 03500 batchs: 1159.7806396484375
INFO:root:Train (Epoch 85): Loss/seq after 03550 batchs: 1152.027099609375
INFO:root:Train (Epoch 85): Loss/seq after 03600 batchs: 1156.8837890625
INFO:root:Train (Epoch 85): Loss/seq after 03650 batchs: 1150.09423828125
INFO:root:Train (Epoch 85): Loss/seq after 03700 batchs: 1148.6956787109375
INFO:root:Train (Epoch 85): Loss/seq after 03750 batchs: 1149.1258544921875
INFO:root:Train (Epoch 85): Loss/seq after 03800 batchs: 1142.5963134765625
INFO:root:Train (Epoch 85): Loss/seq after 03850 batchs: 1138.240234375
INFO:root:Train (Epoch 85): Loss/seq after 03900 batchs: 1143.40673828125
INFO:root:Train (Epoch 85): Loss/seq after 03950 batchs: 1151.7781982421875
INFO:root:Train (Epoch 85): Loss/seq after 04000 batchs: 1143.562255859375
INFO:root:Train (Epoch 85): Loss/seq after 04050 batchs: 1136.273681640625
INFO:root:Train (Epoch 85): Loss/seq after 04100 batchs: 1129.7542724609375
INFO:root:Train (Epoch 85): Loss/seq after 04150 batchs: 1124.4940185546875
INFO:root:Train (Epoch 85): Loss/seq after 04200 batchs: 1118.2301025390625
INFO:root:Train (Epoch 85): Loss/seq after 04250 batchs: 1113.74853515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 85): Loss/seq after 00000 batches: 874.9827270507812
INFO:root:# Valid (Epoch 85): Loss/seq after 00050 batches: 1089.8680419921875
INFO:root:# Valid (Epoch 85): Loss/seq after 00100 batches: 1373.2109375
INFO:root:# Valid (Epoch 85): Loss/seq after 00150 batches: 1088.9866943359375
INFO:root:# Valid (Epoch 85): Loss/seq after 00200 batches: 974.9458618164062
INFO:root:Artifacts: Make stick videos for epoch 85
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_85_on_20220423_033426.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_85_index_831_on_20220423_033426.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 86): Loss/seq after 00000 batchs: 2392.738037109375
INFO:root:Train (Epoch 86): Loss/seq after 00050 batchs: 1512.2899169921875
INFO:root:Train (Epoch 86): Loss/seq after 00100 batchs: 1407.6649169921875
INFO:root:Train (Epoch 86): Loss/seq after 00150 batchs: 1231.6334228515625
INFO:root:Train (Epoch 86): Loss/seq after 00200 batchs: 1363.5406494140625
INFO:root:Train (Epoch 86): Loss/seq after 00250 batchs: 1469.57568359375
INFO:root:Train (Epoch 86): Loss/seq after 00300 batchs: 1403.043212890625
INFO:root:Train (Epoch 86): Loss/seq after 00350 batchs: 1310.340576171875
INFO:root:Train (Epoch 86): Loss/seq after 00400 batchs: 1350.1767578125
INFO:root:Train (Epoch 86): Loss/seq after 00450 batchs: 1295.498779296875
INFO:root:Train (Epoch 86): Loss/seq after 00500 batchs: 1284.0157470703125
INFO:root:Train (Epoch 86): Loss/seq after 00550 batchs: 1231.9644775390625
INFO:root:Train (Epoch 86): Loss/seq after 00600 batchs: 1200.1405029296875
INFO:root:Train (Epoch 86): Loss/seq after 00650 batchs: 1271.9930419921875
INFO:root:Train (Epoch 86): Loss/seq after 00700 batchs: 1358.3695068359375
INFO:root:Train (Epoch 86): Loss/seq after 00750 batchs: 1400.8133544921875
INFO:root:Train (Epoch 86): Loss/seq after 00800 batchs: 1374.37744140625
INFO:root:Train (Epoch 86): Loss/seq after 00850 batchs: 1336.760498046875
INFO:root:Train (Epoch 86): Loss/seq after 00900 batchs: 1335.9202880859375
INFO:root:Train (Epoch 86): Loss/seq after 00950 batchs: 1410.43896484375
INFO:root:Train (Epoch 86): Loss/seq after 01000 batchs: 1407.8109130859375
INFO:root:Train (Epoch 86): Loss/seq after 01050 batchs: 1379.336181640625
INFO:root:Train (Epoch 86): Loss/seq after 01100 batchs: 1367.177734375
INFO:root:Train (Epoch 86): Loss/seq after 01150 batchs: 1347.6383056640625
INFO:root:Train (Epoch 86): Loss/seq after 01200 batchs: 1331.845947265625
INFO:root:Train (Epoch 86): Loss/seq after 01250 batchs: 1322.331787109375
INFO:root:Train (Epoch 86): Loss/seq after 01300 batchs: 1340.1832275390625
INFO:root:Train (Epoch 86): Loss/seq after 01350 batchs: 1346.820556640625
INFO:root:Train (Epoch 86): Loss/seq after 01400 batchs: 1389.73779296875
INFO:root:Train (Epoch 86): Loss/seq after 01450 batchs: 1374.111083984375
INFO:root:Train (Epoch 86): Loss/seq after 01500 batchs: 1361.855224609375
INFO:root:Train (Epoch 86): Loss/seq after 01550 batchs: 1354.7625732421875
INFO:root:Train (Epoch 86): Loss/seq after 01600 batchs: 1335.2296142578125
INFO:root:Train (Epoch 86): Loss/seq after 01650 batchs: 1318.246826171875
INFO:root:Train (Epoch 86): Loss/seq after 01700 batchs: 1307.1231689453125
INFO:root:Train (Epoch 86): Loss/seq after 01750 batchs: 1294.1402587890625
INFO:root:Train (Epoch 86): Loss/seq after 01800 batchs: 1278.5211181640625
INFO:root:Train (Epoch 86): Loss/seq after 01850 batchs: 1262.4937744140625
INFO:root:Train (Epoch 86): Loss/seq after 01900 batchs: 1255.2679443359375
INFO:root:Train (Epoch 86): Loss/seq after 01950 batchs: 1243.977294921875
INFO:root:Train (Epoch 86): Loss/seq after 02000 batchs: 1233.9263916015625
INFO:root:Train (Epoch 86): Loss/seq after 02050 batchs: 1223.5877685546875
INFO:root:Train (Epoch 86): Loss/seq after 02100 batchs: 1211.3013916015625
INFO:root:Train (Epoch 86): Loss/seq after 02150 batchs: 1199.5867919921875
INFO:root:Train (Epoch 86): Loss/seq after 02200 batchs: 1187.8353271484375
INFO:root:Train (Epoch 86): Loss/seq after 02250 batchs: 1184.9080810546875
INFO:root:Train (Epoch 86): Loss/seq after 02300 batchs: 1186.9620361328125
INFO:root:Train (Epoch 86): Loss/seq after 02350 batchs: 1175.3907470703125
INFO:root:Train (Epoch 86): Loss/seq after 02400 batchs: 1170.470703125
INFO:root:Train (Epoch 86): Loss/seq after 02450 batchs: 1157.82861328125
INFO:root:Train (Epoch 86): Loss/seq after 02500 batchs: 1141.752685546875
INFO:root:Train (Epoch 86): Loss/seq after 02550 batchs: 1129.8594970703125
INFO:root:Train (Epoch 86): Loss/seq after 02600 batchs: 1127.419921875
INFO:root:Train (Epoch 86): Loss/seq after 02650 batchs: 1122.4771728515625
INFO:root:Train (Epoch 86): Loss/seq after 02700 batchs: 1117.919921875
INFO:root:Train (Epoch 86): Loss/seq after 02750 batchs: 1135.341064453125
INFO:root:Train (Epoch 86): Loss/seq after 02800 batchs: 1140.2366943359375
INFO:root:Train (Epoch 86): Loss/seq after 02850 batchs: 1134.9000244140625
INFO:root:Train (Epoch 86): Loss/seq after 02900 batchs: 1132.476318359375
INFO:root:Train (Epoch 86): Loss/seq after 02950 batchs: 1124.1416015625
INFO:root:Train (Epoch 86): Loss/seq after 03000 batchs: 1123.0201416015625
INFO:root:Train (Epoch 86): Loss/seq after 03050 batchs: 1126.3603515625
INFO:root:Train (Epoch 86): Loss/seq after 03100 batchs: 1135.1175537109375
INFO:root:Train (Epoch 86): Loss/seq after 03150 batchs: 1148.6087646484375
INFO:root:Train (Epoch 86): Loss/seq after 03200 batchs: 1163.834716796875
INFO:root:Train (Epoch 86): Loss/seq after 03250 batchs: 1176.5184326171875
INFO:root:Train (Epoch 86): Loss/seq after 03300 batchs: 1173.8853759765625
INFO:root:Train (Epoch 86): Loss/seq after 03350 batchs: 1173.53662109375
INFO:root:Train (Epoch 86): Loss/seq after 03400 batchs: 1165.56689453125
INFO:root:Train (Epoch 86): Loss/seq after 03450 batchs: 1158.06689453125
INFO:root:Train (Epoch 86): Loss/seq after 03500 batchs: 1155.440185546875
INFO:root:Train (Epoch 86): Loss/seq after 03550 batchs: 1147.8255615234375
INFO:root:Train (Epoch 86): Loss/seq after 03600 batchs: 1152.2386474609375
INFO:root:Train (Epoch 86): Loss/seq after 03650 batchs: 1145.368408203125
INFO:root:Train (Epoch 86): Loss/seq after 03700 batchs: 1144.08447265625
INFO:root:Train (Epoch 86): Loss/seq after 03750 batchs: 1144.499755859375
INFO:root:Train (Epoch 86): Loss/seq after 03800 batchs: 1138.0330810546875
INFO:root:Train (Epoch 86): Loss/seq after 03850 batchs: 1133.6912841796875
INFO:root:Train (Epoch 86): Loss/seq after 03900 batchs: 1138.997802734375
INFO:root:Train (Epoch 86): Loss/seq after 03950 batchs: 1146.743896484375
INFO:root:Train (Epoch 86): Loss/seq after 04000 batchs: 1138.5921630859375
INFO:root:Train (Epoch 86): Loss/seq after 04050 batchs: 1131.365234375
INFO:root:Train (Epoch 86): Loss/seq after 04100 batchs: 1124.910888671875
INFO:root:Train (Epoch 86): Loss/seq after 04150 batchs: 1119.62451171875
INFO:root:Train (Epoch 86): Loss/seq after 04200 batchs: 1113.656494140625
INFO:root:Train (Epoch 86): Loss/seq after 04250 batchs: 1109.27490234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 86): Loss/seq after 00000 batches: 869.4454345703125
INFO:root:# Valid (Epoch 86): Loss/seq after 00050 batches: 1088.9171142578125
INFO:root:# Valid (Epoch 86): Loss/seq after 00100 batches: 1366.8228759765625
INFO:root:# Valid (Epoch 86): Loss/seq after 00150 batches: 1092.2261962890625
INFO:root:# Valid (Epoch 86): Loss/seq after 00200 batches: 978.224609375
INFO:root:Artifacts: Make stick videos for epoch 86
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_86_on_20220423_033922.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_86_index_1461_on_20220423_033922.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 87): Loss/seq after 00000 batchs: 2441.28662109375
INFO:root:Train (Epoch 87): Loss/seq after 00050 batchs: 1508.6771240234375
INFO:root:Train (Epoch 87): Loss/seq after 00100 batchs: 1401.3837890625
INFO:root:Train (Epoch 87): Loss/seq after 00150 batchs: 1223.13818359375
INFO:root:Train (Epoch 87): Loss/seq after 00200 batchs: 1358.5616455078125
INFO:root:Train (Epoch 87): Loss/seq after 00250 batchs: 1467.2762451171875
INFO:root:Train (Epoch 87): Loss/seq after 00300 batchs: 1401.0479736328125
INFO:root:Train (Epoch 87): Loss/seq after 00350 batchs: 1309.7886962890625
INFO:root:Train (Epoch 87): Loss/seq after 00400 batchs: 1348.3743896484375
INFO:root:Train (Epoch 87): Loss/seq after 00450 batchs: 1294.3013916015625
INFO:root:Train (Epoch 87): Loss/seq after 00500 batchs: 1282.5810546875
INFO:root:Train (Epoch 87): Loss/seq after 00550 batchs: 1230.4818115234375
INFO:root:Train (Epoch 87): Loss/seq after 00600 batchs: 1199.0902099609375
INFO:root:Train (Epoch 87): Loss/seq after 00650 batchs: 1263.048828125
INFO:root:Train (Epoch 87): Loss/seq after 00700 batchs: 1337.2462158203125
INFO:root:Train (Epoch 87): Loss/seq after 00750 batchs: 1377.951904296875
INFO:root:Train (Epoch 87): Loss/seq after 00800 batchs: 1353.8956298828125
INFO:root:Train (Epoch 87): Loss/seq after 00850 batchs: 1317.8739013671875
INFO:root:Train (Epoch 87): Loss/seq after 00900 batchs: 1317.58837890625
INFO:root:Train (Epoch 87): Loss/seq after 00950 batchs: 1390.989501953125
INFO:root:Train (Epoch 87): Loss/seq after 01000 batchs: 1387.6649169921875
INFO:root:Train (Epoch 87): Loss/seq after 01050 batchs: 1359.1055908203125
INFO:root:Train (Epoch 87): Loss/seq after 01100 batchs: 1347.56591796875
INFO:root:Train (Epoch 87): Loss/seq after 01150 batchs: 1328.8060302734375
INFO:root:Train (Epoch 87): Loss/seq after 01200 batchs: 1313.531982421875
INFO:root:Train (Epoch 87): Loss/seq after 01250 batchs: 1304.719970703125
INFO:root:Train (Epoch 87): Loss/seq after 01300 batchs: 1321.7762451171875
INFO:root:Train (Epoch 87): Loss/seq after 01350 batchs: 1328.9891357421875
INFO:root:Train (Epoch 87): Loss/seq after 01400 batchs: 1371.026123046875
INFO:root:Train (Epoch 87): Loss/seq after 01450 batchs: 1356.0501708984375
INFO:root:Train (Epoch 87): Loss/seq after 01500 batchs: 1344.3131103515625
INFO:root:Train (Epoch 87): Loss/seq after 01550 batchs: 1337.5042724609375
INFO:root:Train (Epoch 87): Loss/seq after 01600 batchs: 1318.2017822265625
INFO:root:Train (Epoch 87): Loss/seq after 01650 batchs: 1301.6197509765625
INFO:root:Train (Epoch 87): Loss/seq after 01700 batchs: 1290.7760009765625
INFO:root:Train (Epoch 87): Loss/seq after 01750 batchs: 1277.9852294921875
INFO:root:Train (Epoch 87): Loss/seq after 01800 batchs: 1262.5826416015625
INFO:root:Train (Epoch 87): Loss/seq after 01850 batchs: 1246.748046875
INFO:root:Train (Epoch 87): Loss/seq after 01900 batchs: 1239.6304931640625
INFO:root:Train (Epoch 87): Loss/seq after 01950 batchs: 1228.4639892578125
INFO:root:Train (Epoch 87): Loss/seq after 02000 batchs: 1218.5379638671875
INFO:root:Train (Epoch 87): Loss/seq after 02050 batchs: 1208.0823974609375
INFO:root:Train (Epoch 87): Loss/seq after 02100 batchs: 1196.046142578125
INFO:root:Train (Epoch 87): Loss/seq after 02150 batchs: 1184.79248046875
INFO:root:Train (Epoch 87): Loss/seq after 02200 batchs: 1173.41357421875
INFO:root:Train (Epoch 87): Loss/seq after 02250 batchs: 1170.942626953125
INFO:root:Train (Epoch 87): Loss/seq after 02300 batchs: 1173.4454345703125
INFO:root:Train (Epoch 87): Loss/seq after 02350 batchs: 1161.9871826171875
INFO:root:Train (Epoch 87): Loss/seq after 02400 batchs: 1157.0380859375
INFO:root:Train (Epoch 87): Loss/seq after 02450 batchs: 1144.656005859375
INFO:root:Train (Epoch 87): Loss/seq after 02500 batchs: 1128.83203125
INFO:root:Train (Epoch 87): Loss/seq after 02550 batchs: 1117.0848388671875
INFO:root:Train (Epoch 87): Loss/seq after 02600 batchs: 1114.82568359375
INFO:root:Train (Epoch 87): Loss/seq after 02650 batchs: 1110.051025390625
INFO:root:Train (Epoch 87): Loss/seq after 02700 batchs: 1105.6153564453125
INFO:root:Train (Epoch 87): Loss/seq after 02750 batchs: 1120.376220703125
INFO:root:Train (Epoch 87): Loss/seq after 02800 batchs: 1124.142578125
INFO:root:Train (Epoch 87): Loss/seq after 02850 batchs: 1118.8221435546875
INFO:root:Train (Epoch 87): Loss/seq after 02900 batchs: 1116.5306396484375
INFO:root:Train (Epoch 87): Loss/seq after 02950 batchs: 1108.4346923828125
INFO:root:Train (Epoch 87): Loss/seq after 03000 batchs: 1107.5052490234375
INFO:root:Train (Epoch 87): Loss/seq after 03050 batchs: 1111.1881103515625
INFO:root:Train (Epoch 87): Loss/seq after 03100 batchs: 1120.7650146484375
INFO:root:Train (Epoch 87): Loss/seq after 03150 batchs: 1134.0010986328125
INFO:root:Train (Epoch 87): Loss/seq after 03200 batchs: 1148.5093994140625
INFO:root:Train (Epoch 87): Loss/seq after 03250 batchs: 1163.631591796875
INFO:root:Train (Epoch 87): Loss/seq after 03300 batchs: 1161.219482421875
INFO:root:Train (Epoch 87): Loss/seq after 03350 batchs: 1160.1591796875
INFO:root:Train (Epoch 87): Loss/seq after 03400 batchs: 1152.4410400390625
INFO:root:Train (Epoch 87): Loss/seq after 03450 batchs: 1144.603759765625
INFO:root:Train (Epoch 87): Loss/seq after 03500 batchs: 1141.770751953125
INFO:root:Train (Epoch 87): Loss/seq after 03550 batchs: 1133.99365234375
INFO:root:Train (Epoch 87): Loss/seq after 03600 batchs: 1138.50390625
INFO:root:Train (Epoch 87): Loss/seq after 03650 batchs: 1131.8017578125
INFO:root:Train (Epoch 87): Loss/seq after 03700 batchs: 1130.60107421875
INFO:root:Train (Epoch 87): Loss/seq after 03750 batchs: 1131.1785888671875
INFO:root:Train (Epoch 87): Loss/seq after 03800 batchs: 1124.876708984375
INFO:root:Train (Epoch 87): Loss/seq after 03850 batchs: 1120.693359375
INFO:root:Train (Epoch 87): Loss/seq after 03900 batchs: 1126.9117431640625
INFO:root:Train (Epoch 87): Loss/seq after 03950 batchs: 1134.802490234375
INFO:root:Train (Epoch 87): Loss/seq after 04000 batchs: 1126.7955322265625
INFO:root:Train (Epoch 87): Loss/seq after 04050 batchs: 1119.6956787109375
INFO:root:Train (Epoch 87): Loss/seq after 04100 batchs: 1113.3797607421875
INFO:root:Train (Epoch 87): Loss/seq after 04150 batchs: 1108.203857421875
INFO:root:Train (Epoch 87): Loss/seq after 04200 batchs: 1102.233154296875
INFO:root:Train (Epoch 87): Loss/seq after 04250 batchs: 1097.966796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 87): Loss/seq after 00000 batches: 868.4010620117188
INFO:root:# Valid (Epoch 87): Loss/seq after 00050 batches: 1086.7779541015625
INFO:root:# Valid (Epoch 87): Loss/seq after 00100 batches: 1363.3883056640625
INFO:root:# Valid (Epoch 87): Loss/seq after 00150 batches: 1082.9691162109375
INFO:root:# Valid (Epoch 87): Loss/seq after 00200 batches: 970.6392822265625
INFO:root:Artifacts: Make stick videos for epoch 87
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_87_on_20220423_034410.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_87_index_1456_on_20220423_034410.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 88): Loss/seq after 00000 batchs: 2391.694091796875
INFO:root:Train (Epoch 88): Loss/seq after 00050 batchs: 1495.28466796875
INFO:root:Train (Epoch 88): Loss/seq after 00100 batchs: 1386.8961181640625
INFO:root:Train (Epoch 88): Loss/seq after 00150 batchs: 1216.1484375
INFO:root:Train (Epoch 88): Loss/seq after 00200 batchs: 1359.380859375
INFO:root:Train (Epoch 88): Loss/seq after 00250 batchs: 1471.2724609375
INFO:root:Train (Epoch 88): Loss/seq after 00300 batchs: 1404.635986328125
INFO:root:Train (Epoch 88): Loss/seq after 00350 batchs: 1312.69091796875
INFO:root:Train (Epoch 88): Loss/seq after 00400 batchs: 1352.5037841796875
INFO:root:Train (Epoch 88): Loss/seq after 00450 batchs: 1298.3564453125
INFO:root:Train (Epoch 88): Loss/seq after 00500 batchs: 1288.88671875
INFO:root:Train (Epoch 88): Loss/seq after 00550 batchs: 1236.9920654296875
INFO:root:Train (Epoch 88): Loss/seq after 00600 batchs: 1205.385009765625
INFO:root:Train (Epoch 88): Loss/seq after 00650 batchs: 1281.3349609375
INFO:root:Train (Epoch 88): Loss/seq after 00700 batchs: 1379.938232421875
INFO:root:Train (Epoch 88): Loss/seq after 00750 batchs: 1417.8897705078125
INFO:root:Train (Epoch 88): Loss/seq after 00800 batchs: 1390.383056640625
INFO:root:Train (Epoch 88): Loss/seq after 00850 batchs: 1351.5684814453125
INFO:root:Train (Epoch 88): Loss/seq after 00900 batchs: 1349.1602783203125
INFO:root:Train (Epoch 88): Loss/seq after 00950 batchs: 1431.8609619140625
INFO:root:Train (Epoch 88): Loss/seq after 01000 batchs: 1429.8721923828125
INFO:root:Train (Epoch 88): Loss/seq after 01050 batchs: 1397.951904296875
INFO:root:Train (Epoch 88): Loss/seq after 01100 batchs: 1383.981201171875
INFO:root:Train (Epoch 88): Loss/seq after 01150 batchs: 1363.656494140625
INFO:root:Train (Epoch 88): Loss/seq after 01200 batchs: 1346.850830078125
INFO:root:Train (Epoch 88): Loss/seq after 01250 batchs: 1336.648681640625
INFO:root:Train (Epoch 88): Loss/seq after 01300 batchs: 1351.599365234375
INFO:root:Train (Epoch 88): Loss/seq after 01350 batchs: 1356.4686279296875
INFO:root:Train (Epoch 88): Loss/seq after 01400 batchs: 1403.4903564453125
INFO:root:Train (Epoch 88): Loss/seq after 01450 batchs: 1387.3525390625
INFO:root:Train (Epoch 88): Loss/seq after 01500 batchs: 1374.614501953125
INFO:root:Train (Epoch 88): Loss/seq after 01550 batchs: 1367.0694580078125
INFO:root:Train (Epoch 88): Loss/seq after 01600 batchs: 1346.787109375
INFO:root:Train (Epoch 88): Loss/seq after 01650 batchs: 1329.369873046875
INFO:root:Train (Epoch 88): Loss/seq after 01700 batchs: 1317.7784423828125
INFO:root:Train (Epoch 88): Loss/seq after 01750 batchs: 1304.336181640625
INFO:root:Train (Epoch 88): Loss/seq after 01800 batchs: 1288.3406982421875
INFO:root:Train (Epoch 88): Loss/seq after 01850 batchs: 1272.15087890625
INFO:root:Train (Epoch 88): Loss/seq after 01900 batchs: 1264.52099609375
INFO:root:Train (Epoch 88): Loss/seq after 01950 batchs: 1252.911865234375
INFO:root:Train (Epoch 88): Loss/seq after 02000 batchs: 1242.342529296875
INFO:root:Train (Epoch 88): Loss/seq after 02050 batchs: 1231.3212890625
INFO:root:Train (Epoch 88): Loss/seq after 02100 batchs: 1218.8685302734375
INFO:root:Train (Epoch 88): Loss/seq after 02150 batchs: 1207.064697265625
INFO:root:Train (Epoch 88): Loss/seq after 02200 batchs: 1195.2073974609375
INFO:root:Train (Epoch 88): Loss/seq after 02250 batchs: 1192.5911865234375
INFO:root:Train (Epoch 88): Loss/seq after 02300 batchs: 1194.9864501953125
INFO:root:Train (Epoch 88): Loss/seq after 02350 batchs: 1183.0377197265625
INFO:root:Train (Epoch 88): Loss/seq after 02400 batchs: 1177.6348876953125
INFO:root:Train (Epoch 88): Loss/seq after 02450 batchs: 1164.8653564453125
INFO:root:Train (Epoch 88): Loss/seq after 02500 batchs: 1148.6470947265625
INFO:root:Train (Epoch 88): Loss/seq after 02550 batchs: 1136.6728515625
INFO:root:Train (Epoch 88): Loss/seq after 02600 batchs: 1134.108154296875
INFO:root:Train (Epoch 88): Loss/seq after 02650 batchs: 1129.00439453125
INFO:root:Train (Epoch 88): Loss/seq after 02700 batchs: 1124.32373046875
INFO:root:Train (Epoch 88): Loss/seq after 02750 batchs: 1139.4803466796875
INFO:root:Train (Epoch 88): Loss/seq after 02800 batchs: 1143.18310546875
INFO:root:Train (Epoch 88): Loss/seq after 02850 batchs: 1137.6287841796875
INFO:root:Train (Epoch 88): Loss/seq after 02900 batchs: 1135.0811767578125
INFO:root:Train (Epoch 88): Loss/seq after 02950 batchs: 1126.660888671875
INFO:root:Train (Epoch 88): Loss/seq after 03000 batchs: 1125.3843994140625
INFO:root:Train (Epoch 88): Loss/seq after 03050 batchs: 1128.760986328125
INFO:root:Train (Epoch 88): Loss/seq after 03100 batchs: 1137.7625732421875
INFO:root:Train (Epoch 88): Loss/seq after 03150 batchs: 1154.8905029296875
INFO:root:Train (Epoch 88): Loss/seq after 03200 batchs: 1169.969482421875
INFO:root:Train (Epoch 88): Loss/seq after 03250 batchs: 1184.3858642578125
INFO:root:Train (Epoch 88): Loss/seq after 03300 batchs: 1181.8326416015625
INFO:root:Train (Epoch 88): Loss/seq after 03350 batchs: 1180.8369140625
INFO:root:Train (Epoch 88): Loss/seq after 03400 batchs: 1172.7562255859375
INFO:root:Train (Epoch 88): Loss/seq after 03450 batchs: 1164.9715576171875
INFO:root:Train (Epoch 88): Loss/seq after 03500 batchs: 1161.964599609375
INFO:root:Train (Epoch 88): Loss/seq after 03550 batchs: 1153.7574462890625
INFO:root:Train (Epoch 88): Loss/seq after 03600 batchs: 1158.0166015625
INFO:root:Train (Epoch 88): Loss/seq after 03650 batchs: 1150.94580078125
INFO:root:Train (Epoch 88): Loss/seq after 03700 batchs: 1149.3804931640625
INFO:root:Train (Epoch 88): Loss/seq after 03750 batchs: 1149.7327880859375
INFO:root:Train (Epoch 88): Loss/seq after 03800 batchs: 1143.181884765625
INFO:root:Train (Epoch 88): Loss/seq after 03850 batchs: 1138.7607421875
INFO:root:Train (Epoch 88): Loss/seq after 03900 batchs: 1144.1810302734375
INFO:root:Train (Epoch 88): Loss/seq after 03950 batchs: 1150.5616455078125
INFO:root:Train (Epoch 88): Loss/seq after 04000 batchs: 1142.3482666015625
INFO:root:Train (Epoch 88): Loss/seq after 04050 batchs: 1135.0511474609375
INFO:root:Train (Epoch 88): Loss/seq after 04100 batchs: 1128.3349609375
INFO:root:Train (Epoch 88): Loss/seq after 04150 batchs: 1122.9522705078125
INFO:root:Train (Epoch 88): Loss/seq after 04200 batchs: 1116.71630859375
INFO:root:Train (Epoch 88): Loss/seq after 04250 batchs: 1112.196044921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 88): Loss/seq after 00000 batches: 868.9613037109375
INFO:root:# Valid (Epoch 88): Loss/seq after 00050 batches: 1089.6236572265625
INFO:root:# Valid (Epoch 88): Loss/seq after 00100 batches: 1372.272705078125
INFO:root:# Valid (Epoch 88): Loss/seq after 00150 batches: 1091.2459716796875
INFO:root:# Valid (Epoch 88): Loss/seq after 00200 batches: 976.3297119140625
INFO:root:Artifacts: Make stick videos for epoch 88
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_88_on_20220423_034916.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_88_index_1835_on_20220423_034916.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 89): Loss/seq after 00000 batchs: 2451.45263671875
INFO:root:Train (Epoch 89): Loss/seq after 00050 batchs: 1486.92578125
INFO:root:Train (Epoch 89): Loss/seq after 00100 batchs: 1390.6796875
INFO:root:Train (Epoch 89): Loss/seq after 00150 batchs: 1219.0958251953125
INFO:root:Train (Epoch 89): Loss/seq after 00200 batchs: 1362.2698974609375
INFO:root:Train (Epoch 89): Loss/seq after 00250 batchs: 1468.849365234375
INFO:root:Train (Epoch 89): Loss/seq after 00300 batchs: 1401.9962158203125
INFO:root:Train (Epoch 89): Loss/seq after 00350 batchs: 1309.77978515625
INFO:root:Train (Epoch 89): Loss/seq after 00400 batchs: 1348.393310546875
INFO:root:Train (Epoch 89): Loss/seq after 00450 batchs: 1293.89697265625
INFO:root:Train (Epoch 89): Loss/seq after 00500 batchs: 1285.7265625
INFO:root:Train (Epoch 89): Loss/seq after 00550 batchs: 1233.613037109375
INFO:root:Train (Epoch 89): Loss/seq after 00600 batchs: 1203.7960205078125
INFO:root:Train (Epoch 89): Loss/seq after 00650 batchs: 1266.6409912109375
INFO:root:Train (Epoch 89): Loss/seq after 00700 batchs: 1331.099609375
INFO:root:Train (Epoch 89): Loss/seq after 00750 batchs: 1371.51318359375
INFO:root:Train (Epoch 89): Loss/seq after 00800 batchs: 1347.6602783203125
INFO:root:Train (Epoch 89): Loss/seq after 00850 batchs: 1311.707275390625
INFO:root:Train (Epoch 89): Loss/seq after 00900 batchs: 1311.680908203125
INFO:root:Train (Epoch 89): Loss/seq after 00950 batchs: 1375.4129638671875
INFO:root:Train (Epoch 89): Loss/seq after 01000 batchs: 1371.7288818359375
INFO:root:Train (Epoch 89): Loss/seq after 01050 batchs: 1345.103759765625
INFO:root:Train (Epoch 89): Loss/seq after 01100 batchs: 1334.2291259765625
INFO:root:Train (Epoch 89): Loss/seq after 01150 batchs: 1316.0885009765625
INFO:root:Train (Epoch 89): Loss/seq after 01200 batchs: 1301.8685302734375
INFO:root:Train (Epoch 89): Loss/seq after 01250 batchs: 1292.281005859375
INFO:root:Train (Epoch 89): Loss/seq after 01300 batchs: 1307.409423828125
INFO:root:Train (Epoch 89): Loss/seq after 01350 batchs: 1313.44482421875
INFO:root:Train (Epoch 89): Loss/seq after 01400 batchs: 1354.5784912109375
INFO:root:Train (Epoch 89): Loss/seq after 01450 batchs: 1340.3165283203125
INFO:root:Train (Epoch 89): Loss/seq after 01500 batchs: 1329.16552734375
INFO:root:Train (Epoch 89): Loss/seq after 01550 batchs: 1323.467041015625
INFO:root:Train (Epoch 89): Loss/seq after 01600 batchs: 1304.7357177734375
INFO:root:Train (Epoch 89): Loss/seq after 01650 batchs: 1288.7142333984375
INFO:root:Train (Epoch 89): Loss/seq after 01700 batchs: 1278.3775634765625
INFO:root:Train (Epoch 89): Loss/seq after 01750 batchs: 1265.956787109375
INFO:root:Train (Epoch 89): Loss/seq after 01800 batchs: 1250.9033203125
INFO:root:Train (Epoch 89): Loss/seq after 01850 batchs: 1235.3492431640625
INFO:root:Train (Epoch 89): Loss/seq after 01900 batchs: 1228.5794677734375
INFO:root:Train (Epoch 89): Loss/seq after 01950 batchs: 1218.2998046875
INFO:root:Train (Epoch 89): Loss/seq after 02000 batchs: 1208.9088134765625
INFO:root:Train (Epoch 89): Loss/seq after 02050 batchs: 1198.6986083984375
INFO:root:Train (Epoch 89): Loss/seq after 02100 batchs: 1186.9051513671875
INFO:root:Train (Epoch 89): Loss/seq after 02150 batchs: 1175.81005859375
INFO:root:Train (Epoch 89): Loss/seq after 02200 batchs: 1164.6536865234375
INFO:root:Train (Epoch 89): Loss/seq after 02250 batchs: 1162.3406982421875
INFO:root:Train (Epoch 89): Loss/seq after 02300 batchs: 1164.938720703125
INFO:root:Train (Epoch 89): Loss/seq after 02350 batchs: 1153.830322265625
INFO:root:Train (Epoch 89): Loss/seq after 02400 batchs: 1149.045166015625
INFO:root:Train (Epoch 89): Loss/seq after 02450 batchs: 1136.870849609375
INFO:root:Train (Epoch 89): Loss/seq after 02500 batchs: 1121.2132568359375
INFO:root:Train (Epoch 89): Loss/seq after 02550 batchs: 1109.66357421875
INFO:root:Train (Epoch 89): Loss/seq after 02600 batchs: 1107.6229248046875
INFO:root:Train (Epoch 89): Loss/seq after 02650 batchs: 1102.99951171875
INFO:root:Train (Epoch 89): Loss/seq after 02700 batchs: 1098.660400390625
INFO:root:Train (Epoch 89): Loss/seq after 02750 batchs: 1114.2845458984375
INFO:root:Train (Epoch 89): Loss/seq after 02800 batchs: 1118.0738525390625
INFO:root:Train (Epoch 89): Loss/seq after 02850 batchs: 1112.7471923828125
INFO:root:Train (Epoch 89): Loss/seq after 02900 batchs: 1110.34326171875
INFO:root:Train (Epoch 89): Loss/seq after 02950 batchs: 1102.243408203125
INFO:root:Train (Epoch 89): Loss/seq after 03000 batchs: 1101.4027099609375
INFO:root:Train (Epoch 89): Loss/seq after 03050 batchs: 1104.9833984375
INFO:root:Train (Epoch 89): Loss/seq after 03100 batchs: 1114.0321044921875
INFO:root:Train (Epoch 89): Loss/seq after 03150 batchs: 1125.326416015625
INFO:root:Train (Epoch 89): Loss/seq after 03200 batchs: 1137.802490234375
INFO:root:Train (Epoch 89): Loss/seq after 03250 batchs: 1148.2803955078125
INFO:root:Train (Epoch 89): Loss/seq after 03300 batchs: 1145.9063720703125
INFO:root:Train (Epoch 89): Loss/seq after 03350 batchs: 1144.7777099609375
INFO:root:Train (Epoch 89): Loss/seq after 03400 batchs: 1137.194580078125
INFO:root:Train (Epoch 89): Loss/seq after 03450 batchs: 1129.5975341796875
INFO:root:Train (Epoch 89): Loss/seq after 03500 batchs: 1126.76416015625
INFO:root:Train (Epoch 89): Loss/seq after 03550 batchs: 1118.9879150390625
INFO:root:Train (Epoch 89): Loss/seq after 03600 batchs: 1123.7564697265625
INFO:root:Train (Epoch 89): Loss/seq after 03650 batchs: 1117.7239990234375
INFO:root:Train (Epoch 89): Loss/seq after 03700 batchs: 1117.17919921875
INFO:root:Train (Epoch 89): Loss/seq after 03750 batchs: 1117.9705810546875
INFO:root:Train (Epoch 89): Loss/seq after 03800 batchs: 1111.9361572265625
INFO:root:Train (Epoch 89): Loss/seq after 03850 batchs: 1107.994873046875
INFO:root:Train (Epoch 89): Loss/seq after 03900 batchs: 1112.734130859375
INFO:root:Train (Epoch 89): Loss/seq after 03950 batchs: 1120.1785888671875
INFO:root:Train (Epoch 89): Loss/seq after 04000 batchs: 1112.347900390625
INFO:root:Train (Epoch 89): Loss/seq after 04050 batchs: 1105.4178466796875
INFO:root:Train (Epoch 89): Loss/seq after 04100 batchs: 1099.1368408203125
INFO:root:Train (Epoch 89): Loss/seq after 04150 batchs: 1094.1468505859375
INFO:root:Train (Epoch 89): Loss/seq after 04200 batchs: 1088.2513427734375
INFO:root:Train (Epoch 89): Loss/seq after 04250 batchs: 1084.0469970703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 89): Loss/seq after 00000 batches: 871.196044921875
INFO:root:# Valid (Epoch 89): Loss/seq after 00050 batches: 1086.47802734375
INFO:root:# Valid (Epoch 89): Loss/seq after 00100 batches: 1362.585693359375
INFO:root:# Valid (Epoch 89): Loss/seq after 00150 batches: 1079.3719482421875
INFO:root:# Valid (Epoch 89): Loss/seq after 00200 batches: 966.450927734375
INFO:root:Artifacts: Make stick videos for epoch 89
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_89_on_20220423_035416.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_89_index_275_on_20220423_035416.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 90): Loss/seq after 00000 batchs: 2506.930908203125
INFO:root:Train (Epoch 90): Loss/seq after 00050 batchs: 1501.5943603515625
INFO:root:Train (Epoch 90): Loss/seq after 00100 batchs: 1387.2242431640625
INFO:root:Train (Epoch 90): Loss/seq after 00150 batchs: 1216.6361083984375
INFO:root:Train (Epoch 90): Loss/seq after 00200 batchs: 1364.781005859375
INFO:root:Train (Epoch 90): Loss/seq after 00250 batchs: 1471.8907470703125
INFO:root:Train (Epoch 90): Loss/seq after 00300 batchs: 1404.564453125
INFO:root:Train (Epoch 90): Loss/seq after 00350 batchs: 1313.2491455078125
INFO:root:Train (Epoch 90): Loss/seq after 00400 batchs: 1351.7052001953125
INFO:root:Train (Epoch 90): Loss/seq after 00450 batchs: 1297.1109619140625
INFO:root:Train (Epoch 90): Loss/seq after 00500 batchs: 1288.40625
INFO:root:Train (Epoch 90): Loss/seq after 00550 batchs: 1235.9351806640625
INFO:root:Train (Epoch 90): Loss/seq after 00600 batchs: 1203.945068359375
INFO:root:Train (Epoch 90): Loss/seq after 00650 batchs: 1267.3408203125
INFO:root:Train (Epoch 90): Loss/seq after 00700 batchs: 1319.73388671875
INFO:root:Train (Epoch 90): Loss/seq after 00750 batchs: 1358.239501953125
INFO:root:Train (Epoch 90): Loss/seq after 00800 batchs: 1334.9012451171875
INFO:root:Train (Epoch 90): Loss/seq after 00850 batchs: 1299.42138671875
INFO:root:Train (Epoch 90): Loss/seq after 00900 batchs: 1300.3511962890625
INFO:root:Train (Epoch 90): Loss/seq after 00950 batchs: 1364.0313720703125
INFO:root:Train (Epoch 90): Loss/seq after 01000 batchs: 1358.5885009765625
INFO:root:Train (Epoch 90): Loss/seq after 01050 batchs: 1330.4508056640625
INFO:root:Train (Epoch 90): Loss/seq after 01100 batchs: 1319.7144775390625
INFO:root:Train (Epoch 90): Loss/seq after 01150 batchs: 1302.688720703125
INFO:root:Train (Epoch 90): Loss/seq after 01200 batchs: 1288.5963134765625
INFO:root:Train (Epoch 90): Loss/seq after 01250 batchs: 1280.051513671875
INFO:root:Train (Epoch 90): Loss/seq after 01300 batchs: 1294.041748046875
INFO:root:Train (Epoch 90): Loss/seq after 01350 batchs: 1300.77001953125
INFO:root:Train (Epoch 90): Loss/seq after 01400 batchs: 1342.968994140625
INFO:root:Train (Epoch 90): Loss/seq after 01450 batchs: 1328.7974853515625
INFO:root:Train (Epoch 90): Loss/seq after 01500 batchs: 1318.107177734375
INFO:root:Train (Epoch 90): Loss/seq after 01550 batchs: 1312.0943603515625
INFO:root:Train (Epoch 90): Loss/seq after 01600 batchs: 1293.539794921875
INFO:root:Train (Epoch 90): Loss/seq after 01650 batchs: 1277.7724609375
INFO:root:Train (Epoch 90): Loss/seq after 01700 batchs: 1267.7337646484375
INFO:root:Train (Epoch 90): Loss/seq after 01750 batchs: 1255.69091796875
INFO:root:Train (Epoch 90): Loss/seq after 01800 batchs: 1240.9429931640625
INFO:root:Train (Epoch 90): Loss/seq after 01850 batchs: 1225.70947265625
INFO:root:Train (Epoch 90): Loss/seq after 01900 batchs: 1219.1275634765625
INFO:root:Train (Epoch 90): Loss/seq after 01950 batchs: 1208.8953857421875
INFO:root:Train (Epoch 90): Loss/seq after 02000 batchs: 1199.4779052734375
INFO:root:Train (Epoch 90): Loss/seq after 02050 batchs: 1189.5992431640625
INFO:root:Train (Epoch 90): Loss/seq after 02100 batchs: 1178.2001953125
INFO:root:Train (Epoch 90): Loss/seq after 02150 batchs: 1167.2618408203125
INFO:root:Train (Epoch 90): Loss/seq after 02200 batchs: 1156.2044677734375
INFO:root:Train (Epoch 90): Loss/seq after 02250 batchs: 1153.87109375
INFO:root:Train (Epoch 90): Loss/seq after 02300 batchs: 1156.2144775390625
INFO:root:Train (Epoch 90): Loss/seq after 02350 batchs: 1144.9405517578125
INFO:root:Train (Epoch 90): Loss/seq after 02400 batchs: 1140.4278564453125
INFO:root:Train (Epoch 90): Loss/seq after 02450 batchs: 1128.378662109375
INFO:root:Train (Epoch 90): Loss/seq after 02500 batchs: 1112.866455078125
INFO:root:Train (Epoch 90): Loss/seq after 02550 batchs: 1101.4857177734375
INFO:root:Train (Epoch 90): Loss/seq after 02600 batchs: 1099.4932861328125
INFO:root:Train (Epoch 90): Loss/seq after 02650 batchs: 1094.95703125
INFO:root:Train (Epoch 90): Loss/seq after 02700 batchs: 1090.781982421875
INFO:root:Train (Epoch 90): Loss/seq after 02750 batchs: 1105.95263671875
INFO:root:Train (Epoch 90): Loss/seq after 02800 batchs: 1109.9976806640625
INFO:root:Train (Epoch 90): Loss/seq after 02850 batchs: 1104.947265625
INFO:root:Train (Epoch 90): Loss/seq after 02900 batchs: 1102.6837158203125
INFO:root:Train (Epoch 90): Loss/seq after 02950 batchs: 1094.800537109375
INFO:root:Train (Epoch 90): Loss/seq after 03000 batchs: 1094.11328125
INFO:root:Train (Epoch 90): Loss/seq after 03050 batchs: 1097.8695068359375
INFO:root:Train (Epoch 90): Loss/seq after 03100 batchs: 1106.2752685546875
INFO:root:Train (Epoch 90): Loss/seq after 03150 batchs: 1117.1148681640625
INFO:root:Train (Epoch 90): Loss/seq after 03200 batchs: 1128.7357177734375
INFO:root:Train (Epoch 90): Loss/seq after 03250 batchs: 1139.083984375
INFO:root:Train (Epoch 90): Loss/seq after 03300 batchs: 1137.2855224609375
INFO:root:Train (Epoch 90): Loss/seq after 03350 batchs: 1136.2974853515625
INFO:root:Train (Epoch 90): Loss/seq after 03400 batchs: 1128.818359375
INFO:root:Train (Epoch 90): Loss/seq after 03450 batchs: 1121.3572998046875
INFO:root:Train (Epoch 90): Loss/seq after 03500 batchs: 1118.7169189453125
INFO:root:Train (Epoch 90): Loss/seq after 03550 batchs: 1111.25244140625
INFO:root:Train (Epoch 90): Loss/seq after 03600 batchs: 1116.1705322265625
INFO:root:Train (Epoch 90): Loss/seq after 03650 batchs: 1109.887939453125
INFO:root:Train (Epoch 90): Loss/seq after 03700 batchs: 1109.06591796875
INFO:root:Train (Epoch 90): Loss/seq after 03750 batchs: 1109.9041748046875
INFO:root:Train (Epoch 90): Loss/seq after 03800 batchs: 1103.84228515625
INFO:root:Train (Epoch 90): Loss/seq after 03850 batchs: 1099.9078369140625
INFO:root:Train (Epoch 90): Loss/seq after 03900 batchs: 1104.7757568359375
INFO:root:Train (Epoch 90): Loss/seq after 03950 batchs: 1111.9443359375
INFO:root:Train (Epoch 90): Loss/seq after 04000 batchs: 1104.2296142578125
INFO:root:Train (Epoch 90): Loss/seq after 04050 batchs: 1097.425537109375
INFO:root:Train (Epoch 90): Loss/seq after 04100 batchs: 1091.326171875
INFO:root:Train (Epoch 90): Loss/seq after 04150 batchs: 1086.4388427734375
INFO:root:Train (Epoch 90): Loss/seq after 04200 batchs: 1080.6878662109375
INFO:root:Train (Epoch 90): Loss/seq after 04250 batchs: 1076.5794677734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 90): Loss/seq after 00000 batches: 869.048095703125
INFO:root:# Valid (Epoch 90): Loss/seq after 00050 batches: 1086.2734375
INFO:root:# Valid (Epoch 90): Loss/seq after 00100 batches: 1368.8466796875
INFO:root:# Valid (Epoch 90): Loss/seq after 00150 batches: 1085.5994873046875
INFO:root:# Valid (Epoch 90): Loss/seq after 00200 batches: 971.6358642578125
INFO:root:Artifacts: Make stick videos for epoch 90
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_90_on_20220423_035900.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_90_index_985_on_20220423_035900.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 91): Loss/seq after 00000 batchs: 2350.5576171875
INFO:root:Train (Epoch 91): Loss/seq after 00050 batchs: 1492.1005859375
INFO:root:Train (Epoch 91): Loss/seq after 00100 batchs: 1395.481689453125
INFO:root:Train (Epoch 91): Loss/seq after 00150 batchs: 1220.880859375
INFO:root:Train (Epoch 91): Loss/seq after 00200 batchs: 1344.5870361328125
INFO:root:Train (Epoch 91): Loss/seq after 00250 batchs: 1450.0751953125
INFO:root:Train (Epoch 91): Loss/seq after 00300 batchs: 1386.029296875
INFO:root:Train (Epoch 91): Loss/seq after 00350 batchs: 1295.75341796875
INFO:root:Train (Epoch 91): Loss/seq after 00400 batchs: 1337.2904052734375
INFO:root:Train (Epoch 91): Loss/seq after 00450 batchs: 1283.7088623046875
INFO:root:Train (Epoch 91): Loss/seq after 00500 batchs: 1274.8270263671875
INFO:root:Train (Epoch 91): Loss/seq after 00550 batchs: 1223.4005126953125
INFO:root:Train (Epoch 91): Loss/seq after 00600 batchs: 1192.3681640625
INFO:root:Train (Epoch 91): Loss/seq after 00650 batchs: 1238.87060546875
INFO:root:Train (Epoch 91): Loss/seq after 00700 batchs: 1275.5477294921875
INFO:root:Train (Epoch 91): Loss/seq after 00750 batchs: 1317.7904052734375
INFO:root:Train (Epoch 91): Loss/seq after 00800 batchs: 1297.3988037109375
INFO:root:Train (Epoch 91): Loss/seq after 00850 batchs: 1264.6004638671875
INFO:root:Train (Epoch 91): Loss/seq after 00900 batchs: 1267.174072265625
INFO:root:Train (Epoch 91): Loss/seq after 00950 batchs: 1319.280517578125
INFO:root:Train (Epoch 91): Loss/seq after 01000 batchs: 1309.8226318359375
INFO:root:Train (Epoch 91): Loss/seq after 01050 batchs: 1285.5291748046875
INFO:root:Train (Epoch 91): Loss/seq after 01100 batchs: 1276.920166015625
INFO:root:Train (Epoch 91): Loss/seq after 01150 batchs: 1262.431640625
INFO:root:Train (Epoch 91): Loss/seq after 01200 batchs: 1250.7510986328125
INFO:root:Train (Epoch 91): Loss/seq after 01250 batchs: 1242.4605712890625
INFO:root:Train (Epoch 91): Loss/seq after 01300 batchs: 1255.18603515625
INFO:root:Train (Epoch 91): Loss/seq after 01350 batchs: 1261.719970703125
INFO:root:Train (Epoch 91): Loss/seq after 01400 batchs: 1300.833740234375
INFO:root:Train (Epoch 91): Loss/seq after 01450 batchs: 1288.57568359375
INFO:root:Train (Epoch 91): Loss/seq after 01500 batchs: 1279.0592041015625
INFO:root:Train (Epoch 91): Loss/seq after 01550 batchs: 1274.4412841796875
INFO:root:Train (Epoch 91): Loss/seq after 01600 batchs: 1257.056640625
INFO:root:Train (Epoch 91): Loss/seq after 01650 batchs: 1242.411865234375
INFO:root:Train (Epoch 91): Loss/seq after 01700 batchs: 1233.4779052734375
INFO:root:Train (Epoch 91): Loss/seq after 01750 batchs: 1222.4161376953125
INFO:root:Train (Epoch 91): Loss/seq after 01800 batchs: 1208.692138671875
INFO:root:Train (Epoch 91): Loss/seq after 01850 batchs: 1194.492919921875
INFO:root:Train (Epoch 91): Loss/seq after 01900 batchs: 1188.5699462890625
INFO:root:Train (Epoch 91): Loss/seq after 01950 batchs: 1178.5782470703125
INFO:root:Train (Epoch 91): Loss/seq after 02000 batchs: 1169.9222412109375
INFO:root:Train (Epoch 91): Loss/seq after 02050 batchs: 1160.48486328125
INFO:root:Train (Epoch 91): Loss/seq after 02100 batchs: 1149.5247802734375
INFO:root:Train (Epoch 91): Loss/seq after 02150 batchs: 1139.2733154296875
INFO:root:Train (Epoch 91): Loss/seq after 02200 batchs: 1128.9105224609375
INFO:root:Train (Epoch 91): Loss/seq after 02250 batchs: 1127.4404296875
INFO:root:Train (Epoch 91): Loss/seq after 02300 batchs: 1130.66748046875
INFO:root:Train (Epoch 91): Loss/seq after 02350 batchs: 1120.1275634765625
INFO:root:Train (Epoch 91): Loss/seq after 02400 batchs: 1116.0157470703125
INFO:root:Train (Epoch 91): Loss/seq after 02450 batchs: 1104.4613037109375
INFO:root:Train (Epoch 91): Loss/seq after 02500 batchs: 1089.44921875
INFO:root:Train (Epoch 91): Loss/seq after 02550 batchs: 1078.5460205078125
INFO:root:Train (Epoch 91): Loss/seq after 02600 batchs: 1077.009521484375
INFO:root:Train (Epoch 91): Loss/seq after 02650 batchs: 1073.09765625
INFO:root:Train (Epoch 91): Loss/seq after 02700 batchs: 1069.2218017578125
INFO:root:Train (Epoch 91): Loss/seq after 02750 batchs: 1086.9271240234375
INFO:root:Train (Epoch 91): Loss/seq after 02800 batchs: 1092.224609375
INFO:root:Train (Epoch 91): Loss/seq after 02850 batchs: 1087.6378173828125
INFO:root:Train (Epoch 91): Loss/seq after 02900 batchs: 1085.769775390625
INFO:root:Train (Epoch 91): Loss/seq after 02950 batchs: 1078.260986328125
INFO:root:Train (Epoch 91): Loss/seq after 03000 batchs: 1077.8441162109375
INFO:root:Train (Epoch 91): Loss/seq after 03050 batchs: 1082.038330078125
INFO:root:Train (Epoch 91): Loss/seq after 03100 batchs: 1091.089111328125
INFO:root:Train (Epoch 91): Loss/seq after 03150 batchs: 1101.962646484375
INFO:root:Train (Epoch 91): Loss/seq after 03200 batchs: 1114.3934326171875
INFO:root:Train (Epoch 91): Loss/seq after 03250 batchs: 1123.5283203125
INFO:root:Train (Epoch 91): Loss/seq after 03300 batchs: 1121.383056640625
INFO:root:Train (Epoch 91): Loss/seq after 03350 batchs: 1120.69384765625
INFO:root:Train (Epoch 91): Loss/seq after 03400 batchs: 1113.401611328125
INFO:root:Train (Epoch 91): Loss/seq after 03450 batchs: 1106.2879638671875
INFO:root:Train (Epoch 91): Loss/seq after 03500 batchs: 1103.8760986328125
INFO:root:Train (Epoch 91): Loss/seq after 03550 batchs: 1096.5601806640625
INFO:root:Train (Epoch 91): Loss/seq after 03600 batchs: 1101.5677490234375
INFO:root:Train (Epoch 91): Loss/seq after 03650 batchs: 1095.337158203125
INFO:root:Train (Epoch 91): Loss/seq after 03700 batchs: 1094.826904296875
INFO:root:Train (Epoch 91): Loss/seq after 03750 batchs: 1095.8699951171875
INFO:root:Train (Epoch 91): Loss/seq after 03800 batchs: 1090.021240234375
INFO:root:Train (Epoch 91): Loss/seq after 03850 batchs: 1086.2781982421875
INFO:root:Train (Epoch 91): Loss/seq after 03900 batchs: 1090.8887939453125
INFO:root:Train (Epoch 91): Loss/seq after 03950 batchs: 1097.741455078125
INFO:root:Train (Epoch 91): Loss/seq after 04000 batchs: 1090.1884765625
INFO:root:Train (Epoch 91): Loss/seq after 04050 batchs: 1083.5340576171875
INFO:root:Train (Epoch 91): Loss/seq after 04100 batchs: 1077.4415283203125
INFO:root:Train (Epoch 91): Loss/seq after 04150 batchs: 1072.6666259765625
INFO:root:Train (Epoch 91): Loss/seq after 04200 batchs: 1066.8916015625
INFO:root:Train (Epoch 91): Loss/seq after 04250 batchs: 1062.9285888671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 91): Loss/seq after 00000 batches: 884.0060424804688
INFO:root:# Valid (Epoch 91): Loss/seq after 00050 batches: 1095.378662109375
INFO:root:# Valid (Epoch 91): Loss/seq after 00100 batches: 1377.5458984375
INFO:root:# Valid (Epoch 91): Loss/seq after 00150 batches: 1093.236328125
INFO:root:# Valid (Epoch 91): Loss/seq after 00200 batches: 977.988525390625
INFO:root:Artifacts: Make stick videos for epoch 91
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_91_on_20220423_040345.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_91_index_376_on_20220423_040345.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 92): Loss/seq after 00000 batchs: 1772.256591796875
INFO:root:Train (Epoch 92): Loss/seq after 00050 batchs: 1472.69189453125
INFO:root:Train (Epoch 92): Loss/seq after 00100 batchs: 1365.8104248046875
INFO:root:Train (Epoch 92): Loss/seq after 00150 batchs: 1198.7589111328125
INFO:root:Train (Epoch 92): Loss/seq after 00200 batchs: 1332.9112548828125
INFO:root:Train (Epoch 92): Loss/seq after 00250 batchs: 1443.7745361328125
INFO:root:Train (Epoch 92): Loss/seq after 00300 batchs: 1381.3924560546875
INFO:root:Train (Epoch 92): Loss/seq after 00350 batchs: 1292.219970703125
INFO:root:Train (Epoch 92): Loss/seq after 00400 batchs: 1330.1434326171875
INFO:root:Train (Epoch 92): Loss/seq after 00450 batchs: 1277.5186767578125
INFO:root:Train (Epoch 92): Loss/seq after 00500 batchs: 1261.8056640625
INFO:root:Train (Epoch 92): Loss/seq after 00550 batchs: 1211.258056640625
INFO:root:Train (Epoch 92): Loss/seq after 00600 batchs: 1181.0921630859375
INFO:root:Train (Epoch 92): Loss/seq after 00650 batchs: 1225.251708984375
INFO:root:Train (Epoch 92): Loss/seq after 00700 batchs: 1285.3341064453125
INFO:root:Train (Epoch 92): Loss/seq after 00750 batchs: 1323.2757568359375
INFO:root:Train (Epoch 92): Loss/seq after 00800 batchs: 1301.3553466796875
INFO:root:Train (Epoch 92): Loss/seq after 00850 batchs: 1267.5887451171875
INFO:root:Train (Epoch 92): Loss/seq after 00900 batchs: 1269.963134765625
INFO:root:Train (Epoch 92): Loss/seq after 00950 batchs: 1330.202880859375
INFO:root:Train (Epoch 92): Loss/seq after 01000 batchs: 1325.8668212890625
INFO:root:Train (Epoch 92): Loss/seq after 01050 batchs: 1302.6025390625
INFO:root:Train (Epoch 92): Loss/seq after 01100 batchs: 1293.45751953125
INFO:root:Train (Epoch 92): Loss/seq after 01150 batchs: 1277.048095703125
INFO:root:Train (Epoch 92): Loss/seq after 01200 batchs: 1263.922607421875
INFO:root:Train (Epoch 92): Loss/seq after 01250 batchs: 1256.6373291015625
INFO:root:Train (Epoch 92): Loss/seq after 01300 batchs: 1270.0362548828125
INFO:root:Train (Epoch 92): Loss/seq after 01350 batchs: 1275.109619140625
INFO:root:Train (Epoch 92): Loss/seq after 01400 batchs: 1309.71533203125
INFO:root:Train (Epoch 92): Loss/seq after 01450 batchs: 1296.809814453125
INFO:root:Train (Epoch 92): Loss/seq after 01500 batchs: 1287.0313720703125
INFO:root:Train (Epoch 92): Loss/seq after 01550 batchs: 1282.2152099609375
INFO:root:Train (Epoch 92): Loss/seq after 01600 batchs: 1264.4749755859375
INFO:root:Train (Epoch 92): Loss/seq after 01650 batchs: 1249.2310791015625
INFO:root:Train (Epoch 92): Loss/seq after 01700 batchs: 1240.0482177734375
INFO:root:Train (Epoch 92): Loss/seq after 01750 batchs: 1228.53271484375
INFO:root:Train (Epoch 92): Loss/seq after 01800 batchs: 1214.58740234375
INFO:root:Train (Epoch 92): Loss/seq after 01850 batchs: 1200.1629638671875
INFO:root:Train (Epoch 92): Loss/seq after 01900 batchs: 1194.0462646484375
INFO:root:Train (Epoch 92): Loss/seq after 01950 batchs: 1183.900146484375
INFO:root:Train (Epoch 92): Loss/seq after 02000 batchs: 1175.030517578125
INFO:root:Train (Epoch 92): Loss/seq after 02050 batchs: 1165.636474609375
INFO:root:Train (Epoch 92): Loss/seq after 02100 batchs: 1154.640625
INFO:root:Train (Epoch 92): Loss/seq after 02150 batchs: 1144.2877197265625
INFO:root:Train (Epoch 92): Loss/seq after 02200 batchs: 1133.7886962890625
INFO:root:Train (Epoch 92): Loss/seq after 02250 batchs: 1131.8311767578125
INFO:root:Train (Epoch 92): Loss/seq after 02300 batchs: 1134.523681640625
INFO:root:Train (Epoch 92): Loss/seq after 02350 batchs: 1123.656005859375
INFO:root:Train (Epoch 92): Loss/seq after 02400 batchs: 1119.48974609375
INFO:root:Train (Epoch 92): Loss/seq after 02450 batchs: 1107.850341796875
INFO:root:Train (Epoch 92): Loss/seq after 02500 batchs: 1092.7509765625
INFO:root:Train (Epoch 92): Loss/seq after 02550 batchs: 1081.641845703125
INFO:root:Train (Epoch 92): Loss/seq after 02600 batchs: 1080.08642578125
INFO:root:Train (Epoch 92): Loss/seq after 02650 batchs: 1075.9599609375
INFO:root:Train (Epoch 92): Loss/seq after 02700 batchs: 1072.241943359375
INFO:root:Train (Epoch 92): Loss/seq after 02750 batchs: 1087.5849609375
INFO:root:Train (Epoch 92): Loss/seq after 02800 batchs: 1092.89501953125
INFO:root:Train (Epoch 92): Loss/seq after 02850 batchs: 1087.8094482421875
INFO:root:Train (Epoch 92): Loss/seq after 02900 batchs: 1085.960693359375
INFO:root:Train (Epoch 92): Loss/seq after 02950 batchs: 1078.1585693359375
INFO:root:Train (Epoch 92): Loss/seq after 03000 batchs: 1077.662353515625
INFO:root:Train (Epoch 92): Loss/seq after 03050 batchs: 1081.7125244140625
INFO:root:Train (Epoch 92): Loss/seq after 03100 batchs: 1090.0833740234375
INFO:root:Train (Epoch 92): Loss/seq after 03150 batchs: 1098.470947265625
INFO:root:Train (Epoch 92): Loss/seq after 03200 batchs: 1110.24853515625
INFO:root:Train (Epoch 92): Loss/seq after 03250 batchs: 1118.78125
INFO:root:Train (Epoch 92): Loss/seq after 03300 batchs: 1116.167236328125
INFO:root:Train (Epoch 92): Loss/seq after 03350 batchs: 1115.54443359375
INFO:root:Train (Epoch 92): Loss/seq after 03400 batchs: 1108.3822021484375
INFO:root:Train (Epoch 92): Loss/seq after 03450 batchs: 1101.0902099609375
INFO:root:Train (Epoch 92): Loss/seq after 03500 batchs: 1098.5804443359375
INFO:root:Train (Epoch 92): Loss/seq after 03550 batchs: 1091.5030517578125
INFO:root:Train (Epoch 92): Loss/seq after 03600 batchs: 1096.843017578125
INFO:root:Train (Epoch 92): Loss/seq after 03650 batchs: 1090.6871337890625
INFO:root:Train (Epoch 92): Loss/seq after 03700 batchs: 1089.9598388671875
INFO:root:Train (Epoch 92): Loss/seq after 03750 batchs: 1091.0350341796875
INFO:root:Train (Epoch 92): Loss/seq after 03800 batchs: 1085.2447509765625
INFO:root:Train (Epoch 92): Loss/seq after 03850 batchs: 1081.60107421875
INFO:root:Train (Epoch 92): Loss/seq after 03900 batchs: 1085.761962890625
INFO:root:Train (Epoch 92): Loss/seq after 03950 batchs: 1091.315185546875
INFO:root:Train (Epoch 92): Loss/seq after 04000 batchs: 1083.8402099609375
INFO:root:Train (Epoch 92): Loss/seq after 04050 batchs: 1077.267333984375
INFO:root:Train (Epoch 92): Loss/seq after 04100 batchs: 1071.2684326171875
INFO:root:Train (Epoch 92): Loss/seq after 04150 batchs: 1066.5958251953125
INFO:root:Train (Epoch 92): Loss/seq after 04200 batchs: 1061.0469970703125
INFO:root:Train (Epoch 92): Loss/seq after 04250 batchs: 1057.12353515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 92): Loss/seq after 00000 batches: 870.2800903320312
INFO:root:# Valid (Epoch 92): Loss/seq after 00050 batches: 1086.2642822265625
INFO:root:# Valid (Epoch 92): Loss/seq after 00100 batches: 1366.8621826171875
INFO:root:# Valid (Epoch 92): Loss/seq after 00150 batches: 1082.6419677734375
INFO:root:# Valid (Epoch 92): Loss/seq after 00200 batches: 968.77001953125
INFO:root:Artifacts: Make stick videos for epoch 92
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_92_on_20220423_040848.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_92_index_1803_on_20220423_040848.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 93): Loss/seq after 00000 batchs: 1919.408447265625
INFO:root:Train (Epoch 93): Loss/seq after 00050 batchs: 1454.6231689453125
INFO:root:Train (Epoch 93): Loss/seq after 00100 batchs: 1371.63818359375
INFO:root:Train (Epoch 93): Loss/seq after 00150 batchs: 1200.662353515625
INFO:root:Train (Epoch 93): Loss/seq after 00200 batchs: 1332.986572265625
INFO:root:Train (Epoch 93): Loss/seq after 00250 batchs: 1444.0328369140625
INFO:root:Train (Epoch 93): Loss/seq after 00300 batchs: 1381.5174560546875
INFO:root:Train (Epoch 93): Loss/seq after 00350 batchs: 1292.781005859375
INFO:root:Train (Epoch 93): Loss/seq after 00400 batchs: 1316.5906982421875
INFO:root:Train (Epoch 93): Loss/seq after 00450 batchs: 1265.638671875
INFO:root:Train (Epoch 93): Loss/seq after 00500 batchs: 1250.603271484375
INFO:root:Train (Epoch 93): Loss/seq after 00550 batchs: 1200.8575439453125
INFO:root:Train (Epoch 93): Loss/seq after 00600 batchs: 1170.7320556640625
INFO:root:Train (Epoch 93): Loss/seq after 00650 batchs: 1209.92333984375
INFO:root:Train (Epoch 93): Loss/seq after 00700 batchs: 1259.543212890625
INFO:root:Train (Epoch 93): Loss/seq after 00750 batchs: 1301.1917724609375
INFO:root:Train (Epoch 93): Loss/seq after 00800 batchs: 1279.3946533203125
INFO:root:Train (Epoch 93): Loss/seq after 00850 batchs: 1246.613037109375
INFO:root:Train (Epoch 93): Loss/seq after 00900 batchs: 1250.7470703125
INFO:root:Train (Epoch 93): Loss/seq after 00950 batchs: 1291.2332763671875
INFO:root:Train (Epoch 93): Loss/seq after 01000 batchs: 1286.15673828125
INFO:root:Train (Epoch 93): Loss/seq after 01050 batchs: 1263.0911865234375
INFO:root:Train (Epoch 93): Loss/seq after 01100 batchs: 1255.6619873046875
INFO:root:Train (Epoch 93): Loss/seq after 01150 batchs: 1240.8968505859375
INFO:root:Train (Epoch 93): Loss/seq after 01200 batchs: 1229.3641357421875
INFO:root:Train (Epoch 93): Loss/seq after 01250 batchs: 1221.9189453125
INFO:root:Train (Epoch 93): Loss/seq after 01300 batchs: 1237.4639892578125
INFO:root:Train (Epoch 93): Loss/seq after 01350 batchs: 1243.7437744140625
INFO:root:Train (Epoch 93): Loss/seq after 01400 batchs: 1282.547607421875
INFO:root:Train (Epoch 93): Loss/seq after 01450 batchs: 1270.447509765625
INFO:root:Train (Epoch 93): Loss/seq after 01500 batchs: 1261.512451171875
INFO:root:Train (Epoch 93): Loss/seq after 01550 batchs: 1257.4229736328125
INFO:root:Train (Epoch 93): Loss/seq after 01600 batchs: 1240.50390625
INFO:root:Train (Epoch 93): Loss/seq after 01650 batchs: 1226.2825927734375
INFO:root:Train (Epoch 93): Loss/seq after 01700 batchs: 1217.6761474609375
INFO:root:Train (Epoch 93): Loss/seq after 01750 batchs: 1206.8087158203125
INFO:root:Train (Epoch 93): Loss/seq after 01800 batchs: 1193.2703857421875
INFO:root:Train (Epoch 93): Loss/seq after 01850 batchs: 1179.3466796875
INFO:root:Train (Epoch 93): Loss/seq after 01900 batchs: 1173.83447265625
INFO:root:Train (Epoch 93): Loss/seq after 01950 batchs: 1164.2962646484375
INFO:root:Train (Epoch 93): Loss/seq after 02000 batchs: 1155.8951416015625
INFO:root:Train (Epoch 93): Loss/seq after 02050 batchs: 1147.1376953125
INFO:root:Train (Epoch 93): Loss/seq after 02100 batchs: 1136.6463623046875
INFO:root:Train (Epoch 93): Loss/seq after 02150 batchs: 1126.6434326171875
INFO:root:Train (Epoch 93): Loss/seq after 02200 batchs: 1116.477294921875
INFO:root:Train (Epoch 93): Loss/seq after 02250 batchs: 1114.570556640625
INFO:root:Train (Epoch 93): Loss/seq after 02300 batchs: 1117.6640625
INFO:root:Train (Epoch 93): Loss/seq after 02350 batchs: 1107.165283203125
INFO:root:Train (Epoch 93): Loss/seq after 02400 batchs: 1103.2001953125
INFO:root:Train (Epoch 93): Loss/seq after 02450 batchs: 1091.8768310546875
INFO:root:Train (Epoch 93): Loss/seq after 02500 batchs: 1077.102294921875
INFO:root:Train (Epoch 93): Loss/seq after 02550 batchs: 1066.2176513671875
INFO:root:Train (Epoch 93): Loss/seq after 02600 batchs: 1064.84912109375
INFO:root:Train (Epoch 93): Loss/seq after 02650 batchs: 1060.9483642578125
INFO:root:Train (Epoch 93): Loss/seq after 02700 batchs: 1057.4122314453125
INFO:root:Train (Epoch 93): Loss/seq after 02750 batchs: 1072.3065185546875
INFO:root:Train (Epoch 93): Loss/seq after 02800 batchs: 1077.41552734375
INFO:root:Train (Epoch 93): Loss/seq after 02850 batchs: 1072.6259765625
INFO:root:Train (Epoch 93): Loss/seq after 02900 batchs: 1070.7049560546875
INFO:root:Train (Epoch 93): Loss/seq after 02950 batchs: 1063.238525390625
INFO:root:Train (Epoch 93): Loss/seq after 03000 batchs: 1062.972412109375
INFO:root:Train (Epoch 93): Loss/seq after 03050 batchs: 1067.106201171875
INFO:root:Train (Epoch 93): Loss/seq after 03100 batchs: 1074.4945068359375
INFO:root:Train (Epoch 93): Loss/seq after 03150 batchs: 1086.320556640625
INFO:root:Train (Epoch 93): Loss/seq after 03200 batchs: 1098.074951171875
INFO:root:Train (Epoch 93): Loss/seq after 03250 batchs: 1107.930908203125
INFO:root:Train (Epoch 93): Loss/seq after 03300 batchs: 1105.854736328125
INFO:root:Train (Epoch 93): Loss/seq after 03350 batchs: 1105.465087890625
INFO:root:Train (Epoch 93): Loss/seq after 03400 batchs: 1098.449462890625
INFO:root:Train (Epoch 93): Loss/seq after 03450 batchs: 1091.403564453125
INFO:root:Train (Epoch 93): Loss/seq after 03500 batchs: 1089.0799560546875
INFO:root:Train (Epoch 93): Loss/seq after 03550 batchs: 1082.22021484375
INFO:root:Train (Epoch 93): Loss/seq after 03600 batchs: 1087.7640380859375
INFO:root:Train (Epoch 93): Loss/seq after 03650 batchs: 1081.874755859375
INFO:root:Train (Epoch 93): Loss/seq after 03700 batchs: 1081.293701171875
INFO:root:Train (Epoch 93): Loss/seq after 03750 batchs: 1082.4552001953125
INFO:root:Train (Epoch 93): Loss/seq after 03800 batchs: 1076.768310546875
INFO:root:Train (Epoch 93): Loss/seq after 03850 batchs: 1073.220458984375
INFO:root:Train (Epoch 93): Loss/seq after 03900 batchs: 1077.73779296875
INFO:root:Train (Epoch 93): Loss/seq after 03950 batchs: 1084.3045654296875
INFO:root:Train (Epoch 93): Loss/seq after 04000 batchs: 1076.91845703125
INFO:root:Train (Epoch 93): Loss/seq after 04050 batchs: 1070.4429931640625
INFO:root:Train (Epoch 93): Loss/seq after 04100 batchs: 1064.56103515625
INFO:root:Train (Epoch 93): Loss/seq after 04150 batchs: 1059.990966796875
INFO:root:Train (Epoch 93): Loss/seq after 04200 batchs: 1054.536865234375
INFO:root:Train (Epoch 93): Loss/seq after 04250 batchs: 1050.727783203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 93): Loss/seq after 00000 batches: 870.5706176757812
INFO:root:# Valid (Epoch 93): Loss/seq after 00050 batches: 1083.5858154296875
INFO:root:# Valid (Epoch 93): Loss/seq after 00100 batches: 1363.632568359375
INFO:root:# Valid (Epoch 93): Loss/seq after 00150 batches: 1080.2252197265625
INFO:root:# Valid (Epoch 93): Loss/seq after 00200 batches: 966.2056884765625
INFO:root:Artifacts: Make stick videos for epoch 93
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_93_on_20220423_041344.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_93_index_1580_on_20220423_041344.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 94): Loss/seq after 00000 batchs: 1670.4512939453125
INFO:root:Train (Epoch 94): Loss/seq after 00050 batchs: 1417.137451171875
INFO:root:Train (Epoch 94): Loss/seq after 00100 batchs: 1352.07666015625
INFO:root:Train (Epoch 94): Loss/seq after 00150 batchs: 1188.681640625
INFO:root:Train (Epoch 94): Loss/seq after 00200 batchs: 1303.4267578125
INFO:root:Train (Epoch 94): Loss/seq after 00250 batchs: 1423.7227783203125
INFO:root:Train (Epoch 94): Loss/seq after 00300 batchs: 1364.074951171875
INFO:root:Train (Epoch 94): Loss/seq after 00350 batchs: 1276.793701171875
INFO:root:Train (Epoch 94): Loss/seq after 00400 batchs: 1311.3028564453125
INFO:root:Train (Epoch 94): Loss/seq after 00450 batchs: 1260.6572265625
INFO:root:Train (Epoch 94): Loss/seq after 00500 batchs: 1245.0224609375
INFO:root:Train (Epoch 94): Loss/seq after 00550 batchs: 1196.006103515625
INFO:root:Train (Epoch 94): Loss/seq after 00600 batchs: 1166.1708984375
INFO:root:Train (Epoch 94): Loss/seq after 00650 batchs: 1215.3870849609375
INFO:root:Train (Epoch 94): Loss/seq after 00700 batchs: 1264.2109375
INFO:root:Train (Epoch 94): Loss/seq after 00750 batchs: 1302.6875
INFO:root:Train (Epoch 94): Loss/seq after 00800 batchs: 1281.1458740234375
INFO:root:Train (Epoch 94): Loss/seq after 00850 batchs: 1248.3128662109375
INFO:root:Train (Epoch 94): Loss/seq after 00900 batchs: 1252.23876953125
INFO:root:Train (Epoch 94): Loss/seq after 00950 batchs: 1296.8187255859375
INFO:root:Train (Epoch 94): Loss/seq after 01000 batchs: 1289.4827880859375
INFO:root:Train (Epoch 94): Loss/seq after 01050 batchs: 1264.5430908203125
INFO:root:Train (Epoch 94): Loss/seq after 01100 batchs: 1256.566650390625
INFO:root:Train (Epoch 94): Loss/seq after 01150 batchs: 1241.5789794921875
INFO:root:Train (Epoch 94): Loss/seq after 01200 batchs: 1229.70458984375
INFO:root:Train (Epoch 94): Loss/seq after 01250 batchs: 1221.123046875
INFO:root:Train (Epoch 94): Loss/seq after 01300 batchs: 1230.4901123046875
INFO:root:Train (Epoch 94): Loss/seq after 01350 batchs: 1234.726806640625
INFO:root:Train (Epoch 94): Loss/seq after 01400 batchs: 1267.18994140625
INFO:root:Train (Epoch 94): Loss/seq after 01450 batchs: 1255.625
INFO:root:Train (Epoch 94): Loss/seq after 01500 batchs: 1247.135498046875
INFO:root:Train (Epoch 94): Loss/seq after 01550 batchs: 1243.4822998046875
INFO:root:Train (Epoch 94): Loss/seq after 01600 batchs: 1226.8126220703125
INFO:root:Train (Epoch 94): Loss/seq after 01650 batchs: 1212.875
INFO:root:Train (Epoch 94): Loss/seq after 01700 batchs: 1204.6953125
INFO:root:Train (Epoch 94): Loss/seq after 01750 batchs: 1194.3154296875
INFO:root:Train (Epoch 94): Loss/seq after 01800 batchs: 1181.2545166015625
INFO:root:Train (Epoch 94): Loss/seq after 01850 batchs: 1167.583740234375
INFO:root:Train (Epoch 94): Loss/seq after 01900 batchs: 1162.281005859375
INFO:root:Train (Epoch 94): Loss/seq after 01950 batchs: 1153.072998046875
INFO:root:Train (Epoch 94): Loss/seq after 02000 batchs: 1145.180908203125
INFO:root:Train (Epoch 94): Loss/seq after 02050 batchs: 1136.3916015625
INFO:root:Train (Epoch 94): Loss/seq after 02100 batchs: 1125.90087890625
INFO:root:Train (Epoch 94): Loss/seq after 02150 batchs: 1116.150146484375
INFO:root:Train (Epoch 94): Loss/seq after 02200 batchs: 1106.22265625
INFO:root:Train (Epoch 94): Loss/seq after 02250 batchs: 1104.46826171875
INFO:root:Train (Epoch 94): Loss/seq after 02300 batchs: 1108.02880859375
INFO:root:Train (Epoch 94): Loss/seq after 02350 batchs: 1097.7857666015625
INFO:root:Train (Epoch 94): Loss/seq after 02400 batchs: 1094.0904541015625
INFO:root:Train (Epoch 94): Loss/seq after 02450 batchs: 1082.9990234375
INFO:root:Train (Epoch 94): Loss/seq after 02500 batchs: 1068.383544921875
INFO:root:Train (Epoch 94): Loss/seq after 02550 batchs: 1057.71435546875
INFO:root:Train (Epoch 94): Loss/seq after 02600 batchs: 1056.6334228515625
INFO:root:Train (Epoch 94): Loss/seq after 02650 batchs: 1052.8929443359375
INFO:root:Train (Epoch 94): Loss/seq after 02700 batchs: 1049.2987060546875
INFO:root:Train (Epoch 94): Loss/seq after 02750 batchs: 1064.2567138671875
INFO:root:Train (Epoch 94): Loss/seq after 02800 batchs: 1069.387939453125
INFO:root:Train (Epoch 94): Loss/seq after 02850 batchs: 1064.6009521484375
INFO:root:Train (Epoch 94): Loss/seq after 02900 batchs: 1062.975341796875
INFO:root:Train (Epoch 94): Loss/seq after 02950 batchs: 1055.659912109375
INFO:root:Train (Epoch 94): Loss/seq after 03000 batchs: 1055.494384765625
INFO:root:Train (Epoch 94): Loss/seq after 03050 batchs: 1059.7315673828125
INFO:root:Train (Epoch 94): Loss/seq after 03100 batchs: 1067.6822509765625
INFO:root:Train (Epoch 94): Loss/seq after 03150 batchs: 1078.8612060546875
INFO:root:Train (Epoch 94): Loss/seq after 03200 batchs: 1087.61865234375
INFO:root:Train (Epoch 94): Loss/seq after 03250 batchs: 1096.3836669921875
INFO:root:Train (Epoch 94): Loss/seq after 03300 batchs: 1093.8062744140625
INFO:root:Train (Epoch 94): Loss/seq after 03350 batchs: 1093.862060546875
INFO:root:Train (Epoch 94): Loss/seq after 03400 batchs: 1087.042724609375
INFO:root:Train (Epoch 94): Loss/seq after 03450 batchs: 1080.171142578125
INFO:root:Train (Epoch 94): Loss/seq after 03500 batchs: 1078.111572265625
INFO:root:Train (Epoch 94): Loss/seq after 03550 batchs: 1071.0872802734375
INFO:root:Train (Epoch 94): Loss/seq after 03600 batchs: 1076.67041015625
INFO:root:Train (Epoch 94): Loss/seq after 03650 batchs: 1071.0328369140625
INFO:root:Train (Epoch 94): Loss/seq after 03700 batchs: 1070.6702880859375
INFO:root:Train (Epoch 94): Loss/seq after 03750 batchs: 1072.0087890625
INFO:root:Train (Epoch 94): Loss/seq after 03800 batchs: 1066.4573974609375
INFO:root:Train (Epoch 94): Loss/seq after 03850 batchs: 1063.046630859375
INFO:root:Train (Epoch 94): Loss/seq after 03900 batchs: 1067.435791015625
INFO:root:Train (Epoch 94): Loss/seq after 03950 batchs: 1073.255859375
INFO:root:Train (Epoch 94): Loss/seq after 04000 batchs: 1066.0079345703125
INFO:root:Train (Epoch 94): Loss/seq after 04050 batchs: 1059.6473388671875
INFO:root:Train (Epoch 94): Loss/seq after 04100 batchs: 1053.8671875
INFO:root:Train (Epoch 94): Loss/seq after 04150 batchs: 1049.3992919921875
INFO:root:Train (Epoch 94): Loss/seq after 04200 batchs: 1044.278076171875
INFO:root:Train (Epoch 94): Loss/seq after 04250 batchs: 1040.630615234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 94): Loss/seq after 00000 batches: 875.157958984375
INFO:root:# Valid (Epoch 94): Loss/seq after 00050 batches: 1086.3330078125
INFO:root:# Valid (Epoch 94): Loss/seq after 00100 batches: 1359.758056640625
INFO:root:# Valid (Epoch 94): Loss/seq after 00150 batches: 1077.379638671875
INFO:root:# Valid (Epoch 94): Loss/seq after 00200 batches: 964.4600219726562
INFO:root:Artifacts: Make stick videos for epoch 94
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_94_on_20220423_041846.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_94_index_1482_on_20220423_041846.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 95): Loss/seq after 00000 batchs: 2287.521484375
INFO:root:Train (Epoch 95): Loss/seq after 00050 batchs: 1430.6002197265625
INFO:root:Train (Epoch 95): Loss/seq after 00100 batchs: 1338.177734375
INFO:root:Train (Epoch 95): Loss/seq after 00150 batchs: 1180.148681640625
INFO:root:Train (Epoch 95): Loss/seq after 00200 batchs: 1281.672119140625
INFO:root:Train (Epoch 95): Loss/seq after 00250 batchs: 1405.23974609375
INFO:root:Train (Epoch 95): Loss/seq after 00300 batchs: 1348.8223876953125
INFO:root:Train (Epoch 95): Loss/seq after 00350 batchs: 1264.0977783203125
INFO:root:Train (Epoch 95): Loss/seq after 00400 batchs: 1296.5926513671875
INFO:root:Train (Epoch 95): Loss/seq after 00450 batchs: 1247.65771484375
INFO:root:Train (Epoch 95): Loss/seq after 00500 batchs: 1230.53759765625
INFO:root:Train (Epoch 95): Loss/seq after 00550 batchs: 1182.6748046875
INFO:root:Train (Epoch 95): Loss/seq after 00600 batchs: 1153.93505859375
INFO:root:Train (Epoch 95): Loss/seq after 00650 batchs: 1194.6466064453125
INFO:root:Train (Epoch 95): Loss/seq after 00700 batchs: 1236.9383544921875
INFO:root:Train (Epoch 95): Loss/seq after 00750 batchs: 1278.10302734375
INFO:root:Train (Epoch 95): Loss/seq after 00800 batchs: 1259.236572265625
INFO:root:Train (Epoch 95): Loss/seq after 00850 batchs: 1228.0977783203125
INFO:root:Train (Epoch 95): Loss/seq after 00900 batchs: 1232.4278564453125
INFO:root:Train (Epoch 95): Loss/seq after 00950 batchs: 1274.4373779296875
INFO:root:Train (Epoch 95): Loss/seq after 01000 batchs: 1277.3331298828125
INFO:root:Train (Epoch 95): Loss/seq after 01050 batchs: 1253.7587890625
INFO:root:Train (Epoch 95): Loss/seq after 01100 batchs: 1245.7125244140625
INFO:root:Train (Epoch 95): Loss/seq after 01150 batchs: 1231.9012451171875
INFO:root:Train (Epoch 95): Loss/seq after 01200 batchs: 1220.474853515625
INFO:root:Train (Epoch 95): Loss/seq after 01250 batchs: 1213.31005859375
INFO:root:Train (Epoch 95): Loss/seq after 01300 batchs: 1226.26708984375
INFO:root:Train (Epoch 95): Loss/seq after 01350 batchs: 1229.5819091796875
INFO:root:Train (Epoch 95): Loss/seq after 01400 batchs: 1260.477783203125
INFO:root:Train (Epoch 95): Loss/seq after 01450 batchs: 1249.1881103515625
INFO:root:Train (Epoch 95): Loss/seq after 01500 batchs: 1240.8807373046875
INFO:root:Train (Epoch 95): Loss/seq after 01550 batchs: 1237.5789794921875
INFO:root:Train (Epoch 95): Loss/seq after 01600 batchs: 1221.1171875
INFO:root:Train (Epoch 95): Loss/seq after 01650 batchs: 1207.4432373046875
INFO:root:Train (Epoch 95): Loss/seq after 01700 batchs: 1199.6929931640625
INFO:root:Train (Epoch 95): Loss/seq after 01750 batchs: 1189.9022216796875
INFO:root:Train (Epoch 95): Loss/seq after 01800 batchs: 1177.0274658203125
INFO:root:Train (Epoch 95): Loss/seq after 01850 batchs: 1163.6512451171875
INFO:root:Train (Epoch 95): Loss/seq after 01900 batchs: 1158.37451171875
INFO:root:Train (Epoch 95): Loss/seq after 01950 batchs: 1149.050048828125
INFO:root:Train (Epoch 95): Loss/seq after 02000 batchs: 1140.9110107421875
INFO:root:Train (Epoch 95): Loss/seq after 02050 batchs: 1132.2376708984375
INFO:root:Train (Epoch 95): Loss/seq after 02100 batchs: 1122.096923828125
INFO:root:Train (Epoch 95): Loss/seq after 02150 batchs: 1112.37109375
INFO:root:Train (Epoch 95): Loss/seq after 02200 batchs: 1102.5550537109375
INFO:root:Train (Epoch 95): Loss/seq after 02250 batchs: 1101.5771484375
INFO:root:Train (Epoch 95): Loss/seq after 02300 batchs: 1105.391357421875
INFO:root:Train (Epoch 95): Loss/seq after 02350 batchs: 1095.3577880859375
INFO:root:Train (Epoch 95): Loss/seq after 02400 batchs: 1091.572998046875
INFO:root:Train (Epoch 95): Loss/seq after 02450 batchs: 1080.4232177734375
INFO:root:Train (Epoch 95): Loss/seq after 02500 batchs: 1065.8597412109375
INFO:root:Train (Epoch 95): Loss/seq after 02550 batchs: 1055.10888671875
INFO:root:Train (Epoch 95): Loss/seq after 02600 batchs: 1053.9659423828125
INFO:root:Train (Epoch 95): Loss/seq after 02650 batchs: 1050.2772216796875
INFO:root:Train (Epoch 95): Loss/seq after 02700 batchs: 1047.0869140625
INFO:root:Train (Epoch 95): Loss/seq after 02750 batchs: 1063.2318115234375
INFO:root:Train (Epoch 95): Loss/seq after 02800 batchs: 1068.4698486328125
INFO:root:Train (Epoch 95): Loss/seq after 02850 batchs: 1063.72998046875
INFO:root:Train (Epoch 95): Loss/seq after 02900 batchs: 1062.091796875
INFO:root:Train (Epoch 95): Loss/seq after 02950 batchs: 1054.7440185546875
INFO:root:Train (Epoch 95): Loss/seq after 03000 batchs: 1054.6085205078125
INFO:root:Train (Epoch 95): Loss/seq after 03050 batchs: 1058.857177734375
INFO:root:Train (Epoch 95): Loss/seq after 03100 batchs: 1065.3525390625
INFO:root:Train (Epoch 95): Loss/seq after 03150 batchs: 1073.68505859375
INFO:root:Train (Epoch 95): Loss/seq after 03200 batchs: 1082.521240234375
INFO:root:Train (Epoch 95): Loss/seq after 03250 batchs: 1091.2857666015625
INFO:root:Train (Epoch 95): Loss/seq after 03300 batchs: 1089.3770751953125
INFO:root:Train (Epoch 95): Loss/seq after 03350 batchs: 1089.1727294921875
INFO:root:Train (Epoch 95): Loss/seq after 03400 batchs: 1082.4327392578125
INFO:root:Train (Epoch 95): Loss/seq after 03450 batchs: 1075.728759765625
INFO:root:Train (Epoch 95): Loss/seq after 03500 batchs: 1074.1068115234375
INFO:root:Train (Epoch 95): Loss/seq after 03550 batchs: 1067.1224365234375
INFO:root:Train (Epoch 95): Loss/seq after 03600 batchs: 1072.400634765625
INFO:root:Train (Epoch 95): Loss/seq after 03650 batchs: 1066.4224853515625
INFO:root:Train (Epoch 95): Loss/seq after 03700 batchs: 1066.0172119140625
INFO:root:Train (Epoch 95): Loss/seq after 03750 batchs: 1067.333740234375
INFO:root:Train (Epoch 95): Loss/seq after 03800 batchs: 1061.84912109375
INFO:root:Train (Epoch 95): Loss/seq after 03850 batchs: 1058.48388671875
INFO:root:Train (Epoch 95): Loss/seq after 03900 batchs: 1063.4091796875
INFO:root:Train (Epoch 95): Loss/seq after 03950 batchs: 1068.42236328125
INFO:root:Train (Epoch 95): Loss/seq after 04000 batchs: 1061.22998046875
INFO:root:Train (Epoch 95): Loss/seq after 04050 batchs: 1054.9326171875
INFO:root:Train (Epoch 95): Loss/seq after 04100 batchs: 1049.224609375
INFO:root:Train (Epoch 95): Loss/seq after 04150 batchs: 1044.7769775390625
INFO:root:Train (Epoch 95): Loss/seq after 04200 batchs: 1039.315673828125
INFO:root:Train (Epoch 95): Loss/seq after 04250 batchs: 1035.5916748046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 95): Loss/seq after 00000 batches: 866.19580078125
INFO:root:# Valid (Epoch 95): Loss/seq after 00050 batches: 1085.4097900390625
INFO:root:# Valid (Epoch 95): Loss/seq after 00100 batches: 1360.1875
INFO:root:# Valid (Epoch 95): Loss/seq after 00150 batches: 1078.279541015625
INFO:root:# Valid (Epoch 95): Loss/seq after 00200 batches: 965.667236328125
INFO:root:Artifacts: Make stick videos for epoch 95
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_95_on_20220423_042348.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_95_index_350_on_20220423_042348.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 96): Loss/seq after 00000 batchs: 2090.51318359375
INFO:root:Train (Epoch 96): Loss/seq after 00050 batchs: 1385.1612548828125
INFO:root:Train (Epoch 96): Loss/seq after 00100 batchs: 1315.5284423828125
INFO:root:Train (Epoch 96): Loss/seq after 00150 batchs: 1159.4522705078125
INFO:root:Train (Epoch 96): Loss/seq after 00200 batchs: 1270.31103515625
INFO:root:Train (Epoch 96): Loss/seq after 00250 batchs: 1393.186279296875
INFO:root:Train (Epoch 96): Loss/seq after 00300 batchs: 1339.1983642578125
INFO:root:Train (Epoch 96): Loss/seq after 00350 batchs: 1255.8021240234375
INFO:root:Train (Epoch 96): Loss/seq after 00400 batchs: 1287.4254150390625
INFO:root:Train (Epoch 96): Loss/seq after 00450 batchs: 1239.9129638671875
INFO:root:Train (Epoch 96): Loss/seq after 00500 batchs: 1224.56396484375
INFO:root:Train (Epoch 96): Loss/seq after 00550 batchs: 1177.2508544921875
INFO:root:Train (Epoch 96): Loss/seq after 00600 batchs: 1148.6951904296875
INFO:root:Train (Epoch 96): Loss/seq after 00650 batchs: 1185.012939453125
INFO:root:Train (Epoch 96): Loss/seq after 00700 batchs: 1238.0428466796875
INFO:root:Train (Epoch 96): Loss/seq after 00750 batchs: 1274.1131591796875
INFO:root:Train (Epoch 96): Loss/seq after 00800 batchs: 1254.8565673828125
INFO:root:Train (Epoch 96): Loss/seq after 00850 batchs: 1223.6473388671875
INFO:root:Train (Epoch 96): Loss/seq after 00900 batchs: 1228.5665283203125
INFO:root:Train (Epoch 96): Loss/seq after 00950 batchs: 1267.777587890625
INFO:root:Train (Epoch 96): Loss/seq after 01000 batchs: 1261.8572998046875
INFO:root:Train (Epoch 96): Loss/seq after 01050 batchs: 1237.928955078125
INFO:root:Train (Epoch 96): Loss/seq after 01100 batchs: 1229.9744873046875
INFO:root:Train (Epoch 96): Loss/seq after 01150 batchs: 1216.1859130859375
INFO:root:Train (Epoch 96): Loss/seq after 01200 batchs: 1205.1456298828125
INFO:root:Train (Epoch 96): Loss/seq after 01250 batchs: 1196.9656982421875
INFO:root:Train (Epoch 96): Loss/seq after 01300 batchs: 1207.070068359375
INFO:root:Train (Epoch 96): Loss/seq after 01350 batchs: 1207.6195068359375
INFO:root:Train (Epoch 96): Loss/seq after 01400 batchs: 1233.42138671875
INFO:root:Train (Epoch 96): Loss/seq after 01450 batchs: 1222.903076171875
INFO:root:Train (Epoch 96): Loss/seq after 01500 batchs: 1215.4287109375
INFO:root:Train (Epoch 96): Loss/seq after 01550 batchs: 1212.8643798828125
INFO:root:Train (Epoch 96): Loss/seq after 01600 batchs: 1197.2413330078125
INFO:root:Train (Epoch 96): Loss/seq after 01650 batchs: 1184.18212890625
INFO:root:Train (Epoch 96): Loss/seq after 01700 batchs: 1176.9305419921875
INFO:root:Train (Epoch 96): Loss/seq after 01750 batchs: 1167.3331298828125
INFO:root:Train (Epoch 96): Loss/seq after 01800 batchs: 1154.9189453125
INFO:root:Train (Epoch 96): Loss/seq after 01850 batchs: 1141.974365234375
INFO:root:Train (Epoch 96): Loss/seq after 01900 batchs: 1137.280517578125
INFO:root:Train (Epoch 96): Loss/seq after 01950 batchs: 1128.474609375
INFO:root:Train (Epoch 96): Loss/seq after 02000 batchs: 1120.883056640625
INFO:root:Train (Epoch 96): Loss/seq after 02050 batchs: 1112.6754150390625
INFO:root:Train (Epoch 96): Loss/seq after 02100 batchs: 1102.946533203125
INFO:root:Train (Epoch 96): Loss/seq after 02150 batchs: 1093.78076171875
INFO:root:Train (Epoch 96): Loss/seq after 02200 batchs: 1084.3524169921875
INFO:root:Train (Epoch 96): Loss/seq after 02250 batchs: 1082.9259033203125
INFO:root:Train (Epoch 96): Loss/seq after 02300 batchs: 1086.7833251953125
INFO:root:Train (Epoch 96): Loss/seq after 02350 batchs: 1076.924072265625
INFO:root:Train (Epoch 96): Loss/seq after 02400 batchs: 1073.640380859375
INFO:root:Train (Epoch 96): Loss/seq after 02450 batchs: 1062.9571533203125
INFO:root:Train (Epoch 96): Loss/seq after 02500 batchs: 1048.747314453125
INFO:root:Train (Epoch 96): Loss/seq after 02550 batchs: 1038.4571533203125
INFO:root:Train (Epoch 96): Loss/seq after 02600 batchs: 1037.633544921875
INFO:root:Train (Epoch 96): Loss/seq after 02650 batchs: 1034.2987060546875
INFO:root:Train (Epoch 96): Loss/seq after 02700 batchs: 1031.9603271484375
INFO:root:Train (Epoch 96): Loss/seq after 02750 batchs: 1047.466796875
INFO:root:Train (Epoch 96): Loss/seq after 02800 batchs: 1052.21142578125
INFO:root:Train (Epoch 96): Loss/seq after 02850 batchs: 1047.61865234375
INFO:root:Train (Epoch 96): Loss/seq after 02900 batchs: 1046.2257080078125
INFO:root:Train (Epoch 96): Loss/seq after 02950 batchs: 1039.181884765625
INFO:root:Train (Epoch 96): Loss/seq after 03000 batchs: 1039.297119140625
INFO:root:Train (Epoch 96): Loss/seq after 03050 batchs: 1043.796875
INFO:root:Train (Epoch 96): Loss/seq after 03100 batchs: 1051.0560302734375
INFO:root:Train (Epoch 96): Loss/seq after 03150 batchs: 1060.5830078125
INFO:root:Train (Epoch 96): Loss/seq after 03200 batchs: 1068.8934326171875
INFO:root:Train (Epoch 96): Loss/seq after 03250 batchs: 1075.9278564453125
INFO:root:Train (Epoch 96): Loss/seq after 03300 batchs: 1073.40185546875
INFO:root:Train (Epoch 96): Loss/seq after 03350 batchs: 1072.7884521484375
INFO:root:Train (Epoch 96): Loss/seq after 03400 batchs: 1066.2613525390625
INFO:root:Train (Epoch 96): Loss/seq after 03450 batchs: 1059.591552734375
INFO:root:Train (Epoch 96): Loss/seq after 03500 batchs: 1057.655029296875
INFO:root:Train (Epoch 96): Loss/seq after 03550 batchs: 1050.886474609375
INFO:root:Train (Epoch 96): Loss/seq after 03600 batchs: 1056.54541015625
INFO:root:Train (Epoch 96): Loss/seq after 03650 batchs: 1051.16064453125
INFO:root:Train (Epoch 96): Loss/seq after 03700 batchs: 1051.03857421875
INFO:root:Train (Epoch 96): Loss/seq after 03750 batchs: 1052.6414794921875
INFO:root:Train (Epoch 96): Loss/seq after 03800 batchs: 1047.32568359375
INFO:root:Train (Epoch 96): Loss/seq after 03850 batchs: 1044.101806640625
INFO:root:Train (Epoch 96): Loss/seq after 03900 batchs: 1049.466796875
INFO:root:Train (Epoch 96): Loss/seq after 03950 batchs: 1055.1829833984375
INFO:root:Train (Epoch 96): Loss/seq after 04000 batchs: 1048.1556396484375
INFO:root:Train (Epoch 96): Loss/seq after 04050 batchs: 1042.0035400390625
INFO:root:Train (Epoch 96): Loss/seq after 04100 batchs: 1036.436279296875
INFO:root:Train (Epoch 96): Loss/seq after 04150 batchs: 1032.1173095703125
INFO:root:Train (Epoch 96): Loss/seq after 04200 batchs: 1026.9154052734375
INFO:root:Train (Epoch 96): Loss/seq after 04250 batchs: 1023.3228759765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 96): Loss/seq after 00000 batches: 871.9822387695312
INFO:root:# Valid (Epoch 96): Loss/seq after 00050 batches: 1086.2950439453125
INFO:root:# Valid (Epoch 96): Loss/seq after 00100 batches: 1367.8853759765625
INFO:root:# Valid (Epoch 96): Loss/seq after 00150 batches: 1082.969970703125
INFO:root:# Valid (Epoch 96): Loss/seq after 00200 batches: 968.9082641601562
INFO:root:Artifacts: Make stick videos for epoch 96
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_96_on_20220423_042831.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_96_index_1787_on_20220423_042831.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 97): Loss/seq after 00000 batchs: 1523.092041015625
INFO:root:Train (Epoch 97): Loss/seq after 00050 batchs: 1379.3741455078125
INFO:root:Train (Epoch 97): Loss/seq after 00100 batchs: 1312.6337890625
INFO:root:Train (Epoch 97): Loss/seq after 00150 batchs: 1157.7080078125
INFO:root:Train (Epoch 97): Loss/seq after 00200 batchs: 1273.109130859375
INFO:root:Train (Epoch 97): Loss/seq after 00250 batchs: 1386.390380859375
INFO:root:Train (Epoch 97): Loss/seq after 00300 batchs: 1332.533447265625
INFO:root:Train (Epoch 97): Loss/seq after 00350 batchs: 1250.31640625
INFO:root:Train (Epoch 97): Loss/seq after 00400 batchs: 1277.3885498046875
INFO:root:Train (Epoch 97): Loss/seq after 00450 batchs: 1230.4832763671875
INFO:root:Train (Epoch 97): Loss/seq after 00500 batchs: 1216.23193359375
INFO:root:Train (Epoch 97): Loss/seq after 00550 batchs: 1169.9449462890625
INFO:root:Train (Epoch 97): Loss/seq after 00600 batchs: 1142.9552001953125
INFO:root:Train (Epoch 97): Loss/seq after 00650 batchs: 1174.244384765625
INFO:root:Train (Epoch 97): Loss/seq after 00700 batchs: 1209.761962890625
INFO:root:Train (Epoch 97): Loss/seq after 00750 batchs: 1246.4503173828125
INFO:root:Train (Epoch 97): Loss/seq after 00800 batchs: 1229.63330078125
INFO:root:Train (Epoch 97): Loss/seq after 00850 batchs: 1200.125
INFO:root:Train (Epoch 97): Loss/seq after 00900 batchs: 1206.2738037109375
INFO:root:Train (Epoch 97): Loss/seq after 00950 batchs: 1243.21435546875
INFO:root:Train (Epoch 97): Loss/seq after 01000 batchs: 1239.3092041015625
INFO:root:Train (Epoch 97): Loss/seq after 01050 batchs: 1219.5799560546875
INFO:root:Train (Epoch 97): Loss/seq after 01100 batchs: 1213.2169189453125
INFO:root:Train (Epoch 97): Loss/seq after 01150 batchs: 1200.104736328125
INFO:root:Train (Epoch 97): Loss/seq after 01200 batchs: 1189.7337646484375
INFO:root:Train (Epoch 97): Loss/seq after 01250 batchs: 1182.689453125
INFO:root:Train (Epoch 97): Loss/seq after 01300 batchs: 1191.5830078125
INFO:root:Train (Epoch 97): Loss/seq after 01350 batchs: 1195.0767822265625
INFO:root:Train (Epoch 97): Loss/seq after 01400 batchs: 1226.8575439453125
INFO:root:Train (Epoch 97): Loss/seq after 01450 batchs: 1216.8216552734375
INFO:root:Train (Epoch 97): Loss/seq after 01500 batchs: 1209.5057373046875
INFO:root:Train (Epoch 97): Loss/seq after 01550 batchs: 1207.5234375
INFO:root:Train (Epoch 97): Loss/seq after 01600 batchs: 1192.0628662109375
INFO:root:Train (Epoch 97): Loss/seq after 01650 batchs: 1179.515869140625
INFO:root:Train (Epoch 97): Loss/seq after 01700 batchs: 1172.590576171875
INFO:root:Train (Epoch 97): Loss/seq after 01750 batchs: 1163.7041015625
INFO:root:Train (Epoch 97): Loss/seq after 01800 batchs: 1151.72216796875
INFO:root:Train (Epoch 97): Loss/seq after 01850 batchs: 1139.0189208984375
INFO:root:Train (Epoch 97): Loss/seq after 01900 batchs: 1134.788330078125
INFO:root:Train (Epoch 97): Loss/seq after 01950 batchs: 1127.1512451171875
INFO:root:Train (Epoch 97): Loss/seq after 02000 batchs: 1119.565673828125
INFO:root:Train (Epoch 97): Loss/seq after 02050 batchs: 1111.7484130859375
INFO:root:Train (Epoch 97): Loss/seq after 02100 batchs: 1101.8564453125
INFO:root:Train (Epoch 97): Loss/seq after 02150 batchs: 1092.5474853515625
INFO:root:Train (Epoch 97): Loss/seq after 02200 batchs: 1083.103271484375
INFO:root:Train (Epoch 97): Loss/seq after 02250 batchs: 1082.1357421875
INFO:root:Train (Epoch 97): Loss/seq after 02300 batchs: 1086.3839111328125
INFO:root:Train (Epoch 97): Loss/seq after 02350 batchs: 1076.6083984375
INFO:root:Train (Epoch 97): Loss/seq after 02400 batchs: 1073.311279296875
INFO:root:Train (Epoch 97): Loss/seq after 02450 batchs: 1062.5821533203125
INFO:root:Train (Epoch 97): Loss/seq after 02500 batchs: 1048.3687744140625
INFO:root:Train (Epoch 97): Loss/seq after 02550 batchs: 1038.116455078125
INFO:root:Train (Epoch 97): Loss/seq after 02600 batchs: 1037.377685546875
INFO:root:Train (Epoch 97): Loss/seq after 02650 batchs: 1034.02880859375
INFO:root:Train (Epoch 97): Loss/seq after 02700 batchs: 1031.28466796875
INFO:root:Train (Epoch 97): Loss/seq after 02750 batchs: 1048.2808837890625
INFO:root:Train (Epoch 97): Loss/seq after 02800 batchs: 1053.504150390625
INFO:root:Train (Epoch 97): Loss/seq after 02850 batchs: 1048.9869384765625
INFO:root:Train (Epoch 97): Loss/seq after 02900 batchs: 1047.2752685546875
INFO:root:Train (Epoch 97): Loss/seq after 02950 batchs: 1040.1634521484375
INFO:root:Train (Epoch 97): Loss/seq after 03000 batchs: 1040.2215576171875
INFO:root:Train (Epoch 97): Loss/seq after 03050 batchs: 1044.7686767578125
INFO:root:Train (Epoch 97): Loss/seq after 03100 batchs: 1051.614990234375
INFO:root:Train (Epoch 97): Loss/seq after 03150 batchs: 1060.47314453125
INFO:root:Train (Epoch 97): Loss/seq after 03200 batchs: 1070.4892578125
INFO:root:Train (Epoch 97): Loss/seq after 03250 batchs: 1079.052490234375
INFO:root:Train (Epoch 97): Loss/seq after 03300 batchs: 1077.3350830078125
INFO:root:Train (Epoch 97): Loss/seq after 03350 batchs: 1076.806640625
INFO:root:Train (Epoch 97): Loss/seq after 03400 batchs: 1070.207275390625
INFO:root:Train (Epoch 97): Loss/seq after 03450 batchs: 1063.52978515625
INFO:root:Train (Epoch 97): Loss/seq after 03500 batchs: 1061.826416015625
INFO:root:Train (Epoch 97): Loss/seq after 03550 batchs: 1055.1168212890625
INFO:root:Train (Epoch 97): Loss/seq after 03600 batchs: 1060.619384765625
INFO:root:Train (Epoch 97): Loss/seq after 03650 batchs: 1054.80908203125
INFO:root:Train (Epoch 97): Loss/seq after 03700 batchs: 1054.4205322265625
INFO:root:Train (Epoch 97): Loss/seq after 03750 batchs: 1055.891845703125
INFO:root:Train (Epoch 97): Loss/seq after 03800 batchs: 1050.5267333984375
INFO:root:Train (Epoch 97): Loss/seq after 03850 batchs: 1047.2532958984375
INFO:root:Train (Epoch 97): Loss/seq after 03900 batchs: 1051.4571533203125
INFO:root:Train (Epoch 97): Loss/seq after 03950 batchs: 1056.818359375
INFO:root:Train (Epoch 97): Loss/seq after 04000 batchs: 1049.7698974609375
INFO:root:Train (Epoch 97): Loss/seq after 04050 batchs: 1043.612548828125
INFO:root:Train (Epoch 97): Loss/seq after 04100 batchs: 1037.9774169921875
INFO:root:Train (Epoch 97): Loss/seq after 04150 batchs: 1033.6549072265625
INFO:root:Train (Epoch 97): Loss/seq after 04200 batchs: 1028.4383544921875
INFO:root:Train (Epoch 97): Loss/seq after 04250 batchs: 1024.8433837890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 97): Loss/seq after 00000 batches: 869.3952026367188
INFO:root:# Valid (Epoch 97): Loss/seq after 00050 batches: 1090.1099853515625
INFO:root:# Valid (Epoch 97): Loss/seq after 00100 batches: 1370.38427734375
INFO:root:# Valid (Epoch 97): Loss/seq after 00150 batches: 1083.4266357421875
INFO:root:# Valid (Epoch 97): Loss/seq after 00200 batches: 969.826416015625
INFO:root:Artifacts: Make stick videos for epoch 97
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_97_on_20220423_043316.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_97_index_967_on_20220423_043316.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 98): Loss/seq after 00000 batchs: 1623.3944091796875
INFO:root:Train (Epoch 98): Loss/seq after 00050 batchs: 1358.32080078125
INFO:root:Train (Epoch 98): Loss/seq after 00100 batchs: 1281.2847900390625
INFO:root:Train (Epoch 98): Loss/seq after 00150 batchs: 1131.4217529296875
INFO:root:Train (Epoch 98): Loss/seq after 00200 batchs: 1257.916748046875
INFO:root:Train (Epoch 98): Loss/seq after 00250 batchs: 1374.3385009765625
INFO:root:Train (Epoch 98): Loss/seq after 00300 batchs: 1322.3297119140625
INFO:root:Train (Epoch 98): Loss/seq after 00350 batchs: 1241.75390625
INFO:root:Train (Epoch 98): Loss/seq after 00400 batchs: 1270.3778076171875
INFO:root:Train (Epoch 98): Loss/seq after 00450 batchs: 1224.1192626953125
INFO:root:Train (Epoch 98): Loss/seq after 00500 batchs: 1206.5072021484375
INFO:root:Train (Epoch 98): Loss/seq after 00550 batchs: 1160.4300537109375
INFO:root:Train (Epoch 98): Loss/seq after 00600 batchs: 1132.9146728515625
INFO:root:Train (Epoch 98): Loss/seq after 00650 batchs: 1161.3675537109375
INFO:root:Train (Epoch 98): Loss/seq after 00700 batchs: 1176.0350341796875
INFO:root:Train (Epoch 98): Loss/seq after 00750 batchs: 1217.897216796875
INFO:root:Train (Epoch 98): Loss/seq after 00800 batchs: 1201.5540771484375
INFO:root:Train (Epoch 98): Loss/seq after 00850 batchs: 1173.306884765625
INFO:root:Train (Epoch 98): Loss/seq after 00900 batchs: 1181.403076171875
INFO:root:Train (Epoch 98): Loss/seq after 00950 batchs: 1214.713134765625
INFO:root:Train (Epoch 98): Loss/seq after 01000 batchs: 1208.009521484375
INFO:root:Train (Epoch 98): Loss/seq after 01050 batchs: 1187.94091796875
INFO:root:Train (Epoch 98): Loss/seq after 01100 batchs: 1183.0743408203125
INFO:root:Train (Epoch 98): Loss/seq after 01150 batchs: 1171.3734130859375
INFO:root:Train (Epoch 98): Loss/seq after 01200 batchs: 1162.191650390625
INFO:root:Train (Epoch 98): Loss/seq after 01250 batchs: 1156.777099609375
INFO:root:Train (Epoch 98): Loss/seq after 01300 batchs: 1167.599853515625
INFO:root:Train (Epoch 98): Loss/seq after 01350 batchs: 1171.2982177734375
INFO:root:Train (Epoch 98): Loss/seq after 01400 batchs: 1201.631103515625
INFO:root:Train (Epoch 98): Loss/seq after 01450 batchs: 1192.373779296875
INFO:root:Train (Epoch 98): Loss/seq after 01500 batchs: 1185.8526611328125
INFO:root:Train (Epoch 98): Loss/seq after 01550 batchs: 1183.96826171875
INFO:root:Train (Epoch 98): Loss/seq after 01600 batchs: 1169.4140625
INFO:root:Train (Epoch 98): Loss/seq after 01650 batchs: 1157.374755859375
INFO:root:Train (Epoch 98): Loss/seq after 01700 batchs: 1150.650390625
INFO:root:Train (Epoch 98): Loss/seq after 01750 batchs: 1141.6575927734375
INFO:root:Train (Epoch 98): Loss/seq after 01800 batchs: 1129.9765625
INFO:root:Train (Epoch 98): Loss/seq after 01850 batchs: 1117.6016845703125
INFO:root:Train (Epoch 98): Loss/seq after 01900 batchs: 1113.365234375
INFO:root:Train (Epoch 98): Loss/seq after 01950 batchs: 1105.3321533203125
INFO:root:Train (Epoch 98): Loss/seq after 02000 batchs: 1098.230224609375
INFO:root:Train (Epoch 98): Loss/seq after 02050 batchs: 1090.8232421875
INFO:root:Train (Epoch 98): Loss/seq after 02100 batchs: 1081.6700439453125
INFO:root:Train (Epoch 98): Loss/seq after 02150 batchs: 1072.7799072265625
INFO:root:Train (Epoch 98): Loss/seq after 02200 batchs: 1063.7867431640625
INFO:root:Train (Epoch 98): Loss/seq after 02250 batchs: 1062.5479736328125
INFO:root:Train (Epoch 98): Loss/seq after 02300 batchs: 1067.705322265625
INFO:root:Train (Epoch 98): Loss/seq after 02350 batchs: 1058.2330322265625
INFO:root:Train (Epoch 98): Loss/seq after 02400 batchs: 1055.207275390625
INFO:root:Train (Epoch 98): Loss/seq after 02450 batchs: 1044.81640625
INFO:root:Train (Epoch 98): Loss/seq after 02500 batchs: 1030.963623046875
INFO:root:Train (Epoch 98): Loss/seq after 02550 batchs: 1021.103271484375
INFO:root:Train (Epoch 98): Loss/seq after 02600 batchs: 1020.6619262695312
INFO:root:Train (Epoch 98): Loss/seq after 02650 batchs: 1017.6065673828125
INFO:root:Train (Epoch 98): Loss/seq after 02700 batchs: 1015.300048828125
INFO:root:Train (Epoch 98): Loss/seq after 02750 batchs: 1030.67626953125
INFO:root:Train (Epoch 98): Loss/seq after 02800 batchs: 1035.7691650390625
INFO:root:Train (Epoch 98): Loss/seq after 02850 batchs: 1031.509765625
INFO:root:Train (Epoch 98): Loss/seq after 02900 batchs: 1029.9993896484375
INFO:root:Train (Epoch 98): Loss/seq after 02950 batchs: 1023.1583251953125
INFO:root:Train (Epoch 98): Loss/seq after 03000 batchs: 1023.4782104492188
INFO:root:Train (Epoch 98): Loss/seq after 03050 batchs: 1026.8282470703125
INFO:root:Train (Epoch 98): Loss/seq after 03100 batchs: 1033.1424560546875
INFO:root:Train (Epoch 98): Loss/seq after 03150 batchs: 1040.9339599609375
INFO:root:Train (Epoch 98): Loss/seq after 03200 batchs: 1048.563720703125
INFO:root:Train (Epoch 98): Loss/seq after 03250 batchs: 1052.853515625
INFO:root:Train (Epoch 98): Loss/seq after 03300 batchs: 1050.9742431640625
INFO:root:Train (Epoch 98): Loss/seq after 03350 batchs: 1050.8204345703125
INFO:root:Train (Epoch 98): Loss/seq after 03400 batchs: 1044.624755859375
INFO:root:Train (Epoch 98): Loss/seq after 03450 batchs: 1038.356689453125
INFO:root:Train (Epoch 98): Loss/seq after 03500 batchs: 1036.17724609375
INFO:root:Train (Epoch 98): Loss/seq after 03550 batchs: 1029.820068359375
INFO:root:Train (Epoch 98): Loss/seq after 03600 batchs: 1036.2274169921875
INFO:root:Train (Epoch 98): Loss/seq after 03650 batchs: 1031.0274658203125
INFO:root:Train (Epoch 98): Loss/seq after 03700 batchs: 1031.1829833984375
INFO:root:Train (Epoch 98): Loss/seq after 03750 batchs: 1033.05712890625
INFO:root:Train (Epoch 98): Loss/seq after 03800 batchs: 1028.0225830078125
INFO:root:Train (Epoch 98): Loss/seq after 03850 batchs: 1025.1048583984375
INFO:root:Train (Epoch 98): Loss/seq after 03900 batchs: 1028.563720703125
INFO:root:Train (Epoch 98): Loss/seq after 03950 batchs: 1033.4915771484375
INFO:root:Train (Epoch 98): Loss/seq after 04000 batchs: 1026.742431640625
INFO:root:Train (Epoch 98): Loss/seq after 04050 batchs: 1020.880615234375
INFO:root:Train (Epoch 98): Loss/seq after 04100 batchs: 1015.493408203125
INFO:root:Train (Epoch 98): Loss/seq after 04150 batchs: 1011.4221801757812
INFO:root:Train (Epoch 98): Loss/seq after 04200 batchs: 1006.4773559570312
INFO:root:Train (Epoch 98): Loss/seq after 04250 batchs: 1003.06494140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 98): Loss/seq after 00000 batches: 869.0744018554688
INFO:root:# Valid (Epoch 98): Loss/seq after 00050 batches: 1086.326904296875
INFO:root:# Valid (Epoch 98): Loss/seq after 00100 batches: 1362.2335205078125
INFO:root:# Valid (Epoch 98): Loss/seq after 00150 batches: 1079.1148681640625
INFO:root:# Valid (Epoch 98): Loss/seq after 00200 batches: 966.3577270507812
INFO:root:Artifacts: Make stick videos for epoch 98
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_98_on_20220423_043808.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_98_index_526_on_20220423_043808.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 99): Loss/seq after 00000 batchs: 1524.209228515625
INFO:root:Train (Epoch 99): Loss/seq after 00050 batchs: 1334.21142578125
INFO:root:Train (Epoch 99): Loss/seq after 00100 batchs: 1281.8236083984375
INFO:root:Train (Epoch 99): Loss/seq after 00150 batchs: 1131.1151123046875
INFO:root:Train (Epoch 99): Loss/seq after 00200 batchs: 1256.8642578125
INFO:root:Train (Epoch 99): Loss/seq after 00250 batchs: 1375.7679443359375
INFO:root:Train (Epoch 99): Loss/seq after 00300 batchs: 1323.757080078125
INFO:root:Train (Epoch 99): Loss/seq after 00350 batchs: 1243.3436279296875
INFO:root:Train (Epoch 99): Loss/seq after 00400 batchs: 1271.118896484375
INFO:root:Train (Epoch 99): Loss/seq after 00450 batchs: 1224.9520263671875
INFO:root:Train (Epoch 99): Loss/seq after 00500 batchs: 1207.99169921875
INFO:root:Train (Epoch 99): Loss/seq after 00550 batchs: 1161.5673828125
INFO:root:Train (Epoch 99): Loss/seq after 00600 batchs: 1134.055908203125
INFO:root:Train (Epoch 99): Loss/seq after 00650 batchs: 1158.1688232421875
INFO:root:Train (Epoch 99): Loss/seq after 00700 batchs: 1184.070068359375
INFO:root:Train (Epoch 99): Loss/seq after 00750 batchs: 1218.40771484375
INFO:root:Train (Epoch 99): Loss/seq after 00800 batchs: 1201.8753662109375
INFO:root:Train (Epoch 99): Loss/seq after 00850 batchs: 1173.6318359375
INFO:root:Train (Epoch 99): Loss/seq after 00900 batchs: 1180.9893798828125
INFO:root:Train (Epoch 99): Loss/seq after 00950 batchs: 1206.2972412109375
INFO:root:Train (Epoch 99): Loss/seq after 01000 batchs: 1201.36865234375
INFO:root:Train (Epoch 99): Loss/seq after 01050 batchs: 1180.73095703125
INFO:root:Train (Epoch 99): Loss/seq after 01100 batchs: 1175.92041015625
INFO:root:Train (Epoch 99): Loss/seq after 01150 batchs: 1164.560302734375
INFO:root:Train (Epoch 99): Loss/seq after 01200 batchs: 1155.402099609375
INFO:root:Train (Epoch 99): Loss/seq after 01250 batchs: 1149.0963134765625
INFO:root:Train (Epoch 99): Loss/seq after 01300 batchs: 1156.8973388671875
INFO:root:Train (Epoch 99): Loss/seq after 01350 batchs: 1160.8868408203125
INFO:root:Train (Epoch 99): Loss/seq after 01400 batchs: 1188.0274658203125
INFO:root:Train (Epoch 99): Loss/seq after 01450 batchs: 1179.044677734375
INFO:root:Train (Epoch 99): Loss/seq after 01500 batchs: 1172.9637451171875
INFO:root:Train (Epoch 99): Loss/seq after 01550 batchs: 1171.3583984375
INFO:root:Train (Epoch 99): Loss/seq after 01600 batchs: 1156.8582763671875
INFO:root:Train (Epoch 99): Loss/seq after 01650 batchs: 1144.53125
INFO:root:Train (Epoch 99): Loss/seq after 01700 batchs: 1138.1527099609375
INFO:root:Train (Epoch 99): Loss/seq after 01750 batchs: 1129.4544677734375
INFO:root:Train (Epoch 99): Loss/seq after 01800 batchs: 1118.224853515625
INFO:root:Train (Epoch 99): Loss/seq after 01850 batchs: 1106.23486328125
INFO:root:Train (Epoch 99): Loss/seq after 01900 batchs: 1102.260986328125
INFO:root:Train (Epoch 99): Loss/seq after 01950 batchs: 1094.3709716796875
INFO:root:Train (Epoch 99): Loss/seq after 02000 batchs: 1087.6072998046875
INFO:root:Train (Epoch 99): Loss/seq after 02050 batchs: 1080.221435546875
INFO:root:Train (Epoch 99): Loss/seq after 02100 batchs: 1071.1649169921875
INFO:root:Train (Epoch 99): Loss/seq after 02150 batchs: 1062.507568359375
INFO:root:Train (Epoch 99): Loss/seq after 02200 batchs: 1053.688232421875
INFO:root:Train (Epoch 99): Loss/seq after 02250 batchs: 1052.376708984375
INFO:root:Train (Epoch 99): Loss/seq after 02300 batchs: 1057.4632568359375
INFO:root:Train (Epoch 99): Loss/seq after 02350 batchs: 1047.99609375
INFO:root:Train (Epoch 99): Loss/seq after 02400 batchs: 1045.17724609375
INFO:root:Train (Epoch 99): Loss/seq after 02450 batchs: 1034.983642578125
INFO:root:Train (Epoch 99): Loss/seq after 02500 batchs: 1021.3287963867188
INFO:root:Train (Epoch 99): Loss/seq after 02550 batchs: 1011.5615234375
INFO:root:Train (Epoch 99): Loss/seq after 02600 batchs: 1011.2028198242188
INFO:root:Train (Epoch 99): Loss/seq after 02650 batchs: 1008.2365112304688
INFO:root:Train (Epoch 99): Loss/seq after 02700 batchs: 1005.4447021484375
INFO:root:Train (Epoch 99): Loss/seq after 02750 batchs: 1021.0562744140625
INFO:root:Train (Epoch 99): Loss/seq after 02800 batchs: 1026.9720458984375
INFO:root:Train (Epoch 99): Loss/seq after 02850 batchs: 1022.9089965820312
INFO:root:Train (Epoch 99): Loss/seq after 02900 batchs: 1021.943359375
INFO:root:Train (Epoch 99): Loss/seq after 02950 batchs: 1015.2215576171875
INFO:root:Train (Epoch 99): Loss/seq after 03000 batchs: 1015.6197509765625
INFO:root:Train (Epoch 99): Loss/seq after 03050 batchs: 1020.4649658203125
INFO:root:Train (Epoch 99): Loss/seq after 03100 batchs: 1025.54052734375
INFO:root:Train (Epoch 99): Loss/seq after 03150 batchs: 1032.01611328125
INFO:root:Train (Epoch 99): Loss/seq after 03200 batchs: 1039.280517578125
INFO:root:Train (Epoch 99): Loss/seq after 03250 batchs: 1042.825439453125
INFO:root:Train (Epoch 99): Loss/seq after 03300 batchs: 1040.8116455078125
INFO:root:Train (Epoch 99): Loss/seq after 03350 batchs: 1040.8072509765625
INFO:root:Train (Epoch 99): Loss/seq after 03400 batchs: 1034.6939697265625
INFO:root:Train (Epoch 99): Loss/seq after 03450 batchs: 1028.39990234375
INFO:root:Train (Epoch 99): Loss/seq after 03500 batchs: 1026.8836669921875
INFO:root:Train (Epoch 99): Loss/seq after 03550 batchs: 1020.5185546875
INFO:root:Train (Epoch 99): Loss/seq after 03600 batchs: 1026.466064453125
INFO:root:Train (Epoch 99): Loss/seq after 03650 batchs: 1021.0946655273438
INFO:root:Train (Epoch 99): Loss/seq after 03700 batchs: 1021.2103881835938
INFO:root:Train (Epoch 99): Loss/seq after 03750 batchs: 1023.10107421875
INFO:root:Train (Epoch 99): Loss/seq after 03800 batchs: 1018.1588745117188
INFO:root:Train (Epoch 99): Loss/seq after 03850 batchs: 1015.3163452148438
INFO:root:Train (Epoch 99): Loss/seq after 03900 batchs: 1019.9456176757812
INFO:root:Train (Epoch 99): Loss/seq after 03950 batchs: 1025.1904296875
INFO:root:Train (Epoch 99): Loss/seq after 04000 batchs: 1018.5399169921875
INFO:root:Train (Epoch 99): Loss/seq after 04050 batchs: 1012.7633056640625
INFO:root:Train (Epoch 99): Loss/seq after 04100 batchs: 1007.5111083984375
INFO:root:Train (Epoch 99): Loss/seq after 04150 batchs: 1003.5534057617188
INFO:root:Train (Epoch 99): Loss/seq after 04200 batchs: 998.5467529296875
INFO:root:Train (Epoch 99): Loss/seq after 04250 batchs: 995.2017211914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 99): Loss/seq after 00000 batches: 868.9142456054688
INFO:root:# Valid (Epoch 99): Loss/seq after 00050 batches: 1084.8189697265625
INFO:root:# Valid (Epoch 99): Loss/seq after 00100 batches: 1362.120849609375
INFO:root:# Valid (Epoch 99): Loss/seq after 00150 batches: 1079.0880126953125
INFO:root:# Valid (Epoch 99): Loss/seq after 00200 batches: 966.9392700195312
INFO:root:Artifacts: Make stick videos for epoch 99
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_99_on_20220423_044259.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_99_index_482_on_20220423_044259.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 100): Loss/seq after 00000 batchs: 1936.5413818359375
INFO:root:Train (Epoch 100): Loss/seq after 00050 batchs: 1323.4444580078125
INFO:root:Train (Epoch 100): Loss/seq after 00100 batchs: 1278.3175048828125
INFO:root:Train (Epoch 100): Loss/seq after 00150 batchs: 1125.77197265625
INFO:root:Train (Epoch 100): Loss/seq after 00200 batchs: 1243.8818359375
INFO:root:Train (Epoch 100): Loss/seq after 00250 batchs: 1360.9324951171875
INFO:root:Train (Epoch 100): Loss/seq after 00300 batchs: 1311.2886962890625
INFO:root:Train (Epoch 100): Loss/seq after 00350 batchs: 1231.5830078125
INFO:root:Train (Epoch 100): Loss/seq after 00400 batchs: 1257.5340576171875
INFO:root:Train (Epoch 100): Loss/seq after 00450 batchs: 1212.9071044921875
INFO:root:Train (Epoch 100): Loss/seq after 00500 batchs: 1198.3062744140625
INFO:root:Train (Epoch 100): Loss/seq after 00550 batchs: 1153.3482666015625
INFO:root:Train (Epoch 100): Loss/seq after 00600 batchs: 1126.7110595703125
INFO:root:Train (Epoch 100): Loss/seq after 00650 batchs: 1153.2662353515625
INFO:root:Train (Epoch 100): Loss/seq after 00700 batchs: 1168.7166748046875
INFO:root:Train (Epoch 100): Loss/seq after 00750 batchs: 1206.0699462890625
INFO:root:Train (Epoch 100): Loss/seq after 00800 batchs: 1192.4232177734375
INFO:root:Train (Epoch 100): Loss/seq after 00850 batchs: 1165.3431396484375
INFO:root:Train (Epoch 100): Loss/seq after 00900 batchs: 1173.748291015625
INFO:root:Train (Epoch 100): Loss/seq after 00950 batchs: 1197.61767578125
INFO:root:Train (Epoch 100): Loss/seq after 01000 batchs: 1187.486572265625
INFO:root:Train (Epoch 100): Loss/seq after 01050 batchs: 1168.6622314453125
INFO:root:Train (Epoch 100): Loss/seq after 01100 batchs: 1163.6015625
INFO:root:Train (Epoch 100): Loss/seq after 01150 batchs: 1152.724365234375
INFO:root:Train (Epoch 100): Loss/seq after 01200 batchs: 1144.3336181640625
INFO:root:Train (Epoch 100): Loss/seq after 01250 batchs: 1139.7645263671875
INFO:root:Train (Epoch 100): Loss/seq after 01300 batchs: 1151.00146484375
INFO:root:Train (Epoch 100): Loss/seq after 01350 batchs: 1153.6402587890625
INFO:root:Train (Epoch 100): Loss/seq after 01400 batchs: 1175.15625
INFO:root:Train (Epoch 100): Loss/seq after 01450 batchs: 1166.7418212890625
INFO:root:Train (Epoch 100): Loss/seq after 01500 batchs: 1161.1688232421875
INFO:root:Train (Epoch 100): Loss/seq after 01550 batchs: 1159.9964599609375
INFO:root:Train (Epoch 100): Loss/seq after 01600 batchs: 1145.873291015625
INFO:root:Train (Epoch 100): Loss/seq after 01650 batchs: 1134.10205078125
INFO:root:Train (Epoch 100): Loss/seq after 01700 batchs: 1128.1055908203125
INFO:root:Train (Epoch 100): Loss/seq after 01750 batchs: 1119.713623046875
INFO:root:Train (Epoch 100): Loss/seq after 01800 batchs: 1108.5791015625
INFO:root:Train (Epoch 100): Loss/seq after 01850 batchs: 1096.6982421875
INFO:root:Train (Epoch 100): Loss/seq after 01900 batchs: 1093.1014404296875
INFO:root:Train (Epoch 100): Loss/seq after 01950 batchs: 1085.80859375
INFO:root:Train (Epoch 100): Loss/seq after 02000 batchs: 1079.37939453125
INFO:root:Train (Epoch 100): Loss/seq after 02050 batchs: 1072.0069580078125
INFO:root:Train (Epoch 100): Loss/seq after 02100 batchs: 1063.0618896484375
INFO:root:Train (Epoch 100): Loss/seq after 02150 batchs: 1054.782470703125
INFO:root:Train (Epoch 100): Loss/seq after 02200 batchs: 1046.2314453125
INFO:root:Train (Epoch 100): Loss/seq after 02250 batchs: 1045.247802734375
INFO:root:Train (Epoch 100): Loss/seq after 02300 batchs: 1050.8701171875
INFO:root:Train (Epoch 100): Loss/seq after 02350 batchs: 1041.66455078125
INFO:root:Train (Epoch 100): Loss/seq after 02400 batchs: 1038.9998779296875
INFO:root:Train (Epoch 100): Loss/seq after 02450 batchs: 1028.9195556640625
INFO:root:Train (Epoch 100): Loss/seq after 02500 batchs: 1015.3712768554688
INFO:root:Train (Epoch 100): Loss/seq after 02550 batchs: 1005.7335205078125
INFO:root:Train (Epoch 100): Loss/seq after 02600 batchs: 1005.47607421875
INFO:root:Train (Epoch 100): Loss/seq after 02650 batchs: 1002.63232421875
INFO:root:Train (Epoch 100): Loss/seq after 02700 batchs: 1000.3280029296875
INFO:root:Train (Epoch 100): Loss/seq after 02750 batchs: 1016.1014404296875
INFO:root:Train (Epoch 100): Loss/seq after 02800 batchs: 1021.6167602539062
INFO:root:Train (Epoch 100): Loss/seq after 02850 batchs: 1017.4544067382812
INFO:root:Train (Epoch 100): Loss/seq after 02900 batchs: 1016.0131225585938
INFO:root:Train (Epoch 100): Loss/seq after 02950 batchs: 1009.4196166992188
INFO:root:Train (Epoch 100): Loss/seq after 03000 batchs: 1009.9189453125
INFO:root:Train (Epoch 100): Loss/seq after 03050 batchs: 1014.8473510742188
INFO:root:Train (Epoch 100): Loss/seq after 03100 batchs: 1021.9857177734375
INFO:root:Train (Epoch 100): Loss/seq after 03150 batchs: 1027.855224609375
INFO:root:Train (Epoch 100): Loss/seq after 03200 batchs: 1034.31298828125
INFO:root:Train (Epoch 100): Loss/seq after 03250 batchs: 1038.0174560546875
INFO:root:Train (Epoch 100): Loss/seq after 03300 batchs: 1036.7098388671875
INFO:root:Train (Epoch 100): Loss/seq after 03350 batchs: 1036.5267333984375
INFO:root:Train (Epoch 100): Loss/seq after 03400 batchs: 1030.5059814453125
INFO:root:Train (Epoch 100): Loss/seq after 03450 batchs: 1024.2215576171875
INFO:root:Train (Epoch 100): Loss/seq after 03500 batchs: 1022.34912109375
INFO:root:Train (Epoch 100): Loss/seq after 03550 batchs: 1016.0836791992188
INFO:root:Train (Epoch 100): Loss/seq after 03600 batchs: 1022.0133666992188
INFO:root:Train (Epoch 100): Loss/seq after 03650 batchs: 1016.7598266601562
INFO:root:Train (Epoch 100): Loss/seq after 03700 batchs: 1016.97314453125
INFO:root:Train (Epoch 100): Loss/seq after 03750 batchs: 1018.980712890625
INFO:root:Train (Epoch 100): Loss/seq after 03800 batchs: 1014.0848388671875
INFO:root:Train (Epoch 100): Loss/seq after 03850 batchs: 1011.2650146484375
INFO:root:Train (Epoch 100): Loss/seq after 03900 batchs: 1015.345703125
INFO:root:Train (Epoch 100): Loss/seq after 03950 batchs: 1021.0107421875
INFO:root:Train (Epoch 100): Loss/seq after 04000 batchs: 1014.4141845703125
INFO:root:Train (Epoch 100): Loss/seq after 04050 batchs: 1008.6948852539062
INFO:root:Train (Epoch 100): Loss/seq after 04100 batchs: 1003.519287109375
INFO:root:Train (Epoch 100): Loss/seq after 04150 batchs: 999.5897216796875
INFO:root:Train (Epoch 100): Loss/seq after 04200 batchs: 994.6397094726562
INFO:root:Train (Epoch 100): Loss/seq after 04250 batchs: 991.4093017578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 100): Loss/seq after 00000 batches: 869.6796875
INFO:root:# Valid (Epoch 100): Loss/seq after 00050 batches: 1085.4205322265625
INFO:root:# Valid (Epoch 100): Loss/seq after 00100 batches: 1362.9329833984375
INFO:root:# Valid (Epoch 100): Loss/seq after 00150 batches: 1078.13623046875
INFO:root:# Valid (Epoch 100): Loss/seq after 00200 batches: 965.309814453125
INFO:root:Artifacts: Make stick videos for epoch 100
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_100_on_20220423_044748.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_100_index_1496_on_20220423_044748.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 101): Loss/seq after 00000 batchs: 1822.427734375
INFO:root:Train (Epoch 101): Loss/seq after 00050 batchs: 1361.228271484375
INFO:root:Train (Epoch 101): Loss/seq after 00100 batchs: 1291.992431640625
INFO:root:Train (Epoch 101): Loss/seq after 00150 batchs: 1135.3963623046875
INFO:root:Train (Epoch 101): Loss/seq after 00200 batchs: 1241.6192626953125
INFO:root:Train (Epoch 101): Loss/seq after 00250 batchs: 1361.984619140625
INFO:root:Train (Epoch 101): Loss/seq after 00300 batchs: 1311.9560546875
INFO:root:Train (Epoch 101): Loss/seq after 00350 batchs: 1233.2237548828125
INFO:root:Train (Epoch 101): Loss/seq after 00400 batchs: 1261.2030029296875
INFO:root:Train (Epoch 101): Loss/seq after 00450 batchs: 1216.132080078125
INFO:root:Train (Epoch 101): Loss/seq after 00500 batchs: 1196.2310791015625
INFO:root:Train (Epoch 101): Loss/seq after 00550 batchs: 1151.0045166015625
INFO:root:Train (Epoch 101): Loss/seq after 00600 batchs: 1123.2728271484375
INFO:root:Train (Epoch 101): Loss/seq after 00650 batchs: 1145.9730224609375
INFO:root:Train (Epoch 101): Loss/seq after 00700 batchs: 1145.0970458984375
INFO:root:Train (Epoch 101): Loss/seq after 00750 batchs: 1181.6241455078125
INFO:root:Train (Epoch 101): Loss/seq after 00800 batchs: 1167.3155517578125
INFO:root:Train (Epoch 101): Loss/seq after 00850 batchs: 1141.363037109375
INFO:root:Train (Epoch 101): Loss/seq after 00900 batchs: 1151.4222412109375
INFO:root:Train (Epoch 101): Loss/seq after 00950 batchs: 1170.5665283203125
INFO:root:Train (Epoch 101): Loss/seq after 01000 batchs: 1165.0345458984375
INFO:root:Train (Epoch 101): Loss/seq after 01050 batchs: 1148.7425537109375
INFO:root:Train (Epoch 101): Loss/seq after 01100 batchs: 1144.0
INFO:root:Train (Epoch 101): Loss/seq after 01150 batchs: 1133.9599609375
INFO:root:Train (Epoch 101): Loss/seq after 01200 batchs: 1126.38232421875
INFO:root:Train (Epoch 101): Loss/seq after 01250 batchs: 1121.66259765625
INFO:root:Train (Epoch 101): Loss/seq after 01300 batchs: 1129.19775390625
INFO:root:Train (Epoch 101): Loss/seq after 01350 batchs: 1132.5150146484375
INFO:root:Train (Epoch 101): Loss/seq after 01400 batchs: 1153.8128662109375
INFO:root:Train (Epoch 101): Loss/seq after 01450 batchs: 1146.080078125
INFO:root:Train (Epoch 101): Loss/seq after 01500 batchs: 1141.078369140625
INFO:root:Train (Epoch 101): Loss/seq after 01550 batchs: 1140.784912109375
INFO:root:Train (Epoch 101): Loss/seq after 01600 batchs: 1127.34375
INFO:root:Train (Epoch 101): Loss/seq after 01650 batchs: 1115.881591796875
INFO:root:Train (Epoch 101): Loss/seq after 01700 batchs: 1110.3812255859375
INFO:root:Train (Epoch 101): Loss/seq after 01750 batchs: 1102.4534912109375
INFO:root:Train (Epoch 101): Loss/seq after 01800 batchs: 1091.900146484375
INFO:root:Train (Epoch 101): Loss/seq after 01850 batchs: 1080.5361328125
INFO:root:Train (Epoch 101): Loss/seq after 01900 batchs: 1077.21630859375
INFO:root:Train (Epoch 101): Loss/seq after 01950 batchs: 1069.9571533203125
INFO:root:Train (Epoch 101): Loss/seq after 02000 batchs: 1063.692138671875
INFO:root:Train (Epoch 101): Loss/seq after 02050 batchs: 1056.7138671875
INFO:root:Train (Epoch 101): Loss/seq after 02100 batchs: 1047.88623046875
INFO:root:Train (Epoch 101): Loss/seq after 02150 batchs: 1039.6893310546875
INFO:root:Train (Epoch 101): Loss/seq after 02200 batchs: 1031.3685302734375
INFO:root:Train (Epoch 101): Loss/seq after 02250 batchs: 1029.9967041015625
INFO:root:Train (Epoch 101): Loss/seq after 02300 batchs: 1035.785400390625
INFO:root:Train (Epoch 101): Loss/seq after 02350 batchs: 1027.2171630859375
INFO:root:Train (Epoch 101): Loss/seq after 02400 batchs: 1024.99169921875
INFO:root:Train (Epoch 101): Loss/seq after 02450 batchs: 1015.2824096679688
INFO:root:Train (Epoch 101): Loss/seq after 02500 batchs: 1002.00439453125
INFO:root:Train (Epoch 101): Loss/seq after 02550 batchs: 992.7896728515625
INFO:root:Train (Epoch 101): Loss/seq after 02600 batchs: 992.863037109375
INFO:root:Train (Epoch 101): Loss/seq after 02650 batchs: 990.2366943359375
INFO:root:Train (Epoch 101): Loss/seq after 02700 batchs: 987.7733764648438
INFO:root:Train (Epoch 101): Loss/seq after 02750 batchs: 1003.65673828125
INFO:root:Train (Epoch 101): Loss/seq after 02800 batchs: 1009.5712890625
INFO:root:Train (Epoch 101): Loss/seq after 02850 batchs: 1005.7236328125
INFO:root:Train (Epoch 101): Loss/seq after 02900 batchs: 1004.6974487304688
INFO:root:Train (Epoch 101): Loss/seq after 02950 batchs: 998.2530517578125
INFO:root:Train (Epoch 101): Loss/seq after 03000 batchs: 998.9317016601562
INFO:root:Train (Epoch 101): Loss/seq after 03050 batchs: 1003.9986572265625
INFO:root:Train (Epoch 101): Loss/seq after 03100 batchs: 1009.4883422851562
INFO:root:Train (Epoch 101): Loss/seq after 03150 batchs: 1019.4456176757812
INFO:root:Train (Epoch 101): Loss/seq after 03200 batchs: 1026.13818359375
INFO:root:Train (Epoch 101): Loss/seq after 03250 batchs: 1031.219482421875
INFO:root:Train (Epoch 101): Loss/seq after 03300 batchs: 1029.5318603515625
INFO:root:Train (Epoch 101): Loss/seq after 03350 batchs: 1028.957763671875
INFO:root:Train (Epoch 101): Loss/seq after 03400 batchs: 1023.047607421875
INFO:root:Train (Epoch 101): Loss/seq after 03450 batchs: 1016.9102783203125
INFO:root:Train (Epoch 101): Loss/seq after 03500 batchs: 1015.2409057617188
INFO:root:Train (Epoch 101): Loss/seq after 03550 batchs: 1008.9874877929688
INFO:root:Train (Epoch 101): Loss/seq after 03600 batchs: 1015.1017456054688
INFO:root:Train (Epoch 101): Loss/seq after 03650 batchs: 1010.1357421875
INFO:root:Train (Epoch 101): Loss/seq after 03700 batchs: 1010.394287109375
INFO:root:Train (Epoch 101): Loss/seq after 03750 batchs: 1012.4281616210938
INFO:root:Train (Epoch 101): Loss/seq after 03800 batchs: 1007.6058349609375
INFO:root:Train (Epoch 101): Loss/seq after 03850 batchs: 1004.86572265625
INFO:root:Train (Epoch 101): Loss/seq after 03900 batchs: 1008.0244140625
INFO:root:Train (Epoch 101): Loss/seq after 03950 batchs: 1012.2588500976562
INFO:root:Train (Epoch 101): Loss/seq after 04000 batchs: 1005.7830200195312
INFO:root:Train (Epoch 101): Loss/seq after 04050 batchs: 1000.2349853515625
INFO:root:Train (Epoch 101): Loss/seq after 04100 batchs: 995.239013671875
INFO:root:Train (Epoch 101): Loss/seq after 04150 batchs: 991.5018920898438
INFO:root:Train (Epoch 101): Loss/seq after 04200 batchs: 986.7528686523438
INFO:root:Train (Epoch 101): Loss/seq after 04250 batchs: 983.5159912109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 101): Loss/seq after 00000 batches: 880.4767456054688
INFO:root:# Valid (Epoch 101): Loss/seq after 00050 batches: 1101.2728271484375
INFO:root:# Valid (Epoch 101): Loss/seq after 00100 batches: 1393.8519287109375
INFO:root:# Valid (Epoch 101): Loss/seq after 00150 batches: 1099.427978515625
INFO:root:# Valid (Epoch 101): Loss/seq after 00200 batches: 981.1049194335938
INFO:root:Artifacts: Make stick videos for epoch 101
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_101_on_20220423_045237.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_101_index_1240_on_20220423_045237.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 102): Loss/seq after 00000 batchs: 2459.551025390625
INFO:root:Train (Epoch 102): Loss/seq after 00050 batchs: 1368.9036865234375
INFO:root:Train (Epoch 102): Loss/seq after 00100 batchs: 1285.6824951171875
INFO:root:Train (Epoch 102): Loss/seq after 00150 batchs: 1132.9718017578125
INFO:root:Train (Epoch 102): Loss/seq after 00200 batchs: 1252.8250732421875
INFO:root:Train (Epoch 102): Loss/seq after 00250 batchs: 1371.4075927734375
INFO:root:Train (Epoch 102): Loss/seq after 00300 batchs: 1320.744384765625
INFO:root:Train (Epoch 102): Loss/seq after 00350 batchs: 1239.2283935546875
INFO:root:Train (Epoch 102): Loss/seq after 00400 batchs: 1258.2642822265625
INFO:root:Train (Epoch 102): Loss/seq after 00450 batchs: 1212.988525390625
INFO:root:Train (Epoch 102): Loss/seq after 00500 batchs: 1197.34423828125
INFO:root:Train (Epoch 102): Loss/seq after 00550 batchs: 1152.2835693359375
INFO:root:Train (Epoch 102): Loss/seq after 00600 batchs: 1124.15283203125
INFO:root:Train (Epoch 102): Loss/seq after 00650 batchs: 1142.68896484375
INFO:root:Train (Epoch 102): Loss/seq after 00700 batchs: 1144.72216796875
INFO:root:Train (Epoch 102): Loss/seq after 00750 batchs: 1181.2684326171875
INFO:root:Train (Epoch 102): Loss/seq after 00800 batchs: 1166.3857421875
INFO:root:Train (Epoch 102): Loss/seq after 00850 batchs: 1140.77783203125
INFO:root:Train (Epoch 102): Loss/seq after 00900 batchs: 1151.156494140625
INFO:root:Train (Epoch 102): Loss/seq after 00950 batchs: 1169.01171875
INFO:root:Train (Epoch 102): Loss/seq after 01000 batchs: 1160.283935546875
INFO:root:Train (Epoch 102): Loss/seq after 01050 batchs: 1141.74755859375
INFO:root:Train (Epoch 102): Loss/seq after 01100 batchs: 1138.8701171875
INFO:root:Train (Epoch 102): Loss/seq after 01150 batchs: 1129.164306640625
INFO:root:Train (Epoch 102): Loss/seq after 01200 batchs: 1121.5804443359375
INFO:root:Train (Epoch 102): Loss/seq after 01250 batchs: 1117.2318115234375
INFO:root:Train (Epoch 102): Loss/seq after 01300 batchs: 1123.631103515625
INFO:root:Train (Epoch 102): Loss/seq after 01350 batchs: 1126.1693115234375
INFO:root:Train (Epoch 102): Loss/seq after 01400 batchs: 1146.4017333984375
INFO:root:Train (Epoch 102): Loss/seq after 01450 batchs: 1138.96142578125
INFO:root:Train (Epoch 102): Loss/seq after 01500 batchs: 1134.218017578125
INFO:root:Train (Epoch 102): Loss/seq after 01550 batchs: 1133.8992919921875
INFO:root:Train (Epoch 102): Loss/seq after 01600 batchs: 1120.984375
INFO:root:Train (Epoch 102): Loss/seq after 01650 batchs: 1109.61083984375
INFO:root:Train (Epoch 102): Loss/seq after 01700 batchs: 1104.3572998046875
INFO:root:Train (Epoch 102): Loss/seq after 01750 batchs: 1096.542724609375
INFO:root:Train (Epoch 102): Loss/seq after 01800 batchs: 1086.0218505859375
INFO:root:Train (Epoch 102): Loss/seq after 01850 batchs: 1074.72802734375
INFO:root:Train (Epoch 102): Loss/seq after 01900 batchs: 1071.53515625
INFO:root:Train (Epoch 102): Loss/seq after 01950 batchs: 1064.5289306640625
INFO:root:Train (Epoch 102): Loss/seq after 02000 batchs: 1058.3095703125
INFO:root:Train (Epoch 102): Loss/seq after 02050 batchs: 1051.3311767578125
INFO:root:Train (Epoch 102): Loss/seq after 02100 batchs: 1042.6029052734375
INFO:root:Train (Epoch 102): Loss/seq after 02150 batchs: 1034.544677734375
INFO:root:Train (Epoch 102): Loss/seq after 02200 batchs: 1026.3336181640625
INFO:root:Train (Epoch 102): Loss/seq after 02250 batchs: 1025.2728271484375
INFO:root:Train (Epoch 102): Loss/seq after 02300 batchs: 1032.036376953125
INFO:root:Train (Epoch 102): Loss/seq after 02350 batchs: 1023.1776733398438
INFO:root:Train (Epoch 102): Loss/seq after 02400 batchs: 1020.8840942382812
INFO:root:Train (Epoch 102): Loss/seq after 02450 batchs: 1011.1807250976562
INFO:root:Train (Epoch 102): Loss/seq after 02500 batchs: 997.9877319335938
INFO:root:Train (Epoch 102): Loss/seq after 02550 batchs: 988.7023315429688
INFO:root:Train (Epoch 102): Loss/seq after 02600 batchs: 989.1954956054688
INFO:root:Train (Epoch 102): Loss/seq after 02650 batchs: 986.8619384765625
INFO:root:Train (Epoch 102): Loss/seq after 02700 batchs: 984.4468383789062
INFO:root:Train (Epoch 102): Loss/seq after 02750 batchs: 1001.473388671875
INFO:root:Train (Epoch 102): Loss/seq after 02800 batchs: 1006.3399658203125
INFO:root:Train (Epoch 102): Loss/seq after 02850 batchs: 1002.5861206054688
INFO:root:Train (Epoch 102): Loss/seq after 02900 batchs: 1001.6932373046875
INFO:root:Train (Epoch 102): Loss/seq after 02950 batchs: 995.4111938476562
INFO:root:Train (Epoch 102): Loss/seq after 03000 batchs: 996.1622924804688
INFO:root:Train (Epoch 102): Loss/seq after 03050 batchs: 1001.3268432617188
INFO:root:Train (Epoch 102): Loss/seq after 03100 batchs: 1007.7255249023438
INFO:root:Train (Epoch 102): Loss/seq after 03150 batchs: 1012.7669067382812
INFO:root:Train (Epoch 102): Loss/seq after 03200 batchs: 1018.0328369140625
INFO:root:Train (Epoch 102): Loss/seq after 03250 batchs: 1022.8326416015625
INFO:root:Train (Epoch 102): Loss/seq after 03300 batchs: 1021.3406982421875
INFO:root:Train (Epoch 102): Loss/seq after 03350 batchs: 1020.7279052734375
INFO:root:Train (Epoch 102): Loss/seq after 03400 batchs: 1014.9046630859375
INFO:root:Train (Epoch 102): Loss/seq after 03450 batchs: 1008.8570556640625
INFO:root:Train (Epoch 102): Loss/seq after 03500 batchs: 1007.3104248046875
INFO:root:Train (Epoch 102): Loss/seq after 03550 batchs: 1001.1265869140625
INFO:root:Train (Epoch 102): Loss/seq after 03600 batchs: 1007.28466796875
INFO:root:Train (Epoch 102): Loss/seq after 03650 batchs: 1002.1767578125
INFO:root:Train (Epoch 102): Loss/seq after 03700 batchs: 1002.3519897460938
INFO:root:Train (Epoch 102): Loss/seq after 03750 batchs: 1004.488525390625
INFO:root:Train (Epoch 102): Loss/seq after 03800 batchs: 999.795166015625
INFO:root:Train (Epoch 102): Loss/seq after 03850 batchs: 997.1566162109375
INFO:root:Train (Epoch 102): Loss/seq after 03900 batchs: 1002.2064208984375
INFO:root:Train (Epoch 102): Loss/seq after 03950 batchs: 1006.6808471679688
INFO:root:Train (Epoch 102): Loss/seq after 04000 batchs: 1000.2607421875
INFO:root:Train (Epoch 102): Loss/seq after 04050 batchs: 994.7133178710938
INFO:root:Train (Epoch 102): Loss/seq after 04100 batchs: 989.7139892578125
INFO:root:Train (Epoch 102): Loss/seq after 04150 batchs: 985.9727783203125
INFO:root:Train (Epoch 102): Loss/seq after 04200 batchs: 981.1596069335938
INFO:root:Train (Epoch 102): Loss/seq after 04250 batchs: 978.0379028320312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 102): Loss/seq after 00000 batches: 867.6513061523438
INFO:root:# Valid (Epoch 102): Loss/seq after 00050 batches: 1086.5867919921875
INFO:root:# Valid (Epoch 102): Loss/seq after 00100 batches: 1363.7105712890625
INFO:root:# Valid (Epoch 102): Loss/seq after 00150 batches: 1079.7149658203125
INFO:root:# Valid (Epoch 102): Loss/seq after 00200 batches: 965.051025390625
INFO:root:Artifacts: Make stick videos for epoch 102
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_102_on_20220423_045726.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_102_index_899_on_20220423_045726.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 103): Loss/seq after 00000 batchs: 2226.55810546875
INFO:root:Train (Epoch 103): Loss/seq after 00050 batchs: 1323.2613525390625
INFO:root:Train (Epoch 103): Loss/seq after 00100 batchs: 1271.5389404296875
INFO:root:Train (Epoch 103): Loss/seq after 00150 batchs: 1124.591064453125
INFO:root:Train (Epoch 103): Loss/seq after 00200 batchs: 1247.041748046875
INFO:root:Train (Epoch 103): Loss/seq after 00250 batchs: 1367.085205078125
INFO:root:Train (Epoch 103): Loss/seq after 00300 batchs: 1315.7904052734375
INFO:root:Train (Epoch 103): Loss/seq after 00350 batchs: 1234.25439453125
INFO:root:Train (Epoch 103): Loss/seq after 00400 batchs: 1251.3955078125
INFO:root:Train (Epoch 103): Loss/seq after 00450 batchs: 1206.7545166015625
INFO:root:Train (Epoch 103): Loss/seq after 00500 batchs: 1188.59716796875
INFO:root:Train (Epoch 103): Loss/seq after 00550 batchs: 1143.7938232421875
INFO:root:Train (Epoch 103): Loss/seq after 00600 batchs: 1117.70703125
INFO:root:Train (Epoch 103): Loss/seq after 00650 batchs: 1141.0765380859375
INFO:root:Train (Epoch 103): Loss/seq after 00700 batchs: 1136.5594482421875
INFO:root:Train (Epoch 103): Loss/seq after 00750 batchs: 1173.01123046875
INFO:root:Train (Epoch 103): Loss/seq after 00800 batchs: 1159.3817138671875
INFO:root:Train (Epoch 103): Loss/seq after 00850 batchs: 1133.673583984375
INFO:root:Train (Epoch 103): Loss/seq after 00900 batchs: 1143.15380859375
INFO:root:Train (Epoch 103): Loss/seq after 00950 batchs: 1166.175048828125
INFO:root:Train (Epoch 103): Loss/seq after 01000 batchs: 1160.8089599609375
INFO:root:Train (Epoch 103): Loss/seq after 01050 batchs: 1142.79052734375
INFO:root:Train (Epoch 103): Loss/seq after 01100 batchs: 1139.24560546875
INFO:root:Train (Epoch 103): Loss/seq after 01150 batchs: 1129.4508056640625
INFO:root:Train (Epoch 103): Loss/seq after 01200 batchs: 1121.9012451171875
INFO:root:Train (Epoch 103): Loss/seq after 01250 batchs: 1116.2071533203125
INFO:root:Train (Epoch 103): Loss/seq after 01300 batchs: 1122.6416015625
INFO:root:Train (Epoch 103): Loss/seq after 01350 batchs: 1123.1690673828125
INFO:root:Train (Epoch 103): Loss/seq after 01400 batchs: 1143.18798828125
INFO:root:Train (Epoch 103): Loss/seq after 01450 batchs: 1135.7572021484375
INFO:root:Train (Epoch 103): Loss/seq after 01500 batchs: 1131.0325927734375
INFO:root:Train (Epoch 103): Loss/seq after 01550 batchs: 1130.511962890625
INFO:root:Train (Epoch 103): Loss/seq after 01600 batchs: 1117.20556640625
INFO:root:Train (Epoch 103): Loss/seq after 01650 batchs: 1106.443359375
INFO:root:Train (Epoch 103): Loss/seq after 01700 batchs: 1101.1949462890625
INFO:root:Train (Epoch 103): Loss/seq after 01750 batchs: 1093.453125
INFO:root:Train (Epoch 103): Loss/seq after 01800 batchs: 1082.960693359375
INFO:root:Train (Epoch 103): Loss/seq after 01850 batchs: 1071.80517578125
INFO:root:Train (Epoch 103): Loss/seq after 01900 batchs: 1068.66943359375
INFO:root:Train (Epoch 103): Loss/seq after 01950 batchs: 1061.559814453125
INFO:root:Train (Epoch 103): Loss/seq after 02000 batchs: 1055.365966796875
INFO:root:Train (Epoch 103): Loss/seq after 02050 batchs: 1048.529052734375
INFO:root:Train (Epoch 103): Loss/seq after 02100 batchs: 1039.859375
INFO:root:Train (Epoch 103): Loss/seq after 02150 batchs: 1031.7974853515625
INFO:root:Train (Epoch 103): Loss/seq after 02200 batchs: 1023.6341552734375
INFO:root:Train (Epoch 103): Loss/seq after 02250 batchs: 1022.7464599609375
INFO:root:Train (Epoch 103): Loss/seq after 02300 batchs: 1028.3909912109375
INFO:root:Train (Epoch 103): Loss/seq after 02350 batchs: 1019.6834106445312
INFO:root:Train (Epoch 103): Loss/seq after 02400 batchs: 1017.4468994140625
INFO:root:Train (Epoch 103): Loss/seq after 02450 batchs: 1007.7863159179688
INFO:root:Train (Epoch 103): Loss/seq after 02500 batchs: 994.6681518554688
INFO:root:Train (Epoch 103): Loss/seq after 02550 batchs: 985.4825439453125
INFO:root:Train (Epoch 103): Loss/seq after 02600 batchs: 985.6467895507812
INFO:root:Train (Epoch 103): Loss/seq after 02650 batchs: 983.18310546875
INFO:root:Train (Epoch 103): Loss/seq after 02700 batchs: 980.9859619140625
INFO:root:Train (Epoch 103): Loss/seq after 02750 batchs: 996.1793212890625
INFO:root:Train (Epoch 103): Loss/seq after 02800 batchs: 1002.1203002929688
INFO:root:Train (Epoch 103): Loss/seq after 02850 batchs: 998.3265380859375
INFO:root:Train (Epoch 103): Loss/seq after 02900 batchs: 997.4658203125
INFO:root:Train (Epoch 103): Loss/seq after 02950 batchs: 991.1929931640625
INFO:root:Train (Epoch 103): Loss/seq after 03000 batchs: 991.9443969726562
INFO:root:Train (Epoch 103): Loss/seq after 03050 batchs: 995.794189453125
INFO:root:Train (Epoch 103): Loss/seq after 03100 batchs: 1002.0819091796875
INFO:root:Train (Epoch 103): Loss/seq after 03150 batchs: 1008.057861328125
INFO:root:Train (Epoch 103): Loss/seq after 03200 batchs: 1013.7843627929688
INFO:root:Train (Epoch 103): Loss/seq after 03250 batchs: 1016.2782592773438
INFO:root:Train (Epoch 103): Loss/seq after 03300 batchs: 1014.2481079101562
INFO:root:Train (Epoch 103): Loss/seq after 03350 batchs: 1014.3935546875
INFO:root:Train (Epoch 103): Loss/seq after 03400 batchs: 1008.7071533203125
INFO:root:Train (Epoch 103): Loss/seq after 03450 batchs: 1003.0504760742188
INFO:root:Train (Epoch 103): Loss/seq after 03500 batchs: 1001.684814453125
INFO:root:Train (Epoch 103): Loss/seq after 03550 batchs: 995.7757568359375
INFO:root:Train (Epoch 103): Loss/seq after 03600 batchs: 1002.2514038085938
INFO:root:Train (Epoch 103): Loss/seq after 03650 batchs: 997.4092407226562
INFO:root:Train (Epoch 103): Loss/seq after 03700 batchs: 997.700439453125
INFO:root:Train (Epoch 103): Loss/seq after 03750 batchs: 999.8712768554688
INFO:root:Train (Epoch 103): Loss/seq after 03800 batchs: 995.2408447265625
INFO:root:Train (Epoch 103): Loss/seq after 03850 batchs: 992.7009887695312
INFO:root:Train (Epoch 103): Loss/seq after 03900 batchs: 997.6292724609375
INFO:root:Train (Epoch 103): Loss/seq after 03950 batchs: 1002.5449829101562
INFO:root:Train (Epoch 103): Loss/seq after 04000 batchs: 996.1824340820312
INFO:root:Train (Epoch 103): Loss/seq after 04050 batchs: 990.6735229492188
INFO:root:Train (Epoch 103): Loss/seq after 04100 batchs: 985.7490234375
INFO:root:Train (Epoch 103): Loss/seq after 04150 batchs: 982.039306640625
INFO:root:Train (Epoch 103): Loss/seq after 04200 batchs: 977.2733764648438
INFO:root:Train (Epoch 103): Loss/seq after 04250 batchs: 974.1292724609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 103): Loss/seq after 00000 batches: 866.666015625
INFO:root:# Valid (Epoch 103): Loss/seq after 00050 batches: 1089.660400390625
INFO:root:# Valid (Epoch 103): Loss/seq after 00100 batches: 1363.9373779296875
INFO:root:# Valid (Epoch 103): Loss/seq after 00150 batches: 1078.6898193359375
INFO:root:# Valid (Epoch 103): Loss/seq after 00200 batches: 965.2166137695312
INFO:root:Artifacts: Make stick videos for epoch 103
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_103_on_20220423_050220.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_103_index_609_on_20220423_050220.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 104): Loss/seq after 00000 batchs: 2162.177001953125
INFO:root:Train (Epoch 104): Loss/seq after 00050 batchs: 1303.06396484375
INFO:root:Train (Epoch 104): Loss/seq after 00100 batchs: 1241.8890380859375
INFO:root:Train (Epoch 104): Loss/seq after 00150 batchs: 1100.1463623046875
INFO:root:Train (Epoch 104): Loss/seq after 00200 batchs: 1239.689208984375
INFO:root:Train (Epoch 104): Loss/seq after 00250 batchs: 1354.5772705078125
INFO:root:Train (Epoch 104): Loss/seq after 00300 batchs: 1306.0877685546875
INFO:root:Train (Epoch 104): Loss/seq after 00350 batchs: 1226.6478271484375
INFO:root:Train (Epoch 104): Loss/seq after 00400 batchs: 1253.399169921875
INFO:root:Train (Epoch 104): Loss/seq after 00450 batchs: 1208.548095703125
INFO:root:Train (Epoch 104): Loss/seq after 00500 batchs: 1192.3056640625
INFO:root:Train (Epoch 104): Loss/seq after 00550 batchs: 1147.0518798828125
INFO:root:Train (Epoch 104): Loss/seq after 00600 batchs: 1119.156494140625
INFO:root:Train (Epoch 104): Loss/seq after 00650 batchs: 1134.7705078125
INFO:root:Train (Epoch 104): Loss/seq after 00700 batchs: 1123.4891357421875
INFO:root:Train (Epoch 104): Loss/seq after 00750 batchs: 1157.177490234375
INFO:root:Train (Epoch 104): Loss/seq after 00800 batchs: 1144.4111328125
INFO:root:Train (Epoch 104): Loss/seq after 00850 batchs: 1119.4427490234375
INFO:root:Train (Epoch 104): Loss/seq after 00900 batchs: 1128.966552734375
INFO:root:Train (Epoch 104): Loss/seq after 00950 batchs: 1140.1475830078125
INFO:root:Train (Epoch 104): Loss/seq after 01000 batchs: 1132.3077392578125
INFO:root:Train (Epoch 104): Loss/seq after 01050 batchs: 1115.4654541015625
INFO:root:Train (Epoch 104): Loss/seq after 01100 batchs: 1112.4951171875
INFO:root:Train (Epoch 104): Loss/seq after 01150 batchs: 1103.7940673828125
INFO:root:Train (Epoch 104): Loss/seq after 01200 batchs: 1097.5216064453125
INFO:root:Train (Epoch 104): Loss/seq after 01250 batchs: 1094.232666015625
INFO:root:Train (Epoch 104): Loss/seq after 01300 batchs: 1101.1973876953125
INFO:root:Train (Epoch 104): Loss/seq after 01350 batchs: 1103.6182861328125
INFO:root:Train (Epoch 104): Loss/seq after 01400 batchs: 1123.60693359375
INFO:root:Train (Epoch 104): Loss/seq after 01450 batchs: 1116.9639892578125
INFO:root:Train (Epoch 104): Loss/seq after 01500 batchs: 1112.9696044921875
INFO:root:Train (Epoch 104): Loss/seq after 01550 batchs: 1114.024169921875
INFO:root:Train (Epoch 104): Loss/seq after 01600 batchs: 1101.900634765625
INFO:root:Train (Epoch 104): Loss/seq after 01650 batchs: 1091.716064453125
INFO:root:Train (Epoch 104): Loss/seq after 01700 batchs: 1086.92041015625
INFO:root:Train (Epoch 104): Loss/seq after 01750 batchs: 1079.6998291015625
INFO:root:Train (Epoch 104): Loss/seq after 01800 batchs: 1069.6632080078125
INFO:root:Train (Epoch 104): Loss/seq after 01850 batchs: 1058.8619384765625
INFO:root:Train (Epoch 104): Loss/seq after 01900 batchs: 1056.0740966796875
INFO:root:Train (Epoch 104): Loss/seq after 01950 batchs: 1049.3133544921875
INFO:root:Train (Epoch 104): Loss/seq after 02000 batchs: 1043.46142578125
INFO:root:Train (Epoch 104): Loss/seq after 02050 batchs: 1036.7645263671875
INFO:root:Train (Epoch 104): Loss/seq after 02100 batchs: 1028.4090576171875
INFO:root:Train (Epoch 104): Loss/seq after 02150 batchs: 1020.6159057617188
INFO:root:Train (Epoch 104): Loss/seq after 02200 batchs: 1012.679443359375
INFO:root:Train (Epoch 104): Loss/seq after 02250 batchs: 1012.0317993164062
INFO:root:Train (Epoch 104): Loss/seq after 02300 batchs: 1017.9168701171875
INFO:root:Train (Epoch 104): Loss/seq after 02350 batchs: 1009.3846435546875
INFO:root:Train (Epoch 104): Loss/seq after 02400 batchs: 1007.4019165039062
INFO:root:Train (Epoch 104): Loss/seq after 02450 batchs: 997.9893798828125
INFO:root:Train (Epoch 104): Loss/seq after 02500 batchs: 985.0650024414062
INFO:root:Train (Epoch 104): Loss/seq after 02550 batchs: 975.8016357421875
INFO:root:Train (Epoch 104): Loss/seq after 02600 batchs: 976.1165771484375
INFO:root:Train (Epoch 104): Loss/seq after 02650 batchs: 973.7498779296875
INFO:root:Train (Epoch 104): Loss/seq after 02700 batchs: 970.9784545898438
INFO:root:Train (Epoch 104): Loss/seq after 02750 batchs: 986.9006958007812
INFO:root:Train (Epoch 104): Loss/seq after 02800 batchs: 992.1182250976562
INFO:root:Train (Epoch 104): Loss/seq after 02850 batchs: 988.295166015625
INFO:root:Train (Epoch 104): Loss/seq after 02900 batchs: 987.5264892578125
INFO:root:Train (Epoch 104): Loss/seq after 02950 batchs: 981.39599609375
INFO:root:Train (Epoch 104): Loss/seq after 03000 batchs: 982.2978515625
INFO:root:Train (Epoch 104): Loss/seq after 03050 batchs: 987.6900634765625
INFO:root:Train (Epoch 104): Loss/seq after 03100 batchs: 992.0199584960938
INFO:root:Train (Epoch 104): Loss/seq after 03150 batchs: 996.1293334960938
INFO:root:Train (Epoch 104): Loss/seq after 03200 batchs: 1002.2869262695312
INFO:root:Train (Epoch 104): Loss/seq after 03250 batchs: 1005.5474853515625
INFO:root:Train (Epoch 104): Loss/seq after 03300 batchs: 1003.5009155273438
INFO:root:Train (Epoch 104): Loss/seq after 03350 batchs: 1003.5745849609375
INFO:root:Train (Epoch 104): Loss/seq after 03400 batchs: 997.9923095703125
INFO:root:Train (Epoch 104): Loss/seq after 03450 batchs: 992.1500244140625
INFO:root:Train (Epoch 104): Loss/seq after 03500 batchs: 990.18603515625
INFO:root:Train (Epoch 104): Loss/seq after 03550 batchs: 984.548828125
INFO:root:Train (Epoch 104): Loss/seq after 03600 batchs: 990.9278564453125
INFO:root:Train (Epoch 104): Loss/seq after 03650 batchs: 986.07275390625
INFO:root:Train (Epoch 104): Loss/seq after 03700 batchs: 986.606201171875
INFO:root:Train (Epoch 104): Loss/seq after 03750 batchs: 988.9815673828125
INFO:root:Train (Epoch 104): Loss/seq after 03800 batchs: 984.4899291992188
INFO:root:Train (Epoch 104): Loss/seq after 03850 batchs: 982.056640625
INFO:root:Train (Epoch 104): Loss/seq after 03900 batchs: 986.8298950195312
INFO:root:Train (Epoch 104): Loss/seq after 03950 batchs: 992.3041381835938
INFO:root:Train (Epoch 104): Loss/seq after 04000 batchs: 986.0635986328125
INFO:root:Train (Epoch 104): Loss/seq after 04050 batchs: 980.7554321289062
INFO:root:Train (Epoch 104): Loss/seq after 04100 batchs: 975.9564819335938
INFO:root:Train (Epoch 104): Loss/seq after 04150 batchs: 972.3727416992188
INFO:root:Train (Epoch 104): Loss/seq after 04200 batchs: 967.9547729492188
INFO:root:Train (Epoch 104): Loss/seq after 04250 batchs: 964.9370727539062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 104): Loss/seq after 00000 batches: 872.0179443359375
INFO:root:# Valid (Epoch 104): Loss/seq after 00050 batches: 1094.303466796875
INFO:root:# Valid (Epoch 104): Loss/seq after 00100 batches: 1379.1168212890625
INFO:root:# Valid (Epoch 104): Loss/seq after 00150 batches: 1088.56005859375
INFO:root:# Valid (Epoch 104): Loss/seq after 00200 batches: 972.9782104492188
INFO:root:Artifacts: Make stick videos for epoch 104
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_104_on_20220423_050711.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_104_index_19_on_20220423_050711.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 105): Loss/seq after 00000 batchs: 2049.978515625
INFO:root:Train (Epoch 105): Loss/seq after 00050 batchs: 1264.385986328125
INFO:root:Train (Epoch 105): Loss/seq after 00100 batchs: 1225.2149658203125
INFO:root:Train (Epoch 105): Loss/seq after 00150 batchs: 1089.24169921875
INFO:root:Train (Epoch 105): Loss/seq after 00200 batchs: 1223.6070556640625
INFO:root:Train (Epoch 105): Loss/seq after 00250 batchs: 1337.5517578125
INFO:root:Train (Epoch 105): Loss/seq after 00300 batchs: 1291.6424560546875
INFO:root:Train (Epoch 105): Loss/seq after 00350 batchs: 1214.232666015625
INFO:root:Train (Epoch 105): Loss/seq after 00400 batchs: 1232.68603515625
INFO:root:Train (Epoch 105): Loss/seq after 00450 batchs: 1190.061279296875
INFO:root:Train (Epoch 105): Loss/seq after 00500 batchs: 1165.36181640625
INFO:root:Train (Epoch 105): Loss/seq after 00550 batchs: 1122.4893798828125
INFO:root:Train (Epoch 105): Loss/seq after 00600 batchs: 1095.856201171875
INFO:root:Train (Epoch 105): Loss/seq after 00650 batchs: 1106.3548583984375
INFO:root:Train (Epoch 105): Loss/seq after 00700 batchs: 1104.44580078125
INFO:root:Train (Epoch 105): Loss/seq after 00750 batchs: 1133.230224609375
INFO:root:Train (Epoch 105): Loss/seq after 00800 batchs: 1120.7828369140625
INFO:root:Train (Epoch 105): Loss/seq after 00850 batchs: 1097.4306640625
INFO:root:Train (Epoch 105): Loss/seq after 00900 batchs: 1109.3973388671875
INFO:root:Train (Epoch 105): Loss/seq after 00950 batchs: 1117.9600830078125
INFO:root:Train (Epoch 105): Loss/seq after 01000 batchs: 1113.9979248046875
INFO:root:Train (Epoch 105): Loss/seq after 01050 batchs: 1097.7940673828125
INFO:root:Train (Epoch 105): Loss/seq after 01100 batchs: 1097.0062255859375
INFO:root:Train (Epoch 105): Loss/seq after 01150 batchs: 1089.045654296875
INFO:root:Train (Epoch 105): Loss/seq after 01200 batchs: 1083.078125
INFO:root:Train (Epoch 105): Loss/seq after 01250 batchs: 1077.9017333984375
INFO:root:Train (Epoch 105): Loss/seq after 01300 batchs: 1085.8402099609375
INFO:root:Train (Epoch 105): Loss/seq after 01350 batchs: 1088.2406005859375
INFO:root:Train (Epoch 105): Loss/seq after 01400 batchs: 1108.1922607421875
INFO:root:Train (Epoch 105): Loss/seq after 01450 batchs: 1101.8438720703125
INFO:root:Train (Epoch 105): Loss/seq after 01500 batchs: 1098.195068359375
INFO:root:Train (Epoch 105): Loss/seq after 01550 batchs: 1099.2344970703125
INFO:root:Train (Epoch 105): Loss/seq after 01600 batchs: 1087.1419677734375
INFO:root:Train (Epoch 105): Loss/seq after 01650 batchs: 1076.8243408203125
INFO:root:Train (Epoch 105): Loss/seq after 01700 batchs: 1072.3719482421875
INFO:root:Train (Epoch 105): Loss/seq after 01750 batchs: 1065.5301513671875
INFO:root:Train (Epoch 105): Loss/seq after 01800 batchs: 1056.02783203125
INFO:root:Train (Epoch 105): Loss/seq after 01850 batchs: 1045.8895263671875
INFO:root:Train (Epoch 105): Loss/seq after 01900 batchs: 1043.6837158203125
INFO:root:Train (Epoch 105): Loss/seq after 01950 batchs: 1037.5146484375
INFO:root:Train (Epoch 105): Loss/seq after 02000 batchs: 1031.9949951171875
INFO:root:Train (Epoch 105): Loss/seq after 02050 batchs: 1025.798828125
INFO:root:Train (Epoch 105): Loss/seq after 02100 batchs: 1017.7245483398438
INFO:root:Train (Epoch 105): Loss/seq after 02150 batchs: 1010.15234375
INFO:root:Train (Epoch 105): Loss/seq after 02200 batchs: 1002.409912109375
INFO:root:Train (Epoch 105): Loss/seq after 02250 batchs: 1002.15380859375
INFO:root:Train (Epoch 105): Loss/seq after 02300 batchs: 1008.29541015625
INFO:root:Train (Epoch 105): Loss/seq after 02350 batchs: 999.816162109375
INFO:root:Train (Epoch 105): Loss/seq after 02400 batchs: 998.0344848632812
INFO:root:Train (Epoch 105): Loss/seq after 02450 batchs: 988.759765625
INFO:root:Train (Epoch 105): Loss/seq after 02500 batchs: 976.0167236328125
INFO:root:Train (Epoch 105): Loss/seq after 02550 batchs: 966.8832397460938
INFO:root:Train (Epoch 105): Loss/seq after 02600 batchs: 967.3751220703125
INFO:root:Train (Epoch 105): Loss/seq after 02650 batchs: 965.1991577148438
INFO:root:Train (Epoch 105): Loss/seq after 02700 batchs: 963.7764282226562
INFO:root:Train (Epoch 105): Loss/seq after 02750 batchs: 979.4213256835938
INFO:root:Train (Epoch 105): Loss/seq after 02800 batchs: 985.042724609375
INFO:root:Train (Epoch 105): Loss/seq after 02850 batchs: 981.435546875
INFO:root:Train (Epoch 105): Loss/seq after 02900 batchs: 980.9139404296875
INFO:root:Train (Epoch 105): Loss/seq after 02950 batchs: 974.9164428710938
INFO:root:Train (Epoch 105): Loss/seq after 03000 batchs: 975.9279174804688
INFO:root:Train (Epoch 105): Loss/seq after 03050 batchs: 979.54248046875
INFO:root:Train (Epoch 105): Loss/seq after 03100 batchs: 985.0245361328125
INFO:root:Train (Epoch 105): Loss/seq after 03150 batchs: 993.5755004882812
INFO:root:Train (Epoch 105): Loss/seq after 03200 batchs: 1001.510009765625
INFO:root:Train (Epoch 105): Loss/seq after 03250 batchs: 1004.4451293945312
INFO:root:Train (Epoch 105): Loss/seq after 03300 batchs: 1003.3201293945312
INFO:root:Train (Epoch 105): Loss/seq after 03350 batchs: 1003.1561889648438
INFO:root:Train (Epoch 105): Loss/seq after 03400 batchs: 997.639892578125
INFO:root:Train (Epoch 105): Loss/seq after 03450 batchs: 991.7619018554688
INFO:root:Train (Epoch 105): Loss/seq after 03500 batchs: 990.0448608398438
INFO:root:Train (Epoch 105): Loss/seq after 03550 batchs: 984.3456420898438
INFO:root:Train (Epoch 105): Loss/seq after 03600 batchs: 990.7684936523438
INFO:root:Train (Epoch 105): Loss/seq after 03650 batchs: 985.8820190429688
INFO:root:Train (Epoch 105): Loss/seq after 03700 batchs: 986.3427124023438
INFO:root:Train (Epoch 105): Loss/seq after 03750 batchs: 988.6602172851562
INFO:root:Train (Epoch 105): Loss/seq after 03800 batchs: 984.1307983398438
INFO:root:Train (Epoch 105): Loss/seq after 03850 batchs: 981.6947631835938
INFO:root:Train (Epoch 105): Loss/seq after 03900 batchs: 985.582763671875
INFO:root:Train (Epoch 105): Loss/seq after 03950 batchs: 989.3755493164062
INFO:root:Train (Epoch 105): Loss/seq after 04000 batchs: 983.166015625
INFO:root:Train (Epoch 105): Loss/seq after 04050 batchs: 977.819091796875
INFO:root:Train (Epoch 105): Loss/seq after 04100 batchs: 972.970703125
INFO:root:Train (Epoch 105): Loss/seq after 04150 batchs: 969.421875
INFO:root:Train (Epoch 105): Loss/seq after 04200 batchs: 964.7427368164062
INFO:root:Train (Epoch 105): Loss/seq after 04250 batchs: 961.783203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 105): Loss/seq after 00000 batches: 866.0892333984375
INFO:root:# Valid (Epoch 105): Loss/seq after 00050 batches: 1086.7041015625
INFO:root:# Valid (Epoch 105): Loss/seq after 00100 batches: 1366.7982177734375
INFO:root:# Valid (Epoch 105): Loss/seq after 00150 batches: 1081.7987060546875
INFO:root:# Valid (Epoch 105): Loss/seq after 00200 batches: 967.6041259765625
INFO:root:Artifacts: Make stick videos for epoch 105
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_105_on_20220423_051155.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_105_index_504_on_20220423_051155.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 106): Loss/seq after 00000 batchs: 1781.2032470703125
INFO:root:Train (Epoch 106): Loss/seq after 00050 batchs: 1289.225830078125
INFO:root:Train (Epoch 106): Loss/seq after 00100 batchs: 1215.775146484375
INFO:root:Train (Epoch 106): Loss/seq after 00150 batchs: 1077.4581298828125
INFO:root:Train (Epoch 106): Loss/seq after 00200 batchs: 1208.536376953125
INFO:root:Train (Epoch 106): Loss/seq after 00250 batchs: 1328.7498779296875
INFO:root:Train (Epoch 106): Loss/seq after 00300 batchs: 1283.9322509765625
INFO:root:Train (Epoch 106): Loss/seq after 00350 batchs: 1208.7659912109375
INFO:root:Train (Epoch 106): Loss/seq after 00400 batchs: 1225.2569580078125
INFO:root:Train (Epoch 106): Loss/seq after 00450 batchs: 1183.37109375
INFO:root:Train (Epoch 106): Loss/seq after 00500 batchs: 1165.7255859375
INFO:root:Train (Epoch 106): Loss/seq after 00550 batchs: 1123.193359375
INFO:root:Train (Epoch 106): Loss/seq after 00600 batchs: 1096.252197265625
INFO:root:Train (Epoch 106): Loss/seq after 00650 batchs: 1117.7806396484375
INFO:root:Train (Epoch 106): Loss/seq after 00700 batchs: 1108.585205078125
INFO:root:Train (Epoch 106): Loss/seq after 00750 batchs: 1141.9930419921875
INFO:root:Train (Epoch 106): Loss/seq after 00800 batchs: 1129.4683837890625
INFO:root:Train (Epoch 106): Loss/seq after 00850 batchs: 1105.471435546875
INFO:root:Train (Epoch 106): Loss/seq after 00900 batchs: 1117.123779296875
INFO:root:Train (Epoch 106): Loss/seq after 00950 batchs: 1132.36865234375
INFO:root:Train (Epoch 106): Loss/seq after 01000 batchs: 1128.7459716796875
INFO:root:Train (Epoch 106): Loss/seq after 01050 batchs: 1113.405517578125
INFO:root:Train (Epoch 106): Loss/seq after 01100 batchs: 1112.138916015625
INFO:root:Train (Epoch 106): Loss/seq after 01150 batchs: 1103.73388671875
INFO:root:Train (Epoch 106): Loss/seq after 01200 batchs: 1097.384521484375
INFO:root:Train (Epoch 106): Loss/seq after 01250 batchs: 1093.286376953125
INFO:root:Train (Epoch 106): Loss/seq after 01300 batchs: 1099.1988525390625
INFO:root:Train (Epoch 106): Loss/seq after 01350 batchs: 1100.501708984375
INFO:root:Train (Epoch 106): Loss/seq after 01400 batchs: 1118.854736328125
INFO:root:Train (Epoch 106): Loss/seq after 01450 batchs: 1112.40087890625
INFO:root:Train (Epoch 106): Loss/seq after 01500 batchs: 1108.3770751953125
INFO:root:Train (Epoch 106): Loss/seq after 01550 batchs: 1109.1300048828125
INFO:root:Train (Epoch 106): Loss/seq after 01600 batchs: 1096.89453125
INFO:root:Train (Epoch 106): Loss/seq after 01650 batchs: 1087.0137939453125
INFO:root:Train (Epoch 106): Loss/seq after 01700 batchs: 1082.6904296875
INFO:root:Train (Epoch 106): Loss/seq after 01750 batchs: 1075.70458984375
INFO:root:Train (Epoch 106): Loss/seq after 01800 batchs: 1065.936279296875
INFO:root:Train (Epoch 106): Loss/seq after 01850 batchs: 1055.2327880859375
INFO:root:Train (Epoch 106): Loss/seq after 01900 batchs: 1052.6422119140625
INFO:root:Train (Epoch 106): Loss/seq after 01950 batchs: 1046.1937255859375
INFO:root:Train (Epoch 106): Loss/seq after 02000 batchs: 1040.4287109375
INFO:root:Train (Epoch 106): Loss/seq after 02050 batchs: 1034.0118408203125
INFO:root:Train (Epoch 106): Loss/seq after 02100 batchs: 1025.680908203125
INFO:root:Train (Epoch 106): Loss/seq after 02150 batchs: 1018.0321044921875
INFO:root:Train (Epoch 106): Loss/seq after 02200 batchs: 1010.2278442382812
INFO:root:Train (Epoch 106): Loss/seq after 02250 batchs: 1009.4879150390625
INFO:root:Train (Epoch 106): Loss/seq after 02300 batchs: 1014.8355102539062
INFO:root:Train (Epoch 106): Loss/seq after 02350 batchs: 1006.283935546875
INFO:root:Train (Epoch 106): Loss/seq after 02400 batchs: 1004.3115234375
INFO:root:Train (Epoch 106): Loss/seq after 02450 batchs: 994.912353515625
INFO:root:Train (Epoch 106): Loss/seq after 02500 batchs: 982.0488891601562
INFO:root:Train (Epoch 106): Loss/seq after 02550 batchs: 972.9430541992188
INFO:root:Train (Epoch 106): Loss/seq after 02600 batchs: 973.3374633789062
INFO:root:Train (Epoch 106): Loss/seq after 02650 batchs: 971.0234985351562
INFO:root:Train (Epoch 106): Loss/seq after 02700 batchs: 968.5637817382812
INFO:root:Train (Epoch 106): Loss/seq after 02750 batchs: 983.63916015625
INFO:root:Train (Epoch 106): Loss/seq after 02800 batchs: 989.4862670898438
INFO:root:Train (Epoch 106): Loss/seq after 02850 batchs: 985.9609985351562
INFO:root:Train (Epoch 106): Loss/seq after 02900 batchs: 984.833984375
INFO:root:Train (Epoch 106): Loss/seq after 02950 batchs: 978.7381591796875
INFO:root:Train (Epoch 106): Loss/seq after 03000 batchs: 979.6957397460938
INFO:root:Train (Epoch 106): Loss/seq after 03050 batchs: 985.0525512695312
INFO:root:Train (Epoch 106): Loss/seq after 03100 batchs: 988.6981201171875
INFO:root:Train (Epoch 106): Loss/seq after 03150 batchs: 993.7803955078125
INFO:root:Train (Epoch 106): Loss/seq after 03200 batchs: 1000.949951171875
INFO:root:Train (Epoch 106): Loss/seq after 03250 batchs: 1004.5520629882812
INFO:root:Train (Epoch 106): Loss/seq after 03300 batchs: 1003.0032958984375
INFO:root:Train (Epoch 106): Loss/seq after 03350 batchs: 1003.2772216796875
INFO:root:Train (Epoch 106): Loss/seq after 03400 batchs: 997.7564697265625
INFO:root:Train (Epoch 106): Loss/seq after 03450 batchs: 991.7974243164062
INFO:root:Train (Epoch 106): Loss/seq after 03500 batchs: 989.98193359375
INFO:root:Train (Epoch 106): Loss/seq after 03550 batchs: 984.2418212890625
INFO:root:Train (Epoch 106): Loss/seq after 03600 batchs: 990.7587890625
INFO:root:Train (Epoch 106): Loss/seq after 03650 batchs: 986.0721435546875
INFO:root:Train (Epoch 106): Loss/seq after 03700 batchs: 986.6358032226562
INFO:root:Train (Epoch 106): Loss/seq after 03750 batchs: 988.9636840820312
INFO:root:Train (Epoch 106): Loss/seq after 03800 batchs: 984.4344482421875
INFO:root:Train (Epoch 106): Loss/seq after 03850 batchs: 981.9500732421875
INFO:root:Train (Epoch 106): Loss/seq after 03900 batchs: 985.966796875
INFO:root:Train (Epoch 106): Loss/seq after 03950 batchs: 989.6591796875
INFO:root:Train (Epoch 106): Loss/seq after 04000 batchs: 983.4622192382812
INFO:root:Train (Epoch 106): Loss/seq after 04050 batchs: 978.1450805664062
INFO:root:Train (Epoch 106): Loss/seq after 04100 batchs: 973.4150390625
INFO:root:Train (Epoch 106): Loss/seq after 04150 batchs: 969.86865234375
INFO:root:Train (Epoch 106): Loss/seq after 04200 batchs: 965.27587890625
INFO:root:Train (Epoch 106): Loss/seq after 04250 batchs: 962.296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 106): Loss/seq after 00000 batches: 872.3419189453125
INFO:root:# Valid (Epoch 106): Loss/seq after 00050 batches: 1085.79052734375
INFO:root:# Valid (Epoch 106): Loss/seq after 00100 batches: 1366.71728515625
INFO:root:# Valid (Epoch 106): Loss/seq after 00150 batches: 1080.521484375
INFO:root:# Valid (Epoch 106): Loss/seq after 00200 batches: 965.6993408203125
INFO:root:Artifacts: Make stick videos for epoch 106
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_106_on_20220423_051652.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_106_index_629_on_20220423_051652.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 107): Loss/seq after 00000 batchs: 2136.61376953125
INFO:root:Train (Epoch 107): Loss/seq after 00050 batchs: 1291.216796875
INFO:root:Train (Epoch 107): Loss/seq after 00100 batchs: 1232.1883544921875
INFO:root:Train (Epoch 107): Loss/seq after 00150 batchs: 1094.6361083984375
INFO:root:Train (Epoch 107): Loss/seq after 00200 batchs: 1214.70947265625
INFO:root:Train (Epoch 107): Loss/seq after 00250 batchs: 1329.10888671875
INFO:root:Train (Epoch 107): Loss/seq after 00300 batchs: 1284.0611572265625
INFO:root:Train (Epoch 107): Loss/seq after 00350 batchs: 1207.1361083984375
INFO:root:Train (Epoch 107): Loss/seq after 00400 batchs: 1224.0145263671875
INFO:root:Train (Epoch 107): Loss/seq after 00450 batchs: 1182.8702392578125
INFO:root:Train (Epoch 107): Loss/seq after 00500 batchs: 1165.6495361328125
INFO:root:Train (Epoch 107): Loss/seq after 00550 batchs: 1123.0081787109375
INFO:root:Train (Epoch 107): Loss/seq after 00600 batchs: 1096.490966796875
INFO:root:Train (Epoch 107): Loss/seq after 00650 batchs: 1106.0179443359375
INFO:root:Train (Epoch 107): Loss/seq after 00700 batchs: 1098.9580078125
INFO:root:Train (Epoch 107): Loss/seq after 00750 batchs: 1129.0318603515625
INFO:root:Train (Epoch 107): Loss/seq after 00800 batchs: 1118.10107421875
INFO:root:Train (Epoch 107): Loss/seq after 00850 batchs: 1094.89208984375
INFO:root:Train (Epoch 107): Loss/seq after 00900 batchs: 1107.0152587890625
INFO:root:Train (Epoch 107): Loss/seq after 00950 batchs: 1113.580078125
INFO:root:Train (Epoch 107): Loss/seq after 01000 batchs: 1107.4449462890625
INFO:root:Train (Epoch 107): Loss/seq after 01050 batchs: 1092.27099609375
INFO:root:Train (Epoch 107): Loss/seq after 01100 batchs: 1091.194091796875
INFO:root:Train (Epoch 107): Loss/seq after 01150 batchs: 1083.473388671875
INFO:root:Train (Epoch 107): Loss/seq after 01200 batchs: 1078.075927734375
INFO:root:Train (Epoch 107): Loss/seq after 01250 batchs: 1075.1077880859375
INFO:root:Train (Epoch 107): Loss/seq after 01300 batchs: 1080.052734375
INFO:root:Train (Epoch 107): Loss/seq after 01350 batchs: 1082.4976806640625
INFO:root:Train (Epoch 107): Loss/seq after 01400 batchs: 1096.0491943359375
INFO:root:Train (Epoch 107): Loss/seq after 01450 batchs: 1090.4200439453125
INFO:root:Train (Epoch 107): Loss/seq after 01500 batchs: 1087.230712890625
INFO:root:Train (Epoch 107): Loss/seq after 01550 batchs: 1088.865966796875
INFO:root:Train (Epoch 107): Loss/seq after 01600 batchs: 1076.9578857421875
INFO:root:Train (Epoch 107): Loss/seq after 01650 batchs: 1067.63818359375
INFO:root:Train (Epoch 107): Loss/seq after 01700 batchs: 1063.9617919921875
INFO:root:Train (Epoch 107): Loss/seq after 01750 batchs: 1057.7864990234375
INFO:root:Train (Epoch 107): Loss/seq after 01800 batchs: 1048.5028076171875
INFO:root:Train (Epoch 107): Loss/seq after 01850 batchs: 1038.4188232421875
INFO:root:Train (Epoch 107): Loss/seq after 01900 batchs: 1036.3662109375
INFO:root:Train (Epoch 107): Loss/seq after 01950 batchs: 1030.9337158203125
INFO:root:Train (Epoch 107): Loss/seq after 02000 batchs: 1025.5703125
INFO:root:Train (Epoch 107): Loss/seq after 02050 batchs: 1019.3333740234375
INFO:root:Train (Epoch 107): Loss/seq after 02100 batchs: 1011.462158203125
INFO:root:Train (Epoch 107): Loss/seq after 02150 batchs: 1004.1012573242188
INFO:root:Train (Epoch 107): Loss/seq after 02200 batchs: 996.4793090820312
INFO:root:Train (Epoch 107): Loss/seq after 02250 batchs: 995.4612426757812
INFO:root:Train (Epoch 107): Loss/seq after 02300 batchs: 1001.8765869140625
INFO:root:Train (Epoch 107): Loss/seq after 02350 batchs: 993.6184692382812
INFO:root:Train (Epoch 107): Loss/seq after 02400 batchs: 991.9290771484375
INFO:root:Train (Epoch 107): Loss/seq after 02450 batchs: 982.7821044921875
INFO:root:Train (Epoch 107): Loss/seq after 02500 batchs: 970.1503295898438
INFO:root:Train (Epoch 107): Loss/seq after 02550 batchs: 961.2647705078125
INFO:root:Train (Epoch 107): Loss/seq after 02600 batchs: 961.898193359375
INFO:root:Train (Epoch 107): Loss/seq after 02650 batchs: 959.824951171875
INFO:root:Train (Epoch 107): Loss/seq after 02700 batchs: 957.18310546875
INFO:root:Train (Epoch 107): Loss/seq after 02750 batchs: 972.4081420898438
INFO:root:Train (Epoch 107): Loss/seq after 02800 batchs: 979.102294921875
INFO:root:Train (Epoch 107): Loss/seq after 02850 batchs: 975.6228637695312
INFO:root:Train (Epoch 107): Loss/seq after 02900 batchs: 975.0153198242188
INFO:root:Train (Epoch 107): Loss/seq after 02950 batchs: 969.0642700195312
INFO:root:Train (Epoch 107): Loss/seq after 03000 batchs: 970.1486206054688
INFO:root:Train (Epoch 107): Loss/seq after 03050 batchs: 975.683837890625
INFO:root:Train (Epoch 107): Loss/seq after 03100 batchs: 980.3372192382812
INFO:root:Train (Epoch 107): Loss/seq after 03150 batchs: 985.4067993164062
INFO:root:Train (Epoch 107): Loss/seq after 03200 batchs: 990.9715576171875
INFO:root:Train (Epoch 107): Loss/seq after 03250 batchs: 993.6248779296875
INFO:root:Train (Epoch 107): Loss/seq after 03300 batchs: 991.648681640625
INFO:root:Train (Epoch 107): Loss/seq after 03350 batchs: 991.749755859375
INFO:root:Train (Epoch 107): Loss/seq after 03400 batchs: 986.3892211914062
INFO:root:Train (Epoch 107): Loss/seq after 03450 batchs: 980.5518188476562
INFO:root:Train (Epoch 107): Loss/seq after 03500 batchs: 979.0233764648438
INFO:root:Train (Epoch 107): Loss/seq after 03550 batchs: 973.3182983398438
INFO:root:Train (Epoch 107): Loss/seq after 03600 batchs: 979.7261962890625
INFO:root:Train (Epoch 107): Loss/seq after 03650 batchs: 974.8447875976562
INFO:root:Train (Epoch 107): Loss/seq after 03700 batchs: 975.3001098632812
INFO:root:Train (Epoch 107): Loss/seq after 03750 batchs: 977.69970703125
INFO:root:Train (Epoch 107): Loss/seq after 03800 batchs: 973.35546875
INFO:root:Train (Epoch 107): Loss/seq after 03850 batchs: 971.0394897460938
INFO:root:Train (Epoch 107): Loss/seq after 03900 batchs: 975.0679931640625
INFO:root:Train (Epoch 107): Loss/seq after 03950 batchs: 979.27001953125
INFO:root:Train (Epoch 107): Loss/seq after 04000 batchs: 973.193603515625
INFO:root:Train (Epoch 107): Loss/seq after 04050 batchs: 967.9954223632812
INFO:root:Train (Epoch 107): Loss/seq after 04100 batchs: 963.2860717773438
INFO:root:Train (Epoch 107): Loss/seq after 04150 batchs: 959.8633422851562
INFO:root:Train (Epoch 107): Loss/seq after 04200 batchs: 955.348388671875
INFO:root:Train (Epoch 107): Loss/seq after 04250 batchs: 952.4330444335938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 107): Loss/seq after 00000 batches: 876.3870239257812
INFO:root:# Valid (Epoch 107): Loss/seq after 00050 batches: 1097.8857421875
INFO:root:# Valid (Epoch 107): Loss/seq after 00100 batches: 1375.8739013671875
INFO:root:# Valid (Epoch 107): Loss/seq after 00150 batches: 1085.5445556640625
INFO:root:# Valid (Epoch 107): Loss/seq after 00200 batches: 971.338134765625
INFO:root:Artifacts: Make stick videos for epoch 107
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_107_on_20220423_052139.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_107_index_1640_on_20220423_052139.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 108): Loss/seq after 00000 batchs: 1555.0457763671875
INFO:root:Train (Epoch 108): Loss/seq after 00050 batchs: 1205.5635986328125
INFO:root:Train (Epoch 108): Loss/seq after 00100 batchs: 1184.0703125
INFO:root:Train (Epoch 108): Loss/seq after 00150 batchs: 1055.8087158203125
INFO:root:Train (Epoch 108): Loss/seq after 00200 batchs: 1176.3682861328125
INFO:root:Train (Epoch 108): Loss/seq after 00250 batchs: 1303.7042236328125
INFO:root:Train (Epoch 108): Loss/seq after 00300 batchs: 1262.8983154296875
INFO:root:Train (Epoch 108): Loss/seq after 00350 batchs: 1188.4871826171875
INFO:root:Train (Epoch 108): Loss/seq after 00400 batchs: 1206.0518798828125
INFO:root:Train (Epoch 108): Loss/seq after 00450 batchs: 1166.115966796875
INFO:root:Train (Epoch 108): Loss/seq after 00500 batchs: 1144.1546630859375
INFO:root:Train (Epoch 108): Loss/seq after 00550 batchs: 1103.7508544921875
INFO:root:Train (Epoch 108): Loss/seq after 00600 batchs: 1077.7908935546875
INFO:root:Train (Epoch 108): Loss/seq after 00650 batchs: 1089.0267333984375
INFO:root:Train (Epoch 108): Loss/seq after 00700 batchs: 1084.5709228515625
INFO:root:Train (Epoch 108): Loss/seq after 00750 batchs: 1113.6236572265625
INFO:root:Train (Epoch 108): Loss/seq after 00800 batchs: 1102.8800048828125
INFO:root:Train (Epoch 108): Loss/seq after 00850 batchs: 1080.8126220703125
INFO:root:Train (Epoch 108): Loss/seq after 00900 batchs: 1093.6109619140625
INFO:root:Train (Epoch 108): Loss/seq after 00950 batchs: 1101.906494140625
INFO:root:Train (Epoch 108): Loss/seq after 01000 batchs: 1099.33154296875
INFO:root:Train (Epoch 108): Loss/seq after 01050 batchs: 1085.3525390625
INFO:root:Train (Epoch 108): Loss/seq after 01100 batchs: 1084.2398681640625
INFO:root:Train (Epoch 108): Loss/seq after 01150 batchs: 1077.0517578125
INFO:root:Train (Epoch 108): Loss/seq after 01200 batchs: 1071.6046142578125
INFO:root:Train (Epoch 108): Loss/seq after 01250 batchs: 1067.8482666015625
INFO:root:Train (Epoch 108): Loss/seq after 01300 batchs: 1073.3255615234375
INFO:root:Train (Epoch 108): Loss/seq after 01350 batchs: 1075.4296875
INFO:root:Train (Epoch 108): Loss/seq after 01400 batchs: 1085.8533935546875
INFO:root:Train (Epoch 108): Loss/seq after 01450 batchs: 1080.280517578125
INFO:root:Train (Epoch 108): Loss/seq after 01500 batchs: 1077.297607421875
INFO:root:Train (Epoch 108): Loss/seq after 01550 batchs: 1078.76513671875
INFO:root:Train (Epoch 108): Loss/seq after 01600 batchs: 1067.111572265625
INFO:root:Train (Epoch 108): Loss/seq after 01650 batchs: 1057.625244140625
INFO:root:Train (Epoch 108): Loss/seq after 01700 batchs: 1053.875244140625
INFO:root:Train (Epoch 108): Loss/seq after 01750 batchs: 1047.462158203125
INFO:root:Train (Epoch 108): Loss/seq after 01800 batchs: 1038.2186279296875
INFO:root:Train (Epoch 108): Loss/seq after 01850 batchs: 1028.1307373046875
INFO:root:Train (Epoch 108): Loss/seq after 01900 batchs: 1026.0030517578125
INFO:root:Train (Epoch 108): Loss/seq after 01950 batchs: 1019.9549560546875
INFO:root:Train (Epoch 108): Loss/seq after 02000 batchs: 1014.7160034179688
INFO:root:Train (Epoch 108): Loss/seq after 02050 batchs: 1008.650390625
INFO:root:Train (Epoch 108): Loss/seq after 02100 batchs: 1000.9974365234375
INFO:root:Train (Epoch 108): Loss/seq after 02150 batchs: 994.1174926757812
INFO:root:Train (Epoch 108): Loss/seq after 02200 batchs: 986.7636108398438
INFO:root:Train (Epoch 108): Loss/seq after 02250 batchs: 985.6884765625
INFO:root:Train (Epoch 108): Loss/seq after 02300 batchs: 991.384033203125
INFO:root:Train (Epoch 108): Loss/seq after 02350 batchs: 983.614501953125
INFO:root:Train (Epoch 108): Loss/seq after 02400 batchs: 982.169921875
INFO:root:Train (Epoch 108): Loss/seq after 02450 batchs: 973.2457275390625
INFO:root:Train (Epoch 108): Loss/seq after 02500 batchs: 960.8114013671875
INFO:root:Train (Epoch 108): Loss/seq after 02550 batchs: 951.9322509765625
INFO:root:Train (Epoch 108): Loss/seq after 02600 batchs: 952.6727294921875
INFO:root:Train (Epoch 108): Loss/seq after 02650 batchs: 950.7688598632812
INFO:root:Train (Epoch 108): Loss/seq after 02700 batchs: 948.3239135742188
INFO:root:Train (Epoch 108): Loss/seq after 02750 batchs: 963.2615966796875
INFO:root:Train (Epoch 108): Loss/seq after 02800 batchs: 969.3803100585938
INFO:root:Train (Epoch 108): Loss/seq after 02850 batchs: 966.0827026367188
INFO:root:Train (Epoch 108): Loss/seq after 02900 batchs: 965.2615356445312
INFO:root:Train (Epoch 108): Loss/seq after 02950 batchs: 959.4649047851562
INFO:root:Train (Epoch 108): Loss/seq after 03000 batchs: 960.6987915039062
INFO:root:Train (Epoch 108): Loss/seq after 03050 batchs: 966.3682861328125
INFO:root:Train (Epoch 108): Loss/seq after 03100 batchs: 970.4544067382812
INFO:root:Train (Epoch 108): Loss/seq after 03150 batchs: 978.3138427734375
INFO:root:Train (Epoch 108): Loss/seq after 03200 batchs: 984.083984375
INFO:root:Train (Epoch 108): Loss/seq after 03250 batchs: 989.2691040039062
INFO:root:Train (Epoch 108): Loss/seq after 03300 batchs: 986.908447265625
INFO:root:Train (Epoch 108): Loss/seq after 03350 batchs: 986.6424560546875
INFO:root:Train (Epoch 108): Loss/seq after 03400 batchs: 981.3666381835938
INFO:root:Train (Epoch 108): Loss/seq after 03450 batchs: 975.6194458007812
INFO:root:Train (Epoch 108): Loss/seq after 03500 batchs: 973.5739135742188
INFO:root:Train (Epoch 108): Loss/seq after 03550 batchs: 967.9552612304688
INFO:root:Train (Epoch 108): Loss/seq after 03600 batchs: 974.481201171875
INFO:root:Train (Epoch 108): Loss/seq after 03650 batchs: 969.748291015625
INFO:root:Train (Epoch 108): Loss/seq after 03700 batchs: 970.4014892578125
INFO:root:Train (Epoch 108): Loss/seq after 03750 batchs: 972.884765625
INFO:root:Train (Epoch 108): Loss/seq after 03800 batchs: 968.6157836914062
INFO:root:Train (Epoch 108): Loss/seq after 03850 batchs: 966.3583984375
INFO:root:Train (Epoch 108): Loss/seq after 03900 batchs: 969.83154296875
INFO:root:Train (Epoch 108): Loss/seq after 03950 batchs: 973.5221557617188
INFO:root:Train (Epoch 108): Loss/seq after 04000 batchs: 967.515625
INFO:root:Train (Epoch 108): Loss/seq after 04050 batchs: 962.3717651367188
INFO:root:Train (Epoch 108): Loss/seq after 04100 batchs: 957.75048828125
INFO:root:Train (Epoch 108): Loss/seq after 04150 batchs: 954.3592529296875
INFO:root:Train (Epoch 108): Loss/seq after 04200 batchs: 949.8663940429688
INFO:root:Train (Epoch 108): Loss/seq after 04250 batchs: 947.0826416015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 108): Loss/seq after 00000 batches: 870.2426147460938
INFO:root:# Valid (Epoch 108): Loss/seq after 00050 batches: 1092.34912109375
INFO:root:# Valid (Epoch 108): Loss/seq after 00100 batches: 1372.5428466796875
INFO:root:# Valid (Epoch 108): Loss/seq after 00150 batches: 1084.469970703125
INFO:root:# Valid (Epoch 108): Loss/seq after 00200 batches: 969.9081420898438
INFO:root:Artifacts: Make stick videos for epoch 108
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_108_on_20220423_052623.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_108_index_1638_on_20220423_052623.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 109): Loss/seq after 00000 batchs: 1550.88330078125
INFO:root:Train (Epoch 109): Loss/seq after 00050 batchs: 1223.746337890625
INFO:root:Train (Epoch 109): Loss/seq after 00100 batchs: 1211.449951171875
INFO:root:Train (Epoch 109): Loss/seq after 00150 batchs: 1077.650146484375
INFO:root:Train (Epoch 109): Loss/seq after 00200 batchs: 1202.4947509765625
INFO:root:Train (Epoch 109): Loss/seq after 00250 batchs: 1327.5364990234375
INFO:root:Train (Epoch 109): Loss/seq after 00300 batchs: 1282.91259765625
INFO:root:Train (Epoch 109): Loss/seq after 00350 batchs: 1207.1083984375
INFO:root:Train (Epoch 109): Loss/seq after 00400 batchs: 1224.2593994140625
INFO:root:Train (Epoch 109): Loss/seq after 00450 batchs: 1182.7947998046875
INFO:root:Train (Epoch 109): Loss/seq after 00500 batchs: 1163.9373779296875
INFO:root:Train (Epoch 109): Loss/seq after 00550 batchs: 1122.5994873046875
INFO:root:Train (Epoch 109): Loss/seq after 00600 batchs: 1095.8492431640625
INFO:root:Train (Epoch 109): Loss/seq after 00650 batchs: 1104.1702880859375
INFO:root:Train (Epoch 109): Loss/seq after 00700 batchs: 1093.724853515625
INFO:root:Train (Epoch 109): Loss/seq after 00750 batchs: 1120.2772216796875
INFO:root:Train (Epoch 109): Loss/seq after 00800 batchs: 1108.5594482421875
INFO:root:Train (Epoch 109): Loss/seq after 00850 batchs: 1085.67626953125
INFO:root:Train (Epoch 109): Loss/seq after 00900 batchs: 1097.861083984375
INFO:root:Train (Epoch 109): Loss/seq after 00950 batchs: 1105.4180908203125
INFO:root:Train (Epoch 109): Loss/seq after 01000 batchs: 1098.701171875
INFO:root:Train (Epoch 109): Loss/seq after 01050 batchs: 1084.486572265625
INFO:root:Train (Epoch 109): Loss/seq after 01100 batchs: 1083.200439453125
INFO:root:Train (Epoch 109): Loss/seq after 01150 batchs: 1075.733154296875
INFO:root:Train (Epoch 109): Loss/seq after 01200 batchs: 1070.930419921875
INFO:root:Train (Epoch 109): Loss/seq after 01250 batchs: 1066.6748046875
INFO:root:Train (Epoch 109): Loss/seq after 01300 batchs: 1070.17626953125
INFO:root:Train (Epoch 109): Loss/seq after 01350 batchs: 1070.2459716796875
wandb: Network error (ConnectTimeout), entering retry loop.
INFO:root:Train (Epoch 109): Loss/seq after 01400 batchs: 1084.0648193359375
INFO:root:Train (Epoch 109): Loss/seq after 01450 batchs: 1078.4688720703125
INFO:root:Train (Epoch 109): Loss/seq after 01500 batchs: 1075.5020751953125
INFO:root:Train (Epoch 109): Loss/seq after 01550 batchs: 1076.84326171875
INFO:root:Train (Epoch 109): Loss/seq after 01600 batchs: 1065.359130859375
INFO:root:Train (Epoch 109): Loss/seq after 01650 batchs: 1055.919189453125
INFO:root:Train (Epoch 109): Loss/seq after 01700 batchs: 1052.0582275390625
INFO:root:Train (Epoch 109): Loss/seq after 01750 batchs: 1045.8165283203125
INFO:root:Train (Epoch 109): Loss/seq after 01800 batchs: 1036.7818603515625
INFO:root:Train (Epoch 109): Loss/seq after 01850 batchs: 1026.7882080078125
INFO:root:Train (Epoch 109): Loss/seq after 01900 batchs: 1024.82177734375
INFO:root:Train (Epoch 109): Loss/seq after 01950 batchs: 1018.7890014648438
INFO:root:Train (Epoch 109): Loss/seq after 02000 batchs: 1013.6311645507812
INFO:root:Train (Epoch 109): Loss/seq after 02050 batchs: 1007.522216796875
INFO:root:Train (Epoch 109): Loss/seq after 02100 batchs: 999.7446899414062
INFO:root:Train (Epoch 109): Loss/seq after 02150 batchs: 992.68408203125
INFO:root:Train (Epoch 109): Loss/seq after 02200 batchs: 985.46240234375
INFO:root:Train (Epoch 109): Loss/seq after 02250 batchs: 985.104736328125
INFO:root:Train (Epoch 109): Loss/seq after 02300 batchs: 990.436767578125
INFO:root:Train (Epoch 109): Loss/seq after 02350 batchs: 982.515380859375
INFO:root:Train (Epoch 109): Loss/seq after 02400 batchs: 981.0834350585938
INFO:root:Train (Epoch 109): Loss/seq after 02450 batchs: 972.1846923828125
INFO:root:Train (Epoch 109): Loss/seq after 02500 batchs: 959.77099609375
INFO:root:Train (Epoch 109): Loss/seq after 02550 batchs: 950.9464721679688
INFO:root:Train (Epoch 109): Loss/seq after 02600 batchs: 951.8441772460938
INFO:root:Train (Epoch 109): Loss/seq after 02650 batchs: 949.9224853515625
INFO:root:Train (Epoch 109): Loss/seq after 02700 batchs: 947.80908203125
INFO:root:Train (Epoch 109): Loss/seq after 02750 batchs: 963.116455078125
INFO:root:Train (Epoch 109): Loss/seq after 02800 batchs: 970.3607788085938
INFO:root:Train (Epoch 109): Loss/seq after 02850 batchs: 967.49609375
INFO:root:Train (Epoch 109): Loss/seq after 02900 batchs: 966.9090576171875
INFO:root:Train (Epoch 109): Loss/seq after 02950 batchs: 961.0923461914062
INFO:root:Train (Epoch 109): Loss/seq after 03000 batchs: 962.33349609375
INFO:root:Train (Epoch 109): Loss/seq after 03050 batchs: 967.9718627929688
INFO:root:Train (Epoch 109): Loss/seq after 03100 batchs: 972.8029174804688
INFO:root:Train (Epoch 109): Loss/seq after 03150 batchs: 976.6630859375
INFO:root:Train (Epoch 109): Loss/seq after 03200 batchs: 983.9022827148438
INFO:root:Train (Epoch 109): Loss/seq after 03250 batchs: 987.4754638671875
INFO:root:Train (Epoch 109): Loss/seq after 03300 batchs: 985.7848510742188
INFO:root:Train (Epoch 109): Loss/seq after 03350 batchs: 985.8252563476562
INFO:root:Train (Epoch 109): Loss/seq after 03400 batchs: 980.5582885742188
INFO:root:Train (Epoch 109): Loss/seq after 03450 batchs: 974.9447021484375
INFO:root:Train (Epoch 109): Loss/seq after 03500 batchs: 973.365234375
INFO:root:Train (Epoch 109): Loss/seq after 03550 batchs: 967.91015625
INFO:root:Train (Epoch 109): Loss/seq after 03600 batchs: 974.74169921875
INFO:root:Train (Epoch 109): Loss/seq after 03650 batchs: 970.3306274414062
INFO:root:Train (Epoch 109): Loss/seq after 03700 batchs: 971.0050659179688
INFO:root:Train (Epoch 109): Loss/seq after 03750 batchs: 973.4636840820312
INFO:root:Train (Epoch 109): Loss/seq after 03800 batchs: 969.1646728515625
INFO:root:Train (Epoch 109): Loss/seq after 03850 batchs: 966.91796875
INFO:root:Train (Epoch 109): Loss/seq after 03900 batchs: 970.2877807617188
INFO:root:Train (Epoch 109): Loss/seq after 03950 batchs: 974.2553100585938
INFO:root:Train (Epoch 109): Loss/seq after 04000 batchs: 968.2507934570312
INFO:root:Train (Epoch 109): Loss/seq after 04050 batchs: 963.1119995117188
INFO:root:Train (Epoch 109): Loss/seq after 04100 batchs: 958.5360107421875
INFO:root:Train (Epoch 109): Loss/seq after 04150 batchs: 955.14990234375
INFO:root:Train (Epoch 109): Loss/seq after 04200 batchs: 951.16015625
INFO:root:Train (Epoch 109): Loss/seq after 04250 batchs: 948.456298828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 109): Loss/seq after 00000 batches: 877.6775512695312
INFO:root:# Valid (Epoch 109): Loss/seq after 00050 batches: 1094.4981689453125
INFO:root:# Valid (Epoch 109): Loss/seq after 00100 batches: 1373.27392578125
INFO:root:# Valid (Epoch 109): Loss/seq after 00150 batches: 1086.3052978515625
INFO:root:# Valid (Epoch 109): Loss/seq after 00200 batches: 970.6236572265625
INFO:root:Artifacts: Make stick videos for epoch 109
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_109_on_20220423_053122.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_109_index_1750_on_20220423_053122.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 110): Loss/seq after 00000 batchs: 1485.2576904296875
INFO:root:Train (Epoch 110): Loss/seq after 00050 batchs: 1234.6187744140625
INFO:root:Train (Epoch 110): Loss/seq after 00100 batchs: 1209.0614013671875
INFO:root:Train (Epoch 110): Loss/seq after 00150 batchs: 1079.5003662109375
INFO:root:Train (Epoch 110): Loss/seq after 00200 batchs: 1190.129638671875
INFO:root:Train (Epoch 110): Loss/seq after 00250 batchs: 1313.969482421875
INFO:root:Train (Epoch 110): Loss/seq after 00300 batchs: 1272.000244140625
INFO:root:Train (Epoch 110): Loss/seq after 00350 batchs: 1196.7479248046875
INFO:root:Train (Epoch 110): Loss/seq after 00400 batchs: 1209.3948974609375
INFO:root:Train (Epoch 110): Loss/seq after 00450 batchs: 1169.342529296875
INFO:root:Train (Epoch 110): Loss/seq after 00500 batchs: 1148.400390625
INFO:root:Train (Epoch 110): Loss/seq after 00550 batchs: 1107.2291259765625
INFO:root:Train (Epoch 110): Loss/seq after 00600 batchs: 1081.4776611328125
INFO:root:Train (Epoch 110): Loss/seq after 00650 batchs: 1091.1944580078125
INFO:root:Train (Epoch 110): Loss/seq after 00700 batchs: 1078.48095703125
INFO:root:Train (Epoch 110): Loss/seq after 00750 batchs: 1104.098876953125
INFO:root:Train (Epoch 110): Loss/seq after 00800 batchs: 1093.4990234375
INFO:root:Train (Epoch 110): Loss/seq after 00850 batchs: 1071.7369384765625
INFO:root:Train (Epoch 110): Loss/seq after 00900 batchs: 1085.340087890625
INFO:root:Train (Epoch 110): Loss/seq after 00950 batchs: 1098.1612548828125
INFO:root:Train (Epoch 110): Loss/seq after 01000 batchs: 1093.7569580078125
INFO:root:Train (Epoch 110): Loss/seq after 01050 batchs: 1078.6546630859375
INFO:root:Train (Epoch 110): Loss/seq after 01100 batchs: 1076.88037109375
INFO:root:Train (Epoch 110): Loss/seq after 01150 batchs: 1069.9466552734375
INFO:root:Train (Epoch 110): Loss/seq after 01200 batchs: 1064.919677734375
INFO:root:Train (Epoch 110): Loss/seq after 01250 batchs: 1060.8740234375
INFO:root:Train (Epoch 110): Loss/seq after 01300 batchs: 1061.2056884765625
INFO:root:Train (Epoch 110): Loss/seq after 01350 batchs: 1059.865234375
INFO:root:Train (Epoch 110): Loss/seq after 01400 batchs: 1071.888427734375
INFO:root:Train (Epoch 110): Loss/seq after 01450 batchs: 1066.6864013671875
INFO:root:Train (Epoch 110): Loss/seq after 01500 batchs: 1064.1131591796875
INFO:root:Train (Epoch 110): Loss/seq after 01550 batchs: 1066.0675048828125
INFO:root:Train (Epoch 110): Loss/seq after 01600 batchs: 1054.9573974609375
INFO:root:Train (Epoch 110): Loss/seq after 01650 batchs: 1046.7506103515625
INFO:root:Train (Epoch 110): Loss/seq after 01700 batchs: 1043.5068359375
INFO:root:Train (Epoch 110): Loss/seq after 01750 batchs: 1037.7398681640625
INFO:root:Train (Epoch 110): Loss/seq after 01800 batchs: 1028.8824462890625
INFO:root:Train (Epoch 110): Loss/seq after 01850 batchs: 1019.144287109375
INFO:root:Train (Epoch 110): Loss/seq after 01900 batchs: 1017.3051147460938
INFO:root:Train (Epoch 110): Loss/seq after 01950 batchs: 1011.4280395507812
INFO:root:Train (Epoch 110): Loss/seq after 02000 batchs: 1006.4248046875
INFO:root:Train (Epoch 110): Loss/seq after 02050 batchs: 1000.4454345703125
INFO:root:Train (Epoch 110): Loss/seq after 02100 batchs: 992.7877807617188
INFO:root:Train (Epoch 110): Loss/seq after 02150 batchs: 985.8020629882812
INFO:root:Train (Epoch 110): Loss/seq after 02200 batchs: 978.6318969726562
INFO:root:Train (Epoch 110): Loss/seq after 02250 batchs: 977.7159423828125
INFO:root:Train (Epoch 110): Loss/seq after 02300 batchs: 983.9883422851562
INFO:root:Train (Epoch 110): Loss/seq after 02350 batchs: 976.3802490234375
INFO:root:Train (Epoch 110): Loss/seq after 02400 batchs: 975.0746459960938
INFO:root:Train (Epoch 110): Loss/seq after 02450 batchs: 966.3040771484375
INFO:root:Train (Epoch 110): Loss/seq after 02500 batchs: 954.0089721679688
INFO:root:Train (Epoch 110): Loss/seq after 02550 batchs: 945.3583984375
INFO:root:Train (Epoch 110): Loss/seq after 02600 batchs: 946.269775390625
INFO:root:Train (Epoch 110): Loss/seq after 02650 batchs: 944.534912109375
INFO:root:Train (Epoch 110): Loss/seq after 02700 batchs: 942.4163818359375
INFO:root:Train (Epoch 110): Loss/seq after 02750 batchs: 957.7742309570312
INFO:root:Train (Epoch 110): Loss/seq after 02800 batchs: 963.8102416992188
INFO:root:Train (Epoch 110): Loss/seq after 02850 batchs: 960.6015625
INFO:root:Train (Epoch 110): Loss/seq after 02900 batchs: 959.8960571289062
INFO:root:Train (Epoch 110): Loss/seq after 02950 batchs: 954.1976318359375
INFO:root:Train (Epoch 110): Loss/seq after 03000 batchs: 955.5372924804688
INFO:root:Train (Epoch 110): Loss/seq after 03050 batchs: 961.1871948242188
INFO:root:Train (Epoch 110): Loss/seq after 03100 batchs: 965.2254638671875
INFO:root:Train (Epoch 110): Loss/seq after 03150 batchs: 968.845947265625
INFO:root:Train (Epoch 110): Loss/seq after 03200 batchs: 974.576416015625
INFO:root:Train (Epoch 110): Loss/seq after 03250 batchs: 977.6920776367188
INFO:root:Train (Epoch 110): Loss/seq after 03300 batchs: 976.0975952148438
INFO:root:Train (Epoch 110): Loss/seq after 03350 batchs: 976.0303344726562
INFO:root:Train (Epoch 110): Loss/seq after 03400 batchs: 970.8447265625
INFO:root:Train (Epoch 110): Loss/seq after 03450 batchs: 965.3998413085938
INFO:root:Train (Epoch 110): Loss/seq after 03500 batchs: 963.5147705078125
INFO:root:Train (Epoch 110): Loss/seq after 03550 batchs: 958.4486694335938
INFO:root:Train (Epoch 110): Loss/seq after 03600 batchs: 965.2655029296875
INFO:root:Train (Epoch 110): Loss/seq after 03650 batchs: 960.832275390625
INFO:root:Train (Epoch 110): Loss/seq after 03700 batchs: 961.5151977539062
INFO:root:Train (Epoch 110): Loss/seq after 03750 batchs: 964.1726684570312
INFO:root:Train (Epoch 110): Loss/seq after 03800 batchs: 959.9931030273438
INFO:root:Train (Epoch 110): Loss/seq after 03850 batchs: 957.8316650390625
INFO:root:Train (Epoch 110): Loss/seq after 03900 batchs: 961.9979248046875
INFO:root:Train (Epoch 110): Loss/seq after 03950 batchs: 966.019775390625
INFO:root:Train (Epoch 110): Loss/seq after 04000 batchs: 960.1113891601562
INFO:root:Train (Epoch 110): Loss/seq after 04050 batchs: 955.0529174804688
INFO:root:Train (Epoch 110): Loss/seq after 04100 batchs: 950.5377197265625
INFO:root:Train (Epoch 110): Loss/seq after 04150 batchs: 947.2444458007812
INFO:root:Train (Epoch 110): Loss/seq after 04200 batchs: 942.8833618164062
INFO:root:Train (Epoch 110): Loss/seq after 04250 batchs: 940.1397705078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 110): Loss/seq after 00000 batches: 863.1725463867188
INFO:root:# Valid (Epoch 110): Loss/seq after 00050 batches: 1083.10400390625
INFO:root:# Valid (Epoch 110): Loss/seq after 00100 batches: 1356.6685791015625
INFO:root:# Valid (Epoch 110): Loss/seq after 00150 batches: 1074.5054931640625
INFO:root:# Valid (Epoch 110): Loss/seq after 00200 batches: 960.7152099609375
INFO:root:Artifacts: Make stick videos for epoch 110
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_110_on_20220423_053607.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_110_index_57_on_20220423_053607.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 111): Loss/seq after 00000 batchs: 1365.7000732421875
INFO:root:Train (Epoch 111): Loss/seq after 00050 batchs: 1209.2164306640625
INFO:root:Train (Epoch 111): Loss/seq after 00100 batchs: 1191.95947265625
INFO:root:Train (Epoch 111): Loss/seq after 00150 batchs: 1064.8974609375
INFO:root:Train (Epoch 111): Loss/seq after 00200 batchs: 1184.906982421875
INFO:root:Train (Epoch 111): Loss/seq after 00250 batchs: 1301.4869384765625
INFO:root:Train (Epoch 111): Loss/seq after 00300 batchs: 1261.2091064453125
INFO:root:Train (Epoch 111): Loss/seq after 00350 batchs: 1189.7706298828125
INFO:root:Train (Epoch 111): Loss/seq after 00400 batchs: 1205.2786865234375
INFO:root:Train (Epoch 111): Loss/seq after 00450 batchs: 1166.5235595703125
INFO:root:Train (Epoch 111): Loss/seq after 00500 batchs: 1146.604248046875
INFO:root:Train (Epoch 111): Loss/seq after 00550 batchs: 1106.3934326171875
INFO:root:Train (Epoch 111): Loss/seq after 00600 batchs: 1079.2486572265625
INFO:root:Train (Epoch 111): Loss/seq after 00650 batchs: 1087.41162109375
INFO:root:Train (Epoch 111): Loss/seq after 00700 batchs: 1070.1815185546875
INFO:root:Train (Epoch 111): Loss/seq after 00750 batchs: 1096.892822265625
INFO:root:Train (Epoch 111): Loss/seq after 00800 batchs: 1086.4534912109375
INFO:root:Train (Epoch 111): Loss/seq after 00850 batchs: 1065.2476806640625
INFO:root:Train (Epoch 111): Loss/seq after 00900 batchs: 1078.7816162109375
INFO:root:Train (Epoch 111): Loss/seq after 00950 batchs: 1087.4093017578125
INFO:root:Train (Epoch 111): Loss/seq after 01000 batchs: 1082.9168701171875
INFO:root:Train (Epoch 111): Loss/seq after 01050 batchs: 1068.34521484375
INFO:root:Train (Epoch 111): Loss/seq after 01100 batchs: 1067.116943359375
INFO:root:Train (Epoch 111): Loss/seq after 01150 batchs: 1060.3685302734375
INFO:root:Train (Epoch 111): Loss/seq after 01200 batchs: 1055.620849609375
INFO:root:Train (Epoch 111): Loss/seq after 01250 batchs: 1052.9464111328125
INFO:root:Train (Epoch 111): Loss/seq after 01300 batchs: 1050.5506591796875
INFO:root:Train (Epoch 111): Loss/seq after 01350 batchs: 1049.60693359375
INFO:root:Train (Epoch 111): Loss/seq after 01400 batchs: 1061.4002685546875
INFO:root:Train (Epoch 111): Loss/seq after 01450 batchs: 1056.55615234375
INFO:root:Train (Epoch 111): Loss/seq after 01500 batchs: 1054.329345703125
INFO:root:Train (Epoch 111): Loss/seq after 01550 batchs: 1055.843994140625
INFO:root:Train (Epoch 111): Loss/seq after 01600 batchs: 1044.704345703125
INFO:root:Train (Epoch 111): Loss/seq after 01650 batchs: 1036.0511474609375
INFO:root:Train (Epoch 111): Loss/seq after 01700 batchs: 1033.0223388671875
INFO:root:Train (Epoch 111): Loss/seq after 01750 batchs: 1027.4366455078125
INFO:root:Train (Epoch 111): Loss/seq after 01800 batchs: 1018.8453979492188
INFO:root:Train (Epoch 111): Loss/seq after 01850 batchs: 1009.3236083984375
INFO:root:Train (Epoch 111): Loss/seq after 01900 batchs: 1007.7408447265625
INFO:root:Train (Epoch 111): Loss/seq after 01950 batchs: 1002.7848510742188
INFO:root:Train (Epoch 111): Loss/seq after 02000 batchs: 998.0899047851562
INFO:root:Train (Epoch 111): Loss/seq after 02050 batchs: 992.268310546875
INFO:root:Train (Epoch 111): Loss/seq after 02100 batchs: 984.860595703125
INFO:root:Train (Epoch 111): Loss/seq after 02150 batchs: 978.0503540039062
INFO:root:Train (Epoch 111): Loss/seq after 02200 batchs: 970.9952392578125
INFO:root:Train (Epoch 111): Loss/seq after 02250 batchs: 969.6461791992188
INFO:root:Train (Epoch 111): Loss/seq after 02300 batchs: 976.0281372070312
INFO:root:Train (Epoch 111): Loss/seq after 02350 batchs: 968.2683715820312
INFO:root:Train (Epoch 111): Loss/seq after 02400 batchs: 967.0660400390625
INFO:root:Train (Epoch 111): Loss/seq after 02450 batchs: 958.4470825195312
INFO:root:Train (Epoch 111): Loss/seq after 02500 batchs: 946.3040771484375
INFO:root:Train (Epoch 111): Loss/seq after 02550 batchs: 937.7388916015625
INFO:root:Train (Epoch 111): Loss/seq after 02600 batchs: 938.7759399414062
INFO:root:Train (Epoch 111): Loss/seq after 02650 batchs: 937.2374267578125
INFO:root:Train (Epoch 111): Loss/seq after 02700 batchs: 935.1219482421875
INFO:root:Train (Epoch 111): Loss/seq after 02750 batchs: 949.9036865234375
INFO:root:Train (Epoch 111): Loss/seq after 02800 batchs: 955.7116088867188
INFO:root:Train (Epoch 111): Loss/seq after 02850 batchs: 952.675048828125
INFO:root:Train (Epoch 111): Loss/seq after 02900 batchs: 952.3340454101562
INFO:root:Train (Epoch 111): Loss/seq after 02950 batchs: 946.7312622070312
INFO:root:Train (Epoch 111): Loss/seq after 03000 batchs: 948.1768798828125
INFO:root:Train (Epoch 111): Loss/seq after 03050 batchs: 953.8590087890625
INFO:root:Train (Epoch 111): Loss/seq after 03100 batchs: 958.6555786132812
INFO:root:Train (Epoch 111): Loss/seq after 03150 batchs: 963.0401000976562
INFO:root:Train (Epoch 111): Loss/seq after 03200 batchs: 967.9258422851562
INFO:root:Train (Epoch 111): Loss/seq after 03250 batchs: 970.2394409179688
INFO:root:Train (Epoch 111): Loss/seq after 03300 batchs: 968.2693481445312
INFO:root:Train (Epoch 111): Loss/seq after 03350 batchs: 967.8745727539062
INFO:root:Train (Epoch 111): Loss/seq after 03400 batchs: 962.8237915039062
INFO:root:Train (Epoch 111): Loss/seq after 03450 batchs: 957.3385009765625
INFO:root:Train (Epoch 111): Loss/seq after 03500 batchs: 955.62744140625
INFO:root:Train (Epoch 111): Loss/seq after 03550 batchs: 950.4304809570312
INFO:root:Train (Epoch 111): Loss/seq after 03600 batchs: 957.2128295898438
INFO:root:Train (Epoch 111): Loss/seq after 03650 batchs: 952.6439819335938
INFO:root:Train (Epoch 111): Loss/seq after 03700 batchs: 953.4634399414062
INFO:root:Train (Epoch 111): Loss/seq after 03750 batchs: 956.1676025390625
INFO:root:Train (Epoch 111): Loss/seq after 03800 batchs: 952.0653686523438
INFO:root:Train (Epoch 111): Loss/seq after 03850 batchs: 949.9854736328125
INFO:root:Train (Epoch 111): Loss/seq after 03900 batchs: 953.2938232421875
INFO:root:Train (Epoch 111): Loss/seq after 03950 batchs: 957.474365234375
INFO:root:Train (Epoch 111): Loss/seq after 04000 batchs: 951.6782836914062
INFO:root:Train (Epoch 111): Loss/seq after 04050 batchs: 946.7344970703125
INFO:root:Train (Epoch 111): Loss/seq after 04100 batchs: 942.2740478515625
INFO:root:Train (Epoch 111): Loss/seq after 04150 batchs: 939.0706176757812
INFO:root:Train (Epoch 111): Loss/seq after 04200 batchs: 934.747802734375
INFO:root:Train (Epoch 111): Loss/seq after 04250 batchs: 932.075927734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 111): Loss/seq after 00000 batches: 875.15625
INFO:root:# Valid (Epoch 111): Loss/seq after 00050 batches: 1094.0023193359375
INFO:root:# Valid (Epoch 111): Loss/seq after 00100 batches: 1376.6226806640625
INFO:root:# Valid (Epoch 111): Loss/seq after 00150 batches: 1087.70703125
INFO:root:# Valid (Epoch 111): Loss/seq after 00200 batches: 973.5674438476562
INFO:root:Artifacts: Make stick videos for epoch 111
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_111_on_20220423_054108.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_111_index_746_on_20220423_054108.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 112): Loss/seq after 00000 batchs: 1380.3836669921875
INFO:root:Train (Epoch 112): Loss/seq after 00050 batchs: 1223.044677734375
INFO:root:Train (Epoch 112): Loss/seq after 00100 batchs: 1176.9862060546875
INFO:root:Train (Epoch 112): Loss/seq after 00150 batchs: 1046.8543701171875
INFO:root:Train (Epoch 112): Loss/seq after 00200 batchs: 1160.2763671875
INFO:root:Train (Epoch 112): Loss/seq after 00250 batchs: 1287.8206787109375
INFO:root:Train (Epoch 112): Loss/seq after 00300 batchs: 1249.76171875
INFO:root:Train (Epoch 112): Loss/seq after 00350 batchs: 1177.7298583984375
INFO:root:Train (Epoch 112): Loss/seq after 00400 batchs: 1193.1190185546875
INFO:root:Train (Epoch 112): Loss/seq after 00450 batchs: 1155.1131591796875
INFO:root:Train (Epoch 112): Loss/seq after 00500 batchs: 1136.4395751953125
INFO:root:Train (Epoch 112): Loss/seq after 00550 batchs: 1096.6754150390625
INFO:root:Train (Epoch 112): Loss/seq after 00600 batchs: 1071.760009765625
INFO:root:Train (Epoch 112): Loss/seq after 00650 batchs: 1077.40087890625
INFO:root:Train (Epoch 112): Loss/seq after 00700 batchs: 1076.9801025390625
INFO:root:Train (Epoch 112): Loss/seq after 00750 batchs: 1103.963134765625
INFO:root:Train (Epoch 112): Loss/seq after 00800 batchs: 1093.192138671875
INFO:root:Train (Epoch 112): Loss/seq after 00850 batchs: 1071.2420654296875
INFO:root:Train (Epoch 112): Loss/seq after 00900 batchs: 1084.14990234375
INFO:root:Train (Epoch 112): Loss/seq after 00950 batchs: 1096.456787109375
INFO:root:Train (Epoch 112): Loss/seq after 01000 batchs: 1088.8057861328125
INFO:root:Train (Epoch 112): Loss/seq after 01050 batchs: 1074.06005859375
INFO:root:Train (Epoch 112): Loss/seq after 01100 batchs: 1071.739990234375
INFO:root:Train (Epoch 112): Loss/seq after 01150 batchs: 1064.761962890625
INFO:root:Train (Epoch 112): Loss/seq after 01200 batchs: 1059.866455078125
INFO:root:Train (Epoch 112): Loss/seq after 01250 batchs: 1055.2418212890625
INFO:root:Train (Epoch 112): Loss/seq after 01300 batchs: 1056.8927001953125
INFO:root:Train (Epoch 112): Loss/seq after 01350 batchs: 1055.9080810546875
INFO:root:Train (Epoch 112): Loss/seq after 01400 batchs: 1067.8287353515625
INFO:root:Train (Epoch 112): Loss/seq after 01450 batchs: 1062.8294677734375
INFO:root:Train (Epoch 112): Loss/seq after 01500 batchs: 1060.3277587890625
INFO:root:Train (Epoch 112): Loss/seq after 01550 batchs: 1062.2562255859375
INFO:root:Train (Epoch 112): Loss/seq after 01600 batchs: 1051.2025146484375
INFO:root:Train (Epoch 112): Loss/seq after 01650 batchs: 1041.8809814453125
INFO:root:Train (Epoch 112): Loss/seq after 01700 batchs: 1038.3966064453125
INFO:root:Train (Epoch 112): Loss/seq after 01750 batchs: 1032.3433837890625
INFO:root:Train (Epoch 112): Loss/seq after 01800 batchs: 1023.4219970703125
INFO:root:Train (Epoch 112): Loss/seq after 01850 batchs: 1013.6345825195312
INFO:root:Train (Epoch 112): Loss/seq after 01900 batchs: 1011.8493041992188
INFO:root:Train (Epoch 112): Loss/seq after 01950 batchs: 1005.99853515625
INFO:root:Train (Epoch 112): Loss/seq after 02000 batchs: 1001.0376586914062
INFO:root:Train (Epoch 112): Loss/seq after 02050 batchs: 995.456787109375
INFO:root:Train (Epoch 112): Loss/seq after 02100 batchs: 988.1478881835938
INFO:root:Train (Epoch 112): Loss/seq after 02150 batchs: 981.2466430664062
INFO:root:Train (Epoch 112): Loss/seq after 02200 batchs: 974.1083374023438
INFO:root:Train (Epoch 112): Loss/seq after 02250 batchs: 972.8789672851562
INFO:root:Train (Epoch 112): Loss/seq after 02300 batchs: 978.1594848632812
INFO:root:Train (Epoch 112): Loss/seq after 02350 batchs: 970.4275512695312
INFO:root:Train (Epoch 112): Loss/seq after 02400 batchs: 969.28125
INFO:root:Train (Epoch 112): Loss/seq after 02450 batchs: 960.6602172851562
INFO:root:Train (Epoch 112): Loss/seq after 02500 batchs: 948.4752197265625
INFO:root:Train (Epoch 112): Loss/seq after 02550 batchs: 939.7333984375
INFO:root:Train (Epoch 112): Loss/seq after 02600 batchs: 940.7431640625
INFO:root:Train (Epoch 112): Loss/seq after 02650 batchs: 938.9884033203125
INFO:root:Train (Epoch 112): Loss/seq after 02700 batchs: 936.7716064453125
INFO:root:Train (Epoch 112): Loss/seq after 02750 batchs: 951.5475463867188
INFO:root:Train (Epoch 112): Loss/seq after 02800 batchs: 957.7341918945312
INFO:root:Train (Epoch 112): Loss/seq after 02850 batchs: 954.5037231445312
INFO:root:Train (Epoch 112): Loss/seq after 02900 batchs: 953.7864990234375
INFO:root:Train (Epoch 112): Loss/seq after 02950 batchs: 948.1331787109375
INFO:root:Train (Epoch 112): Loss/seq after 03000 batchs: 949.515380859375
INFO:root:Train (Epoch 112): Loss/seq after 03050 batchs: 955.21240234375
INFO:root:Train (Epoch 112): Loss/seq after 03100 batchs: 959.1903686523438
INFO:root:Train (Epoch 112): Loss/seq after 03150 batchs: 963.0504760742188
INFO:root:Train (Epoch 112): Loss/seq after 03200 batchs: 968.3135986328125
INFO:root:Train (Epoch 112): Loss/seq after 03250 batchs: 971.2470703125
INFO:root:Train (Epoch 112): Loss/seq after 03300 batchs: 969.2894897460938
INFO:root:Train (Epoch 112): Loss/seq after 03350 batchs: 969.289794921875
INFO:root:Train (Epoch 112): Loss/seq after 03400 batchs: 964.2250366210938
INFO:root:Train (Epoch 112): Loss/seq after 03450 batchs: 958.8602905273438
INFO:root:Train (Epoch 112): Loss/seq after 03500 batchs: 957.5115356445312
INFO:root:Train (Epoch 112): Loss/seq after 03550 batchs: 952.4661254882812
INFO:root:Train (Epoch 112): Loss/seq after 03600 batchs: 959.21826171875
INFO:root:Train (Epoch 112): Loss/seq after 03650 batchs: 954.802490234375
INFO:root:Train (Epoch 112): Loss/seq after 03700 batchs: 955.5142822265625
INFO:root:Train (Epoch 112): Loss/seq after 03750 batchs: 958.1787109375
INFO:root:Train (Epoch 112): Loss/seq after 03800 batchs: 954.0593872070312
INFO:root:Train (Epoch 112): Loss/seq after 03850 batchs: 951.9971313476562
INFO:root:Train (Epoch 112): Loss/seq after 03900 batchs: 956.14501953125
INFO:root:Train (Epoch 112): Loss/seq after 03950 batchs: 960.3973999023438
INFO:root:Train (Epoch 112): Loss/seq after 04000 batchs: 954.5556640625
INFO:root:Train (Epoch 112): Loss/seq after 04050 batchs: 949.5739135742188
INFO:root:Train (Epoch 112): Loss/seq after 04100 batchs: 945.0711669921875
INFO:root:Train (Epoch 112): Loss/seq after 04150 batchs: 941.8305053710938
INFO:root:Train (Epoch 112): Loss/seq after 04200 batchs: 937.5319213867188
INFO:root:Train (Epoch 112): Loss/seq after 04250 batchs: 934.8466796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 112): Loss/seq after 00000 batches: 876.2044677734375
INFO:root:# Valid (Epoch 112): Loss/seq after 00050 batches: 1092.373779296875
INFO:root:# Valid (Epoch 112): Loss/seq after 00100 batches: 1362.8363037109375
INFO:root:# Valid (Epoch 112): Loss/seq after 00150 batches: 1078.059814453125
INFO:root:# Valid (Epoch 112): Loss/seq after 00200 batches: 963.7531127929688
INFO:root:Artifacts: Make stick videos for epoch 112
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_112_on_20220423_054559.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_112_index_1586_on_20220423_054559.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 113): Loss/seq after 00000 batchs: 1818.2978515625
INFO:root:Train (Epoch 113): Loss/seq after 00050 batchs: 1211.914306640625
INFO:root:Train (Epoch 113): Loss/seq after 00100 batchs: 1176.6390380859375
INFO:root:Train (Epoch 113): Loss/seq after 00150 batchs: 1054.763916015625
INFO:root:Train (Epoch 113): Loss/seq after 00200 batchs: 1170.0404052734375
INFO:root:Train (Epoch 113): Loss/seq after 00250 batchs: 1302.86669921875
INFO:root:Train (Epoch 113): Loss/seq after 00300 batchs: 1261.9471435546875
INFO:root:Train (Epoch 113): Loss/seq after 00350 batchs: 1188.5037841796875
INFO:root:Train (Epoch 113): Loss/seq after 00400 batchs: 1213.511474609375
INFO:root:Train (Epoch 113): Loss/seq after 00450 batchs: 1174.119140625
INFO:root:Train (Epoch 113): Loss/seq after 00500 batchs: 1153.27880859375
INFO:root:Train (Epoch 113): Loss/seq after 00550 batchs: 1111.427490234375
INFO:root:Train (Epoch 113): Loss/seq after 00600 batchs: 1083.64111328125
INFO:root:Train (Epoch 113): Loss/seq after 00650 batchs: 1097.8494873046875
INFO:root:Train (Epoch 113): Loss/seq after 00700 batchs: 1085.615478515625
INFO:root:Train (Epoch 113): Loss/seq after 00750 batchs: 1109.5660400390625
INFO:root:Train (Epoch 113): Loss/seq after 00800 batchs: 1097.297119140625
INFO:root:Train (Epoch 113): Loss/seq after 00850 batchs: 1075.364013671875
INFO:root:Train (Epoch 113): Loss/seq after 00900 batchs: 1088.595703125
INFO:root:Train (Epoch 113): Loss/seq after 00950 batchs: 1096.6290283203125
INFO:root:Train (Epoch 113): Loss/seq after 01000 batchs: 1091.3111572265625
INFO:root:Train (Epoch 113): Loss/seq after 01050 batchs: 1075.6844482421875
INFO:root:Train (Epoch 113): Loss/seq after 01100 batchs: 1074.876708984375
INFO:root:Train (Epoch 113): Loss/seq after 01150 batchs: 1067.9227294921875
INFO:root:Train (Epoch 113): Loss/seq after 01200 batchs: 1062.8553466796875
INFO:root:Train (Epoch 113): Loss/seq after 01250 batchs: 1058.4908447265625
INFO:root:Train (Epoch 113): Loss/seq after 01300 batchs: 1057.8170166015625
INFO:root:Train (Epoch 113): Loss/seq after 01350 batchs: 1057.043212890625
INFO:root:Train (Epoch 113): Loss/seq after 01400 batchs: 1069.799560546875
INFO:root:Train (Epoch 113): Loss/seq after 01450 batchs: 1064.9200439453125
INFO:root:Train (Epoch 113): Loss/seq after 01500 batchs: 1062.4417724609375
INFO:root:Train (Epoch 113): Loss/seq after 01550 batchs: 1064.118896484375
INFO:root:Train (Epoch 113): Loss/seq after 01600 batchs: 1052.8778076171875
INFO:root:Train (Epoch 113): Loss/seq after 01650 batchs: 1043.749755859375
INFO:root:Train (Epoch 113): Loss/seq after 01700 batchs: 1040.4423828125
INFO:root:Train (Epoch 113): Loss/seq after 01750 batchs: 1034.643310546875
INFO:root:Train (Epoch 113): Loss/seq after 01800 batchs: 1025.72216796875
INFO:root:Train (Epoch 113): Loss/seq after 01850 batchs: 1016.1142578125
INFO:root:Train (Epoch 113): Loss/seq after 01900 batchs: 1014.5596313476562
INFO:root:Train (Epoch 113): Loss/seq after 01950 batchs: 1009.2572021484375
INFO:root:Train (Epoch 113): Loss/seq after 02000 batchs: 1004.410400390625
INFO:root:Train (Epoch 113): Loss/seq after 02050 batchs: 998.392333984375
INFO:root:Train (Epoch 113): Loss/seq after 02100 batchs: 990.7789306640625
INFO:root:Train (Epoch 113): Loss/seq after 02150 batchs: 983.77392578125
INFO:root:Train (Epoch 113): Loss/seq after 02200 batchs: 976.5699462890625
INFO:root:Train (Epoch 113): Loss/seq after 02250 batchs: 974.6919555664062
INFO:root:Train (Epoch 113): Loss/seq after 02300 batchs: 979.9153442382812
INFO:root:Train (Epoch 113): Loss/seq after 02350 batchs: 972.03271484375
INFO:root:Train (Epoch 113): Loss/seq after 02400 batchs: 970.7691650390625
INFO:root:Train (Epoch 113): Loss/seq after 02450 batchs: 962.0377197265625
INFO:root:Train (Epoch 113): Loss/seq after 02500 batchs: 949.8192749023438
INFO:root:Train (Epoch 113): Loss/seq after 02550 batchs: 941.0491943359375
INFO:root:Train (Epoch 113): Loss/seq after 02600 batchs: 941.9791259765625
INFO:root:Train (Epoch 113): Loss/seq after 02650 batchs: 940.2734985351562
INFO:root:Train (Epoch 113): Loss/seq after 02700 batchs: 937.6542358398438
INFO:root:Train (Epoch 113): Loss/seq after 02750 batchs: 952.522216796875
INFO:root:Train (Epoch 113): Loss/seq after 02800 batchs: 958.36279296875
INFO:root:Train (Epoch 113): Loss/seq after 02850 batchs: 955.3573608398438
INFO:root:Train (Epoch 113): Loss/seq after 02900 batchs: 954.5006713867188
INFO:root:Train (Epoch 113): Loss/seq after 02950 batchs: 948.8624267578125
INFO:root:Train (Epoch 113): Loss/seq after 03000 batchs: 950.20703125
INFO:root:Train (Epoch 113): Loss/seq after 03050 batchs: 955.8656616210938
INFO:root:Train (Epoch 113): Loss/seq after 03100 batchs: 960.7711181640625
INFO:root:Train (Epoch 113): Loss/seq after 03150 batchs: 965.2416381835938
INFO:root:Train (Epoch 113): Loss/seq after 03200 batchs: 971.276123046875
INFO:root:Train (Epoch 113): Loss/seq after 03250 batchs: 974.10888671875
INFO:root:Train (Epoch 113): Loss/seq after 03300 batchs: 972.697021484375
INFO:root:Train (Epoch 113): Loss/seq after 03350 batchs: 972.918212890625
INFO:root:Train (Epoch 113): Loss/seq after 03400 batchs: 967.8411254882812
INFO:root:Train (Epoch 113): Loss/seq after 03450 batchs: 962.3440551757812
INFO:root:Train (Epoch 113): Loss/seq after 03500 batchs: 960.9764404296875
INFO:root:Train (Epoch 113): Loss/seq after 03550 batchs: 955.9949951171875
INFO:root:Train (Epoch 113): Loss/seq after 03600 batchs: 963.0371704101562
INFO:root:Train (Epoch 113): Loss/seq after 03650 batchs: 958.8377685546875
INFO:root:Train (Epoch 113): Loss/seq after 03700 batchs: 959.65771484375
INFO:root:Train (Epoch 113): Loss/seq after 03750 batchs: 962.278564453125
INFO:root:Train (Epoch 113): Loss/seq after 03800 batchs: 958.0974731445312
INFO:root:Train (Epoch 113): Loss/seq after 03850 batchs: 955.9752197265625
INFO:root:Train (Epoch 113): Loss/seq after 03900 batchs: 959.7680053710938
INFO:root:Train (Epoch 113): Loss/seq after 03950 batchs: 963.404296875
INFO:root:Train (Epoch 113): Loss/seq after 04000 batchs: 957.5266723632812
INFO:root:Train (Epoch 113): Loss/seq after 04050 batchs: 952.5035400390625
INFO:root:Train (Epoch 113): Loss/seq after 04100 batchs: 948.0145874023438
INFO:root:Train (Epoch 113): Loss/seq after 04150 batchs: 944.7323608398438
INFO:root:Train (Epoch 113): Loss/seq after 04200 batchs: 940.27734375
INFO:root:Train (Epoch 113): Loss/seq after 04250 batchs: 937.529052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 113): Loss/seq after 00000 batches: 882.8609619140625
INFO:root:# Valid (Epoch 113): Loss/seq after 00050 batches: 1086.7049560546875
INFO:root:# Valid (Epoch 113): Loss/seq after 00100 batches: 1367.730224609375
INFO:root:# Valid (Epoch 113): Loss/seq after 00150 batches: 1080.682373046875
INFO:root:# Valid (Epoch 113): Loss/seq after 00200 batches: 965.2122192382812
INFO:root:Artifacts: Make stick videos for epoch 113
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_113_on_20220423_055046.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_113_index_233_on_20220423_055046.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 114): Loss/seq after 00000 batchs: 1653.3433837890625
INFO:root:Train (Epoch 114): Loss/seq after 00050 batchs: 1177.4727783203125
INFO:root:Train (Epoch 114): Loss/seq after 00100 batchs: 1148.5382080078125
INFO:root:Train (Epoch 114): Loss/seq after 00150 batchs: 1034.078857421875
INFO:root:Train (Epoch 114): Loss/seq after 00200 batchs: 1153.1937255859375
INFO:root:Train (Epoch 114): Loss/seq after 00250 batchs: 1280.892578125
INFO:root:Train (Epoch 114): Loss/seq after 00300 batchs: 1243.874267578125
INFO:root:Train (Epoch 114): Loss/seq after 00350 batchs: 1173.2359619140625
INFO:root:Train (Epoch 114): Loss/seq after 00400 batchs: 1188.3924560546875
INFO:root:Train (Epoch 114): Loss/seq after 00450 batchs: 1150.072021484375
INFO:root:Train (Epoch 114): Loss/seq after 00500 batchs: 1129.8311767578125
INFO:root:Train (Epoch 114): Loss/seq after 00550 batchs: 1090.88720703125
INFO:root:Train (Epoch 114): Loss/seq after 00600 batchs: 1064.760009765625
INFO:root:Train (Epoch 114): Loss/seq after 00650 batchs: 1071.2061767578125
INFO:root:Train (Epoch 114): Loss/seq after 00700 batchs: 1058.020751953125
INFO:root:Train (Epoch 114): Loss/seq after 00750 batchs: 1084.21337890625
INFO:root:Train (Epoch 114): Loss/seq after 00800 batchs: 1073.536865234375
INFO:root:Train (Epoch 114): Loss/seq after 00850 batchs: 1052.781982421875
INFO:root:Train (Epoch 114): Loss/seq after 00900 batchs: 1066.3873291015625
INFO:root:Train (Epoch 114): Loss/seq after 00950 batchs: 1072.3939208984375
INFO:root:Train (Epoch 114): Loss/seq after 01000 batchs: 1067.0596923828125
INFO:root:Train (Epoch 114): Loss/seq after 01050 batchs: 1052.3006591796875
INFO:root:Train (Epoch 114): Loss/seq after 01100 batchs: 1052.82763671875
INFO:root:Train (Epoch 114): Loss/seq after 01150 batchs: 1046.9964599609375
INFO:root:Train (Epoch 114): Loss/seq after 01200 batchs: 1042.7147216796875
INFO:root:Train (Epoch 114): Loss/seq after 01250 batchs: 1038.6324462890625
INFO:root:Train (Epoch 114): Loss/seq after 01300 batchs: 1039.880126953125
INFO:root:Train (Epoch 114): Loss/seq after 01350 batchs: 1035.25146484375
INFO:root:Train (Epoch 114): Loss/seq after 01400 batchs: 1044.8953857421875
INFO:root:Train (Epoch 114): Loss/seq after 01450 batchs: 1040.57470703125
INFO:root:Train (Epoch 114): Loss/seq after 01500 batchs: 1038.721923828125
INFO:root:Train (Epoch 114): Loss/seq after 01550 batchs: 1041.024658203125
INFO:root:Train (Epoch 114): Loss/seq after 01600 batchs: 1030.42724609375
INFO:root:Train (Epoch 114): Loss/seq after 01650 batchs: 1021.764404296875
INFO:root:Train (Epoch 114): Loss/seq after 01700 batchs: 1018.9788818359375
INFO:root:Train (Epoch 114): Loss/seq after 01750 batchs: 1013.5325317382812
INFO:root:Train (Epoch 114): Loss/seq after 01800 batchs: 1005.1610717773438
INFO:root:Train (Epoch 114): Loss/seq after 01850 batchs: 996.0768432617188
INFO:root:Train (Epoch 114): Loss/seq after 01900 batchs: 994.8348388671875
INFO:root:Train (Epoch 114): Loss/seq after 01950 batchs: 990.0146484375
INFO:root:Train (Epoch 114): Loss/seq after 02000 batchs: 985.532470703125
INFO:root:Train (Epoch 114): Loss/seq after 02050 batchs: 979.93994140625
INFO:root:Train (Epoch 114): Loss/seq after 02100 batchs: 972.8822631835938
INFO:root:Train (Epoch 114): Loss/seq after 02150 batchs: 966.4873046875
INFO:root:Train (Epoch 114): Loss/seq after 02200 batchs: 959.735107421875
INFO:root:Train (Epoch 114): Loss/seq after 02250 batchs: 959.2658081054688
INFO:root:Train (Epoch 114): Loss/seq after 02300 batchs: 965.6574096679688
INFO:root:Train (Epoch 114): Loss/seq after 02350 batchs: 958.2288208007812
INFO:root:Train (Epoch 114): Loss/seq after 02400 batchs: 957.412353515625
INFO:root:Train (Epoch 114): Loss/seq after 02450 batchs: 948.9752197265625
INFO:root:Train (Epoch 114): Loss/seq after 02500 batchs: 937.0338134765625
INFO:root:Train (Epoch 114): Loss/seq after 02550 batchs: 928.580810546875
INFO:root:Train (Epoch 114): Loss/seq after 02600 batchs: 929.860595703125
INFO:root:Train (Epoch 114): Loss/seq after 02650 batchs: 928.3499755859375
INFO:root:Train (Epoch 114): Loss/seq after 02700 batchs: 925.5513305664062
INFO:root:Train (Epoch 114): Loss/seq after 02750 batchs: 939.5919799804688
INFO:root:Train (Epoch 114): Loss/seq after 02800 batchs: 945.3189697265625
INFO:root:Train (Epoch 114): Loss/seq after 02850 batchs: 942.2479858398438
INFO:root:Train (Epoch 114): Loss/seq after 02900 batchs: 941.5210571289062
INFO:root:Train (Epoch 114): Loss/seq after 02950 batchs: 936.1221313476562
INFO:root:Train (Epoch 114): Loss/seq after 03000 batchs: 937.6766357421875
INFO:root:Train (Epoch 114): Loss/seq after 03050 batchs: 942.3839111328125
INFO:root:Train (Epoch 114): Loss/seq after 03100 batchs: 947.194580078125
INFO:root:Train (Epoch 114): Loss/seq after 03150 batchs: 951.905517578125
INFO:root:Train (Epoch 114): Loss/seq after 03200 batchs: 956.6974487304688
INFO:root:Train (Epoch 114): Loss/seq after 03250 batchs: 960.344482421875
INFO:root:Train (Epoch 114): Loss/seq after 03300 batchs: 958.6751098632812
INFO:root:Train (Epoch 114): Loss/seq after 03350 batchs: 958.6174926757812
INFO:root:Train (Epoch 114): Loss/seq after 03400 batchs: 953.7855834960938
INFO:root:Train (Epoch 114): Loss/seq after 03450 batchs: 948.4635620117188
INFO:root:Train (Epoch 114): Loss/seq after 03500 batchs: 946.7493286132812
INFO:root:Train (Epoch 114): Loss/seq after 03550 batchs: 941.2825317382812
INFO:root:Train (Epoch 114): Loss/seq after 03600 batchs: 948.0097045898438
INFO:root:Train (Epoch 114): Loss/seq after 03650 batchs: 943.7843017578125
INFO:root:Train (Epoch 114): Loss/seq after 03700 batchs: 944.6362915039062
INFO:root:Train (Epoch 114): Loss/seq after 03750 batchs: 947.3707275390625
INFO:root:Train (Epoch 114): Loss/seq after 03800 batchs: 943.389404296875
INFO:root:Train (Epoch 114): Loss/seq after 03850 batchs: 941.460205078125
INFO:root:Train (Epoch 114): Loss/seq after 03900 batchs: 945.3557739257812
INFO:root:Train (Epoch 114): Loss/seq after 03950 batchs: 948.83251953125
INFO:root:Train (Epoch 114): Loss/seq after 04000 batchs: 943.146484375
INFO:root:Train (Epoch 114): Loss/seq after 04050 batchs: 938.3257446289062
INFO:root:Train (Epoch 114): Loss/seq after 04100 batchs: 933.966552734375
INFO:root:Train (Epoch 114): Loss/seq after 04150 batchs: 930.8916625976562
INFO:root:Train (Epoch 114): Loss/seq after 04200 batchs: 926.63916015625
INFO:root:Train (Epoch 114): Loss/seq after 04250 batchs: 924.09716796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 114): Loss/seq after 00000 batches: 866.1405029296875
INFO:root:# Valid (Epoch 114): Loss/seq after 00050 batches: 1088.576904296875
INFO:root:# Valid (Epoch 114): Loss/seq after 00100 batches: 1371.54638671875
INFO:root:# Valid (Epoch 114): Loss/seq after 00150 batches: 1087.7027587890625
INFO:root:# Valid (Epoch 114): Loss/seq after 00200 batches: 971.3421630859375
INFO:root:Artifacts: Make stick videos for epoch 114
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_114_on_20220423_055541.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_114_index_548_on_20220423_055541.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 115): Loss/seq after 00000 batchs: 1484.9759521484375
INFO:root:Train (Epoch 115): Loss/seq after 00050 batchs: 1169.3721923828125
INFO:root:Train (Epoch 115): Loss/seq after 00100 batchs: 1155.0487060546875
INFO:root:Train (Epoch 115): Loss/seq after 00150 batchs: 1036.0845947265625
INFO:root:Train (Epoch 115): Loss/seq after 00200 batchs: 1154.283447265625
INFO:root:Train (Epoch 115): Loss/seq after 00250 batchs: 1289.6138916015625
INFO:root:Train (Epoch 115): Loss/seq after 00300 batchs: 1250.73876953125
INFO:root:Train (Epoch 115): Loss/seq after 00350 batchs: 1178.5675048828125
INFO:root:Train (Epoch 115): Loss/seq after 00400 batchs: 1199.1368408203125
INFO:root:Train (Epoch 115): Loss/seq after 00450 batchs: 1159.9307861328125
INFO:root:Train (Epoch 115): Loss/seq after 00500 batchs: 1141.62548828125
INFO:root:Train (Epoch 115): Loss/seq after 00550 batchs: 1100.869140625
INFO:root:Train (Epoch 115): Loss/seq after 00600 batchs: 1074.6046142578125
INFO:root:Train (Epoch 115): Loss/seq after 00650 batchs: 1077.88623046875
INFO:root:Train (Epoch 115): Loss/seq after 00700 batchs: 1065.4791259765625
INFO:root:Train (Epoch 115): Loss/seq after 00750 batchs: 1088.198974609375
INFO:root:Train (Epoch 115): Loss/seq after 00800 batchs: 1079.5509033203125
INFO:root:Train (Epoch 115): Loss/seq after 00850 batchs: 1058.416015625
INFO:root:Train (Epoch 115): Loss/seq after 00900 batchs: 1071.63232421875
INFO:root:Train (Epoch 115): Loss/seq after 00950 batchs: 1081.1533203125
INFO:root:Train (Epoch 115): Loss/seq after 01000 batchs: 1073.879638671875
INFO:root:Train (Epoch 115): Loss/seq after 01050 batchs: 1059.855712890625
INFO:root:Train (Epoch 115): Loss/seq after 01100 batchs: 1058.0162353515625
INFO:root:Train (Epoch 115): Loss/seq after 01150 batchs: 1051.806640625
INFO:root:Train (Epoch 115): Loss/seq after 01200 batchs: 1047.60205078125
INFO:root:Train (Epoch 115): Loss/seq after 01250 batchs: 1043.88330078125
INFO:root:Train (Epoch 115): Loss/seq after 01300 batchs: 1041.5447998046875
INFO:root:Train (Epoch 115): Loss/seq after 01350 batchs: 1035.32958984375
INFO:root:Train (Epoch 115): Loss/seq after 01400 batchs: 1047.6834716796875
INFO:root:Train (Epoch 115): Loss/seq after 01450 batchs: 1043.2103271484375
INFO:root:Train (Epoch 115): Loss/seq after 01500 batchs: 1041.249267578125
INFO:root:Train (Epoch 115): Loss/seq after 01550 batchs: 1043.161865234375
INFO:root:Train (Epoch 115): Loss/seq after 01600 batchs: 1032.59130859375
INFO:root:Train (Epoch 115): Loss/seq after 01650 batchs: 1024.8563232421875
INFO:root:Train (Epoch 115): Loss/seq after 01700 batchs: 1022.1701049804688
INFO:root:Train (Epoch 115): Loss/seq after 01750 batchs: 1016.8977661132812
INFO:root:Train (Epoch 115): Loss/seq after 01800 batchs: 1008.707275390625
INFO:root:Train (Epoch 115): Loss/seq after 01850 batchs: 999.6554565429688
INFO:root:Train (Epoch 115): Loss/seq after 01900 batchs: 998.3825073242188
INFO:root:Train (Epoch 115): Loss/seq after 01950 batchs: 993.2965087890625
INFO:root:Train (Epoch 115): Loss/seq after 02000 batchs: 988.8057861328125
INFO:root:Train (Epoch 115): Loss/seq after 02050 batchs: 983.2085571289062
INFO:root:Train (Epoch 115): Loss/seq after 02100 batchs: 975.89794921875
INFO:root:Train (Epoch 115): Loss/seq after 02150 batchs: 969.2335205078125
INFO:root:Train (Epoch 115): Loss/seq after 02200 batchs: 962.3516845703125
INFO:root:Train (Epoch 115): Loss/seq after 02250 batchs: 962.2371215820312
INFO:root:Train (Epoch 115): Loss/seq after 02300 batchs: 967.0892944335938
INFO:root:Train (Epoch 115): Loss/seq after 02350 batchs: 959.6036987304688
INFO:root:Train (Epoch 115): Loss/seq after 02400 batchs: 958.6224365234375
INFO:root:Train (Epoch 115): Loss/seq after 02450 batchs: 950.1890258789062
INFO:root:Train (Epoch 115): Loss/seq after 02500 batchs: 938.2161865234375
INFO:root:Train (Epoch 115): Loss/seq after 02550 batchs: 929.5722045898438
INFO:root:Train (Epoch 115): Loss/seq after 02600 batchs: 930.6779174804688
INFO:root:Train (Epoch 115): Loss/seq after 02650 batchs: 929.0302734375
INFO:root:Train (Epoch 115): Loss/seq after 02700 batchs: 926.2919921875
INFO:root:Train (Epoch 115): Loss/seq after 02750 batchs: 941.4271240234375
INFO:root:Train (Epoch 115): Loss/seq after 02800 batchs: 945.8870239257812
INFO:root:Train (Epoch 115): Loss/seq after 02850 batchs: 942.8604125976562
INFO:root:Train (Epoch 115): Loss/seq after 02900 batchs: 942.5654296875
INFO:root:Train (Epoch 115): Loss/seq after 02950 batchs: 937.1467895507812
INFO:root:Train (Epoch 115): Loss/seq after 03000 batchs: 938.6869506835938
INFO:root:Train (Epoch 115): Loss/seq after 03050 batchs: 942.349365234375
INFO:root:Train (Epoch 115): Loss/seq after 03100 batchs: 946.6945190429688
INFO:root:Train (Epoch 115): Loss/seq after 03150 batchs: 950.820556640625
INFO:root:Train (Epoch 115): Loss/seq after 03200 batchs: 955.9979858398438
INFO:root:Train (Epoch 115): Loss/seq after 03250 batchs: 959.0054321289062
INFO:root:Train (Epoch 115): Loss/seq after 03300 batchs: 957.8128051757812
INFO:root:Train (Epoch 115): Loss/seq after 03350 batchs: 957.1126708984375
INFO:root:Train (Epoch 115): Loss/seq after 03400 batchs: 952.218017578125
INFO:root:Train (Epoch 115): Loss/seq after 03450 batchs: 946.8656005859375
INFO:root:Train (Epoch 115): Loss/seq after 03500 batchs: 945.3213500976562
INFO:root:Train (Epoch 115): Loss/seq after 03550 batchs: 940.0526733398438
INFO:root:Train (Epoch 115): Loss/seq after 03600 batchs: 947.2603759765625
INFO:root:Train (Epoch 115): Loss/seq after 03650 batchs: 943.5132446289062
INFO:root:Train (Epoch 115): Loss/seq after 03700 batchs: 944.5453491210938
INFO:root:Train (Epoch 115): Loss/seq after 03750 batchs: 947.3010864257812
INFO:root:Train (Epoch 115): Loss/seq after 03800 batchs: 943.32080078125
INFO:root:Train (Epoch 115): Loss/seq after 03850 batchs: 941.3792724609375
INFO:root:Train (Epoch 115): Loss/seq after 03900 batchs: 945.2373046875
INFO:root:Train (Epoch 115): Loss/seq after 03950 batchs: 949.12744140625
INFO:root:Train (Epoch 115): Loss/seq after 04000 batchs: 943.4306030273438
INFO:root:Train (Epoch 115): Loss/seq after 04050 batchs: 938.6171875
INFO:root:Train (Epoch 115): Loss/seq after 04100 batchs: 934.2302856445312
INFO:root:Train (Epoch 115): Loss/seq after 04150 batchs: 931.0656127929688
INFO:root:Train (Epoch 115): Loss/seq after 04200 batchs: 926.8038940429688
INFO:root:Train (Epoch 115): Loss/seq after 04250 batchs: 924.194091796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 115): Loss/seq after 00000 batches: 881.956787109375
INFO:root:# Valid (Epoch 115): Loss/seq after 00050 batches: 1087.410888671875
INFO:root:# Valid (Epoch 115): Loss/seq after 00100 batches: 1365.2022705078125
INFO:root:# Valid (Epoch 115): Loss/seq after 00150 batches: 1079.660400390625
INFO:root:# Valid (Epoch 115): Loss/seq after 00200 batches: 963.3095092773438
INFO:root:Artifacts: Make stick videos for epoch 115
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_115_on_20220423_060028.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_115_index_110_on_20220423_060028.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 116): Loss/seq after 00000 batchs: 1686.7353515625
INFO:root:Train (Epoch 116): Loss/seq after 00050 batchs: 1175.115966796875
INFO:root:Train (Epoch 116): Loss/seq after 00100 batchs: 1135.6793212890625
INFO:root:Train (Epoch 116): Loss/seq after 00150 batchs: 1023.5628051757812
INFO:root:Train (Epoch 116): Loss/seq after 00200 batchs: 1139.94482421875
INFO:root:Train (Epoch 116): Loss/seq after 00250 batchs: 1271.6031494140625
INFO:root:Train (Epoch 116): Loss/seq after 00300 batchs: 1236.4613037109375
INFO:root:Train (Epoch 116): Loss/seq after 00350 batchs: 1166.1466064453125
INFO:root:Train (Epoch 116): Loss/seq after 00400 batchs: 1182.057373046875
INFO:root:Train (Epoch 116): Loss/seq after 00450 batchs: 1144.6651611328125
INFO:root:Train (Epoch 116): Loss/seq after 00500 batchs: 1126.94384765625
INFO:root:Train (Epoch 116): Loss/seq after 00550 batchs: 1087.98486328125
INFO:root:Train (Epoch 116): Loss/seq after 00600 batchs: 1063.0662841796875
INFO:root:Train (Epoch 116): Loss/seq after 00650 batchs: 1072.9339599609375
INFO:root:Train (Epoch 116): Loss/seq after 00700 batchs: 1059.7755126953125
INFO:root:Train (Epoch 116): Loss/seq after 00750 batchs: 1082.16259765625
INFO:root:Train (Epoch 116): Loss/seq after 00800 batchs: 1072.4940185546875
INFO:root:Train (Epoch 116): Loss/seq after 00850 batchs: 1051.45068359375
INFO:root:Train (Epoch 116): Loss/seq after 00900 batchs: 1065.189697265625
INFO:root:Train (Epoch 116): Loss/seq after 00950 batchs: 1074.582275390625
INFO:root:Train (Epoch 116): Loss/seq after 01000 batchs: 1068.5179443359375
INFO:root:Train (Epoch 116): Loss/seq after 01050 batchs: 1054.2332763671875
INFO:root:Train (Epoch 116): Loss/seq after 01100 batchs: 1052.535888671875
INFO:root:Train (Epoch 116): Loss/seq after 01150 batchs: 1047.052978515625
INFO:root:Train (Epoch 116): Loss/seq after 01200 batchs: 1043.5335693359375
INFO:root:Train (Epoch 116): Loss/seq after 01250 batchs: 1038.525146484375
INFO:root:Train (Epoch 116): Loss/seq after 01300 batchs: 1034.052734375
INFO:root:Train (Epoch 116): Loss/seq after 01350 batchs: 1027.7462158203125
INFO:root:Train (Epoch 116): Loss/seq after 01400 batchs: 1038.392333984375
INFO:root:Train (Epoch 116): Loss/seq after 01450 batchs: 1034.324462890625
INFO:root:Train (Epoch 116): Loss/seq after 01500 batchs: 1032.7279052734375
INFO:root:Train (Epoch 116): Loss/seq after 01550 batchs: 1035.4267578125
INFO:root:Train (Epoch 116): Loss/seq after 01600 batchs: 1025.1842041015625
INFO:root:Train (Epoch 116): Loss/seq after 01650 batchs: 1016.7815551757812
INFO:root:Train (Epoch 116): Loss/seq after 01700 batchs: 1014.042236328125
INFO:root:Train (Epoch 116): Loss/seq after 01750 batchs: 1008.7084350585938
INFO:root:Train (Epoch 116): Loss/seq after 01800 batchs: 1000.58935546875
INFO:root:Train (Epoch 116): Loss/seq after 01850 batchs: 991.487548828125
INFO:root:Train (Epoch 116): Loss/seq after 01900 batchs: 990.2620239257812
INFO:root:Train (Epoch 116): Loss/seq after 01950 batchs: 985.27197265625
INFO:root:Train (Epoch 116): Loss/seq after 02000 batchs: 980.84619140625
INFO:root:Train (Epoch 116): Loss/seq after 02050 batchs: 975.3973999023438
INFO:root:Train (Epoch 116): Loss/seq after 02100 batchs: 968.3145141601562
INFO:root:Train (Epoch 116): Loss/seq after 02150 batchs: 961.822021484375
INFO:root:Train (Epoch 116): Loss/seq after 02200 batchs: 955.102783203125
INFO:root:Train (Epoch 116): Loss/seq after 02250 batchs: 954.1170654296875
INFO:root:Train (Epoch 116): Loss/seq after 02300 batchs: 960.1810913085938
INFO:root:Train (Epoch 116): Loss/seq after 02350 batchs: 952.9192504882812
INFO:root:Train (Epoch 116): Loss/seq after 02400 batchs: 952.1905517578125
INFO:root:Train (Epoch 116): Loss/seq after 02450 batchs: 943.9324951171875
INFO:root:Train (Epoch 116): Loss/seq after 02500 batchs: 932.0847778320312
INFO:root:Train (Epoch 116): Loss/seq after 02550 batchs: 923.741943359375
INFO:root:Train (Epoch 116): Loss/seq after 02600 batchs: 925.03466796875
INFO:root:Train (Epoch 116): Loss/seq after 02650 batchs: 923.55712890625
INFO:root:Train (Epoch 116): Loss/seq after 02700 batchs: 921.1786499023438
INFO:root:Train (Epoch 116): Loss/seq after 02750 batchs: 936.7125244140625
INFO:root:Train (Epoch 116): Loss/seq after 02800 batchs: 942.6934204101562
INFO:root:Train (Epoch 116): Loss/seq after 02850 batchs: 939.6369018554688
INFO:root:Train (Epoch 116): Loss/seq after 02900 batchs: 939.5125732421875
INFO:root:Train (Epoch 116): Loss/seq after 02950 batchs: 934.1019897460938
INFO:root:Train (Epoch 116): Loss/seq after 03000 batchs: 935.6939086914062
INFO:root:Train (Epoch 116): Loss/seq after 03050 batchs: 939.3257446289062
INFO:root:Train (Epoch 116): Loss/seq after 03100 batchs: 943.4788818359375
INFO:root:Train (Epoch 116): Loss/seq after 03150 batchs: 946.9790649414062
INFO:root:Train (Epoch 116): Loss/seq after 03200 batchs: 951.2835693359375
INFO:root:Train (Epoch 116): Loss/seq after 03250 batchs: 952.5926513671875
INFO:root:Train (Epoch 116): Loss/seq after 03300 batchs: 951.0441284179688
INFO:root:Train (Epoch 116): Loss/seq after 03350 batchs: 950.5906982421875
INFO:root:Train (Epoch 116): Loss/seq after 03400 batchs: 945.8126220703125
INFO:root:Train (Epoch 116): Loss/seq after 03450 batchs: 940.65234375
INFO:root:Train (Epoch 116): Loss/seq after 03500 batchs: 939.0193481445312
INFO:root:Train (Epoch 116): Loss/seq after 03550 batchs: 933.724853515625
INFO:root:Train (Epoch 116): Loss/seq after 03600 batchs: 940.4983520507812
INFO:root:Train (Epoch 116): Loss/seq after 03650 batchs: 936.34765625
INFO:root:Train (Epoch 116): Loss/seq after 03700 batchs: 937.484375
INFO:root:Train (Epoch 116): Loss/seq after 03750 batchs: 940.35791015625
INFO:root:Train (Epoch 116): Loss/seq after 03800 batchs: 936.4832153320312
INFO:root:Train (Epoch 116): Loss/seq after 03850 batchs: 934.7461547851562
INFO:root:Train (Epoch 116): Loss/seq after 03900 batchs: 938.5160522460938
INFO:root:Train (Epoch 116): Loss/seq after 03950 batchs: 941.8208618164062
INFO:root:Train (Epoch 116): Loss/seq after 04000 batchs: 936.2162475585938
INFO:root:Train (Epoch 116): Loss/seq after 04050 batchs: 931.47119140625
INFO:root:Train (Epoch 116): Loss/seq after 04100 batchs: 927.2877807617188
INFO:root:Train (Epoch 116): Loss/seq after 04150 batchs: 924.2410278320312
INFO:root:Train (Epoch 116): Loss/seq after 04200 batchs: 920.0753173828125
INFO:root:Train (Epoch 116): Loss/seq after 04250 batchs: 917.5814208984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 116): Loss/seq after 00000 batches: 877.1339721679688
INFO:root:# Valid (Epoch 116): Loss/seq after 00050 batches: 1092.1474609375
INFO:root:# Valid (Epoch 116): Loss/seq after 00100 batches: 1376.60205078125
INFO:root:# Valid (Epoch 116): Loss/seq after 00150 batches: 1088.7071533203125
INFO:root:# Valid (Epoch 116): Loss/seq after 00200 batches: 972.3093872070312
INFO:root:Artifacts: Make stick videos for epoch 116
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_116_on_20220423_060528.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_116_index_1753_on_20220423_060528.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 117): Loss/seq after 00000 batchs: 1681.907958984375
INFO:root:Train (Epoch 117): Loss/seq after 00050 batchs: 1162.2451171875
INFO:root:Train (Epoch 117): Loss/seq after 00100 batchs: 1133.8355712890625
INFO:root:Train (Epoch 117): Loss/seq after 00150 batchs: 1019.5867309570312
INFO:root:Train (Epoch 117): Loss/seq after 00200 batchs: 1137.3045654296875
INFO:root:Train (Epoch 117): Loss/seq after 00250 batchs: 1261.4134521484375
INFO:root:Train (Epoch 117): Loss/seq after 00300 batchs: 1227.7943115234375
INFO:root:Train (Epoch 117): Loss/seq after 00350 batchs: 1158.0552978515625
INFO:root:Train (Epoch 117): Loss/seq after 00400 batchs: 1177.5599365234375
INFO:root:Train (Epoch 117): Loss/seq after 00450 batchs: 1140.443115234375
INFO:root:Train (Epoch 117): Loss/seq after 00500 batchs: 1120.5745849609375
INFO:root:Train (Epoch 117): Loss/seq after 00550 batchs: 1080.9986572265625
INFO:root:Train (Epoch 117): Loss/seq after 00600 batchs: 1056.2747802734375
INFO:root:Train (Epoch 117): Loss/seq after 00650 batchs: 1058.746337890625
INFO:root:Train (Epoch 117): Loss/seq after 00700 batchs: 1041.656005859375
INFO:root:Train (Epoch 117): Loss/seq after 00750 batchs: 1065.127685546875
INFO:root:Train (Epoch 117): Loss/seq after 00800 batchs: 1055.4473876953125
INFO:root:Train (Epoch 117): Loss/seq after 00850 batchs: 1035.52099609375
INFO:root:Train (Epoch 117): Loss/seq after 00900 batchs: 1049.95654296875
INFO:root:Train (Epoch 117): Loss/seq after 00950 batchs: 1054.10107421875
INFO:root:Train (Epoch 117): Loss/seq after 01000 batchs: 1048.8392333984375
INFO:root:Train (Epoch 117): Loss/seq after 01050 batchs: 1036.5191650390625
INFO:root:Train (Epoch 117): Loss/seq after 01100 batchs: 1035.9642333984375
INFO:root:Train (Epoch 117): Loss/seq after 01150 batchs: 1031.2972412109375
INFO:root:Train (Epoch 117): Loss/seq after 01200 batchs: 1028.1888427734375
INFO:root:Train (Epoch 117): Loss/seq after 01250 batchs: 1023.239990234375
INFO:root:Train (Epoch 117): Loss/seq after 01300 batchs: 1019.1110229492188
INFO:root:Train (Epoch 117): Loss/seq after 01350 batchs: 1014.1798095703125
INFO:root:Train (Epoch 117): Loss/seq after 01400 batchs: 1024.904296875
INFO:root:Train (Epoch 117): Loss/seq after 01450 batchs: 1021.2755126953125
INFO:root:Train (Epoch 117): Loss/seq after 01500 batchs: 1020.0540161132812
INFO:root:Train (Epoch 117): Loss/seq after 01550 batchs: 1022.8875122070312
INFO:root:Train (Epoch 117): Loss/seq after 01600 batchs: 1013.0432739257812
INFO:root:Train (Epoch 117): Loss/seq after 01650 batchs: 1005.2313232421875
INFO:root:Train (Epoch 117): Loss/seq after 01700 batchs: 1002.9890747070312
INFO:root:Train (Epoch 117): Loss/seq after 01750 batchs: 998.1397094726562
INFO:root:Train (Epoch 117): Loss/seq after 01800 batchs: 990.2266235351562
INFO:root:Train (Epoch 117): Loss/seq after 01850 batchs: 981.4985961914062
INFO:root:Train (Epoch 117): Loss/seq after 01900 batchs: 980.6246948242188
INFO:root:Train (Epoch 117): Loss/seq after 01950 batchs: 975.5862426757812
INFO:root:Train (Epoch 117): Loss/seq after 02000 batchs: 971.3755493164062
INFO:root:Train (Epoch 117): Loss/seq after 02050 batchs: 966.0479736328125
INFO:root:Train (Epoch 117): Loss/seq after 02100 batchs: 959.1470336914062
INFO:root:Train (Epoch 117): Loss/seq after 02150 batchs: 952.806884765625
INFO:root:Train (Epoch 117): Loss/seq after 02200 batchs: 946.27001953125
INFO:root:Train (Epoch 117): Loss/seq after 02250 batchs: 946.3088989257812
INFO:root:Train (Epoch 117): Loss/seq after 02300 batchs: 951.4749145507812
INFO:root:Train (Epoch 117): Loss/seq after 02350 batchs: 944.3223876953125
INFO:root:Train (Epoch 117): Loss/seq after 02400 batchs: 943.6064453125
INFO:root:Train (Epoch 117): Loss/seq after 02450 batchs: 935.4556274414062
INFO:root:Train (Epoch 117): Loss/seq after 02500 batchs: 923.7913818359375
INFO:root:Train (Epoch 117): Loss/seq after 02550 batchs: 915.5005493164062
INFO:root:Train (Epoch 117): Loss/seq after 02600 batchs: 916.8488159179688
INFO:root:Train (Epoch 117): Loss/seq after 02650 batchs: 915.4994506835938
INFO:root:Train (Epoch 117): Loss/seq after 02700 batchs: 913.170166015625
INFO:root:Train (Epoch 117): Loss/seq after 02750 batchs: 928.0389404296875
INFO:root:Train (Epoch 117): Loss/seq after 02800 batchs: 932.7827758789062
INFO:root:Train (Epoch 117): Loss/seq after 02850 batchs: 929.76806640625
INFO:root:Train (Epoch 117): Loss/seq after 02900 batchs: 929.481689453125
INFO:root:Train (Epoch 117): Loss/seq after 02950 batchs: 924.26416015625
INFO:root:Train (Epoch 117): Loss/seq after 03000 batchs: 925.9756469726562
INFO:root:Train (Epoch 117): Loss/seq after 03050 batchs: 929.9134521484375
INFO:root:Train (Epoch 117): Loss/seq after 03100 batchs: 933.0975952148438
INFO:root:Train (Epoch 117): Loss/seq after 03150 batchs: 937.3890380859375
INFO:root:Train (Epoch 117): Loss/seq after 03200 batchs: 941.9102783203125
INFO:root:Train (Epoch 117): Loss/seq after 03250 batchs: 943.43994140625
INFO:root:Train (Epoch 117): Loss/seq after 03300 batchs: 941.4700927734375
INFO:root:Train (Epoch 117): Loss/seq after 03350 batchs: 941.2675170898438
INFO:root:Train (Epoch 117): Loss/seq after 03400 batchs: 936.6123046875
INFO:root:Train (Epoch 117): Loss/seq after 03450 batchs: 931.4515991210938
INFO:root:Train (Epoch 117): Loss/seq after 03500 batchs: 929.7924194335938
INFO:root:Train (Epoch 117): Loss/seq after 03550 batchs: 924.658447265625
INFO:root:Train (Epoch 117): Loss/seq after 03600 batchs: 931.6810913085938
INFO:root:Train (Epoch 117): Loss/seq after 03650 batchs: 927.4019165039062
INFO:root:Train (Epoch 117): Loss/seq after 03700 batchs: 928.4507446289062
INFO:root:Train (Epoch 117): Loss/seq after 03750 batchs: 931.3717651367188
INFO:root:Train (Epoch 117): Loss/seq after 03800 batchs: 927.6021118164062
INFO:root:Train (Epoch 117): Loss/seq after 03850 batchs: 925.8843383789062
INFO:root:Train (Epoch 117): Loss/seq after 03900 batchs: 929.7864379882812
INFO:root:Train (Epoch 117): Loss/seq after 03950 batchs: 933.4576416015625
INFO:root:Train (Epoch 117): Loss/seq after 04000 batchs: 927.9453125
INFO:root:Train (Epoch 117): Loss/seq after 04050 batchs: 923.2994995117188
INFO:root:Train (Epoch 117): Loss/seq after 04100 batchs: 919.1666259765625
INFO:root:Train (Epoch 117): Loss/seq after 04150 batchs: 916.17138671875
INFO:root:Train (Epoch 117): Loss/seq after 04200 batchs: 912.1303100585938
INFO:root:Train (Epoch 117): Loss/seq after 04250 batchs: 909.6854248046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 117): Loss/seq after 00000 batches: 877.3114624023438
INFO:root:# Valid (Epoch 117): Loss/seq after 00050 batches: 1096.1973876953125
INFO:root:# Valid (Epoch 117): Loss/seq after 00100 batches: 1371.712890625
INFO:root:# Valid (Epoch 117): Loss/seq after 00150 batches: 1083.7142333984375
INFO:root:# Valid (Epoch 117): Loss/seq after 00200 batches: 967.3426513671875
INFO:root:Artifacts: Make stick videos for epoch 117
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_117_on_20220423_061026.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_117_index_69_on_20220423_061026.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 118): Loss/seq after 00000 batchs: 1519.1444091796875
INFO:root:Train (Epoch 118): Loss/seq after 00050 batchs: 1190.9993896484375
INFO:root:Train (Epoch 118): Loss/seq after 00100 batchs: 1165.6898193359375
INFO:root:Train (Epoch 118): Loss/seq after 00150 batchs: 1044.2313232421875
INFO:root:Train (Epoch 118): Loss/seq after 00200 batchs: 1177.136962890625
INFO:root:Train (Epoch 118): Loss/seq after 00250 batchs: 1296.712890625
INFO:root:Train (Epoch 118): Loss/seq after 00300 batchs: 1257.2152099609375
INFO:root:Train (Epoch 118): Loss/seq after 00350 batchs: 1184.4537353515625
INFO:root:Train (Epoch 118): Loss/seq after 00400 batchs: 1195.1168212890625
INFO:root:Train (Epoch 118): Loss/seq after 00450 batchs: 1156.419921875
INFO:root:Train (Epoch 118): Loss/seq after 00500 batchs: 1135.6424560546875
INFO:root:Train (Epoch 118): Loss/seq after 00550 batchs: 1095.5428466796875
INFO:root:Train (Epoch 118): Loss/seq after 00600 batchs: 1069.00146484375
INFO:root:Train (Epoch 118): Loss/seq after 00650 batchs: 1071.66259765625
INFO:root:Train (Epoch 118): Loss/seq after 00700 batchs: 1052.3831787109375
INFO:root:Train (Epoch 118): Loss/seq after 00750 batchs: 1074.7113037109375
INFO:root:Train (Epoch 118): Loss/seq after 00800 batchs: 1064.685546875
INFO:root:Train (Epoch 118): Loss/seq after 00850 batchs: 1044.2586669921875
INFO:root:Train (Epoch 118): Loss/seq after 00900 batchs: 1058.478271484375
INFO:root:Train (Epoch 118): Loss/seq after 00950 batchs: 1064.7677001953125
INFO:root:Train (Epoch 118): Loss/seq after 01000 batchs: 1058.780029296875
INFO:root:Train (Epoch 118): Loss/seq after 01050 batchs: 1043.7799072265625
INFO:root:Train (Epoch 118): Loss/seq after 01100 batchs: 1042.364990234375
INFO:root:Train (Epoch 118): Loss/seq after 01150 batchs: 1036.6759033203125
INFO:root:Train (Epoch 118): Loss/seq after 01200 batchs: 1032.5218505859375
INFO:root:Train (Epoch 118): Loss/seq after 01250 batchs: 1026.701171875
INFO:root:Train (Epoch 118): Loss/seq after 01300 batchs: 1020.8350830078125
INFO:root:Train (Epoch 118): Loss/seq after 01350 batchs: 1014.76025390625
INFO:root:Train (Epoch 118): Loss/seq after 01400 batchs: 1025.4417724609375
INFO:root:Train (Epoch 118): Loss/seq after 01450 batchs: 1021.5387573242188
INFO:root:Train (Epoch 118): Loss/seq after 01500 batchs: 1020.160400390625
INFO:root:Train (Epoch 118): Loss/seq after 01550 batchs: 1023.1282958984375
INFO:root:Train (Epoch 118): Loss/seq after 01600 batchs: 1013.0443725585938
INFO:root:Train (Epoch 118): Loss/seq after 01650 batchs: 1004.5073852539062
INFO:root:Train (Epoch 118): Loss/seq after 01700 batchs: 1002.1118774414062
INFO:root:Train (Epoch 118): Loss/seq after 01750 batchs: 997.0718383789062
INFO:root:Train (Epoch 118): Loss/seq after 01800 batchs: 989.1939697265625
INFO:root:Train (Epoch 118): Loss/seq after 01850 batchs: 980.3623657226562
INFO:root:Train (Epoch 118): Loss/seq after 01900 batchs: 979.3680419921875
INFO:root:Train (Epoch 118): Loss/seq after 01950 batchs: 974.8892211914062
INFO:root:Train (Epoch 118): Loss/seq after 02000 batchs: 970.7285766601562
INFO:root:Train (Epoch 118): Loss/seq after 02050 batchs: 965.5059204101562
INFO:root:Train (Epoch 118): Loss/seq after 02100 batchs: 958.7264404296875
INFO:root:Train (Epoch 118): Loss/seq after 02150 batchs: 952.5083618164062
INFO:root:Train (Epoch 118): Loss/seq after 02200 batchs: 945.9744262695312
INFO:root:Train (Epoch 118): Loss/seq after 02250 batchs: 945.3056640625
INFO:root:Train (Epoch 118): Loss/seq after 02300 batchs: 950.9360961914062
INFO:root:Train (Epoch 118): Loss/seq after 02350 batchs: 943.8899536132812
INFO:root:Train (Epoch 118): Loss/seq after 02400 batchs: 943.3169555664062
INFO:root:Train (Epoch 118): Loss/seq after 02450 batchs: 935.1519775390625
INFO:root:Train (Epoch 118): Loss/seq after 02500 batchs: 923.4804077148438
INFO:root:Train (Epoch 118): Loss/seq after 02550 batchs: 915.0967407226562
INFO:root:Train (Epoch 118): Loss/seq after 02600 batchs: 916.4107055664062
INFO:root:Train (Epoch 118): Loss/seq after 02650 batchs: 915.0977172851562
INFO:root:Train (Epoch 118): Loss/seq after 02700 batchs: 912.8214721679688
INFO:root:Train (Epoch 118): Loss/seq after 02750 batchs: 927.8899536132812
INFO:root:Train (Epoch 118): Loss/seq after 02800 batchs: 932.438232421875
INFO:root:Train (Epoch 118): Loss/seq after 02850 batchs: 929.5863647460938
INFO:root:Train (Epoch 118): Loss/seq after 02900 batchs: 929.302001953125
INFO:root:Train (Epoch 118): Loss/seq after 02950 batchs: 924.03466796875
INFO:root:Train (Epoch 118): Loss/seq after 03000 batchs: 925.7677612304688
INFO:root:Train (Epoch 118): Loss/seq after 03050 batchs: 929.9467163085938
INFO:root:Train (Epoch 118): Loss/seq after 03100 batchs: 935.2708740234375
INFO:root:Train (Epoch 118): Loss/seq after 03150 batchs: 939.0679321289062
INFO:root:Train (Epoch 118): Loss/seq after 03200 batchs: 944.125
INFO:root:Train (Epoch 118): Loss/seq after 03250 batchs: 945.7655639648438
INFO:root:Train (Epoch 118): Loss/seq after 03300 batchs: 943.8548583984375
INFO:root:Train (Epoch 118): Loss/seq after 03350 batchs: 943.9166259765625
INFO:root:Train (Epoch 118): Loss/seq after 03400 batchs: 939.2306518554688
INFO:root:Train (Epoch 118): Loss/seq after 03450 batchs: 933.939208984375
INFO:root:Train (Epoch 118): Loss/seq after 03500 batchs: 932.8990478515625
INFO:root:Train (Epoch 118): Loss/seq after 03550 batchs: 927.8270263671875
INFO:root:Train (Epoch 118): Loss/seq after 03600 batchs: 934.8198852539062
INFO:root:Train (Epoch 118): Loss/seq after 03650 batchs: 930.7554931640625
INFO:root:Train (Epoch 118): Loss/seq after 03700 batchs: 931.7925415039062
INFO:root:Train (Epoch 118): Loss/seq after 03750 batchs: 934.7546997070312
INFO:root:Train (Epoch 118): Loss/seq after 03800 batchs: 930.9071655273438
INFO:root:Train (Epoch 118): Loss/seq after 03850 batchs: 929.1243286132812
INFO:root:Train (Epoch 118): Loss/seq after 03900 batchs: 932.933349609375
INFO:root:Train (Epoch 118): Loss/seq after 03950 batchs: 936.5892944335938
INFO:root:Train (Epoch 118): Loss/seq after 04000 batchs: 931.0445556640625
INFO:root:Train (Epoch 118): Loss/seq after 04050 batchs: 926.354248046875
INFO:root:Train (Epoch 118): Loss/seq after 04100 batchs: 922.1394653320312
INFO:root:Train (Epoch 118): Loss/seq after 04150 batchs: 919.1063842773438
INFO:root:Train (Epoch 118): Loss/seq after 04200 batchs: 914.9705810546875
INFO:root:Train (Epoch 118): Loss/seq after 04250 batchs: 912.4864501953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 118): Loss/seq after 00000 batches: 873.8137817382812
INFO:root:# Valid (Epoch 118): Loss/seq after 00050 batches: 1094.570068359375
INFO:root:# Valid (Epoch 118): Loss/seq after 00100 batches: 1369.713134765625
INFO:root:# Valid (Epoch 118): Loss/seq after 00150 batches: 1082.6343994140625
INFO:root:# Valid (Epoch 118): Loss/seq after 00200 batches: 969.0231323242188
INFO:root:Artifacts: Make stick videos for epoch 118
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_118_on_20220423_061509.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_118_index_1631_on_20220423_061509.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 119): Loss/seq after 00000 batchs: 1587.3720703125
INFO:root:Train (Epoch 119): Loss/seq after 00050 batchs: 1178.0982666015625
INFO:root:Train (Epoch 119): Loss/seq after 00100 batchs: 1146.565673828125
INFO:root:Train (Epoch 119): Loss/seq after 00150 batchs: 1031.39697265625
INFO:root:Train (Epoch 119): Loss/seq after 00200 batchs: 1131.076171875
INFO:root:Train (Epoch 119): Loss/seq after 00250 batchs: 1257.7794189453125
INFO:root:Train (Epoch 119): Loss/seq after 00300 batchs: 1224.6077880859375
INFO:root:Train (Epoch 119): Loss/seq after 00350 batchs: 1156.4281005859375
INFO:root:Train (Epoch 119): Loss/seq after 00400 batchs: 1173.34228515625
INFO:root:Train (Epoch 119): Loss/seq after 00450 batchs: 1137.5869140625
INFO:root:Train (Epoch 119): Loss/seq after 00500 batchs: 1118.0452880859375
INFO:root:Train (Epoch 119): Loss/seq after 00550 batchs: 1079.411865234375
INFO:root:Train (Epoch 119): Loss/seq after 00600 batchs: 1053.681396484375
INFO:root:Train (Epoch 119): Loss/seq after 00650 batchs: 1056.3641357421875
INFO:root:Train (Epoch 119): Loss/seq after 00700 batchs: 1041.8134765625
INFO:root:Train (Epoch 119): Loss/seq after 00750 batchs: 1062.351318359375
INFO:root:Train (Epoch 119): Loss/seq after 00800 batchs: 1053.2301025390625
INFO:root:Train (Epoch 119): Loss/seq after 00850 batchs: 1033.5565185546875
INFO:root:Train (Epoch 119): Loss/seq after 00900 batchs: 1048.8887939453125
INFO:root:Train (Epoch 119): Loss/seq after 00950 batchs: 1056.2205810546875
INFO:root:Train (Epoch 119): Loss/seq after 01000 batchs: 1049.2391357421875
INFO:root:Train (Epoch 119): Loss/seq after 01050 batchs: 1035.6456298828125
INFO:root:Train (Epoch 119): Loss/seq after 01100 batchs: 1034.5242919921875
INFO:root:Train (Epoch 119): Loss/seq after 01150 batchs: 1029.259765625
INFO:root:Train (Epoch 119): Loss/seq after 01200 batchs: 1025.652099609375
INFO:root:Train (Epoch 119): Loss/seq after 01250 batchs: 1020.2194213867188
INFO:root:Train (Epoch 119): Loss/seq after 01300 batchs: 1015.7811889648438
INFO:root:Train (Epoch 119): Loss/seq after 01350 batchs: 1008.4308471679688
INFO:root:Train (Epoch 119): Loss/seq after 01400 batchs: 1020.1907348632812
INFO:root:Train (Epoch 119): Loss/seq after 01450 batchs: 1016.5404663085938
INFO:root:Train (Epoch 119): Loss/seq after 01500 batchs: 1015.4165649414062
INFO:root:Train (Epoch 119): Loss/seq after 01550 batchs: 1018.4540405273438
INFO:root:Train (Epoch 119): Loss/seq after 01600 batchs: 1008.718017578125
INFO:root:Train (Epoch 119): Loss/seq after 01650 batchs: 1000.5250244140625
INFO:root:Train (Epoch 119): Loss/seq after 01700 batchs: 998.3271484375
INFO:root:Train (Epoch 119): Loss/seq after 01750 batchs: 993.4210815429688
INFO:root:Train (Epoch 119): Loss/seq after 01800 batchs: 985.442138671875
INFO:root:Train (Epoch 119): Loss/seq after 01850 batchs: 976.5734252929688
INFO:root:Train (Epoch 119): Loss/seq after 01900 batchs: 975.7119140625
INFO:root:Train (Epoch 119): Loss/seq after 01950 batchs: 970.7919921875
INFO:root:Train (Epoch 119): Loss/seq after 02000 batchs: 966.709228515625
INFO:root:Train (Epoch 119): Loss/seq after 02050 batchs: 961.572998046875
INFO:root:Train (Epoch 119): Loss/seq after 02100 batchs: 954.8589477539062
INFO:root:Train (Epoch 119): Loss/seq after 02150 batchs: 948.607421875
INFO:root:Train (Epoch 119): Loss/seq after 02200 batchs: 942.121826171875
INFO:root:Train (Epoch 119): Loss/seq after 02250 batchs: 941.2061767578125
INFO:root:Train (Epoch 119): Loss/seq after 02300 batchs: 947.4390258789062
INFO:root:Train (Epoch 119): Loss/seq after 02350 batchs: 940.2874145507812
INFO:root:Train (Epoch 119): Loss/seq after 02400 batchs: 939.6924438476562
INFO:root:Train (Epoch 119): Loss/seq after 02450 batchs: 931.576904296875
INFO:root:Train (Epoch 119): Loss/seq after 02500 batchs: 919.9611206054688
INFO:root:Train (Epoch 119): Loss/seq after 02550 batchs: 912.3273315429688
INFO:root:Train (Epoch 119): Loss/seq after 02600 batchs: 913.7354736328125
INFO:root:Train (Epoch 119): Loss/seq after 02650 batchs: 912.4654541015625
INFO:root:Train (Epoch 119): Loss/seq after 02700 batchs: 910.0465698242188
INFO:root:Train (Epoch 119): Loss/seq after 02750 batchs: 925.5736694335938
INFO:root:Train (Epoch 119): Loss/seq after 02800 batchs: 930.2112426757812
INFO:root:Train (Epoch 119): Loss/seq after 02850 batchs: 927.2006225585938
INFO:root:Train (Epoch 119): Loss/seq after 02900 batchs: 926.6720581054688
INFO:root:Train (Epoch 119): Loss/seq after 02950 batchs: 921.458984375
INFO:root:Train (Epoch 119): Loss/seq after 03000 batchs: 923.2296142578125
INFO:root:Train (Epoch 119): Loss/seq after 03050 batchs: 926.9833374023438
INFO:root:Train (Epoch 119): Loss/seq after 03100 batchs: 931.332275390625
INFO:root:Train (Epoch 119): Loss/seq after 03150 batchs: 936.0032958984375
INFO:root:Train (Epoch 119): Loss/seq after 03200 batchs: 940.2462768554688
INFO:root:Train (Epoch 119): Loss/seq after 03250 batchs: 941.656494140625
INFO:root:Train (Epoch 119): Loss/seq after 03300 batchs: 939.98876953125
INFO:root:Train (Epoch 119): Loss/seq after 03350 batchs: 939.5330200195312
INFO:root:Train (Epoch 119): Loss/seq after 03400 batchs: 934.9517822265625
INFO:root:Train (Epoch 119): Loss/seq after 03450 batchs: 929.7485961914062
INFO:root:Train (Epoch 119): Loss/seq after 03500 batchs: 928.7503051757812
INFO:root:Train (Epoch 119): Loss/seq after 03550 batchs: 924.347900390625
INFO:root:Train (Epoch 119): Loss/seq after 03600 batchs: 931.5931396484375
INFO:root:Train (Epoch 119): Loss/seq after 03650 batchs: 927.5808715820312
INFO:root:Train (Epoch 119): Loss/seq after 03700 batchs: 928.7437744140625
INFO:root:Train (Epoch 119): Loss/seq after 03750 batchs: 931.685791015625
INFO:root:Train (Epoch 119): Loss/seq after 03800 batchs: 927.8832397460938
INFO:root:Train (Epoch 119): Loss/seq after 03850 batchs: 926.040283203125
INFO:root:Train (Epoch 119): Loss/seq after 03900 batchs: 929.4550170898438
INFO:root:Train (Epoch 119): Loss/seq after 03950 batchs: 932.9887084960938
INFO:root:Train (Epoch 119): Loss/seq after 04000 batchs: 927.4899291992188
INFO:root:Train (Epoch 119): Loss/seq after 04050 batchs: 922.8516235351562
INFO:root:Train (Epoch 119): Loss/seq after 04100 batchs: 918.7244873046875
INFO:root:Train (Epoch 119): Loss/seq after 04150 batchs: 915.7044067382812
INFO:root:Train (Epoch 119): Loss/seq after 04200 batchs: 911.621337890625
INFO:root:Train (Epoch 119): Loss/seq after 04250 batchs: 909.2052001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 119): Loss/seq after 00000 batches: 893.2526245117188
INFO:root:# Valid (Epoch 119): Loss/seq after 00050 batches: 1091.6845703125
INFO:root:# Valid (Epoch 119): Loss/seq after 00100 batches: 1330.54541015625
INFO:root:# Valid (Epoch 119): Loss/seq after 00150 batches: 1055.7044677734375
INFO:root:# Valid (Epoch 119): Loss/seq after 00200 batches: 945.5816650390625
INFO:root:Artifacts: Make stick videos for epoch 119
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_119_on_20220423_061957.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_119_index_5_on_20220423_061957.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 120): Loss/seq after 00000 batchs: 1436.0167236328125
INFO:root:Train (Epoch 120): Loss/seq after 00050 batchs: 1181.1854248046875
INFO:root:Train (Epoch 120): Loss/seq after 00100 batchs: 1141.2703857421875
INFO:root:Train (Epoch 120): Loss/seq after 00150 batchs: 1021.0283813476562
INFO:root:Train (Epoch 120): Loss/seq after 00200 batchs: 1127.0986328125
INFO:root:Train (Epoch 120): Loss/seq after 00250 batchs: 1248.939697265625
INFO:root:Train (Epoch 120): Loss/seq after 00300 batchs: 1217.3685302734375
INFO:root:Train (Epoch 120): Loss/seq after 00350 batchs: 1149.3060302734375
INFO:root:Train (Epoch 120): Loss/seq after 00400 batchs: 1164.7264404296875
INFO:root:Train (Epoch 120): Loss/seq after 00450 batchs: 1129.0472412109375
INFO:root:Train (Epoch 120): Loss/seq after 00500 batchs: 1109.55859375
INFO:root:Train (Epoch 120): Loss/seq after 00550 batchs: 1070.7933349609375
INFO:root:Train (Epoch 120): Loss/seq after 00600 batchs: 1045.1490478515625
INFO:root:Train (Epoch 120): Loss/seq after 00650 batchs: 1050.5970458984375
INFO:root:Train (Epoch 120): Loss/seq after 00700 batchs: 1037.3719482421875
INFO:root:Train (Epoch 120): Loss/seq after 00750 batchs: 1061.1531982421875
INFO:root:Train (Epoch 120): Loss/seq after 00800 batchs: 1051.6055908203125
INFO:root:Train (Epoch 120): Loss/seq after 00850 batchs: 1032.1632080078125
INFO:root:Train (Epoch 120): Loss/seq after 00900 batchs: 1046.92626953125
INFO:root:Train (Epoch 120): Loss/seq after 00950 batchs: 1050.116943359375
INFO:root:Train (Epoch 120): Loss/seq after 01000 batchs: 1043.810302734375
INFO:root:Train (Epoch 120): Loss/seq after 01050 batchs: 1029.0823974609375
INFO:root:Train (Epoch 120): Loss/seq after 01100 batchs: 1028.181884765625
INFO:root:Train (Epoch 120): Loss/seq after 01150 batchs: 1023.2352905273438
INFO:root:Train (Epoch 120): Loss/seq after 01200 batchs: 1019.9873046875
INFO:root:Train (Epoch 120): Loss/seq after 01250 batchs: 1013.851806640625
INFO:root:Train (Epoch 120): Loss/seq after 01300 batchs: 1009.0396728515625
INFO:root:Train (Epoch 120): Loss/seq after 01350 batchs: 1000.5260620117188
INFO:root:Train (Epoch 120): Loss/seq after 01400 batchs: 1011.7951049804688
INFO:root:Train (Epoch 120): Loss/seq after 01450 batchs: 1008.679931640625
INFO:root:Train (Epoch 120): Loss/seq after 01500 batchs: 1007.7903442382812
INFO:root:Train (Epoch 120): Loss/seq after 01550 batchs: 1010.6732177734375
INFO:root:Train (Epoch 120): Loss/seq after 01600 batchs: 1000.970458984375
INFO:root:Train (Epoch 120): Loss/seq after 01650 batchs: 993.072265625
INFO:root:Train (Epoch 120): Loss/seq after 01700 batchs: 991.2933349609375
INFO:root:Train (Epoch 120): Loss/seq after 01750 batchs: 986.7619018554688
INFO:root:Train (Epoch 120): Loss/seq after 01800 batchs: 979.0169677734375
INFO:root:Train (Epoch 120): Loss/seq after 01850 batchs: 970.6703491210938
INFO:root:Train (Epoch 120): Loss/seq after 01900 batchs: 969.92919921875
INFO:root:Train (Epoch 120): Loss/seq after 01950 batchs: 965.2556762695312
INFO:root:Train (Epoch 120): Loss/seq after 02000 batchs: 961.2879028320312
INFO:root:Train (Epoch 120): Loss/seq after 02050 batchs: 956.2015380859375
INFO:root:Train (Epoch 120): Loss/seq after 02100 batchs: 949.6119995117188
INFO:root:Train (Epoch 120): Loss/seq after 02150 batchs: 943.7055053710938
INFO:root:Train (Epoch 120): Loss/seq after 02200 batchs: 937.4041748046875
INFO:root:Train (Epoch 120): Loss/seq after 02250 batchs: 936.581787109375
INFO:root:Train (Epoch 120): Loss/seq after 02300 batchs: 941.6257934570312
INFO:root:Train (Epoch 120): Loss/seq after 02350 batchs: 934.7295532226562
INFO:root:Train (Epoch 120): Loss/seq after 02400 batchs: 934.192626953125
INFO:root:Train (Epoch 120): Loss/seq after 02450 batchs: 926.1741943359375
INFO:root:Train (Epoch 120): Loss/seq after 02500 batchs: 914.6883544921875
INFO:root:Train (Epoch 120): Loss/seq after 02550 batchs: 906.6356201171875
INFO:root:Train (Epoch 120): Loss/seq after 02600 batchs: 908.1319580078125
INFO:root:Train (Epoch 120): Loss/seq after 02650 batchs: 906.9890747070312
INFO:root:Train (Epoch 120): Loss/seq after 02700 batchs: 904.2415161132812
INFO:root:Train (Epoch 120): Loss/seq after 02750 batchs: 919.19140625
INFO:root:Train (Epoch 120): Loss/seq after 02800 batchs: 923.576904296875
INFO:root:Train (Epoch 120): Loss/seq after 02850 batchs: 920.9071655273438
INFO:root:Train (Epoch 120): Loss/seq after 02900 batchs: 920.7228393554688
INFO:root:Train (Epoch 120): Loss/seq after 02950 batchs: 915.6754760742188
INFO:root:Train (Epoch 120): Loss/seq after 03000 batchs: 917.619384765625
INFO:root:Train (Epoch 120): Loss/seq after 03050 batchs: 921.3858032226562
INFO:root:Train (Epoch 120): Loss/seq after 03100 batchs: 925.541015625
INFO:root:Train (Epoch 120): Loss/seq after 03150 batchs: 929.4273681640625
INFO:root:Train (Epoch 120): Loss/seq after 03200 batchs: 933.637939453125
INFO:root:Train (Epoch 120): Loss/seq after 03250 batchs: 935.5736694335938
INFO:root:Train (Epoch 120): Loss/seq after 03300 batchs: 933.6347045898438
INFO:root:Train (Epoch 120): Loss/seq after 03350 batchs: 933.2348022460938
INFO:root:Train (Epoch 120): Loss/seq after 03400 batchs: 928.68212890625
INFO:root:Train (Epoch 120): Loss/seq after 03450 batchs: 923.6924438476562
INFO:root:Train (Epoch 120): Loss/seq after 03500 batchs: 921.9642333984375
INFO:root:Train (Epoch 120): Loss/seq after 03550 batchs: 916.9788208007812
INFO:root:Train (Epoch 120): Loss/seq after 03600 batchs: 923.9525146484375
INFO:root:Train (Epoch 120): Loss/seq after 03650 batchs: 919.7332763671875
INFO:root:Train (Epoch 120): Loss/seq after 03700 batchs: 920.8543090820312
INFO:root:Train (Epoch 120): Loss/seq after 03750 batchs: 923.81103515625
INFO:root:Train (Epoch 120): Loss/seq after 03800 batchs: 920.11279296875
INFO:root:Train (Epoch 120): Loss/seq after 03850 batchs: 918.3024291992188
INFO:root:Train (Epoch 120): Loss/seq after 03900 batchs: 922.34521484375
INFO:root:Train (Epoch 120): Loss/seq after 03950 batchs: 926.0551147460938
INFO:root:Train (Epoch 120): Loss/seq after 04000 batchs: 920.6541137695312
INFO:root:Train (Epoch 120): Loss/seq after 04050 batchs: 916.1046142578125
INFO:root:Train (Epoch 120): Loss/seq after 04100 batchs: 912.0338745117188
INFO:root:Train (Epoch 120): Loss/seq after 04150 batchs: 909.1216430664062
INFO:root:Train (Epoch 120): Loss/seq after 04200 batchs: 905.1439208984375
INFO:root:Train (Epoch 120): Loss/seq after 04250 batchs: 902.7798461914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 120): Loss/seq after 00000 batches: 891.9566650390625
INFO:root:# Valid (Epoch 120): Loss/seq after 00050 batches: 1102.671630859375
INFO:root:# Valid (Epoch 120): Loss/seq after 00100 batches: 1360.7857666015625
INFO:root:# Valid (Epoch 120): Loss/seq after 00150 batches: 1077.5694580078125
INFO:root:# Valid (Epoch 120): Loss/seq after 00200 batches: 965.3768920898438
INFO:root:Artifacts: Make stick videos for epoch 120
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_120_on_20220423_062441.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_120_index_885_on_20220423_062441.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 121): Loss/seq after 00000 batchs: 1530.6029052734375
INFO:root:Train (Epoch 121): Loss/seq after 00050 batchs: 1188.861572265625
INFO:root:Train (Epoch 121): Loss/seq after 00100 batchs: 1153.5543212890625
INFO:root:Train (Epoch 121): Loss/seq after 00150 batchs: 1028.5806884765625
INFO:root:Train (Epoch 121): Loss/seq after 00200 batchs: 1132.235107421875
INFO:root:Train (Epoch 121): Loss/seq after 00250 batchs: 1254.3336181640625
INFO:root:Train (Epoch 121): Loss/seq after 00300 batchs: 1221.7467041015625
INFO:root:Train (Epoch 121): Loss/seq after 00350 batchs: 1152.3756103515625
INFO:root:Train (Epoch 121): Loss/seq after 00400 batchs: 1170.1893310546875
INFO:root:Train (Epoch 121): Loss/seq after 00450 batchs: 1134.080322265625
INFO:root:Train (Epoch 121): Loss/seq after 00500 batchs: 1113.1881103515625
INFO:root:Train (Epoch 121): Loss/seq after 00550 batchs: 1074.6739501953125
INFO:root:Train (Epoch 121): Loss/seq after 00600 batchs: 1049.5147705078125
INFO:root:Train (Epoch 121): Loss/seq after 00650 batchs: 1049.8685302734375
INFO:root:Train (Epoch 121): Loss/seq after 00700 batchs: 1038.255859375
INFO:root:Train (Epoch 121): Loss/seq after 00750 batchs: 1061.2777099609375
INFO:root:Train (Epoch 121): Loss/seq after 00800 batchs: 1052.59130859375
INFO:root:Train (Epoch 121): Loss/seq after 00850 batchs: 1033.092041015625
INFO:root:Train (Epoch 121): Loss/seq after 00900 batchs: 1047.5753173828125
INFO:root:Train (Epoch 121): Loss/seq after 00950 batchs: 1055.7630615234375
INFO:root:Train (Epoch 121): Loss/seq after 01000 batchs: 1048.195556640625
INFO:root:Train (Epoch 121): Loss/seq after 01050 batchs: 1033.8306884765625
INFO:root:Train (Epoch 121): Loss/seq after 01100 batchs: 1032.826171875
INFO:root:Train (Epoch 121): Loss/seq after 01150 batchs: 1027.595703125
INFO:root:Train (Epoch 121): Loss/seq after 01200 batchs: 1024.18994140625
INFO:root:Train (Epoch 121): Loss/seq after 01250 batchs: 1018.9033813476562
INFO:root:Train (Epoch 121): Loss/seq after 01300 batchs: 1008.7672119140625
INFO:root:Train (Epoch 121): Loss/seq after 01350 batchs: 1001.3700561523438
INFO:root:Train (Epoch 121): Loss/seq after 01400 batchs: 1011.5701904296875
INFO:root:Train (Epoch 121): Loss/seq after 01450 batchs: 1008.3245239257812
INFO:root:Train (Epoch 121): Loss/seq after 01500 batchs: 1007.4597778320312
INFO:root:Train (Epoch 121): Loss/seq after 01550 batchs: 1010.4661865234375
INFO:root:Train (Epoch 121): Loss/seq after 01600 batchs: 1000.7764282226562
INFO:root:Train (Epoch 121): Loss/seq after 01650 batchs: 992.8267211914062
INFO:root:Train (Epoch 121): Loss/seq after 01700 batchs: 990.913818359375
INFO:root:Train (Epoch 121): Loss/seq after 01750 batchs: 986.32470703125
INFO:root:Train (Epoch 121): Loss/seq after 01800 batchs: 978.609619140625
INFO:root:Train (Epoch 121): Loss/seq after 01850 batchs: 970.162109375
INFO:root:Train (Epoch 121): Loss/seq after 01900 batchs: 969.7550048828125
INFO:root:Train (Epoch 121): Loss/seq after 01950 batchs: 965.97265625
INFO:root:Train (Epoch 121): Loss/seq after 02000 batchs: 962.2815551757812
INFO:root:Train (Epoch 121): Loss/seq after 02050 batchs: 957.7061157226562
INFO:root:Train (Epoch 121): Loss/seq after 02100 batchs: 951.2420043945312
INFO:root:Train (Epoch 121): Loss/seq after 02150 batchs: 945.1854858398438
INFO:root:Train (Epoch 121): Loss/seq after 02200 batchs: 938.78955078125
INFO:root:Train (Epoch 121): Loss/seq after 02250 batchs: 937.42041015625
INFO:root:Train (Epoch 121): Loss/seq after 02300 batchs: 941.3760986328125
INFO:root:Train (Epoch 121): Loss/seq after 02350 batchs: 934.483642578125
INFO:root:Train (Epoch 121): Loss/seq after 02400 batchs: 934.1146240234375
INFO:root:Train (Epoch 121): Loss/seq after 02450 batchs: 926.07373046875
INFO:root:Train (Epoch 121): Loss/seq after 02500 batchs: 914.5604858398438
INFO:root:Train (Epoch 121): Loss/seq after 02550 batchs: 906.4732055664062
INFO:root:Train (Epoch 121): Loss/seq after 02600 batchs: 907.9784545898438
INFO:root:Train (Epoch 121): Loss/seq after 02650 batchs: 906.7991333007812
INFO:root:Train (Epoch 121): Loss/seq after 02700 batchs: 904.0094604492188
INFO:root:Train (Epoch 121): Loss/seq after 02750 batchs: 918.93408203125
INFO:root:Train (Epoch 121): Loss/seq after 02800 batchs: 922.610595703125
INFO:root:Train (Epoch 121): Loss/seq after 02850 batchs: 919.7555541992188
INFO:root:Train (Epoch 121): Loss/seq after 02900 batchs: 919.3594360351562
INFO:root:Train (Epoch 121): Loss/seq after 02950 batchs: 914.23486328125
INFO:root:Train (Epoch 121): Loss/seq after 03000 batchs: 916.08349609375
INFO:root:Train (Epoch 121): Loss/seq after 03050 batchs: 919.7547607421875
INFO:root:Train (Epoch 121): Loss/seq after 03100 batchs: 924.1332397460938
INFO:root:Train (Epoch 121): Loss/seq after 03150 batchs: 927.370361328125
INFO:root:Train (Epoch 121): Loss/seq after 03200 batchs: 931.8849487304688
INFO:root:Train (Epoch 121): Loss/seq after 03250 batchs: 933.5662231445312
INFO:root:Train (Epoch 121): Loss/seq after 03300 batchs: 931.6513671875
INFO:root:Train (Epoch 121): Loss/seq after 03350 batchs: 930.6981811523438
INFO:root:Train (Epoch 121): Loss/seq after 03400 batchs: 926.1932983398438
INFO:root:Train (Epoch 121): Loss/seq after 03450 batchs: 921.0199584960938
INFO:root:Train (Epoch 121): Loss/seq after 03500 batchs: 919.7613525390625
INFO:root:Train (Epoch 121): Loss/seq after 03550 batchs: 915.019775390625
INFO:root:Train (Epoch 121): Loss/seq after 03600 batchs: 922.2177124023438
INFO:root:Train (Epoch 121): Loss/seq after 03650 batchs: 918.0137939453125
INFO:root:Train (Epoch 121): Loss/seq after 03700 batchs: 919.1594848632812
INFO:root:Train (Epoch 121): Loss/seq after 03750 batchs: 922.1580810546875
INFO:root:Train (Epoch 121): Loss/seq after 03800 batchs: 918.4657592773438
INFO:root:Train (Epoch 121): Loss/seq after 03850 batchs: 916.6859130859375
INFO:root:Train (Epoch 121): Loss/seq after 03900 batchs: 920.7728271484375
INFO:root:Train (Epoch 121): Loss/seq after 03950 batchs: 924.0570678710938
INFO:root:Train (Epoch 121): Loss/seq after 04000 batchs: 918.6646728515625
INFO:root:Train (Epoch 121): Loss/seq after 04050 batchs: 914.1509399414062
INFO:root:Train (Epoch 121): Loss/seq after 04100 batchs: 910.1031494140625
INFO:root:Train (Epoch 121): Loss/seq after 04150 batchs: 907.1992797851562
INFO:root:Train (Epoch 121): Loss/seq after 04200 batchs: 903.153076171875
INFO:root:Train (Epoch 121): Loss/seq after 04250 batchs: 900.8449096679688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 121): Loss/seq after 00000 batches: 869.34228515625
INFO:root:# Valid (Epoch 121): Loss/seq after 00050 batches: 1091.25830078125
INFO:root:# Valid (Epoch 121): Loss/seq after 00100 batches: 1353.545166015625
INFO:root:# Valid (Epoch 121): Loss/seq after 00150 batches: 1072.4051513671875
INFO:root:# Valid (Epoch 121): Loss/seq after 00200 batches: 958.261962890625
INFO:root:Artifacts: Make stick videos for epoch 121
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_121_on_20220423_062946.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_121_index_929_on_20220423_062946.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 122): Loss/seq after 00000 batchs: 1530.2784423828125
INFO:root:Train (Epoch 122): Loss/seq after 00050 batchs: 1138.56494140625
INFO:root:Train (Epoch 122): Loss/seq after 00100 batchs: 1119.17822265625
INFO:root:Train (Epoch 122): Loss/seq after 00150 batchs: 1006.958740234375
INFO:root:Train (Epoch 122): Loss/seq after 00200 batchs: 1114.1124267578125
INFO:root:Train (Epoch 122): Loss/seq after 00250 batchs: 1241.5355224609375
INFO:root:Train (Epoch 122): Loss/seq after 00300 batchs: 1210.0123291015625
INFO:root:Train (Epoch 122): Loss/seq after 00350 batchs: 1144.0181884765625
INFO:root:Train (Epoch 122): Loss/seq after 00400 batchs: 1157.69482421875
INFO:root:Train (Epoch 122): Loss/seq after 00450 batchs: 1122.853759765625
INFO:root:Train (Epoch 122): Loss/seq after 00500 batchs: 1100.8114013671875
INFO:root:Train (Epoch 122): Loss/seq after 00550 batchs: 1063.0419921875
INFO:root:Train (Epoch 122): Loss/seq after 00600 batchs: 1039.400390625
INFO:root:Train (Epoch 122): Loss/seq after 00650 batchs: 1044.173095703125
INFO:root:Train (Epoch 122): Loss/seq after 00700 batchs: 1030.14697265625
INFO:root:Train (Epoch 122): Loss/seq after 00750 batchs: 1051.7186279296875
INFO:root:Train (Epoch 122): Loss/seq after 00800 batchs: 1042.3502197265625
INFO:root:Train (Epoch 122): Loss/seq after 00850 batchs: 1023.2000122070312
INFO:root:Train (Epoch 122): Loss/seq after 00900 batchs: 1038.34375
INFO:root:Train (Epoch 122): Loss/seq after 00950 batchs: 1043.2579345703125
INFO:root:Train (Epoch 122): Loss/seq after 01000 batchs: 1036.083740234375
INFO:root:Train (Epoch 122): Loss/seq after 01050 batchs: 1022.4810791015625
INFO:root:Train (Epoch 122): Loss/seq after 01100 batchs: 1019.9688110351562
INFO:root:Train (Epoch 122): Loss/seq after 01150 batchs: 1015.2059326171875
INFO:root:Train (Epoch 122): Loss/seq after 01200 batchs: 1012.1629028320312
INFO:root:Train (Epoch 122): Loss/seq after 01250 batchs: 1006.9520263671875
INFO:root:Train (Epoch 122): Loss/seq after 01300 batchs: 998.8142700195312
INFO:root:Train (Epoch 122): Loss/seq after 01350 batchs: 988.8548583984375
INFO:root:Train (Epoch 122): Loss/seq after 01400 batchs: 998.63525390625
INFO:root:Train (Epoch 122): Loss/seq after 01450 batchs: 995.7088012695312
INFO:root:Train (Epoch 122): Loss/seq after 01500 batchs: 995.1902465820312
INFO:root:Train (Epoch 122): Loss/seq after 01550 batchs: 997.9249877929688
INFO:root:Train (Epoch 122): Loss/seq after 01600 batchs: 988.7022094726562
INFO:root:Train (Epoch 122): Loss/seq after 01650 batchs: 981.0427856445312
INFO:root:Train (Epoch 122): Loss/seq after 01700 batchs: 979.2018432617188
INFO:root:Train (Epoch 122): Loss/seq after 01750 batchs: 974.8619384765625
INFO:root:Train (Epoch 122): Loss/seq after 01800 batchs: 967.3997192382812
INFO:root:Train (Epoch 122): Loss/seq after 01850 batchs: 959.1325073242188
INFO:root:Train (Epoch 122): Loss/seq after 01900 batchs: 958.657958984375
INFO:root:Train (Epoch 122): Loss/seq after 01950 batchs: 954.4299926757812
INFO:root:Train (Epoch 122): Loss/seq after 02000 batchs: 950.7902221679688
INFO:root:Train (Epoch 122): Loss/seq after 02050 batchs: 946.0444946289062
INFO:root:Train (Epoch 122): Loss/seq after 02100 batchs: 939.5822143554688
INFO:root:Train (Epoch 122): Loss/seq after 02150 batchs: 933.8399658203125
INFO:root:Train (Epoch 122): Loss/seq after 02200 batchs: 927.73779296875
INFO:root:Train (Epoch 122): Loss/seq after 02250 batchs: 926.96826171875
INFO:root:Train (Epoch 122): Loss/seq after 02300 batchs: 933.2384643554688
INFO:root:Train (Epoch 122): Loss/seq after 02350 batchs: 926.5803833007812
INFO:root:Train (Epoch 122): Loss/seq after 02400 batchs: 926.2752075195312
INFO:root:Train (Epoch 122): Loss/seq after 02450 batchs: 918.4536743164062
INFO:root:Train (Epoch 122): Loss/seq after 02500 batchs: 907.1155395507812
INFO:root:Train (Epoch 122): Loss/seq after 02550 batchs: 899.4398193359375
INFO:root:Train (Epoch 122): Loss/seq after 02600 batchs: 901.0286254882812
INFO:root:Train (Epoch 122): Loss/seq after 02650 batchs: 899.9890747070312
INFO:root:Train (Epoch 122): Loss/seq after 02700 batchs: 897.9849243164062
INFO:root:Train (Epoch 122): Loss/seq after 02750 batchs: 913.224609375
INFO:root:Train (Epoch 122): Loss/seq after 02800 batchs: 915.6874389648438
INFO:root:Train (Epoch 122): Loss/seq after 02850 batchs: 912.962890625
INFO:root:Train (Epoch 122): Loss/seq after 02900 batchs: 912.8063354492188
INFO:root:Train (Epoch 122): Loss/seq after 02950 batchs: 907.8314208984375
INFO:root:Train (Epoch 122): Loss/seq after 03000 batchs: 909.9179077148438
INFO:root:Train (Epoch 122): Loss/seq after 03050 batchs: 913.6618041992188
INFO:root:Train (Epoch 122): Loss/seq after 03100 batchs: 917.0842895507812
INFO:root:Train (Epoch 122): Loss/seq after 03150 batchs: 921.069580078125
INFO:root:Train (Epoch 122): Loss/seq after 03200 batchs: 924.5116577148438
INFO:root:Train (Epoch 122): Loss/seq after 03250 batchs: 926.7117919921875
INFO:root:Train (Epoch 122): Loss/seq after 03300 batchs: 925.3023681640625
INFO:root:Train (Epoch 122): Loss/seq after 03350 batchs: 924.4820556640625
INFO:root:Train (Epoch 122): Loss/seq after 03400 batchs: 920.06103515625
INFO:root:Train (Epoch 122): Loss/seq after 03450 batchs: 915.0403442382812
INFO:root:Train (Epoch 122): Loss/seq after 03500 batchs: 913.3720092773438
INFO:root:Train (Epoch 122): Loss/seq after 03550 batchs: 908.3568725585938
INFO:root:Train (Epoch 122): Loss/seq after 03600 batchs: 915.2310180664062
INFO:root:Train (Epoch 122): Loss/seq after 03650 batchs: 911.1276245117188
INFO:root:Train (Epoch 122): Loss/seq after 03700 batchs: 912.4308471679688
INFO:root:Train (Epoch 122): Loss/seq after 03750 batchs: 915.5703735351562
INFO:root:Train (Epoch 122): Loss/seq after 03800 batchs: 911.985107421875
INFO:root:Train (Epoch 122): Loss/seq after 03850 batchs: 910.134765625
INFO:root:Train (Epoch 122): Loss/seq after 03900 batchs: 913.4896240234375
INFO:root:Train (Epoch 122): Loss/seq after 03950 batchs: 916.906982421875
INFO:root:Train (Epoch 122): Loss/seq after 04000 batchs: 911.6077270507812
INFO:root:Train (Epoch 122): Loss/seq after 04050 batchs: 907.164794921875
INFO:root:Train (Epoch 122): Loss/seq after 04100 batchs: 903.1226806640625
INFO:root:Train (Epoch 122): Loss/seq after 04150 batchs: 900.3197021484375
INFO:root:Train (Epoch 122): Loss/seq after 04200 batchs: 896.29541015625
INFO:root:Train (Epoch 122): Loss/seq after 04250 batchs: 894.0394897460938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 122): Loss/seq after 00000 batches: 890.2400512695312
INFO:root:# Valid (Epoch 122): Loss/seq after 00050 batches: 1091.4342041015625
INFO:root:# Valid (Epoch 122): Loss/seq after 00100 batches: 1335.55322265625
INFO:root:# Valid (Epoch 122): Loss/seq after 00150 batches: 1058.2393798828125
INFO:root:# Valid (Epoch 122): Loss/seq after 00200 batches: 946.6453247070312
INFO:root:Artifacts: Make stick videos for epoch 122
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_122_on_20220423_063439.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_122_index_413_on_20220423_063439.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 123): Loss/seq after 00000 batchs: 1467.75634765625
INFO:root:Train (Epoch 123): Loss/seq after 00050 batchs: 1136.72216796875
INFO:root:Train (Epoch 123): Loss/seq after 00100 batchs: 1129.2913818359375
INFO:root:Train (Epoch 123): Loss/seq after 00150 batchs: 1013.0418090820312
INFO:root:Train (Epoch 123): Loss/seq after 00200 batchs: 1110.8505859375
INFO:root:Train (Epoch 123): Loss/seq after 00250 batchs: 1235.986328125
INFO:root:Train (Epoch 123): Loss/seq after 00300 batchs: 1205.625244140625
INFO:root:Train (Epoch 123): Loss/seq after 00350 batchs: 1139.441650390625
INFO:root:Train (Epoch 123): Loss/seq after 00400 batchs: 1155.556884765625
INFO:root:Train (Epoch 123): Loss/seq after 00450 batchs: 1121.1871337890625
INFO:root:Train (Epoch 123): Loss/seq after 00500 batchs: 1103.6844482421875
INFO:root:Train (Epoch 123): Loss/seq after 00550 batchs: 1066.017578125
INFO:root:Train (Epoch 123): Loss/seq after 00600 batchs: 1041.5086669921875
INFO:root:Train (Epoch 123): Loss/seq after 00650 batchs: 1041.212158203125
INFO:root:Train (Epoch 123): Loss/seq after 00700 batchs: 1022.3553466796875
INFO:root:Train (Epoch 123): Loss/seq after 00750 batchs: 1039.5015869140625
INFO:root:Train (Epoch 123): Loss/seq after 00800 batchs: 1031.5653076171875
INFO:root:Train (Epoch 123): Loss/seq after 00850 batchs: 1013.3172607421875
INFO:root:Train (Epoch 123): Loss/seq after 00900 batchs: 1029.2640380859375
INFO:root:Train (Epoch 123): Loss/seq after 00950 batchs: 1033.59375
INFO:root:Train (Epoch 123): Loss/seq after 01000 batchs: 1027.110595703125
INFO:root:Train (Epoch 123): Loss/seq after 01050 batchs: 1017.3722534179688
INFO:root:Train (Epoch 123): Loss/seq after 01100 batchs: 1016.751708984375
INFO:root:Train (Epoch 123): Loss/seq after 01150 batchs: 1012.1838989257812
INFO:root:Train (Epoch 123): Loss/seq after 01200 batchs: 1009.167236328125
INFO:root:Train (Epoch 123): Loss/seq after 01250 batchs: 1003.6643676757812
INFO:root:Train (Epoch 123): Loss/seq after 01300 batchs: 995.4674072265625
INFO:root:Train (Epoch 123): Loss/seq after 01350 batchs: 984.4594116210938
INFO:root:Train (Epoch 123): Loss/seq after 01400 batchs: 994.9497680664062
INFO:root:Train (Epoch 123): Loss/seq after 01450 batchs: 992.460693359375
INFO:root:Train (Epoch 123): Loss/seq after 01500 batchs: 992.0089111328125
INFO:root:Train (Epoch 123): Loss/seq after 01550 batchs: 995.6241455078125
INFO:root:Train (Epoch 123): Loss/seq after 01600 batchs: 986.7442016601562
INFO:root:Train (Epoch 123): Loss/seq after 01650 batchs: 979.4168090820312
INFO:root:Train (Epoch 123): Loss/seq after 01700 batchs: 977.8101806640625
INFO:root:Train (Epoch 123): Loss/seq after 01750 batchs: 973.5508422851562
INFO:root:Train (Epoch 123): Loss/seq after 01800 batchs: 966.205322265625
INFO:root:Train (Epoch 123): Loss/seq after 01850 batchs: 957.7885131835938
INFO:root:Train (Epoch 123): Loss/seq after 01900 batchs: 957.2134399414062
INFO:root:Train (Epoch 123): Loss/seq after 01950 batchs: 952.7361450195312
INFO:root:Train (Epoch 123): Loss/seq after 02000 batchs: 949.0538330078125
INFO:root:Train (Epoch 123): Loss/seq after 02050 batchs: 944.2540283203125
INFO:root:Train (Epoch 123): Loss/seq after 02100 batchs: 937.7708740234375
INFO:root:Train (Epoch 123): Loss/seq after 02150 batchs: 932.00439453125
INFO:root:Train (Epoch 123): Loss/seq after 02200 batchs: 925.9293212890625
INFO:root:Train (Epoch 123): Loss/seq after 02250 batchs: 924.9462890625
INFO:root:Train (Epoch 123): Loss/seq after 02300 batchs: 929.8411254882812
INFO:root:Train (Epoch 123): Loss/seq after 02350 batchs: 923.2127685546875
INFO:root:Train (Epoch 123): Loss/seq after 02400 batchs: 923.105712890625
INFO:root:Train (Epoch 123): Loss/seq after 02450 batchs: 915.3270874023438
INFO:root:Train (Epoch 123): Loss/seq after 02500 batchs: 904.0478515625
INFO:root:Train (Epoch 123): Loss/seq after 02550 batchs: 896.4075927734375
INFO:root:Train (Epoch 123): Loss/seq after 02600 batchs: 898.0647583007812
INFO:root:Train (Epoch 123): Loss/seq after 02650 batchs: 897.1058349609375
INFO:root:Train (Epoch 123): Loss/seq after 02700 batchs: 894.5511474609375
INFO:root:Train (Epoch 123): Loss/seq after 02750 batchs: 910.3040771484375
INFO:root:Train (Epoch 123): Loss/seq after 02800 batchs: 913.2664184570312
INFO:root:Train (Epoch 123): Loss/seq after 02850 batchs: 910.685302734375
INFO:root:Train (Epoch 123): Loss/seq after 02900 batchs: 909.99365234375
INFO:root:Train (Epoch 123): Loss/seq after 02950 batchs: 904.9928588867188
INFO:root:Train (Epoch 123): Loss/seq after 03000 batchs: 906.99951171875
INFO:root:Train (Epoch 123): Loss/seq after 03050 batchs: 910.640869140625
INFO:root:Train (Epoch 123): Loss/seq after 03100 batchs: 914.0121459960938
INFO:root:Train (Epoch 123): Loss/seq after 03150 batchs: 918.716064453125
INFO:root:Train (Epoch 123): Loss/seq after 03200 batchs: 922.2272338867188
INFO:root:Train (Epoch 123): Loss/seq after 03250 batchs: 924.375
INFO:root:Train (Epoch 123): Loss/seq after 03300 batchs: 922.150634765625
INFO:root:Train (Epoch 123): Loss/seq after 03350 batchs: 921.7200317382812
INFO:root:Train (Epoch 123): Loss/seq after 03400 batchs: 917.2969970703125
INFO:root:Train (Epoch 123): Loss/seq after 03450 batchs: 912.2577514648438
INFO:root:Train (Epoch 123): Loss/seq after 03500 batchs: 910.46044921875
INFO:root:Train (Epoch 123): Loss/seq after 03550 batchs: 905.601318359375
INFO:root:Train (Epoch 123): Loss/seq after 03600 batchs: 912.6831665039062
INFO:root:Train (Epoch 123): Loss/seq after 03650 batchs: 908.895751953125
INFO:root:Train (Epoch 123): Loss/seq after 03700 batchs: 910.197021484375
INFO:root:Train (Epoch 123): Loss/seq after 03750 batchs: 913.343017578125
INFO:root:Train (Epoch 123): Loss/seq after 03800 batchs: 909.7589721679688
INFO:root:Train (Epoch 123): Loss/seq after 03850 batchs: 908.1121215820312
INFO:root:Train (Epoch 123): Loss/seq after 03900 batchs: 911.80517578125
INFO:root:Train (Epoch 123): Loss/seq after 03950 batchs: 915.4220581054688
INFO:root:Train (Epoch 123): Loss/seq after 04000 batchs: 910.1444091796875
INFO:root:Train (Epoch 123): Loss/seq after 04050 batchs: 905.7091674804688
INFO:root:Train (Epoch 123): Loss/seq after 04100 batchs: 901.6865234375
INFO:root:Train (Epoch 123): Loss/seq after 04150 batchs: 898.8809814453125
INFO:root:Train (Epoch 123): Loss/seq after 04200 batchs: 894.83935546875
INFO:root:Train (Epoch 123): Loss/seq after 04250 batchs: 892.596435546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 123): Loss/seq after 00000 batches: 862.6275634765625
INFO:root:# Valid (Epoch 123): Loss/seq after 00050 batches: 1087.9383544921875
INFO:root:# Valid (Epoch 123): Loss/seq after 00100 batches: 1280.20263671875
INFO:root:# Valid (Epoch 123): Loss/seq after 00150 batches: 1022.0696411132812
INFO:root:# Valid (Epoch 123): Loss/seq after 00200 batches: 920.4107666015625
INFO:root:Artifacts: Make stick videos for epoch 123
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_123_on_20220423_063926.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_123_index_400_on_20220423_063926.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 124): Loss/seq after 00000 batchs: 1478.4337158203125
INFO:root:Train (Epoch 124): Loss/seq after 00050 batchs: 1151.9176025390625
INFO:root:Train (Epoch 124): Loss/seq after 00100 batchs: 1135.90087890625
INFO:root:Train (Epoch 124): Loss/seq after 00150 batchs: 1016.7236938476562
INFO:root:Train (Epoch 124): Loss/seq after 00200 batchs: 1135.9395751953125
INFO:root:Train (Epoch 124): Loss/seq after 00250 batchs: 1260.7186279296875
INFO:root:Train (Epoch 124): Loss/seq after 00300 batchs: 1226.7655029296875
INFO:root:Train (Epoch 124): Loss/seq after 00350 batchs: 1157.2484130859375
INFO:root:Train (Epoch 124): Loss/seq after 00400 batchs: 1175.4000244140625
INFO:root:Train (Epoch 124): Loss/seq after 00450 batchs: 1138.5670166015625
INFO:root:Train (Epoch 124): Loss/seq after 00500 batchs: 1114.81201171875
INFO:root:Train (Epoch 124): Loss/seq after 00550 batchs: 1076.1116943359375
INFO:root:Train (Epoch 124): Loss/seq after 00600 batchs: 1050.0001220703125
INFO:root:Train (Epoch 124): Loss/seq after 00650 batchs: 1053.7752685546875
INFO:root:Train (Epoch 124): Loss/seq after 00700 batchs: 1040.5045166015625
INFO:root:Train (Epoch 124): Loss/seq after 00750 batchs: 1063.469970703125
INFO:root:Train (Epoch 124): Loss/seq after 00800 batchs: 1053.9847412109375
INFO:root:Train (Epoch 124): Loss/seq after 00850 batchs: 1034.2470703125
INFO:root:Train (Epoch 124): Loss/seq after 00900 batchs: 1048.4505615234375
INFO:root:Train (Epoch 124): Loss/seq after 00950 batchs: 1052.0909423828125
INFO:root:Train (Epoch 124): Loss/seq after 01000 batchs: 1047.721923828125
INFO:root:Train (Epoch 124): Loss/seq after 01050 batchs: 1034.033203125
INFO:root:Train (Epoch 124): Loss/seq after 01100 batchs: 1032.5863037109375
INFO:root:Train (Epoch 124): Loss/seq after 01150 batchs: 1027.5732421875
INFO:root:Train (Epoch 124): Loss/seq after 01200 batchs: 1023.363037109375
INFO:root:Train (Epoch 124): Loss/seq after 01250 batchs: 1017.1411743164062
INFO:root:Train (Epoch 124): Loss/seq after 01300 batchs: 1008.1924438476562
INFO:root:Train (Epoch 124): Loss/seq after 01350 batchs: 996.6788940429688
INFO:root:Train (Epoch 124): Loss/seq after 01400 batchs: 1006.3910522460938
INFO:root:Train (Epoch 124): Loss/seq after 01450 batchs: 1003.1856079101562
INFO:root:Train (Epoch 124): Loss/seq after 01500 batchs: 1002.4036865234375
INFO:root:Train (Epoch 124): Loss/seq after 01550 batchs: 1004.9096069335938
INFO:root:Train (Epoch 124): Loss/seq after 01600 batchs: 995.4073486328125
INFO:root:Train (Epoch 124): Loss/seq after 01650 batchs: 987.9422607421875
INFO:root:Train (Epoch 124): Loss/seq after 01700 batchs: 985.9785766601562
INFO:root:Train (Epoch 124): Loss/seq after 01750 batchs: 981.447021484375
INFO:root:Train (Epoch 124): Loss/seq after 01800 batchs: 973.9266357421875
INFO:root:Train (Epoch 124): Loss/seq after 01850 batchs: 965.57470703125
INFO:root:Train (Epoch 124): Loss/seq after 01900 batchs: 964.9676513671875
INFO:root:Train (Epoch 124): Loss/seq after 01950 batchs: 960.3525390625
INFO:root:Train (Epoch 124): Loss/seq after 02000 batchs: 956.5341186523438
INFO:root:Train (Epoch 124): Loss/seq after 02050 batchs: 951.8032836914062
INFO:root:Train (Epoch 124): Loss/seq after 02100 batchs: 945.5416259765625
INFO:root:Train (Epoch 124): Loss/seq after 02150 batchs: 939.5912475585938
INFO:root:Train (Epoch 124): Loss/seq after 02200 batchs: 933.2927856445312
INFO:root:Train (Epoch 124): Loss/seq after 02250 batchs: 932.4502563476562
INFO:root:Train (Epoch 124): Loss/seq after 02300 batchs: 937.0330200195312
INFO:root:Train (Epoch 124): Loss/seq after 02350 batchs: 930.1710815429688
INFO:root:Train (Epoch 124): Loss/seq after 02400 batchs: 929.7243041992188
INFO:root:Train (Epoch 124): Loss/seq after 02450 batchs: 921.8568115234375
INFO:root:Train (Epoch 124): Loss/seq after 02500 batchs: 910.4427490234375
INFO:root:Train (Epoch 124): Loss/seq after 02550 batchs: 902.3743286132812
INFO:root:Train (Epoch 124): Loss/seq after 02600 batchs: 903.9166870117188
INFO:root:Train (Epoch 124): Loss/seq after 02650 batchs: 902.7789306640625
INFO:root:Train (Epoch 124): Loss/seq after 02700 batchs: 900.5162963867188
INFO:root:Train (Epoch 124): Loss/seq after 02750 batchs: 914.3961791992188
INFO:root:Train (Epoch 124): Loss/seq after 02800 batchs: 917.9776000976562
INFO:root:Train (Epoch 124): Loss/seq after 02850 batchs: 915.0513305664062
INFO:root:Train (Epoch 124): Loss/seq after 02900 batchs: 914.7360229492188
INFO:root:Train (Epoch 124): Loss/seq after 02950 batchs: 909.7203369140625
INFO:root:Train (Epoch 124): Loss/seq after 03000 batchs: 911.6889038085938
INFO:root:Train (Epoch 124): Loss/seq after 03050 batchs: 915.7035522460938
INFO:root:Train (Epoch 124): Loss/seq after 03100 batchs: 920.2191162109375
INFO:root:Train (Epoch 124): Loss/seq after 03150 batchs: 923.5509033203125
INFO:root:Train (Epoch 124): Loss/seq after 03200 batchs: 928.0477294921875
INFO:root:Train (Epoch 124): Loss/seq after 03250 batchs: 930.9568481445312
INFO:root:Train (Epoch 124): Loss/seq after 03300 batchs: 928.9832763671875
INFO:root:Train (Epoch 124): Loss/seq after 03350 batchs: 929.73095703125
INFO:root:Train (Epoch 124): Loss/seq after 03400 batchs: 925.3585205078125
INFO:root:Train (Epoch 124): Loss/seq after 03450 batchs: 920.6724853515625
INFO:root:Train (Epoch 124): Loss/seq after 03500 batchs: 919.1078491210938
INFO:root:Train (Epoch 124): Loss/seq after 03550 batchs: 914.126953125
INFO:root:Train (Epoch 124): Loss/seq after 03600 batchs: 921.30078125
INFO:root:Train (Epoch 124): Loss/seq after 03650 batchs: 917.1024169921875
INFO:root:Train (Epoch 124): Loss/seq after 03700 batchs: 918.3310546875
INFO:root:Train (Epoch 124): Loss/seq after 03750 batchs: 921.3546752929688
INFO:root:Train (Epoch 124): Loss/seq after 03800 batchs: 917.6715087890625
INFO:root:Train (Epoch 124): Loss/seq after 03850 batchs: 916.1265869140625
INFO:root:Train (Epoch 124): Loss/seq after 03900 batchs: 919.623779296875
INFO:root:Train (Epoch 124): Loss/seq after 03950 batchs: 922.8043212890625
INFO:root:Train (Epoch 124): Loss/seq after 04000 batchs: 917.4281616210938
INFO:root:Train (Epoch 124): Loss/seq after 04050 batchs: 912.9089965820312
INFO:root:Train (Epoch 124): Loss/seq after 04100 batchs: 908.9588012695312
INFO:root:Train (Epoch 124): Loss/seq after 04150 batchs: 906.037841796875
INFO:root:Train (Epoch 124): Loss/seq after 04200 batchs: 902.0001220703125
INFO:root:Train (Epoch 124): Loss/seq after 04250 batchs: 899.6895751953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 124): Loss/seq after 00000 batches: 870.1131591796875
INFO:root:# Valid (Epoch 124): Loss/seq after 00050 batches: 1083.820068359375
INFO:root:# Valid (Epoch 124): Loss/seq after 00100 batches: 1343.4580078125
INFO:root:# Valid (Epoch 124): Loss/seq after 00150 batches: 1066.353759765625
INFO:root:# Valid (Epoch 124): Loss/seq after 00200 batches: 952.7342529296875
INFO:root:Artifacts: Make stick videos for epoch 124
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_124_on_20220423_064416.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_124_index_562_on_20220423_064416.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 125): Loss/seq after 00000 batchs: 1549.614501953125
INFO:root:Train (Epoch 125): Loss/seq after 00050 batchs: 1109.834228515625
INFO:root:Train (Epoch 125): Loss/seq after 00100 batchs: 1105.6304931640625
INFO:root:Train (Epoch 125): Loss/seq after 00150 batchs: 994.0647583007812
INFO:root:Train (Epoch 125): Loss/seq after 00200 batchs: 1107.51904296875
INFO:root:Train (Epoch 125): Loss/seq after 00250 batchs: 1231.576416015625
INFO:root:Train (Epoch 125): Loss/seq after 00300 batchs: 1202.0789794921875
INFO:root:Train (Epoch 125): Loss/seq after 00350 batchs: 1135.4537353515625
INFO:root:Train (Epoch 125): Loss/seq after 00400 batchs: 1153.788330078125
INFO:root:Train (Epoch 125): Loss/seq after 00450 batchs: 1119.4105224609375
INFO:root:Train (Epoch 125): Loss/seq after 00500 batchs: 1098.549560546875
INFO:root:Train (Epoch 125): Loss/seq after 00550 batchs: 1060.8648681640625
INFO:root:Train (Epoch 125): Loss/seq after 00600 batchs: 1036.3387451171875
INFO:root:Train (Epoch 125): Loss/seq after 00650 batchs: 1038.0897216796875
INFO:root:Train (Epoch 125): Loss/seq after 00700 batchs: 1022.6659545898438
INFO:root:Train (Epoch 125): Loss/seq after 00750 batchs: 1043.5457763671875
INFO:root:Train (Epoch 125): Loss/seq after 00800 batchs: 1034.6571044921875
INFO:root:Train (Epoch 125): Loss/seq after 00850 batchs: 1015.732666015625
INFO:root:Train (Epoch 125): Loss/seq after 00900 batchs: 1030.234375
INFO:root:Train (Epoch 125): Loss/seq after 00950 batchs: 1033.8756103515625
INFO:root:Train (Epoch 125): Loss/seq after 01000 batchs: 1027.5855712890625
INFO:root:Train (Epoch 125): Loss/seq after 01050 batchs: 1014.3133544921875
INFO:root:Train (Epoch 125): Loss/seq after 01100 batchs: 1013.2469482421875
INFO:root:Train (Epoch 125): Loss/seq after 01150 batchs: 1008.8777465820312
INFO:root:Train (Epoch 125): Loss/seq after 01200 batchs: 1005.7764282226562
INFO:root:Train (Epoch 125): Loss/seq after 01250 batchs: 1000.9239501953125
INFO:root:Train (Epoch 125): Loss/seq after 01300 batchs: 991.3847045898438
INFO:root:Train (Epoch 125): Loss/seq after 01350 batchs: 982.5131225585938
INFO:root:Train (Epoch 125): Loss/seq after 01400 batchs: 991.3535766601562
INFO:root:Train (Epoch 125): Loss/seq after 01450 batchs: 988.6526489257812
INFO:root:Train (Epoch 125): Loss/seq after 01500 batchs: 988.4057006835938
INFO:root:Train (Epoch 125): Loss/seq after 01550 batchs: 991.6197509765625
INFO:root:Train (Epoch 125): Loss/seq after 01600 batchs: 982.5914916992188
INFO:root:Train (Epoch 125): Loss/seq after 01650 batchs: 974.8547973632812
INFO:root:Train (Epoch 125): Loss/seq after 01700 batchs: 973.4215087890625
INFO:root:Train (Epoch 125): Loss/seq after 01750 batchs: 969.2650146484375
INFO:root:Train (Epoch 125): Loss/seq after 01800 batchs: 962.1130981445312
INFO:root:Train (Epoch 125): Loss/seq after 01850 batchs: 953.9362182617188
INFO:root:Train (Epoch 125): Loss/seq after 01900 batchs: 953.5484619140625
INFO:root:Train (Epoch 125): Loss/seq after 01950 batchs: 949.4088134765625
INFO:root:Train (Epoch 125): Loss/seq after 02000 batchs: 945.7322387695312
INFO:root:Train (Epoch 125): Loss/seq after 02050 batchs: 941.2404174804688
INFO:root:Train (Epoch 125): Loss/seq after 02100 batchs: 934.879150390625
INFO:root:Train (Epoch 125): Loss/seq after 02150 batchs: 929.0828247070312
INFO:root:Train (Epoch 125): Loss/seq after 02200 batchs: 922.9764404296875
INFO:root:Train (Epoch 125): Loss/seq after 02250 batchs: 921.516845703125
INFO:root:Train (Epoch 125): Loss/seq after 02300 batchs: 924.678466796875
INFO:root:Train (Epoch 125): Loss/seq after 02350 batchs: 918.073974609375
INFO:root:Train (Epoch 125): Loss/seq after 02400 batchs: 918.0455322265625
INFO:root:Train (Epoch 125): Loss/seq after 02450 batchs: 910.32861328125
INFO:root:Train (Epoch 125): Loss/seq after 02500 batchs: 899.1571655273438
INFO:root:Train (Epoch 125): Loss/seq after 02550 batchs: 891.1283569335938
INFO:root:Train (Epoch 125): Loss/seq after 02600 batchs: 892.8446655273438
INFO:root:Train (Epoch 125): Loss/seq after 02650 batchs: 891.8941040039062
INFO:root:Train (Epoch 125): Loss/seq after 02700 batchs: 890.2060546875
INFO:root:Train (Epoch 125): Loss/seq after 02750 batchs: 904.782958984375
INFO:root:Train (Epoch 125): Loss/seq after 02800 batchs: 909.138671875
INFO:root:Train (Epoch 125): Loss/seq after 02850 batchs: 906.4487915039062
INFO:root:Train (Epoch 125): Loss/seq after 02900 batchs: 906.3511962890625
INFO:root:Train (Epoch 125): Loss/seq after 02950 batchs: 901.4434814453125
INFO:root:Train (Epoch 125): Loss/seq after 03000 batchs: 903.5172119140625
INFO:root:Train (Epoch 125): Loss/seq after 03050 batchs: 907.0760498046875
INFO:root:Train (Epoch 125): Loss/seq after 03100 batchs: 911.57666015625
INFO:root:Train (Epoch 125): Loss/seq after 03150 batchs: 916.2877197265625
INFO:root:Train (Epoch 125): Loss/seq after 03200 batchs: 920.5870971679688
INFO:root:Train (Epoch 125): Loss/seq after 03250 batchs: 922.6107788085938
INFO:root:Train (Epoch 125): Loss/seq after 03300 batchs: 920.522216796875
INFO:root:Train (Epoch 125): Loss/seq after 03350 batchs: 920.1262817382812
INFO:root:Train (Epoch 125): Loss/seq after 03400 batchs: 915.75439453125
INFO:root:Train (Epoch 125): Loss/seq after 03450 batchs: 910.7241821289062
INFO:root:Train (Epoch 125): Loss/seq after 03500 batchs: 909.454345703125
INFO:root:Train (Epoch 125): Loss/seq after 03550 batchs: 904.4388427734375
INFO:root:Train (Epoch 125): Loss/seq after 03600 batchs: 910.9290771484375
INFO:root:Train (Epoch 125): Loss/seq after 03650 batchs: 906.7009887695312
INFO:root:Train (Epoch 125): Loss/seq after 03700 batchs: 908.08935546875
INFO:root:Train (Epoch 125): Loss/seq after 03750 batchs: 911.253662109375
INFO:root:Train (Epoch 125): Loss/seq after 03800 batchs: 907.6976318359375
INFO:root:Train (Epoch 125): Loss/seq after 03850 batchs: 906.0223999023438
INFO:root:Train (Epoch 125): Loss/seq after 03900 batchs: 909.92431640625
INFO:root:Train (Epoch 125): Loss/seq after 03950 batchs: 913.4176635742188
INFO:root:Train (Epoch 125): Loss/seq after 04000 batchs: 908.1619873046875
INFO:root:Train (Epoch 125): Loss/seq after 04050 batchs: 903.758056640625
INFO:root:Train (Epoch 125): Loss/seq after 04100 batchs: 899.8021240234375
INFO:root:Train (Epoch 125): Loss/seq after 04150 batchs: 896.9713745117188
INFO:root:Train (Epoch 125): Loss/seq after 04200 batchs: 892.9947509765625
INFO:root:Train (Epoch 125): Loss/seq after 04250 batchs: 890.7899780273438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 125): Loss/seq after 00000 batches: 905.4698486328125
INFO:root:# Valid (Epoch 125): Loss/seq after 00050 batches: 1096.7740478515625
INFO:root:# Valid (Epoch 125): Loss/seq after 00100 batches: 1270.25341796875
INFO:root:# Valid (Epoch 125): Loss/seq after 00150 batches: 1015.4029541015625
INFO:root:# Valid (Epoch 125): Loss/seq after 00200 batches: 915.38671875
INFO:root:Artifacts: Make stick videos for epoch 125
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_125_on_20220423_064902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_125_index_1356_on_20220423_064902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 126): Loss/seq after 00000 batchs: 1641.5948486328125
INFO:root:Train (Epoch 126): Loss/seq after 00050 batchs: 1153.7728271484375
INFO:root:Train (Epoch 126): Loss/seq after 00100 batchs: 1128.29345703125
INFO:root:Train (Epoch 126): Loss/seq after 00150 batchs: 1010.0784301757812
INFO:root:Train (Epoch 126): Loss/seq after 00200 batchs: 1118.2958984375
INFO:root:Train (Epoch 126): Loss/seq after 00250 batchs: 1245.3912353515625
INFO:root:Train (Epoch 126): Loss/seq after 00300 batchs: 1213.64111328125
INFO:root:Train (Epoch 126): Loss/seq after 00350 batchs: 1147.5946044921875
INFO:root:Train (Epoch 126): Loss/seq after 00400 batchs: 1156.0582275390625
INFO:root:Train (Epoch 126): Loss/seq after 00450 batchs: 1121.810302734375
INFO:root:Train (Epoch 126): Loss/seq after 00500 batchs: 1103.3076171875
INFO:root:Train (Epoch 126): Loss/seq after 00550 batchs: 1066.0408935546875
INFO:root:Train (Epoch 126): Loss/seq after 00600 batchs: 1040.6851806640625
INFO:root:Train (Epoch 126): Loss/seq after 00650 batchs: 1041.8592529296875
INFO:root:Train (Epoch 126): Loss/seq after 00700 batchs: 1023.140625
INFO:root:Train (Epoch 126): Loss/seq after 00750 batchs: 1046.6102294921875
INFO:root:Train (Epoch 126): Loss/seq after 00800 batchs: 1036.9432373046875
INFO:root:Train (Epoch 126): Loss/seq after 00850 batchs: 1018.008544921875
INFO:root:Train (Epoch 126): Loss/seq after 00900 batchs: 1031.8876953125
INFO:root:Train (Epoch 126): Loss/seq after 00950 batchs: 1035.2554931640625
INFO:root:Train (Epoch 126): Loss/seq after 01000 batchs: 1028.29736328125
INFO:root:Train (Epoch 126): Loss/seq after 01050 batchs: 1014.0125732421875
INFO:root:Train (Epoch 126): Loss/seq after 01100 batchs: 1012.7334594726562
INFO:root:Train (Epoch 126): Loss/seq after 01150 batchs: 1008.3282470703125
INFO:root:Train (Epoch 126): Loss/seq after 01200 batchs: 1005.3242797851562
INFO:root:Train (Epoch 126): Loss/seq after 01250 batchs: 999.8845825195312
INFO:root:Train (Epoch 126): Loss/seq after 01300 batchs: 990.7894897460938
INFO:root:Train (Epoch 126): Loss/seq after 01350 batchs: 977.4320678710938
INFO:root:Train (Epoch 126): Loss/seq after 01400 batchs: 984.8626098632812
INFO:root:Train (Epoch 126): Loss/seq after 01450 batchs: 982.4356689453125
INFO:root:Train (Epoch 126): Loss/seq after 01500 batchs: 982.3956909179688
INFO:root:Train (Epoch 126): Loss/seq after 01550 batchs: 985.6290283203125
INFO:root:Train (Epoch 126): Loss/seq after 01600 batchs: 976.7182006835938
INFO:root:Train (Epoch 126): Loss/seq after 01650 batchs: 969.007080078125
INFO:root:Train (Epoch 126): Loss/seq after 01700 batchs: 967.5367431640625
INFO:root:Train (Epoch 126): Loss/seq after 01750 batchs: 963.5237426757812
INFO:root:Train (Epoch 126): Loss/seq after 01800 batchs: 956.3890380859375
INFO:root:Train (Epoch 126): Loss/seq after 01850 batchs: 948.2445678710938
INFO:root:Train (Epoch 126): Loss/seq after 01900 batchs: 948.0231323242188
INFO:root:Train (Epoch 126): Loss/seq after 01950 batchs: 944.207763671875
INFO:root:Train (Epoch 126): Loss/seq after 02000 batchs: 940.8070068359375
INFO:root:Train (Epoch 126): Loss/seq after 02050 batchs: 936.2547607421875
INFO:root:Train (Epoch 126): Loss/seq after 02100 batchs: 930.1261596679688
INFO:root:Train (Epoch 126): Loss/seq after 02150 batchs: 924.468017578125
INFO:root:Train (Epoch 126): Loss/seq after 02200 batchs: 918.4954223632812
INFO:root:Train (Epoch 126): Loss/seq after 02250 batchs: 916.7669067382812
INFO:root:Train (Epoch 126): Loss/seq after 02300 batchs: 919.8681030273438
INFO:root:Train (Epoch 126): Loss/seq after 02350 batchs: 913.3097534179688
INFO:root:Train (Epoch 126): Loss/seq after 02400 batchs: 913.2996826171875
INFO:root:Train (Epoch 126): Loss/seq after 02450 batchs: 905.6968383789062
INFO:root:Train (Epoch 126): Loss/seq after 02500 batchs: 894.6035766601562
INFO:root:Train (Epoch 126): Loss/seq after 02550 batchs: 886.8045043945312
INFO:root:Train (Epoch 126): Loss/seq after 02600 batchs: 888.5693969726562
INFO:root:Train (Epoch 126): Loss/seq after 02650 batchs: 887.6766967773438
INFO:root:Train (Epoch 126): Loss/seq after 02700 batchs: 885.6009521484375
INFO:root:Train (Epoch 126): Loss/seq after 02750 batchs: 899.8951416015625
INFO:root:Train (Epoch 126): Loss/seq after 02800 batchs: 903.22412109375
INFO:root:Train (Epoch 126): Loss/seq after 02850 batchs: 900.7056274414062
INFO:root:Train (Epoch 126): Loss/seq after 02900 batchs: 900.5159301757812
INFO:root:Train (Epoch 126): Loss/seq after 02950 batchs: 895.8366088867188
INFO:root:Train (Epoch 126): Loss/seq after 03000 batchs: 898.0899047851562
INFO:root:Train (Epoch 126): Loss/seq after 03050 batchs: 901.3767700195312
INFO:root:Train (Epoch 126): Loss/seq after 03100 batchs: 905.5250244140625
INFO:root:Train (Epoch 126): Loss/seq after 03150 batchs: 909.0337524414062
INFO:root:Train (Epoch 126): Loss/seq after 03200 batchs: 912.5927734375
INFO:root:Train (Epoch 126): Loss/seq after 03250 batchs: 914.41455078125
INFO:root:Train (Epoch 126): Loss/seq after 03300 batchs: 912.2413940429688
INFO:root:Train (Epoch 126): Loss/seq after 03350 batchs: 911.43359375
INFO:root:Train (Epoch 126): Loss/seq after 03400 batchs: 907.2661743164062
INFO:root:Train (Epoch 126): Loss/seq after 03450 batchs: 902.4755859375
INFO:root:Train (Epoch 126): Loss/seq after 03500 batchs: 901.1029052734375
INFO:root:Train (Epoch 126): Loss/seq after 03550 batchs: 896.326904296875
INFO:root:Train (Epoch 126): Loss/seq after 03600 batchs: 903.083740234375
INFO:root:Train (Epoch 126): Loss/seq after 03650 batchs: 899.1410522460938
INFO:root:Train (Epoch 126): Loss/seq after 03700 batchs: 900.4478149414062
INFO:root:Train (Epoch 126): Loss/seq after 03750 batchs: 903.773193359375
INFO:root:Train (Epoch 126): Loss/seq after 03800 batchs: 900.3311767578125
INFO:root:Train (Epoch 126): Loss/seq after 03850 batchs: 898.6532592773438
INFO:root:Train (Epoch 126): Loss/seq after 03900 batchs: 902.474853515625
INFO:root:Train (Epoch 126): Loss/seq after 03950 batchs: 905.593017578125
INFO:root:Train (Epoch 126): Loss/seq after 04000 batchs: 900.4281005859375
INFO:root:Train (Epoch 126): Loss/seq after 04050 batchs: 896.1116333007812
INFO:root:Train (Epoch 126): Loss/seq after 04100 batchs: 892.3594970703125
INFO:root:Train (Epoch 126): Loss/seq after 04150 batchs: 889.6558837890625
INFO:root:Train (Epoch 126): Loss/seq after 04200 batchs: 885.733154296875
INFO:root:Train (Epoch 126): Loss/seq after 04250 batchs: 883.60546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 126): Loss/seq after 00000 batches: 893.4100341796875
INFO:root:# Valid (Epoch 126): Loss/seq after 00050 batches: 1098.626220703125
INFO:root:# Valid (Epoch 126): Loss/seq after 00100 batches: 1329.9351806640625
INFO:root:# Valid (Epoch 126): Loss/seq after 00150 batches: 1055.1446533203125
INFO:root:# Valid (Epoch 126): Loss/seq after 00200 batches: 944.3016967773438
INFO:root:Artifacts: Make stick videos for epoch 126
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_126_on_20220423_065351.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_126_index_1221_on_20220423_065351.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 127): Loss/seq after 00000 batchs: 1533.5028076171875
INFO:root:Train (Epoch 127): Loss/seq after 00050 batchs: 1132.3494873046875
INFO:root:Train (Epoch 127): Loss/seq after 00100 batchs: 1115.6761474609375
INFO:root:Train (Epoch 127): Loss/seq after 00150 batchs: 998.9176025390625
INFO:root:Train (Epoch 127): Loss/seq after 00200 batchs: 1102.8358154296875
INFO:root:Train (Epoch 127): Loss/seq after 00250 batchs: 1224.5845947265625
INFO:root:Train (Epoch 127): Loss/seq after 00300 batchs: 1196.75830078125
INFO:root:Train (Epoch 127): Loss/seq after 00350 batchs: 1132.525146484375
INFO:root:Train (Epoch 127): Loss/seq after 00400 batchs: 1148.544189453125
INFO:root:Train (Epoch 127): Loss/seq after 00450 batchs: 1114.6787109375
INFO:root:Train (Epoch 127): Loss/seq after 00500 batchs: 1095.4354248046875
INFO:root:Train (Epoch 127): Loss/seq after 00550 batchs: 1058.751953125
INFO:root:Train (Epoch 127): Loss/seq after 00600 batchs: 1034.519775390625
INFO:root:Train (Epoch 127): Loss/seq after 00650 batchs: 1036.6522216796875
INFO:root:Train (Epoch 127): Loss/seq after 00700 batchs: 1016.5897827148438
INFO:root:Train (Epoch 127): Loss/seq after 00750 batchs: 1039.043701171875
INFO:root:Train (Epoch 127): Loss/seq after 00800 batchs: 1032.244384765625
INFO:root:Train (Epoch 127): Loss/seq after 00850 batchs: 1013.7615356445312
INFO:root:Train (Epoch 127): Loss/seq after 00900 batchs: 1028.5550537109375
INFO:root:Train (Epoch 127): Loss/seq after 00950 batchs: 1028.953369140625
INFO:root:Train (Epoch 127): Loss/seq after 01000 batchs: 1023.2515869140625
INFO:root:Train (Epoch 127): Loss/seq after 01050 batchs: 1009.6473388671875
INFO:root:Train (Epoch 127): Loss/seq after 01100 batchs: 1008.8911743164062
INFO:root:Train (Epoch 127): Loss/seq after 01150 batchs: 1004.6212158203125
INFO:root:Train (Epoch 127): Loss/seq after 01200 batchs: 1001.665283203125
INFO:root:Train (Epoch 127): Loss/seq after 01250 batchs: 996.4029541015625
INFO:root:Train (Epoch 127): Loss/seq after 01300 batchs: 985.7481689453125
INFO:root:Train (Epoch 127): Loss/seq after 01350 batchs: 975.6153564453125
INFO:root:Train (Epoch 127): Loss/seq after 01400 batchs: 984.1835327148438
INFO:root:Train (Epoch 127): Loss/seq after 01450 batchs: 981.7625122070312
INFO:root:Train (Epoch 127): Loss/seq after 01500 batchs: 981.673583984375
INFO:root:Train (Epoch 127): Loss/seq after 01550 batchs: 984.8755493164062
INFO:root:Train (Epoch 127): Loss/seq after 01600 batchs: 976.3771362304688
INFO:root:Train (Epoch 127): Loss/seq after 01650 batchs: 968.88623046875
INFO:root:Train (Epoch 127): Loss/seq after 01700 batchs: 967.72607421875
INFO:root:Train (Epoch 127): Loss/seq after 01750 batchs: 963.6014404296875
INFO:root:Train (Epoch 127): Loss/seq after 01800 batchs: 956.5244140625
INFO:root:Train (Epoch 127): Loss/seq after 01850 batchs: 948.4383544921875
INFO:root:Train (Epoch 127): Loss/seq after 01900 batchs: 948.0260009765625
INFO:root:Train (Epoch 127): Loss/seq after 01950 batchs: 943.9708251953125
INFO:root:Train (Epoch 127): Loss/seq after 02000 batchs: 940.40234375
INFO:root:Train (Epoch 127): Loss/seq after 02050 batchs: 935.9577026367188
INFO:root:Train (Epoch 127): Loss/seq after 02100 batchs: 929.6907348632812
INFO:root:Train (Epoch 127): Loss/seq after 02150 batchs: 924.0059814453125
INFO:root:Train (Epoch 127): Loss/seq after 02200 batchs: 918.023681640625
INFO:root:Train (Epoch 127): Loss/seq after 02250 batchs: 916.2704467773438
INFO:root:Train (Epoch 127): Loss/seq after 02300 batchs: 919.63037109375
INFO:root:Train (Epoch 127): Loss/seq after 02350 batchs: 912.9892578125
INFO:root:Train (Epoch 127): Loss/seq after 02400 batchs: 912.9594116210938
INFO:root:Train (Epoch 127): Loss/seq after 02450 batchs: 905.343017578125
INFO:root:Train (Epoch 127): Loss/seq after 02500 batchs: 894.2506713867188
INFO:root:Train (Epoch 127): Loss/seq after 02550 batchs: 886.3163452148438
INFO:root:Train (Epoch 127): Loss/seq after 02600 batchs: 888.1201171875
INFO:root:Train (Epoch 127): Loss/seq after 02650 batchs: 887.3126220703125
INFO:root:Train (Epoch 127): Loss/seq after 02700 batchs: 885.1672973632812
INFO:root:Train (Epoch 127): Loss/seq after 02750 batchs: 900.0016479492188
INFO:root:Train (Epoch 127): Loss/seq after 02800 batchs: 902.9995727539062
INFO:root:Train (Epoch 127): Loss/seq after 02850 batchs: 900.4232177734375
INFO:root:Train (Epoch 127): Loss/seq after 02900 batchs: 900.1969604492188
INFO:root:Train (Epoch 127): Loss/seq after 02950 batchs: 895.4384765625
INFO:root:Train (Epoch 127): Loss/seq after 03000 batchs: 897.6112670898438
INFO:root:Train (Epoch 127): Loss/seq after 03050 batchs: 900.8165893554688
INFO:root:Train (Epoch 127): Loss/seq after 03100 batchs: 904.7716064453125
INFO:root:Train (Epoch 127): Loss/seq after 03150 batchs: 908.5913696289062
INFO:root:Train (Epoch 127): Loss/seq after 03200 batchs: 911.156005859375
INFO:root:Train (Epoch 127): Loss/seq after 03250 batchs: 912.1238403320312
INFO:root:Train (Epoch 127): Loss/seq after 03300 batchs: 910.0579833984375
INFO:root:Train (Epoch 127): Loss/seq after 03350 batchs: 909.103515625
INFO:root:Train (Epoch 127): Loss/seq after 03400 batchs: 904.90380859375
INFO:root:Train (Epoch 127): Loss/seq after 03450 batchs: 899.965576171875
INFO:root:Train (Epoch 127): Loss/seq after 03500 batchs: 898.7151489257812
INFO:root:Train (Epoch 127): Loss/seq after 03550 batchs: 894.2055053710938
INFO:root:Train (Epoch 127): Loss/seq after 03600 batchs: 900.7244873046875
INFO:root:Train (Epoch 127): Loss/seq after 03650 batchs: 897.0971069335938
INFO:root:Train (Epoch 127): Loss/seq after 03700 batchs: 898.523193359375
INFO:root:Train (Epoch 127): Loss/seq after 03750 batchs: 901.8245849609375
INFO:root:Train (Epoch 127): Loss/seq after 03800 batchs: 898.39013671875
INFO:root:Train (Epoch 127): Loss/seq after 03850 batchs: 896.7285766601562
INFO:root:Train (Epoch 127): Loss/seq after 03900 batchs: 900.7103271484375
INFO:root:Train (Epoch 127): Loss/seq after 03950 batchs: 903.9248657226562
INFO:root:Train (Epoch 127): Loss/seq after 04000 batchs: 898.7852783203125
INFO:root:Train (Epoch 127): Loss/seq after 04050 batchs: 894.4957275390625
INFO:root:Train (Epoch 127): Loss/seq after 04100 batchs: 890.653564453125
INFO:root:Train (Epoch 127): Loss/seq after 04150 batchs: 887.9269409179688
INFO:root:Train (Epoch 127): Loss/seq after 04200 batchs: 884.050537109375
INFO:root:Train (Epoch 127): Loss/seq after 04250 batchs: 881.9066772460938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 127): Loss/seq after 00000 batches: 887.9292602539062
INFO:root:# Valid (Epoch 127): Loss/seq after 00050 batches: 1098.022216796875
INFO:root:# Valid (Epoch 127): Loss/seq after 00100 batches: 1344.825927734375
INFO:root:# Valid (Epoch 127): Loss/seq after 00150 batches: 1065.19677734375
INFO:root:# Valid (Epoch 127): Loss/seq after 00200 batches: 951.9818725585938
INFO:root:Artifacts: Make stick videos for epoch 127
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_127_on_20220423_065837.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_127_index_5_on_20220423_065837.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 128): Loss/seq after 00000 batchs: 1408.835693359375
INFO:root:Train (Epoch 128): Loss/seq after 00050 batchs: 1110.029541015625
INFO:root:Train (Epoch 128): Loss/seq after 00100 batchs: 1092.09619140625
INFO:root:Train (Epoch 128): Loss/seq after 00150 batchs: 982.4293212890625
INFO:root:Train (Epoch 128): Loss/seq after 00200 batchs: 1082.694580078125
INFO:root:Train (Epoch 128): Loss/seq after 00250 batchs: 1203.86767578125
INFO:root:Train (Epoch 128): Loss/seq after 00300 batchs: 1178.8914794921875
INFO:root:Train (Epoch 128): Loss/seq after 00350 batchs: 1115.562255859375
INFO:root:Train (Epoch 128): Loss/seq after 00400 batchs: 1126.314208984375
INFO:root:Train (Epoch 128): Loss/seq after 00450 batchs: 1094.6717529296875
INFO:root:Train (Epoch 128): Loss/seq after 00500 batchs: 1075.1781005859375
INFO:root:Train (Epoch 128): Loss/seq after 00550 batchs: 1039.9580078125
INFO:root:Train (Epoch 128): Loss/seq after 00600 batchs: 1018.4475708007812
INFO:root:Train (Epoch 128): Loss/seq after 00650 batchs: 1019.5205688476562
INFO:root:Train (Epoch 128): Loss/seq after 00700 batchs: 998.1470336914062
INFO:root:Train (Epoch 128): Loss/seq after 00750 batchs: 1021.3416748046875
INFO:root:Train (Epoch 128): Loss/seq after 00800 batchs: 1014.4714965820312
INFO:root:Train (Epoch 128): Loss/seq after 00850 batchs: 996.8729248046875
INFO:root:Train (Epoch 128): Loss/seq after 00900 batchs: 1011.8645629882812
INFO:root:Train (Epoch 128): Loss/seq after 00950 batchs: 1014.562255859375
INFO:root:Train (Epoch 128): Loss/seq after 01000 batchs: 1008.952392578125
INFO:root:Train (Epoch 128): Loss/seq after 01050 batchs: 995.8187866210938
INFO:root:Train (Epoch 128): Loss/seq after 01100 batchs: 996.61083984375
INFO:root:Train (Epoch 128): Loss/seq after 01150 batchs: 992.8894653320312
INFO:root:Train (Epoch 128): Loss/seq after 01200 batchs: 990.5506591796875
INFO:root:Train (Epoch 128): Loss/seq after 01250 batchs: 985.932373046875
INFO:root:Train (Epoch 128): Loss/seq after 01300 batchs: 977.9036865234375
INFO:root:Train (Epoch 128): Loss/seq after 01350 batchs: 966.02392578125
INFO:root:Train (Epoch 128): Loss/seq after 01400 batchs: 973.7861328125
INFO:root:Train (Epoch 128): Loss/seq after 01450 batchs: 971.8438110351562
INFO:root:Train (Epoch 128): Loss/seq after 01500 batchs: 972.1210327148438
INFO:root:Train (Epoch 128): Loss/seq after 01550 batchs: 975.82861328125
INFO:root:Train (Epoch 128): Loss/seq after 01600 batchs: 967.3756713867188
INFO:root:Train (Epoch 128): Loss/seq after 01650 batchs: 960.13818359375
INFO:root:Train (Epoch 128): Loss/seq after 01700 batchs: 958.8758544921875
INFO:root:Train (Epoch 128): Loss/seq after 01750 batchs: 955.0679931640625
INFO:root:Train (Epoch 128): Loss/seq after 01800 batchs: 948.0578002929688
INFO:root:Train (Epoch 128): Loss/seq after 01850 batchs: 940.0438232421875
INFO:root:Train (Epoch 128): Loss/seq after 01900 batchs: 939.83251953125
INFO:root:Train (Epoch 128): Loss/seq after 01950 batchs: 936.0460815429688
INFO:root:Train (Epoch 128): Loss/seq after 02000 batchs: 932.8208618164062
INFO:root:Train (Epoch 128): Loss/seq after 02050 batchs: 928.3739624023438
INFO:root:Train (Epoch 128): Loss/seq after 02100 batchs: 922.2260131835938
INFO:root:Train (Epoch 128): Loss/seq after 02150 batchs: 916.7294311523438
INFO:root:Train (Epoch 128): Loss/seq after 02200 batchs: 910.9242553710938
INFO:root:Train (Epoch 128): Loss/seq after 02250 batchs: 909.3359375
INFO:root:Train (Epoch 128): Loss/seq after 02300 batchs: 912.90869140625
INFO:root:Train (Epoch 128): Loss/seq after 02350 batchs: 906.4646606445312
INFO:root:Train (Epoch 128): Loss/seq after 02400 batchs: 906.535400390625
INFO:root:Train (Epoch 128): Loss/seq after 02450 batchs: 899.0280151367188
INFO:root:Train (Epoch 128): Loss/seq after 02500 batchs: 888.0741577148438
INFO:root:Train (Epoch 128): Loss/seq after 02550 batchs: 880.3704223632812
INFO:root:Train (Epoch 128): Loss/seq after 02600 batchs: 882.3651123046875
INFO:root:Train (Epoch 128): Loss/seq after 02650 batchs: 881.6337890625
INFO:root:Train (Epoch 128): Loss/seq after 02700 batchs: 879.6699829101562
INFO:root:Train (Epoch 128): Loss/seq after 02750 batchs: 893.4135131835938
INFO:root:Train (Epoch 128): Loss/seq after 02800 batchs: 895.8876342773438
INFO:root:Train (Epoch 128): Loss/seq after 02850 batchs: 893.2144165039062
INFO:root:Train (Epoch 128): Loss/seq after 02900 batchs: 893.0136108398438
INFO:root:Train (Epoch 128): Loss/seq after 02950 batchs: 888.3285522460938
INFO:root:Train (Epoch 128): Loss/seq after 03000 batchs: 890.6004028320312
INFO:root:Train (Epoch 128): Loss/seq after 03050 batchs: 893.724609375
INFO:root:Train (Epoch 128): Loss/seq after 03100 batchs: 896.8382568359375
INFO:root:Train (Epoch 128): Loss/seq after 03150 batchs: 900.0829467773438
INFO:root:Train (Epoch 128): Loss/seq after 03200 batchs: 903.3482055664062
INFO:root:Train (Epoch 128): Loss/seq after 03250 batchs: 905.2562255859375
INFO:root:Train (Epoch 128): Loss/seq after 03300 batchs: 903.2537841796875
INFO:root:Train (Epoch 128): Loss/seq after 03350 batchs: 902.2548828125
INFO:root:Train (Epoch 128): Loss/seq after 03400 batchs: 898.11474609375
INFO:root:Train (Epoch 128): Loss/seq after 03450 batchs: 893.2824096679688
INFO:root:Train (Epoch 128): Loss/seq after 03500 batchs: 891.6339111328125
INFO:root:Train (Epoch 128): Loss/seq after 03550 batchs: 886.9104614257812
INFO:root:Train (Epoch 128): Loss/seq after 03600 batchs: 893.7315063476562
INFO:root:Train (Epoch 128): Loss/seq after 03650 batchs: 889.9656372070312
INFO:root:Train (Epoch 128): Loss/seq after 03700 batchs: 891.3837890625
INFO:root:Train (Epoch 128): Loss/seq after 03750 batchs: 894.7443237304688
INFO:root:Train (Epoch 128): Loss/seq after 03800 batchs: 891.4352416992188
INFO:root:Train (Epoch 128): Loss/seq after 03850 batchs: 889.9274291992188
INFO:root:Train (Epoch 128): Loss/seq after 03900 batchs: 893.6408081054688
INFO:root:Train (Epoch 128): Loss/seq after 03950 batchs: 897.545654296875
INFO:root:Train (Epoch 128): Loss/seq after 04000 batchs: 892.4989013671875
INFO:root:Train (Epoch 128): Loss/seq after 04050 batchs: 888.2920532226562
INFO:root:Train (Epoch 128): Loss/seq after 04100 batchs: 884.5125732421875
INFO:root:Train (Epoch 128): Loss/seq after 04150 batchs: 881.8692016601562
INFO:root:Train (Epoch 128): Loss/seq after 04200 batchs: 877.9951171875
INFO:root:Train (Epoch 128): Loss/seq after 04250 batchs: 875.9486694335938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 128): Loss/seq after 00000 batches: 877.1124877929688
INFO:root:# Valid (Epoch 128): Loss/seq after 00050 batches: 1103.2586669921875
INFO:root:# Valid (Epoch 128): Loss/seq after 00100 batches: 1295.925537109375
INFO:root:# Valid (Epoch 128): Loss/seq after 00150 batches: 1033.180419921875
INFO:root:# Valid (Epoch 128): Loss/seq after 00200 batches: 928.68115234375
INFO:root:Artifacts: Make stick videos for epoch 128
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_128_on_20220423_070340.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_128_index_53_on_20220423_070340.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 129): Loss/seq after 00000 batchs: 1595.759521484375
INFO:root:Train (Epoch 129): Loss/seq after 00050 batchs: 1130.5501708984375
INFO:root:Train (Epoch 129): Loss/seq after 00100 batchs: 1103.6207275390625
INFO:root:Train (Epoch 129): Loss/seq after 00150 batchs: 989.6809692382812
INFO:root:Train (Epoch 129): Loss/seq after 00200 batchs: 1098.83837890625
INFO:root:Train (Epoch 129): Loss/seq after 00250 batchs: 1221.8734130859375
INFO:root:Train (Epoch 129): Loss/seq after 00300 batchs: 1193.7779541015625
INFO:root:Train (Epoch 129): Loss/seq after 00350 batchs: 1130.1534423828125
INFO:root:Train (Epoch 129): Loss/seq after 00400 batchs: 1140.50390625
INFO:root:Train (Epoch 129): Loss/seq after 00450 batchs: 1107.7325439453125
INFO:root:Train (Epoch 129): Loss/seq after 00500 batchs: 1087.856689453125
INFO:root:Train (Epoch 129): Loss/seq after 00550 batchs: 1052.4310302734375
INFO:root:Train (Epoch 129): Loss/seq after 00600 batchs: 1027.809814453125
INFO:root:Train (Epoch 129): Loss/seq after 00650 batchs: 1029.3834228515625
INFO:root:Train (Epoch 129): Loss/seq after 00700 batchs: 1016.2156982421875
INFO:root:Train (Epoch 129): Loss/seq after 00750 batchs: 1036.264404296875
INFO:root:Train (Epoch 129): Loss/seq after 00800 batchs: 1028.3951416015625
INFO:root:Train (Epoch 129): Loss/seq after 00850 batchs: 1010.1915893554688
INFO:root:Train (Epoch 129): Loss/seq after 00900 batchs: 1025.0113525390625
INFO:root:Train (Epoch 129): Loss/seq after 00950 batchs: 1028.2376708984375
INFO:root:Train (Epoch 129): Loss/seq after 01000 batchs: 1020.82275390625
INFO:root:Train (Epoch 129): Loss/seq after 01050 batchs: 1006.916015625
INFO:root:Train (Epoch 129): Loss/seq after 01100 batchs: 1004.4310302734375
INFO:root:Train (Epoch 129): Loss/seq after 01150 batchs: 1000.5147094726562
INFO:root:Train (Epoch 129): Loss/seq after 01200 batchs: 997.451904296875
INFO:root:Train (Epoch 129): Loss/seq after 01250 batchs: 991.5897216796875
INFO:root:Train (Epoch 129): Loss/seq after 01300 batchs: 981.0885620117188
INFO:root:Train (Epoch 129): Loss/seq after 01350 batchs: 968.8115844726562
INFO:root:Train (Epoch 129): Loss/seq after 01400 batchs: 976.5078125
INFO:root:Train (Epoch 129): Loss/seq after 01450 batchs: 974.2742919921875
INFO:root:Train (Epoch 129): Loss/seq after 01500 batchs: 974.3650512695312
INFO:root:Train (Epoch 129): Loss/seq after 01550 batchs: 977.887451171875
INFO:root:Train (Epoch 129): Loss/seq after 01600 batchs: 969.1779174804688
INFO:root:Train (Epoch 129): Loss/seq after 01650 batchs: 961.5206298828125
INFO:root:Train (Epoch 129): Loss/seq after 01700 batchs: 960.181396484375
INFO:root:Train (Epoch 129): Loss/seq after 01750 batchs: 956.2581787109375
INFO:root:Train (Epoch 129): Loss/seq after 01800 batchs: 949.109375
INFO:root:Train (Epoch 129): Loss/seq after 01850 batchs: 940.9816284179688
INFO:root:Train (Epoch 129): Loss/seq after 01900 batchs: 940.6707153320312
INFO:root:Train (Epoch 129): Loss/seq after 01950 batchs: 936.7106323242188
INFO:root:Train (Epoch 129): Loss/seq after 02000 batchs: 933.2764892578125
INFO:root:Train (Epoch 129): Loss/seq after 02050 batchs: 928.94775390625
INFO:root:Train (Epoch 129): Loss/seq after 02100 batchs: 922.8449096679688
INFO:root:Train (Epoch 129): Loss/seq after 02150 batchs: 917.3504638671875
INFO:root:Train (Epoch 129): Loss/seq after 02200 batchs: 911.4874877929688
INFO:root:Train (Epoch 129): Loss/seq after 02250 batchs: 909.7706909179688
INFO:root:Train (Epoch 129): Loss/seq after 02300 batchs: 912.959228515625
INFO:root:Train (Epoch 129): Loss/seq after 02350 batchs: 906.546142578125
INFO:root:Train (Epoch 129): Loss/seq after 02400 batchs: 906.7197875976562
INFO:root:Train (Epoch 129): Loss/seq after 02450 batchs: 899.2015380859375
INFO:root:Train (Epoch 129): Loss/seq after 02500 batchs: 888.2283935546875
INFO:root:Train (Epoch 129): Loss/seq after 02550 batchs: 880.272216796875
INFO:root:Train (Epoch 129): Loss/seq after 02600 batchs: 882.10888671875
INFO:root:Train (Epoch 129): Loss/seq after 02650 batchs: 881.3350830078125
INFO:root:Train (Epoch 129): Loss/seq after 02700 batchs: 879.0581665039062
INFO:root:Train (Epoch 129): Loss/seq after 02750 batchs: 893.7201538085938
INFO:root:Train (Epoch 129): Loss/seq after 02800 batchs: 894.4295654296875
INFO:root:Train (Epoch 129): Loss/seq after 02850 batchs: 891.93896484375
INFO:root:Train (Epoch 129): Loss/seq after 02900 batchs: 891.6214599609375
INFO:root:Train (Epoch 129): Loss/seq after 02950 batchs: 886.9624633789062
INFO:root:Train (Epoch 129): Loss/seq after 03000 batchs: 889.3313598632812
INFO:root:Train (Epoch 129): Loss/seq after 03050 batchs: 892.59130859375
INFO:root:Train (Epoch 129): Loss/seq after 03100 batchs: 896.4931030273438
INFO:root:Train (Epoch 129): Loss/seq after 03150 batchs: 899.520751953125
INFO:root:Train (Epoch 129): Loss/seq after 03200 batchs: 903.061767578125
INFO:root:Train (Epoch 129): Loss/seq after 03250 batchs: 904.8364868164062
INFO:root:Train (Epoch 129): Loss/seq after 03300 batchs: 903.1886596679688
INFO:root:Train (Epoch 129): Loss/seq after 03350 batchs: 902.6195678710938
INFO:root:Train (Epoch 129): Loss/seq after 03400 batchs: 898.5047607421875
INFO:root:Train (Epoch 129): Loss/seq after 03450 batchs: 893.637451171875
INFO:root:Train (Epoch 129): Loss/seq after 03500 batchs: 892.2430419921875
INFO:root:Train (Epoch 129): Loss/seq after 03550 batchs: 887.5301513671875
INFO:root:Train (Epoch 129): Loss/seq after 03600 batchs: 893.9644775390625
INFO:root:Train (Epoch 129): Loss/seq after 03650 batchs: 889.8914184570312
INFO:root:Train (Epoch 129): Loss/seq after 03700 batchs: 891.3843383789062
INFO:root:Train (Epoch 129): Loss/seq after 03750 batchs: 894.702880859375
INFO:root:Train (Epoch 129): Loss/seq after 03800 batchs: 891.3623046875
INFO:root:Train (Epoch 129): Loss/seq after 03850 batchs: 889.7715454101562
INFO:root:Train (Epoch 129): Loss/seq after 03900 batchs: 893.9165649414062
INFO:root:Train (Epoch 129): Loss/seq after 03950 batchs: 897.16455078125
INFO:root:Train (Epoch 129): Loss/seq after 04000 batchs: 892.1112670898438
INFO:root:Train (Epoch 129): Loss/seq after 04050 batchs: 887.9017333984375
INFO:root:Train (Epoch 129): Loss/seq after 04100 batchs: 884.0825805664062
INFO:root:Train (Epoch 129): Loss/seq after 04150 batchs: 881.4735717773438
INFO:root:Train (Epoch 129): Loss/seq after 04200 batchs: 877.5907592773438
INFO:root:Train (Epoch 129): Loss/seq after 04250 batchs: 875.5679931640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 129): Loss/seq after 00000 batches: 907.0706787109375
INFO:root:# Valid (Epoch 129): Loss/seq after 00050 batches: 1093.89599609375
INFO:root:# Valid (Epoch 129): Loss/seq after 00100 batches: 1305.089599609375
INFO:root:# Valid (Epoch 129): Loss/seq after 00150 batches: 1042.6265869140625
INFO:root:# Valid (Epoch 129): Loss/seq after 00200 batches: 934.2886962890625
INFO:root:Artifacts: Make stick videos for epoch 129
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_129_on_20220423_070834.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_129_index_1625_on_20220423_070834.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 130): Loss/seq after 00000 batchs: 1362.9490966796875
INFO:root:Train (Epoch 130): Loss/seq after 00050 batchs: 1118.3687744140625
INFO:root:Train (Epoch 130): Loss/seq after 00100 batchs: 1114.0933837890625
INFO:root:Train (Epoch 130): Loss/seq after 00150 batchs: 995.4871826171875
INFO:root:Train (Epoch 130): Loss/seq after 00200 batchs: 1102.6536865234375
INFO:root:Train (Epoch 130): Loss/seq after 00250 batchs: 1218.0738525390625
INFO:root:Train (Epoch 130): Loss/seq after 00300 batchs: 1191.824462890625
INFO:root:Train (Epoch 130): Loss/seq after 00350 batchs: 1129.03369140625
INFO:root:Train (Epoch 130): Loss/seq after 00400 batchs: 1140.7152099609375
INFO:root:Train (Epoch 130): Loss/seq after 00450 batchs: 1107.9093017578125
INFO:root:Train (Epoch 130): Loss/seq after 00500 batchs: 1088.470458984375
INFO:root:Train (Epoch 130): Loss/seq after 00550 batchs: 1051.796142578125
INFO:root:Train (Epoch 130): Loss/seq after 00600 batchs: 1027.407958984375
INFO:root:Train (Epoch 130): Loss/seq after 00650 batchs: 1022.02685546875
INFO:root:Train (Epoch 130): Loss/seq after 00700 batchs: 1001.643310546875
INFO:root:Train (Epoch 130): Loss/seq after 00750 batchs: 1025.969482421875
INFO:root:Train (Epoch 130): Loss/seq after 00800 batchs: 1018.2467651367188
INFO:root:Train (Epoch 130): Loss/seq after 00850 batchs: 1000.7233276367188
INFO:root:Train (Epoch 130): Loss/seq after 00900 batchs: 1015.7529296875
INFO:root:Train (Epoch 130): Loss/seq after 00950 batchs: 1019.6138305664062
INFO:root:Train (Epoch 130): Loss/seq after 01000 batchs: 1012.8460693359375
INFO:root:Train (Epoch 130): Loss/seq after 01050 batchs: 999.5560913085938
INFO:root:Train (Epoch 130): Loss/seq after 01100 batchs: 997.3729858398438
INFO:root:Train (Epoch 130): Loss/seq after 01150 batchs: 993.7805786132812
INFO:root:Train (Epoch 130): Loss/seq after 01200 batchs: 990.585205078125
INFO:root:Train (Epoch 130): Loss/seq after 01250 batchs: 986.1896362304688
INFO:root:Train (Epoch 130): Loss/seq after 01300 batchs: 974.9935302734375
INFO:root:Train (Epoch 130): Loss/seq after 01350 batchs: 962.5776977539062
INFO:root:Train (Epoch 130): Loss/seq after 01400 batchs: 969.051025390625
INFO:root:Train (Epoch 130): Loss/seq after 01450 batchs: 966.9181518554688
INFO:root:Train (Epoch 130): Loss/seq after 01500 batchs: 967.2039794921875
INFO:root:Train (Epoch 130): Loss/seq after 01550 batchs: 970.4111328125
INFO:root:Train (Epoch 130): Loss/seq after 01600 batchs: 961.8135986328125
INFO:root:Train (Epoch 130): Loss/seq after 01650 batchs: 954.562255859375
INFO:root:Train (Epoch 130): Loss/seq after 01700 batchs: 953.6630249023438
INFO:root:Train (Epoch 130): Loss/seq after 01750 batchs: 949.9804077148438
INFO:root:Train (Epoch 130): Loss/seq after 01800 batchs: 943.043212890625
INFO:root:Train (Epoch 130): Loss/seq after 01850 batchs: 935.2959594726562
INFO:root:Train (Epoch 130): Loss/seq after 01900 batchs: 935.1991577148438
INFO:root:Train (Epoch 130): Loss/seq after 01950 batchs: 931.4676513671875
INFO:root:Train (Epoch 130): Loss/seq after 02000 batchs: 928.3133544921875
INFO:root:Train (Epoch 130): Loss/seq after 02050 batchs: 924.2516479492188
INFO:root:Train (Epoch 130): Loss/seq after 02100 batchs: 918.246337890625
INFO:root:Train (Epoch 130): Loss/seq after 02150 batchs: 912.7904052734375
INFO:root:Train (Epoch 130): Loss/seq after 02200 batchs: 907.0675659179688
INFO:root:Train (Epoch 130): Loss/seq after 02250 batchs: 905.9354248046875
INFO:root:Train (Epoch 130): Loss/seq after 02300 batchs: 908.5021362304688
INFO:root:Train (Epoch 130): Loss/seq after 02350 batchs: 902.0822143554688
INFO:root:Train (Epoch 130): Loss/seq after 02400 batchs: 902.2852172851562
INFO:root:Train (Epoch 130): Loss/seq after 02450 batchs: 894.8524169921875
INFO:root:Train (Epoch 130): Loss/seq after 02500 batchs: 883.9598999023438
INFO:root:Train (Epoch 130): Loss/seq after 02550 batchs: 876.1553344726562
INFO:root:Train (Epoch 130): Loss/seq after 02600 batchs: 878.0699462890625
INFO:root:Train (Epoch 130): Loss/seq after 02650 batchs: 877.3724975585938
INFO:root:Train (Epoch 130): Loss/seq after 02700 batchs: 874.9952392578125
INFO:root:Train (Epoch 130): Loss/seq after 02750 batchs: 889.1589965820312
INFO:root:Train (Epoch 130): Loss/seq after 02800 batchs: 893.4229736328125
INFO:root:Train (Epoch 130): Loss/seq after 02850 batchs: 890.9464111328125
INFO:root:Train (Epoch 130): Loss/seq after 02900 batchs: 890.7966918945312
INFO:root:Train (Epoch 130): Loss/seq after 02950 batchs: 886.2119750976562
INFO:root:Train (Epoch 130): Loss/seq after 03000 batchs: 888.5855102539062
INFO:root:Train (Epoch 130): Loss/seq after 03050 batchs: 891.7322387695312
INFO:root:Train (Epoch 130): Loss/seq after 03100 batchs: 895.9109497070312
INFO:root:Train (Epoch 130): Loss/seq after 03150 batchs: 899.7761840820312
INFO:root:Train (Epoch 130): Loss/seq after 03200 batchs: 902.29052734375
INFO:root:Train (Epoch 130): Loss/seq after 03250 batchs: 904.8899536132812
INFO:root:Train (Epoch 130): Loss/seq after 03300 batchs: 902.8814086914062
INFO:root:Train (Epoch 130): Loss/seq after 03350 batchs: 901.8923950195312
INFO:root:Train (Epoch 130): Loss/seq after 03400 batchs: 897.7481079101562
INFO:root:Train (Epoch 130): Loss/seq after 03450 batchs: 892.8878784179688
INFO:root:Train (Epoch 130): Loss/seq after 03500 batchs: 891.314697265625
INFO:root:Train (Epoch 130): Loss/seq after 03550 batchs: 887.147216796875
INFO:root:Train (Epoch 130): Loss/seq after 03600 batchs: 894.278076171875
INFO:root:Train (Epoch 130): Loss/seq after 03650 batchs: 890.9193115234375
INFO:root:Train (Epoch 130): Loss/seq after 03700 batchs: 892.4387817382812
INFO:root:Train (Epoch 130): Loss/seq after 03750 batchs: 895.8294677734375
INFO:root:Train (Epoch 130): Loss/seq after 03800 batchs: 892.46435546875
INFO:root:Train (Epoch 130): Loss/seq after 03850 batchs: 890.7265625
INFO:root:Train (Epoch 130): Loss/seq after 03900 batchs: 894.4793090820312
INFO:root:Train (Epoch 130): Loss/seq after 03950 batchs: 897.6138916015625
INFO:root:Train (Epoch 130): Loss/seq after 04000 batchs: 892.5548706054688
INFO:root:Train (Epoch 130): Loss/seq after 04050 batchs: 888.3303833007812
INFO:root:Train (Epoch 130): Loss/seq after 04100 batchs: 884.6063232421875
INFO:root:Train (Epoch 130): Loss/seq after 04150 batchs: 881.9398193359375
INFO:root:Train (Epoch 130): Loss/seq after 04200 batchs: 878.0784301757812
INFO:root:Train (Epoch 130): Loss/seq after 04250 batchs: 876.0179443359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 130): Loss/seq after 00000 batches: 879.1340942382812
INFO:root:# Valid (Epoch 130): Loss/seq after 00050 batches: 1092.4007568359375
INFO:root:# Valid (Epoch 130): Loss/seq after 00100 batches: 1269.4102783203125
INFO:root:# Valid (Epoch 130): Loss/seq after 00150 batches: 1014.479736328125
INFO:root:# Valid (Epoch 130): Loss/seq after 00200 batches: 915.0977172851562
INFO:root:Artifacts: Make stick videos for epoch 130
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_130_on_20220423_071343.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_130_index_1299_on_20220423_071343.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 131): Loss/seq after 00000 batchs: 1443.5245361328125
INFO:root:Train (Epoch 131): Loss/seq after 00050 batchs: 1126.513671875
INFO:root:Train (Epoch 131): Loss/seq after 00100 batchs: 1088.7447509765625
INFO:root:Train (Epoch 131): Loss/seq after 00150 batchs: 977.756103515625
INFO:root:Train (Epoch 131): Loss/seq after 00200 batchs: 1088.239990234375
INFO:root:Train (Epoch 131): Loss/seq after 00250 batchs: 1211.146728515625
INFO:root:Train (Epoch 131): Loss/seq after 00300 batchs: 1185.3099365234375
INFO:root:Train (Epoch 131): Loss/seq after 00350 batchs: 1121.4969482421875
INFO:root:Train (Epoch 131): Loss/seq after 00400 batchs: 1133.15234375
INFO:root:Train (Epoch 131): Loss/seq after 00450 batchs: 1100.7630615234375
INFO:root:Train (Epoch 131): Loss/seq after 00500 batchs: 1079.6854248046875
INFO:root:Train (Epoch 131): Loss/seq after 00550 batchs: 1044.1234130859375
INFO:root:Train (Epoch 131): Loss/seq after 00600 batchs: 1019.59375
INFO:root:Train (Epoch 131): Loss/seq after 00650 batchs: 1020.6451416015625
INFO:root:Train (Epoch 131): Loss/seq after 00700 batchs: 1002.4376831054688
INFO:root:Train (Epoch 131): Loss/seq after 00750 batchs: 1026.4267578125
INFO:root:Train (Epoch 131): Loss/seq after 00800 batchs: 1018.7116088867188
INFO:root:Train (Epoch 131): Loss/seq after 00850 batchs: 1000.6557006835938
INFO:root:Train (Epoch 131): Loss/seq after 00900 batchs: 1014.9420166015625
INFO:root:Train (Epoch 131): Loss/seq after 00950 batchs: 1018.2949829101562
INFO:root:Train (Epoch 131): Loss/seq after 01000 batchs: 1012.054443359375
INFO:root:Train (Epoch 131): Loss/seq after 01050 batchs: 999.5084228515625
INFO:root:Train (Epoch 131): Loss/seq after 01100 batchs: 998.7225341796875
INFO:root:Train (Epoch 131): Loss/seq after 01150 batchs: 994.9109497070312
INFO:root:Train (Epoch 131): Loss/seq after 01200 batchs: 991.8532104492188
INFO:root:Train (Epoch 131): Loss/seq after 01250 batchs: 985.443359375
INFO:root:Train (Epoch 131): Loss/seq after 01300 batchs: 976.9140014648438
INFO:root:Train (Epoch 131): Loss/seq after 01350 batchs: 964.6304321289062
INFO:root:Train (Epoch 131): Loss/seq after 01400 batchs: 970.612060546875
INFO:root:Train (Epoch 131): Loss/seq after 01450 batchs: 968.619384765625
INFO:root:Train (Epoch 131): Loss/seq after 01500 batchs: 968.9603881835938
INFO:root:Train (Epoch 131): Loss/seq after 01550 batchs: 972.8358764648438
INFO:root:Train (Epoch 131): Loss/seq after 01600 batchs: 964.5660400390625
INFO:root:Train (Epoch 131): Loss/seq after 01650 batchs: 957.2353515625
INFO:root:Train (Epoch 131): Loss/seq after 01700 batchs: 955.9564819335938
INFO:root:Train (Epoch 131): Loss/seq after 01750 batchs: 952.1364135742188
INFO:root:Train (Epoch 131): Loss/seq after 01800 batchs: 945.168701171875
INFO:root:Train (Epoch 131): Loss/seq after 01850 batchs: 937.2664794921875
INFO:root:Train (Epoch 131): Loss/seq after 01900 batchs: 936.987060546875
INFO:root:Train (Epoch 131): Loss/seq after 01950 batchs: 933.22119140625
INFO:root:Train (Epoch 131): Loss/seq after 02000 batchs: 929.8587036132812
INFO:root:Train (Epoch 131): Loss/seq after 02050 batchs: 925.5984497070312
INFO:root:Train (Epoch 131): Loss/seq after 02100 batchs: 919.588134765625
INFO:root:Train (Epoch 131): Loss/seq after 02150 batchs: 914.0589599609375
INFO:root:Train (Epoch 131): Loss/seq after 02200 batchs: 908.2265625
INFO:root:Train (Epoch 131): Loss/seq after 02250 batchs: 906.633056640625
INFO:root:Train (Epoch 131): Loss/seq after 02300 batchs: 910.8970947265625
INFO:root:Train (Epoch 131): Loss/seq after 02350 batchs: 904.4706420898438
INFO:root:Train (Epoch 131): Loss/seq after 02400 batchs: 904.6409912109375
INFO:root:Train (Epoch 131): Loss/seq after 02450 batchs: 897.1862182617188
INFO:root:Train (Epoch 131): Loss/seq after 02500 batchs: 886.24462890625
INFO:root:Train (Epoch 131): Loss/seq after 02550 batchs: 878.652099609375
INFO:root:Train (Epoch 131): Loss/seq after 02600 batchs: 880.46826171875
INFO:root:Train (Epoch 131): Loss/seq after 02650 batchs: 879.5836181640625
INFO:root:Train (Epoch 131): Loss/seq after 02700 batchs: 877.147216796875
INFO:root:Train (Epoch 131): Loss/seq after 02750 batchs: 890.5618286132812
INFO:root:Train (Epoch 131): Loss/seq after 02800 batchs: 893.4794921875
INFO:root:Train (Epoch 131): Loss/seq after 02850 batchs: 890.9678955078125
INFO:root:Train (Epoch 131): Loss/seq after 02900 batchs: 891.0155029296875
INFO:root:Train (Epoch 131): Loss/seq after 02950 batchs: 886.3364868164062
INFO:root:Train (Epoch 131): Loss/seq after 03000 batchs: 888.652587890625
INFO:root:Train (Epoch 131): Loss/seq after 03050 batchs: 891.29541015625
INFO:root:Train (Epoch 131): Loss/seq after 03100 batchs: 894.7337036132812
INFO:root:Train (Epoch 131): Loss/seq after 03150 batchs: 898.2517700195312
INFO:root:Train (Epoch 131): Loss/seq after 03200 batchs: 900.9525146484375
INFO:root:Train (Epoch 131): Loss/seq after 03250 batchs: 901.801513671875
INFO:root:Train (Epoch 131): Loss/seq after 03300 batchs: 899.5099487304688
INFO:root:Train (Epoch 131): Loss/seq after 03350 batchs: 898.791015625
INFO:root:Train (Epoch 131): Loss/seq after 03400 batchs: 894.7421875
INFO:root:Train (Epoch 131): Loss/seq after 03450 batchs: 889.94091796875
INFO:root:Train (Epoch 131): Loss/seq after 03500 batchs: 888.41845703125
INFO:root:Train (Epoch 131): Loss/seq after 03550 batchs: 883.5755615234375
INFO:root:Train (Epoch 131): Loss/seq after 03600 batchs: 890.4979858398438
INFO:root:Train (Epoch 131): Loss/seq after 03650 batchs: 886.5987548828125
INFO:root:Train (Epoch 131): Loss/seq after 03700 batchs: 887.9794921875
INFO:root:Train (Epoch 131): Loss/seq after 03750 batchs: 891.3930053710938
INFO:root:Train (Epoch 131): Loss/seq after 03800 batchs: 888.0827026367188
INFO:root:Train (Epoch 131): Loss/seq after 03850 batchs: 886.39404296875
INFO:root:Train (Epoch 131): Loss/seq after 03900 batchs: 890.1550903320312
INFO:root:Train (Epoch 131): Loss/seq after 03950 batchs: 892.94189453125
INFO:root:Train (Epoch 131): Loss/seq after 04000 batchs: 887.9359130859375
INFO:root:Train (Epoch 131): Loss/seq after 04050 batchs: 883.75439453125
INFO:root:Train (Epoch 131): Loss/seq after 04100 batchs: 879.9740600585938
INFO:root:Train (Epoch 131): Loss/seq after 04150 batchs: 877.4053955078125
INFO:root:Train (Epoch 131): Loss/seq after 04200 batchs: 873.5897216796875
INFO:root:Train (Epoch 131): Loss/seq after 04250 batchs: 871.5735473632812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 131): Loss/seq after 00000 batches: 879.0604248046875
INFO:root:# Valid (Epoch 131): Loss/seq after 00050 batches: 1091.0836181640625
INFO:root:# Valid (Epoch 131): Loss/seq after 00100 batches: 1241.5330810546875
INFO:root:# Valid (Epoch 131): Loss/seq after 00150 batches: 997.8687133789062
INFO:root:# Valid (Epoch 131): Loss/seq after 00200 batches: 901.2202758789062
INFO:root:Artifacts: Make stick videos for epoch 131
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_131_on_20220423_071831.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_131_index_958_on_20220423_071831.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 132): Loss/seq after 00000 batchs: 1389.2642822265625
INFO:root:Train (Epoch 132): Loss/seq after 00050 batchs: 1109.9669189453125
INFO:root:Train (Epoch 132): Loss/seq after 00100 batchs: 1093.9324951171875
INFO:root:Train (Epoch 132): Loss/seq after 00150 batchs: 988.3756103515625
INFO:root:Train (Epoch 132): Loss/seq after 00200 batchs: 1095.59912109375
INFO:root:Train (Epoch 132): Loss/seq after 00250 batchs: 1216.071533203125
INFO:root:Train (Epoch 132): Loss/seq after 00300 batchs: 1188.8480224609375
INFO:root:Train (Epoch 132): Loss/seq after 00350 batchs: 1125.851806640625
INFO:root:Train (Epoch 132): Loss/seq after 00400 batchs: 1136.206787109375
INFO:root:Train (Epoch 132): Loss/seq after 00450 batchs: 1103.7216796875
INFO:root:Train (Epoch 132): Loss/seq after 00500 batchs: 1080.9254150390625
INFO:root:Train (Epoch 132): Loss/seq after 00550 batchs: 1044.6240234375
INFO:root:Train (Epoch 132): Loss/seq after 00600 batchs: 1020.7208251953125
INFO:root:Train (Epoch 132): Loss/seq after 00650 batchs: 1012.2008666992188
INFO:root:Train (Epoch 132): Loss/seq after 00700 batchs: 993.2462768554688
INFO:root:Train (Epoch 132): Loss/seq after 00750 batchs: 1012.267822265625
INFO:root:Train (Epoch 132): Loss/seq after 00800 batchs: 1006.4410400390625
INFO:root:Train (Epoch 132): Loss/seq after 00850 batchs: 989.3959350585938
INFO:root:Train (Epoch 132): Loss/seq after 00900 batchs: 1003.7996826171875
INFO:root:Train (Epoch 132): Loss/seq after 00950 batchs: 1005.0145874023438
INFO:root:Train (Epoch 132): Loss/seq after 01000 batchs: 999.0520629882812
INFO:root:Train (Epoch 132): Loss/seq after 01050 batchs: 986.377197265625
INFO:root:Train (Epoch 132): Loss/seq after 01100 batchs: 986.292236328125
INFO:root:Train (Epoch 132): Loss/seq after 01150 batchs: 982.9609375
INFO:root:Train (Epoch 132): Loss/seq after 01200 batchs: 980.1722412109375
INFO:root:Train (Epoch 132): Loss/seq after 01250 batchs: 975.0548706054688
INFO:root:Train (Epoch 132): Loss/seq after 01300 batchs: 964.3020629882812
INFO:root:Train (Epoch 132): Loss/seq after 01350 batchs: 952.409912109375
INFO:root:Train (Epoch 132): Loss/seq after 01400 batchs: 959.1047973632812
INFO:root:Train (Epoch 132): Loss/seq after 01450 batchs: 957.4896240234375
INFO:root:Train (Epoch 132): Loss/seq after 01500 batchs: 958.11767578125
INFO:root:Train (Epoch 132): Loss/seq after 01550 batchs: 961.5834350585938
INFO:root:Train (Epoch 132): Loss/seq after 01600 batchs: 953.26220703125
INFO:root:Train (Epoch 132): Loss/seq after 01650 batchs: 946.2012939453125
INFO:root:Train (Epoch 132): Loss/seq after 01700 batchs: 945.350341796875
INFO:root:Train (Epoch 132): Loss/seq after 01750 batchs: 941.8738403320312
INFO:root:Train (Epoch 132): Loss/seq after 01800 batchs: 935.3672485351562
INFO:root:Train (Epoch 132): Loss/seq after 01850 batchs: 927.92578125
INFO:root:Train (Epoch 132): Loss/seq after 01900 batchs: 928.0452880859375
INFO:root:Train (Epoch 132): Loss/seq after 01950 batchs: 924.479248046875
INFO:root:Train (Epoch 132): Loss/seq after 02000 batchs: 921.4330444335938
INFO:root:Train (Epoch 132): Loss/seq after 02050 batchs: 917.46484375
INFO:root:Train (Epoch 132): Loss/seq after 02100 batchs: 911.6476440429688
INFO:root:Train (Epoch 132): Loss/seq after 02150 batchs: 906.3046875
INFO:root:Train (Epoch 132): Loss/seq after 02200 batchs: 900.6680297851562
INFO:root:Train (Epoch 132): Loss/seq after 02250 batchs: 899.0083618164062
INFO:root:Train (Epoch 132): Loss/seq after 02300 batchs: 901.9378051757812
INFO:root:Train (Epoch 132): Loss/seq after 02350 batchs: 895.6957397460938
INFO:root:Train (Epoch 132): Loss/seq after 02400 batchs: 895.9874877929688
INFO:root:Train (Epoch 132): Loss/seq after 02450 batchs: 888.6948852539062
INFO:root:Train (Epoch 132): Loss/seq after 02500 batchs: 877.92431640625
INFO:root:Train (Epoch 132): Loss/seq after 02550 batchs: 870.186767578125
INFO:root:Train (Epoch 132): Loss/seq after 02600 batchs: 872.2020263671875
INFO:root:Train (Epoch 132): Loss/seq after 02650 batchs: 871.4730224609375
INFO:root:Train (Epoch 132): Loss/seq after 02700 batchs: 869.1226806640625
INFO:root:Train (Epoch 132): Loss/seq after 02750 batchs: 883.0422973632812
INFO:root:Train (Epoch 132): Loss/seq after 02800 batchs: 887.1187744140625
INFO:root:Train (Epoch 132): Loss/seq after 02850 batchs: 884.5614013671875
INFO:root:Train (Epoch 132): Loss/seq after 02900 batchs: 884.1967163085938
INFO:root:Train (Epoch 132): Loss/seq after 02950 batchs: 879.6218872070312
INFO:root:Train (Epoch 132): Loss/seq after 03000 batchs: 882.0955810546875
INFO:root:Train (Epoch 132): Loss/seq after 03050 batchs: 884.8944091796875
INFO:root:Train (Epoch 132): Loss/seq after 03100 batchs: 887.1028442382812
INFO:root:Train (Epoch 132): Loss/seq after 03150 batchs: 890.2871704101562
INFO:root:Train (Epoch 132): Loss/seq after 03200 batchs: 893.789306640625
INFO:root:Train (Epoch 132): Loss/seq after 03250 batchs: 895.9524536132812
INFO:root:Train (Epoch 132): Loss/seq after 03300 batchs: 893.9224853515625
INFO:root:Train (Epoch 132): Loss/seq after 03350 batchs: 893.0468139648438
INFO:root:Train (Epoch 132): Loss/seq after 03400 batchs: 889.0675048828125
INFO:root:Train (Epoch 132): Loss/seq after 03450 batchs: 884.2849731445312
INFO:root:Train (Epoch 132): Loss/seq after 03500 batchs: 882.6812744140625
INFO:root:Train (Epoch 132): Loss/seq after 03550 batchs: 877.921142578125
INFO:root:Train (Epoch 132): Loss/seq after 03600 batchs: 884.986083984375
INFO:root:Train (Epoch 132): Loss/seq after 03650 batchs: 881.5208740234375
INFO:root:Train (Epoch 132): Loss/seq after 03700 batchs: 883.1198120117188
INFO:root:Train (Epoch 132): Loss/seq after 03750 batchs: 886.5770874023438
INFO:root:Train (Epoch 132): Loss/seq after 03800 batchs: 883.3189697265625
INFO:root:Train (Epoch 132): Loss/seq after 03850 batchs: 881.5362548828125
INFO:root:Train (Epoch 132): Loss/seq after 03900 batchs: 885.4423217773438
INFO:root:Train (Epoch 132): Loss/seq after 03950 batchs: 888.5494995117188
INFO:root:Train (Epoch 132): Loss/seq after 04000 batchs: 883.61474609375
INFO:root:Train (Epoch 132): Loss/seq after 04050 batchs: 879.5044555664062
INFO:root:Train (Epoch 132): Loss/seq after 04100 batchs: 875.8711547851562
INFO:root:Train (Epoch 132): Loss/seq after 04150 batchs: 873.3533935546875
INFO:root:Train (Epoch 132): Loss/seq after 04200 batchs: 869.6241455078125
INFO:root:Train (Epoch 132): Loss/seq after 04250 batchs: 867.5968627929688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 132): Loss/seq after 00000 batches: 882.8700561523438
INFO:root:# Valid (Epoch 132): Loss/seq after 00050 batches: 1089.7711181640625
INFO:root:# Valid (Epoch 132): Loss/seq after 00100 batches: 1240.822509765625
INFO:root:# Valid (Epoch 132): Loss/seq after 00150 batches: 992.3045043945312
INFO:root:# Valid (Epoch 132): Loss/seq after 00200 batches: 897.694580078125
INFO:root:Artifacts: Make stick videos for epoch 132
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_132_on_20220423_072317.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_132_index_1334_on_20220423_072317.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 133): Loss/seq after 00000 batchs: 1553.09228515625
INFO:root:Train (Epoch 133): Loss/seq after 00050 batchs: 1104.7691650390625
INFO:root:Train (Epoch 133): Loss/seq after 00100 batchs: 1095.412841796875
INFO:root:Train (Epoch 133): Loss/seq after 00150 batchs: 989.1500244140625
INFO:root:Train (Epoch 133): Loss/seq after 00200 batchs: 1094.2718505859375
INFO:root:Train (Epoch 133): Loss/seq after 00250 batchs: 1208.2391357421875
INFO:root:Train (Epoch 133): Loss/seq after 00300 batchs: 1182.2535400390625
INFO:root:Train (Epoch 133): Loss/seq after 00350 batchs: 1119.5213623046875
INFO:root:Train (Epoch 133): Loss/seq after 00400 batchs: 1136.2716064453125
INFO:root:Train (Epoch 133): Loss/seq after 00450 batchs: 1103.8692626953125
INFO:root:Train (Epoch 133): Loss/seq after 00500 batchs: 1081.9156494140625
INFO:root:Train (Epoch 133): Loss/seq after 00550 batchs: 1045.7650146484375
INFO:root:Train (Epoch 133): Loss/seq after 00600 batchs: 1020.8812255859375
INFO:root:Train (Epoch 133): Loss/seq after 00650 batchs: 1019.0220947265625
INFO:root:Train (Epoch 133): Loss/seq after 00700 batchs: 997.6634521484375
INFO:root:Train (Epoch 133): Loss/seq after 00750 batchs: 1019.811767578125
INFO:root:Train (Epoch 133): Loss/seq after 00800 batchs: 1012.1176147460938
INFO:root:Train (Epoch 133): Loss/seq after 00850 batchs: 994.3262329101562
INFO:root:Train (Epoch 133): Loss/seq after 00900 batchs: 1007.7877807617188
INFO:root:Train (Epoch 133): Loss/seq after 00950 batchs: 1009.6058349609375
INFO:root:Train (Epoch 133): Loss/seq after 01000 batchs: 1003.18310546875
INFO:root:Train (Epoch 133): Loss/seq after 01050 batchs: 989.4412231445312
INFO:root:Train (Epoch 133): Loss/seq after 01100 batchs: 988.2684326171875
INFO:root:Train (Epoch 133): Loss/seq after 01150 batchs: 985.1334838867188
INFO:root:Train (Epoch 133): Loss/seq after 01200 batchs: 982.2808837890625
INFO:root:Train (Epoch 133): Loss/seq after 01250 batchs: 976.8894653320312
INFO:root:Train (Epoch 133): Loss/seq after 01300 batchs: 964.7823486328125
INFO:root:Train (Epoch 133): Loss/seq after 01350 batchs: 953.5712890625
INFO:root:Train (Epoch 133): Loss/seq after 01400 batchs: 962.22412109375
INFO:root:Train (Epoch 133): Loss/seq after 01450 batchs: 960.5277099609375
INFO:root:Train (Epoch 133): Loss/seq after 01500 batchs: 960.9583740234375
INFO:root:Train (Epoch 133): Loss/seq after 01550 batchs: 964.8278198242188
INFO:root:Train (Epoch 133): Loss/seq after 01600 batchs: 956.6729736328125
INFO:root:Train (Epoch 133): Loss/seq after 01650 batchs: 949.4720458984375
INFO:root:Train (Epoch 133): Loss/seq after 01700 batchs: 948.342041015625
INFO:root:Train (Epoch 133): Loss/seq after 01750 batchs: 944.76220703125
INFO:root:Train (Epoch 133): Loss/seq after 01800 batchs: 938.0169067382812
INFO:root:Train (Epoch 133): Loss/seq after 01850 batchs: 930.3218994140625
INFO:root:Train (Epoch 133): Loss/seq after 01900 batchs: 930.4127197265625
INFO:root:Train (Epoch 133): Loss/seq after 01950 batchs: 926.8744506835938
INFO:root:Train (Epoch 133): Loss/seq after 02000 batchs: 923.6163330078125
INFO:root:Train (Epoch 133): Loss/seq after 02050 batchs: 919.3930053710938
INFO:root:Train (Epoch 133): Loss/seq after 02100 batchs: 913.457763671875
INFO:root:Train (Epoch 133): Loss/seq after 02150 batchs: 908.1159057617188
INFO:root:Train (Epoch 133): Loss/seq after 02200 batchs: 902.477783203125
INFO:root:Train (Epoch 133): Loss/seq after 02250 batchs: 901.1568603515625
INFO:root:Train (Epoch 133): Loss/seq after 02300 batchs: 902.9063720703125
INFO:root:Train (Epoch 133): Loss/seq after 02350 batchs: 896.5169067382812
INFO:root:Train (Epoch 133): Loss/seq after 02400 batchs: 896.7176513671875
INFO:root:Train (Epoch 133): Loss/seq after 02450 batchs: 889.3674926757812
INFO:root:Train (Epoch 133): Loss/seq after 02500 batchs: 878.59423828125
INFO:root:Train (Epoch 133): Loss/seq after 02550 batchs: 871.0458374023438
INFO:root:Train (Epoch 133): Loss/seq after 02600 batchs: 873.0054931640625
INFO:root:Train (Epoch 133): Loss/seq after 02650 batchs: 872.5274658203125
INFO:root:Train (Epoch 133): Loss/seq after 02700 batchs: 870.1209106445312
INFO:root:Train (Epoch 133): Loss/seq after 02750 batchs: 883.5982055664062
INFO:root:Train (Epoch 133): Loss/seq after 02800 batchs: 886.48046875
INFO:root:Train (Epoch 133): Loss/seq after 02850 batchs: 884.0941162109375
INFO:root:Train (Epoch 133): Loss/seq after 02900 batchs: 883.6104736328125
INFO:root:Train (Epoch 133): Loss/seq after 02950 batchs: 879.1009521484375
INFO:root:Train (Epoch 133): Loss/seq after 03000 batchs: 881.5712280273438
INFO:root:Train (Epoch 133): Loss/seq after 03050 batchs: 884.4992065429688
INFO:root:Train (Epoch 133): Loss/seq after 03100 batchs: 887.5595703125
INFO:root:Train (Epoch 133): Loss/seq after 03150 batchs: 890.772216796875
INFO:root:Train (Epoch 133): Loss/seq after 03200 batchs: 894.8641967773438
INFO:root:Train (Epoch 133): Loss/seq after 03250 batchs: 897.0470581054688
INFO:root:Train (Epoch 133): Loss/seq after 03300 batchs: 894.9321899414062
INFO:root:Train (Epoch 133): Loss/seq after 03350 batchs: 894.5320434570312
INFO:root:Train (Epoch 133): Loss/seq after 03400 batchs: 890.5194091796875
INFO:root:Train (Epoch 133): Loss/seq after 03450 batchs: 885.7644653320312
INFO:root:Train (Epoch 133): Loss/seq after 03500 batchs: 884.3152465820312
INFO:root:Train (Epoch 133): Loss/seq after 03550 batchs: 880.1948852539062
INFO:root:Train (Epoch 133): Loss/seq after 03600 batchs: 887.4072875976562
INFO:root:Train (Epoch 133): Loss/seq after 03650 batchs: 884.3408203125
INFO:root:Train (Epoch 133): Loss/seq after 03700 batchs: 886.0095825195312
INFO:root:Train (Epoch 133): Loss/seq after 03750 batchs: 889.40771484375
INFO:root:Train (Epoch 133): Loss/seq after 03800 batchs: 886.1339721679688
INFO:root:Train (Epoch 133): Loss/seq after 03850 batchs: 884.364501953125
INFO:root:Train (Epoch 133): Loss/seq after 03900 batchs: 887.7813720703125
INFO:root:Train (Epoch 133): Loss/seq after 03950 batchs: 890.5592041015625
INFO:root:Train (Epoch 133): Loss/seq after 04000 batchs: 885.5874633789062
INFO:root:Train (Epoch 133): Loss/seq after 04050 batchs: 881.4544677734375
INFO:root:Train (Epoch 133): Loss/seq after 04100 batchs: 877.858154296875
INFO:root:Train (Epoch 133): Loss/seq after 04150 batchs: 875.2825927734375
INFO:root:Train (Epoch 133): Loss/seq after 04200 batchs: 871.4759521484375
INFO:root:Train (Epoch 133): Loss/seq after 04250 batchs: 869.4387817382812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 133): Loss/seq after 00000 batches: 870.6405639648438
INFO:root:# Valid (Epoch 133): Loss/seq after 00050 batches: 1087.8267822265625
INFO:root:# Valid (Epoch 133): Loss/seq after 00100 batches: 1254.1639404296875
INFO:root:# Valid (Epoch 133): Loss/seq after 00150 batches: 1004.391357421875
INFO:root:# Valid (Epoch 133): Loss/seq after 00200 batches: 906.3163452148438
INFO:root:Artifacts: Make stick videos for epoch 133
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_133_on_20220423_072806.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_133_index_566_on_20220423_072806.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 134): Loss/seq after 00000 batchs: 1419.61572265625
INFO:root:Train (Epoch 134): Loss/seq after 00050 batchs: 1102.2518310546875
INFO:root:Train (Epoch 134): Loss/seq after 00100 batchs: 1070.2760009765625
INFO:root:Train (Epoch 134): Loss/seq after 00150 batchs: 968.0096435546875
INFO:root:Train (Epoch 134): Loss/seq after 00200 batchs: 1061.5238037109375
INFO:root:Train (Epoch 134): Loss/seq after 00250 batchs: 1188.255859375
INFO:root:Train (Epoch 134): Loss/seq after 00300 batchs: 1165.9456787109375
INFO:root:Train (Epoch 134): Loss/seq after 00350 batchs: 1105.0948486328125
INFO:root:Train (Epoch 134): Loss/seq after 00400 batchs: 1115.5611572265625
INFO:root:Train (Epoch 134): Loss/seq after 00450 batchs: 1085.4635009765625
INFO:root:Train (Epoch 134): Loss/seq after 00500 batchs: 1063.6044921875
INFO:root:Train (Epoch 134): Loss/seq after 00550 batchs: 1028.8907470703125
INFO:root:Train (Epoch 134): Loss/seq after 00600 batchs: 1005.6400756835938
INFO:root:Train (Epoch 134): Loss/seq after 00650 batchs: 1008.0628051757812
INFO:root:Train (Epoch 134): Loss/seq after 00700 batchs: 988.5234985351562
INFO:root:Train (Epoch 134): Loss/seq after 00750 batchs: 1008.012939453125
INFO:root:Train (Epoch 134): Loss/seq after 00800 batchs: 1000.60400390625
INFO:root:Train (Epoch 134): Loss/seq after 00850 batchs: 983.720947265625
INFO:root:Train (Epoch 134): Loss/seq after 00900 batchs: 996.9441528320312
INFO:root:Train (Epoch 134): Loss/seq after 00950 batchs: 999.4893798828125
INFO:root:Train (Epoch 134): Loss/seq after 01000 batchs: 994.1988525390625
INFO:root:Train (Epoch 134): Loss/seq after 01050 batchs: 982.86279296875
INFO:root:Train (Epoch 134): Loss/seq after 01100 batchs: 981.9434814453125
INFO:root:Train (Epoch 134): Loss/seq after 01150 batchs: 979.4825439453125
INFO:root:Train (Epoch 134): Loss/seq after 01200 batchs: 978.001953125
INFO:root:Train (Epoch 134): Loss/seq after 01250 batchs: 972.631591796875
INFO:root:Train (Epoch 134): Loss/seq after 01300 batchs: 960.4462890625
INFO:root:Train (Epoch 134): Loss/seq after 01350 batchs: 948.1771240234375
INFO:root:Train (Epoch 134): Loss/seq after 01400 batchs: 954.24755859375
INFO:root:Train (Epoch 134): Loss/seq after 01450 batchs: 952.8045043945312
INFO:root:Train (Epoch 134): Loss/seq after 01500 batchs: 953.626953125
INFO:root:Train (Epoch 134): Loss/seq after 01550 batchs: 957.5621337890625
INFO:root:Train (Epoch 134): Loss/seq after 01600 batchs: 949.3970336914062
INFO:root:Train (Epoch 134): Loss/seq after 01650 batchs: 942.2472534179688
INFO:root:Train (Epoch 134): Loss/seq after 01700 batchs: 941.4898071289062
INFO:root:Train (Epoch 134): Loss/seq after 01750 batchs: 938.0458984375
INFO:root:Train (Epoch 134): Loss/seq after 01800 batchs: 931.3639526367188
INFO:root:Train (Epoch 134): Loss/seq after 01850 batchs: 923.684814453125
INFO:root:Train (Epoch 134): Loss/seq after 01900 batchs: 923.8826904296875
INFO:root:Train (Epoch 134): Loss/seq after 01950 batchs: 920.4067993164062
INFO:root:Train (Epoch 134): Loss/seq after 02000 batchs: 917.3038330078125
INFO:root:Train (Epoch 134): Loss/seq after 02050 batchs: 913.2145385742188
INFO:root:Train (Epoch 134): Loss/seq after 02100 batchs: 907.5897216796875
INFO:root:Train (Epoch 134): Loss/seq after 02150 batchs: 902.4666137695312
INFO:root:Train (Epoch 134): Loss/seq after 02200 batchs: 896.9058227539062
INFO:root:Train (Epoch 134): Loss/seq after 02250 batchs: 895.3451538085938
INFO:root:Train (Epoch 134): Loss/seq after 02300 batchs: 898.3133544921875
INFO:root:Train (Epoch 134): Loss/seq after 02350 batchs: 892.197021484375
INFO:root:Train (Epoch 134): Loss/seq after 02400 batchs: 892.4869995117188
INFO:root:Train (Epoch 134): Loss/seq after 02450 batchs: 885.1954345703125
INFO:root:Train (Epoch 134): Loss/seq after 02500 batchs: 874.4890747070312
INFO:root:Train (Epoch 134): Loss/seq after 02550 batchs: 867.1019897460938
INFO:root:Train (Epoch 134): Loss/seq after 02600 batchs: 869.1663818359375
INFO:root:Train (Epoch 134): Loss/seq after 02650 batchs: 868.3759765625
INFO:root:Train (Epoch 134): Loss/seq after 02700 batchs: 866.3375854492188
INFO:root:Train (Epoch 134): Loss/seq after 02750 batchs: 880.104736328125
INFO:root:Train (Epoch 134): Loss/seq after 02800 batchs: 882.5309448242188
INFO:root:Train (Epoch 134): Loss/seq after 02850 batchs: 880.1035766601562
INFO:root:Train (Epoch 134): Loss/seq after 02900 batchs: 880.107177734375
INFO:root:Train (Epoch 134): Loss/seq after 02950 batchs: 875.6578369140625
INFO:root:Train (Epoch 134): Loss/seq after 03000 batchs: 878.147216796875
INFO:root:Train (Epoch 134): Loss/seq after 03050 batchs: 880.7059326171875
INFO:root:Train (Epoch 134): Loss/seq after 03100 batchs: 884.1560668945312
INFO:root:Train (Epoch 134): Loss/seq after 03150 batchs: 888.2781372070312
INFO:root:Train (Epoch 134): Loss/seq after 03200 batchs: 891.5806884765625
INFO:root:Train (Epoch 134): Loss/seq after 03250 batchs: 894.0794067382812
INFO:root:Train (Epoch 134): Loss/seq after 03300 batchs: 892.073486328125
INFO:root:Train (Epoch 134): Loss/seq after 03350 batchs: 891.1223754882812
INFO:root:Train (Epoch 134): Loss/seq after 03400 batchs: 887.1240844726562
INFO:root:Train (Epoch 134): Loss/seq after 03450 batchs: 882.3145141601562
INFO:root:Train (Epoch 134): Loss/seq after 03500 batchs: 880.6757202148438
INFO:root:Train (Epoch 134): Loss/seq after 03550 batchs: 875.9069213867188
INFO:root:Train (Epoch 134): Loss/seq after 03600 batchs: 882.2340087890625
INFO:root:Train (Epoch 134): Loss/seq after 03650 batchs: 878.4373779296875
INFO:root:Train (Epoch 134): Loss/seq after 03700 batchs: 880.1417846679688
INFO:root:Train (Epoch 134): Loss/seq after 03750 batchs: 883.582275390625
INFO:root:Train (Epoch 134): Loss/seq after 03800 batchs: 880.375732421875
INFO:root:Train (Epoch 134): Loss/seq after 03850 batchs: 878.5529174804688
INFO:root:Train (Epoch 134): Loss/seq after 03900 batchs: 881.7915649414062
INFO:root:Train (Epoch 134): Loss/seq after 03950 batchs: 884.5751953125
INFO:root:Train (Epoch 134): Loss/seq after 04000 batchs: 879.682861328125
INFO:root:Train (Epoch 134): Loss/seq after 04050 batchs: 875.6304321289062
INFO:root:Train (Epoch 134): Loss/seq after 04100 batchs: 872.0414428710938
INFO:root:Train (Epoch 134): Loss/seq after 04150 batchs: 869.5617065429688
INFO:root:Train (Epoch 134): Loss/seq after 04200 batchs: 865.8681030273438
INFO:root:Train (Epoch 134): Loss/seq after 04250 batchs: 863.9041137695312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 134): Loss/seq after 00000 batches: 879.9984741210938
INFO:root:# Valid (Epoch 134): Loss/seq after 00050 batches: 1100.60009765625
INFO:root:# Valid (Epoch 134): Loss/seq after 00100 batches: 1276.9698486328125
INFO:root:# Valid (Epoch 134): Loss/seq after 00150 batches: 1019.1134033203125
INFO:root:# Valid (Epoch 134): Loss/seq after 00200 batches: 916.1409301757812
INFO:root:Artifacts: Make stick videos for epoch 134
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_134_on_20220423_073309.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_134_index_1120_on_20220423_073309.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 135): Loss/seq after 00000 batchs: 1375.77197265625
INFO:root:Train (Epoch 135): Loss/seq after 00050 batchs: 1127.8184814453125
INFO:root:Train (Epoch 135): Loss/seq after 00100 batchs: 1092.3865966796875
INFO:root:Train (Epoch 135): Loss/seq after 00150 batchs: 982.1781005859375
INFO:root:Train (Epoch 135): Loss/seq after 00200 batchs: 1097.0311279296875
INFO:root:Train (Epoch 135): Loss/seq after 00250 batchs: 1215.5328369140625
INFO:root:Train (Epoch 135): Loss/seq after 00300 batchs: 1188.5762939453125
INFO:root:Train (Epoch 135): Loss/seq after 00350 batchs: 1123.385009765625
INFO:root:Train (Epoch 135): Loss/seq after 00400 batchs: 1134.874755859375
INFO:root:Train (Epoch 135): Loss/seq after 00450 batchs: 1102.7542724609375
INFO:root:Train (Epoch 135): Loss/seq after 00500 batchs: 1077.7457275390625
INFO:root:Train (Epoch 135): Loss/seq after 00550 batchs: 1041.86376953125
INFO:root:Train (Epoch 135): Loss/seq after 00600 batchs: 1018.0115356445312
INFO:root:Train (Epoch 135): Loss/seq after 00650 batchs: 1015.2350463867188
INFO:root:Train (Epoch 135): Loss/seq after 00700 batchs: 998.9552612304688
INFO:root:Train (Epoch 135): Loss/seq after 00750 batchs: 1015.4116821289062
INFO:root:Train (Epoch 135): Loss/seq after 00800 batchs: 1008.9000244140625
INFO:root:Train (Epoch 135): Loss/seq after 00850 batchs: 991.4376220703125
INFO:root:Train (Epoch 135): Loss/seq after 00900 batchs: 1004.2018432617188
INFO:root:Train (Epoch 135): Loss/seq after 00950 batchs: 1004.7696533203125
INFO:root:Train (Epoch 135): Loss/seq after 01000 batchs: 998.0626220703125
INFO:root:Train (Epoch 135): Loss/seq after 01050 batchs: 986.9425048828125
INFO:root:Train (Epoch 135): Loss/seq after 01100 batchs: 984.1585083007812
INFO:root:Train (Epoch 135): Loss/seq after 01150 batchs: 981.0443115234375
INFO:root:Train (Epoch 135): Loss/seq after 01200 batchs: 979.1915283203125
INFO:root:Train (Epoch 135): Loss/seq after 01250 batchs: 973.158447265625
INFO:root:Train (Epoch 135): Loss/seq after 01300 batchs: 958.8937377929688
INFO:root:Train (Epoch 135): Loss/seq after 01350 batchs: 948.1721801757812
INFO:root:Train (Epoch 135): Loss/seq after 01400 batchs: 954.14892578125
INFO:root:Train (Epoch 135): Loss/seq after 01450 batchs: 952.6602172851562
INFO:root:Train (Epoch 135): Loss/seq after 01500 batchs: 953.231201171875
INFO:root:Train (Epoch 135): Loss/seq after 01550 batchs: 956.3762817382812
INFO:root:Train (Epoch 135): Loss/seq after 01600 batchs: 948.2791137695312
INFO:root:Train (Epoch 135): Loss/seq after 01650 batchs: 940.4544677734375
INFO:root:Train (Epoch 135): Loss/seq after 01700 batchs: 939.647705078125
INFO:root:Train (Epoch 135): Loss/seq after 01750 batchs: 936.30126953125
INFO:root:Train (Epoch 135): Loss/seq after 01800 batchs: 929.6768798828125
INFO:root:Train (Epoch 135): Loss/seq after 01850 batchs: 922.0072021484375
INFO:root:Train (Epoch 135): Loss/seq after 01900 batchs: 922.0802001953125
INFO:root:Train (Epoch 135): Loss/seq after 01950 batchs: 918.6141967773438
INFO:root:Train (Epoch 135): Loss/seq after 02000 batchs: 915.6751098632812
INFO:root:Train (Epoch 135): Loss/seq after 02050 batchs: 911.6582641601562
INFO:root:Train (Epoch 135): Loss/seq after 02100 batchs: 905.8934936523438
INFO:root:Train (Epoch 135): Loss/seq after 02150 batchs: 900.7410278320312
INFO:root:Train (Epoch 135): Loss/seq after 02200 batchs: 895.2589721679688
INFO:root:Train (Epoch 135): Loss/seq after 02250 batchs: 893.1846923828125
INFO:root:Train (Epoch 135): Loss/seq after 02300 batchs: 897.1622924804688
INFO:root:Train (Epoch 135): Loss/seq after 02350 batchs: 890.8912353515625
INFO:root:Train (Epoch 135): Loss/seq after 02400 batchs: 891.2232666015625
INFO:root:Train (Epoch 135): Loss/seq after 02450 batchs: 884.0054931640625
INFO:root:Train (Epoch 135): Loss/seq after 02500 batchs: 873.3297729492188
INFO:root:Train (Epoch 135): Loss/seq after 02550 batchs: 865.8773193359375
INFO:root:Train (Epoch 135): Loss/seq after 02600 batchs: 867.8713989257812
INFO:root:Train (Epoch 135): Loss/seq after 02650 batchs: 867.1944580078125
INFO:root:Train (Epoch 135): Loss/seq after 02700 batchs: 865.0933227539062
INFO:root:Train (Epoch 135): Loss/seq after 02750 batchs: 878.8555297851562
INFO:root:Train (Epoch 135): Loss/seq after 02800 batchs: 880.4891967773438
INFO:root:Train (Epoch 135): Loss/seq after 02850 batchs: 878.1634521484375
INFO:root:Train (Epoch 135): Loss/seq after 02900 batchs: 878.0350952148438
INFO:root:Train (Epoch 135): Loss/seq after 02950 batchs: 873.5570678710938
INFO:root:Train (Epoch 135): Loss/seq after 03000 batchs: 876.115234375
INFO:root:Train (Epoch 135): Loss/seq after 03050 batchs: 878.8200073242188
INFO:root:Train (Epoch 135): Loss/seq after 03100 batchs: 881.4545288085938
INFO:root:Train (Epoch 135): Loss/seq after 03150 batchs: 884.98193359375
INFO:root:Train (Epoch 135): Loss/seq after 03200 batchs: 886.803955078125
INFO:root:Train (Epoch 135): Loss/seq after 03250 batchs: 888.9177856445312
INFO:root:Train (Epoch 135): Loss/seq after 03300 batchs: 887.206298828125
INFO:root:Train (Epoch 135): Loss/seq after 03350 batchs: 886.4378051757812
INFO:root:Train (Epoch 135): Loss/seq after 03400 batchs: 882.500732421875
INFO:root:Train (Epoch 135): Loss/seq after 03450 batchs: 877.7949829101562
INFO:root:Train (Epoch 135): Loss/seq after 03500 batchs: 875.9825439453125
INFO:root:Train (Epoch 135): Loss/seq after 03550 batchs: 871.4105224609375
INFO:root:Train (Epoch 135): Loss/seq after 03600 batchs: 877.8900756835938
INFO:root:Train (Epoch 135): Loss/seq after 03650 batchs: 873.9874267578125
INFO:root:Train (Epoch 135): Loss/seq after 03700 batchs: 875.6282348632812
INFO:root:Train (Epoch 135): Loss/seq after 03750 batchs: 879.143798828125
INFO:root:Train (Epoch 135): Loss/seq after 03800 batchs: 875.97216796875
INFO:root:Train (Epoch 135): Loss/seq after 03850 batchs: 874.162353515625
INFO:root:Train (Epoch 135): Loss/seq after 03900 batchs: 877.9938354492188
INFO:root:Train (Epoch 135): Loss/seq after 03950 batchs: 880.8319702148438
INFO:root:Train (Epoch 135): Loss/seq after 04000 batchs: 875.9775390625
INFO:root:Train (Epoch 135): Loss/seq after 04050 batchs: 871.9616088867188
INFO:root:Train (Epoch 135): Loss/seq after 04100 batchs: 868.3643798828125
INFO:root:Train (Epoch 135): Loss/seq after 04150 batchs: 865.9371948242188
INFO:root:Train (Epoch 135): Loss/seq after 04200 batchs: 862.2617797851562
INFO:root:Train (Epoch 135): Loss/seq after 04250 batchs: 860.397216796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 135): Loss/seq after 00000 batches: 878.3338623046875
INFO:root:# Valid (Epoch 135): Loss/seq after 00050 batches: 1100.3927001953125
INFO:root:# Valid (Epoch 135): Loss/seq after 00100 batches: 1256.26416015625
INFO:root:# Valid (Epoch 135): Loss/seq after 00150 batches: 1005.141845703125
INFO:root:# Valid (Epoch 135): Loss/seq after 00200 batches: 907.1895751953125
INFO:root:Artifacts: Make stick videos for epoch 135
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_135_on_20220423_073754.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_135_index_263_on_20220423_073754.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 136): Loss/seq after 00000 batchs: 1416.4266357421875
INFO:root:Train (Epoch 136): Loss/seq after 00050 batchs: 1113.5955810546875
INFO:root:Train (Epoch 136): Loss/seq after 00100 batchs: 1077.6602783203125
INFO:root:Train (Epoch 136): Loss/seq after 00150 batchs: 971.85888671875
INFO:root:Train (Epoch 136): Loss/seq after 00200 batchs: 1066.7825927734375
INFO:root:Train (Epoch 136): Loss/seq after 00250 batchs: 1191.0155029296875
INFO:root:Train (Epoch 136): Loss/seq after 00300 batchs: 1168.0196533203125
INFO:root:Train (Epoch 136): Loss/seq after 00350 batchs: 1107.4783935546875
INFO:root:Train (Epoch 136): Loss/seq after 00400 batchs: 1117.3419189453125
INFO:root:Train (Epoch 136): Loss/seq after 00450 batchs: 1086.875244140625
INFO:root:Train (Epoch 136): Loss/seq after 00500 batchs: 1066.42626953125
INFO:root:Train (Epoch 136): Loss/seq after 00550 batchs: 1030.948974609375
INFO:root:Train (Epoch 136): Loss/seq after 00600 batchs: 1008.0437622070312
INFO:root:Train (Epoch 136): Loss/seq after 00650 batchs: 1007.3935546875
INFO:root:Train (Epoch 136): Loss/seq after 00700 batchs: 989.3561401367188
INFO:root:Train (Epoch 136): Loss/seq after 00750 batchs: 1010.3049926757812
INFO:root:Train (Epoch 136): Loss/seq after 00800 batchs: 1001.9752197265625
INFO:root:Train (Epoch 136): Loss/seq after 00850 batchs: 985.051513671875
INFO:root:Train (Epoch 136): Loss/seq after 00900 batchs: 996.2167358398438
INFO:root:Train (Epoch 136): Loss/seq after 00950 batchs: 997.1094970703125
INFO:root:Train (Epoch 136): Loss/seq after 01000 batchs: 991.1289672851562
INFO:root:Train (Epoch 136): Loss/seq after 01050 batchs: 979.9871215820312
INFO:root:Train (Epoch 136): Loss/seq after 01100 batchs: 978.0435180664062
INFO:root:Train (Epoch 136): Loss/seq after 01150 batchs: 975.2544555664062
INFO:root:Train (Epoch 136): Loss/seq after 01200 batchs: 973.744873046875
INFO:root:Train (Epoch 136): Loss/seq after 01250 batchs: 969.3409423828125
INFO:root:Train (Epoch 136): Loss/seq after 01300 batchs: 955.9140014648438
INFO:root:Train (Epoch 136): Loss/seq after 01350 batchs: 943.1060791015625
INFO:root:Train (Epoch 136): Loss/seq after 01400 batchs: 952.0388793945312
INFO:root:Train (Epoch 136): Loss/seq after 01450 batchs: 950.6524047851562
INFO:root:Train (Epoch 136): Loss/seq after 01500 batchs: 951.3993530273438
INFO:root:Train (Epoch 136): Loss/seq after 01550 batchs: 955.9010009765625
INFO:root:Train (Epoch 136): Loss/seq after 01600 batchs: 947.9747924804688
INFO:root:Train (Epoch 136): Loss/seq after 01650 batchs: 940.8775634765625
INFO:root:Train (Epoch 136): Loss/seq after 01700 batchs: 940.3936157226562
INFO:root:Train (Epoch 136): Loss/seq after 01750 batchs: 937.1566772460938
INFO:root:Train (Epoch 136): Loss/seq after 01800 batchs: 930.6605834960938
INFO:root:Train (Epoch 136): Loss/seq after 01850 batchs: 923.133056640625
INFO:root:Train (Epoch 136): Loss/seq after 01900 batchs: 923.358154296875
INFO:root:Train (Epoch 136): Loss/seq after 01950 batchs: 920.02783203125
INFO:root:Train (Epoch 136): Loss/seq after 02000 batchs: 917.0203247070312
INFO:root:Train (Epoch 136): Loss/seq after 02050 batchs: 912.9959106445312
INFO:root:Train (Epoch 136): Loss/seq after 02100 batchs: 907.1990356445312
INFO:root:Train (Epoch 136): Loss/seq after 02150 batchs: 901.92529296875
INFO:root:Train (Epoch 136): Loss/seq after 02200 batchs: 896.3798828125
INFO:root:Train (Epoch 136): Loss/seq after 02250 batchs: 895.1689453125
INFO:root:Train (Epoch 136): Loss/seq after 02300 batchs: 896.7450561523438
INFO:root:Train (Epoch 136): Loss/seq after 02350 batchs: 890.6741333007812
INFO:root:Train (Epoch 136): Loss/seq after 02400 batchs: 891.2702026367188
INFO:root:Train (Epoch 136): Loss/seq after 02450 batchs: 884.104248046875
INFO:root:Train (Epoch 136): Loss/seq after 02500 batchs: 873.420654296875
INFO:root:Train (Epoch 136): Loss/seq after 02550 batchs: 865.9841918945312
INFO:root:Train (Epoch 136): Loss/seq after 02600 batchs: 868.0157470703125
INFO:root:Train (Epoch 136): Loss/seq after 02650 batchs: 867.5484619140625
INFO:root:Train (Epoch 136): Loss/seq after 02700 batchs: 865.1468505859375
INFO:root:Train (Epoch 136): Loss/seq after 02750 batchs: 879.6454467773438
INFO:root:Train (Epoch 136): Loss/seq after 02800 batchs: 881.1044921875
INFO:root:Train (Epoch 136): Loss/seq after 02850 batchs: 878.5029296875
INFO:root:Train (Epoch 136): Loss/seq after 02900 batchs: 878.2069702148438
INFO:root:Train (Epoch 136): Loss/seq after 02950 batchs: 873.7288818359375
INFO:root:Train (Epoch 136): Loss/seq after 03000 batchs: 876.234130859375
INFO:root:Train (Epoch 136): Loss/seq after 03050 batchs: 879.0797729492188
INFO:root:Train (Epoch 136): Loss/seq after 03100 batchs: 881.4791870117188
INFO:root:Train (Epoch 136): Loss/seq after 03150 batchs: 885.5377807617188
INFO:root:Train (Epoch 136): Loss/seq after 03200 batchs: 887.6648559570312
INFO:root:Train (Epoch 136): Loss/seq after 03250 batchs: 889.6264038085938
INFO:root:Train (Epoch 136): Loss/seq after 03300 batchs: 887.3305053710938
INFO:root:Train (Epoch 136): Loss/seq after 03350 batchs: 886.2835083007812
INFO:root:Train (Epoch 136): Loss/seq after 03400 batchs: 882.3519287109375
INFO:root:Train (Epoch 136): Loss/seq after 03450 batchs: 877.560791015625
INFO:root:Train (Epoch 136): Loss/seq after 03500 batchs: 875.8193359375
INFO:root:Train (Epoch 136): Loss/seq after 03550 batchs: 871.1478271484375
INFO:root:Train (Epoch 136): Loss/seq after 03600 batchs: 877.6657104492188
INFO:root:Train (Epoch 136): Loss/seq after 03650 batchs: 873.953857421875
INFO:root:Train (Epoch 136): Loss/seq after 03700 batchs: 875.6721801757812
INFO:root:Train (Epoch 136): Loss/seq after 03750 batchs: 879.1980590820312
INFO:root:Train (Epoch 136): Loss/seq after 03800 batchs: 876.0254516601562
INFO:root:Train (Epoch 136): Loss/seq after 03850 batchs: 874.2354736328125
INFO:root:Train (Epoch 136): Loss/seq after 03900 batchs: 877.6510009765625
INFO:root:Train (Epoch 136): Loss/seq after 03950 batchs: 880.3142700195312
INFO:root:Train (Epoch 136): Loss/seq after 04000 batchs: 875.4660034179688
INFO:root:Train (Epoch 136): Loss/seq after 04050 batchs: 871.4326171875
INFO:root:Train (Epoch 136): Loss/seq after 04100 batchs: 867.8836669921875
INFO:root:Train (Epoch 136): Loss/seq after 04150 batchs: 865.420166015625
INFO:root:Train (Epoch 136): Loss/seq after 04200 batchs: 861.7421875
INFO:root:Train (Epoch 136): Loss/seq after 04250 batchs: 859.857177734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 136): Loss/seq after 00000 batches: 868.1809692382812
INFO:root:# Valid (Epoch 136): Loss/seq after 00050 batches: 1087.5784912109375
INFO:root:# Valid (Epoch 136): Loss/seq after 00100 batches: 1262.746826171875
INFO:root:# Valid (Epoch 136): Loss/seq after 00150 batches: 1008.79150390625
INFO:root:# Valid (Epoch 136): Loss/seq after 00200 batches: 909.9627685546875
INFO:root:Artifacts: Make stick videos for epoch 136
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_136_on_20220423_074237.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_136_index_286_on_20220423_074237.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 137): Loss/seq after 00000 batchs: 1332.9278564453125
INFO:root:Train (Epoch 137): Loss/seq after 00050 batchs: 1101.6683349609375
INFO:root:Train (Epoch 137): Loss/seq after 00100 batchs: 1080.08544921875
INFO:root:Train (Epoch 137): Loss/seq after 00150 batchs: 974.2318725585938
INFO:root:Train (Epoch 137): Loss/seq after 00200 batchs: 1065.617919921875
INFO:root:Train (Epoch 137): Loss/seq after 00250 batchs: 1182.32080078125
INFO:root:Train (Epoch 137): Loss/seq after 00300 batchs: 1160.3939208984375
INFO:root:Train (Epoch 137): Loss/seq after 00350 batchs: 1099.97998046875
INFO:root:Train (Epoch 137): Loss/seq after 00400 batchs: 1108.083984375
INFO:root:Train (Epoch 137): Loss/seq after 00450 batchs: 1078.5673828125
INFO:root:Train (Epoch 137): Loss/seq after 00500 batchs: 1060.6629638671875
INFO:root:Train (Epoch 137): Loss/seq after 00550 batchs: 1026.224853515625
INFO:root:Train (Epoch 137): Loss/seq after 00600 batchs: 1003.1168823242188
INFO:root:Train (Epoch 137): Loss/seq after 00650 batchs: 1005.5752563476562
INFO:root:Train (Epoch 137): Loss/seq after 00700 batchs: 990.3779907226562
INFO:root:Train (Epoch 137): Loss/seq after 00750 batchs: 1013.1798095703125
INFO:root:Train (Epoch 137): Loss/seq after 00800 batchs: 1006.0253295898438
INFO:root:Train (Epoch 137): Loss/seq after 00850 batchs: 988.93896484375
INFO:root:Train (Epoch 137): Loss/seq after 00900 batchs: 1001.8489990234375
INFO:root:Train (Epoch 137): Loss/seq after 00950 batchs: 1003.2320556640625
INFO:root:Train (Epoch 137): Loss/seq after 01000 batchs: 997.5833740234375
INFO:root:Train (Epoch 137): Loss/seq after 01050 batchs: 985.5625610351562
INFO:root:Train (Epoch 137): Loss/seq after 01100 batchs: 984.8524169921875
INFO:root:Train (Epoch 137): Loss/seq after 01150 batchs: 981.6316528320312
INFO:root:Train (Epoch 137): Loss/seq after 01200 batchs: 979.0386962890625
INFO:root:Train (Epoch 137): Loss/seq after 01250 batchs: 972.9654541015625
INFO:root:Train (Epoch 137): Loss/seq after 01300 batchs: 962.018310546875
INFO:root:Train (Epoch 137): Loss/seq after 01350 batchs: 948.2371215820312
INFO:root:Train (Epoch 137): Loss/seq after 01400 batchs: 956.1251831054688
INFO:root:Train (Epoch 137): Loss/seq after 01450 batchs: 954.4649047851562
INFO:root:Train (Epoch 137): Loss/seq after 01500 batchs: 955.0709228515625
INFO:root:Train (Epoch 137): Loss/seq after 01550 batchs: 958.4434814453125
INFO:root:Train (Epoch 137): Loss/seq after 01600 batchs: 950.1766357421875
INFO:root:Train (Epoch 137): Loss/seq after 01650 batchs: 942.9318237304688
INFO:root:Train (Epoch 137): Loss/seq after 01700 batchs: 942.0039672851562
INFO:root:Train (Epoch 137): Loss/seq after 01750 batchs: 938.477783203125
INFO:root:Train (Epoch 137): Loss/seq after 01800 batchs: 931.7830810546875
INFO:root:Train (Epoch 137): Loss/seq after 01850 batchs: 924.0354614257812
INFO:root:Train (Epoch 137): Loss/seq after 01900 batchs: 924.0719604492188
INFO:root:Train (Epoch 137): Loss/seq after 01950 batchs: 920.4306030273438
INFO:root:Train (Epoch 137): Loss/seq after 02000 batchs: 917.2533569335938
INFO:root:Train (Epoch 137): Loss/seq after 02050 batchs: 913.3841552734375
INFO:root:Train (Epoch 137): Loss/seq after 02100 batchs: 907.7623291015625
INFO:root:Train (Epoch 137): Loss/seq after 02150 batchs: 902.5568237304688
INFO:root:Train (Epoch 137): Loss/seq after 02200 batchs: 897.0069580078125
INFO:root:Train (Epoch 137): Loss/seq after 02250 batchs: 895.6212158203125
INFO:root:Train (Epoch 137): Loss/seq after 02300 batchs: 897.6380004882812
INFO:root:Train (Epoch 137): Loss/seq after 02350 batchs: 891.5634155273438
INFO:root:Train (Epoch 137): Loss/seq after 02400 batchs: 891.8908081054688
INFO:root:Train (Epoch 137): Loss/seq after 02450 batchs: 884.5421142578125
INFO:root:Train (Epoch 137): Loss/seq after 02500 batchs: 873.8414916992188
INFO:root:Train (Epoch 137): Loss/seq after 02550 batchs: 866.4977416992188
INFO:root:Train (Epoch 137): Loss/seq after 02600 batchs: 868.520263671875
INFO:root:Train (Epoch 137): Loss/seq after 02650 batchs: 867.797119140625
INFO:root:Train (Epoch 137): Loss/seq after 02700 batchs: 865.4100952148438
INFO:root:Train (Epoch 137): Loss/seq after 02750 batchs: 877.4432983398438
INFO:root:Train (Epoch 137): Loss/seq after 02800 batchs: 879.0795288085938
INFO:root:Train (Epoch 137): Loss/seq after 02850 batchs: 876.429931640625
INFO:root:Train (Epoch 137): Loss/seq after 02900 batchs: 876.1406860351562
INFO:root:Train (Epoch 137): Loss/seq after 02950 batchs: 871.8056030273438
INFO:root:Train (Epoch 137): Loss/seq after 03000 batchs: 874.4000854492188
INFO:root:Train (Epoch 137): Loss/seq after 03050 batchs: 876.9426879882812
INFO:root:Train (Epoch 137): Loss/seq after 03100 batchs: 880.197265625
INFO:root:Train (Epoch 137): Loss/seq after 03150 batchs: 885.4852905273438
INFO:root:Train (Epoch 137): Loss/seq after 03200 batchs: 889.703857421875
INFO:root:Train (Epoch 137): Loss/seq after 03250 batchs: 891.3903198242188
INFO:root:Train (Epoch 137): Loss/seq after 03300 batchs: 888.9833374023438
INFO:root:Train (Epoch 137): Loss/seq after 03350 batchs: 887.8158569335938
INFO:root:Train (Epoch 137): Loss/seq after 03400 batchs: 883.8580322265625
INFO:root:Train (Epoch 137): Loss/seq after 03450 batchs: 879.0595092773438
INFO:root:Train (Epoch 137): Loss/seq after 03500 batchs: 877.2131958007812
INFO:root:Train (Epoch 137): Loss/seq after 03550 batchs: 872.6564331054688
INFO:root:Train (Epoch 137): Loss/seq after 03600 batchs: 879.0671997070312
INFO:root:Train (Epoch 137): Loss/seq after 03650 batchs: 875.2133178710938
INFO:root:Train (Epoch 137): Loss/seq after 03700 batchs: 876.825439453125
INFO:root:Train (Epoch 137): Loss/seq after 03750 batchs: 880.29541015625
INFO:root:Train (Epoch 137): Loss/seq after 03800 batchs: 877.1321411132812
INFO:root:Train (Epoch 137): Loss/seq after 03850 batchs: 875.4822998046875
INFO:root:Train (Epoch 137): Loss/seq after 03900 batchs: 878.3704223632812
INFO:root:Train (Epoch 137): Loss/seq after 03950 batchs: 880.95849609375
INFO:root:Train (Epoch 137): Loss/seq after 04000 batchs: 876.1085205078125
INFO:root:Train (Epoch 137): Loss/seq after 04050 batchs: 872.0970458984375
INFO:root:Train (Epoch 137): Loss/seq after 04100 batchs: 868.52490234375
INFO:root:Train (Epoch 137): Loss/seq after 04150 batchs: 865.9869995117188
INFO:root:Train (Epoch 137): Loss/seq after 04200 batchs: 862.3032836914062
INFO:root:Train (Epoch 137): Loss/seq after 04250 batchs: 860.377197265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 137): Loss/seq after 00000 batches: 872.3067626953125
INFO:root:# Valid (Epoch 137): Loss/seq after 00050 batches: 1098.9600830078125
INFO:root:# Valid (Epoch 137): Loss/seq after 00100 batches: 1231.0838623046875
INFO:root:# Valid (Epoch 137): Loss/seq after 00150 batches: 989.2178955078125
INFO:root:# Valid (Epoch 137): Loss/seq after 00200 batches: 894.1624755859375
INFO:root:Artifacts: Make stick videos for epoch 137
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_137_on_20220423_074730.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_137_index_1902_on_20220423_074730.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 138): Loss/seq after 00000 batchs: 1453.4151611328125
INFO:root:Train (Epoch 138): Loss/seq after 00050 batchs: 1089.1556396484375
INFO:root:Train (Epoch 138): Loss/seq after 00100 batchs: 1053.8465576171875
INFO:root:Train (Epoch 138): Loss/seq after 00150 batchs: 955.0602416992188
INFO:root:Train (Epoch 138): Loss/seq after 00200 batchs: 1048.4622802734375
INFO:root:Train (Epoch 138): Loss/seq after 00250 batchs: 1174.59521484375
INFO:root:Train (Epoch 138): Loss/seq after 00300 batchs: 1155.0384521484375
INFO:root:Train (Epoch 138): Loss/seq after 00350 batchs: 1094.638916015625
INFO:root:Train (Epoch 138): Loss/seq after 00400 batchs: 1108.44482421875
INFO:root:Train (Epoch 138): Loss/seq after 00450 batchs: 1078.83447265625
INFO:root:Train (Epoch 138): Loss/seq after 00500 batchs: 1057.8558349609375
INFO:root:Train (Epoch 138): Loss/seq after 00550 batchs: 1023.5272216796875
INFO:root:Train (Epoch 138): Loss/seq after 00600 batchs: 999.8663330078125
INFO:root:Train (Epoch 138): Loss/seq after 00650 batchs: 996.77197265625
INFO:root:Train (Epoch 138): Loss/seq after 00700 batchs: 979.8667602539062
INFO:root:Train (Epoch 138): Loss/seq after 00750 batchs: 997.20703125
INFO:root:Train (Epoch 138): Loss/seq after 00800 batchs: 989.518798828125
INFO:root:Train (Epoch 138): Loss/seq after 00850 batchs: 972.7686157226562
INFO:root:Train (Epoch 138): Loss/seq after 00900 batchs: 983.5267944335938
INFO:root:Train (Epoch 138): Loss/seq after 00950 batchs: 988.4752807617188
INFO:root:Train (Epoch 138): Loss/seq after 01000 batchs: 982.3904418945312
INFO:root:Train (Epoch 138): Loss/seq after 01050 batchs: 969.5245361328125
INFO:root:Train (Epoch 138): Loss/seq after 01100 batchs: 966.0634765625
INFO:root:Train (Epoch 138): Loss/seq after 01150 batchs: 963.1473999023438
INFO:root:Train (Epoch 138): Loss/seq after 01200 batchs: 961.713134765625
INFO:root:Train (Epoch 138): Loss/seq after 01250 batchs: 957.8353271484375
INFO:root:Train (Epoch 138): Loss/seq after 01300 batchs: 943.8480834960938
INFO:root:Train (Epoch 138): Loss/seq after 01350 batchs: 931.1514282226562
INFO:root:Train (Epoch 138): Loss/seq after 01400 batchs: 937.2735595703125
INFO:root:Train (Epoch 138): Loss/seq after 01450 batchs: 936.3991088867188
INFO:root:Train (Epoch 138): Loss/seq after 01500 batchs: 937.7786865234375
INFO:root:Train (Epoch 138): Loss/seq after 01550 batchs: 940.57177734375
INFO:root:Train (Epoch 138): Loss/seq after 01600 batchs: 933.2037353515625
INFO:root:Train (Epoch 138): Loss/seq after 01650 batchs: 926.310302734375
INFO:root:Train (Epoch 138): Loss/seq after 01700 batchs: 926.0319213867188
INFO:root:Train (Epoch 138): Loss/seq after 01750 batchs: 923.017333984375
INFO:root:Train (Epoch 138): Loss/seq after 01800 batchs: 916.7942504882812
INFO:root:Train (Epoch 138): Loss/seq after 01850 batchs: 909.5028076171875
INFO:root:Train (Epoch 138): Loss/seq after 01900 batchs: 909.8988647460938
INFO:root:Train (Epoch 138): Loss/seq after 01950 batchs: 906.8336791992188
INFO:root:Train (Epoch 138): Loss/seq after 02000 batchs: 904.07421875
INFO:root:Train (Epoch 138): Loss/seq after 02050 batchs: 900.2013549804688
INFO:root:Train (Epoch 138): Loss/seq after 02100 batchs: 894.5993041992188
INFO:root:Train (Epoch 138): Loss/seq after 02150 batchs: 889.6246948242188
INFO:root:Train (Epoch 138): Loss/seq after 02200 batchs: 884.3919677734375
INFO:root:Train (Epoch 138): Loss/seq after 02250 batchs: 883.4674072265625
INFO:root:Train (Epoch 138): Loss/seq after 02300 batchs: 886.3416748046875
INFO:root:Train (Epoch 138): Loss/seq after 02350 batchs: 880.4766845703125
INFO:root:Train (Epoch 138): Loss/seq after 02400 batchs: 881.036865234375
INFO:root:Train (Epoch 138): Loss/seq after 02450 batchs: 874.060302734375
INFO:root:Train (Epoch 138): Loss/seq after 02500 batchs: 863.5870361328125
INFO:root:Train (Epoch 138): Loss/seq after 02550 batchs: 856.2655639648438
INFO:root:Train (Epoch 138): Loss/seq after 02600 batchs: 858.3473510742188
INFO:root:Train (Epoch 138): Loss/seq after 02650 batchs: 857.7930297851562
INFO:root:Train (Epoch 138): Loss/seq after 02700 batchs: 855.7823486328125
INFO:root:Train (Epoch 138): Loss/seq after 02750 batchs: 870.9174194335938
INFO:root:Train (Epoch 138): Loss/seq after 02800 batchs: 873.54541015625
INFO:root:Train (Epoch 138): Loss/seq after 02850 batchs: 870.9656372070312
INFO:root:Train (Epoch 138): Loss/seq after 02900 batchs: 870.8413696289062
INFO:root:Train (Epoch 138): Loss/seq after 02950 batchs: 866.6141357421875
INFO:root:Train (Epoch 138): Loss/seq after 03000 batchs: 869.2371215820312
INFO:root:Train (Epoch 138): Loss/seq after 03050 batchs: 871.8236694335938
INFO:root:Train (Epoch 138): Loss/seq after 03100 batchs: 874.4988403320312
INFO:root:Train (Epoch 138): Loss/seq after 03150 batchs: 878.3240356445312
INFO:root:Train (Epoch 138): Loss/seq after 03200 batchs: 881.4539184570312
INFO:root:Train (Epoch 138): Loss/seq after 03250 batchs: 882.9923095703125
INFO:root:Train (Epoch 138): Loss/seq after 03300 batchs: 880.868896484375
INFO:root:Train (Epoch 138): Loss/seq after 03350 batchs: 879.7504272460938
INFO:root:Train (Epoch 138): Loss/seq after 03400 batchs: 875.8673706054688
INFO:root:Train (Epoch 138): Loss/seq after 03450 batchs: 871.1234130859375
INFO:root:Train (Epoch 138): Loss/seq after 03500 batchs: 869.5039672851562
INFO:root:Train (Epoch 138): Loss/seq after 03550 batchs: 864.7615356445312
INFO:root:Train (Epoch 138): Loss/seq after 03600 batchs: 871.3255004882812
INFO:root:Train (Epoch 138): Loss/seq after 03650 batchs: 867.4478149414062
INFO:root:Train (Epoch 138): Loss/seq after 03700 batchs: 869.0192260742188
INFO:root:Train (Epoch 138): Loss/seq after 03750 batchs: 872.5814819335938
INFO:root:Train (Epoch 138): Loss/seq after 03800 batchs: 869.4622192382812
INFO:root:Train (Epoch 138): Loss/seq after 03850 batchs: 867.8362426757812
INFO:root:Train (Epoch 138): Loss/seq after 03900 batchs: 871.407470703125
INFO:root:Train (Epoch 138): Loss/seq after 03950 batchs: 874.509765625
INFO:root:Train (Epoch 138): Loss/seq after 04000 batchs: 869.730712890625
INFO:root:Train (Epoch 138): Loss/seq after 04050 batchs: 865.7755126953125
INFO:root:Train (Epoch 138): Loss/seq after 04100 batchs: 862.1940307617188
INFO:root:Train (Epoch 138): Loss/seq after 04150 batchs: 859.7276611328125
INFO:root:Train (Epoch 138): Loss/seq after 04200 batchs: 856.16845703125
INFO:root:Train (Epoch 138): Loss/seq after 04250 batchs: 854.2709350585938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 138): Loss/seq after 00000 batches: 899.0254516601562
INFO:root:# Valid (Epoch 138): Loss/seq after 00050 batches: 1092.6568603515625
INFO:root:# Valid (Epoch 138): Loss/seq after 00100 batches: 1265.4169921875
INFO:root:# Valid (Epoch 138): Loss/seq after 00150 batches: 1011.1461181640625
INFO:root:# Valid (Epoch 138): Loss/seq after 00200 batches: 910.3751831054688
INFO:root:Artifacts: Make stick videos for epoch 138
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_138_on_20220423_075221.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_138_index_893_on_20220423_075221.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 139): Loss/seq after 00000 batchs: 1399.5213623046875
INFO:root:Train (Epoch 139): Loss/seq after 00050 batchs: 1085.8350830078125
INFO:root:Train (Epoch 139): Loss/seq after 00100 batchs: 1079.96484375
INFO:root:Train (Epoch 139): Loss/seq after 00150 batchs: 977.3449096679688
INFO:root:Train (Epoch 139): Loss/seq after 00200 batchs: 1064.35693359375
INFO:root:Train (Epoch 139): Loss/seq after 00250 batchs: 1192.8514404296875
INFO:root:Train (Epoch 139): Loss/seq after 00300 batchs: 1169.4169921875
INFO:root:Train (Epoch 139): Loss/seq after 00350 batchs: 1107.272216796875
INFO:root:Train (Epoch 139): Loss/seq after 00400 batchs: 1122.050537109375
INFO:root:Train (Epoch 139): Loss/seq after 00450 batchs: 1090.7353515625
INFO:root:Train (Epoch 139): Loss/seq after 00500 batchs: 1067.7410888671875
INFO:root:Train (Epoch 139): Loss/seq after 00550 batchs: 1032.2957763671875
INFO:root:Train (Epoch 139): Loss/seq after 00600 batchs: 1008.33203125
INFO:root:Train (Epoch 139): Loss/seq after 00650 batchs: 1005.3416748046875
INFO:root:Train (Epoch 139): Loss/seq after 00700 batchs: 985.981201171875
INFO:root:Train (Epoch 139): Loss/seq after 00750 batchs: 1003.1959228515625
INFO:root:Train (Epoch 139): Loss/seq after 00800 batchs: 996.1558227539062
INFO:root:Train (Epoch 139): Loss/seq after 00850 batchs: 979.3650512695312
INFO:root:Train (Epoch 139): Loss/seq after 00900 batchs: 988.844970703125
INFO:root:Train (Epoch 139): Loss/seq after 00950 batchs: 990.54541015625
INFO:root:Train (Epoch 139): Loss/seq after 01000 batchs: 983.7493286132812
INFO:root:Train (Epoch 139): Loss/seq after 01050 batchs: 970.70849609375
INFO:root:Train (Epoch 139): Loss/seq after 01100 batchs: 964.632080078125
INFO:root:Train (Epoch 139): Loss/seq after 01150 batchs: 961.1363525390625
INFO:root:Train (Epoch 139): Loss/seq after 01200 batchs: 959.1232299804688
INFO:root:Train (Epoch 139): Loss/seq after 01250 batchs: 954.6738891601562
INFO:root:Train (Epoch 139): Loss/seq after 01300 batchs: 940.5435180664062
INFO:root:Train (Epoch 139): Loss/seq after 01350 batchs: 928.44775390625
INFO:root:Train (Epoch 139): Loss/seq after 01400 batchs: 936.3449096679688
INFO:root:Train (Epoch 139): Loss/seq after 01450 batchs: 935.3865966796875
INFO:root:Train (Epoch 139): Loss/seq after 01500 batchs: 936.3914184570312
INFO:root:Train (Epoch 139): Loss/seq after 01550 batchs: 939.5321044921875
INFO:root:Train (Epoch 139): Loss/seq after 01600 batchs: 931.9154663085938
INFO:root:Train (Epoch 139): Loss/seq after 01650 batchs: 924.9013061523438
INFO:root:Train (Epoch 139): Loss/seq after 01700 batchs: 924.4349975585938
INFO:root:Train (Epoch 139): Loss/seq after 01750 batchs: 921.4134521484375
INFO:root:Train (Epoch 139): Loss/seq after 01800 batchs: 915.2840576171875
INFO:root:Train (Epoch 139): Loss/seq after 01850 batchs: 908.0068359375
INFO:root:Train (Epoch 139): Loss/seq after 01900 batchs: 908.2374877929688
INFO:root:Train (Epoch 139): Loss/seq after 01950 batchs: 904.9380493164062
INFO:root:Train (Epoch 139): Loss/seq after 02000 batchs: 902.1084594726562
INFO:root:Train (Epoch 139): Loss/seq after 02050 batchs: 898.3916625976562
INFO:root:Train (Epoch 139): Loss/seq after 02100 batchs: 892.8739624023438
INFO:root:Train (Epoch 139): Loss/seq after 02150 batchs: 887.9312744140625
INFO:root:Train (Epoch 139): Loss/seq after 02200 batchs: 882.7539672851562
INFO:root:Train (Epoch 139): Loss/seq after 02250 batchs: 881.5796508789062
INFO:root:Train (Epoch 139): Loss/seq after 02300 batchs: 883.6117553710938
INFO:root:Train (Epoch 139): Loss/seq after 02350 batchs: 877.6055297851562
INFO:root:Train (Epoch 139): Loss/seq after 02400 batchs: 878.1914672851562
INFO:root:Train (Epoch 139): Loss/seq after 02450 batchs: 871.2645874023438
INFO:root:Train (Epoch 139): Loss/seq after 02500 batchs: 860.8223876953125
INFO:root:Train (Epoch 139): Loss/seq after 02550 batchs: 853.300537109375
INFO:root:Train (Epoch 139): Loss/seq after 02600 batchs: 855.5618896484375
INFO:root:Train (Epoch 139): Loss/seq after 02650 batchs: 854.5718383789062
INFO:root:Train (Epoch 139): Loss/seq after 02700 batchs: 852.57177734375
INFO:root:Train (Epoch 139): Loss/seq after 02750 batchs: 865.5774536132812
INFO:root:Train (Epoch 139): Loss/seq after 02800 batchs: 868.5633544921875
INFO:root:Train (Epoch 139): Loss/seq after 02850 batchs: 866.351318359375
INFO:root:Train (Epoch 139): Loss/seq after 02900 batchs: 866.080810546875
INFO:root:Train (Epoch 139): Loss/seq after 02950 batchs: 861.8245239257812
INFO:root:Train (Epoch 139): Loss/seq after 03000 batchs: 864.512939453125
INFO:root:Train (Epoch 139): Loss/seq after 03050 batchs: 867.3872680664062
INFO:root:Train (Epoch 139): Loss/seq after 03100 batchs: 870.451416015625
INFO:root:Train (Epoch 139): Loss/seq after 03150 batchs: 874.1478271484375
INFO:root:Train (Epoch 139): Loss/seq after 03200 batchs: 876.0419311523438
INFO:root:Train (Epoch 139): Loss/seq after 03250 batchs: 877.6119384765625
INFO:root:Train (Epoch 139): Loss/seq after 03300 batchs: 875.2408447265625
INFO:root:Train (Epoch 139): Loss/seq after 03350 batchs: 873.97802734375
INFO:root:Train (Epoch 139): Loss/seq after 03400 batchs: 869.907958984375
INFO:root:Train (Epoch 139): Loss/seq after 03450 batchs: 865.5858154296875
INFO:root:Train (Epoch 139): Loss/seq after 03500 batchs: 864.338623046875
INFO:root:Train (Epoch 139): Loss/seq after 03550 batchs: 859.7454833984375
INFO:root:Train (Epoch 139): Loss/seq after 03600 batchs: 866.2874145507812
INFO:root:Train (Epoch 139): Loss/seq after 03650 batchs: 862.5054931640625
INFO:root:Train (Epoch 139): Loss/seq after 03700 batchs: 864.0986328125
INFO:root:Train (Epoch 139): Loss/seq after 03750 batchs: 867.7223510742188
INFO:root:Train (Epoch 139): Loss/seq after 03800 batchs: 864.594482421875
INFO:root:Train (Epoch 139): Loss/seq after 03850 batchs: 862.9444580078125
INFO:root:Train (Epoch 139): Loss/seq after 03900 batchs: 866.37451171875
INFO:root:Train (Epoch 139): Loss/seq after 03950 batchs: 869.3681030273438
INFO:root:Train (Epoch 139): Loss/seq after 04000 batchs: 864.6436157226562
INFO:root:Train (Epoch 139): Loss/seq after 04050 batchs: 860.6444702148438
INFO:root:Train (Epoch 139): Loss/seq after 04100 batchs: 857.1304321289062
INFO:root:Train (Epoch 139): Loss/seq after 04150 batchs: 854.708984375
INFO:root:Train (Epoch 139): Loss/seq after 04200 batchs: 851.2737426757812
INFO:root:Train (Epoch 139): Loss/seq after 04250 batchs: 849.2421264648438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 139): Loss/seq after 00000 batches: 897.0986938476562
INFO:root:# Valid (Epoch 139): Loss/seq after 00050 batches: 1100.2027587890625
INFO:root:# Valid (Epoch 139): Loss/seq after 00100 batches: 1286.5299072265625
INFO:root:# Valid (Epoch 139): Loss/seq after 00150 batches: 1020.2532958984375
INFO:root:# Valid (Epoch 139): Loss/seq after 00200 batches: 918.1057739257812
INFO:root:Artifacts: Make stick videos for epoch 139
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_139_on_20220423_075719.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_139_index_115_on_20220423_075719.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 140): Loss/seq after 00000 batchs: 1461.236083984375
INFO:root:Train (Epoch 140): Loss/seq after 00050 batchs: 1092.9132080078125
INFO:root:Train (Epoch 140): Loss/seq after 00100 batchs: 1062.8602294921875
INFO:root:Train (Epoch 140): Loss/seq after 00150 batchs: 968.0995483398438
INFO:root:Train (Epoch 140): Loss/seq after 00200 batchs: 1053.2950439453125
INFO:root:Train (Epoch 140): Loss/seq after 00250 batchs: 1172.250244140625
INFO:root:Train (Epoch 140): Loss/seq after 00300 batchs: 1151.864013671875
INFO:root:Train (Epoch 140): Loss/seq after 00350 batchs: 1092.001953125
INFO:root:Train (Epoch 140): Loss/seq after 00400 batchs: 1104.5631103515625
INFO:root:Train (Epoch 140): Loss/seq after 00450 batchs: 1075.1663818359375
INFO:root:Train (Epoch 140): Loss/seq after 00500 batchs: 1053.8150634765625
INFO:root:Train (Epoch 140): Loss/seq after 00550 batchs: 1019.8782958984375
INFO:root:Train (Epoch 140): Loss/seq after 00600 batchs: 995.4998779296875
INFO:root:Train (Epoch 140): Loss/seq after 00650 batchs: 989.8408203125
INFO:root:Train (Epoch 140): Loss/seq after 00700 batchs: 971.52587890625
INFO:root:Train (Epoch 140): Loss/seq after 00750 batchs: 986.0402221679688
INFO:root:Train (Epoch 140): Loss/seq after 00800 batchs: 979.100341796875
INFO:root:Train (Epoch 140): Loss/seq after 00850 batchs: 961.3213500976562
INFO:root:Train (Epoch 140): Loss/seq after 00900 batchs: 969.8807983398438
INFO:root:Train (Epoch 140): Loss/seq after 00950 batchs: 971.6046142578125
INFO:root:Train (Epoch 140): Loss/seq after 01000 batchs: 965.2612915039062
INFO:root:Train (Epoch 140): Loss/seq after 01050 batchs: 954.44580078125
INFO:root:Train (Epoch 140): Loss/seq after 01100 batchs: 946.4449462890625
INFO:root:Train (Epoch 140): Loss/seq after 01150 batchs: 940.463134765625
INFO:root:Train (Epoch 140): Loss/seq after 01200 batchs: 939.9430541992188
INFO:root:Train (Epoch 140): Loss/seq after 01250 batchs: 934.7567749023438
INFO:root:Train (Epoch 140): Loss/seq after 01300 batchs: 919.8995971679688
INFO:root:Train (Epoch 140): Loss/seq after 01350 batchs: 908.7589721679688
INFO:root:Train (Epoch 140): Loss/seq after 01400 batchs: 915.3363647460938
INFO:root:Train (Epoch 140): Loss/seq after 01450 batchs: 915.0704345703125
INFO:root:Train (Epoch 140): Loss/seq after 01500 batchs: 916.908447265625
INFO:root:Train (Epoch 140): Loss/seq after 01550 batchs: 920.52734375
INFO:root:Train (Epoch 140): Loss/seq after 01600 batchs: 913.3547973632812
INFO:root:Train (Epoch 140): Loss/seq after 01650 batchs: 906.691650390625
INFO:root:Train (Epoch 140): Loss/seq after 01700 batchs: 906.31640625
INFO:root:Train (Epoch 140): Loss/seq after 01750 batchs: 903.5642700195312
INFO:root:Train (Epoch 140): Loss/seq after 01800 batchs: 897.9237060546875
INFO:root:Train (Epoch 140): Loss/seq after 01850 batchs: 891.1054077148438
INFO:root:Train (Epoch 140): Loss/seq after 01900 batchs: 891.8726196289062
INFO:root:Train (Epoch 140): Loss/seq after 01950 batchs: 888.7702026367188
INFO:root:Train (Epoch 140): Loss/seq after 02000 batchs: 886.6873168945312
INFO:root:Train (Epoch 140): Loss/seq after 02050 batchs: 883.5862426757812
INFO:root:Train (Epoch 140): Loss/seq after 02100 batchs: 878.3623046875
INFO:root:Train (Epoch 140): Loss/seq after 02150 batchs: 873.561279296875
INFO:root:Train (Epoch 140): Loss/seq after 02200 batchs: 868.2732543945312
INFO:root:Train (Epoch 140): Loss/seq after 02250 batchs: 867.58251953125
INFO:root:Train (Epoch 140): Loss/seq after 02300 batchs: 869.4744262695312
INFO:root:Train (Epoch 140): Loss/seq after 02350 batchs: 863.3817138671875
INFO:root:Train (Epoch 140): Loss/seq after 02400 batchs: 863.6508178710938
INFO:root:Train (Epoch 140): Loss/seq after 02450 batchs: 857.08056640625
INFO:root:Train (Epoch 140): Loss/seq after 02500 batchs: 845.6985473632812
INFO:root:Train (Epoch 140): Loss/seq after 02550 batchs: 838.5776977539062
INFO:root:Train (Epoch 140): Loss/seq after 02600 batchs: 839.7183837890625
INFO:root:Train (Epoch 140): Loss/seq after 02650 batchs: 837.6913452148438
INFO:root:Train (Epoch 140): Loss/seq after 02700 batchs: 835.5662841796875
INFO:root:Train (Epoch 140): Loss/seq after 02750 batchs: 849.8648071289062
INFO:root:Train (Epoch 140): Loss/seq after 02800 batchs: 852.1888427734375
INFO:root:Train (Epoch 140): Loss/seq after 02850 batchs: 850.8206176757812
INFO:root:Train (Epoch 140): Loss/seq after 02900 batchs: 851.2145385742188
INFO:root:Train (Epoch 140): Loss/seq after 02950 batchs: 847.1248779296875
INFO:root:Train (Epoch 140): Loss/seq after 03000 batchs: 850.1544799804688
INFO:root:Train (Epoch 140): Loss/seq after 03050 batchs: 853.1649169921875
INFO:root:Train (Epoch 140): Loss/seq after 03100 batchs: 856.0548095703125
INFO:root:Train (Epoch 140): Loss/seq after 03150 batchs: 859.8401489257812
INFO:root:Train (Epoch 140): Loss/seq after 03200 batchs: 862.137939453125
INFO:root:Train (Epoch 140): Loss/seq after 03250 batchs: 863.3642578125
INFO:root:Train (Epoch 140): Loss/seq after 03300 batchs: 861.2125854492188
INFO:root:Train (Epoch 140): Loss/seq after 03350 batchs: 860.724609375
INFO:root:Train (Epoch 140): Loss/seq after 03400 batchs: 855.7048950195312
INFO:root:Train (Epoch 140): Loss/seq after 03450 batchs: 851.7091674804688
INFO:root:Train (Epoch 140): Loss/seq after 03500 batchs: 850.6097412109375
INFO:root:Train (Epoch 140): Loss/seq after 03550 batchs: 846.4251708984375
INFO:root:Train (Epoch 140): Loss/seq after 03600 batchs: 853.3974609375
INFO:root:Train (Epoch 140): Loss/seq after 03650 batchs: 849.849609375
INFO:root:Train (Epoch 140): Loss/seq after 03700 batchs: 851.5673828125
INFO:root:Train (Epoch 140): Loss/seq after 03750 batchs: 855.4366455078125
INFO:root:Train (Epoch 140): Loss/seq after 03800 batchs: 851.8935546875
INFO:root:Train (Epoch 140): Loss/seq after 03850 batchs: 850.53955078125
INFO:root:Train (Epoch 140): Loss/seq after 03900 batchs: 854.790283203125
INFO:root:Train (Epoch 140): Loss/seq after 03950 batchs: 857.7908325195312
INFO:root:Train (Epoch 140): Loss/seq after 04000 batchs: 853.0831298828125
INFO:root:Train (Epoch 140): Loss/seq after 04050 batchs: 848.7459716796875
INFO:root:Train (Epoch 140): Loss/seq after 04100 batchs: 845.34033203125
INFO:root:Train (Epoch 140): Loss/seq after 04150 batchs: 843.1653442382812
INFO:root:Train (Epoch 140): Loss/seq after 04200 batchs: 839.787109375
INFO:root:Train (Epoch 140): Loss/seq after 04250 batchs: 837.572509765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 140): Loss/seq after 00000 batches: 859.1502685546875
INFO:root:# Valid (Epoch 140): Loss/seq after 00050 batches: 1068.8590087890625
INFO:root:# Valid (Epoch 140): Loss/seq after 00100 batches: 1236.819580078125
INFO:root:# Valid (Epoch 140): Loss/seq after 00150 batches: 970.2443237304688
INFO:root:# Valid (Epoch 140): Loss/seq after 00200 batches: 876.0943603515625
INFO:root:Artifacts: Make stick videos for epoch 140
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_140_on_20220423_080212.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_140_index_1896_on_20220423_080212.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 141): Loss/seq after 00000 batchs: 1394.1666259765625
INFO:root:Train (Epoch 141): Loss/seq after 00050 batchs: 1087.2340087890625
INFO:root:Train (Epoch 141): Loss/seq after 00100 batchs: 1062.2799072265625
INFO:root:Train (Epoch 141): Loss/seq after 00150 batchs: 964.4921264648438
INFO:root:Train (Epoch 141): Loss/seq after 00200 batchs: 1059.2646484375
INFO:root:Train (Epoch 141): Loss/seq after 00250 batchs: 1174.3460693359375
INFO:root:Train (Epoch 141): Loss/seq after 00300 batchs: 1153.4136962890625
INFO:root:Train (Epoch 141): Loss/seq after 00350 batchs: 1090.390625
INFO:root:Train (Epoch 141): Loss/seq after 00400 batchs: 1106.688232421875
INFO:root:Train (Epoch 141): Loss/seq after 00450 batchs: 1076.8397216796875
INFO:root:Train (Epoch 141): Loss/seq after 00500 batchs: 1055.7628173828125
INFO:root:Train (Epoch 141): Loss/seq after 00550 batchs: 1020.3217163085938
INFO:root:Train (Epoch 141): Loss/seq after 00600 batchs: 991.6257934570312
INFO:root:Train (Epoch 141): Loss/seq after 00650 batchs: 984.9171752929688
INFO:root:Train (Epoch 141): Loss/seq after 00700 batchs: 968.5398559570312
INFO:root:Train (Epoch 141): Loss/seq after 00750 batchs: 986.0301513671875
INFO:root:Train (Epoch 141): Loss/seq after 00800 batchs: 979.6810302734375
INFO:root:Train (Epoch 141): Loss/seq after 00850 batchs: 959.7599487304688
INFO:root:Train (Epoch 141): Loss/seq after 00900 batchs: 963.7772216796875
INFO:root:Train (Epoch 141): Loss/seq after 00950 batchs: 966.76416015625
INFO:root:Train (Epoch 141): Loss/seq after 01000 batchs: 961.049560546875
INFO:root:Train (Epoch 141): Loss/seq after 01050 batchs: 949.1699829101562
INFO:root:Train (Epoch 141): Loss/seq after 01100 batchs: 939.6607055664062
INFO:root:Train (Epoch 141): Loss/seq after 01150 batchs: 928.5066528320312
INFO:root:Train (Epoch 141): Loss/seq after 01200 batchs: 930.1515502929688
INFO:root:Train (Epoch 141): Loss/seq after 01250 batchs: 925.5305786132812
INFO:root:Train (Epoch 141): Loss/seq after 01300 batchs: 912.6399536132812
INFO:root:Train (Epoch 141): Loss/seq after 01350 batchs: 898.9891357421875
INFO:root:Train (Epoch 141): Loss/seq after 01400 batchs: 905.938720703125
INFO:root:Train (Epoch 141): Loss/seq after 01450 batchs: 905.9225463867188
INFO:root:Train (Epoch 141): Loss/seq after 01500 batchs: 907.7763671875
INFO:root:Train (Epoch 141): Loss/seq after 01550 batchs: 911.9317626953125
INFO:root:Train (Epoch 141): Loss/seq after 01600 batchs: 904.7218017578125
INFO:root:Train (Epoch 141): Loss/seq after 01650 batchs: 898.0625610351562
INFO:root:Train (Epoch 141): Loss/seq after 01700 batchs: 897.2079467773438
INFO:root:Train (Epoch 141): Loss/seq after 01750 batchs: 894.3251953125
INFO:root:Train (Epoch 141): Loss/seq after 01800 batchs: 888.935302734375
INFO:root:Train (Epoch 141): Loss/seq after 01850 batchs: 881.8026123046875
INFO:root:Train (Epoch 141): Loss/seq after 01900 batchs: 882.7070922851562
INFO:root:Train (Epoch 141): Loss/seq after 01950 batchs: 879.3986206054688
INFO:root:Train (Epoch 141): Loss/seq after 02000 batchs: 877.3899536132812
INFO:root:Train (Epoch 141): Loss/seq after 02050 batchs: 874.4335327148438
INFO:root:Train (Epoch 141): Loss/seq after 02100 batchs: 869.1180419921875
INFO:root:Train (Epoch 141): Loss/seq after 02150 batchs: 864.6820678710938
INFO:root:Train (Epoch 141): Loss/seq after 02200 batchs: 859.5484008789062
INFO:root:Train (Epoch 141): Loss/seq after 02250 batchs: 857.9729614257812
INFO:root:Train (Epoch 141): Loss/seq after 02300 batchs: 860.329833984375
INFO:root:Train (Epoch 141): Loss/seq after 02350 batchs: 854.3930053710938
INFO:root:Train (Epoch 141): Loss/seq after 02400 batchs: 854.4723510742188
INFO:root:Train (Epoch 141): Loss/seq after 02450 batchs: 847.4688110351562
INFO:root:Train (Epoch 141): Loss/seq after 02500 batchs: 836.15625
INFO:root:Train (Epoch 141): Loss/seq after 02550 batchs: 828.5314331054688
INFO:root:Train (Epoch 141): Loss/seq after 02600 batchs: 829.8461303710938
INFO:root:Train (Epoch 141): Loss/seq after 02650 batchs: 828.4505615234375
INFO:root:Train (Epoch 141): Loss/seq after 02700 batchs: 826.7979125976562
INFO:root:Train (Epoch 141): Loss/seq after 02750 batchs: 839.9293212890625
INFO:root:Train (Epoch 141): Loss/seq after 02800 batchs: 843.3143310546875
INFO:root:Train (Epoch 141): Loss/seq after 02850 batchs: 841.4185180664062
INFO:root:Train (Epoch 141): Loss/seq after 02900 batchs: 841.0245971679688
INFO:root:Train (Epoch 141): Loss/seq after 02950 batchs: 837.0458984375
INFO:root:Train (Epoch 141): Loss/seq after 03000 batchs: 840.0206909179688
INFO:root:Train (Epoch 141): Loss/seq after 03050 batchs: 843.3291015625
INFO:root:Train (Epoch 141): Loss/seq after 03100 batchs: 846.2149047851562
INFO:root:Train (Epoch 141): Loss/seq after 03150 batchs: 851.1995849609375
INFO:root:Train (Epoch 141): Loss/seq after 03200 batchs: 854.3997802734375
INFO:root:Train (Epoch 141): Loss/seq after 03250 batchs: 856.4609985351562
INFO:root:Train (Epoch 141): Loss/seq after 03300 batchs: 854.282958984375
INFO:root:Train (Epoch 141): Loss/seq after 03350 batchs: 853.9951171875
INFO:root:Train (Epoch 141): Loss/seq after 03400 batchs: 849.1156005859375
INFO:root:Train (Epoch 141): Loss/seq after 03450 batchs: 844.9010620117188
INFO:root:Train (Epoch 141): Loss/seq after 03500 batchs: 843.4653930664062
INFO:root:Train (Epoch 141): Loss/seq after 03550 batchs: 838.94873046875
INFO:root:Train (Epoch 141): Loss/seq after 03600 batchs: 846.0528564453125
INFO:root:Train (Epoch 141): Loss/seq after 03650 batchs: 842.1818237304688
INFO:root:Train (Epoch 141): Loss/seq after 03700 batchs: 843.6389770507812
INFO:root:Train (Epoch 141): Loss/seq after 03750 batchs: 847.517578125
INFO:root:Train (Epoch 141): Loss/seq after 03800 batchs: 843.9434814453125
INFO:root:Train (Epoch 141): Loss/seq after 03850 batchs: 842.884521484375
INFO:root:Train (Epoch 141): Loss/seq after 03900 batchs: 846.680908203125
INFO:root:Train (Epoch 141): Loss/seq after 03950 batchs: 849.7740478515625
INFO:root:Train (Epoch 141): Loss/seq after 04000 batchs: 845.02978515625
INFO:root:Train (Epoch 141): Loss/seq after 04050 batchs: 840.632568359375
INFO:root:Train (Epoch 141): Loss/seq after 04100 batchs: 837.2862548828125
INFO:root:Train (Epoch 141): Loss/seq after 04150 batchs: 835.1246948242188
INFO:root:Train (Epoch 141): Loss/seq after 04200 batchs: 831.6961669921875
INFO:root:Train (Epoch 141): Loss/seq after 04250 batchs: 829.4109497070312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 141): Loss/seq after 00000 batches: 824.6115112304688
INFO:root:# Valid (Epoch 141): Loss/seq after 00050 batches: 1019.5435180664062
INFO:root:# Valid (Epoch 141): Loss/seq after 00100 batches: 1237.105224609375
INFO:root:# Valid (Epoch 141): Loss/seq after 00150 batches: 958.9153442382812
INFO:root:# Valid (Epoch 141): Loss/seq after 00200 batches: 866.1950073242188
INFO:root:Artifacts: Make stick videos for epoch 141
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_141_on_20220423_080710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_141_index_239_on_20220423_080710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 142): Loss/seq after 00000 batchs: 1367.4468994140625
INFO:root:Train (Epoch 142): Loss/seq after 00050 batchs: 1123.9317626953125
INFO:root:Train (Epoch 142): Loss/seq after 00100 batchs: 1080.9122314453125
INFO:root:Train (Epoch 142): Loss/seq after 00150 batchs: 978.0255737304688
INFO:root:Train (Epoch 142): Loss/seq after 00200 batchs: 1068.47607421875
INFO:root:Train (Epoch 142): Loss/seq after 00250 batchs: 1188.355224609375
INFO:root:Train (Epoch 142): Loss/seq after 00300 batchs: 1163.09033203125
INFO:root:Train (Epoch 142): Loss/seq after 00350 batchs: 1095.366455078125
INFO:root:Train (Epoch 142): Loss/seq after 00400 batchs: 1107.305419921875
INFO:root:Train (Epoch 142): Loss/seq after 00450 batchs: 1075.7344970703125
INFO:root:Train (Epoch 142): Loss/seq after 00500 batchs: 1056.8890380859375
INFO:root:Train (Epoch 142): Loss/seq after 00550 batchs: 1022.35546875
INFO:root:Train (Epoch 142): Loss/seq after 00600 batchs: 992.4989013671875
INFO:root:Train (Epoch 142): Loss/seq after 00650 batchs: 986.6139526367188
INFO:root:Train (Epoch 142): Loss/seq after 00700 batchs: 960.849609375
INFO:root:Train (Epoch 142): Loss/seq after 00750 batchs: 978.5319213867188
INFO:root:Train (Epoch 142): Loss/seq after 00800 batchs: 972.4695434570312
INFO:root:Train (Epoch 142): Loss/seq after 00850 batchs: 951.5728149414062
INFO:root:Train (Epoch 142): Loss/seq after 00900 batchs: 950.2694091796875
INFO:root:Train (Epoch 142): Loss/seq after 00950 batchs: 952.8629150390625
INFO:root:Train (Epoch 142): Loss/seq after 01000 batchs: 946.7578125
INFO:root:Train (Epoch 142): Loss/seq after 01050 batchs: 935.8070678710938
INFO:root:Train (Epoch 142): Loss/seq after 01100 batchs: 927.8369750976562
INFO:root:Train (Epoch 142): Loss/seq after 01150 batchs: 917.081787109375
INFO:root:Train (Epoch 142): Loss/seq after 01200 batchs: 917.2208251953125
INFO:root:Train (Epoch 142): Loss/seq after 01250 batchs: 911.5992431640625
INFO:root:Train (Epoch 142): Loss/seq after 01300 batchs: 897.5167236328125
INFO:root:Train (Epoch 142): Loss/seq after 01350 batchs: 884.5421752929688
INFO:root:Train (Epoch 142): Loss/seq after 01400 batchs: 890.1630859375
INFO:root:Train (Epoch 142): Loss/seq after 01450 batchs: 890.0065307617188
INFO:root:Train (Epoch 142): Loss/seq after 01500 batchs: 891.5346069335938
INFO:root:Train (Epoch 142): Loss/seq after 01550 batchs: 895.9338989257812
INFO:root:Train (Epoch 142): Loss/seq after 01600 batchs: 888.8645629882812
INFO:root:Train (Epoch 142): Loss/seq after 01650 batchs: 882.521484375
INFO:root:Train (Epoch 142): Loss/seq after 01700 batchs: 881.72314453125
INFO:root:Train (Epoch 142): Loss/seq after 01750 batchs: 877.9105834960938
INFO:root:Train (Epoch 142): Loss/seq after 01800 batchs: 872.5147094726562
INFO:root:Train (Epoch 142): Loss/seq after 01850 batchs: 865.5197143554688
INFO:root:Train (Epoch 142): Loss/seq after 01900 batchs: 866.6298217773438
INFO:root:Train (Epoch 142): Loss/seq after 01950 batchs: 863.4176635742188
INFO:root:Train (Epoch 142): Loss/seq after 02000 batchs: 860.9796752929688
INFO:root:Train (Epoch 142): Loss/seq after 02050 batchs: 857.8185424804688
INFO:root:Train (Epoch 142): Loss/seq after 02100 batchs: 852.458740234375
INFO:root:Train (Epoch 142): Loss/seq after 02150 batchs: 847.9456787109375
INFO:root:Train (Epoch 142): Loss/seq after 02200 batchs: 843.1753540039062
INFO:root:Train (Epoch 142): Loss/seq after 02250 batchs: 842.6821899414062
INFO:root:Train (Epoch 142): Loss/seq after 02300 batchs: 844.881591796875
INFO:root:Train (Epoch 142): Loss/seq after 02350 batchs: 838.4835815429688
INFO:root:Train (Epoch 142): Loss/seq after 02400 batchs: 838.3976440429688
INFO:root:Train (Epoch 142): Loss/seq after 02450 batchs: 831.347412109375
INFO:root:Train (Epoch 142): Loss/seq after 02500 batchs: 820.1597900390625
INFO:root:Train (Epoch 142): Loss/seq after 02550 batchs: 812.7161254882812
INFO:root:Train (Epoch 142): Loss/seq after 02600 batchs: 813.68115234375
INFO:root:Train (Epoch 142): Loss/seq after 02650 batchs: 811.82421875
INFO:root:Train (Epoch 142): Loss/seq after 02700 batchs: 809.4935302734375
INFO:root:Train (Epoch 142): Loss/seq after 02750 batchs: 822.726318359375
INFO:root:Train (Epoch 142): Loss/seq after 02800 batchs: 825.3432006835938
INFO:root:Train (Epoch 142): Loss/seq after 02850 batchs: 824.0047607421875
INFO:root:Train (Epoch 142): Loss/seq after 02900 batchs: 823.7398681640625
INFO:root:Train (Epoch 142): Loss/seq after 02950 batchs: 820.0170288085938
INFO:root:Train (Epoch 142): Loss/seq after 03000 batchs: 822.9938354492188
INFO:root:Train (Epoch 142): Loss/seq after 03050 batchs: 827.5730590820312
INFO:root:Train (Epoch 142): Loss/seq after 03100 batchs: 830.7645874023438
INFO:root:Train (Epoch 142): Loss/seq after 03150 batchs: 835.1343994140625
INFO:root:Train (Epoch 142): Loss/seq after 03200 batchs: 836.7481079101562
INFO:root:Train (Epoch 142): Loss/seq after 03250 batchs: 838.6320190429688
INFO:root:Train (Epoch 142): Loss/seq after 03300 batchs: 836.764404296875
INFO:root:Train (Epoch 142): Loss/seq after 03350 batchs: 835.9578857421875
INFO:root:Train (Epoch 142): Loss/seq after 03400 batchs: 830.698486328125
INFO:root:Train (Epoch 142): Loss/seq after 03450 batchs: 826.2579345703125
INFO:root:Train (Epoch 142): Loss/seq after 03500 batchs: 825.0623168945312
INFO:root:Train (Epoch 142): Loss/seq after 03550 batchs: 820.9114990234375
INFO:root:Train (Epoch 142): Loss/seq after 03600 batchs: 828.5889892578125
INFO:root:Train (Epoch 142): Loss/seq after 03650 batchs: 824.9461059570312
INFO:root:Train (Epoch 142): Loss/seq after 03700 batchs: 826.3151245117188
INFO:root:Train (Epoch 142): Loss/seq after 03750 batchs: 830.302490234375
INFO:root:Train (Epoch 142): Loss/seq after 03800 batchs: 826.896728515625
INFO:root:Train (Epoch 142): Loss/seq after 03850 batchs: 825.5794677734375
INFO:root:Train (Epoch 142): Loss/seq after 03900 batchs: 828.8317260742188
INFO:root:Train (Epoch 142): Loss/seq after 03950 batchs: 832.2005004882812
INFO:root:Train (Epoch 142): Loss/seq after 04000 batchs: 827.5263671875
INFO:root:Train (Epoch 142): Loss/seq after 04050 batchs: 823.1069946289062
INFO:root:Train (Epoch 142): Loss/seq after 04100 batchs: 819.9591064453125
INFO:root:Train (Epoch 142): Loss/seq after 04150 batchs: 817.9627075195312
INFO:root:Train (Epoch 142): Loss/seq after 04200 batchs: 814.6710205078125
INFO:root:Train (Epoch 142): Loss/seq after 04250 batchs: 812.501708984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 142): Loss/seq after 00000 batches: 780.984619140625
INFO:root:# Valid (Epoch 142): Loss/seq after 00050 batches: 940.4525756835938
INFO:root:# Valid (Epoch 142): Loss/seq after 00100 batches: 1160.119140625
INFO:root:# Valid (Epoch 142): Loss/seq after 00150 batches: 906.0202026367188
INFO:root:# Valid (Epoch 142): Loss/seq after 00200 batches: 825.194091796875
INFO:root:Artifacts: Make stick videos for epoch 142
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_142_on_20220423_081201.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_142_index_1581_on_20220423_081201.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 143): Loss/seq after 00000 batchs: 1412.6429443359375
INFO:root:Train (Epoch 143): Loss/seq after 00050 batchs: 1070.4176025390625
INFO:root:Train (Epoch 143): Loss/seq after 00100 batchs: 1054.6307373046875
INFO:root:Train (Epoch 143): Loss/seq after 00150 batchs: 954.783203125
INFO:root:Train (Epoch 143): Loss/seq after 00200 batchs: 1051.1497802734375
INFO:root:Train (Epoch 143): Loss/seq after 00250 batchs: 1170.0958251953125
INFO:root:Train (Epoch 143): Loss/seq after 00300 batchs: 1145.8199462890625
INFO:root:Train (Epoch 143): Loss/seq after 00350 batchs: 1076.8067626953125
INFO:root:Train (Epoch 143): Loss/seq after 00400 batchs: 1091.5614013671875
INFO:root:Train (Epoch 143): Loss/seq after 00450 batchs: 1061.2413330078125
INFO:root:Train (Epoch 143): Loss/seq after 00500 batchs: 1039.82763671875
INFO:root:Train (Epoch 143): Loss/seq after 00550 batchs: 1006.1450805664062
INFO:root:Train (Epoch 143): Loss/seq after 00600 batchs: 976.3363647460938
INFO:root:Train (Epoch 143): Loss/seq after 00650 batchs: 970.40869140625
INFO:root:Train (Epoch 143): Loss/seq after 00700 batchs: 946.8294067382812
INFO:root:Train (Epoch 143): Loss/seq after 00750 batchs: 965.6431884765625
INFO:root:Train (Epoch 143): Loss/seq after 00800 batchs: 959.1953735351562
INFO:root:Train (Epoch 143): Loss/seq after 00850 batchs: 937.2078247070312
INFO:root:Train (Epoch 143): Loss/seq after 00900 batchs: 937.134033203125
INFO:root:Train (Epoch 143): Loss/seq after 00950 batchs: 940.275146484375
INFO:root:Train (Epoch 143): Loss/seq after 01000 batchs: 934.7225341796875
INFO:root:Train (Epoch 143): Loss/seq after 01050 batchs: 921.8132934570312
INFO:root:Train (Epoch 143): Loss/seq after 01100 batchs: 913.6331176757812
INFO:root:Train (Epoch 143): Loss/seq after 01150 batchs: 900.503173828125
INFO:root:Train (Epoch 143): Loss/seq after 01200 batchs: 900.8547973632812
INFO:root:Train (Epoch 143): Loss/seq after 01250 batchs: 895.6951293945312
INFO:root:Train (Epoch 143): Loss/seq after 01300 batchs: 881.50048828125
INFO:root:Train (Epoch 143): Loss/seq after 01350 batchs: 869.4189453125
INFO:root:Train (Epoch 143): Loss/seq after 01400 batchs: 876.7589721679688
INFO:root:Train (Epoch 143): Loss/seq after 01450 batchs: 876.2192993164062
INFO:root:Train (Epoch 143): Loss/seq after 01500 batchs: 878.5287475585938
INFO:root:Train (Epoch 143): Loss/seq after 01550 batchs: 882.9402465820312
INFO:root:Train (Epoch 143): Loss/seq after 01600 batchs: 874.8826293945312
INFO:root:Train (Epoch 143): Loss/seq after 01650 batchs: 868.0783081054688
INFO:root:Train (Epoch 143): Loss/seq after 01700 batchs: 867.0863647460938
INFO:root:Train (Epoch 143): Loss/seq after 01750 batchs: 863.3831176757812
INFO:root:Train (Epoch 143): Loss/seq after 01800 batchs: 857.9744262695312
INFO:root:Train (Epoch 143): Loss/seq after 01850 batchs: 851.3936157226562
INFO:root:Train (Epoch 143): Loss/seq after 01900 batchs: 852.347900390625
INFO:root:Train (Epoch 143): Loss/seq after 01950 batchs: 848.9163208007812
INFO:root:Train (Epoch 143): Loss/seq after 02000 batchs: 846.2786865234375
INFO:root:Train (Epoch 143): Loss/seq after 02050 batchs: 843.2664794921875
INFO:root:Train (Epoch 143): Loss/seq after 02100 batchs: 837.9825439453125
INFO:root:Train (Epoch 143): Loss/seq after 02150 batchs: 833.870361328125
INFO:root:Train (Epoch 143): Loss/seq after 02200 batchs: 828.6766967773438
INFO:root:Train (Epoch 143): Loss/seq after 02250 batchs: 828.8187866210938
INFO:root:Train (Epoch 143): Loss/seq after 02300 batchs: 832.2106323242188
INFO:root:Train (Epoch 143): Loss/seq after 02350 batchs: 825.784423828125
INFO:root:Train (Epoch 143): Loss/seq after 02400 batchs: 825.5869140625
INFO:root:Train (Epoch 143): Loss/seq after 02450 batchs: 818.428466796875
INFO:root:Train (Epoch 143): Loss/seq after 02500 batchs: 807.2101440429688
INFO:root:Train (Epoch 143): Loss/seq after 02550 batchs: 799.7527465820312
INFO:root:Train (Epoch 143): Loss/seq after 02600 batchs: 800.2860717773438
INFO:root:Train (Epoch 143): Loss/seq after 02650 batchs: 799.0390625
INFO:root:Train (Epoch 143): Loss/seq after 02700 batchs: 796.4420776367188
INFO:root:Train (Epoch 143): Loss/seq after 02750 batchs: 811.1638793945312
INFO:root:Train (Epoch 143): Loss/seq after 02800 batchs: 812.7407836914062
INFO:root:Train (Epoch 143): Loss/seq after 02850 batchs: 811.675048828125
INFO:root:Train (Epoch 143): Loss/seq after 02900 batchs: 811.7042846679688
INFO:root:Train (Epoch 143): Loss/seq after 02950 batchs: 807.9995727539062
INFO:root:Train (Epoch 143): Loss/seq after 03000 batchs: 810.94873046875
INFO:root:Train (Epoch 143): Loss/seq after 03050 batchs: 814.848876953125
INFO:root:Train (Epoch 143): Loss/seq after 03100 batchs: 818.4263916015625
INFO:root:Train (Epoch 143): Loss/seq after 03150 batchs: 823.5624389648438
INFO:root:Train (Epoch 143): Loss/seq after 03200 batchs: 826.0767211914062
INFO:root:Train (Epoch 143): Loss/seq after 03250 batchs: 828.4849243164062
INFO:root:Train (Epoch 143): Loss/seq after 03300 batchs: 826.4898681640625
INFO:root:Train (Epoch 143): Loss/seq after 03350 batchs: 826.185302734375
INFO:root:Train (Epoch 143): Loss/seq after 03400 batchs: 820.88330078125
INFO:root:Train (Epoch 143): Loss/seq after 03450 batchs: 816.611083984375
INFO:root:Train (Epoch 143): Loss/seq after 03500 batchs: 815.0377807617188
INFO:root:Train (Epoch 143): Loss/seq after 03550 batchs: 810.676025390625
INFO:root:Train (Epoch 143): Loss/seq after 03600 batchs: 817.8609619140625
INFO:root:Train (Epoch 143): Loss/seq after 03650 batchs: 814.2892456054688
INFO:root:Train (Epoch 143): Loss/seq after 03700 batchs: 815.8499145507812
INFO:root:Train (Epoch 143): Loss/seq after 03750 batchs: 819.7566528320312
INFO:root:Train (Epoch 143): Loss/seq after 03800 batchs: 816.3936157226562
INFO:root:Train (Epoch 143): Loss/seq after 03850 batchs: 814.7998046875
INFO:root:Train (Epoch 143): Loss/seq after 03900 batchs: 818.2943725585938
INFO:root:Train (Epoch 143): Loss/seq after 03950 batchs: 821.675537109375
INFO:root:Train (Epoch 143): Loss/seq after 04000 batchs: 816.9918212890625
INFO:root:Train (Epoch 143): Loss/seq after 04050 batchs: 812.4448852539062
INFO:root:Train (Epoch 143): Loss/seq after 04100 batchs: 809.3890380859375
INFO:root:Train (Epoch 143): Loss/seq after 04150 batchs: 807.4358520507812
INFO:root:Train (Epoch 143): Loss/seq after 04200 batchs: 804.229736328125
INFO:root:Train (Epoch 143): Loss/seq after 04250 batchs: 801.9591064453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 143): Loss/seq after 00000 batches: 854.96142578125
INFO:root:# Valid (Epoch 143): Loss/seq after 00050 batches: 923.627685546875
INFO:root:# Valid (Epoch 143): Loss/seq after 00100 batches: 1160.5369873046875
INFO:root:# Valid (Epoch 143): Loss/seq after 00150 batches: 897.2463989257812
INFO:root:# Valid (Epoch 143): Loss/seq after 00200 batches: 813.9022827148438
INFO:root:Artifacts: Make stick videos for epoch 143
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_143_on_20220423_081702.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_143_index_1393_on_20220423_081702.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 144): Loss/seq after 00000 batchs: 1377.5882568359375
INFO:root:Train (Epoch 144): Loss/seq after 00050 batchs: 1038.8184814453125
INFO:root:Train (Epoch 144): Loss/seq after 00100 batchs: 1026.4361572265625
INFO:root:Train (Epoch 144): Loss/seq after 00150 batchs: 926.951171875
INFO:root:Train (Epoch 144): Loss/seq after 00200 batchs: 1019.4680786132812
INFO:root:Train (Epoch 144): Loss/seq after 00250 batchs: 1141.0010986328125
INFO:root:Train (Epoch 144): Loss/seq after 00300 batchs: 1119.6439208984375
INFO:root:Train (Epoch 144): Loss/seq after 00350 batchs: 1054.4488525390625
INFO:root:Train (Epoch 144): Loss/seq after 00400 batchs: 1066.477783203125
INFO:root:Train (Epoch 144): Loss/seq after 00450 batchs: 1037.5234375
INFO:root:Train (Epoch 144): Loss/seq after 00500 batchs: 1017.6798095703125
INFO:root:Train (Epoch 144): Loss/seq after 00550 batchs: 984.0364990234375
INFO:root:Train (Epoch 144): Loss/seq after 00600 batchs: 955.3181762695312
INFO:root:Train (Epoch 144): Loss/seq after 00650 batchs: 952.402099609375
INFO:root:Train (Epoch 144): Loss/seq after 00700 batchs: 929.8908081054688
INFO:root:Train (Epoch 144): Loss/seq after 00750 batchs: 944.4718627929688
INFO:root:Train (Epoch 144): Loss/seq after 00800 batchs: 939.7166748046875
INFO:root:Train (Epoch 144): Loss/seq after 00850 batchs: 918.4198608398438
INFO:root:Train (Epoch 144): Loss/seq after 00900 batchs: 917.6106567382812
INFO:root:Train (Epoch 144): Loss/seq after 00950 batchs: 922.2255859375
INFO:root:Train (Epoch 144): Loss/seq after 01000 batchs: 917.2012329101562
INFO:root:Train (Epoch 144): Loss/seq after 01050 batchs: 903.9236450195312
INFO:root:Train (Epoch 144): Loss/seq after 01100 batchs: 896.1160278320312
INFO:root:Train (Epoch 144): Loss/seq after 01150 batchs: 883.6456909179688
INFO:root:Train (Epoch 144): Loss/seq after 01200 batchs: 884.9464111328125
INFO:root:Train (Epoch 144): Loss/seq after 01250 batchs: 879.1513061523438
INFO:root:Train (Epoch 144): Loss/seq after 01300 batchs: 866.3897094726562
INFO:root:Train (Epoch 144): Loss/seq after 01350 batchs: 854.6284790039062
INFO:root:Train (Epoch 144): Loss/seq after 01400 batchs: 864.1387939453125
INFO:root:Train (Epoch 144): Loss/seq after 01450 batchs: 863.8850708007812
INFO:root:Train (Epoch 144): Loss/seq after 01500 batchs: 865.765625
INFO:root:Train (Epoch 144): Loss/seq after 01550 batchs: 869.5596313476562
INFO:root:Train (Epoch 144): Loss/seq after 01600 batchs: 862.051025390625
INFO:root:Train (Epoch 144): Loss/seq after 01650 batchs: 856.2079467773438
INFO:root:Train (Epoch 144): Loss/seq after 01700 batchs: 855.4742431640625
INFO:root:Train (Epoch 144): Loss/seq after 01750 batchs: 852.0051879882812
INFO:root:Train (Epoch 144): Loss/seq after 01800 batchs: 846.6302490234375
INFO:root:Train (Epoch 144): Loss/seq after 01850 batchs: 839.8834838867188
INFO:root:Train (Epoch 144): Loss/seq after 01900 batchs: 840.9766845703125
INFO:root:Train (Epoch 144): Loss/seq after 01950 batchs: 837.6666259765625
INFO:root:Train (Epoch 144): Loss/seq after 02000 batchs: 834.4378662109375
INFO:root:Train (Epoch 144): Loss/seq after 02050 batchs: 831.7354125976562
INFO:root:Train (Epoch 144): Loss/seq after 02100 batchs: 826.93505859375
INFO:root:Train (Epoch 144): Loss/seq after 02150 batchs: 823.0150756835938
INFO:root:Train (Epoch 144): Loss/seq after 02200 batchs: 817.614501953125
INFO:root:Train (Epoch 144): Loss/seq after 02250 batchs: 817.25634765625
INFO:root:Train (Epoch 144): Loss/seq after 02300 batchs: 821.5491333007812
INFO:root:Train (Epoch 144): Loss/seq after 02350 batchs: 815.4075927734375
INFO:root:Train (Epoch 144): Loss/seq after 02400 batchs: 815.685791015625
INFO:root:Train (Epoch 144): Loss/seq after 02450 batchs: 809.0355224609375
INFO:root:Train (Epoch 144): Loss/seq after 02500 batchs: 798.0671997070312
INFO:root:Train (Epoch 144): Loss/seq after 02550 batchs: 790.857177734375
INFO:root:Train (Epoch 144): Loss/seq after 02600 batchs: 792.4113159179688
INFO:root:Train (Epoch 144): Loss/seq after 02650 batchs: 790.5681762695312
INFO:root:Train (Epoch 144): Loss/seq after 02700 batchs: 788.1953125
INFO:root:Train (Epoch 144): Loss/seq after 02750 batchs: 803.5928955078125
INFO:root:Train (Epoch 144): Loss/seq after 02800 batchs: 806.2699584960938
INFO:root:Train (Epoch 144): Loss/seq after 02850 batchs: 804.714599609375
INFO:root:Train (Epoch 144): Loss/seq after 02900 batchs: 804.7074584960938
INFO:root:Train (Epoch 144): Loss/seq after 02950 batchs: 801.0067138671875
INFO:root:Train (Epoch 144): Loss/seq after 03000 batchs: 804.1446533203125
INFO:root:Train (Epoch 144): Loss/seq after 03050 batchs: 808.0294189453125
INFO:root:Train (Epoch 144): Loss/seq after 03100 batchs: 810.9102783203125
INFO:root:Train (Epoch 144): Loss/seq after 03150 batchs: 815.5056762695312
INFO:root:Train (Epoch 144): Loss/seq after 03200 batchs: 818.8273315429688
INFO:root:Train (Epoch 144): Loss/seq after 03250 batchs: 821.0858764648438
INFO:root:Train (Epoch 144): Loss/seq after 03300 batchs: 819.2967529296875
INFO:root:Train (Epoch 144): Loss/seq after 03350 batchs: 818.9368286132812
INFO:root:Train (Epoch 144): Loss/seq after 03400 batchs: 813.9068603515625
INFO:root:Train (Epoch 144): Loss/seq after 03450 batchs: 809.9140625
INFO:root:Train (Epoch 144): Loss/seq after 03500 batchs: 808.8659057617188
INFO:root:Train (Epoch 144): Loss/seq after 03550 batchs: 804.3935546875
INFO:root:Train (Epoch 144): Loss/seq after 03600 batchs: 812.2157592773438
INFO:root:Train (Epoch 144): Loss/seq after 03650 batchs: 808.550048828125
INFO:root:Train (Epoch 144): Loss/seq after 03700 batchs: 809.967041015625
INFO:root:Train (Epoch 144): Loss/seq after 03750 batchs: 813.772705078125
INFO:root:Train (Epoch 144): Loss/seq after 03800 batchs: 810.3052978515625
INFO:root:Train (Epoch 144): Loss/seq after 03850 batchs: 809.41455078125
INFO:root:Train (Epoch 144): Loss/seq after 03900 batchs: 813.2384033203125
INFO:root:Train (Epoch 144): Loss/seq after 03950 batchs: 816.49609375
INFO:root:Train (Epoch 144): Loss/seq after 04000 batchs: 811.8045654296875
INFO:root:Train (Epoch 144): Loss/seq after 04050 batchs: 807.3892822265625
INFO:root:Train (Epoch 144): Loss/seq after 04100 batchs: 804.2282104492188
INFO:root:Train (Epoch 144): Loss/seq after 04150 batchs: 802.3829956054688
INFO:root:Train (Epoch 144): Loss/seq after 04200 batchs: 799.0460815429688
INFO:root:Train (Epoch 144): Loss/seq after 04250 batchs: 796.9302368164062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 144): Loss/seq after 00000 batches: 750.68408203125
INFO:root:# Valid (Epoch 144): Loss/seq after 00050 batches: 932.3541870117188
INFO:root:# Valid (Epoch 144): Loss/seq after 00100 batches: 1214.835693359375
INFO:root:# Valid (Epoch 144): Loss/seq after 00150 batches: 935.8917846679688
INFO:root:# Valid (Epoch 144): Loss/seq after 00200 batches: 840.0073852539062
INFO:root:Artifacts: Make stick videos for epoch 144
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_144_on_20220423_082154.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_144_index_1335_on_20220423_082154.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 145): Loss/seq after 00000 batchs: 1283.6605224609375
INFO:root:Train (Epoch 145): Loss/seq after 00050 batchs: 1040.098876953125
INFO:root:Train (Epoch 145): Loss/seq after 00100 batchs: 1020.4117431640625
INFO:root:Train (Epoch 145): Loss/seq after 00150 batchs: 924.7218627929688
INFO:root:Train (Epoch 145): Loss/seq after 00200 batchs: 1023.826416015625
INFO:root:Train (Epoch 145): Loss/seq after 00250 batchs: 1144.244873046875
INFO:root:Train (Epoch 145): Loss/seq after 00300 batchs: 1122.4481201171875
INFO:root:Train (Epoch 145): Loss/seq after 00350 batchs: 1053.78173828125
INFO:root:Train (Epoch 145): Loss/seq after 00400 batchs: 1064.1739501953125
INFO:root:Train (Epoch 145): Loss/seq after 00450 batchs: 1034.7479248046875
INFO:root:Train (Epoch 145): Loss/seq after 00500 batchs: 1013.0250244140625
INFO:root:Train (Epoch 145): Loss/seq after 00550 batchs: 980.3129272460938
INFO:root:Train (Epoch 145): Loss/seq after 00600 batchs: 951.5079956054688
INFO:root:Train (Epoch 145): Loss/seq after 00650 batchs: 948.5377197265625
INFO:root:Train (Epoch 145): Loss/seq after 00700 batchs: 928.107666015625
INFO:root:Train (Epoch 145): Loss/seq after 00750 batchs: 943.8989868164062
INFO:root:Train (Epoch 145): Loss/seq after 00800 batchs: 938.1111450195312
INFO:root:Train (Epoch 145): Loss/seq after 00850 batchs: 917.1030883789062
INFO:root:Train (Epoch 145): Loss/seq after 00900 batchs: 911.1536254882812
INFO:root:Train (Epoch 145): Loss/seq after 00950 batchs: 915.6307983398438
INFO:root:Train (Epoch 145): Loss/seq after 01000 batchs: 910.4218139648438
INFO:root:Train (Epoch 145): Loss/seq after 01050 batchs: 897.4874267578125
INFO:root:Train (Epoch 145): Loss/seq after 01100 batchs: 888.4586181640625
INFO:root:Train (Epoch 145): Loss/seq after 01150 batchs: 879.9177856445312
INFO:root:Train (Epoch 145): Loss/seq after 01200 batchs: 880.5808715820312
INFO:root:Train (Epoch 145): Loss/seq after 01250 batchs: 875.9365234375
INFO:root:Train (Epoch 145): Loss/seq after 01300 batchs: 862.6629638671875
INFO:root:Train (Epoch 145): Loss/seq after 01350 batchs: 850.6770629882812
INFO:root:Train (Epoch 145): Loss/seq after 01400 batchs: 856.6590576171875
INFO:root:Train (Epoch 145): Loss/seq after 01450 batchs: 855.5146484375
INFO:root:Train (Epoch 145): Loss/seq after 01500 batchs: 857.55029296875
INFO:root:Train (Epoch 145): Loss/seq after 01550 batchs: 861.7254028320312
INFO:root:Train (Epoch 145): Loss/seq after 01600 batchs: 853.969970703125
INFO:root:Train (Epoch 145): Loss/seq after 01650 batchs: 848.49658203125
INFO:root:Train (Epoch 145): Loss/seq after 01700 batchs: 847.9306030273438
INFO:root:Train (Epoch 145): Loss/seq after 01750 batchs: 844.133056640625
INFO:root:Train (Epoch 145): Loss/seq after 01800 batchs: 839.206787109375
INFO:root:Train (Epoch 145): Loss/seq after 01850 batchs: 832.491943359375
INFO:root:Train (Epoch 145): Loss/seq after 01900 batchs: 833.3264770507812
INFO:root:Train (Epoch 145): Loss/seq after 01950 batchs: 830.5254516601562
INFO:root:Train (Epoch 145): Loss/seq after 02000 batchs: 827.8644409179688
INFO:root:Train (Epoch 145): Loss/seq after 02050 batchs: 824.8038940429688
INFO:root:Train (Epoch 145): Loss/seq after 02100 batchs: 819.8251953125
INFO:root:Train (Epoch 145): Loss/seq after 02150 batchs: 815.6401977539062
INFO:root:Train (Epoch 145): Loss/seq after 02200 batchs: 810.63916015625
INFO:root:Train (Epoch 145): Loss/seq after 02250 batchs: 809.6127319335938
INFO:root:Train (Epoch 145): Loss/seq after 02300 batchs: 812.4862670898438
INFO:root:Train (Epoch 145): Loss/seq after 02350 batchs: 805.9398193359375
INFO:root:Train (Epoch 145): Loss/seq after 02400 batchs: 806.0977172851562
INFO:root:Train (Epoch 145): Loss/seq after 02450 batchs: 799.1583251953125
INFO:root:Train (Epoch 145): Loss/seq after 02500 batchs: 788.671875
INFO:root:Train (Epoch 145): Loss/seq after 02550 batchs: 781.4417114257812
INFO:root:Train (Epoch 145): Loss/seq after 02600 batchs: 781.80126953125
INFO:root:Train (Epoch 145): Loss/seq after 02650 batchs: 780.9293823242188
INFO:root:Train (Epoch 145): Loss/seq after 02700 batchs: 778.462158203125
INFO:root:Train (Epoch 145): Loss/seq after 02750 batchs: 791.4629516601562
INFO:root:Train (Epoch 145): Loss/seq after 02800 batchs: 793.3028564453125
INFO:root:Train (Epoch 145): Loss/seq after 02850 batchs: 791.9495849609375
INFO:root:Train (Epoch 145): Loss/seq after 02900 batchs: 791.8865356445312
INFO:root:Train (Epoch 145): Loss/seq after 02950 batchs: 788.5370483398438
INFO:root:Train (Epoch 145): Loss/seq after 03000 batchs: 791.6614990234375
INFO:root:Train (Epoch 145): Loss/seq after 03050 batchs: 796.2044677734375
INFO:root:Train (Epoch 145): Loss/seq after 03100 batchs: 799.4503784179688
INFO:root:Train (Epoch 145): Loss/seq after 03150 batchs: 804.1036376953125
INFO:root:Train (Epoch 145): Loss/seq after 03200 batchs: 806.0811767578125
INFO:root:Train (Epoch 145): Loss/seq after 03250 batchs: 807.8524169921875
INFO:root:Train (Epoch 145): Loss/seq after 03300 batchs: 805.9662475585938
INFO:root:Train (Epoch 145): Loss/seq after 03350 batchs: 805.7877807617188
INFO:root:Train (Epoch 145): Loss/seq after 03400 batchs: 800.7612915039062
INFO:root:Train (Epoch 145): Loss/seq after 03450 batchs: 796.5925903320312
INFO:root:Train (Epoch 145): Loss/seq after 03500 batchs: 795.3588256835938
INFO:root:Train (Epoch 145): Loss/seq after 03550 batchs: 791.1134033203125
INFO:root:Train (Epoch 145): Loss/seq after 03600 batchs: 799.0169677734375
INFO:root:Train (Epoch 145): Loss/seq after 03650 batchs: 795.52197265625
INFO:root:Train (Epoch 145): Loss/seq after 03700 batchs: 797.1635131835938
INFO:root:Train (Epoch 145): Loss/seq after 03750 batchs: 800.8560791015625
INFO:root:Train (Epoch 145): Loss/seq after 03800 batchs: 797.3466796875
INFO:root:Train (Epoch 145): Loss/seq after 03850 batchs: 796.4130249023438
INFO:root:Train (Epoch 145): Loss/seq after 03900 batchs: 799.9921875
INFO:root:Train (Epoch 145): Loss/seq after 03950 batchs: 803.4041748046875
INFO:root:Train (Epoch 145): Loss/seq after 04000 batchs: 798.9210205078125
INFO:root:Train (Epoch 145): Loss/seq after 04050 batchs: 794.6202392578125
INFO:root:Train (Epoch 145): Loss/seq after 04100 batchs: 791.5067749023438
INFO:root:Train (Epoch 145): Loss/seq after 04150 batchs: 789.7324829101562
INFO:root:Train (Epoch 145): Loss/seq after 04200 batchs: 786.5015258789062
INFO:root:Train (Epoch 145): Loss/seq after 04250 batchs: 784.1305541992188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 145): Loss/seq after 00000 batches: 785.952880859375
INFO:root:# Valid (Epoch 145): Loss/seq after 00050 batches: 904.7789916992188
INFO:root:# Valid (Epoch 145): Loss/seq after 00100 batches: 1130.624755859375
INFO:root:# Valid (Epoch 145): Loss/seq after 00150 batches: 878.879150390625
INFO:root:# Valid (Epoch 145): Loss/seq after 00200 batches: 797.09130859375
INFO:root:Artifacts: Make stick videos for epoch 145
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_145_on_20220423_082652.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_145_index_676_on_20220423_082652.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 146): Loss/seq after 00000 batchs: 1247.5723876953125
INFO:root:Train (Epoch 146): Loss/seq after 00050 batchs: 1028.3883056640625
INFO:root:Train (Epoch 146): Loss/seq after 00100 batchs: 1031.8604736328125
INFO:root:Train (Epoch 146): Loss/seq after 00150 batchs: 924.3754272460938
INFO:root:Train (Epoch 146): Loss/seq after 00200 batchs: 1019.5289916992188
INFO:root:Train (Epoch 146): Loss/seq after 00250 batchs: 1134.949951171875
INFO:root:Train (Epoch 146): Loss/seq after 00300 batchs: 1112.4447021484375
INFO:root:Train (Epoch 146): Loss/seq after 00350 batchs: 1045.0531005859375
INFO:root:Train (Epoch 146): Loss/seq after 00400 batchs: 1055.14453125
INFO:root:Train (Epoch 146): Loss/seq after 00450 batchs: 1026.490966796875
INFO:root:Train (Epoch 146): Loss/seq after 00500 batchs: 1007.491455078125
INFO:root:Train (Epoch 146): Loss/seq after 00550 batchs: 973.5487670898438
INFO:root:Train (Epoch 146): Loss/seq after 00600 batchs: 945.9791870117188
INFO:root:Train (Epoch 146): Loss/seq after 00650 batchs: 944.5214233398438
INFO:root:Train (Epoch 146): Loss/seq after 00700 batchs: 924.1235961914062
INFO:root:Train (Epoch 146): Loss/seq after 00750 batchs: 940.3925170898438
INFO:root:Train (Epoch 146): Loss/seq after 00800 batchs: 934.5780639648438
INFO:root:Train (Epoch 146): Loss/seq after 00850 batchs: 912.5431518554688
INFO:root:Train (Epoch 146): Loss/seq after 00900 batchs: 907.6759643554688
INFO:root:Train (Epoch 146): Loss/seq after 00950 batchs: 915.5726318359375
INFO:root:Train (Epoch 146): Loss/seq after 01000 batchs: 909.3477783203125
INFO:root:Train (Epoch 146): Loss/seq after 01050 batchs: 896.1577758789062
INFO:root:Train (Epoch 146): Loss/seq after 01100 batchs: 884.7423706054688
INFO:root:Train (Epoch 146): Loss/seq after 01150 batchs: 870.75732421875
INFO:root:Train (Epoch 146): Loss/seq after 01200 batchs: 871.873779296875
INFO:root:Train (Epoch 146): Loss/seq after 01250 batchs: 867.5349731445312
INFO:root:Train (Epoch 146): Loss/seq after 01300 batchs: 854.5694580078125
INFO:root:Train (Epoch 146): Loss/seq after 01350 batchs: 841.9586181640625
INFO:root:Train (Epoch 146): Loss/seq after 01400 batchs: 850.6557006835938
INFO:root:Train (Epoch 146): Loss/seq after 01450 batchs: 850.0484008789062
INFO:root:Train (Epoch 146): Loss/seq after 01500 batchs: 852.1903076171875
INFO:root:Train (Epoch 146): Loss/seq after 01550 batchs: 856.119873046875
INFO:root:Train (Epoch 146): Loss/seq after 01600 batchs: 848.8327026367188
INFO:root:Train (Epoch 146): Loss/seq after 01650 batchs: 842.687255859375
INFO:root:Train (Epoch 146): Loss/seq after 01700 batchs: 842.3463745117188
INFO:root:Train (Epoch 146): Loss/seq after 01750 batchs: 838.14208984375
INFO:root:Train (Epoch 146): Loss/seq after 01800 batchs: 832.9957275390625
INFO:root:Train (Epoch 146): Loss/seq after 01850 batchs: 826.3079833984375
INFO:root:Train (Epoch 146): Loss/seq after 01900 batchs: 826.6741333007812
INFO:root:Train (Epoch 146): Loss/seq after 01950 batchs: 824.5189819335938
INFO:root:Train (Epoch 146): Loss/seq after 02000 batchs: 821.6669921875
INFO:root:Train (Epoch 146): Loss/seq after 02050 batchs: 818.3867797851562
INFO:root:Train (Epoch 146): Loss/seq after 02100 batchs: 813.8667602539062
INFO:root:Train (Epoch 146): Loss/seq after 02150 batchs: 809.84326171875
INFO:root:Train (Epoch 146): Loss/seq after 02200 batchs: 804.743896484375
INFO:root:Train (Epoch 146): Loss/seq after 02250 batchs: 803.7446899414062
INFO:root:Train (Epoch 146): Loss/seq after 02300 batchs: 807.57421875
INFO:root:Train (Epoch 146): Loss/seq after 02350 batchs: 801.2960815429688
INFO:root:Train (Epoch 146): Loss/seq after 02400 batchs: 801.3944091796875
INFO:root:Train (Epoch 146): Loss/seq after 02450 batchs: 794.81298828125
INFO:root:Train (Epoch 146): Loss/seq after 02500 batchs: 783.94189453125
INFO:root:Train (Epoch 146): Loss/seq after 02550 batchs: 777.731689453125
INFO:root:Train (Epoch 146): Loss/seq after 02600 batchs: 778.8836669921875
INFO:root:Train (Epoch 146): Loss/seq after 02650 batchs: 777.271240234375
INFO:root:Train (Epoch 146): Loss/seq after 02700 batchs: 774.73876953125
INFO:root:Train (Epoch 146): Loss/seq after 02750 batchs: 787.7313842773438
INFO:root:Train (Epoch 146): Loss/seq after 02800 batchs: 789.7943725585938
INFO:root:Train (Epoch 146): Loss/seq after 02850 batchs: 788.195556640625
INFO:root:Train (Epoch 146): Loss/seq after 02900 batchs: 788.3499145507812
INFO:root:Train (Epoch 146): Loss/seq after 02950 batchs: 784.7427368164062
INFO:root:Train (Epoch 146): Loss/seq after 03000 batchs: 787.9284057617188
INFO:root:Train (Epoch 146): Loss/seq after 03050 batchs: 792.22998046875
INFO:root:Train (Epoch 146): Loss/seq after 03100 batchs: 795.0841674804688
INFO:root:Train (Epoch 146): Loss/seq after 03150 batchs: 799.2525634765625
INFO:root:Train (Epoch 146): Loss/seq after 03200 batchs: 801.8875732421875
INFO:root:Train (Epoch 146): Loss/seq after 03250 batchs: 804.3353271484375
INFO:root:Train (Epoch 146): Loss/seq after 03300 batchs: 802.4442138671875
INFO:root:Train (Epoch 146): Loss/seq after 03350 batchs: 801.7327880859375
INFO:root:Train (Epoch 146): Loss/seq after 03400 batchs: 796.6504516601562
INFO:root:Train (Epoch 146): Loss/seq after 03450 batchs: 792.217529296875
INFO:root:Train (Epoch 146): Loss/seq after 03500 batchs: 790.6937255859375
INFO:root:Train (Epoch 146): Loss/seq after 03550 batchs: 786.5571899414062
INFO:root:Train (Epoch 146): Loss/seq after 03600 batchs: 793.672607421875
INFO:root:Train (Epoch 146): Loss/seq after 03650 batchs: 790.0313720703125
INFO:root:Train (Epoch 146): Loss/seq after 03700 batchs: 791.9695434570312
INFO:root:Train (Epoch 146): Loss/seq after 03750 batchs: 795.833984375
INFO:root:Train (Epoch 146): Loss/seq after 03800 batchs: 792.5468139648438
INFO:root:Train (Epoch 146): Loss/seq after 03850 batchs: 791.4440307617188
INFO:root:Train (Epoch 146): Loss/seq after 03900 batchs: 795.0213012695312
INFO:root:Train (Epoch 146): Loss/seq after 03950 batchs: 798.0501708984375
INFO:root:Train (Epoch 146): Loss/seq after 04000 batchs: 793.4967651367188
INFO:root:Train (Epoch 146): Loss/seq after 04050 batchs: 788.9531860351562
INFO:root:Train (Epoch 146): Loss/seq after 04100 batchs: 785.8338623046875
INFO:root:Train (Epoch 146): Loss/seq after 04150 batchs: 784.04248046875
INFO:root:Train (Epoch 146): Loss/seq after 04200 batchs: 781.09375
INFO:root:Train (Epoch 146): Loss/seq after 04250 batchs: 778.6268310546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 146): Loss/seq after 00000 batches: 741.3338623046875
INFO:root:# Valid (Epoch 146): Loss/seq after 00050 batches: 947.3097534179688
INFO:root:# Valid (Epoch 146): Loss/seq after 00100 batches: 1199.7672119140625
INFO:root:# Valid (Epoch 146): Loss/seq after 00150 batches: 916.679931640625
INFO:root:# Valid (Epoch 146): Loss/seq after 00200 batches: 824.5640869140625
INFO:root:Artifacts: Make stick videos for epoch 146
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_146_on_20220423_083138.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_146_index_1705_on_20220423_083138.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 147): Loss/seq after 00000 batchs: 1368.127197265625
INFO:root:Train (Epoch 147): Loss/seq after 00050 batchs: 1047.998046875
INFO:root:Train (Epoch 147): Loss/seq after 00100 batchs: 1022.5397338867188
INFO:root:Train (Epoch 147): Loss/seq after 00150 batchs: 918.6488037109375
INFO:root:Train (Epoch 147): Loss/seq after 00200 batchs: 1010.9583129882812
INFO:root:Train (Epoch 147): Loss/seq after 00250 batchs: 1125.73388671875
INFO:root:Train (Epoch 147): Loss/seq after 00300 batchs: 1105.1356201171875
INFO:root:Train (Epoch 147): Loss/seq after 00350 batchs: 1039.1748046875
INFO:root:Train (Epoch 147): Loss/seq after 00400 batchs: 1059.818359375
INFO:root:Train (Epoch 147): Loss/seq after 00450 batchs: 1030.6265869140625
INFO:root:Train (Epoch 147): Loss/seq after 00500 batchs: 1009.941650390625
INFO:root:Train (Epoch 147): Loss/seq after 00550 batchs: 976.6663818359375
INFO:root:Train (Epoch 147): Loss/seq after 00600 batchs: 944.5087280273438
INFO:root:Train (Epoch 147): Loss/seq after 00650 batchs: 942.2269287109375
INFO:root:Train (Epoch 147): Loss/seq after 00700 batchs: 922.6641845703125
INFO:root:Train (Epoch 147): Loss/seq after 00750 batchs: 938.0418090820312
INFO:root:Train (Epoch 147): Loss/seq after 00800 batchs: 932.597412109375
INFO:root:Train (Epoch 147): Loss/seq after 00850 batchs: 908.0838012695312
INFO:root:Train (Epoch 147): Loss/seq after 00900 batchs: 899.1832275390625
INFO:root:Train (Epoch 147): Loss/seq after 00950 batchs: 900.3295288085938
INFO:root:Train (Epoch 147): Loss/seq after 01000 batchs: 894.3128662109375
INFO:root:Train (Epoch 147): Loss/seq after 01050 batchs: 882.7427978515625
INFO:root:Train (Epoch 147): Loss/seq after 01100 batchs: 873.4888305664062
INFO:root:Train (Epoch 147): Loss/seq after 01150 batchs: 857.7432250976562
INFO:root:Train (Epoch 147): Loss/seq after 01200 batchs: 859.7952880859375
INFO:root:Train (Epoch 147): Loss/seq after 01250 batchs: 855.4256591796875
INFO:root:Train (Epoch 147): Loss/seq after 01300 batchs: 841.8124389648438
INFO:root:Train (Epoch 147): Loss/seq after 01350 batchs: 829.52392578125
INFO:root:Train (Epoch 147): Loss/seq after 01400 batchs: 838.6041870117188
INFO:root:Train (Epoch 147): Loss/seq after 01450 batchs: 838.4346923828125
INFO:root:Train (Epoch 147): Loss/seq after 01500 batchs: 840.3865356445312
INFO:root:Train (Epoch 147): Loss/seq after 01550 batchs: 844.3218383789062
INFO:root:Train (Epoch 147): Loss/seq after 01600 batchs: 836.2847900390625
INFO:root:Train (Epoch 147): Loss/seq after 01650 batchs: 830.5036010742188
INFO:root:Train (Epoch 147): Loss/seq after 01700 batchs: 830.1016845703125
INFO:root:Train (Epoch 147): Loss/seq after 01750 batchs: 826.0394897460938
INFO:root:Train (Epoch 147): Loss/seq after 01800 batchs: 821.1810302734375
INFO:root:Train (Epoch 147): Loss/seq after 01850 batchs: 814.795654296875
INFO:root:Train (Epoch 147): Loss/seq after 01900 batchs: 815.6972045898438
INFO:root:Train (Epoch 147): Loss/seq after 01950 batchs: 812.3671264648438
INFO:root:Train (Epoch 147): Loss/seq after 02000 batchs: 809.7960815429688
INFO:root:Train (Epoch 147): Loss/seq after 02050 batchs: 806.6309204101562
INFO:root:Train (Epoch 147): Loss/seq after 02100 batchs: 801.80859375
INFO:root:Train (Epoch 147): Loss/seq after 02150 batchs: 798.1729736328125
INFO:root:Train (Epoch 147): Loss/seq after 02200 batchs: 793.2769775390625
INFO:root:Train (Epoch 147): Loss/seq after 02250 batchs: 792.5336303710938
INFO:root:Train (Epoch 147): Loss/seq after 02300 batchs: 795.4425659179688
INFO:root:Train (Epoch 147): Loss/seq after 02350 batchs: 789.15283203125
INFO:root:Train (Epoch 147): Loss/seq after 02400 batchs: 788.37451171875
INFO:root:Train (Epoch 147): Loss/seq after 02450 batchs: 781.9205322265625
INFO:root:Train (Epoch 147): Loss/seq after 02500 batchs: 771.2794189453125
INFO:root:Train (Epoch 147): Loss/seq after 02550 batchs: 764.1842041015625
INFO:root:Train (Epoch 147): Loss/seq after 02600 batchs: 765.0536499023438
INFO:root:Train (Epoch 147): Loss/seq after 02650 batchs: 763.1218872070312
INFO:root:Train (Epoch 147): Loss/seq after 02700 batchs: 760.9561767578125
INFO:root:Train (Epoch 147): Loss/seq after 02750 batchs: 773.165771484375
INFO:root:Train (Epoch 147): Loss/seq after 02800 batchs: 775.1156005859375
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 147): Loss/seq after 02850 batchs: 773.3184814453125
INFO:root:Train (Epoch 147): Loss/seq after 02900 batchs: 773.3789672851562
INFO:root:Train (Epoch 147): Loss/seq after 02950 batchs: 770.0608520507812
INFO:root:Train (Epoch 147): Loss/seq after 03000 batchs: 773.4417724609375
INFO:root:Train (Epoch 147): Loss/seq after 03050 batchs: 778.5484619140625
INFO:root:Train (Epoch 147): Loss/seq after 03100 batchs: 782.1500854492188
INFO:root:Train (Epoch 147): Loss/seq after 03150 batchs: 786.7079467773438
INFO:root:Train (Epoch 147): Loss/seq after 03200 batchs: 790.6695556640625
INFO:root:Train (Epoch 147): Loss/seq after 03250 batchs: 793.8728637695312
INFO:root:Train (Epoch 147): Loss/seq after 03300 batchs: 792.2955932617188
INFO:root:Train (Epoch 147): Loss/seq after 03350 batchs: 792.4940795898438
INFO:root:Train (Epoch 147): Loss/seq after 03400 batchs: 786.787353515625
INFO:root:Train (Epoch 147): Loss/seq after 03450 batchs: 783.0471801757812
INFO:root:Train (Epoch 147): Loss/seq after 03500 batchs: 782.2886962890625
INFO:root:Train (Epoch 147): Loss/seq after 03550 batchs: 778.064453125
INFO:root:Train (Epoch 147): Loss/seq after 03600 batchs: 785.9035034179688
INFO:root:Train (Epoch 147): Loss/seq after 03650 batchs: 782.152099609375
INFO:root:Train (Epoch 147): Loss/seq after 03700 batchs: 783.3616333007812
INFO:root:Train (Epoch 147): Loss/seq after 03750 batchs: 786.9683227539062
INFO:root:Train (Epoch 147): Loss/seq after 03800 batchs: 783.464599609375
INFO:root:Train (Epoch 147): Loss/seq after 03850 batchs: 782.505126953125
INFO:root:Train (Epoch 147): Loss/seq after 03900 batchs: 786.1998291015625
INFO:root:Train (Epoch 147): Loss/seq after 03950 batchs: 789.2730102539062
INFO:root:Train (Epoch 147): Loss/seq after 04000 batchs: 784.7774658203125
INFO:root:Train (Epoch 147): Loss/seq after 04050 batchs: 780.0703125
INFO:root:Train (Epoch 147): Loss/seq after 04100 batchs: 777.18408203125
INFO:root:Train (Epoch 147): Loss/seq after 04150 batchs: 775.5297241210938
INFO:root:Train (Epoch 147): Loss/seq after 04200 batchs: 772.3883056640625
INFO:root:Train (Epoch 147): Loss/seq after 04250 batchs: 769.8152465820312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 147): Loss/seq after 00000 batches: 777.6594848632812
INFO:root:# Valid (Epoch 147): Loss/seq after 00050 batches: 913.7984619140625
INFO:root:# Valid (Epoch 147): Loss/seq after 00100 batches: 1197.2069091796875
INFO:root:# Valid (Epoch 147): Loss/seq after 00150 batches: 901.15673828125
INFO:root:# Valid (Epoch 147): Loss/seq after 00200 batches: 813.143798828125
INFO:root:Artifacts: Make stick videos for epoch 147
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_147_on_20220423_083625.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_147_index_630_on_20220423_083625.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 148): Loss/seq after 00000 batchs: 1411.6932373046875
INFO:root:Train (Epoch 148): Loss/seq after 00050 batchs: 1049.502197265625
INFO:root:Train (Epoch 148): Loss/seq after 00100 batchs: 1029.968017578125
INFO:root:Train (Epoch 148): Loss/seq after 00150 batchs: 919.0909423828125
INFO:root:Train (Epoch 148): Loss/seq after 00200 batchs: 1006.73388671875
INFO:root:Train (Epoch 148): Loss/seq after 00250 batchs: 1127.198486328125
INFO:root:Train (Epoch 148): Loss/seq after 00300 batchs: 1103.0228271484375
INFO:root:Train (Epoch 148): Loss/seq after 00350 batchs: 1033.3133544921875
INFO:root:Train (Epoch 148): Loss/seq after 00400 batchs: 1044.40380859375
INFO:root:Train (Epoch 148): Loss/seq after 00450 batchs: 1015.4717407226562
INFO:root:Train (Epoch 148): Loss/seq after 00500 batchs: 993.6126098632812
INFO:root:Train (Epoch 148): Loss/seq after 00550 batchs: 960.9757080078125
INFO:root:Train (Epoch 148): Loss/seq after 00600 batchs: 929.7410278320312
INFO:root:Train (Epoch 148): Loss/seq after 00650 batchs: 926.4445190429688
INFO:root:Train (Epoch 148): Loss/seq after 00700 batchs: 905.357666015625
INFO:root:Train (Epoch 148): Loss/seq after 00750 batchs: 918.568603515625
INFO:root:Train (Epoch 148): Loss/seq after 00800 batchs: 913.3225708007812
INFO:root:Train (Epoch 148): Loss/seq after 00850 batchs: 891.1326293945312
INFO:root:Train (Epoch 148): Loss/seq after 00900 batchs: 878.3338012695312
INFO:root:Train (Epoch 148): Loss/seq after 00950 batchs: 886.15234375
INFO:root:Train (Epoch 148): Loss/seq after 01000 batchs: 881.6085205078125
INFO:root:Train (Epoch 148): Loss/seq after 01050 batchs: 871.798095703125
INFO:root:Train (Epoch 148): Loss/seq after 01100 batchs: 861.9773559570312
INFO:root:Train (Epoch 148): Loss/seq after 01150 batchs: 847.779052734375
INFO:root:Train (Epoch 148): Loss/seq after 01200 batchs: 848.2987060546875
INFO:root:Train (Epoch 148): Loss/seq after 01250 batchs: 843.7597045898438
INFO:root:Train (Epoch 148): Loss/seq after 01300 batchs: 831.7814331054688
INFO:root:Train (Epoch 148): Loss/seq after 01350 batchs: 820.2671508789062
INFO:root:Train (Epoch 148): Loss/seq after 01400 batchs: 828.3432006835938
INFO:root:Train (Epoch 148): Loss/seq after 01450 batchs: 827.4266967773438
INFO:root:Train (Epoch 148): Loss/seq after 01500 batchs: 829.9686279296875
INFO:root:Train (Epoch 148): Loss/seq after 01550 batchs: 833.182861328125
INFO:root:Train (Epoch 148): Loss/seq after 01600 batchs: 825.9493408203125
INFO:root:Train (Epoch 148): Loss/seq after 01650 batchs: 820.762939453125
INFO:root:Train (Epoch 148): Loss/seq after 01700 batchs: 820.3644409179688
INFO:root:Train (Epoch 148): Loss/seq after 01750 batchs: 816.62451171875
INFO:root:Train (Epoch 148): Loss/seq after 01800 batchs: 811.5645141601562
INFO:root:Train (Epoch 148): Loss/seq after 01850 batchs: 805.0474243164062
INFO:root:Train (Epoch 148): Loss/seq after 01900 batchs: 806.2428588867188
INFO:root:Train (Epoch 148): Loss/seq after 01950 batchs: 802.824462890625
INFO:root:Train (Epoch 148): Loss/seq after 02000 batchs: 800.3162841796875
INFO:root:Train (Epoch 148): Loss/seq after 02050 batchs: 797.2243041992188
INFO:root:Train (Epoch 148): Loss/seq after 02100 batchs: 792.1438598632812
INFO:root:Train (Epoch 148): Loss/seq after 02150 batchs: 788.5990600585938
INFO:root:Train (Epoch 148): Loss/seq after 02200 batchs: 783.5211791992188
INFO:root:Train (Epoch 148): Loss/seq after 02250 batchs: 783.0577392578125
INFO:root:Train (Epoch 148): Loss/seq after 02300 batchs: 784.5205078125
INFO:root:Train (Epoch 148): Loss/seq after 02350 batchs: 778.2693481445312
INFO:root:Train (Epoch 148): Loss/seq after 02400 batchs: 777.9517822265625
INFO:root:Train (Epoch 148): Loss/seq after 02450 batchs: 771.441162109375
INFO:root:Train (Epoch 148): Loss/seq after 02500 batchs: 760.5305786132812
INFO:root:Train (Epoch 148): Loss/seq after 02550 batchs: 753.5748901367188
INFO:root:Train (Epoch 148): Loss/seq after 02600 batchs: 754.1271362304688
INFO:root:Train (Epoch 148): Loss/seq after 02650 batchs: 751.9959716796875
INFO:root:Train (Epoch 148): Loss/seq after 02700 batchs: 749.3444213867188
INFO:root:Train (Epoch 148): Loss/seq after 02750 batchs: 764.9205322265625
INFO:root:Train (Epoch 148): Loss/seq after 02800 batchs: 766.8934936523438
INFO:root:Train (Epoch 148): Loss/seq after 02850 batchs: 765.4791259765625
INFO:root:Train (Epoch 148): Loss/seq after 02900 batchs: 765.5421752929688
INFO:root:Train (Epoch 148): Loss/seq after 02950 batchs: 762.0765991210938
INFO:root:Train (Epoch 148): Loss/seq after 03000 batchs: 765.3734130859375
INFO:root:Train (Epoch 148): Loss/seq after 03050 batchs: 770.2333374023438
INFO:root:Train (Epoch 148): Loss/seq after 03100 batchs: 773.8807983398438
INFO:root:Train (Epoch 148): Loss/seq after 03150 batchs: 778.89306640625
INFO:root:Train (Epoch 148): Loss/seq after 03200 batchs: 782.1083984375
INFO:root:Train (Epoch 148): Loss/seq after 03250 batchs: 783.8941650390625
INFO:root:Train (Epoch 148): Loss/seq after 03300 batchs: 782.2048950195312
INFO:root:Train (Epoch 148): Loss/seq after 03350 batchs: 781.629150390625
INFO:root:Train (Epoch 148): Loss/seq after 03400 batchs: 776.109130859375
INFO:root:Train (Epoch 148): Loss/seq after 03450 batchs: 772.3082275390625
INFO:root:Train (Epoch 148): Loss/seq after 03500 batchs: 771.008056640625
INFO:root:Train (Epoch 148): Loss/seq after 03550 batchs: 767.0826416015625
INFO:root:Train (Epoch 148): Loss/seq after 03600 batchs: 774.5386962890625
INFO:root:Train (Epoch 148): Loss/seq after 03650 batchs: 770.9063720703125
INFO:root:Train (Epoch 148): Loss/seq after 03700 batchs: 772.634521484375
INFO:root:Train (Epoch 148): Loss/seq after 03750 batchs: 776.4539794921875
INFO:root:Train (Epoch 148): Loss/seq after 03800 batchs: 772.643310546875
INFO:root:Train (Epoch 148): Loss/seq after 03850 batchs: 771.8161010742188
INFO:root:Train (Epoch 148): Loss/seq after 03900 batchs: 776.4866333007812
INFO:root:Train (Epoch 148): Loss/seq after 03950 batchs: 779.6043090820312
INFO:root:Train (Epoch 148): Loss/seq after 04000 batchs: 775.0525512695312
INFO:root:Train (Epoch 148): Loss/seq after 04050 batchs: 770.2171630859375
INFO:root:Train (Epoch 148): Loss/seq after 04100 batchs: 767.1953735351562
INFO:root:Train (Epoch 148): Loss/seq after 04150 batchs: 765.7269287109375
INFO:root:Train (Epoch 148): Loss/seq after 04200 batchs: 762.5540771484375
INFO:root:Train (Epoch 148): Loss/seq after 04250 batchs: 759.8191528320312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 148): Loss/seq after 00000 batches: 818.3214111328125
INFO:root:# Valid (Epoch 148): Loss/seq after 00050 batches: 891.6630249023438
INFO:root:# Valid (Epoch 148): Loss/seq after 00100 batches: 1154.7364501953125
INFO:root:# Valid (Epoch 148): Loss/seq after 00150 batches: 874.6182861328125
INFO:root:# Valid (Epoch 148): Loss/seq after 00200 batches: 784.8112182617188
INFO:root:Artifacts: Make stick videos for epoch 148
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_148_on_20220423_084134.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_148_index_1432_on_20220423_084134.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 149): Loss/seq after 00000 batchs: 1413.4476318359375
INFO:root:Train (Epoch 149): Loss/seq after 00050 batchs: 1023.3306274414062
INFO:root:Train (Epoch 149): Loss/seq after 00100 batchs: 1007.2194213867188
INFO:root:Train (Epoch 149): Loss/seq after 00150 batchs: 908.3486328125
INFO:root:Train (Epoch 149): Loss/seq after 00200 batchs: 1028.421142578125
INFO:root:Train (Epoch 149): Loss/seq after 00250 batchs: 1138.9459228515625
INFO:root:Train (Epoch 149): Loss/seq after 00300 batchs: 1114.271728515625
INFO:root:Train (Epoch 149): Loss/seq after 00350 batchs: 1041.9627685546875
INFO:root:Train (Epoch 149): Loss/seq after 00400 batchs: 1052.038818359375
INFO:root:Train (Epoch 149): Loss/seq after 00450 batchs: 1020.3920288085938
INFO:root:Train (Epoch 149): Loss/seq after 00500 batchs: 998.9840087890625
INFO:root:Train (Epoch 149): Loss/seq after 00550 batchs: 965.4381713867188
INFO:root:Train (Epoch 149): Loss/seq after 00600 batchs: 933.9332275390625
INFO:root:Train (Epoch 149): Loss/seq after 00650 batchs: 931.4830932617188
INFO:root:Train (Epoch 149): Loss/seq after 00700 batchs: 910.545654296875
INFO:root:Train (Epoch 149): Loss/seq after 00750 batchs: 924.4918823242188
INFO:root:Train (Epoch 149): Loss/seq after 00800 batchs: 918.7230834960938
INFO:root:Train (Epoch 149): Loss/seq after 00850 batchs: 894.5384521484375
INFO:root:Train (Epoch 149): Loss/seq after 00900 batchs: 879.2515258789062
INFO:root:Train (Epoch 149): Loss/seq after 00950 batchs: 882.545654296875
INFO:root:Train (Epoch 149): Loss/seq after 01000 batchs: 876.7210083007812
INFO:root:Train (Epoch 149): Loss/seq after 01050 batchs: 864.808349609375
INFO:root:Train (Epoch 149): Loss/seq after 01100 batchs: 852.5525512695312
INFO:root:Train (Epoch 149): Loss/seq after 01150 batchs: 836.882568359375
INFO:root:Train (Epoch 149): Loss/seq after 01200 batchs: 838.0869750976562
INFO:root:Train (Epoch 149): Loss/seq after 01250 batchs: 833.7522583007812
INFO:root:Train (Epoch 149): Loss/seq after 01300 batchs: 820.72021484375
INFO:root:Train (Epoch 149): Loss/seq after 01350 batchs: 807.97607421875
INFO:root:Train (Epoch 149): Loss/seq after 01400 batchs: 816.1343383789062
INFO:root:Train (Epoch 149): Loss/seq after 01450 batchs: 814.960693359375
INFO:root:Train (Epoch 149): Loss/seq after 01500 batchs: 817.802734375
INFO:root:Train (Epoch 149): Loss/seq after 01550 batchs: 821.3204345703125
INFO:root:Train (Epoch 149): Loss/seq after 01600 batchs: 814.390625
INFO:root:Train (Epoch 149): Loss/seq after 01650 batchs: 809.7772216796875
INFO:root:Train (Epoch 149): Loss/seq after 01700 batchs: 808.9887084960938
INFO:root:Train (Epoch 149): Loss/seq after 01750 batchs: 805.1185302734375
INFO:root:Train (Epoch 149): Loss/seq after 01800 batchs: 799.8026733398438
INFO:root:Train (Epoch 149): Loss/seq after 01850 batchs: 793.5059814453125
INFO:root:Train (Epoch 149): Loss/seq after 01900 batchs: 794.1324462890625
INFO:root:Train (Epoch 149): Loss/seq after 01950 batchs: 791.0452270507812
INFO:root:Train (Epoch 149): Loss/seq after 02000 batchs: 788.2278442382812
INFO:root:Train (Epoch 149): Loss/seq after 02050 batchs: 785.4049682617188
INFO:root:Train (Epoch 149): Loss/seq after 02100 batchs: 780.9288330078125
INFO:root:Train (Epoch 149): Loss/seq after 02150 batchs: 777.2129516601562
INFO:root:Train (Epoch 149): Loss/seq after 02200 batchs: 772.4338989257812
INFO:root:Train (Epoch 149): Loss/seq after 02250 batchs: 772.8992309570312
INFO:root:Train (Epoch 149): Loss/seq after 02300 batchs: 775.1851806640625
INFO:root:Train (Epoch 149): Loss/seq after 02350 batchs: 769.056640625
INFO:root:Train (Epoch 149): Loss/seq after 02400 batchs: 768.3936767578125
INFO:root:Train (Epoch 149): Loss/seq after 02450 batchs: 761.93115234375
INFO:root:Train (Epoch 149): Loss/seq after 02500 batchs: 750.818359375
INFO:root:Train (Epoch 149): Loss/seq after 02550 batchs: 744.2908325195312
INFO:root:Train (Epoch 149): Loss/seq after 02600 batchs: 745.588134765625
INFO:root:Train (Epoch 149): Loss/seq after 02650 batchs: 743.39453125
INFO:root:Train (Epoch 149): Loss/seq after 02700 batchs: 741.8615112304688
INFO:root:Train (Epoch 149): Loss/seq after 02750 batchs: 756.5989379882812
INFO:root:Train (Epoch 149): Loss/seq after 02800 batchs: 759.5144653320312
INFO:root:Train (Epoch 149): Loss/seq after 02850 batchs: 758.3576049804688
INFO:root:Train (Epoch 149): Loss/seq after 02900 batchs: 758.7825317382812
INFO:root:Train (Epoch 149): Loss/seq after 02950 batchs: 755.4956665039062
INFO:root:Train (Epoch 149): Loss/seq after 03000 batchs: 758.8233032226562
INFO:root:Train (Epoch 149): Loss/seq after 03050 batchs: 764.018798828125
INFO:root:Train (Epoch 149): Loss/seq after 03100 batchs: 766.59912109375
INFO:root:Train (Epoch 149): Loss/seq after 03150 batchs: 772.1896362304688
INFO:root:Train (Epoch 149): Loss/seq after 03200 batchs: 775.9740600585938
INFO:root:Train (Epoch 149): Loss/seq after 03250 batchs: 778.5550537109375
INFO:root:Train (Epoch 149): Loss/seq after 03300 batchs: 776.884765625
INFO:root:Train (Epoch 149): Loss/seq after 03350 batchs: 776.6455078125
INFO:root:Train (Epoch 149): Loss/seq after 03400 batchs: 770.4856567382812
INFO:root:Train (Epoch 149): Loss/seq after 03450 batchs: 766.7120971679688
INFO:root:Train (Epoch 149): Loss/seq after 03500 batchs: 766.4923706054688
INFO:root:Train (Epoch 149): Loss/seq after 03550 batchs: 762.5707397460938
INFO:root:Train (Epoch 149): Loss/seq after 03600 batchs: 770.3269653320312
INFO:root:Train (Epoch 149): Loss/seq after 03650 batchs: 766.5929565429688
INFO:root:Train (Epoch 149): Loss/seq after 03700 batchs: 768.0357666015625
INFO:root:Train (Epoch 149): Loss/seq after 03750 batchs: 772.048583984375
INFO:root:Train (Epoch 149): Loss/seq after 03800 batchs: 768.0198974609375
INFO:root:Train (Epoch 149): Loss/seq after 03850 batchs: 766.967041015625
INFO:root:Train (Epoch 149): Loss/seq after 03900 batchs: 770.9190063476562
INFO:root:Train (Epoch 149): Loss/seq after 03950 batchs: 774.1427612304688
INFO:root:Train (Epoch 149): Loss/seq after 04000 batchs: 769.657470703125
INFO:root:Train (Epoch 149): Loss/seq after 04050 batchs: 764.454833984375
INFO:root:Train (Epoch 149): Loss/seq after 04100 batchs: 761.4013061523438
INFO:root:Train (Epoch 149): Loss/seq after 04150 batchs: 759.8909912109375
INFO:root:Train (Epoch 149): Loss/seq after 04200 batchs: 756.7745971679688
INFO:root:Train (Epoch 149): Loss/seq after 04250 batchs: 754.3225708007812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 149): Loss/seq after 00000 batches: 553.6914672851562
INFO:root:# Valid (Epoch 149): Loss/seq after 00050 batches: 871.6134643554688
INFO:root:# Valid (Epoch 149): Loss/seq after 00100 batches: 1104.91357421875
INFO:root:# Valid (Epoch 149): Loss/seq after 00150 batches: 831.620849609375
INFO:root:# Valid (Epoch 149): Loss/seq after 00200 batches: 748.6969604492188
INFO:root:Artifacts: Make stick videos for epoch 149
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_149_on_20220423_084618.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_149_index_1529_on_20220423_084618.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 150): Loss/seq after 00000 batchs: 1303.1539306640625
INFO:root:Train (Epoch 150): Loss/seq after 00050 batchs: 1012.9091796875
INFO:root:Train (Epoch 150): Loss/seq after 00100 batchs: 995.3863525390625
INFO:root:Train (Epoch 150): Loss/seq after 00150 batchs: 896.8507080078125
INFO:root:Train (Epoch 150): Loss/seq after 00200 batchs: 997.4389038085938
INFO:root:Train (Epoch 150): Loss/seq after 00250 batchs: 1116.522216796875
INFO:root:Train (Epoch 150): Loss/seq after 00300 batchs: 1093.484375
INFO:root:Train (Epoch 150): Loss/seq after 00350 batchs: 1024.5565185546875
INFO:root:Train (Epoch 150): Loss/seq after 00400 batchs: 1032.67822265625
INFO:root:Train (Epoch 150): Loss/seq after 00450 batchs: 1003.420654296875
INFO:root:Train (Epoch 150): Loss/seq after 00500 batchs: 982.4529418945312
INFO:root:Train (Epoch 150): Loss/seq after 00550 batchs: 950.2051391601562
INFO:root:Train (Epoch 150): Loss/seq after 00600 batchs: 917.8827514648438
INFO:root:Train (Epoch 150): Loss/seq after 00650 batchs: 916.5584716796875
INFO:root:Train (Epoch 150): Loss/seq after 00700 batchs: 896.473388671875
INFO:root:Train (Epoch 150): Loss/seq after 00750 batchs: 911.6624755859375
INFO:root:Train (Epoch 150): Loss/seq after 00800 batchs: 905.2108764648438
INFO:root:Train (Epoch 150): Loss/seq after 00850 batchs: 880.1343383789062
INFO:root:Train (Epoch 150): Loss/seq after 00900 batchs: 868.9871215820312
INFO:root:Train (Epoch 150): Loss/seq after 00950 batchs: 870.5521850585938
INFO:root:Train (Epoch 150): Loss/seq after 01000 batchs: 864.2437133789062
INFO:root:Train (Epoch 150): Loss/seq after 01050 batchs: 851.800537109375
INFO:root:Train (Epoch 150): Loss/seq after 01100 batchs: 839.5736083984375
INFO:root:Train (Epoch 150): Loss/seq after 01150 batchs: 821.4122314453125
INFO:root:Train (Epoch 150): Loss/seq after 01200 batchs: 823.3402099609375
INFO:root:Train (Epoch 150): Loss/seq after 01250 batchs: 819.6868896484375
INFO:root:Train (Epoch 150): Loss/seq after 01300 batchs: 808.1051025390625
INFO:root:Train (Epoch 150): Loss/seq after 01350 batchs: 798.1311645507812
INFO:root:Train (Epoch 150): Loss/seq after 01400 batchs: 806.1962890625
INFO:root:Train (Epoch 150): Loss/seq after 01450 batchs: 805.4448852539062
INFO:root:Train (Epoch 150): Loss/seq after 01500 batchs: 807.9715576171875
INFO:root:Train (Epoch 150): Loss/seq after 01550 batchs: 811.0850830078125
INFO:root:Train (Epoch 150): Loss/seq after 01600 batchs: 803.4834594726562
INFO:root:Train (Epoch 150): Loss/seq after 01650 batchs: 798.7988891601562
INFO:root:Train (Epoch 150): Loss/seq after 01700 batchs: 798.1802368164062
INFO:root:Train (Epoch 150): Loss/seq after 01750 batchs: 794.1896362304688
INFO:root:Train (Epoch 150): Loss/seq after 01800 batchs: 789.44384765625
INFO:root:Train (Epoch 150): Loss/seq after 01850 batchs: 782.8245239257812
INFO:root:Train (Epoch 150): Loss/seq after 01900 batchs: 783.4542236328125
INFO:root:Train (Epoch 150): Loss/seq after 01950 batchs: 780.066650390625
INFO:root:Train (Epoch 150): Loss/seq after 02000 batchs: 777.4022216796875
INFO:root:Train (Epoch 150): Loss/seq after 02050 batchs: 774.3634643554688
INFO:root:Train (Epoch 150): Loss/seq after 02100 batchs: 769.96142578125
INFO:root:Train (Epoch 150): Loss/seq after 02150 batchs: 766.4849243164062
INFO:root:Train (Epoch 150): Loss/seq after 02200 batchs: 761.724609375
INFO:root:Train (Epoch 150): Loss/seq after 02250 batchs: 761.1082763671875
INFO:root:Train (Epoch 150): Loss/seq after 02300 batchs: 764.5394897460938
INFO:root:Train (Epoch 150): Loss/seq after 02350 batchs: 757.896484375
INFO:root:Train (Epoch 150): Loss/seq after 02400 batchs: 757.3113403320312
INFO:root:Train (Epoch 150): Loss/seq after 02450 batchs: 750.96240234375
INFO:root:Train (Epoch 150): Loss/seq after 02500 batchs: 740.1244506835938
INFO:root:Train (Epoch 150): Loss/seq after 02550 batchs: 732.939453125
INFO:root:Train (Epoch 150): Loss/seq after 02600 batchs: 733.4851684570312
INFO:root:Train (Epoch 150): Loss/seq after 02650 batchs: 731.75537109375
INFO:root:Train (Epoch 150): Loss/seq after 02700 batchs: 729.301513671875
INFO:root:Train (Epoch 150): Loss/seq after 02750 batchs: 743.8800048828125
INFO:root:Train (Epoch 150): Loss/seq after 02800 batchs: 746.5684204101562
INFO:root:Train (Epoch 150): Loss/seq after 02850 batchs: 745.919921875
INFO:root:Train (Epoch 150): Loss/seq after 02900 batchs: 747.2559204101562
INFO:root:Train (Epoch 150): Loss/seq after 02950 batchs: 744.2557373046875
INFO:root:Train (Epoch 150): Loss/seq after 03000 batchs: 747.7496948242188
INFO:root:Train (Epoch 150): Loss/seq after 03050 batchs: 751.72216796875
INFO:root:Train (Epoch 150): Loss/seq after 03100 batchs: 755.7794189453125
INFO:root:Train (Epoch 150): Loss/seq after 03150 batchs: 761.1280517578125
INFO:root:Train (Epoch 150): Loss/seq after 03200 batchs: 763.4926147460938
INFO:root:Train (Epoch 150): Loss/seq after 03250 batchs: 766.0267944335938
INFO:root:Train (Epoch 150): Loss/seq after 03300 batchs: 765.4129028320312
INFO:root:Train (Epoch 150): Loss/seq after 03350 batchs: 765.5062866210938
INFO:root:Train (Epoch 150): Loss/seq after 03400 batchs: 759.5616455078125
INFO:root:Train (Epoch 150): Loss/seq after 03450 batchs: 755.7102661132812
INFO:root:Train (Epoch 150): Loss/seq after 03500 batchs: 754.9143676757812
INFO:root:Train (Epoch 150): Loss/seq after 03550 batchs: 750.8067016601562
INFO:root:Train (Epoch 150): Loss/seq after 03600 batchs: 758.34912109375
INFO:root:Train (Epoch 150): Loss/seq after 03650 batchs: 754.5614624023438
INFO:root:Train (Epoch 150): Loss/seq after 03700 batchs: 756.1390380859375
INFO:root:Train (Epoch 150): Loss/seq after 03750 batchs: 760.0333862304688
INFO:root:Train (Epoch 150): Loss/seq after 03800 batchs: 756.2003784179688
INFO:root:Train (Epoch 150): Loss/seq after 03850 batchs: 754.8679809570312
INFO:root:Train (Epoch 150): Loss/seq after 03900 batchs: 758.1797485351562
INFO:root:Train (Epoch 150): Loss/seq after 03950 batchs: 761.1719360351562
INFO:root:Train (Epoch 150): Loss/seq after 04000 batchs: 756.6466674804688
INFO:root:Train (Epoch 150): Loss/seq after 04050 batchs: 751.6320190429688
INFO:root:Train (Epoch 150): Loss/seq after 04100 batchs: 748.6312255859375
INFO:root:Train (Epoch 150): Loss/seq after 04150 batchs: 747.290283203125
INFO:root:Train (Epoch 150): Loss/seq after 04200 batchs: 744.5281982421875
INFO:root:Train (Epoch 150): Loss/seq after 04250 batchs: 741.9208984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 150): Loss/seq after 00000 batches: 807.9649658203125
INFO:root:# Valid (Epoch 150): Loss/seq after 00050 batches: 839.2107543945312
INFO:root:# Valid (Epoch 150): Loss/seq after 00100 batches: 1098.4046630859375
INFO:root:# Valid (Epoch 150): Loss/seq after 00150 batches: 823.4533081054688
INFO:root:# Valid (Epoch 150): Loss/seq after 00200 batches: 746.0708618164062
INFO:root:Artifacts: Make stick videos for epoch 150
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_150_on_20220423_085110.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_150_index_1904_on_20220423_085110.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 151): Loss/seq after 00000 batchs: 1450.855224609375
INFO:root:Train (Epoch 151): Loss/seq after 00050 batchs: 1000.3475952148438
INFO:root:Train (Epoch 151): Loss/seq after 00100 batchs: 1002.8090209960938
INFO:root:Train (Epoch 151): Loss/seq after 00150 batchs: 895.3717041015625
INFO:root:Train (Epoch 151): Loss/seq after 00200 batchs: 988.0043334960938
INFO:root:Train (Epoch 151): Loss/seq after 00250 batchs: 1110.3353271484375
INFO:root:Train (Epoch 151): Loss/seq after 00300 batchs: 1085.24609375
INFO:root:Train (Epoch 151): Loss/seq after 00350 batchs: 1014.9602661132812
INFO:root:Train (Epoch 151): Loss/seq after 00400 batchs: 1034.489013671875
INFO:root:Train (Epoch 151): Loss/seq after 00450 batchs: 1003.0473022460938
INFO:root:Train (Epoch 151): Loss/seq after 00500 batchs: 980.443603515625
INFO:root:Train (Epoch 151): Loss/seq after 00550 batchs: 947.4179077148438
INFO:root:Train (Epoch 151): Loss/seq after 00600 batchs: 914.329345703125
INFO:root:Train (Epoch 151): Loss/seq after 00650 batchs: 909.3865966796875
INFO:root:Train (Epoch 151): Loss/seq after 00700 batchs: 888.0349731445312
INFO:root:Train (Epoch 151): Loss/seq after 00750 batchs: 903.0858764648438
INFO:root:Train (Epoch 151): Loss/seq after 00800 batchs: 899.6361694335938
INFO:root:Train (Epoch 151): Loss/seq after 00850 batchs: 875.3782958984375
INFO:root:Train (Epoch 151): Loss/seq after 00900 batchs: 860.7870483398438
INFO:root:Train (Epoch 151): Loss/seq after 00950 batchs: 863.2440185546875
INFO:root:Train (Epoch 151): Loss/seq after 01000 batchs: 858.335205078125
INFO:root:Train (Epoch 151): Loss/seq after 01050 batchs: 845.53173828125
INFO:root:Train (Epoch 151): Loss/seq after 01100 batchs: 831.6734619140625
INFO:root:Train (Epoch 151): Loss/seq after 01150 batchs: 814.2431030273438
INFO:root:Train (Epoch 151): Loss/seq after 01200 batchs: 815.920654296875
INFO:root:Train (Epoch 151): Loss/seq after 01250 batchs: 811.6339111328125
INFO:root:Train (Epoch 151): Loss/seq after 01300 batchs: 798.420654296875
INFO:root:Train (Epoch 151): Loss/seq after 01350 batchs: 787.447509765625
INFO:root:Train (Epoch 151): Loss/seq after 01400 batchs: 796.3309326171875
INFO:root:Train (Epoch 151): Loss/seq after 01450 batchs: 795.1871948242188
INFO:root:Train (Epoch 151): Loss/seq after 01500 batchs: 797.4039306640625
INFO:root:Train (Epoch 151): Loss/seq after 01550 batchs: 800.79833984375
INFO:root:Train (Epoch 151): Loss/seq after 01600 batchs: 793.4601440429688
INFO:root:Train (Epoch 151): Loss/seq after 01650 batchs: 788.3678588867188
INFO:root:Train (Epoch 151): Loss/seq after 01700 batchs: 787.6383056640625
INFO:root:Train (Epoch 151): Loss/seq after 01750 batchs: 784.01806640625
INFO:root:Train (Epoch 151): Loss/seq after 01800 batchs: 779.1403198242188
INFO:root:Train (Epoch 151): Loss/seq after 01850 batchs: 772.651611328125
INFO:root:Train (Epoch 151): Loss/seq after 01900 batchs: 773.14501953125
INFO:root:Train (Epoch 151): Loss/seq after 01950 batchs: 769.7282104492188
INFO:root:Train (Epoch 151): Loss/seq after 02000 batchs: 766.678466796875
INFO:root:Train (Epoch 151): Loss/seq after 02050 batchs: 763.075439453125
INFO:root:Train (Epoch 151): Loss/seq after 02100 batchs: 758.0745849609375
INFO:root:Train (Epoch 151): Loss/seq after 02150 batchs: 754.6925659179688
INFO:root:Train (Epoch 151): Loss/seq after 02200 batchs: 749.819091796875
INFO:root:Train (Epoch 151): Loss/seq after 02250 batchs: 748.9610595703125
INFO:root:Train (Epoch 151): Loss/seq after 02300 batchs: 751.0966796875
INFO:root:Train (Epoch 151): Loss/seq after 02350 batchs: 744.9039306640625
INFO:root:Train (Epoch 151): Loss/seq after 02400 batchs: 744.2298583984375
INFO:root:Train (Epoch 151): Loss/seq after 02450 batchs: 737.7174072265625
INFO:root:Train (Epoch 151): Loss/seq after 02500 batchs: 726.75537109375
INFO:root:Train (Epoch 151): Loss/seq after 02550 batchs: 719.8556518554688
INFO:root:Train (Epoch 151): Loss/seq after 02600 batchs: 721.631103515625
INFO:root:Train (Epoch 151): Loss/seq after 02650 batchs: 719.5192260742188
INFO:root:Train (Epoch 151): Loss/seq after 02700 batchs: 717.344970703125
INFO:root:Train (Epoch 151): Loss/seq after 02750 batchs: 731.6128540039062
INFO:root:Train (Epoch 151): Loss/seq after 02800 batchs: 734.952880859375
INFO:root:Train (Epoch 151): Loss/seq after 02850 batchs: 733.5219116210938
INFO:root:Train (Epoch 151): Loss/seq after 02900 batchs: 733.83544921875
INFO:root:Train (Epoch 151): Loss/seq after 02950 batchs: 730.8363037109375
INFO:root:Train (Epoch 151): Loss/seq after 03000 batchs: 734.3849487304688
INFO:root:Train (Epoch 151): Loss/seq after 03050 batchs: 740.638916015625
INFO:root:Train (Epoch 151): Loss/seq after 03100 batchs: 743.7868041992188
INFO:root:Train (Epoch 151): Loss/seq after 03150 batchs: 749.3912963867188
INFO:root:Train (Epoch 151): Loss/seq after 03200 batchs: 752.9479370117188
INFO:root:Train (Epoch 151): Loss/seq after 03250 batchs: 755.4013061523438
INFO:root:Train (Epoch 151): Loss/seq after 03300 batchs: 753.7973022460938
INFO:root:Train (Epoch 151): Loss/seq after 03350 batchs: 753.085693359375
INFO:root:Train (Epoch 151): Loss/seq after 03400 batchs: 747.2491455078125
INFO:root:Train (Epoch 151): Loss/seq after 03450 batchs: 743.7659301757812
INFO:root:Train (Epoch 151): Loss/seq after 03500 batchs: 742.4794311523438
INFO:root:Train (Epoch 151): Loss/seq after 03550 batchs: 738.3983764648438
INFO:root:Train (Epoch 151): Loss/seq after 03600 batchs: 746.316650390625
INFO:root:Train (Epoch 151): Loss/seq after 03650 batchs: 742.6361694335938
INFO:root:Train (Epoch 151): Loss/seq after 03700 batchs: 743.721923828125
INFO:root:Train (Epoch 151): Loss/seq after 03750 batchs: 747.6846923828125
INFO:root:Train (Epoch 151): Loss/seq after 03800 batchs: 743.9747314453125
INFO:root:Train (Epoch 151): Loss/seq after 03850 batchs: 743.25830078125
INFO:root:Train (Epoch 151): Loss/seq after 03900 batchs: 747.0218505859375
INFO:root:Train (Epoch 151): Loss/seq after 03950 batchs: 750.3421630859375
INFO:root:Train (Epoch 151): Loss/seq after 04000 batchs: 745.6240844726562
INFO:root:Train (Epoch 151): Loss/seq after 04050 batchs: 740.7339477539062
INFO:root:Train (Epoch 151): Loss/seq after 04100 batchs: 737.8819580078125
INFO:root:Train (Epoch 151): Loss/seq after 04150 batchs: 736.5137329101562
INFO:root:Train (Epoch 151): Loss/seq after 04200 batchs: 733.6531372070312
INFO:root:Train (Epoch 151): Loss/seq after 04250 batchs: 731.597900390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 151): Loss/seq after 00000 batches: 558.17236328125
INFO:root:# Valid (Epoch 151): Loss/seq after 00050 batches: 835.8749389648438
INFO:root:# Valid (Epoch 151): Loss/seq after 00100 batches: 1093.213134765625
INFO:root:# Valid (Epoch 151): Loss/seq after 00150 batches: 825.12548828125
INFO:root:# Valid (Epoch 151): Loss/seq after 00200 batches: 746.2742309570312
INFO:root:Artifacts: Make stick videos for epoch 151
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_151_on_20220423_085559.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_151_index_1302_on_20220423_085559.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 152): Loss/seq after 00000 batchs: 1304.3294677734375
INFO:root:Train (Epoch 152): Loss/seq after 00050 batchs: 1004.9097290039062
INFO:root:Train (Epoch 152): Loss/seq after 00100 batchs: 991.46337890625
INFO:root:Train (Epoch 152): Loss/seq after 00150 batchs: 889.0092163085938
INFO:root:Train (Epoch 152): Loss/seq after 00200 batchs: 986.9640502929688
INFO:root:Train (Epoch 152): Loss/seq after 00250 batchs: 1100.8326416015625
INFO:root:Train (Epoch 152): Loss/seq after 00300 batchs: 1076.0108642578125
INFO:root:Train (Epoch 152): Loss/seq after 00350 batchs: 1006.1629028320312
INFO:root:Train (Epoch 152): Loss/seq after 00400 batchs: 1018.663818359375
INFO:root:Train (Epoch 152): Loss/seq after 00450 batchs: 988.8043212890625
INFO:root:Train (Epoch 152): Loss/seq after 00500 batchs: 964.9287719726562
INFO:root:Train (Epoch 152): Loss/seq after 00550 batchs: 931.5620727539062
INFO:root:Train (Epoch 152): Loss/seq after 00600 batchs: 898.2221069335938
INFO:root:Train (Epoch 152): Loss/seq after 00650 batchs: 893.3162231445312
INFO:root:Train (Epoch 152): Loss/seq after 00700 batchs: 870.189208984375
INFO:root:Train (Epoch 152): Loss/seq after 00750 batchs: 888.9871215820312
INFO:root:Train (Epoch 152): Loss/seq after 00800 batchs: 884.0611572265625
INFO:root:Train (Epoch 152): Loss/seq after 00850 batchs: 859.5209350585938
INFO:root:Train (Epoch 152): Loss/seq after 00900 batchs: 844.1209106445312
INFO:root:Train (Epoch 152): Loss/seq after 00950 batchs: 849.83154296875
INFO:root:Train (Epoch 152): Loss/seq after 01000 batchs: 842.75390625
INFO:root:Train (Epoch 152): Loss/seq after 01050 batchs: 829.7540283203125
INFO:root:Train (Epoch 152): Loss/seq after 01100 batchs: 818.6908569335938
INFO:root:Train (Epoch 152): Loss/seq after 01150 batchs: 800.778076171875
INFO:root:Train (Epoch 152): Loss/seq after 01200 batchs: 802.3302612304688
INFO:root:Train (Epoch 152): Loss/seq after 01250 batchs: 798.5899047851562
INFO:root:Train (Epoch 152): Loss/seq after 01300 batchs: 785.2850952148438
INFO:root:Train (Epoch 152): Loss/seq after 01350 batchs: 775.2654418945312
INFO:root:Train (Epoch 152): Loss/seq after 01400 batchs: 781.7799682617188
INFO:root:Train (Epoch 152): Loss/seq after 01450 batchs: 781.5732421875
INFO:root:Train (Epoch 152): Loss/seq after 01500 batchs: 784.5413208007812
INFO:root:Train (Epoch 152): Loss/seq after 01550 batchs: 788.7513427734375
INFO:root:Train (Epoch 152): Loss/seq after 01600 batchs: 781.249267578125
INFO:root:Train (Epoch 152): Loss/seq after 01650 batchs: 776.97314453125
INFO:root:Train (Epoch 152): Loss/seq after 01700 batchs: 776.3511962890625
INFO:root:Train (Epoch 152): Loss/seq after 01750 batchs: 771.861083984375
INFO:root:Train (Epoch 152): Loss/seq after 01800 batchs: 766.96826171875
INFO:root:Train (Epoch 152): Loss/seq after 01850 batchs: 760.7138671875
INFO:root:Train (Epoch 152): Loss/seq after 01900 batchs: 761.111083984375
INFO:root:Train (Epoch 152): Loss/seq after 01950 batchs: 758.0625610351562
INFO:root:Train (Epoch 152): Loss/seq after 02000 batchs: 754.8662109375
INFO:root:Train (Epoch 152): Loss/seq after 02050 batchs: 751.8262939453125
INFO:root:Train (Epoch 152): Loss/seq after 02100 batchs: 747.279052734375
INFO:root:Train (Epoch 152): Loss/seq after 02150 batchs: 744.008056640625
INFO:root:Train (Epoch 152): Loss/seq after 02200 batchs: 738.9979248046875
INFO:root:Train (Epoch 152): Loss/seq after 02250 batchs: 738.59130859375
INFO:root:Train (Epoch 152): Loss/seq after 02300 batchs: 740.47705078125
INFO:root:Train (Epoch 152): Loss/seq after 02350 batchs: 734.19677734375
INFO:root:Train (Epoch 152): Loss/seq after 02400 batchs: 733.7343139648438
INFO:root:Train (Epoch 152): Loss/seq after 02450 batchs: 727.328369140625
INFO:root:Train (Epoch 152): Loss/seq after 02500 batchs: 716.4750366210938
INFO:root:Train (Epoch 152): Loss/seq after 02550 batchs: 709.4276733398438
INFO:root:Train (Epoch 152): Loss/seq after 02600 batchs: 710.2090454101562
INFO:root:Train (Epoch 152): Loss/seq after 02650 batchs: 708.2236938476562
INFO:root:Train (Epoch 152): Loss/seq after 02700 batchs: 705.8829956054688
INFO:root:Train (Epoch 152): Loss/seq after 02750 batchs: 727.20849609375
INFO:root:Train (Epoch 152): Loss/seq after 02800 batchs: 729.3549194335938
INFO:root:Train (Epoch 152): Loss/seq after 02850 batchs: 728.51025390625
INFO:root:Train (Epoch 152): Loss/seq after 02900 batchs: 729.2343139648438
INFO:root:Train (Epoch 152): Loss/seq after 02950 batchs: 726.3734130859375
INFO:root:Train (Epoch 152): Loss/seq after 03000 batchs: 729.831298828125
INFO:root:Train (Epoch 152): Loss/seq after 03050 batchs: 734.447021484375
INFO:root:Train (Epoch 152): Loss/seq after 03100 batchs: 738.1953735351562
INFO:root:Train (Epoch 152): Loss/seq after 03150 batchs: 743.3063354492188
INFO:root:Train (Epoch 152): Loss/seq after 03200 batchs: 745.6812744140625
INFO:root:Train (Epoch 152): Loss/seq after 03250 batchs: 747.8709716796875
INFO:root:Train (Epoch 152): Loss/seq after 03300 batchs: 746.6596069335938
INFO:root:Train (Epoch 152): Loss/seq after 03350 batchs: 746.3311767578125
INFO:root:Train (Epoch 152): Loss/seq after 03400 batchs: 740.3524780273438
INFO:root:Train (Epoch 152): Loss/seq after 03450 batchs: 737.1572875976562
INFO:root:Train (Epoch 152): Loss/seq after 03500 batchs: 736.13818359375
INFO:root:Train (Epoch 152): Loss/seq after 03550 batchs: 732.35009765625
INFO:root:Train (Epoch 152): Loss/seq after 03600 batchs: 740.4189453125
INFO:root:Train (Epoch 152): Loss/seq after 03650 batchs: 736.8228759765625
INFO:root:Train (Epoch 152): Loss/seq after 03700 batchs: 738.2371215820312
INFO:root:Train (Epoch 152): Loss/seq after 03750 batchs: 742.0134887695312
INFO:root:Train (Epoch 152): Loss/seq after 03800 batchs: 738.3580932617188
INFO:root:Train (Epoch 152): Loss/seq after 03850 batchs: 737.432373046875
INFO:root:Train (Epoch 152): Loss/seq after 03900 batchs: 741.3193969726562
INFO:root:Train (Epoch 152): Loss/seq after 03950 batchs: 744.7157592773438
INFO:root:Train (Epoch 152): Loss/seq after 04000 batchs: 739.975341796875
INFO:root:Train (Epoch 152): Loss/seq after 04050 batchs: 735.0450439453125
INFO:root:Train (Epoch 152): Loss/seq after 04100 batchs: 732.3086547851562
INFO:root:Train (Epoch 152): Loss/seq after 04150 batchs: 731.0718383789062
INFO:root:Train (Epoch 152): Loss/seq after 04200 batchs: 728.3775024414062
INFO:root:Train (Epoch 152): Loss/seq after 04250 batchs: 725.88720703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 152): Loss/seq after 00000 batches: 573.4916381835938
INFO:root:# Valid (Epoch 152): Loss/seq after 00050 batches: 827.9861450195312
INFO:root:# Valid (Epoch 152): Loss/seq after 00100 batches: 1088.4324951171875
INFO:root:# Valid (Epoch 152): Loss/seq after 00150 batches: 817.9165649414062
INFO:root:# Valid (Epoch 152): Loss/seq after 00200 batches: 735.8145141601562
INFO:root:Artifacts: Make stick videos for epoch 152
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_152_on_20220423_090052.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_152_index_729_on_20220423_090052.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 153): Loss/seq after 00000 batchs: 1328.237548828125
INFO:root:Train (Epoch 153): Loss/seq after 00050 batchs: 979.8079223632812
INFO:root:Train (Epoch 153): Loss/seq after 00100 batchs: 980.2671508789062
INFO:root:Train (Epoch 153): Loss/seq after 00150 batchs: 879.1378173828125
INFO:root:Train (Epoch 153): Loss/seq after 00200 batchs: 975.198486328125
INFO:root:Train (Epoch 153): Loss/seq after 00250 batchs: 1087.452880859375
INFO:root:Train (Epoch 153): Loss/seq after 00300 batchs: 1063.9615478515625
INFO:root:Train (Epoch 153): Loss/seq after 00350 batchs: 996.144775390625
INFO:root:Train (Epoch 153): Loss/seq after 00400 batchs: 1006.8740844726562
INFO:root:Train (Epoch 153): Loss/seq after 00450 batchs: 977.3567504882812
INFO:root:Train (Epoch 153): Loss/seq after 00500 batchs: 953.3363037109375
INFO:root:Train (Epoch 153): Loss/seq after 00550 batchs: 923.39208984375
INFO:root:Train (Epoch 153): Loss/seq after 00600 batchs: 891.4515380859375
INFO:root:Train (Epoch 153): Loss/seq after 00650 batchs: 887.23291015625
INFO:root:Train (Epoch 153): Loss/seq after 00700 batchs: 866.8775024414062
INFO:root:Train (Epoch 153): Loss/seq after 00750 batchs: 882.5337524414062
INFO:root:Train (Epoch 153): Loss/seq after 00800 batchs: 877.7554321289062
INFO:root:Train (Epoch 153): Loss/seq after 00850 batchs: 853.4871215820312
INFO:root:Train (Epoch 153): Loss/seq after 00900 batchs: 839.2850341796875
INFO:root:Train (Epoch 153): Loss/seq after 00950 batchs: 841.4971923828125
INFO:root:Train (Epoch 153): Loss/seq after 01000 batchs: 836.8463745117188
INFO:root:Train (Epoch 153): Loss/seq after 01050 batchs: 824.8898315429688
INFO:root:Train (Epoch 153): Loss/seq after 01100 batchs: 812.935791015625
INFO:root:Train (Epoch 153): Loss/seq after 01150 batchs: 795.53125
INFO:root:Train (Epoch 153): Loss/seq after 01200 batchs: 796.2550659179688
INFO:root:Train (Epoch 153): Loss/seq after 01250 batchs: 793.10400390625
INFO:root:Train (Epoch 153): Loss/seq after 01300 batchs: 781.1049194335938
INFO:root:Train (Epoch 153): Loss/seq after 01350 batchs: 770.3662109375
INFO:root:Train (Epoch 153): Loss/seq after 01400 batchs: 778.2816772460938
INFO:root:Train (Epoch 153): Loss/seq after 01450 batchs: 776.9392700195312
INFO:root:Train (Epoch 153): Loss/seq after 01500 batchs: 779.7060546875
INFO:root:Train (Epoch 153): Loss/seq after 01550 batchs: 782.9872436523438
INFO:root:Train (Epoch 153): Loss/seq after 01600 batchs: 775.1181030273438
INFO:root:Train (Epoch 153): Loss/seq after 01650 batchs: 769.9681396484375
INFO:root:Train (Epoch 153): Loss/seq after 01700 batchs: 769.0897216796875
INFO:root:Train (Epoch 153): Loss/seq after 01750 batchs: 764.7322387695312
INFO:root:Train (Epoch 153): Loss/seq after 01800 batchs: 759.8590698242188
INFO:root:Train (Epoch 153): Loss/seq after 01850 batchs: 753.8367309570312
INFO:root:Train (Epoch 153): Loss/seq after 01900 batchs: 754.3790893554688
INFO:root:Train (Epoch 153): Loss/seq after 01950 batchs: 751.3502807617188
INFO:root:Train (Epoch 153): Loss/seq after 02000 batchs: 748.1672973632812
INFO:root:Train (Epoch 153): Loss/seq after 02050 batchs: 744.6903686523438
INFO:root:Train (Epoch 153): Loss/seq after 02100 batchs: 740.12646484375
INFO:root:Train (Epoch 153): Loss/seq after 02150 batchs: 736.6561279296875
INFO:root:Train (Epoch 153): Loss/seq after 02200 batchs: 732.1412963867188
INFO:root:Train (Epoch 153): Loss/seq after 02250 batchs: 731.57373046875
INFO:root:Train (Epoch 153): Loss/seq after 02300 batchs: 733.8567504882812
INFO:root:Train (Epoch 153): Loss/seq after 02350 batchs: 727.476318359375
INFO:root:Train (Epoch 153): Loss/seq after 02400 batchs: 726.9558715820312
INFO:root:Train (Epoch 153): Loss/seq after 02450 batchs: 720.5756225585938
INFO:root:Train (Epoch 153): Loss/seq after 02500 batchs: 709.8833618164062
INFO:root:Train (Epoch 153): Loss/seq after 02550 batchs: 702.943603515625
INFO:root:Train (Epoch 153): Loss/seq after 02600 batchs: 703.826416015625
INFO:root:Train (Epoch 153): Loss/seq after 02650 batchs: 701.8025512695312
INFO:root:Train (Epoch 153): Loss/seq after 02700 batchs: 699.499267578125
INFO:root:Train (Epoch 153): Loss/seq after 02750 batchs: 718.48046875
INFO:root:Train (Epoch 153): Loss/seq after 02800 batchs: 719.958984375
INFO:root:Train (Epoch 153): Loss/seq after 02850 batchs: 719.6887817382812
INFO:root:Train (Epoch 153): Loss/seq after 02900 batchs: 720.2960205078125
INFO:root:Train (Epoch 153): Loss/seq after 02950 batchs: 717.46533203125
INFO:root:Train (Epoch 153): Loss/seq after 03000 batchs: 721.0286254882812
INFO:root:Train (Epoch 153): Loss/seq after 03050 batchs: 727.4052124023438
INFO:root:Train (Epoch 153): Loss/seq after 03100 batchs: 731.1715087890625
INFO:root:Train (Epoch 153): Loss/seq after 03150 batchs: 736.6304321289062
INFO:root:Train (Epoch 153): Loss/seq after 03200 batchs: 738.6649780273438
INFO:root:Train (Epoch 153): Loss/seq after 03250 batchs: 742.0272216796875
INFO:root:Train (Epoch 153): Loss/seq after 03300 batchs: 740.4637451171875
INFO:root:Train (Epoch 153): Loss/seq after 03350 batchs: 740.4422607421875
INFO:root:Train (Epoch 153): Loss/seq after 03400 batchs: 734.676025390625
INFO:root:Train (Epoch 153): Loss/seq after 03450 batchs: 731.3297119140625
INFO:root:Train (Epoch 153): Loss/seq after 03500 batchs: 730.2684936523438
INFO:root:Train (Epoch 153): Loss/seq after 03550 batchs: 726.4739379882812
INFO:root:Train (Epoch 153): Loss/seq after 03600 batchs: 734.4427490234375
INFO:root:Train (Epoch 153): Loss/seq after 03650 batchs: 731.0571899414062
INFO:root:Train (Epoch 153): Loss/seq after 03700 batchs: 732.3928833007812
INFO:root:Train (Epoch 153): Loss/seq after 03750 batchs: 736.3392333984375
INFO:root:Train (Epoch 153): Loss/seq after 03800 batchs: 732.5704345703125
INFO:root:Train (Epoch 153): Loss/seq after 03850 batchs: 731.5698852539062
INFO:root:Train (Epoch 153): Loss/seq after 03900 batchs: 735.872314453125
INFO:root:Train (Epoch 153): Loss/seq after 03950 batchs: 739.271240234375
INFO:root:Train (Epoch 153): Loss/seq after 04000 batchs: 734.4375610351562
INFO:root:Train (Epoch 153): Loss/seq after 04050 batchs: 729.4830932617188
INFO:root:Train (Epoch 153): Loss/seq after 04100 batchs: 726.6213989257812
INFO:root:Train (Epoch 153): Loss/seq after 04150 batchs: 725.5067138671875
INFO:root:Train (Epoch 153): Loss/seq after 04200 batchs: 722.6480712890625
INFO:root:Train (Epoch 153): Loss/seq after 04250 batchs: 720.1053466796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 153): Loss/seq after 00000 batches: 626.550048828125
INFO:root:# Valid (Epoch 153): Loss/seq after 00050 batches: 815.6084594726562
INFO:root:# Valid (Epoch 153): Loss/seq after 00100 batches: 1076.886474609375
INFO:root:# Valid (Epoch 153): Loss/seq after 00150 batches: 805.372802734375
INFO:root:# Valid (Epoch 153): Loss/seq after 00200 batches: 719.3349609375
INFO:root:Artifacts: Make stick videos for epoch 153
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_153_on_20220423_090541.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_153_index_101_on_20220423_090541.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 154): Loss/seq after 00000 batchs: 1262.491455078125
INFO:root:Train (Epoch 154): Loss/seq after 00050 batchs: 983.537841796875
INFO:root:Train (Epoch 154): Loss/seq after 00100 batchs: 993.1436767578125
INFO:root:Train (Epoch 154): Loss/seq after 00150 batchs: 883.2199096679688
INFO:root:Train (Epoch 154): Loss/seq after 00200 batchs: 977.5535888671875
INFO:root:Train (Epoch 154): Loss/seq after 00250 batchs: 1089.843505859375
INFO:root:Train (Epoch 154): Loss/seq after 00300 batchs: 1064.893798828125
INFO:root:Train (Epoch 154): Loss/seq after 00350 batchs: 994.0451049804688
INFO:root:Train (Epoch 154): Loss/seq after 00400 batchs: 1008.3629760742188
INFO:root:Train (Epoch 154): Loss/seq after 00450 batchs: 978.0272216796875
INFO:root:Train (Epoch 154): Loss/seq after 00500 batchs: 953.1422729492188
INFO:root:Train (Epoch 154): Loss/seq after 00550 batchs: 921.01171875
INFO:root:Train (Epoch 154): Loss/seq after 00600 batchs: 888.0908813476562
INFO:root:Train (Epoch 154): Loss/seq after 00650 batchs: 880.2335815429688
INFO:root:Train (Epoch 154): Loss/seq after 00700 batchs: 859.8662719726562
INFO:root:Train (Epoch 154): Loss/seq after 00750 batchs: 875.6748046875
INFO:root:Train (Epoch 154): Loss/seq after 00800 batchs: 871.3743286132812
INFO:root:Train (Epoch 154): Loss/seq after 00850 batchs: 845.4344482421875
INFO:root:Train (Epoch 154): Loss/seq after 00900 batchs: 830.7067260742188
INFO:root:Train (Epoch 154): Loss/seq after 00950 batchs: 836.4701538085938
INFO:root:Train (Epoch 154): Loss/seq after 01000 batchs: 831.9556884765625
INFO:root:Train (Epoch 154): Loss/seq after 01050 batchs: 819.0751953125
INFO:root:Train (Epoch 154): Loss/seq after 01100 batchs: 808.064697265625
INFO:root:Train (Epoch 154): Loss/seq after 01150 batchs: 790.300537109375
INFO:root:Train (Epoch 154): Loss/seq after 01200 batchs: 792.0375366210938
INFO:root:Train (Epoch 154): Loss/seq after 01250 batchs: 788.147705078125
INFO:root:Train (Epoch 154): Loss/seq after 01300 batchs: 776.12744140625
INFO:root:Train (Epoch 154): Loss/seq after 01350 batchs: 766.43701171875
INFO:root:Train (Epoch 154): Loss/seq after 01400 batchs: 774.2778930664062
INFO:root:Train (Epoch 154): Loss/seq after 01450 batchs: 773.046875
INFO:root:Train (Epoch 154): Loss/seq after 01500 batchs: 775.7032470703125
INFO:root:Train (Epoch 154): Loss/seq after 01550 batchs: 778.4432983398438
INFO:root:Train (Epoch 154): Loss/seq after 01600 batchs: 770.3250122070312
INFO:root:Train (Epoch 154): Loss/seq after 01650 batchs: 765.23876953125
INFO:root:Train (Epoch 154): Loss/seq after 01700 batchs: 764.9552001953125
INFO:root:Train (Epoch 154): Loss/seq after 01750 batchs: 761.1964111328125
INFO:root:Train (Epoch 154): Loss/seq after 01800 batchs: 756.1945190429688
INFO:root:Train (Epoch 154): Loss/seq after 01850 batchs: 749.577392578125
INFO:root:Train (Epoch 154): Loss/seq after 01900 batchs: 750.14794921875
INFO:root:Train (Epoch 154): Loss/seq after 01950 batchs: 747.4043579101562
INFO:root:Train (Epoch 154): Loss/seq after 02000 batchs: 743.8509521484375
INFO:root:Train (Epoch 154): Loss/seq after 02050 batchs: 740.437744140625
INFO:root:Train (Epoch 154): Loss/seq after 02100 batchs: 735.7542724609375
INFO:root:Train (Epoch 154): Loss/seq after 02150 batchs: 732.7427978515625
INFO:root:Train (Epoch 154): Loss/seq after 02200 batchs: 727.7499389648438
INFO:root:Train (Epoch 154): Loss/seq after 02250 batchs: 727.240478515625
INFO:root:Train (Epoch 154): Loss/seq after 02300 batchs: 728.433349609375
INFO:root:Train (Epoch 154): Loss/seq after 02350 batchs: 722.3534545898438
INFO:root:Train (Epoch 154): Loss/seq after 02400 batchs: 721.7711791992188
INFO:root:Train (Epoch 154): Loss/seq after 02450 batchs: 715.4694213867188
INFO:root:Train (Epoch 154): Loss/seq after 02500 batchs: 704.8922729492188
INFO:root:Train (Epoch 154): Loss/seq after 02550 batchs: 698.1342163085938
INFO:root:Train (Epoch 154): Loss/seq after 02600 batchs: 698.8710327148438
INFO:root:Train (Epoch 154): Loss/seq after 02650 batchs: 696.7401123046875
INFO:root:Train (Epoch 154): Loss/seq after 02700 batchs: 694.4443969726562
INFO:root:Train (Epoch 154): Loss/seq after 02750 batchs: 710.9610595703125
INFO:root:Train (Epoch 154): Loss/seq after 02800 batchs: 714.3709106445312
INFO:root:Train (Epoch 154): Loss/seq after 02850 batchs: 713.4580078125
INFO:root:Train (Epoch 154): Loss/seq after 02900 batchs: 713.74755859375
INFO:root:Train (Epoch 154): Loss/seq after 02950 batchs: 710.976806640625
INFO:root:Train (Epoch 154): Loss/seq after 03000 batchs: 714.3590087890625
INFO:root:Train (Epoch 154): Loss/seq after 03050 batchs: 719.4406127929688
INFO:root:Train (Epoch 154): Loss/seq after 03100 batchs: 722.7158813476562
INFO:root:Train (Epoch 154): Loss/seq after 03150 batchs: 728.3955078125
INFO:root:Train (Epoch 154): Loss/seq after 03200 batchs: 730.572265625
INFO:root:Train (Epoch 154): Loss/seq after 03250 batchs: 733.0923461914062
INFO:root:Train (Epoch 154): Loss/seq after 03300 batchs: 731.5278930664062
INFO:root:Train (Epoch 154): Loss/seq after 03350 batchs: 731.0645141601562
INFO:root:Train (Epoch 154): Loss/seq after 03400 batchs: 725.2511596679688
INFO:root:Train (Epoch 154): Loss/seq after 03450 batchs: 721.8455200195312
INFO:root:Train (Epoch 154): Loss/seq after 03500 batchs: 720.6638793945312
INFO:root:Train (Epoch 154): Loss/seq after 03550 batchs: 716.6018676757812
INFO:root:Train (Epoch 154): Loss/seq after 03600 batchs: 724.695556640625
INFO:root:Train (Epoch 154): Loss/seq after 03650 batchs: 721.058837890625
INFO:root:Train (Epoch 154): Loss/seq after 03700 batchs: 722.5623779296875
INFO:root:Train (Epoch 154): Loss/seq after 03750 batchs: 726.5137329101562
INFO:root:Train (Epoch 154): Loss/seq after 03800 batchs: 722.7381591796875
INFO:root:Train (Epoch 154): Loss/seq after 03850 batchs: 721.7869262695312
INFO:root:Train (Epoch 154): Loss/seq after 03900 batchs: 725.5689086914062
INFO:root:Train (Epoch 154): Loss/seq after 03950 batchs: 729.349609375
INFO:root:Train (Epoch 154): Loss/seq after 04000 batchs: 724.5908203125
INFO:root:Train (Epoch 154): Loss/seq after 04050 batchs: 719.7913818359375
INFO:root:Train (Epoch 154): Loss/seq after 04100 batchs: 717.009521484375
INFO:root:Train (Epoch 154): Loss/seq after 04150 batchs: 715.8529052734375
INFO:root:Train (Epoch 154): Loss/seq after 04200 batchs: 713.1681518554688
INFO:root:Train (Epoch 154): Loss/seq after 04250 batchs: 710.6900634765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 154): Loss/seq after 00000 batches: 551.050537109375
INFO:root:# Valid (Epoch 154): Loss/seq after 00050 batches: 808.2075805664062
INFO:root:# Valid (Epoch 154): Loss/seq after 00100 batches: 1066.98388671875
INFO:root:# Valid (Epoch 154): Loss/seq after 00150 batches: 796.2314453125
INFO:root:# Valid (Epoch 154): Loss/seq after 00200 batches: 716.4536743164062
INFO:root:Artifacts: Make stick videos for epoch 154
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_154_on_20220423_091027.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_154_index_789_on_20220423_091027.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 155): Loss/seq after 00000 batchs: 1311.9737548828125
INFO:root:Train (Epoch 155): Loss/seq after 00050 batchs: 964.3259887695312
INFO:root:Train (Epoch 155): Loss/seq after 00100 batchs: 982.0924682617188
INFO:root:Train (Epoch 155): Loss/seq after 00150 batchs: 868.2409057617188
INFO:root:Train (Epoch 155): Loss/seq after 00200 batchs: 959.9309692382812
INFO:root:Train (Epoch 155): Loss/seq after 00250 batchs: 1074.542236328125
INFO:root:Train (Epoch 155): Loss/seq after 00300 batchs: 1051.662109375
INFO:root:Train (Epoch 155): Loss/seq after 00350 batchs: 982.1498413085938
INFO:root:Train (Epoch 155): Loss/seq after 00400 batchs: 990.2574462890625
INFO:root:Train (Epoch 155): Loss/seq after 00450 batchs: 961.6375732421875
INFO:root:Train (Epoch 155): Loss/seq after 00500 batchs: 937.5189208984375
INFO:root:Train (Epoch 155): Loss/seq after 00550 batchs: 906.0443725585938
INFO:root:Train (Epoch 155): Loss/seq after 00600 batchs: 873.9281005859375
INFO:root:Train (Epoch 155): Loss/seq after 00650 batchs: 865.2939453125
INFO:root:Train (Epoch 155): Loss/seq after 00700 batchs: 841.9041748046875
INFO:root:Train (Epoch 155): Loss/seq after 00750 batchs: 856.05029296875
INFO:root:Train (Epoch 155): Loss/seq after 00800 batchs: 852.4193115234375
INFO:root:Train (Epoch 155): Loss/seq after 00850 batchs: 827.4741821289062
INFO:root:Train (Epoch 155): Loss/seq after 00900 batchs: 811.7822265625
INFO:root:Train (Epoch 155): Loss/seq after 00950 batchs: 818.4708862304688
INFO:root:Train (Epoch 155): Loss/seq after 01000 batchs: 812.9877319335938
INFO:root:Train (Epoch 155): Loss/seq after 01050 batchs: 800.5267944335938
INFO:root:Train (Epoch 155): Loss/seq after 01100 batchs: 787.6824340820312
INFO:root:Train (Epoch 155): Loss/seq after 01150 batchs: 769.4248046875
INFO:root:Train (Epoch 155): Loss/seq after 01200 batchs: 771.6581420898438
INFO:root:Train (Epoch 155): Loss/seq after 01250 batchs: 768.2721557617188
INFO:root:Train (Epoch 155): Loss/seq after 01300 batchs: 756.7154541015625
INFO:root:Train (Epoch 155): Loss/seq after 01350 batchs: 747.4007568359375
INFO:root:Train (Epoch 155): Loss/seq after 01400 batchs: 755.0083618164062
INFO:root:Train (Epoch 155): Loss/seq after 01450 batchs: 754.5598754882812
INFO:root:Train (Epoch 155): Loss/seq after 01500 batchs: 757.9755249023438
INFO:root:Train (Epoch 155): Loss/seq after 01550 batchs: 761.7337036132812
INFO:root:Train (Epoch 155): Loss/seq after 01600 batchs: 754.4607543945312
INFO:root:Train (Epoch 155): Loss/seq after 01650 batchs: 749.8412475585938
INFO:root:Train (Epoch 155): Loss/seq after 01700 batchs: 749.7943115234375
INFO:root:Train (Epoch 155): Loss/seq after 01750 batchs: 745.8756713867188
INFO:root:Train (Epoch 155): Loss/seq after 01800 batchs: 741.2855224609375
INFO:root:Train (Epoch 155): Loss/seq after 01850 batchs: 735.020751953125
INFO:root:Train (Epoch 155): Loss/seq after 01900 batchs: 735.3532104492188
INFO:root:Train (Epoch 155): Loss/seq after 01950 batchs: 732.1157836914062
INFO:root:Train (Epoch 155): Loss/seq after 02000 batchs: 729.371826171875
INFO:root:Train (Epoch 155): Loss/seq after 02050 batchs: 726.6224365234375
INFO:root:Train (Epoch 155): Loss/seq after 02100 batchs: 722.2794799804688
INFO:root:Train (Epoch 155): Loss/seq after 02150 batchs: 719.202392578125
INFO:root:Train (Epoch 155): Loss/seq after 02200 batchs: 714.54052734375
INFO:root:Train (Epoch 155): Loss/seq after 02250 batchs: 714.1875610351562
INFO:root:Train (Epoch 155): Loss/seq after 02300 batchs: 716.873291015625
INFO:root:Train (Epoch 155): Loss/seq after 02350 batchs: 710.7017822265625
INFO:root:Train (Epoch 155): Loss/seq after 02400 batchs: 710.619873046875
INFO:root:Train (Epoch 155): Loss/seq after 02450 batchs: 704.3638305664062
INFO:root:Train (Epoch 155): Loss/seq after 02500 batchs: 693.83984375
INFO:root:Train (Epoch 155): Loss/seq after 02550 batchs: 687.2053833007812
INFO:root:Train (Epoch 155): Loss/seq after 02600 batchs: 687.4876708984375
INFO:root:Train (Epoch 155): Loss/seq after 02650 batchs: 684.9122924804688
INFO:root:Train (Epoch 155): Loss/seq after 02700 batchs: 682.87548828125
INFO:root:Train (Epoch 155): Loss/seq after 02750 batchs: 695.9093627929688
INFO:root:Train (Epoch 155): Loss/seq after 02800 batchs: 697.4891357421875
INFO:root:Train (Epoch 155): Loss/seq after 02850 batchs: 696.6801147460938
INFO:root:Train (Epoch 155): Loss/seq after 02900 batchs: 697.588623046875
INFO:root:Train (Epoch 155): Loss/seq after 02950 batchs: 695.0928344726562
INFO:root:Train (Epoch 155): Loss/seq after 03000 batchs: 698.7406616210938
INFO:root:Train (Epoch 155): Loss/seq after 03050 batchs: 705.3389282226562
INFO:root:Train (Epoch 155): Loss/seq after 03100 batchs: 708.9630737304688
INFO:root:Train (Epoch 155): Loss/seq after 03150 batchs: 714.7732543945312
INFO:root:Train (Epoch 155): Loss/seq after 03200 batchs: 717.5750122070312
INFO:root:Train (Epoch 155): Loss/seq after 03250 batchs: 719.841552734375
INFO:root:Train (Epoch 155): Loss/seq after 03300 batchs: 718.7406005859375
INFO:root:Train (Epoch 155): Loss/seq after 03350 batchs: 718.461669921875
INFO:root:Train (Epoch 155): Loss/seq after 03400 batchs: 712.9136352539062
INFO:root:Train (Epoch 155): Loss/seq after 03450 batchs: 709.8525390625
INFO:root:Train (Epoch 155): Loss/seq after 03500 batchs: 709.1532592773438
INFO:root:Train (Epoch 155): Loss/seq after 03550 batchs: 705.34521484375
INFO:root:Train (Epoch 155): Loss/seq after 03600 batchs: 713.6740112304688
INFO:root:Train (Epoch 155): Loss/seq after 03650 batchs: 710.1665649414062
INFO:root:Train (Epoch 155): Loss/seq after 03700 batchs: 711.47509765625
INFO:root:Train (Epoch 155): Loss/seq after 03750 batchs: 715.6453247070312
INFO:root:Train (Epoch 155): Loss/seq after 03800 batchs: 712.1092529296875
INFO:root:Train (Epoch 155): Loss/seq after 03850 batchs: 711.045654296875
INFO:root:Train (Epoch 155): Loss/seq after 03900 batchs: 714.5468139648438
INFO:root:Train (Epoch 155): Loss/seq after 03950 batchs: 717.8154296875
INFO:root:Train (Epoch 155): Loss/seq after 04000 batchs: 713.2177734375
INFO:root:Train (Epoch 155): Loss/seq after 04050 batchs: 708.4529418945312
INFO:root:Train (Epoch 155): Loss/seq after 04100 batchs: 705.7057495117188
INFO:root:Train (Epoch 155): Loss/seq after 04150 batchs: 704.7432861328125
INFO:root:Train (Epoch 155): Loss/seq after 04200 batchs: 702.0414428710938
INFO:root:Train (Epoch 155): Loss/seq after 04250 batchs: 699.801513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 155): Loss/seq after 00000 batches: 629.71533203125
INFO:root:# Valid (Epoch 155): Loss/seq after 00050 batches: 788.8950805664062
INFO:root:# Valid (Epoch 155): Loss/seq after 00100 batches: 990.616943359375
INFO:root:# Valid (Epoch 155): Loss/seq after 00150 batches: 743.9220581054688
INFO:root:# Valid (Epoch 155): Loss/seq after 00200 batches: 670.9398193359375
INFO:root:Artifacts: Make stick videos for epoch 155
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_155_on_20220423_091523.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_155_index_926_on_20220423_091523.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 156): Loss/seq after 00000 batchs: 1281.2994384765625
INFO:root:Train (Epoch 156): Loss/seq after 00050 batchs: 976.1656494140625
INFO:root:Train (Epoch 156): Loss/seq after 00100 batchs: 967.069580078125
INFO:root:Train (Epoch 156): Loss/seq after 00150 batchs: 859.2199096679688
INFO:root:Train (Epoch 156): Loss/seq after 00200 batchs: 956.3707885742188
INFO:root:Train (Epoch 156): Loss/seq after 00250 batchs: 1073.6961669921875
INFO:root:Train (Epoch 156): Loss/seq after 00300 batchs: 1052.010498046875
INFO:root:Train (Epoch 156): Loss/seq after 00350 batchs: 983.2507934570312
INFO:root:Train (Epoch 156): Loss/seq after 00400 batchs: 998.6495971679688
INFO:root:Train (Epoch 156): Loss/seq after 00450 batchs: 968.8920288085938
INFO:root:Train (Epoch 156): Loss/seq after 00500 batchs: 944.6519165039062
INFO:root:Train (Epoch 156): Loss/seq after 00550 batchs: 912.2997436523438
INFO:root:Train (Epoch 156): Loss/seq after 00600 batchs: 878.6864624023438
INFO:root:Train (Epoch 156): Loss/seq after 00650 batchs: 872.0635375976562
INFO:root:Train (Epoch 156): Loss/seq after 00700 batchs: 853.2015991210938
INFO:root:Train (Epoch 156): Loss/seq after 00750 batchs: 871.4918212890625
INFO:root:Train (Epoch 156): Loss/seq after 00800 batchs: 865.3492431640625
INFO:root:Train (Epoch 156): Loss/seq after 00850 batchs: 839.22998046875
INFO:root:Train (Epoch 156): Loss/seq after 00900 batchs: 823.0877685546875
INFO:root:Train (Epoch 156): Loss/seq after 00950 batchs: 825.9292602539062
INFO:root:Train (Epoch 156): Loss/seq after 01000 batchs: 818.5062866210938
INFO:root:Train (Epoch 156): Loss/seq after 01050 batchs: 805.3639526367188
INFO:root:Train (Epoch 156): Loss/seq after 01100 batchs: 793.1785888671875
INFO:root:Train (Epoch 156): Loss/seq after 01150 batchs: 774.5946655273438
INFO:root:Train (Epoch 156): Loss/seq after 01200 batchs: 775.8790283203125
INFO:root:Train (Epoch 156): Loss/seq after 01250 batchs: 772.3919677734375
INFO:root:Train (Epoch 156): Loss/seq after 01300 batchs: 760.3427734375
INFO:root:Train (Epoch 156): Loss/seq after 01350 batchs: 751.178466796875
INFO:root:Train (Epoch 156): Loss/seq after 01400 batchs: 759.4169311523438
INFO:root:Train (Epoch 156): Loss/seq after 01450 batchs: 758.9802856445312
INFO:root:Train (Epoch 156): Loss/seq after 01500 batchs: 761.635009765625
INFO:root:Train (Epoch 156): Loss/seq after 01550 batchs: 765.0999145507812
INFO:root:Train (Epoch 156): Loss/seq after 01600 batchs: 757.1757202148438
INFO:root:Train (Epoch 156): Loss/seq after 01650 batchs: 752.6929321289062
INFO:root:Train (Epoch 156): Loss/seq after 01700 batchs: 752.0584106445312
INFO:root:Train (Epoch 156): Loss/seq after 01750 batchs: 747.7274169921875
INFO:root:Train (Epoch 156): Loss/seq after 01800 batchs: 742.7091674804688
INFO:root:Train (Epoch 156): Loss/seq after 01850 batchs: 736.0636596679688
INFO:root:Train (Epoch 156): Loss/seq after 01900 batchs: 736.4913940429688
INFO:root:Train (Epoch 156): Loss/seq after 01950 batchs: 733.429443359375
INFO:root:Train (Epoch 156): Loss/seq after 02000 batchs: 730.6594848632812
INFO:root:Train (Epoch 156): Loss/seq after 02050 batchs: 727.7119140625
INFO:root:Train (Epoch 156): Loss/seq after 02100 batchs: 723.1514892578125
INFO:root:Train (Epoch 156): Loss/seq after 02150 batchs: 720.42041015625
INFO:root:Train (Epoch 156): Loss/seq after 02200 batchs: 715.79736328125
INFO:root:Train (Epoch 156): Loss/seq after 02250 batchs: 715.4421997070312
INFO:root:Train (Epoch 156): Loss/seq after 02300 batchs: 718.3463745117188
INFO:root:Train (Epoch 156): Loss/seq after 02350 batchs: 711.8609619140625
INFO:root:Train (Epoch 156): Loss/seq after 02400 batchs: 711.2313232421875
INFO:root:Train (Epoch 156): Loss/seq after 02450 batchs: 705.1350708007812
INFO:root:Train (Epoch 156): Loss/seq after 02500 batchs: 694.6075439453125
INFO:root:Train (Epoch 156): Loss/seq after 02550 batchs: 687.7593383789062
INFO:root:Train (Epoch 156): Loss/seq after 02600 batchs: 688.0573120117188
INFO:root:Train (Epoch 156): Loss/seq after 02650 batchs: 685.5311889648438
INFO:root:Train (Epoch 156): Loss/seq after 02700 batchs: 683.2157592773438
INFO:root:Train (Epoch 156): Loss/seq after 02750 batchs: 702.389404296875
INFO:root:Train (Epoch 156): Loss/seq after 02800 batchs: 704.8936767578125
INFO:root:Train (Epoch 156): Loss/seq after 02850 batchs: 704.078125
INFO:root:Train (Epoch 156): Loss/seq after 02900 batchs: 704.6011352539062
INFO:root:Train (Epoch 156): Loss/seq after 02950 batchs: 702.1881713867188
INFO:root:Train (Epoch 156): Loss/seq after 03000 batchs: 705.7587890625
INFO:root:Train (Epoch 156): Loss/seq after 03050 batchs: 711.3064575195312
INFO:root:Train (Epoch 156): Loss/seq after 03100 batchs: 714.4463500976562
INFO:root:Train (Epoch 156): Loss/seq after 03150 batchs: 720.1743774414062
INFO:root:Train (Epoch 156): Loss/seq after 03200 batchs: 723.3231201171875
INFO:root:Train (Epoch 156): Loss/seq after 03250 batchs: 726.0474243164062
INFO:root:Train (Epoch 156): Loss/seq after 03300 batchs: 724.8963623046875
INFO:root:Train (Epoch 156): Loss/seq after 03350 batchs: 724.58837890625
INFO:root:Train (Epoch 156): Loss/seq after 03400 batchs: 718.9014892578125
INFO:root:Train (Epoch 156): Loss/seq after 03450 batchs: 715.6943359375
INFO:root:Train (Epoch 156): Loss/seq after 03500 batchs: 714.7633056640625
INFO:root:Train (Epoch 156): Loss/seq after 03550 batchs: 710.8009643554688
INFO:root:Train (Epoch 156): Loss/seq after 03600 batchs: 718.7460327148438
INFO:root:Train (Epoch 156): Loss/seq after 03650 batchs: 715.1875610351562
INFO:root:Train (Epoch 156): Loss/seq after 03700 batchs: 716.451416015625
INFO:root:Train (Epoch 156): Loss/seq after 03750 batchs: 720.3951416015625
INFO:root:Train (Epoch 156): Loss/seq after 03800 batchs: 716.769775390625
INFO:root:Train (Epoch 156): Loss/seq after 03850 batchs: 715.869384765625
INFO:root:Train (Epoch 156): Loss/seq after 03900 batchs: 720.1361694335938
INFO:root:Train (Epoch 156): Loss/seq after 03950 batchs: 723.2211303710938
INFO:root:Train (Epoch 156): Loss/seq after 04000 batchs: 718.5230712890625
INFO:root:Train (Epoch 156): Loss/seq after 04050 batchs: 713.624755859375
INFO:root:Train (Epoch 156): Loss/seq after 04100 batchs: 710.7459716796875
INFO:root:Train (Epoch 156): Loss/seq after 04150 batchs: 709.552734375
INFO:root:Train (Epoch 156): Loss/seq after 04200 batchs: 706.7711791992188
INFO:root:Train (Epoch 156): Loss/seq after 04250 batchs: 704.2258911132812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 156): Loss/seq after 00000 batches: 629.4156494140625
INFO:root:# Valid (Epoch 156): Loss/seq after 00050 batches: 792.3698120117188
INFO:root:# Valid (Epoch 156): Loss/seq after 00100 batches: 1038.06884765625
INFO:root:# Valid (Epoch 156): Loss/seq after 00150 batches: 778.49462890625
INFO:root:# Valid (Epoch 156): Loss/seq after 00200 batches: 702.0571899414062
INFO:root:Artifacts: Make stick videos for epoch 156
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_156_on_20220423_092019.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_156_index_630_on_20220423_092019.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 157): Loss/seq after 00000 batchs: 1310.379638671875
INFO:root:Train (Epoch 157): Loss/seq after 00050 batchs: 973.3826904296875
INFO:root:Train (Epoch 157): Loss/seq after 00100 batchs: 966.18505859375
INFO:root:Train (Epoch 157): Loss/seq after 00150 batchs: 856.8737182617188
INFO:root:Train (Epoch 157): Loss/seq after 00200 batchs: 961.4537353515625
INFO:root:Train (Epoch 157): Loss/seq after 00250 batchs: 1073.8204345703125
INFO:root:Train (Epoch 157): Loss/seq after 00300 batchs: 1050.4324951171875
INFO:root:Train (Epoch 157): Loss/seq after 00350 batchs: 981.368408203125
INFO:root:Train (Epoch 157): Loss/seq after 00400 batchs: 996.0134887695312
INFO:root:Train (Epoch 157): Loss/seq after 00450 batchs: 966.6840209960938
INFO:root:Train (Epoch 157): Loss/seq after 00500 batchs: 941.9744262695312
INFO:root:Train (Epoch 157): Loss/seq after 00550 batchs: 910.1201171875
INFO:root:Train (Epoch 157): Loss/seq after 00600 batchs: 877.235107421875
INFO:root:Train (Epoch 157): Loss/seq after 00650 batchs: 868.7384643554688
INFO:root:Train (Epoch 157): Loss/seq after 00700 batchs: 847.0076904296875
INFO:root:Train (Epoch 157): Loss/seq after 00750 batchs: 862.5316772460938
INFO:root:Train (Epoch 157): Loss/seq after 00800 batchs: 856.6205444335938
INFO:root:Train (Epoch 157): Loss/seq after 00850 batchs: 830.669921875
INFO:root:Train (Epoch 157): Loss/seq after 00900 batchs: 813.2650756835938
INFO:root:Train (Epoch 157): Loss/seq after 00950 batchs: 818.023681640625
INFO:root:Train (Epoch 157): Loss/seq after 01000 batchs: 810.3584594726562
INFO:root:Train (Epoch 157): Loss/seq after 01050 batchs: 797.482421875
INFO:root:Train (Epoch 157): Loss/seq after 01100 batchs: 784.2579956054688
INFO:root:Train (Epoch 157): Loss/seq after 01150 batchs: 767.3177490234375
INFO:root:Train (Epoch 157): Loss/seq after 01200 batchs: 768.02490234375
INFO:root:Train (Epoch 157): Loss/seq after 01250 batchs: 765.0474853515625
INFO:root:Train (Epoch 157): Loss/seq after 01300 batchs: 752.0425415039062
INFO:root:Train (Epoch 157): Loss/seq after 01350 batchs: 743.4661254882812
INFO:root:Train (Epoch 157): Loss/seq after 01400 batchs: 752.0177612304688
INFO:root:Train (Epoch 157): Loss/seq after 01450 batchs: 751.2802124023438
INFO:root:Train (Epoch 157): Loss/seq after 01500 batchs: 754.4126586914062
INFO:root:Train (Epoch 157): Loss/seq after 01550 batchs: 757.8811645507812
INFO:root:Train (Epoch 157): Loss/seq after 01600 batchs: 750.5846557617188
INFO:root:Train (Epoch 157): Loss/seq after 01650 batchs: 746.5574340820312
INFO:root:Train (Epoch 157): Loss/seq after 01700 batchs: 746.3192138671875
INFO:root:Train (Epoch 157): Loss/seq after 01750 batchs: 742.0755615234375
INFO:root:Train (Epoch 157): Loss/seq after 01800 batchs: 737.31201171875
INFO:root:Train (Epoch 157): Loss/seq after 01850 batchs: 730.9502563476562
INFO:root:Train (Epoch 157): Loss/seq after 01900 batchs: 731.5184326171875
INFO:root:Train (Epoch 157): Loss/seq after 01950 batchs: 728.4279174804688
INFO:root:Train (Epoch 157): Loss/seq after 02000 batchs: 725.3326416015625
INFO:root:Train (Epoch 157): Loss/seq after 02050 batchs: 721.9200439453125
INFO:root:Train (Epoch 157): Loss/seq after 02100 batchs: 717.5590209960938
INFO:root:Train (Epoch 157): Loss/seq after 02150 batchs: 714.6139526367188
INFO:root:Train (Epoch 157): Loss/seq after 02200 batchs: 709.9949340820312
INFO:root:Train (Epoch 157): Loss/seq after 02250 batchs: 709.3692626953125
INFO:root:Train (Epoch 157): Loss/seq after 02300 batchs: 712.883056640625
INFO:root:Train (Epoch 157): Loss/seq after 02350 batchs: 706.8191528320312
INFO:root:Train (Epoch 157): Loss/seq after 02400 batchs: 706.4490966796875
INFO:root:Train (Epoch 157): Loss/seq after 02450 batchs: 700.3323364257812
INFO:root:Train (Epoch 157): Loss/seq after 02500 batchs: 689.8211669921875
INFO:root:Train (Epoch 157): Loss/seq after 02550 batchs: 683.188232421875
INFO:root:Train (Epoch 157): Loss/seq after 02600 batchs: 683.4135131835938
INFO:root:Train (Epoch 157): Loss/seq after 02650 batchs: 681.005126953125
INFO:root:Train (Epoch 157): Loss/seq after 02700 batchs: 678.636474609375
INFO:root:Train (Epoch 157): Loss/seq after 02750 batchs: 693.3124389648438
INFO:root:Train (Epoch 157): Loss/seq after 02800 batchs: 695.4268188476562
INFO:root:Train (Epoch 157): Loss/seq after 02850 batchs: 694.5809326171875
INFO:root:Train (Epoch 157): Loss/seq after 02900 batchs: 695.4229736328125
INFO:root:Train (Epoch 157): Loss/seq after 02950 batchs: 692.8380737304688
INFO:root:Train (Epoch 157): Loss/seq after 03000 batchs: 696.4459838867188
INFO:root:Train (Epoch 157): Loss/seq after 03050 batchs: 701.652587890625
INFO:root:Train (Epoch 157): Loss/seq after 03100 batchs: 705.3233642578125
INFO:root:Train (Epoch 157): Loss/seq after 03150 batchs: 710.857666015625
INFO:root:Train (Epoch 157): Loss/seq after 03200 batchs: 713.2247314453125
INFO:root:Train (Epoch 157): Loss/seq after 03250 batchs: 717.08349609375
INFO:root:Train (Epoch 157): Loss/seq after 03300 batchs: 715.6535034179688
INFO:root:Train (Epoch 157): Loss/seq after 03350 batchs: 715.4934692382812
INFO:root:Train (Epoch 157): Loss/seq after 03400 batchs: 709.910888671875
INFO:root:Train (Epoch 157): Loss/seq after 03450 batchs: 706.6529541015625
INFO:root:Train (Epoch 157): Loss/seq after 03500 batchs: 705.8477783203125
INFO:root:Train (Epoch 157): Loss/seq after 03550 batchs: 702.1837768554688
INFO:root:Train (Epoch 157): Loss/seq after 03600 batchs: 710.0700073242188
INFO:root:Train (Epoch 157): Loss/seq after 03650 batchs: 706.69580078125
INFO:root:Train (Epoch 157): Loss/seq after 03700 batchs: 708.0064086914062
INFO:root:Train (Epoch 157): Loss/seq after 03750 batchs: 711.9487915039062
INFO:root:Train (Epoch 157): Loss/seq after 03800 batchs: 708.1284790039062
INFO:root:Train (Epoch 157): Loss/seq after 03850 batchs: 707.0609130859375
INFO:root:Train (Epoch 157): Loss/seq after 03900 batchs: 710.809814453125
INFO:root:Train (Epoch 157): Loss/seq after 03950 batchs: 714.2734985351562
INFO:root:Train (Epoch 157): Loss/seq after 04000 batchs: 709.4017333984375
INFO:root:Train (Epoch 157): Loss/seq after 04050 batchs: 704.5755004882812
INFO:root:Train (Epoch 157): Loss/seq after 04100 batchs: 701.8421630859375
INFO:root:Train (Epoch 157): Loss/seq after 04150 batchs: 700.7521362304688
INFO:root:Train (Epoch 157): Loss/seq after 04200 batchs: 698.12109375
INFO:root:Train (Epoch 157): Loss/seq after 04250 batchs: 695.66552734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 157): Loss/seq after 00000 batches: 629.5344848632812
INFO:root:# Valid (Epoch 157): Loss/seq after 00050 batches: 807.320556640625
INFO:root:# Valid (Epoch 157): Loss/seq after 00100 batches: 1049.5377197265625
INFO:root:# Valid (Epoch 157): Loss/seq after 00150 batches: 785.8738403320312
INFO:root:# Valid (Epoch 157): Loss/seq after 00200 batches: 712.67333984375
INFO:root:Artifacts: Make stick videos for epoch 157
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_157_on_20220423_092528.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_157_index_150_on_20220423_092528.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 158): Loss/seq after 00000 batchs: 1349.4608154296875
INFO:root:Train (Epoch 158): Loss/seq after 00050 batchs: 974.2261352539062
INFO:root:Train (Epoch 158): Loss/seq after 00100 batchs: 972.3095703125
INFO:root:Train (Epoch 158): Loss/seq after 00150 batchs: 862.0325317382812
INFO:root:Train (Epoch 158): Loss/seq after 00200 batchs: 962.9359741210938
INFO:root:Train (Epoch 158): Loss/seq after 00250 batchs: 1072.5888671875
INFO:root:Train (Epoch 158): Loss/seq after 00300 batchs: 1049.8524169921875
INFO:root:Train (Epoch 158): Loss/seq after 00350 batchs: 979.9410400390625
INFO:root:Train (Epoch 158): Loss/seq after 00400 batchs: 991.629150390625
INFO:root:Train (Epoch 158): Loss/seq after 00450 batchs: 961.162109375
INFO:root:Train (Epoch 158): Loss/seq after 00500 batchs: 937.057373046875
INFO:root:Train (Epoch 158): Loss/seq after 00550 batchs: 905.7431640625
INFO:root:Train (Epoch 158): Loss/seq after 00600 batchs: 873.9072265625
INFO:root:Train (Epoch 158): Loss/seq after 00650 batchs: 869.0972290039062
INFO:root:Train (Epoch 158): Loss/seq after 00700 batchs: 845.6266479492188
INFO:root:Train (Epoch 158): Loss/seq after 00750 batchs: 858.972412109375
INFO:root:Train (Epoch 158): Loss/seq after 00800 batchs: 854.283203125
INFO:root:Train (Epoch 158): Loss/seq after 00850 batchs: 829.1160888671875
INFO:root:Train (Epoch 158): Loss/seq after 00900 batchs: 813.0801391601562
INFO:root:Train (Epoch 158): Loss/seq after 00950 batchs: 819.152099609375
INFO:root:Train (Epoch 158): Loss/seq after 01000 batchs: 811.8273315429688
INFO:root:Train (Epoch 158): Loss/seq after 01050 batchs: 798.2047729492188
INFO:root:Train (Epoch 158): Loss/seq after 01100 batchs: 784.945068359375
INFO:root:Train (Epoch 158): Loss/seq after 01150 batchs: 766.7428588867188
INFO:root:Train (Epoch 158): Loss/seq after 01200 batchs: 768.5834350585938
INFO:root:Train (Epoch 158): Loss/seq after 01250 batchs: 764.8338623046875
INFO:root:Train (Epoch 158): Loss/seq after 01300 batchs: 754.0809936523438
INFO:root:Train (Epoch 158): Loss/seq after 01350 batchs: 744.2042236328125
INFO:root:Train (Epoch 158): Loss/seq after 01400 batchs: 750.8080444335938
INFO:root:Train (Epoch 158): Loss/seq after 01450 batchs: 749.978271484375
INFO:root:Train (Epoch 158): Loss/seq after 01500 batchs: 753.2286376953125
INFO:root:Train (Epoch 158): Loss/seq after 01550 batchs: 756.0512084960938
INFO:root:Train (Epoch 158): Loss/seq after 01600 batchs: 748.7960205078125
INFO:root:Train (Epoch 158): Loss/seq after 01650 batchs: 743.7461547851562
INFO:root:Train (Epoch 158): Loss/seq after 01700 batchs: 743.2471923828125
INFO:root:Train (Epoch 158): Loss/seq after 01750 batchs: 738.8712768554688
INFO:root:Train (Epoch 158): Loss/seq after 01800 batchs: 734.077880859375
INFO:root:Train (Epoch 158): Loss/seq after 01850 batchs: 727.5929565429688
INFO:root:Train (Epoch 158): Loss/seq after 01900 batchs: 727.9351196289062
INFO:root:Train (Epoch 158): Loss/seq after 01950 batchs: 725.1048583984375
INFO:root:Train (Epoch 158): Loss/seq after 02000 batchs: 722.4989624023438
INFO:root:Train (Epoch 158): Loss/seq after 02050 batchs: 719.5476684570312
INFO:root:Train (Epoch 158): Loss/seq after 02100 batchs: 714.944580078125
INFO:root:Train (Epoch 158): Loss/seq after 02150 batchs: 711.9027709960938
INFO:root:Train (Epoch 158): Loss/seq after 02200 batchs: 707.1954345703125
INFO:root:Train (Epoch 158): Loss/seq after 02250 batchs: 706.5225830078125
INFO:root:Train (Epoch 158): Loss/seq after 02300 batchs: 707.613037109375
INFO:root:Train (Epoch 158): Loss/seq after 02350 batchs: 701.1135864257812
INFO:root:Train (Epoch 158): Loss/seq after 02400 batchs: 700.678466796875
INFO:root:Train (Epoch 158): Loss/seq after 02450 batchs: 694.72509765625
INFO:root:Train (Epoch 158): Loss/seq after 02500 batchs: 684.3333129882812
INFO:root:Train (Epoch 158): Loss/seq after 02550 batchs: 677.483154296875
INFO:root:Train (Epoch 158): Loss/seq after 02600 batchs: 677.58837890625
INFO:root:Train (Epoch 158): Loss/seq after 02650 batchs: 675.1871337890625
INFO:root:Train (Epoch 158): Loss/seq after 02700 batchs: 672.6093139648438
INFO:root:Train (Epoch 158): Loss/seq after 02750 batchs: 686.7841796875
INFO:root:Train (Epoch 158): Loss/seq after 02800 batchs: 688.9765625
INFO:root:Train (Epoch 158): Loss/seq after 02850 batchs: 688.7163696289062
INFO:root:Train (Epoch 158): Loss/seq after 02900 batchs: 689.4852905273438
INFO:root:Train (Epoch 158): Loss/seq after 02950 batchs: 687.1207885742188
INFO:root:Train (Epoch 158): Loss/seq after 03000 batchs: 690.820068359375
INFO:root:Train (Epoch 158): Loss/seq after 03050 batchs: 695.8421020507812
INFO:root:Train (Epoch 158): Loss/seq after 03100 batchs: 699.62060546875
INFO:root:Train (Epoch 158): Loss/seq after 03150 batchs: 705.4710693359375
INFO:root:Train (Epoch 158): Loss/seq after 03200 batchs: 708.1574096679688
INFO:root:Train (Epoch 158): Loss/seq after 03250 batchs: 711.0241088867188
INFO:root:Train (Epoch 158): Loss/seq after 03300 batchs: 710.5850830078125
INFO:root:Train (Epoch 158): Loss/seq after 03350 batchs: 710.62841796875
INFO:root:Train (Epoch 158): Loss/seq after 03400 batchs: 705.1805419921875
INFO:root:Train (Epoch 158): Loss/seq after 03450 batchs: 701.9696655273438
INFO:root:Train (Epoch 158): Loss/seq after 03500 batchs: 701.0206298828125
INFO:root:Train (Epoch 158): Loss/seq after 03550 batchs: 697.0595092773438
INFO:root:Train (Epoch 158): Loss/seq after 03600 batchs: 705.3350830078125
INFO:root:Train (Epoch 158): Loss/seq after 03650 batchs: 701.7855834960938
INFO:root:Train (Epoch 158): Loss/seq after 03700 batchs: 703.2080688476562
INFO:root:Train (Epoch 158): Loss/seq after 03750 batchs: 707.0335693359375
INFO:root:Train (Epoch 158): Loss/seq after 03800 batchs: 703.3464965820312
INFO:root:Train (Epoch 158): Loss/seq after 03850 batchs: 702.4872436523438
INFO:root:Train (Epoch 158): Loss/seq after 03900 batchs: 706.3084106445312
INFO:root:Train (Epoch 158): Loss/seq after 03950 batchs: 709.5399169921875
INFO:root:Train (Epoch 158): Loss/seq after 04000 batchs: 704.8649291992188
INFO:root:Train (Epoch 158): Loss/seq after 04050 batchs: 700.0819702148438
INFO:root:Train (Epoch 158): Loss/seq after 04100 batchs: 697.2920532226562
INFO:root:Train (Epoch 158): Loss/seq after 04150 batchs: 696.2003784179688
INFO:root:Train (Epoch 158): Loss/seq after 04200 batchs: 693.4205322265625
INFO:root:Train (Epoch 158): Loss/seq after 04250 batchs: 690.9950561523438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 158): Loss/seq after 00000 batches: 610.5899047851562
INFO:root:# Valid (Epoch 158): Loss/seq after 00050 batches: 790.5885620117188
INFO:root:# Valid (Epoch 158): Loss/seq after 00100 batches: 1002.5687255859375
INFO:root:# Valid (Epoch 158): Loss/seq after 00150 batches: 753.32763671875
INFO:root:# Valid (Epoch 158): Loss/seq after 00200 batches: 682.6590576171875
INFO:root:Artifacts: Make stick videos for epoch 158
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_158_on_20220423_093012.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_158_index_1015_on_20220423_093012.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 159): Loss/seq after 00000 batchs: 1336.236572265625
INFO:root:Train (Epoch 159): Loss/seq after 00050 batchs: 984.5018920898438
INFO:root:Train (Epoch 159): Loss/seq after 00100 batchs: 970.8707275390625
INFO:root:Train (Epoch 159): Loss/seq after 00150 batchs: 859.47021484375
INFO:root:Train (Epoch 159): Loss/seq after 00200 batchs: 950.6444702148438
INFO:root:Train (Epoch 159): Loss/seq after 00250 batchs: 1061.671630859375
INFO:root:Train (Epoch 159): Loss/seq after 00300 batchs: 1040.2156982421875
INFO:root:Train (Epoch 159): Loss/seq after 00350 batchs: 971.414794921875
INFO:root:Train (Epoch 159): Loss/seq after 00400 batchs: 984.0905151367188
INFO:root:Train (Epoch 159): Loss/seq after 00450 batchs: 956.0326538085938
INFO:root:Train (Epoch 159): Loss/seq after 00500 batchs: 930.4488525390625
INFO:root:Train (Epoch 159): Loss/seq after 00550 batchs: 898.5941772460938
INFO:root:Train (Epoch 159): Loss/seq after 00600 batchs: 866.3616333007812
INFO:root:Train (Epoch 159): Loss/seq after 00650 batchs: 864.9003295898438
INFO:root:Train (Epoch 159): Loss/seq after 00700 batchs: 844.8074340820312
INFO:root:Train (Epoch 159): Loss/seq after 00750 batchs: 860.0074462890625
INFO:root:Train (Epoch 159): Loss/seq after 00800 batchs: 855.2697143554688
INFO:root:Train (Epoch 159): Loss/seq after 00850 batchs: 829.34765625
INFO:root:Train (Epoch 159): Loss/seq after 00900 batchs: 813.4636840820312
INFO:root:Train (Epoch 159): Loss/seq after 00950 batchs: 820.2413940429688
INFO:root:Train (Epoch 159): Loss/seq after 01000 batchs: 814.240478515625
INFO:root:Train (Epoch 159): Loss/seq after 01050 batchs: 799.8731689453125
INFO:root:Train (Epoch 159): Loss/seq after 01100 batchs: 788.2466430664062
INFO:root:Train (Epoch 159): Loss/seq after 01150 batchs: 770.0784912109375
INFO:root:Train (Epoch 159): Loss/seq after 01200 batchs: 771.9530029296875
INFO:root:Train (Epoch 159): Loss/seq after 01250 batchs: 768.0580444335938
INFO:root:Train (Epoch 159): Loss/seq after 01300 batchs: 757.04248046875
INFO:root:Train (Epoch 159): Loss/seq after 01350 batchs: 746.2969360351562
INFO:root:Train (Epoch 159): Loss/seq after 01400 batchs: 752.9920654296875
INFO:root:Train (Epoch 159): Loss/seq after 01450 batchs: 751.6417846679688
INFO:root:Train (Epoch 159): Loss/seq after 01500 batchs: 754.3605346679688
INFO:root:Train (Epoch 159): Loss/seq after 01550 batchs: 756.7058715820312
INFO:root:Train (Epoch 159): Loss/seq after 01600 batchs: 749.0841064453125
INFO:root:Train (Epoch 159): Loss/seq after 01650 batchs: 744.1396484375
INFO:root:Train (Epoch 159): Loss/seq after 01700 batchs: 743.7235107421875
INFO:root:Train (Epoch 159): Loss/seq after 01750 batchs: 739.5260620117188
INFO:root:Train (Epoch 159): Loss/seq after 01800 batchs: 734.5982666015625
INFO:root:Train (Epoch 159): Loss/seq after 01850 batchs: 728.1472778320312
INFO:root:Train (Epoch 159): Loss/seq after 01900 batchs: 727.87353515625
INFO:root:Train (Epoch 159): Loss/seq after 01950 batchs: 725.3297119140625
INFO:root:Train (Epoch 159): Loss/seq after 02000 batchs: 721.9983520507812
INFO:root:Train (Epoch 159): Loss/seq after 02050 batchs: 718.75
INFO:root:Train (Epoch 159): Loss/seq after 02100 batchs: 714.31982421875
INFO:root:Train (Epoch 159): Loss/seq after 02150 batchs: 711.1959228515625
INFO:root:Train (Epoch 159): Loss/seq after 02200 batchs: 706.3178100585938
INFO:root:Train (Epoch 159): Loss/seq after 02250 batchs: 705.932373046875
INFO:root:Train (Epoch 159): Loss/seq after 02300 batchs: 707.8348388671875
INFO:root:Train (Epoch 159): Loss/seq after 02350 batchs: 701.5595703125
INFO:root:Train (Epoch 159): Loss/seq after 02400 batchs: 701.1103515625
INFO:root:Train (Epoch 159): Loss/seq after 02450 batchs: 694.9039306640625
INFO:root:Train (Epoch 159): Loss/seq after 02500 batchs: 684.4989624023438
INFO:root:Train (Epoch 159): Loss/seq after 02550 batchs: 678.1370239257812
INFO:root:Train (Epoch 159): Loss/seq after 02600 batchs: 678.2100830078125
INFO:root:Train (Epoch 159): Loss/seq after 02650 batchs: 675.9495239257812
INFO:root:Train (Epoch 159): Loss/seq after 02700 batchs: 672.98095703125
INFO:root:Train (Epoch 159): Loss/seq after 02750 batchs: 687.087158203125
INFO:root:Train (Epoch 159): Loss/seq after 02800 batchs: 688.3303833007812
INFO:root:Train (Epoch 159): Loss/seq after 02850 batchs: 687.8631591796875
INFO:root:Train (Epoch 159): Loss/seq after 02900 batchs: 688.572509765625
INFO:root:Train (Epoch 159): Loss/seq after 02950 batchs: 685.937744140625
INFO:root:Train (Epoch 159): Loss/seq after 03000 batchs: 689.6021728515625
INFO:root:Train (Epoch 159): Loss/seq after 03050 batchs: 694.7879028320312
INFO:root:Train (Epoch 159): Loss/seq after 03100 batchs: 698.66455078125
INFO:root:Train (Epoch 159): Loss/seq after 03150 batchs: 705.1256713867188
INFO:root:Train (Epoch 159): Loss/seq after 03200 batchs: 707.8047485351562
INFO:root:Train (Epoch 159): Loss/seq after 03250 batchs: 711.1578369140625
INFO:root:Train (Epoch 159): Loss/seq after 03300 batchs: 710.0621948242188
INFO:root:Train (Epoch 159): Loss/seq after 03350 batchs: 709.5853271484375
INFO:root:Train (Epoch 159): Loss/seq after 03400 batchs: 704.0371704101562
INFO:root:Train (Epoch 159): Loss/seq after 03450 batchs: 700.947509765625
INFO:root:Train (Epoch 159): Loss/seq after 03500 batchs: 699.9163818359375
INFO:root:Train (Epoch 159): Loss/seq after 03550 batchs: 695.9229125976562
INFO:root:Train (Epoch 159): Loss/seq after 03600 batchs: 703.9282836914062
INFO:root:Train (Epoch 159): Loss/seq after 03650 batchs: 700.2727661132812
INFO:root:Train (Epoch 159): Loss/seq after 03700 batchs: 701.81787109375
INFO:root:Train (Epoch 159): Loss/seq after 03750 batchs: 705.6517333984375
INFO:root:Train (Epoch 159): Loss/seq after 03800 batchs: 702.008056640625
INFO:root:Train (Epoch 159): Loss/seq after 03850 batchs: 701.12060546875
INFO:root:Train (Epoch 159): Loss/seq after 03900 batchs: 704.531494140625
INFO:root:Train (Epoch 159): Loss/seq after 03950 batchs: 707.7991943359375
INFO:root:Train (Epoch 159): Loss/seq after 04000 batchs: 703.0479125976562
INFO:root:Train (Epoch 159): Loss/seq after 04050 batchs: 698.2313842773438
INFO:root:Train (Epoch 159): Loss/seq after 04100 batchs: 695.4586791992188
INFO:root:Train (Epoch 159): Loss/seq after 04150 batchs: 694.4554443359375
INFO:root:Train (Epoch 159): Loss/seq after 04200 batchs: 691.6917114257812
INFO:root:Train (Epoch 159): Loss/seq after 04250 batchs: 689.255615234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 159): Loss/seq after 00000 batches: 579.4437255859375
INFO:root:# Valid (Epoch 159): Loss/seq after 00050 batches: 748.7987670898438
INFO:root:# Valid (Epoch 159): Loss/seq after 00100 batches: 1019.6724243164062
INFO:root:# Valid (Epoch 159): Loss/seq after 00150 batches: 752.7880859375
INFO:root:# Valid (Epoch 159): Loss/seq after 00200 batches: 675.5475463867188
INFO:root:Artifacts: Make stick videos for epoch 159
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_159_on_20220423_093458.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_159_index_1148_on_20220423_093458.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 160): Loss/seq after 00000 batchs: 1375.564453125
INFO:root:Train (Epoch 160): Loss/seq after 00050 batchs: 971.3706665039062
INFO:root:Train (Epoch 160): Loss/seq after 00100 batchs: 955.8732299804688
INFO:root:Train (Epoch 160): Loss/seq after 00150 batchs: 849.318115234375
INFO:root:Train (Epoch 160): Loss/seq after 00200 batchs: 935.4364624023438
INFO:root:Train (Epoch 160): Loss/seq after 00250 batchs: 1049.74609375
INFO:root:Train (Epoch 160): Loss/seq after 00300 batchs: 1028.1983642578125
INFO:root:Train (Epoch 160): Loss/seq after 00350 batchs: 958.83251953125
INFO:root:Train (Epoch 160): Loss/seq after 00400 batchs: 968.5775146484375
INFO:root:Train (Epoch 160): Loss/seq after 00450 batchs: 940.30712890625
INFO:root:Train (Epoch 160): Loss/seq after 00500 batchs: 918.1781616210938
INFO:root:Train (Epoch 160): Loss/seq after 00550 batchs: 887.5859985351562
INFO:root:Train (Epoch 160): Loss/seq after 00600 batchs: 855.4478149414062
INFO:root:Train (Epoch 160): Loss/seq after 00650 batchs: 848.8997802734375
INFO:root:Train (Epoch 160): Loss/seq after 00700 batchs: 826.65625
INFO:root:Train (Epoch 160): Loss/seq after 00750 batchs: 848.18115234375
INFO:root:Train (Epoch 160): Loss/seq after 00800 batchs: 843.248291015625
INFO:root:Train (Epoch 160): Loss/seq after 00850 batchs: 818.9253540039062
INFO:root:Train (Epoch 160): Loss/seq after 00900 batchs: 801.968994140625
INFO:root:Train (Epoch 160): Loss/seq after 00950 batchs: 808.1985473632812
INFO:root:Train (Epoch 160): Loss/seq after 01000 batchs: 801.7814331054688
INFO:root:Train (Epoch 160): Loss/seq after 01050 batchs: 788.0484619140625
INFO:root:Train (Epoch 160): Loss/seq after 01100 batchs: 776.4249267578125
INFO:root:Train (Epoch 160): Loss/seq after 01150 batchs: 758.49169921875
INFO:root:Train (Epoch 160): Loss/seq after 01200 batchs: 760.4776611328125
INFO:root:Train (Epoch 160): Loss/seq after 01250 batchs: 756.6926879882812
INFO:root:Train (Epoch 160): Loss/seq after 01300 batchs: 745.296875
INFO:root:Train (Epoch 160): Loss/seq after 01350 batchs: 735.474853515625
INFO:root:Train (Epoch 160): Loss/seq after 01400 batchs: 741.9950561523438
INFO:root:Train (Epoch 160): Loss/seq after 01450 batchs: 741.288818359375
INFO:root:Train (Epoch 160): Loss/seq after 01500 batchs: 744.5299682617188
INFO:root:Train (Epoch 160): Loss/seq after 01550 batchs: 747.0426025390625
INFO:root:Train (Epoch 160): Loss/seq after 01600 batchs: 739.0426635742188
INFO:root:Train (Epoch 160): Loss/seq after 01650 batchs: 733.9945068359375
INFO:root:Train (Epoch 160): Loss/seq after 01700 batchs: 733.686279296875
INFO:root:Train (Epoch 160): Loss/seq after 01750 batchs: 729.8281860351562
INFO:root:Train (Epoch 160): Loss/seq after 01800 batchs: 725.088134765625
INFO:root:Train (Epoch 160): Loss/seq after 01850 batchs: 718.918701171875
INFO:root:Train (Epoch 160): Loss/seq after 01900 batchs: 719.16357421875
INFO:root:Train (Epoch 160): Loss/seq after 01950 batchs: 716.1129760742188
INFO:root:Train (Epoch 160): Loss/seq after 02000 batchs: 713.0491943359375
INFO:root:Train (Epoch 160): Loss/seq after 02050 batchs: 710.0616455078125
INFO:root:Train (Epoch 160): Loss/seq after 02100 batchs: 705.7713623046875
INFO:root:Train (Epoch 160): Loss/seq after 02150 batchs: 702.7706298828125
INFO:root:Train (Epoch 160): Loss/seq after 02200 batchs: 697.978759765625
INFO:root:Train (Epoch 160): Loss/seq after 02250 batchs: 697.3785400390625
INFO:root:Train (Epoch 160): Loss/seq after 02300 batchs: 698.7998657226562
INFO:root:Train (Epoch 160): Loss/seq after 02350 batchs: 692.4384155273438
INFO:root:Train (Epoch 160): Loss/seq after 02400 batchs: 692.0437622070312
INFO:root:Train (Epoch 160): Loss/seq after 02450 batchs: 685.9127197265625
INFO:root:Train (Epoch 160): Loss/seq after 02500 batchs: 675.671142578125
INFO:root:Train (Epoch 160): Loss/seq after 02550 batchs: 669.0772705078125
INFO:root:Train (Epoch 160): Loss/seq after 02600 batchs: 669.3110961914062
INFO:root:Train (Epoch 160): Loss/seq after 02650 batchs: 666.8597412109375
INFO:root:Train (Epoch 160): Loss/seq after 02700 batchs: 664.3427124023438
INFO:root:Train (Epoch 160): Loss/seq after 02750 batchs: 677.291015625
INFO:root:Train (Epoch 160): Loss/seq after 02800 batchs: 679.992431640625
INFO:root:Train (Epoch 160): Loss/seq after 02850 batchs: 679.3711547851562
INFO:root:Train (Epoch 160): Loss/seq after 02900 batchs: 680.4303588867188
INFO:root:Train (Epoch 160): Loss/seq after 02950 batchs: 678.2476196289062
INFO:root:Train (Epoch 160): Loss/seq after 03000 batchs: 682.0057983398438
INFO:root:Train (Epoch 160): Loss/seq after 03050 batchs: 686.5499267578125
INFO:root:Train (Epoch 160): Loss/seq after 03100 batchs: 690.8106689453125
INFO:root:Train (Epoch 160): Loss/seq after 03150 batchs: 696.902099609375
INFO:root:Train (Epoch 160): Loss/seq after 03200 batchs: 699.5387573242188
INFO:root:Train (Epoch 160): Loss/seq after 03250 batchs: 703.179931640625
INFO:root:Train (Epoch 160): Loss/seq after 03300 batchs: 702.4530029296875
INFO:root:Train (Epoch 160): Loss/seq after 03350 batchs: 702.0867309570312
INFO:root:Train (Epoch 160): Loss/seq after 03400 batchs: 696.5842895507812
INFO:root:Train (Epoch 160): Loss/seq after 03450 batchs: 693.5648193359375
INFO:root:Train (Epoch 160): Loss/seq after 03500 batchs: 692.9663696289062
INFO:root:Train (Epoch 160): Loss/seq after 03550 batchs: 689.1700439453125
INFO:root:Train (Epoch 160): Loss/seq after 03600 batchs: 697.4403686523438
INFO:root:Train (Epoch 160): Loss/seq after 03650 batchs: 693.8353881835938
INFO:root:Train (Epoch 160): Loss/seq after 03700 batchs: 695.201416015625
INFO:root:Train (Epoch 160): Loss/seq after 03750 batchs: 699.1947631835938
INFO:root:Train (Epoch 160): Loss/seq after 03800 batchs: 695.6070556640625
INFO:root:Train (Epoch 160): Loss/seq after 03850 batchs: 694.8265380859375
INFO:root:Train (Epoch 160): Loss/seq after 03900 batchs: 698.38720703125
INFO:root:Train (Epoch 160): Loss/seq after 03950 batchs: 702.20068359375
INFO:root:Train (Epoch 160): Loss/seq after 04000 batchs: 697.572265625
INFO:root:Train (Epoch 160): Loss/seq after 04050 batchs: 692.7608642578125
INFO:root:Train (Epoch 160): Loss/seq after 04100 batchs: 689.917236328125
INFO:root:Train (Epoch 160): Loss/seq after 04150 batchs: 688.949951171875
INFO:root:Train (Epoch 160): Loss/seq after 04200 batchs: 686.1492919921875
INFO:root:Train (Epoch 160): Loss/seq after 04250 batchs: 683.6680908203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 160): Loss/seq after 00000 batches: 590.4896240234375
INFO:root:# Valid (Epoch 160): Loss/seq after 00050 batches: 773.9515380859375
INFO:root:# Valid (Epoch 160): Loss/seq after 00100 batches: 981.4956665039062
INFO:root:# Valid (Epoch 160): Loss/seq after 00150 batches: 735.2587280273438
INFO:root:# Valid (Epoch 160): Loss/seq after 00200 batches: 669.3513793945312
INFO:root:Artifacts: Make stick videos for epoch 160
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_160_on_20220423_093942.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_160_index_826_on_20220423_093942.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 161): Loss/seq after 00000 batchs: 1354.0057373046875
INFO:root:Train (Epoch 161): Loss/seq after 00050 batchs: 939.5965576171875
INFO:root:Train (Epoch 161): Loss/seq after 00100 batchs: 943.0027465820312
INFO:root:Train (Epoch 161): Loss/seq after 00150 batchs: 836.740966796875
INFO:root:Train (Epoch 161): Loss/seq after 00200 batchs: 940.0336303710938
INFO:root:Train (Epoch 161): Loss/seq after 00250 batchs: 1058.030517578125
INFO:root:Train (Epoch 161): Loss/seq after 00300 batchs: 1037.7137451171875
INFO:root:Train (Epoch 161): Loss/seq after 00350 batchs: 970.16552734375
INFO:root:Train (Epoch 161): Loss/seq after 00400 batchs: 980.38623046875
INFO:root:Train (Epoch 161): Loss/seq after 00450 batchs: 952.4334106445312
INFO:root:Train (Epoch 161): Loss/seq after 00500 batchs: 927.1483154296875
INFO:root:Train (Epoch 161): Loss/seq after 00550 batchs: 895.7263793945312
INFO:root:Train (Epoch 161): Loss/seq after 00600 batchs: 862.4833984375
INFO:root:Train (Epoch 161): Loss/seq after 00650 batchs: 851.72216796875
INFO:root:Train (Epoch 161): Loss/seq after 00700 batchs: 825.9281005859375
INFO:root:Train (Epoch 161): Loss/seq after 00750 batchs: 840.4699096679688
INFO:root:Train (Epoch 161): Loss/seq after 00800 batchs: 835.3527221679688
INFO:root:Train (Epoch 161): Loss/seq after 00850 batchs: 809.6597900390625
INFO:root:Train (Epoch 161): Loss/seq after 00900 batchs: 791.6998291015625
INFO:root:Train (Epoch 161): Loss/seq after 00950 batchs: 796.418701171875
INFO:root:Train (Epoch 161): Loss/seq after 01000 batchs: 790.0350341796875
INFO:root:Train (Epoch 161): Loss/seq after 01050 batchs: 775.9402465820312
INFO:root:Train (Epoch 161): Loss/seq after 01100 batchs: 763.8508911132812
INFO:root:Train (Epoch 161): Loss/seq after 01150 batchs: 747.0687866210938
INFO:root:Train (Epoch 161): Loss/seq after 01200 batchs: 748.8240966796875
INFO:root:Train (Epoch 161): Loss/seq after 01250 batchs: 745.1948852539062
INFO:root:Train (Epoch 161): Loss/seq after 01300 batchs: 734.33544921875
INFO:root:Train (Epoch 161): Loss/seq after 01350 batchs: 724.7496337890625
INFO:root:Train (Epoch 161): Loss/seq after 01400 batchs: 729.4823608398438
INFO:root:Train (Epoch 161): Loss/seq after 01450 batchs: 729.041015625
INFO:root:Train (Epoch 161): Loss/seq after 01500 batchs: 732.6240844726562
INFO:root:Train (Epoch 161): Loss/seq after 01550 batchs: 735.7244873046875
INFO:root:Train (Epoch 161): Loss/seq after 01600 batchs: 728.3377075195312
INFO:root:Train (Epoch 161): Loss/seq after 01650 batchs: 723.75048828125
INFO:root:Train (Epoch 161): Loss/seq after 01700 batchs: 723.99462890625
INFO:root:Train (Epoch 161): Loss/seq after 01750 batchs: 719.9151000976562
INFO:root:Train (Epoch 161): Loss/seq after 01800 batchs: 715.1303100585938
INFO:root:Train (Epoch 161): Loss/seq after 01850 batchs: 709.1641845703125
INFO:root:Train (Epoch 161): Loss/seq after 01900 batchs: 709.33154296875
INFO:root:Train (Epoch 161): Loss/seq after 01950 batchs: 706.2401123046875
INFO:root:Train (Epoch 161): Loss/seq after 02000 batchs: 703.8380126953125
INFO:root:Train (Epoch 161): Loss/seq after 02050 batchs: 701.0752563476562
INFO:root:Train (Epoch 161): Loss/seq after 02100 batchs: 696.9388427734375
INFO:root:Train (Epoch 161): Loss/seq after 02150 batchs: 693.9290771484375
INFO:root:Train (Epoch 161): Loss/seq after 02200 batchs: 689.4957885742188
INFO:root:Train (Epoch 161): Loss/seq after 02250 batchs: 689.1128540039062
INFO:root:Train (Epoch 161): Loss/seq after 02300 batchs: 689.3432006835938
INFO:root:Train (Epoch 161): Loss/seq after 02350 batchs: 683.1818237304688
INFO:root:Train (Epoch 161): Loss/seq after 02400 batchs: 682.8248901367188
INFO:root:Train (Epoch 161): Loss/seq after 02450 batchs: 676.9160766601562
INFO:root:Train (Epoch 161): Loss/seq after 02500 batchs: 666.9840087890625
INFO:root:Train (Epoch 161): Loss/seq after 02550 batchs: 660.24462890625
INFO:root:Train (Epoch 161): Loss/seq after 02600 batchs: 660.2073364257812
INFO:root:Train (Epoch 161): Loss/seq after 02650 batchs: 658.0382080078125
INFO:root:Train (Epoch 161): Loss/seq after 02700 batchs: 655.373779296875
INFO:root:Train (Epoch 161): Loss/seq after 02750 batchs: 667.5126953125
INFO:root:Train (Epoch 161): Loss/seq after 02800 batchs: 670.7098999023438
INFO:root:Train (Epoch 161): Loss/seq after 02850 batchs: 670.7803344726562
INFO:root:Train (Epoch 161): Loss/seq after 02900 batchs: 671.8916015625
INFO:root:Train (Epoch 161): Loss/seq after 02950 batchs: 669.7319946289062
INFO:root:Train (Epoch 161): Loss/seq after 03000 batchs: 673.6552734375
INFO:root:Train (Epoch 161): Loss/seq after 03050 batchs: 679.3975830078125
INFO:root:Train (Epoch 161): Loss/seq after 03100 batchs: 683.1669311523438
INFO:root:Train (Epoch 161): Loss/seq after 03150 batchs: 688.849609375
INFO:root:Train (Epoch 161): Loss/seq after 03200 batchs: 692.657470703125
INFO:root:Train (Epoch 161): Loss/seq after 03250 batchs: 695.7026977539062
INFO:root:Train (Epoch 161): Loss/seq after 03300 batchs: 694.7635498046875
INFO:root:Train (Epoch 161): Loss/seq after 03350 batchs: 694.8221435546875
INFO:root:Train (Epoch 161): Loss/seq after 03400 batchs: 689.400390625
INFO:root:Train (Epoch 161): Loss/seq after 03450 batchs: 686.191650390625
INFO:root:Train (Epoch 161): Loss/seq after 03500 batchs: 685.556884765625
INFO:root:Train (Epoch 161): Loss/seq after 03550 batchs: 681.7564697265625
INFO:root:Train (Epoch 161): Loss/seq after 03600 batchs: 689.6927490234375
INFO:root:Train (Epoch 161): Loss/seq after 03650 batchs: 686.1599731445312
INFO:root:Train (Epoch 161): Loss/seq after 03700 batchs: 687.6099243164062
INFO:root:Train (Epoch 161): Loss/seq after 03750 batchs: 691.5753173828125
INFO:root:Train (Epoch 161): Loss/seq after 03800 batchs: 688.0231323242188
INFO:root:Train (Epoch 161): Loss/seq after 03850 batchs: 687.0559692382812
INFO:root:Train (Epoch 161): Loss/seq after 03900 batchs: 690.6670532226562
INFO:root:Train (Epoch 161): Loss/seq after 03950 batchs: 693.8710327148438
INFO:root:Train (Epoch 161): Loss/seq after 04000 batchs: 689.2838134765625
INFO:root:Train (Epoch 161): Loss/seq after 04050 batchs: 684.6031494140625
INFO:root:Train (Epoch 161): Loss/seq after 04100 batchs: 681.9172973632812
INFO:root:Train (Epoch 161): Loss/seq after 04150 batchs: 680.8190307617188
INFO:root:Train (Epoch 161): Loss/seq after 04200 batchs: 678.3528442382812
INFO:root:Train (Epoch 161): Loss/seq after 04250 batchs: 675.9766845703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 161): Loss/seq after 00000 batches: 592.334716796875
INFO:root:# Valid (Epoch 161): Loss/seq after 00050 batches: 763.7925415039062
INFO:root:# Valid (Epoch 161): Loss/seq after 00100 batches: 1020.6959228515625
INFO:root:# Valid (Epoch 161): Loss/seq after 00150 batches: 754.8762817382812
INFO:root:# Valid (Epoch 161): Loss/seq after 00200 batches: 677.6976928710938
INFO:root:Artifacts: Make stick videos for epoch 161
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_161_on_20220423_094431.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_161_index_1711_on_20220423_094431.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 162): Loss/seq after 00000 batchs: 1374.0562744140625
INFO:root:Train (Epoch 162): Loss/seq after 00050 batchs: 947.9592895507812
INFO:root:Train (Epoch 162): Loss/seq after 00100 batchs: 950.9331665039062
INFO:root:Train (Epoch 162): Loss/seq after 00150 batchs: 846.3120727539062
INFO:root:Train (Epoch 162): Loss/seq after 00200 batchs: 949.57373046875
INFO:root:Train (Epoch 162): Loss/seq after 00250 batchs: 1061.1318359375
INFO:root:Train (Epoch 162): Loss/seq after 00300 batchs: 1038.5186767578125
INFO:root:Train (Epoch 162): Loss/seq after 00350 batchs: 968.3961791992188
INFO:root:Train (Epoch 162): Loss/seq after 00400 batchs: 979.0438232421875
INFO:root:Train (Epoch 162): Loss/seq after 00450 batchs: 950.3466796875
INFO:root:Train (Epoch 162): Loss/seq after 00500 batchs: 929.2698974609375
INFO:root:Train (Epoch 162): Loss/seq after 00550 batchs: 898.3275146484375
INFO:root:Train (Epoch 162): Loss/seq after 00600 batchs: 865.6719970703125
INFO:root:Train (Epoch 162): Loss/seq after 00650 batchs: 856.7529907226562
INFO:root:Train (Epoch 162): Loss/seq after 00700 batchs: 833.9295654296875
INFO:root:Train (Epoch 162): Loss/seq after 00750 batchs: 848.8441772460938
INFO:root:Train (Epoch 162): Loss/seq after 00800 batchs: 842.8462524414062
INFO:root:Train (Epoch 162): Loss/seq after 00850 batchs: 816.7182006835938
INFO:root:Train (Epoch 162): Loss/seq after 00900 batchs: 799.1145629882812
INFO:root:Train (Epoch 162): Loss/seq after 00950 batchs: 801.4619750976562
INFO:root:Train (Epoch 162): Loss/seq after 01000 batchs: 793.3252563476562
INFO:root:Train (Epoch 162): Loss/seq after 01050 batchs: 778.2589111328125
INFO:root:Train (Epoch 162): Loss/seq after 01100 batchs: 764.6734619140625
INFO:root:Train (Epoch 162): Loss/seq after 01150 batchs: 746.8490600585938
INFO:root:Train (Epoch 162): Loss/seq after 01200 batchs: 747.7049560546875
INFO:root:Train (Epoch 162): Loss/seq after 01250 batchs: 744.00146484375
INFO:root:Train (Epoch 162): Loss/seq after 01300 batchs: 732.5513916015625
INFO:root:Train (Epoch 162): Loss/seq after 01350 batchs: 722.778076171875
INFO:root:Train (Epoch 162): Loss/seq after 01400 batchs: 730.3074340820312
INFO:root:Train (Epoch 162): Loss/seq after 01450 batchs: 730.0489501953125
INFO:root:Train (Epoch 162): Loss/seq after 01500 batchs: 733.255859375
INFO:root:Train (Epoch 162): Loss/seq after 01550 batchs: 736.5131225585938
INFO:root:Train (Epoch 162): Loss/seq after 01600 batchs: 728.7578125
INFO:root:Train (Epoch 162): Loss/seq after 01650 batchs: 723.99658203125
INFO:root:Train (Epoch 162): Loss/seq after 01700 batchs: 723.9207763671875
INFO:root:Train (Epoch 162): Loss/seq after 01750 batchs: 719.8341064453125
INFO:root:Train (Epoch 162): Loss/seq after 01800 batchs: 715.1106567382812
INFO:root:Train (Epoch 162): Loss/seq after 01850 batchs: 708.885009765625
INFO:root:Train (Epoch 162): Loss/seq after 01900 batchs: 709.1155395507812
INFO:root:Train (Epoch 162): Loss/seq after 01950 batchs: 706.2254638671875
INFO:root:Train (Epoch 162): Loss/seq after 02000 batchs: 703.3717041015625
INFO:root:Train (Epoch 162): Loss/seq after 02050 batchs: 700.3457641601562
INFO:root:Train (Epoch 162): Loss/seq after 02100 batchs: 696.3535766601562
INFO:root:Train (Epoch 162): Loss/seq after 02150 batchs: 693.6544189453125
INFO:root:Train (Epoch 162): Loss/seq after 02200 batchs: 689.4046630859375
INFO:root:Train (Epoch 162): Loss/seq after 02250 batchs: 688.725830078125
INFO:root:Train (Epoch 162): Loss/seq after 02300 batchs: 690.1856079101562
INFO:root:Train (Epoch 162): Loss/seq after 02350 batchs: 684.1255493164062
INFO:root:Train (Epoch 162): Loss/seq after 02400 batchs: 683.807373046875
INFO:root:Train (Epoch 162): Loss/seq after 02450 batchs: 678.003662109375
INFO:root:Train (Epoch 162): Loss/seq after 02500 batchs: 667.8936157226562
INFO:root:Train (Epoch 162): Loss/seq after 02550 batchs: 661.4196166992188
INFO:root:Train (Epoch 162): Loss/seq after 02600 batchs: 661.5438232421875
INFO:root:Train (Epoch 162): Loss/seq after 02650 batchs: 659.1724853515625
INFO:root:Train (Epoch 162): Loss/seq after 02700 batchs: 657.3883666992188
INFO:root:Train (Epoch 162): Loss/seq after 02750 batchs: 670.89599609375
INFO:root:Train (Epoch 162): Loss/seq after 02800 batchs: 673.869873046875
INFO:root:Train (Epoch 162): Loss/seq after 02850 batchs: 673.104248046875
INFO:root:Train (Epoch 162): Loss/seq after 02900 batchs: 674.298828125
INFO:root:Train (Epoch 162): Loss/seq after 02950 batchs: 672.130615234375
INFO:root:Train (Epoch 162): Loss/seq after 03000 batchs: 676.037109375
INFO:root:Train (Epoch 162): Loss/seq after 03050 batchs: 681.6001586914062
INFO:root:Train (Epoch 162): Loss/seq after 03100 batchs: 686.2120971679688
INFO:root:Train (Epoch 162): Loss/seq after 03150 batchs: 692.4412231445312
INFO:root:Train (Epoch 162): Loss/seq after 03200 batchs: 695.4680786132812
INFO:root:Train (Epoch 162): Loss/seq after 03250 batchs: 698.17822265625
INFO:root:Train (Epoch 162): Loss/seq after 03300 batchs: 697.104248046875
INFO:root:Train (Epoch 162): Loss/seq after 03350 batchs: 696.6149291992188
INFO:root:Train (Epoch 162): Loss/seq after 03400 batchs: 691.1698608398438
INFO:root:Train (Epoch 162): Loss/seq after 03450 batchs: 688.2371215820312
INFO:root:Train (Epoch 162): Loss/seq after 03500 batchs: 687.3553466796875
INFO:root:Train (Epoch 162): Loss/seq after 03550 batchs: 683.580810546875
INFO:root:Train (Epoch 162): Loss/seq after 03600 batchs: 691.607666015625
INFO:root:Train (Epoch 162): Loss/seq after 03650 batchs: 688.1155395507812
INFO:root:Train (Epoch 162): Loss/seq after 03700 batchs: 689.4476928710938
INFO:root:Train (Epoch 162): Loss/seq after 03750 batchs: 693.4385986328125
INFO:root:Train (Epoch 162): Loss/seq after 03800 batchs: 689.7791748046875
INFO:root:Train (Epoch 162): Loss/seq after 03850 batchs: 688.7948608398438
INFO:root:Train (Epoch 162): Loss/seq after 03900 batchs: 692.435791015625
INFO:root:Train (Epoch 162): Loss/seq after 03950 batchs: 695.8171997070312
INFO:root:Train (Epoch 162): Loss/seq after 04000 batchs: 691.1951904296875
INFO:root:Train (Epoch 162): Loss/seq after 04050 batchs: 686.5428466796875
INFO:root:Train (Epoch 162): Loss/seq after 04100 batchs: 683.7628784179688
INFO:root:Train (Epoch 162): Loss/seq after 04150 batchs: 682.7409057617188
INFO:root:Train (Epoch 162): Loss/seq after 04200 batchs: 680.1019287109375
INFO:root:Train (Epoch 162): Loss/seq after 04250 batchs: 677.5819702148438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 162): Loss/seq after 00000 batches: 548.2944946289062
INFO:root:# Valid (Epoch 162): Loss/seq after 00050 batches: 753.3200073242188
INFO:root:# Valid (Epoch 162): Loss/seq after 00100 batches: 1035.699462890625
INFO:root:# Valid (Epoch 162): Loss/seq after 00150 batches: 768.1781616210938
INFO:root:# Valid (Epoch 162): Loss/seq after 00200 batches: 689.9076538085938
INFO:root:Artifacts: Make stick videos for epoch 162
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_162_on_20220423_094922.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_162_index_398_on_20220423_094922.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 163): Loss/seq after 00000 batchs: 1315.56689453125
INFO:root:Train (Epoch 163): Loss/seq after 00050 batchs: 963.5668334960938
INFO:root:Train (Epoch 163): Loss/seq after 00100 batchs: 938.4487915039062
INFO:root:Train (Epoch 163): Loss/seq after 00150 batchs: 833.3605346679688
INFO:root:Train (Epoch 163): Loss/seq after 00200 batchs: 929.8403930664062
INFO:root:Train (Epoch 163): Loss/seq after 00250 batchs: 1043.224365234375
INFO:root:Train (Epoch 163): Loss/seq after 00300 batchs: 1024.29296875
INFO:root:Train (Epoch 163): Loss/seq after 00350 batchs: 955.9303588867188
INFO:root:Train (Epoch 163): Loss/seq after 00400 batchs: 966.5859985351562
INFO:root:Train (Epoch 163): Loss/seq after 00450 batchs: 938.3334350585938
INFO:root:Train (Epoch 163): Loss/seq after 00500 batchs: 912.454833984375
INFO:root:Train (Epoch 163): Loss/seq after 00550 batchs: 881.4089965820312
INFO:root:Train (Epoch 163): Loss/seq after 00600 batchs: 848.7727661132812
INFO:root:Train (Epoch 163): Loss/seq after 00650 batchs: 838.2493286132812
INFO:root:Train (Epoch 163): Loss/seq after 00700 batchs: 815.9337768554688
INFO:root:Train (Epoch 163): Loss/seq after 00750 batchs: 833.6531982421875
INFO:root:Train (Epoch 163): Loss/seq after 00800 batchs: 829.3657836914062
INFO:root:Train (Epoch 163): Loss/seq after 00850 batchs: 804.6676025390625
INFO:root:Train (Epoch 163): Loss/seq after 00900 batchs: 789.0095825195312
INFO:root:Train (Epoch 163): Loss/seq after 00950 batchs: 792.2371215820312
INFO:root:Train (Epoch 163): Loss/seq after 01000 batchs: 784.2139892578125
INFO:root:Train (Epoch 163): Loss/seq after 01050 batchs: 769.4107666015625
INFO:root:Train (Epoch 163): Loss/seq after 01100 batchs: 757.1346435546875
INFO:root:Train (Epoch 163): Loss/seq after 01150 batchs: 740.1561279296875
INFO:root:Train (Epoch 163): Loss/seq after 01200 batchs: 741.4157104492188
INFO:root:Train (Epoch 163): Loss/seq after 01250 batchs: 737.9854125976562
INFO:root:Train (Epoch 163): Loss/seq after 01300 batchs: 726.1619873046875
INFO:root:Train (Epoch 163): Loss/seq after 01350 batchs: 717.9066772460938
INFO:root:Train (Epoch 163): Loss/seq after 01400 batchs: 724.3952026367188
INFO:root:Train (Epoch 163): Loss/seq after 01450 batchs: 724.081298828125
INFO:root:Train (Epoch 163): Loss/seq after 01500 batchs: 727.6697387695312
INFO:root:Train (Epoch 163): Loss/seq after 01550 batchs: 730.0775756835938
INFO:root:Train (Epoch 163): Loss/seq after 01600 batchs: 722.7369384765625
INFO:root:Train (Epoch 163): Loss/seq after 01650 batchs: 718.1080322265625
INFO:root:Train (Epoch 163): Loss/seq after 01700 batchs: 717.9910278320312
INFO:root:Train (Epoch 163): Loss/seq after 01750 batchs: 714.078857421875
INFO:root:Train (Epoch 163): Loss/seq after 01800 batchs: 709.631103515625
INFO:root:Train (Epoch 163): Loss/seq after 01850 batchs: 703.338134765625
INFO:root:Train (Epoch 163): Loss/seq after 01900 batchs: 703.31884765625
INFO:root:Train (Epoch 163): Loss/seq after 01950 batchs: 700.7059326171875
INFO:root:Train (Epoch 163): Loss/seq after 02000 batchs: 698.0647583007812
INFO:root:Train (Epoch 163): Loss/seq after 02050 batchs: 694.9834594726562
INFO:root:Train (Epoch 163): Loss/seq after 02100 batchs: 690.685546875
INFO:root:Train (Epoch 163): Loss/seq after 02150 batchs: 687.6138305664062
INFO:root:Train (Epoch 163): Loss/seq after 02200 batchs: 683.1136474609375
INFO:root:Train (Epoch 163): Loss/seq after 02250 batchs: 683.1786499023438
INFO:root:Train (Epoch 163): Loss/seq after 02300 batchs: 683.197021484375
INFO:root:Train (Epoch 163): Loss/seq after 02350 batchs: 677.2235107421875
INFO:root:Train (Epoch 163): Loss/seq after 02400 batchs: 677.1994018554688
INFO:root:Train (Epoch 163): Loss/seq after 02450 batchs: 671.4298706054688
INFO:root:Train (Epoch 163): Loss/seq after 02500 batchs: 661.4777221679688
INFO:root:Train (Epoch 163): Loss/seq after 02550 batchs: 654.919677734375
INFO:root:Train (Epoch 163): Loss/seq after 02600 batchs: 655.0264892578125
INFO:root:Train (Epoch 163): Loss/seq after 02650 batchs: 652.6632080078125
INFO:root:Train (Epoch 163): Loss/seq after 02700 batchs: 649.9464721679688
INFO:root:Train (Epoch 163): Loss/seq after 02750 batchs: 664.2777709960938
INFO:root:Train (Epoch 163): Loss/seq after 02800 batchs: 665.8629150390625
INFO:root:Train (Epoch 163): Loss/seq after 02850 batchs: 665.7341918945312
INFO:root:Train (Epoch 163): Loss/seq after 02900 batchs: 666.5559692382812
INFO:root:Train (Epoch 163): Loss/seq after 02950 batchs: 664.30029296875
INFO:root:Train (Epoch 163): Loss/seq after 03000 batchs: 668.3068237304688
INFO:root:Train (Epoch 163): Loss/seq after 03050 batchs: 672.7522583007812
INFO:root:Train (Epoch 163): Loss/seq after 03100 batchs: 676.447265625
INFO:root:Train (Epoch 163): Loss/seq after 03150 batchs: 681.6256713867188
INFO:root:Train (Epoch 163): Loss/seq after 03200 batchs: 683.9234619140625
INFO:root:Train (Epoch 163): Loss/seq after 03250 batchs: 686.9691772460938
INFO:root:Train (Epoch 163): Loss/seq after 03300 batchs: 686.5075073242188
INFO:root:Train (Epoch 163): Loss/seq after 03350 batchs: 686.4467163085938
INFO:root:Train (Epoch 163): Loss/seq after 03400 batchs: 681.26220703125
INFO:root:Train (Epoch 163): Loss/seq after 03450 batchs: 678.5548706054688
INFO:root:Train (Epoch 163): Loss/seq after 03500 batchs: 678.2826538085938
INFO:root:Train (Epoch 163): Loss/seq after 03550 batchs: 674.46435546875
INFO:root:Train (Epoch 163): Loss/seq after 03600 batchs: 682.4620971679688
INFO:root:Train (Epoch 163): Loss/seq after 03650 batchs: 678.9835205078125
INFO:root:Train (Epoch 163): Loss/seq after 03700 batchs: 680.6717529296875
INFO:root:Train (Epoch 163): Loss/seq after 03750 batchs: 684.8045043945312
INFO:root:Train (Epoch 163): Loss/seq after 03800 batchs: 681.3470458984375
INFO:root:Train (Epoch 163): Loss/seq after 03850 batchs: 680.5745849609375
INFO:root:Train (Epoch 163): Loss/seq after 03900 batchs: 684.4366455078125
INFO:root:Train (Epoch 163): Loss/seq after 03950 batchs: 687.9237060546875
INFO:root:Train (Epoch 163): Loss/seq after 04000 batchs: 683.28125
INFO:root:Train (Epoch 163): Loss/seq after 04050 batchs: 678.6282348632812
INFO:root:Train (Epoch 163): Loss/seq after 04100 batchs: 675.9118041992188
INFO:root:Train (Epoch 163): Loss/seq after 04150 batchs: 674.892333984375
INFO:root:Train (Epoch 163): Loss/seq after 04200 batchs: 672.389892578125
INFO:root:Train (Epoch 163): Loss/seq after 04250 batchs: 669.96142578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 163): Loss/seq after 00000 batches: 583.426025390625
INFO:root:# Valid (Epoch 163): Loss/seq after 00050 batches: 736.56201171875
INFO:root:# Valid (Epoch 163): Loss/seq after 00100 batches: 971.7534790039062
INFO:root:# Valid (Epoch 163): Loss/seq after 00150 batches: 724.3697509765625
INFO:root:# Valid (Epoch 163): Loss/seq after 00200 batches: 658.2052001953125
INFO:root:Artifacts: Make stick videos for epoch 163
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_163_on_20220423_095411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_163_index_935_on_20220423_095411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 164): Loss/seq after 00000 batchs: 1285.22412109375
INFO:root:Train (Epoch 164): Loss/seq after 00050 batchs: 916.6622314453125
INFO:root:Train (Epoch 164): Loss/seq after 00100 batchs: 917.8605346679688
INFO:root:Train (Epoch 164): Loss/seq after 00150 batchs: 815.9790649414062
INFO:root:Train (Epoch 164): Loss/seq after 00200 batchs: 912.4603881835938
INFO:root:Train (Epoch 164): Loss/seq after 00250 batchs: 1026.0390625
INFO:root:Train (Epoch 164): Loss/seq after 00300 batchs: 1008.6138916015625
INFO:root:Train (Epoch 164): Loss/seq after 00350 batchs: 941.8353881835938
INFO:root:Train (Epoch 164): Loss/seq after 00400 batchs: 951.2427978515625
INFO:root:Train (Epoch 164): Loss/seq after 00450 batchs: 926.2711181640625
INFO:root:Train (Epoch 164): Loss/seq after 00500 batchs: 900.5293579101562
INFO:root:Train (Epoch 164): Loss/seq after 00550 batchs: 870.4780883789062
INFO:root:Train (Epoch 164): Loss/seq after 00600 batchs: 838.6752319335938
INFO:root:Train (Epoch 164): Loss/seq after 00650 batchs: 829.7723388671875
INFO:root:Train (Epoch 164): Loss/seq after 00700 batchs: 805.7089233398438
INFO:root:Train (Epoch 164): Loss/seq after 00750 batchs: 818.8792114257812
INFO:root:Train (Epoch 164): Loss/seq after 00800 batchs: 814.1382446289062
INFO:root:Train (Epoch 164): Loss/seq after 00850 batchs: 789.1235961914062
INFO:root:Train (Epoch 164): Loss/seq after 00900 batchs: 774.28759765625
INFO:root:Train (Epoch 164): Loss/seq after 00950 batchs: 776.61181640625
INFO:root:Train (Epoch 164): Loss/seq after 01000 batchs: 769.2481689453125
INFO:root:Train (Epoch 164): Loss/seq after 01050 batchs: 755.11474609375
INFO:root:Train (Epoch 164): Loss/seq after 01100 batchs: 742.197021484375
INFO:root:Train (Epoch 164): Loss/seq after 01150 batchs: 725.3717651367188
INFO:root:Train (Epoch 164): Loss/seq after 01200 batchs: 727.9764404296875
INFO:root:Train (Epoch 164): Loss/seq after 01250 batchs: 724.9642944335938
INFO:root:Train (Epoch 164): Loss/seq after 01300 batchs: 713.6728515625
INFO:root:Train (Epoch 164): Loss/seq after 01350 batchs: 704.1316528320312
INFO:root:Train (Epoch 164): Loss/seq after 01400 batchs: 709.631103515625
INFO:root:Train (Epoch 164): Loss/seq after 01450 batchs: 709.538818359375
INFO:root:Train (Epoch 164): Loss/seq after 01500 batchs: 713.6051025390625
INFO:root:Train (Epoch 164): Loss/seq after 01550 batchs: 716.8253173828125
INFO:root:Train (Epoch 164): Loss/seq after 01600 batchs: 709.4171142578125
INFO:root:Train (Epoch 164): Loss/seq after 01650 batchs: 704.5991821289062
INFO:root:Train (Epoch 164): Loss/seq after 01700 batchs: 704.982177734375
INFO:root:Train (Epoch 164): Loss/seq after 01750 batchs: 701.297119140625
INFO:root:Train (Epoch 164): Loss/seq after 01800 batchs: 696.7291870117188
INFO:root:Train (Epoch 164): Loss/seq after 01850 batchs: 690.9856567382812
INFO:root:Train (Epoch 164): Loss/seq after 01900 batchs: 691.4925537109375
INFO:root:Train (Epoch 164): Loss/seq after 01950 batchs: 688.8746948242188
INFO:root:Train (Epoch 164): Loss/seq after 02000 batchs: 686.3473510742188
INFO:root:Train (Epoch 164): Loss/seq after 02050 batchs: 683.5721435546875
INFO:root:Train (Epoch 164): Loss/seq after 02100 batchs: 679.4718627929688
INFO:root:Train (Epoch 164): Loss/seq after 02150 batchs: 676.874755859375
INFO:root:Train (Epoch 164): Loss/seq after 02200 batchs: 672.4793090820312
INFO:root:Train (Epoch 164): Loss/seq after 02250 batchs: 671.8540649414062
INFO:root:Train (Epoch 164): Loss/seq after 02300 batchs: 672.7069702148438
INFO:root:Train (Epoch 164): Loss/seq after 02350 batchs: 666.6954956054688
INFO:root:Train (Epoch 164): Loss/seq after 02400 batchs: 666.8362426757812
INFO:root:Train (Epoch 164): Loss/seq after 02450 batchs: 661.322509765625
INFO:root:Train (Epoch 164): Loss/seq after 02500 batchs: 651.5062255859375
INFO:root:Train (Epoch 164): Loss/seq after 02550 batchs: 645.2138671875
INFO:root:Train (Epoch 164): Loss/seq after 02600 batchs: 645.3729858398438
INFO:root:Train (Epoch 164): Loss/seq after 02650 batchs: 643.1179809570312
INFO:root:Train (Epoch 164): Loss/seq after 02700 batchs: 640.904296875
INFO:root:Train (Epoch 164): Loss/seq after 02750 batchs: 649.5467529296875
INFO:root:Train (Epoch 164): Loss/seq after 02800 batchs: 651.8384399414062
INFO:root:Train (Epoch 164): Loss/seq after 02850 batchs: 651.5999145507812
INFO:root:Train (Epoch 164): Loss/seq after 02900 batchs: 653.130615234375
INFO:root:Train (Epoch 164): Loss/seq after 02950 batchs: 651.2804565429688
INFO:root:Train (Epoch 164): Loss/seq after 03000 batchs: 655.4266967773438
INFO:root:Train (Epoch 164): Loss/seq after 03050 batchs: 659.3712158203125
INFO:root:Train (Epoch 164): Loss/seq after 03100 batchs: 663.34228515625
INFO:root:Train (Epoch 164): Loss/seq after 03150 batchs: 669.9711303710938
INFO:root:Train (Epoch 164): Loss/seq after 03200 batchs: 672.773681640625
INFO:root:Train (Epoch 164): Loss/seq after 03250 batchs: 675.4793701171875
INFO:root:Train (Epoch 164): Loss/seq after 03300 batchs: 674.4713745117188
INFO:root:Train (Epoch 164): Loss/seq after 03350 batchs: 674.3656005859375
INFO:root:Train (Epoch 164): Loss/seq after 03400 batchs: 669.1900024414062
INFO:root:Train (Epoch 164): Loss/seq after 03450 batchs: 666.2099609375
INFO:root:Train (Epoch 164): Loss/seq after 03500 batchs: 665.6965942382812
INFO:root:Train (Epoch 164): Loss/seq after 03550 batchs: 662.0494995117188
INFO:root:Train (Epoch 164): Loss/seq after 03600 batchs: 670.5294799804688
INFO:root:Train (Epoch 164): Loss/seq after 03650 batchs: 667.1786499023438
INFO:root:Train (Epoch 164): Loss/seq after 03700 batchs: 668.8267211914062
INFO:root:Train (Epoch 164): Loss/seq after 03750 batchs: 672.8909301757812
INFO:root:Train (Epoch 164): Loss/seq after 03800 batchs: 669.5402221679688
INFO:root:Train (Epoch 164): Loss/seq after 03850 batchs: 668.5452270507812
INFO:root:Train (Epoch 164): Loss/seq after 03900 batchs: 672.4089965820312
INFO:root:Train (Epoch 164): Loss/seq after 03950 batchs: 675.9169311523438
INFO:root:Train (Epoch 164): Loss/seq after 04000 batchs: 671.6030883789062
INFO:root:Train (Epoch 164): Loss/seq after 04050 batchs: 667.1234130859375
INFO:root:Train (Epoch 164): Loss/seq after 04100 batchs: 664.5921630859375
INFO:root:Train (Epoch 164): Loss/seq after 04150 batchs: 663.6953125
INFO:root:Train (Epoch 164): Loss/seq after 04200 batchs: 661.2562255859375
INFO:root:Train (Epoch 164): Loss/seq after 04250 batchs: 658.9327392578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 164): Loss/seq after 00000 batches: 586.8745727539062
INFO:root:# Valid (Epoch 164): Loss/seq after 00050 batches: 732.6113891601562
INFO:root:# Valid (Epoch 164): Loss/seq after 00100 batches: 943.5411376953125
INFO:root:# Valid (Epoch 164): Loss/seq after 00150 batches: 701.9345092773438
INFO:root:# Valid (Epoch 164): Loss/seq after 00200 batches: 636.6422119140625
INFO:root:Artifacts: Make stick videos for epoch 164
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_164_on_20220423_095902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_164_index_636_on_20220423_095902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 165): Loss/seq after 00000 batchs: 1332.3302001953125
INFO:root:Train (Epoch 165): Loss/seq after 00050 batchs: 940.93798828125
INFO:root:Train (Epoch 165): Loss/seq after 00100 batchs: 920.2186279296875
INFO:root:Train (Epoch 165): Loss/seq after 00150 batchs: 819.318359375
INFO:root:Train (Epoch 165): Loss/seq after 00200 batchs: 917.3173217773438
INFO:root:Train (Epoch 165): Loss/seq after 00250 batchs: 1031.9400634765625
INFO:root:Train (Epoch 165): Loss/seq after 00300 batchs: 1014.1304931640625
INFO:root:Train (Epoch 165): Loss/seq after 00350 batchs: 946.9219970703125
INFO:root:Train (Epoch 165): Loss/seq after 00400 batchs: 957.2744140625
INFO:root:Train (Epoch 165): Loss/seq after 00450 batchs: 930.4349975585938
INFO:root:Train (Epoch 165): Loss/seq after 00500 batchs: 904.7783203125
INFO:root:Train (Epoch 165): Loss/seq after 00550 batchs: 875.3800659179688
INFO:root:Train (Epoch 165): Loss/seq after 00600 batchs: 843.7901611328125
INFO:root:Train (Epoch 165): Loss/seq after 00650 batchs: 833.7026977539062
INFO:root:Train (Epoch 165): Loss/seq after 00700 batchs: 809.493408203125
INFO:root:Train (Epoch 165): Loss/seq after 00750 batchs: 824.6598510742188
INFO:root:Train (Epoch 165): Loss/seq after 00800 batchs: 819.841796875
INFO:root:Train (Epoch 165): Loss/seq after 00850 batchs: 794.5098266601562
INFO:root:Train (Epoch 165): Loss/seq after 00900 batchs: 777.9448852539062
INFO:root:Train (Epoch 165): Loss/seq after 00950 batchs: 783.3523559570312
INFO:root:Train (Epoch 165): Loss/seq after 01000 batchs: 775.5234375
INFO:root:Train (Epoch 165): Loss/seq after 01050 batchs: 761.6502075195312
INFO:root:Train (Epoch 165): Loss/seq after 01100 batchs: 749.5452880859375
INFO:root:Train (Epoch 165): Loss/seq after 01150 batchs: 732.6554565429688
INFO:root:Train (Epoch 165): Loss/seq after 01200 batchs: 734.5640258789062
INFO:root:Train (Epoch 165): Loss/seq after 01250 batchs: 730.13134765625
INFO:root:Train (Epoch 165): Loss/seq after 01300 batchs: 718.2368774414062
INFO:root:Train (Epoch 165): Loss/seq after 01350 batchs: 708.5512084960938
INFO:root:Train (Epoch 165): Loss/seq after 01400 batchs: 714.6793212890625
INFO:root:Train (Epoch 165): Loss/seq after 01450 batchs: 714.5010986328125
INFO:root:Train (Epoch 165): Loss/seq after 01500 batchs: 718.1893920898438
INFO:root:Train (Epoch 165): Loss/seq after 01550 batchs: 720.7459716796875
INFO:root:Train (Epoch 165): Loss/seq after 01600 batchs: 713.29345703125
INFO:root:Train (Epoch 165): Loss/seq after 01650 batchs: 708.459228515625
INFO:root:Train (Epoch 165): Loss/seq after 01700 batchs: 708.80859375
INFO:root:Train (Epoch 165): Loss/seq after 01750 batchs: 705.017822265625
INFO:root:Train (Epoch 165): Loss/seq after 01800 batchs: 700.6160888671875
INFO:root:Train (Epoch 165): Loss/seq after 01850 batchs: 694.6586303710938
INFO:root:Train (Epoch 165): Loss/seq after 01900 batchs: 694.3851318359375
INFO:root:Train (Epoch 165): Loss/seq after 01950 batchs: 691.7581176757812
INFO:root:Train (Epoch 165): Loss/seq after 02000 batchs: 689.3705444335938
INFO:root:Train (Epoch 165): Loss/seq after 02050 batchs: 686.296875
INFO:root:Train (Epoch 165): Loss/seq after 02100 batchs: 682.1929931640625
INFO:root:Train (Epoch 165): Loss/seq after 02150 batchs: 679.212158203125
INFO:root:Train (Epoch 165): Loss/seq after 02200 batchs: 675.023193359375
INFO:root:Train (Epoch 165): Loss/seq after 02250 batchs: 674.671630859375
INFO:root:Train (Epoch 165): Loss/seq after 02300 batchs: 675.9171142578125
INFO:root:Train (Epoch 165): Loss/seq after 02350 batchs: 669.7429809570312
INFO:root:Train (Epoch 165): Loss/seq after 02400 batchs: 669.6866455078125
INFO:root:Train (Epoch 165): Loss/seq after 02450 batchs: 663.7792358398438
INFO:root:Train (Epoch 165): Loss/seq after 02500 batchs: 653.9771728515625
INFO:root:Train (Epoch 165): Loss/seq after 02550 batchs: 647.4760131835938
INFO:root:Train (Epoch 165): Loss/seq after 02600 batchs: 647.1846313476562
INFO:root:Train (Epoch 165): Loss/seq after 02650 batchs: 644.7664794921875
INFO:root:Train (Epoch 165): Loss/seq after 02700 batchs: 642.5299072265625
INFO:root:Train (Epoch 165): Loss/seq after 02750 batchs: 652.4922485351562
INFO:root:Train (Epoch 165): Loss/seq after 02800 batchs: 654.5128784179688
INFO:root:Train (Epoch 165): Loss/seq after 02850 batchs: 654.1204223632812
INFO:root:Train (Epoch 165): Loss/seq after 02900 batchs: 654.8084716796875
INFO:root:Train (Epoch 165): Loss/seq after 02950 batchs: 652.8570556640625
INFO:root:Train (Epoch 165): Loss/seq after 03000 batchs: 656.9962158203125
INFO:root:Train (Epoch 165): Loss/seq after 03050 batchs: 661.7766723632812
INFO:root:Train (Epoch 165): Loss/seq after 03100 batchs: 665.8252563476562
INFO:root:Train (Epoch 165): Loss/seq after 03150 batchs: 672.6737670898438
INFO:root:Train (Epoch 165): Loss/seq after 03200 batchs: 675.908935546875
INFO:root:Train (Epoch 165): Loss/seq after 03250 batchs: 678.7727661132812
INFO:root:Train (Epoch 165): Loss/seq after 03300 batchs: 678.1377563476562
INFO:root:Train (Epoch 165): Loss/seq after 03350 batchs: 678.1189575195312
INFO:root:Train (Epoch 165): Loss/seq after 03400 batchs: 672.8514404296875
INFO:root:Train (Epoch 165): Loss/seq after 03450 batchs: 670.15673828125
INFO:root:Train (Epoch 165): Loss/seq after 03500 batchs: 669.699462890625
INFO:root:Train (Epoch 165): Loss/seq after 03550 batchs: 665.9554443359375
INFO:root:Train (Epoch 165): Loss/seq after 03600 batchs: 674.12939453125
INFO:root:Train (Epoch 165): Loss/seq after 03650 batchs: 670.7719116210938
INFO:root:Train (Epoch 165): Loss/seq after 03700 batchs: 672.3641357421875
INFO:root:Train (Epoch 165): Loss/seq after 03750 batchs: 676.4471435546875
INFO:root:Train (Epoch 165): Loss/seq after 03800 batchs: 673.1024169921875
INFO:root:Train (Epoch 165): Loss/seq after 03850 batchs: 672.3035888671875
INFO:root:Train (Epoch 165): Loss/seq after 03900 batchs: 675.9456176757812
INFO:root:Train (Epoch 165): Loss/seq after 03950 batchs: 679.4437255859375
INFO:root:Train (Epoch 165): Loss/seq after 04000 batchs: 674.9420776367188
INFO:root:Train (Epoch 165): Loss/seq after 04050 batchs: 670.4230346679688
INFO:root:Train (Epoch 165): Loss/seq after 04100 batchs: 667.8418579101562
INFO:root:Train (Epoch 165): Loss/seq after 04150 batchs: 666.855712890625
INFO:root:Train (Epoch 165): Loss/seq after 04200 batchs: 664.186767578125
INFO:root:Train (Epoch 165): Loss/seq after 04250 batchs: 661.7935791015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 165): Loss/seq after 00000 batches: 515.4411010742188
INFO:root:# Valid (Epoch 165): Loss/seq after 00050 batches: 732.8342895507812
INFO:root:# Valid (Epoch 165): Loss/seq after 00100 batches: 991.1436157226562
INFO:root:# Valid (Epoch 165): Loss/seq after 00150 batches: 738.261474609375
INFO:root:# Valid (Epoch 165): Loss/seq after 00200 batches: 664.49609375
INFO:root:Artifacts: Make stick videos for epoch 165
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_165_on_20220423_100406.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_165_index_1562_on_20220423_100406.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 166): Loss/seq after 00000 batchs: 1313.53515625
INFO:root:Train (Epoch 166): Loss/seq after 00050 batchs: 927.8971557617188
INFO:root:Train (Epoch 166): Loss/seq after 00100 batchs: 933.5648193359375
INFO:root:Train (Epoch 166): Loss/seq after 00150 batchs: 824.5480346679688
INFO:root:Train (Epoch 166): Loss/seq after 00200 batchs: 918.6949462890625
INFO:root:Train (Epoch 166): Loss/seq after 00250 batchs: 1026.2479248046875
INFO:root:Train (Epoch 166): Loss/seq after 00300 batchs: 1008.3621826171875
INFO:root:Train (Epoch 166): Loss/seq after 00350 batchs: 940.065185546875
INFO:root:Train (Epoch 166): Loss/seq after 00400 batchs: 948.4745483398438
INFO:root:Train (Epoch 166): Loss/seq after 00450 batchs: 923.2206420898438
INFO:root:Train (Epoch 166): Loss/seq after 00500 batchs: 898.3544311523438
INFO:root:Train (Epoch 166): Loss/seq after 00550 batchs: 868.8425903320312
INFO:root:Train (Epoch 166): Loss/seq after 00600 batchs: 836.0830078125
INFO:root:Train (Epoch 166): Loss/seq after 00650 batchs: 827.9428100585938
INFO:root:Train (Epoch 166): Loss/seq after 00700 batchs: 804.970703125
INFO:root:Train (Epoch 166): Loss/seq after 00750 batchs: 818.4066162109375
INFO:root:Train (Epoch 166): Loss/seq after 00800 batchs: 813.6932373046875
INFO:root:Train (Epoch 166): Loss/seq after 00850 batchs: 789.0759887695312
INFO:root:Train (Epoch 166): Loss/seq after 00900 batchs: 772.22119140625
INFO:root:Train (Epoch 166): Loss/seq after 00950 batchs: 776.0240478515625
INFO:root:Train (Epoch 166): Loss/seq after 01000 batchs: 769.458251953125
INFO:root:Train (Epoch 166): Loss/seq after 01050 batchs: 755.4442749023438
INFO:root:Train (Epoch 166): Loss/seq after 01100 batchs: 742.575439453125
INFO:root:Train (Epoch 166): Loss/seq after 01150 batchs: 725.9957885742188
INFO:root:Train (Epoch 166): Loss/seq after 01200 batchs: 728.39306640625
INFO:root:Train (Epoch 166): Loss/seq after 01250 batchs: 725.0936279296875
INFO:root:Train (Epoch 166): Loss/seq after 01300 batchs: 713.36376953125
INFO:root:Train (Epoch 166): Loss/seq after 01350 batchs: 704.2802124023438
INFO:root:Train (Epoch 166): Loss/seq after 01400 batchs: 709.478271484375
INFO:root:Train (Epoch 166): Loss/seq after 01450 batchs: 708.8673095703125
INFO:root:Train (Epoch 166): Loss/seq after 01500 batchs: 712.66259765625
INFO:root:Train (Epoch 166): Loss/seq after 01550 batchs: 715.650634765625
INFO:root:Train (Epoch 166): Loss/seq after 01600 batchs: 708.3486938476562
INFO:root:Train (Epoch 166): Loss/seq after 01650 batchs: 703.9207153320312
INFO:root:Train (Epoch 166): Loss/seq after 01700 batchs: 704.3134765625
INFO:root:Train (Epoch 166): Loss/seq after 01750 batchs: 700.4729614257812
INFO:root:Train (Epoch 166): Loss/seq after 01800 batchs: 696.1229248046875
INFO:root:Train (Epoch 166): Loss/seq after 01850 batchs: 690.6299438476562
INFO:root:Train (Epoch 166): Loss/seq after 01900 batchs: 691.0652465820312
INFO:root:Train (Epoch 166): Loss/seq after 01950 batchs: 688.8311157226562
INFO:root:Train (Epoch 166): Loss/seq after 02000 batchs: 686.3762817382812
INFO:root:Train (Epoch 166): Loss/seq after 02050 batchs: 683.472900390625
INFO:root:Train (Epoch 166): Loss/seq after 02100 batchs: 679.642822265625
INFO:root:Train (Epoch 166): Loss/seq after 02150 batchs: 676.5261840820312
INFO:root:Train (Epoch 166): Loss/seq after 02200 batchs: 672.1078491210938
INFO:root:Train (Epoch 166): Loss/seq after 02250 batchs: 671.0527954101562
INFO:root:Train (Epoch 166): Loss/seq after 02300 batchs: 672.17041015625
INFO:root:Train (Epoch 166): Loss/seq after 02350 batchs: 666.0117797851562
INFO:root:Train (Epoch 166): Loss/seq after 02400 batchs: 665.9066162109375
INFO:root:Train (Epoch 166): Loss/seq after 02450 batchs: 660.1643676757812
INFO:root:Train (Epoch 166): Loss/seq after 02500 batchs: 650.3850708007812
INFO:root:Train (Epoch 166): Loss/seq after 02550 batchs: 643.8660278320312
INFO:root:Train (Epoch 166): Loss/seq after 02600 batchs: 643.6765747070312
INFO:root:Train (Epoch 166): Loss/seq after 02650 batchs: 641.055908203125
INFO:root:Train (Epoch 166): Loss/seq after 02700 batchs: 638.6243286132812
INFO:root:Train (Epoch 166): Loss/seq after 02750 batchs: 646.1890258789062
INFO:root:Train (Epoch 166): Loss/seq after 02800 batchs: 647.4234619140625
INFO:root:Train (Epoch 166): Loss/seq after 02850 batchs: 647.15625
INFO:root:Train (Epoch 166): Loss/seq after 02900 batchs: 648.486083984375
INFO:root:Train (Epoch 166): Loss/seq after 02950 batchs: 646.6162719726562
INFO:root:Train (Epoch 166): Loss/seq after 03000 batchs: 650.802490234375
INFO:root:Train (Epoch 166): Loss/seq after 03050 batchs: 656.4579467773438
INFO:root:Train (Epoch 166): Loss/seq after 03100 batchs: 660.16064453125
INFO:root:Train (Epoch 166): Loss/seq after 03150 batchs: 666.16259765625
INFO:root:Train (Epoch 166): Loss/seq after 03200 batchs: 668.7340698242188
INFO:root:Train (Epoch 166): Loss/seq after 03250 batchs: 671.112548828125
INFO:root:Train (Epoch 166): Loss/seq after 03300 batchs: 670.9238891601562
INFO:root:Train (Epoch 166): Loss/seq after 03350 batchs: 670.8054809570312
INFO:root:Train (Epoch 166): Loss/seq after 03400 batchs: 665.6870727539062
INFO:root:Train (Epoch 166): Loss/seq after 03450 batchs: 663.11767578125
INFO:root:Train (Epoch 166): Loss/seq after 03500 batchs: 662.6116943359375
INFO:root:Train (Epoch 166): Loss/seq after 03550 batchs: 659.103271484375
INFO:root:Train (Epoch 166): Loss/seq after 03600 batchs: 667.2229614257812
INFO:root:Train (Epoch 166): Loss/seq after 03650 batchs: 664.1153564453125
INFO:root:Train (Epoch 166): Loss/seq after 03700 batchs: 665.7320556640625
INFO:root:Train (Epoch 166): Loss/seq after 03750 batchs: 669.8333740234375
INFO:root:Train (Epoch 166): Loss/seq after 03800 batchs: 666.4475708007812
INFO:root:Train (Epoch 166): Loss/seq after 03850 batchs: 665.6339111328125
INFO:root:Train (Epoch 166): Loss/seq after 03900 batchs: 669.3400268554688
INFO:root:Train (Epoch 166): Loss/seq after 03950 batchs: 672.4933471679688
INFO:root:Train (Epoch 166): Loss/seq after 04000 batchs: 668.1443481445312
INFO:root:Train (Epoch 166): Loss/seq after 04050 batchs: 663.59228515625
INFO:root:Train (Epoch 166): Loss/seq after 04100 batchs: 661.2617797851562
INFO:root:Train (Epoch 166): Loss/seq after 04150 batchs: 660.3487548828125
INFO:root:Train (Epoch 166): Loss/seq after 04200 batchs: 658.0022583007812
INFO:root:Train (Epoch 166): Loss/seq after 04250 batchs: 655.8528442382812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 166): Loss/seq after 00000 batches: 566.9247436523438
INFO:root:# Valid (Epoch 166): Loss/seq after 00050 batches: 738.7708740234375
INFO:root:# Valid (Epoch 166): Loss/seq after 00100 batches: 994.9204711914062
INFO:root:# Valid (Epoch 166): Loss/seq after 00150 batches: 739.1301879882812
INFO:root:# Valid (Epoch 166): Loss/seq after 00200 batches: 663.2427368164062
INFO:root:Artifacts: Make stick videos for epoch 166
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_166_on_20220423_100854.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_166_index_1653_on_20220423_100854.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 167): Loss/seq after 00000 batchs: 1319.177734375
INFO:root:Train (Epoch 167): Loss/seq after 00050 batchs: 939.1025390625
INFO:root:Train (Epoch 167): Loss/seq after 00100 batchs: 922.8265380859375
INFO:root:Train (Epoch 167): Loss/seq after 00150 batchs: 812.8449096679688
INFO:root:Train (Epoch 167): Loss/seq after 00200 batchs: 911.8439331054688
INFO:root:Train (Epoch 167): Loss/seq after 00250 batchs: 1022.8248291015625
INFO:root:Train (Epoch 167): Loss/seq after 00300 batchs: 1006.1099243164062
INFO:root:Train (Epoch 167): Loss/seq after 00350 batchs: 939.139892578125
INFO:root:Train (Epoch 167): Loss/seq after 00400 batchs: 948.9209594726562
INFO:root:Train (Epoch 167): Loss/seq after 00450 batchs: 921.8255615234375
INFO:root:Train (Epoch 167): Loss/seq after 00500 batchs: 895.9169921875
INFO:root:Train (Epoch 167): Loss/seq after 00550 batchs: 866.59765625
INFO:root:Train (Epoch 167): Loss/seq after 00600 batchs: 834.917236328125
INFO:root:Train (Epoch 167): Loss/seq after 00650 batchs: 826.6617431640625
INFO:root:Train (Epoch 167): Loss/seq after 00700 batchs: 804.1255493164062
INFO:root:Train (Epoch 167): Loss/seq after 00750 batchs: 820.1909790039062
INFO:root:Train (Epoch 167): Loss/seq after 00800 batchs: 815.3501586914062
INFO:root:Train (Epoch 167): Loss/seq after 00850 batchs: 790.2818603515625
INFO:root:Train (Epoch 167): Loss/seq after 00900 batchs: 772.9810180664062
INFO:root:Train (Epoch 167): Loss/seq after 00950 batchs: 777.29443359375
INFO:root:Train (Epoch 167): Loss/seq after 01000 batchs: 769.8994750976562
INFO:root:Train (Epoch 167): Loss/seq after 01050 batchs: 755.4661865234375
INFO:root:Train (Epoch 167): Loss/seq after 01100 batchs: 741.9964599609375
INFO:root:Train (Epoch 167): Loss/seq after 01150 batchs: 725.3959350585938
INFO:root:Train (Epoch 167): Loss/seq after 01200 batchs: 727.6226196289062
INFO:root:Train (Epoch 167): Loss/seq after 01250 batchs: 724.1751708984375
INFO:root:Train (Epoch 167): Loss/seq after 01300 batchs: 711.562744140625
INFO:root:Train (Epoch 167): Loss/seq after 01350 batchs: 701.7886962890625
INFO:root:Train (Epoch 167): Loss/seq after 01400 batchs: 708.9241943359375
INFO:root:Train (Epoch 167): Loss/seq after 01450 batchs: 708.7968139648438
INFO:root:Train (Epoch 167): Loss/seq after 01500 batchs: 712.71826171875
INFO:root:Train (Epoch 167): Loss/seq after 01550 batchs: 715.4132080078125
INFO:root:Train (Epoch 167): Loss/seq after 01600 batchs: 707.8538818359375
INFO:root:Train (Epoch 167): Loss/seq after 01650 batchs: 703.0643310546875
INFO:root:Train (Epoch 167): Loss/seq after 01700 batchs: 703.279541015625
INFO:root:Train (Epoch 167): Loss/seq after 01750 batchs: 699.7091674804688
INFO:root:Train (Epoch 167): Loss/seq after 01800 batchs: 695.52392578125
INFO:root:Train (Epoch 167): Loss/seq after 01850 batchs: 689.6917724609375
INFO:root:Train (Epoch 167): Loss/seq after 01900 batchs: 689.6166381835938
INFO:root:Train (Epoch 167): Loss/seq after 01950 batchs: 687.0173950195312
INFO:root:Train (Epoch 167): Loss/seq after 02000 batchs: 684.38037109375
INFO:root:Train (Epoch 167): Loss/seq after 02050 batchs: 681.4512939453125
INFO:root:Train (Epoch 167): Loss/seq after 02100 batchs: 677.2162475585938
INFO:root:Train (Epoch 167): Loss/seq after 02150 batchs: 674.3056030273438
INFO:root:Train (Epoch 167): Loss/seq after 02200 batchs: 669.9489135742188
INFO:root:Train (Epoch 167): Loss/seq after 02250 batchs: 669.0505981445312
INFO:root:Train (Epoch 167): Loss/seq after 02300 batchs: 669.427490234375
INFO:root:Train (Epoch 167): Loss/seq after 02350 batchs: 663.5760498046875
INFO:root:Train (Epoch 167): Loss/seq after 02400 batchs: 663.655029296875
INFO:root:Train (Epoch 167): Loss/seq after 02450 batchs: 658.01513671875
INFO:root:Train (Epoch 167): Loss/seq after 02500 batchs: 648.2421264648438
INFO:root:Train (Epoch 167): Loss/seq after 02550 batchs: 641.8876953125
INFO:root:Train (Epoch 167): Loss/seq after 02600 batchs: 641.7406005859375
INFO:root:Train (Epoch 167): Loss/seq after 02650 batchs: 639.18212890625
INFO:root:Train (Epoch 167): Loss/seq after 02700 batchs: 637.1915283203125
INFO:root:Train (Epoch 167): Loss/seq after 02750 batchs: 644.6532592773438
INFO:root:Train (Epoch 167): Loss/seq after 02800 batchs: 645.5905151367188
INFO:root:Train (Epoch 167): Loss/seq after 02850 batchs: 645.2319946289062
INFO:root:Train (Epoch 167): Loss/seq after 02900 batchs: 645.9627685546875
INFO:root:Train (Epoch 167): Loss/seq after 02950 batchs: 643.9869995117188
INFO:root:Train (Epoch 167): Loss/seq after 03000 batchs: 648.12158203125
INFO:root:Train (Epoch 167): Loss/seq after 03050 batchs: 652.65185546875
INFO:root:Train (Epoch 167): Loss/seq after 03100 batchs: 656.6417236328125
INFO:root:Train (Epoch 167): Loss/seq after 03150 batchs: 662.704345703125
INFO:root:Train (Epoch 167): Loss/seq after 03200 batchs: 665.03173828125
INFO:root:Train (Epoch 167): Loss/seq after 03250 batchs: 668.1787109375
INFO:root:Train (Epoch 167): Loss/seq after 03300 batchs: 667.3360595703125
INFO:root:Train (Epoch 167): Loss/seq after 03350 batchs: 667.2767333984375
INFO:root:Train (Epoch 167): Loss/seq after 03400 batchs: 662.1260375976562
INFO:root:Train (Epoch 167): Loss/seq after 03450 batchs: 659.3594970703125
INFO:root:Train (Epoch 167): Loss/seq after 03500 batchs: 658.692626953125
INFO:root:Train (Epoch 167): Loss/seq after 03550 batchs: 655.0353393554688
INFO:root:Train (Epoch 167): Loss/seq after 03600 batchs: 663.3541870117188
INFO:root:Train (Epoch 167): Loss/seq after 03650 batchs: 660.0960693359375
INFO:root:Train (Epoch 167): Loss/seq after 03700 batchs: 661.621826171875
INFO:root:Train (Epoch 167): Loss/seq after 03750 batchs: 665.5938720703125
INFO:root:Train (Epoch 167): Loss/seq after 03800 batchs: 662.2803344726562
INFO:root:Train (Epoch 167): Loss/seq after 03850 batchs: 661.6539306640625
INFO:root:Train (Epoch 167): Loss/seq after 03900 batchs: 665.164794921875
INFO:root:Train (Epoch 167): Loss/seq after 03950 batchs: 668.4852294921875
INFO:root:Train (Epoch 167): Loss/seq after 04000 batchs: 664.1666870117188
INFO:root:Train (Epoch 167): Loss/seq after 04050 batchs: 659.7188720703125
INFO:root:Train (Epoch 167): Loss/seq after 04100 batchs: 657.1727905273438
INFO:root:Train (Epoch 167): Loss/seq after 04150 batchs: 656.3900146484375
INFO:root:Train (Epoch 167): Loss/seq after 04200 batchs: 653.9506225585938
INFO:root:Train (Epoch 167): Loss/seq after 04250 batchs: 651.7783813476562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 167): Loss/seq after 00000 batches: 533.0784912109375
INFO:root:# Valid (Epoch 167): Loss/seq after 00050 batches: 731.14892578125
INFO:root:# Valid (Epoch 167): Loss/seq after 00100 batches: 956.2807006835938
INFO:root:# Valid (Epoch 167): Loss/seq after 00150 batches: 714.394775390625
INFO:root:# Valid (Epoch 167): Loss/seq after 00200 batches: 645.341796875
INFO:root:Artifacts: Make stick videos for epoch 167
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_167_on_20220423_101346.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_167_index_1506_on_20220423_101346.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 168): Loss/seq after 00000 batchs: 1312.7467041015625
INFO:root:Train (Epoch 168): Loss/seq after 00050 batchs: 925.0137939453125
INFO:root:Train (Epoch 168): Loss/seq after 00100 batchs: 900.8237915039062
INFO:root:Train (Epoch 168): Loss/seq after 00150 batchs: 798.5086669921875
INFO:root:Train (Epoch 168): Loss/seq after 00200 batchs: 896.05859375
INFO:root:Train (Epoch 168): Loss/seq after 00250 batchs: 1010.9385986328125
INFO:root:Train (Epoch 168): Loss/seq after 00300 batchs: 994.4607543945312
INFO:root:Train (Epoch 168): Loss/seq after 00350 batchs: 928.8814086914062
INFO:root:Train (Epoch 168): Loss/seq after 00400 batchs: 935.725341796875
INFO:root:Train (Epoch 168): Loss/seq after 00450 batchs: 910.7025756835938
INFO:root:Train (Epoch 168): Loss/seq after 00500 batchs: 890.2889404296875
INFO:root:Train (Epoch 168): Loss/seq after 00550 batchs: 861.8607788085938
INFO:root:Train (Epoch 168): Loss/seq after 00600 batchs: 830.771240234375
INFO:root:Train (Epoch 168): Loss/seq after 00650 batchs: 824.0216674804688
INFO:root:Train (Epoch 168): Loss/seq after 00700 batchs: 799.2838134765625
INFO:root:Train (Epoch 168): Loss/seq after 00750 batchs: 816.1699829101562
INFO:root:Train (Epoch 168): Loss/seq after 00800 batchs: 811.7141723632812
INFO:root:Train (Epoch 168): Loss/seq after 00850 batchs: 786.1445922851562
INFO:root:Train (Epoch 168): Loss/seq after 00900 batchs: 769.0853271484375
INFO:root:Train (Epoch 168): Loss/seq after 00950 batchs: 770.7708129882812
INFO:root:Train (Epoch 168): Loss/seq after 01000 batchs: 764.0560302734375
INFO:root:Train (Epoch 168): Loss/seq after 01050 batchs: 750.6874389648438
INFO:root:Train (Epoch 168): Loss/seq after 01100 batchs: 738.386474609375
INFO:root:Train (Epoch 168): Loss/seq after 01150 batchs: 722.008544921875
INFO:root:Train (Epoch 168): Loss/seq after 01200 batchs: 723.3973999023438
INFO:root:Train (Epoch 168): Loss/seq after 01250 batchs: 719.97802734375
INFO:root:Train (Epoch 168): Loss/seq after 01300 batchs: 708.76171875
INFO:root:Train (Epoch 168): Loss/seq after 01350 batchs: 698.9856567382812
INFO:root:Train (Epoch 168): Loss/seq after 01400 batchs: 705.9901733398438
INFO:root:Train (Epoch 168): Loss/seq after 01450 batchs: 705.787353515625
INFO:root:Train (Epoch 168): Loss/seq after 01500 batchs: 709.3541259765625
INFO:root:Train (Epoch 168): Loss/seq after 01550 batchs: 711.72998046875
INFO:root:Train (Epoch 168): Loss/seq after 01600 batchs: 704.5806274414062
INFO:root:Train (Epoch 168): Loss/seq after 01650 batchs: 699.8267211914062
INFO:root:Train (Epoch 168): Loss/seq after 01700 batchs: 699.8320922851562
INFO:root:Train (Epoch 168): Loss/seq after 01750 batchs: 695.68994140625
INFO:root:Train (Epoch 168): Loss/seq after 01800 batchs: 691.4027709960938
INFO:root:Train (Epoch 168): Loss/seq after 01850 batchs: 685.6788940429688
INFO:root:Train (Epoch 168): Loss/seq after 01900 batchs: 685.8803100585938
INFO:root:Train (Epoch 168): Loss/seq after 01950 batchs: 683.2546997070312
INFO:root:Train (Epoch 168): Loss/seq after 02000 batchs: 680.6497802734375
INFO:root:Train (Epoch 168): Loss/seq after 02050 batchs: 677.8108520507812
INFO:root:Train (Epoch 168): Loss/seq after 02100 batchs: 673.9461059570312
INFO:root:Train (Epoch 168): Loss/seq after 02150 batchs: 671.0662231445312
INFO:root:Train (Epoch 168): Loss/seq after 02200 batchs: 666.8717041015625
INFO:root:Train (Epoch 168): Loss/seq after 02250 batchs: 666.2552490234375
INFO:root:Train (Epoch 168): Loss/seq after 02300 batchs: 666.3703002929688
INFO:root:Train (Epoch 168): Loss/seq after 02350 batchs: 660.3079833984375
INFO:root:Train (Epoch 168): Loss/seq after 02400 batchs: 660.502197265625
INFO:root:Train (Epoch 168): Loss/seq after 02450 batchs: 654.7982177734375
INFO:root:Train (Epoch 168): Loss/seq after 02500 batchs: 644.9930419921875
INFO:root:Train (Epoch 168): Loss/seq after 02550 batchs: 638.48828125
INFO:root:Train (Epoch 168): Loss/seq after 02600 batchs: 638.364013671875
INFO:root:Train (Epoch 168): Loss/seq after 02650 batchs: 635.843505859375
INFO:root:Train (Epoch 168): Loss/seq after 02700 batchs: 633.8557739257812
INFO:root:Train (Epoch 168): Loss/seq after 02750 batchs: 639.96533203125
INFO:root:Train (Epoch 168): Loss/seq after 02800 batchs: 641.1510620117188
INFO:root:Train (Epoch 168): Loss/seq after 02850 batchs: 640.9961547851562
INFO:root:Train (Epoch 168): Loss/seq after 02900 batchs: 641.8289794921875
INFO:root:Train (Epoch 168): Loss/seq after 02950 batchs: 639.9494018554688
INFO:root:Train (Epoch 168): Loss/seq after 03000 batchs: 644.171142578125
INFO:root:Train (Epoch 168): Loss/seq after 03050 batchs: 648.1321411132812
INFO:root:Train (Epoch 168): Loss/seq after 03100 batchs: 652.1912231445312
INFO:root:Train (Epoch 168): Loss/seq after 03150 batchs: 658.6095581054688
INFO:root:Train (Epoch 168): Loss/seq after 03200 batchs: 661.3609008789062
INFO:root:Train (Epoch 168): Loss/seq after 03250 batchs: 663.9176025390625
INFO:root:Train (Epoch 168): Loss/seq after 03300 batchs: 663.0681762695312
INFO:root:Train (Epoch 168): Loss/seq after 03350 batchs: 663.0677490234375
INFO:root:Train (Epoch 168): Loss/seq after 03400 batchs: 657.961181640625
INFO:root:Train (Epoch 168): Loss/seq after 03450 batchs: 655.0851440429688
INFO:root:Train (Epoch 168): Loss/seq after 03500 batchs: 654.3214111328125
INFO:root:Train (Epoch 168): Loss/seq after 03550 batchs: 650.8824462890625
INFO:root:Train (Epoch 168): Loss/seq after 03600 batchs: 659.1983032226562
INFO:root:Train (Epoch 168): Loss/seq after 03650 batchs: 656.1455078125
INFO:root:Train (Epoch 168): Loss/seq after 03700 batchs: 657.7974853515625
INFO:root:Train (Epoch 168): Loss/seq after 03750 batchs: 661.8203735351562
INFO:root:Train (Epoch 168): Loss/seq after 03800 batchs: 658.5377197265625
INFO:root:Train (Epoch 168): Loss/seq after 03850 batchs: 657.829345703125
INFO:root:Train (Epoch 168): Loss/seq after 03900 batchs: 661.5953979492188
INFO:root:Train (Epoch 168): Loss/seq after 03950 batchs: 665.2299194335938
INFO:root:Train (Epoch 168): Loss/seq after 04000 batchs: 660.82177734375
INFO:root:Train (Epoch 168): Loss/seq after 04050 batchs: 656.37841796875
INFO:root:Train (Epoch 168): Loss/seq after 04100 batchs: 653.8862915039062
INFO:root:Train (Epoch 168): Loss/seq after 04150 batchs: 652.961669921875
INFO:root:Train (Epoch 168): Loss/seq after 04200 batchs: 650.4064331054688
INFO:root:Train (Epoch 168): Loss/seq after 04250 batchs: 648.046142578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 168): Loss/seq after 00000 batches: 547.4927978515625
INFO:root:# Valid (Epoch 168): Loss/seq after 00050 batches: 733.4849853515625
INFO:root:# Valid (Epoch 168): Loss/seq after 00100 batches: 963.8612670898438
INFO:root:# Valid (Epoch 168): Loss/seq after 00150 batches: 712.6204223632812
INFO:root:# Valid (Epoch 168): Loss/seq after 00200 batches: 645.2695922851562
INFO:root:Artifacts: Make stick videos for epoch 168
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_168_on_20220423_101832.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_168_index_215_on_20220423_101832.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 169): Loss/seq after 00000 batchs: 1370.5775146484375
INFO:root:Train (Epoch 169): Loss/seq after 00050 batchs: 914.6281127929688
INFO:root:Train (Epoch 169): Loss/seq after 00100 batchs: 889.1484375
INFO:root:Train (Epoch 169): Loss/seq after 00150 batchs: 789.9277954101562
INFO:root:Train (Epoch 169): Loss/seq after 00200 batchs: 882.3356323242188
INFO:root:Train (Epoch 169): Loss/seq after 00250 batchs: 1000.3414306640625
INFO:root:Train (Epoch 169): Loss/seq after 00300 batchs: 984.866455078125
INFO:root:Train (Epoch 169): Loss/seq after 00350 batchs: 920.0960693359375
INFO:root:Train (Epoch 169): Loss/seq after 00400 batchs: 929.3307495117188
INFO:root:Train (Epoch 169): Loss/seq after 00450 batchs: 904.60400390625
INFO:root:Train (Epoch 169): Loss/seq after 00500 batchs: 881.3858032226562
INFO:root:Train (Epoch 169): Loss/seq after 00550 batchs: 852.8676147460938
INFO:root:Train (Epoch 169): Loss/seq after 00600 batchs: 821.6433715820312
INFO:root:Train (Epoch 169): Loss/seq after 00650 batchs: 811.2409057617188
INFO:root:Train (Epoch 169): Loss/seq after 00700 batchs: 789.5692749023438
INFO:root:Train (Epoch 169): Loss/seq after 00750 batchs: 804.6450805664062
INFO:root:Train (Epoch 169): Loss/seq after 00800 batchs: 800.128173828125
INFO:root:Train (Epoch 169): Loss/seq after 00850 batchs: 775.91552734375
INFO:root:Train (Epoch 169): Loss/seq after 00900 batchs: 759.5184936523438
INFO:root:Train (Epoch 169): Loss/seq after 00950 batchs: 760.3976440429688
INFO:root:Train (Epoch 169): Loss/seq after 01000 batchs: 753.127197265625
INFO:root:Train (Epoch 169): Loss/seq after 01050 batchs: 739.942626953125
INFO:root:Train (Epoch 169): Loss/seq after 01100 batchs: 727.1488037109375
INFO:root:Train (Epoch 169): Loss/seq after 01150 batchs: 710.979736328125
INFO:root:Train (Epoch 169): Loss/seq after 01200 batchs: 713.4005737304688
INFO:root:Train (Epoch 169): Loss/seq after 01250 batchs: 710.0306396484375
INFO:root:Train (Epoch 169): Loss/seq after 01300 batchs: 698.9230346679688
INFO:root:Train (Epoch 169): Loss/seq after 01350 batchs: 689.1740112304688
INFO:root:Train (Epoch 169): Loss/seq after 01400 batchs: 695.903076171875
INFO:root:Train (Epoch 169): Loss/seq after 01450 batchs: 695.9091796875
INFO:root:Train (Epoch 169): Loss/seq after 01500 batchs: 699.9674682617188
INFO:root:Train (Epoch 169): Loss/seq after 01550 batchs: 703.1904907226562
INFO:root:Train (Epoch 169): Loss/seq after 01600 batchs: 695.8480224609375
INFO:root:Train (Epoch 169): Loss/seq after 01650 batchs: 691.5302734375
INFO:root:Train (Epoch 169): Loss/seq after 01700 batchs: 692.0303344726562
INFO:root:Train (Epoch 169): Loss/seq after 01750 batchs: 688.1716918945312
INFO:root:Train (Epoch 169): Loss/seq after 01800 batchs: 683.9882202148438
INFO:root:Train (Epoch 169): Loss/seq after 01850 batchs: 678.2813110351562
INFO:root:Train (Epoch 169): Loss/seq after 01900 batchs: 678.3280029296875
INFO:root:Train (Epoch 169): Loss/seq after 01950 batchs: 675.615234375
INFO:root:Train (Epoch 169): Loss/seq after 02000 batchs: 673.4183959960938
INFO:root:Train (Epoch 169): Loss/seq after 02050 batchs: 670.5645141601562
INFO:root:Train (Epoch 169): Loss/seq after 02100 batchs: 666.5586547851562
INFO:root:Train (Epoch 169): Loss/seq after 02150 batchs: 663.6786499023438
INFO:root:Train (Epoch 169): Loss/seq after 02200 batchs: 659.5492553710938
INFO:root:Train (Epoch 169): Loss/seq after 02250 batchs: 658.9536743164062
INFO:root:Train (Epoch 169): Loss/seq after 02300 batchs: 660.1572265625
INFO:root:Train (Epoch 169): Loss/seq after 02350 batchs: 654.1666259765625
INFO:root:Train (Epoch 169): Loss/seq after 02400 batchs: 654.4456787109375
INFO:root:Train (Epoch 169): Loss/seq after 02450 batchs: 648.8013305664062
INFO:root:Train (Epoch 169): Loss/seq after 02500 batchs: 639.1828002929688
INFO:root:Train (Epoch 169): Loss/seq after 02550 batchs: 632.6554565429688
INFO:root:Train (Epoch 169): Loss/seq after 02600 batchs: 632.2932739257812
INFO:root:Train (Epoch 169): Loss/seq after 02650 batchs: 629.6953735351562
INFO:root:Train (Epoch 169): Loss/seq after 02700 batchs: 627.74853515625
INFO:root:Train (Epoch 169): Loss/seq after 02750 batchs: 635.074951171875
INFO:root:Train (Epoch 169): Loss/seq after 02800 batchs: 636.3941650390625
INFO:root:Train (Epoch 169): Loss/seq after 02850 batchs: 635.994384765625
INFO:root:Train (Epoch 169): Loss/seq after 02900 batchs: 637.1524047851562
INFO:root:Train (Epoch 169): Loss/seq after 02950 batchs: 635.2921142578125
INFO:root:Train (Epoch 169): Loss/seq after 03000 batchs: 639.62158203125
INFO:root:Train (Epoch 169): Loss/seq after 03050 batchs: 643.77099609375
INFO:root:Train (Epoch 169): Loss/seq after 03100 batchs: 648.28564453125
INFO:root:Train (Epoch 169): Loss/seq after 03150 batchs: 655.7020263671875
INFO:root:Train (Epoch 169): Loss/seq after 03200 batchs: 658.8131103515625
INFO:root:Train (Epoch 169): Loss/seq after 03250 batchs: 661.7698364257812
INFO:root:Train (Epoch 169): Loss/seq after 03300 batchs: 661.1004638671875
INFO:root:Train (Epoch 169): Loss/seq after 03350 batchs: 661.3610229492188
INFO:root:Train (Epoch 169): Loss/seq after 03400 batchs: 656.2761840820312
INFO:root:Train (Epoch 169): Loss/seq after 03450 batchs: 653.740966796875
INFO:root:Train (Epoch 169): Loss/seq after 03500 batchs: 653.3709106445312
INFO:root:Train (Epoch 169): Loss/seq after 03550 batchs: 649.671630859375
INFO:root:Train (Epoch 169): Loss/seq after 03600 batchs: 657.8280029296875
INFO:root:Train (Epoch 169): Loss/seq after 03650 batchs: 654.7894897460938
INFO:root:Train (Epoch 169): Loss/seq after 03700 batchs: 656.5242919921875
INFO:root:Train (Epoch 169): Loss/seq after 03750 batchs: 660.708251953125
INFO:root:Train (Epoch 169): Loss/seq after 03800 batchs: 657.4911499023438
INFO:root:Train (Epoch 169): Loss/seq after 03850 batchs: 656.80615234375
INFO:root:Train (Epoch 169): Loss/seq after 03900 batchs: 660.97119140625
INFO:root:Train (Epoch 169): Loss/seq after 03950 batchs: 664.4196166992188
INFO:root:Train (Epoch 169): Loss/seq after 04000 batchs: 660.0925903320312
INFO:root:Train (Epoch 169): Loss/seq after 04050 batchs: 655.6508178710938
INFO:root:Train (Epoch 169): Loss/seq after 04100 batchs: 653.2208862304688
INFO:root:Train (Epoch 169): Loss/seq after 04150 batchs: 652.3643188476562
INFO:root:Train (Epoch 169): Loss/seq after 04200 batchs: 649.9437255859375
INFO:root:Train (Epoch 169): Loss/seq after 04250 batchs: 647.73974609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 169): Loss/seq after 00000 batches: 528.8629760742188
INFO:root:# Valid (Epoch 169): Loss/seq after 00050 batches: 730.166259765625
INFO:root:# Valid (Epoch 169): Loss/seq after 00100 batches: 955.97265625
INFO:root:# Valid (Epoch 169): Loss/seq after 00150 batches: 709.009765625
INFO:root:# Valid (Epoch 169): Loss/seq after 00200 batches: 642.6543579101562
INFO:root:Artifacts: Make stick videos for epoch 169
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_169_on_20220423_102343.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_169_index_1456_on_20220423_102343.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 170): Loss/seq after 00000 batchs: 1349.71826171875
INFO:root:Train (Epoch 170): Loss/seq after 00050 batchs: 918.932373046875
INFO:root:Train (Epoch 170): Loss/seq after 00100 batchs: 898.8790893554688
INFO:root:Train (Epoch 170): Loss/seq after 00150 batchs: 795.4652709960938
INFO:root:Train (Epoch 170): Loss/seq after 00200 batchs: 899.8818359375
INFO:root:Train (Epoch 170): Loss/seq after 00250 batchs: 1023.7450561523438
INFO:root:Train (Epoch 170): Loss/seq after 00300 batchs: 1005.1808471679688
INFO:root:Train (Epoch 170): Loss/seq after 00350 batchs: 937.4209594726562
INFO:root:Train (Epoch 170): Loss/seq after 00400 batchs: 944.82861328125
INFO:root:Train (Epoch 170): Loss/seq after 00450 batchs: 918.2755126953125
INFO:root:Train (Epoch 170): Loss/seq after 00500 batchs: 890.69482421875
INFO:root:Train (Epoch 170): Loss/seq after 00550 batchs: 861.8309936523438
INFO:root:Train (Epoch 170): Loss/seq after 00600 batchs: 829.7239990234375
INFO:root:Train (Epoch 170): Loss/seq after 00650 batchs: 819.6935424804688
INFO:root:Train (Epoch 170): Loss/seq after 00700 batchs: 796.5963745117188
INFO:root:Train (Epoch 170): Loss/seq after 00750 batchs: 809.655029296875
INFO:root:Train (Epoch 170): Loss/seq after 00800 batchs: 804.667724609375
INFO:root:Train (Epoch 170): Loss/seq after 00850 batchs: 779.9174194335938
INFO:root:Train (Epoch 170): Loss/seq after 00900 batchs: 764.026123046875
INFO:root:Train (Epoch 170): Loss/seq after 00950 batchs: 766.4817504882812
INFO:root:Train (Epoch 170): Loss/seq after 01000 batchs: 758.1812133789062
INFO:root:Train (Epoch 170): Loss/seq after 01050 batchs: 743.73681640625
INFO:root:Train (Epoch 170): Loss/seq after 01100 batchs: 730.1157836914062
INFO:root:Train (Epoch 170): Loss/seq after 01150 batchs: 714.1683959960938
INFO:root:Train (Epoch 170): Loss/seq after 01200 batchs: 716.3535766601562
INFO:root:Train (Epoch 170): Loss/seq after 01250 batchs: 712.9356079101562
INFO:root:Train (Epoch 170): Loss/seq after 01300 batchs: 701.2119140625
INFO:root:Train (Epoch 170): Loss/seq after 01350 batchs: 691.4205932617188
INFO:root:Train (Epoch 170): Loss/seq after 01400 batchs: 697.7473754882812
INFO:root:Train (Epoch 170): Loss/seq after 01450 batchs: 697.4696044921875
INFO:root:Train (Epoch 170): Loss/seq after 01500 batchs: 701.1893310546875
INFO:root:Train (Epoch 170): Loss/seq after 01550 batchs: 703.6054077148438
INFO:root:Train (Epoch 170): Loss/seq after 01600 batchs: 696.4733276367188
INFO:root:Train (Epoch 170): Loss/seq after 01650 batchs: 692.0709838867188
INFO:root:Train (Epoch 170): Loss/seq after 01700 batchs: 692.4287719726562
INFO:root:Train (Epoch 170): Loss/seq after 01750 batchs: 688.588623046875
INFO:root:Train (Epoch 170): Loss/seq after 01800 batchs: 684.355712890625
INFO:root:Train (Epoch 170): Loss/seq after 01850 batchs: 678.41748046875
INFO:root:Train (Epoch 170): Loss/seq after 01900 batchs: 678.4779663085938
INFO:root:Train (Epoch 170): Loss/seq after 01950 batchs: 676.0922241210938
INFO:root:Train (Epoch 170): Loss/seq after 02000 batchs: 673.8070678710938
INFO:root:Train (Epoch 170): Loss/seq after 02050 batchs: 670.7017822265625
INFO:root:Train (Epoch 170): Loss/seq after 02100 batchs: 666.7689208984375
INFO:root:Train (Epoch 170): Loss/seq after 02150 batchs: 663.9411010742188
INFO:root:Train (Epoch 170): Loss/seq after 02200 batchs: 659.5169677734375
INFO:root:Train (Epoch 170): Loss/seq after 02250 batchs: 658.514892578125
INFO:root:Train (Epoch 170): Loss/seq after 02300 batchs: 659.1484375
INFO:root:Train (Epoch 170): Loss/seq after 02350 batchs: 653.3485717773438
INFO:root:Train (Epoch 170): Loss/seq after 02400 batchs: 653.4088745117188
INFO:root:Train (Epoch 170): Loss/seq after 02450 batchs: 647.7990112304688
INFO:root:Train (Epoch 170): Loss/seq after 02500 batchs: 638.1920166015625
INFO:root:Train (Epoch 170): Loss/seq after 02550 batchs: 631.7129516601562
INFO:root:Train (Epoch 170): Loss/seq after 02600 batchs: 631.4500732421875
INFO:root:Train (Epoch 170): Loss/seq after 02650 batchs: 628.9971923828125
INFO:root:Train (Epoch 170): Loss/seq after 02700 batchs: 626.6995849609375
INFO:root:Train (Epoch 170): Loss/seq after 02750 batchs: 632.0014038085938
INFO:root:Train (Epoch 170): Loss/seq after 02800 batchs: 633.177734375
INFO:root:Train (Epoch 170): Loss/seq after 02850 batchs: 632.6876831054688
INFO:root:Train (Epoch 170): Loss/seq after 02900 batchs: 633.5914306640625
INFO:root:Train (Epoch 170): Loss/seq after 02950 batchs: 631.913818359375
INFO:root:Train (Epoch 170): Loss/seq after 03000 batchs: 636.094970703125
INFO:root:Train (Epoch 170): Loss/seq after 03050 batchs: 640.6036987304688
INFO:root:Train (Epoch 170): Loss/seq after 03100 batchs: 645.2192993164062
INFO:root:Train (Epoch 170): Loss/seq after 03150 batchs: 651.298583984375
INFO:root:Train (Epoch 170): Loss/seq after 03200 batchs: 653.9520263671875
INFO:root:Train (Epoch 170): Loss/seq after 03250 batchs: 657.5135498046875
INFO:root:Train (Epoch 170): Loss/seq after 03300 batchs: 656.4166259765625
INFO:root:Train (Epoch 170): Loss/seq after 03350 batchs: 656.213623046875
INFO:root:Train (Epoch 170): Loss/seq after 03400 batchs: 651.2802124023438
INFO:root:Train (Epoch 170): Loss/seq after 03450 batchs: 648.6002807617188
INFO:root:Train (Epoch 170): Loss/seq after 03500 batchs: 648.2841796875
INFO:root:Train (Epoch 170): Loss/seq after 03550 batchs: 644.611572265625
INFO:root:Train (Epoch 170): Loss/seq after 03600 batchs: 652.9537963867188
INFO:root:Train (Epoch 170): Loss/seq after 03650 batchs: 649.6605224609375
INFO:root:Train (Epoch 170): Loss/seq after 03700 batchs: 651.5028686523438
INFO:root:Train (Epoch 170): Loss/seq after 03750 batchs: 655.7811889648438
INFO:root:Train (Epoch 170): Loss/seq after 03800 batchs: 652.566650390625
INFO:root:Train (Epoch 170): Loss/seq after 03850 batchs: 651.8358764648438
INFO:root:Train (Epoch 170): Loss/seq after 03900 batchs: 655.5673217773438
INFO:root:Train (Epoch 170): Loss/seq after 03950 batchs: 658.8980102539062
INFO:root:Train (Epoch 170): Loss/seq after 04000 batchs: 654.525146484375
INFO:root:Train (Epoch 170): Loss/seq after 04050 batchs: 650.1021728515625
INFO:root:Train (Epoch 170): Loss/seq after 04100 batchs: 647.5901489257812
INFO:root:Train (Epoch 170): Loss/seq after 04150 batchs: 646.768310546875
INFO:root:Train (Epoch 170): Loss/seq after 04200 batchs: 644.45263671875
INFO:root:Train (Epoch 170): Loss/seq after 04250 batchs: 642.275146484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 170): Loss/seq after 00000 batches: 552.34326171875
INFO:root:# Valid (Epoch 170): Loss/seq after 00050 batches: 736.1670532226562
INFO:root:# Valid (Epoch 170): Loss/seq after 00100 batches: 962.9584350585938
INFO:root:# Valid (Epoch 170): Loss/seq after 00150 batches: 718.2486572265625
INFO:root:# Valid (Epoch 170): Loss/seq after 00200 batches: 649.6483764648438
INFO:root:Artifacts: Make stick videos for epoch 170
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_170_on_20220423_102834.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_170_index_1741_on_20220423_102834.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 171): Loss/seq after 00000 batchs: 1369.7816162109375
INFO:root:Train (Epoch 171): Loss/seq after 00050 batchs: 922.2328491210938
INFO:root:Train (Epoch 171): Loss/seq after 00100 batchs: 913.2171020507812
INFO:root:Train (Epoch 171): Loss/seq after 00150 batchs: 803.568115234375
INFO:root:Train (Epoch 171): Loss/seq after 00200 batchs: 889.2498168945312
INFO:root:Train (Epoch 171): Loss/seq after 00250 batchs: 996.881591796875
INFO:root:Train (Epoch 171): Loss/seq after 00300 batchs: 982.0606079101562
INFO:root:Train (Epoch 171): Loss/seq after 00350 batchs: 916.5396118164062
INFO:root:Train (Epoch 171): Loss/seq after 00400 batchs: 926.923583984375
INFO:root:Train (Epoch 171): Loss/seq after 00450 batchs: 902.599609375
INFO:root:Train (Epoch 171): Loss/seq after 00500 batchs: 877.3193359375
INFO:root:Train (Epoch 171): Loss/seq after 00550 batchs: 848.9683837890625
INFO:root:Train (Epoch 171): Loss/seq after 00600 batchs: 818.5151977539062
INFO:root:Train (Epoch 171): Loss/seq after 00650 batchs: 807.5165405273438
INFO:root:Train (Epoch 171): Loss/seq after 00700 batchs: 783.3912353515625
INFO:root:Train (Epoch 171): Loss/seq after 00750 batchs: 795.8010864257812
INFO:root:Train (Epoch 171): Loss/seq after 00800 batchs: 792.5252075195312
INFO:root:Train (Epoch 171): Loss/seq after 00850 batchs: 768.8953247070312
INFO:root:Train (Epoch 171): Loss/seq after 00900 batchs: 751.20556640625
INFO:root:Train (Epoch 171): Loss/seq after 00950 batchs: 752.6107788085938
INFO:root:Train (Epoch 171): Loss/seq after 01000 batchs: 746.5242309570312
INFO:root:Train (Epoch 171): Loss/seq after 01050 batchs: 732.406005859375
INFO:root:Train (Epoch 171): Loss/seq after 01100 batchs: 720.3661499023438
INFO:root:Train (Epoch 171): Loss/seq after 01150 batchs: 704.6647338867188
INFO:root:Train (Epoch 171): Loss/seq after 01200 batchs: 707.3209228515625
INFO:root:Train (Epoch 171): Loss/seq after 01250 batchs: 704.2672119140625
INFO:root:Train (Epoch 171): Loss/seq after 01300 batchs: 693.5914916992188
INFO:root:Train (Epoch 171): Loss/seq after 01350 batchs: 684.47607421875
INFO:root:Train (Epoch 171): Loss/seq after 01400 batchs: 690.2314453125
INFO:root:Train (Epoch 171): Loss/seq after 01450 batchs: 690.4745483398438
INFO:root:Train (Epoch 171): Loss/seq after 01500 batchs: 694.6105346679688
INFO:root:Train (Epoch 171): Loss/seq after 01550 batchs: 696.6987915039062
INFO:root:Train (Epoch 171): Loss/seq after 01600 batchs: 689.5914306640625
INFO:root:Train (Epoch 171): Loss/seq after 01650 batchs: 684.9077758789062
INFO:root:Train (Epoch 171): Loss/seq after 01700 batchs: 685.2886962890625
INFO:root:Train (Epoch 171): Loss/seq after 01750 batchs: 681.6524658203125
INFO:root:Train (Epoch 171): Loss/seq after 01800 batchs: 677.7611083984375
INFO:root:Train (Epoch 171): Loss/seq after 01850 batchs: 671.8242797851562
INFO:root:Train (Epoch 171): Loss/seq after 01900 batchs: 671.7462768554688
INFO:root:Train (Epoch 171): Loss/seq after 01950 batchs: 669.656005859375
INFO:root:Train (Epoch 171): Loss/seq after 02000 batchs: 667.3991088867188
INFO:root:Train (Epoch 171): Loss/seq after 02050 batchs: 664.5535278320312
INFO:root:Train (Epoch 171): Loss/seq after 02100 batchs: 660.6064453125
INFO:root:Train (Epoch 171): Loss/seq after 02150 batchs: 657.6581420898438
INFO:root:Train (Epoch 171): Loss/seq after 02200 batchs: 653.7610473632812
INFO:root:Train (Epoch 171): Loss/seq after 02250 batchs: 653.6053466796875
INFO:root:Train (Epoch 171): Loss/seq after 02300 batchs: 653.1296997070312
INFO:root:Train (Epoch 171): Loss/seq after 02350 batchs: 647.3260498046875
INFO:root:Train (Epoch 171): Loss/seq after 02400 batchs: 647.6049194335938
INFO:root:Train (Epoch 171): Loss/seq after 02450 batchs: 642.047607421875
INFO:root:Train (Epoch 171): Loss/seq after 02500 batchs: 632.5186157226562
INFO:root:Train (Epoch 171): Loss/seq after 02550 batchs: 625.9523315429688
INFO:root:Train (Epoch 171): Loss/seq after 02600 batchs: 625.4891967773438
INFO:root:Train (Epoch 171): Loss/seq after 02650 batchs: 623.0490112304688
INFO:root:Train (Epoch 171): Loss/seq after 02700 batchs: 620.5531616210938
INFO:root:Train (Epoch 171): Loss/seq after 02750 batchs: 628.2785034179688
INFO:root:Train (Epoch 171): Loss/seq after 02800 batchs: 629.9384765625
INFO:root:Train (Epoch 171): Loss/seq after 02850 batchs: 629.7779541015625
INFO:root:Train (Epoch 171): Loss/seq after 02900 batchs: 630.565673828125
INFO:root:Train (Epoch 171): Loss/seq after 02950 batchs: 628.8170776367188
INFO:root:Train (Epoch 171): Loss/seq after 03000 batchs: 633.113037109375
INFO:root:Train (Epoch 171): Loss/seq after 03050 batchs: 637.7061157226562
INFO:root:Train (Epoch 171): Loss/seq after 03100 batchs: 641.810302734375
INFO:root:Train (Epoch 171): Loss/seq after 03150 batchs: 647.6205444335938
INFO:root:Train (Epoch 171): Loss/seq after 03200 batchs: 649.1049194335938
INFO:root:Train (Epoch 171): Loss/seq after 03250 batchs: 651.7621459960938
INFO:root:Train (Epoch 171): Loss/seq after 03300 batchs: 651.2510986328125
INFO:root:Train (Epoch 171): Loss/seq after 03350 batchs: 651.631103515625
INFO:root:Train (Epoch 171): Loss/seq after 03400 batchs: 646.8187866210938
INFO:root:Train (Epoch 171): Loss/seq after 03450 batchs: 644.3104248046875
INFO:root:Train (Epoch 171): Loss/seq after 03500 batchs: 644.1936645507812
INFO:root:Train (Epoch 171): Loss/seq after 03550 batchs: 640.6868286132812
INFO:root:Train (Epoch 171): Loss/seq after 03600 batchs: 649.095703125
INFO:root:Train (Epoch 171): Loss/seq after 03650 batchs: 646.123046875
INFO:root:Train (Epoch 171): Loss/seq after 03700 batchs: 647.9287719726562
INFO:root:Train (Epoch 171): Loss/seq after 03750 batchs: 652.0537719726562
INFO:root:Train (Epoch 171): Loss/seq after 03800 batchs: 648.8582763671875
INFO:root:Train (Epoch 171): Loss/seq after 03850 batchs: 647.867431640625
INFO:root:Train (Epoch 171): Loss/seq after 03900 batchs: 651.1228637695312
INFO:root:Train (Epoch 171): Loss/seq after 03950 batchs: 654.53662109375
INFO:root:Train (Epoch 171): Loss/seq after 04000 batchs: 650.2017211914062
INFO:root:Train (Epoch 171): Loss/seq after 04050 batchs: 645.8409423828125
INFO:root:Train (Epoch 171): Loss/seq after 04100 batchs: 643.3948364257812
INFO:root:Train (Epoch 171): Loss/seq after 04150 batchs: 642.635498046875
INFO:root:Train (Epoch 171): Loss/seq after 04200 batchs: 640.0206909179688
INFO:root:Train (Epoch 171): Loss/seq after 04250 batchs: 637.8248901367188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 171): Loss/seq after 00000 batches: 541.5037231445312
INFO:root:# Valid (Epoch 171): Loss/seq after 00050 batches: 713.1973876953125
INFO:root:# Valid (Epoch 171): Loss/seq after 00100 batches: 950.12841796875
INFO:root:# Valid (Epoch 171): Loss/seq after 00150 batches: 707.3738403320312
INFO:root:# Valid (Epoch 171): Loss/seq after 00200 batches: 638.3792114257812
INFO:root:Artifacts: Make stick videos for epoch 171
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_171_on_20220423_103322.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_171_index_1221_on_20220423_103322.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 172): Loss/seq after 00000 batchs: 1268.025634765625
INFO:root:Train (Epoch 172): Loss/seq after 00050 batchs: 909.0582275390625
INFO:root:Train (Epoch 172): Loss/seq after 00100 batchs: 901.1024169921875
INFO:root:Train (Epoch 172): Loss/seq after 00150 batchs: 797.5569458007812
INFO:root:Train (Epoch 172): Loss/seq after 00200 batchs: 886.3405151367188
INFO:root:Train (Epoch 172): Loss/seq after 00250 batchs: 989.92333984375
INFO:root:Train (Epoch 172): Loss/seq after 00300 batchs: 977.5423583984375
INFO:root:Train (Epoch 172): Loss/seq after 00350 batchs: 914.60986328125
INFO:root:Train (Epoch 172): Loss/seq after 00400 batchs: 923.4067993164062
INFO:root:Train (Epoch 172): Loss/seq after 00450 batchs: 900.35400390625
INFO:root:Train (Epoch 172): Loss/seq after 00500 batchs: 874.272216796875
INFO:root:Train (Epoch 172): Loss/seq after 00550 batchs: 846.0333862304688
INFO:root:Train (Epoch 172): Loss/seq after 00600 batchs: 815.8128662109375
INFO:root:Train (Epoch 172): Loss/seq after 00650 batchs: 806.014404296875
INFO:root:Train (Epoch 172): Loss/seq after 00700 batchs: 780.8821411132812
INFO:root:Train (Epoch 172): Loss/seq after 00750 batchs: 794.5546264648438
INFO:root:Train (Epoch 172): Loss/seq after 00800 batchs: 790.0841674804688
INFO:root:Train (Epoch 172): Loss/seq after 00850 batchs: 766.0108032226562
INFO:root:Train (Epoch 172): Loss/seq after 00900 batchs: 749.609619140625
INFO:root:Train (Epoch 172): Loss/seq after 00950 batchs: 753.2000732421875
INFO:root:Train (Epoch 172): Loss/seq after 01000 batchs: 746.0431518554688
INFO:root:Train (Epoch 172): Loss/seq after 01050 batchs: 733.3031005859375
INFO:root:Train (Epoch 172): Loss/seq after 01100 batchs: 721.4276733398438
INFO:root:Train (Epoch 172): Loss/seq after 01150 batchs: 705.127197265625
INFO:root:Train (Epoch 172): Loss/seq after 01200 batchs: 707.430908203125
INFO:root:Train (Epoch 172): Loss/seq after 01250 batchs: 703.8804931640625
INFO:root:Train (Epoch 172): Loss/seq after 01300 batchs: 693.18701171875
INFO:root:Train (Epoch 172): Loss/seq after 01350 batchs: 683.839111328125
INFO:root:Train (Epoch 172): Loss/seq after 01400 batchs: 690.8877563476562
INFO:root:Train (Epoch 172): Loss/seq after 01450 batchs: 690.9008178710938
INFO:root:Train (Epoch 172): Loss/seq after 01500 batchs: 694.9325561523438
INFO:root:Train (Epoch 172): Loss/seq after 01550 batchs: 697.3783569335938
INFO:root:Train (Epoch 172): Loss/seq after 01600 batchs: 690.285400390625
INFO:root:Train (Epoch 172): Loss/seq after 01650 batchs: 685.7337646484375
INFO:root:Train (Epoch 172): Loss/seq after 01700 batchs: 686.2335815429688
INFO:root:Train (Epoch 172): Loss/seq after 01750 batchs: 682.3721313476562
INFO:root:Train (Epoch 172): Loss/seq after 01800 batchs: 678.1763305664062
INFO:root:Train (Epoch 172): Loss/seq after 01850 batchs: 672.484375
INFO:root:Train (Epoch 172): Loss/seq after 01900 batchs: 672.2922973632812
INFO:root:Train (Epoch 172): Loss/seq after 01950 batchs: 669.7978515625
INFO:root:Train (Epoch 172): Loss/seq after 02000 batchs: 667.4097290039062
INFO:root:Train (Epoch 172): Loss/seq after 02050 batchs: 664.5547485351562
INFO:root:Train (Epoch 172): Loss/seq after 02100 batchs: 660.3595581054688
INFO:root:Train (Epoch 172): Loss/seq after 02150 batchs: 657.1852416992188
INFO:root:Train (Epoch 172): Loss/seq after 02200 batchs: 653.0681762695312
INFO:root:Train (Epoch 172): Loss/seq after 02250 batchs: 651.9226684570312
INFO:root:Train (Epoch 172): Loss/seq after 02300 batchs: 651.7969970703125
INFO:root:Train (Epoch 172): Loss/seq after 02350 batchs: 645.9121704101562
INFO:root:Train (Epoch 172): Loss/seq after 02400 batchs: 646.1051635742188
INFO:root:Train (Epoch 172): Loss/seq after 02450 batchs: 640.6152954101562
INFO:root:Train (Epoch 172): Loss/seq after 02500 batchs: 631.1188354492188
INFO:root:Train (Epoch 172): Loss/seq after 02550 batchs: 624.759521484375
INFO:root:Train (Epoch 172): Loss/seq after 02600 batchs: 624.59423828125
INFO:root:Train (Epoch 172): Loss/seq after 02650 batchs: 622.1018676757812
INFO:root:Train (Epoch 172): Loss/seq after 02700 batchs: 619.6825561523438
INFO:root:Train (Epoch 172): Loss/seq after 02750 batchs: 624.8961791992188
INFO:root:Train (Epoch 172): Loss/seq after 02800 batchs: 626.1527099609375
INFO:root:Train (Epoch 172): Loss/seq after 02850 batchs: 625.9669189453125
INFO:root:Train (Epoch 172): Loss/seq after 02900 batchs: 626.772216796875
INFO:root:Train (Epoch 172): Loss/seq after 02950 batchs: 625.0188598632812
INFO:root:Train (Epoch 172): Loss/seq after 03000 batchs: 629.2548217773438
INFO:root:Train (Epoch 172): Loss/seq after 03050 batchs: 632.5881958007812
INFO:root:Train (Epoch 172): Loss/seq after 03100 batchs: 637.088623046875
INFO:root:Train (Epoch 172): Loss/seq after 03150 batchs: 643.6336059570312
INFO:root:Train (Epoch 172): Loss/seq after 03200 batchs: 646.8359985351562
INFO:root:Train (Epoch 172): Loss/seq after 03250 batchs: 649.8490600585938
INFO:root:Train (Epoch 172): Loss/seq after 03300 batchs: 649.3087158203125
INFO:root:Train (Epoch 172): Loss/seq after 03350 batchs: 649.1304321289062
INFO:root:Train (Epoch 172): Loss/seq after 03400 batchs: 644.2463989257812
INFO:root:Train (Epoch 172): Loss/seq after 03450 batchs: 641.740234375
INFO:root:Train (Epoch 172): Loss/seq after 03500 batchs: 641.2755737304688
INFO:root:Train (Epoch 172): Loss/seq after 03550 batchs: 637.7529907226562
INFO:root:Train (Epoch 172): Loss/seq after 03600 batchs: 645.8079223632812
INFO:root:Train (Epoch 172): Loss/seq after 03650 batchs: 642.768798828125
INFO:root:Train (Epoch 172): Loss/seq after 03700 batchs: 644.6181640625
INFO:root:Train (Epoch 172): Loss/seq after 03750 batchs: 648.6858520507812
INFO:root:Train (Epoch 172): Loss/seq after 03800 batchs: 645.5156860351562
INFO:root:Train (Epoch 172): Loss/seq after 03850 batchs: 644.6192626953125
INFO:root:Train (Epoch 172): Loss/seq after 03900 batchs: 648.226318359375
INFO:root:Train (Epoch 172): Loss/seq after 03950 batchs: 651.5596923828125
INFO:root:Train (Epoch 172): Loss/seq after 04000 batchs: 647.224365234375
INFO:root:Train (Epoch 172): Loss/seq after 04050 batchs: 642.851318359375
INFO:root:Train (Epoch 172): Loss/seq after 04100 batchs: 640.4605102539062
INFO:root:Train (Epoch 172): Loss/seq after 04150 batchs: 639.7286376953125
INFO:root:Train (Epoch 172): Loss/seq after 04200 batchs: 637.3936157226562
INFO:root:Train (Epoch 172): Loss/seq after 04250 batchs: 635.246337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 172): Loss/seq after 00000 batches: 557.826171875
INFO:root:# Valid (Epoch 172): Loss/seq after 00050 batches: 721.0940551757812
INFO:root:# Valid (Epoch 172): Loss/seq after 00100 batches: 904.7711791992188
INFO:root:# Valid (Epoch 172): Loss/seq after 00150 batches: 676.9148559570312
INFO:root:# Valid (Epoch 172): Loss/seq after 00200 batches: 613.7219848632812
INFO:root:Artifacts: Make stick videos for epoch 172
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_172_on_20220423_103806.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_172_index_1650_on_20220423_103806.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 173): Loss/seq after 00000 batchs: 1273.18115234375
INFO:root:Train (Epoch 173): Loss/seq after 00050 batchs: 907.7760009765625
INFO:root:Train (Epoch 173): Loss/seq after 00100 batchs: 885.6751708984375
INFO:root:Train (Epoch 173): Loss/seq after 00150 batchs: 785.011474609375
INFO:root:Train (Epoch 173): Loss/seq after 00200 batchs: 872.1778564453125
INFO:root:Train (Epoch 173): Loss/seq after 00250 batchs: 984.6143188476562
INFO:root:Train (Epoch 173): Loss/seq after 00300 batchs: 971.5556030273438
INFO:root:Train (Epoch 173): Loss/seq after 00350 batchs: 909.1227416992188
INFO:root:Train (Epoch 173): Loss/seq after 00400 batchs: 916.6524047851562
INFO:root:Train (Epoch 173): Loss/seq after 00450 batchs: 892.7108154296875
INFO:root:Train (Epoch 173): Loss/seq after 00500 batchs: 865.3194580078125
INFO:root:Train (Epoch 173): Loss/seq after 00550 batchs: 837.633056640625
INFO:root:Train (Epoch 173): Loss/seq after 00600 batchs: 807.940185546875
INFO:root:Train (Epoch 173): Loss/seq after 00650 batchs: 800.8638916015625
INFO:root:Train (Epoch 173): Loss/seq after 00700 batchs: 777.0125732421875
INFO:root:Train (Epoch 173): Loss/seq after 00750 batchs: 787.5958251953125
INFO:root:Train (Epoch 173): Loss/seq after 00800 batchs: 783.2669067382812
INFO:root:Train (Epoch 173): Loss/seq after 00850 batchs: 759.5726928710938
INFO:root:Train (Epoch 173): Loss/seq after 00900 batchs: 741.82421875
INFO:root:Train (Epoch 173): Loss/seq after 00950 batchs: 744.3443603515625
INFO:root:Train (Epoch 173): Loss/seq after 01000 batchs: 737.3164672851562
INFO:root:Train (Epoch 173): Loss/seq after 01050 batchs: 722.8213500976562
INFO:root:Train (Epoch 173): Loss/seq after 01100 batchs: 711.1693725585938
INFO:root:Train (Epoch 173): Loss/seq after 01150 batchs: 696.330322265625
INFO:root:Train (Epoch 173): Loss/seq after 01200 batchs: 699.0020141601562
INFO:root:Train (Epoch 173): Loss/seq after 01250 batchs: 695.4945068359375
INFO:root:Train (Epoch 173): Loss/seq after 01300 batchs: 683.2766723632812
INFO:root:Train (Epoch 173): Loss/seq after 01350 batchs: 673.4785766601562
INFO:root:Train (Epoch 173): Loss/seq after 01400 batchs: 681.4068603515625
INFO:root:Train (Epoch 173): Loss/seq after 01450 batchs: 681.39990234375
INFO:root:Train (Epoch 173): Loss/seq after 01500 batchs: 685.7942504882812
INFO:root:Train (Epoch 173): Loss/seq after 01550 batchs: 687.6486206054688
INFO:root:Train (Epoch 173): Loss/seq after 01600 batchs: 680.48095703125
INFO:root:Train (Epoch 173): Loss/seq after 01650 batchs: 676.2453002929688
INFO:root:Train (Epoch 173): Loss/seq after 01700 batchs: 676.8585815429688
INFO:root:Train (Epoch 173): Loss/seq after 01750 batchs: 673.5527954101562
INFO:root:Train (Epoch 173): Loss/seq after 01800 batchs: 669.7007446289062
INFO:root:Train (Epoch 173): Loss/seq after 01850 batchs: 664.0343017578125
INFO:root:Train (Epoch 173): Loss/seq after 01900 batchs: 664.1649169921875
INFO:root:Train (Epoch 173): Loss/seq after 01950 batchs: 662.081298828125
INFO:root:Train (Epoch 173): Loss/seq after 02000 batchs: 659.7880249023438
INFO:root:Train (Epoch 173): Loss/seq after 02050 batchs: 657.233154296875
INFO:root:Train (Epoch 173): Loss/seq after 02100 batchs: 653.399658203125
INFO:root:Train (Epoch 173): Loss/seq after 02150 batchs: 650.4505615234375
INFO:root:Train (Epoch 173): Loss/seq after 02200 batchs: 646.238525390625
INFO:root:Train (Epoch 173): Loss/seq after 02250 batchs: 645.6088256835938
INFO:root:Train (Epoch 173): Loss/seq after 02300 batchs: 645.1578979492188
INFO:root:Train (Epoch 173): Loss/seq after 02350 batchs: 639.4803466796875
INFO:root:Train (Epoch 173): Loss/seq after 02400 batchs: 639.974853515625
INFO:root:Train (Epoch 173): Loss/seq after 02450 batchs: 634.5869750976562
INFO:root:Train (Epoch 173): Loss/seq after 02500 batchs: 625.2006225585938
INFO:root:Train (Epoch 173): Loss/seq after 02550 batchs: 618.7559814453125
INFO:root:Train (Epoch 173): Loss/seq after 02600 batchs: 618.5288696289062
INFO:root:Train (Epoch 173): Loss/seq after 02650 batchs: 616.1160888671875
INFO:root:Train (Epoch 173): Loss/seq after 02700 batchs: 613.9935302734375
INFO:root:Train (Epoch 173): Loss/seq after 02750 batchs: 615.7098999023438
INFO:root:Train (Epoch 173): Loss/seq after 02800 batchs: 616.6360473632812
INFO:root:Train (Epoch 173): Loss/seq after 02850 batchs: 616.5017700195312
INFO:root:Train (Epoch 173): Loss/seq after 02900 batchs: 617.7951049804688
INFO:root:Train (Epoch 173): Loss/seq after 02950 batchs: 616.09228515625
INFO:root:Train (Epoch 173): Loss/seq after 03000 batchs: 620.6178588867188
INFO:root:Train (Epoch 173): Loss/seq after 03050 batchs: 623.8959350585938
INFO:root:Train (Epoch 173): Loss/seq after 03100 batchs: 627.9808349609375
INFO:root:Train (Epoch 173): Loss/seq after 03150 batchs: 633.5582885742188
INFO:root:Train (Epoch 173): Loss/seq after 03200 batchs: 636.07275390625
INFO:root:Train (Epoch 173): Loss/seq after 03250 batchs: 638.9954223632812
INFO:root:Train (Epoch 173): Loss/seq after 03300 batchs: 638.3140869140625
INFO:root:Train (Epoch 173): Loss/seq after 03350 batchs: 638.4075927734375
INFO:root:Train (Epoch 173): Loss/seq after 03400 batchs: 633.6788330078125
INFO:root:Train (Epoch 173): Loss/seq after 03450 batchs: 631.3761596679688
INFO:root:Train (Epoch 173): Loss/seq after 03500 batchs: 631.184814453125
INFO:root:Train (Epoch 173): Loss/seq after 03550 batchs: 627.8017578125
INFO:root:Train (Epoch 173): Loss/seq after 03600 batchs: 636.1434936523438
INFO:root:Train (Epoch 173): Loss/seq after 03650 batchs: 633.1133422851562
INFO:root:Train (Epoch 173): Loss/seq after 03700 batchs: 634.9041748046875
INFO:root:Train (Epoch 173): Loss/seq after 03750 batchs: 639.1520385742188
INFO:root:Train (Epoch 173): Loss/seq after 03800 batchs: 636.131591796875
INFO:root:Train (Epoch 173): Loss/seq after 03850 batchs: 635.42529296875
INFO:root:Train (Epoch 173): Loss/seq after 03900 batchs: 639.1381225585938
INFO:root:Train (Epoch 173): Loss/seq after 03950 batchs: 642.6622314453125
INFO:root:Train (Epoch 173): Loss/seq after 04000 batchs: 638.4401245117188
INFO:root:Train (Epoch 173): Loss/seq after 04050 batchs: 634.2162475585938
INFO:root:Train (Epoch 173): Loss/seq after 04100 batchs: 631.9666748046875
INFO:root:Train (Epoch 173): Loss/seq after 04150 batchs: 631.3567504882812
INFO:root:Train (Epoch 173): Loss/seq after 04200 batchs: 628.9556884765625
INFO:root:Train (Epoch 173): Loss/seq after 04250 batchs: 626.8385009765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 173): Loss/seq after 00000 batches: 577.653564453125
INFO:root:# Valid (Epoch 173): Loss/seq after 00050 batches: 720.2655639648438
INFO:root:# Valid (Epoch 173): Loss/seq after 00100 batches: 908.8032836914062
INFO:root:# Valid (Epoch 173): Loss/seq after 00150 batches: 679.2664794921875
INFO:root:# Valid (Epoch 173): Loss/seq after 00200 batches: 623.8126831054688
INFO:root:Artifacts: Make stick videos for epoch 173
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_173_on_20220423_104251.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_173_index_120_on_20220423_104251.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 174): Loss/seq after 00000 batchs: 1198.2135009765625
INFO:root:Train (Epoch 174): Loss/seq after 00050 batchs: 904.6672973632812
INFO:root:Train (Epoch 174): Loss/seq after 00100 batchs: 890.48828125
INFO:root:Train (Epoch 174): Loss/seq after 00150 batchs: 783.2511596679688
INFO:root:Train (Epoch 174): Loss/seq after 00200 batchs: 874.6961669921875
INFO:root:Train (Epoch 174): Loss/seq after 00250 batchs: 989.0385131835938
INFO:root:Train (Epoch 174): Loss/seq after 00300 batchs: 975.3125
INFO:root:Train (Epoch 174): Loss/seq after 00350 batchs: 910.7708129882812
INFO:root:Train (Epoch 174): Loss/seq after 00400 batchs: 917.4596557617188
INFO:root:Train (Epoch 174): Loss/seq after 00450 batchs: 893.0012817382812
INFO:root:Train (Epoch 174): Loss/seq after 00500 batchs: 868.878662109375
INFO:root:Train (Epoch 174): Loss/seq after 00550 batchs: 841.5436401367188
INFO:root:Train (Epoch 174): Loss/seq after 00600 batchs: 810.9585571289062
INFO:root:Train (Epoch 174): Loss/seq after 00650 batchs: 798.4476318359375
INFO:root:Train (Epoch 174): Loss/seq after 00700 batchs: 775.652587890625
INFO:root:Train (Epoch 174): Loss/seq after 00750 batchs: 786.4002075195312
INFO:root:Train (Epoch 174): Loss/seq after 00800 batchs: 781.3629760742188
INFO:root:Train (Epoch 174): Loss/seq after 00850 batchs: 756.8133544921875
INFO:root:Train (Epoch 174): Loss/seq after 00900 batchs: 739.2482299804688
INFO:root:Train (Epoch 174): Loss/seq after 00950 batchs: 742.0554809570312
INFO:root:Train (Epoch 174): Loss/seq after 01000 batchs: 735.543212890625
INFO:root:Train (Epoch 174): Loss/seq after 01050 batchs: 720.842529296875
INFO:root:Train (Epoch 174): Loss/seq after 01100 batchs: 708.4290771484375
INFO:root:Train (Epoch 174): Loss/seq after 01150 batchs: 693.3182373046875
INFO:root:Train (Epoch 174): Loss/seq after 01200 batchs: 696.5348510742188
INFO:root:Train (Epoch 174): Loss/seq after 01250 batchs: 692.8359375
INFO:root:Train (Epoch 174): Loss/seq after 01300 batchs: 681.6511840820312
INFO:root:Train (Epoch 174): Loss/seq after 01350 batchs: 672.6262817382812
INFO:root:Train (Epoch 174): Loss/seq after 01400 batchs: 678.2124633789062
INFO:root:Train (Epoch 174): Loss/seq after 01450 batchs: 678.4140014648438
INFO:root:Train (Epoch 174): Loss/seq after 01500 batchs: 682.8319091796875
INFO:root:Train (Epoch 174): Loss/seq after 01550 batchs: 685.0712280273438
INFO:root:Train (Epoch 174): Loss/seq after 01600 batchs: 678.1121215820312
INFO:root:Train (Epoch 174): Loss/seq after 01650 batchs: 673.960205078125
INFO:root:Train (Epoch 174): Loss/seq after 01700 batchs: 674.602294921875
INFO:root:Train (Epoch 174): Loss/seq after 01750 batchs: 671.0269165039062
INFO:root:Train (Epoch 174): Loss/seq after 01800 batchs: 667.1597290039062
INFO:root:Train (Epoch 174): Loss/seq after 01850 batchs: 661.6779174804688
INFO:root:Train (Epoch 174): Loss/seq after 01900 batchs: 661.7413330078125
INFO:root:Train (Epoch 174): Loss/seq after 01950 batchs: 659.2401733398438
INFO:root:Train (Epoch 174): Loss/seq after 02000 batchs: 656.8744506835938
INFO:root:Train (Epoch 174): Loss/seq after 02050 batchs: 654.3858642578125
INFO:root:Train (Epoch 174): Loss/seq after 02100 batchs: 650.5827026367188
INFO:root:Train (Epoch 174): Loss/seq after 02150 batchs: 647.5240478515625
INFO:root:Train (Epoch 174): Loss/seq after 02200 batchs: 643.460205078125
INFO:root:Train (Epoch 174): Loss/seq after 02250 batchs: 642.6408081054688
INFO:root:Train (Epoch 174): Loss/seq after 02300 batchs: 642.1397705078125
INFO:root:Train (Epoch 174): Loss/seq after 02350 batchs: 636.5479736328125
INFO:root:Train (Epoch 174): Loss/seq after 02400 batchs: 636.95703125
INFO:root:Train (Epoch 174): Loss/seq after 02450 batchs: 631.4319458007812
INFO:root:Train (Epoch 174): Loss/seq after 02500 batchs: 622.0831909179688
INFO:root:Train (Epoch 174): Loss/seq after 02550 batchs: 615.5397338867188
INFO:root:Train (Epoch 174): Loss/seq after 02600 batchs: 615.2351684570312
INFO:root:Train (Epoch 174): Loss/seq after 02650 batchs: 612.565185546875
INFO:root:Train (Epoch 174): Loss/seq after 02700 batchs: 610.30029296875
INFO:root:Train (Epoch 174): Loss/seq after 02750 batchs: 612.134521484375
INFO:root:Train (Epoch 174): Loss/seq after 02800 batchs: 613.4358520507812
INFO:root:Train (Epoch 174): Loss/seq after 02850 batchs: 613.2816162109375
INFO:root:Train (Epoch 174): Loss/seq after 02900 batchs: 614.8624267578125
INFO:root:Train (Epoch 174): Loss/seq after 02950 batchs: 613.200927734375
INFO:root:Train (Epoch 174): Loss/seq after 03000 batchs: 617.603515625
INFO:root:Train (Epoch 174): Loss/seq after 03050 batchs: 620.6991577148438
INFO:root:Train (Epoch 174): Loss/seq after 03100 batchs: 625.1683349609375
INFO:root:Train (Epoch 174): Loss/seq after 03150 batchs: 631.5593872070312
INFO:root:Train (Epoch 174): Loss/seq after 03200 batchs: 634.2645263671875
INFO:root:Train (Epoch 174): Loss/seq after 03250 batchs: 637.8359375
INFO:root:Train (Epoch 174): Loss/seq after 03300 batchs: 637.7831420898438
INFO:root:Train (Epoch 174): Loss/seq after 03350 batchs: 638.5065307617188
INFO:root:Train (Epoch 174): Loss/seq after 03400 batchs: 633.7667846679688
INFO:root:Train (Epoch 174): Loss/seq after 03450 batchs: 631.44970703125
INFO:root:Train (Epoch 174): Loss/seq after 03500 batchs: 631.483642578125
INFO:root:Train (Epoch 174): Loss/seq after 03550 batchs: 628.1275634765625
INFO:root:Train (Epoch 174): Loss/seq after 03600 batchs: 636.4964599609375
INFO:root:Train (Epoch 174): Loss/seq after 03650 batchs: 633.3984985351562
INFO:root:Train (Epoch 174): Loss/seq after 03700 batchs: 635.2576293945312
INFO:root:Train (Epoch 174): Loss/seq after 03750 batchs: 639.464111328125
INFO:root:Train (Epoch 174): Loss/seq after 03800 batchs: 636.3724975585938
INFO:root:Train (Epoch 174): Loss/seq after 03850 batchs: 635.515625
INFO:root:Train (Epoch 174): Loss/seq after 03900 batchs: 639.2847290039062
INFO:root:Train (Epoch 174): Loss/seq after 03950 batchs: 642.9426879882812
INFO:root:Train (Epoch 174): Loss/seq after 04000 batchs: 638.5384521484375
INFO:root:Train (Epoch 174): Loss/seq after 04050 batchs: 634.2269287109375
INFO:root:Train (Epoch 174): Loss/seq after 04100 batchs: 632.015625
INFO:root:Train (Epoch 174): Loss/seq after 04150 batchs: 631.2888793945312
INFO:root:Train (Epoch 174): Loss/seq after 04200 batchs: 628.9849853515625
INFO:root:Train (Epoch 174): Loss/seq after 04250 batchs: 626.7107543945312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 174): Loss/seq after 00000 batches: 565.8665161132812
INFO:root:# Valid (Epoch 174): Loss/seq after 00050 batches: 707.107421875
INFO:root:# Valid (Epoch 174): Loss/seq after 00100 batches: 851.7318725585938
INFO:root:# Valid (Epoch 174): Loss/seq after 00150 batches: 636.881591796875
INFO:root:# Valid (Epoch 174): Loss/seq after 00200 batches: 582.2090454101562
INFO:root:Artifacts: Make stick videos for epoch 174
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_174_on_20220423_104736.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_174_index_1791_on_20220423_104736.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 175): Loss/seq after 00000 batchs: 1320.126220703125
INFO:root:Train (Epoch 175): Loss/seq after 00050 batchs: 898.6143188476562
INFO:root:Train (Epoch 175): Loss/seq after 00100 batchs: 907.5891723632812
INFO:root:Train (Epoch 175): Loss/seq after 00150 batchs: 794.2977294921875
INFO:root:Train (Epoch 175): Loss/seq after 00200 batchs: 878.0199584960938
INFO:root:Train (Epoch 175): Loss/seq after 00250 batchs: 985.6620483398438
INFO:root:Train (Epoch 175): Loss/seq after 00300 batchs: 971.09228515625
INFO:root:Train (Epoch 175): Loss/seq after 00350 batchs: 905.7847900390625
INFO:root:Train (Epoch 175): Loss/seq after 00400 batchs: 914.62548828125
INFO:root:Train (Epoch 175): Loss/seq after 00450 batchs: 889.7408447265625
INFO:root:Train (Epoch 175): Loss/seq after 00500 batchs: 862.9871826171875
INFO:root:Train (Epoch 175): Loss/seq after 00550 batchs: 835.0150756835938
INFO:root:Train (Epoch 175): Loss/seq after 00600 batchs: 804.2715454101562
INFO:root:Train (Epoch 175): Loss/seq after 00650 batchs: 797.0841674804688
INFO:root:Train (Epoch 175): Loss/seq after 00700 batchs: 775.1644897460938
INFO:root:Train (Epoch 175): Loss/seq after 00750 batchs: 789.5152587890625
INFO:root:Train (Epoch 175): Loss/seq after 00800 batchs: 785.397216796875
INFO:root:Train (Epoch 175): Loss/seq after 00850 batchs: 760.8653564453125
INFO:root:Train (Epoch 175): Loss/seq after 00900 batchs: 743.908935546875
INFO:root:Train (Epoch 175): Loss/seq after 00950 batchs: 746.236083984375
INFO:root:Train (Epoch 175): Loss/seq after 01000 batchs: 737.8907470703125
INFO:root:Train (Epoch 175): Loss/seq after 01050 batchs: 724.824462890625
INFO:root:Train (Epoch 175): Loss/seq after 01100 batchs: 712.3412475585938
INFO:root:Train (Epoch 175): Loss/seq after 01150 batchs: 696.0265502929688
INFO:root:Train (Epoch 175): Loss/seq after 01200 batchs: 698.71826171875
INFO:root:Train (Epoch 175): Loss/seq after 01250 batchs: 694.8333740234375
INFO:root:Train (Epoch 175): Loss/seq after 01300 batchs: 683.9821166992188
INFO:root:Train (Epoch 175): Loss/seq after 01350 batchs: 675.0908203125
INFO:root:Train (Epoch 175): Loss/seq after 01400 batchs: 682.9308471679688
INFO:root:Train (Epoch 175): Loss/seq after 01450 batchs: 683.1570434570312
INFO:root:Train (Epoch 175): Loss/seq after 01500 batchs: 687.2510375976562
INFO:root:Train (Epoch 175): Loss/seq after 01550 batchs: 689.5787963867188
INFO:root:Train (Epoch 175): Loss/seq after 01600 batchs: 682.6913452148438
INFO:root:Train (Epoch 175): Loss/seq after 01650 batchs: 678.255126953125
INFO:root:Train (Epoch 175): Loss/seq after 01700 batchs: 678.6011962890625
INFO:root:Train (Epoch 175): Loss/seq after 01750 batchs: 674.8278198242188
INFO:root:Train (Epoch 175): Loss/seq after 01800 batchs: 670.8134155273438
INFO:root:Train (Epoch 175): Loss/seq after 01850 batchs: 665.0640258789062
INFO:root:Train (Epoch 175): Loss/seq after 01900 batchs: 664.50537109375
INFO:root:Train (Epoch 175): Loss/seq after 01950 batchs: 662.0923461914062
INFO:root:Train (Epoch 175): Loss/seq after 02000 batchs: 659.9714965820312
INFO:root:Train (Epoch 175): Loss/seq after 02050 batchs: 657.1696166992188
INFO:root:Train (Epoch 175): Loss/seq after 02100 batchs: 652.958984375
INFO:root:Train (Epoch 175): Loss/seq after 02150 batchs: 649.9679565429688
INFO:root:Train (Epoch 175): Loss/seq after 02200 batchs: 645.7800903320312
INFO:root:Train (Epoch 175): Loss/seq after 02250 batchs: 644.5680541992188
INFO:root:Train (Epoch 175): Loss/seq after 02300 batchs: 643.7421264648438
INFO:root:Train (Epoch 175): Loss/seq after 02350 batchs: 637.9436645507812
INFO:root:Train (Epoch 175): Loss/seq after 02400 batchs: 638.3164672851562
INFO:root:Train (Epoch 175): Loss/seq after 02450 batchs: 632.875732421875
INFO:root:Train (Epoch 175): Loss/seq after 02500 batchs: 623.4937744140625
INFO:root:Train (Epoch 175): Loss/seq after 02550 batchs: 616.8218994140625
INFO:root:Train (Epoch 175): Loss/seq after 02600 batchs: 616.6912841796875
INFO:root:Train (Epoch 175): Loss/seq after 02650 batchs: 614.3466186523438
INFO:root:Train (Epoch 175): Loss/seq after 02700 batchs: 611.8009643554688
INFO:root:Train (Epoch 175): Loss/seq after 02750 batchs: 612.884521484375
INFO:root:Train (Epoch 175): Loss/seq after 02800 batchs: 613.751220703125
INFO:root:Train (Epoch 175): Loss/seq after 02850 batchs: 613.7693481445312
INFO:root:Train (Epoch 175): Loss/seq after 02900 batchs: 615.0844116210938
INFO:root:Train (Epoch 175): Loss/seq after 02950 batchs: 613.3605346679688
INFO:root:Train (Epoch 175): Loss/seq after 03000 batchs: 617.8118896484375
INFO:root:Train (Epoch 175): Loss/seq after 03050 batchs: 622.14501953125
INFO:root:Train (Epoch 175): Loss/seq after 03100 batchs: 625.52685546875
INFO:root:Train (Epoch 175): Loss/seq after 03150 batchs: 632.0153198242188
INFO:root:Train (Epoch 175): Loss/seq after 03200 batchs: 633.651123046875
INFO:root:Train (Epoch 175): Loss/seq after 03250 batchs: 636.709716796875
INFO:root:Train (Epoch 175): Loss/seq after 03300 batchs: 635.8909301757812
INFO:root:Train (Epoch 175): Loss/seq after 03350 batchs: 636.31103515625
INFO:root:Train (Epoch 175): Loss/seq after 03400 batchs: 631.7330322265625
INFO:root:Train (Epoch 175): Loss/seq after 03450 batchs: 629.35107421875
INFO:root:Train (Epoch 175): Loss/seq after 03500 batchs: 629.1722412109375
INFO:root:Train (Epoch 175): Loss/seq after 03550 batchs: 625.9241943359375
INFO:root:Train (Epoch 175): Loss/seq after 03600 batchs: 634.2908935546875
INFO:root:Train (Epoch 175): Loss/seq after 03650 batchs: 631.2034912109375
INFO:root:Train (Epoch 175): Loss/seq after 03700 batchs: 633.0231323242188
INFO:root:Train (Epoch 175): Loss/seq after 03750 batchs: 637.1275024414062
INFO:root:Train (Epoch 175): Loss/seq after 03800 batchs: 634.083740234375
INFO:root:Train (Epoch 175): Loss/seq after 03850 batchs: 633.2910766601562
INFO:root:Train (Epoch 175): Loss/seq after 03900 batchs: 636.8087768554688
INFO:root:Train (Epoch 175): Loss/seq after 03950 batchs: 640.4142456054688
INFO:root:Train (Epoch 175): Loss/seq after 04000 batchs: 636.1500244140625
INFO:root:Train (Epoch 175): Loss/seq after 04050 batchs: 631.9253540039062
INFO:root:Train (Epoch 175): Loss/seq after 04100 batchs: 629.6441040039062
INFO:root:Train (Epoch 175): Loss/seq after 04150 batchs: 628.8897705078125
INFO:root:Train (Epoch 175): Loss/seq after 04200 batchs: 626.5419311523438
INFO:root:Train (Epoch 175): Loss/seq after 04250 batchs: 624.4319458007812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 175): Loss/seq after 00000 batches: 540.5452880859375
INFO:root:# Valid (Epoch 175): Loss/seq after 00050 batches: 707.9481201171875
INFO:root:# Valid (Epoch 175): Loss/seq after 00100 batches: 799.3186645507812
INFO:root:# Valid (Epoch 175): Loss/seq after 00150 batches: 607.3064575195312
INFO:root:# Valid (Epoch 175): Loss/seq after 00200 batches: 565.1060791015625
INFO:root:Artifacts: Make stick videos for epoch 175
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_175_on_20220423_105231.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_175_index_781_on_20220423_105231.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 176): Loss/seq after 00000 batchs: 1251.5233154296875
INFO:root:Train (Epoch 176): Loss/seq after 00050 batchs: 934.7583618164062
INFO:root:Train (Epoch 176): Loss/seq after 00100 batchs: 916.3087768554688
INFO:root:Train (Epoch 176): Loss/seq after 00150 batchs: 805.8219604492188
INFO:root:Train (Epoch 176): Loss/seq after 00200 batchs: 892.6895141601562
INFO:root:Train (Epoch 176): Loss/seq after 00250 batchs: 995.439697265625
INFO:root:Train (Epoch 176): Loss/seq after 00300 batchs: 979.68505859375
INFO:root:Train (Epoch 176): Loss/seq after 00350 batchs: 914.9982299804688
INFO:root:Train (Epoch 176): Loss/seq after 00400 batchs: 918.780029296875
INFO:root:Train (Epoch 176): Loss/seq after 00450 batchs: 892.39501953125
INFO:root:Train (Epoch 176): Loss/seq after 00500 batchs: 866.5343017578125
INFO:root:Train (Epoch 176): Loss/seq after 00550 batchs: 837.8333129882812
INFO:root:Train (Epoch 176): Loss/seq after 00600 batchs: 807.417724609375
INFO:root:Train (Epoch 176): Loss/seq after 00650 batchs: 794.1281127929688
INFO:root:Train (Epoch 176): Loss/seq after 00700 batchs: 769.4367065429688
INFO:root:Train (Epoch 176): Loss/seq after 00750 batchs: 784.1891479492188
INFO:root:Train (Epoch 176): Loss/seq after 00800 batchs: 779.4710083007812
INFO:root:Train (Epoch 176): Loss/seq after 00850 batchs: 755.896240234375
INFO:root:Train (Epoch 176): Loss/seq after 00900 batchs: 738.3333129882812
INFO:root:Train (Epoch 176): Loss/seq after 00950 batchs: 740.3623046875
INFO:root:Train (Epoch 176): Loss/seq after 01000 batchs: 732.4589233398438
INFO:root:Train (Epoch 176): Loss/seq after 01050 batchs: 718.5534057617188
INFO:root:Train (Epoch 176): Loss/seq after 01100 batchs: 705.620361328125
INFO:root:Train (Epoch 176): Loss/seq after 01150 batchs: 689.4640502929688
INFO:root:Train (Epoch 176): Loss/seq after 01200 batchs: 692.5119018554688
INFO:root:Train (Epoch 176): Loss/seq after 01250 batchs: 688.7586669921875
INFO:root:Train (Epoch 176): Loss/seq after 01300 batchs: 677.7279663085938
INFO:root:Train (Epoch 176): Loss/seq after 01350 batchs: 668.677001953125
INFO:root:Train (Epoch 176): Loss/seq after 01400 batchs: 673.243896484375
INFO:root:Train (Epoch 176): Loss/seq after 01450 batchs: 672.849609375
INFO:root:Train (Epoch 176): Loss/seq after 01500 batchs: 677.3628540039062
INFO:root:Train (Epoch 176): Loss/seq after 01550 batchs: 679.783935546875
INFO:root:Train (Epoch 176): Loss/seq after 01600 batchs: 672.8717651367188
INFO:root:Train (Epoch 176): Loss/seq after 01650 batchs: 668.491943359375
INFO:root:Train (Epoch 176): Loss/seq after 01700 batchs: 669.071533203125
INFO:root:Train (Epoch 176): Loss/seq after 01750 batchs: 665.2362670898438
INFO:root:Train (Epoch 176): Loss/seq after 01800 batchs: 661.2899780273438
INFO:root:Train (Epoch 176): Loss/seq after 01850 batchs: 655.7257080078125
INFO:root:Train (Epoch 176): Loss/seq after 01900 batchs: 655.5120849609375
INFO:root:Train (Epoch 176): Loss/seq after 01950 batchs: 653.1558837890625
INFO:root:Train (Epoch 176): Loss/seq after 02000 batchs: 650.7951049804688
INFO:root:Train (Epoch 176): Loss/seq after 02050 batchs: 648.054443359375
INFO:root:Train (Epoch 176): Loss/seq after 02100 batchs: 644.0886840820312
INFO:root:Train (Epoch 176): Loss/seq after 02150 batchs: 641.158203125
INFO:root:Train (Epoch 176): Loss/seq after 02200 batchs: 637.0447387695312
INFO:root:Train (Epoch 176): Loss/seq after 02250 batchs: 635.8046875
INFO:root:Train (Epoch 176): Loss/seq after 02300 batchs: 635.171630859375
INFO:root:Train (Epoch 176): Loss/seq after 02350 batchs: 629.5372314453125
INFO:root:Train (Epoch 176): Loss/seq after 02400 batchs: 630.03173828125
INFO:root:Train (Epoch 176): Loss/seq after 02450 batchs: 624.5382080078125
INFO:root:Train (Epoch 176): Loss/seq after 02500 batchs: 615.33447265625
INFO:root:Train (Epoch 176): Loss/seq after 02550 batchs: 608.8526000976562
INFO:root:Train (Epoch 176): Loss/seq after 02600 batchs: 608.5453491210938
INFO:root:Train (Epoch 176): Loss/seq after 02650 batchs: 605.9487915039062
INFO:root:Train (Epoch 176): Loss/seq after 02700 batchs: 603.58154296875
INFO:root:Train (Epoch 176): Loss/seq after 02750 batchs: 603.8970336914062
INFO:root:Train (Epoch 176): Loss/seq after 02800 batchs: 606.14208984375
INFO:root:Train (Epoch 176): Loss/seq after 02850 batchs: 605.8109130859375
INFO:root:Train (Epoch 176): Loss/seq after 02900 batchs: 606.9579467773438
INFO:root:Train (Epoch 176): Loss/seq after 02950 batchs: 605.26611328125
INFO:root:Train (Epoch 176): Loss/seq after 03000 batchs: 609.7464599609375
INFO:root:Train (Epoch 176): Loss/seq after 03050 batchs: 613.2258911132812
INFO:root:Train (Epoch 176): Loss/seq after 03100 batchs: 617.146728515625
INFO:root:Train (Epoch 176): Loss/seq after 03150 batchs: 623.7394409179688
INFO:root:Train (Epoch 176): Loss/seq after 03200 batchs: 625.529541015625
INFO:root:Train (Epoch 176): Loss/seq after 03250 batchs: 628.454833984375
INFO:root:Train (Epoch 176): Loss/seq after 03300 batchs: 627.9479370117188
INFO:root:Train (Epoch 176): Loss/seq after 03350 batchs: 627.8495483398438
INFO:root:Train (Epoch 176): Loss/seq after 03400 batchs: 623.403564453125
INFO:root:Train (Epoch 176): Loss/seq after 03450 batchs: 621.0375366210938
INFO:root:Train (Epoch 176): Loss/seq after 03500 batchs: 620.5894775390625
INFO:root:Train (Epoch 176): Loss/seq after 03550 batchs: 617.1459350585938
INFO:root:Train (Epoch 176): Loss/seq after 03600 batchs: 625.0279541015625
INFO:root:Train (Epoch 176): Loss/seq after 03650 batchs: 622.0216674804688
INFO:root:Train (Epoch 176): Loss/seq after 03700 batchs: 624.0147705078125
INFO:root:Train (Epoch 176): Loss/seq after 03750 batchs: 628.22607421875
INFO:root:Train (Epoch 176): Loss/seq after 03800 batchs: 625.2073974609375
INFO:root:Train (Epoch 176): Loss/seq after 03850 batchs: 624.0921630859375
INFO:root:Train (Epoch 176): Loss/seq after 03900 batchs: 627.9718627929688
INFO:root:Train (Epoch 176): Loss/seq after 03950 batchs: 631.776123046875
INFO:root:Train (Epoch 176): Loss/seq after 04000 batchs: 627.5909423828125
INFO:root:Train (Epoch 176): Loss/seq after 04050 batchs: 623.4398803710938
INFO:root:Train (Epoch 176): Loss/seq after 04100 batchs: 621.343994140625
INFO:root:Train (Epoch 176): Loss/seq after 04150 batchs: 620.7123413085938
INFO:root:Train (Epoch 176): Loss/seq after 04200 batchs: 618.4961547851562
INFO:root:Train (Epoch 176): Loss/seq after 04250 batchs: 616.4476928710938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 176): Loss/seq after 00000 batches: 573.925537109375
INFO:root:# Valid (Epoch 176): Loss/seq after 00050 batches: 708.6314086914062
INFO:root:# Valid (Epoch 176): Loss/seq after 00100 batches: 829.2520751953125
INFO:root:# Valid (Epoch 176): Loss/seq after 00150 batches: 618.7061157226562
INFO:root:# Valid (Epoch 176): Loss/seq after 00200 batches: 568.3933715820312
INFO:root:Artifacts: Make stick videos for epoch 176
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_176_on_20220423_105724.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_176_index_408_on_20220423_105724.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 177): Loss/seq after 00000 batchs: 1266.3671875
INFO:root:Train (Epoch 177): Loss/seq after 00050 batchs: 892.8543701171875
INFO:root:Train (Epoch 177): Loss/seq after 00100 batchs: 877.432861328125
INFO:root:Train (Epoch 177): Loss/seq after 00150 batchs: 774.5501098632812
INFO:root:Train (Epoch 177): Loss/seq after 00200 batchs: 870.369384765625
INFO:root:Train (Epoch 177): Loss/seq after 00250 batchs: 977.3194580078125
INFO:root:Train (Epoch 177): Loss/seq after 00300 batchs: 964.009521484375
INFO:root:Train (Epoch 177): Loss/seq after 00350 batchs: 899.042724609375
INFO:root:Train (Epoch 177): Loss/seq after 00400 batchs: 904.5814819335938
INFO:root:Train (Epoch 177): Loss/seq after 00450 batchs: 879.8603515625
INFO:root:Train (Epoch 177): Loss/seq after 00500 batchs: 855.4288940429688
INFO:root:Train (Epoch 177): Loss/seq after 00550 batchs: 827.21044921875
INFO:root:Train (Epoch 177): Loss/seq after 00600 batchs: 797.2166137695312
INFO:root:Train (Epoch 177): Loss/seq after 00650 batchs: 784.2442626953125
INFO:root:Train (Epoch 177): Loss/seq after 00700 batchs: 759.2872924804688
INFO:root:Train (Epoch 177): Loss/seq after 00750 batchs: 776.2518920898438
INFO:root:Train (Epoch 177): Loss/seq after 00800 batchs: 772.4600830078125
INFO:root:Train (Epoch 177): Loss/seq after 00850 batchs: 748.9569702148438
INFO:root:Train (Epoch 177): Loss/seq after 00900 batchs: 730.5504760742188
INFO:root:Train (Epoch 177): Loss/seq after 00950 batchs: 733.4962768554688
INFO:root:Train (Epoch 177): Loss/seq after 01000 batchs: 725.9810791015625
INFO:root:Train (Epoch 177): Loss/seq after 01050 batchs: 712.5974731445312
INFO:root:Train (Epoch 177): Loss/seq after 01100 batchs: 700.3342895507812
INFO:root:Train (Epoch 177): Loss/seq after 01150 batchs: 684.15576171875
INFO:root:Train (Epoch 177): Loss/seq after 01200 batchs: 687.0040283203125
INFO:root:Train (Epoch 177): Loss/seq after 01250 batchs: 683.378173828125
INFO:root:Train (Epoch 177): Loss/seq after 01300 batchs: 671.4837036132812
INFO:root:Train (Epoch 177): Loss/seq after 01350 batchs: 661.506103515625
INFO:root:Train (Epoch 177): Loss/seq after 01400 batchs: 665.9213256835938
INFO:root:Train (Epoch 177): Loss/seq after 01450 batchs: 666.2694091796875
INFO:root:Train (Epoch 177): Loss/seq after 01500 batchs: 670.8953247070312
INFO:root:Train (Epoch 177): Loss/seq after 01550 batchs: 672.60546875
INFO:root:Train (Epoch 177): Loss/seq after 01600 batchs: 665.4893798828125
INFO:root:Train (Epoch 177): Loss/seq after 01650 batchs: 661.1298828125
INFO:root:Train (Epoch 177): Loss/seq after 01700 batchs: 662.06396484375
INFO:root:Train (Epoch 177): Loss/seq after 01750 batchs: 658.4765625
INFO:root:Train (Epoch 177): Loss/seq after 01800 batchs: 654.7310180664062
INFO:root:Train (Epoch 177): Loss/seq after 01850 batchs: 649.503173828125
INFO:root:Train (Epoch 177): Loss/seq after 01900 batchs: 649.2451782226562
INFO:root:Train (Epoch 177): Loss/seq after 01950 batchs: 647.0335083007812
INFO:root:Train (Epoch 177): Loss/seq after 02000 batchs: 644.70166015625
INFO:root:Train (Epoch 177): Loss/seq after 02050 batchs: 642.1588134765625
INFO:root:Train (Epoch 177): Loss/seq after 02100 batchs: 638.4063110351562
INFO:root:Train (Epoch 177): Loss/seq after 02150 batchs: 635.3602294921875
INFO:root:Train (Epoch 177): Loss/seq after 02200 batchs: 631.41748046875
INFO:root:Train (Epoch 177): Loss/seq after 02250 batchs: 630.633544921875
INFO:root:Train (Epoch 177): Loss/seq after 02300 batchs: 629.8248291015625
INFO:root:Train (Epoch 177): Loss/seq after 02350 batchs: 624.3880615234375
INFO:root:Train (Epoch 177): Loss/seq after 02400 batchs: 624.8780517578125
INFO:root:Train (Epoch 177): Loss/seq after 02450 batchs: 619.6511840820312
INFO:root:Train (Epoch 177): Loss/seq after 02500 batchs: 610.4959716796875
INFO:root:Train (Epoch 177): Loss/seq after 02550 batchs: 604.101318359375
INFO:root:Train (Epoch 177): Loss/seq after 02600 batchs: 603.5364990234375
INFO:root:Train (Epoch 177): Loss/seq after 02650 batchs: 601.0264282226562
INFO:root:Train (Epoch 177): Loss/seq after 02700 batchs: 598.8646850585938
INFO:root:Train (Epoch 177): Loss/seq after 02750 batchs: 599.3930053710938
INFO:root:Train (Epoch 177): Loss/seq after 02800 batchs: 600.5186767578125
INFO:root:Train (Epoch 177): Loss/seq after 02850 batchs: 600.2671508789062
INFO:root:Train (Epoch 177): Loss/seq after 02900 batchs: 601.620849609375
INFO:root:Train (Epoch 177): Loss/seq after 02950 batchs: 599.9298706054688
INFO:root:Train (Epoch 177): Loss/seq after 03000 batchs: 604.465087890625
INFO:root:Train (Epoch 177): Loss/seq after 03050 batchs: 607.4873046875
INFO:root:Train (Epoch 177): Loss/seq after 03100 batchs: 611.4320068359375
INFO:root:Train (Epoch 177): Loss/seq after 03150 batchs: 618.4514770507812
INFO:root:Train (Epoch 177): Loss/seq after 03200 batchs: 620.4290771484375
INFO:root:Train (Epoch 177): Loss/seq after 03250 batchs: 623.9186401367188
INFO:root:Train (Epoch 177): Loss/seq after 03300 batchs: 622.875
INFO:root:Train (Epoch 177): Loss/seq after 03350 batchs: 623.1692504882812
INFO:root:Train (Epoch 177): Loss/seq after 03400 batchs: 618.5021362304688
INFO:root:Train (Epoch 177): Loss/seq after 03450 batchs: 616.1692504882812
INFO:root:Train (Epoch 177): Loss/seq after 03500 batchs: 615.5786743164062
INFO:root:Train (Epoch 177): Loss/seq after 03550 batchs: 612.2798461914062
INFO:root:Train (Epoch 177): Loss/seq after 03600 batchs: 620.4769287109375
INFO:root:Train (Epoch 177): Loss/seq after 03650 batchs: 617.6380615234375
INFO:root:Train (Epoch 177): Loss/seq after 03700 batchs: 619.3645629882812
INFO:root:Train (Epoch 177): Loss/seq after 03750 batchs: 623.360107421875
INFO:root:Train (Epoch 177): Loss/seq after 03800 batchs: 620.4091186523438
INFO:root:Train (Epoch 177): Loss/seq after 03850 batchs: 619.1007080078125
INFO:root:Train (Epoch 177): Loss/seq after 03900 batchs: 622.9171752929688
INFO:root:Train (Epoch 177): Loss/seq after 03950 batchs: 626.3486938476562
INFO:root:Train (Epoch 177): Loss/seq after 04000 batchs: 622.0344848632812
INFO:root:Train (Epoch 177): Loss/seq after 04050 batchs: 617.9019165039062
INFO:root:Train (Epoch 177): Loss/seq after 04100 batchs: 615.8463745117188
INFO:root:Train (Epoch 177): Loss/seq after 04150 batchs: 615.2225952148438
INFO:root:Train (Epoch 177): Loss/seq after 04200 batchs: 612.8782348632812
INFO:root:Train (Epoch 177): Loss/seq after 04250 batchs: 610.7556762695312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 177): Loss/seq after 00000 batches: 588.1048583984375
INFO:root:# Valid (Epoch 177): Loss/seq after 00050 batches: 695.2117919921875
INFO:root:# Valid (Epoch 177): Loss/seq after 00100 batches: 814.2005615234375
INFO:root:# Valid (Epoch 177): Loss/seq after 00150 batches: 612.3759765625
INFO:root:# Valid (Epoch 177): Loss/seq after 00200 batches: 566.2960815429688
INFO:root:Artifacts: Make stick videos for epoch 177
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_177_on_20220423_110226.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_177_index_1158_on_20220423_110226.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 178): Loss/seq after 00000 batchs: 1367.888427734375
INFO:root:Train (Epoch 178): Loss/seq after 00050 batchs: 889.9888305664062
INFO:root:Train (Epoch 178): Loss/seq after 00100 batchs: 864.9793090820312
INFO:root:Train (Epoch 178): Loss/seq after 00150 batchs: 761.1754150390625
INFO:root:Train (Epoch 178): Loss/seq after 00200 batchs: 870.6411743164062
INFO:root:Train (Epoch 178): Loss/seq after 00250 batchs: 975.5875244140625
INFO:root:Train (Epoch 178): Loss/seq after 00300 batchs: 962.213623046875
INFO:root:Train (Epoch 178): Loss/seq after 00350 batchs: 897.8658447265625
INFO:root:Train (Epoch 178): Loss/seq after 00400 batchs: 906.6422729492188
INFO:root:Train (Epoch 178): Loss/seq after 00450 batchs: 881.910400390625
INFO:root:Train (Epoch 178): Loss/seq after 00500 batchs: 857.8953247070312
INFO:root:Train (Epoch 178): Loss/seq after 00550 batchs: 830.1724853515625
INFO:root:Train (Epoch 178): Loss/seq after 00600 batchs: 799.9622802734375
INFO:root:Train (Epoch 178): Loss/seq after 00650 batchs: 787.037841796875
INFO:root:Train (Epoch 178): Loss/seq after 00700 batchs: 762.9647827148438
INFO:root:Train (Epoch 178): Loss/seq after 00750 batchs: 780.0243530273438
INFO:root:Train (Epoch 178): Loss/seq after 00800 batchs: 775.889404296875
INFO:root:Train (Epoch 178): Loss/seq after 00850 batchs: 752.1207885742188
INFO:root:Train (Epoch 178): Loss/seq after 00900 batchs: 732.7283325195312
INFO:root:Train (Epoch 178): Loss/seq after 00950 batchs: 735.8721923828125
INFO:root:Train (Epoch 178): Loss/seq after 01000 batchs: 728.3143310546875
INFO:root:Train (Epoch 178): Loss/seq after 01050 batchs: 713.9655151367188
INFO:root:Train (Epoch 178): Loss/seq after 01100 batchs: 701.6736450195312
INFO:root:Train (Epoch 178): Loss/seq after 01150 batchs: 686.0010986328125
INFO:root:Train (Epoch 178): Loss/seq after 01200 batchs: 688.723388671875
INFO:root:Train (Epoch 178): Loss/seq after 01250 batchs: 684.8567504882812
INFO:root:Train (Epoch 178): Loss/seq after 01300 batchs: 674.06640625
INFO:root:Train (Epoch 178): Loss/seq after 01350 batchs: 665.3837890625
INFO:root:Train (Epoch 178): Loss/seq after 01400 batchs: 671.7009887695312
INFO:root:Train (Epoch 178): Loss/seq after 01450 batchs: 671.457763671875
INFO:root:Train (Epoch 178): Loss/seq after 01500 batchs: 675.7733764648438
INFO:root:Train (Epoch 178): Loss/seq after 01550 batchs: 678.281982421875
INFO:root:Train (Epoch 178): Loss/seq after 01600 batchs: 670.8997192382812
INFO:root:Train (Epoch 178): Loss/seq after 01650 batchs: 666.5672607421875
INFO:root:Train (Epoch 178): Loss/seq after 01700 batchs: 667.3046264648438
INFO:root:Train (Epoch 178): Loss/seq after 01750 batchs: 663.291015625
INFO:root:Train (Epoch 178): Loss/seq after 01800 batchs: 659.3222045898438
INFO:root:Train (Epoch 178): Loss/seq after 01850 batchs: 654.0194702148438
INFO:root:Train (Epoch 178): Loss/seq after 01900 batchs: 653.3329467773438
INFO:root:Train (Epoch 178): Loss/seq after 01950 batchs: 650.9440307617188
INFO:root:Train (Epoch 178): Loss/seq after 02000 batchs: 648.6942749023438
INFO:root:Train (Epoch 178): Loss/seq after 02050 batchs: 646.0883178710938
INFO:root:Train (Epoch 178): Loss/seq after 02100 batchs: 642.1497192382812
INFO:root:Train (Epoch 178): Loss/seq after 02150 batchs: 638.819580078125
INFO:root:Train (Epoch 178): Loss/seq after 02200 batchs: 634.8328247070312
INFO:root:Train (Epoch 178): Loss/seq after 02250 batchs: 633.6712646484375
INFO:root:Train (Epoch 178): Loss/seq after 02300 batchs: 634.1903686523438
INFO:root:Train (Epoch 178): Loss/seq after 02350 batchs: 628.4259033203125
INFO:root:Train (Epoch 178): Loss/seq after 02400 batchs: 628.9027099609375
INFO:root:Train (Epoch 178): Loss/seq after 02450 batchs: 623.3887939453125
INFO:root:Train (Epoch 178): Loss/seq after 02500 batchs: 614.1204223632812
INFO:root:Train (Epoch 178): Loss/seq after 02550 batchs: 607.57080078125
INFO:root:Train (Epoch 178): Loss/seq after 02600 batchs: 606.8992919921875
INFO:root:Train (Epoch 178): Loss/seq after 02650 batchs: 603.9796752929688
INFO:root:Train (Epoch 178): Loss/seq after 02700 batchs: 601.8323364257812
INFO:root:Train (Epoch 178): Loss/seq after 02750 batchs: 601.4197998046875
INFO:root:Train (Epoch 178): Loss/seq after 02800 batchs: 602.3905639648438
INFO:root:Train (Epoch 178): Loss/seq after 02850 batchs: 602.18798828125
INFO:root:Train (Epoch 178): Loss/seq after 02900 batchs: 603.4126586914062
INFO:root:Train (Epoch 178): Loss/seq after 02950 batchs: 601.7579956054688
INFO:root:Train (Epoch 178): Loss/seq after 03000 batchs: 606.1761474609375
INFO:root:Train (Epoch 178): Loss/seq after 03050 batchs: 609.5993041992188
INFO:root:Train (Epoch 178): Loss/seq after 03100 batchs: 613.0054321289062
INFO:root:Train (Epoch 178): Loss/seq after 03150 batchs: 618.9917602539062
INFO:root:Train (Epoch 178): Loss/seq after 03200 batchs: 621.3646850585938
INFO:root:Train (Epoch 178): Loss/seq after 03250 batchs: 624.1304321289062
INFO:root:Train (Epoch 178): Loss/seq after 03300 batchs: 623.0888671875
INFO:root:Train (Epoch 178): Loss/seq after 03350 batchs: 623.4461669921875
INFO:root:Train (Epoch 178): Loss/seq after 03400 batchs: 618.8349609375
INFO:root:Train (Epoch 178): Loss/seq after 03450 batchs: 616.6268310546875
INFO:root:Train (Epoch 178): Loss/seq after 03500 batchs: 616.2827758789062
INFO:root:Train (Epoch 178): Loss/seq after 03550 batchs: 613.15771484375
INFO:root:Train (Epoch 178): Loss/seq after 03600 batchs: 621.1005249023438
INFO:root:Train (Epoch 178): Loss/seq after 03650 batchs: 618.223388671875
INFO:root:Train (Epoch 178): Loss/seq after 03700 batchs: 619.942626953125
INFO:root:Train (Epoch 178): Loss/seq after 03750 batchs: 624.0311889648438
INFO:root:Train (Epoch 178): Loss/seq after 03800 batchs: 621.0494384765625
INFO:root:Train (Epoch 178): Loss/seq after 03850 batchs: 620.1132202148438
INFO:root:Train (Epoch 178): Loss/seq after 03900 batchs: 623.823974609375
INFO:root:Train (Epoch 178): Loss/seq after 03950 batchs: 627.6420288085938
INFO:root:Train (Epoch 178): Loss/seq after 04000 batchs: 623.2693481445312
INFO:root:Train (Epoch 178): Loss/seq after 04050 batchs: 619.0700073242188
INFO:root:Train (Epoch 178): Loss/seq after 04100 batchs: 616.8914184570312
INFO:root:Train (Epoch 178): Loss/seq after 04150 batchs: 616.1856689453125
INFO:root:Train (Epoch 178): Loss/seq after 04200 batchs: 613.8143920898438
INFO:root:Train (Epoch 178): Loss/seq after 04250 batchs: 611.5965576171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 178): Loss/seq after 00000 batches: 577.6079711914062
INFO:root:# Valid (Epoch 178): Loss/seq after 00050 batches: 694.9019165039062
INFO:root:# Valid (Epoch 178): Loss/seq after 00100 batches: 794.0562133789062
INFO:root:# Valid (Epoch 178): Loss/seq after 00150 batches: 600.2960205078125
INFO:root:# Valid (Epoch 178): Loss/seq after 00200 batches: 555.7382202148438
INFO:root:Artifacts: Make stick videos for epoch 178
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_178_on_20220423_110715.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_178_index_162_on_20220423_110715.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 179): Loss/seq after 00000 batchs: 1320.90478515625
INFO:root:Train (Epoch 179): Loss/seq after 00050 batchs: 889.2622680664062
INFO:root:Train (Epoch 179): Loss/seq after 00100 batchs: 873.9850463867188
INFO:root:Train (Epoch 179): Loss/seq after 00150 batchs: 765.8707885742188
INFO:root:Train (Epoch 179): Loss/seq after 00200 batchs: 861.8248901367188
INFO:root:Train (Epoch 179): Loss/seq after 00250 batchs: 961.2553100585938
INFO:root:Train (Epoch 179): Loss/seq after 00300 batchs: 948.1392211914062
INFO:root:Train (Epoch 179): Loss/seq after 00350 batchs: 885.4662475585938
INFO:root:Train (Epoch 179): Loss/seq after 00400 batchs: 896.0620727539062
INFO:root:Train (Epoch 179): Loss/seq after 00450 batchs: 871.6036987304688
INFO:root:Train (Epoch 179): Loss/seq after 00500 batchs: 846.8369750976562
INFO:root:Train (Epoch 179): Loss/seq after 00550 batchs: 818.9169311523438
INFO:root:Train (Epoch 179): Loss/seq after 00600 batchs: 788.7030029296875
INFO:root:Train (Epoch 179): Loss/seq after 00650 batchs: 778.5088500976562
INFO:root:Train (Epoch 179): Loss/seq after 00700 batchs: 755.4396362304688
INFO:root:Train (Epoch 179): Loss/seq after 00750 batchs: 767.247802734375
INFO:root:Train (Epoch 179): Loss/seq after 00800 batchs: 764.2815551757812
INFO:root:Train (Epoch 179): Loss/seq after 00850 batchs: 740.6004638671875
INFO:root:Train (Epoch 179): Loss/seq after 00900 batchs: 722.4984130859375
INFO:root:Train (Epoch 179): Loss/seq after 00950 batchs: 725.9103393554688
INFO:root:Train (Epoch 179): Loss/seq after 01000 batchs: 718.11474609375
INFO:root:Train (Epoch 179): Loss/seq after 01050 batchs: 704.169921875
INFO:root:Train (Epoch 179): Loss/seq after 01100 batchs: 694.0402221679688
INFO:root:Train (Epoch 179): Loss/seq after 01150 batchs: 678.43701171875
INFO:root:Train (Epoch 179): Loss/seq after 01200 batchs: 681.373779296875
INFO:root:Train (Epoch 179): Loss/seq after 01250 batchs: 677.99658203125
INFO:root:Train (Epoch 179): Loss/seq after 01300 batchs: 666.4481201171875
INFO:root:Train (Epoch 179): Loss/seq after 01350 batchs: 657.137939453125
INFO:root:Train (Epoch 179): Loss/seq after 01400 batchs: 663.6156005859375
INFO:root:Train (Epoch 179): Loss/seq after 01450 batchs: 663.5013427734375
INFO:root:Train (Epoch 179): Loss/seq after 01500 batchs: 667.7008666992188
INFO:root:Train (Epoch 179): Loss/seq after 01550 batchs: 670.4246215820312
INFO:root:Train (Epoch 179): Loss/seq after 01600 batchs: 663.1554565429688
INFO:root:Train (Epoch 179): Loss/seq after 01650 batchs: 658.504638671875
INFO:root:Train (Epoch 179): Loss/seq after 01700 batchs: 659.130126953125
INFO:root:Train (Epoch 179): Loss/seq after 01750 batchs: 655.3599243164062
INFO:root:Train (Epoch 179): Loss/seq after 01800 batchs: 651.3524169921875
INFO:root:Train (Epoch 179): Loss/seq after 01850 batchs: 646.045166015625
INFO:root:Train (Epoch 179): Loss/seq after 01900 batchs: 646.0077514648438
INFO:root:Train (Epoch 179): Loss/seq after 01950 batchs: 643.4964599609375
INFO:root:Train (Epoch 179): Loss/seq after 02000 batchs: 641.2496948242188
INFO:root:Train (Epoch 179): Loss/seq after 02050 batchs: 638.6324462890625
INFO:root:Train (Epoch 179): Loss/seq after 02100 batchs: 634.667724609375
INFO:root:Train (Epoch 179): Loss/seq after 02150 batchs: 631.591796875
INFO:root:Train (Epoch 179): Loss/seq after 02200 batchs: 627.5330200195312
INFO:root:Train (Epoch 179): Loss/seq after 02250 batchs: 626.5650634765625
INFO:root:Train (Epoch 179): Loss/seq after 02300 batchs: 627.0042114257812
INFO:root:Train (Epoch 179): Loss/seq after 02350 batchs: 621.3936767578125
INFO:root:Train (Epoch 179): Loss/seq after 02400 batchs: 621.9014282226562
INFO:root:Train (Epoch 179): Loss/seq after 02450 batchs: 616.4027099609375
INFO:root:Train (Epoch 179): Loss/seq after 02500 batchs: 607.2706909179688
INFO:root:Train (Epoch 179): Loss/seq after 02550 batchs: 600.8115844726562
INFO:root:Train (Epoch 179): Loss/seq after 02600 batchs: 600.046630859375
INFO:root:Train (Epoch 179): Loss/seq after 02650 batchs: 597.2899169921875
INFO:root:Train (Epoch 179): Loss/seq after 02700 batchs: 595.05712890625
INFO:root:Train (Epoch 179): Loss/seq after 02750 batchs: 595.9400634765625
INFO:root:Train (Epoch 179): Loss/seq after 02800 batchs: 596.7371826171875
INFO:root:Train (Epoch 179): Loss/seq after 02850 batchs: 596.5465087890625
INFO:root:Train (Epoch 179): Loss/seq after 02900 batchs: 597.7479248046875
INFO:root:Train (Epoch 179): Loss/seq after 02950 batchs: 596.1288452148438
INFO:root:Train (Epoch 179): Loss/seq after 03000 batchs: 600.5494384765625
INFO:root:Train (Epoch 179): Loss/seq after 03050 batchs: 603.0075073242188
INFO:root:Train (Epoch 179): Loss/seq after 03100 batchs: 607.1717529296875
INFO:root:Train (Epoch 179): Loss/seq after 03150 batchs: 613.6390380859375
INFO:root:Train (Epoch 179): Loss/seq after 03200 batchs: 616.33349609375
INFO:root:Train (Epoch 179): Loss/seq after 03250 batchs: 619.8221435546875
INFO:root:Train (Epoch 179): Loss/seq after 03300 batchs: 619.4378662109375
INFO:root:Train (Epoch 179): Loss/seq after 03350 batchs: 619.1817626953125
INFO:root:Train (Epoch 179): Loss/seq after 03400 batchs: 614.6270751953125
INFO:root:Train (Epoch 179): Loss/seq after 03450 batchs: 612.51611328125
INFO:root:Train (Epoch 179): Loss/seq after 03500 batchs: 612.4730224609375
INFO:root:Train (Epoch 179): Loss/seq after 03550 batchs: 609.2214965820312
INFO:root:Train (Epoch 179): Loss/seq after 03600 batchs: 617.4713134765625
INFO:root:Train (Epoch 179): Loss/seq after 03650 batchs: 614.4749755859375
INFO:root:Train (Epoch 179): Loss/seq after 03700 batchs: 616.4154052734375
INFO:root:Train (Epoch 179): Loss/seq after 03750 batchs: 620.4401245117188
INFO:root:Train (Epoch 179): Loss/seq after 03800 batchs: 617.469482421875
INFO:root:Train (Epoch 179): Loss/seq after 03850 batchs: 616.7026977539062
INFO:root:Train (Epoch 179): Loss/seq after 03900 batchs: 620.3451538085938
INFO:root:Train (Epoch 179): Loss/seq after 03950 batchs: 624.2006225585938
INFO:root:Train (Epoch 179): Loss/seq after 04000 batchs: 619.8103637695312
INFO:root:Train (Epoch 179): Loss/seq after 04050 batchs: 615.5977783203125
INFO:root:Train (Epoch 179): Loss/seq after 04100 batchs: 613.3994750976562
INFO:root:Train (Epoch 179): Loss/seq after 04150 batchs: 612.766845703125
INFO:root:Train (Epoch 179): Loss/seq after 04200 batchs: 610.4866333007812
INFO:root:Train (Epoch 179): Loss/seq after 04250 batchs: 608.3120727539062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 179): Loss/seq after 00000 batches: 507.2888488769531
INFO:root:# Valid (Epoch 179): Loss/seq after 00050 batches: 686.7955322265625
INFO:root:# Valid (Epoch 179): Loss/seq after 00100 batches: 809.2667236328125
INFO:root:# Valid (Epoch 179): Loss/seq after 00150 batches: 606.3203125
INFO:root:# Valid (Epoch 179): Loss/seq after 00200 batches: 557.221435546875
INFO:root:Artifacts: Make stick videos for epoch 179
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_179_on_20220423_111159.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_179_index_274_on_20220423_111159.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 180): Loss/seq after 00000 batchs: 1490.2459716796875
INFO:root:Train (Epoch 180): Loss/seq after 00050 batchs: 873.8448486328125
INFO:root:Train (Epoch 180): Loss/seq after 00100 batchs: 878.396240234375
INFO:root:Train (Epoch 180): Loss/seq after 00150 batchs: 765.6412353515625
INFO:root:Train (Epoch 180): Loss/seq after 00200 batchs: 857.5596923828125
INFO:root:Train (Epoch 180): Loss/seq after 00250 batchs: 950.1539306640625
INFO:root:Train (Epoch 180): Loss/seq after 00300 batchs: 941.0079956054688
INFO:root:Train (Epoch 180): Loss/seq after 00350 batchs: 879.4696655273438
INFO:root:Train (Epoch 180): Loss/seq after 00400 batchs: 888.2567138671875
INFO:root:Train (Epoch 180): Loss/seq after 00450 batchs: 863.564697265625
INFO:root:Train (Epoch 180): Loss/seq after 00500 batchs: 839.8837890625
INFO:root:Train (Epoch 180): Loss/seq after 00550 batchs: 811.9795532226562
INFO:root:Train (Epoch 180): Loss/seq after 00600 batchs: 782.3021850585938
INFO:root:Train (Epoch 180): Loss/seq after 00650 batchs: 769.5668334960938
INFO:root:Train (Epoch 180): Loss/seq after 00700 batchs: 745.5392456054688
INFO:root:Train (Epoch 180): Loss/seq after 00750 batchs: 761.9091186523438
INFO:root:Train (Epoch 180): Loss/seq after 00800 batchs: 757.9172973632812
INFO:root:Train (Epoch 180): Loss/seq after 00850 batchs: 734.22509765625
INFO:root:Train (Epoch 180): Loss/seq after 00900 batchs: 715.2031860351562
INFO:root:Train (Epoch 180): Loss/seq after 00950 batchs: 717.7454833984375
INFO:root:Train (Epoch 180): Loss/seq after 01000 batchs: 709.5866088867188
INFO:root:Train (Epoch 180): Loss/seq after 01050 batchs: 696.87890625
INFO:root:Train (Epoch 180): Loss/seq after 01100 batchs: 684.9127807617188
INFO:root:Train (Epoch 180): Loss/seq after 01150 batchs: 668.8916015625
INFO:root:Train (Epoch 180): Loss/seq after 01200 batchs: 671.4130249023438
INFO:root:Train (Epoch 180): Loss/seq after 01250 batchs: 667.9802856445312
INFO:root:Train (Epoch 180): Loss/seq after 01300 batchs: 656.8619995117188
INFO:root:Train (Epoch 180): Loss/seq after 01350 batchs: 647.560546875
INFO:root:Train (Epoch 180): Loss/seq after 01400 batchs: 652.7802734375
INFO:root:Train (Epoch 180): Loss/seq after 01450 batchs: 653.177490234375
INFO:root:Train (Epoch 180): Loss/seq after 01500 batchs: 657.486083984375
INFO:root:Train (Epoch 180): Loss/seq after 01550 batchs: 659.4474487304688
INFO:root:Train (Epoch 180): Loss/seq after 01600 batchs: 652.7349853515625
INFO:root:Train (Epoch 180): Loss/seq after 01650 batchs: 648.3125610351562
INFO:root:Train (Epoch 180): Loss/seq after 01700 batchs: 648.970947265625
INFO:root:Train (Epoch 180): Loss/seq after 01750 batchs: 645.1282958984375
INFO:root:Train (Epoch 180): Loss/seq after 01800 batchs: 641.2662353515625
INFO:root:Train (Epoch 180): Loss/seq after 01850 batchs: 635.9534912109375
INFO:root:Train (Epoch 180): Loss/seq after 01900 batchs: 635.4114379882812
INFO:root:Train (Epoch 180): Loss/seq after 01950 batchs: 633.2400512695312
INFO:root:Train (Epoch 180): Loss/seq after 02000 batchs: 631.1870727539062
INFO:root:Train (Epoch 180): Loss/seq after 02050 batchs: 628.591552734375
INFO:root:Train (Epoch 180): Loss/seq after 02100 batchs: 624.8145141601562
INFO:root:Train (Epoch 180): Loss/seq after 02150 batchs: 621.8721313476562
INFO:root:Train (Epoch 180): Loss/seq after 02200 batchs: 618.2105102539062
INFO:root:Train (Epoch 180): Loss/seq after 02250 batchs: 616.7005615234375
INFO:root:Train (Epoch 180): Loss/seq after 02300 batchs: 614.6609497070312
INFO:root:Train (Epoch 180): Loss/seq after 02350 batchs: 609.2742919921875
INFO:root:Train (Epoch 180): Loss/seq after 02400 batchs: 609.8931274414062
INFO:root:Train (Epoch 180): Loss/seq after 02450 batchs: 604.5599975585938
INFO:root:Train (Epoch 180): Loss/seq after 02500 batchs: 595.6602783203125
INFO:root:Train (Epoch 180): Loss/seq after 02550 batchs: 589.3226928710938
INFO:root:Train (Epoch 180): Loss/seq after 02600 batchs: 588.7550048828125
INFO:root:Train (Epoch 180): Loss/seq after 02650 batchs: 586.1534423828125
INFO:root:Train (Epoch 180): Loss/seq after 02700 batchs: 584.0700073242188
INFO:root:Train (Epoch 180): Loss/seq after 02750 batchs: 584.1675415039062
INFO:root:Train (Epoch 180): Loss/seq after 02800 batchs: 585.2373046875
INFO:root:Train (Epoch 180): Loss/seq after 02850 batchs: 585.1593017578125
INFO:root:Train (Epoch 180): Loss/seq after 02900 batchs: 586.786376953125
INFO:root:Train (Epoch 180): Loss/seq after 02950 batchs: 585.309326171875
INFO:root:Train (Epoch 180): Loss/seq after 03000 batchs: 589.9060668945312
INFO:root:Train (Epoch 180): Loss/seq after 03050 batchs: 592.77880859375
INFO:root:Train (Epoch 180): Loss/seq after 03100 batchs: 596.82666015625
INFO:root:Train (Epoch 180): Loss/seq after 03150 batchs: 602.8246459960938
INFO:root:Train (Epoch 180): Loss/seq after 03200 batchs: 604.8378295898438
INFO:root:Train (Epoch 180): Loss/seq after 03250 batchs: 608.1535034179688
INFO:root:Train (Epoch 180): Loss/seq after 03300 batchs: 607.0667114257812
INFO:root:Train (Epoch 180): Loss/seq after 03350 batchs: 607.3135986328125
INFO:root:Train (Epoch 180): Loss/seq after 03400 batchs: 602.9003295898438
INFO:root:Train (Epoch 180): Loss/seq after 03450 batchs: 600.8003540039062
INFO:root:Train (Epoch 180): Loss/seq after 03500 batchs: 600.8110961914062
INFO:root:Train (Epoch 180): Loss/seq after 03550 batchs: 597.6725463867188
INFO:root:Train (Epoch 180): Loss/seq after 03600 batchs: 605.7750244140625
INFO:root:Train (Epoch 180): Loss/seq after 03650 batchs: 602.9114990234375
INFO:root:Train (Epoch 180): Loss/seq after 03700 batchs: 604.732177734375
INFO:root:Train (Epoch 180): Loss/seq after 03750 batchs: 609.0164794921875
INFO:root:Train (Epoch 180): Loss/seq after 03800 batchs: 606.1561889648438
INFO:root:Train (Epoch 180): Loss/seq after 03850 batchs: 605.2862548828125
INFO:root:Train (Epoch 180): Loss/seq after 03900 batchs: 609.2059326171875
INFO:root:Train (Epoch 180): Loss/seq after 03950 batchs: 613.082763671875
INFO:root:Train (Epoch 180): Loss/seq after 04000 batchs: 608.8468627929688
INFO:root:Train (Epoch 180): Loss/seq after 04050 batchs: 604.8121337890625
INFO:root:Train (Epoch 180): Loss/seq after 04100 batchs: 602.7439575195312
INFO:root:Train (Epoch 180): Loss/seq after 04150 batchs: 602.1830444335938
INFO:root:Train (Epoch 180): Loss/seq after 04200 batchs: 599.9007568359375
INFO:root:Train (Epoch 180): Loss/seq after 04250 batchs: 597.72314453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 180): Loss/seq after 00000 batches: 548.9896850585938
INFO:root:# Valid (Epoch 180): Loss/seq after 00050 batches: 682.883544921875
INFO:root:# Valid (Epoch 180): Loss/seq after 00100 batches: 777.8612060546875
INFO:root:# Valid (Epoch 180): Loss/seq after 00150 batches: 583.427001953125
INFO:root:# Valid (Epoch 180): Loss/seq after 00200 batches: 537.99169921875
INFO:root:Artifacts: Make stick videos for epoch 180
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_180_on_20220423_111643.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_180_index_1407_on_20220423_111643.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 181): Loss/seq after 00000 batchs: 1297.291015625
INFO:root:Train (Epoch 181): Loss/seq after 00050 batchs: 884.852294921875
INFO:root:Train (Epoch 181): Loss/seq after 00100 batchs: 866.2742919921875
INFO:root:Train (Epoch 181): Loss/seq after 00150 batchs: 757.408203125
INFO:root:Train (Epoch 181): Loss/seq after 00200 batchs: 836.9775390625
INFO:root:Train (Epoch 181): Loss/seq after 00250 batchs: 936.775634765625
INFO:root:Train (Epoch 181): Loss/seq after 00300 batchs: 930.1494750976562
INFO:root:Train (Epoch 181): Loss/seq after 00350 batchs: 869.8580932617188
INFO:root:Train (Epoch 181): Loss/seq after 00400 batchs: 879.0106811523438
INFO:root:Train (Epoch 181): Loss/seq after 00450 batchs: 855.4573364257812
INFO:root:Train (Epoch 181): Loss/seq after 00500 batchs: 830.2025756835938
INFO:root:Train (Epoch 181): Loss/seq after 00550 batchs: 803.2512817382812
INFO:root:Train (Epoch 181): Loss/seq after 00600 batchs: 774.803955078125
INFO:root:Train (Epoch 181): Loss/seq after 00650 batchs: 761.7626953125
INFO:root:Train (Epoch 181): Loss/seq after 00700 batchs: 740.5632934570312
INFO:root:Train (Epoch 181): Loss/seq after 00750 batchs: 756.7437133789062
INFO:root:Train (Epoch 181): Loss/seq after 00800 batchs: 753.328857421875
INFO:root:Train (Epoch 181): Loss/seq after 00850 batchs: 729.6614990234375
INFO:root:Train (Epoch 181): Loss/seq after 00900 batchs: 710.8189086914062
INFO:root:Train (Epoch 181): Loss/seq after 00950 batchs: 713.111572265625
INFO:root:Train (Epoch 181): Loss/seq after 01000 batchs: 704.6578979492188
INFO:root:Train (Epoch 181): Loss/seq after 01050 batchs: 689.9671630859375
INFO:root:Train (Epoch 181): Loss/seq after 01100 batchs: 678.503662109375
INFO:root:Train (Epoch 181): Loss/seq after 01150 batchs: 662.9747314453125
INFO:root:Train (Epoch 181): Loss/seq after 01200 batchs: 665.6917724609375
INFO:root:Train (Epoch 181): Loss/seq after 01250 batchs: 662.284912109375
INFO:root:Train (Epoch 181): Loss/seq after 01300 batchs: 651.3185424804688
INFO:root:Train (Epoch 181): Loss/seq after 01350 batchs: 642.5596313476562
INFO:root:Train (Epoch 181): Loss/seq after 01400 batchs: 648.280029296875
INFO:root:Train (Epoch 181): Loss/seq after 01450 batchs: 648.3963012695312
INFO:root:Train (Epoch 181): Loss/seq after 01500 batchs: 652.8770751953125
INFO:root:Train (Epoch 181): Loss/seq after 01550 batchs: 655.092041015625
INFO:root:Train (Epoch 181): Loss/seq after 01600 batchs: 648.2060546875
INFO:root:Train (Epoch 181): Loss/seq after 01650 batchs: 644.2111206054688
INFO:root:Train (Epoch 181): Loss/seq after 01700 batchs: 644.9546508789062
INFO:root:Train (Epoch 181): Loss/seq after 01750 batchs: 641.444580078125
INFO:root:Train (Epoch 181): Loss/seq after 01800 batchs: 637.8817749023438
INFO:root:Train (Epoch 181): Loss/seq after 01850 batchs: 632.6763916015625
INFO:root:Train (Epoch 181): Loss/seq after 01900 batchs: 632.2808227539062
INFO:root:Train (Epoch 181): Loss/seq after 01950 batchs: 630.0728149414062
INFO:root:Train (Epoch 181): Loss/seq after 02000 batchs: 628.015625
INFO:root:Train (Epoch 181): Loss/seq after 02050 batchs: 625.339111328125
INFO:root:Train (Epoch 181): Loss/seq after 02100 batchs: 621.5738525390625
INFO:root:Train (Epoch 181): Loss/seq after 02150 batchs: 618.7799682617188
INFO:root:Train (Epoch 181): Loss/seq after 02200 batchs: 614.9675903320312
INFO:root:Train (Epoch 181): Loss/seq after 02250 batchs: 613.522705078125
INFO:root:Train (Epoch 181): Loss/seq after 02300 batchs: 614.107666015625
INFO:root:Train (Epoch 181): Loss/seq after 02350 batchs: 608.9923095703125
INFO:root:Train (Epoch 181): Loss/seq after 02400 batchs: 609.771728515625
INFO:root:Train (Epoch 181): Loss/seq after 02450 batchs: 604.46044921875
INFO:root:Train (Epoch 181): Loss/seq after 02500 batchs: 595.513916015625
INFO:root:Train (Epoch 181): Loss/seq after 02550 batchs: 589.1798706054688
INFO:root:Train (Epoch 181): Loss/seq after 02600 batchs: 588.7075805664062
INFO:root:Train (Epoch 181): Loss/seq after 02650 batchs: 585.9694213867188
INFO:root:Train (Epoch 181): Loss/seq after 02700 batchs: 583.9034423828125
INFO:root:Train (Epoch 181): Loss/seq after 02750 batchs: 583.8861694335938
INFO:root:Train (Epoch 181): Loss/seq after 02800 batchs: 586.1974487304688
INFO:root:Train (Epoch 181): Loss/seq after 02850 batchs: 585.9813232421875
INFO:root:Train (Epoch 181): Loss/seq after 02900 batchs: 587.2014770507812
INFO:root:Train (Epoch 181): Loss/seq after 02950 batchs: 585.6367797851562
INFO:root:Train (Epoch 181): Loss/seq after 03000 batchs: 590.0499267578125
INFO:root:Train (Epoch 181): Loss/seq after 03050 batchs: 593.1456909179688
INFO:root:Train (Epoch 181): Loss/seq after 03100 batchs: 598.017822265625
INFO:root:Train (Epoch 181): Loss/seq after 03150 batchs: 603.94482421875
INFO:root:Train (Epoch 181): Loss/seq after 03200 batchs: 606.5556640625
INFO:root:Train (Epoch 181): Loss/seq after 03250 batchs: 609.4876708984375
INFO:root:Train (Epoch 181): Loss/seq after 03300 batchs: 608.4968872070312
INFO:root:Train (Epoch 181): Loss/seq after 03350 batchs: 608.5477294921875
INFO:root:Train (Epoch 181): Loss/seq after 03400 batchs: 604.1353149414062
INFO:root:Train (Epoch 181): Loss/seq after 03450 batchs: 601.9683837890625
INFO:root:Train (Epoch 181): Loss/seq after 03500 batchs: 601.55419921875
INFO:root:Train (Epoch 181): Loss/seq after 03550 batchs: 598.3018798828125
INFO:root:Train (Epoch 181): Loss/seq after 03600 batchs: 606.3671875
INFO:root:Train (Epoch 181): Loss/seq after 03650 batchs: 603.4964599609375
INFO:root:Train (Epoch 181): Loss/seq after 03700 batchs: 605.2957153320312
INFO:root:Train (Epoch 181): Loss/seq after 03750 batchs: 609.3179321289062
INFO:root:Train (Epoch 181): Loss/seq after 03800 batchs: 606.45703125
INFO:root:Train (Epoch 181): Loss/seq after 03850 batchs: 605.5465087890625
INFO:root:Train (Epoch 181): Loss/seq after 03900 batchs: 609.0663452148438
INFO:root:Train (Epoch 181): Loss/seq after 03950 batchs: 612.8515625
INFO:root:Train (Epoch 181): Loss/seq after 04000 batchs: 608.590576171875
INFO:root:Train (Epoch 181): Loss/seq after 04050 batchs: 604.5795288085938
INFO:root:Train (Epoch 181): Loss/seq after 04100 batchs: 602.5224609375
INFO:root:Train (Epoch 181): Loss/seq after 04150 batchs: 601.9016723632812
INFO:root:Train (Epoch 181): Loss/seq after 04200 batchs: 599.5797119140625
INFO:root:Train (Epoch 181): Loss/seq after 04250 batchs: 597.4600830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 181): Loss/seq after 00000 batches: 489.5608215332031
INFO:root:# Valid (Epoch 181): Loss/seq after 00050 batches: 678.1019897460938
INFO:root:# Valid (Epoch 181): Loss/seq after 00100 batches: 776.3389282226562
INFO:root:# Valid (Epoch 181): Loss/seq after 00150 batches: 585.7569580078125
INFO:root:# Valid (Epoch 181): Loss/seq after 00200 batches: 534.4961547851562
INFO:root:Artifacts: Make stick videos for epoch 181
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_181_on_20220423_112127.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_181_index_250_on_20220423_112127.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 182): Loss/seq after 00000 batchs: 1297.948974609375
INFO:root:Train (Epoch 182): Loss/seq after 00050 batchs: 843.9990234375
INFO:root:Train (Epoch 182): Loss/seq after 00100 batchs: 842.1309204101562
INFO:root:Train (Epoch 182): Loss/seq after 00150 batchs: 740.29296875
INFO:root:Train (Epoch 182): Loss/seq after 00200 batchs: 849.2688598632812
INFO:root:Train (Epoch 182): Loss/seq after 00250 batchs: 946.6375122070312
INFO:root:Train (Epoch 182): Loss/seq after 00300 batchs: 936.5729370117188
INFO:root:Train (Epoch 182): Loss/seq after 00350 batchs: 874.47900390625
INFO:root:Train (Epoch 182): Loss/seq after 00400 batchs: 880.5357055664062
INFO:root:Train (Epoch 182): Loss/seq after 00450 batchs: 856.6514892578125
INFO:root:Train (Epoch 182): Loss/seq after 00500 batchs: 831.0966796875
INFO:root:Train (Epoch 182): Loss/seq after 00550 batchs: 802.8360595703125
INFO:root:Train (Epoch 182): Loss/seq after 00600 batchs: 774.2755737304688
INFO:root:Train (Epoch 182): Loss/seq after 00650 batchs: 762.0143432617188
INFO:root:Train (Epoch 182): Loss/seq after 00700 batchs: 736.7000732421875
INFO:root:Train (Epoch 182): Loss/seq after 00750 batchs: 750.96484375
INFO:root:Train (Epoch 182): Loss/seq after 00800 batchs: 748.2655639648438
INFO:root:Train (Epoch 182): Loss/seq after 00850 batchs: 724.79052734375
INFO:root:Train (Epoch 182): Loss/seq after 00900 batchs: 705.9912109375
INFO:root:Train (Epoch 182): Loss/seq after 00950 batchs: 707.5555419921875
INFO:root:Train (Epoch 182): Loss/seq after 01000 batchs: 699.8577880859375
INFO:root:Train (Epoch 182): Loss/seq after 01050 batchs: 686.2169799804688
INFO:root:Train (Epoch 182): Loss/seq after 01100 batchs: 673.5859985351562
INFO:root:Train (Epoch 182): Loss/seq after 01150 batchs: 658.0232543945312
INFO:root:Train (Epoch 182): Loss/seq after 01200 batchs: 660.7587280273438
INFO:root:Train (Epoch 182): Loss/seq after 01250 batchs: 657.1482543945312
INFO:root:Train (Epoch 182): Loss/seq after 01300 batchs: 646.8609008789062
INFO:root:Train (Epoch 182): Loss/seq after 01350 batchs: 637.8303833007812
INFO:root:Train (Epoch 182): Loss/seq after 01400 batchs: 643.0328369140625
INFO:root:Train (Epoch 182): Loss/seq after 01450 batchs: 643.1743774414062
INFO:root:Train (Epoch 182): Loss/seq after 01500 batchs: 647.8934326171875
INFO:root:Train (Epoch 182): Loss/seq after 01550 batchs: 650.136962890625
INFO:root:Train (Epoch 182): Loss/seq after 01600 batchs: 643.6251220703125
INFO:root:Train (Epoch 182): Loss/seq after 01650 batchs: 639.5831298828125
INFO:root:Train (Epoch 182): Loss/seq after 01700 batchs: 640.5671997070312
INFO:root:Train (Epoch 182): Loss/seq after 01750 batchs: 637.0647583007812
INFO:root:Train (Epoch 182): Loss/seq after 01800 batchs: 633.4684448242188
INFO:root:Train (Epoch 182): Loss/seq after 01850 batchs: 628.3896484375
INFO:root:Train (Epoch 182): Loss/seq after 01900 batchs: 628.2467651367188
INFO:root:Train (Epoch 182): Loss/seq after 01950 batchs: 626.2177734375
INFO:root:Train (Epoch 182): Loss/seq after 02000 batchs: 624.1883544921875
INFO:root:Train (Epoch 182): Loss/seq after 02050 batchs: 621.8529663085938
INFO:root:Train (Epoch 182): Loss/seq after 02100 batchs: 618.076171875
INFO:root:Train (Epoch 182): Loss/seq after 02150 batchs: 615.0706176757812
INFO:root:Train (Epoch 182): Loss/seq after 02200 batchs: 611.3836059570312
INFO:root:Train (Epoch 182): Loss/seq after 02250 batchs: 610.1156005859375
INFO:root:Train (Epoch 182): Loss/seq after 02300 batchs: 609.5431518554688
INFO:root:Train (Epoch 182): Loss/seq after 02350 batchs: 604.1292724609375
INFO:root:Train (Epoch 182): Loss/seq after 02400 batchs: 604.990478515625
INFO:root:Train (Epoch 182): Loss/seq after 02450 batchs: 599.722412109375
INFO:root:Train (Epoch 182): Loss/seq after 02500 batchs: 590.9046020507812
INFO:root:Train (Epoch 182): Loss/seq after 02550 batchs: 584.6748046875
INFO:root:Train (Epoch 182): Loss/seq after 02600 batchs: 583.9806518554688
INFO:root:Train (Epoch 182): Loss/seq after 02650 batchs: 581.1776733398438
INFO:root:Train (Epoch 182): Loss/seq after 02700 batchs: 578.9288940429688
INFO:root:Train (Epoch 182): Loss/seq after 02750 batchs: 579.0751953125
INFO:root:Train (Epoch 182): Loss/seq after 02800 batchs: 580.5394897460938
INFO:root:Train (Epoch 182): Loss/seq after 02850 batchs: 580.1337890625
INFO:root:Train (Epoch 182): Loss/seq after 02900 batchs: 581.119873046875
INFO:root:Train (Epoch 182): Loss/seq after 02950 batchs: 579.6793212890625
INFO:root:Train (Epoch 182): Loss/seq after 03000 batchs: 584.2371826171875
INFO:root:Train (Epoch 182): Loss/seq after 03050 batchs: 587.2759399414062
INFO:root:Train (Epoch 182): Loss/seq after 03100 batchs: 591.41064453125
INFO:root:Train (Epoch 182): Loss/seq after 03150 batchs: 596.867919921875
INFO:root:Train (Epoch 182): Loss/seq after 03200 batchs: 598.34130859375
INFO:root:Train (Epoch 182): Loss/seq after 03250 batchs: 601.7631225585938
INFO:root:Train (Epoch 182): Loss/seq after 03300 batchs: 601.1743774414062
INFO:root:Train (Epoch 182): Loss/seq after 03350 batchs: 601.3989868164062
INFO:root:Train (Epoch 182): Loss/seq after 03400 batchs: 597.0460815429688
INFO:root:Train (Epoch 182): Loss/seq after 03450 batchs: 595.0120849609375
INFO:root:Train (Epoch 182): Loss/seq after 03500 batchs: 594.832763671875
INFO:root:Train (Epoch 182): Loss/seq after 03550 batchs: 591.62109375
INFO:root:Train (Epoch 182): Loss/seq after 03600 batchs: 599.7853393554688
INFO:root:Train (Epoch 182): Loss/seq after 03650 batchs: 597.05615234375
INFO:root:Train (Epoch 182): Loss/seq after 03700 batchs: 598.874267578125
INFO:root:Train (Epoch 182): Loss/seq after 03750 batchs: 602.9848022460938
INFO:root:Train (Epoch 182): Loss/seq after 03800 batchs: 600.2998046875
INFO:root:Train (Epoch 182): Loss/seq after 03850 batchs: 599.3335571289062
INFO:root:Train (Epoch 182): Loss/seq after 03900 batchs: 602.9105834960938
INFO:root:Train (Epoch 182): Loss/seq after 03950 batchs: 606.4493408203125
INFO:root:Train (Epoch 182): Loss/seq after 04000 batchs: 602.2487182617188
INFO:root:Train (Epoch 182): Loss/seq after 04050 batchs: 598.2171630859375
INFO:root:Train (Epoch 182): Loss/seq after 04100 batchs: 596.1910400390625
INFO:root:Train (Epoch 182): Loss/seq after 04150 batchs: 595.6292724609375
INFO:root:Train (Epoch 182): Loss/seq after 04200 batchs: 593.36328125
INFO:root:Train (Epoch 182): Loss/seq after 04250 batchs: 591.2693481445312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 182): Loss/seq after 00000 batches: 537.6057739257812
INFO:root:# Valid (Epoch 182): Loss/seq after 00050 batches: 680.5062866210938
INFO:root:# Valid (Epoch 182): Loss/seq after 00100 batches: 738.410888671875
INFO:root:# Valid (Epoch 182): Loss/seq after 00150 batches: 556.0321044921875
INFO:root:# Valid (Epoch 182): Loss/seq after 00200 batches: 518.2620849609375
INFO:root:Artifacts: Make stick videos for epoch 182
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_182_on_20220423_112615.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_182_index_878_on_20220423_112615.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 183): Loss/seq after 00000 batchs: 1283.32177734375
INFO:root:Train (Epoch 183): Loss/seq after 00050 batchs: 873.3121948242188
INFO:root:Train (Epoch 183): Loss/seq after 00100 batchs: 849.650146484375
INFO:root:Train (Epoch 183): Loss/seq after 00150 batchs: 748.8519287109375
INFO:root:Train (Epoch 183): Loss/seq after 00200 batchs: 849.9943237304688
INFO:root:Train (Epoch 183): Loss/seq after 00250 batchs: 947.798583984375
INFO:root:Train (Epoch 183): Loss/seq after 00300 batchs: 937.73095703125
INFO:root:Train (Epoch 183): Loss/seq after 00350 batchs: 875.8584594726562
INFO:root:Train (Epoch 183): Loss/seq after 00400 batchs: 880.2477416992188
INFO:root:Train (Epoch 183): Loss/seq after 00450 batchs: 856.673583984375
INFO:root:Train (Epoch 183): Loss/seq after 00500 batchs: 831.8228149414062
INFO:root:Train (Epoch 183): Loss/seq after 00550 batchs: 804.1320190429688
INFO:root:Train (Epoch 183): Loss/seq after 00600 batchs: 774.9304809570312
INFO:root:Train (Epoch 183): Loss/seq after 00650 batchs: 762.0134887695312
INFO:root:Train (Epoch 183): Loss/seq after 00700 batchs: 738.7199096679688
INFO:root:Train (Epoch 183): Loss/seq after 00750 batchs: 754.5690307617188
INFO:root:Train (Epoch 183): Loss/seq after 00800 batchs: 751.31591796875
INFO:root:Train (Epoch 183): Loss/seq after 00850 batchs: 727.5984497070312
INFO:root:Train (Epoch 183): Loss/seq after 00900 batchs: 708.0401611328125
INFO:root:Train (Epoch 183): Loss/seq after 00950 batchs: 711.1480102539062
INFO:root:Train (Epoch 183): Loss/seq after 01000 batchs: 703.4850463867188
INFO:root:Train (Epoch 183): Loss/seq after 01050 batchs: 691.0546264648438
INFO:root:Train (Epoch 183): Loss/seq after 01100 batchs: 678.011474609375
INFO:root:Train (Epoch 183): Loss/seq after 01150 batchs: 662.2874145507812
INFO:root:Train (Epoch 183): Loss/seq after 01200 batchs: 665.051025390625
INFO:root:Train (Epoch 183): Loss/seq after 01250 batchs: 661.81396484375
INFO:root:Train (Epoch 183): Loss/seq after 01300 batchs: 651.9627075195312
INFO:root:Train (Epoch 183): Loss/seq after 01350 batchs: 642.563720703125
INFO:root:Train (Epoch 183): Loss/seq after 01400 batchs: 647.9337158203125
INFO:root:Train (Epoch 183): Loss/seq after 01450 batchs: 647.83154296875
INFO:root:Train (Epoch 183): Loss/seq after 01500 batchs: 652.1021728515625
INFO:root:Train (Epoch 183): Loss/seq after 01550 batchs: 653.9246826171875
INFO:root:Train (Epoch 183): Loss/seq after 01600 batchs: 647.01220703125
INFO:root:Train (Epoch 183): Loss/seq after 01650 batchs: 642.8211669921875
INFO:root:Train (Epoch 183): Loss/seq after 01700 batchs: 643.601806640625
INFO:root:Train (Epoch 183): Loss/seq after 01750 batchs: 639.8341674804688
INFO:root:Train (Epoch 183): Loss/seq after 01800 batchs: 635.9287719726562
INFO:root:Train (Epoch 183): Loss/seq after 01850 batchs: 630.7921142578125
INFO:root:Train (Epoch 183): Loss/seq after 01900 batchs: 630.3226928710938
INFO:root:Train (Epoch 183): Loss/seq after 01950 batchs: 628.186767578125
INFO:root:Train (Epoch 183): Loss/seq after 02000 batchs: 626.0221557617188
INFO:root:Train (Epoch 183): Loss/seq after 02050 batchs: 623.3406982421875
INFO:root:Train (Epoch 183): Loss/seq after 02100 batchs: 619.5866088867188
INFO:root:Train (Epoch 183): Loss/seq after 02150 batchs: 616.5877075195312
INFO:root:Train (Epoch 183): Loss/seq after 02200 batchs: 612.6561279296875
INFO:root:Train (Epoch 183): Loss/seq after 02250 batchs: 611.5968017578125
INFO:root:Train (Epoch 183): Loss/seq after 02300 batchs: 609.899169921875
INFO:root:Train (Epoch 183): Loss/seq after 02350 batchs: 604.4690551757812
INFO:root:Train (Epoch 183): Loss/seq after 02400 batchs: 605.0775756835938
INFO:root:Train (Epoch 183): Loss/seq after 02450 batchs: 599.7254638671875
INFO:root:Train (Epoch 183): Loss/seq after 02500 batchs: 590.83544921875
INFO:root:Train (Epoch 183): Loss/seq after 02550 batchs: 584.697021484375
INFO:root:Train (Epoch 183): Loss/seq after 02600 batchs: 583.9729614257812
INFO:root:Train (Epoch 183): Loss/seq after 02650 batchs: 581.3182373046875
INFO:root:Train (Epoch 183): Loss/seq after 02700 batchs: 579.3679809570312
INFO:root:Train (Epoch 183): Loss/seq after 02750 batchs: 578.2808837890625
INFO:root:Train (Epoch 183): Loss/seq after 02800 batchs: 579.0564575195312
INFO:root:Train (Epoch 183): Loss/seq after 02850 batchs: 578.7960815429688
INFO:root:Train (Epoch 183): Loss/seq after 02900 batchs: 580.1077270507812
INFO:root:Train (Epoch 183): Loss/seq after 02950 batchs: 578.7337646484375
INFO:root:Train (Epoch 183): Loss/seq after 03000 batchs: 583.2788696289062
INFO:root:Train (Epoch 183): Loss/seq after 03050 batchs: 585.2304077148438
INFO:root:Train (Epoch 183): Loss/seq after 03100 batchs: 588.958984375
INFO:root:Train (Epoch 183): Loss/seq after 03150 batchs: 595.2811279296875
INFO:root:Train (Epoch 183): Loss/seq after 03200 batchs: 597.2525634765625
INFO:root:Train (Epoch 183): Loss/seq after 03250 batchs: 600.169677734375
INFO:root:Train (Epoch 183): Loss/seq after 03300 batchs: 600.0303955078125
INFO:root:Train (Epoch 183): Loss/seq after 03350 batchs: 600.5160522460938
INFO:root:Train (Epoch 183): Loss/seq after 03400 batchs: 596.205810546875
INFO:root:Train (Epoch 183): Loss/seq after 03450 batchs: 594.0908813476562
INFO:root:Train (Epoch 183): Loss/seq after 03500 batchs: 593.935791015625
INFO:root:Train (Epoch 183): Loss/seq after 03550 batchs: 590.712158203125
INFO:root:Train (Epoch 183): Loss/seq after 03600 batchs: 598.7593383789062
INFO:root:Train (Epoch 183): Loss/seq after 03650 batchs: 595.8270874023438
INFO:root:Train (Epoch 183): Loss/seq after 03700 batchs: 597.6686401367188
INFO:root:Train (Epoch 183): Loss/seq after 03750 batchs: 601.7540893554688
INFO:root:Train (Epoch 183): Loss/seq after 03800 batchs: 598.9829711914062
INFO:root:Train (Epoch 183): Loss/seq after 03850 batchs: 597.9105224609375
INFO:root:Train (Epoch 183): Loss/seq after 03900 batchs: 601.9039916992188
INFO:root:Train (Epoch 183): Loss/seq after 03950 batchs: 605.6232299804688
INFO:root:Train (Epoch 183): Loss/seq after 04000 batchs: 601.4234619140625
INFO:root:Train (Epoch 183): Loss/seq after 04050 batchs: 597.4249877929688
INFO:root:Train (Epoch 183): Loss/seq after 04100 batchs: 595.3456420898438
INFO:root:Train (Epoch 183): Loss/seq after 04150 batchs: 594.8080444335938
INFO:root:Train (Epoch 183): Loss/seq after 04200 batchs: 592.5592651367188
INFO:root:Train (Epoch 183): Loss/seq after 04250 batchs: 590.4725341796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 183): Loss/seq after 00000 batches: 542.8958129882812
INFO:root:# Valid (Epoch 183): Loss/seq after 00050 batches: 670.49951171875
INFO:root:# Valid (Epoch 183): Loss/seq after 00100 batches: 753.1777954101562
INFO:root:# Valid (Epoch 183): Loss/seq after 00150 batches: 570.197021484375
INFO:root:# Valid (Epoch 183): Loss/seq after 00200 batches: 526.9254150390625
INFO:root:Artifacts: Make stick videos for epoch 183
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_183_on_20220423_113101.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_183_index_1297_on_20220423_113101.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 184): Loss/seq after 00000 batchs: 1262.379638671875
INFO:root:Train (Epoch 184): Loss/seq after 00050 batchs: 871.5509033203125
INFO:root:Train (Epoch 184): Loss/seq after 00100 batchs: 866.5584716796875
INFO:root:Train (Epoch 184): Loss/seq after 00150 batchs: 756.4581909179688
INFO:root:Train (Epoch 184): Loss/seq after 00200 batchs: 846.8538208007812
INFO:root:Train (Epoch 184): Loss/seq after 00250 batchs: 939.5126953125
INFO:root:Train (Epoch 184): Loss/seq after 00300 batchs: 929.2950439453125
INFO:root:Train (Epoch 184): Loss/seq after 00350 batchs: 868.2573852539062
INFO:root:Train (Epoch 184): Loss/seq after 00400 batchs: 872.9677734375
INFO:root:Train (Epoch 184): Loss/seq after 00450 batchs: 849.9330444335938
INFO:root:Train (Epoch 184): Loss/seq after 00500 batchs: 824.608154296875
INFO:root:Train (Epoch 184): Loss/seq after 00550 batchs: 797.5810546875
INFO:root:Train (Epoch 184): Loss/seq after 00600 batchs: 767.8661499023438
INFO:root:Train (Epoch 184): Loss/seq after 00650 batchs: 755.8546142578125
INFO:root:Train (Epoch 184): Loss/seq after 00700 batchs: 733.917236328125
INFO:root:Train (Epoch 184): Loss/seq after 00750 batchs: 746.1180419921875
INFO:root:Train (Epoch 184): Loss/seq after 00800 batchs: 742.6170043945312
INFO:root:Train (Epoch 184): Loss/seq after 00850 batchs: 719.0535278320312
INFO:root:Train (Epoch 184): Loss/seq after 00900 batchs: 699.595458984375
INFO:root:Train (Epoch 184): Loss/seq after 00950 batchs: 703.7276000976562
INFO:root:Train (Epoch 184): Loss/seq after 01000 batchs: 695.9780883789062
INFO:root:Train (Epoch 184): Loss/seq after 01050 batchs: 682.2031860351562
INFO:root:Train (Epoch 184): Loss/seq after 01100 batchs: 669.3181762695312
INFO:root:Train (Epoch 184): Loss/seq after 01150 batchs: 654.1412963867188
INFO:root:Train (Epoch 184): Loss/seq after 01200 batchs: 656.9995727539062
INFO:root:Train (Epoch 184): Loss/seq after 01250 batchs: 653.2416381835938
INFO:root:Train (Epoch 184): Loss/seq after 01300 batchs: 641.7998657226562
INFO:root:Train (Epoch 184): Loss/seq after 01350 batchs: 632.9832153320312
INFO:root:Train (Epoch 184): Loss/seq after 01400 batchs: 638.8822021484375
INFO:root:Train (Epoch 184): Loss/seq after 01450 batchs: 638.7322387695312
INFO:root:Train (Epoch 184): Loss/seq after 01500 batchs: 643.6565551757812
INFO:root:Train (Epoch 184): Loss/seq after 01550 batchs: 645.7125244140625
INFO:root:Train (Epoch 184): Loss/seq after 01600 batchs: 639.1341552734375
INFO:root:Train (Epoch 184): Loss/seq after 01650 batchs: 634.814453125
INFO:root:Train (Epoch 184): Loss/seq after 01700 batchs: 635.6746826171875
INFO:root:Train (Epoch 184): Loss/seq after 01750 batchs: 632.1449584960938
INFO:root:Train (Epoch 184): Loss/seq after 01800 batchs: 628.4283447265625
INFO:root:Train (Epoch 184): Loss/seq after 01850 batchs: 623.4842529296875
INFO:root:Train (Epoch 184): Loss/seq after 01900 batchs: 623.0362548828125
INFO:root:Train (Epoch 184): Loss/seq after 01950 batchs: 621.1409912109375
INFO:root:Train (Epoch 184): Loss/seq after 02000 batchs: 619.1275024414062
INFO:root:Train (Epoch 184): Loss/seq after 02050 batchs: 616.5753784179688
INFO:root:Train (Epoch 184): Loss/seq after 02100 batchs: 612.889892578125
INFO:root:Train (Epoch 184): Loss/seq after 02150 batchs: 610.0809326171875
INFO:root:Train (Epoch 184): Loss/seq after 02200 batchs: 606.3504028320312
INFO:root:Train (Epoch 184): Loss/seq after 02250 batchs: 605.3592529296875
INFO:root:Train (Epoch 184): Loss/seq after 02300 batchs: 604.5337524414062
INFO:root:Train (Epoch 184): Loss/seq after 02350 batchs: 599.2642822265625
INFO:root:Train (Epoch 184): Loss/seq after 02400 batchs: 599.9581909179688
INFO:root:Train (Epoch 184): Loss/seq after 02450 batchs: 594.5863647460938
INFO:root:Train (Epoch 184): Loss/seq after 02500 batchs: 585.7362670898438
INFO:root:Train (Epoch 184): Loss/seq after 02550 batchs: 579.5741577148438
INFO:root:Train (Epoch 184): Loss/seq after 02600 batchs: 578.5905151367188
INFO:root:Train (Epoch 184): Loss/seq after 02650 batchs: 575.4869384765625
INFO:root:Train (Epoch 184): Loss/seq after 02700 batchs: 573.293701171875
INFO:root:Train (Epoch 184): Loss/seq after 02750 batchs: 572.0303955078125
INFO:root:Train (Epoch 184): Loss/seq after 02800 batchs: 573.295654296875
INFO:root:Train (Epoch 184): Loss/seq after 02850 batchs: 573.1154174804688
INFO:root:Train (Epoch 184): Loss/seq after 02900 batchs: 574.5029907226562
INFO:root:Train (Epoch 184): Loss/seq after 02950 batchs: 573.0874633789062
INFO:root:Train (Epoch 184): Loss/seq after 03000 batchs: 577.5802612304688
INFO:root:Train (Epoch 184): Loss/seq after 03050 batchs: 580.4021606445312
INFO:root:Train (Epoch 184): Loss/seq after 03100 batchs: 584.7183227539062
INFO:root:Train (Epoch 184): Loss/seq after 03150 batchs: 591.0526733398438
INFO:root:Train (Epoch 184): Loss/seq after 03200 batchs: 593.3086547851562
INFO:root:Train (Epoch 184): Loss/seq after 03250 batchs: 596.9064331054688
INFO:root:Train (Epoch 184): Loss/seq after 03300 batchs: 596.0426635742188
INFO:root:Train (Epoch 184): Loss/seq after 03350 batchs: 595.9428100585938
INFO:root:Train (Epoch 184): Loss/seq after 03400 batchs: 591.7568969726562
INFO:root:Train (Epoch 184): Loss/seq after 03450 batchs: 589.7261962890625
INFO:root:Train (Epoch 184): Loss/seq after 03500 batchs: 589.6669921875
INFO:root:Train (Epoch 184): Loss/seq after 03550 batchs: 586.4994506835938
INFO:root:Train (Epoch 184): Loss/seq after 03600 batchs: 594.3480224609375
INFO:root:Train (Epoch 184): Loss/seq after 03650 batchs: 591.4472045898438
INFO:root:Train (Epoch 184): Loss/seq after 03700 batchs: 593.2959594726562
INFO:root:Train (Epoch 184): Loss/seq after 03750 batchs: 597.4561157226562
INFO:root:Train (Epoch 184): Loss/seq after 03800 batchs: 594.6749267578125
INFO:root:Train (Epoch 184): Loss/seq after 03850 batchs: 593.50390625
INFO:root:Train (Epoch 184): Loss/seq after 03900 batchs: 597.1481323242188
INFO:root:Train (Epoch 184): Loss/seq after 03950 batchs: 600.5424194335938
INFO:root:Train (Epoch 184): Loss/seq after 04000 batchs: 596.3392333984375
INFO:root:Train (Epoch 184): Loss/seq after 04050 batchs: 592.3935546875
INFO:root:Train (Epoch 184): Loss/seq after 04100 batchs: 590.3240356445312
INFO:root:Train (Epoch 184): Loss/seq after 04150 batchs: 589.7959594726562
INFO:root:Train (Epoch 184): Loss/seq after 04200 batchs: 587.626220703125
INFO:root:Train (Epoch 184): Loss/seq after 04250 batchs: 585.5863037109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 184): Loss/seq after 00000 batches: 537.232177734375
INFO:root:# Valid (Epoch 184): Loss/seq after 00050 batches: 680.844482421875
INFO:root:# Valid (Epoch 184): Loss/seq after 00100 batches: 730.0827026367188
INFO:root:# Valid (Epoch 184): Loss/seq after 00150 batches: 554.4611206054688
INFO:root:# Valid (Epoch 184): Loss/seq after 00200 batches: 515.9373779296875
INFO:root:Artifacts: Make stick videos for epoch 184
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_184_on_20220423_113557.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_184_index_784_on_20220423_113557.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 185): Loss/seq after 00000 batchs: 1367.9898681640625
INFO:root:Train (Epoch 185): Loss/seq after 00050 batchs: 857.630615234375
INFO:root:Train (Epoch 185): Loss/seq after 00100 batchs: 842.4734497070312
INFO:root:Train (Epoch 185): Loss/seq after 00150 batchs: 737.7017211914062
INFO:root:Train (Epoch 185): Loss/seq after 00200 batchs: 830.6452026367188
INFO:root:Train (Epoch 185): Loss/seq after 00250 batchs: 920.7325439453125
INFO:root:Train (Epoch 185): Loss/seq after 00300 batchs: 912.896484375
INFO:root:Train (Epoch 185): Loss/seq after 00350 batchs: 853.621337890625
INFO:root:Train (Epoch 185): Loss/seq after 00400 batchs: 859.9887084960938
INFO:root:Train (Epoch 185): Loss/seq after 00450 batchs: 837.9933471679688
INFO:root:Train (Epoch 185): Loss/seq after 00500 batchs: 815.109130859375
INFO:root:Train (Epoch 185): Loss/seq after 00550 batchs: 788.6329345703125
INFO:root:Train (Epoch 185): Loss/seq after 00600 batchs: 760.3825073242188
INFO:root:Train (Epoch 185): Loss/seq after 00650 batchs: 749.3007202148438
INFO:root:Train (Epoch 185): Loss/seq after 00700 batchs: 725.2892456054688
INFO:root:Train (Epoch 185): Loss/seq after 00750 batchs: 738.0138549804688
INFO:root:Train (Epoch 185): Loss/seq after 00800 batchs: 735.9154663085938
INFO:root:Train (Epoch 185): Loss/seq after 00850 batchs: 712.655029296875
INFO:root:Train (Epoch 185): Loss/seq after 00900 batchs: 694.6082763671875
INFO:root:Train (Epoch 185): Loss/seq after 00950 batchs: 698.29150390625
INFO:root:Train (Epoch 185): Loss/seq after 01000 batchs: 691.4119873046875
INFO:root:Train (Epoch 185): Loss/seq after 01050 batchs: 677.80419921875
INFO:root:Train (Epoch 185): Loss/seq after 01100 batchs: 666.3630981445312
INFO:root:Train (Epoch 185): Loss/seq after 01150 batchs: 650.9361572265625
INFO:root:Train (Epoch 185): Loss/seq after 01200 batchs: 653.9527587890625
INFO:root:Train (Epoch 185): Loss/seq after 01250 batchs: 650.8159790039062
INFO:root:Train (Epoch 185): Loss/seq after 01300 batchs: 641.073486328125
INFO:root:Train (Epoch 185): Loss/seq after 01350 batchs: 632.0438232421875
INFO:root:Train (Epoch 185): Loss/seq after 01400 batchs: 637.4222412109375
INFO:root:Train (Epoch 185): Loss/seq after 01450 batchs: 637.7064208984375
INFO:root:Train (Epoch 185): Loss/seq after 01500 batchs: 642.2965698242188
INFO:root:Train (Epoch 185): Loss/seq after 01550 batchs: 644.2687377929688
INFO:root:Train (Epoch 185): Loss/seq after 01600 batchs: 637.4224853515625
INFO:root:Train (Epoch 185): Loss/seq after 01650 batchs: 633.3597412109375
INFO:root:Train (Epoch 185): Loss/seq after 01700 batchs: 634.2442626953125
INFO:root:Train (Epoch 185): Loss/seq after 01750 batchs: 630.6685791015625
INFO:root:Train (Epoch 185): Loss/seq after 01800 batchs: 626.9126586914062
INFO:root:Train (Epoch 185): Loss/seq after 01850 batchs: 621.8988037109375
INFO:root:Train (Epoch 185): Loss/seq after 01900 batchs: 621.0946044921875
INFO:root:Train (Epoch 185): Loss/seq after 01950 batchs: 618.917724609375
INFO:root:Train (Epoch 185): Loss/seq after 02000 batchs: 616.7572631835938
INFO:root:Train (Epoch 185): Loss/seq after 02050 batchs: 614.23095703125
INFO:root:Train (Epoch 185): Loss/seq after 02100 batchs: 610.6759643554688
INFO:root:Train (Epoch 185): Loss/seq after 02150 batchs: 607.8284301757812
INFO:root:Train (Epoch 185): Loss/seq after 02200 batchs: 604.1488037109375
INFO:root:Train (Epoch 185): Loss/seq after 02250 batchs: 603.1885375976562
INFO:root:Train (Epoch 185): Loss/seq after 02300 batchs: 603.1435546875
INFO:root:Train (Epoch 185): Loss/seq after 02350 batchs: 597.7662353515625
INFO:root:Train (Epoch 185): Loss/seq after 02400 batchs: 598.4843139648438
INFO:root:Train (Epoch 185): Loss/seq after 02450 batchs: 593.1881713867188
INFO:root:Train (Epoch 185): Loss/seq after 02500 batchs: 584.389404296875
INFO:root:Train (Epoch 185): Loss/seq after 02550 batchs: 578.187255859375
INFO:root:Train (Epoch 185): Loss/seq after 02600 batchs: 577.14111328125
INFO:root:Train (Epoch 185): Loss/seq after 02650 batchs: 574.421630859375
INFO:root:Train (Epoch 185): Loss/seq after 02700 batchs: 572.6173706054688
INFO:root:Train (Epoch 185): Loss/seq after 02750 batchs: 571.034423828125
INFO:root:Train (Epoch 185): Loss/seq after 02800 batchs: 572.2090454101562
INFO:root:Train (Epoch 185): Loss/seq after 02850 batchs: 571.8844604492188
INFO:root:Train (Epoch 185): Loss/seq after 02900 batchs: 573.183349609375
INFO:root:Train (Epoch 185): Loss/seq after 02950 batchs: 571.817138671875
INFO:root:Train (Epoch 185): Loss/seq after 03000 batchs: 576.4682006835938
INFO:root:Train (Epoch 185): Loss/seq after 03050 batchs: 579.0068359375
INFO:root:Train (Epoch 185): Loss/seq after 03100 batchs: 583.2655639648438
INFO:root:Train (Epoch 185): Loss/seq after 03150 batchs: 590.0203857421875
INFO:root:Train (Epoch 185): Loss/seq after 03200 batchs: 593.2098388671875
INFO:root:Train (Epoch 185): Loss/seq after 03250 batchs: 596.4917602539062
INFO:root:Train (Epoch 185): Loss/seq after 03300 batchs: 596.613037109375
INFO:root:Train (Epoch 185): Loss/seq after 03350 batchs: 596.6588134765625
INFO:root:Train (Epoch 185): Loss/seq after 03400 batchs: 592.423828125
INFO:root:Train (Epoch 185): Loss/seq after 03450 batchs: 590.2644653320312
INFO:root:Train (Epoch 185): Loss/seq after 03500 batchs: 590.34912109375
INFO:root:Train (Epoch 185): Loss/seq after 03550 batchs: 587.2186889648438
INFO:root:Train (Epoch 185): Loss/seq after 03600 batchs: 595.121337890625
INFO:root:Train (Epoch 185): Loss/seq after 03650 batchs: 592.3358154296875
INFO:root:Train (Epoch 185): Loss/seq after 03700 batchs: 594.1326904296875
INFO:root:Train (Epoch 185): Loss/seq after 03750 batchs: 598.0708618164062
INFO:root:Train (Epoch 185): Loss/seq after 03800 batchs: 595.23779296875
INFO:root:Train (Epoch 185): Loss/seq after 03850 batchs: 593.9741821289062
INFO:root:Train (Epoch 185): Loss/seq after 03900 batchs: 597.6463623046875
INFO:root:Train (Epoch 185): Loss/seq after 03950 batchs: 601.5286254882812
INFO:root:Train (Epoch 185): Loss/seq after 04000 batchs: 597.321533203125
INFO:root:Train (Epoch 185): Loss/seq after 04050 batchs: 593.3181762695312
INFO:root:Train (Epoch 185): Loss/seq after 04100 batchs: 591.33544921875
INFO:root:Train (Epoch 185): Loss/seq after 04150 batchs: 590.7110595703125
INFO:root:Train (Epoch 185): Loss/seq after 04200 batchs: 588.5037231445312
INFO:root:Train (Epoch 185): Loss/seq after 04250 batchs: 586.4278564453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 185): Loss/seq after 00000 batches: 525.5713500976562
INFO:root:# Valid (Epoch 185): Loss/seq after 00050 batches: 674.8616333007812
INFO:root:# Valid (Epoch 185): Loss/seq after 00100 batches: 734.9420776367188
INFO:root:# Valid (Epoch 185): Loss/seq after 00150 batches: 557.218505859375
INFO:root:# Valid (Epoch 185): Loss/seq after 00200 batches: 519.1748657226562
INFO:root:Artifacts: Make stick videos for epoch 185
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_185_on_20220423_114054.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_185_index_565_on_20220423_114054.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 186): Loss/seq after 00000 batchs: 1225.2882080078125
INFO:root:Train (Epoch 186): Loss/seq after 00050 batchs: 869.763916015625
INFO:root:Train (Epoch 186): Loss/seq after 00100 batchs: 843.6530151367188
INFO:root:Train (Epoch 186): Loss/seq after 00150 batchs: 735.5900268554688
INFO:root:Train (Epoch 186): Loss/seq after 00200 batchs: 833.8782958984375
INFO:root:Train (Epoch 186): Loss/seq after 00250 batchs: 923.26318359375
INFO:root:Train (Epoch 186): Loss/seq after 00300 batchs: 915.31640625
INFO:root:Train (Epoch 186): Loss/seq after 00350 batchs: 855.5277709960938
INFO:root:Train (Epoch 186): Loss/seq after 00400 batchs: 862.4302978515625
INFO:root:Train (Epoch 186): Loss/seq after 00450 batchs: 839.839111328125
INFO:root:Train (Epoch 186): Loss/seq after 00500 batchs: 815.15478515625
INFO:root:Train (Epoch 186): Loss/seq after 00550 batchs: 789.225830078125
INFO:root:Train (Epoch 186): Loss/seq after 00600 batchs: 760.6177978515625
INFO:root:Train (Epoch 186): Loss/seq after 00650 batchs: 747.058837890625
INFO:root:Train (Epoch 186): Loss/seq after 00700 batchs: 721.5484619140625
INFO:root:Train (Epoch 186): Loss/seq after 00750 batchs: 736.2080078125
INFO:root:Train (Epoch 186): Loss/seq after 00800 batchs: 733.7567138671875
INFO:root:Train (Epoch 186): Loss/seq after 00850 batchs: 710.2698364257812
INFO:root:Train (Epoch 186): Loss/seq after 00900 batchs: 691.5084838867188
INFO:root:Train (Epoch 186): Loss/seq after 00950 batchs: 691.4661254882812
INFO:root:Train (Epoch 186): Loss/seq after 01000 batchs: 682.447998046875
INFO:root:Train (Epoch 186): Loss/seq after 01050 batchs: 670.2482299804688
INFO:root:Train (Epoch 186): Loss/seq after 01100 batchs: 658.4788208007812
INFO:root:Train (Epoch 186): Loss/seq after 01150 batchs: 643.3184204101562
INFO:root:Train (Epoch 186): Loss/seq after 01200 batchs: 646.0333862304688
INFO:root:Train (Epoch 186): Loss/seq after 01250 batchs: 642.9102172851562
INFO:root:Train (Epoch 186): Loss/seq after 01300 batchs: 632.0529174804688
INFO:root:Train (Epoch 186): Loss/seq after 01350 batchs: 622.712158203125
INFO:root:Train (Epoch 186): Loss/seq after 01400 batchs: 629.2485961914062
INFO:root:Train (Epoch 186): Loss/seq after 01450 batchs: 629.3748779296875
INFO:root:Train (Epoch 186): Loss/seq after 01500 batchs: 634.340087890625
INFO:root:Train (Epoch 186): Loss/seq after 01550 batchs: 636.1904296875
INFO:root:Train (Epoch 186): Loss/seq after 01600 batchs: 629.5426025390625
INFO:root:Train (Epoch 186): Loss/seq after 01650 batchs: 625.43212890625
INFO:root:Train (Epoch 186): Loss/seq after 01700 batchs: 626.5317993164062
INFO:root:Train (Epoch 186): Loss/seq after 01750 batchs: 623.1992797851562
INFO:root:Train (Epoch 186): Loss/seq after 01800 batchs: 619.7554931640625
INFO:root:Train (Epoch 186): Loss/seq after 01850 batchs: 614.9574584960938
INFO:root:Train (Epoch 186): Loss/seq after 01900 batchs: 614.748779296875
INFO:root:Train (Epoch 186): Loss/seq after 01950 batchs: 612.7689208984375
INFO:root:Train (Epoch 186): Loss/seq after 02000 batchs: 611.0794067382812
INFO:root:Train (Epoch 186): Loss/seq after 02050 batchs: 608.6160888671875
INFO:root:Train (Epoch 186): Loss/seq after 02100 batchs: 605.0525512695312
INFO:root:Train (Epoch 186): Loss/seq after 02150 batchs: 602.3226928710938
INFO:root:Train (Epoch 186): Loss/seq after 02200 batchs: 598.698486328125
INFO:root:Train (Epoch 186): Loss/seq after 02250 batchs: 597.6369018554688
INFO:root:Train (Epoch 186): Loss/seq after 02300 batchs: 596.91748046875
INFO:root:Train (Epoch 186): Loss/seq after 02350 batchs: 591.7477416992188
INFO:root:Train (Epoch 186): Loss/seq after 02400 batchs: 592.6868286132812
INFO:root:Train (Epoch 186): Loss/seq after 02450 batchs: 587.4430541992188
INFO:root:Train (Epoch 186): Loss/seq after 02500 batchs: 578.726318359375
INFO:root:Train (Epoch 186): Loss/seq after 02550 batchs: 572.3959350585938
INFO:root:Train (Epoch 186): Loss/seq after 02600 batchs: 571.2276611328125
INFO:root:Train (Epoch 186): Loss/seq after 02650 batchs: 568.5751953125
INFO:root:Train (Epoch 186): Loss/seq after 02700 batchs: 566.5945434570312
INFO:root:Train (Epoch 186): Loss/seq after 02750 batchs: 564.6259155273438
INFO:root:Train (Epoch 186): Loss/seq after 02800 batchs: 565.5792236328125
INFO:root:Train (Epoch 186): Loss/seq after 02850 batchs: 565.4742431640625
INFO:root:Train (Epoch 186): Loss/seq after 02900 batchs: 566.6219482421875
INFO:root:Train (Epoch 186): Loss/seq after 02950 batchs: 565.3746337890625
INFO:root:Train (Epoch 186): Loss/seq after 03000 batchs: 570.113037109375
INFO:root:Train (Epoch 186): Loss/seq after 03050 batchs: 572.5297241210938
INFO:root:Train (Epoch 186): Loss/seq after 03100 batchs: 576.24609375
INFO:root:Train (Epoch 186): Loss/seq after 03150 batchs: 582.5980224609375
INFO:root:Train (Epoch 186): Loss/seq after 03200 batchs: 584.9569091796875
INFO:root:Train (Epoch 186): Loss/seq after 03250 batchs: 588.0928955078125
INFO:root:Train (Epoch 186): Loss/seq after 03300 batchs: 587.409912109375
INFO:root:Train (Epoch 186): Loss/seq after 03350 batchs: 587.686279296875
INFO:root:Train (Epoch 186): Loss/seq after 03400 batchs: 583.5609130859375
INFO:root:Train (Epoch 186): Loss/seq after 03450 batchs: 581.7097778320312
INFO:root:Train (Epoch 186): Loss/seq after 03500 batchs: 581.7843017578125
INFO:root:Train (Epoch 186): Loss/seq after 03550 batchs: 578.870361328125
INFO:root:Train (Epoch 186): Loss/seq after 03600 batchs: 587.1796264648438
INFO:root:Train (Epoch 186): Loss/seq after 03650 batchs: 584.5538940429688
INFO:root:Train (Epoch 186): Loss/seq after 03700 batchs: 586.4771118164062
INFO:root:Train (Epoch 186): Loss/seq after 03750 batchs: 590.5517578125
INFO:root:Train (Epoch 186): Loss/seq after 03800 batchs: 587.8199462890625
INFO:root:Train (Epoch 186): Loss/seq after 03850 batchs: 586.6919555664062
INFO:root:Train (Epoch 186): Loss/seq after 03900 batchs: 590.5830688476562
INFO:root:Train (Epoch 186): Loss/seq after 03950 batchs: 594.1311645507812
INFO:root:Train (Epoch 186): Loss/seq after 04000 batchs: 589.9282836914062
INFO:root:Train (Epoch 186): Loss/seq after 04050 batchs: 586.05126953125
INFO:root:Train (Epoch 186): Loss/seq after 04100 batchs: 584.0540771484375
INFO:root:Train (Epoch 186): Loss/seq after 04150 batchs: 583.4532470703125
INFO:root:Train (Epoch 186): Loss/seq after 04200 batchs: 581.4109497070312
INFO:root:Train (Epoch 186): Loss/seq after 04250 batchs: 579.3888549804688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 186): Loss/seq after 00000 batches: 540.2179565429688
INFO:root:# Valid (Epoch 186): Loss/seq after 00050 batches: 681.692138671875
INFO:root:# Valid (Epoch 186): Loss/seq after 00100 batches: 729.7453002929688
INFO:root:# Valid (Epoch 186): Loss/seq after 00150 batches: 554.9175415039062
INFO:root:# Valid (Epoch 186): Loss/seq after 00200 batches: 514.9510498046875
INFO:root:Artifacts: Make stick videos for epoch 186
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_186_on_20220423_114539.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_186_index_740_on_20220423_114539.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 187): Loss/seq after 00000 batchs: 1219.7454833984375
INFO:root:Train (Epoch 187): Loss/seq after 00050 batchs: 856.056884765625
INFO:root:Train (Epoch 187): Loss/seq after 00100 batchs: 851.3432006835938
INFO:root:Train (Epoch 187): Loss/seq after 00150 batchs: 739.1784057617188
INFO:root:Train (Epoch 187): Loss/seq after 00200 batchs: 827.7984008789062
INFO:root:Train (Epoch 187): Loss/seq after 00250 batchs: 918.43798828125
INFO:root:Train (Epoch 187): Loss/seq after 00300 batchs: 912.3135986328125
INFO:root:Train (Epoch 187): Loss/seq after 00350 batchs: 854.8491821289062
INFO:root:Train (Epoch 187): Loss/seq after 00400 batchs: 863.626953125
INFO:root:Train (Epoch 187): Loss/seq after 00450 batchs: 841.1353149414062
INFO:root:Train (Epoch 187): Loss/seq after 00500 batchs: 820.3743896484375
INFO:root:Train (Epoch 187): Loss/seq after 00550 batchs: 793.4137573242188
INFO:root:Train (Epoch 187): Loss/seq after 00600 batchs: 764.8424072265625
INFO:root:Train (Epoch 187): Loss/seq after 00650 batchs: 753.0663452148438
INFO:root:Train (Epoch 187): Loss/seq after 00700 batchs: 731.1104736328125
INFO:root:Train (Epoch 187): Loss/seq after 00750 batchs: 744.0390014648438
INFO:root:Train (Epoch 187): Loss/seq after 00800 batchs: 740.6771240234375
INFO:root:Train (Epoch 187): Loss/seq after 00850 batchs: 716.9931640625
INFO:root:Train (Epoch 187): Loss/seq after 00900 batchs: 697.9479370117188
INFO:root:Train (Epoch 187): Loss/seq after 00950 batchs: 698.7440185546875
INFO:root:Train (Epoch 187): Loss/seq after 01000 batchs: 689.8856201171875
INFO:root:Train (Epoch 187): Loss/seq after 01050 batchs: 675.292236328125
INFO:root:Train (Epoch 187): Loss/seq after 01100 batchs: 662.5675659179688
INFO:root:Train (Epoch 187): Loss/seq after 01150 batchs: 647.06787109375
INFO:root:Train (Epoch 187): Loss/seq after 01200 batchs: 649.739990234375
INFO:root:Train (Epoch 187): Loss/seq after 01250 batchs: 645.8817749023438
INFO:root:Train (Epoch 187): Loss/seq after 01300 batchs: 634.6075439453125
INFO:root:Train (Epoch 187): Loss/seq after 01350 batchs: 625.211669921875
INFO:root:Train (Epoch 187): Loss/seq after 01400 batchs: 629.502685546875
INFO:root:Train (Epoch 187): Loss/seq after 01450 batchs: 629.7860717773438
INFO:root:Train (Epoch 187): Loss/seq after 01500 batchs: 634.4970703125
INFO:root:Train (Epoch 187): Loss/seq after 01550 batchs: 636.262939453125
INFO:root:Train (Epoch 187): Loss/seq after 01600 batchs: 629.7569580078125
INFO:root:Train (Epoch 187): Loss/seq after 01650 batchs: 625.6497192382812
INFO:root:Train (Epoch 187): Loss/seq after 01700 batchs: 626.7058715820312
INFO:root:Train (Epoch 187): Loss/seq after 01750 batchs: 623.3040161132812
INFO:root:Train (Epoch 187): Loss/seq after 01800 batchs: 619.8177490234375
INFO:root:Train (Epoch 187): Loss/seq after 01850 batchs: 614.9598388671875
INFO:root:Train (Epoch 187): Loss/seq after 01900 batchs: 614.412841796875
INFO:root:Train (Epoch 187): Loss/seq after 01950 batchs: 612.2490844726562
INFO:root:Train (Epoch 187): Loss/seq after 02000 batchs: 610.15576171875
INFO:root:Train (Epoch 187): Loss/seq after 02050 batchs: 607.7704467773438
INFO:root:Train (Epoch 187): Loss/seq after 02100 batchs: 604.16650390625
INFO:root:Train (Epoch 187): Loss/seq after 02150 batchs: 601.3309326171875
INFO:root:Train (Epoch 187): Loss/seq after 02200 batchs: 597.5972900390625
INFO:root:Train (Epoch 187): Loss/seq after 02250 batchs: 596.2102661132812
INFO:root:Train (Epoch 187): Loss/seq after 02300 batchs: 595.34130859375
INFO:root:Train (Epoch 187): Loss/seq after 02350 batchs: 590.1143798828125
INFO:root:Train (Epoch 187): Loss/seq after 02400 batchs: 591.0156860351562
INFO:root:Train (Epoch 187): Loss/seq after 02450 batchs: 585.6790161132812
INFO:root:Train (Epoch 187): Loss/seq after 02500 batchs: 577.0029907226562
INFO:root:Train (Epoch 187): Loss/seq after 02550 batchs: 570.6984252929688
INFO:root:Train (Epoch 187): Loss/seq after 02600 batchs: 569.6563720703125
INFO:root:Train (Epoch 187): Loss/seq after 02650 batchs: 566.8394165039062
INFO:root:Train (Epoch 187): Loss/seq after 02700 batchs: 565.0281372070312
INFO:root:Train (Epoch 187): Loss/seq after 02750 batchs: 563.0455932617188
INFO:root:Train (Epoch 187): Loss/seq after 02800 batchs: 564.15576171875
INFO:root:Train (Epoch 187): Loss/seq after 02850 batchs: 563.8278198242188
INFO:root:Train (Epoch 187): Loss/seq after 02900 batchs: 565.1311645507812
INFO:root:Train (Epoch 187): Loss/seq after 02950 batchs: 563.8335571289062
INFO:root:Train (Epoch 187): Loss/seq after 03000 batchs: 568.5164184570312
INFO:root:Train (Epoch 187): Loss/seq after 03050 batchs: 570.8313598632812
INFO:root:Train (Epoch 187): Loss/seq after 03100 batchs: 574.3569946289062
INFO:root:Train (Epoch 187): Loss/seq after 03150 batchs: 580.699462890625
INFO:root:Train (Epoch 187): Loss/seq after 03200 batchs: 583.1021118164062
INFO:root:Train (Epoch 187): Loss/seq after 03250 batchs: 586.9191284179688
INFO:root:Train (Epoch 187): Loss/seq after 03300 batchs: 585.794921875
INFO:root:Train (Epoch 187): Loss/seq after 03350 batchs: 585.6583862304688
INFO:root:Train (Epoch 187): Loss/seq after 03400 batchs: 581.5513916015625
INFO:root:Train (Epoch 187): Loss/seq after 03450 batchs: 579.534423828125
INFO:root:Train (Epoch 187): Loss/seq after 03500 batchs: 579.0272827148438
INFO:root:Train (Epoch 187): Loss/seq after 03550 batchs: 575.9228515625
INFO:root:Train (Epoch 187): Loss/seq after 03600 batchs: 583.8171997070312
INFO:root:Train (Epoch 187): Loss/seq after 03650 batchs: 581.1021118164062
INFO:root:Train (Epoch 187): Loss/seq after 03700 batchs: 582.9742431640625
INFO:root:Train (Epoch 187): Loss/seq after 03750 batchs: 587.0023193359375
INFO:root:Train (Epoch 187): Loss/seq after 03800 batchs: 584.3384399414062
INFO:root:Train (Epoch 187): Loss/seq after 03850 batchs: 583.31005859375
INFO:root:Train (Epoch 187): Loss/seq after 03900 batchs: 587.0221557617188
INFO:root:Train (Epoch 187): Loss/seq after 03950 batchs: 590.5028686523438
INFO:root:Train (Epoch 187): Loss/seq after 04000 batchs: 586.3457641601562
INFO:root:Train (Epoch 187): Loss/seq after 04050 batchs: 582.4462280273438
INFO:root:Train (Epoch 187): Loss/seq after 04100 batchs: 580.5993041992188
INFO:root:Train (Epoch 187): Loss/seq after 04150 batchs: 580.1769409179688
INFO:root:Train (Epoch 187): Loss/seq after 04200 batchs: 578.0842895507812
INFO:root:Train (Epoch 187): Loss/seq after 04250 batchs: 576.0927124023438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 187): Loss/seq after 00000 batches: 512.0437622070312
INFO:root:# Valid (Epoch 187): Loss/seq after 00050 batches: 675.0708618164062
INFO:root:# Valid (Epoch 187): Loss/seq after 00100 batches: 729.703857421875
INFO:root:# Valid (Epoch 187): Loss/seq after 00150 batches: 550.903564453125
INFO:root:# Valid (Epoch 187): Loss/seq after 00200 batches: 510.7535705566406
INFO:root:Artifacts: Make stick videos for epoch 187
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_187_on_20220423_115032.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_187_index_1440_on_20220423_115032.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 188): Loss/seq after 00000 batchs: 1118.6783447265625
INFO:root:Train (Epoch 188): Loss/seq after 00050 batchs: 846.5006713867188
INFO:root:Train (Epoch 188): Loss/seq after 00100 batchs: 819.8894653320312
INFO:root:Train (Epoch 188): Loss/seq after 00150 batchs: 719.6261596679688
INFO:root:Train (Epoch 188): Loss/seq after 00200 batchs: 810.3904418945312
INFO:root:Train (Epoch 188): Loss/seq after 00250 batchs: 907.5831298828125
INFO:root:Train (Epoch 188): Loss/seq after 00300 batchs: 901.1275634765625
INFO:root:Train (Epoch 188): Loss/seq after 00350 batchs: 842.2581176757812
INFO:root:Train (Epoch 188): Loss/seq after 00400 batchs: 847.8966064453125
INFO:root:Train (Epoch 188): Loss/seq after 00450 batchs: 826.8787841796875
INFO:root:Train (Epoch 188): Loss/seq after 00500 batchs: 806.7911376953125
INFO:root:Train (Epoch 188): Loss/seq after 00550 batchs: 781.8642578125
INFO:root:Train (Epoch 188): Loss/seq after 00600 batchs: 753.2354736328125
INFO:root:Train (Epoch 188): Loss/seq after 00650 batchs: 742.06201171875
INFO:root:Train (Epoch 188): Loss/seq after 00700 batchs: 717.3021850585938
INFO:root:Train (Epoch 188): Loss/seq after 00750 batchs: 731.4227294921875
INFO:root:Train (Epoch 188): Loss/seq after 00800 batchs: 728.407470703125
INFO:root:Train (Epoch 188): Loss/seq after 00850 batchs: 704.95458984375
INFO:root:Train (Epoch 188): Loss/seq after 00900 batchs: 686.781005859375
INFO:root:Train (Epoch 188): Loss/seq after 00950 batchs: 690.8043212890625
INFO:root:Train (Epoch 188): Loss/seq after 01000 batchs: 683.2869873046875
INFO:root:Train (Epoch 188): Loss/seq after 01050 batchs: 669.5196533203125
INFO:root:Train (Epoch 188): Loss/seq after 01100 batchs: 658.1344604492188
INFO:root:Train (Epoch 188): Loss/seq after 01150 batchs: 642.8626708984375
INFO:root:Train (Epoch 188): Loss/seq after 01200 batchs: 645.8750610351562
INFO:root:Train (Epoch 188): Loss/seq after 01250 batchs: 642.1554565429688
INFO:root:Train (Epoch 188): Loss/seq after 01300 batchs: 632.6351928710938
INFO:root:Train (Epoch 188): Loss/seq after 01350 batchs: 623.65576171875
INFO:root:Train (Epoch 188): Loss/seq after 01400 batchs: 627.5098266601562
INFO:root:Train (Epoch 188): Loss/seq after 01450 batchs: 628.0421752929688
INFO:root:Train (Epoch 188): Loss/seq after 01500 batchs: 632.7523193359375
INFO:root:Train (Epoch 188): Loss/seq after 01550 batchs: 634.8702392578125
INFO:root:Train (Epoch 188): Loss/seq after 01600 batchs: 628.4003295898438
INFO:root:Train (Epoch 188): Loss/seq after 01650 batchs: 624.0958251953125
INFO:root:Train (Epoch 188): Loss/seq after 01700 batchs: 625.195068359375
INFO:root:Train (Epoch 188): Loss/seq after 01750 batchs: 621.7039184570312
INFO:root:Train (Epoch 188): Loss/seq after 01800 batchs: 618.3419189453125
INFO:root:Train (Epoch 188): Loss/seq after 01850 batchs: 613.4521484375
INFO:root:Train (Epoch 188): Loss/seq after 01900 batchs: 612.600830078125
INFO:root:Train (Epoch 188): Loss/seq after 01950 batchs: 610.729736328125
INFO:root:Train (Epoch 188): Loss/seq after 02000 batchs: 608.61279296875
INFO:root:Train (Epoch 188): Loss/seq after 02050 batchs: 606.2681884765625
INFO:root:Train (Epoch 188): Loss/seq after 02100 batchs: 602.5999755859375
INFO:root:Train (Epoch 188): Loss/seq after 02150 batchs: 599.6944580078125
INFO:root:Train (Epoch 188): Loss/seq after 02200 batchs: 596.114501953125
INFO:root:Train (Epoch 188): Loss/seq after 02250 batchs: 594.6884765625
INFO:root:Train (Epoch 188): Loss/seq after 02300 batchs: 593.7958984375
INFO:root:Train (Epoch 188): Loss/seq after 02350 batchs: 588.6390991210938
INFO:root:Train (Epoch 188): Loss/seq after 02400 batchs: 589.491943359375
INFO:root:Train (Epoch 188): Loss/seq after 02450 batchs: 584.3641967773438
INFO:root:Train (Epoch 188): Loss/seq after 02500 batchs: 575.6866455078125
INFO:root:Train (Epoch 188): Loss/seq after 02550 batchs: 569.4757690429688
INFO:root:Train (Epoch 188): Loss/seq after 02600 batchs: 568.0797729492188
INFO:root:Train (Epoch 188): Loss/seq after 02650 batchs: 565.1880493164062
INFO:root:Train (Epoch 188): Loss/seq after 02700 batchs: 563.0632934570312
INFO:root:Train (Epoch 188): Loss/seq after 02750 batchs: 561.7234497070312
INFO:root:Train (Epoch 188): Loss/seq after 02800 batchs: 562.150390625
INFO:root:Train (Epoch 188): Loss/seq after 02850 batchs: 562.0479125976562
INFO:root:Train (Epoch 188): Loss/seq after 02900 batchs: 563.1671752929688
INFO:root:Train (Epoch 188): Loss/seq after 02950 batchs: 561.903076171875
INFO:root:Train (Epoch 188): Loss/seq after 03000 batchs: 566.47119140625
INFO:root:Train (Epoch 188): Loss/seq after 03050 batchs: 568.505126953125
INFO:root:Train (Epoch 188): Loss/seq after 03100 batchs: 572.59423828125
INFO:root:Train (Epoch 188): Loss/seq after 03150 batchs: 579.5381469726562
INFO:root:Train (Epoch 188): Loss/seq after 03200 batchs: 581.3890380859375
INFO:root:Train (Epoch 188): Loss/seq after 03250 batchs: 585.0816650390625
INFO:root:Train (Epoch 188): Loss/seq after 03300 batchs: 584.0726318359375
INFO:root:Train (Epoch 188): Loss/seq after 03350 batchs: 584.1610107421875
INFO:root:Train (Epoch 188): Loss/seq after 03400 batchs: 579.9107055664062
INFO:root:Train (Epoch 188): Loss/seq after 03450 batchs: 577.8805541992188
INFO:root:Train (Epoch 188): Loss/seq after 03500 batchs: 577.9909057617188
INFO:root:Train (Epoch 188): Loss/seq after 03550 batchs: 575.155029296875
INFO:root:Train (Epoch 188): Loss/seq after 03600 batchs: 582.9151000976562
INFO:root:Train (Epoch 188): Loss/seq after 03650 batchs: 580.3939819335938
INFO:root:Train (Epoch 188): Loss/seq after 03700 batchs: 582.2767333984375
INFO:root:Train (Epoch 188): Loss/seq after 03750 batchs: 586.2579345703125
INFO:root:Train (Epoch 188): Loss/seq after 03800 batchs: 583.6124877929688
INFO:root:Train (Epoch 188): Loss/seq after 03850 batchs: 582.2865600585938
INFO:root:Train (Epoch 188): Loss/seq after 03900 batchs: 586.4014282226562
INFO:root:Train (Epoch 188): Loss/seq after 03950 batchs: 590.209716796875
INFO:root:Train (Epoch 188): Loss/seq after 04000 batchs: 586.08154296875
INFO:root:Train (Epoch 188): Loss/seq after 04050 batchs: 582.233642578125
INFO:root:Train (Epoch 188): Loss/seq after 04100 batchs: 580.3576049804688
INFO:root:Train (Epoch 188): Loss/seq after 04150 batchs: 579.8780517578125
INFO:root:Train (Epoch 188): Loss/seq after 04200 batchs: 577.700927734375
INFO:root:Train (Epoch 188): Loss/seq after 04250 batchs: 575.6046752929688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 188): Loss/seq after 00000 batches: 522.5374145507812
INFO:root:# Valid (Epoch 188): Loss/seq after 00050 batches: 669.6051025390625
INFO:root:# Valid (Epoch 188): Loss/seq after 00100 batches: 719.09765625
INFO:root:# Valid (Epoch 188): Loss/seq after 00150 batches: 545.2164916992188
INFO:root:# Valid (Epoch 188): Loss/seq after 00200 batches: 504.7718200683594
INFO:root:Artifacts: Make stick videos for epoch 188
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_188_on_20220423_115537.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_188_index_1172_on_20220423_115537.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 189): Loss/seq after 00000 batchs: 1178.4619140625
INFO:root:Train (Epoch 189): Loss/seq after 00050 batchs: 849.7664794921875
INFO:root:Train (Epoch 189): Loss/seq after 00100 batchs: 832.0261840820312
INFO:root:Train (Epoch 189): Loss/seq after 00150 batchs: 726.3084106445312
INFO:root:Train (Epoch 189): Loss/seq after 00200 batchs: 822.0608520507812
INFO:root:Train (Epoch 189): Loss/seq after 00250 batchs: 909.5902709960938
INFO:root:Train (Epoch 189): Loss/seq after 00300 batchs: 903.9498291015625
INFO:root:Train (Epoch 189): Loss/seq after 00350 batchs: 846.4099731445312
INFO:root:Train (Epoch 189): Loss/seq after 00400 batchs: 853.08203125
INFO:root:Train (Epoch 189): Loss/seq after 00450 batchs: 831.5211791992188
INFO:root:Train (Epoch 189): Loss/seq after 00500 batchs: 805.9993286132812
INFO:root:Train (Epoch 189): Loss/seq after 00550 batchs: 779.8441162109375
INFO:root:Train (Epoch 189): Loss/seq after 00600 batchs: 751.4234008789062
INFO:root:Train (Epoch 189): Loss/seq after 00650 batchs: 738.5869140625
INFO:root:Train (Epoch 189): Loss/seq after 00700 batchs: 713.156005859375
INFO:root:Train (Epoch 189): Loss/seq after 00750 batchs: 723.388427734375
INFO:root:Train (Epoch 189): Loss/seq after 00800 batchs: 720.5604858398438
INFO:root:Train (Epoch 189): Loss/seq after 00850 batchs: 697.6670532226562
INFO:root:Train (Epoch 189): Loss/seq after 00900 batchs: 679.1637573242188
INFO:root:Train (Epoch 189): Loss/seq after 00950 batchs: 680.7232666015625
INFO:root:Train (Epoch 189): Loss/seq after 01000 batchs: 673.5059814453125
INFO:root:Train (Epoch 189): Loss/seq after 01050 batchs: 659.774169921875
INFO:root:Train (Epoch 189): Loss/seq after 01100 batchs: 648.442626953125
INFO:root:Train (Epoch 189): Loss/seq after 01150 batchs: 633.4296264648438
INFO:root:Train (Epoch 189): Loss/seq after 01200 batchs: 636.94189453125
INFO:root:Train (Epoch 189): Loss/seq after 01250 batchs: 633.0952758789062
INFO:root:Train (Epoch 189): Loss/seq after 01300 batchs: 622.070068359375
INFO:root:Train (Epoch 189): Loss/seq after 01350 batchs: 613.117919921875
INFO:root:Train (Epoch 189): Loss/seq after 01400 batchs: 619.2728881835938
INFO:root:Train (Epoch 189): Loss/seq after 01450 batchs: 619.7391357421875
INFO:root:Train (Epoch 189): Loss/seq after 01500 batchs: 624.9802856445312
INFO:root:Train (Epoch 189): Loss/seq after 01550 batchs: 627.159423828125
INFO:root:Train (Epoch 189): Loss/seq after 01600 batchs: 620.7689208984375
INFO:root:Train (Epoch 189): Loss/seq after 01650 batchs: 616.6973266601562
INFO:root:Train (Epoch 189): Loss/seq after 01700 batchs: 617.8051147460938
INFO:root:Train (Epoch 189): Loss/seq after 01750 batchs: 614.2200317382812
INFO:root:Train (Epoch 189): Loss/seq after 01800 batchs: 610.8800659179688
INFO:root:Train (Epoch 189): Loss/seq after 01850 batchs: 606.009765625
INFO:root:Train (Epoch 189): Loss/seq after 01900 batchs: 605.5665283203125
INFO:root:Train (Epoch 189): Loss/seq after 01950 batchs: 603.4443969726562
INFO:root:Train (Epoch 189): Loss/seq after 02000 batchs: 601.6051025390625
INFO:root:Train (Epoch 189): Loss/seq after 02050 batchs: 599.2788696289062
INFO:root:Train (Epoch 189): Loss/seq after 02100 batchs: 595.8650512695312
INFO:root:Train (Epoch 189): Loss/seq after 02150 batchs: 593.0250244140625
INFO:root:Train (Epoch 189): Loss/seq after 02200 batchs: 589.5745849609375
INFO:root:Train (Epoch 189): Loss/seq after 02250 batchs: 588.2056274414062
INFO:root:Train (Epoch 189): Loss/seq after 02300 batchs: 588.5668334960938
INFO:root:Train (Epoch 189): Loss/seq after 02350 batchs: 583.4093017578125
INFO:root:Train (Epoch 189): Loss/seq after 02400 batchs: 584.344482421875
INFO:root:Train (Epoch 189): Loss/seq after 02450 batchs: 579.2107543945312
INFO:root:Train (Epoch 189): Loss/seq after 02500 batchs: 570.5823364257812
INFO:root:Train (Epoch 189): Loss/seq after 02550 batchs: 564.4965209960938
INFO:root:Train (Epoch 189): Loss/seq after 02600 batchs: 563.3157958984375
INFO:root:Train (Epoch 189): Loss/seq after 02650 batchs: 560.793212890625
INFO:root:Train (Epoch 189): Loss/seq after 02700 batchs: 558.6448364257812
INFO:root:Train (Epoch 189): Loss/seq after 02750 batchs: 557.2531127929688
INFO:root:Train (Epoch 189): Loss/seq after 02800 batchs: 557.8802490234375
INFO:root:Train (Epoch 189): Loss/seq after 02850 batchs: 557.59228515625
INFO:root:Train (Epoch 189): Loss/seq after 02900 batchs: 558.8553466796875
INFO:root:Train (Epoch 189): Loss/seq after 02950 batchs: 557.5925903320312
INFO:root:Train (Epoch 189): Loss/seq after 03000 batchs: 562.2255859375
INFO:root:Train (Epoch 189): Loss/seq after 03050 batchs: 564.1895141601562
INFO:root:Train (Epoch 189): Loss/seq after 03100 batchs: 567.7664184570312
INFO:root:Train (Epoch 189): Loss/seq after 03150 batchs: 574.4579467773438
INFO:root:Train (Epoch 189): Loss/seq after 03200 batchs: 575.7542724609375
INFO:root:Train (Epoch 189): Loss/seq after 03250 batchs: 579.638916015625
INFO:root:Train (Epoch 189): Loss/seq after 03300 batchs: 578.6919555664062
INFO:root:Train (Epoch 189): Loss/seq after 03350 batchs: 578.4910278320312
INFO:root:Train (Epoch 189): Loss/seq after 03400 batchs: 574.4390258789062
INFO:root:Train (Epoch 189): Loss/seq after 03450 batchs: 572.5659790039062
INFO:root:Train (Epoch 189): Loss/seq after 03500 batchs: 572.4486083984375
INFO:root:Train (Epoch 189): Loss/seq after 03550 batchs: 569.3815307617188
INFO:root:Train (Epoch 189): Loss/seq after 03600 batchs: 577.4588623046875
INFO:root:Train (Epoch 189): Loss/seq after 03650 batchs: 574.6995849609375
INFO:root:Train (Epoch 189): Loss/seq after 03700 batchs: 576.5331420898438
INFO:root:Train (Epoch 189): Loss/seq after 03750 batchs: 580.5869750976562
INFO:root:Train (Epoch 189): Loss/seq after 03800 batchs: 577.977294921875
INFO:root:Train (Epoch 189): Loss/seq after 03850 batchs: 577.0242309570312
INFO:root:Train (Epoch 189): Loss/seq after 03900 batchs: 580.612548828125
INFO:root:Train (Epoch 189): Loss/seq after 03950 batchs: 584.1542358398438
INFO:root:Train (Epoch 189): Loss/seq after 04000 batchs: 580.0199584960938
INFO:root:Train (Epoch 189): Loss/seq after 04050 batchs: 576.2804565429688
INFO:root:Train (Epoch 189): Loss/seq after 04100 batchs: 574.4366455078125
INFO:root:Train (Epoch 189): Loss/seq after 04150 batchs: 574.01904296875
INFO:root:Train (Epoch 189): Loss/seq after 04200 batchs: 571.8717651367188
INFO:root:Train (Epoch 189): Loss/seq after 04250 batchs: 569.9133911132812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 189): Loss/seq after 00000 batches: 498.8451232910156
INFO:root:# Valid (Epoch 189): Loss/seq after 00050 batches: 668.2398071289062
INFO:root:# Valid (Epoch 189): Loss/seq after 00100 batches: 741.091796875
INFO:root:# Valid (Epoch 189): Loss/seq after 00150 batches: 561.4498901367188
INFO:root:# Valid (Epoch 189): Loss/seq after 00200 batches: 517.6229858398438
INFO:root:Artifacts: Make stick videos for epoch 189
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_189_on_20220423_120035.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_189_index_292_on_20220423_120035.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 190): Loss/seq after 00000 batchs: 1279.416259765625
INFO:root:Train (Epoch 190): Loss/seq after 00050 batchs: 830.264892578125
INFO:root:Train (Epoch 190): Loss/seq after 00100 batchs: 827.7376708984375
INFO:root:Train (Epoch 190): Loss/seq after 00150 batchs: 722.1974487304688
INFO:root:Train (Epoch 190): Loss/seq after 00200 batchs: 812.0318603515625
INFO:root:Train (Epoch 190): Loss/seq after 00250 batchs: 891.0142822265625
INFO:root:Train (Epoch 190): Loss/seq after 00300 batchs: 887.1974487304688
INFO:root:Train (Epoch 190): Loss/seq after 00350 batchs: 830.2173461914062
INFO:root:Train (Epoch 190): Loss/seq after 00400 batchs: 838.1040649414062
INFO:root:Train (Epoch 190): Loss/seq after 00450 batchs: 818.3826904296875
INFO:root:Train (Epoch 190): Loss/seq after 00500 batchs: 795.717041015625
INFO:root:Train (Epoch 190): Loss/seq after 00550 batchs: 770.0771484375
INFO:root:Train (Epoch 190): Loss/seq after 00600 batchs: 742.0429077148438
INFO:root:Train (Epoch 190): Loss/seq after 00650 batchs: 730.1500854492188
INFO:root:Train (Epoch 190): Loss/seq after 00700 batchs: 707.8184204101562
INFO:root:Train (Epoch 190): Loss/seq after 00750 batchs: 720.0800170898438
INFO:root:Train (Epoch 190): Loss/seq after 00800 batchs: 717.231201171875
INFO:root:Train (Epoch 190): Loss/seq after 00850 batchs: 694.5151977539062
INFO:root:Train (Epoch 190): Loss/seq after 00900 batchs: 675.8426513671875
INFO:root:Train (Epoch 190): Loss/seq after 00950 batchs: 677.432861328125
INFO:root:Train (Epoch 190): Loss/seq after 01000 batchs: 669.329833984375
INFO:root:Train (Epoch 190): Loss/seq after 01050 batchs: 656.4935913085938
INFO:root:Train (Epoch 190): Loss/seq after 01100 batchs: 644.693359375
INFO:root:Train (Epoch 190): Loss/seq after 01150 batchs: 629.8614501953125
INFO:root:Train (Epoch 190): Loss/seq after 01200 batchs: 632.68359375
INFO:root:Train (Epoch 190): Loss/seq after 01250 batchs: 630.6942138671875
INFO:root:Train (Epoch 190): Loss/seq after 01300 batchs: 620.9459838867188
INFO:root:Train (Epoch 190): Loss/seq after 01350 batchs: 612.0818481445312
INFO:root:Train (Epoch 190): Loss/seq after 01400 batchs: 617.2924194335938
INFO:root:Train (Epoch 190): Loss/seq after 01450 batchs: 617.8753662109375
INFO:root:Train (Epoch 190): Loss/seq after 01500 batchs: 622.8721313476562
INFO:root:Train (Epoch 190): Loss/seq after 01550 batchs: 624.7657470703125
INFO:root:Train (Epoch 190): Loss/seq after 01600 batchs: 618.6325073242188
INFO:root:Train (Epoch 190): Loss/seq after 01650 batchs: 614.709228515625
INFO:root:Train (Epoch 190): Loss/seq after 01700 batchs: 615.9613037109375
INFO:root:Train (Epoch 190): Loss/seq after 01750 batchs: 612.7420043945312
INFO:root:Train (Epoch 190): Loss/seq after 01800 batchs: 609.5529174804688
INFO:root:Train (Epoch 190): Loss/seq after 01850 batchs: 604.8486328125
INFO:root:Train (Epoch 190): Loss/seq after 01900 batchs: 604.0348510742188
INFO:root:Train (Epoch 190): Loss/seq after 01950 batchs: 602.0474243164062
INFO:root:Train (Epoch 190): Loss/seq after 02000 batchs: 600.2880249023438
INFO:root:Train (Epoch 190): Loss/seq after 02050 batchs: 597.947509765625
INFO:root:Train (Epoch 190): Loss/seq after 02100 batchs: 594.5339965820312
INFO:root:Train (Epoch 190): Loss/seq after 02150 batchs: 591.7738037109375
INFO:root:Train (Epoch 190): Loss/seq after 02200 batchs: 588.32666015625
INFO:root:Train (Epoch 190): Loss/seq after 02250 batchs: 587.062744140625
INFO:root:Train (Epoch 190): Loss/seq after 02300 batchs: 585.21142578125
INFO:root:Train (Epoch 190): Loss/seq after 02350 batchs: 580.1784057617188
INFO:root:Train (Epoch 190): Loss/seq after 02400 batchs: 581.2139282226562
INFO:root:Train (Epoch 190): Loss/seq after 02450 batchs: 576.0670166015625
INFO:root:Train (Epoch 190): Loss/seq after 02500 batchs: 567.5018920898438
INFO:root:Train (Epoch 190): Loss/seq after 02550 batchs: 561.1678466796875
INFO:root:Train (Epoch 190): Loss/seq after 02600 batchs: 559.80224609375
INFO:root:Train (Epoch 190): Loss/seq after 02650 batchs: 556.9661865234375
INFO:root:Train (Epoch 190): Loss/seq after 02700 batchs: 554.9828491210938
INFO:root:Train (Epoch 190): Loss/seq after 02750 batchs: 552.55419921875
INFO:root:Train (Epoch 190): Loss/seq after 02800 batchs: 552.99267578125
INFO:root:Train (Epoch 190): Loss/seq after 02850 batchs: 552.6382446289062
INFO:root:Train (Epoch 190): Loss/seq after 02900 batchs: 554.0872192382812
INFO:root:Train (Epoch 190): Loss/seq after 02950 batchs: 552.9669799804688
INFO:root:Train (Epoch 190): Loss/seq after 03000 batchs: 557.662109375
INFO:root:Train (Epoch 190): Loss/seq after 03050 batchs: 559.8944702148438
INFO:root:Train (Epoch 190): Loss/seq after 03100 batchs: 563.6510620117188
INFO:root:Train (Epoch 190): Loss/seq after 03150 batchs: 571.3549194335938
INFO:root:Train (Epoch 190): Loss/seq after 03200 batchs: 573.8394165039062
INFO:root:Train (Epoch 190): Loss/seq after 03250 batchs: 577.6002197265625
INFO:root:Train (Epoch 190): Loss/seq after 03300 batchs: 576.8326416015625
INFO:root:Train (Epoch 190): Loss/seq after 03350 batchs: 576.5568237304688
INFO:root:Train (Epoch 190): Loss/seq after 03400 batchs: 572.5429077148438
INFO:root:Train (Epoch 190): Loss/seq after 03450 batchs: 570.8910522460938
INFO:root:Train (Epoch 190): Loss/seq after 03500 batchs: 570.8521728515625
INFO:root:Train (Epoch 190): Loss/seq after 03550 batchs: 568.0765380859375
INFO:root:Train (Epoch 190): Loss/seq after 03600 batchs: 576.2261962890625
INFO:root:Train (Epoch 190): Loss/seq after 03650 batchs: 573.622314453125
INFO:root:Train (Epoch 190): Loss/seq after 03700 batchs: 575.6033935546875
INFO:root:Train (Epoch 190): Loss/seq after 03750 batchs: 579.7936401367188
INFO:root:Train (Epoch 190): Loss/seq after 03800 batchs: 577.1385498046875
INFO:root:Train (Epoch 190): Loss/seq after 03850 batchs: 575.9893798828125
INFO:root:Train (Epoch 190): Loss/seq after 03900 batchs: 579.9116821289062
INFO:root:Train (Epoch 190): Loss/seq after 03950 batchs: 583.68505859375
INFO:root:Train (Epoch 190): Loss/seq after 04000 batchs: 579.6826171875
INFO:root:Train (Epoch 190): Loss/seq after 04050 batchs: 575.913818359375
INFO:root:Train (Epoch 190): Loss/seq after 04100 batchs: 574.0040893554688
INFO:root:Train (Epoch 190): Loss/seq after 04150 batchs: 573.5970458984375
INFO:root:Train (Epoch 190): Loss/seq after 04200 batchs: 571.4080810546875
INFO:root:Train (Epoch 190): Loss/seq after 04250 batchs: 569.4654541015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 190): Loss/seq after 00000 batches: 451.2275390625
INFO:root:# Valid (Epoch 190): Loss/seq after 00050 batches: 683.2315063476562
INFO:root:# Valid (Epoch 190): Loss/seq after 00100 batches: 758.1537475585938
INFO:root:# Valid (Epoch 190): Loss/seq after 00150 batches: 570.1034545898438
INFO:root:# Valid (Epoch 190): Loss/seq after 00200 batches: 525.9255981445312
INFO:root:Artifacts: Make stick videos for epoch 190
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_190_on_20220423_120531.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_190_index_1017_on_20220423_120531.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 191): Loss/seq after 00000 batchs: 1307.367919921875
INFO:root:Train (Epoch 191): Loss/seq after 00050 batchs: 837.646484375
INFO:root:Train (Epoch 191): Loss/seq after 00100 batchs: 823.315673828125
INFO:root:Train (Epoch 191): Loss/seq after 00150 batchs: 718.6041259765625
INFO:root:Train (Epoch 191): Loss/seq after 00200 batchs: 810.962890625
INFO:root:Train (Epoch 191): Loss/seq after 00250 batchs: 889.25830078125
INFO:root:Train (Epoch 191): Loss/seq after 00300 batchs: 886.0148315429688
INFO:root:Train (Epoch 191): Loss/seq after 00350 batchs: 830.1361083984375
INFO:root:Train (Epoch 191): Loss/seq after 00400 batchs: 837.721435546875
INFO:root:Train (Epoch 191): Loss/seq after 00450 batchs: 818.1768798828125
INFO:root:Train (Epoch 191): Loss/seq after 00500 batchs: 793.4592895507812
INFO:root:Train (Epoch 191): Loss/seq after 00550 batchs: 767.9718627929688
INFO:root:Train (Epoch 191): Loss/seq after 00600 batchs: 740.4194946289062
INFO:root:Train (Epoch 191): Loss/seq after 00650 batchs: 727.9671630859375
INFO:root:Train (Epoch 191): Loss/seq after 00700 batchs: 706.2327270507812
INFO:root:Train (Epoch 191): Loss/seq after 00750 batchs: 717.4505615234375
INFO:root:Train (Epoch 191): Loss/seq after 00800 batchs: 715.6278076171875
INFO:root:Train (Epoch 191): Loss/seq after 00850 batchs: 693.2769165039062
INFO:root:Train (Epoch 191): Loss/seq after 00900 batchs: 674.6298828125
INFO:root:Train (Epoch 191): Loss/seq after 00950 batchs: 675.0709838867188
INFO:root:Train (Epoch 191): Loss/seq after 01000 batchs: 665.9987182617188
INFO:root:Train (Epoch 191): Loss/seq after 01050 batchs: 653.028564453125
INFO:root:Train (Epoch 191): Loss/seq after 01100 batchs: 642.4306030273438
INFO:root:Train (Epoch 191): Loss/seq after 01150 batchs: 626.8970947265625
INFO:root:Train (Epoch 191): Loss/seq after 01200 batchs: 630.580322265625
INFO:root:Train (Epoch 191): Loss/seq after 01250 batchs: 627.926025390625
INFO:root:Train (Epoch 191): Loss/seq after 01300 batchs: 616.8036499023438
INFO:root:Train (Epoch 191): Loss/seq after 01350 batchs: 608.082763671875
INFO:root:Train (Epoch 191): Loss/seq after 01400 batchs: 612.8634643554688
INFO:root:Train (Epoch 191): Loss/seq after 01450 batchs: 613.6998291015625
INFO:root:Train (Epoch 191): Loss/seq after 01500 batchs: 618.8428955078125
INFO:root:Train (Epoch 191): Loss/seq after 01550 batchs: 620.4990234375
INFO:root:Train (Epoch 191): Loss/seq after 01600 batchs: 614.1146240234375
INFO:root:Train (Epoch 191): Loss/seq after 01650 batchs: 610.4266967773438
INFO:root:Train (Epoch 191): Loss/seq after 01700 batchs: 611.896240234375
INFO:root:Train (Epoch 191): Loss/seq after 01750 batchs: 608.761474609375
INFO:root:Train (Epoch 191): Loss/seq after 01800 batchs: 605.5989990234375
INFO:root:Train (Epoch 191): Loss/seq after 01850 batchs: 600.9615478515625
INFO:root:Train (Epoch 191): Loss/seq after 01900 batchs: 600.370361328125
INFO:root:Train (Epoch 191): Loss/seq after 01950 batchs: 598.499755859375
INFO:root:Train (Epoch 191): Loss/seq after 02000 batchs: 596.6178588867188
INFO:root:Train (Epoch 191): Loss/seq after 02050 batchs: 594.3458251953125
INFO:root:Train (Epoch 191): Loss/seq after 02100 batchs: 591.054443359375
INFO:root:Train (Epoch 191): Loss/seq after 02150 batchs: 588.4889526367188
INFO:root:Train (Epoch 191): Loss/seq after 02200 batchs: 585.126220703125
INFO:root:Train (Epoch 191): Loss/seq after 02250 batchs: 584.0501098632812
INFO:root:Train (Epoch 191): Loss/seq after 02300 batchs: 582.7774658203125
INFO:root:Train (Epoch 191): Loss/seq after 02350 batchs: 577.7924194335938
INFO:root:Train (Epoch 191): Loss/seq after 02400 batchs: 578.79345703125
INFO:root:Train (Epoch 191): Loss/seq after 02450 batchs: 573.8035888671875
INFO:root:Train (Epoch 191): Loss/seq after 02500 batchs: 565.2855834960938
INFO:root:Train (Epoch 191): Loss/seq after 02550 batchs: 559.1817626953125
INFO:root:Train (Epoch 191): Loss/seq after 02600 batchs: 557.975341796875
INFO:root:Train (Epoch 191): Loss/seq after 02650 batchs: 555.236328125
INFO:root:Train (Epoch 191): Loss/seq after 02700 batchs: 552.85888671875
INFO:root:Train (Epoch 191): Loss/seq after 02750 batchs: 551.2384033203125
INFO:root:Train (Epoch 191): Loss/seq after 02800 batchs: 551.8081665039062
INFO:root:Train (Epoch 191): Loss/seq after 02850 batchs: 551.6797485351562
INFO:root:Train (Epoch 191): Loss/seq after 02900 batchs: 553.1423950195312
INFO:root:Train (Epoch 191): Loss/seq after 02950 batchs: 552.0249633789062
INFO:root:Train (Epoch 191): Loss/seq after 03000 batchs: 556.7905883789062
INFO:root:Train (Epoch 191): Loss/seq after 03050 batchs: 558.8692626953125
INFO:root:Train (Epoch 191): Loss/seq after 03100 batchs: 561.8020629882812
INFO:root:Train (Epoch 191): Loss/seq after 03150 batchs: 568.6157836914062
INFO:root:Train (Epoch 191): Loss/seq after 03200 batchs: 570.3846435546875
INFO:root:Train (Epoch 191): Loss/seq after 03250 batchs: 573.6823120117188
INFO:root:Train (Epoch 191): Loss/seq after 03300 batchs: 572.6640014648438
INFO:root:Train (Epoch 191): Loss/seq after 03350 batchs: 572.2570190429688
INFO:root:Train (Epoch 191): Loss/seq after 03400 batchs: 568.2716064453125
INFO:root:Train (Epoch 191): Loss/seq after 03450 batchs: 566.3092041015625
INFO:root:Train (Epoch 191): Loss/seq after 03500 batchs: 566.45068359375
INFO:root:Train (Epoch 191): Loss/seq after 03550 batchs: 563.5905151367188
INFO:root:Train (Epoch 191): Loss/seq after 03600 batchs: 571.629638671875
INFO:root:Train (Epoch 191): Loss/seq after 03650 batchs: 569.0573120117188
INFO:root:Train (Epoch 191): Loss/seq after 03700 batchs: 571.1315307617188
INFO:root:Train (Epoch 191): Loss/seq after 03750 batchs: 575.3175659179688
INFO:root:Train (Epoch 191): Loss/seq after 03800 batchs: 572.7587280273438
INFO:root:Train (Epoch 191): Loss/seq after 03850 batchs: 571.558349609375
INFO:root:Train (Epoch 191): Loss/seq after 03900 batchs: 575.1309814453125
INFO:root:Train (Epoch 191): Loss/seq after 03950 batchs: 578.4096069335938
INFO:root:Train (Epoch 191): Loss/seq after 04000 batchs: 574.3687744140625
INFO:root:Train (Epoch 191): Loss/seq after 04050 batchs: 570.632080078125
INFO:root:Train (Epoch 191): Loss/seq after 04100 batchs: 568.8544921875
INFO:root:Train (Epoch 191): Loss/seq after 04150 batchs: 568.4345703125
INFO:root:Train (Epoch 191): Loss/seq after 04200 batchs: 566.2786254882812
INFO:root:Train (Epoch 191): Loss/seq after 04250 batchs: 564.4054565429688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 191): Loss/seq after 00000 batches: 552.59716796875
INFO:root:# Valid (Epoch 191): Loss/seq after 00050 batches: 681.967041015625
INFO:root:# Valid (Epoch 191): Loss/seq after 00100 batches: 730.558837890625
INFO:root:# Valid (Epoch 191): Loss/seq after 00150 batches: 553.9513549804688
INFO:root:# Valid (Epoch 191): Loss/seq after 00200 batches: 512.0120239257812
INFO:root:Artifacts: Make stick videos for epoch 191
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_191_on_20220423_121015.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_191_index_1698_on_20220423_121015.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 192): Loss/seq after 00000 batchs: 1124.2109375
INFO:root:Train (Epoch 192): Loss/seq after 00050 batchs: 800.2863159179688
INFO:root:Train (Epoch 192): Loss/seq after 00100 batchs: 813.4095458984375
INFO:root:Train (Epoch 192): Loss/seq after 00150 batchs: 712.6591186523438
INFO:root:Train (Epoch 192): Loss/seq after 00200 batchs: 799.9547119140625
INFO:root:Train (Epoch 192): Loss/seq after 00250 batchs: 873.4446411132812
INFO:root:Train (Epoch 192): Loss/seq after 00300 batchs: 872.9856567382812
INFO:root:Train (Epoch 192): Loss/seq after 00350 batchs: 818.500732421875
INFO:root:Train (Epoch 192): Loss/seq after 00400 batchs: 825.6510620117188
INFO:root:Train (Epoch 192): Loss/seq after 00450 batchs: 806.9505615234375
INFO:root:Train (Epoch 192): Loss/seq after 00500 batchs: 785.5430297851562
INFO:root:Train (Epoch 192): Loss/seq after 00550 batchs: 760.9400634765625
INFO:root:Train (Epoch 192): Loss/seq after 00600 batchs: 733.3602294921875
INFO:root:Train (Epoch 192): Loss/seq after 00650 batchs: 719.1170654296875
INFO:root:Train (Epoch 192): Loss/seq after 00700 batchs: 695.7361450195312
INFO:root:Train (Epoch 192): Loss/seq after 00750 batchs: 711.6875610351562
INFO:root:Train (Epoch 192): Loss/seq after 00800 batchs: 711.3348999023438
INFO:root:Train (Epoch 192): Loss/seq after 00850 batchs: 688.9122924804688
INFO:root:Train (Epoch 192): Loss/seq after 00900 batchs: 670.5682983398438
INFO:root:Train (Epoch 192): Loss/seq after 00950 batchs: 673.6026611328125
INFO:root:Train (Epoch 192): Loss/seq after 01000 batchs: 666.1210327148438
INFO:root:Train (Epoch 192): Loss/seq after 01050 batchs: 653.1026611328125
INFO:root:Train (Epoch 192): Loss/seq after 01100 batchs: 641.9500122070312
INFO:root:Train (Epoch 192): Loss/seq after 01150 batchs: 626.3882446289062
INFO:root:Train (Epoch 192): Loss/seq after 01200 batchs: 629.3588256835938
INFO:root:Train (Epoch 192): Loss/seq after 01250 batchs: 626.0927734375
INFO:root:Train (Epoch 192): Loss/seq after 01300 batchs: 616.4296875
INFO:root:Train (Epoch 192): Loss/seq after 01350 batchs: 608.5804443359375
INFO:root:Train (Epoch 192): Loss/seq after 01400 batchs: 613.038818359375
INFO:root:Train (Epoch 192): Loss/seq after 01450 batchs: 613.6603393554688
INFO:root:Train (Epoch 192): Loss/seq after 01500 batchs: 618.8946533203125
INFO:root:Train (Epoch 192): Loss/seq after 01550 batchs: 620.4312744140625
INFO:root:Train (Epoch 192): Loss/seq after 01600 batchs: 614.024169921875
INFO:root:Train (Epoch 192): Loss/seq after 01650 batchs: 609.9940795898438
INFO:root:Train (Epoch 192): Loss/seq after 01700 batchs: 611.610107421875
INFO:root:Train (Epoch 192): Loss/seq after 01750 batchs: 608.60791015625
INFO:root:Train (Epoch 192): Loss/seq after 01800 batchs: 605.183349609375
INFO:root:Train (Epoch 192): Loss/seq after 01850 batchs: 600.4798583984375
INFO:root:Train (Epoch 192): Loss/seq after 01900 batchs: 599.7005615234375
INFO:root:Train (Epoch 192): Loss/seq after 01950 batchs: 597.8115844726562
INFO:root:Train (Epoch 192): Loss/seq after 02000 batchs: 595.9745483398438
INFO:root:Train (Epoch 192): Loss/seq after 02050 batchs: 593.664794921875
INFO:root:Train (Epoch 192): Loss/seq after 02100 batchs: 590.2130126953125
INFO:root:Train (Epoch 192): Loss/seq after 02150 batchs: 587.5421142578125
INFO:root:Train (Epoch 192): Loss/seq after 02200 batchs: 584.0792236328125
INFO:root:Train (Epoch 192): Loss/seq after 02250 batchs: 583.12451171875
INFO:root:Train (Epoch 192): Loss/seq after 02300 batchs: 582.2154541015625
INFO:root:Train (Epoch 192): Loss/seq after 02350 batchs: 577.3831176757812
INFO:root:Train (Epoch 192): Loss/seq after 02400 batchs: 578.474853515625
INFO:root:Train (Epoch 192): Loss/seq after 02450 batchs: 573.4944458007812
INFO:root:Train (Epoch 192): Loss/seq after 02500 batchs: 564.9862060546875
INFO:root:Train (Epoch 192): Loss/seq after 02550 batchs: 558.5630493164062
INFO:root:Train (Epoch 192): Loss/seq after 02600 batchs: 557.343017578125
INFO:root:Train (Epoch 192): Loss/seq after 02650 batchs: 554.6759033203125
INFO:root:Train (Epoch 192): Loss/seq after 02700 batchs: 552.3966674804688
INFO:root:Train (Epoch 192): Loss/seq after 02750 batchs: 550.0670776367188
INFO:root:Train (Epoch 192): Loss/seq after 02800 batchs: 550.8051147460938
INFO:root:Train (Epoch 192): Loss/seq after 02850 batchs: 550.5090942382812
INFO:root:Train (Epoch 192): Loss/seq after 02900 batchs: 551.9342651367188
INFO:root:Train (Epoch 192): Loss/seq after 02950 batchs: 550.7823486328125
INFO:root:Train (Epoch 192): Loss/seq after 03000 batchs: 555.372314453125
INFO:root:Train (Epoch 192): Loss/seq after 03050 batchs: 557.5155639648438
INFO:root:Train (Epoch 192): Loss/seq after 03100 batchs: 560.9056396484375
INFO:root:Train (Epoch 192): Loss/seq after 03150 batchs: 566.417724609375
INFO:root:Train (Epoch 192): Loss/seq after 03200 batchs: 568.5062866210938
INFO:root:Train (Epoch 192): Loss/seq after 03250 batchs: 571.362548828125
INFO:root:Train (Epoch 192): Loss/seq after 03300 batchs: 570.8410034179688
INFO:root:Train (Epoch 192): Loss/seq after 03350 batchs: 570.6901245117188
INFO:root:Train (Epoch 192): Loss/seq after 03400 batchs: 566.685546875
INFO:root:Train (Epoch 192): Loss/seq after 03450 batchs: 564.9874877929688
INFO:root:Train (Epoch 192): Loss/seq after 03500 batchs: 565.4225463867188
INFO:root:Train (Epoch 192): Loss/seq after 03550 batchs: 562.7662353515625
INFO:root:Train (Epoch 192): Loss/seq after 03600 batchs: 570.9586791992188
INFO:root:Train (Epoch 192): Loss/seq after 03650 batchs: 568.5382690429688
INFO:root:Train (Epoch 192): Loss/seq after 03700 batchs: 570.5443115234375
INFO:root:Train (Epoch 192): Loss/seq after 03750 batchs: 574.78564453125
INFO:root:Train (Epoch 192): Loss/seq after 03800 batchs: 572.20751953125
INFO:root:Train (Epoch 192): Loss/seq after 03850 batchs: 571.0944213867188
INFO:root:Train (Epoch 192): Loss/seq after 03900 batchs: 575.5026245117188
INFO:root:Train (Epoch 192): Loss/seq after 03950 batchs: 579.6796264648438
INFO:root:Train (Epoch 192): Loss/seq after 04000 batchs: 575.687255859375
INFO:root:Train (Epoch 192): Loss/seq after 04050 batchs: 572.02099609375
INFO:root:Train (Epoch 192): Loss/seq after 04100 batchs: 570.0969848632812
INFO:root:Train (Epoch 192): Loss/seq after 04150 batchs: 569.69873046875
INFO:root:Train (Epoch 192): Loss/seq after 04200 batchs: 567.59912109375
INFO:root:Train (Epoch 192): Loss/seq after 04250 batchs: 565.752197265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 192): Loss/seq after 00000 batches: 585.5675048828125
INFO:root:# Valid (Epoch 192): Loss/seq after 00050 batches: 694.3451538085938
INFO:root:# Valid (Epoch 192): Loss/seq after 00100 batches: 729.83203125
INFO:root:# Valid (Epoch 192): Loss/seq after 00150 batches: 553.1903686523438
INFO:root:# Valid (Epoch 192): Loss/seq after 00200 batches: 514.1771850585938
INFO:root:Artifacts: Make stick videos for epoch 192
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_192_on_20220423_121500.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_192_index_1905_on_20220423_121500.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 193): Loss/seq after 00000 batchs: 1365.9229736328125
INFO:root:Train (Epoch 193): Loss/seq after 00050 batchs: 855.2847900390625
INFO:root:Train (Epoch 193): Loss/seq after 00100 batchs: 829.8113403320312
INFO:root:Train (Epoch 193): Loss/seq after 00150 batchs: 723.436279296875
INFO:root:Train (Epoch 193): Loss/seq after 00200 batchs: 810.8004150390625
INFO:root:Train (Epoch 193): Loss/seq after 00250 batchs: 890.73681640625
INFO:root:Train (Epoch 193): Loss/seq after 00300 batchs: 886.45751953125
INFO:root:Train (Epoch 193): Loss/seq after 00350 batchs: 829.3395385742188
INFO:root:Train (Epoch 193): Loss/seq after 00400 batchs: 835.0697021484375
INFO:root:Train (Epoch 193): Loss/seq after 00450 batchs: 815.3587646484375
INFO:root:Train (Epoch 193): Loss/seq after 00500 batchs: 793.4918212890625
INFO:root:Train (Epoch 193): Loss/seq after 00550 batchs: 768.2280883789062
INFO:root:Train (Epoch 193): Loss/seq after 00600 batchs: 740.3387451171875
INFO:root:Train (Epoch 193): Loss/seq after 00650 batchs: 727.749267578125
INFO:root:Train (Epoch 193): Loss/seq after 00700 batchs: 706.4639892578125
INFO:root:Train (Epoch 193): Loss/seq after 00750 batchs: 719.1244506835938
INFO:root:Train (Epoch 193): Loss/seq after 00800 batchs: 716.4176025390625
INFO:root:Train (Epoch 193): Loss/seq after 00850 batchs: 693.4561157226562
INFO:root:Train (Epoch 193): Loss/seq after 00900 batchs: 675.3294067382812
INFO:root:Train (Epoch 193): Loss/seq after 00950 batchs: 681.6514282226562
INFO:root:Train (Epoch 193): Loss/seq after 01000 batchs: 673.273681640625
INFO:root:Train (Epoch 193): Loss/seq after 01050 batchs: 659.3789672851562
INFO:root:Train (Epoch 193): Loss/seq after 01100 batchs: 647.0252685546875
INFO:root:Train (Epoch 193): Loss/seq after 01150 batchs: 631.43212890625
INFO:root:Train (Epoch 193): Loss/seq after 01200 batchs: 633.9794311523438
INFO:root:Train (Epoch 193): Loss/seq after 01250 batchs: 630.9796752929688
INFO:root:Train (Epoch 193): Loss/seq after 01300 batchs: 621.0172119140625
INFO:root:Train (Epoch 193): Loss/seq after 01350 batchs: 612.9197387695312
INFO:root:Train (Epoch 193): Loss/seq after 01400 batchs: 618.4378051757812
INFO:root:Train (Epoch 193): Loss/seq after 01450 batchs: 618.8353271484375
INFO:root:Train (Epoch 193): Loss/seq after 01500 batchs: 623.746826171875
INFO:root:Train (Epoch 193): Loss/seq after 01550 batchs: 625.0608520507812
INFO:root:Train (Epoch 193): Loss/seq after 01600 batchs: 618.653076171875
INFO:root:Train (Epoch 193): Loss/seq after 01650 batchs: 614.4942626953125
INFO:root:Train (Epoch 193): Loss/seq after 01700 batchs: 615.83740234375
INFO:root:Train (Epoch 193): Loss/seq after 01750 batchs: 612.4369506835938
INFO:root:Train (Epoch 193): Loss/seq after 01800 batchs: 608.979736328125
INFO:root:Train (Epoch 193): Loss/seq after 01850 batchs: 604.0859375
INFO:root:Train (Epoch 193): Loss/seq after 01900 batchs: 603.2492065429688
INFO:root:Train (Epoch 193): Loss/seq after 01950 batchs: 601.0964965820312
INFO:root:Train (Epoch 193): Loss/seq after 02000 batchs: 599.20751953125
INFO:root:Train (Epoch 193): Loss/seq after 02050 batchs: 596.8239135742188
INFO:root:Train (Epoch 193): Loss/seq after 02100 batchs: 593.1962890625
INFO:root:Train (Epoch 193): Loss/seq after 02150 batchs: 590.3446655273438
INFO:root:Train (Epoch 193): Loss/seq after 02200 batchs: 586.737060546875
INFO:root:Train (Epoch 193): Loss/seq after 02250 batchs: 585.59130859375
INFO:root:Train (Epoch 193): Loss/seq after 02300 batchs: 584.1200561523438
INFO:root:Train (Epoch 193): Loss/seq after 02350 batchs: 578.941650390625
INFO:root:Train (Epoch 193): Loss/seq after 02400 batchs: 580.16259765625
INFO:root:Train (Epoch 193): Loss/seq after 02450 batchs: 575.09765625
INFO:root:Train (Epoch 193): Loss/seq after 02500 batchs: 566.5198364257812
INFO:root:Train (Epoch 193): Loss/seq after 02550 batchs: 560.1665649414062
INFO:root:Train (Epoch 193): Loss/seq after 02600 batchs: 558.8480224609375
INFO:root:Train (Epoch 193): Loss/seq after 02650 batchs: 556.0426025390625
INFO:root:Train (Epoch 193): Loss/seq after 02700 batchs: 554.1925659179688
INFO:root:Train (Epoch 193): Loss/seq after 02750 batchs: 552.0616455078125
INFO:root:Train (Epoch 193): Loss/seq after 02800 batchs: 552.1632690429688
INFO:root:Train (Epoch 193): Loss/seq after 02850 batchs: 551.7559814453125
INFO:root:Train (Epoch 193): Loss/seq after 02900 batchs: 552.9616088867188
INFO:root:Train (Epoch 193): Loss/seq after 02950 batchs: 551.9060668945312
INFO:root:Train (Epoch 193): Loss/seq after 03000 batchs: 556.2930297851562
INFO:root:Train (Epoch 193): Loss/seq after 03050 batchs: 558.8226318359375
INFO:root:Train (Epoch 193): Loss/seq after 03100 batchs: 562.1502685546875
INFO:root:Train (Epoch 193): Loss/seq after 03150 batchs: 569.010986328125
INFO:root:Train (Epoch 193): Loss/seq after 03200 batchs: 571.4253540039062
INFO:root:Train (Epoch 193): Loss/seq after 03250 batchs: 574.5364990234375
INFO:root:Train (Epoch 193): Loss/seq after 03300 batchs: 574.0523071289062
INFO:root:Train (Epoch 193): Loss/seq after 03350 batchs: 573.8623657226562
INFO:root:Train (Epoch 193): Loss/seq after 03400 batchs: 569.8040161132812
INFO:root:Train (Epoch 193): Loss/seq after 03450 batchs: 567.827392578125
INFO:root:Train (Epoch 193): Loss/seq after 03500 batchs: 567.8765869140625
INFO:root:Train (Epoch 193): Loss/seq after 03550 batchs: 564.9266967773438
INFO:root:Train (Epoch 193): Loss/seq after 03600 batchs: 572.8390502929688
INFO:root:Train (Epoch 193): Loss/seq after 03650 batchs: 570.2205200195312
INFO:root:Train (Epoch 193): Loss/seq after 03700 batchs: 572.1498413085938
INFO:root:Train (Epoch 193): Loss/seq after 03750 batchs: 576.1748046875
INFO:root:Train (Epoch 193): Loss/seq after 03800 batchs: 573.514892578125
INFO:root:Train (Epoch 193): Loss/seq after 03850 batchs: 572.3038330078125
INFO:root:Train (Epoch 193): Loss/seq after 03900 batchs: 576.31787109375
INFO:root:Train (Epoch 193): Loss/seq after 03950 batchs: 579.63818359375
INFO:root:Train (Epoch 193): Loss/seq after 04000 batchs: 575.6131591796875
INFO:root:Train (Epoch 193): Loss/seq after 04050 batchs: 571.8627319335938
INFO:root:Train (Epoch 193): Loss/seq after 04100 batchs: 570.010009765625
INFO:root:Train (Epoch 193): Loss/seq after 04150 batchs: 569.631103515625
INFO:root:Train (Epoch 193): Loss/seq after 04200 batchs: 567.4993286132812
INFO:root:Train (Epoch 193): Loss/seq after 04250 batchs: 565.5733642578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 193): Loss/seq after 00000 batches: 556.0509643554688
INFO:root:# Valid (Epoch 193): Loss/seq after 00050 batches: 696.4644775390625
INFO:root:# Valid (Epoch 193): Loss/seq after 00100 batches: 740.5379638671875
INFO:root:# Valid (Epoch 193): Loss/seq after 00150 batches: 559.2506103515625
INFO:root:# Valid (Epoch 193): Loss/seq after 00200 batches: 520.7861938476562
INFO:root:Artifacts: Make stick videos for epoch 193
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_193_on_20220423_121956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_193_index_1896_on_20220423_121956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 194): Loss/seq after 00000 batchs: 1169.705078125
INFO:root:Train (Epoch 194): Loss/seq after 00050 batchs: 829.8500366210938
INFO:root:Train (Epoch 194): Loss/seq after 00100 batchs: 828.67822265625
INFO:root:Train (Epoch 194): Loss/seq after 00150 batchs: 720.6408081054688
INFO:root:Train (Epoch 194): Loss/seq after 00200 batchs: 809.1798706054688
INFO:root:Train (Epoch 194): Loss/seq after 00250 batchs: 875.657958984375
INFO:root:Train (Epoch 194): Loss/seq after 00300 batchs: 873.8598022460938
INFO:root:Train (Epoch 194): Loss/seq after 00350 batchs: 817.6964721679688
INFO:root:Train (Epoch 194): Loss/seq after 00400 batchs: 825.246826171875
INFO:root:Train (Epoch 194): Loss/seq after 00450 batchs: 806.6376953125
INFO:root:Train (Epoch 194): Loss/seq after 00500 batchs: 786.3150634765625
INFO:root:Train (Epoch 194): Loss/seq after 00550 batchs: 762.0064697265625
INFO:root:Train (Epoch 194): Loss/seq after 00600 batchs: 735.3876953125
INFO:root:Train (Epoch 194): Loss/seq after 00650 batchs: 725.76416015625
INFO:root:Train (Epoch 194): Loss/seq after 00700 batchs: 702.2706298828125
INFO:root:Train (Epoch 194): Loss/seq after 00750 batchs: 712.7846069335938
INFO:root:Train (Epoch 194): Loss/seq after 00800 batchs: 711.145263671875
INFO:root:Train (Epoch 194): Loss/seq after 00850 batchs: 688.7552490234375
INFO:root:Train (Epoch 194): Loss/seq after 00900 batchs: 670.3034057617188
INFO:root:Train (Epoch 194): Loss/seq after 00950 batchs: 673.0833740234375
INFO:root:Train (Epoch 194): Loss/seq after 01000 batchs: 664.9730224609375
INFO:root:Train (Epoch 194): Loss/seq after 01050 batchs: 652.0733032226562
INFO:root:Train (Epoch 194): Loss/seq after 01100 batchs: 640.01416015625
INFO:root:Train (Epoch 194): Loss/seq after 01150 batchs: 625.0869750976562
INFO:root:Train (Epoch 194): Loss/seq after 01200 batchs: 628.1326904296875
INFO:root:Train (Epoch 194): Loss/seq after 01250 batchs: 624.6710815429688
INFO:root:Train (Epoch 194): Loss/seq after 01300 batchs: 614.5043334960938
INFO:root:Train (Epoch 194): Loss/seq after 01350 batchs: 605.5457763671875
INFO:root:Train (Epoch 194): Loss/seq after 01400 batchs: 609.7840576171875
INFO:root:Train (Epoch 194): Loss/seq after 01450 batchs: 610.72265625
INFO:root:Train (Epoch 194): Loss/seq after 01500 batchs: 616.0618286132812
INFO:root:Train (Epoch 194): Loss/seq after 01550 batchs: 617.9342041015625
INFO:root:Train (Epoch 194): Loss/seq after 01600 batchs: 611.5821533203125
INFO:root:Train (Epoch 194): Loss/seq after 01650 batchs: 607.8589477539062
INFO:root:Train (Epoch 194): Loss/seq after 01700 batchs: 609.2205200195312
INFO:root:Train (Epoch 194): Loss/seq after 01750 batchs: 606.0230102539062
INFO:root:Train (Epoch 194): Loss/seq after 01800 batchs: 602.8032836914062
INFO:root:Train (Epoch 194): Loss/seq after 01850 batchs: 598.28857421875
INFO:root:Train (Epoch 194): Loss/seq after 01900 batchs: 597.3345336914062
INFO:root:Train (Epoch 194): Loss/seq after 01950 batchs: 595.6021728515625
INFO:root:Train (Epoch 194): Loss/seq after 02000 batchs: 593.9200439453125
INFO:root:Train (Epoch 194): Loss/seq after 02050 batchs: 591.601806640625
INFO:root:Train (Epoch 194): Loss/seq after 02100 batchs: 588.3331298828125
INFO:root:Train (Epoch 194): Loss/seq after 02150 batchs: 585.5733032226562
INFO:root:Train (Epoch 194): Loss/seq after 02200 batchs: 582.0287475585938
INFO:root:Train (Epoch 194): Loss/seq after 02250 batchs: 580.5042114257812
INFO:root:Train (Epoch 194): Loss/seq after 02300 batchs: 579.1150512695312
INFO:root:Train (Epoch 194): Loss/seq after 02350 batchs: 574.0060424804688
INFO:root:Train (Epoch 194): Loss/seq after 02400 batchs: 575.0699462890625
INFO:root:Train (Epoch 194): Loss/seq after 02450 batchs: 569.9783935546875
INFO:root:Train (Epoch 194): Loss/seq after 02500 batchs: 561.50439453125
INFO:root:Train (Epoch 194): Loss/seq after 02550 batchs: 555.0781860351562
INFO:root:Train (Epoch 194): Loss/seq after 02600 batchs: 553.4134521484375
INFO:root:Train (Epoch 194): Loss/seq after 02650 batchs: 550.60302734375
INFO:root:Train (Epoch 194): Loss/seq after 02700 batchs: 548.589599609375
INFO:root:Train (Epoch 194): Loss/seq after 02750 batchs: 546.3255004882812
INFO:root:Train (Epoch 194): Loss/seq after 02800 batchs: 546.4330444335938
INFO:root:Train (Epoch 194): Loss/seq after 02850 batchs: 546.1884765625
INFO:root:Train (Epoch 194): Loss/seq after 02900 batchs: 547.86474609375
INFO:root:Train (Epoch 194): Loss/seq after 02950 batchs: 546.7138061523438
INFO:root:Train (Epoch 194): Loss/seq after 03000 batchs: 551.3369750976562
INFO:root:Train (Epoch 194): Loss/seq after 03050 batchs: 553.425537109375
INFO:root:Train (Epoch 194): Loss/seq after 03100 batchs: 557.0421142578125
INFO:root:Train (Epoch 194): Loss/seq after 03150 batchs: 563.7056274414062
INFO:root:Train (Epoch 194): Loss/seq after 03200 batchs: 565.8888549804688
INFO:root:Train (Epoch 194): Loss/seq after 03250 batchs: 570.093505859375
INFO:root:Train (Epoch 194): Loss/seq after 03300 batchs: 569.1597900390625
INFO:root:Train (Epoch 194): Loss/seq after 03350 batchs: 568.896240234375
INFO:root:Train (Epoch 194): Loss/seq after 03400 batchs: 564.878662109375
INFO:root:Train (Epoch 194): Loss/seq after 03450 batchs: 563.1067504882812
INFO:root:Train (Epoch 194): Loss/seq after 03500 batchs: 563.2274169921875
INFO:root:Train (Epoch 194): Loss/seq after 03550 batchs: 560.3223876953125
INFO:root:Train (Epoch 194): Loss/seq after 03600 batchs: 568.7234497070312
INFO:root:Train (Epoch 194): Loss/seq after 03650 batchs: 566.1380615234375
INFO:root:Train (Epoch 194): Loss/seq after 03700 batchs: 568.0979614257812
INFO:root:Train (Epoch 194): Loss/seq after 03750 batchs: 572.1497192382812
INFO:root:Train (Epoch 194): Loss/seq after 03800 batchs: 569.6201171875
INFO:root:Train (Epoch 194): Loss/seq after 03850 batchs: 568.252197265625
INFO:root:Train (Epoch 194): Loss/seq after 03900 batchs: 572.148193359375
INFO:root:Train (Epoch 194): Loss/seq after 03950 batchs: 576.0311279296875
INFO:root:Train (Epoch 194): Loss/seq after 04000 batchs: 572.0001220703125
INFO:root:Train (Epoch 194): Loss/seq after 04050 batchs: 568.3045654296875
INFO:root:Train (Epoch 194): Loss/seq after 04100 batchs: 566.464111328125
INFO:root:Train (Epoch 194): Loss/seq after 04150 batchs: 566.0844116210938
INFO:root:Train (Epoch 194): Loss/seq after 04200 batchs: 563.8721313476562
INFO:root:Train (Epoch 194): Loss/seq after 04250 batchs: 561.8027954101562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 194): Loss/seq after 00000 batches: 572.50830078125
INFO:root:# Valid (Epoch 194): Loss/seq after 00050 batches: 664.1774291992188
INFO:root:# Valid (Epoch 194): Loss/seq after 00100 batches: 725.5811157226562
INFO:root:# Valid (Epoch 194): Loss/seq after 00150 batches: 547.106201171875
INFO:root:# Valid (Epoch 194): Loss/seq after 00200 batches: 505.4363708496094
INFO:root:Artifacts: Make stick videos for epoch 194
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_194_on_20220423_122448.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_194_index_360_on_20220423_122448.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 195): Loss/seq after 00000 batchs: 1307.3876953125
INFO:root:Train (Epoch 195): Loss/seq after 00050 batchs: 834.210205078125
INFO:root:Train (Epoch 195): Loss/seq after 00100 batchs: 818.6475219726562
INFO:root:Train (Epoch 195): Loss/seq after 00150 batchs: 714.5997924804688
INFO:root:Train (Epoch 195): Loss/seq after 00200 batchs: 800.8486938476562
INFO:root:Train (Epoch 195): Loss/seq after 00250 batchs: 876.0485229492188
INFO:root:Train (Epoch 195): Loss/seq after 00300 batchs: 874.0340576171875
INFO:root:Train (Epoch 195): Loss/seq after 00350 batchs: 818.0106201171875
INFO:root:Train (Epoch 195): Loss/seq after 00400 batchs: 831.5562744140625
INFO:root:Train (Epoch 195): Loss/seq after 00450 batchs: 812.20751953125
INFO:root:Train (Epoch 195): Loss/seq after 00500 batchs: 787.3170166015625
INFO:root:Train (Epoch 195): Loss/seq after 00550 batchs: 761.6624755859375
INFO:root:Train (Epoch 195): Loss/seq after 00600 batchs: 734.3701171875
INFO:root:Train (Epoch 195): Loss/seq after 00650 batchs: 724.5421142578125
INFO:root:Train (Epoch 195): Loss/seq after 00700 batchs: 700.1927490234375
INFO:root:Train (Epoch 195): Loss/seq after 00750 batchs: 712.7520751953125
INFO:root:Train (Epoch 195): Loss/seq after 00800 batchs: 710.2444458007812
INFO:root:Train (Epoch 195): Loss/seq after 00850 batchs: 687.31787109375
INFO:root:Train (Epoch 195): Loss/seq after 00900 batchs: 669.0575561523438
INFO:root:Train (Epoch 195): Loss/seq after 00950 batchs: 671.6262817382812
INFO:root:Train (Epoch 195): Loss/seq after 01000 batchs: 663.47802734375
INFO:root:Train (Epoch 195): Loss/seq after 01050 batchs: 650.38525390625
INFO:root:Train (Epoch 195): Loss/seq after 01100 batchs: 638.863037109375
INFO:root:Train (Epoch 195): Loss/seq after 01150 batchs: 623.3692016601562
INFO:root:Train (Epoch 195): Loss/seq after 01200 batchs: 626.3289794921875
INFO:root:Train (Epoch 195): Loss/seq after 01250 batchs: 623.1485595703125
INFO:root:Train (Epoch 195): Loss/seq after 01300 batchs: 612.9228515625
INFO:root:Train (Epoch 195): Loss/seq after 01350 batchs: 604.6491088867188
INFO:root:Train (Epoch 195): Loss/seq after 01400 batchs: 609.5330200195312
INFO:root:Train (Epoch 195): Loss/seq after 01450 batchs: 610.2589721679688
INFO:root:Train (Epoch 195): Loss/seq after 01500 batchs: 615.4617309570312
INFO:root:Train (Epoch 195): Loss/seq after 01550 batchs: 617.032470703125
INFO:root:Train (Epoch 195): Loss/seq after 01600 batchs: 610.89111328125
INFO:root:Train (Epoch 195): Loss/seq after 01650 batchs: 606.9161376953125
INFO:root:Train (Epoch 195): Loss/seq after 01700 batchs: 608.3703002929688
INFO:root:Train (Epoch 195): Loss/seq after 01750 batchs: 605.1087036132812
INFO:root:Train (Epoch 195): Loss/seq after 01800 batchs: 601.903564453125
INFO:root:Train (Epoch 195): Loss/seq after 01850 batchs: 597.1351318359375
INFO:root:Train (Epoch 195): Loss/seq after 01900 batchs: 596.4822998046875
INFO:root:Train (Epoch 195): Loss/seq after 01950 batchs: 594.41064453125
INFO:root:Train (Epoch 195): Loss/seq after 02000 batchs: 592.5389404296875
INFO:root:Train (Epoch 195): Loss/seq after 02050 batchs: 590.2348022460938
INFO:root:Train (Epoch 195): Loss/seq after 02100 batchs: 586.7582397460938
INFO:root:Train (Epoch 195): Loss/seq after 02150 batchs: 584.0684204101562
INFO:root:Train (Epoch 195): Loss/seq after 02200 batchs: 580.626953125
INFO:root:Train (Epoch 195): Loss/seq after 02250 batchs: 578.987548828125
INFO:root:Train (Epoch 195): Loss/seq after 02300 batchs: 577.8794555664062
INFO:root:Train (Epoch 195): Loss/seq after 02350 batchs: 572.9385375976562
INFO:root:Train (Epoch 195): Loss/seq after 02400 batchs: 574.101318359375
INFO:root:Train (Epoch 195): Loss/seq after 02450 batchs: 569.0421752929688
INFO:root:Train (Epoch 195): Loss/seq after 02500 batchs: 560.5676879882812
INFO:root:Train (Epoch 195): Loss/seq after 02550 batchs: 554.2235107421875
INFO:root:Train (Epoch 195): Loss/seq after 02600 batchs: 552.6112670898438
INFO:root:Train (Epoch 195): Loss/seq after 02650 batchs: 549.6690673828125
INFO:root:Train (Epoch 195): Loss/seq after 02700 batchs: 547.534423828125
INFO:root:Train (Epoch 195): Loss/seq after 02750 batchs: 544.8570556640625
INFO:root:Train (Epoch 195): Loss/seq after 02800 batchs: 544.8446655273438
INFO:root:Train (Epoch 195): Loss/seq after 02850 batchs: 544.3292236328125
INFO:root:Train (Epoch 195): Loss/seq after 02900 batchs: 545.6458740234375
INFO:root:Train (Epoch 195): Loss/seq after 02950 batchs: 544.6736450195312
INFO:root:Train (Epoch 195): Loss/seq after 03000 batchs: 549.3269653320312
INFO:root:Train (Epoch 195): Loss/seq after 03050 batchs: 551.3140258789062
INFO:root:Train (Epoch 195): Loss/seq after 03100 batchs: 554.712158203125
INFO:root:Train (Epoch 195): Loss/seq after 03150 batchs: 561.1534423828125
INFO:root:Train (Epoch 195): Loss/seq after 03200 batchs: 562.9821166992188
INFO:root:Train (Epoch 195): Loss/seq after 03250 batchs: 566.1107788085938
INFO:root:Train (Epoch 195): Loss/seq after 03300 batchs: 565.0470581054688
INFO:root:Train (Epoch 195): Loss/seq after 03350 batchs: 564.7899169921875
INFO:root:Train (Epoch 195): Loss/seq after 03400 batchs: 560.8442993164062
INFO:root:Train (Epoch 195): Loss/seq after 03450 batchs: 558.9954223632812
INFO:root:Train (Epoch 195): Loss/seq after 03500 batchs: 559.0408935546875
INFO:root:Train (Epoch 195): Loss/seq after 03550 batchs: 556.2092895507812
INFO:root:Train (Epoch 195): Loss/seq after 03600 batchs: 564.1747436523438
INFO:root:Train (Epoch 195): Loss/seq after 03650 batchs: 561.7918090820312
INFO:root:Train (Epoch 195): Loss/seq after 03700 batchs: 563.7733154296875
INFO:root:Train (Epoch 195): Loss/seq after 03750 batchs: 567.8887939453125
INFO:root:Train (Epoch 195): Loss/seq after 03800 batchs: 565.4020385742188
INFO:root:Train (Epoch 195): Loss/seq after 03850 batchs: 564.134521484375
INFO:root:Train (Epoch 195): Loss/seq after 03900 batchs: 567.8917236328125
INFO:root:Train (Epoch 195): Loss/seq after 03950 batchs: 571.1798095703125
INFO:root:Train (Epoch 195): Loss/seq after 04000 batchs: 567.1882934570312
INFO:root:Train (Epoch 195): Loss/seq after 04050 batchs: 563.506591796875
INFO:root:Train (Epoch 195): Loss/seq after 04100 batchs: 561.7813110351562
INFO:root:Train (Epoch 195): Loss/seq after 04150 batchs: 561.3185424804688
INFO:root:Train (Epoch 195): Loss/seq after 04200 batchs: 559.3458251953125
INFO:root:Train (Epoch 195): Loss/seq after 04250 batchs: 557.4886474609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 195): Loss/seq after 00000 batches: 578.3302612304688
INFO:root:# Valid (Epoch 195): Loss/seq after 00050 batches: 681.4767456054688
INFO:root:# Valid (Epoch 195): Loss/seq after 00100 batches: 730.6419067382812
INFO:root:# Valid (Epoch 195): Loss/seq after 00150 batches: 553.443359375
INFO:root:# Valid (Epoch 195): Loss/seq after 00200 batches: 509.8561096191406
INFO:root:Artifacts: Make stick videos for epoch 195
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_195_on_20220423_122932.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_195_index_1322_on_20220423_122932.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 196): Loss/seq after 00000 batchs: 1235.813232421875
INFO:root:Train (Epoch 196): Loss/seq after 00050 batchs: 827.9403686523438
INFO:root:Train (Epoch 196): Loss/seq after 00100 batchs: 822.094970703125
INFO:root:Train (Epoch 196): Loss/seq after 00150 batchs: 712.7376708984375
INFO:root:Train (Epoch 196): Loss/seq after 00200 batchs: 802.4102172851562
INFO:root:Train (Epoch 196): Loss/seq after 00250 batchs: 875.9918823242188
INFO:root:Train (Epoch 196): Loss/seq after 00300 batchs: 873.9861450195312
INFO:root:Train (Epoch 196): Loss/seq after 00350 batchs: 819.120361328125
INFO:root:Train (Epoch 196): Loss/seq after 00400 batchs: 824.1917114257812
INFO:root:Train (Epoch 196): Loss/seq after 00450 batchs: 805.2601318359375
INFO:root:Train (Epoch 196): Loss/seq after 00500 batchs: 780.1195068359375
INFO:root:Train (Epoch 196): Loss/seq after 00550 batchs: 755.030517578125
INFO:root:Train (Epoch 196): Loss/seq after 00600 batchs: 727.9003295898438
INFO:root:Train (Epoch 196): Loss/seq after 00650 batchs: 714.603759765625
INFO:root:Train (Epoch 196): Loss/seq after 00700 batchs: 693.3569946289062
INFO:root:Train (Epoch 196): Loss/seq after 00750 batchs: 704.8855590820312
INFO:root:Train (Epoch 196): Loss/seq after 00800 batchs: 702.77099609375
INFO:root:Train (Epoch 196): Loss/seq after 00850 batchs: 680.0441284179688
INFO:root:Train (Epoch 196): Loss/seq after 00900 batchs: 661.4226684570312
INFO:root:Train (Epoch 196): Loss/seq after 00950 batchs: 665.1486206054688
INFO:root:Train (Epoch 196): Loss/seq after 01000 batchs: 657.369384765625
INFO:root:Train (Epoch 196): Loss/seq after 01050 batchs: 645.2476806640625
INFO:root:Train (Epoch 196): Loss/seq after 01100 batchs: 633.8822631835938
INFO:root:Train (Epoch 196): Loss/seq after 01150 batchs: 618.7242431640625
INFO:root:Train (Epoch 196): Loss/seq after 01200 batchs: 622.1555786132812
INFO:root:Train (Epoch 196): Loss/seq after 01250 batchs: 619.0073852539062
INFO:root:Train (Epoch 196): Loss/seq after 01300 batchs: 607.9312744140625
INFO:root:Train (Epoch 196): Loss/seq after 01350 batchs: 599.2660522460938
INFO:root:Train (Epoch 196): Loss/seq after 01400 batchs: 603.553955078125
INFO:root:Train (Epoch 196): Loss/seq after 01450 batchs: 604.419189453125
INFO:root:Train (Epoch 196): Loss/seq after 01500 batchs: 609.8305053710938
INFO:root:Train (Epoch 196): Loss/seq after 01550 batchs: 611.1527099609375
INFO:root:Train (Epoch 196): Loss/seq after 01600 batchs: 604.9652709960938
INFO:root:Train (Epoch 196): Loss/seq after 01650 batchs: 601.1951293945312
INFO:root:Train (Epoch 196): Loss/seq after 01700 batchs: 602.6419067382812
INFO:root:Train (Epoch 196): Loss/seq after 01750 batchs: 599.4425048828125
INFO:root:Train (Epoch 196): Loss/seq after 01800 batchs: 596.180419921875
INFO:root:Train (Epoch 196): Loss/seq after 01850 batchs: 591.6246948242188
INFO:root:Train (Epoch 196): Loss/seq after 01900 batchs: 591.1116333007812
INFO:root:Train (Epoch 196): Loss/seq after 01950 batchs: 589.0209350585938
INFO:root:Train (Epoch 196): Loss/seq after 02000 batchs: 587.3353271484375
INFO:root:Train (Epoch 196): Loss/seq after 02050 batchs: 585.0927734375
INFO:root:Train (Epoch 196): Loss/seq after 02100 batchs: 581.81298828125
INFO:root:Train (Epoch 196): Loss/seq after 02150 batchs: 579.2190551757812
INFO:root:Train (Epoch 196): Loss/seq after 02200 batchs: 575.8856811523438
INFO:root:Train (Epoch 196): Loss/seq after 02250 batchs: 574.497314453125
INFO:root:Train (Epoch 196): Loss/seq after 02300 batchs: 575.0338134765625
INFO:root:Train (Epoch 196): Loss/seq after 02350 batchs: 570.2255249023438
INFO:root:Train (Epoch 196): Loss/seq after 02400 batchs: 571.5458984375
INFO:root:Train (Epoch 196): Loss/seq after 02450 batchs: 566.5005493164062
INFO:root:Train (Epoch 196): Loss/seq after 02500 batchs: 558.0506591796875
INFO:root:Train (Epoch 196): Loss/seq after 02550 batchs: 551.8184204101562
INFO:root:Train (Epoch 196): Loss/seq after 02600 batchs: 550.33935546875
INFO:root:Train (Epoch 196): Loss/seq after 02650 batchs: 547.4013061523438
INFO:root:Train (Epoch 196): Loss/seq after 02700 batchs: 545.3816528320312
INFO:root:Train (Epoch 196): Loss/seq after 02750 batchs: 542.52783203125
INFO:root:Train (Epoch 196): Loss/seq after 02800 batchs: 542.8517456054688
INFO:root:Train (Epoch 196): Loss/seq after 02850 batchs: 542.5399169921875
INFO:root:Train (Epoch 196): Loss/seq after 02900 batchs: 543.8425903320312
INFO:root:Train (Epoch 196): Loss/seq after 02950 batchs: 542.8502807617188
INFO:root:Train (Epoch 196): Loss/seq after 03000 batchs: 547.5267333984375
INFO:root:Train (Epoch 196): Loss/seq after 03050 batchs: 549.4906005859375
INFO:root:Train (Epoch 196): Loss/seq after 03100 batchs: 552.2109375
INFO:root:Train (Epoch 196): Loss/seq after 03150 batchs: 557.7266845703125
INFO:root:Train (Epoch 196): Loss/seq after 03200 batchs: 560.1680297851562
INFO:root:Train (Epoch 196): Loss/seq after 03250 batchs: 563.7371215820312
INFO:root:Train (Epoch 196): Loss/seq after 03300 batchs: 562.81201171875
INFO:root:Train (Epoch 196): Loss/seq after 03350 batchs: 562.3726806640625
INFO:root:Train (Epoch 196): Loss/seq after 03400 batchs: 558.38818359375
INFO:root:Train (Epoch 196): Loss/seq after 03450 batchs: 556.6852416992188
INFO:root:Train (Epoch 196): Loss/seq after 03500 batchs: 556.7354125976562
INFO:root:Train (Epoch 196): Loss/seq after 03550 batchs: 553.9170532226562
INFO:root:Train (Epoch 196): Loss/seq after 03600 batchs: 561.64892578125
INFO:root:Train (Epoch 196): Loss/seq after 03650 batchs: 559.169189453125
INFO:root:Train (Epoch 196): Loss/seq after 03700 batchs: 561.1923828125
INFO:root:Train (Epoch 196): Loss/seq after 03750 batchs: 565.2957153320312
INFO:root:Train (Epoch 196): Loss/seq after 03800 batchs: 562.7951049804688
INFO:root:Train (Epoch 196): Loss/seq after 03850 batchs: 561.5656127929688
INFO:root:Train (Epoch 196): Loss/seq after 03900 batchs: 565.24365234375
INFO:root:Train (Epoch 196): Loss/seq after 03950 batchs: 569.09814453125
INFO:root:Train (Epoch 196): Loss/seq after 04000 batchs: 565.1117553710938
INFO:root:Train (Epoch 196): Loss/seq after 04050 batchs: 561.4139404296875
INFO:root:Train (Epoch 196): Loss/seq after 04100 batchs: 559.6038818359375
INFO:root:Train (Epoch 196): Loss/seq after 04150 batchs: 559.1901245117188
INFO:root:Train (Epoch 196): Loss/seq after 04200 batchs: 557.1098022460938
INFO:root:Train (Epoch 196): Loss/seq after 04250 batchs: 555.2625122070312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 196): Loss/seq after 00000 batches: 559.9938354492188
INFO:root:# Valid (Epoch 196): Loss/seq after 00050 batches: 699.4608154296875
INFO:root:# Valid (Epoch 196): Loss/seq after 00100 batches: 712.9154663085938
INFO:root:# Valid (Epoch 196): Loss/seq after 00150 batches: 541.062744140625
INFO:root:# Valid (Epoch 196): Loss/seq after 00200 batches: 499.4497985839844
INFO:root:Artifacts: Make stick videos for epoch 196
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_196_on_20220423_123423.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_196_index_935_on_20220423_123423.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 197): Loss/seq after 00000 batchs: 1332.499755859375
INFO:root:Train (Epoch 197): Loss/seq after 00050 batchs: 841.9730834960938
INFO:root:Train (Epoch 197): Loss/seq after 00100 batchs: 836.0596923828125
INFO:root:Train (Epoch 197): Loss/seq after 00150 batchs: 725.6644287109375
INFO:root:Train (Epoch 197): Loss/seq after 00200 batchs: 806.6799926757812
INFO:root:Train (Epoch 197): Loss/seq after 00250 batchs: 868.41796875
INFO:root:Train (Epoch 197): Loss/seq after 00300 batchs: 865.7907104492188
INFO:root:Train (Epoch 197): Loss/seq after 00350 batchs: 811.0244750976562
INFO:root:Train (Epoch 197): Loss/seq after 00400 batchs: 815.1686401367188
INFO:root:Train (Epoch 197): Loss/seq after 00450 batchs: 797.549560546875
INFO:root:Train (Epoch 197): Loss/seq after 00500 batchs: 775.68017578125
INFO:root:Train (Epoch 197): Loss/seq after 00550 batchs: 751.3191528320312
INFO:root:Train (Epoch 197): Loss/seq after 00600 batchs: 724.2874145507812
INFO:root:Train (Epoch 197): Loss/seq after 00650 batchs: 713.8062133789062
INFO:root:Train (Epoch 197): Loss/seq after 00700 batchs: 690.7017822265625
INFO:root:Train (Epoch 197): Loss/seq after 00750 batchs: 701.5040283203125
INFO:root:Train (Epoch 197): Loss/seq after 00800 batchs: 699.7012939453125
INFO:root:Train (Epoch 197): Loss/seq after 00850 batchs: 677.4296875
INFO:root:Train (Epoch 197): Loss/seq after 00900 batchs: 659.1614990234375
INFO:root:Train (Epoch 197): Loss/seq after 00950 batchs: 663.8515014648438
INFO:root:Train (Epoch 197): Loss/seq after 01000 batchs: 655.7409057617188
INFO:root:Train (Epoch 197): Loss/seq after 01050 batchs: 643.1143188476562
INFO:root:Train (Epoch 197): Loss/seq after 01100 batchs: 632.161865234375
INFO:root:Train (Epoch 197): Loss/seq after 01150 batchs: 616.860107421875
INFO:root:Train (Epoch 197): Loss/seq after 01200 batchs: 619.8529052734375
INFO:root:Train (Epoch 197): Loss/seq after 01250 batchs: 616.3972778320312
INFO:root:Train (Epoch 197): Loss/seq after 01300 batchs: 606.20556640625
INFO:root:Train (Epoch 197): Loss/seq after 01350 batchs: 597.2848510742188
INFO:root:Train (Epoch 197): Loss/seq after 01400 batchs: 602.537353515625
INFO:root:Train (Epoch 197): Loss/seq after 01450 batchs: 603.0989990234375
INFO:root:Train (Epoch 197): Loss/seq after 01500 batchs: 608.576416015625
INFO:root:Train (Epoch 197): Loss/seq after 01550 batchs: 609.7547607421875
INFO:root:Train (Epoch 197): Loss/seq after 01600 batchs: 603.551513671875
INFO:root:Train (Epoch 197): Loss/seq after 01650 batchs: 599.9638061523438
INFO:root:Train (Epoch 197): Loss/seq after 01700 batchs: 601.5986938476562
INFO:root:Train (Epoch 197): Loss/seq after 01750 batchs: 598.479248046875
INFO:root:Train (Epoch 197): Loss/seq after 01800 batchs: 595.532958984375
INFO:root:Train (Epoch 197): Loss/seq after 01850 batchs: 590.95458984375
INFO:root:Train (Epoch 197): Loss/seq after 01900 batchs: 590.13671875
INFO:root:Train (Epoch 197): Loss/seq after 01950 batchs: 588.18701171875
INFO:root:Train (Epoch 197): Loss/seq after 02000 batchs: 586.5350952148438
INFO:root:Train (Epoch 197): Loss/seq after 02050 batchs: 584.5291137695312
INFO:root:Train (Epoch 197): Loss/seq after 02100 batchs: 581.233154296875
INFO:root:Train (Epoch 197): Loss/seq after 02150 batchs: 578.443603515625
INFO:root:Train (Epoch 197): Loss/seq after 02200 batchs: 575.0497436523438
INFO:root:Train (Epoch 197): Loss/seq after 02250 batchs: 573.5164794921875
INFO:root:Train (Epoch 197): Loss/seq after 02300 batchs: 572.0479736328125
INFO:root:Train (Epoch 197): Loss/seq after 02350 batchs: 567.1514282226562
INFO:root:Train (Epoch 197): Loss/seq after 02400 batchs: 568.1768798828125
INFO:root:Train (Epoch 197): Loss/seq after 02450 batchs: 563.281494140625
INFO:root:Train (Epoch 197): Loss/seq after 02500 batchs: 554.9193725585938
INFO:root:Train (Epoch 197): Loss/seq after 02550 batchs: 548.659423828125
INFO:root:Train (Epoch 197): Loss/seq after 02600 batchs: 546.901611328125
INFO:root:Train (Epoch 197): Loss/seq after 02650 batchs: 543.8162841796875
INFO:root:Train (Epoch 197): Loss/seq after 02700 batchs: 541.9065551757812
INFO:root:Train (Epoch 197): Loss/seq after 02750 batchs: 539.1593017578125
INFO:root:Train (Epoch 197): Loss/seq after 02800 batchs: 539.7345581054688
INFO:root:Train (Epoch 197): Loss/seq after 02850 batchs: 539.42333984375
INFO:root:Train (Epoch 197): Loss/seq after 02900 batchs: 540.7467651367188
INFO:root:Train (Epoch 197): Loss/seq after 02950 batchs: 539.660400390625
INFO:root:Train (Epoch 197): Loss/seq after 03000 batchs: 544.1434936523438
INFO:root:Train (Epoch 197): Loss/seq after 03050 batchs: 545.98681640625
INFO:root:Train (Epoch 197): Loss/seq after 03100 batchs: 549.031005859375
INFO:root:Train (Epoch 197): Loss/seq after 03150 batchs: 554.8992309570312
INFO:root:Train (Epoch 197): Loss/seq after 03200 batchs: 556.7422485351562
INFO:root:Train (Epoch 197): Loss/seq after 03250 batchs: 559.251708984375
INFO:root:Train (Epoch 197): Loss/seq after 03300 batchs: 558.6036376953125
INFO:root:Train (Epoch 197): Loss/seq after 03350 batchs: 558.7194213867188
INFO:root:Train (Epoch 197): Loss/seq after 03400 batchs: 554.8402099609375
INFO:root:Train (Epoch 197): Loss/seq after 03450 batchs: 553.2369995117188
INFO:root:Train (Epoch 197): Loss/seq after 03500 batchs: 553.1386108398438
INFO:root:Train (Epoch 197): Loss/seq after 03550 batchs: 550.3885498046875
INFO:root:Train (Epoch 197): Loss/seq after 03600 batchs: 558.4149169921875
INFO:root:Train (Epoch 197): Loss/seq after 03650 batchs: 555.7891235351562
INFO:root:Train (Epoch 197): Loss/seq after 03700 batchs: 557.7010498046875
INFO:root:Train (Epoch 197): Loss/seq after 03750 batchs: 561.9872436523438
INFO:root:Train (Epoch 197): Loss/seq after 03800 batchs: 559.54931640625
INFO:root:Train (Epoch 197): Loss/seq after 03850 batchs: 558.515625
INFO:root:Train (Epoch 197): Loss/seq after 03900 batchs: 562.1549072265625
INFO:root:Train (Epoch 197): Loss/seq after 03950 batchs: 565.73974609375
INFO:root:Train (Epoch 197): Loss/seq after 04000 batchs: 561.7832641601562
INFO:root:Train (Epoch 197): Loss/seq after 04050 batchs: 558.2415771484375
INFO:root:Train (Epoch 197): Loss/seq after 04100 batchs: 556.5078125
INFO:root:Train (Epoch 197): Loss/seq after 04150 batchs: 556.1671142578125
INFO:root:Train (Epoch 197): Loss/seq after 04200 batchs: 554.19482421875
INFO:root:Train (Epoch 197): Loss/seq after 04250 batchs: 552.3138427734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 197): Loss/seq after 00000 batches: 453.63922119140625
INFO:root:# Valid (Epoch 197): Loss/seq after 00050 batches: 657.29248046875
INFO:root:# Valid (Epoch 197): Loss/seq after 00100 batches: 718.5210571289062
INFO:root:# Valid (Epoch 197): Loss/seq after 00150 batches: 543.6204833984375
INFO:root:# Valid (Epoch 197): Loss/seq after 00200 batches: 500.3335266113281
INFO:root:Artifacts: Make stick videos for epoch 197
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_197_on_20220423_123920.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_197_index_1136_on_20220423_123920.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 198): Loss/seq after 00000 batchs: 1324.2620849609375
INFO:root:Train (Epoch 198): Loss/seq after 00050 batchs: 805.4361572265625
INFO:root:Train (Epoch 198): Loss/seq after 00100 batchs: 800.0752563476562
INFO:root:Train (Epoch 198): Loss/seq after 00150 batchs: 700.6314697265625
INFO:root:Train (Epoch 198): Loss/seq after 00200 batchs: 783.0699462890625
INFO:root:Train (Epoch 198): Loss/seq after 00250 batchs: 856.1244506835938
INFO:root:Train (Epoch 198): Loss/seq after 00300 batchs: 856.2730712890625
INFO:root:Train (Epoch 198): Loss/seq after 00350 batchs: 802.852294921875
INFO:root:Train (Epoch 198): Loss/seq after 00400 batchs: 809.3990478515625
INFO:root:Train (Epoch 198): Loss/seq after 00450 batchs: 792.0747680664062
INFO:root:Train (Epoch 198): Loss/seq after 00500 batchs: 769.7550659179688
INFO:root:Train (Epoch 198): Loss/seq after 00550 batchs: 746.0582275390625
INFO:root:Train (Epoch 198): Loss/seq after 00600 batchs: 720.4247436523438
INFO:root:Train (Epoch 198): Loss/seq after 00650 batchs: 707.0807495117188
INFO:root:Train (Epoch 198): Loss/seq after 00700 batchs: 685.3030395507812
INFO:root:Train (Epoch 198): Loss/seq after 00750 batchs: 696.2661743164062
INFO:root:Train (Epoch 198): Loss/seq after 00800 batchs: 695.5089721679688
INFO:root:Train (Epoch 198): Loss/seq after 00850 batchs: 673.48779296875
INFO:root:Train (Epoch 198): Loss/seq after 00900 batchs: 655.6741333007812
INFO:root:Train (Epoch 198): Loss/seq after 00950 batchs: 656.2864990234375
INFO:root:Train (Epoch 198): Loss/seq after 01000 batchs: 647.7376708984375
INFO:root:Train (Epoch 198): Loss/seq after 01050 batchs: 634.947021484375
INFO:root:Train (Epoch 198): Loss/seq after 01100 batchs: 623.6463012695312
INFO:root:Train (Epoch 198): Loss/seq after 01150 batchs: 608.1260986328125
INFO:root:Train (Epoch 198): Loss/seq after 01200 batchs: 611.0248413085938
INFO:root:Train (Epoch 198): Loss/seq after 01250 batchs: 608.42578125
INFO:root:Train (Epoch 198): Loss/seq after 01300 batchs: 598.6250610351562
INFO:root:Train (Epoch 198): Loss/seq after 01350 batchs: 589.6810302734375
INFO:root:Train (Epoch 198): Loss/seq after 01400 batchs: 592.9173583984375
INFO:root:Train (Epoch 198): Loss/seq after 01450 batchs: 593.7703857421875
INFO:root:Train (Epoch 198): Loss/seq after 01500 batchs: 599.4907836914062
INFO:root:Train (Epoch 198): Loss/seq after 01550 batchs: 601.3987426757812
INFO:root:Train (Epoch 198): Loss/seq after 01600 batchs: 595.4256591796875
INFO:root:Train (Epoch 198): Loss/seq after 01650 batchs: 591.8216552734375
INFO:root:Train (Epoch 198): Loss/seq after 01700 batchs: 593.7509155273438
INFO:root:Train (Epoch 198): Loss/seq after 01750 batchs: 590.8915405273438
INFO:root:Train (Epoch 198): Loss/seq after 01800 batchs: 588.0484008789062
INFO:root:Train (Epoch 198): Loss/seq after 01850 batchs: 583.6200561523438
INFO:root:Train (Epoch 198): Loss/seq after 01900 batchs: 582.9288330078125
INFO:root:Train (Epoch 198): Loss/seq after 01950 batchs: 581.1288452148438
INFO:root:Train (Epoch 198): Loss/seq after 02000 batchs: 579.4436645507812
INFO:root:Train (Epoch 198): Loss/seq after 02050 batchs: 577.471435546875
INFO:root:Train (Epoch 198): Loss/seq after 02100 batchs: 574.26953125
INFO:root:Train (Epoch 198): Loss/seq after 02150 batchs: 571.9091796875
INFO:root:Train (Epoch 198): Loss/seq after 02200 batchs: 568.7678833007812
INFO:root:Train (Epoch 198): Loss/seq after 02250 batchs: 567.43359375
INFO:root:Train (Epoch 198): Loss/seq after 02300 batchs: 565.967529296875
INFO:root:Train (Epoch 198): Loss/seq after 02350 batchs: 561.2041015625
INFO:root:Train (Epoch 198): Loss/seq after 02400 batchs: 562.356689453125
INFO:root:Train (Epoch 198): Loss/seq after 02450 batchs: 557.4481811523438
INFO:root:Train (Epoch 198): Loss/seq after 02500 batchs: 549.187255859375
INFO:root:Train (Epoch 198): Loss/seq after 02550 batchs: 542.9360961914062
INFO:root:Train (Epoch 198): Loss/seq after 02600 batchs: 541.204833984375
INFO:root:Train (Epoch 198): Loss/seq after 02650 batchs: 538.1366577148438
INFO:root:Train (Epoch 198): Loss/seq after 02700 batchs: 536.1837768554688
INFO:root:Train (Epoch 198): Loss/seq after 02750 batchs: 533.5938720703125
INFO:root:Train (Epoch 198): Loss/seq after 02800 batchs: 535.09228515625
INFO:root:Train (Epoch 198): Loss/seq after 02850 batchs: 534.8434448242188
INFO:root:Train (Epoch 198): Loss/seq after 02900 batchs: 536.2066650390625
INFO:root:Train (Epoch 198): Loss/seq after 02950 batchs: 535.1150512695312
INFO:root:Train (Epoch 198): Loss/seq after 03000 batchs: 540.0153198242188
INFO:root:Train (Epoch 198): Loss/seq after 03050 batchs: 541.93994140625
INFO:root:Train (Epoch 198): Loss/seq after 03100 batchs: 544.9509887695312
INFO:root:Train (Epoch 198): Loss/seq after 03150 batchs: 550.796875
INFO:root:Train (Epoch 198): Loss/seq after 03200 batchs: 552.3663940429688
INFO:root:Train (Epoch 198): Loss/seq after 03250 batchs: 555.7320556640625
INFO:root:Train (Epoch 198): Loss/seq after 03300 batchs: 555.28955078125
INFO:root:Train (Epoch 198): Loss/seq after 03350 batchs: 555.14892578125
INFO:root:Train (Epoch 198): Loss/seq after 03400 batchs: 551.28662109375
INFO:root:Train (Epoch 198): Loss/seq after 03450 batchs: 549.5262451171875
INFO:root:Train (Epoch 198): Loss/seq after 03500 batchs: 549.7557373046875
INFO:root:Train (Epoch 198): Loss/seq after 03550 batchs: 547.0050659179688
INFO:root:Train (Epoch 198): Loss/seq after 03600 batchs: 554.8339233398438
INFO:root:Train (Epoch 198): Loss/seq after 03650 batchs: 552.2313232421875
INFO:root:Train (Epoch 198): Loss/seq after 03700 batchs: 554.1990966796875
INFO:root:Train (Epoch 198): Loss/seq after 03750 batchs: 558.3305053710938
INFO:root:Train (Epoch 198): Loss/seq after 03800 batchs: 555.930419921875
INFO:root:Train (Epoch 198): Loss/seq after 03850 batchs: 554.6548461914062
INFO:root:Train (Epoch 198): Loss/seq after 03900 batchs: 558.1618041992188
INFO:root:Train (Epoch 198): Loss/seq after 03950 batchs: 561.505126953125
INFO:root:Train (Epoch 198): Loss/seq after 04000 batchs: 557.4921875
INFO:root:Train (Epoch 198): Loss/seq after 04050 batchs: 553.8980102539062
INFO:root:Train (Epoch 198): Loss/seq after 04100 batchs: 552.1286010742188
INFO:root:Train (Epoch 198): Loss/seq after 04150 batchs: 551.7584838867188
INFO:root:Train (Epoch 198): Loss/seq after 04200 batchs: 549.8842163085938
INFO:root:Train (Epoch 198): Loss/seq after 04250 batchs: 548.0188598632812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 198): Loss/seq after 00000 batches: 567.544189453125
INFO:root:# Valid (Epoch 198): Loss/seq after 00050 batches: 686.3431396484375
INFO:root:# Valid (Epoch 198): Loss/seq after 00100 batches: 705.0128173828125
INFO:root:# Valid (Epoch 198): Loss/seq after 00150 batches: 533.4692993164062
INFO:root:# Valid (Epoch 198): Loss/seq after 00200 batches: 493.371826171875
INFO:root:Artifacts: Make stick videos for epoch 198
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_198_on_20220423_124413.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_198_index_417_on_20220423_124413.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 199): Loss/seq after 00000 batchs: 1116.768310546875
INFO:root:Train (Epoch 199): Loss/seq after 00050 batchs: 801.4317016601562
INFO:root:Train (Epoch 199): Loss/seq after 00100 batchs: 804.5283203125
INFO:root:Train (Epoch 199): Loss/seq after 00150 batchs: 705.7838134765625
INFO:root:Train (Epoch 199): Loss/seq after 00200 batchs: 800.5677490234375
INFO:root:Train (Epoch 199): Loss/seq after 00250 batchs: 866.2530517578125
INFO:root:Train (Epoch 199): Loss/seq after 00300 batchs: 862.396728515625
INFO:root:Train (Epoch 199): Loss/seq after 00350 batchs: 808.7918701171875
INFO:root:Train (Epoch 199): Loss/seq after 00400 batchs: 812.2648315429688
INFO:root:Train (Epoch 199): Loss/seq after 00450 batchs: 794.6661987304688
INFO:root:Train (Epoch 199): Loss/seq after 00500 batchs: 771.8761596679688
INFO:root:Train (Epoch 199): Loss/seq after 00550 batchs: 748.0266723632812
INFO:root:Train (Epoch 199): Loss/seq after 00600 batchs: 720.7044067382812
INFO:root:Train (Epoch 199): Loss/seq after 00650 batchs: 704.4025268554688
INFO:root:Train (Epoch 199): Loss/seq after 00700 batchs: 681.2760009765625
INFO:root:Train (Epoch 199): Loss/seq after 00750 batchs: 690.4599609375
INFO:root:Train (Epoch 199): Loss/seq after 00800 batchs: 689.0655517578125
INFO:root:Train (Epoch 199): Loss/seq after 00850 batchs: 667.5311889648438
INFO:root:Train (Epoch 199): Loss/seq after 00900 batchs: 649.3779907226562
INFO:root:Train (Epoch 199): Loss/seq after 00950 batchs: 650.0538330078125
INFO:root:Train (Epoch 199): Loss/seq after 01000 batchs: 641.3975219726562
INFO:root:Train (Epoch 199): Loss/seq after 01050 batchs: 628.6857299804688
INFO:root:Train (Epoch 199): Loss/seq after 01100 batchs: 617.8234252929688
INFO:root:Train (Epoch 199): Loss/seq after 01150 batchs: 603.0951538085938
INFO:root:Train (Epoch 199): Loss/seq after 01200 batchs: 606.4166870117188
INFO:root:Train (Epoch 199): Loss/seq after 01250 batchs: 603.9642944335938
INFO:root:Train (Epoch 199): Loss/seq after 01300 batchs: 593.822021484375
INFO:root:Train (Epoch 199): Loss/seq after 01350 batchs: 584.8046875
INFO:root:Train (Epoch 199): Loss/seq after 01400 batchs: 589.13037109375
INFO:root:Train (Epoch 199): Loss/seq after 01450 batchs: 590.3592529296875
INFO:root:Train (Epoch 199): Loss/seq after 01500 batchs: 596.3157958984375
INFO:root:Train (Epoch 199): Loss/seq after 01550 batchs: 598.4121704101562
INFO:root:Train (Epoch 199): Loss/seq after 01600 batchs: 592.772705078125
INFO:root:Train (Epoch 199): Loss/seq after 01650 batchs: 589.3114624023438
INFO:root:Train (Epoch 199): Loss/seq after 01700 batchs: 591.0790405273438
INFO:root:Train (Epoch 199): Loss/seq after 01750 batchs: 588.1808471679688
INFO:root:Train (Epoch 199): Loss/seq after 01800 batchs: 585.3300170898438
INFO:root:Train (Epoch 199): Loss/seq after 01850 batchs: 581.01513671875
INFO:root:Train (Epoch 199): Loss/seq after 01900 batchs: 580.3761596679688
INFO:root:Train (Epoch 199): Loss/seq after 01950 batchs: 578.6849365234375
INFO:root:Train (Epoch 199): Loss/seq after 02000 batchs: 577.27490234375
INFO:root:Train (Epoch 199): Loss/seq after 02050 batchs: 575.2882080078125
INFO:root:Train (Epoch 199): Loss/seq after 02100 batchs: 572.1459350585938
INFO:root:Train (Epoch 199): Loss/seq after 02150 batchs: 569.6102294921875
INFO:root:Train (Epoch 199): Loss/seq after 02200 batchs: 566.2886352539062
INFO:root:Train (Epoch 199): Loss/seq after 02250 batchs: 565.23291015625
INFO:root:Train (Epoch 199): Loss/seq after 02300 batchs: 563.7611694335938
INFO:root:Train (Epoch 199): Loss/seq after 02350 batchs: 559.0284423828125
INFO:root:Train (Epoch 199): Loss/seq after 02400 batchs: 560.23291015625
INFO:root:Train (Epoch 199): Loss/seq after 02450 batchs: 555.4005126953125
INFO:root:Train (Epoch 199): Loss/seq after 02500 batchs: 547.12353515625
INFO:root:Train (Epoch 199): Loss/seq after 02550 batchs: 540.9585571289062
INFO:root:Train (Epoch 199): Loss/seq after 02600 batchs: 539.2408447265625
INFO:root:Train (Epoch 199): Loss/seq after 02650 batchs: 536.2818603515625
INFO:root:Train (Epoch 199): Loss/seq after 02700 batchs: 534.101318359375
INFO:root:Train (Epoch 199): Loss/seq after 02750 batchs: 530.7520141601562
INFO:root:Train (Epoch 199): Loss/seq after 02800 batchs: 530.9637451171875
INFO:root:Train (Epoch 199): Loss/seq after 02850 batchs: 530.5858764648438
INFO:root:Train (Epoch 199): Loss/seq after 02900 batchs: 532.0046997070312
INFO:root:Train (Epoch 199): Loss/seq after 02950 batchs: 531.0210571289062
INFO:root:Train (Epoch 199): Loss/seq after 03000 batchs: 536.1014404296875
INFO:root:Train (Epoch 199): Loss/seq after 03050 batchs: 538.0595703125
INFO:root:Train (Epoch 199): Loss/seq after 03100 batchs: 540.9921875
INFO:root:Train (Epoch 199): Loss/seq after 03150 batchs: 546.6787719726562
INFO:root:Train (Epoch 199): Loss/seq after 03200 batchs: 548.2244262695312
INFO:root:Train (Epoch 199): Loss/seq after 03250 batchs: 550.7457885742188
INFO:root:Train (Epoch 199): Loss/seq after 03300 batchs: 550.0211181640625
INFO:root:Train (Epoch 199): Loss/seq after 03350 batchs: 550.013671875
INFO:root:Train (Epoch 199): Loss/seq after 03400 batchs: 546.361083984375
INFO:root:Train (Epoch 199): Loss/seq after 03450 batchs: 545.0103759765625
INFO:root:Train (Epoch 199): Loss/seq after 03500 batchs: 545.0673217773438
INFO:root:Train (Epoch 199): Loss/seq after 03550 batchs: 542.4249267578125
INFO:root:Train (Epoch 199): Loss/seq after 03600 batchs: 550.2674560546875
INFO:root:Train (Epoch 199): Loss/seq after 03650 batchs: 547.923828125
INFO:root:Train (Epoch 199): Loss/seq after 03700 batchs: 549.979736328125
INFO:root:Train (Epoch 199): Loss/seq after 03750 batchs: 554.1220092773438
INFO:root:Train (Epoch 199): Loss/seq after 03800 batchs: 551.7545166015625
INFO:root:Train (Epoch 199): Loss/seq after 03850 batchs: 550.665771484375
INFO:root:Train (Epoch 199): Loss/seq after 03900 batchs: 554.1006469726562
INFO:root:Train (Epoch 199): Loss/seq after 03950 batchs: 557.997802734375
INFO:root:Train (Epoch 199): Loss/seq after 04000 batchs: 554.09716796875
INFO:root:Train (Epoch 199): Loss/seq after 04050 batchs: 550.6199340820312
INFO:root:Train (Epoch 199): Loss/seq after 04100 batchs: 548.88671875
INFO:root:Train (Epoch 199): Loss/seq after 04150 batchs: 548.5881958007812
INFO:root:Train (Epoch 199): Loss/seq after 04200 batchs: 546.6907348632812
INFO:root:Train (Epoch 199): Loss/seq after 04250 batchs: 544.8969116210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 199): Loss/seq after 00000 batches: 594.8944702148438
INFO:root:# Valid (Epoch 199): Loss/seq after 00050 batches: 687.4065551757812
INFO:root:# Valid (Epoch 199): Loss/seq after 00100 batches: 725.9710083007812
INFO:root:# Valid (Epoch 199): Loss/seq after 00150 batches: 548.7429809570312
INFO:root:# Valid (Epoch 199): Loss/seq after 00200 batches: 505.48297119140625
INFO:root:Artifacts: Make stick videos for epoch 199
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_199_on_20220423_124914.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_199_index_1396_on_20220423_124914.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 200): Loss/seq after 00000 batchs: 1148.7987060546875
INFO:root:Train (Epoch 200): Loss/seq after 00050 batchs: 809.2144165039062
INFO:root:Train (Epoch 200): Loss/seq after 00100 batchs: 797.4546508789062
INFO:root:Train (Epoch 200): Loss/seq after 00150 batchs: 697.9347534179688
INFO:root:Train (Epoch 200): Loss/seq after 00200 batchs: 780.9628295898438
INFO:root:Train (Epoch 200): Loss/seq after 00250 batchs: 856.2139282226562
INFO:root:Train (Epoch 200): Loss/seq after 00300 batchs: 855.31640625
INFO:root:Train (Epoch 200): Loss/seq after 00350 batchs: 802.4915161132812
INFO:root:Train (Epoch 200): Loss/seq after 00400 batchs: 809.6154174804688
INFO:root:Train (Epoch 200): Loss/seq after 00450 batchs: 792.6920776367188
INFO:root:Train (Epoch 200): Loss/seq after 00500 batchs: 769.8953247070312
INFO:root:Train (Epoch 200): Loss/seq after 00550 batchs: 745.6089477539062
INFO:root:Train (Epoch 200): Loss/seq after 00600 batchs: 718.0983276367188
INFO:root:Train (Epoch 200): Loss/seq after 00650 batchs: 707.00146484375
INFO:root:Train (Epoch 200): Loss/seq after 00700 batchs: 685.8802490234375
INFO:root:Train (Epoch 200): Loss/seq after 00750 batchs: 691.5940551757812
INFO:root:Train (Epoch 200): Loss/seq after 00800 batchs: 689.8052368164062
INFO:root:Train (Epoch 200): Loss/seq after 00850 batchs: 667.6607666015625
INFO:root:Train (Epoch 200): Loss/seq after 00900 batchs: 649.4465942382812
INFO:root:Train (Epoch 200): Loss/seq after 00950 batchs: 649.1528930664062
INFO:root:Train (Epoch 200): Loss/seq after 01000 batchs: 640.9102172851562
INFO:root:Train (Epoch 200): Loss/seq after 01050 batchs: 627.760498046875
INFO:root:Train (Epoch 200): Loss/seq after 01100 batchs: 616.1890258789062
INFO:root:Train (Epoch 200): Loss/seq after 01150 batchs: 601.2587890625
INFO:root:Train (Epoch 200): Loss/seq after 01200 batchs: 603.8695068359375
INFO:root:Train (Epoch 200): Loss/seq after 01250 batchs: 600.5408935546875
INFO:root:Train (Epoch 200): Loss/seq after 01300 batchs: 590.6878051757812
INFO:root:Train (Epoch 200): Loss/seq after 01350 batchs: 582.3480224609375
INFO:root:Train (Epoch 200): Loss/seq after 01400 batchs: 585.2854614257812
INFO:root:Train (Epoch 200): Loss/seq after 01450 batchs: 586.3186645507812
INFO:root:Train (Epoch 200): Loss/seq after 01500 batchs: 591.895263671875
INFO:root:Train (Epoch 200): Loss/seq after 01550 batchs: 593.9657592773438
INFO:root:Train (Epoch 200): Loss/seq after 01600 batchs: 588.3209228515625
INFO:root:Train (Epoch 200): Loss/seq after 01650 batchs: 584.8702392578125
INFO:root:Train (Epoch 200): Loss/seq after 01700 batchs: 586.5553588867188
INFO:root:Train (Epoch 200): Loss/seq after 01750 batchs: 583.6476440429688
INFO:root:Train (Epoch 200): Loss/seq after 01800 batchs: 580.706787109375
INFO:root:Train (Epoch 200): Loss/seq after 01850 batchs: 576.2402954101562
INFO:root:Train (Epoch 200): Loss/seq after 01900 batchs: 575.2788696289062
INFO:root:Train (Epoch 200): Loss/seq after 01950 batchs: 573.3560791015625
INFO:root:Train (Epoch 200): Loss/seq after 02000 batchs: 572.0709838867188
INFO:root:Train (Epoch 200): Loss/seq after 02050 batchs: 570.0685424804688
INFO:root:Train (Epoch 200): Loss/seq after 02100 batchs: 566.972412109375
INFO:root:Train (Epoch 200): Loss/seq after 02150 batchs: 564.4314575195312
INFO:root:Train (Epoch 200): Loss/seq after 02200 batchs: 561.3269653320312
INFO:root:Train (Epoch 200): Loss/seq after 02250 batchs: 560.0663452148438
INFO:root:Train (Epoch 200): Loss/seq after 02300 batchs: 559.1780395507812
INFO:root:Train (Epoch 200): Loss/seq after 02350 batchs: 554.5640869140625
INFO:root:Train (Epoch 200): Loss/seq after 02400 batchs: 555.8327026367188
INFO:root:Train (Epoch 200): Loss/seq after 02450 batchs: 551.0640258789062
INFO:root:Train (Epoch 200): Loss/seq after 02500 batchs: 542.9423217773438
INFO:root:Train (Epoch 200): Loss/seq after 02550 batchs: 536.8192749023438
INFO:root:Train (Epoch 200): Loss/seq after 02600 batchs: 535.58349609375
INFO:root:Train (Epoch 200): Loss/seq after 02650 batchs: 532.7742919921875
INFO:root:Train (Epoch 200): Loss/seq after 02700 batchs: 530.8235473632812
INFO:root:Train (Epoch 200): Loss/seq after 02750 batchs: 528.66552734375
INFO:root:Train (Epoch 200): Loss/seq after 02800 batchs: 529.0573120117188
INFO:root:Train (Epoch 200): Loss/seq after 02850 batchs: 528.6774291992188
INFO:root:Train (Epoch 200): Loss/seq after 02900 batchs: 529.921142578125
INFO:root:Train (Epoch 200): Loss/seq after 02950 batchs: 529.1389770507812
INFO:root:Train (Epoch 200): Loss/seq after 03000 batchs: 534.1600341796875
INFO:root:Train (Epoch 200): Loss/seq after 03050 batchs: 536.1686401367188
INFO:root:Train (Epoch 200): Loss/seq after 03100 batchs: 539.25439453125
INFO:root:Train (Epoch 200): Loss/seq after 03150 batchs: 545.2817993164062
INFO:root:Train (Epoch 200): Loss/seq after 03200 batchs: 547.0546875
INFO:root:Train (Epoch 200): Loss/seq after 03250 batchs: 550.103759765625
INFO:root:Train (Epoch 200): Loss/seq after 03300 batchs: 549.2391357421875
INFO:root:Train (Epoch 200): Loss/seq after 03350 batchs: 548.7741088867188
INFO:root:Train (Epoch 200): Loss/seq after 03400 batchs: 544.9743041992188
INFO:root:Train (Epoch 200): Loss/seq after 03450 batchs: 543.419189453125
INFO:root:Train (Epoch 200): Loss/seq after 03500 batchs: 543.3740234375
INFO:root:Train (Epoch 200): Loss/seq after 03550 batchs: 540.4947509765625
INFO:root:Train (Epoch 200): Loss/seq after 03600 batchs: 548.2826538085938
INFO:root:Train (Epoch 200): Loss/seq after 03650 batchs: 545.7644653320312
INFO:root:Train (Epoch 200): Loss/seq after 03700 batchs: 547.816650390625
INFO:root:Train (Epoch 200): Loss/seq after 03750 batchs: 551.9844360351562
INFO:root:Train (Epoch 200): Loss/seq after 03800 batchs: 549.6397094726562
INFO:root:Train (Epoch 200): Loss/seq after 03850 batchs: 548.473388671875
INFO:root:Train (Epoch 200): Loss/seq after 03900 batchs: 552.125
INFO:root:Train (Epoch 200): Loss/seq after 03950 batchs: 556.001953125
INFO:root:Train (Epoch 200): Loss/seq after 04000 batchs: 552.126953125
INFO:root:Train (Epoch 200): Loss/seq after 04050 batchs: 548.5521850585938
INFO:root:Train (Epoch 200): Loss/seq after 04100 batchs: 546.8421630859375
INFO:root:Train (Epoch 200): Loss/seq after 04150 batchs: 546.497802734375
INFO:root:Train (Epoch 200): Loss/seq after 04200 batchs: 544.5111694335938
INFO:root:Train (Epoch 200): Loss/seq after 04250 batchs: 542.7845458984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 200): Loss/seq after 00000 batches: 487.0364990234375
INFO:root:# Valid (Epoch 200): Loss/seq after 00050 batches: 666.7376098632812
INFO:root:# Valid (Epoch 200): Loss/seq after 00100 batches: 721.176513671875
INFO:root:# Valid (Epoch 200): Loss/seq after 00150 batches: 543.271728515625
INFO:root:# Valid (Epoch 200): Loss/seq after 00200 batches: 499.9580078125
INFO:root:Artifacts: Make stick videos for epoch 200
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_200_on_20220423_125411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_200_index_1458_on_20220423_125411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 201): Loss/seq after 00000 batchs: 1046.946533203125
INFO:root:Train (Epoch 201): Loss/seq after 00050 batchs: 806.9030151367188
INFO:root:Train (Epoch 201): Loss/seq after 00100 batchs: 795.0043334960938
INFO:root:Train (Epoch 201): Loss/seq after 00150 batchs: 694.8411254882812
INFO:root:Train (Epoch 201): Loss/seq after 00200 batchs: 773.9728393554688
INFO:root:Train (Epoch 201): Loss/seq after 00250 batchs: 848.9547729492188
INFO:root:Train (Epoch 201): Loss/seq after 00300 batchs: 849.7403564453125
INFO:root:Train (Epoch 201): Loss/seq after 00350 batchs: 797.3118896484375
INFO:root:Train (Epoch 201): Loss/seq after 00400 batchs: 800.9334106445312
INFO:root:Train (Epoch 201): Loss/seq after 00450 batchs: 784.533447265625
INFO:root:Train (Epoch 201): Loss/seq after 00500 batchs: 759.1005249023438
INFO:root:Train (Epoch 201): Loss/seq after 00550 batchs: 735.3319091796875
INFO:root:Train (Epoch 201): Loss/seq after 00600 batchs: 709.4422607421875
INFO:root:Train (Epoch 201): Loss/seq after 00650 batchs: 695.8599243164062
INFO:root:Train (Epoch 201): Loss/seq after 00700 batchs: 674.152587890625
INFO:root:Train (Epoch 201): Loss/seq after 00750 batchs: 679.3698120117188
INFO:root:Train (Epoch 201): Loss/seq after 00800 batchs: 678.44677734375
INFO:root:Train (Epoch 201): Loss/seq after 00850 batchs: 656.9681396484375
INFO:root:Train (Epoch 201): Loss/seq after 00900 batchs: 638.5314331054688
INFO:root:Train (Epoch 201): Loss/seq after 00950 batchs: 640.8468627929688
INFO:root:Train (Epoch 201): Loss/seq after 01000 batchs: 632.484619140625
INFO:root:Train (Epoch 201): Loss/seq after 01050 batchs: 619.7562255859375
INFO:root:Train (Epoch 201): Loss/seq after 01100 batchs: 609.3680419921875
INFO:root:Train (Epoch 201): Loss/seq after 01150 batchs: 594.2862548828125
INFO:root:Train (Epoch 201): Loss/seq after 01200 batchs: 597.43017578125
INFO:root:Train (Epoch 201): Loss/seq after 01250 batchs: 594.477294921875
INFO:root:Train (Epoch 201): Loss/seq after 01300 batchs: 584.47412109375
INFO:root:Train (Epoch 201): Loss/seq after 01350 batchs: 576.5147094726562
INFO:root:Train (Epoch 201): Loss/seq after 01400 batchs: 580.6758422851562
INFO:root:Train (Epoch 201): Loss/seq after 01450 batchs: 582.0971069335938
INFO:root:Train (Epoch 201): Loss/seq after 01500 batchs: 587.8521728515625
INFO:root:Train (Epoch 201): Loss/seq after 01550 batchs: 589.7296142578125
INFO:root:Train (Epoch 201): Loss/seq after 01600 batchs: 584.1402587890625
INFO:root:Train (Epoch 201): Loss/seq after 01650 batchs: 580.4949340820312
INFO:root:Train (Epoch 201): Loss/seq after 01700 batchs: 582.7424926757812
INFO:root:Train (Epoch 201): Loss/seq after 01750 batchs: 579.824462890625
INFO:root:Train (Epoch 201): Loss/seq after 01800 batchs: 577.0272827148438
INFO:root:Train (Epoch 201): Loss/seq after 01850 batchs: 572.845703125
INFO:root:Train (Epoch 201): Loss/seq after 01900 batchs: 571.8110961914062
INFO:root:Train (Epoch 201): Loss/seq after 01950 batchs: 569.9283447265625
INFO:root:Train (Epoch 201): Loss/seq after 02000 batchs: 568.6836547851562
INFO:root:Train (Epoch 201): Loss/seq after 02050 batchs: 566.823486328125
INFO:root:Train (Epoch 201): Loss/seq after 02100 batchs: 563.7852783203125
INFO:root:Train (Epoch 201): Loss/seq after 02150 batchs: 561.2279052734375
INFO:root:Train (Epoch 201): Loss/seq after 02200 batchs: 558.168701171875
INFO:root:Train (Epoch 201): Loss/seq after 02250 batchs: 556.9186401367188
INFO:root:Train (Epoch 201): Loss/seq after 02300 batchs: 555.9196166992188
INFO:root:Train (Epoch 201): Loss/seq after 02350 batchs: 551.36962890625
INFO:root:Train (Epoch 201): Loss/seq after 02400 batchs: 552.619384765625
INFO:root:Train (Epoch 201): Loss/seq after 02450 batchs: 547.8125610351562
INFO:root:Train (Epoch 201): Loss/seq after 02500 batchs: 539.69970703125
INFO:root:Train (Epoch 201): Loss/seq after 02550 batchs: 533.7930908203125
INFO:root:Train (Epoch 201): Loss/seq after 02600 batchs: 532.2769775390625
INFO:root:Train (Epoch 201): Loss/seq after 02650 batchs: 529.5865478515625
INFO:root:Train (Epoch 201): Loss/seq after 02700 batchs: 527.4797973632812
INFO:root:Train (Epoch 201): Loss/seq after 02750 batchs: 524.8363037109375
INFO:root:Train (Epoch 201): Loss/seq after 02800 batchs: 524.8159790039062
INFO:root:Train (Epoch 201): Loss/seq after 02850 batchs: 524.6284790039062
INFO:root:Train (Epoch 201): Loss/seq after 02900 batchs: 526.1757202148438
INFO:root:Train (Epoch 201): Loss/seq after 02950 batchs: 525.345458984375
INFO:root:Train (Epoch 201): Loss/seq after 03000 batchs: 530.2102661132812
INFO:root:Train (Epoch 201): Loss/seq after 03050 batchs: 532.2473754882812
INFO:root:Train (Epoch 201): Loss/seq after 03100 batchs: 535.4771118164062
INFO:root:Train (Epoch 201): Loss/seq after 03150 batchs: 540.8483276367188
INFO:root:Train (Epoch 201): Loss/seq after 03200 batchs: 542.3781127929688
INFO:root:Train (Epoch 201): Loss/seq after 03250 batchs: 544.8803100585938
INFO:root:Train (Epoch 201): Loss/seq after 03300 batchs: 544.2132568359375
INFO:root:Train (Epoch 201): Loss/seq after 03350 batchs: 544.23193359375
INFO:root:Train (Epoch 201): Loss/seq after 03400 batchs: 540.5181274414062
INFO:root:Train (Epoch 201): Loss/seq after 03450 batchs: 539.375244140625
INFO:root:Train (Epoch 201): Loss/seq after 03500 batchs: 539.536376953125
INFO:root:Train (Epoch 201): Loss/seq after 03550 batchs: 536.751708984375
INFO:root:Train (Epoch 201): Loss/seq after 03600 batchs: 544.44921875
INFO:root:Train (Epoch 201): Loss/seq after 03650 batchs: 542.0209350585938
INFO:root:Train (Epoch 201): Loss/seq after 03700 batchs: 544.0977172851562
INFO:root:Train (Epoch 201): Loss/seq after 03750 batchs: 548.29736328125
INFO:root:Train (Epoch 201): Loss/seq after 03800 batchs: 546.0078125
INFO:root:Train (Epoch 201): Loss/seq after 03850 batchs: 544.8505249023438
INFO:root:Train (Epoch 201): Loss/seq after 03900 batchs: 548.59375
INFO:root:Train (Epoch 201): Loss/seq after 03950 batchs: 552.1563720703125
INFO:root:Train (Epoch 201): Loss/seq after 04000 batchs: 548.3212280273438
INFO:root:Train (Epoch 201): Loss/seq after 04050 batchs: 544.7890014648438
INFO:root:Train (Epoch 201): Loss/seq after 04100 batchs: 543.1116333007812
INFO:root:Train (Epoch 201): Loss/seq after 04150 batchs: 542.8304443359375
INFO:root:Train (Epoch 201): Loss/seq after 04200 batchs: 540.9207763671875
INFO:root:Train (Epoch 201): Loss/seq after 04250 batchs: 539.0809936523438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 201): Loss/seq after 00000 batches: 598.8165893554688
INFO:root:# Valid (Epoch 201): Loss/seq after 00050 batches: 689.5401611328125
INFO:root:# Valid (Epoch 201): Loss/seq after 00100 batches: 700.2152709960938
INFO:root:# Valid (Epoch 201): Loss/seq after 00150 batches: 532.104736328125
INFO:root:# Valid (Epoch 201): Loss/seq after 00200 batches: 489.9831848144531
INFO:root:Artifacts: Make stick videos for epoch 201
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_201_on_20220423_125901.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_201_index_214_on_20220423_125901.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 202): Loss/seq after 00000 batchs: 1182.8408203125
INFO:root:Train (Epoch 202): Loss/seq after 00050 batchs: 800.5836791992188
INFO:root:Train (Epoch 202): Loss/seq after 00100 batchs: 795.380859375
INFO:root:Train (Epoch 202): Loss/seq after 00150 batchs: 701.57373046875
INFO:root:Train (Epoch 202): Loss/seq after 00200 batchs: 787.9932861328125
INFO:root:Train (Epoch 202): Loss/seq after 00250 batchs: 858.8449096679688
INFO:root:Train (Epoch 202): Loss/seq after 00300 batchs: 855.0420532226562
INFO:root:Train (Epoch 202): Loss/seq after 00350 batchs: 802.353515625
INFO:root:Train (Epoch 202): Loss/seq after 00400 batchs: 811.4457397460938
INFO:root:Train (Epoch 202): Loss/seq after 00450 batchs: 794.291015625
INFO:root:Train (Epoch 202): Loss/seq after 00500 batchs: 772.1649780273438
INFO:root:Train (Epoch 202): Loss/seq after 00550 batchs: 747.2594604492188
INFO:root:Train (Epoch 202): Loss/seq after 00600 batchs: 720.4240112304688
INFO:root:Train (Epoch 202): Loss/seq after 00650 batchs: 706.3446655273438
INFO:root:Train (Epoch 202): Loss/seq after 00700 batchs: 681.6541748046875
INFO:root:Train (Epoch 202): Loss/seq after 00750 batchs: 689.4429931640625
INFO:root:Train (Epoch 202): Loss/seq after 00800 batchs: 687.1793823242188
INFO:root:Train (Epoch 202): Loss/seq after 00850 batchs: 664.5947875976562
INFO:root:Train (Epoch 202): Loss/seq after 00900 batchs: 645.8373413085938
INFO:root:Train (Epoch 202): Loss/seq after 00950 batchs: 648.2994384765625
INFO:root:Train (Epoch 202): Loss/seq after 01000 batchs: 639.1510620117188
INFO:root:Train (Epoch 202): Loss/seq after 01050 batchs: 625.6668090820312
INFO:root:Train (Epoch 202): Loss/seq after 01100 batchs: 613.4771118164062
INFO:root:Train (Epoch 202): Loss/seq after 01150 batchs: 598.1882934570312
INFO:root:Train (Epoch 202): Loss/seq after 01200 batchs: 601.1114501953125
INFO:root:Train (Epoch 202): Loss/seq after 01250 batchs: 597.6499633789062
INFO:root:Train (Epoch 202): Loss/seq after 01300 batchs: 587.6769409179688
INFO:root:Train (Epoch 202): Loss/seq after 01350 batchs: 579.1484985351562
INFO:root:Train (Epoch 202): Loss/seq after 01400 batchs: 582.3949584960938
INFO:root:Train (Epoch 202): Loss/seq after 01450 batchs: 583.101806640625
INFO:root:Train (Epoch 202): Loss/seq after 01500 batchs: 588.74072265625
INFO:root:Train (Epoch 202): Loss/seq after 01550 batchs: 589.9474487304688
INFO:root:Train (Epoch 202): Loss/seq after 01600 batchs: 584.3707885742188
INFO:root:Train (Epoch 202): Loss/seq after 01650 batchs: 581.01953125
INFO:root:Train (Epoch 202): Loss/seq after 01700 batchs: 583.180908203125
INFO:root:Train (Epoch 202): Loss/seq after 01750 batchs: 580.4805297851562
INFO:root:Train (Epoch 202): Loss/seq after 01800 batchs: 577.6207275390625
INFO:root:Train (Epoch 202): Loss/seq after 01850 batchs: 573.4298706054688
INFO:root:Train (Epoch 202): Loss/seq after 01900 batchs: 572.2166748046875
INFO:root:Train (Epoch 202): Loss/seq after 01950 batchs: 570.1482543945312
INFO:root:Train (Epoch 202): Loss/seq after 02000 batchs: 568.9209594726562
INFO:root:Train (Epoch 202): Loss/seq after 02050 batchs: 567.0227661132812
INFO:root:Train (Epoch 202): Loss/seq after 02100 batchs: 563.915283203125
INFO:root:Train (Epoch 202): Loss/seq after 02150 batchs: 561.4966430664062
INFO:root:Train (Epoch 202): Loss/seq after 02200 batchs: 558.3136596679688
INFO:root:Train (Epoch 202): Loss/seq after 02250 batchs: 557.0419311523438
INFO:root:Train (Epoch 202): Loss/seq after 02300 batchs: 555.8011474609375
INFO:root:Train (Epoch 202): Loss/seq after 02350 batchs: 551.079345703125
INFO:root:Train (Epoch 202): Loss/seq after 02400 batchs: 552.4429931640625
INFO:root:Train (Epoch 202): Loss/seq after 02450 batchs: 547.632568359375
INFO:root:Train (Epoch 202): Loss/seq after 02500 batchs: 539.4913330078125
INFO:root:Train (Epoch 202): Loss/seq after 02550 batchs: 533.4561767578125
INFO:root:Train (Epoch 202): Loss/seq after 02600 batchs: 531.7001342773438
INFO:root:Train (Epoch 202): Loss/seq after 02650 batchs: 528.5081787109375
INFO:root:Train (Epoch 202): Loss/seq after 02700 batchs: 526.5453491210938
INFO:root:Train (Epoch 202): Loss/seq after 02750 batchs: 524.099853515625
INFO:root:Train (Epoch 202): Loss/seq after 02800 batchs: 525.1400146484375
INFO:root:Train (Epoch 202): Loss/seq after 02850 batchs: 524.8890380859375
INFO:root:Train (Epoch 202): Loss/seq after 02900 batchs: 526.5177612304688
INFO:root:Train (Epoch 202): Loss/seq after 02950 batchs: 525.774658203125
INFO:root:Train (Epoch 202): Loss/seq after 03000 batchs: 530.6433715820312
INFO:root:Train (Epoch 202): Loss/seq after 03050 batchs: 532.5743408203125
INFO:root:Train (Epoch 202): Loss/seq after 03100 batchs: 535.3054809570312
INFO:root:Train (Epoch 202): Loss/seq after 03150 batchs: 540.2945556640625
INFO:root:Train (Epoch 202): Loss/seq after 03200 batchs: 541.81005859375
INFO:root:Train (Epoch 202): Loss/seq after 03250 batchs: 544.252197265625
INFO:root:Train (Epoch 202): Loss/seq after 03300 batchs: 543.4795532226562
INFO:root:Train (Epoch 202): Loss/seq after 03350 batchs: 543.0697631835938
INFO:root:Train (Epoch 202): Loss/seq after 03400 batchs: 539.3339233398438
INFO:root:Train (Epoch 202): Loss/seq after 03450 batchs: 538.0703125
INFO:root:Train (Epoch 202): Loss/seq after 03500 batchs: 538.8338012695312
INFO:root:Train (Epoch 202): Loss/seq after 03550 batchs: 536.4308471679688
INFO:root:Train (Epoch 202): Loss/seq after 03600 batchs: 544.4286499023438
INFO:root:Train (Epoch 202): Loss/seq after 03650 batchs: 542.3245239257812
INFO:root:Train (Epoch 202): Loss/seq after 03700 batchs: 544.544677734375
INFO:root:Train (Epoch 202): Loss/seq after 03750 batchs: 548.7796630859375
INFO:root:Train (Epoch 202): Loss/seq after 03800 batchs: 546.5045166015625
INFO:root:Train (Epoch 202): Loss/seq after 03850 batchs: 545.3552856445312
INFO:root:Train (Epoch 202): Loss/seq after 03900 batchs: 549.23388671875
INFO:root:Train (Epoch 202): Loss/seq after 03950 batchs: 552.9317626953125
INFO:root:Train (Epoch 202): Loss/seq after 04000 batchs: 549.0794067382812
INFO:root:Train (Epoch 202): Loss/seq after 04050 batchs: 545.5768432617188
INFO:root:Train (Epoch 202): Loss/seq after 04100 batchs: 543.89013671875
INFO:root:Train (Epoch 202): Loss/seq after 04150 batchs: 543.6116943359375
INFO:root:Train (Epoch 202): Loss/seq after 04200 batchs: 541.6962280273438
INFO:root:Train (Epoch 202): Loss/seq after 04250 batchs: 539.91650390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 202): Loss/seq after 00000 batches: 618.6812744140625
INFO:root:# Valid (Epoch 202): Loss/seq after 00050 batches: 685.4486083984375
INFO:root:# Valid (Epoch 202): Loss/seq after 00100 batches: 704.97509765625
INFO:root:# Valid (Epoch 202): Loss/seq after 00150 batches: 535.7327880859375
INFO:root:# Valid (Epoch 202): Loss/seq after 00200 batches: 495.58331298828125
INFO:root:Artifacts: Make stick videos for epoch 202
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_202_on_20220423_130408.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_202_index_855_on_20220423_130408.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 203): Loss/seq after 00000 batchs: 1309.2618408203125
INFO:root:Train (Epoch 203): Loss/seq after 00050 batchs: 831.4232788085938
INFO:root:Train (Epoch 203): Loss/seq after 00100 batchs: 810.99462890625
INFO:root:Train (Epoch 203): Loss/seq after 00150 batchs: 705.1978759765625
INFO:root:Train (Epoch 203): Loss/seq after 00200 batchs: 781.8355712890625
INFO:root:Train (Epoch 203): Loss/seq after 00250 batchs: 853.5112915039062
INFO:root:Train (Epoch 203): Loss/seq after 00300 batchs: 851.8019409179688
INFO:root:Train (Epoch 203): Loss/seq after 00350 batchs: 798.3707275390625
INFO:root:Train (Epoch 203): Loss/seq after 00400 batchs: 805.8883666992188
INFO:root:Train (Epoch 203): Loss/seq after 00450 batchs: 788.5538940429688
INFO:root:Train (Epoch 203): Loss/seq after 00500 batchs: 765.2685546875
INFO:root:Train (Epoch 203): Loss/seq after 00550 batchs: 740.12646484375
INFO:root:Train (Epoch 203): Loss/seq after 00600 batchs: 714.2078857421875
INFO:root:Train (Epoch 203): Loss/seq after 00650 batchs: 700.8572998046875
INFO:root:Train (Epoch 203): Loss/seq after 00700 batchs: 679.3797607421875
INFO:root:Train (Epoch 203): Loss/seq after 00750 batchs: 688.4424438476562
INFO:root:Train (Epoch 203): Loss/seq after 00800 batchs: 686.3056030273438
INFO:root:Train (Epoch 203): Loss/seq after 00850 batchs: 664.5690307617188
INFO:root:Train (Epoch 203): Loss/seq after 00900 batchs: 646.9779663085938
INFO:root:Train (Epoch 203): Loss/seq after 00950 batchs: 647.7230834960938
INFO:root:Train (Epoch 203): Loss/seq after 01000 batchs: 638.9092407226562
INFO:root:Train (Epoch 203): Loss/seq after 01050 batchs: 625.90185546875
INFO:root:Train (Epoch 203): Loss/seq after 01100 batchs: 613.8809204101562
INFO:root:Train (Epoch 203): Loss/seq after 01150 batchs: 598.6129760742188
INFO:root:Train (Epoch 203): Loss/seq after 01200 batchs: 601.6913452148438
INFO:root:Train (Epoch 203): Loss/seq after 01250 batchs: 598.6676025390625
INFO:root:Train (Epoch 203): Loss/seq after 01300 batchs: 588.1553955078125
INFO:root:Train (Epoch 203): Loss/seq after 01350 batchs: 579.403564453125
INFO:root:Train (Epoch 203): Loss/seq after 01400 batchs: 582.6868896484375
INFO:root:Train (Epoch 203): Loss/seq after 01450 batchs: 584.01171875
INFO:root:Train (Epoch 203): Loss/seq after 01500 batchs: 589.5896606445312
INFO:root:Train (Epoch 203): Loss/seq after 01550 batchs: 591.2015380859375
INFO:root:Train (Epoch 203): Loss/seq after 01600 batchs: 585.651611328125
INFO:root:Train (Epoch 203): Loss/seq after 01650 batchs: 582.1055908203125
INFO:root:Train (Epoch 203): Loss/seq after 01700 batchs: 584.016845703125
INFO:root:Train (Epoch 203): Loss/seq after 01750 batchs: 581.1171264648438
INFO:root:Train (Epoch 203): Loss/seq after 01800 batchs: 578.1105346679688
INFO:root:Train (Epoch 203): Loss/seq after 01850 batchs: 573.753662109375
INFO:root:Train (Epoch 203): Loss/seq after 01900 batchs: 572.8663330078125
INFO:root:Train (Epoch 203): Loss/seq after 01950 batchs: 570.8759765625
INFO:root:Train (Epoch 203): Loss/seq after 02000 batchs: 569.6830444335938
INFO:root:Train (Epoch 203): Loss/seq after 02050 batchs: 567.5853881835938
INFO:root:Train (Epoch 203): Loss/seq after 02100 batchs: 564.342041015625
INFO:root:Train (Epoch 203): Loss/seq after 02150 batchs: 561.6856079101562
INFO:root:Train (Epoch 203): Loss/seq after 02200 batchs: 558.5006103515625
INFO:root:Train (Epoch 203): Loss/seq after 02250 batchs: 557.0409545898438
INFO:root:Train (Epoch 203): Loss/seq after 02300 batchs: 554.90478515625
INFO:root:Train (Epoch 203): Loss/seq after 02350 batchs: 550.2384033203125
INFO:root:Train (Epoch 203): Loss/seq after 02400 batchs: 551.4452514648438
INFO:root:Train (Epoch 203): Loss/seq after 02450 batchs: 546.6107788085938
INFO:root:Train (Epoch 203): Loss/seq after 02500 batchs: 538.4924926757812
INFO:root:Train (Epoch 203): Loss/seq after 02550 batchs: 532.2928466796875
INFO:root:Train (Epoch 203): Loss/seq after 02600 batchs: 530.5582885742188
INFO:root:Train (Epoch 203): Loss/seq after 02650 batchs: 527.5104370117188
INFO:root:Train (Epoch 203): Loss/seq after 02700 batchs: 525.3643798828125
INFO:root:Train (Epoch 203): Loss/seq after 02750 batchs: 523.459228515625
INFO:root:Train (Epoch 203): Loss/seq after 02800 batchs: 523.6697387695312
INFO:root:Train (Epoch 203): Loss/seq after 02850 batchs: 523.4854125976562
INFO:root:Train (Epoch 203): Loss/seq after 02900 batchs: 524.8062744140625
INFO:root:Train (Epoch 203): Loss/seq after 02950 batchs: 524.0514526367188
INFO:root:Train (Epoch 203): Loss/seq after 03000 batchs: 528.7783203125
INFO:root:Train (Epoch 203): Loss/seq after 03050 batchs: 530.5478515625
INFO:root:Train (Epoch 203): Loss/seq after 03100 batchs: 533.462646484375
INFO:root:Train (Epoch 203): Loss/seq after 03150 batchs: 538.970458984375
INFO:root:Train (Epoch 203): Loss/seq after 03200 batchs: 541.2392578125
INFO:root:Train (Epoch 203): Loss/seq after 03250 batchs: 544.2362060546875
INFO:root:Train (Epoch 203): Loss/seq after 03300 batchs: 543.3908081054688
INFO:root:Train (Epoch 203): Loss/seq after 03350 batchs: 543.2037963867188
INFO:root:Train (Epoch 203): Loss/seq after 03400 batchs: 539.4669799804688
INFO:root:Train (Epoch 203): Loss/seq after 03450 batchs: 537.865234375
INFO:root:Train (Epoch 203): Loss/seq after 03500 batchs: 537.9723510742188
INFO:root:Train (Epoch 203): Loss/seq after 03550 batchs: 535.2152709960938
INFO:root:Train (Epoch 203): Loss/seq after 03600 batchs: 543.0162353515625
INFO:root:Train (Epoch 203): Loss/seq after 03650 batchs: 540.6605834960938
INFO:root:Train (Epoch 203): Loss/seq after 03700 batchs: 542.5337524414062
INFO:root:Train (Epoch 203): Loss/seq after 03750 batchs: 546.5260009765625
INFO:root:Train (Epoch 203): Loss/seq after 03800 batchs: 544.1897583007812
INFO:root:Train (Epoch 203): Loss/seq after 03850 batchs: 542.8915405273438
INFO:root:Train (Epoch 203): Loss/seq after 03900 batchs: 546.758544921875
INFO:root:Train (Epoch 203): Loss/seq after 03950 batchs: 550.081787109375
INFO:root:Train (Epoch 203): Loss/seq after 04000 batchs: 546.2198486328125
INFO:root:Train (Epoch 203): Loss/seq after 04050 batchs: 542.6800537109375
INFO:root:Train (Epoch 203): Loss/seq after 04100 batchs: 541.0929565429688
INFO:root:Train (Epoch 203): Loss/seq after 04150 batchs: 540.7352905273438
INFO:root:Train (Epoch 203): Loss/seq after 04200 batchs: 538.8320922851562
INFO:root:Train (Epoch 203): Loss/seq after 04250 batchs: 536.9654541015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 203): Loss/seq after 00000 batches: 459.9451904296875
INFO:root:# Valid (Epoch 203): Loss/seq after 00050 batches: 683.41162109375
INFO:root:# Valid (Epoch 203): Loss/seq after 00100 batches: 721.4551391601562
INFO:root:# Valid (Epoch 203): Loss/seq after 00150 batches: 545.9652709960938
INFO:root:# Valid (Epoch 203): Loss/seq after 00200 batches: 503.7110900878906
INFO:root:Artifacts: Make stick videos for epoch 203
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_203_on_20220423_130908.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_203_index_1517_on_20220423_130908.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 204): Loss/seq after 00000 batchs: 1172.2310791015625
INFO:root:Train (Epoch 204): Loss/seq after 00050 batchs: 819.5929565429688
INFO:root:Train (Epoch 204): Loss/seq after 00100 batchs: 799.3803100585938
INFO:root:Train (Epoch 204): Loss/seq after 00150 batchs: 695.4676513671875
INFO:root:Train (Epoch 204): Loss/seq after 00200 batchs: 774.8703002929688
INFO:root:Train (Epoch 204): Loss/seq after 00250 batchs: 833.031005859375
INFO:root:Train (Epoch 204): Loss/seq after 00300 batchs: 834.4597778320312
INFO:root:Train (Epoch 204): Loss/seq after 00350 batchs: 784.5715942382812
INFO:root:Train (Epoch 204): Loss/seq after 00400 batchs: 789.9710083007812
INFO:root:Train (Epoch 204): Loss/seq after 00450 batchs: 774.7079467773438
INFO:root:Train (Epoch 204): Loss/seq after 00500 batchs: 753.9749145507812
INFO:root:Train (Epoch 204): Loss/seq after 00550 batchs: 730.6888427734375
INFO:root:Train (Epoch 204): Loss/seq after 00600 batchs: 704.7560424804688
INFO:root:Train (Epoch 204): Loss/seq after 00650 batchs: 691.4391479492188
INFO:root:Train (Epoch 204): Loss/seq after 00700 batchs: 669.5032958984375
INFO:root:Train (Epoch 204): Loss/seq after 00750 batchs: 680.4912719726562
INFO:root:Train (Epoch 204): Loss/seq after 00800 batchs: 678.9308471679688
INFO:root:Train (Epoch 204): Loss/seq after 00850 batchs: 657.050048828125
INFO:root:Train (Epoch 204): Loss/seq after 00900 batchs: 639.39013671875
INFO:root:Train (Epoch 204): Loss/seq after 00950 batchs: 641.267578125
INFO:root:Train (Epoch 204): Loss/seq after 01000 batchs: 632.6318969726562
INFO:root:Train (Epoch 204): Loss/seq after 01050 batchs: 620.1609497070312
INFO:root:Train (Epoch 204): Loss/seq after 01100 batchs: 608.4468383789062
INFO:root:Train (Epoch 204): Loss/seq after 01150 batchs: 593.935791015625
INFO:root:Train (Epoch 204): Loss/seq after 01200 batchs: 597.615478515625
INFO:root:Train (Epoch 204): Loss/seq after 01250 batchs: 594.9713134765625
INFO:root:Train (Epoch 204): Loss/seq after 01300 batchs: 584.8038940429688
INFO:root:Train (Epoch 204): Loss/seq after 01350 batchs: 575.7013549804688
INFO:root:Train (Epoch 204): Loss/seq after 01400 batchs: 579.8806762695312
INFO:root:Train (Epoch 204): Loss/seq after 01450 batchs: 581.07275390625
INFO:root:Train (Epoch 204): Loss/seq after 01500 batchs: 586.7003784179688
INFO:root:Train (Epoch 204): Loss/seq after 01550 batchs: 589.11962890625
INFO:root:Train (Epoch 204): Loss/seq after 01600 batchs: 583.4620361328125
INFO:root:Train (Epoch 204): Loss/seq after 01650 batchs: 579.76513671875
INFO:root:Train (Epoch 204): Loss/seq after 01700 batchs: 581.4990844726562
INFO:root:Train (Epoch 204): Loss/seq after 01750 batchs: 578.4564819335938
INFO:root:Train (Epoch 204): Loss/seq after 01800 batchs: 575.62548828125
INFO:root:Train (Epoch 204): Loss/seq after 01850 batchs: 571.304443359375
INFO:root:Train (Epoch 204): Loss/seq after 01900 batchs: 569.568603515625
INFO:root:Train (Epoch 204): Loss/seq after 01950 batchs: 567.5100708007812
INFO:root:Train (Epoch 204): Loss/seq after 02000 batchs: 566.0961303710938
INFO:root:Train (Epoch 204): Loss/seq after 02050 batchs: 564.1683959960938
INFO:root:Train (Epoch 204): Loss/seq after 02100 batchs: 560.9598999023438
INFO:root:Train (Epoch 204): Loss/seq after 02150 batchs: 558.6016235351562
INFO:root:Train (Epoch 204): Loss/seq after 02200 batchs: 555.6273803710938
INFO:root:Train (Epoch 204): Loss/seq after 02250 batchs: 554.4349975585938
INFO:root:Train (Epoch 204): Loss/seq after 02300 batchs: 552.0962524414062
INFO:root:Train (Epoch 204): Loss/seq after 02350 batchs: 547.403564453125
INFO:root:Train (Epoch 204): Loss/seq after 02400 batchs: 548.7987060546875
INFO:root:Train (Epoch 204): Loss/seq after 02450 batchs: 544.063232421875
INFO:root:Train (Epoch 204): Loss/seq after 02500 batchs: 535.9813842773438
INFO:root:Train (Epoch 204): Loss/seq after 02550 batchs: 529.8553466796875
INFO:root:Train (Epoch 204): Loss/seq after 02600 batchs: 527.9539794921875
INFO:root:Train (Epoch 204): Loss/seq after 02650 batchs: 524.9674682617188
INFO:root:Train (Epoch 204): Loss/seq after 02700 batchs: 523.0847778320312
INFO:root:Train (Epoch 204): Loss/seq after 02750 batchs: 520.183837890625
INFO:root:Train (Epoch 204): Loss/seq after 02800 batchs: 520.4091186523438
INFO:root:Train (Epoch 204): Loss/seq after 02850 batchs: 520.0609741210938
INFO:root:Train (Epoch 204): Loss/seq after 02900 batchs: 521.8133544921875
INFO:root:Train (Epoch 204): Loss/seq after 02950 batchs: 521.000732421875
INFO:root:Train (Epoch 204): Loss/seq after 03000 batchs: 525.8215942382812
INFO:root:Train (Epoch 204): Loss/seq after 03050 batchs: 528.0260620117188
INFO:root:Train (Epoch 204): Loss/seq after 03100 batchs: 531.2557373046875
INFO:root:Train (Epoch 204): Loss/seq after 03150 batchs: 536.3616943359375
INFO:root:Train (Epoch 204): Loss/seq after 03200 batchs: 538.8109741210938
INFO:root:Train (Epoch 204): Loss/seq after 03250 batchs: 541.9022216796875
INFO:root:Train (Epoch 204): Loss/seq after 03300 batchs: 541.507080078125
INFO:root:Train (Epoch 204): Loss/seq after 03350 batchs: 541.0552978515625
INFO:root:Train (Epoch 204): Loss/seq after 03400 batchs: 537.3364868164062
INFO:root:Train (Epoch 204): Loss/seq after 03450 batchs: 535.8822631835938
INFO:root:Train (Epoch 204): Loss/seq after 03500 batchs: 537.437255859375
INFO:root:Train (Epoch 204): Loss/seq after 03550 batchs: 535.14208984375
INFO:root:Train (Epoch 204): Loss/seq after 03600 batchs: 543.3280639648438
INFO:root:Train (Epoch 204): Loss/seq after 03650 batchs: 541.0907592773438
INFO:root:Train (Epoch 204): Loss/seq after 03700 batchs: 543.130126953125
INFO:root:Train (Epoch 204): Loss/seq after 03750 batchs: 547.3888549804688
INFO:root:Train (Epoch 204): Loss/seq after 03800 batchs: 545.0543212890625
INFO:root:Train (Epoch 204): Loss/seq after 03850 batchs: 543.94091796875
INFO:root:Train (Epoch 204): Loss/seq after 03900 batchs: 548.029541015625
INFO:root:Train (Epoch 204): Loss/seq after 03950 batchs: 551.5345458984375
INFO:root:Train (Epoch 204): Loss/seq after 04000 batchs: 547.6002197265625
INFO:root:Train (Epoch 204): Loss/seq after 04050 batchs: 544.0977172851562
INFO:root:Train (Epoch 204): Loss/seq after 04100 batchs: 542.4007568359375
INFO:root:Train (Epoch 204): Loss/seq after 04150 batchs: 542.0552978515625
INFO:root:Train (Epoch 204): Loss/seq after 04200 batchs: 540.2166137695312
INFO:root:Train (Epoch 204): Loss/seq after 04250 batchs: 538.37255859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 204): Loss/seq after 00000 batches: 466.6421203613281
INFO:root:# Valid (Epoch 204): Loss/seq after 00050 batches: 681.9205932617188
INFO:root:# Valid (Epoch 204): Loss/seq after 00100 batches: 700.2933349609375
INFO:root:# Valid (Epoch 204): Loss/seq after 00150 batches: 531.127197265625
INFO:root:# Valid (Epoch 204): Loss/seq after 00200 batches: 490.4642333984375
INFO:root:Artifacts: Make stick videos for epoch 204
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_204_on_20220423_131411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_204_index_1847_on_20220423_131411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 205): Loss/seq after 00000 batchs: 1151.9833984375
INFO:root:Train (Epoch 205): Loss/seq after 00050 batchs: 786.1883544921875
INFO:root:Train (Epoch 205): Loss/seq after 00100 batchs: 776.6690673828125
INFO:root:Train (Epoch 205): Loss/seq after 00150 batchs: 681.5809936523438
INFO:root:Train (Epoch 205): Loss/seq after 00200 batchs: 770.2454833984375
INFO:root:Train (Epoch 205): Loss/seq after 00250 batchs: 837.2380981445312
INFO:root:Train (Epoch 205): Loss/seq after 00300 batchs: 835.4738159179688
INFO:root:Train (Epoch 205): Loss/seq after 00350 batchs: 784.4773559570312
INFO:root:Train (Epoch 205): Loss/seq after 00400 batchs: 787.3901977539062
INFO:root:Train (Epoch 205): Loss/seq after 00450 batchs: 772.3744506835938
INFO:root:Train (Epoch 205): Loss/seq after 00500 batchs: 749.7218627929688
INFO:root:Train (Epoch 205): Loss/seq after 00550 batchs: 726.5966186523438
INFO:root:Train (Epoch 205): Loss/seq after 00600 batchs: 700.412353515625
INFO:root:Train (Epoch 205): Loss/seq after 00650 batchs: 686.8854370117188
INFO:root:Train (Epoch 205): Loss/seq after 00700 batchs: 666.3408203125
INFO:root:Train (Epoch 205): Loss/seq after 00750 batchs: 674.4092407226562
INFO:root:Train (Epoch 205): Loss/seq after 00800 batchs: 672.364990234375
INFO:root:Train (Epoch 205): Loss/seq after 00850 batchs: 650.4725952148438
INFO:root:Train (Epoch 205): Loss/seq after 00900 batchs: 632.9803466796875
INFO:root:Train (Epoch 205): Loss/seq after 00950 batchs: 634.6231689453125
INFO:root:Train (Epoch 205): Loss/seq after 01000 batchs: 626.9468994140625
INFO:root:Train (Epoch 205): Loss/seq after 01050 batchs: 614.1709594726562
INFO:root:Train (Epoch 205): Loss/seq after 01100 batchs: 602.7830200195312
INFO:root:Train (Epoch 205): Loss/seq after 01150 batchs: 587.9169921875
INFO:root:Train (Epoch 205): Loss/seq after 01200 batchs: 591.65673828125
INFO:root:Train (Epoch 205): Loss/seq after 01250 batchs: 589.1873779296875
INFO:root:Train (Epoch 205): Loss/seq after 01300 batchs: 579.126953125
INFO:root:Train (Epoch 205): Loss/seq after 01350 batchs: 570.3807983398438
INFO:root:Train (Epoch 205): Loss/seq after 01400 batchs: 574.826416015625
INFO:root:Train (Epoch 205): Loss/seq after 01450 batchs: 575.9913330078125
INFO:root:Train (Epoch 205): Loss/seq after 01500 batchs: 581.5697631835938
INFO:root:Train (Epoch 205): Loss/seq after 01550 batchs: 583.0682983398438
INFO:root:Train (Epoch 205): Loss/seq after 01600 batchs: 577.5220947265625
INFO:root:Train (Epoch 205): Loss/seq after 01650 batchs: 574.4200439453125
INFO:root:Train (Epoch 205): Loss/seq after 01700 batchs: 576.4126586914062
INFO:root:Train (Epoch 205): Loss/seq after 01750 batchs: 573.587646484375
INFO:root:Train (Epoch 205): Loss/seq after 01800 batchs: 570.7930908203125
INFO:root:Train (Epoch 205): Loss/seq after 01850 batchs: 566.6923828125
INFO:root:Train (Epoch 205): Loss/seq after 01900 batchs: 565.4176635742188
INFO:root:Train (Epoch 205): Loss/seq after 01950 batchs: 563.3617553710938
INFO:root:Train (Epoch 205): Loss/seq after 02000 batchs: 562.1082763671875
INFO:root:Train (Epoch 205): Loss/seq after 02050 batchs: 560.16455078125
INFO:root:Train (Epoch 205): Loss/seq after 02100 batchs: 557.1053466796875
INFO:root:Train (Epoch 205): Loss/seq after 02150 batchs: 554.6123657226562
INFO:root:Train (Epoch 205): Loss/seq after 02200 batchs: 551.6051635742188
INFO:root:Train (Epoch 205): Loss/seq after 02250 batchs: 550.5323486328125
INFO:root:Train (Epoch 205): Loss/seq after 02300 batchs: 548.9381103515625
INFO:root:Train (Epoch 205): Loss/seq after 02350 batchs: 544.3235473632812
INFO:root:Train (Epoch 205): Loss/seq after 02400 batchs: 545.728271484375
INFO:root:Train (Epoch 205): Loss/seq after 02450 batchs: 541.0657958984375
INFO:root:Train (Epoch 205): Loss/seq after 02500 batchs: 533.0296020507812
INFO:root:Train (Epoch 205): Loss/seq after 02550 batchs: 526.8980102539062
INFO:root:Train (Epoch 205): Loss/seq after 02600 batchs: 525.1847534179688
INFO:root:Train (Epoch 205): Loss/seq after 02650 batchs: 522.2657470703125
INFO:root:Train (Epoch 205): Loss/seq after 02700 batchs: 520.154541015625
INFO:root:Train (Epoch 205): Loss/seq after 02750 batchs: 517.1826171875
INFO:root:Train (Epoch 205): Loss/seq after 02800 batchs: 517.6873779296875
INFO:root:Train (Epoch 205): Loss/seq after 02850 batchs: 517.419921875
INFO:root:Train (Epoch 205): Loss/seq after 02900 batchs: 518.9248046875
INFO:root:Train (Epoch 205): Loss/seq after 02950 batchs: 518.1240844726562
INFO:root:Train (Epoch 205): Loss/seq after 03000 batchs: 523.1640014648438
INFO:root:Train (Epoch 205): Loss/seq after 03050 batchs: 525.1796264648438
INFO:root:Train (Epoch 205): Loss/seq after 03100 batchs: 528.2595825195312
INFO:root:Train (Epoch 205): Loss/seq after 03150 batchs: 533.9628295898438
INFO:root:Train (Epoch 205): Loss/seq after 03200 batchs: 535.7584228515625
INFO:root:Train (Epoch 205): Loss/seq after 03250 batchs: 538.4033813476562
INFO:root:Train (Epoch 205): Loss/seq after 03300 batchs: 537.8475341796875
INFO:root:Train (Epoch 205): Loss/seq after 03350 batchs: 536.9696044921875
INFO:root:Train (Epoch 205): Loss/seq after 03400 batchs: 533.3497314453125
INFO:root:Train (Epoch 205): Loss/seq after 03450 batchs: 531.8862915039062
INFO:root:Train (Epoch 205): Loss/seq after 03500 batchs: 532.1891479492188
INFO:root:Train (Epoch 205): Loss/seq after 03550 batchs: 529.5820922851562
INFO:root:Train (Epoch 205): Loss/seq after 03600 batchs: 537.278564453125
INFO:root:Train (Epoch 205): Loss/seq after 03650 batchs: 534.9251708984375
INFO:root:Train (Epoch 205): Loss/seq after 03700 batchs: 537.0941772460938
INFO:root:Train (Epoch 205): Loss/seq after 03750 batchs: 541.3046264648438
INFO:root:Train (Epoch 205): Loss/seq after 03800 batchs: 538.9700317382812
INFO:root:Train (Epoch 205): Loss/seq after 03850 batchs: 537.541259765625
INFO:root:Train (Epoch 205): Loss/seq after 03900 batchs: 540.9500122070312
INFO:root:Train (Epoch 205): Loss/seq after 03950 batchs: 544.0262451171875
INFO:root:Train (Epoch 205): Loss/seq after 04000 batchs: 540.1710205078125
INFO:root:Train (Epoch 205): Loss/seq after 04050 batchs: 536.6828002929688
INFO:root:Train (Epoch 205): Loss/seq after 04100 batchs: 535.0889282226562
INFO:root:Train (Epoch 205): Loss/seq after 04150 batchs: 534.8032836914062
INFO:root:Train (Epoch 205): Loss/seq after 04200 batchs: 532.9202270507812
INFO:root:Train (Epoch 205): Loss/seq after 04250 batchs: 531.1368408203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 205): Loss/seq after 00000 batches: 504.5471496582031
INFO:root:# Valid (Epoch 205): Loss/seq after 00050 batches: 697.7977905273438
INFO:root:# Valid (Epoch 205): Loss/seq after 00100 batches: 723.4476928710938
INFO:root:# Valid (Epoch 205): Loss/seq after 00150 batches: 549.193115234375
INFO:root:# Valid (Epoch 205): Loss/seq after 00200 batches: 506.08795166015625
INFO:root:Artifacts: Make stick videos for epoch 205
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_205_on_20220423_131855.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_205_index_96_on_20220423_131855.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 206): Loss/seq after 00000 batchs: 994.272216796875
INFO:root:Train (Epoch 206): Loss/seq after 00050 batchs: 788.6567993164062
INFO:root:Train (Epoch 206): Loss/seq after 00100 batchs: 784.801025390625
INFO:root:Train (Epoch 206): Loss/seq after 00150 batchs: 687.975341796875
INFO:root:Train (Epoch 206): Loss/seq after 00200 batchs: 777.46337890625
INFO:root:Train (Epoch 206): Loss/seq after 00250 batchs: 836.2742309570312
INFO:root:Train (Epoch 206): Loss/seq after 00300 batchs: 837.9435424804688
INFO:root:Train (Epoch 206): Loss/seq after 00350 batchs: 785.5795288085938
INFO:root:Train (Epoch 206): Loss/seq after 00400 batchs: 788.94775390625
INFO:root:Train (Epoch 206): Loss/seq after 00450 batchs: 773.674560546875
INFO:root:Train (Epoch 206): Loss/seq after 00500 batchs: 752.4356689453125
INFO:root:Train (Epoch 206): Loss/seq after 00550 batchs: 729.1814575195312
INFO:root:Train (Epoch 206): Loss/seq after 00600 batchs: 703.4917602539062
INFO:root:Train (Epoch 206): Loss/seq after 00650 batchs: 690.9677124023438
INFO:root:Train (Epoch 206): Loss/seq after 00700 batchs: 672.9535522460938
INFO:root:Train (Epoch 206): Loss/seq after 00750 batchs: 679.393798828125
INFO:root:Train (Epoch 206): Loss/seq after 00800 batchs: 678.439208984375
INFO:root:Train (Epoch 206): Loss/seq after 00850 batchs: 656.8096313476562
INFO:root:Train (Epoch 206): Loss/seq after 00900 batchs: 638.6124267578125
INFO:root:Train (Epoch 206): Loss/seq after 00950 batchs: 642.048583984375
INFO:root:Train (Epoch 206): Loss/seq after 01000 batchs: 633.615966796875
INFO:root:Train (Epoch 206): Loss/seq after 01050 batchs: 620.752197265625
INFO:root:Train (Epoch 206): Loss/seq after 01100 batchs: 608.75830078125
INFO:root:Train (Epoch 206): Loss/seq after 01150 batchs: 593.6915893554688
INFO:root:Train (Epoch 206): Loss/seq after 01200 batchs: 596.5534057617188
INFO:root:Train (Epoch 206): Loss/seq after 01250 batchs: 593.6937255859375
INFO:root:Train (Epoch 206): Loss/seq after 01300 batchs: 582.6998291015625
INFO:root:Train (Epoch 206): Loss/seq after 01350 batchs: 573.3734741210938
INFO:root:Train (Epoch 206): Loss/seq after 01400 batchs: 577.706298828125
INFO:root:Train (Epoch 206): Loss/seq after 01450 batchs: 578.5223388671875
INFO:root:Train (Epoch 206): Loss/seq after 01500 batchs: 584.1967163085938
INFO:root:Train (Epoch 206): Loss/seq after 01550 batchs: 585.90380859375
INFO:root:Train (Epoch 206): Loss/seq after 01600 batchs: 580.0053100585938
INFO:root:Train (Epoch 206): Loss/seq after 01650 batchs: 576.6627807617188
INFO:root:Train (Epoch 206): Loss/seq after 01700 batchs: 578.4385986328125
INFO:root:Train (Epoch 206): Loss/seq after 01750 batchs: 575.535888671875
INFO:root:Train (Epoch 206): Loss/seq after 01800 batchs: 572.61865234375
INFO:root:Train (Epoch 206): Loss/seq after 01850 batchs: 568.4568481445312
INFO:root:Train (Epoch 206): Loss/seq after 01900 batchs: 566.975341796875
INFO:root:Train (Epoch 206): Loss/seq after 01950 batchs: 564.5389404296875
INFO:root:Train (Epoch 206): Loss/seq after 02000 batchs: 563.0694580078125
INFO:root:Train (Epoch 206): Loss/seq after 02050 batchs: 561.0858154296875
INFO:root:Train (Epoch 206): Loss/seq after 02100 batchs: 557.8551025390625
INFO:root:Train (Epoch 206): Loss/seq after 02150 batchs: 555.343505859375
INFO:root:Train (Epoch 206): Loss/seq after 02200 batchs: 552.1634521484375
INFO:root:Train (Epoch 206): Loss/seq after 02250 batchs: 550.5780639648438
INFO:root:Train (Epoch 206): Loss/seq after 02300 batchs: 548.6702270507812
INFO:root:Train (Epoch 206): Loss/seq after 02350 batchs: 544.0652465820312
INFO:root:Train (Epoch 206): Loss/seq after 02400 batchs: 545.43115234375
INFO:root:Train (Epoch 206): Loss/seq after 02450 batchs: 540.7472534179688
INFO:root:Train (Epoch 206): Loss/seq after 02500 batchs: 532.6876220703125
INFO:root:Train (Epoch 206): Loss/seq after 02550 batchs: 527.119140625
INFO:root:Train (Epoch 206): Loss/seq after 02600 batchs: 524.9846801757812
INFO:root:Train (Epoch 206): Loss/seq after 02650 batchs: 521.9052124023438
INFO:root:Train (Epoch 206): Loss/seq after 02700 batchs: 519.7919311523438
INFO:root:Train (Epoch 206): Loss/seq after 02750 batchs: 516.9700317382812
INFO:root:Train (Epoch 206): Loss/seq after 02800 batchs: 517.97216796875
INFO:root:Train (Epoch 206): Loss/seq after 02850 batchs: 517.7032470703125
INFO:root:Train (Epoch 206): Loss/seq after 02900 batchs: 519.2284545898438
INFO:root:Train (Epoch 206): Loss/seq after 02950 batchs: 518.3767700195312
INFO:root:Train (Epoch 206): Loss/seq after 03000 batchs: 523.2410888671875
INFO:root:Train (Epoch 206): Loss/seq after 03050 batchs: 525.2418823242188
INFO:root:Train (Epoch 206): Loss/seq after 03100 batchs: 528.6237182617188
INFO:root:Train (Epoch 206): Loss/seq after 03150 batchs: 534.1398315429688
INFO:root:Train (Epoch 206): Loss/seq after 03200 batchs: 535.8222045898438
INFO:root:Train (Epoch 206): Loss/seq after 03250 batchs: 538.8656616210938
INFO:root:Train (Epoch 206): Loss/seq after 03300 batchs: 538.4268798828125
INFO:root:Train (Epoch 206): Loss/seq after 03350 batchs: 538.1634521484375
INFO:root:Train (Epoch 206): Loss/seq after 03400 batchs: 534.3663940429688
INFO:root:Train (Epoch 206): Loss/seq after 03450 batchs: 533.2286376953125
INFO:root:Train (Epoch 206): Loss/seq after 03500 batchs: 534.182373046875
INFO:root:Train (Epoch 206): Loss/seq after 03550 batchs: 531.5480346679688
INFO:root:Train (Epoch 206): Loss/seq after 03600 batchs: 538.8301391601562
INFO:root:Train (Epoch 206): Loss/seq after 03650 batchs: 536.4640502929688
INFO:root:Train (Epoch 206): Loss/seq after 03700 batchs: 538.5891723632812
INFO:root:Train (Epoch 206): Loss/seq after 03750 batchs: 542.6920776367188
INFO:root:Train (Epoch 206): Loss/seq after 03800 batchs: 540.4658203125
INFO:root:Train (Epoch 206): Loss/seq after 03850 batchs: 539.532470703125
INFO:root:Train (Epoch 206): Loss/seq after 03900 batchs: 543.2808227539062
INFO:root:Train (Epoch 206): Loss/seq after 03950 batchs: 547.0542602539062
INFO:root:Train (Epoch 206): Loss/seq after 04000 batchs: 543.219482421875
INFO:root:Train (Epoch 206): Loss/seq after 04050 batchs: 539.7567138671875
INFO:root:Train (Epoch 206): Loss/seq after 04100 batchs: 538.163818359375
INFO:root:Train (Epoch 206): Loss/seq after 04150 batchs: 537.7742309570312
INFO:root:Train (Epoch 206): Loss/seq after 04200 batchs: 535.9781494140625
INFO:root:Train (Epoch 206): Loss/seq after 04250 batchs: 534.1937255859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 206): Loss/seq after 00000 batches: 518.469970703125
INFO:root:# Valid (Epoch 206): Loss/seq after 00050 batches: 664.301025390625
INFO:root:# Valid (Epoch 206): Loss/seq after 00100 batches: 691.0883178710938
INFO:root:# Valid (Epoch 206): Loss/seq after 00150 batches: 524.4556274414062
INFO:root:# Valid (Epoch 206): Loss/seq after 00200 batches: 486.2619323730469
INFO:root:Artifacts: Make stick videos for epoch 206
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_206_on_20220423_132342.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_206_index_290_on_20220423_132342.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 207): Loss/seq after 00000 batchs: 1416.977294921875
INFO:root:Train (Epoch 207): Loss/seq after 00050 batchs: 795.8197021484375
INFO:root:Train (Epoch 207): Loss/seq after 00100 batchs: 796.8427124023438
INFO:root:Train (Epoch 207): Loss/seq after 00150 batchs: 700.9154663085938
INFO:root:Train (Epoch 207): Loss/seq after 00200 batchs: 779.2996826171875
INFO:root:Train (Epoch 207): Loss/seq after 00250 batchs: 835.3353271484375
INFO:root:Train (Epoch 207): Loss/seq after 00300 batchs: 833.4749145507812
INFO:root:Train (Epoch 207): Loss/seq after 00350 batchs: 783.5440673828125
INFO:root:Train (Epoch 207): Loss/seq after 00400 batchs: 789.66650390625
INFO:root:Train (Epoch 207): Loss/seq after 00450 batchs: 774.85986328125
INFO:root:Train (Epoch 207): Loss/seq after 00500 batchs: 757.4429931640625
INFO:root:Train (Epoch 207): Loss/seq after 00550 batchs: 735.142578125
INFO:root:Train (Epoch 207): Loss/seq after 00600 batchs: 709.728271484375
INFO:root:Train (Epoch 207): Loss/seq after 00650 batchs: 696.534423828125
INFO:root:Train (Epoch 207): Loss/seq after 00700 batchs: 672.5224609375
INFO:root:Train (Epoch 207): Loss/seq after 00750 batchs: 678.6002807617188
INFO:root:Train (Epoch 207): Loss/seq after 00800 batchs: 677.2953491210938
INFO:root:Train (Epoch 207): Loss/seq after 00850 batchs: 655.7733154296875
INFO:root:Train (Epoch 207): Loss/seq after 00900 batchs: 638.4522705078125
INFO:root:Train (Epoch 207): Loss/seq after 00950 batchs: 640.1503295898438
INFO:root:Train (Epoch 207): Loss/seq after 01000 batchs: 632.0247802734375
INFO:root:Train (Epoch 207): Loss/seq after 01050 batchs: 619.2858276367188
INFO:root:Train (Epoch 207): Loss/seq after 01100 batchs: 607.705810546875
INFO:root:Train (Epoch 207): Loss/seq after 01150 batchs: 592.8314819335938
INFO:root:Train (Epoch 207): Loss/seq after 01200 batchs: 595.853271484375
INFO:root:Train (Epoch 207): Loss/seq after 01250 batchs: 592.9100952148438
INFO:root:Train (Epoch 207): Loss/seq after 01300 batchs: 583.0557861328125
INFO:root:Train (Epoch 207): Loss/seq after 01350 batchs: 573.3265380859375
INFO:root:Train (Epoch 207): Loss/seq after 01400 batchs: 578.1771850585938
INFO:root:Train (Epoch 207): Loss/seq after 01450 batchs: 579.0221557617188
INFO:root:Train (Epoch 207): Loss/seq after 01500 batchs: 584.63427734375
INFO:root:Train (Epoch 207): Loss/seq after 01550 batchs: 585.6607055664062
INFO:root:Train (Epoch 207): Loss/seq after 01600 batchs: 580.0147705078125
INFO:root:Train (Epoch 207): Loss/seq after 01650 batchs: 576.7744140625
INFO:root:Train (Epoch 207): Loss/seq after 01700 batchs: 578.6004638671875
INFO:root:Train (Epoch 207): Loss/seq after 01750 batchs: 575.55126953125
INFO:root:Train (Epoch 207): Loss/seq after 01800 batchs: 572.4276733398438
INFO:root:Train (Epoch 207): Loss/seq after 01850 batchs: 567.9814453125
INFO:root:Train (Epoch 207): Loss/seq after 01900 batchs: 566.465576171875
INFO:root:Train (Epoch 207): Loss/seq after 01950 batchs: 564.25927734375
INFO:root:Train (Epoch 207): Loss/seq after 02000 batchs: 562.9625854492188
INFO:root:Train (Epoch 207): Loss/seq after 02050 batchs: 560.9264526367188
INFO:root:Train (Epoch 207): Loss/seq after 02100 batchs: 557.7254028320312
INFO:root:Train (Epoch 207): Loss/seq after 02150 batchs: 555.2173461914062
INFO:root:Train (Epoch 207): Loss/seq after 02200 batchs: 552.1023559570312
INFO:root:Train (Epoch 207): Loss/seq after 02250 batchs: 550.967041015625
INFO:root:Train (Epoch 207): Loss/seq after 02300 batchs: 549.5396118164062
INFO:root:Train (Epoch 207): Loss/seq after 02350 batchs: 544.991455078125
INFO:root:Train (Epoch 207): Loss/seq after 02400 batchs: 546.3536376953125
INFO:root:Train (Epoch 207): Loss/seq after 02450 batchs: 541.6856079101562
INFO:root:Train (Epoch 207): Loss/seq after 02500 batchs: 533.646240234375
INFO:root:Train (Epoch 207): Loss/seq after 02550 batchs: 527.4866333007812
INFO:root:Train (Epoch 207): Loss/seq after 02600 batchs: 525.6980590820312
INFO:root:Train (Epoch 207): Loss/seq after 02650 batchs: 522.9398193359375
INFO:root:Train (Epoch 207): Loss/seq after 02700 batchs: 520.7074584960938
INFO:root:Train (Epoch 207): Loss/seq after 02750 batchs: 518.0248413085938
INFO:root:Train (Epoch 207): Loss/seq after 02800 batchs: 517.889404296875
INFO:root:Train (Epoch 207): Loss/seq after 02850 batchs: 517.4935913085938
INFO:root:Train (Epoch 207): Loss/seq after 02900 batchs: 519.0630493164062
INFO:root:Train (Epoch 207): Loss/seq after 02950 batchs: 518.3375244140625
INFO:root:Train (Epoch 207): Loss/seq after 03000 batchs: 523.2200927734375
INFO:root:Train (Epoch 207): Loss/seq after 03050 batchs: 525.0747680664062
INFO:root:Train (Epoch 207): Loss/seq after 03100 batchs: 528.4757080078125
INFO:root:Train (Epoch 207): Loss/seq after 03150 batchs: 532.8038940429688
INFO:root:Train (Epoch 207): Loss/seq after 03200 batchs: 534.7345581054688
INFO:root:Train (Epoch 207): Loss/seq after 03250 batchs: 537.6641235351562
INFO:root:Train (Epoch 207): Loss/seq after 03300 batchs: 537.4006958007812
INFO:root:Train (Epoch 207): Loss/seq after 03350 batchs: 536.73046875
INFO:root:Train (Epoch 207): Loss/seq after 03400 batchs: 533.0294189453125
INFO:root:Train (Epoch 207): Loss/seq after 03450 batchs: 531.6360473632812
INFO:root:Train (Epoch 207): Loss/seq after 03500 batchs: 532.3805541992188
INFO:root:Train (Epoch 207): Loss/seq after 03550 batchs: 529.803466796875
INFO:root:Train (Epoch 207): Loss/seq after 03600 batchs: 537.4845581054688
INFO:root:Train (Epoch 207): Loss/seq after 03650 batchs: 535.1692504882812
INFO:root:Train (Epoch 207): Loss/seq after 03700 batchs: 537.2413330078125
INFO:root:Train (Epoch 207): Loss/seq after 03750 batchs: 541.4566040039062
INFO:root:Train (Epoch 207): Loss/seq after 03800 batchs: 539.1943359375
INFO:root:Train (Epoch 207): Loss/seq after 03850 batchs: 537.830322265625
INFO:root:Train (Epoch 207): Loss/seq after 03900 batchs: 542.1737670898438
INFO:root:Train (Epoch 207): Loss/seq after 03950 batchs: 545.5328979492188
INFO:root:Train (Epoch 207): Loss/seq after 04000 batchs: 541.7183227539062
INFO:root:Train (Epoch 207): Loss/seq after 04050 batchs: 538.233154296875
INFO:root:Train (Epoch 207): Loss/seq after 04100 batchs: 536.4869995117188
INFO:root:Train (Epoch 207): Loss/seq after 04150 batchs: 536.16064453125
INFO:root:Train (Epoch 207): Loss/seq after 04200 batchs: 534.279541015625
INFO:root:Train (Epoch 207): Loss/seq after 04250 batchs: 532.3256225585938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 207): Loss/seq after 00000 batches: 613.4691162109375
INFO:root:# Valid (Epoch 207): Loss/seq after 00050 batches: 669.97802734375
INFO:root:# Valid (Epoch 207): Loss/seq after 00100 batches: 709.0726318359375
INFO:root:# Valid (Epoch 207): Loss/seq after 00150 batches: 533.5891723632812
INFO:root:# Valid (Epoch 207): Loss/seq after 00200 batches: 491.8409729003906
INFO:root:Artifacts: Make stick videos for epoch 207
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_207_on_20220423_132825.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_207_index_308_on_20220423_132825.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 208): Loss/seq after 00000 batchs: 1260.4500732421875
INFO:root:Train (Epoch 208): Loss/seq after 00050 batchs: 774.7220458984375
INFO:root:Train (Epoch 208): Loss/seq after 00100 batchs: 775.169921875
INFO:root:Train (Epoch 208): Loss/seq after 00150 batchs: 677.7979736328125
INFO:root:Train (Epoch 208): Loss/seq after 00200 batchs: 759.0466918945312
INFO:root:Train (Epoch 208): Loss/seq after 00250 batchs: 815.0914306640625
INFO:root:Train (Epoch 208): Loss/seq after 00300 batchs: 816.4610595703125
INFO:root:Train (Epoch 208): Loss/seq after 00350 batchs: 767.2020263671875
INFO:root:Train (Epoch 208): Loss/seq after 00400 batchs: 769.689453125
INFO:root:Train (Epoch 208): Loss/seq after 00450 batchs: 755.5672607421875
INFO:root:Train (Epoch 208): Loss/seq after 00500 batchs: 732.4696044921875
INFO:root:Train (Epoch 208): Loss/seq after 00550 batchs: 710.3832397460938
INFO:root:Train (Epoch 208): Loss/seq after 00600 batchs: 686.4874267578125
INFO:root:Train (Epoch 208): Loss/seq after 00650 batchs: 673.1825561523438
INFO:root:Train (Epoch 208): Loss/seq after 00700 batchs: 651.9741821289062
INFO:root:Train (Epoch 208): Loss/seq after 00750 batchs: 660.8576049804688
INFO:root:Train (Epoch 208): Loss/seq after 00800 batchs: 660.3279418945312
INFO:root:Train (Epoch 208): Loss/seq after 00850 batchs: 639.1210327148438
INFO:root:Train (Epoch 208): Loss/seq after 00900 batchs: 622.1535034179688
INFO:root:Train (Epoch 208): Loss/seq after 00950 batchs: 623.456787109375
INFO:root:Train (Epoch 208): Loss/seq after 01000 batchs: 615.1480712890625
INFO:root:Train (Epoch 208): Loss/seq after 01050 batchs: 601.9065551757812
INFO:root:Train (Epoch 208): Loss/seq after 01100 batchs: 590.46826171875
INFO:root:Train (Epoch 208): Loss/seq after 01150 batchs: 575.5707397460938
INFO:root:Train (Epoch 208): Loss/seq after 01200 batchs: 579.1785278320312
INFO:root:Train (Epoch 208): Loss/seq after 01250 batchs: 576.3426513671875
INFO:root:Train (Epoch 208): Loss/seq after 01300 batchs: 566.3844604492188
INFO:root:Train (Epoch 208): Loss/seq after 01350 batchs: 558.3964233398438
INFO:root:Train (Epoch 208): Loss/seq after 01400 batchs: 562.287109375
INFO:root:Train (Epoch 208): Loss/seq after 01450 batchs: 563.6549072265625
INFO:root:Train (Epoch 208): Loss/seq after 01500 batchs: 569.87548828125
INFO:root:Train (Epoch 208): Loss/seq after 01550 batchs: 571.7445678710938
INFO:root:Train (Epoch 208): Loss/seq after 01600 batchs: 566.6072387695312
INFO:root:Train (Epoch 208): Loss/seq after 01650 batchs: 563.628173828125
INFO:root:Train (Epoch 208): Loss/seq after 01700 batchs: 565.8156127929688
INFO:root:Train (Epoch 208): Loss/seq after 01750 batchs: 563.177734375
INFO:root:Train (Epoch 208): Loss/seq after 01800 batchs: 560.4238891601562
INFO:root:Train (Epoch 208): Loss/seq after 01850 batchs: 556.6091918945312
INFO:root:Train (Epoch 208): Loss/seq after 01900 batchs: 555.1668090820312
INFO:root:Train (Epoch 208): Loss/seq after 01950 batchs: 553.5746459960938
INFO:root:Train (Epoch 208): Loss/seq after 02000 batchs: 552.6304321289062
INFO:root:Train (Epoch 208): Loss/seq after 02050 batchs: 551.0927734375
INFO:root:Train (Epoch 208): Loss/seq after 02100 batchs: 548.231689453125
INFO:root:Train (Epoch 208): Loss/seq after 02150 batchs: 546.01171875
INFO:root:Train (Epoch 208): Loss/seq after 02200 batchs: 542.9883422851562
INFO:root:Train (Epoch 208): Loss/seq after 02250 batchs: 541.5953369140625
INFO:root:Train (Epoch 208): Loss/seq after 02300 batchs: 541.1142578125
INFO:root:Train (Epoch 208): Loss/seq after 02350 batchs: 536.7943725585938
INFO:root:Train (Epoch 208): Loss/seq after 02400 batchs: 538.16748046875
INFO:root:Train (Epoch 208): Loss/seq after 02450 batchs: 533.5753173828125
INFO:root:Train (Epoch 208): Loss/seq after 02500 batchs: 525.6287231445312
INFO:root:Train (Epoch 208): Loss/seq after 02550 batchs: 519.5626831054688
INFO:root:Train (Epoch 208): Loss/seq after 02600 batchs: 517.8197631835938
INFO:root:Train (Epoch 208): Loss/seq after 02650 batchs: 514.81591796875
INFO:root:Train (Epoch 208): Loss/seq after 02700 batchs: 512.4602661132812
INFO:root:Train (Epoch 208): Loss/seq after 02750 batchs: 509.43499755859375
INFO:root:Train (Epoch 208): Loss/seq after 02800 batchs: 509.3578186035156
INFO:root:Train (Epoch 208): Loss/seq after 02850 batchs: 509.0072326660156
INFO:root:Train (Epoch 208): Loss/seq after 02900 batchs: 510.6217041015625
INFO:root:Train (Epoch 208): Loss/seq after 02950 batchs: 509.9313049316406
INFO:root:Train (Epoch 208): Loss/seq after 03000 batchs: 514.9304809570312
INFO:root:Train (Epoch 208): Loss/seq after 03050 batchs: 517.2926025390625
INFO:root:Train (Epoch 208): Loss/seq after 03100 batchs: 520.50341796875
INFO:root:Train (Epoch 208): Loss/seq after 03150 batchs: 525.4293823242188
INFO:root:Train (Epoch 208): Loss/seq after 03200 batchs: 527.519287109375
INFO:root:Train (Epoch 208): Loss/seq after 03250 batchs: 530.1651000976562
INFO:root:Train (Epoch 208): Loss/seq after 03300 batchs: 529.8108520507812
INFO:root:Train (Epoch 208): Loss/seq after 03350 batchs: 528.9705810546875
INFO:root:Train (Epoch 208): Loss/seq after 03400 batchs: 525.3158569335938
INFO:root:Train (Epoch 208): Loss/seq after 03450 batchs: 523.6937866210938
INFO:root:Train (Epoch 208): Loss/seq after 03500 batchs: 524.050537109375
INFO:root:Train (Epoch 208): Loss/seq after 03550 batchs: 521.43994140625
INFO:root:Train (Epoch 208): Loss/seq after 03600 batchs: 528.9630737304688
INFO:root:Train (Epoch 208): Loss/seq after 03650 batchs: 526.7608642578125
INFO:root:Train (Epoch 208): Loss/seq after 03700 batchs: 529.00390625
INFO:root:Train (Epoch 208): Loss/seq after 03750 batchs: 533.3165283203125
INFO:root:Train (Epoch 208): Loss/seq after 03800 batchs: 531.2326049804688
INFO:root:Train (Epoch 208): Loss/seq after 03850 batchs: 529.8350830078125
INFO:root:Train (Epoch 208): Loss/seq after 03900 batchs: 533.5004272460938
INFO:root:Train (Epoch 208): Loss/seq after 03950 batchs: 537.4025268554688
INFO:root:Train (Epoch 208): Loss/seq after 04000 batchs: 533.6115112304688
INFO:root:Train (Epoch 208): Loss/seq after 04050 batchs: 530.208740234375
INFO:root:Train (Epoch 208): Loss/seq after 04100 batchs: 528.665283203125
INFO:root:Train (Epoch 208): Loss/seq after 04150 batchs: 528.5595092773438
INFO:root:Train (Epoch 208): Loss/seq after 04200 batchs: 526.6722412109375
INFO:root:Train (Epoch 208): Loss/seq after 04250 batchs: 524.9013671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 208): Loss/seq after 00000 batches: 489.2552795410156
INFO:root:# Valid (Epoch 208): Loss/seq after 00050 batches: 699.90380859375
INFO:root:# Valid (Epoch 208): Loss/seq after 00100 batches: 718.2806396484375
INFO:root:# Valid (Epoch 208): Loss/seq after 00150 batches: 540.3574829101562
INFO:root:# Valid (Epoch 208): Loss/seq after 00200 batches: 497.5877380371094
INFO:root:Artifacts: Make stick videos for epoch 208
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_208_on_20220423_133325.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_208_index_927_on_20220423_133325.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 209): Loss/seq after 00000 batchs: 1122.2008056640625
INFO:root:Train (Epoch 209): Loss/seq after 00050 batchs: 762.0128784179688
INFO:root:Train (Epoch 209): Loss/seq after 00100 batchs: 764.3178100585938
INFO:root:Train (Epoch 209): Loss/seq after 00150 batchs: 672.8427124023438
INFO:root:Train (Epoch 209): Loss/seq after 00200 batchs: 769.2459106445312
INFO:root:Train (Epoch 209): Loss/seq after 00250 batchs: 821.75537109375
INFO:root:Train (Epoch 209): Loss/seq after 00300 batchs: 820.2564086914062
INFO:root:Train (Epoch 209): Loss/seq after 00350 batchs: 771.513427734375
INFO:root:Train (Epoch 209): Loss/seq after 00400 batchs: 780.2122802734375
INFO:root:Train (Epoch 209): Loss/seq after 00450 batchs: 765.4103393554688
INFO:root:Train (Epoch 209): Loss/seq after 00500 batchs: 743.0399169921875
INFO:root:Train (Epoch 209): Loss/seq after 00550 batchs: 719.7449340820312
INFO:root:Train (Epoch 209): Loss/seq after 00600 batchs: 694.724609375
INFO:root:Train (Epoch 209): Loss/seq after 00650 batchs: 680.3690185546875
INFO:root:Train (Epoch 209): Loss/seq after 00700 batchs: 659.1240234375
INFO:root:Train (Epoch 209): Loss/seq after 00750 batchs: 665.48828125
INFO:root:Train (Epoch 209): Loss/seq after 00800 batchs: 663.7321166992188
INFO:root:Train (Epoch 209): Loss/seq after 00850 batchs: 642.276123046875
INFO:root:Train (Epoch 209): Loss/seq after 00900 batchs: 624.6828002929688
INFO:root:Train (Epoch 209): Loss/seq after 00950 batchs: 626.75830078125
INFO:root:Train (Epoch 209): Loss/seq after 01000 batchs: 618.8517456054688
INFO:root:Train (Epoch 209): Loss/seq after 01050 batchs: 606.6896362304688
INFO:root:Train (Epoch 209): Loss/seq after 01100 batchs: 596.6593017578125
INFO:root:Train (Epoch 209): Loss/seq after 01150 batchs: 581.8755493164062
INFO:root:Train (Epoch 209): Loss/seq after 01200 batchs: 584.6873168945312
INFO:root:Train (Epoch 209): Loss/seq after 01250 batchs: 581.5459594726562
INFO:root:Train (Epoch 209): Loss/seq after 01300 batchs: 571.1939086914062
INFO:root:Train (Epoch 209): Loss/seq after 01350 batchs: 562.5510864257812
INFO:root:Train (Epoch 209): Loss/seq after 01400 batchs: 566.41943359375
INFO:root:Train (Epoch 209): Loss/seq after 01450 batchs: 567.5128784179688
INFO:root:Train (Epoch 209): Loss/seq after 01500 batchs: 573.3951416015625
INFO:root:Train (Epoch 209): Loss/seq after 01550 batchs: 575.35400390625
INFO:root:Train (Epoch 209): Loss/seq after 01600 batchs: 569.9736938476562
INFO:root:Train (Epoch 209): Loss/seq after 01650 batchs: 567.2000732421875
INFO:root:Train (Epoch 209): Loss/seq after 01700 batchs: 569.7030639648438
INFO:root:Train (Epoch 209): Loss/seq after 01750 batchs: 566.9884643554688
INFO:root:Train (Epoch 209): Loss/seq after 01800 batchs: 564.0714721679688
INFO:root:Train (Epoch 209): Loss/seq after 01850 batchs: 560.0069580078125
INFO:root:Train (Epoch 209): Loss/seq after 01900 batchs: 558.591796875
INFO:root:Train (Epoch 209): Loss/seq after 01950 batchs: 556.8713989257812
INFO:root:Train (Epoch 209): Loss/seq after 02000 batchs: 555.8366088867188
INFO:root:Train (Epoch 209): Loss/seq after 02050 batchs: 554.267333984375
INFO:root:Train (Epoch 209): Loss/seq after 02100 batchs: 551.1978759765625
INFO:root:Train (Epoch 209): Loss/seq after 02150 batchs: 548.8857421875
INFO:root:Train (Epoch 209): Loss/seq after 02200 batchs: 545.8255615234375
INFO:root:Train (Epoch 209): Loss/seq after 02250 batchs: 544.5746459960938
INFO:root:Train (Epoch 209): Loss/seq after 02300 batchs: 543.6049194335938
INFO:root:Train (Epoch 209): Loss/seq after 02350 batchs: 539.2893676757812
INFO:root:Train (Epoch 209): Loss/seq after 02400 batchs: 540.7930297851562
INFO:root:Train (Epoch 209): Loss/seq after 02450 batchs: 536.207763671875
INFO:root:Train (Epoch 209): Loss/seq after 02500 batchs: 528.2675170898438
INFO:root:Train (Epoch 209): Loss/seq after 02550 batchs: 522.125732421875
INFO:root:Train (Epoch 209): Loss/seq after 02600 batchs: 520.0824584960938
INFO:root:Train (Epoch 209): Loss/seq after 02650 batchs: 517.1793823242188
INFO:root:Train (Epoch 209): Loss/seq after 02700 batchs: 515.195068359375
INFO:root:Train (Epoch 209): Loss/seq after 02750 batchs: 511.36187744140625
INFO:root:Train (Epoch 209): Loss/seq after 02800 batchs: 512.2078857421875
INFO:root:Train (Epoch 209): Loss/seq after 02850 batchs: 511.9283142089844
INFO:root:Train (Epoch 209): Loss/seq after 02900 batchs: 513.14111328125
INFO:root:Train (Epoch 209): Loss/seq after 02950 batchs: 512.4801635742188
INFO:root:Train (Epoch 209): Loss/seq after 03000 batchs: 517.5358276367188
INFO:root:Train (Epoch 209): Loss/seq after 03050 batchs: 519.3392333984375
INFO:root:Train (Epoch 209): Loss/seq after 03100 batchs: 522.3120727539062
INFO:root:Train (Epoch 209): Loss/seq after 03150 batchs: 527.75390625
INFO:root:Train (Epoch 209): Loss/seq after 03200 batchs: 529.9046630859375
INFO:root:Train (Epoch 209): Loss/seq after 03250 batchs: 532.7985229492188
INFO:root:Train (Epoch 209): Loss/seq after 03300 batchs: 531.8190307617188
INFO:root:Train (Epoch 209): Loss/seq after 03350 batchs: 531.1233520507812
INFO:root:Train (Epoch 209): Loss/seq after 03400 batchs: 527.4741821289062
INFO:root:Train (Epoch 209): Loss/seq after 03450 batchs: 525.8931274414062
INFO:root:Train (Epoch 209): Loss/seq after 03500 batchs: 526.1434936523438
INFO:root:Train (Epoch 209): Loss/seq after 03550 batchs: 523.2415771484375
INFO:root:Train (Epoch 209): Loss/seq after 03600 batchs: 530.7315063476562
INFO:root:Train (Epoch 209): Loss/seq after 03650 batchs: 528.4071655273438
INFO:root:Train (Epoch 209): Loss/seq after 03700 batchs: 530.6610717773438
INFO:root:Train (Epoch 209): Loss/seq after 03750 batchs: 534.7948608398438
INFO:root:Train (Epoch 209): Loss/seq after 03800 batchs: 532.625244140625
INFO:root:Train (Epoch 209): Loss/seq after 03850 batchs: 531.2688598632812
INFO:root:Train (Epoch 209): Loss/seq after 03900 batchs: 534.4480590820312
INFO:root:Train (Epoch 209): Loss/seq after 03950 batchs: 537.472900390625
INFO:root:Train (Epoch 209): Loss/seq after 04000 batchs: 533.7459106445312
INFO:root:Train (Epoch 209): Loss/seq after 04050 batchs: 530.3286743164062
INFO:root:Train (Epoch 209): Loss/seq after 04100 batchs: 528.7467651367188
INFO:root:Train (Epoch 209): Loss/seq after 04150 batchs: 528.3937377929688
INFO:root:Train (Epoch 209): Loss/seq after 04200 batchs: 526.5181274414062
INFO:root:Train (Epoch 209): Loss/seq after 04250 batchs: 524.772705078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 209): Loss/seq after 00000 batches: 550.2955932617188
INFO:root:# Valid (Epoch 209): Loss/seq after 00050 batches: 690.0426635742188
INFO:root:# Valid (Epoch 209): Loss/seq after 00100 batches: 700.015869140625
INFO:root:# Valid (Epoch 209): Loss/seq after 00150 batches: 528.9041137695312
INFO:root:# Valid (Epoch 209): Loss/seq after 00200 batches: 488.93365478515625
INFO:root:Artifacts: Make stick videos for epoch 209
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_209_on_20220423_133809.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_209_index_1240_on_20220423_133809.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 210): Loss/seq after 00000 batchs: 1033.4903564453125
INFO:root:Train (Epoch 210): Loss/seq after 00050 batchs: 781.955322265625
INFO:root:Train (Epoch 210): Loss/seq after 00100 batchs: 770.775146484375
INFO:root:Train (Epoch 210): Loss/seq after 00150 batchs: 674.1414794921875
INFO:root:Train (Epoch 210): Loss/seq after 00200 batchs: 762.4918823242188
INFO:root:Train (Epoch 210): Loss/seq after 00250 batchs: 817.921630859375
INFO:root:Train (Epoch 210): Loss/seq after 00300 batchs: 817.5538940429688
INFO:root:Train (Epoch 210): Loss/seq after 00350 batchs: 767.5952758789062
INFO:root:Train (Epoch 210): Loss/seq after 00400 batchs: 775.0234985351562
INFO:root:Train (Epoch 210): Loss/seq after 00450 batchs: 761.0942993164062
INFO:root:Train (Epoch 210): Loss/seq after 00500 batchs: 740.8480224609375
INFO:root:Train (Epoch 210): Loss/seq after 00550 batchs: 718.1533813476562
INFO:root:Train (Epoch 210): Loss/seq after 00600 batchs: 692.4848022460938
INFO:root:Train (Epoch 210): Loss/seq after 00650 batchs: 678.3590087890625
INFO:root:Train (Epoch 210): Loss/seq after 00700 batchs: 655.4829711914062
INFO:root:Train (Epoch 210): Loss/seq after 00750 batchs: 663.09765625
INFO:root:Train (Epoch 210): Loss/seq after 00800 batchs: 661.1643676757812
INFO:root:Train (Epoch 210): Loss/seq after 00850 batchs: 640.1926879882812
INFO:root:Train (Epoch 210): Loss/seq after 00900 batchs: 622.192138671875
INFO:root:Train (Epoch 210): Loss/seq after 00950 batchs: 623.861572265625
INFO:root:Train (Epoch 210): Loss/seq after 01000 batchs: 615.6422729492188
INFO:root:Train (Epoch 210): Loss/seq after 01050 batchs: 602.5418701171875
INFO:root:Train (Epoch 210): Loss/seq after 01100 batchs: 591.3026733398438
INFO:root:Train (Epoch 210): Loss/seq after 01150 batchs: 576.634033203125
INFO:root:Train (Epoch 210): Loss/seq after 01200 batchs: 579.7166137695312
INFO:root:Train (Epoch 210): Loss/seq after 01250 batchs: 576.6870727539062
INFO:root:Train (Epoch 210): Loss/seq after 01300 batchs: 566.7384033203125
INFO:root:Train (Epoch 210): Loss/seq after 01350 batchs: 557.7929077148438
INFO:root:Train (Epoch 210): Loss/seq after 01400 batchs: 562.3922119140625
INFO:root:Train (Epoch 210): Loss/seq after 01450 batchs: 563.7037963867188
INFO:root:Train (Epoch 210): Loss/seq after 01500 batchs: 569.5642700195312
INFO:root:Train (Epoch 210): Loss/seq after 01550 batchs: 571.3343505859375
INFO:root:Train (Epoch 210): Loss/seq after 01600 batchs: 565.9512939453125
INFO:root:Train (Epoch 210): Loss/seq after 01650 batchs: 562.7980346679688
INFO:root:Train (Epoch 210): Loss/seq after 01700 batchs: 565.0198364257812
INFO:root:Train (Epoch 210): Loss/seq after 01750 batchs: 562.2697143554688
INFO:root:Train (Epoch 210): Loss/seq after 01800 batchs: 559.423828125
INFO:root:Train (Epoch 210): Loss/seq after 01850 batchs: 555.43408203125
INFO:root:Train (Epoch 210): Loss/seq after 01900 batchs: 553.8605346679688
INFO:root:Train (Epoch 210): Loss/seq after 01950 batchs: 551.8706665039062
INFO:root:Train (Epoch 210): Loss/seq after 02000 batchs: 550.8714599609375
INFO:root:Train (Epoch 210): Loss/seq after 02050 batchs: 549.0732421875
INFO:root:Train (Epoch 210): Loss/seq after 02100 batchs: 545.9656982421875
INFO:root:Train (Epoch 210): Loss/seq after 02150 batchs: 543.7501220703125
INFO:root:Train (Epoch 210): Loss/seq after 02200 batchs: 540.7459716796875
INFO:root:Train (Epoch 210): Loss/seq after 02250 batchs: 539.6724853515625
INFO:root:Train (Epoch 210): Loss/seq after 02300 batchs: 538.0738525390625
INFO:root:Train (Epoch 210): Loss/seq after 02350 batchs: 533.668701171875
INFO:root:Train (Epoch 210): Loss/seq after 02400 batchs: 534.824951171875
INFO:root:Train (Epoch 210): Loss/seq after 02450 batchs: 530.2227783203125
INFO:root:Train (Epoch 210): Loss/seq after 02500 batchs: 522.3607788085938
INFO:root:Train (Epoch 210): Loss/seq after 02550 batchs: 516.253173828125
INFO:root:Train (Epoch 210): Loss/seq after 02600 batchs: 514.071533203125
INFO:root:Train (Epoch 210): Loss/seq after 02650 batchs: 511.0046691894531
INFO:root:Train (Epoch 210): Loss/seq after 02700 batchs: 508.6412048339844
INFO:root:Train (Epoch 210): Loss/seq after 02750 batchs: 505.1864929199219
INFO:root:Train (Epoch 210): Loss/seq after 02800 batchs: 505.8790283203125
INFO:root:Train (Epoch 210): Loss/seq after 02850 batchs: 505.58782958984375
INFO:root:Train (Epoch 210): Loss/seq after 02900 batchs: 507.07818603515625
INFO:root:Train (Epoch 210): Loss/seq after 02950 batchs: 506.4102478027344
INFO:root:Train (Epoch 210): Loss/seq after 03000 batchs: 511.1192626953125
INFO:root:Train (Epoch 210): Loss/seq after 03050 batchs: 513.0985717773438
INFO:root:Train (Epoch 210): Loss/seq after 03100 batchs: 516.2421875
INFO:root:Train (Epoch 210): Loss/seq after 03150 batchs: 521.28466796875
INFO:root:Train (Epoch 210): Loss/seq after 03200 batchs: 523.0999755859375
INFO:root:Train (Epoch 210): Loss/seq after 03250 batchs: 525.7527465820312
INFO:root:Train (Epoch 210): Loss/seq after 03300 batchs: 525.3720092773438
INFO:root:Train (Epoch 210): Loss/seq after 03350 batchs: 524.7819213867188
INFO:root:Train (Epoch 210): Loss/seq after 03400 batchs: 521.2520141601562
INFO:root:Train (Epoch 210): Loss/seq after 03450 batchs: 519.6848754882812
INFO:root:Train (Epoch 210): Loss/seq after 03500 batchs: 519.8373413085938
INFO:root:Train (Epoch 210): Loss/seq after 03550 batchs: 517.2485961914062
INFO:root:Train (Epoch 210): Loss/seq after 03600 batchs: 525.2686157226562
INFO:root:Train (Epoch 210): Loss/seq after 03650 batchs: 522.9782104492188
INFO:root:Train (Epoch 210): Loss/seq after 03700 batchs: 524.8982543945312
INFO:root:Train (Epoch 210): Loss/seq after 03750 batchs: 529.0018920898438
INFO:root:Train (Epoch 210): Loss/seq after 03800 batchs: 526.8987426757812
INFO:root:Train (Epoch 210): Loss/seq after 03850 batchs: 525.8724975585938
INFO:root:Train (Epoch 210): Loss/seq after 03900 batchs: 529.0036010742188
INFO:root:Train (Epoch 210): Loss/seq after 03950 batchs: 532.4854736328125
INFO:root:Train (Epoch 210): Loss/seq after 04000 batchs: 528.73486328125
INFO:root:Train (Epoch 210): Loss/seq after 04050 batchs: 525.3646850585938
INFO:root:Train (Epoch 210): Loss/seq after 04100 batchs: 523.8594360351562
INFO:root:Train (Epoch 210): Loss/seq after 04150 batchs: 523.555419921875
INFO:root:Train (Epoch 210): Loss/seq after 04200 batchs: 521.7369384765625
INFO:root:Train (Epoch 210): Loss/seq after 04250 batchs: 520.2241821289062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 210): Loss/seq after 00000 batches: 647.918701171875
INFO:root:# Valid (Epoch 210): Loss/seq after 00050 batches: 710.8983154296875
INFO:root:# Valid (Epoch 210): Loss/seq after 00100 batches: 755.9221801757812
INFO:root:# Valid (Epoch 210): Loss/seq after 00150 batches: 571.5748291015625
INFO:root:# Valid (Epoch 210): Loss/seq after 00200 batches: 523.5306396484375
INFO:root:Artifacts: Make stick videos for epoch 210
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_210_on_20220423_134253.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_210_index_640_on_20220423_134253.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 211): Loss/seq after 00000 batchs: 1260.273193359375
INFO:root:Train (Epoch 211): Loss/seq after 00050 batchs: 766.0695190429688
INFO:root:Train (Epoch 211): Loss/seq after 00100 batchs: 765.7256469726562
INFO:root:Train (Epoch 211): Loss/seq after 00150 batchs: 670.1514892578125
INFO:root:Train (Epoch 211): Loss/seq after 00200 batchs: 745.9775390625
INFO:root:Train (Epoch 211): Loss/seq after 00250 batchs: 805.6004638671875
INFO:root:Train (Epoch 211): Loss/seq after 00300 batchs: 809.108642578125
INFO:root:Train (Epoch 211): Loss/seq after 00350 batchs: 762.011474609375
INFO:root:Train (Epoch 211): Loss/seq after 00400 batchs: 763.4984130859375
INFO:root:Train (Epoch 211): Loss/seq after 00450 batchs: 750.9423217773438
INFO:root:Train (Epoch 211): Loss/seq after 00500 batchs: 728.1778564453125
INFO:root:Train (Epoch 211): Loss/seq after 00550 batchs: 706.8956909179688
INFO:root:Train (Epoch 211): Loss/seq after 00600 batchs: 681.8256225585938
INFO:root:Train (Epoch 211): Loss/seq after 00650 batchs: 668.1821899414062
INFO:root:Train (Epoch 211): Loss/seq after 00700 batchs: 648.3919677734375
INFO:root:Train (Epoch 211): Loss/seq after 00750 batchs: 655.3998413085938
INFO:root:Train (Epoch 211): Loss/seq after 00800 batchs: 654.3925170898438
INFO:root:Train (Epoch 211): Loss/seq after 00850 batchs: 633.5922241210938
INFO:root:Train (Epoch 211): Loss/seq after 00900 batchs: 615.88916015625
INFO:root:Train (Epoch 211): Loss/seq after 00950 batchs: 620.0030517578125
INFO:root:Train (Epoch 211): Loss/seq after 01000 batchs: 611.6201171875
INFO:root:Train (Epoch 211): Loss/seq after 01050 batchs: 599.0618896484375
INFO:root:Train (Epoch 211): Loss/seq after 01100 batchs: 587.2592163085938
INFO:root:Train (Epoch 211): Loss/seq after 01150 batchs: 572.6549682617188
INFO:root:Train (Epoch 211): Loss/seq after 01200 batchs: 575.3369140625
INFO:root:Train (Epoch 211): Loss/seq after 01250 batchs: 572.498291015625
INFO:root:Train (Epoch 211): Loss/seq after 01300 batchs: 562.31103515625
INFO:root:Train (Epoch 211): Loss/seq after 01350 batchs: 554.5345458984375
INFO:root:Train (Epoch 211): Loss/seq after 01400 batchs: 558.3958740234375
INFO:root:Train (Epoch 211): Loss/seq after 01450 batchs: 559.593505859375
INFO:root:Train (Epoch 211): Loss/seq after 01500 batchs: 565.6776733398438
INFO:root:Train (Epoch 211): Loss/seq after 01550 batchs: 567.3932495117188
INFO:root:Train (Epoch 211): Loss/seq after 01600 batchs: 562.2993774414062
INFO:root:Train (Epoch 211): Loss/seq after 01650 batchs: 559.38623046875
INFO:root:Train (Epoch 211): Loss/seq after 01700 batchs: 561.759521484375
INFO:root:Train (Epoch 211): Loss/seq after 01750 batchs: 559.0519409179688
INFO:root:Train (Epoch 211): Loss/seq after 01800 batchs: 556.227294921875
INFO:root:Train (Epoch 211): Loss/seq after 01850 batchs: 552.33642578125
INFO:root:Train (Epoch 211): Loss/seq after 01900 batchs: 550.64013671875
INFO:root:Train (Epoch 211): Loss/seq after 01950 batchs: 548.7156982421875
INFO:root:Train (Epoch 211): Loss/seq after 02000 batchs: 547.7073974609375
INFO:root:Train (Epoch 211): Loss/seq after 02050 batchs: 546.064453125
INFO:root:Train (Epoch 211): Loss/seq after 02100 batchs: 543.1014404296875
INFO:root:Train (Epoch 211): Loss/seq after 02150 batchs: 540.8272705078125
INFO:root:Train (Epoch 211): Loss/seq after 02200 batchs: 538.0382080078125
INFO:root:Train (Epoch 211): Loss/seq after 02250 batchs: 536.4749145507812
INFO:root:Train (Epoch 211): Loss/seq after 02300 batchs: 534.115234375
INFO:root:Train (Epoch 211): Loss/seq after 02350 batchs: 529.8291625976562
INFO:root:Train (Epoch 211): Loss/seq after 02400 batchs: 531.2926635742188
INFO:root:Train (Epoch 211): Loss/seq after 02450 batchs: 526.73583984375
INFO:root:Train (Epoch 211): Loss/seq after 02500 batchs: 518.9706420898438
INFO:root:Train (Epoch 211): Loss/seq after 02550 batchs: 513.0145263671875
INFO:root:Train (Epoch 211): Loss/seq after 02600 batchs: 511.0947570800781
INFO:root:Train (Epoch 211): Loss/seq after 02650 batchs: 508.1929931640625
INFO:root:Train (Epoch 211): Loss/seq after 02700 batchs: 505.99822998046875
INFO:root:Train (Epoch 211): Loss/seq after 02750 batchs: 502.2724609375
INFO:root:Train (Epoch 211): Loss/seq after 02800 batchs: 502.4764709472656
INFO:root:Train (Epoch 211): Loss/seq after 02850 batchs: 502.31646728515625
INFO:root:Train (Epoch 211): Loss/seq after 02900 batchs: 503.665771484375
INFO:root:Train (Epoch 211): Loss/seq after 02950 batchs: 503.0592041015625
INFO:root:Train (Epoch 211): Loss/seq after 03000 batchs: 508.020751953125
INFO:root:Train (Epoch 211): Loss/seq after 03050 batchs: 509.8690490722656
INFO:root:Train (Epoch 211): Loss/seq after 03100 batchs: 513.2888793945312
INFO:root:Train (Epoch 211): Loss/seq after 03150 batchs: 518.2349243164062
INFO:root:Train (Epoch 211): Loss/seq after 03200 batchs: 519.90625
INFO:root:Train (Epoch 211): Loss/seq after 03250 batchs: 523.1987915039062
INFO:root:Train (Epoch 211): Loss/seq after 03300 batchs: 522.7439575195312
INFO:root:Train (Epoch 211): Loss/seq after 03350 batchs: 522.344970703125
INFO:root:Train (Epoch 211): Loss/seq after 03400 batchs: 518.75439453125
INFO:root:Train (Epoch 211): Loss/seq after 03450 batchs: 517.2156372070312
INFO:root:Train (Epoch 211): Loss/seq after 03500 batchs: 517.3676147460938
INFO:root:Train (Epoch 211): Loss/seq after 03550 batchs: 514.6265258789062
INFO:root:Train (Epoch 211): Loss/seq after 03600 batchs: 522.1189575195312
INFO:root:Train (Epoch 211): Loss/seq after 03650 batchs: 519.8848266601562
INFO:root:Train (Epoch 211): Loss/seq after 03700 batchs: 521.892578125
INFO:root:Train (Epoch 211): Loss/seq after 03750 batchs: 525.9327392578125
INFO:root:Train (Epoch 211): Loss/seq after 03800 batchs: 523.8803100585938
INFO:root:Train (Epoch 211): Loss/seq after 03850 batchs: 522.512451171875
INFO:root:Train (Epoch 211): Loss/seq after 03900 batchs: 526.0438232421875
INFO:root:Train (Epoch 211): Loss/seq after 03950 batchs: 529.3485717773438
INFO:root:Train (Epoch 211): Loss/seq after 04000 batchs: 525.5850219726562
INFO:root:Train (Epoch 211): Loss/seq after 04050 batchs: 522.241943359375
INFO:root:Train (Epoch 211): Loss/seq after 04100 batchs: 520.7400512695312
INFO:root:Train (Epoch 211): Loss/seq after 04150 batchs: 520.4630126953125
INFO:root:Train (Epoch 211): Loss/seq after 04200 batchs: 518.7369384765625
INFO:root:Train (Epoch 211): Loss/seq after 04250 batchs: 516.9359130859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 211): Loss/seq after 00000 batches: 448.50347900390625
INFO:root:# Valid (Epoch 211): Loss/seq after 00050 batches: 683.9061279296875
INFO:root:# Valid (Epoch 211): Loss/seq after 00100 batches: 721.3043823242188
INFO:root:# Valid (Epoch 211): Loss/seq after 00150 batches: 544.5819702148438
INFO:root:# Valid (Epoch 211): Loss/seq after 00200 batches: 498.6986389160156
INFO:root:Artifacts: Make stick videos for epoch 211
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_211_on_20220423_134741.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_211_index_921_on_20220423_134741.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 212): Loss/seq after 00000 batchs: 1251.645751953125
INFO:root:Train (Epoch 212): Loss/seq after 00050 batchs: 790.5823364257812
INFO:root:Train (Epoch 212): Loss/seq after 00100 batchs: 771.239990234375
INFO:root:Train (Epoch 212): Loss/seq after 00150 batchs: 674.4066772460938
INFO:root:Train (Epoch 212): Loss/seq after 00200 batchs: 754.9453125
INFO:root:Train (Epoch 212): Loss/seq after 00250 batchs: 813.69775390625
INFO:root:Train (Epoch 212): Loss/seq after 00300 batchs: 816.9168701171875
INFO:root:Train (Epoch 212): Loss/seq after 00350 batchs: 767.4188232421875
INFO:root:Train (Epoch 212): Loss/seq after 00400 batchs: 770.5934448242188
INFO:root:Train (Epoch 212): Loss/seq after 00450 batchs: 757.4857177734375
INFO:root:Train (Epoch 212): Loss/seq after 00500 batchs: 735.3690795898438
INFO:root:Train (Epoch 212): Loss/seq after 00550 batchs: 712.6261596679688
INFO:root:Train (Epoch 212): Loss/seq after 00600 batchs: 688.5122680664062
INFO:root:Train (Epoch 212): Loss/seq after 00650 batchs: 675.417236328125
INFO:root:Train (Epoch 212): Loss/seq after 00700 batchs: 655.0997924804688
INFO:root:Train (Epoch 212): Loss/seq after 00750 batchs: 661.0518798828125
INFO:root:Train (Epoch 212): Loss/seq after 00800 batchs: 660.4478759765625
INFO:root:Train (Epoch 212): Loss/seq after 00850 batchs: 639.5235595703125
INFO:root:Train (Epoch 212): Loss/seq after 00900 batchs: 622.4759521484375
INFO:root:Train (Epoch 212): Loss/seq after 00950 batchs: 623.5360107421875
INFO:root:Train (Epoch 212): Loss/seq after 01000 batchs: 614.9295043945312
INFO:root:Train (Epoch 212): Loss/seq after 01050 batchs: 602.17724609375
INFO:root:Train (Epoch 212): Loss/seq after 01100 batchs: 591.7246704101562
INFO:root:Train (Epoch 212): Loss/seq after 01150 batchs: 577.5384521484375
INFO:root:Train (Epoch 212): Loss/seq after 01200 batchs: 581.2437133789062
INFO:root:Train (Epoch 212): Loss/seq after 01250 batchs: 578.9520263671875
INFO:root:Train (Epoch 212): Loss/seq after 01300 batchs: 569.0164184570312
INFO:root:Train (Epoch 212): Loss/seq after 01350 batchs: 560.658935546875
INFO:root:Train (Epoch 212): Loss/seq after 01400 batchs: 563.0465087890625
INFO:root:Train (Epoch 212): Loss/seq after 01450 batchs: 564.4719848632812
INFO:root:Train (Epoch 212): Loss/seq after 01500 batchs: 570.3428955078125
INFO:root:Train (Epoch 212): Loss/seq after 01550 batchs: 571.873291015625
INFO:root:Train (Epoch 212): Loss/seq after 01600 batchs: 566.5252685546875
INFO:root:Train (Epoch 212): Loss/seq after 01650 batchs: 563.3991088867188
INFO:root:Train (Epoch 212): Loss/seq after 01700 batchs: 565.5377807617188
INFO:root:Train (Epoch 212): Loss/seq after 01750 batchs: 562.7865600585938
INFO:root:Train (Epoch 212): Loss/seq after 01800 batchs: 559.6973266601562
INFO:root:Train (Epoch 212): Loss/seq after 01850 batchs: 555.7811889648438
INFO:root:Train (Epoch 212): Loss/seq after 01900 batchs: 553.9285278320312
INFO:root:Train (Epoch 212): Loss/seq after 01950 batchs: 552.376953125
INFO:root:Train (Epoch 212): Loss/seq after 02000 batchs: 551.3135986328125
INFO:root:Train (Epoch 212): Loss/seq after 02050 batchs: 549.4783935546875
INFO:root:Train (Epoch 212): Loss/seq after 02100 batchs: 546.4837036132812
INFO:root:Train (Epoch 212): Loss/seq after 02150 batchs: 544.100341796875
INFO:root:Train (Epoch 212): Loss/seq after 02200 batchs: 541.0090942382812
INFO:root:Train (Epoch 212): Loss/seq after 02250 batchs: 539.7115478515625
INFO:root:Train (Epoch 212): Loss/seq after 02300 batchs: 537.5117797851562
INFO:root:Train (Epoch 212): Loss/seq after 02350 batchs: 532.974853515625
INFO:root:Train (Epoch 212): Loss/seq after 02400 batchs: 534.28662109375
INFO:root:Train (Epoch 212): Loss/seq after 02450 batchs: 529.720703125
INFO:root:Train (Epoch 212): Loss/seq after 02500 batchs: 521.8277587890625
INFO:root:Train (Epoch 212): Loss/seq after 02550 batchs: 515.7523193359375
INFO:root:Train (Epoch 212): Loss/seq after 02600 batchs: 513.9727783203125
INFO:root:Train (Epoch 212): Loss/seq after 02650 batchs: 510.98980712890625
INFO:root:Train (Epoch 212): Loss/seq after 02700 batchs: 508.6851501464844
INFO:root:Train (Epoch 212): Loss/seq after 02750 batchs: 505.4215393066406
INFO:root:Train (Epoch 212): Loss/seq after 02800 batchs: 506.4202880859375
INFO:root:Train (Epoch 212): Loss/seq after 02850 batchs: 505.9330139160156
INFO:root:Train (Epoch 212): Loss/seq after 02900 batchs: 507.4707336425781
INFO:root:Train (Epoch 212): Loss/seq after 02950 batchs: 506.7335205078125
INFO:root:Train (Epoch 212): Loss/seq after 03000 batchs: 511.7261047363281
INFO:root:Train (Epoch 212): Loss/seq after 03050 batchs: 513.3992309570312
INFO:root:Train (Epoch 212): Loss/seq after 03100 batchs: 515.9734497070312
INFO:root:Train (Epoch 212): Loss/seq after 03150 batchs: 520.301025390625
INFO:root:Train (Epoch 212): Loss/seq after 03200 batchs: 521.6603393554688
INFO:root:Train (Epoch 212): Loss/seq after 03250 batchs: 524.73974609375
INFO:root:Train (Epoch 212): Loss/seq after 03300 batchs: 524.1863403320312
INFO:root:Train (Epoch 212): Loss/seq after 03350 batchs: 523.5859375
INFO:root:Train (Epoch 212): Loss/seq after 03400 batchs: 520.0328369140625
INFO:root:Train (Epoch 212): Loss/seq after 03450 batchs: 518.4166259765625
INFO:root:Train (Epoch 212): Loss/seq after 03500 batchs: 519.1917724609375
INFO:root:Train (Epoch 212): Loss/seq after 03550 batchs: 516.7233276367188
INFO:root:Train (Epoch 212): Loss/seq after 03600 batchs: 524.6085815429688
INFO:root:Train (Epoch 212): Loss/seq after 03650 batchs: 522.3737182617188
INFO:root:Train (Epoch 212): Loss/seq after 03700 batchs: 524.5044555664062
INFO:root:Train (Epoch 212): Loss/seq after 03750 batchs: 528.6453247070312
INFO:root:Train (Epoch 212): Loss/seq after 03800 batchs: 526.517333984375
INFO:root:Train (Epoch 212): Loss/seq after 03850 batchs: 525.1652221679688
INFO:root:Train (Epoch 212): Loss/seq after 03900 batchs: 528.5122680664062
INFO:root:Train (Epoch 212): Loss/seq after 03950 batchs: 531.61962890625
INFO:root:Train (Epoch 212): Loss/seq after 04000 batchs: 527.8289794921875
INFO:root:Train (Epoch 212): Loss/seq after 04050 batchs: 524.5048828125
INFO:root:Train (Epoch 212): Loss/seq after 04100 batchs: 522.9242553710938
INFO:root:Train (Epoch 212): Loss/seq after 04150 batchs: 522.6024780273438
INFO:root:Train (Epoch 212): Loss/seq after 04200 batchs: 520.6940307617188
INFO:root:Train (Epoch 212): Loss/seq after 04250 batchs: 518.9605102539062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 212): Loss/seq after 00000 batches: 412.4413146972656
INFO:root:# Valid (Epoch 212): Loss/seq after 00050 batches: 659.5335693359375
INFO:root:# Valid (Epoch 212): Loss/seq after 00100 batches: 697.0717163085938
INFO:root:# Valid (Epoch 212): Loss/seq after 00150 batches: 529.8228759765625
INFO:root:# Valid (Epoch 212): Loss/seq after 00200 batches: 486.3716125488281
INFO:root:Artifacts: Make stick videos for epoch 212
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_212_on_20220423_135244.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_212_index_1702_on_20220423_135244.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 213): Loss/seq after 00000 batchs: 1016.5402221679688
INFO:root:Train (Epoch 213): Loss/seq after 00050 batchs: 771.7098388671875
INFO:root:Train (Epoch 213): Loss/seq after 00100 batchs: 768.22021484375
INFO:root:Train (Epoch 213): Loss/seq after 00150 batchs: 672.3123168945312
INFO:root:Train (Epoch 213): Loss/seq after 00200 batchs: 753.7100830078125
INFO:root:Train (Epoch 213): Loss/seq after 00250 batchs: 807.744140625
INFO:root:Train (Epoch 213): Loss/seq after 00300 batchs: 808.86474609375
INFO:root:Train (Epoch 213): Loss/seq after 00350 batchs: 761.1320190429688
INFO:root:Train (Epoch 213): Loss/seq after 00400 batchs: 765.6809692382812
INFO:root:Train (Epoch 213): Loss/seq after 00450 batchs: 752.9498901367188
INFO:root:Train (Epoch 213): Loss/seq after 00500 batchs: 728.0396728515625
INFO:root:Train (Epoch 213): Loss/seq after 00550 batchs: 706.204833984375
INFO:root:Train (Epoch 213): Loss/seq after 00600 batchs: 682.0951538085938
INFO:root:Train (Epoch 213): Loss/seq after 00650 batchs: 670.9036254882812
INFO:root:Train (Epoch 213): Loss/seq after 00700 batchs: 651.4349975585938
INFO:root:Train (Epoch 213): Loss/seq after 00750 batchs: 655.636474609375
INFO:root:Train (Epoch 213): Loss/seq after 00800 batchs: 655.7014770507812
INFO:root:Train (Epoch 213): Loss/seq after 00850 batchs: 634.3706665039062
INFO:root:Train (Epoch 213): Loss/seq after 00900 batchs: 617.01416015625
INFO:root:Train (Epoch 213): Loss/seq after 00950 batchs: 618.08056640625
INFO:root:Train (Epoch 213): Loss/seq after 01000 batchs: 609.7012329101562
INFO:root:Train (Epoch 213): Loss/seq after 01050 batchs: 596.4298706054688
INFO:root:Train (Epoch 213): Loss/seq after 01100 batchs: 584.6383056640625
INFO:root:Train (Epoch 213): Loss/seq after 01150 batchs: 570.0560302734375
INFO:root:Train (Epoch 213): Loss/seq after 01200 batchs: 573.9168090820312
INFO:root:Train (Epoch 213): Loss/seq after 01250 batchs: 571.2625122070312
INFO:root:Train (Epoch 213): Loss/seq after 01300 batchs: 560.7108764648438
INFO:root:Train (Epoch 213): Loss/seq after 01350 batchs: 552.0028686523438
INFO:root:Train (Epoch 213): Loss/seq after 01400 batchs: 555.5176391601562
INFO:root:Train (Epoch 213): Loss/seq after 01450 batchs: 557.1742553710938
INFO:root:Train (Epoch 213): Loss/seq after 01500 batchs: 563.123046875
INFO:root:Train (Epoch 213): Loss/seq after 01550 batchs: 564.437744140625
INFO:root:Train (Epoch 213): Loss/seq after 01600 batchs: 559.3787231445312
INFO:root:Train (Epoch 213): Loss/seq after 01650 batchs: 556.5331420898438
INFO:root:Train (Epoch 213): Loss/seq after 01700 batchs: 558.915771484375
INFO:root:Train (Epoch 213): Loss/seq after 01750 batchs: 556.32177734375
INFO:root:Train (Epoch 213): Loss/seq after 01800 batchs: 553.3599243164062
INFO:root:Train (Epoch 213): Loss/seq after 01850 batchs: 549.3917846679688
INFO:root:Train (Epoch 213): Loss/seq after 01900 batchs: 547.2322387695312
INFO:root:Train (Epoch 213): Loss/seq after 01950 batchs: 545.1234130859375
INFO:root:Train (Epoch 213): Loss/seq after 02000 batchs: 544.2537231445312
INFO:root:Train (Epoch 213): Loss/seq after 02050 batchs: 542.7274780273438
INFO:root:Train (Epoch 213): Loss/seq after 02100 batchs: 539.8074340820312
INFO:root:Train (Epoch 213): Loss/seq after 02150 batchs: 537.5346069335938
INFO:root:Train (Epoch 213): Loss/seq after 02200 batchs: 534.5265502929688
INFO:root:Train (Epoch 213): Loss/seq after 02250 batchs: 533.1103515625
INFO:root:Train (Epoch 213): Loss/seq after 02300 batchs: 530.982177734375
INFO:root:Train (Epoch 213): Loss/seq after 02350 batchs: 526.6305541992188
INFO:root:Train (Epoch 213): Loss/seq after 02400 batchs: 528.0400390625
INFO:root:Train (Epoch 213): Loss/seq after 02450 batchs: 523.525390625
INFO:root:Train (Epoch 213): Loss/seq after 02500 batchs: 515.7210083007812
INFO:root:Train (Epoch 213): Loss/seq after 02550 batchs: 509.6171569824219
INFO:root:Train (Epoch 213): Loss/seq after 02600 batchs: 507.6952209472656
INFO:root:Train (Epoch 213): Loss/seq after 02650 batchs: 504.7792663574219
INFO:root:Train (Epoch 213): Loss/seq after 02700 batchs: 502.3841247558594
INFO:root:Train (Epoch 213): Loss/seq after 02750 batchs: 498.15631103515625
INFO:root:Train (Epoch 213): Loss/seq after 02800 batchs: 498.52252197265625
INFO:root:Train (Epoch 213): Loss/seq after 02850 batchs: 497.9987487792969
INFO:root:Train (Epoch 213): Loss/seq after 02900 batchs: 499.638671875
INFO:root:Train (Epoch 213): Loss/seq after 02950 batchs: 499.0671691894531
INFO:root:Train (Epoch 213): Loss/seq after 03000 batchs: 504.3466491699219
INFO:root:Train (Epoch 213): Loss/seq after 03050 batchs: 506.6353759765625
INFO:root:Train (Epoch 213): Loss/seq after 03100 batchs: 509.5907287597656
INFO:root:Train (Epoch 213): Loss/seq after 03150 batchs: 514.3807983398438
INFO:root:Train (Epoch 213): Loss/seq after 03200 batchs: 515.4853515625
INFO:root:Train (Epoch 213): Loss/seq after 03250 batchs: 519.4374389648438
INFO:root:Train (Epoch 213): Loss/seq after 03300 batchs: 518.8495483398438
INFO:root:Train (Epoch 213): Loss/seq after 03350 batchs: 517.9338989257812
INFO:root:Train (Epoch 213): Loss/seq after 03400 batchs: 514.3782958984375
INFO:root:Train (Epoch 213): Loss/seq after 03450 batchs: 512.962646484375
INFO:root:Train (Epoch 213): Loss/seq after 03500 batchs: 513.2817993164062
INFO:root:Train (Epoch 213): Loss/seq after 03550 batchs: 510.51947021484375
INFO:root:Train (Epoch 213): Loss/seq after 03600 batchs: 517.9654541015625
INFO:root:Train (Epoch 213): Loss/seq after 03650 batchs: 516.1281127929688
INFO:root:Train (Epoch 213): Loss/seq after 03700 batchs: 518.3675537109375
INFO:root:Train (Epoch 213): Loss/seq after 03750 batchs: 522.52001953125
INFO:root:Train (Epoch 213): Loss/seq after 03800 batchs: 520.5306396484375
INFO:root:Train (Epoch 213): Loss/seq after 03850 batchs: 519.717529296875
INFO:root:Train (Epoch 213): Loss/seq after 03900 batchs: 522.9215087890625
INFO:root:Train (Epoch 213): Loss/seq after 03950 batchs: 526.1182250976562
INFO:root:Train (Epoch 213): Loss/seq after 04000 batchs: 522.42724609375
INFO:root:Train (Epoch 213): Loss/seq after 04050 batchs: 519.17333984375
INFO:root:Train (Epoch 213): Loss/seq after 04100 batchs: 517.6714477539062
INFO:root:Train (Epoch 213): Loss/seq after 04150 batchs: 517.4218139648438
INFO:root:Train (Epoch 213): Loss/seq after 04200 batchs: 515.8367919921875
INFO:root:Train (Epoch 213): Loss/seq after 04250 batchs: 514.1177978515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 213): Loss/seq after 00000 batches: 577.3419189453125
INFO:root:# Valid (Epoch 213): Loss/seq after 00050 batches: 683.4490966796875
INFO:root:# Valid (Epoch 213): Loss/seq after 00100 batches: 724.1183471679688
INFO:root:# Valid (Epoch 213): Loss/seq after 00150 batches: 546.115234375
INFO:root:# Valid (Epoch 213): Loss/seq after 00200 batches: 497.1078796386719
INFO:root:Artifacts: Make stick videos for epoch 213
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_213_on_20220423_135728.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_213_index_1371_on_20220423_135728.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 214): Loss/seq after 00000 batchs: 1124.85498046875
INFO:root:Train (Epoch 214): Loss/seq after 00050 batchs: 777.2776489257812
INFO:root:Train (Epoch 214): Loss/seq after 00100 batchs: 780.531005859375
INFO:root:Train (Epoch 214): Loss/seq after 00150 batchs: 679.4200439453125
INFO:root:Train (Epoch 214): Loss/seq after 00200 batchs: 759.3573608398438
INFO:root:Train (Epoch 214): Loss/seq after 00250 batchs: 821.7164306640625
INFO:root:Train (Epoch 214): Loss/seq after 00300 batchs: 818.8634643554688
INFO:root:Train (Epoch 214): Loss/seq after 00350 batchs: 769.26806640625
INFO:root:Train (Epoch 214): Loss/seq after 00400 batchs: 775.31298828125
INFO:root:Train (Epoch 214): Loss/seq after 00450 batchs: 761.2673950195312
INFO:root:Train (Epoch 214): Loss/seq after 00500 batchs: 737.0344848632812
INFO:root:Train (Epoch 214): Loss/seq after 00550 batchs: 714.5676879882812
INFO:root:Train (Epoch 214): Loss/seq after 00600 batchs: 688.5858764648438
INFO:root:Train (Epoch 214): Loss/seq after 00650 batchs: 674.1383666992188
INFO:root:Train (Epoch 214): Loss/seq after 00700 batchs: 652.8753662109375
INFO:root:Train (Epoch 214): Loss/seq after 00750 batchs: 655.60693359375
INFO:root:Train (Epoch 214): Loss/seq after 00800 batchs: 654.7808837890625
INFO:root:Train (Epoch 214): Loss/seq after 00850 batchs: 633.8389892578125
INFO:root:Train (Epoch 214): Loss/seq after 00900 batchs: 616.78955078125
INFO:root:Train (Epoch 214): Loss/seq after 00950 batchs: 617.15380859375
INFO:root:Train (Epoch 214): Loss/seq after 01000 batchs: 608.6698608398438
INFO:root:Train (Epoch 214): Loss/seq after 01050 batchs: 596.06787109375
INFO:root:Train (Epoch 214): Loss/seq after 01100 batchs: 584.694580078125
INFO:root:Train (Epoch 214): Loss/seq after 01150 batchs: 569.9620971679688
INFO:root:Train (Epoch 214): Loss/seq after 01200 batchs: 573.4549560546875
INFO:root:Train (Epoch 214): Loss/seq after 01250 batchs: 570.9306640625
INFO:root:Train (Epoch 214): Loss/seq after 01300 batchs: 560.3267211914062
INFO:root:Train (Epoch 214): Loss/seq after 01350 batchs: 551.189453125
INFO:root:Train (Epoch 214): Loss/seq after 01400 batchs: 555.1084594726562
INFO:root:Train (Epoch 214): Loss/seq after 01450 batchs: 556.642578125
INFO:root:Train (Epoch 214): Loss/seq after 01500 batchs: 562.401123046875
INFO:root:Train (Epoch 214): Loss/seq after 01550 batchs: 563.8724365234375
INFO:root:Train (Epoch 214): Loss/seq after 01600 batchs: 558.8389282226562
INFO:root:Train (Epoch 214): Loss/seq after 01650 batchs: 555.8206787109375
INFO:root:Train (Epoch 214): Loss/seq after 01700 batchs: 557.9993286132812
INFO:root:Train (Epoch 214): Loss/seq after 01750 batchs: 555.2644653320312
INFO:root:Train (Epoch 214): Loss/seq after 01800 batchs: 552.3129272460938
INFO:root:Train (Epoch 214): Loss/seq after 01850 batchs: 548.3426513671875
INFO:root:Train (Epoch 214): Loss/seq after 01900 batchs: 547.0383911132812
INFO:root:Train (Epoch 214): Loss/seq after 01950 batchs: 545.1713256835938
INFO:root:Train (Epoch 214): Loss/seq after 02000 batchs: 544.2078857421875
INFO:root:Train (Epoch 214): Loss/seq after 02050 batchs: 542.5153198242188
INFO:root:Train (Epoch 214): Loss/seq after 02100 batchs: 539.5762329101562
INFO:root:Train (Epoch 214): Loss/seq after 02150 batchs: 537.303466796875
INFO:root:Train (Epoch 214): Loss/seq after 02200 batchs: 534.48388671875
INFO:root:Train (Epoch 214): Loss/seq after 02250 batchs: 533.3081665039062
INFO:root:Train (Epoch 214): Loss/seq after 02300 batchs: 530.4862060546875
INFO:root:Train (Epoch 214): Loss/seq after 02350 batchs: 526.062744140625
INFO:root:Train (Epoch 214): Loss/seq after 02400 batchs: 527.2674560546875
INFO:root:Train (Epoch 214): Loss/seq after 02450 batchs: 522.7264404296875
INFO:root:Train (Epoch 214): Loss/seq after 02500 batchs: 514.947265625
INFO:root:Train (Epoch 214): Loss/seq after 02550 batchs: 508.8440856933594
INFO:root:Train (Epoch 214): Loss/seq after 02600 batchs: 506.8788757324219
INFO:root:Train (Epoch 214): Loss/seq after 02650 batchs: 503.5840759277344
INFO:root:Train (Epoch 214): Loss/seq after 02700 batchs: 501.3606872558594
INFO:root:Train (Epoch 214): Loss/seq after 02750 batchs: 497.9198303222656
INFO:root:Train (Epoch 214): Loss/seq after 02800 batchs: 497.96600341796875
INFO:root:Train (Epoch 214): Loss/seq after 02850 batchs: 497.5864562988281
INFO:root:Train (Epoch 214): Loss/seq after 02900 batchs: 499.3126220703125
INFO:root:Train (Epoch 214): Loss/seq after 02950 batchs: 498.9445495605469
INFO:root:Train (Epoch 214): Loss/seq after 03000 batchs: 504.2864074707031
INFO:root:Train (Epoch 214): Loss/seq after 03050 batchs: 506.0080871582031
INFO:root:Train (Epoch 214): Loss/seq after 03100 batchs: 509.199462890625
INFO:root:Train (Epoch 214): Loss/seq after 03150 batchs: 513.4888916015625
INFO:root:Train (Epoch 214): Loss/seq after 03200 batchs: 514.6133422851562
INFO:root:Train (Epoch 214): Loss/seq after 03250 batchs: 517.3724975585938
INFO:root:Train (Epoch 214): Loss/seq after 03300 batchs: 516.7906494140625
INFO:root:Train (Epoch 214): Loss/seq after 03350 batchs: 515.9855346679688
INFO:root:Train (Epoch 214): Loss/seq after 03400 batchs: 512.6505126953125
INFO:root:Train (Epoch 214): Loss/seq after 03450 batchs: 510.92724609375
INFO:root:Train (Epoch 214): Loss/seq after 03500 batchs: 511.2947692871094
INFO:root:Train (Epoch 214): Loss/seq after 03550 batchs: 508.7166748046875
INFO:root:Train (Epoch 214): Loss/seq after 03600 batchs: 516.2509765625
INFO:root:Train (Epoch 214): Loss/seq after 03650 batchs: 514.2113647460938
INFO:root:Train (Epoch 214): Loss/seq after 03700 batchs: 516.1856689453125
INFO:root:Train (Epoch 214): Loss/seq after 03750 batchs: 520.3245239257812
INFO:root:Train (Epoch 214): Loss/seq after 03800 batchs: 518.307373046875
INFO:root:Train (Epoch 214): Loss/seq after 03850 batchs: 517.06787109375
INFO:root:Train (Epoch 214): Loss/seq after 03900 batchs: 520.4326782226562
INFO:root:Train (Epoch 214): Loss/seq after 03950 batchs: 523.6287841796875
INFO:root:Train (Epoch 214): Loss/seq after 04000 batchs: 519.9255981445312
INFO:root:Train (Epoch 214): Loss/seq after 04050 batchs: 516.6548461914062
INFO:root:Train (Epoch 214): Loss/seq after 04100 batchs: 515.1928100585938
INFO:root:Train (Epoch 214): Loss/seq after 04150 batchs: 514.8726196289062
INFO:root:Train (Epoch 214): Loss/seq after 04200 batchs: 513.0912475585938
INFO:root:Train (Epoch 214): Loss/seq after 04250 batchs: 511.5435791015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 214): Loss/seq after 00000 batches: 478.20208740234375
INFO:root:# Valid (Epoch 214): Loss/seq after 00050 batches: 685.4535522460938
INFO:root:# Valid (Epoch 214): Loss/seq after 00100 batches: 735.3820190429688
INFO:root:# Valid (Epoch 214): Loss/seq after 00150 batches: 555.0269775390625
INFO:root:# Valid (Epoch 214): Loss/seq after 00200 batches: 505.9200744628906
INFO:root:Artifacts: Make stick videos for epoch 214
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_214_on_20220423_140214.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_214_index_1252_on_20220423_140214.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 215): Loss/seq after 00000 batchs: 1035.7310791015625
INFO:root:Train (Epoch 215): Loss/seq after 00050 batchs: 771.4768676757812
INFO:root:Train (Epoch 215): Loss/seq after 00100 batchs: 759.34033203125
INFO:root:Train (Epoch 215): Loss/seq after 00150 batchs: 667.5177612304688
INFO:root:Train (Epoch 215): Loss/seq after 00200 batchs: 745.7704467773438
INFO:root:Train (Epoch 215): Loss/seq after 00250 batchs: 810.173095703125
INFO:root:Train (Epoch 215): Loss/seq after 00300 batchs: 809.4486083984375
INFO:root:Train (Epoch 215): Loss/seq after 00350 batchs: 760.842041015625
INFO:root:Train (Epoch 215): Loss/seq after 00400 batchs: 766.0559692382812
INFO:root:Train (Epoch 215): Loss/seq after 00450 batchs: 752.8720092773438
INFO:root:Train (Epoch 215): Loss/seq after 00500 batchs: 728.6588745117188
INFO:root:Train (Epoch 215): Loss/seq after 00550 batchs: 706.126953125
INFO:root:Train (Epoch 215): Loss/seq after 00600 batchs: 683.4658203125
INFO:root:Train (Epoch 215): Loss/seq after 00650 batchs: 672.1578979492188
INFO:root:Train (Epoch 215): Loss/seq after 00700 batchs: 651.0372314453125
INFO:root:Train (Epoch 215): Loss/seq after 00750 batchs: 659.07666015625
INFO:root:Train (Epoch 215): Loss/seq after 00800 batchs: 656.9288330078125
INFO:root:Train (Epoch 215): Loss/seq after 00850 batchs: 635.1749877929688
INFO:root:Train (Epoch 215): Loss/seq after 00900 batchs: 617.4307250976562
INFO:root:Train (Epoch 215): Loss/seq after 00950 batchs: 617.2282104492188
INFO:root:Train (Epoch 215): Loss/seq after 01000 batchs: 609.16015625
INFO:root:Train (Epoch 215): Loss/seq after 01050 batchs: 596.4251708984375
INFO:root:Train (Epoch 215): Loss/seq after 01100 batchs: 585.5203247070312
INFO:root:Train (Epoch 215): Loss/seq after 01150 batchs: 571.2560424804688
INFO:root:Train (Epoch 215): Loss/seq after 01200 batchs: 574.2391357421875
INFO:root:Train (Epoch 215): Loss/seq after 01250 batchs: 571.6307983398438
INFO:root:Train (Epoch 215): Loss/seq after 01300 batchs: 561.5969848632812
INFO:root:Train (Epoch 215): Loss/seq after 01350 batchs: 553.049072265625
INFO:root:Train (Epoch 215): Loss/seq after 01400 batchs: 557.02490234375
INFO:root:Train (Epoch 215): Loss/seq after 01450 batchs: 558.3704833984375
INFO:root:Train (Epoch 215): Loss/seq after 01500 batchs: 564.194091796875
INFO:root:Train (Epoch 215): Loss/seq after 01550 batchs: 566.31298828125
INFO:root:Train (Epoch 215): Loss/seq after 01600 batchs: 561.1724853515625
INFO:root:Train (Epoch 215): Loss/seq after 01650 batchs: 558.2990112304688
INFO:root:Train (Epoch 215): Loss/seq after 01700 batchs: 560.4598999023438
INFO:root:Train (Epoch 215): Loss/seq after 01750 batchs: 557.5684204101562
INFO:root:Train (Epoch 215): Loss/seq after 01800 batchs: 554.5526123046875
INFO:root:Train (Epoch 215): Loss/seq after 01850 batchs: 550.5022583007812
INFO:root:Train (Epoch 215): Loss/seq after 01900 batchs: 548.69189453125
INFO:root:Train (Epoch 215): Loss/seq after 01950 batchs: 546.6828002929688
INFO:root:Train (Epoch 215): Loss/seq after 02000 batchs: 545.7025756835938
INFO:root:Train (Epoch 215): Loss/seq after 02050 batchs: 543.890380859375
INFO:root:Train (Epoch 215): Loss/seq after 02100 batchs: 541.03515625
INFO:root:Train (Epoch 215): Loss/seq after 02150 batchs: 538.7117309570312
INFO:root:Train (Epoch 215): Loss/seq after 02200 batchs: 535.7843017578125
INFO:root:Train (Epoch 215): Loss/seq after 02250 batchs: 534.278076171875
INFO:root:Train (Epoch 215): Loss/seq after 02300 batchs: 532.0339965820312
INFO:root:Train (Epoch 215): Loss/seq after 02350 batchs: 527.5723876953125
INFO:root:Train (Epoch 215): Loss/seq after 02400 batchs: 528.8900756835938
INFO:root:Train (Epoch 215): Loss/seq after 02450 batchs: 524.3165283203125
INFO:root:Train (Epoch 215): Loss/seq after 02500 batchs: 516.4744873046875
INFO:root:Train (Epoch 215): Loss/seq after 02550 batchs: 510.20721435546875
INFO:root:Train (Epoch 215): Loss/seq after 02600 batchs: 508.3122863769531
INFO:root:Train (Epoch 215): Loss/seq after 02650 batchs: 505.2996520996094
INFO:root:Train (Epoch 215): Loss/seq after 02700 batchs: 503.1365966796875
INFO:root:Train (Epoch 215): Loss/seq after 02750 batchs: 499.0919494628906
INFO:root:Train (Epoch 215): Loss/seq after 02800 batchs: 499.2922668457031
INFO:root:Train (Epoch 215): Loss/seq after 02850 batchs: 499.1096496582031
INFO:root:Train (Epoch 215): Loss/seq after 02900 batchs: 500.59735107421875
INFO:root:Train (Epoch 215): Loss/seq after 02950 batchs: 500.15521240234375
INFO:root:Train (Epoch 215): Loss/seq after 03000 batchs: 505.37738037109375
INFO:root:Train (Epoch 215): Loss/seq after 03050 batchs: 507.510986328125
INFO:root:Train (Epoch 215): Loss/seq after 03100 batchs: 510.10284423828125
INFO:root:Train (Epoch 215): Loss/seq after 03150 batchs: 514.8833618164062
INFO:root:Train (Epoch 215): Loss/seq after 03200 batchs: 515.9923706054688
INFO:root:Train (Epoch 215): Loss/seq after 03250 batchs: 518.766845703125
INFO:root:Train (Epoch 215): Loss/seq after 03300 batchs: 518.1188354492188
INFO:root:Train (Epoch 215): Loss/seq after 03350 batchs: 517.1527099609375
INFO:root:Train (Epoch 215): Loss/seq after 03400 batchs: 513.6383666992188
INFO:root:Train (Epoch 215): Loss/seq after 03450 batchs: 512.0199584960938
INFO:root:Train (Epoch 215): Loss/seq after 03500 batchs: 512.6818237304688
INFO:root:Train (Epoch 215): Loss/seq after 03550 batchs: 510.3038635253906
INFO:root:Train (Epoch 215): Loss/seq after 03600 batchs: 517.6148681640625
INFO:root:Train (Epoch 215): Loss/seq after 03650 batchs: 515.4262084960938
INFO:root:Train (Epoch 215): Loss/seq after 03700 batchs: 517.5119018554688
INFO:root:Train (Epoch 215): Loss/seq after 03750 batchs: 521.7496948242188
INFO:root:Train (Epoch 215): Loss/seq after 03800 batchs: 519.68603515625
INFO:root:Train (Epoch 215): Loss/seq after 03850 batchs: 518.413330078125
INFO:root:Train (Epoch 215): Loss/seq after 03900 batchs: 521.6295166015625
INFO:root:Train (Epoch 215): Loss/seq after 03950 batchs: 525.2899780273438
INFO:root:Train (Epoch 215): Loss/seq after 04000 batchs: 521.4825439453125
INFO:root:Train (Epoch 215): Loss/seq after 04050 batchs: 518.2024536132812
INFO:root:Train (Epoch 215): Loss/seq after 04100 batchs: 516.6660766601562
INFO:root:Train (Epoch 215): Loss/seq after 04150 batchs: 516.4110717773438
INFO:root:Train (Epoch 215): Loss/seq after 04200 batchs: 514.6219482421875
INFO:root:Train (Epoch 215): Loss/seq after 04250 batchs: 512.9168701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 215): Loss/seq after 00000 batches: 458.3604736328125
INFO:root:# Valid (Epoch 215): Loss/seq after 00050 batches: 695.7977294921875
INFO:root:# Valid (Epoch 215): Loss/seq after 00100 batches: 734.6618041992188
INFO:root:# Valid (Epoch 215): Loss/seq after 00150 batches: 554.8402099609375
INFO:root:# Valid (Epoch 215): Loss/seq after 00200 batches: 509.07537841796875
INFO:root:Artifacts: Make stick videos for epoch 215
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_215_on_20220423_140724.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_215_index_823_on_20220423_140724.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 216): Loss/seq after 00000 batchs: 1303.1522216796875
INFO:root:Train (Epoch 216): Loss/seq after 00050 batchs: 745.0516967773438
INFO:root:Train (Epoch 216): Loss/seq after 00100 batchs: 747.1723022460938
INFO:root:Train (Epoch 216): Loss/seq after 00150 batchs: 657.200439453125
INFO:root:Train (Epoch 216): Loss/seq after 00200 batchs: 733.006103515625
INFO:root:Train (Epoch 216): Loss/seq after 00250 batchs: 795.8518676757812
INFO:root:Train (Epoch 216): Loss/seq after 00300 batchs: 798.1492309570312
INFO:root:Train (Epoch 216): Loss/seq after 00350 batchs: 750.0941162109375
INFO:root:Train (Epoch 216): Loss/seq after 00400 batchs: 758.7841796875
INFO:root:Train (Epoch 216): Loss/seq after 00450 batchs: 746.1649780273438
INFO:root:Train (Epoch 216): Loss/seq after 00500 batchs: 724.9087524414062
INFO:root:Train (Epoch 216): Loss/seq after 00550 batchs: 703.267822265625
INFO:root:Train (Epoch 216): Loss/seq after 00600 batchs: 678.1021118164062
INFO:root:Train (Epoch 216): Loss/seq after 00650 batchs: 662.1244506835938
INFO:root:Train (Epoch 216): Loss/seq after 00700 batchs: 639.9498291015625
INFO:root:Train (Epoch 216): Loss/seq after 00750 batchs: 646.4693603515625
INFO:root:Train (Epoch 216): Loss/seq after 00800 batchs: 645.348388671875
INFO:root:Train (Epoch 216): Loss/seq after 00850 batchs: 624.6763305664062
INFO:root:Train (Epoch 216): Loss/seq after 00900 batchs: 608.75244140625
INFO:root:Train (Epoch 216): Loss/seq after 00950 batchs: 609.5036010742188
INFO:root:Train (Epoch 216): Loss/seq after 01000 batchs: 600.8510131835938
INFO:root:Train (Epoch 216): Loss/seq after 01050 batchs: 588.3748168945312
INFO:root:Train (Epoch 216): Loss/seq after 01100 batchs: 576.9617309570312
INFO:root:Train (Epoch 216): Loss/seq after 01150 batchs: 562.7616577148438
INFO:root:Train (Epoch 216): Loss/seq after 01200 batchs: 565.94873046875
INFO:root:Train (Epoch 216): Loss/seq after 01250 batchs: 563.306396484375
INFO:root:Train (Epoch 216): Loss/seq after 01300 batchs: 552.96240234375
INFO:root:Train (Epoch 216): Loss/seq after 01350 batchs: 544.5330810546875
INFO:root:Train (Epoch 216): Loss/seq after 01400 batchs: 547.8359375
INFO:root:Train (Epoch 216): Loss/seq after 01450 batchs: 549.5291748046875
INFO:root:Train (Epoch 216): Loss/seq after 01500 batchs: 555.2836303710938
INFO:root:Train (Epoch 216): Loss/seq after 01550 batchs: 557.1458740234375
INFO:root:Train (Epoch 216): Loss/seq after 01600 batchs: 552.0662231445312
INFO:root:Train (Epoch 216): Loss/seq after 01650 batchs: 548.8033447265625
INFO:root:Train (Epoch 216): Loss/seq after 01700 batchs: 551.123779296875
INFO:root:Train (Epoch 216): Loss/seq after 01750 batchs: 548.4638061523438
INFO:root:Train (Epoch 216): Loss/seq after 01800 batchs: 545.76171875
INFO:root:Train (Epoch 216): Loss/seq after 01850 batchs: 541.8533935546875
INFO:root:Train (Epoch 216): Loss/seq after 01900 batchs: 540.39697265625
INFO:root:Train (Epoch 216): Loss/seq after 01950 batchs: 538.7365112304688
INFO:root:Train (Epoch 216): Loss/seq after 02000 batchs: 538.0458374023438
INFO:root:Train (Epoch 216): Loss/seq after 02050 batchs: 536.4403686523438
INFO:root:Train (Epoch 216): Loss/seq after 02100 batchs: 533.5652465820312
INFO:root:Train (Epoch 216): Loss/seq after 02150 batchs: 531.5233154296875
INFO:root:Train (Epoch 216): Loss/seq after 02200 batchs: 528.743896484375
INFO:root:Train (Epoch 216): Loss/seq after 02250 batchs: 527.8126831054688
INFO:root:Train (Epoch 216): Loss/seq after 02300 batchs: 526.28662109375
INFO:root:Train (Epoch 216): Loss/seq after 02350 batchs: 521.959716796875
INFO:root:Train (Epoch 216): Loss/seq after 02400 batchs: 523.5308837890625
INFO:root:Train (Epoch 216): Loss/seq after 02450 batchs: 518.9971923828125
INFO:root:Train (Epoch 216): Loss/seq after 02500 batchs: 511.25390625
INFO:root:Train (Epoch 216): Loss/seq after 02550 batchs: 505.3047790527344
INFO:root:Train (Epoch 216): Loss/seq after 02600 batchs: 503.15118408203125
INFO:root:Train (Epoch 216): Loss/seq after 02650 batchs: 500.0822448730469
INFO:root:Train (Epoch 216): Loss/seq after 02700 batchs: 497.7679748535156
INFO:root:Train (Epoch 216): Loss/seq after 02750 batchs: 493.6505126953125
INFO:root:Train (Epoch 216): Loss/seq after 02800 batchs: 493.8099670410156
INFO:root:Train (Epoch 216): Loss/seq after 02850 batchs: 493.4299011230469
INFO:root:Train (Epoch 216): Loss/seq after 02900 batchs: 494.9998474121094
INFO:root:Train (Epoch 216): Loss/seq after 02950 batchs: 494.5163879394531
INFO:root:Train (Epoch 216): Loss/seq after 03000 batchs: 499.4599914550781
INFO:root:Train (Epoch 216): Loss/seq after 03050 batchs: 501.14166259765625
INFO:root:Train (Epoch 216): Loss/seq after 03100 batchs: 504.07696533203125
INFO:root:Train (Epoch 216): Loss/seq after 03150 batchs: 508.3135681152344
INFO:root:Train (Epoch 216): Loss/seq after 03200 batchs: 509.666015625
INFO:root:Train (Epoch 216): Loss/seq after 03250 batchs: 512.5526733398438
INFO:root:Train (Epoch 216): Loss/seq after 03300 batchs: 512.2782592773438
INFO:root:Train (Epoch 216): Loss/seq after 03350 batchs: 511.8376159667969
INFO:root:Train (Epoch 216): Loss/seq after 03400 batchs: 508.50396728515625
INFO:root:Train (Epoch 216): Loss/seq after 03450 batchs: 507.0155029296875
INFO:root:Train (Epoch 216): Loss/seq after 03500 batchs: 507.2278747558594
INFO:root:Train (Epoch 216): Loss/seq after 03550 batchs: 504.49237060546875
INFO:root:Train (Epoch 216): Loss/seq after 03600 batchs: 512.0550537109375
INFO:root:Train (Epoch 216): Loss/seq after 03650 batchs: 510.00897216796875
INFO:root:Train (Epoch 216): Loss/seq after 03700 batchs: 512.0797119140625
INFO:root:Train (Epoch 216): Loss/seq after 03750 batchs: 516.2630615234375
INFO:root:Train (Epoch 216): Loss/seq after 03800 batchs: 514.30712890625
INFO:root:Train (Epoch 216): Loss/seq after 03850 batchs: 512.9603881835938
INFO:root:Train (Epoch 216): Loss/seq after 03900 batchs: 516.483642578125
INFO:root:Train (Epoch 216): Loss/seq after 03950 batchs: 519.8777465820312
INFO:root:Train (Epoch 216): Loss/seq after 04000 batchs: 516.1893920898438
INFO:root:Train (Epoch 216): Loss/seq after 04050 batchs: 512.9049682617188
INFO:root:Train (Epoch 216): Loss/seq after 04100 batchs: 511.3869934082031
INFO:root:Train (Epoch 216): Loss/seq after 04150 batchs: 511.0240783691406
INFO:root:Train (Epoch 216): Loss/seq after 04200 batchs: 509.2558288574219
INFO:root:Train (Epoch 216): Loss/seq after 04250 batchs: 507.6316223144531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 216): Loss/seq after 00000 batches: 440.37213134765625
INFO:root:# Valid (Epoch 216): Loss/seq after 00050 batches: 699.770751953125
INFO:root:# Valid (Epoch 216): Loss/seq after 00100 batches: 700.943115234375
INFO:root:# Valid (Epoch 216): Loss/seq after 00150 batches: 530.4930419921875
INFO:root:# Valid (Epoch 216): Loss/seq after 00200 batches: 485.3656921386719
INFO:root:Artifacts: Make stick videos for epoch 216
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_216_on_20220423_141213.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_216_index_339_on_20220423_141213.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 217): Loss/seq after 00000 batchs: 1146.6402587890625
INFO:root:Train (Epoch 217): Loss/seq after 00050 batchs: 748.9382934570312
INFO:root:Train (Epoch 217): Loss/seq after 00100 batchs: 745.0792236328125
INFO:root:Train (Epoch 217): Loss/seq after 00150 batchs: 657.6604614257812
INFO:root:Train (Epoch 217): Loss/seq after 00200 batchs: 737.7366943359375
INFO:root:Train (Epoch 217): Loss/seq after 00250 batchs: 793.361572265625
INFO:root:Train (Epoch 217): Loss/seq after 00300 batchs: 796.5430908203125
INFO:root:Train (Epoch 217): Loss/seq after 00350 batchs: 749.5064697265625
INFO:root:Train (Epoch 217): Loss/seq after 00400 batchs: 751.098388671875
INFO:root:Train (Epoch 217): Loss/seq after 00450 batchs: 739.7348022460938
INFO:root:Train (Epoch 217): Loss/seq after 00500 batchs: 715.8330078125
INFO:root:Train (Epoch 217): Loss/seq after 00550 batchs: 694.601318359375
INFO:root:Train (Epoch 217): Loss/seq after 00600 batchs: 670.7105712890625
INFO:root:Train (Epoch 217): Loss/seq after 00650 batchs: 657.33984375
INFO:root:Train (Epoch 217): Loss/seq after 00700 batchs: 635.98974609375
INFO:root:Train (Epoch 217): Loss/seq after 00750 batchs: 641.2623901367188
INFO:root:Train (Epoch 217): Loss/seq after 00800 batchs: 641.169921875
INFO:root:Train (Epoch 217): Loss/seq after 00850 batchs: 621.0516967773438
INFO:root:Train (Epoch 217): Loss/seq after 00900 batchs: 604.0185546875
INFO:root:Train (Epoch 217): Loss/seq after 00950 batchs: 605.7448120117188
INFO:root:Train (Epoch 217): Loss/seq after 01000 batchs: 596.933837890625
INFO:root:Train (Epoch 217): Loss/seq after 01050 batchs: 584.4642944335938
INFO:root:Train (Epoch 217): Loss/seq after 01100 batchs: 574.3748779296875
INFO:root:Train (Epoch 217): Loss/seq after 01150 batchs: 560.412109375
INFO:root:Train (Epoch 217): Loss/seq after 01200 batchs: 564.26220703125
INFO:root:Train (Epoch 217): Loss/seq after 01250 batchs: 561.69677734375
INFO:root:Train (Epoch 217): Loss/seq after 01300 batchs: 551.7724609375
INFO:root:Train (Epoch 217): Loss/seq after 01350 batchs: 543.3013916015625
INFO:root:Train (Epoch 217): Loss/seq after 01400 batchs: 546.7416381835938
INFO:root:Train (Epoch 217): Loss/seq after 01450 batchs: 548.2408447265625
INFO:root:Train (Epoch 217): Loss/seq after 01500 batchs: 554.4057006835938
INFO:root:Train (Epoch 217): Loss/seq after 01550 batchs: 555.8596801757812
INFO:root:Train (Epoch 217): Loss/seq after 01600 batchs: 550.7945556640625
INFO:root:Train (Epoch 217): Loss/seq after 01650 batchs: 547.7298583984375
INFO:root:Train (Epoch 217): Loss/seq after 01700 batchs: 550.096923828125
INFO:root:Train (Epoch 217): Loss/seq after 01750 batchs: 547.4280395507812
INFO:root:Train (Epoch 217): Loss/seq after 01800 batchs: 544.5093383789062
INFO:root:Train (Epoch 217): Loss/seq after 01850 batchs: 540.5420532226562
INFO:root:Train (Epoch 217): Loss/seq after 01900 batchs: 538.8985595703125
INFO:root:Train (Epoch 217): Loss/seq after 01950 batchs: 537.3756713867188
INFO:root:Train (Epoch 217): Loss/seq after 02000 batchs: 536.5225830078125
INFO:root:Train (Epoch 217): Loss/seq after 02050 batchs: 534.9005126953125
INFO:root:Train (Epoch 217): Loss/seq after 02100 batchs: 532.3176879882812
INFO:root:Train (Epoch 217): Loss/seq after 02150 batchs: 530.1685791015625
INFO:root:Train (Epoch 217): Loss/seq after 02200 batchs: 527.28564453125
INFO:root:Train (Epoch 217): Loss/seq after 02250 batchs: 525.9956665039062
INFO:root:Train (Epoch 217): Loss/seq after 02300 batchs: 524.03369140625
INFO:root:Train (Epoch 217): Loss/seq after 02350 batchs: 519.7368774414062
INFO:root:Train (Epoch 217): Loss/seq after 02400 batchs: 521.48095703125
INFO:root:Train (Epoch 217): Loss/seq after 02450 batchs: 517.024658203125
INFO:root:Train (Epoch 217): Loss/seq after 02500 batchs: 509.4169921875
INFO:root:Train (Epoch 217): Loss/seq after 02550 batchs: 503.2460632324219
INFO:root:Train (Epoch 217): Loss/seq after 02600 batchs: 500.9869689941406
INFO:root:Train (Epoch 217): Loss/seq after 02650 batchs: 498.0245666503906
INFO:root:Train (Epoch 217): Loss/seq after 02700 batchs: 495.7044677734375
INFO:root:Train (Epoch 217): Loss/seq after 02750 batchs: 491.688232421875
INFO:root:Train (Epoch 217): Loss/seq after 02800 batchs: 492.0926818847656
INFO:root:Train (Epoch 217): Loss/seq after 02850 batchs: 491.7577209472656
INFO:root:Train (Epoch 217): Loss/seq after 02900 batchs: 493.22021484375
INFO:root:Train (Epoch 217): Loss/seq after 02950 batchs: 492.83197021484375
INFO:root:Train (Epoch 217): Loss/seq after 03000 batchs: 497.8975524902344
INFO:root:Train (Epoch 217): Loss/seq after 03050 batchs: 499.6697082519531
INFO:root:Train (Epoch 217): Loss/seq after 03100 batchs: 502.40283203125
INFO:root:Train (Epoch 217): Loss/seq after 03150 batchs: 506.7670593261719
INFO:root:Train (Epoch 217): Loss/seq after 03200 batchs: 507.5596618652344
INFO:root:Train (Epoch 217): Loss/seq after 03250 batchs: 510.3868408203125
INFO:root:Train (Epoch 217): Loss/seq after 03300 batchs: 509.8449401855469
INFO:root:Train (Epoch 217): Loss/seq after 03350 batchs: 509.03955078125
INFO:root:Train (Epoch 217): Loss/seq after 03400 batchs: 505.4989013671875
INFO:root:Train (Epoch 217): Loss/seq after 03450 batchs: 503.8782043457031
INFO:root:Train (Epoch 217): Loss/seq after 03500 batchs: 504.021240234375
INFO:root:Train (Epoch 217): Loss/seq after 03550 batchs: 501.4132080078125
INFO:root:Train (Epoch 217): Loss/seq after 03600 batchs: 508.94940185546875
INFO:root:Train (Epoch 217): Loss/seq after 03650 batchs: 506.84552001953125
INFO:root:Train (Epoch 217): Loss/seq after 03700 batchs: 509.01397705078125
INFO:root:Train (Epoch 217): Loss/seq after 03750 batchs: 513.2059936523438
INFO:root:Train (Epoch 217): Loss/seq after 03800 batchs: 511.325927734375
INFO:root:Train (Epoch 217): Loss/seq after 03850 batchs: 510.1498107910156
INFO:root:Train (Epoch 217): Loss/seq after 03900 batchs: 513.4769897460938
INFO:root:Train (Epoch 217): Loss/seq after 03950 batchs: 516.6129760742188
INFO:root:Train (Epoch 217): Loss/seq after 04000 batchs: 512.9229736328125
INFO:root:Train (Epoch 217): Loss/seq after 04050 batchs: 509.737060546875
INFO:root:Train (Epoch 217): Loss/seq after 04100 batchs: 508.32977294921875
INFO:root:Train (Epoch 217): Loss/seq after 04150 batchs: 508.0215759277344
INFO:root:Train (Epoch 217): Loss/seq after 04200 batchs: 506.31622314453125
INFO:root:Train (Epoch 217): Loss/seq after 04250 batchs: 504.6201477050781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 217): Loss/seq after 00000 batches: 485.9891357421875
INFO:root:# Valid (Epoch 217): Loss/seq after 00050 batches: 694.509521484375
INFO:root:# Valid (Epoch 217): Loss/seq after 00100 batches: 699.9502563476562
INFO:root:# Valid (Epoch 217): Loss/seq after 00150 batches: 528.1416625976562
INFO:root:# Valid (Epoch 217): Loss/seq after 00200 batches: 484.34234619140625
INFO:root:Artifacts: Make stick videos for epoch 217
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_217_on_20220423_141658.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_217_index_1557_on_20220423_141658.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 218): Loss/seq after 00000 batchs: 970.4330444335938
INFO:root:Train (Epoch 218): Loss/seq after 00050 batchs: 744.0707397460938
INFO:root:Train (Epoch 218): Loss/seq after 00100 batchs: 750.219970703125
INFO:root:Train (Epoch 218): Loss/seq after 00150 batchs: 660.2064208984375
INFO:root:Train (Epoch 218): Loss/seq after 00200 batchs: 733.2606201171875
INFO:root:Train (Epoch 218): Loss/seq after 00250 batchs: 788.7490234375
INFO:root:Train (Epoch 218): Loss/seq after 00300 batchs: 790.9547119140625
INFO:root:Train (Epoch 218): Loss/seq after 00350 batchs: 744.555419921875
INFO:root:Train (Epoch 218): Loss/seq after 00400 batchs: 750.4793090820312
INFO:root:Train (Epoch 218): Loss/seq after 00450 batchs: 738.5226440429688
INFO:root:Train (Epoch 218): Loss/seq after 00500 batchs: 717.0929565429688
INFO:root:Train (Epoch 218): Loss/seq after 00550 batchs: 695.9750366210938
INFO:root:Train (Epoch 218): Loss/seq after 00600 batchs: 671.1696166992188
INFO:root:Train (Epoch 218): Loss/seq after 00650 batchs: 656.3926391601562
INFO:root:Train (Epoch 218): Loss/seq after 00700 batchs: 636.6434936523438
INFO:root:Train (Epoch 218): Loss/seq after 00750 batchs: 639.5169677734375
INFO:root:Train (Epoch 218): Loss/seq after 00800 batchs: 637.9383544921875
INFO:root:Train (Epoch 218): Loss/seq after 00850 batchs: 617.7269287109375
INFO:root:Train (Epoch 218): Loss/seq after 00900 batchs: 601.5690307617188
INFO:root:Train (Epoch 218): Loss/seq after 00950 batchs: 603.5355224609375
INFO:root:Train (Epoch 218): Loss/seq after 01000 batchs: 595.9732666015625
INFO:root:Train (Epoch 218): Loss/seq after 01050 batchs: 583.9892578125
INFO:root:Train (Epoch 218): Loss/seq after 01100 batchs: 573.0580444335938
INFO:root:Train (Epoch 218): Loss/seq after 01150 batchs: 558.6240844726562
INFO:root:Train (Epoch 218): Loss/seq after 01200 batchs: 561.9323120117188
INFO:root:Train (Epoch 218): Loss/seq after 01250 batchs: 559.5154418945312
INFO:root:Train (Epoch 218): Loss/seq after 01300 batchs: 549.2178344726562
INFO:root:Train (Epoch 218): Loss/seq after 01350 batchs: 540.5450439453125
INFO:root:Train (Epoch 218): Loss/seq after 01400 batchs: 545.2645874023438
INFO:root:Train (Epoch 218): Loss/seq after 01450 batchs: 546.94775390625
INFO:root:Train (Epoch 218): Loss/seq after 01500 batchs: 552.466796875
INFO:root:Train (Epoch 218): Loss/seq after 01550 batchs: 553.890380859375
INFO:root:Train (Epoch 218): Loss/seq after 01600 batchs: 548.7501220703125
INFO:root:Train (Epoch 218): Loss/seq after 01650 batchs: 545.7144775390625
INFO:root:Train (Epoch 218): Loss/seq after 01700 batchs: 548.328857421875
INFO:root:Train (Epoch 218): Loss/seq after 01750 batchs: 545.6317749023438
INFO:root:Train (Epoch 218): Loss/seq after 01800 batchs: 542.89208984375
INFO:root:Train (Epoch 218): Loss/seq after 01850 batchs: 538.994873046875
INFO:root:Train (Epoch 218): Loss/seq after 01900 batchs: 537.685302734375
INFO:root:Train (Epoch 218): Loss/seq after 01950 batchs: 535.962646484375
INFO:root:Train (Epoch 218): Loss/seq after 02000 batchs: 535.2581787109375
INFO:root:Train (Epoch 218): Loss/seq after 02050 batchs: 533.7847290039062
INFO:root:Train (Epoch 218): Loss/seq after 02100 batchs: 531.0244750976562
INFO:root:Train (Epoch 218): Loss/seq after 02150 batchs: 528.9536743164062
INFO:root:Train (Epoch 218): Loss/seq after 02200 batchs: 526.180419921875
INFO:root:Train (Epoch 218): Loss/seq after 02250 batchs: 524.9701538085938
INFO:root:Train (Epoch 218): Loss/seq after 02300 batchs: 523.0374755859375
INFO:root:Train (Epoch 218): Loss/seq after 02350 batchs: 518.9077758789062
INFO:root:Train (Epoch 218): Loss/seq after 02400 batchs: 520.4418334960938
INFO:root:Train (Epoch 218): Loss/seq after 02450 batchs: 515.8424072265625
INFO:root:Train (Epoch 218): Loss/seq after 02500 batchs: 508.19207763671875
INFO:root:Train (Epoch 218): Loss/seq after 02550 batchs: 502.306396484375
INFO:root:Train (Epoch 218): Loss/seq after 02600 batchs: 500.0179748535156
INFO:root:Train (Epoch 218): Loss/seq after 02650 batchs: 496.78997802734375
INFO:root:Train (Epoch 218): Loss/seq after 02700 batchs: 494.7320556640625
INFO:root:Train (Epoch 218): Loss/seq after 02750 batchs: 490.8843688964844
INFO:root:Train (Epoch 218): Loss/seq after 02800 batchs: 490.9664306640625
INFO:root:Train (Epoch 218): Loss/seq after 02850 batchs: 490.434814453125
INFO:root:Train (Epoch 218): Loss/seq after 02900 batchs: 491.90985107421875
INFO:root:Train (Epoch 218): Loss/seq after 02950 batchs: 491.3638610839844
INFO:root:Train (Epoch 218): Loss/seq after 03000 batchs: 496.341064453125
INFO:root:Train (Epoch 218): Loss/seq after 03050 batchs: 497.95428466796875
INFO:root:Train (Epoch 218): Loss/seq after 03100 batchs: 500.93450927734375
INFO:root:Train (Epoch 218): Loss/seq after 03150 batchs: 504.82464599609375
INFO:root:Train (Epoch 218): Loss/seq after 03200 batchs: 506.1750183105469
INFO:root:Train (Epoch 218): Loss/seq after 03250 batchs: 508.79840087890625
INFO:root:Train (Epoch 218): Loss/seq after 03300 batchs: 508.3535461425781
INFO:root:Train (Epoch 218): Loss/seq after 03350 batchs: 507.3554382324219
INFO:root:Train (Epoch 218): Loss/seq after 03400 batchs: 503.980712890625
INFO:root:Train (Epoch 218): Loss/seq after 03450 batchs: 502.79119873046875
INFO:root:Train (Epoch 218): Loss/seq after 03500 batchs: 503.5323181152344
INFO:root:Train (Epoch 218): Loss/seq after 03550 batchs: 501.2145690917969
INFO:root:Train (Epoch 218): Loss/seq after 03600 batchs: 508.9126281738281
INFO:root:Train (Epoch 218): Loss/seq after 03650 batchs: 507.0439147949219
INFO:root:Train (Epoch 218): Loss/seq after 03700 batchs: 509.250244140625
INFO:root:Train (Epoch 218): Loss/seq after 03750 batchs: 513.4266967773438
INFO:root:Train (Epoch 218): Loss/seq after 03800 batchs: 511.4720764160156
INFO:root:Train (Epoch 218): Loss/seq after 03850 batchs: 510.3365173339844
INFO:root:Train (Epoch 218): Loss/seq after 03900 batchs: 513.7506713867188
INFO:root:Train (Epoch 218): Loss/seq after 03950 batchs: 516.9633178710938
INFO:root:Train (Epoch 218): Loss/seq after 04000 batchs: 513.2666625976562
INFO:root:Train (Epoch 218): Loss/seq after 04050 batchs: 509.99578857421875
INFO:root:Train (Epoch 218): Loss/seq after 04100 batchs: 508.50628662109375
INFO:root:Train (Epoch 218): Loss/seq after 04150 batchs: 508.0973815917969
INFO:root:Train (Epoch 218): Loss/seq after 04200 batchs: 506.3716125488281
INFO:root:Train (Epoch 218): Loss/seq after 04250 batchs: 504.6380310058594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 218): Loss/seq after 00000 batches: 461.90606689453125
INFO:root:# Valid (Epoch 218): Loss/seq after 00050 batches: 674.9202880859375
INFO:root:# Valid (Epoch 218): Loss/seq after 00100 batches: 684.3267211914062
INFO:root:# Valid (Epoch 218): Loss/seq after 00150 batches: 517.916015625
INFO:root:# Valid (Epoch 218): Loss/seq after 00200 batches: 475.43994140625
INFO:root:Artifacts: Make stick videos for epoch 218
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_218_on_20220423_142144.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_218_index_1678_on_20220423_142144.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 219): Loss/seq after 00000 batchs: 920.0938720703125
INFO:root:Train (Epoch 219): Loss/seq after 00050 batchs: 741.2713012695312
INFO:root:Train (Epoch 219): Loss/seq after 00100 batchs: 733.0376586914062
INFO:root:Train (Epoch 219): Loss/seq after 00150 batchs: 646.6336669921875
INFO:root:Train (Epoch 219): Loss/seq after 00200 batchs: 713.89404296875
INFO:root:Train (Epoch 219): Loss/seq after 00250 batchs: 782.3425903320312
INFO:root:Train (Epoch 219): Loss/seq after 00300 batchs: 784.835205078125
INFO:root:Train (Epoch 219): Loss/seq after 00350 batchs: 740.1799926757812
INFO:root:Train (Epoch 219): Loss/seq after 00400 batchs: 739.4711303710938
INFO:root:Train (Epoch 219): Loss/seq after 00450 batchs: 729.2950439453125
INFO:root:Train (Epoch 219): Loss/seq after 00500 batchs: 706.6869506835938
INFO:root:Train (Epoch 219): Loss/seq after 00550 batchs: 686.1182250976562
INFO:root:Train (Epoch 219): Loss/seq after 00600 batchs: 661.9188232421875
INFO:root:Train (Epoch 219): Loss/seq after 00650 batchs: 645.511962890625
INFO:root:Train (Epoch 219): Loss/seq after 00700 batchs: 624.5989990234375
INFO:root:Train (Epoch 219): Loss/seq after 00750 batchs: 630.6631469726562
INFO:root:Train (Epoch 219): Loss/seq after 00800 batchs: 629.77099609375
INFO:root:Train (Epoch 219): Loss/seq after 00850 batchs: 609.8613891601562
INFO:root:Train (Epoch 219): Loss/seq after 00900 batchs: 593.4686889648438
INFO:root:Train (Epoch 219): Loss/seq after 00950 batchs: 595.3475341796875
INFO:root:Train (Epoch 219): Loss/seq after 01000 batchs: 586.4221801757812
INFO:root:Train (Epoch 219): Loss/seq after 01050 batchs: 574.5171508789062
INFO:root:Train (Epoch 219): Loss/seq after 01100 batchs: 564.0253295898438
INFO:root:Train (Epoch 219): Loss/seq after 01150 batchs: 550.1134033203125
INFO:root:Train (Epoch 219): Loss/seq after 01200 batchs: 553.597900390625
INFO:root:Train (Epoch 219): Loss/seq after 01250 batchs: 551.1720581054688
INFO:root:Train (Epoch 219): Loss/seq after 01300 batchs: 540.9879760742188
INFO:root:Train (Epoch 219): Loss/seq after 01350 batchs: 532.5818481445312
INFO:root:Train (Epoch 219): Loss/seq after 01400 batchs: 535.3169555664062
INFO:root:Train (Epoch 219): Loss/seq after 01450 batchs: 537.1929321289062
INFO:root:Train (Epoch 219): Loss/seq after 01500 batchs: 543.1248168945312
INFO:root:Train (Epoch 219): Loss/seq after 01550 batchs: 544.1422119140625
INFO:root:Train (Epoch 219): Loss/seq after 01600 batchs: 539.3021240234375
INFO:root:Train (Epoch 219): Loss/seq after 01650 batchs: 536.4977416992188
INFO:root:Train (Epoch 219): Loss/seq after 01700 batchs: 538.9903564453125
INFO:root:Train (Epoch 219): Loss/seq after 01750 batchs: 536.310546875
INFO:root:Train (Epoch 219): Loss/seq after 01800 batchs: 533.6381225585938
INFO:root:Train (Epoch 219): Loss/seq after 01850 batchs: 529.7914428710938
INFO:root:Train (Epoch 219): Loss/seq after 01900 batchs: 527.8502197265625
INFO:root:Train (Epoch 219): Loss/seq after 01950 batchs: 526.4348754882812
INFO:root:Train (Epoch 219): Loss/seq after 02000 batchs: 525.9981689453125
INFO:root:Train (Epoch 219): Loss/seq after 02050 batchs: 524.5083618164062
INFO:root:Train (Epoch 219): Loss/seq after 02100 batchs: 521.832275390625
INFO:root:Train (Epoch 219): Loss/seq after 02150 batchs: 519.81640625
INFO:root:Train (Epoch 219): Loss/seq after 02200 batchs: 517.1174926757812
INFO:root:Train (Epoch 219): Loss/seq after 02250 batchs: 515.673828125
INFO:root:Train (Epoch 219): Loss/seq after 02300 batchs: 513.9190063476562
INFO:root:Train (Epoch 219): Loss/seq after 02350 batchs: 509.8318176269531
INFO:root:Train (Epoch 219): Loss/seq after 02400 batchs: 511.5179138183594
INFO:root:Train (Epoch 219): Loss/seq after 02450 batchs: 507.04339599609375
INFO:root:Train (Epoch 219): Loss/seq after 02500 batchs: 499.57830810546875
INFO:root:Train (Epoch 219): Loss/seq after 02550 batchs: 493.5576171875
INFO:root:Train (Epoch 219): Loss/seq after 02600 batchs: 491.478759765625
INFO:root:Train (Epoch 219): Loss/seq after 02650 batchs: 488.4297790527344
INFO:root:Train (Epoch 219): Loss/seq after 02700 batchs: 486.057861328125
INFO:root:Train (Epoch 219): Loss/seq after 02750 batchs: 482.2435607910156
INFO:root:Train (Epoch 219): Loss/seq after 02800 batchs: 482.50494384765625
INFO:root:Train (Epoch 219): Loss/seq after 02850 batchs: 482.06304931640625
INFO:root:Train (Epoch 219): Loss/seq after 02900 batchs: 483.8493957519531
INFO:root:Train (Epoch 219): Loss/seq after 02950 batchs: 483.4187927246094
INFO:root:Train (Epoch 219): Loss/seq after 03000 batchs: 488.57904052734375
INFO:root:Train (Epoch 219): Loss/seq after 03050 batchs: 490.11492919921875
INFO:root:Train (Epoch 219): Loss/seq after 03100 batchs: 492.71710205078125
INFO:root:Train (Epoch 219): Loss/seq after 03150 batchs: 497.54681396484375
INFO:root:Train (Epoch 219): Loss/seq after 03200 batchs: 498.7762756347656
INFO:root:Train (Epoch 219): Loss/seq after 03250 batchs: 501.4799499511719
INFO:root:Train (Epoch 219): Loss/seq after 03300 batchs: 500.9984130859375
INFO:root:Train (Epoch 219): Loss/seq after 03350 batchs: 500.0289611816406
INFO:root:Train (Epoch 219): Loss/seq after 03400 batchs: 496.78094482421875
INFO:root:Train (Epoch 219): Loss/seq after 03450 batchs: 495.4653625488281
INFO:root:Train (Epoch 219): Loss/seq after 03500 batchs: 496.30206298828125
INFO:root:Train (Epoch 219): Loss/seq after 03550 batchs: 493.7778625488281
INFO:root:Train (Epoch 219): Loss/seq after 03600 batchs: 501.3438720703125
INFO:root:Train (Epoch 219): Loss/seq after 03650 batchs: 499.45184326171875
INFO:root:Train (Epoch 219): Loss/seq after 03700 batchs: 501.6853332519531
INFO:root:Train (Epoch 219): Loss/seq after 03750 batchs: 505.8243408203125
INFO:root:Train (Epoch 219): Loss/seq after 03800 batchs: 503.99676513671875
INFO:root:Train (Epoch 219): Loss/seq after 03850 batchs: 502.8499755859375
INFO:root:Train (Epoch 219): Loss/seq after 03900 batchs: 506.3673095703125
INFO:root:Train (Epoch 219): Loss/seq after 03950 batchs: 510.3243713378906
INFO:root:Train (Epoch 219): Loss/seq after 04000 batchs: 506.67340087890625
INFO:root:Train (Epoch 219): Loss/seq after 04050 batchs: 503.5130920410156
INFO:root:Train (Epoch 219): Loss/seq after 04100 batchs: 502.11016845703125
INFO:root:Train (Epoch 219): Loss/seq after 04150 batchs: 501.8291015625
INFO:root:Train (Epoch 219): Loss/seq after 04200 batchs: 500.1938171386719
INFO:root:Train (Epoch 219): Loss/seq after 04250 batchs: 498.6492004394531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 219): Loss/seq after 00000 batches: 412.4974670410156
INFO:root:# Valid (Epoch 219): Loss/seq after 00050 batches: 675.574462890625
INFO:root:# Valid (Epoch 219): Loss/seq after 00100 batches: 693.9348754882812
INFO:root:# Valid (Epoch 219): Loss/seq after 00150 batches: 523.459716796875
INFO:root:# Valid (Epoch 219): Loss/seq after 00200 batches: 477.811279296875
INFO:root:Artifacts: Make stick videos for epoch 219
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_219_on_20220423_142644.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_219_index_1154_on_20220423_142644.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 220): Loss/seq after 00000 batchs: 1183.6300048828125
INFO:root:Train (Epoch 220): Loss/seq after 00050 batchs: 739.9730834960938
INFO:root:Train (Epoch 220): Loss/seq after 00100 batchs: 748.480712890625
INFO:root:Train (Epoch 220): Loss/seq after 00150 batchs: 655.1917114257812
INFO:root:Train (Epoch 220): Loss/seq after 00200 batchs: 726.408935546875
INFO:root:Train (Epoch 220): Loss/seq after 00250 batchs: 768.0868530273438
INFO:root:Train (Epoch 220): Loss/seq after 00300 batchs: 773.3264770507812
INFO:root:Train (Epoch 220): Loss/seq after 00350 batchs: 728.686767578125
INFO:root:Train (Epoch 220): Loss/seq after 00400 batchs: 734.1101684570312
INFO:root:Train (Epoch 220): Loss/seq after 00450 batchs: 724.716552734375
INFO:root:Train (Epoch 220): Loss/seq after 00500 batchs: 702.3964233398438
INFO:root:Train (Epoch 220): Loss/seq after 00550 batchs: 681.4998779296875
INFO:root:Train (Epoch 220): Loss/seq after 00600 batchs: 657.2816162109375
INFO:root:Train (Epoch 220): Loss/seq after 00650 batchs: 640.6091918945312
INFO:root:Train (Epoch 220): Loss/seq after 00700 batchs: 619.6215209960938
INFO:root:Train (Epoch 220): Loss/seq after 00750 batchs: 623.7033081054688
INFO:root:Train (Epoch 220): Loss/seq after 00800 batchs: 623.3865966796875
INFO:root:Train (Epoch 220): Loss/seq after 00850 batchs: 603.9073486328125
INFO:root:Train (Epoch 220): Loss/seq after 00900 batchs: 587.4430541992188
INFO:root:Train (Epoch 220): Loss/seq after 00950 batchs: 587.9822998046875
INFO:root:Train (Epoch 220): Loss/seq after 01000 batchs: 579.9613647460938
INFO:root:Train (Epoch 220): Loss/seq after 01050 batchs: 567.674560546875
INFO:root:Train (Epoch 220): Loss/seq after 01100 batchs: 557.328369140625
INFO:root:Train (Epoch 220): Loss/seq after 01150 batchs: 543.3306274414062
INFO:root:Train (Epoch 220): Loss/seq after 01200 batchs: 547.433349609375
INFO:root:Train (Epoch 220): Loss/seq after 01250 batchs: 545.587646484375
INFO:root:Train (Epoch 220): Loss/seq after 01300 batchs: 536.1414184570312
INFO:root:Train (Epoch 220): Loss/seq after 01350 batchs: 529.0399169921875
INFO:root:Train (Epoch 220): Loss/seq after 01400 batchs: 532.7755737304688
INFO:root:Train (Epoch 220): Loss/seq after 01450 batchs: 534.6370239257812
INFO:root:Train (Epoch 220): Loss/seq after 01500 batchs: 540.761962890625
INFO:root:Train (Epoch 220): Loss/seq after 01550 batchs: 542.2606201171875
INFO:root:Train (Epoch 220): Loss/seq after 01600 batchs: 537.4623413085938
INFO:root:Train (Epoch 220): Loss/seq after 01650 batchs: 534.5399780273438
INFO:root:Train (Epoch 220): Loss/seq after 01700 batchs: 537.2339477539062
INFO:root:Train (Epoch 220): Loss/seq after 01750 batchs: 534.8580322265625
INFO:root:Train (Epoch 220): Loss/seq after 01800 batchs: 532.184814453125
INFO:root:Train (Epoch 220): Loss/seq after 01850 batchs: 528.4302368164062
INFO:root:Train (Epoch 220): Loss/seq after 01900 batchs: 526.8489990234375
INFO:root:Train (Epoch 220): Loss/seq after 01950 batchs: 525.1998291015625
INFO:root:Train (Epoch 220): Loss/seq after 02000 batchs: 524.6824951171875
INFO:root:Train (Epoch 220): Loss/seq after 02050 batchs: 523.2205810546875
INFO:root:Train (Epoch 220): Loss/seq after 02100 batchs: 520.6806640625
INFO:root:Train (Epoch 220): Loss/seq after 02150 batchs: 518.670166015625
INFO:root:Train (Epoch 220): Loss/seq after 02200 batchs: 516.0728759765625
INFO:root:Train (Epoch 220): Loss/seq after 02250 batchs: 514.8920288085938
INFO:root:Train (Epoch 220): Loss/seq after 02300 batchs: 512.6104125976562
INFO:root:Train (Epoch 220): Loss/seq after 02350 batchs: 508.41583251953125
INFO:root:Train (Epoch 220): Loss/seq after 02400 batchs: 509.97442626953125
INFO:root:Train (Epoch 220): Loss/seq after 02450 batchs: 505.6632080078125
INFO:root:Train (Epoch 220): Loss/seq after 02500 batchs: 498.1568908691406
INFO:root:Train (Epoch 220): Loss/seq after 02550 batchs: 492.2254943847656
INFO:root:Train (Epoch 220): Loss/seq after 02600 batchs: 490.05084228515625
INFO:root:Train (Epoch 220): Loss/seq after 02650 batchs: 487.10076904296875
INFO:root:Train (Epoch 220): Loss/seq after 02700 batchs: 485.0108337402344
INFO:root:Train (Epoch 220): Loss/seq after 02750 batchs: 481.4234619140625
INFO:root:Train (Epoch 220): Loss/seq after 02800 batchs: 481.8625793457031
INFO:root:Train (Epoch 220): Loss/seq after 02850 batchs: 481.4361267089844
INFO:root:Train (Epoch 220): Loss/seq after 02900 batchs: 482.9739074707031
INFO:root:Train (Epoch 220): Loss/seq after 02950 batchs: 482.62939453125
INFO:root:Train (Epoch 220): Loss/seq after 03000 batchs: 487.6306457519531
INFO:root:Train (Epoch 220): Loss/seq after 03050 batchs: 489.16656494140625
INFO:root:Train (Epoch 220): Loss/seq after 03100 batchs: 491.8953857421875
INFO:root:Train (Epoch 220): Loss/seq after 03150 batchs: 496.75537109375
INFO:root:Train (Epoch 220): Loss/seq after 03200 batchs: 498.11328125
INFO:root:Train (Epoch 220): Loss/seq after 03250 batchs: 501.3931884765625
INFO:root:Train (Epoch 220): Loss/seq after 03300 batchs: 501.0324401855469
INFO:root:Train (Epoch 220): Loss/seq after 03350 batchs: 500.0958557128906
INFO:root:Train (Epoch 220): Loss/seq after 03400 batchs: 496.7691345214844
INFO:root:Train (Epoch 220): Loss/seq after 03450 batchs: 495.1707763671875
INFO:root:Train (Epoch 220): Loss/seq after 03500 batchs: 495.6213684082031
INFO:root:Train (Epoch 220): Loss/seq after 03550 batchs: 493.1567077636719
INFO:root:Train (Epoch 220): Loss/seq after 03600 batchs: 500.873779296875
INFO:root:Train (Epoch 220): Loss/seq after 03650 batchs: 498.9852294921875
INFO:root:Train (Epoch 220): Loss/seq after 03700 batchs: 500.9202880859375
INFO:root:Train (Epoch 220): Loss/seq after 03750 batchs: 505.0205078125
INFO:root:Train (Epoch 220): Loss/seq after 03800 batchs: 503.1605529785156
INFO:root:Train (Epoch 220): Loss/seq after 03850 batchs: 502.0657958984375
INFO:root:Train (Epoch 220): Loss/seq after 03900 batchs: 505.7635803222656
INFO:root:Train (Epoch 220): Loss/seq after 03950 batchs: 508.9849853515625
INFO:root:Train (Epoch 220): Loss/seq after 04000 batchs: 505.4368896484375
INFO:root:Train (Epoch 220): Loss/seq after 04050 batchs: 502.3070068359375
INFO:root:Train (Epoch 220): Loss/seq after 04100 batchs: 500.894775390625
INFO:root:Train (Epoch 220): Loss/seq after 04150 batchs: 500.6171875
INFO:root:Train (Epoch 220): Loss/seq after 04200 batchs: 498.9324645996094
INFO:root:Train (Epoch 220): Loss/seq after 04250 batchs: 497.2795715332031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 220): Loss/seq after 00000 batches: 462.6278991699219
INFO:root:# Valid (Epoch 220): Loss/seq after 00050 batches: 686.3967895507812
INFO:root:# Valid (Epoch 220): Loss/seq after 00100 batches: 712.6226806640625
INFO:root:# Valid (Epoch 220): Loss/seq after 00150 batches: 537.2913208007812
INFO:root:# Valid (Epoch 220): Loss/seq after 00200 batches: 494.05035400390625
INFO:root:Artifacts: Make stick videos for epoch 220
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_220_on_20220423_143128.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_220_index_1049_on_20220423_143128.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 221): Loss/seq after 00000 batchs: 1129.107666015625
INFO:root:Train (Epoch 221): Loss/seq after 00050 batchs: 725.99609375
INFO:root:Train (Epoch 221): Loss/seq after 00100 batchs: 706.9887084960938
INFO:root:Train (Epoch 221): Loss/seq after 00150 batchs: 625.03955078125
INFO:root:Train (Epoch 221): Loss/seq after 00200 batchs: 709.6207275390625
INFO:root:Train (Epoch 221): Loss/seq after 00250 batchs: 759.052001953125
INFO:root:Train (Epoch 221): Loss/seq after 00300 batchs: 762.4349975585938
INFO:root:Train (Epoch 221): Loss/seq after 00350 batchs: 719.0708618164062
INFO:root:Train (Epoch 221): Loss/seq after 00400 batchs: 724.782470703125
INFO:root:Train (Epoch 221): Loss/seq after 00450 batchs: 716.0553588867188
INFO:root:Train (Epoch 221): Loss/seq after 00500 batchs: 695.57421875
INFO:root:Train (Epoch 221): Loss/seq after 00550 batchs: 675.5487060546875
INFO:root:Train (Epoch 221): Loss/seq after 00600 batchs: 652.2222900390625
INFO:root:Train (Epoch 221): Loss/seq after 00650 batchs: 637.8250122070312
INFO:root:Train (Epoch 221): Loss/seq after 00700 batchs: 616.641845703125
INFO:root:Train (Epoch 221): Loss/seq after 00750 batchs: 620.1842041015625
INFO:root:Train (Epoch 221): Loss/seq after 00800 batchs: 621.3538208007812
INFO:root:Train (Epoch 221): Loss/seq after 00850 batchs: 601.8063354492188
INFO:root:Train (Epoch 221): Loss/seq after 00900 batchs: 586.075439453125
INFO:root:Train (Epoch 221): Loss/seq after 00950 batchs: 586.474609375
INFO:root:Train (Epoch 221): Loss/seq after 01000 batchs: 578.6031494140625
INFO:root:Train (Epoch 221): Loss/seq after 01050 batchs: 566.6190185546875
INFO:root:Train (Epoch 221): Loss/seq after 01100 batchs: 556.4382934570312
INFO:root:Train (Epoch 221): Loss/seq after 01150 batchs: 542.7127685546875
INFO:root:Train (Epoch 221): Loss/seq after 01200 batchs: 546.9020385742188
INFO:root:Train (Epoch 221): Loss/seq after 01250 batchs: 544.5551147460938
INFO:root:Train (Epoch 221): Loss/seq after 01300 batchs: 535.0884399414062
INFO:root:Train (Epoch 221): Loss/seq after 01350 batchs: 527.1337890625
INFO:root:Train (Epoch 221): Loss/seq after 01400 batchs: 531.9630126953125
INFO:root:Train (Epoch 221): Loss/seq after 01450 batchs: 534.0765380859375
INFO:root:Train (Epoch 221): Loss/seq after 01500 batchs: 540.5603637695312
INFO:root:Train (Epoch 221): Loss/seq after 01550 batchs: 542.6227416992188
INFO:root:Train (Epoch 221): Loss/seq after 01600 batchs: 537.9698486328125
INFO:root:Train (Epoch 221): Loss/seq after 01650 batchs: 535.3355102539062
INFO:root:Train (Epoch 221): Loss/seq after 01700 batchs: 537.8154296875
INFO:root:Train (Epoch 221): Loss/seq after 01750 batchs: 535.2671508789062
INFO:root:Train (Epoch 221): Loss/seq after 01800 batchs: 532.4033203125
INFO:root:Train (Epoch 221): Loss/seq after 01850 batchs: 528.5445556640625
INFO:root:Train (Epoch 221): Loss/seq after 01900 batchs: 527.4191284179688
INFO:root:Train (Epoch 221): Loss/seq after 01950 batchs: 525.847412109375
INFO:root:Train (Epoch 221): Loss/seq after 02000 batchs: 525.4066772460938
INFO:root:Train (Epoch 221): Loss/seq after 02050 batchs: 523.9295043945312
INFO:root:Train (Epoch 221): Loss/seq after 02100 batchs: 521.4981079101562
INFO:root:Train (Epoch 221): Loss/seq after 02150 batchs: 519.642578125
INFO:root:Train (Epoch 221): Loss/seq after 02200 batchs: 516.9541625976562
INFO:root:Train (Epoch 221): Loss/seq after 02250 batchs: 515.6307373046875
INFO:root:Train (Epoch 221): Loss/seq after 02300 batchs: 512.8736572265625
INFO:root:Train (Epoch 221): Loss/seq after 02350 batchs: 508.7064514160156
INFO:root:Train (Epoch 221): Loss/seq after 02400 batchs: 510.43548583984375
INFO:root:Train (Epoch 221): Loss/seq after 02450 batchs: 506.037841796875
INFO:root:Train (Epoch 221): Loss/seq after 02500 batchs: 498.5129089355469
INFO:root:Train (Epoch 221): Loss/seq after 02550 batchs: 492.7859191894531
INFO:root:Train (Epoch 221): Loss/seq after 02600 batchs: 490.76263427734375
INFO:root:Train (Epoch 221): Loss/seq after 02650 batchs: 487.5195617675781
INFO:root:Train (Epoch 221): Loss/seq after 02700 batchs: 485.2649230957031
INFO:root:Train (Epoch 221): Loss/seq after 02750 batchs: 481.4335021972656
INFO:root:Train (Epoch 221): Loss/seq after 02800 batchs: 481.28515625
INFO:root:Train (Epoch 221): Loss/seq after 02850 batchs: 480.9999084472656
INFO:root:Train (Epoch 221): Loss/seq after 02900 batchs: 482.4493408203125
INFO:root:Train (Epoch 221): Loss/seq after 02950 batchs: 482.0314636230469
INFO:root:Train (Epoch 221): Loss/seq after 03000 batchs: 487.2555847167969
INFO:root:Train (Epoch 221): Loss/seq after 03050 batchs: 489.0559387207031
INFO:root:Train (Epoch 221): Loss/seq after 03100 batchs: 492.00946044921875
INFO:root:Train (Epoch 221): Loss/seq after 03150 batchs: 496.3014221191406
INFO:root:Train (Epoch 221): Loss/seq after 03200 batchs: 498.3945007324219
INFO:root:Train (Epoch 221): Loss/seq after 03250 batchs: 500.9945068359375
INFO:root:Train (Epoch 221): Loss/seq after 03300 batchs: 500.73974609375
INFO:root:Train (Epoch 221): Loss/seq after 03350 batchs: 499.4541320800781
INFO:root:Train (Epoch 221): Loss/seq after 03400 batchs: 496.13824462890625
INFO:root:Train (Epoch 221): Loss/seq after 03450 batchs: 494.5157470703125
INFO:root:Train (Epoch 221): Loss/seq after 03500 batchs: 495.6597595214844
INFO:root:Train (Epoch 221): Loss/seq after 03550 batchs: 493.39080810546875
INFO:root:Train (Epoch 221): Loss/seq after 03600 batchs: 500.81341552734375
INFO:root:Train (Epoch 221): Loss/seq after 03650 batchs: 498.835693359375
INFO:root:Train (Epoch 221): Loss/seq after 03700 batchs: 500.99725341796875
INFO:root:Train (Epoch 221): Loss/seq after 03750 batchs: 505.0421447753906
INFO:root:Train (Epoch 221): Loss/seq after 03800 batchs: 503.1809997558594
INFO:root:Train (Epoch 221): Loss/seq after 03850 batchs: 501.8840637207031
INFO:root:Train (Epoch 221): Loss/seq after 03900 batchs: 504.9139099121094
INFO:root:Train (Epoch 221): Loss/seq after 03950 batchs: 508.1127014160156
INFO:root:Train (Epoch 221): Loss/seq after 04000 batchs: 504.4857177734375
INFO:root:Train (Epoch 221): Loss/seq after 04050 batchs: 501.2965087890625
INFO:root:Train (Epoch 221): Loss/seq after 04100 batchs: 499.9501953125
INFO:root:Train (Epoch 221): Loss/seq after 04150 batchs: 499.72247314453125
INFO:root:Train (Epoch 221): Loss/seq after 04200 batchs: 498.03387451171875
INFO:root:Train (Epoch 221): Loss/seq after 04250 batchs: 496.45123291015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 221): Loss/seq after 00000 batches: 454.0021667480469
INFO:root:# Valid (Epoch 221): Loss/seq after 00050 batches: 691.3356323242188
INFO:root:# Valid (Epoch 221): Loss/seq after 00100 batches: 699.6207275390625
INFO:root:# Valid (Epoch 221): Loss/seq after 00150 batches: 527.684326171875
INFO:root:# Valid (Epoch 221): Loss/seq after 00200 batches: 483.47271728515625
INFO:root:Artifacts: Make stick videos for epoch 221
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_221_on_20220423_143612.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_221_index_664_on_20220423_143612.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 222): Loss/seq after 00000 batchs: 937.2564086914062
INFO:root:Train (Epoch 222): Loss/seq after 00050 batchs: 728.9562377929688
INFO:root:Train (Epoch 222): Loss/seq after 00100 batchs: 715.8825073242188
INFO:root:Train (Epoch 222): Loss/seq after 00150 batchs: 634.6189575195312
INFO:root:Train (Epoch 222): Loss/seq after 00200 batchs: 715.812255859375
INFO:root:Train (Epoch 222): Loss/seq after 00250 batchs: 768.6375122070312
INFO:root:Train (Epoch 222): Loss/seq after 00300 batchs: 768.3178100585938
INFO:root:Train (Epoch 222): Loss/seq after 00350 batchs: 724.11865234375
INFO:root:Train (Epoch 222): Loss/seq after 00400 batchs: 728.622314453125
INFO:root:Train (Epoch 222): Loss/seq after 00450 batchs: 719.683837890625
INFO:root:Train (Epoch 222): Loss/seq after 00500 batchs: 697.5425415039062
INFO:root:Train (Epoch 222): Loss/seq after 00550 batchs: 677.3890380859375
INFO:root:Train (Epoch 222): Loss/seq after 00600 batchs: 653.757568359375
INFO:root:Train (Epoch 222): Loss/seq after 00650 batchs: 638.8274536132812
INFO:root:Train (Epoch 222): Loss/seq after 00700 batchs: 617.0166625976562
INFO:root:Train (Epoch 222): Loss/seq after 00750 batchs: 620.93994140625
INFO:root:Train (Epoch 222): Loss/seq after 00800 batchs: 620.982666015625
INFO:root:Train (Epoch 222): Loss/seq after 00850 batchs: 600.950439453125
INFO:root:Train (Epoch 222): Loss/seq after 00900 batchs: 584.943603515625
INFO:root:Train (Epoch 222): Loss/seq after 00950 batchs: 584.2571411132812
INFO:root:Train (Epoch 222): Loss/seq after 01000 batchs: 575.661865234375
INFO:root:Train (Epoch 222): Loss/seq after 01050 batchs: 563.3890991210938
INFO:root:Train (Epoch 222): Loss/seq after 01100 batchs: 553.10107421875
INFO:root:Train (Epoch 222): Loss/seq after 01150 batchs: 540.0892333984375
INFO:root:Train (Epoch 222): Loss/seq after 01200 batchs: 543.6136474609375
INFO:root:Train (Epoch 222): Loss/seq after 01250 batchs: 541.0733642578125
INFO:root:Train (Epoch 222): Loss/seq after 01300 batchs: 531.6361083984375
INFO:root:Train (Epoch 222): Loss/seq after 01350 batchs: 523.2772827148438
INFO:root:Train (Epoch 222): Loss/seq after 01400 batchs: 527.3098754882812
INFO:root:Train (Epoch 222): Loss/seq after 01450 batchs: 529.1295776367188
INFO:root:Train (Epoch 222): Loss/seq after 01500 batchs: 535.20068359375
INFO:root:Train (Epoch 222): Loss/seq after 01550 batchs: 537.2518310546875
INFO:root:Train (Epoch 222): Loss/seq after 01600 batchs: 532.5150756835938
INFO:root:Train (Epoch 222): Loss/seq after 01650 batchs: 529.8328247070312
INFO:root:Train (Epoch 222): Loss/seq after 01700 batchs: 532.1127319335938
INFO:root:Train (Epoch 222): Loss/seq after 01750 batchs: 529.700439453125
INFO:root:Train (Epoch 222): Loss/seq after 01800 batchs: 527.056884765625
INFO:root:Train (Epoch 222): Loss/seq after 01850 batchs: 523.3930053710938
INFO:root:Train (Epoch 222): Loss/seq after 01900 batchs: 521.8614501953125
INFO:root:Train (Epoch 222): Loss/seq after 01950 batchs: 520.3058471679688
INFO:root:Train (Epoch 222): Loss/seq after 02000 batchs: 519.8783569335938
INFO:root:Train (Epoch 222): Loss/seq after 02050 batchs: 518.4471435546875
INFO:root:Train (Epoch 222): Loss/seq after 02100 batchs: 515.8933715820312
INFO:root:Train (Epoch 222): Loss/seq after 02150 batchs: 514.0170288085938
INFO:root:Train (Epoch 222): Loss/seq after 02200 batchs: 511.47052001953125
INFO:root:Train (Epoch 222): Loss/seq after 02250 batchs: 510.3581237792969
INFO:root:Train (Epoch 222): Loss/seq after 02300 batchs: 508.29541015625
INFO:root:Train (Epoch 222): Loss/seq after 02350 batchs: 504.2790222167969
INFO:root:Train (Epoch 222): Loss/seq after 02400 batchs: 505.9604797363281
INFO:root:Train (Epoch 222): Loss/seq after 02450 batchs: 501.59759521484375
INFO:root:Train (Epoch 222): Loss/seq after 02500 batchs: 494.1170654296875
INFO:root:Train (Epoch 222): Loss/seq after 02550 batchs: 488.2001953125
INFO:root:Train (Epoch 222): Loss/seq after 02600 batchs: 486.1135559082031
INFO:root:Train (Epoch 222): Loss/seq after 02650 batchs: 483.2723083496094
INFO:root:Train (Epoch 222): Loss/seq after 02700 batchs: 481.2840270996094
INFO:root:Train (Epoch 222): Loss/seq after 02750 batchs: 477.1846008300781
INFO:root:Train (Epoch 222): Loss/seq after 02800 batchs: 476.78472900390625
INFO:root:Train (Epoch 222): Loss/seq after 02850 batchs: 476.4755859375
INFO:root:Train (Epoch 222): Loss/seq after 02900 batchs: 477.8820495605469
INFO:root:Train (Epoch 222): Loss/seq after 02950 batchs: 477.6266174316406
INFO:root:Train (Epoch 222): Loss/seq after 03000 batchs: 482.9264221191406
INFO:root:Train (Epoch 222): Loss/seq after 03050 batchs: 484.7555847167969
INFO:root:Train (Epoch 222): Loss/seq after 03100 batchs: 486.8685302734375
INFO:root:Train (Epoch 222): Loss/seq after 03150 batchs: 491.082275390625
INFO:root:Train (Epoch 222): Loss/seq after 03200 batchs: 492.7772521972656
INFO:root:Train (Epoch 222): Loss/seq after 03250 batchs: 495.61126708984375
INFO:root:Train (Epoch 222): Loss/seq after 03300 batchs: 494.99432373046875
INFO:root:Train (Epoch 222): Loss/seq after 03350 batchs: 493.683349609375
INFO:root:Train (Epoch 222): Loss/seq after 03400 batchs: 490.4200134277344
INFO:root:Train (Epoch 222): Loss/seq after 03450 batchs: 488.8292541503906
INFO:root:Train (Epoch 222): Loss/seq after 03500 batchs: 489.3079528808594
INFO:root:Train (Epoch 222): Loss/seq after 03550 batchs: 486.86517333984375
INFO:root:Train (Epoch 222): Loss/seq after 03600 batchs: 494.30145263671875
INFO:root:Train (Epoch 222): Loss/seq after 03650 batchs: 492.4289855957031
INFO:root:Train (Epoch 222): Loss/seq after 03700 batchs: 494.3950500488281
INFO:root:Train (Epoch 222): Loss/seq after 03750 batchs: 498.599853515625
INFO:root:Train (Epoch 222): Loss/seq after 03800 batchs: 496.8379821777344
INFO:root:Train (Epoch 222): Loss/seq after 03850 batchs: 495.5811767578125
INFO:root:Train (Epoch 222): Loss/seq after 03900 batchs: 498.5796203613281
INFO:root:Train (Epoch 222): Loss/seq after 03950 batchs: 502.01287841796875
INFO:root:Train (Epoch 222): Loss/seq after 04000 batchs: 498.47027587890625
INFO:root:Train (Epoch 222): Loss/seq after 04050 batchs: 495.3968811035156
INFO:root:Train (Epoch 222): Loss/seq after 04100 batchs: 494.0650634765625
INFO:root:Train (Epoch 222): Loss/seq after 04150 batchs: 493.8188781738281
INFO:root:Train (Epoch 222): Loss/seq after 04200 batchs: 492.22247314453125
INFO:root:Train (Epoch 222): Loss/seq after 04250 batchs: 490.64599609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 222): Loss/seq after 00000 batches: 412.11712646484375
INFO:root:# Valid (Epoch 222): Loss/seq after 00050 batches: 669.0009155273438
INFO:root:# Valid (Epoch 222): Loss/seq after 00100 batches: 690.2603759765625
INFO:root:# Valid (Epoch 222): Loss/seq after 00150 batches: 522.65966796875
INFO:root:# Valid (Epoch 222): Loss/seq after 00200 batches: 477.197509765625
INFO:root:Artifacts: Make stick videos for epoch 222
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_222_on_20220423_144106.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_222_index_1005_on_20220423_144106.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 223): Loss/seq after 00000 batchs: 1040.9178466796875
INFO:root:Train (Epoch 223): Loss/seq after 00050 batchs: 729.3579711914062
INFO:root:Train (Epoch 223): Loss/seq after 00100 batchs: 731.2367553710938
INFO:root:Train (Epoch 223): Loss/seq after 00150 batchs: 643.3522338867188
INFO:root:Train (Epoch 223): Loss/seq after 00200 batchs: 720.91943359375
INFO:root:Train (Epoch 223): Loss/seq after 00250 batchs: 774.3837890625
INFO:root:Train (Epoch 223): Loss/seq after 00300 batchs: 776.993408203125
INFO:root:Train (Epoch 223): Loss/seq after 00350 batchs: 732.6901245117188
INFO:root:Train (Epoch 223): Loss/seq after 00400 batchs: 737.0216064453125
INFO:root:Train (Epoch 223): Loss/seq after 00450 batchs: 726.6211547851562
INFO:root:Train (Epoch 223): Loss/seq after 00500 batchs: 701.3922119140625
INFO:root:Train (Epoch 223): Loss/seq after 00550 batchs: 680.5733642578125
INFO:root:Train (Epoch 223): Loss/seq after 00600 batchs: 656.7604370117188
INFO:root:Train (Epoch 223): Loss/seq after 00650 batchs: 643.9860229492188
INFO:root:Train (Epoch 223): Loss/seq after 00700 batchs: 623.8695068359375
INFO:root:Train (Epoch 223): Loss/seq after 00750 batchs: 626.7584228515625
INFO:root:Train (Epoch 223): Loss/seq after 00800 batchs: 626.3837890625
INFO:root:Train (Epoch 223): Loss/seq after 00850 batchs: 606.2742919921875
INFO:root:Train (Epoch 223): Loss/seq after 00900 batchs: 589.989013671875
INFO:root:Train (Epoch 223): Loss/seq after 00950 batchs: 591.5026245117188
INFO:root:Train (Epoch 223): Loss/seq after 01000 batchs: 582.6019897460938
INFO:root:Train (Epoch 223): Loss/seq after 01050 batchs: 569.9551391601562
INFO:root:Train (Epoch 223): Loss/seq after 01100 batchs: 559.045166015625
INFO:root:Train (Epoch 223): Loss/seq after 01150 batchs: 544.8787231445312
INFO:root:Train (Epoch 223): Loss/seq after 01200 batchs: 548.00244140625
INFO:root:Train (Epoch 223): Loss/seq after 01250 batchs: 545.533447265625
INFO:root:Train (Epoch 223): Loss/seq after 01300 batchs: 535.8801879882812
INFO:root:Train (Epoch 223): Loss/seq after 01350 batchs: 527.073974609375
INFO:root:Train (Epoch 223): Loss/seq after 01400 batchs: 530.154052734375
INFO:root:Train (Epoch 223): Loss/seq after 01450 batchs: 532.31591796875
INFO:root:Train (Epoch 223): Loss/seq after 01500 batchs: 538.3118286132812
INFO:root:Train (Epoch 223): Loss/seq after 01550 batchs: 540.0020141601562
INFO:root:Train (Epoch 223): Loss/seq after 01600 batchs: 535.3480224609375
INFO:root:Train (Epoch 223): Loss/seq after 01650 batchs: 532.65576171875
INFO:root:Train (Epoch 223): Loss/seq after 01700 batchs: 535.0227661132812
INFO:root:Train (Epoch 223): Loss/seq after 01750 batchs: 532.3893432617188
INFO:root:Train (Epoch 223): Loss/seq after 01800 batchs: 529.6004028320312
INFO:root:Train (Epoch 223): Loss/seq after 01850 batchs: 525.7335815429688
INFO:root:Train (Epoch 223): Loss/seq after 01900 batchs: 523.894287109375
INFO:root:Train (Epoch 223): Loss/seq after 01950 batchs: 522.3008422851562
INFO:root:Train (Epoch 223): Loss/seq after 02000 batchs: 521.760498046875
INFO:root:Train (Epoch 223): Loss/seq after 02050 batchs: 520.4883422851562
INFO:root:Train (Epoch 223): Loss/seq after 02100 batchs: 517.870849609375
INFO:root:Train (Epoch 223): Loss/seq after 02150 batchs: 515.9451904296875
INFO:root:Train (Epoch 223): Loss/seq after 02200 batchs: 513.3212890625
INFO:root:Train (Epoch 223): Loss/seq after 02250 batchs: 512.1026000976562
INFO:root:Train (Epoch 223): Loss/seq after 02300 batchs: 509.5934753417969
INFO:root:Train (Epoch 223): Loss/seq after 02350 batchs: 505.45989990234375
INFO:root:Train (Epoch 223): Loss/seq after 02400 batchs: 507.17498779296875
INFO:root:Train (Epoch 223): Loss/seq after 02450 batchs: 502.8690185546875
INFO:root:Train (Epoch 223): Loss/seq after 02500 batchs: 495.3732604980469
INFO:root:Train (Epoch 223): Loss/seq after 02550 batchs: 489.4718322753906
INFO:root:Train (Epoch 223): Loss/seq after 02600 batchs: 487.1388854980469
INFO:root:Train (Epoch 223): Loss/seq after 02650 batchs: 484.0237731933594
INFO:root:Train (Epoch 223): Loss/seq after 02700 batchs: 481.94171142578125
INFO:root:Train (Epoch 223): Loss/seq after 02750 batchs: 478.39599609375
INFO:root:Train (Epoch 223): Loss/seq after 02800 batchs: 478.4264221191406
INFO:root:Train (Epoch 223): Loss/seq after 02850 batchs: 478.0205993652344
INFO:root:Train (Epoch 223): Loss/seq after 02900 batchs: 479.4083251953125
INFO:root:Train (Epoch 223): Loss/seq after 02950 batchs: 479.009521484375
INFO:root:Train (Epoch 223): Loss/seq after 03000 batchs: 484.141357421875
INFO:root:Train (Epoch 223): Loss/seq after 03050 batchs: 486.03857421875
INFO:root:Train (Epoch 223): Loss/seq after 03100 batchs: 488.2937927246094
INFO:root:Train (Epoch 223): Loss/seq after 03150 batchs: 492.0847473144531
INFO:root:Train (Epoch 223): Loss/seq after 03200 batchs: 493.7336120605469
INFO:root:Train (Epoch 223): Loss/seq after 03250 batchs: 495.981201171875
INFO:root:Train (Epoch 223): Loss/seq after 03300 batchs: 495.30767822265625
INFO:root:Train (Epoch 223): Loss/seq after 03350 batchs: 494.2998962402344
INFO:root:Train (Epoch 223): Loss/seq after 03400 batchs: 491.0920715332031
INFO:root:Train (Epoch 223): Loss/seq after 03450 batchs: 489.5122985839844
INFO:root:Train (Epoch 223): Loss/seq after 03500 batchs: 489.818359375
INFO:root:Train (Epoch 223): Loss/seq after 03550 batchs: 487.18304443359375
INFO:root:Train (Epoch 223): Loss/seq after 03600 batchs: 494.2198486328125
INFO:root:Train (Epoch 223): Loss/seq after 03650 batchs: 492.3702697753906
INFO:root:Train (Epoch 223): Loss/seq after 03700 batchs: 494.5244140625
INFO:root:Train (Epoch 223): Loss/seq after 03750 batchs: 498.6974792480469
INFO:root:Train (Epoch 223): Loss/seq after 03800 batchs: 496.98052978515625
INFO:root:Train (Epoch 223): Loss/seq after 03850 batchs: 495.7579345703125
INFO:root:Train (Epoch 223): Loss/seq after 03900 batchs: 498.9694519042969
INFO:root:Train (Epoch 223): Loss/seq after 03950 batchs: 502.362060546875
INFO:root:Train (Epoch 223): Loss/seq after 04000 batchs: 498.8180847167969
INFO:root:Train (Epoch 223): Loss/seq after 04050 batchs: 495.7023010253906
INFO:root:Train (Epoch 223): Loss/seq after 04100 batchs: 494.33038330078125
INFO:root:Train (Epoch 223): Loss/seq after 04150 batchs: 494.15618896484375
INFO:root:Train (Epoch 223): Loss/seq after 04200 batchs: 492.61627197265625
INFO:root:Train (Epoch 223): Loss/seq after 04250 batchs: 490.9557189941406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 223): Loss/seq after 00000 batches: 461.2199401855469
INFO:root:# Valid (Epoch 223): Loss/seq after 00050 batches: 672.3319702148438
INFO:root:# Valid (Epoch 223): Loss/seq after 00100 batches: 692.1201171875
INFO:root:# Valid (Epoch 223): Loss/seq after 00150 batches: 522.4310913085938
INFO:root:# Valid (Epoch 223): Loss/seq after 00200 batches: 477.4849548339844
INFO:root:Artifacts: Make stick videos for epoch 223
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_223_on_20220423_144557.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_223_index_204_on_20220423_144557.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 224): Loss/seq after 00000 batchs: 937.4952392578125
INFO:root:Train (Epoch 224): Loss/seq after 00050 batchs: 717.9893798828125
INFO:root:Train (Epoch 224): Loss/seq after 00100 batchs: 732.4500122070312
INFO:root:Train (Epoch 224): Loss/seq after 00150 batchs: 643.1122436523438
INFO:root:Train (Epoch 224): Loss/seq after 00200 batchs: 710.9049072265625
INFO:root:Train (Epoch 224): Loss/seq after 00250 batchs: 761.2590942382812
INFO:root:Train (Epoch 224): Loss/seq after 00300 batchs: 765.8677368164062
INFO:root:Train (Epoch 224): Loss/seq after 00350 batchs: 721.6701049804688
INFO:root:Train (Epoch 224): Loss/seq after 00400 batchs: 726.6486206054688
INFO:root:Train (Epoch 224): Loss/seq after 00450 batchs: 717.8579711914062
INFO:root:Train (Epoch 224): Loss/seq after 00500 batchs: 694.5357666015625
INFO:root:Train (Epoch 224): Loss/seq after 00550 batchs: 674.1957397460938
INFO:root:Train (Epoch 224): Loss/seq after 00600 batchs: 650.8040161132812
INFO:root:Train (Epoch 224): Loss/seq after 00650 batchs: 632.1885986328125
INFO:root:Train (Epoch 224): Loss/seq after 00700 batchs: 609.8792114257812
INFO:root:Train (Epoch 224): Loss/seq after 00750 batchs: 613.0720825195312
INFO:root:Train (Epoch 224): Loss/seq after 00800 batchs: 613.4946899414062
INFO:root:Train (Epoch 224): Loss/seq after 00850 batchs: 594.1820068359375
INFO:root:Train (Epoch 224): Loss/seq after 00900 batchs: 578.2848510742188
INFO:root:Train (Epoch 224): Loss/seq after 00950 batchs: 578.1871948242188
INFO:root:Train (Epoch 224): Loss/seq after 01000 batchs: 569.9752807617188
INFO:root:Train (Epoch 224): Loss/seq after 01050 batchs: 557.7322387695312
INFO:root:Train (Epoch 224): Loss/seq after 01100 batchs: 547.4177856445312
INFO:root:Train (Epoch 224): Loss/seq after 01150 batchs: 534.2845458984375
INFO:root:Train (Epoch 224): Loss/seq after 01200 batchs: 538.7985229492188
INFO:root:Train (Epoch 224): Loss/seq after 01250 batchs: 536.5128784179688
INFO:root:Train (Epoch 224): Loss/seq after 01300 batchs: 527.371337890625
INFO:root:Train (Epoch 224): Loss/seq after 01350 batchs: 519.321533203125
INFO:root:Train (Epoch 224): Loss/seq after 01400 batchs: 522.9580078125
INFO:root:Train (Epoch 224): Loss/seq after 01450 batchs: 525.1156616210938
INFO:root:Train (Epoch 224): Loss/seq after 01500 batchs: 531.5349731445312
INFO:root:Train (Epoch 224): Loss/seq after 01550 batchs: 533.1325073242188
INFO:root:Train (Epoch 224): Loss/seq after 01600 batchs: 528.52783203125
INFO:root:Train (Epoch 224): Loss/seq after 01650 batchs: 525.9757690429688
INFO:root:Train (Epoch 224): Loss/seq after 01700 batchs: 528.4733276367188
INFO:root:Train (Epoch 224): Loss/seq after 01750 batchs: 526.0614013671875
INFO:root:Train (Epoch 224): Loss/seq after 01800 batchs: 523.4988403320312
INFO:root:Train (Epoch 224): Loss/seq after 01850 batchs: 519.833251953125
INFO:root:Train (Epoch 224): Loss/seq after 01900 batchs: 518.4205322265625
INFO:root:Train (Epoch 224): Loss/seq after 01950 batchs: 516.501708984375
INFO:root:Train (Epoch 224): Loss/seq after 02000 batchs: 515.992431640625
INFO:root:Train (Epoch 224): Loss/seq after 02050 batchs: 514.6945190429688
INFO:root:Train (Epoch 224): Loss/seq after 02100 batchs: 512.1078491210938
INFO:root:Train (Epoch 224): Loss/seq after 02150 batchs: 510.22674560546875
INFO:root:Train (Epoch 224): Loss/seq after 02200 batchs: 507.7447204589844
INFO:root:Train (Epoch 224): Loss/seq after 02250 batchs: 506.3027648925781
INFO:root:Train (Epoch 224): Loss/seq after 02300 batchs: 503.7796936035156
INFO:root:Train (Epoch 224): Loss/seq after 02350 batchs: 499.8711242675781
INFO:root:Train (Epoch 224): Loss/seq after 02400 batchs: 501.38348388671875
INFO:root:Train (Epoch 224): Loss/seq after 02450 batchs: 497.1756286621094
INFO:root:Train (Epoch 224): Loss/seq after 02500 batchs: 489.7692565917969
INFO:root:Train (Epoch 224): Loss/seq after 02550 batchs: 484.0552673339844
INFO:root:Train (Epoch 224): Loss/seq after 02600 batchs: 481.7215576171875
INFO:root:Train (Epoch 224): Loss/seq after 02650 batchs: 478.89801025390625
INFO:root:Train (Epoch 224): Loss/seq after 02700 batchs: 476.5115966796875
INFO:root:Train (Epoch 224): Loss/seq after 02750 batchs: 472.11737060546875
INFO:root:Train (Epoch 224): Loss/seq after 02800 batchs: 472.28753662109375
INFO:root:Train (Epoch 224): Loss/seq after 02850 batchs: 472.0495910644531
INFO:root:Train (Epoch 224): Loss/seq after 02900 batchs: 473.4615173339844
INFO:root:Train (Epoch 224): Loss/seq after 02950 batchs: 473.2201232910156
INFO:root:Train (Epoch 224): Loss/seq after 03000 batchs: 478.417236328125
INFO:root:Train (Epoch 224): Loss/seq after 03050 batchs: 480.114990234375
INFO:root:Train (Epoch 224): Loss/seq after 03100 batchs: 482.60906982421875
INFO:root:Train (Epoch 224): Loss/seq after 03150 batchs: 486.8249206542969
INFO:root:Train (Epoch 224): Loss/seq after 03200 batchs: 488.76544189453125
INFO:root:Train (Epoch 224): Loss/seq after 03250 batchs: 491.04248046875
INFO:root:Train (Epoch 224): Loss/seq after 03300 batchs: 490.1559143066406
INFO:root:Train (Epoch 224): Loss/seq after 03350 batchs: 488.9389953613281
INFO:root:Train (Epoch 224): Loss/seq after 03400 batchs: 485.692138671875
INFO:root:Train (Epoch 224): Loss/seq after 03450 batchs: 484.18682861328125
INFO:root:Train (Epoch 224): Loss/seq after 03500 batchs: 484.5754089355469
INFO:root:Train (Epoch 224): Loss/seq after 03550 batchs: 482.2469177246094
INFO:root:Train (Epoch 224): Loss/seq after 03600 batchs: 489.5029296875
INFO:root:Train (Epoch 224): Loss/seq after 03650 batchs: 487.6700439453125
INFO:root:Train (Epoch 224): Loss/seq after 03700 batchs: 489.6959533691406
INFO:root:Train (Epoch 224): Loss/seq after 03750 batchs: 493.80780029296875
INFO:root:Train (Epoch 224): Loss/seq after 03800 batchs: 492.14678955078125
INFO:root:Train (Epoch 224): Loss/seq after 03850 batchs: 490.99273681640625
INFO:root:Train (Epoch 224): Loss/seq after 03900 batchs: 494.0967102050781
INFO:root:Train (Epoch 224): Loss/seq after 03950 batchs: 497.7650451660156
INFO:root:Train (Epoch 224): Loss/seq after 04000 batchs: 494.2655334472656
INFO:root:Train (Epoch 224): Loss/seq after 04050 batchs: 491.1911926269531
INFO:root:Train (Epoch 224): Loss/seq after 04100 batchs: 489.8734130859375
INFO:root:Train (Epoch 224): Loss/seq after 04150 batchs: 489.5821228027344
INFO:root:Train (Epoch 224): Loss/seq after 04200 batchs: 487.986083984375
INFO:root:Train (Epoch 224): Loss/seq after 04250 batchs: 486.4459228515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 224): Loss/seq after 00000 batches: 456.4101867675781
INFO:root:# Valid (Epoch 224): Loss/seq after 00050 batches: 670.7437133789062
INFO:root:# Valid (Epoch 224): Loss/seq after 00100 batches: 698.4856567382812
INFO:root:# Valid (Epoch 224): Loss/seq after 00150 batches: 527.3768310546875
INFO:root:# Valid (Epoch 224): Loss/seq after 00200 batches: 482.64788818359375
INFO:root:Artifacts: Make stick videos for epoch 224
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_224_on_20220423_145057.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_224_index_127_on_20220423_145057.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 225): Loss/seq after 00000 batchs: 873.5173950195312
INFO:root:Train (Epoch 225): Loss/seq after 00050 batchs: 698.2589111328125
INFO:root:Train (Epoch 225): Loss/seq after 00100 batchs: 714.0172119140625
INFO:root:Train (Epoch 225): Loss/seq after 00150 batchs: 631.540771484375
INFO:root:Train (Epoch 225): Loss/seq after 00200 batchs: 712.8282470703125
INFO:root:Train (Epoch 225): Loss/seq after 00250 batchs: 760.3052368164062
INFO:root:Train (Epoch 225): Loss/seq after 00300 batchs: 763.1771240234375
INFO:root:Train (Epoch 225): Loss/seq after 00350 batchs: 719.2560424804688
INFO:root:Train (Epoch 225): Loss/seq after 00400 batchs: 717.7267456054688
INFO:root:Train (Epoch 225): Loss/seq after 00450 batchs: 709.3651123046875
INFO:root:Train (Epoch 225): Loss/seq after 00500 batchs: 685.8675537109375
INFO:root:Train (Epoch 225): Loss/seq after 00550 batchs: 666.2495727539062
INFO:root:Train (Epoch 225): Loss/seq after 00600 batchs: 644.021240234375
INFO:root:Train (Epoch 225): Loss/seq after 00650 batchs: 632.6893310546875
INFO:root:Train (Epoch 225): Loss/seq after 00700 batchs: 612.6333618164062
INFO:root:Train (Epoch 225): Loss/seq after 00750 batchs: 615.8408813476562
INFO:root:Train (Epoch 225): Loss/seq after 00800 batchs: 615.4879760742188
INFO:root:Train (Epoch 225): Loss/seq after 00850 batchs: 595.1740112304688
INFO:root:Train (Epoch 225): Loss/seq after 00900 batchs: 579.294921875
INFO:root:Train (Epoch 225): Loss/seq after 00950 batchs: 581.4932861328125
INFO:root:Train (Epoch 225): Loss/seq after 01000 batchs: 574.074951171875
INFO:root:Train (Epoch 225): Loss/seq after 01050 batchs: 561.5687255859375
INFO:root:Train (Epoch 225): Loss/seq after 01100 batchs: 550.998291015625
INFO:root:Train (Epoch 225): Loss/seq after 01150 batchs: 537.6002807617188
INFO:root:Train (Epoch 225): Loss/seq after 01200 batchs: 541.2742919921875
INFO:root:Train (Epoch 225): Loss/seq after 01250 batchs: 539.60595703125
INFO:root:Train (Epoch 225): Loss/seq after 01300 batchs: 529.5863037109375
INFO:root:Train (Epoch 225): Loss/seq after 01350 batchs: 521.03271484375
INFO:root:Train (Epoch 225): Loss/seq after 01400 batchs: 524.76611328125
INFO:root:Train (Epoch 225): Loss/seq after 01450 batchs: 526.6334838867188
INFO:root:Train (Epoch 225): Loss/seq after 01500 batchs: 532.50927734375
INFO:root:Train (Epoch 225): Loss/seq after 01550 batchs: 534.2718505859375
INFO:root:Train (Epoch 225): Loss/seq after 01600 batchs: 529.6729125976562
INFO:root:Train (Epoch 225): Loss/seq after 01650 batchs: 527.0049438476562
INFO:root:Train (Epoch 225): Loss/seq after 01700 batchs: 529.6061401367188
INFO:root:Train (Epoch 225): Loss/seq after 01750 batchs: 527.380615234375
INFO:root:Train (Epoch 225): Loss/seq after 01800 batchs: 524.8064575195312
INFO:root:Train (Epoch 225): Loss/seq after 01850 batchs: 521.0578002929688
INFO:root:Train (Epoch 225): Loss/seq after 01900 batchs: 519.1323852539062
INFO:root:Train (Epoch 225): Loss/seq after 01950 batchs: 517.4142456054688
INFO:root:Train (Epoch 225): Loss/seq after 02000 batchs: 516.9534912109375
INFO:root:Train (Epoch 225): Loss/seq after 02050 batchs: 515.4786376953125
INFO:root:Train (Epoch 225): Loss/seq after 02100 batchs: 513.067626953125
INFO:root:Train (Epoch 225): Loss/seq after 02150 batchs: 511.2528381347656
INFO:root:Train (Epoch 225): Loss/seq after 02200 batchs: 508.7113342285156
INFO:root:Train (Epoch 225): Loss/seq after 02250 batchs: 507.3625793457031
INFO:root:Train (Epoch 225): Loss/seq after 02300 batchs: 505.01483154296875
INFO:root:Train (Epoch 225): Loss/seq after 02350 batchs: 501.2366943359375
INFO:root:Train (Epoch 225): Loss/seq after 02400 batchs: 502.9707336425781
INFO:root:Train (Epoch 225): Loss/seq after 02450 batchs: 498.69293212890625
INFO:root:Train (Epoch 225): Loss/seq after 02500 batchs: 491.2547912597656
INFO:root:Train (Epoch 225): Loss/seq after 02550 batchs: 485.40350341796875
INFO:root:Train (Epoch 225): Loss/seq after 02600 batchs: 483.2091979980469
INFO:root:Train (Epoch 225): Loss/seq after 02650 batchs: 480.3005065917969
INFO:root:Train (Epoch 225): Loss/seq after 02700 batchs: 477.89764404296875
INFO:root:Train (Epoch 225): Loss/seq after 02750 batchs: 473.6165771484375
INFO:root:Train (Epoch 225): Loss/seq after 02800 batchs: 473.20428466796875
INFO:root:Train (Epoch 225): Loss/seq after 02850 batchs: 472.799072265625
INFO:root:Train (Epoch 225): Loss/seq after 02900 batchs: 474.24932861328125
INFO:root:Train (Epoch 225): Loss/seq after 02950 batchs: 473.9472961425781
INFO:root:Train (Epoch 225): Loss/seq after 03000 batchs: 479.1731262207031
INFO:root:Train (Epoch 225): Loss/seq after 03050 batchs: 481.0743408203125
INFO:root:Train (Epoch 225): Loss/seq after 03100 batchs: 483.4495544433594
INFO:root:Train (Epoch 225): Loss/seq after 03150 batchs: 487.40771484375
INFO:root:Train (Epoch 225): Loss/seq after 03200 batchs: 488.780029296875
INFO:root:Train (Epoch 225): Loss/seq after 03250 batchs: 491.20855712890625
INFO:root:Train (Epoch 225): Loss/seq after 03300 batchs: 490.2103271484375
INFO:root:Train (Epoch 225): Loss/seq after 03350 batchs: 488.920654296875
INFO:root:Train (Epoch 225): Loss/seq after 03400 batchs: 485.62744140625
INFO:root:Train (Epoch 225): Loss/seq after 03450 batchs: 484.0264587402344
INFO:root:Train (Epoch 225): Loss/seq after 03500 batchs: 484.3450012207031
INFO:root:Train (Epoch 225): Loss/seq after 03550 batchs: 481.8949890136719
INFO:root:Train (Epoch 225): Loss/seq after 03600 batchs: 489.5927734375
INFO:root:Train (Epoch 225): Loss/seq after 03650 batchs: 487.8947448730469
INFO:root:Train (Epoch 225): Loss/seq after 03700 batchs: 490.0737609863281
INFO:root:Train (Epoch 225): Loss/seq after 03750 batchs: 494.39239501953125
INFO:root:Train (Epoch 225): Loss/seq after 03800 batchs: 492.70721435546875
INFO:root:Train (Epoch 225): Loss/seq after 03850 batchs: 491.6772766113281
INFO:root:Train (Epoch 225): Loss/seq after 03900 batchs: 495.5072937011719
INFO:root:Train (Epoch 225): Loss/seq after 03950 batchs: 498.92205810546875
INFO:root:Train (Epoch 225): Loss/seq after 04000 batchs: 495.3979797363281
INFO:root:Train (Epoch 225): Loss/seq after 04050 batchs: 492.3437805175781
INFO:root:Train (Epoch 225): Loss/seq after 04100 batchs: 491.0600891113281
INFO:root:Train (Epoch 225): Loss/seq after 04150 batchs: 490.76593017578125
INFO:root:Train (Epoch 225): Loss/seq after 04200 batchs: 489.1988830566406
INFO:root:Train (Epoch 225): Loss/seq after 04250 batchs: 487.6933898925781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 225): Loss/seq after 00000 batches: 446.7629089355469
INFO:root:# Valid (Epoch 225): Loss/seq after 00050 batches: 682.4129638671875
INFO:root:# Valid (Epoch 225): Loss/seq after 00100 batches: 703.4630737304688
INFO:root:# Valid (Epoch 225): Loss/seq after 00150 batches: 528.6016235351562
INFO:root:# Valid (Epoch 225): Loss/seq after 00200 batches: 481.57537841796875
INFO:root:Artifacts: Make stick videos for epoch 225
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_225_on_20220423_145542.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_225_index_1090_on_20220423_145542.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 226): Loss/seq after 00000 batchs: 1006.5200805664062
INFO:root:Train (Epoch 226): Loss/seq after 00050 batchs: 719.0062255859375
INFO:root:Train (Epoch 226): Loss/seq after 00100 batchs: 705.2163696289062
INFO:root:Train (Epoch 226): Loss/seq after 00150 batchs: 621.3422241210938
INFO:root:Train (Epoch 226): Loss/seq after 00200 batchs: 705.857177734375
INFO:root:Train (Epoch 226): Loss/seq after 00250 batchs: 754.0718994140625
INFO:root:Train (Epoch 226): Loss/seq after 00300 batchs: 758.2503662109375
INFO:root:Train (Epoch 226): Loss/seq after 00350 batchs: 714.7689208984375
INFO:root:Train (Epoch 226): Loss/seq after 00400 batchs: 719.0194091796875
INFO:root:Train (Epoch 226): Loss/seq after 00450 batchs: 710.3260498046875
INFO:root:Train (Epoch 226): Loss/seq after 00500 batchs: 687.6267700195312
INFO:root:Train (Epoch 226): Loss/seq after 00550 batchs: 667.1381225585938
INFO:root:Train (Epoch 226): Loss/seq after 00600 batchs: 643.4524536132812
INFO:root:Train (Epoch 226): Loss/seq after 00650 batchs: 630.7440795898438
INFO:root:Train (Epoch 226): Loss/seq after 00700 batchs: 611.3306274414062
INFO:root:Train (Epoch 226): Loss/seq after 00750 batchs: 614.20458984375
INFO:root:Train (Epoch 226): Loss/seq after 00800 batchs: 614.1744384765625
INFO:root:Train (Epoch 226): Loss/seq after 00850 batchs: 594.9358520507812
INFO:root:Train (Epoch 226): Loss/seq after 00900 batchs: 578.8432006835938
INFO:root:Train (Epoch 226): Loss/seq after 00950 batchs: 580.4097290039062
INFO:root:Train (Epoch 226): Loss/seq after 01000 batchs: 571.1243896484375
INFO:root:Train (Epoch 226): Loss/seq after 01050 batchs: 559.3567504882812
INFO:root:Train (Epoch 226): Loss/seq after 01100 batchs: 548.2222900390625
INFO:root:Train (Epoch 226): Loss/seq after 01150 batchs: 534.9920043945312
INFO:root:Train (Epoch 226): Loss/seq after 01200 batchs: 538.7017822265625
INFO:root:Train (Epoch 226): Loss/seq after 01250 batchs: 536.1588134765625
INFO:root:Train (Epoch 226): Loss/seq after 01300 batchs: 526.3079833984375
INFO:root:Train (Epoch 226): Loss/seq after 01350 batchs: 517.5502319335938
INFO:root:Train (Epoch 226): Loss/seq after 01400 batchs: 520.6829223632812
INFO:root:Train (Epoch 226): Loss/seq after 01450 batchs: 522.6887817382812
INFO:root:Train (Epoch 226): Loss/seq after 01500 batchs: 528.8529052734375
INFO:root:Train (Epoch 226): Loss/seq after 01550 batchs: 530.970703125
INFO:root:Train (Epoch 226): Loss/seq after 01600 batchs: 526.7005615234375
INFO:root:Train (Epoch 226): Loss/seq after 01650 batchs: 524.1412353515625
INFO:root:Train (Epoch 226): Loss/seq after 01700 batchs: 526.8186645507812
INFO:root:Train (Epoch 226): Loss/seq after 01750 batchs: 524.3228759765625
INFO:root:Train (Epoch 226): Loss/seq after 01800 batchs: 521.7264404296875
INFO:root:Train (Epoch 226): Loss/seq after 01850 batchs: 518.0403442382812
INFO:root:Train (Epoch 226): Loss/seq after 01900 batchs: 516.3212890625
INFO:root:Train (Epoch 226): Loss/seq after 01950 batchs: 514.5426635742188
INFO:root:Train (Epoch 226): Loss/seq after 02000 batchs: 514.0122680664062
INFO:root:Train (Epoch 226): Loss/seq after 02050 batchs: 512.5330200195312
INFO:root:Train (Epoch 226): Loss/seq after 02100 batchs: 510.0306396484375
INFO:root:Train (Epoch 226): Loss/seq after 02150 batchs: 508.2969665527344
INFO:root:Train (Epoch 226): Loss/seq after 02200 batchs: 505.814453125
INFO:root:Train (Epoch 226): Loss/seq after 02250 batchs: 504.6500549316406
INFO:root:Train (Epoch 226): Loss/seq after 02300 batchs: 502.9216003417969
INFO:root:Train (Epoch 226): Loss/seq after 02350 batchs: 499.24078369140625
INFO:root:Train (Epoch 226): Loss/seq after 02400 batchs: 500.92291259765625
INFO:root:Train (Epoch 226): Loss/seq after 02450 batchs: 496.7358093261719
INFO:root:Train (Epoch 226): Loss/seq after 02500 batchs: 489.3123779296875
INFO:root:Train (Epoch 226): Loss/seq after 02550 batchs: 483.3837585449219
INFO:root:Train (Epoch 226): Loss/seq after 02600 batchs: 481.2315979003906
INFO:root:Train (Epoch 226): Loss/seq after 02650 batchs: 478.094482421875
INFO:root:Train (Epoch 226): Loss/seq after 02700 batchs: 475.8484191894531
INFO:root:Train (Epoch 226): Loss/seq after 02750 batchs: 472.4256896972656
INFO:root:Train (Epoch 226): Loss/seq after 02800 batchs: 472.0507507324219
INFO:root:Train (Epoch 226): Loss/seq after 02850 batchs: 471.6573181152344
INFO:root:Train (Epoch 226): Loss/seq after 02900 batchs: 472.93182373046875
INFO:root:Train (Epoch 226): Loss/seq after 02950 batchs: 472.5805358886719
INFO:root:Train (Epoch 226): Loss/seq after 03000 batchs: 477.6900329589844
INFO:root:Train (Epoch 226): Loss/seq after 03050 batchs: 479.7507629394531
INFO:root:Train (Epoch 226): Loss/seq after 03100 batchs: 482.1767578125
INFO:root:Train (Epoch 226): Loss/seq after 03150 batchs: 486.0464782714844
INFO:root:Train (Epoch 226): Loss/seq after 03200 batchs: 487.0993957519531
INFO:root:Train (Epoch 226): Loss/seq after 03250 batchs: 490.1272277832031
INFO:root:Train (Epoch 226): Loss/seq after 03300 batchs: 489.6204833984375
INFO:root:Train (Epoch 226): Loss/seq after 03350 batchs: 488.4799499511719
INFO:root:Train (Epoch 226): Loss/seq after 03400 batchs: 485.303466796875
INFO:root:Train (Epoch 226): Loss/seq after 03450 batchs: 483.6932678222656
INFO:root:Train (Epoch 226): Loss/seq after 03500 batchs: 484.545166015625
INFO:root:Train (Epoch 226): Loss/seq after 03550 batchs: 482.1741027832031
INFO:root:Train (Epoch 226): Loss/seq after 03600 batchs: 489.5156555175781
INFO:root:Train (Epoch 226): Loss/seq after 03650 batchs: 487.6550598144531
INFO:root:Train (Epoch 226): Loss/seq after 03700 batchs: 489.86468505859375
INFO:root:Train (Epoch 226): Loss/seq after 03750 batchs: 493.9218444824219
INFO:root:Train (Epoch 226): Loss/seq after 03800 batchs: 492.21649169921875
INFO:root:Train (Epoch 226): Loss/seq after 03850 batchs: 491.1207580566406
INFO:root:Train (Epoch 226): Loss/seq after 03900 batchs: 494.3868408203125
INFO:root:Train (Epoch 226): Loss/seq after 03950 batchs: 497.4941101074219
INFO:root:Train (Epoch 226): Loss/seq after 04000 batchs: 493.994873046875
INFO:root:Train (Epoch 226): Loss/seq after 04050 batchs: 490.93096923828125
INFO:root:Train (Epoch 226): Loss/seq after 04100 batchs: 489.69671630859375
INFO:root:Train (Epoch 226): Loss/seq after 04150 batchs: 489.4526672363281
INFO:root:Train (Epoch 226): Loss/seq after 04200 batchs: 487.9059753417969
INFO:root:Train (Epoch 226): Loss/seq after 04250 batchs: 486.2377014160156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 226): Loss/seq after 00000 batches: 454.0929260253906
INFO:root:# Valid (Epoch 226): Loss/seq after 00050 batches: 704.5399169921875
INFO:root:# Valid (Epoch 226): Loss/seq after 00100 batches: 709.8363037109375
INFO:root:# Valid (Epoch 226): Loss/seq after 00150 batches: 534.5405883789062
INFO:root:# Valid (Epoch 226): Loss/seq after 00200 batches: 487.2602844238281
INFO:root:Artifacts: Make stick videos for epoch 226
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_226_on_20220423_150041.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_226_index_917_on_20220423_150041.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 227): Loss/seq after 00000 batchs: 1362.7115478515625
INFO:root:Train (Epoch 227): Loss/seq after 00050 batchs: 699.2836303710938
INFO:root:Train (Epoch 227): Loss/seq after 00100 batchs: 699.58740234375
INFO:root:Train (Epoch 227): Loss/seq after 00150 batchs: 619.2319946289062
INFO:root:Train (Epoch 227): Loss/seq after 00200 batchs: 699.5287475585938
INFO:root:Train (Epoch 227): Loss/seq after 00250 batchs: 748.864013671875
INFO:root:Train (Epoch 227): Loss/seq after 00300 batchs: 753.1467895507812
INFO:root:Train (Epoch 227): Loss/seq after 00350 batchs: 710.5367431640625
INFO:root:Train (Epoch 227): Loss/seq after 00400 batchs: 711.4251098632812
INFO:root:Train (Epoch 227): Loss/seq after 00450 batchs: 703.9271240234375
INFO:root:Train (Epoch 227): Loss/seq after 00500 batchs: 681.9671630859375
INFO:root:Train (Epoch 227): Loss/seq after 00550 batchs: 663.2071533203125
INFO:root:Train (Epoch 227): Loss/seq after 00600 batchs: 641.2805786132812
INFO:root:Train (Epoch 227): Loss/seq after 00650 batchs: 627.1395874023438
INFO:root:Train (Epoch 227): Loss/seq after 00700 batchs: 605.5698852539062
INFO:root:Train (Epoch 227): Loss/seq after 00750 batchs: 609.7689208984375
INFO:root:Train (Epoch 227): Loss/seq after 00800 batchs: 608.6924438476562
INFO:root:Train (Epoch 227): Loss/seq after 00850 batchs: 589.3256225585938
INFO:root:Train (Epoch 227): Loss/seq after 00900 batchs: 574.1312866210938
INFO:root:Train (Epoch 227): Loss/seq after 00950 batchs: 573.3826293945312
INFO:root:Train (Epoch 227): Loss/seq after 01000 batchs: 564.3834838867188
INFO:root:Train (Epoch 227): Loss/seq after 01050 batchs: 552.072021484375
INFO:root:Train (Epoch 227): Loss/seq after 01100 batchs: 541.7652587890625
INFO:root:Train (Epoch 227): Loss/seq after 01150 batchs: 528.8201904296875
INFO:root:Train (Epoch 227): Loss/seq after 01200 batchs: 532.4332275390625
INFO:root:Train (Epoch 227): Loss/seq after 01250 batchs: 530.4458618164062
INFO:root:Train (Epoch 227): Loss/seq after 01300 batchs: 520.8021240234375
INFO:root:Train (Epoch 227): Loss/seq after 01350 batchs: 512.05224609375
INFO:root:Train (Epoch 227): Loss/seq after 01400 batchs: 514.3643188476562
INFO:root:Train (Epoch 227): Loss/seq after 01450 batchs: 516.4856567382812
INFO:root:Train (Epoch 227): Loss/seq after 01500 batchs: 522.4169311523438
INFO:root:Train (Epoch 227): Loss/seq after 01550 batchs: 524.2962036132812
INFO:root:Train (Epoch 227): Loss/seq after 01600 batchs: 520.0399780273438
INFO:root:Train (Epoch 227): Loss/seq after 01650 batchs: 517.4426879882812
INFO:root:Train (Epoch 227): Loss/seq after 01700 batchs: 520.3829345703125
INFO:root:Train (Epoch 227): Loss/seq after 01750 batchs: 517.997802734375
INFO:root:Train (Epoch 227): Loss/seq after 01800 batchs: 515.3287353515625
INFO:root:Train (Epoch 227): Loss/seq after 01850 batchs: 511.7980041503906
INFO:root:Train (Epoch 227): Loss/seq after 01900 batchs: 509.9660339355469
INFO:root:Train (Epoch 227): Loss/seq after 01950 batchs: 508.51055908203125
INFO:root:Train (Epoch 227): Loss/seq after 02000 batchs: 508.15338134765625
INFO:root:Train (Epoch 227): Loss/seq after 02050 batchs: 506.66973876953125
INFO:root:Train (Epoch 227): Loss/seq after 02100 batchs: 504.3860168457031
INFO:root:Train (Epoch 227): Loss/seq after 02150 batchs: 502.69146728515625
INFO:root:Train (Epoch 227): Loss/seq after 02200 batchs: 500.3706970214844
INFO:root:Train (Epoch 227): Loss/seq after 02250 batchs: 498.9277648925781
INFO:root:Train (Epoch 227): Loss/seq after 02300 batchs: 496.32208251953125
INFO:root:Train (Epoch 227): Loss/seq after 02350 batchs: 492.4449157714844
INFO:root:Train (Epoch 227): Loss/seq after 02400 batchs: 494.4665222167969
INFO:root:Train (Epoch 227): Loss/seq after 02450 batchs: 490.3753967285156
INFO:root:Train (Epoch 227): Loss/seq after 02500 batchs: 483.077880859375
INFO:root:Train (Epoch 227): Loss/seq after 02550 batchs: 477.4064636230469
INFO:root:Train (Epoch 227): Loss/seq after 02600 batchs: 475.2164611816406
INFO:root:Train (Epoch 227): Loss/seq after 02650 batchs: 472.09429931640625
INFO:root:Train (Epoch 227): Loss/seq after 02700 batchs: 469.8328552246094
INFO:root:Train (Epoch 227): Loss/seq after 02750 batchs: 465.6205139160156
INFO:root:Train (Epoch 227): Loss/seq after 02800 batchs: 465.41998291015625
INFO:root:Train (Epoch 227): Loss/seq after 02850 batchs: 465.1535339355469
INFO:root:Train (Epoch 227): Loss/seq after 02900 batchs: 466.6961669921875
INFO:root:Train (Epoch 227): Loss/seq after 02950 batchs: 466.4116516113281
INFO:root:Train (Epoch 227): Loss/seq after 03000 batchs: 471.41632080078125
INFO:root:Train (Epoch 227): Loss/seq after 03050 batchs: 473.5086669921875
INFO:root:Train (Epoch 227): Loss/seq after 03100 batchs: 475.9364929199219
INFO:root:Train (Epoch 227): Loss/seq after 03150 batchs: 480.7480773925781
INFO:root:Train (Epoch 227): Loss/seq after 03200 batchs: 482.38079833984375
INFO:root:Train (Epoch 227): Loss/seq after 03250 batchs: 484.7909851074219
INFO:root:Train (Epoch 227): Loss/seq after 03300 batchs: 484.21820068359375
INFO:root:Train (Epoch 227): Loss/seq after 03350 batchs: 483.3616027832031
INFO:root:Train (Epoch 227): Loss/seq after 03400 batchs: 480.2467041015625
INFO:root:Train (Epoch 227): Loss/seq after 03450 batchs: 478.78057861328125
INFO:root:Train (Epoch 227): Loss/seq after 03500 batchs: 479.4840087890625
INFO:root:Train (Epoch 227): Loss/seq after 03550 batchs: 477.0639953613281
INFO:root:Train (Epoch 227): Loss/seq after 03600 batchs: 484.3131408691406
INFO:root:Train (Epoch 227): Loss/seq after 03650 batchs: 482.4625549316406
INFO:root:Train (Epoch 227): Loss/seq after 03700 batchs: 484.497314453125
INFO:root:Train (Epoch 227): Loss/seq after 03750 batchs: 488.6017150878906
INFO:root:Train (Epoch 227): Loss/seq after 03800 batchs: 487.0189514160156
INFO:root:Train (Epoch 227): Loss/seq after 03850 batchs: 485.9908142089844
INFO:root:Train (Epoch 227): Loss/seq after 03900 batchs: 489.2513427734375
INFO:root:Train (Epoch 227): Loss/seq after 03950 batchs: 492.6885070800781
INFO:root:Train (Epoch 227): Loss/seq after 04000 batchs: 489.261962890625
INFO:root:Train (Epoch 227): Loss/seq after 04050 batchs: 486.3066101074219
INFO:root:Train (Epoch 227): Loss/seq after 04100 batchs: 485.0812072753906
INFO:root:Train (Epoch 227): Loss/seq after 04150 batchs: 484.8106384277344
INFO:root:Train (Epoch 227): Loss/seq after 04200 batchs: 483.2421569824219
INFO:root:Train (Epoch 227): Loss/seq after 04250 batchs: 481.7344055175781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 227): Loss/seq after 00000 batches: 445.6101379394531
INFO:root:# Valid (Epoch 227): Loss/seq after 00050 batches: 670.081298828125
INFO:root:# Valid (Epoch 227): Loss/seq after 00100 batches: 708.6535034179688
INFO:root:# Valid (Epoch 227): Loss/seq after 00150 batches: 535.40576171875
INFO:root:# Valid (Epoch 227): Loss/seq after 00200 batches: 490.8240051269531
INFO:root:Artifacts: Make stick videos for epoch 227
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_227_on_20220423_150532.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_227_index_1752_on_20220423_150532.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 228): Loss/seq after 00000 batchs: 1066.73779296875
INFO:root:Train (Epoch 228): Loss/seq after 00050 batchs: 705.607421875
INFO:root:Train (Epoch 228): Loss/seq after 00100 batchs: 703.029296875
INFO:root:Train (Epoch 228): Loss/seq after 00150 batchs: 621.3927001953125
INFO:root:Train (Epoch 228): Loss/seq after 00200 batchs: 694.2442016601562
INFO:root:Train (Epoch 228): Loss/seq after 00250 batchs: 739.0812377929688
INFO:root:Train (Epoch 228): Loss/seq after 00300 batchs: 744.1735229492188
INFO:root:Train (Epoch 228): Loss/seq after 00350 batchs: 702.71435546875
INFO:root:Train (Epoch 228): Loss/seq after 00400 batchs: 702.8336181640625
INFO:root:Train (Epoch 228): Loss/seq after 00450 batchs: 695.9468994140625
INFO:root:Train (Epoch 228): Loss/seq after 00500 batchs: 674.2677001953125
INFO:root:Train (Epoch 228): Loss/seq after 00550 batchs: 654.7496337890625
INFO:root:Train (Epoch 228): Loss/seq after 00600 batchs: 632.1941528320312
INFO:root:Train (Epoch 228): Loss/seq after 00650 batchs: 619.5961303710938
INFO:root:Train (Epoch 228): Loss/seq after 00700 batchs: 600.5747680664062
INFO:root:Train (Epoch 228): Loss/seq after 00750 batchs: 604.8712158203125
INFO:root:Train (Epoch 228): Loss/seq after 00800 batchs: 604.5921020507812
INFO:root:Train (Epoch 228): Loss/seq after 00850 batchs: 585.5867919921875
INFO:root:Train (Epoch 228): Loss/seq after 00900 batchs: 569.6641235351562
INFO:root:Train (Epoch 228): Loss/seq after 00950 batchs: 572.5390014648438
INFO:root:Train (Epoch 228): Loss/seq after 01000 batchs: 563.9304809570312
INFO:root:Train (Epoch 228): Loss/seq after 01050 batchs: 551.9296875
INFO:root:Train (Epoch 228): Loss/seq after 01100 batchs: 541.568359375
INFO:root:Train (Epoch 228): Loss/seq after 01150 batchs: 528.2503051757812
INFO:root:Train (Epoch 228): Loss/seq after 01200 batchs: 531.8241577148438
INFO:root:Train (Epoch 228): Loss/seq after 01250 batchs: 529.880859375
INFO:root:Train (Epoch 228): Loss/seq after 01300 batchs: 520.4678344726562
INFO:root:Train (Epoch 228): Loss/seq after 01350 batchs: 511.8943176269531
INFO:root:Train (Epoch 228): Loss/seq after 01400 batchs: 515.4151611328125
INFO:root:Train (Epoch 228): Loss/seq after 01450 batchs: 517.5338745117188
INFO:root:Train (Epoch 228): Loss/seq after 01500 batchs: 523.2874145507812
INFO:root:Train (Epoch 228): Loss/seq after 01550 batchs: 524.7389526367188
INFO:root:Train (Epoch 228): Loss/seq after 01600 batchs: 520.201904296875
INFO:root:Train (Epoch 228): Loss/seq after 01650 batchs: 517.7760009765625
INFO:root:Train (Epoch 228): Loss/seq after 01700 batchs: 520.431396484375
INFO:root:Train (Epoch 228): Loss/seq after 01750 batchs: 518.062255859375
INFO:root:Train (Epoch 228): Loss/seq after 01800 batchs: 515.6971435546875
INFO:root:Train (Epoch 228): Loss/seq after 01850 batchs: 512.1900634765625
INFO:root:Train (Epoch 228): Loss/seq after 01900 batchs: 510.9822692871094
INFO:root:Train (Epoch 228): Loss/seq after 01950 batchs: 509.59033203125
INFO:root:Train (Epoch 228): Loss/seq after 02000 batchs: 509.4170837402344
INFO:root:Train (Epoch 228): Loss/seq after 02050 batchs: 507.96173095703125
INFO:root:Train (Epoch 228): Loss/seq after 02100 batchs: 505.6245422363281
INFO:root:Train (Epoch 228): Loss/seq after 02150 batchs: 503.91290283203125
INFO:root:Train (Epoch 228): Loss/seq after 02200 batchs: 501.5249328613281
INFO:root:Train (Epoch 228): Loss/seq after 02250 batchs: 500.517333984375
INFO:root:Train (Epoch 228): Loss/seq after 02300 batchs: 498.0381164550781
INFO:root:Train (Epoch 228): Loss/seq after 02350 batchs: 494.146484375
INFO:root:Train (Epoch 228): Loss/seq after 02400 batchs: 495.8636169433594
INFO:root:Train (Epoch 228): Loss/seq after 02450 batchs: 491.6288146972656
INFO:root:Train (Epoch 228): Loss/seq after 02500 batchs: 484.2961730957031
INFO:root:Train (Epoch 228): Loss/seq after 02550 batchs: 478.45477294921875
INFO:root:Train (Epoch 228): Loss/seq after 02600 batchs: 476.2346496582031
INFO:root:Train (Epoch 228): Loss/seq after 02650 batchs: 473.0700988769531
INFO:root:Train (Epoch 228): Loss/seq after 02700 batchs: 470.9334716796875
INFO:root:Train (Epoch 228): Loss/seq after 02750 batchs: 467.44793701171875
INFO:root:Train (Epoch 228): Loss/seq after 02800 batchs: 466.8860168457031
INFO:root:Train (Epoch 228): Loss/seq after 02850 batchs: 466.5037841796875
INFO:root:Train (Epoch 228): Loss/seq after 02900 batchs: 467.7437744140625
INFO:root:Train (Epoch 228): Loss/seq after 02950 batchs: 467.4706726074219
INFO:root:Train (Epoch 228): Loss/seq after 03000 batchs: 472.7465515136719
INFO:root:Train (Epoch 228): Loss/seq after 03050 batchs: 474.77484130859375
INFO:root:Train (Epoch 228): Loss/seq after 03100 batchs: 477.7115173339844
INFO:root:Train (Epoch 228): Loss/seq after 03150 batchs: 480.90087890625
INFO:root:Train (Epoch 228): Loss/seq after 03200 batchs: 482.0754089355469
INFO:root:Train (Epoch 228): Loss/seq after 03250 batchs: 484.9020690917969
INFO:root:Train (Epoch 228): Loss/seq after 03300 batchs: 484.6250915527344
INFO:root:Train (Epoch 228): Loss/seq after 03350 batchs: 483.53900146484375
INFO:root:Train (Epoch 228): Loss/seq after 03400 batchs: 480.43597412109375
INFO:root:Train (Epoch 228): Loss/seq after 03450 batchs: 478.9664306640625
INFO:root:Train (Epoch 228): Loss/seq after 03500 batchs: 479.4853515625
INFO:root:Train (Epoch 228): Loss/seq after 03550 batchs: 477.0248107910156
INFO:root:Train (Epoch 228): Loss/seq after 03600 batchs: 484.2170715332031
INFO:root:Train (Epoch 228): Loss/seq after 03650 batchs: 482.31585693359375
INFO:root:Train (Epoch 228): Loss/seq after 03700 batchs: 484.32562255859375
INFO:root:Train (Epoch 228): Loss/seq after 03750 batchs: 488.4366455078125
INFO:root:Train (Epoch 228): Loss/seq after 03800 batchs: 486.8000183105469
INFO:root:Train (Epoch 228): Loss/seq after 03850 batchs: 485.69287109375
INFO:root:Train (Epoch 228): Loss/seq after 03900 batchs: 488.8819580078125
INFO:root:Train (Epoch 228): Loss/seq after 03950 batchs: 492.2777404785156
INFO:root:Train (Epoch 228): Loss/seq after 04000 batchs: 488.8128662109375
INFO:root:Train (Epoch 228): Loss/seq after 04050 batchs: 485.8814697265625
INFO:root:Train (Epoch 228): Loss/seq after 04100 batchs: 484.6510925292969
INFO:root:Train (Epoch 228): Loss/seq after 04150 batchs: 484.436767578125
INFO:root:Train (Epoch 228): Loss/seq after 04200 batchs: 482.92144775390625
INFO:root:Train (Epoch 228): Loss/seq after 04250 batchs: 481.4104919433594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 228): Loss/seq after 00000 batches: 463.0005798339844
INFO:root:# Valid (Epoch 228): Loss/seq after 00050 batches: 685.415771484375
INFO:root:# Valid (Epoch 228): Loss/seq after 00100 batches: 693.1019897460938
INFO:root:# Valid (Epoch 228): Loss/seq after 00150 batches: 522.316650390625
INFO:root:# Valid (Epoch 228): Loss/seq after 00200 batches: 479.63275146484375
INFO:root:Artifacts: Make stick videos for epoch 228
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_228_on_20220423_151023.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_228_index_301_on_20220423_151023.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 229): Loss/seq after 00000 batchs: 821.19384765625
INFO:root:Train (Epoch 229): Loss/seq after 00050 batchs: 698.5349731445312
INFO:root:Train (Epoch 229): Loss/seq after 00100 batchs: 697.7937622070312
INFO:root:Train (Epoch 229): Loss/seq after 00150 batchs: 616.732177734375
INFO:root:Train (Epoch 229): Loss/seq after 00200 batchs: 684.4848022460938
INFO:root:Train (Epoch 229): Loss/seq after 00250 batchs: 741.3953857421875
INFO:root:Train (Epoch 229): Loss/seq after 00300 batchs: 746.6743774414062
INFO:root:Train (Epoch 229): Loss/seq after 00350 batchs: 704.7921752929688
INFO:root:Train (Epoch 229): Loss/seq after 00400 batchs: 706.6366577148438
INFO:root:Train (Epoch 229): Loss/seq after 00450 batchs: 699.5859985351562
INFO:root:Train (Epoch 229): Loss/seq after 00500 batchs: 677.124267578125
INFO:root:Train (Epoch 229): Loss/seq after 00550 batchs: 658.4103393554688
INFO:root:Train (Epoch 229): Loss/seq after 00600 batchs: 635.7813720703125
INFO:root:Train (Epoch 229): Loss/seq after 00650 batchs: 616.6835327148438
INFO:root:Train (Epoch 229): Loss/seq after 00700 batchs: 597.3697509765625
INFO:root:Train (Epoch 229): Loss/seq after 00750 batchs: 600.9349975585938
INFO:root:Train (Epoch 229): Loss/seq after 00800 batchs: 600.7766723632812
INFO:root:Train (Epoch 229): Loss/seq after 00850 batchs: 582.1138916015625
INFO:root:Train (Epoch 229): Loss/seq after 00900 batchs: 566.270751953125
INFO:root:Train (Epoch 229): Loss/seq after 00950 batchs: 566.4580688476562
INFO:root:Train (Epoch 229): Loss/seq after 01000 batchs: 557.6676025390625
INFO:root:Train (Epoch 229): Loss/seq after 01050 batchs: 546.612060546875
INFO:root:Train (Epoch 229): Loss/seq after 01100 batchs: 537.0001831054688
INFO:root:Train (Epoch 229): Loss/seq after 01150 batchs: 524.1024780273438
INFO:root:Train (Epoch 229): Loss/seq after 01200 batchs: 528.8230590820312
INFO:root:Train (Epoch 229): Loss/seq after 01250 batchs: 526.7688598632812
INFO:root:Train (Epoch 229): Loss/seq after 01300 batchs: 516.7464599609375
INFO:root:Train (Epoch 229): Loss/seq after 01350 batchs: 508.4214172363281
INFO:root:Train (Epoch 229): Loss/seq after 01400 batchs: 512.4622802734375
INFO:root:Train (Epoch 229): Loss/seq after 01450 batchs: 514.732177734375
INFO:root:Train (Epoch 229): Loss/seq after 01500 batchs: 520.9738159179688
INFO:root:Train (Epoch 229): Loss/seq after 01550 batchs: 522.1129150390625
INFO:root:Train (Epoch 229): Loss/seq after 01600 batchs: 518.0633544921875
INFO:root:Train (Epoch 229): Loss/seq after 01650 batchs: 515.7305297851562
INFO:root:Train (Epoch 229): Loss/seq after 01700 batchs: 518.4874267578125
INFO:root:Train (Epoch 229): Loss/seq after 01750 batchs: 516.2684936523438
INFO:root:Train (Epoch 229): Loss/seq after 01800 batchs: 513.8060302734375
INFO:root:Train (Epoch 229): Loss/seq after 01850 batchs: 510.3472595214844
INFO:root:Train (Epoch 229): Loss/seq after 01900 batchs: 508.8543701171875
INFO:root:Train (Epoch 229): Loss/seq after 01950 batchs: 507.4388732910156
INFO:root:Train (Epoch 229): Loss/seq after 02000 batchs: 507.19964599609375
INFO:root:Train (Epoch 229): Loss/seq after 02050 batchs: 505.9639892578125
INFO:root:Train (Epoch 229): Loss/seq after 02100 batchs: 503.48150634765625
INFO:root:Train (Epoch 229): Loss/seq after 02150 batchs: 501.6622619628906
INFO:root:Train (Epoch 229): Loss/seq after 02200 batchs: 499.1222839355469
INFO:root:Train (Epoch 229): Loss/seq after 02250 batchs: 497.81475830078125
INFO:root:Train (Epoch 229): Loss/seq after 02300 batchs: 495.4798278808594
INFO:root:Train (Epoch 229): Loss/seq after 02350 batchs: 491.56585693359375
INFO:root:Train (Epoch 229): Loss/seq after 02400 batchs: 493.3572082519531
INFO:root:Train (Epoch 229): Loss/seq after 02450 batchs: 489.2898864746094
INFO:root:Train (Epoch 229): Loss/seq after 02500 batchs: 481.911376953125
INFO:root:Train (Epoch 229): Loss/seq after 02550 batchs: 476.2716064453125
INFO:root:Train (Epoch 229): Loss/seq after 02600 batchs: 473.93670654296875
INFO:root:Train (Epoch 229): Loss/seq after 02650 batchs: 470.9674072265625
INFO:root:Train (Epoch 229): Loss/seq after 02700 batchs: 468.96673583984375
INFO:root:Train (Epoch 229): Loss/seq after 02750 batchs: 464.8678283691406
INFO:root:Train (Epoch 229): Loss/seq after 02800 batchs: 464.5107421875
INFO:root:Train (Epoch 229): Loss/seq after 02850 batchs: 464.01885986328125
INFO:root:Train (Epoch 229): Loss/seq after 02900 batchs: 465.52862548828125
INFO:root:Train (Epoch 229): Loss/seq after 02950 batchs: 465.35089111328125
INFO:root:Train (Epoch 229): Loss/seq after 03000 batchs: 470.5364074707031
INFO:root:Train (Epoch 229): Loss/seq after 03050 batchs: 472.1266174316406
INFO:root:Train (Epoch 229): Loss/seq after 03100 batchs: 474.7542724609375
INFO:root:Train (Epoch 229): Loss/seq after 03150 batchs: 478.5411071777344
INFO:root:Train (Epoch 229): Loss/seq after 03200 batchs: 479.649169921875
INFO:root:Train (Epoch 229): Loss/seq after 03250 batchs: 482.04022216796875
INFO:root:Train (Epoch 229): Loss/seq after 03300 batchs: 481.2905578613281
INFO:root:Train (Epoch 229): Loss/seq after 03350 batchs: 479.88116455078125
INFO:root:Train (Epoch 229): Loss/seq after 03400 batchs: 476.6983947753906
INFO:root:Train (Epoch 229): Loss/seq after 03450 batchs: 475.28704833984375
INFO:root:Train (Epoch 229): Loss/seq after 03500 batchs: 475.79083251953125
INFO:root:Train (Epoch 229): Loss/seq after 03550 batchs: 473.2835388183594
INFO:root:Train (Epoch 229): Loss/seq after 03600 batchs: 480.7083435058594
INFO:root:Train (Epoch 229): Loss/seq after 03650 batchs: 478.88690185546875
INFO:root:Train (Epoch 229): Loss/seq after 03700 batchs: 481.0639343261719
INFO:root:Train (Epoch 229): Loss/seq after 03750 batchs: 485.0936279296875
INFO:root:Train (Epoch 229): Loss/seq after 03800 batchs: 483.56536865234375
INFO:root:Train (Epoch 229): Loss/seq after 03850 batchs: 482.45184326171875
INFO:root:Train (Epoch 229): Loss/seq after 03900 batchs: 485.328125
INFO:root:Train (Epoch 229): Loss/seq after 03950 batchs: 488.9351806640625
INFO:root:Train (Epoch 229): Loss/seq after 04000 batchs: 485.5157165527344
INFO:root:Train (Epoch 229): Loss/seq after 04050 batchs: 482.5448913574219
INFO:root:Train (Epoch 229): Loss/seq after 04100 batchs: 481.3080749511719
INFO:root:Train (Epoch 229): Loss/seq after 04150 batchs: 481.15350341796875
INFO:root:Train (Epoch 229): Loss/seq after 04200 batchs: 479.5997314453125
INFO:root:Train (Epoch 229): Loss/seq after 04250 batchs: 478.13232421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 229): Loss/seq after 00000 batches: 446.0516357421875
INFO:root:# Valid (Epoch 229): Loss/seq after 00050 batches: 662.5723876953125
INFO:root:# Valid (Epoch 229): Loss/seq after 00100 batches: 706.834228515625
INFO:root:# Valid (Epoch 229): Loss/seq after 00150 batches: 530.3155517578125
INFO:root:# Valid (Epoch 229): Loss/seq after 00200 batches: 481.82342529296875
INFO:root:Artifacts: Make stick videos for epoch 229
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_229_on_20220423_151507.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_229_index_995_on_20220423_151507.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 230): Loss/seq after 00000 batchs: 751.033935546875
INFO:root:Train (Epoch 230): Loss/seq after 00050 batchs: 681.116455078125
INFO:root:Train (Epoch 230): Loss/seq after 00100 batchs: 685.6180419921875
INFO:root:Train (Epoch 230): Loss/seq after 00150 batchs: 606.2898559570312
INFO:root:Train (Epoch 230): Loss/seq after 00200 batchs: 684.2784423828125
INFO:root:Train (Epoch 230): Loss/seq after 00250 batchs: 732.4303588867188
INFO:root:Train (Epoch 230): Loss/seq after 00300 batchs: 737.90625
INFO:root:Train (Epoch 230): Loss/seq after 00350 batchs: 699.188232421875
INFO:root:Train (Epoch 230): Loss/seq after 00400 batchs: 705.5164794921875
INFO:root:Train (Epoch 230): Loss/seq after 00450 batchs: 699.1024780273438
INFO:root:Train (Epoch 230): Loss/seq after 00500 batchs: 679.8153076171875
INFO:root:Train (Epoch 230): Loss/seq after 00550 batchs: 660.464111328125
INFO:root:Train (Epoch 230): Loss/seq after 00600 batchs: 637.5847778320312
INFO:root:Train (Epoch 230): Loss/seq after 00650 batchs: 621.9208374023438
INFO:root:Train (Epoch 230): Loss/seq after 00700 batchs: 601.2222290039062
INFO:root:Train (Epoch 230): Loss/seq after 00750 batchs: 605.14306640625
INFO:root:Train (Epoch 230): Loss/seq after 00800 batchs: 604.4522705078125
INFO:root:Train (Epoch 230): Loss/seq after 00850 batchs: 585.2473754882812
INFO:root:Train (Epoch 230): Loss/seq after 00900 batchs: 569.7935180664062
INFO:root:Train (Epoch 230): Loss/seq after 00950 batchs: 569.2215576171875
INFO:root:Train (Epoch 230): Loss/seq after 01000 batchs: 560.528076171875
INFO:root:Train (Epoch 230): Loss/seq after 01050 batchs: 548.4419555664062
INFO:root:Train (Epoch 230): Loss/seq after 01100 batchs: 538.364013671875
INFO:root:Train (Epoch 230): Loss/seq after 01150 batchs: 524.9652709960938
INFO:root:Train (Epoch 230): Loss/seq after 01200 batchs: 528.9804077148438
INFO:root:Train (Epoch 230): Loss/seq after 01250 batchs: 527.4651489257812
INFO:root:Train (Epoch 230): Loss/seq after 01300 batchs: 517.6983642578125
INFO:root:Train (Epoch 230): Loss/seq after 01350 batchs: 508.8082580566406
INFO:root:Train (Epoch 230): Loss/seq after 01400 batchs: 511.2803649902344
INFO:root:Train (Epoch 230): Loss/seq after 01450 batchs: 513.6730346679688
INFO:root:Train (Epoch 230): Loss/seq after 01500 batchs: 520.1730346679688
INFO:root:Train (Epoch 230): Loss/seq after 01550 batchs: 521.0762329101562
INFO:root:Train (Epoch 230): Loss/seq after 01600 batchs: 516.5882568359375
INFO:root:Train (Epoch 230): Loss/seq after 01650 batchs: 514.2596435546875
INFO:root:Train (Epoch 230): Loss/seq after 01700 batchs: 517.1185302734375
INFO:root:Train (Epoch 230): Loss/seq after 01750 batchs: 514.6702880859375
INFO:root:Train (Epoch 230): Loss/seq after 01800 batchs: 512.260498046875
INFO:root:Train (Epoch 230): Loss/seq after 01850 batchs: 508.7374267578125
INFO:root:Train (Epoch 230): Loss/seq after 01900 batchs: 507.06500244140625
INFO:root:Train (Epoch 230): Loss/seq after 01950 batchs: 505.3736267089844
INFO:root:Train (Epoch 230): Loss/seq after 02000 batchs: 505.1487731933594
INFO:root:Train (Epoch 230): Loss/seq after 02050 batchs: 503.876220703125
INFO:root:Train (Epoch 230): Loss/seq after 02100 batchs: 501.58966064453125
INFO:root:Train (Epoch 230): Loss/seq after 02150 batchs: 499.91607666015625
INFO:root:Train (Epoch 230): Loss/seq after 02200 batchs: 497.63958740234375
INFO:root:Train (Epoch 230): Loss/seq after 02250 batchs: 496.2639465332031
INFO:root:Train (Epoch 230): Loss/seq after 02300 batchs: 493.6488952636719
INFO:root:Train (Epoch 230): Loss/seq after 02350 batchs: 489.8033142089844
INFO:root:Train (Epoch 230): Loss/seq after 02400 batchs: 491.43487548828125
INFO:root:Train (Epoch 230): Loss/seq after 02450 batchs: 487.33160400390625
INFO:root:Train (Epoch 230): Loss/seq after 02500 batchs: 480.0653381347656
INFO:root:Train (Epoch 230): Loss/seq after 02550 batchs: 474.0973205566406
INFO:root:Train (Epoch 230): Loss/seq after 02600 batchs: 471.8407897949219
INFO:root:Train (Epoch 230): Loss/seq after 02650 batchs: 468.61712646484375
INFO:root:Train (Epoch 230): Loss/seq after 02700 batchs: 466.300048828125
INFO:root:Train (Epoch 230): Loss/seq after 02750 batchs: 462.4361267089844
INFO:root:Train (Epoch 230): Loss/seq after 02800 batchs: 461.906982421875
INFO:root:Train (Epoch 230): Loss/seq after 02850 batchs: 461.5050354003906
INFO:root:Train (Epoch 230): Loss/seq after 02900 batchs: 462.87176513671875
INFO:root:Train (Epoch 230): Loss/seq after 02950 batchs: 462.796630859375
INFO:root:Train (Epoch 230): Loss/seq after 03000 batchs: 467.9744873046875
INFO:root:Train (Epoch 230): Loss/seq after 03050 batchs: 469.7673034667969
INFO:root:Train (Epoch 230): Loss/seq after 03100 batchs: 472.243408203125
INFO:root:Train (Epoch 230): Loss/seq after 03150 batchs: 475.5598449707031
INFO:root:Train (Epoch 230): Loss/seq after 03200 batchs: 477.43853759765625
INFO:root:Train (Epoch 230): Loss/seq after 03250 batchs: 480.79571533203125
INFO:root:Train (Epoch 230): Loss/seq after 03300 batchs: 480.5487060546875
INFO:root:Train (Epoch 230): Loss/seq after 03350 batchs: 479.2607116699219
INFO:root:Train (Epoch 230): Loss/seq after 03400 batchs: 476.19512939453125
INFO:root:Train (Epoch 230): Loss/seq after 03450 batchs: 474.6575927734375
INFO:root:Train (Epoch 230): Loss/seq after 03500 batchs: 475.58984375
INFO:root:Train (Epoch 230): Loss/seq after 03550 batchs: 473.30987548828125
INFO:root:Train (Epoch 230): Loss/seq after 03600 batchs: 480.4034423828125
INFO:root:Train (Epoch 230): Loss/seq after 03650 batchs: 478.51434326171875
INFO:root:Train (Epoch 230): Loss/seq after 03700 batchs: 480.7711181640625
INFO:root:Train (Epoch 230): Loss/seq after 03750 batchs: 484.8014221191406
INFO:root:Train (Epoch 230): Loss/seq after 03800 batchs: 483.2468566894531
INFO:root:Train (Epoch 230): Loss/seq after 03850 batchs: 482.279052734375
INFO:root:Train (Epoch 230): Loss/seq after 03900 batchs: 485.5868835449219
INFO:root:Train (Epoch 230): Loss/seq after 03950 batchs: 489.1851806640625
INFO:root:Train (Epoch 230): Loss/seq after 04000 batchs: 485.7810363769531
INFO:root:Train (Epoch 230): Loss/seq after 04050 batchs: 482.7887878417969
INFO:root:Train (Epoch 230): Loss/seq after 04100 batchs: 481.50787353515625
INFO:root:Train (Epoch 230): Loss/seq after 04150 batchs: 481.36468505859375
INFO:root:Train (Epoch 230): Loss/seq after 04200 batchs: 479.9064025878906
INFO:root:Train (Epoch 230): Loss/seq after 04250 batchs: 478.3896789550781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 230): Loss/seq after 00000 batches: 439.178955078125
INFO:root:# Valid (Epoch 230): Loss/seq after 00050 batches: 673.3043212890625
INFO:root:# Valid (Epoch 230): Loss/seq after 00100 batches: 701.4467163085938
INFO:root:# Valid (Epoch 230): Loss/seq after 00150 batches: 527.6524658203125
INFO:root:# Valid (Epoch 230): Loss/seq after 00200 batches: 482.27716064453125
INFO:root:Artifacts: Make stick videos for epoch 230
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_230_on_20220423_151959.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_230_index_1589_on_20220423_151959.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 231): Loss/seq after 00000 batchs: 913.304443359375
INFO:root:Train (Epoch 231): Loss/seq after 00050 batchs: 686.1753540039062
INFO:root:Train (Epoch 231): Loss/seq after 00100 batchs: 693.9058227539062
INFO:root:Train (Epoch 231): Loss/seq after 00150 batchs: 613.8387451171875
INFO:root:Train (Epoch 231): Loss/seq after 00200 batchs: 693.559326171875
INFO:root:Train (Epoch 231): Loss/seq after 00250 batchs: 738.3411865234375
INFO:root:Train (Epoch 231): Loss/seq after 00300 batchs: 743.1401977539062
INFO:root:Train (Epoch 231): Loss/seq after 00350 batchs: 701.8848876953125
INFO:root:Train (Epoch 231): Loss/seq after 00400 batchs: 701.293212890625
INFO:root:Train (Epoch 231): Loss/seq after 00450 batchs: 695.2944946289062
INFO:root:Train (Epoch 231): Loss/seq after 00500 batchs: 672.0731201171875
INFO:root:Train (Epoch 231): Loss/seq after 00550 batchs: 653.0494995117188
INFO:root:Train (Epoch 231): Loss/seq after 00600 batchs: 629.6541137695312
INFO:root:Train (Epoch 231): Loss/seq after 00650 batchs: 613.67626953125
INFO:root:Train (Epoch 231): Loss/seq after 00700 batchs: 594.0156860351562
INFO:root:Train (Epoch 231): Loss/seq after 00750 batchs: 594.6185302734375
INFO:root:Train (Epoch 231): Loss/seq after 00800 batchs: 594.456298828125
INFO:root:Train (Epoch 231): Loss/seq after 00850 batchs: 575.5409545898438
INFO:root:Train (Epoch 231): Loss/seq after 00900 batchs: 560.2186279296875
INFO:root:Train (Epoch 231): Loss/seq after 00950 batchs: 560.6390380859375
INFO:root:Train (Epoch 231): Loss/seq after 01000 batchs: 552.121826171875
INFO:root:Train (Epoch 231): Loss/seq after 01050 batchs: 541.3438110351562
INFO:root:Train (Epoch 231): Loss/seq after 01100 batchs: 531.8494262695312
INFO:root:Train (Epoch 231): Loss/seq after 01150 batchs: 519.140625
INFO:root:Train (Epoch 231): Loss/seq after 01200 batchs: 523.3466186523438
INFO:root:Train (Epoch 231): Loss/seq after 01250 batchs: 521.1616821289062
INFO:root:Train (Epoch 231): Loss/seq after 01300 batchs: 511.35784912109375
INFO:root:Train (Epoch 231): Loss/seq after 01350 batchs: 503.27435302734375
INFO:root:Train (Epoch 231): Loss/seq after 01400 batchs: 506.1725158691406
INFO:root:Train (Epoch 231): Loss/seq after 01450 batchs: 508.4854431152344
INFO:root:Train (Epoch 231): Loss/seq after 01500 batchs: 514.4779663085938
INFO:root:Train (Epoch 231): Loss/seq after 01550 batchs: 515.6728515625
INFO:root:Train (Epoch 231): Loss/seq after 01600 batchs: 511.421875
INFO:root:Train (Epoch 231): Loss/seq after 01650 batchs: 508.8243713378906
INFO:root:Train (Epoch 231): Loss/seq after 01700 batchs: 511.88037109375
INFO:root:Train (Epoch 231): Loss/seq after 01750 batchs: 509.7318420410156
INFO:root:Train (Epoch 231): Loss/seq after 01800 batchs: 507.2425842285156
INFO:root:Train (Epoch 231): Loss/seq after 01850 batchs: 503.9842529296875
INFO:root:Train (Epoch 231): Loss/seq after 01900 batchs: 502.3606262207031
INFO:root:Train (Epoch 231): Loss/seq after 01950 batchs: 500.8058166503906
INFO:root:Train (Epoch 231): Loss/seq after 02000 batchs: 500.8328857421875
INFO:root:Train (Epoch 231): Loss/seq after 02050 batchs: 499.9152526855469
INFO:root:Train (Epoch 231): Loss/seq after 02100 batchs: 497.7672119140625
INFO:root:Train (Epoch 231): Loss/seq after 02150 batchs: 496.07635498046875
INFO:root:Train (Epoch 231): Loss/seq after 02200 batchs: 493.9007873535156
INFO:root:Train (Epoch 231): Loss/seq after 02250 batchs: 492.6336669921875
INFO:root:Train (Epoch 231): Loss/seq after 02300 batchs: 489.6961669921875
INFO:root:Train (Epoch 231): Loss/seq after 02350 batchs: 486.0785217285156
INFO:root:Train (Epoch 231): Loss/seq after 02400 batchs: 487.9215393066406
INFO:root:Train (Epoch 231): Loss/seq after 02450 batchs: 483.94964599609375
INFO:root:Train (Epoch 231): Loss/seq after 02500 batchs: 476.7264099121094
INFO:root:Train (Epoch 231): Loss/seq after 02550 batchs: 471.0860290527344
INFO:root:Train (Epoch 231): Loss/seq after 02600 batchs: 468.5928039550781
INFO:root:Train (Epoch 231): Loss/seq after 02650 batchs: 465.3962707519531
INFO:root:Train (Epoch 231): Loss/seq after 02700 batchs: 463.1882019042969
INFO:root:Train (Epoch 231): Loss/seq after 02750 batchs: 459.0211486816406
INFO:root:Train (Epoch 231): Loss/seq after 02800 batchs: 458.78948974609375
INFO:root:Train (Epoch 231): Loss/seq after 02850 batchs: 458.3027038574219
INFO:root:Train (Epoch 231): Loss/seq after 02900 batchs: 459.9329833984375
INFO:root:Train (Epoch 231): Loss/seq after 02950 batchs: 459.74468994140625
INFO:root:Train (Epoch 231): Loss/seq after 03000 batchs: 465.0133056640625
INFO:root:Train (Epoch 231): Loss/seq after 03050 batchs: 466.7236022949219
INFO:root:Train (Epoch 231): Loss/seq after 03100 batchs: 469.05621337890625
INFO:root:Train (Epoch 231): Loss/seq after 03150 batchs: 472.2391052246094
INFO:root:Train (Epoch 231): Loss/seq after 03200 batchs: 473.6822509765625
INFO:root:Train (Epoch 231): Loss/seq after 03250 batchs: 476.69659423828125
INFO:root:Train (Epoch 231): Loss/seq after 03300 batchs: 475.9056396484375
INFO:root:Train (Epoch 231): Loss/seq after 03350 batchs: 474.1802978515625
INFO:root:Train (Epoch 231): Loss/seq after 03400 batchs: 470.96478271484375
INFO:root:Train (Epoch 231): Loss/seq after 03450 batchs: 469.4621276855469
INFO:root:Train (Epoch 231): Loss/seq after 03500 batchs: 470.06256103515625
INFO:root:Train (Epoch 231): Loss/seq after 03550 batchs: 467.9263610839844
INFO:root:Train (Epoch 231): Loss/seq after 03600 batchs: 475.39410400390625
INFO:root:Train (Epoch 231): Loss/seq after 03650 batchs: 473.9945983886719
INFO:root:Train (Epoch 231): Loss/seq after 03700 batchs: 476.01806640625
INFO:root:Train (Epoch 231): Loss/seq after 03750 batchs: 480.3460998535156
INFO:root:Train (Epoch 231): Loss/seq after 03800 batchs: 478.8528137207031
INFO:root:Train (Epoch 231): Loss/seq after 03850 batchs: 477.9623718261719
INFO:root:Train (Epoch 231): Loss/seq after 03900 batchs: 480.9776306152344
INFO:root:Train (Epoch 231): Loss/seq after 03950 batchs: 484.1923828125
INFO:root:Train (Epoch 231): Loss/seq after 04000 batchs: 480.85302734375
INFO:root:Train (Epoch 231): Loss/seq after 04050 batchs: 477.9525451660156
INFO:root:Train (Epoch 231): Loss/seq after 04100 batchs: 476.8210754394531
INFO:root:Train (Epoch 231): Loss/seq after 04150 batchs: 476.68756103515625
INFO:root:Train (Epoch 231): Loss/seq after 04200 batchs: 475.208251953125
INFO:root:Train (Epoch 231): Loss/seq after 04250 batchs: 473.6407165527344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 231): Loss/seq after 00000 batches: 403.41864013671875
INFO:root:# Valid (Epoch 231): Loss/seq after 00050 batches: 664.042236328125
INFO:root:# Valid (Epoch 231): Loss/seq after 00100 batches: 688.7045288085938
INFO:root:# Valid (Epoch 231): Loss/seq after 00150 batches: 518.7250366210938
INFO:root:# Valid (Epoch 231): Loss/seq after 00200 batches: 474.5575256347656
INFO:root:Artifacts: Make stick videos for epoch 231
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_231_on_20220423_152509.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_231_index_1848_on_20220423_152509.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 232): Loss/seq after 00000 batchs: 990.3770751953125
INFO:root:Train (Epoch 232): Loss/seq after 00050 batchs: 667.1082763671875
INFO:root:Train (Epoch 232): Loss/seq after 00100 batchs: 682.233642578125
INFO:root:Train (Epoch 232): Loss/seq after 00150 batchs: 609.9735717773438
INFO:root:Train (Epoch 232): Loss/seq after 00200 batchs: 686.1895141601562
INFO:root:Train (Epoch 232): Loss/seq after 00250 batchs: 741.623046875
INFO:root:Train (Epoch 232): Loss/seq after 00300 batchs: 744.8551635742188
INFO:root:Train (Epoch 232): Loss/seq after 00350 batchs: 703.85791015625
INFO:root:Train (Epoch 232): Loss/seq after 00400 batchs: 703.6229248046875
INFO:root:Train (Epoch 232): Loss/seq after 00450 batchs: 696.4234008789062
INFO:root:Train (Epoch 232): Loss/seq after 00500 batchs: 673.9154663085938
INFO:root:Train (Epoch 232): Loss/seq after 00550 batchs: 655.3727416992188
INFO:root:Train (Epoch 232): Loss/seq after 00600 batchs: 631.8016357421875
INFO:root:Train (Epoch 232): Loss/seq after 00650 batchs: 617.5693969726562
INFO:root:Train (Epoch 232): Loss/seq after 00700 batchs: 595.9142456054688
INFO:root:Train (Epoch 232): Loss/seq after 00750 batchs: 598.2306518554688
INFO:root:Train (Epoch 232): Loss/seq after 00800 batchs: 597.7848510742188
INFO:root:Train (Epoch 232): Loss/seq after 00850 batchs: 579.2134399414062
INFO:root:Train (Epoch 232): Loss/seq after 00900 batchs: 564.687744140625
INFO:root:Train (Epoch 232): Loss/seq after 00950 batchs: 565.07373046875
INFO:root:Train (Epoch 232): Loss/seq after 01000 batchs: 556.645263671875
INFO:root:Train (Epoch 232): Loss/seq after 01050 batchs: 546.165771484375
INFO:root:Train (Epoch 232): Loss/seq after 01100 batchs: 537.7239990234375
INFO:root:Train (Epoch 232): Loss/seq after 01150 batchs: 524.404052734375
INFO:root:Train (Epoch 232): Loss/seq after 01200 batchs: 527.588134765625
INFO:root:Train (Epoch 232): Loss/seq after 01250 batchs: 525.5805053710938
INFO:root:Train (Epoch 232): Loss/seq after 01300 batchs: 515.2708129882812
INFO:root:Train (Epoch 232): Loss/seq after 01350 batchs: 506.9335632324219
INFO:root:Train (Epoch 232): Loss/seq after 01400 batchs: 508.9956359863281
INFO:root:Train (Epoch 232): Loss/seq after 01450 batchs: 511.0313415527344
INFO:root:Train (Epoch 232): Loss/seq after 01500 batchs: 517.318359375
INFO:root:Train (Epoch 232): Loss/seq after 01550 batchs: 519.1896362304688
INFO:root:Train (Epoch 232): Loss/seq after 01600 batchs: 514.9304809570312
INFO:root:Train (Epoch 232): Loss/seq after 01650 batchs: 512.5604858398438
INFO:root:Train (Epoch 232): Loss/seq after 01700 batchs: 515.382080078125
INFO:root:Train (Epoch 232): Loss/seq after 01750 batchs: 513.24560546875
INFO:root:Train (Epoch 232): Loss/seq after 01800 batchs: 510.70654296875
INFO:root:Train (Epoch 232): Loss/seq after 01850 batchs: 507.15020751953125
INFO:root:Train (Epoch 232): Loss/seq after 01900 batchs: 505.0091552734375
INFO:root:Train (Epoch 232): Loss/seq after 01950 batchs: 503.4706726074219
INFO:root:Train (Epoch 232): Loss/seq after 02000 batchs: 503.34002685546875
INFO:root:Train (Epoch 232): Loss/seq after 02050 batchs: 502.0756530761719
INFO:root:Train (Epoch 232): Loss/seq after 02100 batchs: 500.0705261230469
INFO:root:Train (Epoch 232): Loss/seq after 02150 batchs: 498.4717102050781
INFO:root:Train (Epoch 232): Loss/seq after 02200 batchs: 496.0758056640625
INFO:root:Train (Epoch 232): Loss/seq after 02250 batchs: 494.78570556640625
INFO:root:Train (Epoch 232): Loss/seq after 02300 batchs: 491.9959716796875
INFO:root:Train (Epoch 232): Loss/seq after 02350 batchs: 488.2319030761719
INFO:root:Train (Epoch 232): Loss/seq after 02400 batchs: 490.04541015625
INFO:root:Train (Epoch 232): Loss/seq after 02450 batchs: 485.9521484375
INFO:root:Train (Epoch 232): Loss/seq after 02500 batchs: 478.6035461425781
INFO:root:Train (Epoch 232): Loss/seq after 02550 batchs: 472.6351013183594
INFO:root:Train (Epoch 232): Loss/seq after 02600 batchs: 470.1722717285156
INFO:root:Train (Epoch 232): Loss/seq after 02650 batchs: 466.92913818359375
INFO:root:Train (Epoch 232): Loss/seq after 02700 batchs: 464.5523681640625
INFO:root:Train (Epoch 232): Loss/seq after 02750 batchs: 460.5697326660156
INFO:root:Train (Epoch 232): Loss/seq after 02800 batchs: 459.8011779785156
INFO:root:Train (Epoch 232): Loss/seq after 02850 batchs: 459.5055847167969
INFO:root:Train (Epoch 232): Loss/seq after 02900 batchs: 460.9508056640625
INFO:root:Train (Epoch 232): Loss/seq after 02950 batchs: 460.70892333984375
INFO:root:Train (Epoch 232): Loss/seq after 03000 batchs: 465.9872741699219
INFO:root:Train (Epoch 232): Loss/seq after 03050 batchs: 467.7386779785156
INFO:root:Train (Epoch 232): Loss/seq after 03100 batchs: 470.53179931640625
INFO:root:Train (Epoch 232): Loss/seq after 03150 batchs: 474.5628356933594
INFO:root:Train (Epoch 232): Loss/seq after 03200 batchs: 475.4576721191406
INFO:root:Train (Epoch 232): Loss/seq after 03250 batchs: 478.46221923828125
INFO:root:Train (Epoch 232): Loss/seq after 03300 batchs: 478.1374206542969
INFO:root:Train (Epoch 232): Loss/seq after 03350 batchs: 477.1288757324219
INFO:root:Train (Epoch 232): Loss/seq after 03400 batchs: 473.96185302734375
INFO:root:Train (Epoch 232): Loss/seq after 03450 batchs: 472.4979248046875
INFO:root:Train (Epoch 232): Loss/seq after 03500 batchs: 473.1459655761719
INFO:root:Train (Epoch 232): Loss/seq after 03550 batchs: 470.7980651855469
INFO:root:Train (Epoch 232): Loss/seq after 03600 batchs: 478.0703125
INFO:root:Train (Epoch 232): Loss/seq after 03650 batchs: 476.3165588378906
INFO:root:Train (Epoch 232): Loss/seq after 03700 batchs: 478.3168029785156
INFO:root:Train (Epoch 232): Loss/seq after 03750 batchs: 482.4376525878906
INFO:root:Train (Epoch 232): Loss/seq after 03800 batchs: 480.92498779296875
INFO:root:Train (Epoch 232): Loss/seq after 03850 batchs: 479.802001953125
INFO:root:Train (Epoch 232): Loss/seq after 03900 batchs: 482.7247314453125
INFO:root:Train (Epoch 232): Loss/seq after 03950 batchs: 485.950439453125
INFO:root:Train (Epoch 232): Loss/seq after 04000 batchs: 482.6097412109375
INFO:root:Train (Epoch 232): Loss/seq after 04050 batchs: 479.6777648925781
INFO:root:Train (Epoch 232): Loss/seq after 04100 batchs: 478.4601745605469
INFO:root:Train (Epoch 232): Loss/seq after 04150 batchs: 478.2440185546875
INFO:root:Train (Epoch 232): Loss/seq after 04200 batchs: 476.8311767578125
INFO:root:Train (Epoch 232): Loss/seq after 04250 batchs: 475.37353515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 232): Loss/seq after 00000 batches: 398.8494873046875
INFO:root:# Valid (Epoch 232): Loss/seq after 00050 batches: 694.2949829101562
INFO:root:# Valid (Epoch 232): Loss/seq after 00100 batches: 700.5877075195312
INFO:root:# Valid (Epoch 232): Loss/seq after 00150 batches: 528.6937866210938
INFO:root:# Valid (Epoch 232): Loss/seq after 00200 batches: 483.8573913574219
INFO:root:Artifacts: Make stick videos for epoch 232
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_232_on_20220423_152954.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_232_index_173_on_20220423_152954.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 233): Loss/seq after 00000 batchs: 1115.7298583984375
INFO:root:Train (Epoch 233): Loss/seq after 00050 batchs: 678.893798828125
INFO:root:Train (Epoch 233): Loss/seq after 00100 batchs: 699.5582275390625
INFO:root:Train (Epoch 233): Loss/seq after 00150 batchs: 618.8651733398438
INFO:root:Train (Epoch 233): Loss/seq after 00200 batchs: 692.1434936523438
INFO:root:Train (Epoch 233): Loss/seq after 00250 batchs: 728.650390625
INFO:root:Train (Epoch 233): Loss/seq after 00300 batchs: 734.2748413085938
INFO:root:Train (Epoch 233): Loss/seq after 00350 batchs: 692.3526000976562
INFO:root:Train (Epoch 233): Loss/seq after 00400 batchs: 691.4566040039062
INFO:root:Train (Epoch 233): Loss/seq after 00450 batchs: 685.9363403320312
INFO:root:Train (Epoch 233): Loss/seq after 00500 batchs: 663.542236328125
INFO:root:Train (Epoch 233): Loss/seq after 00550 batchs: 645.2696533203125
INFO:root:Train (Epoch 233): Loss/seq after 00600 batchs: 622.774658203125
INFO:root:Train (Epoch 233): Loss/seq after 00650 batchs: 606.1885375976562
INFO:root:Train (Epoch 233): Loss/seq after 00700 batchs: 587.1835327148438
INFO:root:Train (Epoch 233): Loss/seq after 00750 batchs: 589.2105712890625
INFO:root:Train (Epoch 233): Loss/seq after 00800 batchs: 590.1721801757812
INFO:root:Train (Epoch 233): Loss/seq after 00850 batchs: 571.8356323242188
INFO:root:Train (Epoch 233): Loss/seq after 00900 batchs: 556.4208374023438
INFO:root:Train (Epoch 233): Loss/seq after 00950 batchs: 556.411376953125
INFO:root:Train (Epoch 233): Loss/seq after 01000 batchs: 547.5449829101562
INFO:root:Train (Epoch 233): Loss/seq after 01050 batchs: 535.950439453125
INFO:root:Train (Epoch 233): Loss/seq after 01100 batchs: 525.34423828125
INFO:root:Train (Epoch 233): Loss/seq after 01150 batchs: 512.2962646484375
INFO:root:Train (Epoch 233): Loss/seq after 01200 batchs: 515.9528198242188
INFO:root:Train (Epoch 233): Loss/seq after 01250 batchs: 514.4404296875
INFO:root:Train (Epoch 233): Loss/seq after 01300 batchs: 504.2652282714844
INFO:root:Train (Epoch 233): Loss/seq after 01350 batchs: 496.0796813964844
INFO:root:Train (Epoch 233): Loss/seq after 01400 batchs: 499.1786193847656
INFO:root:Train (Epoch 233): Loss/seq after 01450 batchs: 501.9049377441406
INFO:root:Train (Epoch 233): Loss/seq after 01500 batchs: 507.948974609375
INFO:root:Train (Epoch 233): Loss/seq after 01550 batchs: 509.034912109375
INFO:root:Train (Epoch 233): Loss/seq after 01600 batchs: 505.1888122558594
INFO:root:Train (Epoch 233): Loss/seq after 01650 batchs: 503.0842590332031
INFO:root:Train (Epoch 233): Loss/seq after 01700 batchs: 506.3405456542969
INFO:root:Train (Epoch 233): Loss/seq after 01750 batchs: 504.20880126953125
INFO:root:Train (Epoch 233): Loss/seq after 01800 batchs: 501.9525451660156
INFO:root:Train (Epoch 233): Loss/seq after 01850 batchs: 498.7623291015625
INFO:root:Train (Epoch 233): Loss/seq after 01900 batchs: 497.0365905761719
INFO:root:Train (Epoch 233): Loss/seq after 01950 batchs: 495.46221923828125
INFO:root:Train (Epoch 233): Loss/seq after 02000 batchs: 495.3571472167969
INFO:root:Train (Epoch 233): Loss/seq after 02050 batchs: 494.43988037109375
INFO:root:Train (Epoch 233): Loss/seq after 02100 batchs: 492.49896240234375
INFO:root:Train (Epoch 233): Loss/seq after 02150 batchs: 490.9130554199219
INFO:root:Train (Epoch 233): Loss/seq after 02200 batchs: 488.76239013671875
INFO:root:Train (Epoch 233): Loss/seq after 02250 batchs: 487.5660400390625
INFO:root:Train (Epoch 233): Loss/seq after 02300 batchs: 484.9799499511719
INFO:root:Train (Epoch 233): Loss/seq after 02350 batchs: 481.44830322265625
INFO:root:Train (Epoch 233): Loss/seq after 02400 batchs: 482.977294921875
INFO:root:Train (Epoch 233): Loss/seq after 02450 batchs: 478.9669494628906
INFO:root:Train (Epoch 233): Loss/seq after 02500 batchs: 471.7135009765625
INFO:root:Train (Epoch 233): Loss/seq after 02550 batchs: 465.98309326171875
INFO:root:Train (Epoch 233): Loss/seq after 02600 batchs: 463.8529968261719
INFO:root:Train (Epoch 233): Loss/seq after 02650 batchs: 460.95458984375
INFO:root:Train (Epoch 233): Loss/seq after 02700 batchs: 458.6684265136719
INFO:root:Train (Epoch 233): Loss/seq after 02750 batchs: 454.6720886230469
INFO:root:Train (Epoch 233): Loss/seq after 02800 batchs: 453.92645263671875
INFO:root:Train (Epoch 233): Loss/seq after 02850 batchs: 453.71142578125
INFO:root:Train (Epoch 233): Loss/seq after 02900 batchs: 455.0777282714844
INFO:root:Train (Epoch 233): Loss/seq after 02950 batchs: 455.0417175292969
INFO:root:Train (Epoch 233): Loss/seq after 03000 batchs: 460.19915771484375
INFO:root:Train (Epoch 233): Loss/seq after 03050 batchs: 462.3059387207031
INFO:root:Train (Epoch 233): Loss/seq after 03100 batchs: 464.6595764160156
INFO:root:Train (Epoch 233): Loss/seq after 03150 batchs: 467.7467956542969
INFO:root:Train (Epoch 233): Loss/seq after 03200 batchs: 469.3482666015625
INFO:root:Train (Epoch 233): Loss/seq after 03250 batchs: 471.8986511230469
INFO:root:Train (Epoch 233): Loss/seq after 03300 batchs: 471.9072265625
INFO:root:Train (Epoch 233): Loss/seq after 03350 batchs: 470.7255859375
INFO:root:Train (Epoch 233): Loss/seq after 03400 batchs: 467.8717041015625
INFO:root:Train (Epoch 233): Loss/seq after 03450 batchs: 466.5269470214844
INFO:root:Train (Epoch 233): Loss/seq after 03500 batchs: 468.45037841796875
INFO:root:Train (Epoch 233): Loss/seq after 03550 batchs: 466.4869079589844
INFO:root:Train (Epoch 233): Loss/seq after 03600 batchs: 473.84246826171875
INFO:root:Train (Epoch 233): Loss/seq after 03650 batchs: 472.22625732421875
INFO:root:Train (Epoch 233): Loss/seq after 03700 batchs: 474.5835876464844
INFO:root:Train (Epoch 233): Loss/seq after 03750 batchs: 478.7518615722656
INFO:root:Train (Epoch 233): Loss/seq after 03800 batchs: 477.2254638671875
INFO:root:Train (Epoch 233): Loss/seq after 03850 batchs: 476.28448486328125
INFO:root:Train (Epoch 233): Loss/seq after 03900 batchs: 479.3900451660156
INFO:root:Train (Epoch 233): Loss/seq after 03950 batchs: 482.8088073730469
INFO:root:Train (Epoch 233): Loss/seq after 04000 batchs: 479.45281982421875
INFO:root:Train (Epoch 233): Loss/seq after 04050 batchs: 476.5221862792969
INFO:root:Train (Epoch 233): Loss/seq after 04100 batchs: 475.3583679199219
INFO:root:Train (Epoch 233): Loss/seq after 04150 batchs: 475.19915771484375
INFO:root:Train (Epoch 233): Loss/seq after 04200 batchs: 473.7480773925781
INFO:root:Train (Epoch 233): Loss/seq after 04250 batchs: 472.27978515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 233): Loss/seq after 00000 batches: 460.1580505371094
INFO:root:# Valid (Epoch 233): Loss/seq after 00050 batches: 693.59765625
INFO:root:# Valid (Epoch 233): Loss/seq after 00100 batches: 716.24365234375
INFO:root:# Valid (Epoch 233): Loss/seq after 00150 batches: 537.3004150390625
INFO:root:# Valid (Epoch 233): Loss/seq after 00200 batches: 489.15985107421875
INFO:root:Artifacts: Make stick videos for epoch 233
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_233_on_20220423_153451.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_233_index_486_on_20220423_153451.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 234): Loss/seq after 00000 batchs: 1004.6405029296875
INFO:root:Train (Epoch 234): Loss/seq after 00050 batchs: 698.242919921875
INFO:root:Train (Epoch 234): Loss/seq after 00100 batchs: 702.225830078125
INFO:root:Train (Epoch 234): Loss/seq after 00150 batchs: 620.5364990234375
INFO:root:Train (Epoch 234): Loss/seq after 00200 batchs: 701.3515625
INFO:root:Train (Epoch 234): Loss/seq after 00250 batchs: 748.5023193359375
INFO:root:Train (Epoch 234): Loss/seq after 00300 batchs: 749.3195190429688
INFO:root:Train (Epoch 234): Loss/seq after 00350 batchs: 705.1572265625
INFO:root:Train (Epoch 234): Loss/seq after 00400 batchs: 700.3698120117188
INFO:root:Train (Epoch 234): Loss/seq after 00450 batchs: 693.9119873046875
INFO:root:Train (Epoch 234): Loss/seq after 00500 batchs: 670.5858154296875
INFO:root:Train (Epoch 234): Loss/seq after 00550 batchs: 651.6402587890625
INFO:root:Train (Epoch 234): Loss/seq after 00600 batchs: 629.029296875
INFO:root:Train (Epoch 234): Loss/seq after 00650 batchs: 612.2719116210938
INFO:root:Train (Epoch 234): Loss/seq after 00700 batchs: 592.6712646484375
INFO:root:Train (Epoch 234): Loss/seq after 00750 batchs: 594.746826171875
INFO:root:Train (Epoch 234): Loss/seq after 00800 batchs: 593.9044189453125
INFO:root:Train (Epoch 234): Loss/seq after 00850 batchs: 574.92138671875
INFO:root:Train (Epoch 234): Loss/seq after 00900 batchs: 559.2911376953125
INFO:root:Train (Epoch 234): Loss/seq after 00950 batchs: 559.8865356445312
INFO:root:Train (Epoch 234): Loss/seq after 01000 batchs: 552.3101806640625
INFO:root:Train (Epoch 234): Loss/seq after 01050 batchs: 540.6651000976562
INFO:root:Train (Epoch 234): Loss/seq after 01100 batchs: 530.431640625
INFO:root:Train (Epoch 234): Loss/seq after 01150 batchs: 517.4640502929688
INFO:root:Train (Epoch 234): Loss/seq after 01200 batchs: 521.280517578125
INFO:root:Train (Epoch 234): Loss/seq after 01250 batchs: 519.2418823242188
INFO:root:Train (Epoch 234): Loss/seq after 01300 batchs: 509.97589111328125
INFO:root:Train (Epoch 234): Loss/seq after 01350 batchs: 502.2559814453125
INFO:root:Train (Epoch 234): Loss/seq after 01400 batchs: 506.1597595214844
INFO:root:Train (Epoch 234): Loss/seq after 01450 batchs: 508.2658386230469
INFO:root:Train (Epoch 234): Loss/seq after 01500 batchs: 514.20166015625
INFO:root:Train (Epoch 234): Loss/seq after 01550 batchs: 515.5884399414062
INFO:root:Train (Epoch 234): Loss/seq after 01600 batchs: 511.3789978027344
INFO:root:Train (Epoch 234): Loss/seq after 01650 batchs: 508.8753967285156
INFO:root:Train (Epoch 234): Loss/seq after 01700 batchs: 511.6282043457031
INFO:root:Train (Epoch 234): Loss/seq after 01750 batchs: 509.0821533203125
INFO:root:Train (Epoch 234): Loss/seq after 01800 batchs: 506.4362487792969
INFO:root:Train (Epoch 234): Loss/seq after 01850 batchs: 503.0294189453125
INFO:root:Train (Epoch 234): Loss/seq after 01900 batchs: 501.2855224609375
INFO:root:Train (Epoch 234): Loss/seq after 01950 batchs: 499.8663330078125
INFO:root:Train (Epoch 234): Loss/seq after 02000 batchs: 499.6217956542969
INFO:root:Train (Epoch 234): Loss/seq after 02050 batchs: 498.2930603027344
INFO:root:Train (Epoch 234): Loss/seq after 02100 batchs: 496.0133972167969
INFO:root:Train (Epoch 234): Loss/seq after 02150 batchs: 494.1514892578125
INFO:root:Train (Epoch 234): Loss/seq after 02200 batchs: 492.02618408203125
INFO:root:Train (Epoch 234): Loss/seq after 02250 batchs: 490.8509216308594
INFO:root:Train (Epoch 234): Loss/seq after 02300 batchs: 488.92523193359375
INFO:root:Train (Epoch 234): Loss/seq after 02350 batchs: 485.1257019042969
INFO:root:Train (Epoch 234): Loss/seq after 02400 batchs: 486.8720397949219
INFO:root:Train (Epoch 234): Loss/seq after 02450 batchs: 482.6946105957031
INFO:root:Train (Epoch 234): Loss/seq after 02500 batchs: 475.3567199707031
INFO:root:Train (Epoch 234): Loss/seq after 02550 batchs: 469.64337158203125
INFO:root:Train (Epoch 234): Loss/seq after 02600 batchs: 466.7580261230469
INFO:root:Train (Epoch 234): Loss/seq after 02650 batchs: 463.62982177734375
INFO:root:Train (Epoch 234): Loss/seq after 02700 batchs: 461.6527404785156
INFO:root:Train (Epoch 234): Loss/seq after 02750 batchs: 457.442626953125
INFO:root:Train (Epoch 234): Loss/seq after 02800 batchs: 456.8488464355469
INFO:root:Train (Epoch 234): Loss/seq after 02850 batchs: 456.6507873535156
INFO:root:Train (Epoch 234): Loss/seq after 02900 batchs: 458.0537109375
INFO:root:Train (Epoch 234): Loss/seq after 02950 batchs: 457.8858947753906
INFO:root:Train (Epoch 234): Loss/seq after 03000 batchs: 463.2652282714844
INFO:root:Train (Epoch 234): Loss/seq after 03050 batchs: 465.1631164550781
INFO:root:Train (Epoch 234): Loss/seq after 03100 batchs: 467.7991943359375
INFO:root:Train (Epoch 234): Loss/seq after 03150 batchs: 470.5601806640625
INFO:root:Train (Epoch 234): Loss/seq after 03200 batchs: 470.9228820800781
INFO:root:Train (Epoch 234): Loss/seq after 03250 batchs: 473.1446533203125
INFO:root:Train (Epoch 234): Loss/seq after 03300 batchs: 472.5641174316406
INFO:root:Train (Epoch 234): Loss/seq after 03350 batchs: 471.5252380371094
INFO:root:Train (Epoch 234): Loss/seq after 03400 batchs: 468.43133544921875
INFO:root:Train (Epoch 234): Loss/seq after 03450 batchs: 467.2592468261719
INFO:root:Train (Epoch 234): Loss/seq after 03500 batchs: 468.75128173828125
INFO:root:Train (Epoch 234): Loss/seq after 03550 batchs: 466.6388854980469
INFO:root:Train (Epoch 234): Loss/seq after 03600 batchs: 473.85101318359375
INFO:root:Train (Epoch 234): Loss/seq after 03650 batchs: 472.17901611328125
INFO:root:Train (Epoch 234): Loss/seq after 03700 batchs: 474.5181884765625
INFO:root:Train (Epoch 234): Loss/seq after 03750 batchs: 478.6986999511719
INFO:root:Train (Epoch 234): Loss/seq after 03800 batchs: 477.2380676269531
INFO:root:Train (Epoch 234): Loss/seq after 03850 batchs: 476.2073669433594
INFO:root:Train (Epoch 234): Loss/seq after 03900 batchs: 479.2347106933594
INFO:root:Train (Epoch 234): Loss/seq after 03950 batchs: 482.7202453613281
INFO:root:Train (Epoch 234): Loss/seq after 04000 batchs: 479.3826599121094
INFO:root:Train (Epoch 234): Loss/seq after 04050 batchs: 476.4909973144531
INFO:root:Train (Epoch 234): Loss/seq after 04100 batchs: 475.392822265625
INFO:root:Train (Epoch 234): Loss/seq after 04150 batchs: 475.14654541015625
INFO:root:Train (Epoch 234): Loss/seq after 04200 batchs: 473.92626953125
INFO:root:Train (Epoch 234): Loss/seq after 04250 batchs: 472.41900634765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 234): Loss/seq after 00000 batches: 462.0691223144531
INFO:root:# Valid (Epoch 234): Loss/seq after 00050 batches: 675.98486328125
INFO:root:# Valid (Epoch 234): Loss/seq after 00100 batches: 686.9351196289062
INFO:root:# Valid (Epoch 234): Loss/seq after 00150 batches: 517.7816162109375
INFO:root:# Valid (Epoch 234): Loss/seq after 00200 batches: 472.8452453613281
INFO:root:Artifacts: Make stick videos for epoch 234
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_234_on_20220423_153959.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_234_index_669_on_20220423_153959.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 235): Loss/seq after 00000 batchs: 959.5890502929688
INFO:root:Train (Epoch 235): Loss/seq after 00050 batchs: 665.0533447265625
INFO:root:Train (Epoch 235): Loss/seq after 00100 batchs: 684.925048828125
INFO:root:Train (Epoch 235): Loss/seq after 00150 batchs: 608.0074462890625
INFO:root:Train (Epoch 235): Loss/seq after 00200 batchs: 680.8375854492188
INFO:root:Train (Epoch 235): Loss/seq after 00250 batchs: 726.7459106445312
INFO:root:Train (Epoch 235): Loss/seq after 00300 batchs: 734.08203125
INFO:root:Train (Epoch 235): Loss/seq after 00350 batchs: 692.8350830078125
INFO:root:Train (Epoch 235): Loss/seq after 00400 batchs: 693.1552124023438
INFO:root:Train (Epoch 235): Loss/seq after 00450 batchs: 687.8336181640625
INFO:root:Train (Epoch 235): Loss/seq after 00500 batchs: 665.9483032226562
INFO:root:Train (Epoch 235): Loss/seq after 00550 batchs: 647.3866577148438
INFO:root:Train (Epoch 235): Loss/seq after 00600 batchs: 625.6439208984375
INFO:root:Train (Epoch 235): Loss/seq after 00650 batchs: 610.1481323242188
INFO:root:Train (Epoch 235): Loss/seq after 00700 batchs: 591.4473266601562
INFO:root:Train (Epoch 235): Loss/seq after 00750 batchs: 592.3443603515625
INFO:root:Train (Epoch 235): Loss/seq after 00800 batchs: 591.565673828125
INFO:root:Train (Epoch 235): Loss/seq after 00850 batchs: 573.1897583007812
INFO:root:Train (Epoch 235): Loss/seq after 00900 batchs: 558.0841064453125
INFO:root:Train (Epoch 235): Loss/seq after 00950 batchs: 558.9404907226562
INFO:root:Train (Epoch 235): Loss/seq after 01000 batchs: 549.8226318359375
INFO:root:Train (Epoch 235): Loss/seq after 01050 batchs: 539.5137329101562
INFO:root:Train (Epoch 235): Loss/seq after 01100 batchs: 528.7238159179688
INFO:root:Train (Epoch 235): Loss/seq after 01150 batchs: 515.18994140625
INFO:root:Train (Epoch 235): Loss/seq after 01200 batchs: 518.6961059570312
INFO:root:Train (Epoch 235): Loss/seq after 01250 batchs: 516.8077392578125
INFO:root:Train (Epoch 235): Loss/seq after 01300 batchs: 507.4472961425781
INFO:root:Train (Epoch 235): Loss/seq after 01350 batchs: 498.86614990234375
INFO:root:Train (Epoch 235): Loss/seq after 01400 batchs: 501.3794860839844
INFO:root:Train (Epoch 235): Loss/seq after 01450 batchs: 503.8992004394531
INFO:root:Train (Epoch 235): Loss/seq after 01500 batchs: 510.2625427246094
INFO:root:Train (Epoch 235): Loss/seq after 01550 batchs: 511.3894958496094
INFO:root:Train (Epoch 235): Loss/seq after 01600 batchs: 507.2534484863281
INFO:root:Train (Epoch 235): Loss/seq after 01650 batchs: 504.8471984863281
INFO:root:Train (Epoch 235): Loss/seq after 01700 batchs: 508.10919189453125
INFO:root:Train (Epoch 235): Loss/seq after 01750 batchs: 505.8247375488281
INFO:root:Train (Epoch 235): Loss/seq after 01800 batchs: 503.4237365722656
INFO:root:Train (Epoch 235): Loss/seq after 01850 batchs: 499.98162841796875
INFO:root:Train (Epoch 235): Loss/seq after 01900 batchs: 498.1357116699219
INFO:root:Train (Epoch 235): Loss/seq after 01950 batchs: 496.4288330078125
INFO:root:Train (Epoch 235): Loss/seq after 02000 batchs: 496.3554992675781
INFO:root:Train (Epoch 235): Loss/seq after 02050 batchs: 495.080322265625
INFO:root:Train (Epoch 235): Loss/seq after 02100 batchs: 492.9002380371094
INFO:root:Train (Epoch 235): Loss/seq after 02150 batchs: 491.2375793457031
INFO:root:Train (Epoch 235): Loss/seq after 02200 batchs: 489.00311279296875
INFO:root:Train (Epoch 235): Loss/seq after 02250 batchs: 487.7313537597656
INFO:root:Train (Epoch 235): Loss/seq after 02300 batchs: 484.95062255859375
INFO:root:Train (Epoch 235): Loss/seq after 02350 batchs: 481.2773132324219
INFO:root:Train (Epoch 235): Loss/seq after 02400 batchs: 483.04998779296875
INFO:root:Train (Epoch 235): Loss/seq after 02450 batchs: 478.9952087402344
INFO:root:Train (Epoch 235): Loss/seq after 02500 batchs: 471.74139404296875
INFO:root:Train (Epoch 235): Loss/seq after 02550 batchs: 465.9729309082031
INFO:root:Train (Epoch 235): Loss/seq after 02600 batchs: 463.51220703125
INFO:root:Train (Epoch 235): Loss/seq after 02650 batchs: 460.48583984375
INFO:root:Train (Epoch 235): Loss/seq after 02700 batchs: 458.0933532714844
INFO:root:Train (Epoch 235): Loss/seq after 02750 batchs: 454.05413818359375
INFO:root:Train (Epoch 235): Loss/seq after 02800 batchs: 453.44781494140625
INFO:root:Train (Epoch 235): Loss/seq after 02850 batchs: 453.0096435546875
INFO:root:Train (Epoch 235): Loss/seq after 02900 batchs: 454.07763671875
INFO:root:Train (Epoch 235): Loss/seq after 02950 batchs: 453.9122009277344
INFO:root:Train (Epoch 235): Loss/seq after 03000 batchs: 459.17669677734375
INFO:root:Train (Epoch 235): Loss/seq after 03050 batchs: 460.73370361328125
INFO:root:Train (Epoch 235): Loss/seq after 03100 batchs: 462.87066650390625
INFO:root:Train (Epoch 235): Loss/seq after 03150 batchs: 465.7488708496094
INFO:root:Train (Epoch 235): Loss/seq after 03200 batchs: 466.02496337890625
INFO:root:Train (Epoch 235): Loss/seq after 03250 batchs: 468.36334228515625
INFO:root:Train (Epoch 235): Loss/seq after 03300 batchs: 467.7689514160156
INFO:root:Train (Epoch 235): Loss/seq after 03350 batchs: 466.46368408203125
INFO:root:Train (Epoch 235): Loss/seq after 03400 batchs: 463.46649169921875
INFO:root:Train (Epoch 235): Loss/seq after 03450 batchs: 461.9901428222656
INFO:root:Train (Epoch 235): Loss/seq after 03500 batchs: 462.3443908691406
INFO:root:Train (Epoch 235): Loss/seq after 03550 batchs: 460.1046142578125
INFO:root:Train (Epoch 235): Loss/seq after 03600 batchs: 467.27197265625
INFO:root:Train (Epoch 235): Loss/seq after 03650 batchs: 465.78961181640625
INFO:root:Train (Epoch 235): Loss/seq after 03700 batchs: 468.0289306640625
INFO:root:Train (Epoch 235): Loss/seq after 03750 batchs: 472.25408935546875
INFO:root:Train (Epoch 235): Loss/seq after 03800 batchs: 470.8626708984375
INFO:root:Train (Epoch 235): Loss/seq after 03850 batchs: 470.0447998046875
INFO:root:Train (Epoch 235): Loss/seq after 03900 batchs: 472.670166015625
INFO:root:Train (Epoch 235): Loss/seq after 03950 batchs: 476.31744384765625
INFO:root:Train (Epoch 235): Loss/seq after 04000 batchs: 473.0976257324219
INFO:root:Train (Epoch 235): Loss/seq after 04050 batchs: 470.24853515625
INFO:root:Train (Epoch 235): Loss/seq after 04100 batchs: 469.11590576171875
INFO:root:Train (Epoch 235): Loss/seq after 04150 batchs: 468.9219665527344
INFO:root:Train (Epoch 235): Loss/seq after 04200 batchs: 467.4834289550781
INFO:root:Train (Epoch 235): Loss/seq after 04250 batchs: 466.0749816894531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 235): Loss/seq after 00000 batches: 433.8944091796875
INFO:root:# Valid (Epoch 235): Loss/seq after 00050 batches: 677.8742065429688
INFO:root:# Valid (Epoch 235): Loss/seq after 00100 batches: 697.09765625
INFO:root:# Valid (Epoch 235): Loss/seq after 00150 batches: 523.0702514648438
INFO:root:# Valid (Epoch 235): Loss/seq after 00200 batches: 476.5673522949219
INFO:root:Artifacts: Make stick videos for epoch 235
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_235_on_20220423_154504.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_235_index_97_on_20220423_154504.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 236): Loss/seq after 00000 batchs: 1078.1536865234375
INFO:root:Train (Epoch 236): Loss/seq after 00050 batchs: 662.4136962890625
INFO:root:Train (Epoch 236): Loss/seq after 00100 batchs: 666.22119140625
INFO:root:Train (Epoch 236): Loss/seq after 00150 batchs: 592.8419189453125
INFO:root:Train (Epoch 236): Loss/seq after 00200 batchs: 666.6849975585938
INFO:root:Train (Epoch 236): Loss/seq after 00250 batchs: 708.885009765625
INFO:root:Train (Epoch 236): Loss/seq after 00300 batchs: 715.9546508789062
INFO:root:Train (Epoch 236): Loss/seq after 00350 batchs: 677.6039428710938
INFO:root:Train (Epoch 236): Loss/seq after 00400 batchs: 676.84765625
INFO:root:Train (Epoch 236): Loss/seq after 00450 batchs: 673.710693359375
INFO:root:Train (Epoch 236): Loss/seq after 00500 batchs: 652.9346923828125
INFO:root:Train (Epoch 236): Loss/seq after 00550 batchs: 636.3239135742188
INFO:root:Train (Epoch 236): Loss/seq after 00600 batchs: 614.6699829101562
INFO:root:Train (Epoch 236): Loss/seq after 00650 batchs: 599.453125
INFO:root:Train (Epoch 236): Loss/seq after 00700 batchs: 579.0126953125
INFO:root:Train (Epoch 236): Loss/seq after 00750 batchs: 581.7664184570312
INFO:root:Train (Epoch 236): Loss/seq after 00800 batchs: 580.829833984375
INFO:root:Train (Epoch 236): Loss/seq after 00850 batchs: 562.945556640625
INFO:root:Train (Epoch 236): Loss/seq after 00900 batchs: 549.714111328125
INFO:root:Train (Epoch 236): Loss/seq after 00950 batchs: 549.4329223632812
INFO:root:Train (Epoch 236): Loss/seq after 01000 batchs: 540.8967895507812
INFO:root:Train (Epoch 236): Loss/seq after 01050 batchs: 529.2474975585938
INFO:root:Train (Epoch 236): Loss/seq after 01100 batchs: 518.9513549804688
INFO:root:Train (Epoch 236): Loss/seq after 01150 batchs: 506.4679870605469
INFO:root:Train (Epoch 236): Loss/seq after 01200 batchs: 510.6241149902344
INFO:root:Train (Epoch 236): Loss/seq after 01250 batchs: 509.22021484375
INFO:root:Train (Epoch 236): Loss/seq after 01300 batchs: 499.72808837890625
INFO:root:Train (Epoch 236): Loss/seq after 01350 batchs: 491.10791015625
INFO:root:Train (Epoch 236): Loss/seq after 01400 batchs: 493.7425842285156
INFO:root:Train (Epoch 236): Loss/seq after 01450 batchs: 496.3756408691406
INFO:root:Train (Epoch 236): Loss/seq after 01500 batchs: 502.5362854003906
INFO:root:Train (Epoch 236): Loss/seq after 01550 batchs: 504.00537109375
INFO:root:Train (Epoch 236): Loss/seq after 01600 batchs: 499.9804992675781
INFO:root:Train (Epoch 236): Loss/seq after 01650 batchs: 497.6943664550781
INFO:root:Train (Epoch 236): Loss/seq after 01700 batchs: 500.6363830566406
INFO:root:Train (Epoch 236): Loss/seq after 01750 batchs: 498.4049377441406
INFO:root:Train (Epoch 236): Loss/seq after 01800 batchs: 496.0150451660156
INFO:root:Train (Epoch 236): Loss/seq after 01850 batchs: 492.8105163574219
INFO:root:Train (Epoch 236): Loss/seq after 01900 batchs: 491.1523132324219
INFO:root:Train (Epoch 236): Loss/seq after 01950 batchs: 489.6105041503906
INFO:root:Train (Epoch 236): Loss/seq after 02000 batchs: 489.7823486328125
INFO:root:Train (Epoch 236): Loss/seq after 02050 batchs: 488.8049621582031
INFO:root:Train (Epoch 236): Loss/seq after 02100 batchs: 486.80523681640625
INFO:root:Train (Epoch 236): Loss/seq after 02150 batchs: 485.3375549316406
INFO:root:Train (Epoch 236): Loss/seq after 02200 batchs: 483.19873046875
INFO:root:Train (Epoch 236): Loss/seq after 02250 batchs: 482.41436767578125
INFO:root:Train (Epoch 236): Loss/seq after 02300 batchs: 479.68115234375
INFO:root:Train (Epoch 236): Loss/seq after 02350 batchs: 475.9980163574219
INFO:root:Train (Epoch 236): Loss/seq after 02400 batchs: 477.9570007324219
INFO:root:Train (Epoch 236): Loss/seq after 02450 batchs: 473.9801940917969
INFO:root:Train (Epoch 236): Loss/seq after 02500 batchs: 466.88848876953125
INFO:root:Train (Epoch 236): Loss/seq after 02550 batchs: 461.1877136230469
INFO:root:Train (Epoch 236): Loss/seq after 02600 batchs: 458.74359130859375
INFO:root:Train (Epoch 236): Loss/seq after 02650 batchs: 455.710205078125
INFO:root:Train (Epoch 236): Loss/seq after 02700 batchs: 453.5290222167969
INFO:root:Train (Epoch 236): Loss/seq after 02750 batchs: 449.3790283203125
INFO:root:Train (Epoch 236): Loss/seq after 02800 batchs: 448.6607360839844
INFO:root:Train (Epoch 236): Loss/seq after 02850 batchs: 448.28936767578125
INFO:root:Train (Epoch 236): Loss/seq after 02900 batchs: 449.5830993652344
INFO:root:Train (Epoch 236): Loss/seq after 02950 batchs: 449.61590576171875
INFO:root:Train (Epoch 236): Loss/seq after 03000 batchs: 454.9154052734375
INFO:root:Train (Epoch 236): Loss/seq after 03050 batchs: 456.85321044921875
INFO:root:Train (Epoch 236): Loss/seq after 03100 batchs: 459.0185546875
INFO:root:Train (Epoch 236): Loss/seq after 03150 batchs: 461.4736328125
INFO:root:Train (Epoch 236): Loss/seq after 03200 batchs: 462.3478698730469
INFO:root:Train (Epoch 236): Loss/seq after 03250 batchs: 464.5744934082031
INFO:root:Train (Epoch 236): Loss/seq after 03300 batchs: 464.25531005859375
INFO:root:Train (Epoch 236): Loss/seq after 03350 batchs: 463.11041259765625
INFO:root:Train (Epoch 236): Loss/seq after 03400 batchs: 460.312255859375
INFO:root:Train (Epoch 236): Loss/seq after 03450 batchs: 458.9100341796875
INFO:root:Train (Epoch 236): Loss/seq after 03500 batchs: 459.53594970703125
INFO:root:Train (Epoch 236): Loss/seq after 03550 batchs: 457.3243713378906
INFO:root:Train (Epoch 236): Loss/seq after 03600 batchs: 464.35833740234375
INFO:root:Train (Epoch 236): Loss/seq after 03650 batchs: 462.7063293457031
INFO:root:Train (Epoch 236): Loss/seq after 03700 batchs: 464.73760986328125
INFO:root:Train (Epoch 236): Loss/seq after 03750 batchs: 468.87030029296875
INFO:root:Train (Epoch 236): Loss/seq after 03800 batchs: 467.45220947265625
INFO:root:Train (Epoch 236): Loss/seq after 03850 batchs: 466.4906921386719
INFO:root:Train (Epoch 236): Loss/seq after 03900 batchs: 469.4864196777344
INFO:root:Train (Epoch 236): Loss/seq after 03950 batchs: 472.4510192871094
INFO:root:Train (Epoch 236): Loss/seq after 04000 batchs: 469.2449951171875
INFO:root:Train (Epoch 236): Loss/seq after 04050 batchs: 466.5068359375
INFO:root:Train (Epoch 236): Loss/seq after 04100 batchs: 465.4389343261719
INFO:root:Train (Epoch 236): Loss/seq after 04150 batchs: 465.3311462402344
INFO:root:Train (Epoch 236): Loss/seq after 04200 batchs: 463.97821044921875
INFO:root:Train (Epoch 236): Loss/seq after 04250 batchs: 462.54351806640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 236): Loss/seq after 00000 batches: 394.62322998046875
INFO:root:# Valid (Epoch 236): Loss/seq after 00050 batches: 670.3865356445312
INFO:root:# Valid (Epoch 236): Loss/seq after 00100 batches: 679.8585205078125
INFO:root:# Valid (Epoch 236): Loss/seq after 00150 batches: 511.32611083984375
INFO:root:# Valid (Epoch 236): Loss/seq after 00200 batches: 468.275634765625
INFO:root:Artifacts: Make stick videos for epoch 236
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_236_on_20220423_154956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_236_index_1317_on_20220423_154956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 237): Loss/seq after 00000 batchs: 750.8707275390625
INFO:root:Train (Epoch 237): Loss/seq after 00050 batchs: 655.2767333984375
INFO:root:Train (Epoch 237): Loss/seq after 00100 batchs: 667.9180908203125
INFO:root:Train (Epoch 237): Loss/seq after 00150 batchs: 592.5982055664062
INFO:root:Train (Epoch 237): Loss/seq after 00200 batchs: 671.3326416015625
INFO:root:Train (Epoch 237): Loss/seq after 00250 batchs: 711.94140625
INFO:root:Train (Epoch 237): Loss/seq after 00300 batchs: 718.2247314453125
INFO:root:Train (Epoch 237): Loss/seq after 00350 batchs: 679.333251953125
INFO:root:Train (Epoch 237): Loss/seq after 00400 batchs: 678.755859375
INFO:root:Train (Epoch 237): Loss/seq after 00450 batchs: 675.1127319335938
INFO:root:Train (Epoch 237): Loss/seq after 00500 batchs: 654.3800659179688
INFO:root:Train (Epoch 237): Loss/seq after 00550 batchs: 637.3096923828125
INFO:root:Train (Epoch 237): Loss/seq after 00600 batchs: 615.6651000976562
INFO:root:Train (Epoch 237): Loss/seq after 00650 batchs: 599.910888671875
INFO:root:Train (Epoch 237): Loss/seq after 00700 batchs: 578.8353271484375
INFO:root:Train (Epoch 237): Loss/seq after 00750 batchs: 581.1760864257812
INFO:root:Train (Epoch 237): Loss/seq after 00800 batchs: 580.4619140625
INFO:root:Train (Epoch 237): Loss/seq after 00850 batchs: 561.8947143554688
INFO:root:Train (Epoch 237): Loss/seq after 00900 batchs: 546.962646484375
INFO:root:Train (Epoch 237): Loss/seq after 00950 batchs: 546.1464233398438
INFO:root:Train (Epoch 237): Loss/seq after 01000 batchs: 537.0189208984375
INFO:root:Train (Epoch 237): Loss/seq after 01050 batchs: 525.3217163085938
INFO:root:Train (Epoch 237): Loss/seq after 01100 batchs: 514.6423950195312
INFO:root:Train (Epoch 237): Loss/seq after 01150 batchs: 501.9449157714844
INFO:root:Train (Epoch 237): Loss/seq after 01200 batchs: 506.0126953125
INFO:root:Train (Epoch 237): Loss/seq after 01250 batchs: 504.6694030761719
INFO:root:Train (Epoch 237): Loss/seq after 01300 batchs: 495.4046936035156
INFO:root:Train (Epoch 237): Loss/seq after 01350 batchs: 486.81207275390625
INFO:root:Train (Epoch 237): Loss/seq after 01400 batchs: 488.8138427734375
INFO:root:Train (Epoch 237): Loss/seq after 01450 batchs: 491.40911865234375
INFO:root:Train (Epoch 237): Loss/seq after 01500 batchs: 497.8761291503906
INFO:root:Train (Epoch 237): Loss/seq after 01550 batchs: 499.4092712402344
INFO:root:Train (Epoch 237): Loss/seq after 01600 batchs: 496.0531921386719
INFO:root:Train (Epoch 237): Loss/seq after 01650 batchs: 493.8312683105469
INFO:root:Train (Epoch 237): Loss/seq after 01700 batchs: 497.3622131347656
INFO:root:Train (Epoch 237): Loss/seq after 01750 batchs: 495.35693359375
INFO:root:Train (Epoch 237): Loss/seq after 01800 batchs: 493.1365661621094
INFO:root:Train (Epoch 237): Loss/seq after 01850 batchs: 489.95361328125
INFO:root:Train (Epoch 237): Loss/seq after 01900 batchs: 488.22528076171875
INFO:root:Train (Epoch 237): Loss/seq after 01950 batchs: 486.82012939453125
INFO:root:Train (Epoch 237): Loss/seq after 02000 batchs: 487.0086669921875
INFO:root:Train (Epoch 237): Loss/seq after 02050 batchs: 486.2698669433594
INFO:root:Train (Epoch 237): Loss/seq after 02100 batchs: 484.2842712402344
INFO:root:Train (Epoch 237): Loss/seq after 02150 batchs: 482.8704833984375
INFO:root:Train (Epoch 237): Loss/seq after 02200 batchs: 480.9146423339844
INFO:root:Train (Epoch 237): Loss/seq after 02250 batchs: 480.0201721191406
INFO:root:Train (Epoch 237): Loss/seq after 02300 batchs: 477.3721008300781
INFO:root:Train (Epoch 237): Loss/seq after 02350 batchs: 473.8038024902344
INFO:root:Train (Epoch 237): Loss/seq after 02400 batchs: 475.8006591796875
INFO:root:Train (Epoch 237): Loss/seq after 02450 batchs: 471.9184875488281
INFO:root:Train (Epoch 237): Loss/seq after 02500 batchs: 464.79962158203125
INFO:root:Train (Epoch 237): Loss/seq after 02550 batchs: 459.1459045410156
INFO:root:Train (Epoch 237): Loss/seq after 02600 batchs: 456.78839111328125
INFO:root:Train (Epoch 237): Loss/seq after 02650 batchs: 453.94091796875
INFO:root:Train (Epoch 237): Loss/seq after 02700 batchs: 451.867431640625
INFO:root:Train (Epoch 237): Loss/seq after 02750 batchs: 447.41668701171875
INFO:root:Train (Epoch 237): Loss/seq after 02800 batchs: 446.863525390625
INFO:root:Train (Epoch 237): Loss/seq after 02850 batchs: 446.7375183105469
INFO:root:Train (Epoch 237): Loss/seq after 02900 batchs: 448.37982177734375
INFO:root:Train (Epoch 237): Loss/seq after 02950 batchs: 448.35284423828125
INFO:root:Train (Epoch 237): Loss/seq after 03000 batchs: 453.4796142578125
INFO:root:Train (Epoch 237): Loss/seq after 03050 batchs: 455.51385498046875
INFO:root:Train (Epoch 237): Loss/seq after 03100 batchs: 459.2013854980469
INFO:root:Train (Epoch 237): Loss/seq after 03150 batchs: 461.947998046875
INFO:root:Train (Epoch 237): Loss/seq after 03200 batchs: 462.9689636230469
INFO:root:Train (Epoch 237): Loss/seq after 03250 batchs: 466.0155944824219
INFO:root:Train (Epoch 237): Loss/seq after 03300 batchs: 465.7900085449219
INFO:root:Train (Epoch 237): Loss/seq after 03350 batchs: 464.4508056640625
INFO:root:Train (Epoch 237): Loss/seq after 03400 batchs: 461.4521789550781
INFO:root:Train (Epoch 237): Loss/seq after 03450 batchs: 459.9868469238281
INFO:root:Train (Epoch 237): Loss/seq after 03500 batchs: 460.5498352050781
INFO:root:Train (Epoch 237): Loss/seq after 03550 batchs: 458.2986755371094
INFO:root:Train (Epoch 237): Loss/seq after 03600 batchs: 465.23590087890625
INFO:root:Train (Epoch 237): Loss/seq after 03650 batchs: 463.61480712890625
INFO:root:Train (Epoch 237): Loss/seq after 03700 batchs: 465.83935546875
INFO:root:Train (Epoch 237): Loss/seq after 03750 batchs: 469.90234375
INFO:root:Train (Epoch 237): Loss/seq after 03800 batchs: 468.5119934082031
INFO:root:Train (Epoch 237): Loss/seq after 03850 batchs: 467.5197448730469
INFO:root:Train (Epoch 237): Loss/seq after 03900 batchs: 471.12945556640625
INFO:root:Train (Epoch 237): Loss/seq after 03950 batchs: 474.3433837890625
INFO:root:Train (Epoch 237): Loss/seq after 04000 batchs: 471.0561828613281
INFO:root:Train (Epoch 237): Loss/seq after 04050 batchs: 468.1984558105469
INFO:root:Train (Epoch 237): Loss/seq after 04100 batchs: 467.07147216796875
INFO:root:Train (Epoch 237): Loss/seq after 04150 batchs: 466.885498046875
INFO:root:Train (Epoch 237): Loss/seq after 04200 batchs: 465.422119140625
INFO:root:Train (Epoch 237): Loss/seq after 04250 batchs: 464.0343017578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 237): Loss/seq after 00000 batches: 425.85528564453125
INFO:root:# Valid (Epoch 237): Loss/seq after 00050 batches: 681.4998168945312
INFO:root:# Valid (Epoch 237): Loss/seq after 00100 batches: 682.2053833007812
INFO:root:# Valid (Epoch 237): Loss/seq after 00150 batches: 512.9583129882812
INFO:root:# Valid (Epoch 237): Loss/seq after 00200 batches: 469.8756408691406
INFO:root:Artifacts: Make stick videos for epoch 237
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_237_on_20220423_155441.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_237_index_1228_on_20220423_155441.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 238): Loss/seq after 00000 batchs: 1009.9952392578125
INFO:root:Train (Epoch 238): Loss/seq after 00050 batchs: 656.4391479492188
INFO:root:Train (Epoch 238): Loss/seq after 00100 batchs: 671.287841796875
INFO:root:Train (Epoch 238): Loss/seq after 00150 batchs: 596.669677734375
INFO:root:Train (Epoch 238): Loss/seq after 00200 batchs: 673.0787963867188
INFO:root:Train (Epoch 238): Loss/seq after 00250 batchs: 715.6707153320312
INFO:root:Train (Epoch 238): Loss/seq after 00300 batchs: 720.0565795898438
INFO:root:Train (Epoch 238): Loss/seq after 00350 batchs: 680.9114379882812
INFO:root:Train (Epoch 238): Loss/seq after 00400 batchs: 686.2684326171875
INFO:root:Train (Epoch 238): Loss/seq after 00450 batchs: 681.7318115234375
INFO:root:Train (Epoch 238): Loss/seq after 00500 batchs: 663.0191650390625
INFO:root:Train (Epoch 238): Loss/seq after 00550 batchs: 644.0374755859375
INFO:root:Train (Epoch 238): Loss/seq after 00600 batchs: 621.3783569335938
INFO:root:Train (Epoch 238): Loss/seq after 00650 batchs: 609.28125
INFO:root:Train (Epoch 238): Loss/seq after 00700 batchs: 587.757080078125
INFO:root:Train (Epoch 238): Loss/seq after 00750 batchs: 587.2084350585938
INFO:root:Train (Epoch 238): Loss/seq after 00800 batchs: 587.289794921875
INFO:root:Train (Epoch 238): Loss/seq after 00850 batchs: 568.6599731445312
INFO:root:Train (Epoch 238): Loss/seq after 00900 batchs: 553.0892944335938
INFO:root:Train (Epoch 238): Loss/seq after 00950 batchs: 551.7348022460938
INFO:root:Train (Epoch 238): Loss/seq after 01000 batchs: 543.5676879882812
INFO:root:Train (Epoch 238): Loss/seq after 01050 batchs: 531.876708984375
INFO:root:Train (Epoch 238): Loss/seq after 01100 batchs: 521.443603515625
INFO:root:Train (Epoch 238): Loss/seq after 01150 batchs: 508.3946228027344
INFO:root:Train (Epoch 238): Loss/seq after 01200 batchs: 512.1441650390625
INFO:root:Train (Epoch 238): Loss/seq after 01250 batchs: 510.37005615234375
INFO:root:Train (Epoch 238): Loss/seq after 01300 batchs: 500.1758728027344
INFO:root:Train (Epoch 238): Loss/seq after 01350 batchs: 491.9597473144531
INFO:root:Train (Epoch 238): Loss/seq after 01400 batchs: 493.9894714355469
INFO:root:Train (Epoch 238): Loss/seq after 01450 batchs: 496.3971862792969
INFO:root:Train (Epoch 238): Loss/seq after 01500 batchs: 502.7181091308594
INFO:root:Train (Epoch 238): Loss/seq after 01550 batchs: 505.21246337890625
INFO:root:Train (Epoch 238): Loss/seq after 01600 batchs: 501.5809020996094
INFO:root:Train (Epoch 238): Loss/seq after 01650 batchs: 499.27191162109375
INFO:root:Train (Epoch 238): Loss/seq after 01700 batchs: 502.39691162109375
INFO:root:Train (Epoch 238): Loss/seq after 01750 batchs: 500.23699951171875
INFO:root:Train (Epoch 238): Loss/seq after 01800 batchs: 497.6874084472656
INFO:root:Train (Epoch 238): Loss/seq after 01850 batchs: 494.2884826660156
INFO:root:Train (Epoch 238): Loss/seq after 01900 batchs: 492.3121032714844
INFO:root:Train (Epoch 238): Loss/seq after 01950 batchs: 490.8307800292969
INFO:root:Train (Epoch 238): Loss/seq after 02000 batchs: 490.80279541015625
INFO:root:Train (Epoch 238): Loss/seq after 02050 batchs: 489.5885009765625
INFO:root:Train (Epoch 238): Loss/seq after 02100 batchs: 487.42041015625
INFO:root:Train (Epoch 238): Loss/seq after 02150 batchs: 485.95050048828125
INFO:root:Train (Epoch 238): Loss/seq after 02200 batchs: 483.941162109375
INFO:root:Train (Epoch 238): Loss/seq after 02250 batchs: 482.6650390625
INFO:root:Train (Epoch 238): Loss/seq after 02300 batchs: 480.4239807128906
INFO:root:Train (Epoch 238): Loss/seq after 02350 batchs: 476.8437194824219
INFO:root:Train (Epoch 238): Loss/seq after 02400 batchs: 478.4537353515625
INFO:root:Train (Epoch 238): Loss/seq after 02450 batchs: 474.41400146484375
INFO:root:Train (Epoch 238): Loss/seq after 02500 batchs: 467.2413635253906
INFO:root:Train (Epoch 238): Loss/seq after 02550 batchs: 461.5267333984375
INFO:root:Train (Epoch 238): Loss/seq after 02600 batchs: 459.11236572265625
INFO:root:Train (Epoch 238): Loss/seq after 02650 batchs: 455.9167785644531
INFO:root:Train (Epoch 238): Loss/seq after 02700 batchs: 453.6289367675781
INFO:root:Train (Epoch 238): Loss/seq after 02750 batchs: 449.18780517578125
INFO:root:Train (Epoch 238): Loss/seq after 02800 batchs: 449.18560791015625
INFO:root:Train (Epoch 238): Loss/seq after 02850 batchs: 448.7066345214844
INFO:root:Train (Epoch 238): Loss/seq after 02900 batchs: 450.305908203125
INFO:root:Train (Epoch 238): Loss/seq after 02950 batchs: 450.2459716796875
INFO:root:Train (Epoch 238): Loss/seq after 03000 batchs: 455.5634460449219
INFO:root:Train (Epoch 238): Loss/seq after 03050 batchs: 457.1456298828125
INFO:root:Train (Epoch 238): Loss/seq after 03100 batchs: 459.75811767578125
INFO:root:Train (Epoch 238): Loss/seq after 03150 batchs: 462.6032409667969
INFO:root:Train (Epoch 238): Loss/seq after 03200 batchs: 463.6474914550781
INFO:root:Train (Epoch 238): Loss/seq after 03250 batchs: 465.87188720703125
INFO:root:Train (Epoch 238): Loss/seq after 03300 batchs: 465.5530700683594
INFO:root:Train (Epoch 238): Loss/seq after 03350 batchs: 463.9471740722656
INFO:root:Train (Epoch 238): Loss/seq after 03400 batchs: 460.9919738769531
INFO:root:Train (Epoch 238): Loss/seq after 03450 batchs: 459.587890625
INFO:root:Train (Epoch 238): Loss/seq after 03500 batchs: 460.1632080078125
INFO:root:Train (Epoch 238): Loss/seq after 03550 batchs: 457.7867126464844
INFO:root:Train (Epoch 238): Loss/seq after 03600 batchs: 464.8265075683594
INFO:root:Train (Epoch 238): Loss/seq after 03650 batchs: 463.17596435546875
INFO:root:Train (Epoch 238): Loss/seq after 03700 batchs: 465.72412109375
INFO:root:Train (Epoch 238): Loss/seq after 03750 batchs: 469.76287841796875
INFO:root:Train (Epoch 238): Loss/seq after 03800 batchs: 468.3462219238281
INFO:root:Train (Epoch 238): Loss/seq after 03850 batchs: 467.42852783203125
INFO:root:Train (Epoch 238): Loss/seq after 03900 batchs: 470.27734375
INFO:root:Train (Epoch 238): Loss/seq after 03950 batchs: 473.5624694824219
INFO:root:Train (Epoch 238): Loss/seq after 04000 batchs: 470.3840026855469
INFO:root:Train (Epoch 238): Loss/seq after 04050 batchs: 467.5152893066406
INFO:root:Train (Epoch 238): Loss/seq after 04100 batchs: 466.46002197265625
INFO:root:Train (Epoch 238): Loss/seq after 04150 batchs: 466.40191650390625
INFO:root:Train (Epoch 238): Loss/seq after 04200 batchs: 465.09393310546875
INFO:root:Train (Epoch 238): Loss/seq after 04250 batchs: 463.7431335449219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 238): Loss/seq after 00000 batches: 436.0238952636719
INFO:root:# Valid (Epoch 238): Loss/seq after 00050 batches: 699.1455688476562
INFO:root:# Valid (Epoch 238): Loss/seq after 00100 batches: 696.569580078125
INFO:root:# Valid (Epoch 238): Loss/seq after 00150 batches: 522.911865234375
INFO:root:# Valid (Epoch 238): Loss/seq after 00200 batches: 479.2213134765625
INFO:root:Artifacts: Make stick videos for epoch 238
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_238_on_20220423_155947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_238_index_1284_on_20220423_155947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 239): Loss/seq after 00000 batchs: 1326.3807373046875
INFO:root:Train (Epoch 239): Loss/seq after 00050 batchs: 673.9830932617188
INFO:root:Train (Epoch 239): Loss/seq after 00100 batchs: 656.3092651367188
INFO:root:Train (Epoch 239): Loss/seq after 00150 batchs: 585.9328002929688
INFO:root:Train (Epoch 239): Loss/seq after 00200 batchs: 660.0440063476562
INFO:root:Train (Epoch 239): Loss/seq after 00250 batchs: 705.1209716796875
INFO:root:Train (Epoch 239): Loss/seq after 00300 batchs: 712.1533203125
INFO:root:Train (Epoch 239): Loss/seq after 00350 batchs: 673.308349609375
INFO:root:Train (Epoch 239): Loss/seq after 00400 batchs: 670.8654174804688
INFO:root:Train (Epoch 239): Loss/seq after 00450 batchs: 667.7435302734375
INFO:root:Train (Epoch 239): Loss/seq after 00500 batchs: 645.5634155273438
INFO:root:Train (Epoch 239): Loss/seq after 00550 batchs: 628.71630859375
INFO:root:Train (Epoch 239): Loss/seq after 00600 batchs: 607.8497924804688
INFO:root:Train (Epoch 239): Loss/seq after 00650 batchs: 593.3494873046875
INFO:root:Train (Epoch 239): Loss/seq after 00700 batchs: 573.6129760742188
INFO:root:Train (Epoch 239): Loss/seq after 00750 batchs: 572.885986328125
INFO:root:Train (Epoch 239): Loss/seq after 00800 batchs: 573.0441284179688
INFO:root:Train (Epoch 239): Loss/seq after 00850 batchs: 555.7565307617188
INFO:root:Train (Epoch 239): Loss/seq after 00900 batchs: 541.5309448242188
INFO:root:Train (Epoch 239): Loss/seq after 00950 batchs: 542.3004150390625
INFO:root:Train (Epoch 239): Loss/seq after 01000 batchs: 534.388671875
INFO:root:Train (Epoch 239): Loss/seq after 01050 batchs: 523.35400390625
INFO:root:Train (Epoch 239): Loss/seq after 01100 batchs: 513.1749877929688
INFO:root:Train (Epoch 239): Loss/seq after 01150 batchs: 500.3992919921875
INFO:root:Train (Epoch 239): Loss/seq after 01200 batchs: 504.03411865234375
INFO:root:Train (Epoch 239): Loss/seq after 01250 batchs: 502.476806640625
INFO:root:Train (Epoch 239): Loss/seq after 01300 batchs: 492.8747863769531
INFO:root:Train (Epoch 239): Loss/seq after 01350 batchs: 484.24749755859375
INFO:root:Train (Epoch 239): Loss/seq after 01400 batchs: 486.2925109863281
INFO:root:Train (Epoch 239): Loss/seq after 01450 batchs: 488.993408203125
INFO:root:Train (Epoch 239): Loss/seq after 01500 batchs: 495.10687255859375
INFO:root:Train (Epoch 239): Loss/seq after 01550 batchs: 497.0148620605469
INFO:root:Train (Epoch 239): Loss/seq after 01600 batchs: 493.41217041015625
INFO:root:Train (Epoch 239): Loss/seq after 01650 batchs: 491.33746337890625
INFO:root:Train (Epoch 239): Loss/seq after 01700 batchs: 494.72161865234375
INFO:root:Train (Epoch 239): Loss/seq after 01750 batchs: 492.80950927734375
INFO:root:Train (Epoch 239): Loss/seq after 01800 batchs: 490.5235900878906
INFO:root:Train (Epoch 239): Loss/seq after 01850 batchs: 487.4524230957031
INFO:root:Train (Epoch 239): Loss/seq after 01900 batchs: 485.8194274902344
INFO:root:Train (Epoch 239): Loss/seq after 01950 batchs: 484.2307434082031
INFO:root:Train (Epoch 239): Loss/seq after 02000 batchs: 484.3354187011719
INFO:root:Train (Epoch 239): Loss/seq after 02050 batchs: 483.28668212890625
INFO:root:Train (Epoch 239): Loss/seq after 02100 batchs: 481.4375305175781
INFO:root:Train (Epoch 239): Loss/seq after 02150 batchs: 479.9798583984375
INFO:root:Train (Epoch 239): Loss/seq after 02200 batchs: 478.0762634277344
INFO:root:Train (Epoch 239): Loss/seq after 02250 batchs: 477.1153564453125
INFO:root:Train (Epoch 239): Loss/seq after 02300 batchs: 474.528076171875
INFO:root:Train (Epoch 239): Loss/seq after 02350 batchs: 470.99407958984375
INFO:root:Train (Epoch 239): Loss/seq after 02400 batchs: 472.9654846191406
INFO:root:Train (Epoch 239): Loss/seq after 02450 batchs: 469.08245849609375
INFO:root:Train (Epoch 239): Loss/seq after 02500 batchs: 462.0249328613281
INFO:root:Train (Epoch 239): Loss/seq after 02550 batchs: 456.3075256347656
INFO:root:Train (Epoch 239): Loss/seq after 02600 batchs: 453.8531188964844
INFO:root:Train (Epoch 239): Loss/seq after 02650 batchs: 450.64532470703125
INFO:root:Train (Epoch 239): Loss/seq after 02700 batchs: 448.45208740234375
INFO:root:Train (Epoch 239): Loss/seq after 02750 batchs: 444.00665283203125
INFO:root:Train (Epoch 239): Loss/seq after 02800 batchs: 443.86920166015625
INFO:root:Train (Epoch 239): Loss/seq after 02850 batchs: 443.5228576660156
INFO:root:Train (Epoch 239): Loss/seq after 02900 batchs: 444.9378356933594
INFO:root:Train (Epoch 239): Loss/seq after 02950 batchs: 445.0356140136719
INFO:root:Train (Epoch 239): Loss/seq after 03000 batchs: 450.5113525390625
INFO:root:Train (Epoch 239): Loss/seq after 03050 batchs: 452.4487609863281
INFO:root:Train (Epoch 239): Loss/seq after 03100 batchs: 454.502197265625
INFO:root:Train (Epoch 239): Loss/seq after 03150 batchs: 457.5161437988281
INFO:root:Train (Epoch 239): Loss/seq after 03200 batchs: 458.3212585449219
INFO:root:Train (Epoch 239): Loss/seq after 03250 batchs: 461.1240539550781
INFO:root:Train (Epoch 239): Loss/seq after 03300 batchs: 460.1065673828125
INFO:root:Train (Epoch 239): Loss/seq after 03350 batchs: 458.4391174316406
INFO:root:Train (Epoch 239): Loss/seq after 03400 batchs: 455.54437255859375
INFO:root:Train (Epoch 239): Loss/seq after 03450 batchs: 454.1925048828125
INFO:root:Train (Epoch 239): Loss/seq after 03500 batchs: 454.4945068359375
INFO:root:Train (Epoch 239): Loss/seq after 03550 batchs: 452.404541015625
INFO:root:Train (Epoch 239): Loss/seq after 03600 batchs: 459.12872314453125
INFO:root:Train (Epoch 239): Loss/seq after 03650 batchs: 457.4559326171875
INFO:root:Train (Epoch 239): Loss/seq after 03700 batchs: 459.4073181152344
INFO:root:Train (Epoch 239): Loss/seq after 03750 batchs: 463.6013488769531
INFO:root:Train (Epoch 239): Loss/seq after 03800 batchs: 462.31744384765625
INFO:root:Train (Epoch 239): Loss/seq after 03850 batchs: 461.4489440917969
INFO:root:Train (Epoch 239): Loss/seq after 03900 batchs: 464.41552734375
INFO:root:Train (Epoch 239): Loss/seq after 03950 batchs: 467.77001953125
INFO:root:Train (Epoch 239): Loss/seq after 04000 batchs: 464.6250915527344
INFO:root:Train (Epoch 239): Loss/seq after 04050 batchs: 461.8382873535156
INFO:root:Train (Epoch 239): Loss/seq after 04100 batchs: 460.7676086425781
INFO:root:Train (Epoch 239): Loss/seq after 04150 batchs: 460.69952392578125
INFO:root:Train (Epoch 239): Loss/seq after 04200 batchs: 459.2916564941406
INFO:root:Train (Epoch 239): Loss/seq after 04250 batchs: 457.91790771484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 239): Loss/seq after 00000 batches: 438.9510498046875
INFO:root:# Valid (Epoch 239): Loss/seq after 00050 batches: 688.9010620117188
INFO:root:# Valid (Epoch 239): Loss/seq after 00100 batches: 701.2106323242188
INFO:root:# Valid (Epoch 239): Loss/seq after 00150 batches: 526.6369018554688
INFO:root:# Valid (Epoch 239): Loss/seq after 00200 batches: 480.2249450683594
INFO:root:Artifacts: Make stick videos for epoch 239
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_239_on_20220423_160442.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_239_index_26_on_20220423_160442.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 240): Loss/seq after 00000 batchs: 1121.9854736328125
INFO:root:Train (Epoch 240): Loss/seq after 00050 batchs: 647.2045288085938
INFO:root:Train (Epoch 240): Loss/seq after 00100 batchs: 671.2155151367188
INFO:root:Train (Epoch 240): Loss/seq after 00150 batchs: 596.78564453125
INFO:root:Train (Epoch 240): Loss/seq after 00200 batchs: 666.4784545898438
INFO:root:Train (Epoch 240): Loss/seq after 00250 batchs: 706.9625854492188
INFO:root:Train (Epoch 240): Loss/seq after 00300 batchs: 717.5206298828125
INFO:root:Train (Epoch 240): Loss/seq after 00350 batchs: 679.2697143554688
INFO:root:Train (Epoch 240): Loss/seq after 00400 batchs: 677.6488037109375
INFO:root:Train (Epoch 240): Loss/seq after 00450 batchs: 673.68701171875
INFO:root:Train (Epoch 240): Loss/seq after 00500 batchs: 652.1979370117188
INFO:root:Train (Epoch 240): Loss/seq after 00550 batchs: 634.9095458984375
INFO:root:Train (Epoch 240): Loss/seq after 00600 batchs: 613.2772216796875
INFO:root:Train (Epoch 240): Loss/seq after 00650 batchs: 594.777099609375
INFO:root:Train (Epoch 240): Loss/seq after 00700 batchs: 575.43701171875
INFO:root:Train (Epoch 240): Loss/seq after 00750 batchs: 575.7391357421875
INFO:root:Train (Epoch 240): Loss/seq after 00800 batchs: 575.9754638671875
INFO:root:Train (Epoch 240): Loss/seq after 00850 batchs: 557.7815551757812
INFO:root:Train (Epoch 240): Loss/seq after 00900 batchs: 543.0978393554688
INFO:root:Train (Epoch 240): Loss/seq after 00950 batchs: 542.7734985351562
INFO:root:Train (Epoch 240): Loss/seq after 01000 batchs: 535.2635498046875
INFO:root:Train (Epoch 240): Loss/seq after 01050 batchs: 524.2470703125
INFO:root:Train (Epoch 240): Loss/seq after 01100 batchs: 514.3025512695312
INFO:root:Train (Epoch 240): Loss/seq after 01150 batchs: 501.7040710449219
INFO:root:Train (Epoch 240): Loss/seq after 01200 batchs: 505.4400329589844
INFO:root:Train (Epoch 240): Loss/seq after 01250 batchs: 504.0358581542969
INFO:root:Train (Epoch 240): Loss/seq after 01300 batchs: 494.61474609375
INFO:root:Train (Epoch 240): Loss/seq after 01350 batchs: 486.0616149902344
INFO:root:Train (Epoch 240): Loss/seq after 01400 batchs: 490.45501708984375
INFO:root:Train (Epoch 240): Loss/seq after 01450 batchs: 493.0499267578125
INFO:root:Train (Epoch 240): Loss/seq after 01500 batchs: 498.8398132324219
INFO:root:Train (Epoch 240): Loss/seq after 01550 batchs: 500.08544921875
INFO:root:Train (Epoch 240): Loss/seq after 01600 batchs: 496.3451232910156
INFO:root:Train (Epoch 240): Loss/seq after 01650 batchs: 493.89306640625
INFO:root:Train (Epoch 240): Loss/seq after 01700 batchs: 496.9296569824219
INFO:root:Train (Epoch 240): Loss/seq after 01750 batchs: 494.8943176269531
INFO:root:Train (Epoch 240): Loss/seq after 01800 batchs: 492.4425964355469
INFO:root:Train (Epoch 240): Loss/seq after 01850 batchs: 489.1124572753906
INFO:root:Train (Epoch 240): Loss/seq after 01900 batchs: 487.50714111328125
INFO:root:Train (Epoch 240): Loss/seq after 01950 batchs: 486.0107116699219
INFO:root:Train (Epoch 240): Loss/seq after 02000 batchs: 486.0967712402344
INFO:root:Train (Epoch 240): Loss/seq after 02050 batchs: 485.118408203125
INFO:root:Train (Epoch 240): Loss/seq after 02100 batchs: 483.22265625
INFO:root:Train (Epoch 240): Loss/seq after 02150 batchs: 481.7760925292969
INFO:root:Train (Epoch 240): Loss/seq after 02200 batchs: 479.81536865234375
INFO:root:Train (Epoch 240): Loss/seq after 02250 batchs: 478.5084533691406
INFO:root:Train (Epoch 240): Loss/seq after 02300 batchs: 476.18902587890625
INFO:root:Train (Epoch 240): Loss/seq after 02350 batchs: 472.6915588378906
INFO:root:Train (Epoch 240): Loss/seq after 02400 batchs: 474.5426025390625
INFO:root:Train (Epoch 240): Loss/seq after 02450 batchs: 470.5986328125
INFO:root:Train (Epoch 240): Loss/seq after 02500 batchs: 463.4320373535156
INFO:root:Train (Epoch 240): Loss/seq after 02550 batchs: 457.6490478515625
INFO:root:Train (Epoch 240): Loss/seq after 02600 batchs: 455.15704345703125
INFO:root:Train (Epoch 240): Loss/seq after 02650 batchs: 451.8709411621094
INFO:root:Train (Epoch 240): Loss/seq after 02700 batchs: 449.4416198730469
INFO:root:Train (Epoch 240): Loss/seq after 02750 batchs: 445.1777648925781
INFO:root:Train (Epoch 240): Loss/seq after 02800 batchs: 445.1177673339844
INFO:root:Train (Epoch 240): Loss/seq after 02850 batchs: 444.7326354980469
INFO:root:Train (Epoch 240): Loss/seq after 02900 batchs: 446.0829772949219
INFO:root:Train (Epoch 240): Loss/seq after 02950 batchs: 446.0516357421875
INFO:root:Train (Epoch 240): Loss/seq after 03000 batchs: 451.501220703125
INFO:root:Train (Epoch 240): Loss/seq after 03050 batchs: 453.4517517089844
INFO:root:Train (Epoch 240): Loss/seq after 03100 batchs: 456.0683898925781
INFO:root:Train (Epoch 240): Loss/seq after 03150 batchs: 459.3233337402344
INFO:root:Train (Epoch 240): Loss/seq after 03200 batchs: 461.3822021484375
INFO:root:Train (Epoch 240): Loss/seq after 03250 batchs: 463.881591796875
INFO:root:Train (Epoch 240): Loss/seq after 03300 batchs: 464.19415283203125
INFO:root:Train (Epoch 240): Loss/seq after 03350 batchs: 463.3648681640625
INFO:root:Train (Epoch 240): Loss/seq after 03400 batchs: 460.40606689453125
INFO:root:Train (Epoch 240): Loss/seq after 03450 batchs: 459.080810546875
INFO:root:Train (Epoch 240): Loss/seq after 03500 batchs: 460.0387268066406
INFO:root:Train (Epoch 240): Loss/seq after 03550 batchs: 457.9469909667969
INFO:root:Train (Epoch 240): Loss/seq after 03600 batchs: 464.8875732421875
INFO:root:Train (Epoch 240): Loss/seq after 03650 batchs: 463.2543029785156
INFO:root:Train (Epoch 240): Loss/seq after 03700 batchs: 465.2171630859375
INFO:root:Train (Epoch 240): Loss/seq after 03750 batchs: 469.1653747558594
INFO:root:Train (Epoch 240): Loss/seq after 03800 batchs: 467.7728576660156
INFO:root:Train (Epoch 240): Loss/seq after 03850 batchs: 466.7601318359375
INFO:root:Train (Epoch 240): Loss/seq after 03900 batchs: 469.6556701660156
INFO:root:Train (Epoch 240): Loss/seq after 03950 batchs: 473.1743469238281
INFO:root:Train (Epoch 240): Loss/seq after 04000 batchs: 469.9203796386719
INFO:root:Train (Epoch 240): Loss/seq after 04050 batchs: 467.1194763183594
INFO:root:Train (Epoch 240): Loss/seq after 04100 batchs: 465.98138427734375
INFO:root:Train (Epoch 240): Loss/seq after 04150 batchs: 465.7543640136719
INFO:root:Train (Epoch 240): Loss/seq after 04200 batchs: 464.29071044921875
INFO:root:Train (Epoch 240): Loss/seq after 04250 batchs: 462.80548095703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 240): Loss/seq after 00000 batches: 425.26507568359375
INFO:root:# Valid (Epoch 240): Loss/seq after 00050 batches: 671.3184204101562
INFO:root:# Valid (Epoch 240): Loss/seq after 00100 batches: 705.6566772460938
INFO:root:# Valid (Epoch 240): Loss/seq after 00150 batches: 529.153076171875
INFO:root:# Valid (Epoch 240): Loss/seq after 00200 batches: 482.26666259765625
INFO:root:Artifacts: Make stick videos for epoch 240
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_240_on_20220423_160949.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_240_index_501_on_20220423_160949.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 241): Loss/seq after 00000 batchs: 949.0836181640625
INFO:root:Train (Epoch 241): Loss/seq after 00050 batchs: 640.0341186523438
INFO:root:Train (Epoch 241): Loss/seq after 00100 batchs: 650.87353515625
INFO:root:Train (Epoch 241): Loss/seq after 00150 batchs: 582.3167114257812
INFO:root:Train (Epoch 241): Loss/seq after 00200 batchs: 659.1031494140625
INFO:root:Train (Epoch 241): Loss/seq after 00250 batchs: 709.595947265625
INFO:root:Train (Epoch 241): Loss/seq after 00300 batchs: 716.343017578125
INFO:root:Train (Epoch 241): Loss/seq after 00350 batchs: 676.69580078125
INFO:root:Train (Epoch 241): Loss/seq after 00400 batchs: 675.9794311523438
INFO:root:Train (Epoch 241): Loss/seq after 00450 batchs: 672.0541381835938
INFO:root:Train (Epoch 241): Loss/seq after 00500 batchs: 651.0890502929688
INFO:root:Train (Epoch 241): Loss/seq after 00550 batchs: 633.1903076171875
INFO:root:Train (Epoch 241): Loss/seq after 00600 batchs: 610.4554443359375
INFO:root:Train (Epoch 241): Loss/seq after 00650 batchs: 596.201171875
INFO:root:Train (Epoch 241): Loss/seq after 00700 batchs: 574.8726806640625
INFO:root:Train (Epoch 241): Loss/seq after 00750 batchs: 574.520751953125
INFO:root:Train (Epoch 241): Loss/seq after 00800 batchs: 575.6991577148438
INFO:root:Train (Epoch 241): Loss/seq after 00850 batchs: 557.5597534179688
INFO:root:Train (Epoch 241): Loss/seq after 00900 batchs: 542.8123168945312
INFO:root:Train (Epoch 241): Loss/seq after 00950 batchs: 545.0103149414062
INFO:root:Train (Epoch 241): Loss/seq after 01000 batchs: 537.4231567382812
INFO:root:Train (Epoch 241): Loss/seq after 01050 batchs: 528.492919921875
INFO:root:Train (Epoch 241): Loss/seq after 01100 batchs: 519.5160522460938
INFO:root:Train (Epoch 241): Loss/seq after 01150 batchs: 506.9831848144531
INFO:root:Train (Epoch 241): Loss/seq after 01200 batchs: 510.5559387207031
INFO:root:Train (Epoch 241): Loss/seq after 01250 batchs: 509.2300720214844
INFO:root:Train (Epoch 241): Loss/seq after 01300 batchs: 499.5437927246094
INFO:root:Train (Epoch 241): Loss/seq after 01350 batchs: 490.6761474609375
INFO:root:Train (Epoch 241): Loss/seq after 01400 batchs: 492.9898681640625
INFO:root:Train (Epoch 241): Loss/seq after 01450 batchs: 495.42706298828125
INFO:root:Train (Epoch 241): Loss/seq after 01500 batchs: 501.3946533203125
INFO:root:Train (Epoch 241): Loss/seq after 01550 batchs: 502.8180847167969
INFO:root:Train (Epoch 241): Loss/seq after 01600 batchs: 498.7274169921875
INFO:root:Train (Epoch 241): Loss/seq after 01650 batchs: 496.2403259277344
INFO:root:Train (Epoch 241): Loss/seq after 01700 batchs: 499.57244873046875
INFO:root:Train (Epoch 241): Loss/seq after 01750 batchs: 497.4577941894531
INFO:root:Train (Epoch 241): Loss/seq after 01800 batchs: 494.9164123535156
INFO:root:Train (Epoch 241): Loss/seq after 01850 batchs: 491.5895690917969
INFO:root:Train (Epoch 241): Loss/seq after 01900 batchs: 489.45269775390625
INFO:root:Train (Epoch 241): Loss/seq after 01950 batchs: 487.8133850097656
INFO:root:Train (Epoch 241): Loss/seq after 02000 batchs: 487.7222595214844
INFO:root:Train (Epoch 241): Loss/seq after 02050 batchs: 486.8602600097656
INFO:root:Train (Epoch 241): Loss/seq after 02100 batchs: 484.71014404296875
INFO:root:Train (Epoch 241): Loss/seq after 02150 batchs: 483.34075927734375
INFO:root:Train (Epoch 241): Loss/seq after 02200 batchs: 481.2259216308594
INFO:root:Train (Epoch 241): Loss/seq after 02250 batchs: 479.92138671875
INFO:root:Train (Epoch 241): Loss/seq after 02300 batchs: 477.4538269042969
INFO:root:Train (Epoch 241): Loss/seq after 02350 batchs: 474.0290832519531
INFO:root:Train (Epoch 241): Loss/seq after 02400 batchs: 475.7402648925781
INFO:root:Train (Epoch 241): Loss/seq after 02450 batchs: 471.8493347167969
INFO:root:Train (Epoch 241): Loss/seq after 02500 batchs: 464.6720886230469
INFO:root:Train (Epoch 241): Loss/seq after 02550 batchs: 458.8586730957031
INFO:root:Train (Epoch 241): Loss/seq after 02600 batchs: 456.0617370605469
INFO:root:Train (Epoch 241): Loss/seq after 02650 batchs: 452.7420349121094
INFO:root:Train (Epoch 241): Loss/seq after 02700 batchs: 450.53436279296875
INFO:root:Train (Epoch 241): Loss/seq after 02750 batchs: 446.55035400390625
INFO:root:Train (Epoch 241): Loss/seq after 02800 batchs: 446.6702575683594
INFO:root:Train (Epoch 241): Loss/seq after 02850 batchs: 446.3718566894531
INFO:root:Train (Epoch 241): Loss/seq after 02900 batchs: 447.76605224609375
INFO:root:Train (Epoch 241): Loss/seq after 02950 batchs: 447.7806396484375
INFO:root:Train (Epoch 241): Loss/seq after 03000 batchs: 453.0066223144531
INFO:root:Train (Epoch 241): Loss/seq after 03050 batchs: 454.8680419921875
INFO:root:Train (Epoch 241): Loss/seq after 03100 batchs: 457.4756774902344
INFO:root:Train (Epoch 241): Loss/seq after 03150 batchs: 459.54736328125
INFO:root:Train (Epoch 241): Loss/seq after 03200 batchs: 460.1124267578125
INFO:root:Train (Epoch 241): Loss/seq after 03250 batchs: 461.7055969238281
INFO:root:Train (Epoch 241): Loss/seq after 03300 batchs: 461.17730712890625
INFO:root:Train (Epoch 241): Loss/seq after 03350 batchs: 460.5859680175781
INFO:root:Train (Epoch 241): Loss/seq after 03400 batchs: 457.6440734863281
INFO:root:Train (Epoch 241): Loss/seq after 03450 batchs: 456.1871032714844
INFO:root:Train (Epoch 241): Loss/seq after 03500 batchs: 456.8955078125
INFO:root:Train (Epoch 241): Loss/seq after 03550 batchs: 454.6011047363281
INFO:root:Train (Epoch 241): Loss/seq after 03600 batchs: 461.4069519042969
INFO:root:Train (Epoch 241): Loss/seq after 03650 batchs: 459.7108459472656
INFO:root:Train (Epoch 241): Loss/seq after 03700 batchs: 462.0634460449219
INFO:root:Train (Epoch 241): Loss/seq after 03750 batchs: 466.09698486328125
INFO:root:Train (Epoch 241): Loss/seq after 03800 batchs: 464.781982421875
INFO:root:Train (Epoch 241): Loss/seq after 03850 batchs: 463.826416015625
INFO:root:Train (Epoch 241): Loss/seq after 03900 batchs: 466.5301208496094
INFO:root:Train (Epoch 241): Loss/seq after 03950 batchs: 469.4739990234375
INFO:root:Train (Epoch 241): Loss/seq after 04000 batchs: 466.28546142578125
INFO:root:Train (Epoch 241): Loss/seq after 04050 batchs: 463.3998107910156
INFO:root:Train (Epoch 241): Loss/seq after 04100 batchs: 462.2581787109375
INFO:root:Train (Epoch 241): Loss/seq after 04150 batchs: 462.1260986328125
INFO:root:Train (Epoch 241): Loss/seq after 04200 batchs: 460.7082824707031
INFO:root:Train (Epoch 241): Loss/seq after 04250 batchs: 459.2406311035156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 241): Loss/seq after 00000 batches: 426.27374267578125
INFO:root:# Valid (Epoch 241): Loss/seq after 00050 batches: 682.8761596679688
INFO:root:# Valid (Epoch 241): Loss/seq after 00100 batches: 703.2691040039062
INFO:root:# Valid (Epoch 241): Loss/seq after 00150 batches: 527.6973876953125
INFO:root:# Valid (Epoch 241): Loss/seq after 00200 batches: 481.0765075683594
INFO:root:Artifacts: Make stick videos for epoch 241
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_241_on_20220423_161457.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_241_index_1125_on_20220423_161457.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 242): Loss/seq after 00000 batchs: 845.8408203125
INFO:root:Train (Epoch 242): Loss/seq after 00050 batchs: 653.3175659179688
INFO:root:Train (Epoch 242): Loss/seq after 00100 batchs: 671.3645629882812
INFO:root:Train (Epoch 242): Loss/seq after 00150 batchs: 600.5747680664062
INFO:root:Train (Epoch 242): Loss/seq after 00200 batchs: 670.14501953125
INFO:root:Train (Epoch 242): Loss/seq after 00250 batchs: 707.5816040039062
INFO:root:Train (Epoch 242): Loss/seq after 00300 batchs: 713.8417358398438
INFO:root:Train (Epoch 242): Loss/seq after 00350 batchs: 674.5752563476562
INFO:root:Train (Epoch 242): Loss/seq after 00400 batchs: 672.49658203125
INFO:root:Train (Epoch 242): Loss/seq after 00450 batchs: 669.109619140625
INFO:root:Train (Epoch 242): Loss/seq after 00500 batchs: 646.6608276367188
INFO:root:Train (Epoch 242): Loss/seq after 00550 batchs: 629.5191040039062
INFO:root:Train (Epoch 242): Loss/seq after 00600 batchs: 608.3121948242188
INFO:root:Train (Epoch 242): Loss/seq after 00650 batchs: 589.611083984375
INFO:root:Train (Epoch 242): Loss/seq after 00700 batchs: 568.3435668945312
INFO:root:Train (Epoch 242): Loss/seq after 00750 batchs: 569.39404296875
INFO:root:Train (Epoch 242): Loss/seq after 00800 batchs: 568.907958984375
INFO:root:Train (Epoch 242): Loss/seq after 00850 batchs: 551.16552734375
INFO:root:Train (Epoch 242): Loss/seq after 00900 batchs: 536.9888305664062
INFO:root:Train (Epoch 242): Loss/seq after 00950 batchs: 539.317626953125
INFO:root:Train (Epoch 242): Loss/seq after 01000 batchs: 530.7020263671875
INFO:root:Train (Epoch 242): Loss/seq after 01050 batchs: 521.8961791992188
INFO:root:Train (Epoch 242): Loss/seq after 01100 batchs: 512.547119140625
INFO:root:Train (Epoch 242): Loss/seq after 01150 batchs: 499.6293640136719
INFO:root:Train (Epoch 242): Loss/seq after 01200 batchs: 503.7967224121094
INFO:root:Train (Epoch 242): Loss/seq after 01250 batchs: 502.59722900390625
INFO:root:Train (Epoch 242): Loss/seq after 01300 batchs: 492.84716796875
INFO:root:Train (Epoch 242): Loss/seq after 01350 batchs: 484.1488037109375
INFO:root:Train (Epoch 242): Loss/seq after 01400 batchs: 486.4972839355469
INFO:root:Train (Epoch 242): Loss/seq after 01450 batchs: 489.2323913574219
INFO:root:Train (Epoch 242): Loss/seq after 01500 batchs: 494.755126953125
INFO:root:Train (Epoch 242): Loss/seq after 01550 batchs: 496.0567626953125
INFO:root:Train (Epoch 242): Loss/seq after 01600 batchs: 492.27142333984375
INFO:root:Train (Epoch 242): Loss/seq after 01650 batchs: 490.1481018066406
INFO:root:Train (Epoch 242): Loss/seq after 01700 batchs: 493.3122253417969
INFO:root:Train (Epoch 242): Loss/seq after 01750 batchs: 491.2318115234375
INFO:root:Train (Epoch 242): Loss/seq after 01800 batchs: 488.84033203125
INFO:root:Train (Epoch 242): Loss/seq after 01850 batchs: 485.76470947265625
INFO:root:Train (Epoch 242): Loss/seq after 01900 batchs: 484.1848449707031
INFO:root:Train (Epoch 242): Loss/seq after 01950 batchs: 482.583984375
INFO:root:Train (Epoch 242): Loss/seq after 02000 batchs: 482.7196960449219
INFO:root:Train (Epoch 242): Loss/seq after 02050 batchs: 481.80877685546875
INFO:root:Train (Epoch 242): Loss/seq after 02100 batchs: 479.9385681152344
INFO:root:Train (Epoch 242): Loss/seq after 02150 batchs: 478.636474609375
INFO:root:Train (Epoch 242): Loss/seq after 02200 batchs: 476.5977478027344
INFO:root:Train (Epoch 242): Loss/seq after 02250 batchs: 475.3312072753906
INFO:root:Train (Epoch 242): Loss/seq after 02300 batchs: 472.68133544921875
INFO:root:Train (Epoch 242): Loss/seq after 02350 batchs: 469.3222961425781
INFO:root:Train (Epoch 242): Loss/seq after 02400 batchs: 470.96527099609375
INFO:root:Train (Epoch 242): Loss/seq after 02450 batchs: 467.09063720703125
INFO:root:Train (Epoch 242): Loss/seq after 02500 batchs: 460.00885009765625
INFO:root:Train (Epoch 242): Loss/seq after 02550 batchs: 454.3240966796875
INFO:root:Train (Epoch 242): Loss/seq after 02600 batchs: 451.44366455078125
INFO:root:Train (Epoch 242): Loss/seq after 02650 batchs: 448.1490783691406
INFO:root:Train (Epoch 242): Loss/seq after 02700 batchs: 446.03887939453125
INFO:root:Train (Epoch 242): Loss/seq after 02750 batchs: 442.53912353515625
INFO:root:Train (Epoch 242): Loss/seq after 02800 batchs: 442.3003845214844
INFO:root:Train (Epoch 242): Loss/seq after 02850 batchs: 441.834228515625
INFO:root:Train (Epoch 242): Loss/seq after 02900 batchs: 443.07952880859375
INFO:root:Train (Epoch 242): Loss/seq after 02950 batchs: 443.0354919433594
INFO:root:Train (Epoch 242): Loss/seq after 03000 batchs: 448.16082763671875
INFO:root:Train (Epoch 242): Loss/seq after 03050 batchs: 449.8453674316406
INFO:root:Train (Epoch 242): Loss/seq after 03100 batchs: 452.633056640625
INFO:root:Train (Epoch 242): Loss/seq after 03150 batchs: 454.45751953125
INFO:root:Train (Epoch 242): Loss/seq after 03200 batchs: 455.1426696777344
INFO:root:Train (Epoch 242): Loss/seq after 03250 batchs: 457.1311340332031
INFO:root:Train (Epoch 242): Loss/seq after 03300 batchs: 456.9631042480469
INFO:root:Train (Epoch 242): Loss/seq after 03350 batchs: 455.70086669921875
INFO:root:Train (Epoch 242): Loss/seq after 03400 batchs: 452.7421875
INFO:root:Train (Epoch 242): Loss/seq after 03450 batchs: 451.2459716796875
INFO:root:Train (Epoch 242): Loss/seq after 03500 batchs: 452.5531921386719
INFO:root:Train (Epoch 242): Loss/seq after 03550 batchs: 450.42327880859375
INFO:root:Train (Epoch 242): Loss/seq after 03600 batchs: 457.05902099609375
INFO:root:Train (Epoch 242): Loss/seq after 03650 batchs: 455.541748046875
INFO:root:Train (Epoch 242): Loss/seq after 03700 batchs: 457.6040344238281
INFO:root:Train (Epoch 242): Loss/seq after 03750 batchs: 461.70477294921875
INFO:root:Train (Epoch 242): Loss/seq after 03800 batchs: 460.43701171875
INFO:root:Train (Epoch 242): Loss/seq after 03850 batchs: 459.58538818359375
INFO:root:Train (Epoch 242): Loss/seq after 03900 batchs: 462.1857604980469
INFO:root:Train (Epoch 242): Loss/seq after 03950 batchs: 465.2934265136719
INFO:root:Train (Epoch 242): Loss/seq after 04000 batchs: 462.1080627441406
INFO:root:Train (Epoch 242): Loss/seq after 04050 batchs: 459.31494140625
INFO:root:Train (Epoch 242): Loss/seq after 04100 batchs: 458.2565002441406
INFO:root:Train (Epoch 242): Loss/seq after 04150 batchs: 458.0617980957031
INFO:root:Train (Epoch 242): Loss/seq after 04200 batchs: 456.775634765625
INFO:root:Train (Epoch 242): Loss/seq after 04250 batchs: 455.3556213378906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 242): Loss/seq after 00000 batches: 430.8138732910156
INFO:root:# Valid (Epoch 242): Loss/seq after 00050 batches: 689.0930786132812
INFO:root:# Valid (Epoch 242): Loss/seq after 00100 batches: 709.873046875
INFO:root:# Valid (Epoch 242): Loss/seq after 00150 batches: 531.9346313476562
INFO:root:# Valid (Epoch 242): Loss/seq after 00200 batches: 483.4276123046875
INFO:root:Artifacts: Make stick videos for epoch 242
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_242_on_20220423_161945.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_242_index_644_on_20220423_161945.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 243): Loss/seq after 00000 batchs: 1081.3109130859375
INFO:root:Train (Epoch 243): Loss/seq after 00050 batchs: 642.0979614257812
INFO:root:Train (Epoch 243): Loss/seq after 00100 batchs: 662.410888671875
INFO:root:Train (Epoch 243): Loss/seq after 00150 batchs: 591.2815551757812
INFO:root:Train (Epoch 243): Loss/seq after 00200 batchs: 664.875244140625
INFO:root:Train (Epoch 243): Loss/seq after 00250 batchs: 702.8397216796875
INFO:root:Train (Epoch 243): Loss/seq after 00300 batchs: 711.3555297851562
INFO:root:Train (Epoch 243): Loss/seq after 00350 batchs: 673.5933227539062
INFO:root:Train (Epoch 243): Loss/seq after 00400 batchs: 668.02978515625
INFO:root:Train (Epoch 243): Loss/seq after 00450 batchs: 665.4459228515625
INFO:root:Train (Epoch 243): Loss/seq after 00500 batchs: 647.3319091796875
INFO:root:Train (Epoch 243): Loss/seq after 00550 batchs: 630.5787353515625
INFO:root:Train (Epoch 243): Loss/seq after 00600 batchs: 609.4905395507812
INFO:root:Train (Epoch 243): Loss/seq after 00650 batchs: 592.5048217773438
INFO:root:Train (Epoch 243): Loss/seq after 00700 batchs: 571.218017578125
INFO:root:Train (Epoch 243): Loss/seq after 00750 batchs: 571.0704956054688
INFO:root:Train (Epoch 243): Loss/seq after 00800 batchs: 570.7882080078125
INFO:root:Train (Epoch 243): Loss/seq after 00850 batchs: 552.5631713867188
INFO:root:Train (Epoch 243): Loss/seq after 00900 batchs: 538.0009765625
INFO:root:Train (Epoch 243): Loss/seq after 00950 batchs: 538.9801635742188
INFO:root:Train (Epoch 243): Loss/seq after 01000 batchs: 531.7069702148438
INFO:root:Train (Epoch 243): Loss/seq after 01050 batchs: 520.741455078125
INFO:root:Train (Epoch 243): Loss/seq after 01100 batchs: 510.28668212890625
INFO:root:Train (Epoch 243): Loss/seq after 01150 batchs: 497.32977294921875
INFO:root:Train (Epoch 243): Loss/seq after 01200 batchs: 501.4615478515625
INFO:root:Train (Epoch 243): Loss/seq after 01250 batchs: 499.8761901855469
INFO:root:Train (Epoch 243): Loss/seq after 01300 batchs: 490.6139831542969
INFO:root:Train (Epoch 243): Loss/seq after 01350 batchs: 482.4706115722656
INFO:root:Train (Epoch 243): Loss/seq after 01400 batchs: 486.317626953125
INFO:root:Train (Epoch 243): Loss/seq after 01450 batchs: 488.8049011230469
INFO:root:Train (Epoch 243): Loss/seq after 01500 batchs: 494.53948974609375
INFO:root:Train (Epoch 243): Loss/seq after 01550 batchs: 496.3339538574219
INFO:root:Train (Epoch 243): Loss/seq after 01600 batchs: 492.438720703125
INFO:root:Train (Epoch 243): Loss/seq after 01650 batchs: 489.766357421875
INFO:root:Train (Epoch 243): Loss/seq after 01700 batchs: 492.62017822265625
INFO:root:Train (Epoch 243): Loss/seq after 01750 batchs: 490.49920654296875
INFO:root:Train (Epoch 243): Loss/seq after 01800 batchs: 487.9664001464844
INFO:root:Train (Epoch 243): Loss/seq after 01850 batchs: 484.8669738769531
INFO:root:Train (Epoch 243): Loss/seq after 01900 batchs: 483.0758361816406
INFO:root:Train (Epoch 243): Loss/seq after 01950 batchs: 481.7972106933594
INFO:root:Train (Epoch 243): Loss/seq after 02000 batchs: 481.8548583984375
INFO:root:Train (Epoch 243): Loss/seq after 02050 batchs: 480.7416687011719
INFO:root:Train (Epoch 243): Loss/seq after 02100 batchs: 478.7377624511719
INFO:root:Train (Epoch 243): Loss/seq after 02150 batchs: 477.3251953125
INFO:root:Train (Epoch 243): Loss/seq after 02200 batchs: 475.51605224609375
INFO:root:Train (Epoch 243): Loss/seq after 02250 batchs: 474.2696533203125
INFO:root:Train (Epoch 243): Loss/seq after 02300 batchs: 471.4961853027344
INFO:root:Train (Epoch 243): Loss/seq after 02350 batchs: 468.00567626953125
INFO:root:Train (Epoch 243): Loss/seq after 02400 batchs: 469.8876647949219
INFO:root:Train (Epoch 243): Loss/seq after 02450 batchs: 465.99835205078125
INFO:root:Train (Epoch 243): Loss/seq after 02500 batchs: 458.891845703125
INFO:root:Train (Epoch 243): Loss/seq after 02550 batchs: 453.1720886230469
INFO:root:Train (Epoch 243): Loss/seq after 02600 batchs: 450.6219787597656
INFO:root:Train (Epoch 243): Loss/seq after 02650 batchs: 447.3736267089844
INFO:root:Train (Epoch 243): Loss/seq after 02700 batchs: 445.114501953125
INFO:root:Train (Epoch 243): Loss/seq after 02750 batchs: 441.2914123535156
INFO:root:Train (Epoch 243): Loss/seq after 02800 batchs: 441.0590515136719
INFO:root:Train (Epoch 243): Loss/seq after 02850 batchs: 440.5585021972656
INFO:root:Train (Epoch 243): Loss/seq after 02900 batchs: 442.1602783203125
INFO:root:Train (Epoch 243): Loss/seq after 02950 batchs: 442.1967468261719
INFO:root:Train (Epoch 243): Loss/seq after 03000 batchs: 447.3592224121094
INFO:root:Train (Epoch 243): Loss/seq after 03050 batchs: 449.2770690917969
INFO:root:Train (Epoch 243): Loss/seq after 03100 batchs: 451.61578369140625
INFO:root:Train (Epoch 243): Loss/seq after 03150 batchs: 454.4781494140625
INFO:root:Train (Epoch 243): Loss/seq after 03200 batchs: 455.2995300292969
INFO:root:Train (Epoch 243): Loss/seq after 03250 batchs: 456.85162353515625
INFO:root:Train (Epoch 243): Loss/seq after 03300 batchs: 456.35638427734375
INFO:root:Train (Epoch 243): Loss/seq after 03350 batchs: 455.0733947753906
INFO:root:Train (Epoch 243): Loss/seq after 03400 batchs: 452.1033935546875
INFO:root:Train (Epoch 243): Loss/seq after 03450 batchs: 450.8102722167969
INFO:root:Train (Epoch 243): Loss/seq after 03500 batchs: 451.4213562011719
INFO:root:Train (Epoch 243): Loss/seq after 03550 batchs: 449.2467041015625
INFO:root:Train (Epoch 243): Loss/seq after 03600 batchs: 455.8660583496094
INFO:root:Train (Epoch 243): Loss/seq after 03650 batchs: 454.2499084472656
INFO:root:Train (Epoch 243): Loss/seq after 03700 batchs: 456.3647766113281
INFO:root:Train (Epoch 243): Loss/seq after 03750 batchs: 460.4728088378906
INFO:root:Train (Epoch 243): Loss/seq after 03800 batchs: 459.1607971191406
INFO:root:Train (Epoch 243): Loss/seq after 03850 batchs: 458.1139831542969
INFO:root:Train (Epoch 243): Loss/seq after 03900 batchs: 460.73931884765625
INFO:root:Train (Epoch 243): Loss/seq after 03950 batchs: 463.7099304199219
INFO:root:Train (Epoch 243): Loss/seq after 04000 batchs: 460.555419921875
INFO:root:Train (Epoch 243): Loss/seq after 04050 batchs: 457.7992858886719
INFO:root:Train (Epoch 243): Loss/seq after 04100 batchs: 456.7789611816406
INFO:root:Train (Epoch 243): Loss/seq after 04150 batchs: 456.6460876464844
INFO:root:Train (Epoch 243): Loss/seq after 04200 batchs: 455.3119201660156
INFO:root:Train (Epoch 243): Loss/seq after 04250 batchs: 453.8505859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 243): Loss/seq after 00000 batches: 427.173095703125
INFO:root:# Valid (Epoch 243): Loss/seq after 00050 batches: 684.1245727539062
INFO:root:# Valid (Epoch 243): Loss/seq after 00100 batches: 686.8677978515625
INFO:root:# Valid (Epoch 243): Loss/seq after 00150 batches: 516.9666137695312
INFO:root:# Valid (Epoch 243): Loss/seq after 00200 batches: 472.8578796386719
INFO:root:Artifacts: Make stick videos for epoch 243
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_243_on_20220423_162432.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_243_index_1453_on_20220423_162432.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 244): Loss/seq after 00000 batchs: 1060.1749267578125
INFO:root:Train (Epoch 244): Loss/seq after 00050 batchs: 637.6174926757812
INFO:root:Train (Epoch 244): Loss/seq after 00100 batchs: 654.3572998046875
INFO:root:Train (Epoch 244): Loss/seq after 00150 batchs: 581.009521484375
INFO:root:Train (Epoch 244): Loss/seq after 00200 batchs: 658.3616943359375
INFO:root:Train (Epoch 244): Loss/seq after 00250 batchs: 705.3717041015625
INFO:root:Train (Epoch 244): Loss/seq after 00300 batchs: 712.5380249023438
INFO:root:Train (Epoch 244): Loss/seq after 00350 batchs: 674.5067749023438
INFO:root:Train (Epoch 244): Loss/seq after 00400 batchs: 670.2960815429688
INFO:root:Train (Epoch 244): Loss/seq after 00450 batchs: 667.034912109375
INFO:root:Train (Epoch 244): Loss/seq after 00500 batchs: 647.2652587890625
INFO:root:Train (Epoch 244): Loss/seq after 00550 batchs: 629.94189453125
INFO:root:Train (Epoch 244): Loss/seq after 00600 batchs: 608.9395141601562
INFO:root:Train (Epoch 244): Loss/seq after 00650 batchs: 592.1300659179688
INFO:root:Train (Epoch 244): Loss/seq after 00700 batchs: 571.83056640625
INFO:root:Train (Epoch 244): Loss/seq after 00750 batchs: 570.7923583984375
INFO:root:Train (Epoch 244): Loss/seq after 00800 batchs: 570.2239990234375
INFO:root:Train (Epoch 244): Loss/seq after 00850 batchs: 552.081787109375
INFO:root:Train (Epoch 244): Loss/seq after 00900 batchs: 536.86279296875
INFO:root:Train (Epoch 244): Loss/seq after 00950 batchs: 534.9784545898438
INFO:root:Train (Epoch 244): Loss/seq after 01000 batchs: 526.5612182617188
INFO:root:Train (Epoch 244): Loss/seq after 01050 batchs: 515.2750244140625
INFO:root:Train (Epoch 244): Loss/seq after 01100 batchs: 504.8629150390625
INFO:root:Train (Epoch 244): Loss/seq after 01150 batchs: 492.259033203125
INFO:root:Train (Epoch 244): Loss/seq after 01200 batchs: 495.7759094238281
INFO:root:Train (Epoch 244): Loss/seq after 01250 batchs: 494.1424865722656
INFO:root:Train (Epoch 244): Loss/seq after 01300 batchs: 484.1720275878906
INFO:root:Train (Epoch 244): Loss/seq after 01350 batchs: 475.7300109863281
INFO:root:Train (Epoch 244): Loss/seq after 01400 batchs: 477.90155029296875
INFO:root:Train (Epoch 244): Loss/seq after 01450 batchs: 480.6488952636719
INFO:root:Train (Epoch 244): Loss/seq after 01500 batchs: 486.4749450683594
INFO:root:Train (Epoch 244): Loss/seq after 01550 batchs: 488.37921142578125
INFO:root:Train (Epoch 244): Loss/seq after 01600 batchs: 484.9737548828125
INFO:root:Train (Epoch 244): Loss/seq after 01650 batchs: 482.7962341308594
INFO:root:Train (Epoch 244): Loss/seq after 01700 batchs: 486.114501953125
INFO:root:Train (Epoch 244): Loss/seq after 01750 batchs: 484.1578674316406
INFO:root:Train (Epoch 244): Loss/seq after 01800 batchs: 481.93450927734375
INFO:root:Train (Epoch 244): Loss/seq after 01850 batchs: 478.9667053222656
INFO:root:Train (Epoch 244): Loss/seq after 01900 batchs: 477.4621887207031
INFO:root:Train (Epoch 244): Loss/seq after 01950 batchs: 476.1925048828125
INFO:root:Train (Epoch 244): Loss/seq after 02000 batchs: 476.4217834472656
INFO:root:Train (Epoch 244): Loss/seq after 02050 batchs: 475.5950012207031
INFO:root:Train (Epoch 244): Loss/seq after 02100 batchs: 473.75787353515625
INFO:root:Train (Epoch 244): Loss/seq after 02150 batchs: 472.3432922363281
INFO:root:Train (Epoch 244): Loss/seq after 02200 batchs: 470.427490234375
INFO:root:Train (Epoch 244): Loss/seq after 02250 batchs: 469.2774353027344
INFO:root:Train (Epoch 244): Loss/seq after 02300 batchs: 467.026123046875
INFO:root:Train (Epoch 244): Loss/seq after 02350 batchs: 463.68157958984375
INFO:root:Train (Epoch 244): Loss/seq after 02400 batchs: 465.53228759765625
INFO:root:Train (Epoch 244): Loss/seq after 02450 batchs: 461.85955810546875
INFO:root:Train (Epoch 244): Loss/seq after 02500 batchs: 454.8717041015625
INFO:root:Train (Epoch 244): Loss/seq after 02550 batchs: 449.2635803222656
INFO:root:Train (Epoch 244): Loss/seq after 02600 batchs: 446.44317626953125
INFO:root:Train (Epoch 244): Loss/seq after 02650 batchs: 443.1797790527344
INFO:root:Train (Epoch 244): Loss/seq after 02700 batchs: 441.03704833984375
INFO:root:Train (Epoch 244): Loss/seq after 02750 batchs: 436.87554931640625
INFO:root:Train (Epoch 244): Loss/seq after 02800 batchs: 436.5989685058594
INFO:root:Train (Epoch 244): Loss/seq after 02850 batchs: 436.1953430175781
INFO:root:Train (Epoch 244): Loss/seq after 02900 batchs: 437.482177734375
INFO:root:Train (Epoch 244): Loss/seq after 02950 batchs: 437.6167907714844
INFO:root:Train (Epoch 244): Loss/seq after 03000 batchs: 442.9916687011719
INFO:root:Train (Epoch 244): Loss/seq after 03050 batchs: 444.9461669921875
INFO:root:Train (Epoch 244): Loss/seq after 03100 batchs: 446.8533020019531
INFO:root:Train (Epoch 244): Loss/seq after 03150 batchs: 449.15142822265625
INFO:root:Train (Epoch 244): Loss/seq after 03200 batchs: 450.2326965332031
INFO:root:Train (Epoch 244): Loss/seq after 03250 batchs: 452.6556701660156
INFO:root:Train (Epoch 244): Loss/seq after 03300 batchs: 452.4217529296875
INFO:root:Train (Epoch 244): Loss/seq after 03350 batchs: 451.05279541015625
INFO:root:Train (Epoch 244): Loss/seq after 03400 batchs: 448.25732421875
INFO:root:Train (Epoch 244): Loss/seq after 03450 batchs: 446.9017028808594
INFO:root:Train (Epoch 244): Loss/seq after 03500 batchs: 448.1325378417969
INFO:root:Train (Epoch 244): Loss/seq after 03550 batchs: 446.36346435546875
INFO:root:Train (Epoch 244): Loss/seq after 03600 batchs: 453.2403564453125
INFO:root:Train (Epoch 244): Loss/seq after 03650 batchs: 451.6844482421875
INFO:root:Train (Epoch 244): Loss/seq after 03700 batchs: 454.0986022949219
INFO:root:Train (Epoch 244): Loss/seq after 03750 batchs: 458.2218933105469
INFO:root:Train (Epoch 244): Loss/seq after 03800 batchs: 456.9328918457031
INFO:root:Train (Epoch 244): Loss/seq after 03850 batchs: 456.0101623535156
INFO:root:Train (Epoch 244): Loss/seq after 03900 batchs: 458.36602783203125
INFO:root:Train (Epoch 244): Loss/seq after 03950 batchs: 461.7476501464844
INFO:root:Train (Epoch 244): Loss/seq after 04000 batchs: 458.62774658203125
INFO:root:Train (Epoch 244): Loss/seq after 04050 batchs: 455.94384765625
INFO:root:Train (Epoch 244): Loss/seq after 04100 batchs: 454.9234619140625
INFO:root:Train (Epoch 244): Loss/seq after 04150 batchs: 454.7682189941406
INFO:root:Train (Epoch 244): Loss/seq after 04200 batchs: 453.3911437988281
INFO:root:Train (Epoch 244): Loss/seq after 04250 batchs: 451.9259033203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 244): Loss/seq after 00000 batches: 393.48583984375
INFO:root:# Valid (Epoch 244): Loss/seq after 00050 batches: 678.733154296875
INFO:root:# Valid (Epoch 244): Loss/seq after 00100 batches: 673.5606079101562
INFO:root:# Valid (Epoch 244): Loss/seq after 00150 batches: 506.0727844238281
INFO:root:# Valid (Epoch 244): Loss/seq after 00200 batches: 464.97845458984375
INFO:root:Artifacts: Make stick videos for epoch 244
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_244_on_20220423_162926.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_244_index_384_on_20220423_162926.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 245): Loss/seq after 00000 batchs: 1012.0261840820312
INFO:root:Train (Epoch 245): Loss/seq after 00050 batchs: 677.371826171875
INFO:root:Train (Epoch 245): Loss/seq after 00100 batchs: 677.66845703125
INFO:root:Train (Epoch 245): Loss/seq after 00150 batchs: 600.9172973632812
INFO:root:Train (Epoch 245): Loss/seq after 00200 batchs: 669.7671508789062
INFO:root:Train (Epoch 245): Loss/seq after 00250 batchs: 714.9425048828125
INFO:root:Train (Epoch 245): Loss/seq after 00300 batchs: 717.6965942382812
INFO:root:Train (Epoch 245): Loss/seq after 00350 batchs: 677.5546875
INFO:root:Train (Epoch 245): Loss/seq after 00400 batchs: 674.6875
INFO:root:Train (Epoch 245): Loss/seq after 00450 batchs: 670.7138061523438
INFO:root:Train (Epoch 245): Loss/seq after 00500 batchs: 648.361083984375
INFO:root:Train (Epoch 245): Loss/seq after 00550 batchs: 630.7648315429688
INFO:root:Train (Epoch 245): Loss/seq after 00600 batchs: 608.88623046875
INFO:root:Train (Epoch 245): Loss/seq after 00650 batchs: 592.9539184570312
INFO:root:Train (Epoch 245): Loss/seq after 00700 batchs: 570.4296875
INFO:root:Train (Epoch 245): Loss/seq after 00750 batchs: 568.3489990234375
INFO:root:Train (Epoch 245): Loss/seq after 00800 batchs: 568.5704956054688
INFO:root:Train (Epoch 245): Loss/seq after 00850 batchs: 550.317138671875
INFO:root:Train (Epoch 245): Loss/seq after 00900 batchs: 535.4446411132812
INFO:root:Train (Epoch 245): Loss/seq after 00950 batchs: 534.7916870117188
INFO:root:Train (Epoch 245): Loss/seq after 01000 batchs: 525.8781127929688
INFO:root:Train (Epoch 245): Loss/seq after 01050 batchs: 514.7191772460938
INFO:root:Train (Epoch 245): Loss/seq after 01100 batchs: 504.6384582519531
INFO:root:Train (Epoch 245): Loss/seq after 01150 batchs: 492.4221496582031
INFO:root:Train (Epoch 245): Loss/seq after 01200 batchs: 495.47393798828125
INFO:root:Train (Epoch 245): Loss/seq after 01250 batchs: 493.6763610839844
INFO:root:Train (Epoch 245): Loss/seq after 01300 batchs: 483.96112060546875
INFO:root:Train (Epoch 245): Loss/seq after 01350 batchs: 475.7290344238281
INFO:root:Train (Epoch 245): Loss/seq after 01400 batchs: 478.22259521484375
INFO:root:Train (Epoch 245): Loss/seq after 01450 batchs: 480.9051818847656
INFO:root:Train (Epoch 245): Loss/seq after 01500 batchs: 486.41131591796875
INFO:root:Train (Epoch 245): Loss/seq after 01550 batchs: 487.96856689453125
INFO:root:Train (Epoch 245): Loss/seq after 01600 batchs: 484.3324279785156
INFO:root:Train (Epoch 245): Loss/seq after 01650 batchs: 481.90814208984375
INFO:root:Train (Epoch 245): Loss/seq after 01700 batchs: 485.2772521972656
INFO:root:Train (Epoch 245): Loss/seq after 01750 batchs: 483.2552795410156
INFO:root:Train (Epoch 245): Loss/seq after 01800 batchs: 481.12603759765625
INFO:root:Train (Epoch 245): Loss/seq after 01850 batchs: 478.2611999511719
INFO:root:Train (Epoch 245): Loss/seq after 01900 batchs: 476.41375732421875
INFO:root:Train (Epoch 245): Loss/seq after 01950 batchs: 475.2014465332031
INFO:root:Train (Epoch 245): Loss/seq after 02000 batchs: 475.4780578613281
INFO:root:Train (Epoch 245): Loss/seq after 02050 batchs: 474.66851806640625
INFO:root:Train (Epoch 245): Loss/seq after 02100 batchs: 472.838134765625
INFO:root:Train (Epoch 245): Loss/seq after 02150 batchs: 471.4977111816406
INFO:root:Train (Epoch 245): Loss/seq after 02200 batchs: 469.677490234375
INFO:root:Train (Epoch 245): Loss/seq after 02250 batchs: 468.5008544921875
INFO:root:Train (Epoch 245): Loss/seq after 02300 batchs: 465.3231201171875
INFO:root:Train (Epoch 245): Loss/seq after 02350 batchs: 462.03662109375
INFO:root:Train (Epoch 245): Loss/seq after 02400 batchs: 463.98980712890625
INFO:root:Train (Epoch 245): Loss/seq after 02450 batchs: 460.28753662109375
INFO:root:Train (Epoch 245): Loss/seq after 02500 batchs: 453.2344055175781
INFO:root:Train (Epoch 245): Loss/seq after 02550 batchs: 447.60284423828125
INFO:root:Train (Epoch 245): Loss/seq after 02600 batchs: 444.67034912109375
INFO:root:Train (Epoch 245): Loss/seq after 02650 batchs: 441.6000061035156
INFO:root:Train (Epoch 245): Loss/seq after 02700 batchs: 439.1686706542969
INFO:root:Train (Epoch 245): Loss/seq after 02750 batchs: 435.181396484375
INFO:root:Train (Epoch 245): Loss/seq after 02800 batchs: 434.8598327636719
INFO:root:Train (Epoch 245): Loss/seq after 02850 batchs: 434.6263732910156
INFO:root:Train (Epoch 245): Loss/seq after 02900 batchs: 435.754150390625
INFO:root:Train (Epoch 245): Loss/seq after 02950 batchs: 435.83245849609375
INFO:root:Train (Epoch 245): Loss/seq after 03000 batchs: 441.04901123046875
INFO:root:Train (Epoch 245): Loss/seq after 03050 batchs: 442.91741943359375
INFO:root:Train (Epoch 245): Loss/seq after 03100 batchs: 444.7366027832031
INFO:root:Train (Epoch 245): Loss/seq after 03150 batchs: 446.68896484375
INFO:root:Train (Epoch 245): Loss/seq after 03200 batchs: 447.7287902832031
INFO:root:Train (Epoch 245): Loss/seq after 03250 batchs: 450.3133239746094
INFO:root:Train (Epoch 245): Loss/seq after 03300 batchs: 449.96978759765625
INFO:root:Train (Epoch 245): Loss/seq after 03350 batchs: 448.4646911621094
INFO:root:Train (Epoch 245): Loss/seq after 03400 batchs: 445.64678955078125
INFO:root:Train (Epoch 245): Loss/seq after 03450 batchs: 444.20013427734375
INFO:root:Train (Epoch 245): Loss/seq after 03500 batchs: 445.0971374511719
INFO:root:Train (Epoch 245): Loss/seq after 03550 batchs: 442.99285888671875
INFO:root:Train (Epoch 245): Loss/seq after 03600 batchs: 449.5429992675781
INFO:root:Train (Epoch 245): Loss/seq after 03650 batchs: 448.0223693847656
INFO:root:Train (Epoch 245): Loss/seq after 03700 batchs: 450.19732666015625
INFO:root:Train (Epoch 245): Loss/seq after 03750 batchs: 454.1612854003906
INFO:root:Train (Epoch 245): Loss/seq after 03800 batchs: 452.8841857910156
INFO:root:Train (Epoch 245): Loss/seq after 03850 batchs: 451.9457092285156
INFO:root:Train (Epoch 245): Loss/seq after 03900 batchs: 454.8414306640625
INFO:root:Train (Epoch 245): Loss/seq after 03950 batchs: 457.9097900390625
INFO:root:Train (Epoch 245): Loss/seq after 04000 batchs: 454.8653869628906
INFO:root:Train (Epoch 245): Loss/seq after 04050 batchs: 452.1308898925781
INFO:root:Train (Epoch 245): Loss/seq after 04100 batchs: 451.1180419921875
INFO:root:Train (Epoch 245): Loss/seq after 04150 batchs: 451.05816650390625
INFO:root:Train (Epoch 245): Loss/seq after 04200 batchs: 449.7151794433594
INFO:root:Train (Epoch 245): Loss/seq after 04250 batchs: 448.3744812011719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 245): Loss/seq after 00000 batches: 458.97967529296875
INFO:root:# Valid (Epoch 245): Loss/seq after 00050 batches: 669.345458984375
INFO:root:# Valid (Epoch 245): Loss/seq after 00100 batches: 701.1746215820312
INFO:root:# Valid (Epoch 245): Loss/seq after 00150 batches: 524.6637573242188
INFO:root:# Valid (Epoch 245): Loss/seq after 00200 batches: 478.6513671875
INFO:root:Artifacts: Make stick videos for epoch 245
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_245_on_20220423_163416.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_245_index_26_on_20220423_163416.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 246): Loss/seq after 00000 batchs: 953.5424194335938
INFO:root:Train (Epoch 246): Loss/seq after 00050 batchs: 651.6666259765625
INFO:root:Train (Epoch 246): Loss/seq after 00100 batchs: 665.237548828125
INFO:root:Train (Epoch 246): Loss/seq after 00150 batchs: 588.0416259765625
INFO:root:Train (Epoch 246): Loss/seq after 00200 batchs: 654.142578125
INFO:root:Train (Epoch 246): Loss/seq after 00250 batchs: 697.5657958984375
INFO:root:Train (Epoch 246): Loss/seq after 00300 batchs: 702.2842407226562
INFO:root:Train (Epoch 246): Loss/seq after 00350 batchs: 664.1245727539062
INFO:root:Train (Epoch 246): Loss/seq after 00400 batchs: 659.4605712890625
INFO:root:Train (Epoch 246): Loss/seq after 00450 batchs: 656.7860717773438
INFO:root:Train (Epoch 246): Loss/seq after 00500 batchs: 635.4302368164062
INFO:root:Train (Epoch 246): Loss/seq after 00550 batchs: 618.7191772460938
INFO:root:Train (Epoch 246): Loss/seq after 00600 batchs: 599.8829956054688
INFO:root:Train (Epoch 246): Loss/seq after 00650 batchs: 581.253662109375
INFO:root:Train (Epoch 246): Loss/seq after 00700 batchs: 561.646240234375
INFO:root:Train (Epoch 246): Loss/seq after 00750 batchs: 560.83447265625
INFO:root:Train (Epoch 246): Loss/seq after 00800 batchs: 561.8536987304688
INFO:root:Train (Epoch 246): Loss/seq after 00850 batchs: 544.3771362304688
INFO:root:Train (Epoch 246): Loss/seq after 00900 batchs: 529.9466552734375
INFO:root:Train (Epoch 246): Loss/seq after 00950 batchs: 531.12158203125
INFO:root:Train (Epoch 246): Loss/seq after 01000 batchs: 522.8429565429688
INFO:root:Train (Epoch 246): Loss/seq after 01050 batchs: 512.8419799804688
INFO:root:Train (Epoch 246): Loss/seq after 01100 batchs: 503.0962829589844
INFO:root:Train (Epoch 246): Loss/seq after 01150 batchs: 490.73773193359375
INFO:root:Train (Epoch 246): Loss/seq after 01200 batchs: 494.346435546875
INFO:root:Train (Epoch 246): Loss/seq after 01250 batchs: 493.196533203125
INFO:root:Train (Epoch 246): Loss/seq after 01300 batchs: 484.1616516113281
INFO:root:Train (Epoch 246): Loss/seq after 01350 batchs: 475.5611877441406
INFO:root:Train (Epoch 246): Loss/seq after 01400 batchs: 477.42816162109375
INFO:root:Train (Epoch 246): Loss/seq after 01450 batchs: 480.46881103515625
INFO:root:Train (Epoch 246): Loss/seq after 01500 batchs: 486.4325866699219
INFO:root:Train (Epoch 246): Loss/seq after 01550 batchs: 488.2852478027344
INFO:root:Train (Epoch 246): Loss/seq after 01600 batchs: 484.8480529785156
INFO:root:Train (Epoch 246): Loss/seq after 01650 batchs: 482.582763671875
INFO:root:Train (Epoch 246): Loss/seq after 01700 batchs: 485.8874816894531
INFO:root:Train (Epoch 246): Loss/seq after 01750 batchs: 483.8766174316406
INFO:root:Train (Epoch 246): Loss/seq after 01800 batchs: 481.7244567871094
INFO:root:Train (Epoch 246): Loss/seq after 01850 batchs: 478.625244140625
INFO:root:Train (Epoch 246): Loss/seq after 01900 batchs: 477.0668029785156
INFO:root:Train (Epoch 246): Loss/seq after 01950 batchs: 476.0749816894531
INFO:root:Train (Epoch 246): Loss/seq after 02000 batchs: 476.3558349609375
INFO:root:Train (Epoch 246): Loss/seq after 02050 batchs: 475.5462341308594
INFO:root:Train (Epoch 246): Loss/seq after 02100 batchs: 473.62738037109375
INFO:root:Train (Epoch 246): Loss/seq after 02150 batchs: 472.2533874511719
INFO:root:Train (Epoch 246): Loss/seq after 02200 batchs: 470.21405029296875
INFO:root:Train (Epoch 246): Loss/seq after 02250 batchs: 469.0030517578125
INFO:root:Train (Epoch 246): Loss/seq after 02300 batchs: 466.6324462890625
INFO:root:Train (Epoch 246): Loss/seq after 02350 batchs: 463.1453552246094
INFO:root:Train (Epoch 246): Loss/seq after 02400 batchs: 464.98797607421875
INFO:root:Train (Epoch 246): Loss/seq after 02450 batchs: 461.1784973144531
INFO:root:Train (Epoch 246): Loss/seq after 02500 batchs: 454.1129150390625
INFO:root:Train (Epoch 246): Loss/seq after 02550 batchs: 448.38262939453125
INFO:root:Train (Epoch 246): Loss/seq after 02600 batchs: 445.6222229003906
INFO:root:Train (Epoch 246): Loss/seq after 02650 batchs: 442.5857238769531
INFO:root:Train (Epoch 246): Loss/seq after 02700 batchs: 440.47650146484375
INFO:root:Train (Epoch 246): Loss/seq after 02750 batchs: 436.2261962890625
INFO:root:Train (Epoch 246): Loss/seq after 02800 batchs: 435.6861877441406
INFO:root:Train (Epoch 246): Loss/seq after 02850 batchs: 435.4312438964844
INFO:root:Train (Epoch 246): Loss/seq after 02900 batchs: 436.5300598144531
INFO:root:Train (Epoch 246): Loss/seq after 02950 batchs: 436.5302734375
INFO:root:Train (Epoch 246): Loss/seq after 03000 batchs: 441.70111083984375
INFO:root:Train (Epoch 246): Loss/seq after 03050 batchs: 443.606201171875
INFO:root:Train (Epoch 246): Loss/seq after 03100 batchs: 445.671142578125
INFO:root:Train (Epoch 246): Loss/seq after 03150 batchs: 447.2943115234375
INFO:root:Train (Epoch 246): Loss/seq after 03200 batchs: 448.2519226074219
INFO:root:Train (Epoch 246): Loss/seq after 03250 batchs: 450.8768615722656
INFO:root:Train (Epoch 246): Loss/seq after 03300 batchs: 450.5037536621094
INFO:root:Train (Epoch 246): Loss/seq after 03350 batchs: 448.6787414550781
INFO:root:Train (Epoch 246): Loss/seq after 03400 batchs: 445.9094543457031
INFO:root:Train (Epoch 246): Loss/seq after 03450 batchs: 444.6285705566406
INFO:root:Train (Epoch 246): Loss/seq after 03500 batchs: 445.42315673828125
INFO:root:Train (Epoch 246): Loss/seq after 03550 batchs: 443.2503967285156
INFO:root:Train (Epoch 246): Loss/seq after 03600 batchs: 449.6319274902344
INFO:root:Train (Epoch 246): Loss/seq after 03650 batchs: 448.1182861328125
INFO:root:Train (Epoch 246): Loss/seq after 03700 batchs: 450.4094543457031
INFO:root:Train (Epoch 246): Loss/seq after 03750 batchs: 454.46923828125
INFO:root:Train (Epoch 246): Loss/seq after 03800 batchs: 453.3365478515625
INFO:root:Train (Epoch 246): Loss/seq after 03850 batchs: 452.3753967285156
INFO:root:Train (Epoch 246): Loss/seq after 03900 batchs: 455.0892028808594
INFO:root:Train (Epoch 246): Loss/seq after 03950 batchs: 458.64697265625
INFO:root:Train (Epoch 246): Loss/seq after 04000 batchs: 455.6155090332031
INFO:root:Train (Epoch 246): Loss/seq after 04050 batchs: 452.90814208984375
INFO:root:Train (Epoch 246): Loss/seq after 04100 batchs: 451.97613525390625
INFO:root:Train (Epoch 246): Loss/seq after 04150 batchs: 451.8141784667969
INFO:root:Train (Epoch 246): Loss/seq after 04200 batchs: 450.4281921386719
INFO:root:Train (Epoch 246): Loss/seq after 04250 batchs: 449.0409851074219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 246): Loss/seq after 00000 batches: 461.6866455078125
INFO:root:# Valid (Epoch 246): Loss/seq after 00050 batches: 698.9452514648438
INFO:root:# Valid (Epoch 246): Loss/seq after 00100 batches: 684.4971923828125
INFO:root:# Valid (Epoch 246): Loss/seq after 00150 batches: 514.0201416015625
INFO:root:# Valid (Epoch 246): Loss/seq after 00200 batches: 470.4978942871094
INFO:root:Artifacts: Make stick videos for epoch 246
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_246_on_20220423_163859.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_246_index_801_on_20220423_163859.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 247): Loss/seq after 00000 batchs: 749.1255493164062
INFO:root:Train (Epoch 247): Loss/seq after 00050 batchs: 646.6162719726562
INFO:root:Train (Epoch 247): Loss/seq after 00100 batchs: 658.7632446289062
INFO:root:Train (Epoch 247): Loss/seq after 00150 batchs: 585.0498657226562
INFO:root:Train (Epoch 247): Loss/seq after 00200 batchs: 664.0993041992188
INFO:root:Train (Epoch 247): Loss/seq after 00250 batchs: 695.8192138671875
INFO:root:Train (Epoch 247): Loss/seq after 00300 batchs: 703.5045166015625
INFO:root:Train (Epoch 247): Loss/seq after 00350 batchs: 664.453369140625
INFO:root:Train (Epoch 247): Loss/seq after 00400 batchs: 658.6295166015625
INFO:root:Train (Epoch 247): Loss/seq after 00450 batchs: 656.6798706054688
INFO:root:Train (Epoch 247): Loss/seq after 00500 batchs: 634.7437744140625
INFO:root:Train (Epoch 247): Loss/seq after 00550 batchs: 618.7081909179688
INFO:root:Train (Epoch 247): Loss/seq after 00600 batchs: 596.9857788085938
INFO:root:Train (Epoch 247): Loss/seq after 00650 batchs: 582.003662109375
INFO:root:Train (Epoch 247): Loss/seq after 00700 batchs: 560.2645263671875
INFO:root:Train (Epoch 247): Loss/seq after 00750 batchs: 559.0083618164062
INFO:root:Train (Epoch 247): Loss/seq after 00800 batchs: 557.6541137695312
INFO:root:Train (Epoch 247): Loss/seq after 00850 batchs: 540.1237182617188
INFO:root:Train (Epoch 247): Loss/seq after 00900 batchs: 525.6708984375
INFO:root:Train (Epoch 247): Loss/seq after 00950 batchs: 525.5216064453125
INFO:root:Train (Epoch 247): Loss/seq after 01000 batchs: 517.6534423828125
INFO:root:Train (Epoch 247): Loss/seq after 01050 batchs: 506.68658447265625
INFO:root:Train (Epoch 247): Loss/seq after 01100 batchs: 497.0706787109375
INFO:root:Train (Epoch 247): Loss/seq after 01150 batchs: 485.2249755859375
INFO:root:Train (Epoch 247): Loss/seq after 01200 batchs: 490.0556335449219
INFO:root:Train (Epoch 247): Loss/seq after 01250 batchs: 488.7467956542969
INFO:root:Train (Epoch 247): Loss/seq after 01300 batchs: 479.0278625488281
INFO:root:Train (Epoch 247): Loss/seq after 01350 batchs: 470.64459228515625
INFO:root:Train (Epoch 247): Loss/seq after 01400 batchs: 473.200927734375
INFO:root:Train (Epoch 247): Loss/seq after 01450 batchs: 476.1803894042969
INFO:root:Train (Epoch 247): Loss/seq after 01500 batchs: 481.91058349609375
INFO:root:Train (Epoch 247): Loss/seq after 01550 batchs: 483.79132080078125
INFO:root:Train (Epoch 247): Loss/seq after 01600 batchs: 480.552490234375
INFO:root:Train (Epoch 247): Loss/seq after 01650 batchs: 478.67169189453125
INFO:root:Train (Epoch 247): Loss/seq after 01700 batchs: 482.1924133300781
INFO:root:Train (Epoch 247): Loss/seq after 01750 batchs: 480.27288818359375
INFO:root:Train (Epoch 247): Loss/seq after 01800 batchs: 478.1139831542969
INFO:root:Train (Epoch 247): Loss/seq after 01850 batchs: 475.1883239746094
INFO:root:Train (Epoch 247): Loss/seq after 01900 batchs: 473.5193786621094
INFO:root:Train (Epoch 247): Loss/seq after 01950 batchs: 472.01397705078125
INFO:root:Train (Epoch 247): Loss/seq after 02000 batchs: 472.2862243652344
INFO:root:Train (Epoch 247): Loss/seq after 02050 batchs: 471.1656799316406
INFO:root:Train (Epoch 247): Loss/seq after 02100 batchs: 469.623291015625
INFO:root:Train (Epoch 247): Loss/seq after 02150 batchs: 468.4349670410156
INFO:root:Train (Epoch 247): Loss/seq after 02200 batchs: 466.7070617675781
INFO:root:Train (Epoch 247): Loss/seq after 02250 batchs: 465.6396789550781
INFO:root:Train (Epoch 247): Loss/seq after 02300 batchs: 463.37200927734375
INFO:root:Train (Epoch 247): Loss/seq after 02350 batchs: 460.29278564453125
INFO:root:Train (Epoch 247): Loss/seq after 02400 batchs: 462.085693359375
INFO:root:Train (Epoch 247): Loss/seq after 02450 batchs: 458.30120849609375
INFO:root:Train (Epoch 247): Loss/seq after 02500 batchs: 451.28369140625
INFO:root:Train (Epoch 247): Loss/seq after 02550 batchs: 445.7914123535156
INFO:root:Train (Epoch 247): Loss/seq after 02600 batchs: 443.0023498535156
INFO:root:Train (Epoch 247): Loss/seq after 02650 batchs: 440.03857421875
INFO:root:Train (Epoch 247): Loss/seq after 02700 batchs: 437.8063049316406
INFO:root:Train (Epoch 247): Loss/seq after 02750 batchs: 433.52972412109375
INFO:root:Train (Epoch 247): Loss/seq after 02800 batchs: 432.5644836425781
INFO:root:Train (Epoch 247): Loss/seq after 02850 batchs: 432.1954650878906
INFO:root:Train (Epoch 247): Loss/seq after 02900 batchs: 433.647705078125
INFO:root:Train (Epoch 247): Loss/seq after 02950 batchs: 433.7291564941406
INFO:root:Train (Epoch 247): Loss/seq after 03000 batchs: 438.78558349609375
INFO:root:Train (Epoch 247): Loss/seq after 03050 batchs: 440.89837646484375
INFO:root:Train (Epoch 247): Loss/seq after 03100 batchs: 442.88104248046875
INFO:root:Train (Epoch 247): Loss/seq after 03150 batchs: 445.0038146972656
INFO:root:Train (Epoch 247): Loss/seq after 03200 batchs: 445.60540771484375
INFO:root:Train (Epoch 247): Loss/seq after 03250 batchs: 447.6878967285156
INFO:root:Train (Epoch 247): Loss/seq after 03300 batchs: 447.02685546875
INFO:root:Train (Epoch 247): Loss/seq after 03350 batchs: 445.43212890625
INFO:root:Train (Epoch 247): Loss/seq after 03400 batchs: 442.6566162109375
INFO:root:Train (Epoch 247): Loss/seq after 03450 batchs: 441.4057312011719
INFO:root:Train (Epoch 247): Loss/seq after 03500 batchs: 442.1060485839844
INFO:root:Train (Epoch 247): Loss/seq after 03550 batchs: 439.87017822265625
INFO:root:Train (Epoch 247): Loss/seq after 03600 batchs: 446.2101135253906
INFO:root:Train (Epoch 247): Loss/seq after 03650 batchs: 444.776123046875
INFO:root:Train (Epoch 247): Loss/seq after 03700 batchs: 446.8907775878906
INFO:root:Train (Epoch 247): Loss/seq after 03750 batchs: 450.80377197265625
INFO:root:Train (Epoch 247): Loss/seq after 03800 batchs: 449.6475524902344
INFO:root:Train (Epoch 247): Loss/seq after 03850 batchs: 448.7276306152344
INFO:root:Train (Epoch 247): Loss/seq after 03900 batchs: 451.31011962890625
INFO:root:Train (Epoch 247): Loss/seq after 03950 batchs: 454.38555908203125
INFO:root:Train (Epoch 247): Loss/seq after 04000 batchs: 451.33978271484375
INFO:root:Train (Epoch 247): Loss/seq after 04050 batchs: 448.647705078125
INFO:root:Train (Epoch 247): Loss/seq after 04100 batchs: 447.7268981933594
INFO:root:Train (Epoch 247): Loss/seq after 04150 batchs: 447.6174621582031
INFO:root:Train (Epoch 247): Loss/seq after 04200 batchs: 446.2657165527344
INFO:root:Train (Epoch 247): Loss/seq after 04250 batchs: 444.8522033691406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 247): Loss/seq after 00000 batches: 429.00115966796875
INFO:root:# Valid (Epoch 247): Loss/seq after 00050 batches: 697.2916870117188
INFO:root:# Valid (Epoch 247): Loss/seq after 00100 batches: 694.099365234375
INFO:root:# Valid (Epoch 247): Loss/seq after 00150 batches: 520.093017578125
INFO:root:# Valid (Epoch 247): Loss/seq after 00200 batches: 476.8039245605469
INFO:root:Artifacts: Make stick videos for epoch 247
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_247_on_20220423_164345.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_247_index_1552_on_20220423_164345.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 248): Loss/seq after 00000 batchs: 945.5164794921875
INFO:root:Train (Epoch 248): Loss/seq after 00050 batchs: 611.8446655273438
INFO:root:Train (Epoch 248): Loss/seq after 00100 batchs: 635.6976928710938
INFO:root:Train (Epoch 248): Loss/seq after 00150 batchs: 569.8346557617188
INFO:root:Train (Epoch 248): Loss/seq after 00200 batchs: 642.9463500976562
INFO:root:Train (Epoch 248): Loss/seq after 00250 batchs: 686.5429077148438
INFO:root:Train (Epoch 248): Loss/seq after 00300 batchs: 693.5952758789062
INFO:root:Train (Epoch 248): Loss/seq after 00350 batchs: 655.6607055664062
INFO:root:Train (Epoch 248): Loss/seq after 00400 batchs: 649.1880493164062
INFO:root:Train (Epoch 248): Loss/seq after 00450 batchs: 647.1771850585938
INFO:root:Train (Epoch 248): Loss/seq after 00500 batchs: 626.6500854492188
INFO:root:Train (Epoch 248): Loss/seq after 00550 batchs: 610.3872680664062
INFO:root:Train (Epoch 248): Loss/seq after 00600 batchs: 590.287109375
INFO:root:Train (Epoch 248): Loss/seq after 00650 batchs: 574.4421997070312
INFO:root:Train (Epoch 248): Loss/seq after 00700 batchs: 554.0520629882812
INFO:root:Train (Epoch 248): Loss/seq after 00750 batchs: 553.7349853515625
INFO:root:Train (Epoch 248): Loss/seq after 00800 batchs: 554.1014404296875
INFO:root:Train (Epoch 248): Loss/seq after 00850 batchs: 537.2310791015625
INFO:root:Train (Epoch 248): Loss/seq after 00900 batchs: 523.20068359375
INFO:root:Train (Epoch 248): Loss/seq after 00950 batchs: 522.0677490234375
INFO:root:Train (Epoch 248): Loss/seq after 01000 batchs: 514.5349731445312
INFO:root:Train (Epoch 248): Loss/seq after 01050 batchs: 505.58013916015625
INFO:root:Train (Epoch 248): Loss/seq after 01100 batchs: 495.7604064941406
INFO:root:Train (Epoch 248): Loss/seq after 01150 batchs: 484.2425231933594
INFO:root:Train (Epoch 248): Loss/seq after 01200 batchs: 487.59576416015625
INFO:root:Train (Epoch 248): Loss/seq after 01250 batchs: 486.5034484863281
INFO:root:Train (Epoch 248): Loss/seq after 01300 batchs: 477.51422119140625
INFO:root:Train (Epoch 248): Loss/seq after 01350 batchs: 469.2598876953125
INFO:root:Train (Epoch 248): Loss/seq after 01400 batchs: 473.47943115234375
INFO:root:Train (Epoch 248): Loss/seq after 01450 batchs: 476.58648681640625
INFO:root:Train (Epoch 248): Loss/seq after 01500 batchs: 482.7493896484375
INFO:root:Train (Epoch 248): Loss/seq after 01550 batchs: 484.3197021484375
INFO:root:Train (Epoch 248): Loss/seq after 01600 batchs: 480.73077392578125
INFO:root:Train (Epoch 248): Loss/seq after 01650 batchs: 478.513916015625
INFO:root:Train (Epoch 248): Loss/seq after 01700 batchs: 482.02679443359375
INFO:root:Train (Epoch 248): Loss/seq after 01750 batchs: 480.1042175292969
INFO:root:Train (Epoch 248): Loss/seq after 01800 batchs: 477.77264404296875
INFO:root:Train (Epoch 248): Loss/seq after 01850 batchs: 474.7156677246094
INFO:root:Train (Epoch 248): Loss/seq after 01900 batchs: 472.87896728515625
INFO:root:Train (Epoch 248): Loss/seq after 01950 batchs: 471.7208557128906
INFO:root:Train (Epoch 248): Loss/seq after 02000 batchs: 472.1299743652344
INFO:root:Train (Epoch 248): Loss/seq after 02050 batchs: 471.03118896484375
INFO:root:Train (Epoch 248): Loss/seq after 02100 batchs: 469.1834716796875
INFO:root:Train (Epoch 248): Loss/seq after 02150 batchs: 467.9414367675781
INFO:root:Train (Epoch 248): Loss/seq after 02200 batchs: 466.1679382324219
INFO:root:Train (Epoch 248): Loss/seq after 02250 batchs: 465.1042785644531
INFO:root:Train (Epoch 248): Loss/seq after 02300 batchs: 462.1700134277344
INFO:root:Train (Epoch 248): Loss/seq after 02350 batchs: 458.8128967285156
INFO:root:Train (Epoch 248): Loss/seq after 02400 batchs: 460.4730224609375
INFO:root:Train (Epoch 248): Loss/seq after 02450 batchs: 456.72332763671875
INFO:root:Train (Epoch 248): Loss/seq after 02500 batchs: 449.7401123046875
INFO:root:Train (Epoch 248): Loss/seq after 02550 batchs: 444.2084045410156
INFO:root:Train (Epoch 248): Loss/seq after 02600 batchs: 441.3268737792969
INFO:root:Train (Epoch 248): Loss/seq after 02650 batchs: 438.4262390136719
INFO:root:Train (Epoch 248): Loss/seq after 02700 batchs: 435.99993896484375
INFO:root:Train (Epoch 248): Loss/seq after 02750 batchs: 432.1103820800781
INFO:root:Train (Epoch 248): Loss/seq after 02800 batchs: 431.4884033203125
INFO:root:Train (Epoch 248): Loss/seq after 02850 batchs: 431.20361328125
INFO:root:Train (Epoch 248): Loss/seq after 02900 batchs: 432.4638366699219
INFO:root:Train (Epoch 248): Loss/seq after 02950 batchs: 432.5727233886719
INFO:root:Train (Epoch 248): Loss/seq after 03000 batchs: 437.6277770996094
INFO:root:Train (Epoch 248): Loss/seq after 03050 batchs: 439.5286560058594
INFO:root:Train (Epoch 248): Loss/seq after 03100 batchs: 441.54022216796875
INFO:root:Train (Epoch 248): Loss/seq after 03150 batchs: 443.376708984375
INFO:root:Train (Epoch 248): Loss/seq after 03200 batchs: 444.74310302734375
INFO:root:Train (Epoch 248): Loss/seq after 03250 batchs: 447.2523498535156
INFO:root:Train (Epoch 248): Loss/seq after 03300 batchs: 446.52386474609375
INFO:root:Train (Epoch 248): Loss/seq after 03350 batchs: 444.76165771484375
INFO:root:Train (Epoch 248): Loss/seq after 03400 batchs: 442.02734375
INFO:root:Train (Epoch 248): Loss/seq after 03450 batchs: 440.6371154785156
INFO:root:Train (Epoch 248): Loss/seq after 03500 batchs: 441.1357421875
INFO:root:Train (Epoch 248): Loss/seq after 03550 batchs: 438.9792785644531
INFO:root:Train (Epoch 248): Loss/seq after 03600 batchs: 445.216064453125
INFO:root:Train (Epoch 248): Loss/seq after 03650 batchs: 443.6866455078125
INFO:root:Train (Epoch 248): Loss/seq after 03700 batchs: 445.604248046875
INFO:root:Train (Epoch 248): Loss/seq after 03750 batchs: 449.5744934082031
INFO:root:Train (Epoch 248): Loss/seq after 03800 batchs: 448.4115295410156
INFO:root:Train (Epoch 248): Loss/seq after 03850 batchs: 447.6121826171875
INFO:root:Train (Epoch 248): Loss/seq after 03900 batchs: 449.9627685546875
INFO:root:Train (Epoch 248): Loss/seq after 03950 batchs: 453.3133544921875
INFO:root:Train (Epoch 248): Loss/seq after 04000 batchs: 450.273193359375
INFO:root:Train (Epoch 248): Loss/seq after 04050 batchs: 447.6256408691406
INFO:root:Train (Epoch 248): Loss/seq after 04100 batchs: 446.67559814453125
INFO:root:Train (Epoch 248): Loss/seq after 04150 batchs: 446.6160583496094
INFO:root:Train (Epoch 248): Loss/seq after 04200 batchs: 445.2748107910156
INFO:root:Train (Epoch 248): Loss/seq after 04250 batchs: 443.857666015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 248): Loss/seq after 00000 batches: 427.0804748535156
INFO:root:# Valid (Epoch 248): Loss/seq after 00050 batches: 673.1554565429688
INFO:root:# Valid (Epoch 248): Loss/seq after 00100 batches: 677.0292358398438
INFO:root:# Valid (Epoch 248): Loss/seq after 00150 batches: 508.1421203613281
INFO:root:# Valid (Epoch 248): Loss/seq after 00200 batches: 466.6925354003906
INFO:root:Artifacts: Make stick videos for epoch 248
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_248_on_20220423_164828.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_248_index_689_on_20220423_164828.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 249): Loss/seq after 00000 batchs: 825.0296020507812
INFO:root:Train (Epoch 249): Loss/seq after 00050 batchs: 593.2407836914062
INFO:root:Train (Epoch 249): Loss/seq after 00100 batchs: 609.6119995117188
INFO:root:Train (Epoch 249): Loss/seq after 00150 batchs: 549.8810424804688
INFO:root:Train (Epoch 249): Loss/seq after 00200 batchs: 628.740478515625
INFO:root:Train (Epoch 249): Loss/seq after 00250 batchs: 666.3167724609375
INFO:root:Train (Epoch 249): Loss/seq after 00300 batchs: 676.1465454101562
INFO:root:Train (Epoch 249): Loss/seq after 00350 batchs: 642.2716064453125
INFO:root:Train (Epoch 249): Loss/seq after 00400 batchs: 639.9874267578125
INFO:root:Train (Epoch 249): Loss/seq after 00450 batchs: 640.3494873046875
INFO:root:Train (Epoch 249): Loss/seq after 00500 batchs: 619.1090698242188
INFO:root:Train (Epoch 249): Loss/seq after 00550 batchs: 603.4867553710938
INFO:root:Train (Epoch 249): Loss/seq after 00600 batchs: 584.1489868164062
INFO:root:Train (Epoch 249): Loss/seq after 00650 batchs: 566.8897094726562
INFO:root:Train (Epoch 249): Loss/seq after 00700 batchs: 546.4649047851562
INFO:root:Train (Epoch 249): Loss/seq after 00750 batchs: 546.431396484375
INFO:root:Train (Epoch 249): Loss/seq after 00800 batchs: 547.471923828125
INFO:root:Train (Epoch 249): Loss/seq after 00850 batchs: 530.949951171875
INFO:root:Train (Epoch 249): Loss/seq after 00900 batchs: 516.77197265625
INFO:root:Train (Epoch 249): Loss/seq after 00950 batchs: 517.885009765625
INFO:root:Train (Epoch 249): Loss/seq after 01000 batchs: 509.3609619140625
INFO:root:Train (Epoch 249): Loss/seq after 01050 batchs: 499.6349792480469
INFO:root:Train (Epoch 249): Loss/seq after 01100 batchs: 490.4275207519531
INFO:root:Train (Epoch 249): Loss/seq after 01150 batchs: 478.4562072753906
INFO:root:Train (Epoch 249): Loss/seq after 01200 batchs: 483.126708984375
INFO:root:Train (Epoch 249): Loss/seq after 01250 batchs: 482.1070251464844
INFO:root:Train (Epoch 249): Loss/seq after 01300 batchs: 472.8248291015625
INFO:root:Train (Epoch 249): Loss/seq after 01350 batchs: 464.5223693847656
INFO:root:Train (Epoch 249): Loss/seq after 01400 batchs: 465.66607666015625
INFO:root:Train (Epoch 249): Loss/seq after 01450 batchs: 468.7023620605469
INFO:root:Train (Epoch 249): Loss/seq after 01500 batchs: 475.1663513183594
INFO:root:Train (Epoch 249): Loss/seq after 01550 batchs: 476.0899658203125
INFO:root:Train (Epoch 249): Loss/seq after 01600 batchs: 472.6478271484375
INFO:root:Train (Epoch 249): Loss/seq after 01650 batchs: 470.36126708984375
INFO:root:Train (Epoch 249): Loss/seq after 01700 batchs: 473.880615234375
INFO:root:Train (Epoch 249): Loss/seq after 01750 batchs: 472.1581115722656
INFO:root:Train (Epoch 249): Loss/seq after 01800 batchs: 469.90447998046875
INFO:root:Train (Epoch 249): Loss/seq after 01850 batchs: 467.0438232421875
INFO:root:Train (Epoch 249): Loss/seq after 01900 batchs: 465.5859069824219
INFO:root:Train (Epoch 249): Loss/seq after 01950 batchs: 464.30255126953125
INFO:root:Train (Epoch 249): Loss/seq after 02000 batchs: 464.72833251953125
INFO:root:Train (Epoch 249): Loss/seq after 02050 batchs: 464.006591796875
INFO:root:Train (Epoch 249): Loss/seq after 02100 batchs: 462.33514404296875
INFO:root:Train (Epoch 249): Loss/seq after 02150 batchs: 461.2335510253906
INFO:root:Train (Epoch 249): Loss/seq after 02200 batchs: 459.50335693359375
INFO:root:Train (Epoch 249): Loss/seq after 02250 batchs: 458.4585266113281
INFO:root:Train (Epoch 249): Loss/seq after 02300 batchs: 455.8746032714844
INFO:root:Train (Epoch 249): Loss/seq after 02350 batchs: 452.57843017578125
INFO:root:Train (Epoch 249): Loss/seq after 02400 batchs: 454.3409423828125
INFO:root:Train (Epoch 249): Loss/seq after 02450 batchs: 450.64208984375
INFO:root:Train (Epoch 249): Loss/seq after 02500 batchs: 443.7366027832031
INFO:root:Train (Epoch 249): Loss/seq after 02550 batchs: 438.30010986328125
INFO:root:Train (Epoch 249): Loss/seq after 02600 batchs: 435.426513671875
INFO:root:Train (Epoch 249): Loss/seq after 02650 batchs: 432.4355773925781
INFO:root:Train (Epoch 249): Loss/seq after 02700 batchs: 430.17791748046875
INFO:root:Train (Epoch 249): Loss/seq after 02750 batchs: 426.1522216796875
INFO:root:Train (Epoch 249): Loss/seq after 02800 batchs: 425.17242431640625
INFO:root:Train (Epoch 249): Loss/seq after 02850 batchs: 424.8648681640625
INFO:root:Train (Epoch 249): Loss/seq after 02900 batchs: 426.1407470703125
INFO:root:Train (Epoch 249): Loss/seq after 02950 batchs: 426.3563232421875
INFO:root:Train (Epoch 249): Loss/seq after 03000 batchs: 431.6114807128906
INFO:root:Train (Epoch 249): Loss/seq after 03050 batchs: 433.45391845703125
INFO:root:Train (Epoch 249): Loss/seq after 03100 batchs: 435.4963684082031
INFO:root:Train (Epoch 249): Loss/seq after 03150 batchs: 437.1329040527344
INFO:root:Train (Epoch 249): Loss/seq after 03200 batchs: 438.5706787109375
INFO:root:Train (Epoch 249): Loss/seq after 03250 batchs: 440.76568603515625
INFO:root:Train (Epoch 249): Loss/seq after 03300 batchs: 440.08563232421875
INFO:root:Train (Epoch 249): Loss/seq after 03350 batchs: 438.490234375
INFO:root:Train (Epoch 249): Loss/seq after 03400 batchs: 435.8320617675781
INFO:root:Train (Epoch 249): Loss/seq after 03450 batchs: 434.5736999511719
INFO:root:Train (Epoch 249): Loss/seq after 03500 batchs: 435.58984375
INFO:root:Train (Epoch 249): Loss/seq after 03550 batchs: 433.67041015625
INFO:root:Train (Epoch 249): Loss/seq after 03600 batchs: 439.7009582519531
INFO:root:Train (Epoch 249): Loss/seq after 03650 batchs: 438.35455322265625
INFO:root:Train (Epoch 249): Loss/seq after 03700 batchs: 440.7093505859375
INFO:root:Train (Epoch 249): Loss/seq after 03750 batchs: 444.8800354003906
INFO:root:Train (Epoch 249): Loss/seq after 03800 batchs: 443.8289794921875
INFO:root:Train (Epoch 249): Loss/seq after 03850 batchs: 443.04718017578125
INFO:root:Train (Epoch 249): Loss/seq after 03900 batchs: 445.5899963378906
INFO:root:Train (Epoch 249): Loss/seq after 03950 batchs: 448.5160827636719
INFO:root:Train (Epoch 249): Loss/seq after 04000 batchs: 445.5814208984375
INFO:root:Train (Epoch 249): Loss/seq after 04050 batchs: 442.9189147949219
INFO:root:Train (Epoch 249): Loss/seq after 04100 batchs: 441.98626708984375
INFO:root:Train (Epoch 249): Loss/seq after 04150 batchs: 442.0129089355469
INFO:root:Train (Epoch 249): Loss/seq after 04200 batchs: 440.72222900390625
INFO:root:Train (Epoch 249): Loss/seq after 04250 batchs: 439.4768371582031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 249): Loss/seq after 00000 batches: 416.9139404296875
INFO:root:# Valid (Epoch 249): Loss/seq after 00050 batches: 685.0855712890625
INFO:root:# Valid (Epoch 249): Loss/seq after 00100 batches: 698.6732788085938
INFO:root:# Valid (Epoch 249): Loss/seq after 00150 batches: 521.9324951171875
INFO:root:# Valid (Epoch 249): Loss/seq after 00200 batches: 476.45587158203125
INFO:root:Artifacts: Make stick videos for epoch 249
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_249_on_20220423_165314.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_249_index_852_on_20220423_165314.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 250): Loss/seq after 00000 batchs: 1005.6538696289062
INFO:root:Train (Epoch 250): Loss/seq after 00050 batchs: 610.7600708007812
INFO:root:Train (Epoch 250): Loss/seq after 00100 batchs: 618.0166015625
INFO:root:Train (Epoch 250): Loss/seq after 00150 batchs: 557.9774169921875
INFO:root:Train (Epoch 250): Loss/seq after 00200 batchs: 640.8847045898438
INFO:root:Train (Epoch 250): Loss/seq after 00250 batchs: 672.0621948242188
INFO:root:Train (Epoch 250): Loss/seq after 00300 batchs: 684.30517578125
INFO:root:Train (Epoch 250): Loss/seq after 00350 batchs: 648.7453002929688
INFO:root:Train (Epoch 250): Loss/seq after 00400 batchs: 647.9586791992188
INFO:root:Train (Epoch 250): Loss/seq after 00450 batchs: 647.1502685546875
INFO:root:Train (Epoch 250): Loss/seq after 00500 batchs: 629.8541870117188
INFO:root:Train (Epoch 250): Loss/seq after 00550 batchs: 614.18896484375
INFO:root:Train (Epoch 250): Loss/seq after 00600 batchs: 596.3643798828125
INFO:root:Train (Epoch 250): Loss/seq after 00650 batchs: 580.6116943359375
INFO:root:Train (Epoch 250): Loss/seq after 00700 batchs: 561.5953979492188
INFO:root:Train (Epoch 250): Loss/seq after 00750 batchs: 559.6295776367188
INFO:root:Train (Epoch 250): Loss/seq after 00800 batchs: 559.1318359375
INFO:root:Train (Epoch 250): Loss/seq after 00850 batchs: 541.7728881835938
INFO:root:Train (Epoch 250): Loss/seq after 00900 batchs: 526.5695190429688
INFO:root:Train (Epoch 250): Loss/seq after 00950 batchs: 526.408447265625
INFO:root:Train (Epoch 250): Loss/seq after 01000 batchs: 519.0806884765625
INFO:root:Train (Epoch 250): Loss/seq after 01050 batchs: 507.9955749511719
INFO:root:Train (Epoch 250): Loss/seq after 01100 batchs: 497.7691955566406
INFO:root:Train (Epoch 250): Loss/seq after 01150 batchs: 486.02178955078125
INFO:root:Train (Epoch 250): Loss/seq after 01200 batchs: 489.1201477050781
INFO:root:Train (Epoch 250): Loss/seq after 01250 batchs: 487.86956787109375
INFO:root:Train (Epoch 250): Loss/seq after 01300 batchs: 478.076416015625
INFO:root:Train (Epoch 250): Loss/seq after 01350 batchs: 469.79290771484375
INFO:root:Train (Epoch 250): Loss/seq after 01400 batchs: 471.6535339355469
INFO:root:Train (Epoch 250): Loss/seq after 01450 batchs: 474.0876159667969
INFO:root:Train (Epoch 250): Loss/seq after 01500 batchs: 479.94183349609375
INFO:root:Train (Epoch 250): Loss/seq after 01550 batchs: 481.3689270019531
INFO:root:Train (Epoch 250): Loss/seq after 01600 batchs: 477.8465881347656
INFO:root:Train (Epoch 250): Loss/seq after 01650 batchs: 475.4059143066406
INFO:root:Train (Epoch 250): Loss/seq after 01700 batchs: 478.9586181640625
INFO:root:Train (Epoch 250): Loss/seq after 01750 batchs: 477.1411437988281
INFO:root:Train (Epoch 250): Loss/seq after 01800 batchs: 474.88922119140625
INFO:root:Train (Epoch 250): Loss/seq after 01850 batchs: 471.9658508300781
INFO:root:Train (Epoch 250): Loss/seq after 01900 batchs: 470.2314147949219
INFO:root:Train (Epoch 250): Loss/seq after 01950 batchs: 469.0892639160156
INFO:root:Train (Epoch 250): Loss/seq after 02000 batchs: 469.34368896484375
INFO:root:Train (Epoch 250): Loss/seq after 02050 batchs: 468.2626037597656
INFO:root:Train (Epoch 250): Loss/seq after 02100 batchs: 466.5032043457031
INFO:root:Train (Epoch 250): Loss/seq after 02150 batchs: 465.1794738769531
INFO:root:Train (Epoch 250): Loss/seq after 02200 batchs: 463.4175109863281
INFO:root:Train (Epoch 250): Loss/seq after 02250 batchs: 462.2210693359375
INFO:root:Train (Epoch 250): Loss/seq after 02300 batchs: 460.7381896972656
INFO:root:Train (Epoch 250): Loss/seq after 02350 batchs: 457.4761657714844
INFO:root:Train (Epoch 250): Loss/seq after 02400 batchs: 459.38885498046875
INFO:root:Train (Epoch 250): Loss/seq after 02450 batchs: 455.6167297363281
INFO:root:Train (Epoch 250): Loss/seq after 02500 batchs: 448.64544677734375
INFO:root:Train (Epoch 250): Loss/seq after 02550 batchs: 443.0693664550781
INFO:root:Train (Epoch 250): Loss/seq after 02600 batchs: 439.9923400878906
INFO:root:Train (Epoch 250): Loss/seq after 02650 batchs: 436.9860534667969
INFO:root:Train (Epoch 250): Loss/seq after 02700 batchs: 434.6071472167969
INFO:root:Train (Epoch 250): Loss/seq after 02750 batchs: 430.5166015625
INFO:root:Train (Epoch 250): Loss/seq after 02800 batchs: 429.7881164550781
INFO:root:Train (Epoch 250): Loss/seq after 02850 batchs: 429.39898681640625
INFO:root:Train (Epoch 250): Loss/seq after 02900 batchs: 430.5746154785156
INFO:root:Train (Epoch 250): Loss/seq after 02950 batchs: 430.667236328125
INFO:root:Train (Epoch 250): Loss/seq after 03000 batchs: 435.74029541015625
INFO:root:Train (Epoch 250): Loss/seq after 03050 batchs: 437.5722961425781
INFO:root:Train (Epoch 250): Loss/seq after 03100 batchs: 439.6351318359375
INFO:root:Train (Epoch 250): Loss/seq after 03150 batchs: 441.7417907714844
INFO:root:Train (Epoch 250): Loss/seq after 03200 batchs: 442.20892333984375
INFO:root:Train (Epoch 250): Loss/seq after 03250 batchs: 444.36590576171875
INFO:root:Train (Epoch 250): Loss/seq after 03300 batchs: 443.5166320800781
INFO:root:Train (Epoch 250): Loss/seq after 03350 batchs: 442.1531677246094
INFO:root:Train (Epoch 250): Loss/seq after 03400 batchs: 439.3141784667969
INFO:root:Train (Epoch 250): Loss/seq after 03450 batchs: 438.1954040527344
INFO:root:Train (Epoch 250): Loss/seq after 03500 batchs: 439.074951171875
INFO:root:Train (Epoch 250): Loss/seq after 03550 batchs: 436.9023132324219
INFO:root:Train (Epoch 250): Loss/seq after 03600 batchs: 442.89105224609375
INFO:root:Train (Epoch 250): Loss/seq after 03650 batchs: 441.43780517578125
INFO:root:Train (Epoch 250): Loss/seq after 03700 batchs: 443.5086975097656
INFO:root:Train (Epoch 250): Loss/seq after 03750 batchs: 447.43646240234375
INFO:root:Train (Epoch 250): Loss/seq after 03800 batchs: 446.3114929199219
INFO:root:Train (Epoch 250): Loss/seq after 03850 batchs: 445.4454650878906
INFO:root:Train (Epoch 250): Loss/seq after 03900 batchs: 448.03680419921875
INFO:root:Train (Epoch 250): Loss/seq after 03950 batchs: 451.0279541015625
INFO:root:Train (Epoch 250): Loss/seq after 04000 batchs: 448.0111999511719
INFO:root:Train (Epoch 250): Loss/seq after 04050 batchs: 445.3419189453125
INFO:root:Train (Epoch 250): Loss/seq after 04100 batchs: 444.4337463378906
INFO:root:Train (Epoch 250): Loss/seq after 04150 batchs: 444.3388671875
INFO:root:Train (Epoch 250): Loss/seq after 04200 batchs: 442.969482421875
INFO:root:Train (Epoch 250): Loss/seq after 04250 batchs: 441.6906433105469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 250): Loss/seq after 00000 batches: 424.3882141113281
INFO:root:# Valid (Epoch 250): Loss/seq after 00050 batches: 710.8646240234375
INFO:root:# Valid (Epoch 250): Loss/seq after 00100 batches: 721.1829833984375
INFO:root:# Valid (Epoch 250): Loss/seq after 00150 batches: 539.3434448242188
INFO:root:# Valid (Epoch 250): Loss/seq after 00200 batches: 491.39666748046875
INFO:root:Artifacts: Make stick videos for epoch 250
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_250_on_20220423_165800.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_250_index_954_on_20220423_165800.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 251): Loss/seq after 00000 batchs: 955.4104614257812
INFO:root:Train (Epoch 251): Loss/seq after 00050 batchs: 616.6630859375
INFO:root:Train (Epoch 251): Loss/seq after 00100 batchs: 628.4573364257812
INFO:root:Train (Epoch 251): Loss/seq after 00150 batchs: 563.9398193359375
INFO:root:Train (Epoch 251): Loss/seq after 00200 batchs: 642.9375
INFO:root:Train (Epoch 251): Loss/seq after 00250 batchs: 692.708251953125
INFO:root:Train (Epoch 251): Loss/seq after 00300 batchs: 698.6591186523438
INFO:root:Train (Epoch 251): Loss/seq after 00350 batchs: 661.5332641601562
INFO:root:Train (Epoch 251): Loss/seq after 00400 batchs: 655.3228149414062
INFO:root:Train (Epoch 251): Loss/seq after 00450 batchs: 653.5545654296875
INFO:root:Train (Epoch 251): Loss/seq after 00500 batchs: 634.2179565429688
INFO:root:Train (Epoch 251): Loss/seq after 00550 batchs: 617.6033935546875
INFO:root:Train (Epoch 251): Loss/seq after 00600 batchs: 597.9971923828125
INFO:root:Train (Epoch 251): Loss/seq after 00650 batchs: 579.4036865234375
INFO:root:Train (Epoch 251): Loss/seq after 00700 batchs: 558.4095458984375
INFO:root:Train (Epoch 251): Loss/seq after 00750 batchs: 557.0746459960938
INFO:root:Train (Epoch 251): Loss/seq after 00800 batchs: 558.3309326171875
INFO:root:Train (Epoch 251): Loss/seq after 00850 batchs: 541.3821411132812
INFO:root:Train (Epoch 251): Loss/seq after 00900 batchs: 527.7049560546875
INFO:root:Train (Epoch 251): Loss/seq after 00950 batchs: 526.8157348632812
INFO:root:Train (Epoch 251): Loss/seq after 01000 batchs: 518.8748168945312
INFO:root:Train (Epoch 251): Loss/seq after 01050 batchs: 508.8604736328125
INFO:root:Train (Epoch 251): Loss/seq after 01100 batchs: 498.74957275390625
INFO:root:Train (Epoch 251): Loss/seq after 01150 batchs: 486.2332458496094
INFO:root:Train (Epoch 251): Loss/seq after 01200 batchs: 490.5058898925781
INFO:root:Train (Epoch 251): Loss/seq after 01250 batchs: 488.84771728515625
INFO:root:Train (Epoch 251): Loss/seq after 01300 batchs: 479.1447448730469
INFO:root:Train (Epoch 251): Loss/seq after 01350 batchs: 470.6646728515625
INFO:root:Train (Epoch 251): Loss/seq after 01400 batchs: 473.59320068359375
INFO:root:Train (Epoch 251): Loss/seq after 01450 batchs: 476.55657958984375
INFO:root:Train (Epoch 251): Loss/seq after 01500 batchs: 482.76116943359375
INFO:root:Train (Epoch 251): Loss/seq after 01550 batchs: 484.7019958496094
INFO:root:Train (Epoch 251): Loss/seq after 01600 batchs: 480.9709777832031
INFO:root:Train (Epoch 251): Loss/seq after 01650 batchs: 478.533935546875
INFO:root:Train (Epoch 251): Loss/seq after 01700 batchs: 481.6731872558594
INFO:root:Train (Epoch 251): Loss/seq after 01750 batchs: 479.7987365722656
INFO:root:Train (Epoch 251): Loss/seq after 01800 batchs: 477.5217590332031
INFO:root:Train (Epoch 251): Loss/seq after 01850 batchs: 474.43145751953125
INFO:root:Train (Epoch 251): Loss/seq after 01900 batchs: 472.4693603515625
INFO:root:Train (Epoch 251): Loss/seq after 01950 batchs: 470.9453125
INFO:root:Train (Epoch 251): Loss/seq after 02000 batchs: 471.21551513671875
INFO:root:Train (Epoch 251): Loss/seq after 02050 batchs: 469.8824462890625
INFO:root:Train (Epoch 251): Loss/seq after 02100 batchs: 468.137939453125
INFO:root:Train (Epoch 251): Loss/seq after 02150 batchs: 466.6983642578125
INFO:root:Train (Epoch 251): Loss/seq after 02200 batchs: 464.861328125
INFO:root:Train (Epoch 251): Loss/seq after 02250 batchs: 463.8341369628906
INFO:root:Train (Epoch 251): Loss/seq after 02300 batchs: 461.1958312988281
INFO:root:Train (Epoch 251): Loss/seq after 02350 batchs: 457.90924072265625
INFO:root:Train (Epoch 251): Loss/seq after 02400 batchs: 459.2952880859375
INFO:root:Train (Epoch 251): Loss/seq after 02450 batchs: 455.55267333984375
INFO:root:Train (Epoch 251): Loss/seq after 02500 batchs: 448.5494689941406
INFO:root:Train (Epoch 251): Loss/seq after 02550 batchs: 442.7724914550781
INFO:root:Train (Epoch 251): Loss/seq after 02600 batchs: 439.6700134277344
INFO:root:Train (Epoch 251): Loss/seq after 02650 batchs: 436.5086364746094
INFO:root:Train (Epoch 251): Loss/seq after 02700 batchs: 434.3526611328125
INFO:root:Train (Epoch 251): Loss/seq after 02750 batchs: 430.6177978515625
INFO:root:Train (Epoch 251): Loss/seq after 02800 batchs: 430.6197814941406
INFO:root:Train (Epoch 251): Loss/seq after 02850 batchs: 430.19580078125
INFO:root:Train (Epoch 251): Loss/seq after 02900 batchs: 431.2174072265625
INFO:root:Train (Epoch 251): Loss/seq after 02950 batchs: 431.33282470703125
INFO:root:Train (Epoch 251): Loss/seq after 03000 batchs: 436.4925537109375
INFO:root:Train (Epoch 251): Loss/seq after 03050 batchs: 438.31561279296875
INFO:root:Train (Epoch 251): Loss/seq after 03100 batchs: 440.61871337890625
INFO:root:Train (Epoch 251): Loss/seq after 03150 batchs: 441.9737548828125
INFO:root:Train (Epoch 251): Loss/seq after 03200 batchs: 442.66748046875
INFO:root:Train (Epoch 251): Loss/seq after 03250 batchs: 444.56817626953125
INFO:root:Train (Epoch 251): Loss/seq after 03300 batchs: 444.24835205078125
INFO:root:Train (Epoch 251): Loss/seq after 03350 batchs: 443.4879455566406
INFO:root:Train (Epoch 251): Loss/seq after 03400 batchs: 440.8323974609375
INFO:root:Train (Epoch 251): Loss/seq after 03450 batchs: 439.44024658203125
INFO:root:Train (Epoch 251): Loss/seq after 03500 batchs: 440.80975341796875
INFO:root:Train (Epoch 251): Loss/seq after 03550 batchs: 438.6789245605469
INFO:root:Train (Epoch 251): Loss/seq after 03600 batchs: 445.0565185546875
INFO:root:Train (Epoch 251): Loss/seq after 03650 batchs: 443.7650451660156
INFO:root:Train (Epoch 251): Loss/seq after 03700 batchs: 446.3294372558594
INFO:root:Train (Epoch 251): Loss/seq after 03750 batchs: 450.4127502441406
INFO:root:Train (Epoch 251): Loss/seq after 03800 batchs: 449.2225341796875
INFO:root:Train (Epoch 251): Loss/seq after 03850 batchs: 448.34442138671875
INFO:root:Train (Epoch 251): Loss/seq after 03900 batchs: 450.88580322265625
INFO:root:Train (Epoch 251): Loss/seq after 03950 batchs: 454.0586853027344
INFO:root:Train (Epoch 251): Loss/seq after 04000 batchs: 451.0392150878906
INFO:root:Train (Epoch 251): Loss/seq after 04050 batchs: 448.2765197753906
INFO:root:Train (Epoch 251): Loss/seq after 04100 batchs: 447.290283203125
INFO:root:Train (Epoch 251): Loss/seq after 04150 batchs: 447.0769958496094
INFO:root:Train (Epoch 251): Loss/seq after 04200 batchs: 445.74615478515625
INFO:root:Train (Epoch 251): Loss/seq after 04250 batchs: 444.3890686035156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 251): Loss/seq after 00000 batches: 403.59552001953125
INFO:root:# Valid (Epoch 251): Loss/seq after 00050 batches: 699.9185791015625
INFO:root:# Valid (Epoch 251): Loss/seq after 00100 batches: 716.5955200195312
INFO:root:# Valid (Epoch 251): Loss/seq after 00150 batches: 533.334716796875
INFO:root:# Valid (Epoch 251): Loss/seq after 00200 batches: 485.1632385253906
INFO:root:Artifacts: Make stick videos for epoch 251
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_251_on_20220423_170303.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_251_index_78_on_20220423_170303.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 252): Loss/seq after 00000 batchs: 720.445068359375
INFO:root:Train (Epoch 252): Loss/seq after 00050 batchs: 604.6580200195312
INFO:root:Train (Epoch 252): Loss/seq after 00100 batchs: 612.7847290039062
INFO:root:Train (Epoch 252): Loss/seq after 00150 batchs: 553.49609375
INFO:root:Train (Epoch 252): Loss/seq after 00200 batchs: 622.6615600585938
INFO:root:Train (Epoch 252): Loss/seq after 00250 batchs: 663.1048583984375
INFO:root:Train (Epoch 252): Loss/seq after 00300 batchs: 674.1984252929688
INFO:root:Train (Epoch 252): Loss/seq after 00350 batchs: 639.3096313476562
INFO:root:Train (Epoch 252): Loss/seq after 00400 batchs: 632.9288330078125
INFO:root:Train (Epoch 252): Loss/seq after 00450 batchs: 633.0020141601562
INFO:root:Train (Epoch 252): Loss/seq after 00500 batchs: 612.0902709960938
INFO:root:Train (Epoch 252): Loss/seq after 00550 batchs: 597.7063598632812
INFO:root:Train (Epoch 252): Loss/seq after 00600 batchs: 578.4259643554688
INFO:root:Train (Epoch 252): Loss/seq after 00650 batchs: 562.6864624023438
INFO:root:Train (Epoch 252): Loss/seq after 00700 batchs: 542.7447509765625
INFO:root:Train (Epoch 252): Loss/seq after 00750 batchs: 540.6719970703125
INFO:root:Train (Epoch 252): Loss/seq after 00800 batchs: 542.0941772460938
INFO:root:Train (Epoch 252): Loss/seq after 00850 batchs: 525.6444702148438
INFO:root:Train (Epoch 252): Loss/seq after 00900 batchs: 511.6253356933594
INFO:root:Train (Epoch 252): Loss/seq after 00950 batchs: 512.2962646484375
INFO:root:Train (Epoch 252): Loss/seq after 01000 batchs: 504.804443359375
INFO:root:Train (Epoch 252): Loss/seq after 01050 batchs: 494.6112976074219
INFO:root:Train (Epoch 252): Loss/seq after 01100 batchs: 486.337646484375
INFO:root:Train (Epoch 252): Loss/seq after 01150 batchs: 474.359375
INFO:root:Train (Epoch 252): Loss/seq after 01200 batchs: 477.9909973144531
INFO:root:Train (Epoch 252): Loss/seq after 01250 batchs: 476.9691162109375
INFO:root:Train (Epoch 252): Loss/seq after 01300 batchs: 467.1766357421875
INFO:root:Train (Epoch 252): Loss/seq after 01350 batchs: 459.12396240234375
INFO:root:Train (Epoch 252): Loss/seq after 01400 batchs: 462.0746154785156
INFO:root:Train (Epoch 252): Loss/seq after 01450 batchs: 465.160888671875
INFO:root:Train (Epoch 252): Loss/seq after 01500 batchs: 471.1072692871094
INFO:root:Train (Epoch 252): Loss/seq after 01550 batchs: 472.6658020019531
INFO:root:Train (Epoch 252): Loss/seq after 01600 batchs: 469.3048400878906
INFO:root:Train (Epoch 252): Loss/seq after 01650 batchs: 467.357666015625
INFO:root:Train (Epoch 252): Loss/seq after 01700 batchs: 470.75750732421875
INFO:root:Train (Epoch 252): Loss/seq after 01750 batchs: 469.08843994140625
INFO:root:Train (Epoch 252): Loss/seq after 01800 batchs: 466.8962097167969
INFO:root:Train (Epoch 252): Loss/seq after 01850 batchs: 464.12176513671875
INFO:root:Train (Epoch 252): Loss/seq after 01900 batchs: 462.3417053222656
INFO:root:Train (Epoch 252): Loss/seq after 01950 batchs: 461.0230407714844
INFO:root:Train (Epoch 252): Loss/seq after 02000 batchs: 461.55120849609375
INFO:root:Train (Epoch 252): Loss/seq after 02050 batchs: 460.5953063964844
INFO:root:Train (Epoch 252): Loss/seq after 02100 batchs: 458.91156005859375
INFO:root:Train (Epoch 252): Loss/seq after 02150 batchs: 457.7651672363281
INFO:root:Train (Epoch 252): Loss/seq after 02200 batchs: 455.9573974609375
INFO:root:Train (Epoch 252): Loss/seq after 02250 batchs: 455.3871765136719
INFO:root:Train (Epoch 252): Loss/seq after 02300 batchs: 452.7378234863281
INFO:root:Train (Epoch 252): Loss/seq after 02350 batchs: 449.6824645996094
INFO:root:Train (Epoch 252): Loss/seq after 02400 batchs: 451.6549987792969
INFO:root:Train (Epoch 252): Loss/seq after 02450 batchs: 448.0687561035156
INFO:root:Train (Epoch 252): Loss/seq after 02500 batchs: 441.2144775390625
INFO:root:Train (Epoch 252): Loss/seq after 02550 batchs: 435.7543640136719
INFO:root:Train (Epoch 252): Loss/seq after 02600 batchs: 432.6991882324219
INFO:root:Train (Epoch 252): Loss/seq after 02650 batchs: 429.7241516113281
INFO:root:Train (Epoch 252): Loss/seq after 02700 batchs: 427.333740234375
INFO:root:Train (Epoch 252): Loss/seq after 02750 batchs: 423.2744140625
INFO:root:Train (Epoch 252): Loss/seq after 02800 batchs: 422.3759765625
INFO:root:Train (Epoch 252): Loss/seq after 02850 batchs: 422.13043212890625
INFO:root:Train (Epoch 252): Loss/seq after 02900 batchs: 423.1579895019531
INFO:root:Train (Epoch 252): Loss/seq after 02950 batchs: 423.4100646972656
INFO:root:Train (Epoch 252): Loss/seq after 03000 batchs: 428.64404296875
INFO:root:Train (Epoch 252): Loss/seq after 03050 batchs: 430.5816345214844
INFO:root:Train (Epoch 252): Loss/seq after 03100 batchs: 433.020751953125
INFO:root:Train (Epoch 252): Loss/seq after 03150 batchs: 434.28277587890625
INFO:root:Train (Epoch 252): Loss/seq after 03200 batchs: 434.7841796875
INFO:root:Train (Epoch 252): Loss/seq after 03250 batchs: 436.3558044433594
INFO:root:Train (Epoch 252): Loss/seq after 03300 batchs: 435.74078369140625
INFO:root:Train (Epoch 252): Loss/seq after 03350 batchs: 434.02850341796875
INFO:root:Train (Epoch 252): Loss/seq after 03400 batchs: 431.49835205078125
INFO:root:Train (Epoch 252): Loss/seq after 03450 batchs: 430.25897216796875
INFO:root:Train (Epoch 252): Loss/seq after 03500 batchs: 430.9999694824219
INFO:root:Train (Epoch 252): Loss/seq after 03550 batchs: 428.984375
INFO:root:Train (Epoch 252): Loss/seq after 03600 batchs: 435.4798889160156
INFO:root:Train (Epoch 252): Loss/seq after 03650 batchs: 434.02557373046875
INFO:root:Train (Epoch 252): Loss/seq after 03700 batchs: 436.1722106933594
INFO:root:Train (Epoch 252): Loss/seq after 03750 batchs: 440.3100280761719
INFO:root:Train (Epoch 252): Loss/seq after 03800 batchs: 439.27392578125
INFO:root:Train (Epoch 252): Loss/seq after 03850 batchs: 438.4908142089844
INFO:root:Train (Epoch 252): Loss/seq after 03900 batchs: 441.25299072265625
INFO:root:Train (Epoch 252): Loss/seq after 03950 batchs: 444.35980224609375
INFO:root:Train (Epoch 252): Loss/seq after 04000 batchs: 441.4770202636719
INFO:root:Train (Epoch 252): Loss/seq after 04050 batchs: 438.8633728027344
INFO:root:Train (Epoch 252): Loss/seq after 04100 batchs: 438.0732421875
INFO:root:Train (Epoch 252): Loss/seq after 04150 batchs: 438.08709716796875
INFO:root:Train (Epoch 252): Loss/seq after 04200 batchs: 436.79534912109375
INFO:root:Train (Epoch 252): Loss/seq after 04250 batchs: 435.4737854003906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 252): Loss/seq after 00000 batches: 402.801025390625
INFO:root:# Valid (Epoch 252): Loss/seq after 00050 batches: 650.8638916015625
INFO:root:# Valid (Epoch 252): Loss/seq after 00100 batches: 649.8872680664062
INFO:root:# Valid (Epoch 252): Loss/seq after 00150 batches: 487.65411376953125
INFO:root:# Valid (Epoch 252): Loss/seq after 00200 batches: 449.2377014160156
INFO:root:Artifacts: Make stick videos for epoch 252
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_252_on_20220423_170747.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_252_index_964_on_20220423_170747.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 253): Loss/seq after 00000 batchs: 655.9139404296875
INFO:root:Train (Epoch 253): Loss/seq after 00050 batchs: 578.2120971679688
INFO:root:Train (Epoch 253): Loss/seq after 00100 batchs: 608.1019287109375
INFO:root:Train (Epoch 253): Loss/seq after 00150 batchs: 550.7842407226562
INFO:root:Train (Epoch 253): Loss/seq after 00200 batchs: 622.0389404296875
INFO:root:Train (Epoch 253): Loss/seq after 00250 batchs: 688.2230224609375
INFO:root:Train (Epoch 253): Loss/seq after 00300 batchs: 696.6002197265625
INFO:root:Train (Epoch 253): Loss/seq after 00350 batchs: 659.5928344726562
INFO:root:Train (Epoch 253): Loss/seq after 00400 batchs: 655.4805297851562
INFO:root:Train (Epoch 253): Loss/seq after 00450 batchs: 653.7388916015625
INFO:root:Train (Epoch 253): Loss/seq after 00500 batchs: 634.8358764648438
INFO:root:Train (Epoch 253): Loss/seq after 00550 batchs: 618.2955932617188
INFO:root:Train (Epoch 253): Loss/seq after 00600 batchs: 598.5492553710938
INFO:root:Train (Epoch 253): Loss/seq after 00650 batchs: 581.2210693359375
INFO:root:Train (Epoch 253): Loss/seq after 00700 batchs: 561.1410522460938
INFO:root:Train (Epoch 253): Loss/seq after 00750 batchs: 560.007080078125
INFO:root:Train (Epoch 253): Loss/seq after 00800 batchs: 559.1905517578125
INFO:root:Train (Epoch 253): Loss/seq after 00850 batchs: 541.7926025390625
INFO:root:Train (Epoch 253): Loss/seq after 00900 batchs: 527.6912231445312
INFO:root:Train (Epoch 253): Loss/seq after 00950 batchs: 524.0220947265625
INFO:root:Train (Epoch 253): Loss/seq after 01000 batchs: 514.4525146484375
INFO:root:Train (Epoch 253): Loss/seq after 01050 batchs: 503.1947326660156
INFO:root:Train (Epoch 253): Loss/seq after 01100 batchs: 492.65618896484375
INFO:root:Train (Epoch 253): Loss/seq after 01150 batchs: 480.48687744140625
INFO:root:Train (Epoch 253): Loss/seq after 01200 batchs: 483.4132385253906
INFO:root:Train (Epoch 253): Loss/seq after 01250 batchs: 481.8403625488281
INFO:root:Train (Epoch 253): Loss/seq after 01300 batchs: 472.07562255859375
INFO:root:Train (Epoch 253): Loss/seq after 01350 batchs: 463.19378662109375
INFO:root:Train (Epoch 253): Loss/seq after 01400 batchs: 465.5519104003906
INFO:root:Train (Epoch 253): Loss/seq after 01450 batchs: 468.36810302734375
INFO:root:Train (Epoch 253): Loss/seq after 01500 batchs: 473.7229919433594
INFO:root:Train (Epoch 253): Loss/seq after 01550 batchs: 475.1009826660156
INFO:root:Train (Epoch 253): Loss/seq after 01600 batchs: 471.53619384765625
INFO:root:Train (Epoch 253): Loss/seq after 01650 batchs: 469.26617431640625
INFO:root:Train (Epoch 253): Loss/seq after 01700 batchs: 472.4147644042969
INFO:root:Train (Epoch 253): Loss/seq after 01750 batchs: 470.67144775390625
INFO:root:Train (Epoch 253): Loss/seq after 01800 batchs: 468.41607666015625
INFO:root:Train (Epoch 253): Loss/seq after 01850 batchs: 465.591064453125
INFO:root:Train (Epoch 253): Loss/seq after 01900 batchs: 463.7373046875
INFO:root:Train (Epoch 253): Loss/seq after 01950 batchs: 462.3189697265625
INFO:root:Train (Epoch 253): Loss/seq after 02000 batchs: 462.62481689453125
INFO:root:Train (Epoch 253): Loss/seq after 02050 batchs: 461.7392578125
INFO:root:Train (Epoch 253): Loss/seq after 02100 batchs: 460.07342529296875
INFO:root:Train (Epoch 253): Loss/seq after 02150 batchs: 459.01513671875
INFO:root:Train (Epoch 253): Loss/seq after 02200 batchs: 457.3402099609375
INFO:root:Train (Epoch 253): Loss/seq after 02250 batchs: 456.1896057128906
INFO:root:Train (Epoch 253): Loss/seq after 02300 batchs: 453.11297607421875
INFO:root:Train (Epoch 253): Loss/seq after 02350 batchs: 449.8384704589844
INFO:root:Train (Epoch 253): Loss/seq after 02400 batchs: 451.5179138183594
INFO:root:Train (Epoch 253): Loss/seq after 02450 batchs: 447.8478698730469
INFO:root:Train (Epoch 253): Loss/seq after 02500 batchs: 440.99041748046875
INFO:root:Train (Epoch 253): Loss/seq after 02550 batchs: 435.47515869140625
INFO:root:Train (Epoch 253): Loss/seq after 02600 batchs: 432.6590270996094
INFO:root:Train (Epoch 253): Loss/seq after 02650 batchs: 429.6445617675781
INFO:root:Train (Epoch 253): Loss/seq after 02700 batchs: 427.3262939453125
INFO:root:Train (Epoch 253): Loss/seq after 02750 batchs: 423.10528564453125
INFO:root:Train (Epoch 253): Loss/seq after 02800 batchs: 422.4073486328125
INFO:root:Train (Epoch 253): Loss/seq after 02850 batchs: 422.284912109375
INFO:root:Train (Epoch 253): Loss/seq after 02900 batchs: 423.3945007324219
INFO:root:Train (Epoch 253): Loss/seq after 02950 batchs: 423.6011962890625
INFO:root:Train (Epoch 253): Loss/seq after 03000 batchs: 428.6744689941406
INFO:root:Train (Epoch 253): Loss/seq after 03050 batchs: 430.62017822265625
INFO:root:Train (Epoch 253): Loss/seq after 03100 batchs: 432.5235290527344
INFO:root:Train (Epoch 253): Loss/seq after 03150 batchs: 435.0701599121094
INFO:root:Train (Epoch 253): Loss/seq after 03200 batchs: 436.26446533203125
INFO:root:Train (Epoch 253): Loss/seq after 03250 batchs: 437.7515563964844
INFO:root:Train (Epoch 253): Loss/seq after 03300 batchs: 436.91357421875
INFO:root:Train (Epoch 253): Loss/seq after 03350 batchs: 435.5543212890625
INFO:root:Train (Epoch 253): Loss/seq after 03400 batchs: 432.75006103515625
INFO:root:Train (Epoch 253): Loss/seq after 03450 batchs: 431.51165771484375
INFO:root:Train (Epoch 253): Loss/seq after 03500 batchs: 432.4265441894531
INFO:root:Train (Epoch 253): Loss/seq after 03550 batchs: 430.5723876953125
INFO:root:Train (Epoch 253): Loss/seq after 03600 batchs: 436.6589660644531
INFO:root:Train (Epoch 253): Loss/seq after 03650 batchs: 435.2149963378906
INFO:root:Train (Epoch 253): Loss/seq after 03700 batchs: 437.1894836425781
INFO:root:Train (Epoch 253): Loss/seq after 03750 batchs: 441.1681213378906
INFO:root:Train (Epoch 253): Loss/seq after 03800 batchs: 440.09259033203125
INFO:root:Train (Epoch 253): Loss/seq after 03850 batchs: 439.2546691894531
INFO:root:Train (Epoch 253): Loss/seq after 03900 batchs: 441.7408447265625
INFO:root:Train (Epoch 253): Loss/seq after 03950 batchs: 444.9764404296875
INFO:root:Train (Epoch 253): Loss/seq after 04000 batchs: 442.05548095703125
INFO:root:Train (Epoch 253): Loss/seq after 04050 batchs: 439.40142822265625
INFO:root:Train (Epoch 253): Loss/seq after 04100 batchs: 438.5439147949219
INFO:root:Train (Epoch 253): Loss/seq after 04150 batchs: 438.4461364746094
INFO:root:Train (Epoch 253): Loss/seq after 04200 batchs: 437.1853942871094
INFO:root:Train (Epoch 253): Loss/seq after 04250 batchs: 435.9039306640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 253): Loss/seq after 00000 batches: 446.9422302246094
INFO:root:# Valid (Epoch 253): Loss/seq after 00050 batches: 674.3318481445312
INFO:root:# Valid (Epoch 253): Loss/seq after 00100 batches: 697.5159301757812
INFO:root:# Valid (Epoch 253): Loss/seq after 00150 batches: 521.1729736328125
INFO:root:# Valid (Epoch 253): Loss/seq after 00200 batches: 477.1201171875
INFO:root:Artifacts: Make stick videos for epoch 253
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_253_on_20220423_171229.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_253_index_341_on_20220423_171229.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 254): Loss/seq after 00000 batchs: 924.2476806640625
INFO:root:Train (Epoch 254): Loss/seq after 00050 batchs: 599.3831176757812
INFO:root:Train (Epoch 254): Loss/seq after 00100 batchs: 611.5409545898438
INFO:root:Train (Epoch 254): Loss/seq after 00150 batchs: 554.0015869140625
INFO:root:Train (Epoch 254): Loss/seq after 00200 batchs: 633.470458984375
INFO:root:Train (Epoch 254): Loss/seq after 00250 batchs: 679.9574584960938
INFO:root:Train (Epoch 254): Loss/seq after 00300 batchs: 689.21533203125
INFO:root:Train (Epoch 254): Loss/seq after 00350 batchs: 652.60986328125
INFO:root:Train (Epoch 254): Loss/seq after 00400 batchs: 646.5310668945312
INFO:root:Train (Epoch 254): Loss/seq after 00450 batchs: 645.881591796875
INFO:root:Train (Epoch 254): Loss/seq after 00500 batchs: 625.0252685546875
INFO:root:Train (Epoch 254): Loss/seq after 00550 batchs: 609.340087890625
INFO:root:Train (Epoch 254): Loss/seq after 00600 batchs: 587.7166748046875
INFO:root:Train (Epoch 254): Loss/seq after 00650 batchs: 570.5308837890625
INFO:root:Train (Epoch 254): Loss/seq after 00700 batchs: 550.08544921875
INFO:root:Train (Epoch 254): Loss/seq after 00750 batchs: 547.335693359375
INFO:root:Train (Epoch 254): Loss/seq after 00800 batchs: 547.3805541992188
INFO:root:Train (Epoch 254): Loss/seq after 00850 batchs: 530.1057739257812
INFO:root:Train (Epoch 254): Loss/seq after 00900 batchs: 515.6748657226562
INFO:root:Train (Epoch 254): Loss/seq after 00950 batchs: 514.78369140625
INFO:root:Train (Epoch 254): Loss/seq after 01000 batchs: 507.0328369140625
INFO:root:Train (Epoch 254): Loss/seq after 01050 batchs: 496.00799560546875
INFO:root:Train (Epoch 254): Loss/seq after 01100 batchs: 486.5870361328125
INFO:root:Train (Epoch 254): Loss/seq after 01150 batchs: 474.2906799316406
INFO:root:Train (Epoch 254): Loss/seq after 01200 batchs: 477.7435302734375
INFO:root:Train (Epoch 254): Loss/seq after 01250 batchs: 476.1828918457031
INFO:root:Train (Epoch 254): Loss/seq after 01300 batchs: 466.8018798828125
INFO:root:Train (Epoch 254): Loss/seq after 01350 batchs: 458.04791259765625
INFO:root:Train (Epoch 254): Loss/seq after 01400 batchs: 460.0454406738281
INFO:root:Train (Epoch 254): Loss/seq after 01450 batchs: 462.8511047363281
INFO:root:Train (Epoch 254): Loss/seq after 01500 batchs: 468.68475341796875
INFO:root:Train (Epoch 254): Loss/seq after 01550 batchs: 470.4783935546875
INFO:root:Train (Epoch 254): Loss/seq after 01600 batchs: 467.2074279785156
INFO:root:Train (Epoch 254): Loss/seq after 01650 batchs: 465.004150390625
INFO:root:Train (Epoch 254): Loss/seq after 01700 batchs: 468.69830322265625
INFO:root:Train (Epoch 254): Loss/seq after 01750 batchs: 466.83209228515625
INFO:root:Train (Epoch 254): Loss/seq after 01800 batchs: 464.7814025878906
INFO:root:Train (Epoch 254): Loss/seq after 01850 batchs: 461.9517517089844
INFO:root:Train (Epoch 254): Loss/seq after 01900 batchs: 460.315185546875
INFO:root:Train (Epoch 254): Loss/seq after 01950 batchs: 459.3435363769531
INFO:root:Train (Epoch 254): Loss/seq after 02000 batchs: 459.8533935546875
INFO:root:Train (Epoch 254): Loss/seq after 02050 batchs: 458.9207458496094
INFO:root:Train (Epoch 254): Loss/seq after 02100 batchs: 457.3492431640625
INFO:root:Train (Epoch 254): Loss/seq after 02150 batchs: 456.24853515625
INFO:root:Train (Epoch 254): Loss/seq after 02200 batchs: 454.53021240234375
INFO:root:Train (Epoch 254): Loss/seq after 02250 batchs: 453.57000732421875
INFO:root:Train (Epoch 254): Loss/seq after 02300 batchs: 450.8985290527344
INFO:root:Train (Epoch 254): Loss/seq after 02350 batchs: 447.7137451171875
INFO:root:Train (Epoch 254): Loss/seq after 02400 batchs: 449.5428466796875
INFO:root:Train (Epoch 254): Loss/seq after 02450 batchs: 445.8727111816406
INFO:root:Train (Epoch 254): Loss/seq after 02500 batchs: 439.05548095703125
INFO:root:Train (Epoch 254): Loss/seq after 02550 batchs: 433.64288330078125
INFO:root:Train (Epoch 254): Loss/seq after 02600 batchs: 430.7383728027344
INFO:root:Train (Epoch 254): Loss/seq after 02650 batchs: 427.63116455078125
INFO:root:Train (Epoch 254): Loss/seq after 02700 batchs: 425.7262268066406
INFO:root:Train (Epoch 254): Loss/seq after 02750 batchs: 421.9864196777344
INFO:root:Train (Epoch 254): Loss/seq after 02800 batchs: 420.985595703125
INFO:root:Train (Epoch 254): Loss/seq after 02850 batchs: 420.7469482421875
INFO:root:Train (Epoch 254): Loss/seq after 02900 batchs: 421.84619140625
INFO:root:Train (Epoch 254): Loss/seq after 02950 batchs: 422.0658264160156
INFO:root:Train (Epoch 254): Loss/seq after 03000 batchs: 426.95098876953125
INFO:root:Train (Epoch 254): Loss/seq after 03050 batchs: 428.91552734375
INFO:root:Train (Epoch 254): Loss/seq after 03100 batchs: 430.7378845214844
INFO:root:Train (Epoch 254): Loss/seq after 03150 batchs: 432.9402770996094
INFO:root:Train (Epoch 254): Loss/seq after 03200 batchs: 433.5777282714844
INFO:root:Train (Epoch 254): Loss/seq after 03250 batchs: 434.8611145019531
INFO:root:Train (Epoch 254): Loss/seq after 03300 batchs: 434.1101989746094
INFO:root:Train (Epoch 254): Loss/seq after 03350 batchs: 432.18646240234375
INFO:root:Train (Epoch 254): Loss/seq after 03400 batchs: 429.45733642578125
INFO:root:Train (Epoch 254): Loss/seq after 03450 batchs: 428.15228271484375
INFO:root:Train (Epoch 254): Loss/seq after 03500 batchs: 428.9455871582031
INFO:root:Train (Epoch 254): Loss/seq after 03550 batchs: 427.0224609375
INFO:root:Train (Epoch 254): Loss/seq after 03600 batchs: 432.9390563964844
INFO:root:Train (Epoch 254): Loss/seq after 03650 batchs: 431.6899108886719
INFO:root:Train (Epoch 254): Loss/seq after 03700 batchs: 434.0330505371094
INFO:root:Train (Epoch 254): Loss/seq after 03750 batchs: 438.0525207519531
INFO:root:Train (Epoch 254): Loss/seq after 03800 batchs: 437.05242919921875
INFO:root:Train (Epoch 254): Loss/seq after 03850 batchs: 436.1191711425781
INFO:root:Train (Epoch 254): Loss/seq after 03900 batchs: 438.2577209472656
INFO:root:Train (Epoch 254): Loss/seq after 03950 batchs: 441.5148010253906
INFO:root:Train (Epoch 254): Loss/seq after 04000 batchs: 438.65264892578125
INFO:root:Train (Epoch 254): Loss/seq after 04050 batchs: 436.0184020996094
INFO:root:Train (Epoch 254): Loss/seq after 04100 batchs: 435.249267578125
INFO:root:Train (Epoch 254): Loss/seq after 04150 batchs: 435.29034423828125
INFO:root:Train (Epoch 254): Loss/seq after 04200 batchs: 434.03961181640625
INFO:root:Train (Epoch 254): Loss/seq after 04250 batchs: 432.6961975097656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 254): Loss/seq after 00000 batches: 381.53802490234375
INFO:root:# Valid (Epoch 254): Loss/seq after 00050 batches: 704.802490234375
INFO:root:# Valid (Epoch 254): Loss/seq after 00100 batches: 716.09765625
INFO:root:# Valid (Epoch 254): Loss/seq after 00150 batches: 539.5068359375
INFO:root:# Valid (Epoch 254): Loss/seq after 00200 batches: 493.4036865234375
INFO:root:Artifacts: Make stick videos for epoch 254
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_254_on_20220423_171726.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_254_index_822_on_20220423_171726.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 255): Loss/seq after 00000 batchs: 1115.2176513671875
INFO:root:Train (Epoch 255): Loss/seq after 00050 batchs: 603.515625
INFO:root:Train (Epoch 255): Loss/seq after 00100 batchs: 613.256591796875
INFO:root:Train (Epoch 255): Loss/seq after 00150 batchs: 552.6473999023438
INFO:root:Train (Epoch 255): Loss/seq after 00200 batchs: 619.6747436523438
INFO:root:Train (Epoch 255): Loss/seq after 00250 batchs: 659.3023681640625
INFO:root:Train (Epoch 255): Loss/seq after 00300 batchs: 669.6019897460938
INFO:root:Train (Epoch 255): Loss/seq after 00350 batchs: 635.9354248046875
INFO:root:Train (Epoch 255): Loss/seq after 00400 batchs: 628.5702514648438
INFO:root:Train (Epoch 255): Loss/seq after 00450 batchs: 629.1280517578125
INFO:root:Train (Epoch 255): Loss/seq after 00500 batchs: 609.1758422851562
INFO:root:Train (Epoch 255): Loss/seq after 00550 batchs: 594.2247924804688
INFO:root:Train (Epoch 255): Loss/seq after 00600 batchs: 575.8463134765625
INFO:root:Train (Epoch 255): Loss/seq after 00650 batchs: 561.9666137695312
INFO:root:Train (Epoch 255): Loss/seq after 00700 batchs: 541.317138671875
INFO:root:Train (Epoch 255): Loss/seq after 00750 batchs: 541.1551513671875
INFO:root:Train (Epoch 255): Loss/seq after 00800 batchs: 542.7960815429688
INFO:root:Train (Epoch 255): Loss/seq after 00850 batchs: 526.4016723632812
INFO:root:Train (Epoch 255): Loss/seq after 00900 batchs: 512.2854614257812
INFO:root:Train (Epoch 255): Loss/seq after 00950 batchs: 511.6745300292969
INFO:root:Train (Epoch 255): Loss/seq after 01000 batchs: 503.4997863769531
INFO:root:Train (Epoch 255): Loss/seq after 01050 batchs: 492.9103088378906
INFO:root:Train (Epoch 255): Loss/seq after 01100 batchs: 482.8462829589844
INFO:root:Train (Epoch 255): Loss/seq after 01150 batchs: 470.48236083984375
INFO:root:Train (Epoch 255): Loss/seq after 01200 batchs: 473.3226318359375
INFO:root:Train (Epoch 255): Loss/seq after 01250 batchs: 472.0240783691406
INFO:root:Train (Epoch 255): Loss/seq after 01300 batchs: 462.5144958496094
INFO:root:Train (Epoch 255): Loss/seq after 01350 batchs: 454.4731140136719
INFO:root:Train (Epoch 255): Loss/seq after 01400 batchs: 456.470947265625
INFO:root:Train (Epoch 255): Loss/seq after 01450 batchs: 459.4741516113281
INFO:root:Train (Epoch 255): Loss/seq after 01500 batchs: 465.1242980957031
INFO:root:Train (Epoch 255): Loss/seq after 01550 batchs: 467.0378112792969
INFO:root:Train (Epoch 255): Loss/seq after 01600 batchs: 463.8630065917969
INFO:root:Train (Epoch 255): Loss/seq after 01650 batchs: 461.5879211425781
INFO:root:Train (Epoch 255): Loss/seq after 01700 batchs: 465.1001892089844
INFO:root:Train (Epoch 255): Loss/seq after 01750 batchs: 463.2505798339844
INFO:root:Train (Epoch 255): Loss/seq after 01800 batchs: 461.3233337402344
INFO:root:Train (Epoch 255): Loss/seq after 01850 batchs: 458.5243835449219
INFO:root:Train (Epoch 255): Loss/seq after 01900 batchs: 456.7001953125
INFO:root:Train (Epoch 255): Loss/seq after 01950 batchs: 455.6324462890625
INFO:root:Train (Epoch 255): Loss/seq after 02000 batchs: 456.323974609375
INFO:root:Train (Epoch 255): Loss/seq after 02050 batchs: 455.4794616699219
INFO:root:Train (Epoch 255): Loss/seq after 02100 batchs: 453.8597717285156
INFO:root:Train (Epoch 255): Loss/seq after 02150 batchs: 452.8182067871094
INFO:root:Train (Epoch 255): Loss/seq after 02200 batchs: 451.3330993652344
INFO:root:Train (Epoch 255): Loss/seq after 02250 batchs: 450.30523681640625
INFO:root:Train (Epoch 255): Loss/seq after 02300 batchs: 447.3714294433594
INFO:root:Train (Epoch 255): Loss/seq after 02350 batchs: 444.2140808105469
INFO:root:Train (Epoch 255): Loss/seq after 02400 batchs: 445.89599609375
INFO:root:Train (Epoch 255): Loss/seq after 02450 batchs: 442.2301025390625
INFO:root:Train (Epoch 255): Loss/seq after 02500 batchs: 435.4085998535156
INFO:root:Train (Epoch 255): Loss/seq after 02550 batchs: 429.9892272949219
INFO:root:Train (Epoch 255): Loss/seq after 02600 batchs: 427.0191345214844
INFO:root:Train (Epoch 255): Loss/seq after 02650 batchs: 423.88824462890625
INFO:root:Train (Epoch 255): Loss/seq after 02700 batchs: 421.85919189453125
INFO:root:Train (Epoch 255): Loss/seq after 02750 batchs: 417.92462158203125
INFO:root:Train (Epoch 255): Loss/seq after 02800 batchs: 417.05426025390625
INFO:root:Train (Epoch 255): Loss/seq after 02850 batchs: 416.9128112792969
INFO:root:Train (Epoch 255): Loss/seq after 02900 batchs: 418.0975341796875
INFO:root:Train (Epoch 255): Loss/seq after 02950 batchs: 418.3346252441406
INFO:root:Train (Epoch 255): Loss/seq after 03000 batchs: 423.4775085449219
INFO:root:Train (Epoch 255): Loss/seq after 03050 batchs: 425.3365173339844
INFO:root:Train (Epoch 255): Loss/seq after 03100 batchs: 426.9445495605469
INFO:root:Train (Epoch 255): Loss/seq after 03150 batchs: 429.4718933105469
INFO:root:Train (Epoch 255): Loss/seq after 03200 batchs: 430.95343017578125
INFO:root:Train (Epoch 255): Loss/seq after 03250 batchs: 432.4794616699219
INFO:root:Train (Epoch 255): Loss/seq after 03300 batchs: 431.6126403808594
INFO:root:Train (Epoch 255): Loss/seq after 03350 batchs: 430.0912170410156
INFO:root:Train (Epoch 255): Loss/seq after 03400 batchs: 427.38763427734375
INFO:root:Train (Epoch 255): Loss/seq after 03450 batchs: 426.070556640625
INFO:root:Train (Epoch 255): Loss/seq after 03500 batchs: 426.5037841796875
INFO:root:Train (Epoch 255): Loss/seq after 03550 batchs: 424.44512939453125
INFO:root:Train (Epoch 255): Loss/seq after 03600 batchs: 430.4776916503906
INFO:root:Train (Epoch 255): Loss/seq after 03650 batchs: 429.1746520996094
INFO:root:Train (Epoch 255): Loss/seq after 03700 batchs: 431.3415222167969
INFO:root:Train (Epoch 255): Loss/seq after 03750 batchs: 435.3121032714844
INFO:root:Train (Epoch 255): Loss/seq after 03800 batchs: 434.3141784667969
INFO:root:Train (Epoch 255): Loss/seq after 03850 batchs: 433.59625244140625
INFO:root:Train (Epoch 255): Loss/seq after 03900 batchs: 435.8844299316406
INFO:root:Train (Epoch 255): Loss/seq after 03950 batchs: 439.0845947265625
INFO:root:Train (Epoch 255): Loss/seq after 04000 batchs: 436.2403259277344
INFO:root:Train (Epoch 255): Loss/seq after 04050 batchs: 433.68450927734375
INFO:root:Train (Epoch 255): Loss/seq after 04100 batchs: 432.8506774902344
INFO:root:Train (Epoch 255): Loss/seq after 04150 batchs: 432.9444885253906
INFO:root:Train (Epoch 255): Loss/seq after 04200 batchs: 431.7614440917969
INFO:root:Train (Epoch 255): Loss/seq after 04250 batchs: 430.56475830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 255): Loss/seq after 00000 batches: 392.484130859375
INFO:root:# Valid (Epoch 255): Loss/seq after 00050 batches: 678.0154418945312
INFO:root:# Valid (Epoch 255): Loss/seq after 00100 batches: 663.5126953125
INFO:root:# Valid (Epoch 255): Loss/seq after 00150 batches: 501.0032043457031
INFO:root:# Valid (Epoch 255): Loss/seq after 00200 batches: 462.49554443359375
INFO:root:Artifacts: Make stick videos for epoch 255
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_255_on_20220423_172216.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_255_index_33_on_20220423_172216.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 256): Loss/seq after 00000 batchs: 953.3649291992188
INFO:root:Train (Epoch 256): Loss/seq after 00050 batchs: 583.2361450195312
INFO:root:Train (Epoch 256): Loss/seq after 00100 batchs: 590.8677978515625
INFO:root:Train (Epoch 256): Loss/seq after 00150 batchs: 537.555419921875
INFO:root:Train (Epoch 256): Loss/seq after 00200 batchs: 617.03564453125
INFO:root:Train (Epoch 256): Loss/seq after 00250 batchs: 652.9412841796875
INFO:root:Train (Epoch 256): Loss/seq after 00300 batchs: 665.2013549804688
INFO:root:Train (Epoch 256): Loss/seq after 00350 batchs: 632.6731567382812
INFO:root:Train (Epoch 256): Loss/seq after 00400 batchs: 632.7012939453125
INFO:root:Train (Epoch 256): Loss/seq after 00450 batchs: 633.4685668945312
INFO:root:Train (Epoch 256): Loss/seq after 00500 batchs: 616.8370361328125
INFO:root:Train (Epoch 256): Loss/seq after 00550 batchs: 602.6519775390625
INFO:root:Train (Epoch 256): Loss/seq after 00600 batchs: 582.5910034179688
INFO:root:Train (Epoch 256): Loss/seq after 00650 batchs: 564.54052734375
INFO:root:Train (Epoch 256): Loss/seq after 00700 batchs: 543.6747436523438
INFO:root:Train (Epoch 256): Loss/seq after 00750 batchs: 540.835693359375
INFO:root:Train (Epoch 256): Loss/seq after 00800 batchs: 540.630859375
INFO:root:Train (Epoch 256): Loss/seq after 00850 batchs: 523.6505737304688
INFO:root:Train (Epoch 256): Loss/seq after 00900 batchs: 510.42926025390625
INFO:root:Train (Epoch 256): Loss/seq after 00950 batchs: 508.0491027832031
INFO:root:Train (Epoch 256): Loss/seq after 01000 batchs: 500.3927001953125
INFO:root:Train (Epoch 256): Loss/seq after 01050 batchs: 490.32611083984375
INFO:root:Train (Epoch 256): Loss/seq after 01100 batchs: 480.00665283203125
INFO:root:Train (Epoch 256): Loss/seq after 01150 batchs: 467.9403381347656
INFO:root:Train (Epoch 256): Loss/seq after 01200 batchs: 471.208251953125
INFO:root:Train (Epoch 256): Loss/seq after 01250 batchs: 469.7132873535156
INFO:root:Train (Epoch 256): Loss/seq after 01300 batchs: 460.1622314453125
INFO:root:Train (Epoch 256): Loss/seq after 01350 batchs: 452.6282653808594
INFO:root:Train (Epoch 256): Loss/seq after 01400 batchs: 455.4753723144531
INFO:root:Train (Epoch 256): Loss/seq after 01450 batchs: 458.5481872558594
INFO:root:Train (Epoch 256): Loss/seq after 01500 batchs: 464.48443603515625
INFO:root:Train (Epoch 256): Loss/seq after 01550 batchs: 465.59765625
INFO:root:Train (Epoch 256): Loss/seq after 01600 batchs: 462.49688720703125
INFO:root:Train (Epoch 256): Loss/seq after 01650 batchs: 460.2919616699219
INFO:root:Train (Epoch 256): Loss/seq after 01700 batchs: 463.8651428222656
INFO:root:Train (Epoch 256): Loss/seq after 01750 batchs: 462.12860107421875
INFO:root:Train (Epoch 256): Loss/seq after 01800 batchs: 460.1714172363281
INFO:root:Train (Epoch 256): Loss/seq after 01850 batchs: 457.3529357910156
INFO:root:Train (Epoch 256): Loss/seq after 01900 batchs: 455.8424987792969
INFO:root:Train (Epoch 256): Loss/seq after 01950 batchs: 454.6568603515625
INFO:root:Train (Epoch 256): Loss/seq after 02000 batchs: 455.21258544921875
INFO:root:Train (Epoch 256): Loss/seq after 02050 batchs: 454.6378173828125
INFO:root:Train (Epoch 256): Loss/seq after 02100 batchs: 453.1686706542969
INFO:root:Train (Epoch 256): Loss/seq after 02150 batchs: 452.11572265625
INFO:root:Train (Epoch 256): Loss/seq after 02200 batchs: 450.5543518066406
INFO:root:Train (Epoch 256): Loss/seq after 02250 batchs: 449.6771240234375
INFO:root:Train (Epoch 256): Loss/seq after 02300 batchs: 447.6096496582031
INFO:root:Train (Epoch 256): Loss/seq after 02350 batchs: 444.62115478515625
INFO:root:Train (Epoch 256): Loss/seq after 02400 batchs: 446.4789733886719
INFO:root:Train (Epoch 256): Loss/seq after 02450 batchs: 442.9374694824219
INFO:root:Train (Epoch 256): Loss/seq after 02500 batchs: 436.10430908203125
INFO:root:Train (Epoch 256): Loss/seq after 02550 batchs: 430.6181335449219
INFO:root:Train (Epoch 256): Loss/seq after 02600 batchs: 427.82525634765625
INFO:root:Train (Epoch 256): Loss/seq after 02650 batchs: 424.90155029296875
INFO:root:Train (Epoch 256): Loss/seq after 02700 batchs: 422.6024475097656
INFO:root:Train (Epoch 256): Loss/seq after 02750 batchs: 418.7562255859375
INFO:root:Train (Epoch 256): Loss/seq after 02800 batchs: 417.6792297363281
INFO:root:Train (Epoch 256): Loss/seq after 02850 batchs: 417.561767578125
INFO:root:Train (Epoch 256): Loss/seq after 02900 batchs: 418.7030029296875
INFO:root:Train (Epoch 256): Loss/seq after 02950 batchs: 418.95782470703125
INFO:root:Train (Epoch 256): Loss/seq after 03000 batchs: 423.9551086425781
INFO:root:Train (Epoch 256): Loss/seq after 03050 batchs: 425.8247375488281
INFO:root:Train (Epoch 256): Loss/seq after 03100 batchs: 427.7425842285156
INFO:root:Train (Epoch 256): Loss/seq after 03150 batchs: 428.75958251953125
INFO:root:Train (Epoch 256): Loss/seq after 03200 batchs: 428.9105529785156
INFO:root:Train (Epoch 256): Loss/seq after 03250 batchs: 430.1709899902344
INFO:root:Train (Epoch 256): Loss/seq after 03300 batchs: 429.99993896484375
INFO:root:Train (Epoch 256): Loss/seq after 03350 batchs: 428.5133361816406
INFO:root:Train (Epoch 256): Loss/seq after 03400 batchs: 425.89068603515625
INFO:root:Train (Epoch 256): Loss/seq after 03450 batchs: 424.5588073730469
INFO:root:Train (Epoch 256): Loss/seq after 03500 batchs: 425.05853271484375
INFO:root:Train (Epoch 256): Loss/seq after 03550 batchs: 423.0892639160156
INFO:root:Train (Epoch 256): Loss/seq after 03600 batchs: 429.25360107421875
INFO:root:Train (Epoch 256): Loss/seq after 03650 batchs: 428.07281494140625
INFO:root:Train (Epoch 256): Loss/seq after 03700 batchs: 430.83642578125
INFO:root:Train (Epoch 256): Loss/seq after 03750 batchs: 434.91070556640625
INFO:root:Train (Epoch 256): Loss/seq after 03800 batchs: 433.8636474609375
INFO:root:Train (Epoch 256): Loss/seq after 03850 batchs: 433.2942810058594
INFO:root:Train (Epoch 256): Loss/seq after 03900 batchs: 435.3953552246094
INFO:root:Train (Epoch 256): Loss/seq after 03950 batchs: 438.35845947265625
INFO:root:Train (Epoch 256): Loss/seq after 04000 batchs: 435.52099609375
INFO:root:Train (Epoch 256): Loss/seq after 04050 batchs: 432.96270751953125
INFO:root:Train (Epoch 256): Loss/seq after 04100 batchs: 432.2012634277344
INFO:root:Train (Epoch 256): Loss/seq after 04150 batchs: 432.1455078125
INFO:root:Train (Epoch 256): Loss/seq after 04200 batchs: 430.9448547363281
INFO:root:Train (Epoch 256): Loss/seq after 04250 batchs: 429.6544189453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 256): Loss/seq after 00000 batches: 392.8702697753906
INFO:root:# Valid (Epoch 256): Loss/seq after 00050 batches: 688.376708984375
INFO:root:# Valid (Epoch 256): Loss/seq after 00100 batches: 708.7709350585938
INFO:root:# Valid (Epoch 256): Loss/seq after 00150 batches: 529.7801513671875
INFO:root:# Valid (Epoch 256): Loss/seq after 00200 batches: 485.0416564941406
INFO:root:Artifacts: Make stick videos for epoch 256
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_256_on_20220423_172712.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_256_index_381_on_20220423_172712.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 257): Loss/seq after 00000 batchs: 719.218017578125
INFO:root:Train (Epoch 257): Loss/seq after 00050 batchs: 591.5737915039062
INFO:root:Train (Epoch 257): Loss/seq after 00100 batchs: 603.6796875
INFO:root:Train (Epoch 257): Loss/seq after 00150 batchs: 546.9298706054688
INFO:root:Train (Epoch 257): Loss/seq after 00200 batchs: 617.0201416015625
INFO:root:Train (Epoch 257): Loss/seq after 00250 batchs: 663.8688354492188
INFO:root:Train (Epoch 257): Loss/seq after 00300 batchs: 672.5354614257812
INFO:root:Train (Epoch 257): Loss/seq after 00350 batchs: 637.408935546875
INFO:root:Train (Epoch 257): Loss/seq after 00400 batchs: 631.080810546875
INFO:root:Train (Epoch 257): Loss/seq after 00450 batchs: 630.95849609375
INFO:root:Train (Epoch 257): Loss/seq after 00500 batchs: 610.0135498046875
INFO:root:Train (Epoch 257): Loss/seq after 00550 batchs: 594.8642578125
INFO:root:Train (Epoch 257): Loss/seq after 00600 batchs: 574.813232421875
INFO:root:Train (Epoch 257): Loss/seq after 00650 batchs: 556.8126831054688
INFO:root:Train (Epoch 257): Loss/seq after 00700 batchs: 535.95458984375
INFO:root:Train (Epoch 257): Loss/seq after 00750 batchs: 534.4415283203125
INFO:root:Train (Epoch 257): Loss/seq after 00800 batchs: 534.4639892578125
INFO:root:Train (Epoch 257): Loss/seq after 00850 batchs: 518.2116088867188
INFO:root:Train (Epoch 257): Loss/seq after 00900 batchs: 504.4684143066406
INFO:root:Train (Epoch 257): Loss/seq after 00950 batchs: 503.3226013183594
INFO:root:Train (Epoch 257): Loss/seq after 01000 batchs: 495.6432800292969
INFO:root:Train (Epoch 257): Loss/seq after 01050 batchs: 485.5273132324219
INFO:root:Train (Epoch 257): Loss/seq after 01100 batchs: 475.493896484375
INFO:root:Train (Epoch 257): Loss/seq after 01150 batchs: 463.9709777832031
INFO:root:Train (Epoch 257): Loss/seq after 01200 batchs: 466.9753723144531
INFO:root:Train (Epoch 257): Loss/seq after 01250 batchs: 465.5722961425781
INFO:root:Train (Epoch 257): Loss/seq after 01300 batchs: 456.14105224609375
INFO:root:Train (Epoch 257): Loss/seq after 01350 batchs: 447.5888671875
INFO:root:Train (Epoch 257): Loss/seq after 01400 batchs: 449.6979675292969
INFO:root:Train (Epoch 257): Loss/seq after 01450 batchs: 453.201416015625
INFO:root:Train (Epoch 257): Loss/seq after 01500 batchs: 459.1929931640625
INFO:root:Train (Epoch 257): Loss/seq after 01550 batchs: 460.17120361328125
INFO:root:Train (Epoch 257): Loss/seq after 01600 batchs: 457.20001220703125
INFO:root:Train (Epoch 257): Loss/seq after 01650 batchs: 455.2598876953125
INFO:root:Train (Epoch 257): Loss/seq after 01700 batchs: 458.626708984375
INFO:root:Train (Epoch 257): Loss/seq after 01750 batchs: 457.0744323730469
INFO:root:Train (Epoch 257): Loss/seq after 01800 batchs: 455.3758544921875
INFO:root:Train (Epoch 257): Loss/seq after 01850 batchs: 452.5449523925781
INFO:root:Train (Epoch 257): Loss/seq after 01900 batchs: 450.9842224121094
INFO:root:Train (Epoch 257): Loss/seq after 01950 batchs: 449.5867919921875
INFO:root:Train (Epoch 257): Loss/seq after 02000 batchs: 450.1878356933594
INFO:root:Train (Epoch 257): Loss/seq after 02050 batchs: 449.3459167480469
INFO:root:Train (Epoch 257): Loss/seq after 02100 batchs: 448.0397644042969
INFO:root:Train (Epoch 257): Loss/seq after 02150 batchs: 446.9590148925781
INFO:root:Train (Epoch 257): Loss/seq after 02200 batchs: 445.433349609375
INFO:root:Train (Epoch 257): Loss/seq after 02250 batchs: 444.6610412597656
INFO:root:Train (Epoch 257): Loss/seq after 02300 batchs: 442.25872802734375
INFO:root:Train (Epoch 257): Loss/seq after 02350 batchs: 439.2028503417969
INFO:root:Train (Epoch 257): Loss/seq after 02400 batchs: 440.9029541015625
INFO:root:Train (Epoch 257): Loss/seq after 02450 batchs: 437.34149169921875
INFO:root:Train (Epoch 257): Loss/seq after 02500 batchs: 430.5892639160156
INFO:root:Train (Epoch 257): Loss/seq after 02550 batchs: 425.1802062988281
INFO:root:Train (Epoch 257): Loss/seq after 02600 batchs: 422.00537109375
INFO:root:Train (Epoch 257): Loss/seq after 02650 batchs: 419.5334167480469
INFO:root:Train (Epoch 257): Loss/seq after 02700 batchs: 417.6828308105469
INFO:root:Train (Epoch 257): Loss/seq after 02750 batchs: 413.8795471191406
INFO:root:Train (Epoch 257): Loss/seq after 02800 batchs: 414.1527099609375
INFO:root:Train (Epoch 257): Loss/seq after 02850 batchs: 414.2463073730469
INFO:root:Train (Epoch 257): Loss/seq after 02900 batchs: 415.5569763183594
INFO:root:Train (Epoch 257): Loss/seq after 02950 batchs: 415.8355712890625
INFO:root:Train (Epoch 257): Loss/seq after 03000 batchs: 420.9444885253906
INFO:root:Train (Epoch 257): Loss/seq after 03050 batchs: 422.9156494140625
INFO:root:Train (Epoch 257): Loss/seq after 03100 batchs: 424.8160705566406
INFO:root:Train (Epoch 257): Loss/seq after 03150 batchs: 426.2237548828125
INFO:root:Train (Epoch 257): Loss/seq after 03200 batchs: 426.5604248046875
INFO:root:Train (Epoch 257): Loss/seq after 03250 batchs: 428.60064697265625
INFO:root:Train (Epoch 257): Loss/seq after 03300 batchs: 427.93341064453125
INFO:root:Train (Epoch 257): Loss/seq after 03350 batchs: 426.8363037109375
INFO:root:Train (Epoch 257): Loss/seq after 03400 batchs: 424.2691955566406
INFO:root:Train (Epoch 257): Loss/seq after 03450 batchs: 422.8677978515625
INFO:root:Train (Epoch 257): Loss/seq after 03500 batchs: 424.0075378417969
INFO:root:Train (Epoch 257): Loss/seq after 03550 batchs: 422.1656188964844
INFO:root:Train (Epoch 257): Loss/seq after 03600 batchs: 428.453125
INFO:root:Train (Epoch 257): Loss/seq after 03650 batchs: 426.92388916015625
INFO:root:Train (Epoch 257): Loss/seq after 03700 batchs: 429.0599365234375
INFO:root:Train (Epoch 257): Loss/seq after 03750 batchs: 433.1158752441406
INFO:root:Train (Epoch 257): Loss/seq after 03800 batchs: 432.0495300292969
INFO:root:Train (Epoch 257): Loss/seq after 03850 batchs: 431.26953125
INFO:root:Train (Epoch 257): Loss/seq after 03900 batchs: 433.3670959472656
INFO:root:Train (Epoch 257): Loss/seq after 03950 batchs: 436.2323913574219
INFO:root:Train (Epoch 257): Loss/seq after 04000 batchs: 433.4019775390625
INFO:root:Train (Epoch 257): Loss/seq after 04050 batchs: 430.85101318359375
INFO:root:Train (Epoch 257): Loss/seq after 04100 batchs: 430.09527587890625
INFO:root:Train (Epoch 257): Loss/seq after 04150 batchs: 430.004150390625
INFO:root:Train (Epoch 257): Loss/seq after 04200 batchs: 428.9471740722656
INFO:root:Train (Epoch 257): Loss/seq after 04250 batchs: 427.6820373535156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 257): Loss/seq after 00000 batches: 392.50213623046875
INFO:root:# Valid (Epoch 257): Loss/seq after 00050 batches: 672.5498046875
INFO:root:# Valid (Epoch 257): Loss/seq after 00100 batches: 687.7882080078125
INFO:root:# Valid (Epoch 257): Loss/seq after 00150 batches: 515.259033203125
INFO:root:# Valid (Epoch 257): Loss/seq after 00200 batches: 473.3150634765625
INFO:root:Artifacts: Make stick videos for epoch 257
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_257_on_20220423_173212.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_257_index_1509_on_20220423_173212.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 258): Loss/seq after 00000 batchs: 729.8779907226562
INFO:root:Train (Epoch 258): Loss/seq after 00050 batchs: 577.2125854492188
INFO:root:Train (Epoch 258): Loss/seq after 00100 batchs: 592.4430541992188
INFO:root:Train (Epoch 258): Loss/seq after 00150 batchs: 534.53857421875
INFO:root:Train (Epoch 258): Loss/seq after 00200 batchs: 594.5711059570312
INFO:root:Train (Epoch 258): Loss/seq after 00250 batchs: 630.9902954101562
INFO:root:Train (Epoch 258): Loss/seq after 00300 batchs: 645.3198852539062
INFO:root:Train (Epoch 258): Loss/seq after 00350 batchs: 613.3984985351562
INFO:root:Train (Epoch 258): Loss/seq after 00400 batchs: 608.7509765625
INFO:root:Train (Epoch 258): Loss/seq after 00450 batchs: 611.5440063476562
INFO:root:Train (Epoch 258): Loss/seq after 00500 batchs: 591.4989013671875
INFO:root:Train (Epoch 258): Loss/seq after 00550 batchs: 577.5043334960938
INFO:root:Train (Epoch 258): Loss/seq after 00600 batchs: 558.2426147460938
INFO:root:Train (Epoch 258): Loss/seq after 00650 batchs: 540.21240234375
INFO:root:Train (Epoch 258): Loss/seq after 00700 batchs: 521.5684204101562
INFO:root:Train (Epoch 258): Loss/seq after 00750 batchs: 520.9566040039062
INFO:root:Train (Epoch 258): Loss/seq after 00800 batchs: 521.6103515625
INFO:root:Train (Epoch 258): Loss/seq after 00850 batchs: 505.8269348144531
INFO:root:Train (Epoch 258): Loss/seq after 00900 batchs: 492.60089111328125
INFO:root:Train (Epoch 258): Loss/seq after 00950 batchs: 491.72357177734375
INFO:root:Train (Epoch 258): Loss/seq after 01000 batchs: 483.9078063964844
INFO:root:Train (Epoch 258): Loss/seq after 01050 batchs: 474.2579650878906
INFO:root:Train (Epoch 258): Loss/seq after 01100 batchs: 465.5819091796875
INFO:root:Train (Epoch 258): Loss/seq after 01150 batchs: 454.1399841308594
INFO:root:Train (Epoch 258): Loss/seq after 01200 batchs: 457.37786865234375
INFO:root:Train (Epoch 258): Loss/seq after 01250 batchs: 456.8521728515625
INFO:root:Train (Epoch 258): Loss/seq after 01300 batchs: 448.9561462402344
INFO:root:Train (Epoch 258): Loss/seq after 01350 batchs: 441.0047912597656
INFO:root:Train (Epoch 258): Loss/seq after 01400 batchs: 442.9447326660156
INFO:root:Train (Epoch 258): Loss/seq after 01450 batchs: 446.172119140625
INFO:root:Train (Epoch 258): Loss/seq after 01500 batchs: 451.9918518066406
INFO:root:Train (Epoch 258): Loss/seq after 01550 batchs: 453.8636169433594
INFO:root:Train (Epoch 258): Loss/seq after 01600 batchs: 451.0010070800781
INFO:root:Train (Epoch 258): Loss/seq after 01650 batchs: 448.93768310546875
INFO:root:Train (Epoch 258): Loss/seq after 01700 batchs: 452.70001220703125
INFO:root:Train (Epoch 258): Loss/seq after 01750 batchs: 451.28814697265625
INFO:root:Train (Epoch 258): Loss/seq after 01800 batchs: 449.38189697265625
INFO:root:Train (Epoch 258): Loss/seq after 01850 batchs: 446.8898620605469
INFO:root:Train (Epoch 258): Loss/seq after 01900 batchs: 445.66497802734375
INFO:root:Train (Epoch 258): Loss/seq after 01950 batchs: 444.8092346191406
INFO:root:Train (Epoch 258): Loss/seq after 02000 batchs: 445.6219177246094
INFO:root:Train (Epoch 258): Loss/seq after 02050 batchs: 445.0932922363281
INFO:root:Train (Epoch 258): Loss/seq after 02100 batchs: 443.6911926269531
INFO:root:Train (Epoch 258): Loss/seq after 02150 batchs: 442.70440673828125
INFO:root:Train (Epoch 258): Loss/seq after 02200 batchs: 441.2592468261719
INFO:root:Train (Epoch 258): Loss/seq after 02250 batchs: 440.12744140625
INFO:root:Train (Epoch 258): Loss/seq after 02300 batchs: 437.3471374511719
INFO:root:Train (Epoch 258): Loss/seq after 02350 batchs: 434.4007568359375
INFO:root:Train (Epoch 258): Loss/seq after 02400 batchs: 436.144775390625
INFO:root:Train (Epoch 258): Loss/seq after 02450 batchs: 432.5942077636719
INFO:root:Train (Epoch 258): Loss/seq after 02500 batchs: 425.9043273925781
INFO:root:Train (Epoch 258): Loss/seq after 02550 batchs: 420.98553466796875
INFO:root:Train (Epoch 258): Loss/seq after 02600 batchs: 418.3249816894531
INFO:root:Train (Epoch 258): Loss/seq after 02650 batchs: 415.5661926269531
INFO:root:Train (Epoch 258): Loss/seq after 02700 batchs: 413.5144958496094
INFO:root:Train (Epoch 258): Loss/seq after 02750 batchs: 409.98016357421875
INFO:root:Train (Epoch 258): Loss/seq after 02800 batchs: 409.5577087402344
INFO:root:Train (Epoch 258): Loss/seq after 02850 batchs: 409.3871154785156
INFO:root:Train (Epoch 258): Loss/seq after 02900 batchs: 410.5897521972656
INFO:root:Train (Epoch 258): Loss/seq after 02950 batchs: 410.9916687011719
INFO:root:Train (Epoch 258): Loss/seq after 03000 batchs: 416.0323486328125
INFO:root:Train (Epoch 258): Loss/seq after 03050 batchs: 418.0084533691406
INFO:root:Train (Epoch 258): Loss/seq after 03100 batchs: 419.9198913574219
INFO:root:Train (Epoch 258): Loss/seq after 03150 batchs: 422.0674133300781
INFO:root:Train (Epoch 258): Loss/seq after 03200 batchs: 422.79998779296875
INFO:root:Train (Epoch 258): Loss/seq after 03250 batchs: 423.821533203125
INFO:root:Train (Epoch 258): Loss/seq after 03300 batchs: 423.12322998046875
INFO:root:Train (Epoch 258): Loss/seq after 03350 batchs: 421.2715148925781
INFO:root:Train (Epoch 258): Loss/seq after 03400 batchs: 418.63018798828125
INFO:root:Train (Epoch 258): Loss/seq after 03450 batchs: 417.6194152832031
INFO:root:Train (Epoch 258): Loss/seq after 03500 batchs: 418.5696716308594
INFO:root:Train (Epoch 258): Loss/seq after 03550 batchs: 416.7190856933594
INFO:root:Train (Epoch 258): Loss/seq after 03600 batchs: 422.994873046875
INFO:root:Train (Epoch 258): Loss/seq after 03650 batchs: 421.8450927734375
INFO:root:Train (Epoch 258): Loss/seq after 03700 batchs: 424.14056396484375
INFO:root:Train (Epoch 258): Loss/seq after 03750 batchs: 428.0951232910156
INFO:root:Train (Epoch 258): Loss/seq after 03800 batchs: 427.17352294921875
INFO:root:Train (Epoch 258): Loss/seq after 03850 batchs: 426.5979919433594
INFO:root:Train (Epoch 258): Loss/seq after 03900 batchs: 428.87127685546875
INFO:root:Train (Epoch 258): Loss/seq after 03950 batchs: 431.8800964355469
INFO:root:Train (Epoch 258): Loss/seq after 04000 batchs: 429.1356506347656
INFO:root:Train (Epoch 258): Loss/seq after 04050 batchs: 426.6243591308594
INFO:root:Train (Epoch 258): Loss/seq after 04100 batchs: 425.9136962890625
INFO:root:Train (Epoch 258): Loss/seq after 04150 batchs: 425.98614501953125
INFO:root:Train (Epoch 258): Loss/seq after 04200 batchs: 425.0218811035156
INFO:root:Train (Epoch 258): Loss/seq after 04250 batchs: 423.8662414550781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 258): Loss/seq after 00000 batches: 389.9602355957031
INFO:root:# Valid (Epoch 258): Loss/seq after 00050 batches: 678.647216796875
INFO:root:# Valid (Epoch 258): Loss/seq after 00100 batches: 686.9627075195312
INFO:root:# Valid (Epoch 258): Loss/seq after 00150 batches: 513.2721557617188
INFO:root:# Valid (Epoch 258): Loss/seq after 00200 batches: 470.9487609863281
INFO:root:Artifacts: Make stick videos for epoch 258
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_258_on_20220423_173702.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_258_index_1432_on_20220423_173702.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 259): Loss/seq after 00000 batchs: 1016.0156860351562
INFO:root:Train (Epoch 259): Loss/seq after 00050 batchs: 578.98974609375
INFO:root:Train (Epoch 259): Loss/seq after 00100 batchs: 592.1949462890625
INFO:root:Train (Epoch 259): Loss/seq after 00150 batchs: 538.7542724609375
INFO:root:Train (Epoch 259): Loss/seq after 00200 batchs: 598.614013671875
INFO:root:Train (Epoch 259): Loss/seq after 00250 batchs: 641.3552856445312
INFO:root:Train (Epoch 259): Loss/seq after 00300 batchs: 653.1795043945312
INFO:root:Train (Epoch 259): Loss/seq after 00350 batchs: 620.4137573242188
INFO:root:Train (Epoch 259): Loss/seq after 00400 batchs: 615.8555297851562
INFO:root:Train (Epoch 259): Loss/seq after 00450 batchs: 617.8442993164062
INFO:root:Train (Epoch 259): Loss/seq after 00500 batchs: 599.0202026367188
INFO:root:Train (Epoch 259): Loss/seq after 00550 batchs: 584.782958984375
INFO:root:Train (Epoch 259): Loss/seq after 00600 batchs: 566.2872924804688
INFO:root:Train (Epoch 259): Loss/seq after 00650 batchs: 547.7188720703125
INFO:root:Train (Epoch 259): Loss/seq after 00700 batchs: 528.2454833984375
INFO:root:Train (Epoch 259): Loss/seq after 00750 batchs: 528.0731811523438
INFO:root:Train (Epoch 259): Loss/seq after 00800 batchs: 528.7744750976562
INFO:root:Train (Epoch 259): Loss/seq after 00850 batchs: 512.755859375
INFO:root:Train (Epoch 259): Loss/seq after 00900 batchs: 499.4292907714844
INFO:root:Train (Epoch 259): Loss/seq after 00950 batchs: 498.61346435546875
INFO:root:Train (Epoch 259): Loss/seq after 01000 batchs: 490.83221435546875
INFO:root:Train (Epoch 259): Loss/seq after 01050 batchs: 482.29583740234375
INFO:root:Train (Epoch 259): Loss/seq after 01100 batchs: 472.3837585449219
INFO:root:Train (Epoch 259): Loss/seq after 01150 batchs: 460.4287109375
INFO:root:Train (Epoch 259): Loss/seq after 01200 batchs: 463.4544677734375
INFO:root:Train (Epoch 259): Loss/seq after 01250 batchs: 462.03741455078125
INFO:root:Train (Epoch 259): Loss/seq after 01300 batchs: 453.2685852050781
INFO:root:Train (Epoch 259): Loss/seq after 01350 batchs: 444.72265625
INFO:root:Train (Epoch 259): Loss/seq after 01400 batchs: 446.1053161621094
INFO:root:Train (Epoch 259): Loss/seq after 01450 batchs: 449.1258239746094
INFO:root:Train (Epoch 259): Loss/seq after 01500 batchs: 455.3702697753906
INFO:root:Train (Epoch 259): Loss/seq after 01550 batchs: 456.9147033691406
INFO:root:Train (Epoch 259): Loss/seq after 01600 batchs: 453.83880615234375
INFO:root:Train (Epoch 259): Loss/seq after 01650 batchs: 452.10272216796875
INFO:root:Train (Epoch 259): Loss/seq after 01700 batchs: 456.00042724609375
INFO:root:Train (Epoch 259): Loss/seq after 01750 batchs: 454.5682067871094
INFO:root:Train (Epoch 259): Loss/seq after 01800 batchs: 452.6166687011719
INFO:root:Train (Epoch 259): Loss/seq after 01850 batchs: 450.1186828613281
INFO:root:Train (Epoch 259): Loss/seq after 01900 batchs: 448.74505615234375
INFO:root:Train (Epoch 259): Loss/seq after 01950 batchs: 447.720703125
INFO:root:Train (Epoch 259): Loss/seq after 02000 batchs: 448.4358215332031
INFO:root:Train (Epoch 259): Loss/seq after 02050 batchs: 447.6121520996094
INFO:root:Train (Epoch 259): Loss/seq after 02100 batchs: 446.1846618652344
INFO:root:Train (Epoch 259): Loss/seq after 02150 batchs: 445.09759521484375
INFO:root:Train (Epoch 259): Loss/seq after 02200 batchs: 443.7298889160156
INFO:root:Train (Epoch 259): Loss/seq after 02250 batchs: 442.676513671875
INFO:root:Train (Epoch 259): Loss/seq after 02300 batchs: 440.15460205078125
INFO:root:Train (Epoch 259): Loss/seq after 02350 batchs: 437.072998046875
INFO:root:Train (Epoch 259): Loss/seq after 02400 batchs: 438.75506591796875
INFO:root:Train (Epoch 259): Loss/seq after 02450 batchs: 435.3186950683594
INFO:root:Train (Epoch 259): Loss/seq after 02500 batchs: 428.54718017578125
INFO:root:Train (Epoch 259): Loss/seq after 02550 batchs: 423.1772766113281
INFO:root:Train (Epoch 259): Loss/seq after 02600 batchs: 420.5599365234375
INFO:root:Train (Epoch 259): Loss/seq after 02650 batchs: 417.7297668457031
INFO:root:Train (Epoch 259): Loss/seq after 02700 batchs: 415.57171630859375
INFO:root:Train (Epoch 259): Loss/seq after 02750 batchs: 411.8388366699219
INFO:root:Train (Epoch 259): Loss/seq after 02800 batchs: 412.4413146972656
INFO:root:Train (Epoch 259): Loss/seq after 02850 batchs: 412.1595153808594
INFO:root:Train (Epoch 259): Loss/seq after 02900 batchs: 413.27996826171875
INFO:root:Train (Epoch 259): Loss/seq after 02950 batchs: 413.6245422363281
INFO:root:Train (Epoch 259): Loss/seq after 03000 batchs: 418.5948181152344
INFO:root:Train (Epoch 259): Loss/seq after 03050 batchs: 421.01068115234375
INFO:root:Train (Epoch 259): Loss/seq after 03100 batchs: 422.59136962890625
INFO:root:Train (Epoch 259): Loss/seq after 03150 batchs: 423.14141845703125
INFO:root:Train (Epoch 259): Loss/seq after 03200 batchs: 423.5970764160156
INFO:root:Train (Epoch 259): Loss/seq after 03250 batchs: 424.672119140625
INFO:root:Train (Epoch 259): Loss/seq after 03300 batchs: 423.9386901855469
INFO:root:Train (Epoch 259): Loss/seq after 03350 batchs: 421.9141540527344
INFO:root:Train (Epoch 259): Loss/seq after 03400 batchs: 419.3447570800781
INFO:root:Train (Epoch 259): Loss/seq after 03450 batchs: 418.1467590332031
INFO:root:Train (Epoch 259): Loss/seq after 03500 batchs: 418.8713684082031
INFO:root:Train (Epoch 259): Loss/seq after 03550 batchs: 416.9471740722656
INFO:root:Train (Epoch 259): Loss/seq after 03600 batchs: 421.8713073730469
INFO:root:Train (Epoch 259): Loss/seq after 03650 batchs: 420.5793762207031
INFO:root:Train (Epoch 259): Loss/seq after 03700 batchs: 422.71673583984375
INFO:root:Train (Epoch 259): Loss/seq after 03750 batchs: 426.6725158691406
INFO:root:Train (Epoch 259): Loss/seq after 03800 batchs: 425.7659912109375
INFO:root:Train (Epoch 259): Loss/seq after 03850 batchs: 425.1238708496094
INFO:root:Train (Epoch 259): Loss/seq after 03900 batchs: 427.3089904785156
INFO:root:Train (Epoch 259): Loss/seq after 03950 batchs: 430.23406982421875
INFO:root:Train (Epoch 259): Loss/seq after 04000 batchs: 427.4573974609375
INFO:root:Train (Epoch 259): Loss/seq after 04050 batchs: 424.9651794433594
INFO:root:Train (Epoch 259): Loss/seq after 04100 batchs: 424.26702880859375
INFO:root:Train (Epoch 259): Loss/seq after 04150 batchs: 424.2635192871094
INFO:root:Train (Epoch 259): Loss/seq after 04200 batchs: 423.1204833984375
INFO:root:Train (Epoch 259): Loss/seq after 04250 batchs: 421.79803466796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 259): Loss/seq after 00000 batches: 443.3431701660156
INFO:root:# Valid (Epoch 259): Loss/seq after 00050 batches: 689.3680419921875
INFO:root:# Valid (Epoch 259): Loss/seq after 00100 batches: 691.7320556640625
INFO:root:# Valid (Epoch 259): Loss/seq after 00150 batches: 518.0714721679688
INFO:root:# Valid (Epoch 259): Loss/seq after 00200 batches: 475.90447998046875
INFO:root:Artifacts: Make stick videos for epoch 259
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_259_on_20220423_174202.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_259_index_1821_on_20220423_174202.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 260): Loss/seq after 00000 batchs: 641.115478515625
INFO:root:Train (Epoch 260): Loss/seq after 00050 batchs: 584.2904052734375
INFO:root:Train (Epoch 260): Loss/seq after 00100 batchs: 614.1381225585938
INFO:root:Train (Epoch 260): Loss/seq after 00150 batchs: 554.242919921875
INFO:root:Train (Epoch 260): Loss/seq after 00200 batchs: 623.2908935546875
INFO:root:Train (Epoch 260): Loss/seq after 00250 batchs: 650.7698364257812
INFO:root:Train (Epoch 260): Loss/seq after 00300 batchs: 662.4048461914062
INFO:root:Train (Epoch 260): Loss/seq after 00350 batchs: 630.0103149414062
INFO:root:Train (Epoch 260): Loss/seq after 00400 batchs: 628.1428833007812
INFO:root:Train (Epoch 260): Loss/seq after 00450 batchs: 628.2129516601562
INFO:root:Train (Epoch 260): Loss/seq after 00500 batchs: 608.3104248046875
INFO:root:Train (Epoch 260): Loss/seq after 00550 batchs: 593.3939208984375
INFO:root:Train (Epoch 260): Loss/seq after 00600 batchs: 574.1223754882812
INFO:root:Train (Epoch 260): Loss/seq after 00650 batchs: 554.7181396484375
INFO:root:Train (Epoch 260): Loss/seq after 00700 batchs: 533.6735229492188
INFO:root:Train (Epoch 260): Loss/seq after 00750 batchs: 529.4323120117188
INFO:root:Train (Epoch 260): Loss/seq after 00800 batchs: 529.0533447265625
INFO:root:Train (Epoch 260): Loss/seq after 00850 batchs: 512.4260864257812
INFO:root:Train (Epoch 260): Loss/seq after 00900 batchs: 498.5164794921875
INFO:root:Train (Epoch 260): Loss/seq after 00950 batchs: 495.0537414550781
INFO:root:Train (Epoch 260): Loss/seq after 01000 batchs: 487.196044921875
INFO:root:Train (Epoch 260): Loss/seq after 01050 batchs: 477.165771484375
INFO:root:Train (Epoch 260): Loss/seq after 01100 batchs: 468.297607421875
INFO:root:Train (Epoch 260): Loss/seq after 01150 batchs: 456.6493835449219
INFO:root:Train (Epoch 260): Loss/seq after 01200 batchs: 460.31640625
INFO:root:Train (Epoch 260): Loss/seq after 01250 batchs: 459.1395263671875
INFO:root:Train (Epoch 260): Loss/seq after 01300 batchs: 450.4156799316406
INFO:root:Train (Epoch 260): Loss/seq after 01350 batchs: 442.50592041015625
INFO:root:Train (Epoch 260): Loss/seq after 01400 batchs: 444.3291015625
INFO:root:Train (Epoch 260): Loss/seq after 01450 batchs: 447.546875
INFO:root:Train (Epoch 260): Loss/seq after 01500 batchs: 453.4380187988281
INFO:root:Train (Epoch 260): Loss/seq after 01550 batchs: 454.48883056640625
INFO:root:Train (Epoch 260): Loss/seq after 01600 batchs: 451.8847351074219
INFO:root:Train (Epoch 260): Loss/seq after 01650 batchs: 450.31182861328125
INFO:root:Train (Epoch 260): Loss/seq after 01700 batchs: 454.28857421875
INFO:root:Train (Epoch 260): Loss/seq after 01750 batchs: 452.78662109375
INFO:root:Train (Epoch 260): Loss/seq after 01800 batchs: 450.9394226074219
INFO:root:Train (Epoch 260): Loss/seq after 01850 batchs: 448.416748046875
INFO:root:Train (Epoch 260): Loss/seq after 01900 batchs: 447.3106384277344
INFO:root:Train (Epoch 260): Loss/seq after 01950 batchs: 446.5724792480469
INFO:root:Train (Epoch 260): Loss/seq after 02000 batchs: 447.2807922363281
INFO:root:Train (Epoch 260): Loss/seq after 02050 batchs: 446.7771301269531
INFO:root:Train (Epoch 260): Loss/seq after 02100 batchs: 445.5826721191406
INFO:root:Train (Epoch 260): Loss/seq after 02150 batchs: 444.6454162597656
INFO:root:Train (Epoch 260): Loss/seq after 02200 batchs: 443.19781494140625
INFO:root:Train (Epoch 260): Loss/seq after 02250 batchs: 442.2780456542969
INFO:root:Train (Epoch 260): Loss/seq after 02300 batchs: 440.3606872558594
INFO:root:Train (Epoch 260): Loss/seq after 02350 batchs: 437.33294677734375
INFO:root:Train (Epoch 260): Loss/seq after 02400 batchs: 438.89984130859375
INFO:root:Train (Epoch 260): Loss/seq after 02450 batchs: 435.44964599609375
INFO:root:Train (Epoch 260): Loss/seq after 02500 batchs: 428.6761779785156
INFO:root:Train (Epoch 260): Loss/seq after 02550 batchs: 423.2546081542969
INFO:root:Train (Epoch 260): Loss/seq after 02600 batchs: 420.2957458496094
INFO:root:Train (Epoch 260): Loss/seq after 02650 batchs: 417.41650390625
INFO:root:Train (Epoch 260): Loss/seq after 02700 batchs: 415.14788818359375
INFO:root:Train (Epoch 260): Loss/seq after 02750 batchs: 411.37646484375
INFO:root:Train (Epoch 260): Loss/seq after 02800 batchs: 410.85003662109375
INFO:root:Train (Epoch 260): Loss/seq after 02850 batchs: 410.67095947265625
INFO:root:Train (Epoch 260): Loss/seq after 02900 batchs: 411.646484375
INFO:root:Train (Epoch 260): Loss/seq after 02950 batchs: 412.0529479980469
INFO:root:Train (Epoch 260): Loss/seq after 03000 batchs: 416.980224609375
INFO:root:Train (Epoch 260): Loss/seq after 03050 batchs: 419.0041198730469
INFO:root:Train (Epoch 260): Loss/seq after 03100 batchs: 420.872314453125
INFO:root:Train (Epoch 260): Loss/seq after 03150 batchs: 422.1646728515625
INFO:root:Train (Epoch 260): Loss/seq after 03200 batchs: 422.5963134765625
INFO:root:Train (Epoch 260): Loss/seq after 03250 batchs: 424.2657470703125
INFO:root:Train (Epoch 260): Loss/seq after 03300 batchs: 423.7402038574219
INFO:root:Train (Epoch 260): Loss/seq after 03350 batchs: 422.6159973144531
INFO:root:Train (Epoch 260): Loss/seq after 03400 batchs: 420.00146484375
INFO:root:Train (Epoch 260): Loss/seq after 03450 batchs: 418.91363525390625
INFO:root:Train (Epoch 260): Loss/seq after 03500 batchs: 419.82965087890625
INFO:root:Train (Epoch 260): Loss/seq after 03550 batchs: 417.86480712890625
INFO:root:Train (Epoch 260): Loss/seq after 03600 batchs: 423.4809265136719
INFO:root:Train (Epoch 260): Loss/seq after 03650 batchs: 422.0357360839844
INFO:root:Train (Epoch 260): Loss/seq after 03700 batchs: 424.28875732421875
INFO:root:Train (Epoch 260): Loss/seq after 03750 batchs: 428.0903015136719
INFO:root:Train (Epoch 260): Loss/seq after 03800 batchs: 427.1493835449219
INFO:root:Train (Epoch 260): Loss/seq after 03850 batchs: 426.3409729003906
INFO:root:Train (Epoch 260): Loss/seq after 03900 batchs: 428.3529357910156
INFO:root:Train (Epoch 260): Loss/seq after 03950 batchs: 431.4663391113281
INFO:root:Train (Epoch 260): Loss/seq after 04000 batchs: 428.6899719238281
INFO:root:Train (Epoch 260): Loss/seq after 04050 batchs: 426.1930847167969
INFO:root:Train (Epoch 260): Loss/seq after 04100 batchs: 425.4512634277344
INFO:root:Train (Epoch 260): Loss/seq after 04150 batchs: 425.4967346191406
INFO:root:Train (Epoch 260): Loss/seq after 04200 batchs: 424.3217468261719
INFO:root:Train (Epoch 260): Loss/seq after 04250 batchs: 422.9447021484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 260): Loss/seq after 00000 batches: 386.4963684082031
INFO:root:# Valid (Epoch 260): Loss/seq after 00050 batches: 657.5582885742188
INFO:root:# Valid (Epoch 260): Loss/seq after 00100 batches: 672.860107421875
INFO:root:# Valid (Epoch 260): Loss/seq after 00150 batches: 503.5232849121094
INFO:root:# Valid (Epoch 260): Loss/seq after 00200 batches: 460.83038330078125
INFO:root:Artifacts: Make stick videos for epoch 260
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_260_on_20220423_174656.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_260_index_694_on_20220423_174656.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 261): Loss/seq after 00000 batchs: 764.596435546875
INFO:root:Train (Epoch 261): Loss/seq after 00050 batchs: 564.6760864257812
INFO:root:Train (Epoch 261): Loss/seq after 00100 batchs: 579.4889526367188
INFO:root:Train (Epoch 261): Loss/seq after 00150 batchs: 526.9273681640625
INFO:root:Train (Epoch 261): Loss/seq after 00200 batchs: 608.66357421875
INFO:root:Train (Epoch 261): Loss/seq after 00250 batchs: 636.4285888671875
INFO:root:Train (Epoch 261): Loss/seq after 00300 batchs: 648.5223999023438
INFO:root:Train (Epoch 261): Loss/seq after 00350 batchs: 617.4278564453125
INFO:root:Train (Epoch 261): Loss/seq after 00400 batchs: 610.3259887695312
INFO:root:Train (Epoch 261): Loss/seq after 00450 batchs: 612.7252807617188
INFO:root:Train (Epoch 261): Loss/seq after 00500 batchs: 594.1504516601562
INFO:root:Train (Epoch 261): Loss/seq after 00550 batchs: 580.4212036132812
INFO:root:Train (Epoch 261): Loss/seq after 00600 batchs: 561.931396484375
INFO:root:Train (Epoch 261): Loss/seq after 00650 batchs: 544.8142700195312
INFO:root:Train (Epoch 261): Loss/seq after 00700 batchs: 524.8705444335938
INFO:root:Train (Epoch 261): Loss/seq after 00750 batchs: 520.39697265625
INFO:root:Train (Epoch 261): Loss/seq after 00800 batchs: 521.4725341796875
INFO:root:Train (Epoch 261): Loss/seq after 00850 batchs: 505.8841857910156
INFO:root:Train (Epoch 261): Loss/seq after 00900 batchs: 492.9981689453125
INFO:root:Train (Epoch 261): Loss/seq after 00950 batchs: 491.2313232421875
INFO:root:Train (Epoch 261): Loss/seq after 01000 batchs: 483.42962646484375
INFO:root:Train (Epoch 261): Loss/seq after 01050 batchs: 476.1053466796875
INFO:root:Train (Epoch 261): Loss/seq after 01100 batchs: 467.43267822265625
INFO:root:Train (Epoch 261): Loss/seq after 01150 batchs: 455.6844177246094
INFO:root:Train (Epoch 261): Loss/seq after 01200 batchs: 458.3423156738281
INFO:root:Train (Epoch 261): Loss/seq after 01250 batchs: 457.5362243652344
INFO:root:Train (Epoch 261): Loss/seq after 01300 batchs: 448.78466796875
INFO:root:Train (Epoch 261): Loss/seq after 01350 batchs: 440.5357971191406
INFO:root:Train (Epoch 261): Loss/seq after 01400 batchs: 442.7637023925781
INFO:root:Train (Epoch 261): Loss/seq after 01450 batchs: 446.1891784667969
INFO:root:Train (Epoch 261): Loss/seq after 01500 batchs: 452.2690124511719
INFO:root:Train (Epoch 261): Loss/seq after 01550 batchs: 454.0067443847656
INFO:root:Train (Epoch 261): Loss/seq after 01600 batchs: 451.1040954589844
INFO:root:Train (Epoch 261): Loss/seq after 01650 batchs: 449.0321960449219
INFO:root:Train (Epoch 261): Loss/seq after 01700 batchs: 452.73931884765625
INFO:root:Train (Epoch 261): Loss/seq after 01750 batchs: 451.302001953125
INFO:root:Train (Epoch 261): Loss/seq after 01800 batchs: 449.4919738769531
INFO:root:Train (Epoch 261): Loss/seq after 01850 batchs: 446.7995910644531
INFO:root:Train (Epoch 261): Loss/seq after 01900 batchs: 445.6860656738281
INFO:root:Train (Epoch 261): Loss/seq after 01950 batchs: 445.0237121582031
INFO:root:Train (Epoch 261): Loss/seq after 02000 batchs: 445.724609375
INFO:root:Train (Epoch 261): Loss/seq after 02050 batchs: 445.2401428222656
INFO:root:Train (Epoch 261): Loss/seq after 02100 batchs: 443.7445068359375
INFO:root:Train (Epoch 261): Loss/seq after 02150 batchs: 442.79901123046875
INFO:root:Train (Epoch 261): Loss/seq after 02200 batchs: 441.3653869628906
INFO:root:Train (Epoch 261): Loss/seq after 02250 batchs: 440.3293762207031
INFO:root:Train (Epoch 261): Loss/seq after 02300 batchs: 438.1007995605469
INFO:root:Train (Epoch 261): Loss/seq after 02350 batchs: 435.04132080078125
INFO:root:Train (Epoch 261): Loss/seq after 02400 batchs: 436.9451904296875
INFO:root:Train (Epoch 261): Loss/seq after 02450 batchs: 433.46429443359375
INFO:root:Train (Epoch 261): Loss/seq after 02500 batchs: 426.72265625
INFO:root:Train (Epoch 261): Loss/seq after 02550 batchs: 421.27923583984375
INFO:root:Train (Epoch 261): Loss/seq after 02600 batchs: 417.9902038574219
INFO:root:Train (Epoch 261): Loss/seq after 02650 batchs: 415.0144348144531
INFO:root:Train (Epoch 261): Loss/seq after 02700 batchs: 412.72369384765625
INFO:root:Train (Epoch 261): Loss/seq after 02750 batchs: 408.3567810058594
INFO:root:Train (Epoch 261): Loss/seq after 02800 batchs: 407.44073486328125
INFO:root:Train (Epoch 261): Loss/seq after 02850 batchs: 407.26324462890625
INFO:root:Train (Epoch 261): Loss/seq after 02900 batchs: 408.3587951660156
INFO:root:Train (Epoch 261): Loss/seq after 02950 batchs: 408.8004150390625
INFO:root:Train (Epoch 261): Loss/seq after 03000 batchs: 413.8625183105469
INFO:root:Train (Epoch 261): Loss/seq after 03050 batchs: 415.9620666503906
INFO:root:Train (Epoch 261): Loss/seq after 03100 batchs: 417.8406982421875
INFO:root:Train (Epoch 261): Loss/seq after 03150 batchs: 418.4716491699219
INFO:root:Train (Epoch 261): Loss/seq after 03200 batchs: 418.76934814453125
INFO:root:Train (Epoch 261): Loss/seq after 03250 batchs: 420.17852783203125
INFO:root:Train (Epoch 261): Loss/seq after 03300 batchs: 419.33563232421875
INFO:root:Train (Epoch 261): Loss/seq after 03350 batchs: 417.7963562011719
INFO:root:Train (Epoch 261): Loss/seq after 03400 batchs: 415.25323486328125
INFO:root:Train (Epoch 261): Loss/seq after 03450 batchs: 413.9626159667969
INFO:root:Train (Epoch 261): Loss/seq after 03500 batchs: 414.7359619140625
INFO:root:Train (Epoch 261): Loss/seq after 03550 batchs: 412.906005859375
INFO:root:Train (Epoch 261): Loss/seq after 03600 batchs: 418.1697692871094
INFO:root:Train (Epoch 261): Loss/seq after 03650 batchs: 417.0028991699219
INFO:root:Train (Epoch 261): Loss/seq after 03700 batchs: 419.3178405761719
INFO:root:Train (Epoch 261): Loss/seq after 03750 batchs: 423.22552490234375
INFO:root:Train (Epoch 261): Loss/seq after 03800 batchs: 422.2967834472656
INFO:root:Train (Epoch 261): Loss/seq after 03850 batchs: 421.5478515625
INFO:root:Train (Epoch 261): Loss/seq after 03900 batchs: 423.276123046875
INFO:root:Train (Epoch 261): Loss/seq after 03950 batchs: 426.1351623535156
INFO:root:Train (Epoch 261): Loss/seq after 04000 batchs: 423.44000244140625
INFO:root:Train (Epoch 261): Loss/seq after 04050 batchs: 420.97796630859375
INFO:root:Train (Epoch 261): Loss/seq after 04100 batchs: 420.34808349609375
INFO:root:Train (Epoch 261): Loss/seq after 04150 batchs: 420.3595886230469
INFO:root:Train (Epoch 261): Loss/seq after 04200 batchs: 419.27874755859375
INFO:root:Train (Epoch 261): Loss/seq after 04250 batchs: 418.1468200683594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 261): Loss/seq after 00000 batches: 403.5002136230469
INFO:root:# Valid (Epoch 261): Loss/seq after 00050 batches: 709.3635864257812
INFO:root:# Valid (Epoch 261): Loss/seq after 00100 batches: 691.6577758789062
INFO:root:# Valid (Epoch 261): Loss/seq after 00150 batches: 516.6288452148438
INFO:root:# Valid (Epoch 261): Loss/seq after 00200 batches: 472.161376953125
INFO:root:Artifacts: Make stick videos for epoch 261
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_261_on_20220423_175159.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_261_index_320_on_20220423_175159.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 262): Loss/seq after 00000 batchs: 763.5057983398438
INFO:root:Train (Epoch 262): Loss/seq after 00050 batchs: 560.8563842773438
INFO:root:Train (Epoch 262): Loss/seq after 00100 batchs: 570.2714233398438
INFO:root:Train (Epoch 262): Loss/seq after 00150 batchs: 518.79443359375
INFO:root:Train (Epoch 262): Loss/seq after 00200 batchs: 584.82568359375
INFO:root:Train (Epoch 262): Loss/seq after 00250 batchs: 613.7017822265625
INFO:root:Train (Epoch 262): Loss/seq after 00300 batchs: 630.9609375
INFO:root:Train (Epoch 262): Loss/seq after 00350 batchs: 600.7088623046875
INFO:root:Train (Epoch 262): Loss/seq after 00400 batchs: 597.3858032226562
INFO:root:Train (Epoch 262): Loss/seq after 00450 batchs: 601.0821533203125
INFO:root:Train (Epoch 262): Loss/seq after 00500 batchs: 583.5828857421875
INFO:root:Train (Epoch 262): Loss/seq after 00550 batchs: 570.4345092773438
INFO:root:Train (Epoch 262): Loss/seq after 00600 batchs: 551.63671875
INFO:root:Train (Epoch 262): Loss/seq after 00650 batchs: 532.5678100585938
INFO:root:Train (Epoch 262): Loss/seq after 00700 batchs: 513.1126098632812
INFO:root:Train (Epoch 262): Loss/seq after 00750 batchs: 512.8385009765625
INFO:root:Train (Epoch 262): Loss/seq after 00800 batchs: 515.2062377929688
INFO:root:Train (Epoch 262): Loss/seq after 00850 batchs: 500.2229309082031
INFO:root:Train (Epoch 262): Loss/seq after 00900 batchs: 487.22406005859375
INFO:root:Train (Epoch 262): Loss/seq after 00950 batchs: 485.27972412109375
INFO:root:Train (Epoch 262): Loss/seq after 01000 batchs: 477.7822265625
INFO:root:Train (Epoch 262): Loss/seq after 01050 batchs: 468.2107849121094
INFO:root:Train (Epoch 262): Loss/seq after 01100 batchs: 458.6419982910156
INFO:root:Train (Epoch 262): Loss/seq after 01150 batchs: 447.0438232421875
INFO:root:Train (Epoch 262): Loss/seq after 01200 batchs: 449.22674560546875
INFO:root:Train (Epoch 262): Loss/seq after 01250 batchs: 448.6181945800781
INFO:root:Train (Epoch 262): Loss/seq after 01300 batchs: 439.9530029296875
INFO:root:Train (Epoch 262): Loss/seq after 01350 batchs: 431.83306884765625
INFO:root:Train (Epoch 262): Loss/seq after 01400 batchs: 432.9042053222656
INFO:root:Train (Epoch 262): Loss/seq after 01450 batchs: 436.3915710449219
INFO:root:Train (Epoch 262): Loss/seq after 01500 batchs: 442.6007385253906
INFO:root:Train (Epoch 262): Loss/seq after 01550 batchs: 443.77947998046875
INFO:root:Train (Epoch 262): Loss/seq after 01600 batchs: 440.93585205078125
INFO:root:Train (Epoch 262): Loss/seq after 01650 batchs: 439.01129150390625
INFO:root:Train (Epoch 262): Loss/seq after 01700 batchs: 443.03741455078125
INFO:root:Train (Epoch 262): Loss/seq after 01750 batchs: 441.5508117675781
INFO:root:Train (Epoch 262): Loss/seq after 01800 batchs: 439.71142578125
INFO:root:Train (Epoch 262): Loss/seq after 01850 batchs: 437.31243896484375
INFO:root:Train (Epoch 262): Loss/seq after 01900 batchs: 436.23193359375
INFO:root:Train (Epoch 262): Loss/seq after 01950 batchs: 435.7222595214844
INFO:root:Train (Epoch 262): Loss/seq after 02000 batchs: 436.82745361328125
INFO:root:Train (Epoch 262): Loss/seq after 02050 batchs: 436.5523681640625
INFO:root:Train (Epoch 262): Loss/seq after 02100 batchs: 435.48760986328125
INFO:root:Train (Epoch 262): Loss/seq after 02150 batchs: 434.59466552734375
INFO:root:Train (Epoch 262): Loss/seq after 02200 batchs: 433.3809814453125
INFO:root:Train (Epoch 262): Loss/seq after 02250 batchs: 432.42523193359375
INFO:root:Train (Epoch 262): Loss/seq after 02300 batchs: 431.28326416015625
INFO:root:Train (Epoch 262): Loss/seq after 02350 batchs: 428.42816162109375
INFO:root:Train (Epoch 262): Loss/seq after 02400 batchs: 430.09844970703125
INFO:root:Train (Epoch 262): Loss/seq after 02450 batchs: 426.7372131347656
INFO:root:Train (Epoch 262): Loss/seq after 02500 batchs: 420.15069580078125
INFO:root:Train (Epoch 262): Loss/seq after 02550 batchs: 414.8747863769531
INFO:root:Train (Epoch 262): Loss/seq after 02600 batchs: 411.9288635253906
INFO:root:Train (Epoch 262): Loss/seq after 02650 batchs: 409.04473876953125
INFO:root:Train (Epoch 262): Loss/seq after 02700 batchs: 407.1311340332031
INFO:root:Train (Epoch 262): Loss/seq after 02750 batchs: 402.89959716796875
INFO:root:Train (Epoch 262): Loss/seq after 02800 batchs: 402.4290771484375
INFO:root:Train (Epoch 262): Loss/seq after 02850 batchs: 402.56036376953125
INFO:root:Train (Epoch 262): Loss/seq after 02900 batchs: 403.8482971191406
INFO:root:Train (Epoch 262): Loss/seq after 02950 batchs: 404.32159423828125
INFO:root:Train (Epoch 262): Loss/seq after 03000 batchs: 409.5911560058594
INFO:root:Train (Epoch 262): Loss/seq after 03050 batchs: 411.54400634765625
INFO:root:Train (Epoch 262): Loss/seq after 03100 batchs: 413.6384582519531
INFO:root:Train (Epoch 262): Loss/seq after 03150 batchs: 415.8851623535156
INFO:root:Train (Epoch 262): Loss/seq after 03200 batchs: 416.4543151855469
INFO:root:Train (Epoch 262): Loss/seq after 03250 batchs: 417.5519104003906
INFO:root:Train (Epoch 262): Loss/seq after 03300 batchs: 416.96258544921875
INFO:root:Train (Epoch 262): Loss/seq after 03350 batchs: 415.56884765625
INFO:root:Train (Epoch 262): Loss/seq after 03400 batchs: 413.14312744140625
INFO:root:Train (Epoch 262): Loss/seq after 03450 batchs: 412.1016845703125
INFO:root:Train (Epoch 262): Loss/seq after 03500 batchs: 413.0332336425781
INFO:root:Train (Epoch 262): Loss/seq after 03550 batchs: 411.1007080078125
INFO:root:Train (Epoch 262): Loss/seq after 03600 batchs: 416.43359375
INFO:root:Train (Epoch 262): Loss/seq after 03650 batchs: 415.5088195800781
INFO:root:Train (Epoch 262): Loss/seq after 03700 batchs: 418.00445556640625
INFO:root:Train (Epoch 262): Loss/seq after 03750 batchs: 421.9515075683594
INFO:root:Train (Epoch 262): Loss/seq after 03800 batchs: 421.0917053222656
INFO:root:Train (Epoch 262): Loss/seq after 03850 batchs: 420.3995361328125
INFO:root:Train (Epoch 262): Loss/seq after 03900 batchs: 422.93255615234375
INFO:root:Train (Epoch 262): Loss/seq after 03950 batchs: 426.0468444824219
INFO:root:Train (Epoch 262): Loss/seq after 04000 batchs: 423.34173583984375
INFO:root:Train (Epoch 262): Loss/seq after 04050 batchs: 420.918212890625
INFO:root:Train (Epoch 262): Loss/seq after 04100 batchs: 420.2966003417969
INFO:root:Train (Epoch 262): Loss/seq after 04150 batchs: 420.375
INFO:root:Train (Epoch 262): Loss/seq after 04200 batchs: 419.2371520996094
INFO:root:Train (Epoch 262): Loss/seq after 04250 batchs: 417.9945983886719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 262): Loss/seq after 00000 batches: 347.1724548339844
INFO:root:# Valid (Epoch 262): Loss/seq after 00050 batches: 690.3854370117188
INFO:root:# Valid (Epoch 262): Loss/seq after 00100 batches: 692.1907958984375
INFO:root:# Valid (Epoch 262): Loss/seq after 00150 batches: 516.993408203125
INFO:root:# Valid (Epoch 262): Loss/seq after 00200 batches: 472.3476257324219
INFO:root:Artifacts: Make stick videos for epoch 262
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_262_on_20220423_175647.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_262_index_766_on_20220423_175647.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 263): Loss/seq after 00000 batchs: 600.8126220703125
INFO:root:Train (Epoch 263): Loss/seq after 00050 batchs: 562.7946166992188
INFO:root:Train (Epoch 263): Loss/seq after 00100 batchs: 589.1510009765625
INFO:root:Train (Epoch 263): Loss/seq after 00150 batchs: 532.8047485351562
INFO:root:Train (Epoch 263): Loss/seq after 00200 batchs: 596.5416259765625
INFO:root:Train (Epoch 263): Loss/seq after 00250 batchs: 637.5431518554688
INFO:root:Train (Epoch 263): Loss/seq after 00300 batchs: 649.1695556640625
INFO:root:Train (Epoch 263): Loss/seq after 00350 batchs: 615.7010498046875
INFO:root:Train (Epoch 263): Loss/seq after 00400 batchs: 610.463134765625
INFO:root:Train (Epoch 263): Loss/seq after 00450 batchs: 612.46435546875
INFO:root:Train (Epoch 263): Loss/seq after 00500 batchs: 595.3381958007812
INFO:root:Train (Epoch 263): Loss/seq after 00550 batchs: 581.6283569335938
INFO:root:Train (Epoch 263): Loss/seq after 00600 batchs: 562.4972534179688
INFO:root:Train (Epoch 263): Loss/seq after 00650 batchs: 544.1981201171875
INFO:root:Train (Epoch 263): Loss/seq after 00700 batchs: 524.48291015625
INFO:root:Train (Epoch 263): Loss/seq after 00750 batchs: 523.2860717773438
INFO:root:Train (Epoch 263): Loss/seq after 00800 batchs: 523.7394409179688
INFO:root:Train (Epoch 263): Loss/seq after 00850 batchs: 508.1234436035156
INFO:root:Train (Epoch 263): Loss/seq after 00900 batchs: 495.4445495605469
INFO:root:Train (Epoch 263): Loss/seq after 00950 batchs: 494.4269104003906
INFO:root:Train (Epoch 263): Loss/seq after 01000 batchs: 487.4447937011719
INFO:root:Train (Epoch 263): Loss/seq after 01050 batchs: 477.32373046875
INFO:root:Train (Epoch 263): Loss/seq after 01100 batchs: 467.9726867675781
INFO:root:Train (Epoch 263): Loss/seq after 01150 batchs: 456.18011474609375
INFO:root:Train (Epoch 263): Loss/seq after 01200 batchs: 458.5126953125
INFO:root:Train (Epoch 263): Loss/seq after 01250 batchs: 457.3486633300781
INFO:root:Train (Epoch 263): Loss/seq after 01300 batchs: 448.5186462402344
INFO:root:Train (Epoch 263): Loss/seq after 01350 batchs: 440.4109802246094
INFO:root:Train (Epoch 263): Loss/seq after 01400 batchs: 442.227294921875
INFO:root:Train (Epoch 263): Loss/seq after 01450 batchs: 445.60772705078125
INFO:root:Train (Epoch 263): Loss/seq after 01500 batchs: 451.35693359375
INFO:root:Train (Epoch 263): Loss/seq after 01550 batchs: 452.45050048828125
INFO:root:Train (Epoch 263): Loss/seq after 01600 batchs: 449.5206298828125
INFO:root:Train (Epoch 263): Loss/seq after 01650 batchs: 447.3670654296875
INFO:root:Train (Epoch 263): Loss/seq after 01700 batchs: 451.0279235839844
INFO:root:Train (Epoch 263): Loss/seq after 01750 batchs: 449.5916442871094
INFO:root:Train (Epoch 263): Loss/seq after 01800 batchs: 447.56103515625
INFO:root:Train (Epoch 263): Loss/seq after 01850 batchs: 445.0104064941406
INFO:root:Train (Epoch 263): Loss/seq after 01900 batchs: 443.6210021972656
INFO:root:Train (Epoch 263): Loss/seq after 01950 batchs: 442.5450439453125
INFO:root:Train (Epoch 263): Loss/seq after 02000 batchs: 443.3807678222656
INFO:root:Train (Epoch 263): Loss/seq after 02050 batchs: 442.7799072265625
INFO:root:Train (Epoch 263): Loss/seq after 02100 batchs: 441.2851257324219
INFO:root:Train (Epoch 263): Loss/seq after 02150 batchs: 440.3884582519531
INFO:root:Train (Epoch 263): Loss/seq after 02200 batchs: 438.9728698730469
INFO:root:Train (Epoch 263): Loss/seq after 02250 batchs: 438.0233154296875
INFO:root:Train (Epoch 263): Loss/seq after 02300 batchs: 435.4139404296875
INFO:root:Train (Epoch 263): Loss/seq after 02350 batchs: 432.3503723144531
INFO:root:Train (Epoch 263): Loss/seq after 02400 batchs: 434.20849609375
INFO:root:Train (Epoch 263): Loss/seq after 02450 batchs: 430.6739501953125
INFO:root:Train (Epoch 263): Loss/seq after 02500 batchs: 423.9607238769531
INFO:root:Train (Epoch 263): Loss/seq after 02550 batchs: 418.6380920410156
INFO:root:Train (Epoch 263): Loss/seq after 02600 batchs: 415.4496154785156
INFO:root:Train (Epoch 263): Loss/seq after 02650 batchs: 412.4706115722656
INFO:root:Train (Epoch 263): Loss/seq after 02700 batchs: 410.36395263671875
INFO:root:Train (Epoch 263): Loss/seq after 02750 batchs: 406.55291748046875
INFO:root:Train (Epoch 263): Loss/seq after 02800 batchs: 405.4622497558594
INFO:root:Train (Epoch 263): Loss/seq after 02850 batchs: 405.2325134277344
INFO:root:Train (Epoch 263): Loss/seq after 02900 batchs: 406.421142578125
INFO:root:Train (Epoch 263): Loss/seq after 02950 batchs: 406.75579833984375
INFO:root:Train (Epoch 263): Loss/seq after 03000 batchs: 411.6473083496094
INFO:root:Train (Epoch 263): Loss/seq after 03050 batchs: 413.5366516113281
INFO:root:Train (Epoch 263): Loss/seq after 03100 batchs: 415.46649169921875
INFO:root:Train (Epoch 263): Loss/seq after 03150 batchs: 417.128662109375
INFO:root:Train (Epoch 263): Loss/seq after 03200 batchs: 417.4880065917969
INFO:root:Train (Epoch 263): Loss/seq after 03250 batchs: 418.33746337890625
INFO:root:Train (Epoch 263): Loss/seq after 03300 batchs: 417.60076904296875
INFO:root:Train (Epoch 263): Loss/seq after 03350 batchs: 416.20819091796875
INFO:root:Train (Epoch 263): Loss/seq after 03400 batchs: 413.5787353515625
INFO:root:Train (Epoch 263): Loss/seq after 03450 batchs: 412.3089294433594
INFO:root:Train (Epoch 263): Loss/seq after 03500 batchs: 413.3289794921875
INFO:root:Train (Epoch 263): Loss/seq after 03550 batchs: 411.4100036621094
INFO:root:Train (Epoch 263): Loss/seq after 03600 batchs: 416.1651916503906
INFO:root:Train (Epoch 263): Loss/seq after 03650 batchs: 414.75152587890625
INFO:root:Train (Epoch 263): Loss/seq after 03700 batchs: 417.1322937011719
INFO:root:Train (Epoch 263): Loss/seq after 03750 batchs: 421.1377868652344
INFO:root:Train (Epoch 263): Loss/seq after 03800 batchs: 420.2665710449219
INFO:root:Train (Epoch 263): Loss/seq after 03850 batchs: 419.6038818359375
INFO:root:Train (Epoch 263): Loss/seq after 03900 batchs: 421.7719421386719
INFO:root:Train (Epoch 263): Loss/seq after 03950 batchs: 425.1156311035156
INFO:root:Train (Epoch 263): Loss/seq after 04000 batchs: 422.36480712890625
INFO:root:Train (Epoch 263): Loss/seq after 04050 batchs: 419.91253662109375
INFO:root:Train (Epoch 263): Loss/seq after 04100 batchs: 419.23016357421875
INFO:root:Train (Epoch 263): Loss/seq after 04150 batchs: 419.2548522949219
INFO:root:Train (Epoch 263): Loss/seq after 04200 batchs: 418.1413879394531
INFO:root:Train (Epoch 263): Loss/seq after 04250 batchs: 416.8438415527344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 263): Loss/seq after 00000 batches: 382.9866027832031
INFO:root:# Valid (Epoch 263): Loss/seq after 00050 batches: 700.7958374023438
INFO:root:# Valid (Epoch 263): Loss/seq after 00100 batches: 713.43115234375
INFO:root:# Valid (Epoch 263): Loss/seq after 00150 batches: 530.7814331054688
INFO:root:# Valid (Epoch 263): Loss/seq after 00200 batches: 482.5541076660156
INFO:root:Artifacts: Make stick videos for epoch 263
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_263_on_20220423_180138.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_263_index_1001_on_20220423_180138.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 264): Loss/seq after 00000 batchs: 692.3473510742188
INFO:root:Train (Epoch 264): Loss/seq after 00050 batchs: 579.9903564453125
INFO:root:Train (Epoch 264): Loss/seq after 00100 batchs: 580.931884765625
INFO:root:Train (Epoch 264): Loss/seq after 00150 batchs: 527.627197265625
INFO:root:Train (Epoch 264): Loss/seq after 00200 batchs: 597.5363159179688
INFO:root:Train (Epoch 264): Loss/seq after 00250 batchs: 631.8822631835938
INFO:root:Train (Epoch 264): Loss/seq after 00300 batchs: 643.0476684570312
INFO:root:Train (Epoch 264): Loss/seq after 00350 batchs: 611.5576171875
INFO:root:Train (Epoch 264): Loss/seq after 00400 batchs: 600.5560913085938
INFO:root:Train (Epoch 264): Loss/seq after 00450 batchs: 603.5676879882812
INFO:root:Train (Epoch 264): Loss/seq after 00500 batchs: 584.8663330078125
INFO:root:Train (Epoch 264): Loss/seq after 00550 batchs: 571.2520141601562
INFO:root:Train (Epoch 264): Loss/seq after 00600 batchs: 552.2916259765625
INFO:root:Train (Epoch 264): Loss/seq after 00650 batchs: 537.2999267578125
INFO:root:Train (Epoch 264): Loss/seq after 00700 batchs: 519.320068359375
INFO:root:Train (Epoch 264): Loss/seq after 00750 batchs: 519.4848022460938
INFO:root:Train (Epoch 264): Loss/seq after 00800 batchs: 519.95361328125
INFO:root:Train (Epoch 264): Loss/seq after 00850 batchs: 503.7919921875
INFO:root:Train (Epoch 264): Loss/seq after 00900 batchs: 490.8437194824219
INFO:root:Train (Epoch 264): Loss/seq after 00950 batchs: 489.859130859375
INFO:root:Train (Epoch 264): Loss/seq after 01000 batchs: 482.2232360839844
INFO:root:Train (Epoch 264): Loss/seq after 01050 batchs: 473.6966247558594
INFO:root:Train (Epoch 264): Loss/seq after 01100 batchs: 464.34674072265625
INFO:root:Train (Epoch 264): Loss/seq after 01150 batchs: 452.82623291015625
INFO:root:Train (Epoch 264): Loss/seq after 01200 batchs: 454.8930969238281
INFO:root:Train (Epoch 264): Loss/seq after 01250 batchs: 453.72906494140625
INFO:root:Train (Epoch 264): Loss/seq after 01300 batchs: 445.3489685058594
INFO:root:Train (Epoch 264): Loss/seq after 01350 batchs: 436.9916076660156
INFO:root:Train (Epoch 264): Loss/seq after 01400 batchs: 439.93072509765625
INFO:root:Train (Epoch 264): Loss/seq after 01450 batchs: 443.3221435546875
INFO:root:Train (Epoch 264): Loss/seq after 01500 batchs: 449.4077453613281
INFO:root:Train (Epoch 264): Loss/seq after 01550 batchs: 450.8919982910156
INFO:root:Train (Epoch 264): Loss/seq after 01600 batchs: 448.0368957519531
INFO:root:Train (Epoch 264): Loss/seq after 01650 batchs: 445.8663024902344
INFO:root:Train (Epoch 264): Loss/seq after 01700 batchs: 449.5809631347656
INFO:root:Train (Epoch 264): Loss/seq after 01750 batchs: 448.1817321777344
INFO:root:Train (Epoch 264): Loss/seq after 01800 batchs: 446.36529541015625
INFO:root:Train (Epoch 264): Loss/seq after 01850 batchs: 443.7822570800781
INFO:root:Train (Epoch 264): Loss/seq after 01900 batchs: 442.3213806152344
INFO:root:Train (Epoch 264): Loss/seq after 01950 batchs: 441.4081726074219
INFO:root:Train (Epoch 264): Loss/seq after 02000 batchs: 442.2325744628906
INFO:root:Train (Epoch 264): Loss/seq after 02050 batchs: 441.6847839355469
INFO:root:Train (Epoch 264): Loss/seq after 02100 batchs: 440.27734375
INFO:root:Train (Epoch 264): Loss/seq after 02150 batchs: 439.22625732421875
INFO:root:Train (Epoch 264): Loss/seq after 02200 batchs: 437.84490966796875
INFO:root:Train (Epoch 264): Loss/seq after 02250 batchs: 436.6688537597656
INFO:root:Train (Epoch 264): Loss/seq after 02300 batchs: 434.31304931640625
INFO:root:Train (Epoch 264): Loss/seq after 02350 batchs: 431.31671142578125
INFO:root:Train (Epoch 264): Loss/seq after 02400 batchs: 432.7443542480469
INFO:root:Train (Epoch 264): Loss/seq after 02450 batchs: 429.1579284667969
INFO:root:Train (Epoch 264): Loss/seq after 02500 batchs: 422.4189758300781
INFO:root:Train (Epoch 264): Loss/seq after 02550 batchs: 417.0514831542969
INFO:root:Train (Epoch 264): Loss/seq after 02600 batchs: 413.80596923828125
INFO:root:Train (Epoch 264): Loss/seq after 02650 batchs: 410.7004089355469
INFO:root:Train (Epoch 264): Loss/seq after 02700 batchs: 408.57293701171875
INFO:root:Train (Epoch 264): Loss/seq after 02750 batchs: 404.4224548339844
INFO:root:Train (Epoch 264): Loss/seq after 02800 batchs: 403.5477600097656
INFO:root:Train (Epoch 264): Loss/seq after 02850 batchs: 403.26226806640625
INFO:root:Train (Epoch 264): Loss/seq after 02900 batchs: 404.330810546875
INFO:root:Train (Epoch 264): Loss/seq after 02950 batchs: 404.8038024902344
INFO:root:Train (Epoch 264): Loss/seq after 03000 batchs: 409.8288879394531
INFO:root:Train (Epoch 264): Loss/seq after 03050 batchs: 411.8021240234375
INFO:root:Train (Epoch 264): Loss/seq after 03100 batchs: 413.654296875
INFO:root:Train (Epoch 264): Loss/seq after 03150 batchs: 414.8129577636719
INFO:root:Train (Epoch 264): Loss/seq after 03200 batchs: 415.5331115722656
INFO:root:Train (Epoch 264): Loss/seq after 03250 batchs: 416.7612609863281
INFO:root:Train (Epoch 264): Loss/seq after 03300 batchs: 415.98443603515625
INFO:root:Train (Epoch 264): Loss/seq after 03350 batchs: 414.4361572265625
INFO:root:Train (Epoch 264): Loss/seq after 03400 batchs: 411.8292541503906
INFO:root:Train (Epoch 264): Loss/seq after 03450 batchs: 410.6123046875
INFO:root:Train (Epoch 264): Loss/seq after 03500 batchs: 411.3110046386719
INFO:root:Train (Epoch 264): Loss/seq after 03550 batchs: 409.3910217285156
INFO:root:Train (Epoch 264): Loss/seq after 03600 batchs: 414.45513916015625
INFO:root:Train (Epoch 264): Loss/seq after 03650 batchs: 413.0467834472656
INFO:root:Train (Epoch 264): Loss/seq after 03700 batchs: 415.23388671875
INFO:root:Train (Epoch 264): Loss/seq after 03750 batchs: 419.0228271484375
INFO:root:Train (Epoch 264): Loss/seq after 03800 batchs: 418.2112121582031
INFO:root:Train (Epoch 264): Loss/seq after 03850 batchs: 417.68817138671875
INFO:root:Train (Epoch 264): Loss/seq after 03900 batchs: 419.0632019042969
INFO:root:Train (Epoch 264): Loss/seq after 03950 batchs: 421.9610900878906
INFO:root:Train (Epoch 264): Loss/seq after 04000 batchs: 419.2667541503906
INFO:root:Train (Epoch 264): Loss/seq after 04050 batchs: 416.8524169921875
INFO:root:Train (Epoch 264): Loss/seq after 04100 batchs: 416.2436218261719
INFO:root:Train (Epoch 264): Loss/seq after 04150 batchs: 416.3155822753906
INFO:root:Train (Epoch 264): Loss/seq after 04200 batchs: 415.1924743652344
INFO:root:Train (Epoch 264): Loss/seq after 04250 batchs: 413.9424743652344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 264): Loss/seq after 00000 batches: 413.2486267089844
INFO:root:# Valid (Epoch 264): Loss/seq after 00050 batches: 704.1651000976562
INFO:root:# Valid (Epoch 264): Loss/seq after 00100 batches: 702.8328247070312
INFO:root:# Valid (Epoch 264): Loss/seq after 00150 batches: 523.9150390625
INFO:root:# Valid (Epoch 264): Loss/seq after 00200 batches: 475.8880615234375
INFO:root:Artifacts: Make stick videos for epoch 264
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_264_on_20220423_180621.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_264_index_236_on_20220423_180621.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 265): Loss/seq after 00000 batchs: 998.53271484375
INFO:root:Train (Epoch 265): Loss/seq after 00050 batchs: 547.3344116210938
INFO:root:Train (Epoch 265): Loss/seq after 00100 batchs: 570.207275390625
INFO:root:Train (Epoch 265): Loss/seq after 00150 batchs: 521.6577758789062
INFO:root:Train (Epoch 265): Loss/seq after 00200 batchs: 590.0748291015625
INFO:root:Train (Epoch 265): Loss/seq after 00250 batchs: 633.295654296875
INFO:root:Train (Epoch 265): Loss/seq after 00300 batchs: 645.8792114257812
INFO:root:Train (Epoch 265): Loss/seq after 00350 batchs: 614.2643432617188
INFO:root:Train (Epoch 265): Loss/seq after 00400 batchs: 605.0706176757812
INFO:root:Train (Epoch 265): Loss/seq after 00450 batchs: 607.208740234375
INFO:root:Train (Epoch 265): Loss/seq after 00500 batchs: 588.0440063476562
INFO:root:Train (Epoch 265): Loss/seq after 00550 batchs: 575.3372802734375
INFO:root:Train (Epoch 265): Loss/seq after 00600 batchs: 556.2442016601562
INFO:root:Train (Epoch 265): Loss/seq after 00650 batchs: 537.410888671875
INFO:root:Train (Epoch 265): Loss/seq after 00700 batchs: 518.4761962890625
INFO:root:Train (Epoch 265): Loss/seq after 00750 batchs: 515.8366088867188
INFO:root:Train (Epoch 265): Loss/seq after 00800 batchs: 517.0335693359375
INFO:root:Train (Epoch 265): Loss/seq after 00850 batchs: 501.24798583984375
INFO:root:Train (Epoch 265): Loss/seq after 00900 batchs: 488.4981994628906
INFO:root:Train (Epoch 265): Loss/seq after 00950 batchs: 487.9737243652344
INFO:root:Train (Epoch 265): Loss/seq after 01000 batchs: 481.0606689453125
INFO:root:Train (Epoch 265): Loss/seq after 01050 batchs: 473.2427062988281
INFO:root:Train (Epoch 265): Loss/seq after 01100 batchs: 463.36431884765625
INFO:root:Train (Epoch 265): Loss/seq after 01150 batchs: 452.25518798828125
INFO:root:Train (Epoch 265): Loss/seq after 01200 batchs: 455.1414794921875
INFO:root:Train (Epoch 265): Loss/seq after 01250 batchs: 454.4986877441406
INFO:root:Train (Epoch 265): Loss/seq after 01300 batchs: 445.88641357421875
INFO:root:Train (Epoch 265): Loss/seq after 01350 batchs: 437.8770751953125
INFO:root:Train (Epoch 265): Loss/seq after 01400 batchs: 439.3506774902344
INFO:root:Train (Epoch 265): Loss/seq after 01450 batchs: 442.73114013671875
INFO:root:Train (Epoch 265): Loss/seq after 01500 batchs: 448.4004821777344
INFO:root:Train (Epoch 265): Loss/seq after 01550 batchs: 449.9151306152344
INFO:root:Train (Epoch 265): Loss/seq after 01600 batchs: 447.2668762207031
INFO:root:Train (Epoch 265): Loss/seq after 01650 batchs: 445.33587646484375
INFO:root:Train (Epoch 265): Loss/seq after 01700 batchs: 449.16436767578125
INFO:root:Train (Epoch 265): Loss/seq after 01750 batchs: 447.654296875
INFO:root:Train (Epoch 265): Loss/seq after 01800 batchs: 445.56134033203125
INFO:root:Train (Epoch 265): Loss/seq after 01850 batchs: 442.933349609375
INFO:root:Train (Epoch 265): Loss/seq after 01900 batchs: 441.1797180175781
INFO:root:Train (Epoch 265): Loss/seq after 01950 batchs: 440.037841796875
INFO:root:Train (Epoch 265): Loss/seq after 02000 batchs: 440.74322509765625
INFO:root:Train (Epoch 265): Loss/seq after 02050 batchs: 440.0904235839844
INFO:root:Train (Epoch 265): Loss/seq after 02100 batchs: 438.8136291503906
INFO:root:Train (Epoch 265): Loss/seq after 02150 batchs: 437.7316589355469
INFO:root:Train (Epoch 265): Loss/seq after 02200 batchs: 436.4781494140625
INFO:root:Train (Epoch 265): Loss/seq after 02250 batchs: 435.35498046875
INFO:root:Train (Epoch 265): Loss/seq after 02300 batchs: 432.3103332519531
INFO:root:Train (Epoch 265): Loss/seq after 02350 batchs: 429.3163757324219
INFO:root:Train (Epoch 265): Loss/seq after 02400 batchs: 430.8123474121094
INFO:root:Train (Epoch 265): Loss/seq after 02450 batchs: 427.3402099609375
INFO:root:Train (Epoch 265): Loss/seq after 02500 batchs: 420.6322937011719
INFO:root:Train (Epoch 265): Loss/seq after 02550 batchs: 415.2696838378906
INFO:root:Train (Epoch 265): Loss/seq after 02600 batchs: 412.1617126464844
INFO:root:Train (Epoch 265): Loss/seq after 02650 batchs: 409.16851806640625
INFO:root:Train (Epoch 265): Loss/seq after 02700 batchs: 406.9493713378906
INFO:root:Train (Epoch 265): Loss/seq after 02750 batchs: 403.07958984375
INFO:root:Train (Epoch 265): Loss/seq after 02800 batchs: 402.7750244140625
INFO:root:Train (Epoch 265): Loss/seq after 02850 batchs: 402.6639709472656
INFO:root:Train (Epoch 265): Loss/seq after 02900 batchs: 403.83038330078125
INFO:root:Train (Epoch 265): Loss/seq after 02950 batchs: 404.2276916503906
INFO:root:Train (Epoch 265): Loss/seq after 03000 batchs: 409.0772705078125
INFO:root:Train (Epoch 265): Loss/seq after 03050 batchs: 411.2710266113281
INFO:root:Train (Epoch 265): Loss/seq after 03100 batchs: 412.8148498535156
INFO:root:Train (Epoch 265): Loss/seq after 03150 batchs: 413.6759948730469
INFO:root:Train (Epoch 265): Loss/seq after 03200 batchs: 414.0790100097656
INFO:root:Train (Epoch 265): Loss/seq after 03250 batchs: 415.43084716796875
INFO:root:Train (Epoch 265): Loss/seq after 03300 batchs: 414.8356628417969
INFO:root:Train (Epoch 265): Loss/seq after 03350 batchs: 412.9605407714844
INFO:root:Train (Epoch 265): Loss/seq after 03400 batchs: 410.31524658203125
INFO:root:Train (Epoch 265): Loss/seq after 03450 batchs: 409.1806640625
INFO:root:Train (Epoch 265): Loss/seq after 03500 batchs: 409.8596496582031
INFO:root:Train (Epoch 265): Loss/seq after 03550 batchs: 407.95574951171875
INFO:root:Train (Epoch 265): Loss/seq after 03600 batchs: 412.67767333984375
INFO:root:Train (Epoch 265): Loss/seq after 03650 batchs: 411.6695861816406
INFO:root:Train (Epoch 265): Loss/seq after 03700 batchs: 413.7197570800781
INFO:root:Train (Epoch 265): Loss/seq after 03750 batchs: 417.59783935546875
INFO:root:Train (Epoch 265): Loss/seq after 03800 batchs: 416.90380859375
INFO:root:Train (Epoch 265): Loss/seq after 03850 batchs: 416.11505126953125
INFO:root:Train (Epoch 265): Loss/seq after 03900 batchs: 418.0750427246094
INFO:root:Train (Epoch 265): Loss/seq after 03950 batchs: 421.0101318359375
INFO:root:Train (Epoch 265): Loss/seq after 04000 batchs: 418.3264465332031
INFO:root:Train (Epoch 265): Loss/seq after 04050 batchs: 415.860595703125
INFO:root:Train (Epoch 265): Loss/seq after 04100 batchs: 415.19366455078125
INFO:root:Train (Epoch 265): Loss/seq after 04150 batchs: 415.21600341796875
INFO:root:Train (Epoch 265): Loss/seq after 04200 batchs: 414.0719299316406
INFO:root:Train (Epoch 265): Loss/seq after 04250 batchs: 412.9048767089844
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 265): Loss/seq after 00000 batches: 406.7180480957031
INFO:root:# Valid (Epoch 265): Loss/seq after 00050 batches: 692.4693603515625
INFO:root:# Valid (Epoch 265): Loss/seq after 00100 batches: 730.9429931640625
INFO:root:# Valid (Epoch 265): Loss/seq after 00150 batches: 543.1622314453125
INFO:root:# Valid (Epoch 265): Loss/seq after 00200 batches: 490.7242431640625
INFO:root:Artifacts: Make stick videos for epoch 265
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_265_on_20220423_181120.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_265_index_0_on_20220423_181120.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 266): Loss/seq after 00000 batchs: 571.6753540039062
INFO:root:Train (Epoch 266): Loss/seq after 00050 batchs: 554.6111450195312
INFO:root:Train (Epoch 266): Loss/seq after 00100 batchs: 560.7805786132812
INFO:root:Train (Epoch 266): Loss/seq after 00150 batchs: 512.3045043945312
INFO:root:Train (Epoch 266): Loss/seq after 00200 batchs: 581.4371948242188
INFO:root:Train (Epoch 266): Loss/seq after 00250 batchs: 624.0762939453125
INFO:root:Train (Epoch 266): Loss/seq after 00300 batchs: 637.1004028320312
INFO:root:Train (Epoch 266): Loss/seq after 00350 batchs: 605.46826171875
INFO:root:Train (Epoch 266): Loss/seq after 00400 batchs: 597.558837890625
INFO:root:Train (Epoch 266): Loss/seq after 00450 batchs: 601.339111328125
INFO:root:Train (Epoch 266): Loss/seq after 00500 batchs: 582.3748779296875
INFO:root:Train (Epoch 266): Loss/seq after 00550 batchs: 569.2185668945312
INFO:root:Train (Epoch 266): Loss/seq after 00600 batchs: 550.1995239257812
INFO:root:Train (Epoch 266): Loss/seq after 00650 batchs: 535.0484619140625
INFO:root:Train (Epoch 266): Loss/seq after 00700 batchs: 514.4498901367188
INFO:root:Train (Epoch 266): Loss/seq after 00750 batchs: 510.9270324707031
INFO:root:Train (Epoch 266): Loss/seq after 00800 batchs: 510.9081115722656
INFO:root:Train (Epoch 266): Loss/seq after 00850 batchs: 495.50799560546875
INFO:root:Train (Epoch 266): Loss/seq after 00900 batchs: 482.5138854980469
INFO:root:Train (Epoch 266): Loss/seq after 00950 batchs: 482.2994384765625
INFO:root:Train (Epoch 266): Loss/seq after 01000 batchs: 473.79986572265625
INFO:root:Train (Epoch 266): Loss/seq after 01050 batchs: 464.48095703125
INFO:root:Train (Epoch 266): Loss/seq after 01100 batchs: 455.0388488769531
INFO:root:Train (Epoch 266): Loss/seq after 01150 batchs: 443.6837158203125
INFO:root:Train (Epoch 266): Loss/seq after 01200 batchs: 445.8818664550781
INFO:root:Train (Epoch 266): Loss/seq after 01250 batchs: 444.85931396484375
INFO:root:Train (Epoch 266): Loss/seq after 01300 batchs: 436.5700378417969
INFO:root:Train (Epoch 266): Loss/seq after 01350 batchs: 428.84283447265625
INFO:root:Train (Epoch 266): Loss/seq after 01400 batchs: 430.6662292480469
INFO:root:Train (Epoch 266): Loss/seq after 01450 batchs: 434.3354187011719
INFO:root:Train (Epoch 266): Loss/seq after 01500 batchs: 440.4441223144531
INFO:root:Train (Epoch 266): Loss/seq after 01550 batchs: 442.4925842285156
INFO:root:Train (Epoch 266): Loss/seq after 01600 batchs: 439.749267578125
INFO:root:Train (Epoch 266): Loss/seq after 01650 batchs: 438.00274658203125
INFO:root:Train (Epoch 266): Loss/seq after 01700 batchs: 441.7758483886719
INFO:root:Train (Epoch 266): Loss/seq after 01750 batchs: 440.45135498046875
INFO:root:Train (Epoch 266): Loss/seq after 01800 batchs: 438.74261474609375
INFO:root:Train (Epoch 266): Loss/seq after 01850 batchs: 436.2822265625
INFO:root:Train (Epoch 266): Loss/seq after 01900 batchs: 435.1106872558594
INFO:root:Train (Epoch 266): Loss/seq after 01950 batchs: 434.2629699707031
INFO:root:Train (Epoch 266): Loss/seq after 02000 batchs: 435.19049072265625
INFO:root:Train (Epoch 266): Loss/seq after 02050 batchs: 434.6343688964844
INFO:root:Train (Epoch 266): Loss/seq after 02100 batchs: 433.36663818359375
INFO:root:Train (Epoch 266): Loss/seq after 02150 batchs: 432.5093688964844
INFO:root:Train (Epoch 266): Loss/seq after 02200 batchs: 431.19207763671875
INFO:root:Train (Epoch 266): Loss/seq after 02250 batchs: 430.306396484375
INFO:root:Train (Epoch 266): Loss/seq after 02300 batchs: 427.5303955078125
INFO:root:Train (Epoch 266): Loss/seq after 02350 batchs: 424.6716613769531
INFO:root:Train (Epoch 266): Loss/seq after 02400 batchs: 426.4544372558594
INFO:root:Train (Epoch 266): Loss/seq after 02450 batchs: 423.1414489746094
INFO:root:Train (Epoch 266): Loss/seq after 02500 batchs: 416.5232238769531
INFO:root:Train (Epoch 266): Loss/seq after 02550 batchs: 411.4059753417969
INFO:root:Train (Epoch 266): Loss/seq after 02600 batchs: 408.1025085449219
INFO:root:Train (Epoch 266): Loss/seq after 02650 batchs: 405.21221923828125
INFO:root:Train (Epoch 266): Loss/seq after 02700 batchs: 403.1109619140625
INFO:root:Train (Epoch 266): Loss/seq after 02750 batchs: 399.47021484375
INFO:root:Train (Epoch 266): Loss/seq after 02800 batchs: 399.1275329589844
INFO:root:Train (Epoch 266): Loss/seq after 02850 batchs: 399.1096496582031
INFO:root:Train (Epoch 266): Loss/seq after 02900 batchs: 400.564697265625
INFO:root:Train (Epoch 266): Loss/seq after 02950 batchs: 401.0646057128906
INFO:root:Train (Epoch 266): Loss/seq after 03000 batchs: 405.8173522949219
INFO:root:Train (Epoch 266): Loss/seq after 03050 batchs: 408.3896484375
INFO:root:Train (Epoch 266): Loss/seq after 03100 batchs: 410.0516357421875
INFO:root:Train (Epoch 266): Loss/seq after 03150 batchs: 412.0491638183594
INFO:root:Train (Epoch 266): Loss/seq after 03200 batchs: 412.5639343261719
INFO:root:Train (Epoch 266): Loss/seq after 03250 batchs: 414.1020812988281
INFO:root:Train (Epoch 266): Loss/seq after 03300 batchs: 413.51177978515625
INFO:root:Train (Epoch 266): Loss/seq after 03350 batchs: 411.98748779296875
INFO:root:Train (Epoch 266): Loss/seq after 03400 batchs: 409.5118408203125
INFO:root:Train (Epoch 266): Loss/seq after 03450 batchs: 408.258544921875
INFO:root:Train (Epoch 266): Loss/seq after 03500 batchs: 409.0199279785156
INFO:root:Train (Epoch 266): Loss/seq after 03550 batchs: 407.157470703125
INFO:root:Train (Epoch 266): Loss/seq after 03600 batchs: 412.1678771972656
INFO:root:Train (Epoch 266): Loss/seq after 03650 batchs: 411.026611328125
INFO:root:Train (Epoch 266): Loss/seq after 03700 batchs: 413.3563537597656
INFO:root:Train (Epoch 266): Loss/seq after 03750 batchs: 417.0561218261719
INFO:root:Train (Epoch 266): Loss/seq after 03800 batchs: 416.1856384277344
INFO:root:Train (Epoch 266): Loss/seq after 03850 batchs: 415.5411682128906
INFO:root:Train (Epoch 266): Loss/seq after 03900 batchs: 417.3452453613281
INFO:root:Train (Epoch 266): Loss/seq after 03950 batchs: 420.0265808105469
INFO:root:Train (Epoch 266): Loss/seq after 04000 batchs: 417.3955993652344
INFO:root:Train (Epoch 266): Loss/seq after 04050 batchs: 415.06646728515625
INFO:root:Train (Epoch 266): Loss/seq after 04100 batchs: 414.5617370605469
INFO:root:Train (Epoch 266): Loss/seq after 04150 batchs: 414.6045837402344
INFO:root:Train (Epoch 266): Loss/seq after 04200 batchs: 413.435546875
INFO:root:Train (Epoch 266): Loss/seq after 04250 batchs: 412.1591491699219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 266): Loss/seq after 00000 batches: 392.66217041015625
INFO:root:# Valid (Epoch 266): Loss/seq after 00050 batches: 714.7881469726562
INFO:root:# Valid (Epoch 266): Loss/seq after 00100 batches: 714.8587646484375
INFO:root:# Valid (Epoch 266): Loss/seq after 00150 batches: 535.8609008789062
INFO:root:# Valid (Epoch 266): Loss/seq after 00200 batches: 490.73046875
INFO:root:Artifacts: Make stick videos for epoch 266
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_266_on_20220423_181613.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_266_index_761_on_20220423_181613.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 267): Loss/seq after 00000 batchs: 815.7135620117188
INFO:root:Train (Epoch 267): Loss/seq after 00050 batchs: 562.617431640625
INFO:root:Train (Epoch 267): Loss/seq after 00100 batchs: 565.3582763671875
INFO:root:Train (Epoch 267): Loss/seq after 00150 batchs: 516.0488891601562
INFO:root:Train (Epoch 267): Loss/seq after 00200 batchs: 588.1995239257812
INFO:root:Train (Epoch 267): Loss/seq after 00250 batchs: 627.442138671875
INFO:root:Train (Epoch 267): Loss/seq after 00300 batchs: 637.3666381835938
INFO:root:Train (Epoch 267): Loss/seq after 00350 batchs: 606.7788696289062
INFO:root:Train (Epoch 267): Loss/seq after 00400 batchs: 599.8959350585938
INFO:root:Train (Epoch 267): Loss/seq after 00450 batchs: 602.8743286132812
INFO:root:Train (Epoch 267): Loss/seq after 00500 batchs: 584.0014038085938
INFO:root:Train (Epoch 267): Loss/seq after 00550 batchs: 570.7693481445312
INFO:root:Train (Epoch 267): Loss/seq after 00600 batchs: 552.4252319335938
INFO:root:Train (Epoch 267): Loss/seq after 00650 batchs: 534.575439453125
INFO:root:Train (Epoch 267): Loss/seq after 00700 batchs: 514.851806640625
INFO:root:Train (Epoch 267): Loss/seq after 00750 batchs: 513.1753540039062
INFO:root:Train (Epoch 267): Loss/seq after 00800 batchs: 513.5653076171875
INFO:root:Train (Epoch 267): Loss/seq after 00850 batchs: 497.7924499511719
INFO:root:Train (Epoch 267): Loss/seq after 00900 batchs: 484.9243469238281
INFO:root:Train (Epoch 267): Loss/seq after 00950 batchs: 482.28460693359375
INFO:root:Train (Epoch 267): Loss/seq after 01000 batchs: 474.4022521972656
INFO:root:Train (Epoch 267): Loss/seq after 01050 batchs: 464.161865234375
INFO:root:Train (Epoch 267): Loss/seq after 01100 batchs: 454.6576232910156
INFO:root:Train (Epoch 267): Loss/seq after 01150 batchs: 443.23052978515625
INFO:root:Train (Epoch 267): Loss/seq after 01200 batchs: 444.8739929199219
INFO:root:Train (Epoch 267): Loss/seq after 01250 batchs: 444.06793212890625
INFO:root:Train (Epoch 267): Loss/seq after 01300 batchs: 435.3001403808594
INFO:root:Train (Epoch 267): Loss/seq after 01350 batchs: 427.1084289550781
INFO:root:Train (Epoch 267): Loss/seq after 01400 batchs: 429.2249755859375
INFO:root:Train (Epoch 267): Loss/seq after 01450 batchs: 432.6308898925781
INFO:root:Train (Epoch 267): Loss/seq after 01500 batchs: 438.61517333984375
INFO:root:Train (Epoch 267): Loss/seq after 01550 batchs: 440.3605651855469
INFO:root:Train (Epoch 267): Loss/seq after 01600 batchs: 437.5386657714844
INFO:root:Train (Epoch 267): Loss/seq after 01650 batchs: 435.5718078613281
INFO:root:Train (Epoch 267): Loss/seq after 01700 batchs: 439.59271240234375
INFO:root:Train (Epoch 267): Loss/seq after 01750 batchs: 438.36431884765625
INFO:root:Train (Epoch 267): Loss/seq after 01800 batchs: 436.7225036621094
INFO:root:Train (Epoch 267): Loss/seq after 01850 batchs: 434.244873046875
INFO:root:Train (Epoch 267): Loss/seq after 01900 batchs: 433.1329345703125
INFO:root:Train (Epoch 267): Loss/seq after 01950 batchs: 432.95245361328125
INFO:root:Train (Epoch 267): Loss/seq after 02000 batchs: 434.3357238769531
INFO:root:Train (Epoch 267): Loss/seq after 02050 batchs: 433.947998046875
INFO:root:Train (Epoch 267): Loss/seq after 02100 batchs: 432.64764404296875
INFO:root:Train (Epoch 267): Loss/seq after 02150 batchs: 431.63421630859375
INFO:root:Train (Epoch 267): Loss/seq after 02200 batchs: 430.35272216796875
INFO:root:Train (Epoch 267): Loss/seq after 02250 batchs: 429.3418884277344
INFO:root:Train (Epoch 267): Loss/seq after 02300 batchs: 426.234619140625
INFO:root:Train (Epoch 267): Loss/seq after 02350 batchs: 423.5065002441406
INFO:root:Train (Epoch 267): Loss/seq after 02400 batchs: 425.3150939941406
INFO:root:Train (Epoch 267): Loss/seq after 02450 batchs: 421.9706115722656
INFO:root:Train (Epoch 267): Loss/seq after 02500 batchs: 415.3618469238281
INFO:root:Train (Epoch 267): Loss/seq after 02550 batchs: 410.153564453125
INFO:root:Train (Epoch 267): Loss/seq after 02600 batchs: 406.9869384765625
INFO:root:Train (Epoch 267): Loss/seq after 02650 batchs: 404.0639343261719
INFO:root:Train (Epoch 267): Loss/seq after 02700 batchs: 401.7377624511719
INFO:root:Train (Epoch 267): Loss/seq after 02750 batchs: 397.6694030761719
INFO:root:Train (Epoch 267): Loss/seq after 02800 batchs: 396.5923156738281
INFO:root:Train (Epoch 267): Loss/seq after 02850 batchs: 396.5791015625
INFO:root:Train (Epoch 267): Loss/seq after 02900 batchs: 397.8794250488281
INFO:root:Train (Epoch 267): Loss/seq after 02950 batchs: 398.2691345214844
INFO:root:Train (Epoch 267): Loss/seq after 03000 batchs: 402.88995361328125
INFO:root:Train (Epoch 267): Loss/seq after 03050 batchs: 405.3823547363281
INFO:root:Train (Epoch 267): Loss/seq after 03100 batchs: 407.1757507324219
INFO:root:Train (Epoch 267): Loss/seq after 03150 batchs: 408.1644287109375
INFO:root:Train (Epoch 267): Loss/seq after 03200 batchs: 408.321533203125
INFO:root:Train (Epoch 267): Loss/seq after 03250 batchs: 409.19244384765625
INFO:root:Train (Epoch 267): Loss/seq after 03300 batchs: 409.0290222167969
INFO:root:Train (Epoch 267): Loss/seq after 03350 batchs: 407.0323181152344
INFO:root:Train (Epoch 267): Loss/seq after 03400 batchs: 404.68701171875
INFO:root:Train (Epoch 267): Loss/seq after 03450 batchs: 403.5400390625
INFO:root:Train (Epoch 267): Loss/seq after 03500 batchs: 404.5323486328125
INFO:root:Train (Epoch 267): Loss/seq after 03550 batchs: 402.91094970703125
INFO:root:Train (Epoch 267): Loss/seq after 03600 batchs: 407.6415100097656
INFO:root:Train (Epoch 267): Loss/seq after 03650 batchs: 406.695068359375
INFO:root:Train (Epoch 267): Loss/seq after 03700 batchs: 409.21197509765625
INFO:root:Train (Epoch 267): Loss/seq after 03750 batchs: 412.90838623046875
INFO:root:Train (Epoch 267): Loss/seq after 03800 batchs: 412.119384765625
INFO:root:Train (Epoch 267): Loss/seq after 03850 batchs: 411.5314025878906
INFO:root:Train (Epoch 267): Loss/seq after 03900 batchs: 413.2724609375
INFO:root:Train (Epoch 267): Loss/seq after 03950 batchs: 416.648681640625
INFO:root:Train (Epoch 267): Loss/seq after 04000 batchs: 414.04254150390625
INFO:root:Train (Epoch 267): Loss/seq after 04050 batchs: 411.69244384765625
INFO:root:Train (Epoch 267): Loss/seq after 04100 batchs: 411.1734619140625
INFO:root:Train (Epoch 267): Loss/seq after 04150 batchs: 411.3045654296875
INFO:root:Train (Epoch 267): Loss/seq after 04200 batchs: 410.1869812011719
INFO:root:Train (Epoch 267): Loss/seq after 04250 batchs: 409.0343322753906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 267): Loss/seq after 00000 batches: 402.3542175292969
INFO:root:# Valid (Epoch 267): Loss/seq after 00050 batches: 720.785888671875
INFO:root:# Valid (Epoch 267): Loss/seq after 00100 batches: 687.72802734375
INFO:root:# Valid (Epoch 267): Loss/seq after 00150 batches: 512.2904052734375
INFO:root:# Valid (Epoch 267): Loss/seq after 00200 batches: 468.7882385253906
INFO:root:Artifacts: Make stick videos for epoch 267
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_267_on_20220423_182106.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_267_index_590_on_20220423_182106.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 268): Loss/seq after 00000 batchs: 1089.7596435546875
INFO:root:Train (Epoch 268): Loss/seq after 00050 batchs: 591.3937377929688
INFO:root:Train (Epoch 268): Loss/seq after 00100 batchs: 587.2877197265625
INFO:root:Train (Epoch 268): Loss/seq after 00150 batchs: 528.4930419921875
INFO:root:Train (Epoch 268): Loss/seq after 00200 batchs: 597.2439575195312
INFO:root:Train (Epoch 268): Loss/seq after 00250 batchs: 636.072265625
INFO:root:Train (Epoch 268): Loss/seq after 00300 batchs: 649.7355346679688
INFO:root:Train (Epoch 268): Loss/seq after 00350 batchs: 615.9927368164062
INFO:root:Train (Epoch 268): Loss/seq after 00400 batchs: 608.8109130859375
INFO:root:Train (Epoch 268): Loss/seq after 00450 batchs: 611.2594604492188
INFO:root:Train (Epoch 268): Loss/seq after 00500 batchs: 592.6063842773438
INFO:root:Train (Epoch 268): Loss/seq after 00550 batchs: 578.6888427734375
INFO:root:Train (Epoch 268): Loss/seq after 00600 batchs: 558.4725952148438
INFO:root:Train (Epoch 268): Loss/seq after 00650 batchs: 539.452392578125
INFO:root:Train (Epoch 268): Loss/seq after 00700 batchs: 518.6722412109375
INFO:root:Train (Epoch 268): Loss/seq after 00750 batchs: 514.752197265625
INFO:root:Train (Epoch 268): Loss/seq after 00800 batchs: 514.8463134765625
INFO:root:Train (Epoch 268): Loss/seq after 00850 batchs: 499.12945556640625
INFO:root:Train (Epoch 268): Loss/seq after 00900 batchs: 486.0617980957031
INFO:root:Train (Epoch 268): Loss/seq after 00950 batchs: 483.6845397949219
INFO:root:Train (Epoch 268): Loss/seq after 01000 batchs: 476.7609558105469
INFO:root:Train (Epoch 268): Loss/seq after 01050 batchs: 467.2664794921875
INFO:root:Train (Epoch 268): Loss/seq after 01100 batchs: 457.390380859375
INFO:root:Train (Epoch 268): Loss/seq after 01150 batchs: 445.3600769042969
INFO:root:Train (Epoch 268): Loss/seq after 01200 batchs: 447.5180969238281
INFO:root:Train (Epoch 268): Loss/seq after 01250 batchs: 446.27117919921875
INFO:root:Train (Epoch 268): Loss/seq after 01300 batchs: 437.1236572265625
INFO:root:Train (Epoch 268): Loss/seq after 01350 batchs: 428.74249267578125
INFO:root:Train (Epoch 268): Loss/seq after 01400 batchs: 430.271240234375
INFO:root:Train (Epoch 268): Loss/seq after 01450 batchs: 433.5586242675781
INFO:root:Train (Epoch 268): Loss/seq after 01500 batchs: 439.48272705078125
INFO:root:Train (Epoch 268): Loss/seq after 01550 batchs: 440.8602294921875
INFO:root:Train (Epoch 268): Loss/seq after 01600 batchs: 438.1268615722656
INFO:root:Train (Epoch 268): Loss/seq after 01650 batchs: 436.0389404296875
INFO:root:Train (Epoch 268): Loss/seq after 01700 batchs: 439.57879638671875
INFO:root:Train (Epoch 268): Loss/seq after 01750 batchs: 438.1981201171875
INFO:root:Train (Epoch 268): Loss/seq after 01800 batchs: 436.3280944824219
INFO:root:Train (Epoch 268): Loss/seq after 01850 batchs: 433.75653076171875
INFO:root:Train (Epoch 268): Loss/seq after 01900 batchs: 432.3738098144531
INFO:root:Train (Epoch 268): Loss/seq after 01950 batchs: 431.9340515136719
INFO:root:Train (Epoch 268): Loss/seq after 02000 batchs: 432.8695068359375
INFO:root:Train (Epoch 268): Loss/seq after 02050 batchs: 432.36767578125
INFO:root:Train (Epoch 268): Loss/seq after 02100 batchs: 431.1668395996094
INFO:root:Train (Epoch 268): Loss/seq after 02150 batchs: 430.3599548339844
INFO:root:Train (Epoch 268): Loss/seq after 02200 batchs: 429.06329345703125
INFO:root:Train (Epoch 268): Loss/seq after 02250 batchs: 427.99200439453125
INFO:root:Train (Epoch 268): Loss/seq after 02300 batchs: 425.3314514160156
INFO:root:Train (Epoch 268): Loss/seq after 02350 batchs: 422.5353698730469
INFO:root:Train (Epoch 268): Loss/seq after 02400 batchs: 424.158935546875
INFO:root:Train (Epoch 268): Loss/seq after 02450 batchs: 420.7103576660156
INFO:root:Train (Epoch 268): Loss/seq after 02500 batchs: 414.1046447753906
INFO:root:Train (Epoch 268): Loss/seq after 02550 batchs: 408.88641357421875
INFO:root:Train (Epoch 268): Loss/seq after 02600 batchs: 405.8392333984375
INFO:root:Train (Epoch 268): Loss/seq after 02650 batchs: 402.75146484375
INFO:root:Train (Epoch 268): Loss/seq after 02700 batchs: 400.3931884765625
INFO:root:Train (Epoch 268): Loss/seq after 02750 batchs: 396.4632568359375
INFO:root:Train (Epoch 268): Loss/seq after 02800 batchs: 395.37066650390625
INFO:root:Train (Epoch 268): Loss/seq after 02850 batchs: 395.1378173828125
INFO:root:Train (Epoch 268): Loss/seq after 02900 batchs: 396.130859375
INFO:root:Train (Epoch 268): Loss/seq after 02950 batchs: 396.5473937988281
INFO:root:Train (Epoch 268): Loss/seq after 03000 batchs: 401.1766662597656
INFO:root:Train (Epoch 268): Loss/seq after 03050 batchs: 403.485595703125
INFO:root:Train (Epoch 268): Loss/seq after 03100 batchs: 405.5395202636719
INFO:root:Train (Epoch 268): Loss/seq after 03150 batchs: 406.55438232421875
INFO:root:Train (Epoch 268): Loss/seq after 03200 batchs: 406.95587158203125
INFO:root:Train (Epoch 268): Loss/seq after 03250 batchs: 408.596923828125
INFO:root:Train (Epoch 268): Loss/seq after 03300 batchs: 407.9953918457031
INFO:root:Train (Epoch 268): Loss/seq after 03350 batchs: 406.190673828125
INFO:root:Train (Epoch 268): Loss/seq after 03400 batchs: 403.9082336425781
INFO:root:Train (Epoch 268): Loss/seq after 03450 batchs: 402.7511901855469
INFO:root:Train (Epoch 268): Loss/seq after 03500 batchs: 403.86053466796875
INFO:root:Train (Epoch 268): Loss/seq after 03550 batchs: 402.1254577636719
INFO:root:Train (Epoch 268): Loss/seq after 03600 batchs: 407.02252197265625
INFO:root:Train (Epoch 268): Loss/seq after 03650 batchs: 405.9891357421875
INFO:root:Train (Epoch 268): Loss/seq after 03700 batchs: 408.4210205078125
INFO:root:Train (Epoch 268): Loss/seq after 03750 batchs: 412.20501708984375
INFO:root:Train (Epoch 268): Loss/seq after 03800 batchs: 411.49951171875
INFO:root:Train (Epoch 268): Loss/seq after 03850 batchs: 410.77423095703125
INFO:root:Train (Epoch 268): Loss/seq after 03900 batchs: 412.7967529296875
INFO:root:Train (Epoch 268): Loss/seq after 03950 batchs: 415.7398376464844
INFO:root:Train (Epoch 268): Loss/seq after 04000 batchs: 413.16607666015625
INFO:root:Train (Epoch 268): Loss/seq after 04050 batchs: 410.813720703125
INFO:root:Train (Epoch 268): Loss/seq after 04100 batchs: 410.2674255371094
INFO:root:Train (Epoch 268): Loss/seq after 04150 batchs: 410.3341369628906
INFO:root:Train (Epoch 268): Loss/seq after 04200 batchs: 409.2070617675781
INFO:root:Train (Epoch 268): Loss/seq after 04250 batchs: 407.9945068359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 268): Loss/seq after 00000 batches: 390.2838439941406
INFO:root:# Valid (Epoch 268): Loss/seq after 00050 batches: 714.0381469726562
INFO:root:# Valid (Epoch 268): Loss/seq after 00100 batches: 703.6650390625
INFO:root:# Valid (Epoch 268): Loss/seq after 00150 batches: 526.7157592773438
INFO:root:# Valid (Epoch 268): Loss/seq after 00200 batches: 480.9429626464844
INFO:root:Artifacts: Make stick videos for epoch 268
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_268_on_20220423_182614.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_268_index_1068_on_20220423_182614.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 269): Loss/seq after 00000 batchs: 1076.9215087890625
INFO:root:Train (Epoch 269): Loss/seq after 00050 batchs: 590.4874877929688
INFO:root:Train (Epoch 269): Loss/seq after 00100 batchs: 594.6751708984375
INFO:root:Train (Epoch 269): Loss/seq after 00150 batchs: 536.0095825195312
INFO:root:Train (Epoch 269): Loss/seq after 00200 batchs: 599.1949462890625
INFO:root:Train (Epoch 269): Loss/seq after 00250 batchs: 625.5211791992188
INFO:root:Train (Epoch 269): Loss/seq after 00300 batchs: 633.6680297851562
INFO:root:Train (Epoch 269): Loss/seq after 00350 batchs: 601.8908081054688
INFO:root:Train (Epoch 269): Loss/seq after 00400 batchs: 595.4181518554688
INFO:root:Train (Epoch 269): Loss/seq after 00450 batchs: 598.8356323242188
INFO:root:Train (Epoch 269): Loss/seq after 00500 batchs: 580.4580688476562
INFO:root:Train (Epoch 269): Loss/seq after 00550 batchs: 565.9459838867188
INFO:root:Train (Epoch 269): Loss/seq after 00600 batchs: 547.1072387695312
INFO:root:Train (Epoch 269): Loss/seq after 00650 batchs: 528.812744140625
INFO:root:Train (Epoch 269): Loss/seq after 00700 batchs: 509.3783264160156
INFO:root:Train (Epoch 269): Loss/seq after 00750 batchs: 508.1479187011719
INFO:root:Train (Epoch 269): Loss/seq after 00800 batchs: 508.3632507324219
INFO:root:Train (Epoch 269): Loss/seq after 00850 batchs: 493.06976318359375
INFO:root:Train (Epoch 269): Loss/seq after 00900 batchs: 480.0119934082031
INFO:root:Train (Epoch 269): Loss/seq after 00950 batchs: 479.91949462890625
INFO:root:Train (Epoch 269): Loss/seq after 01000 batchs: 472.3343505859375
INFO:root:Train (Epoch 269): Loss/seq after 01050 batchs: 463.8556213378906
INFO:root:Train (Epoch 269): Loss/seq after 01100 batchs: 453.89520263671875
INFO:root:Train (Epoch 269): Loss/seq after 01150 batchs: 442.172607421875
INFO:root:Train (Epoch 269): Loss/seq after 01200 batchs: 444.2540588378906
INFO:root:Train (Epoch 269): Loss/seq after 01250 batchs: 443.132080078125
INFO:root:Train (Epoch 269): Loss/seq after 01300 batchs: 434.13067626953125
INFO:root:Train (Epoch 269): Loss/seq after 01350 batchs: 426.087890625
INFO:root:Train (Epoch 269): Loss/seq after 01400 batchs: 426.9237976074219
INFO:root:Train (Epoch 269): Loss/seq after 01450 batchs: 430.27996826171875
INFO:root:Train (Epoch 269): Loss/seq after 01500 batchs: 435.9830322265625
INFO:root:Train (Epoch 269): Loss/seq after 01550 batchs: 437.7998046875
INFO:root:Train (Epoch 269): Loss/seq after 01600 batchs: 435.2519836425781
INFO:root:Train (Epoch 269): Loss/seq after 01650 batchs: 433.6111755371094
INFO:root:Train (Epoch 269): Loss/seq after 01700 batchs: 437.8152160644531
INFO:root:Train (Epoch 269): Loss/seq after 01750 batchs: 436.43060302734375
INFO:root:Train (Epoch 269): Loss/seq after 01800 batchs: 434.7048645019531
INFO:root:Train (Epoch 269): Loss/seq after 01850 batchs: 432.2021179199219
INFO:root:Train (Epoch 269): Loss/seq after 01900 batchs: 430.90625
INFO:root:Train (Epoch 269): Loss/seq after 01950 batchs: 430.0873718261719
INFO:root:Train (Epoch 269): Loss/seq after 02000 batchs: 431.0580749511719
INFO:root:Train (Epoch 269): Loss/seq after 02050 batchs: 430.8523864746094
INFO:root:Train (Epoch 269): Loss/seq after 02100 batchs: 429.6890869140625
INFO:root:Train (Epoch 269): Loss/seq after 02150 batchs: 428.886474609375
INFO:root:Train (Epoch 269): Loss/seq after 02200 batchs: 427.65093994140625
INFO:root:Train (Epoch 269): Loss/seq after 02250 batchs: 426.745849609375
INFO:root:Train (Epoch 269): Loss/seq after 02300 batchs: 423.79461669921875
INFO:root:Train (Epoch 269): Loss/seq after 02350 batchs: 420.9410095214844
INFO:root:Train (Epoch 269): Loss/seq after 02400 batchs: 422.3731689453125
INFO:root:Train (Epoch 269): Loss/seq after 02450 batchs: 418.9251403808594
INFO:root:Train (Epoch 269): Loss/seq after 02500 batchs: 412.30126953125
INFO:root:Train (Epoch 269): Loss/seq after 02550 batchs: 407.2290954589844
INFO:root:Train (Epoch 269): Loss/seq after 02600 batchs: 404.0230712890625
INFO:root:Train (Epoch 269): Loss/seq after 02650 batchs: 400.6882629394531
INFO:root:Train (Epoch 269): Loss/seq after 02700 batchs: 398.8045349121094
INFO:root:Train (Epoch 269): Loss/seq after 02750 batchs: 394.9432678222656
INFO:root:Train (Epoch 269): Loss/seq after 02800 batchs: 394.3754577636719
INFO:root:Train (Epoch 269): Loss/seq after 02850 batchs: 394.2572937011719
INFO:root:Train (Epoch 269): Loss/seq after 02900 batchs: 395.31005859375
INFO:root:Train (Epoch 269): Loss/seq after 02950 batchs: 395.88153076171875
INFO:root:Train (Epoch 269): Loss/seq after 03000 batchs: 400.2919921875
INFO:root:Train (Epoch 269): Loss/seq after 03050 batchs: 402.9382019042969
INFO:root:Train (Epoch 269): Loss/seq after 03100 batchs: 404.982177734375
INFO:root:Train (Epoch 269): Loss/seq after 03150 batchs: 406.0675964355469
INFO:root:Train (Epoch 269): Loss/seq after 03200 batchs: 406.62451171875
INFO:root:Train (Epoch 269): Loss/seq after 03250 batchs: 407.7341003417969
INFO:root:Train (Epoch 269): Loss/seq after 03300 batchs: 407.7211608886719
INFO:root:Train (Epoch 269): Loss/seq after 03350 batchs: 405.989013671875
INFO:root:Train (Epoch 269): Loss/seq after 03400 batchs: 403.557861328125
INFO:root:Train (Epoch 269): Loss/seq after 03450 batchs: 402.45294189453125
INFO:root:Train (Epoch 269): Loss/seq after 03500 batchs: 403.3351745605469
INFO:root:Train (Epoch 269): Loss/seq after 03550 batchs: 401.6303405761719
INFO:root:Train (Epoch 269): Loss/seq after 03600 batchs: 406.4308776855469
INFO:root:Train (Epoch 269): Loss/seq after 03650 batchs: 405.4091491699219
INFO:root:Train (Epoch 269): Loss/seq after 03700 batchs: 407.746337890625
INFO:root:Train (Epoch 269): Loss/seq after 03750 batchs: 411.6841735839844
INFO:root:Train (Epoch 269): Loss/seq after 03800 batchs: 411.0352783203125
INFO:root:Train (Epoch 269): Loss/seq after 03850 batchs: 410.4718017578125
INFO:root:Train (Epoch 269): Loss/seq after 03900 batchs: 412.7383117675781
INFO:root:Train (Epoch 269): Loss/seq after 03950 batchs: 415.88287353515625
INFO:root:Train (Epoch 269): Loss/seq after 04000 batchs: 413.2434997558594
INFO:root:Train (Epoch 269): Loss/seq after 04050 batchs: 410.8870544433594
INFO:root:Train (Epoch 269): Loss/seq after 04100 batchs: 410.29840087890625
INFO:root:Train (Epoch 269): Loss/seq after 04150 batchs: 410.38812255859375
INFO:root:Train (Epoch 269): Loss/seq after 04200 batchs: 409.3864440917969
INFO:root:Train (Epoch 269): Loss/seq after 04250 batchs: 408.1394348144531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 269): Loss/seq after 00000 batches: 398.30712890625
INFO:root:# Valid (Epoch 269): Loss/seq after 00050 batches: 697.2110595703125
INFO:root:# Valid (Epoch 269): Loss/seq after 00100 batches: 680.7265014648438
INFO:root:# Valid (Epoch 269): Loss/seq after 00150 batches: 509.2045593261719
INFO:root:# Valid (Epoch 269): Loss/seq after 00200 batches: 465.678466796875
INFO:root:Artifacts: Make stick videos for epoch 269
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_269_on_20220423_183059.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_269_index_632_on_20220423_183059.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 270): Loss/seq after 00000 batchs: 805.8209838867188
INFO:root:Train (Epoch 270): Loss/seq after 00050 batchs: 539.9158325195312
INFO:root:Train (Epoch 270): Loss/seq after 00100 batchs: 580.7601928710938
INFO:root:Train (Epoch 270): Loss/seq after 00150 batchs: 523.6856079101562
INFO:root:Train (Epoch 270): Loss/seq after 00200 batchs: 589.0709838867188
INFO:root:Train (Epoch 270): Loss/seq after 00250 batchs: 609.3768310546875
INFO:root:Train (Epoch 270): Loss/seq after 00300 batchs: 621.1141967773438
INFO:root:Train (Epoch 270): Loss/seq after 00350 batchs: 591.5575561523438
INFO:root:Train (Epoch 270): Loss/seq after 00400 batchs: 581.5783081054688
INFO:root:Train (Epoch 270): Loss/seq after 00450 batchs: 586.13671875
INFO:root:Train (Epoch 270): Loss/seq after 00500 batchs: 568.2052612304688
INFO:root:Train (Epoch 270): Loss/seq after 00550 batchs: 555.5225830078125
INFO:root:Train (Epoch 270): Loss/seq after 00600 batchs: 537.4566650390625
INFO:root:Train (Epoch 270): Loss/seq after 00650 batchs: 521.27978515625
INFO:root:Train (Epoch 270): Loss/seq after 00700 batchs: 501.4321594238281
INFO:root:Train (Epoch 270): Loss/seq after 00750 batchs: 503.2969055175781
INFO:root:Train (Epoch 270): Loss/seq after 00800 batchs: 504.5510559082031
INFO:root:Train (Epoch 270): Loss/seq after 00850 batchs: 488.9481506347656
INFO:root:Train (Epoch 270): Loss/seq after 00900 batchs: 476.4214782714844
INFO:root:Train (Epoch 270): Loss/seq after 00950 batchs: 473.1610107421875
INFO:root:Train (Epoch 270): Loss/seq after 01000 batchs: 466.0501403808594
INFO:root:Train (Epoch 270): Loss/seq after 01050 batchs: 456.7589416503906
INFO:root:Train (Epoch 270): Loss/seq after 01100 batchs: 447.32708740234375
INFO:root:Train (Epoch 270): Loss/seq after 01150 batchs: 436.04974365234375
INFO:root:Train (Epoch 270): Loss/seq after 01200 batchs: 437.8229675292969
INFO:root:Train (Epoch 270): Loss/seq after 01250 batchs: 437.2245788574219
INFO:root:Train (Epoch 270): Loss/seq after 01300 batchs: 429.3965759277344
INFO:root:Train (Epoch 270): Loss/seq after 01350 batchs: 421.4788513183594
INFO:root:Train (Epoch 270): Loss/seq after 01400 batchs: 423.94024658203125
INFO:root:Train (Epoch 270): Loss/seq after 01450 batchs: 426.8892517089844
INFO:root:Train (Epoch 270): Loss/seq after 01500 batchs: 432.58392333984375
INFO:root:Train (Epoch 270): Loss/seq after 01550 batchs: 433.79718017578125
INFO:root:Train (Epoch 270): Loss/seq after 01600 batchs: 431.312744140625
INFO:root:Train (Epoch 270): Loss/seq after 01650 batchs: 429.65130615234375
INFO:root:Train (Epoch 270): Loss/seq after 01700 batchs: 433.667236328125
INFO:root:Train (Epoch 270): Loss/seq after 01750 batchs: 432.3074645996094
INFO:root:Train (Epoch 270): Loss/seq after 01800 batchs: 430.6763000488281
INFO:root:Train (Epoch 270): Loss/seq after 01850 batchs: 428.2283020019531
INFO:root:Train (Epoch 270): Loss/seq after 01900 batchs: 426.8572082519531
INFO:root:Train (Epoch 270): Loss/seq after 01950 batchs: 426.0155334472656
INFO:root:Train (Epoch 270): Loss/seq after 02000 batchs: 427.0231628417969
INFO:root:Train (Epoch 270): Loss/seq after 02050 batchs: 426.65692138671875
INFO:root:Train (Epoch 270): Loss/seq after 02100 batchs: 425.5334167480469
INFO:root:Train (Epoch 270): Loss/seq after 02150 batchs: 424.7084045410156
INFO:root:Train (Epoch 270): Loss/seq after 02200 batchs: 423.5606994628906
INFO:root:Train (Epoch 270): Loss/seq after 02250 batchs: 422.7740478515625
INFO:root:Train (Epoch 270): Loss/seq after 02300 batchs: 421.7733459472656
INFO:root:Train (Epoch 270): Loss/seq after 02350 batchs: 418.9561462402344
INFO:root:Train (Epoch 270): Loss/seq after 02400 batchs: 420.3907470703125
INFO:root:Train (Epoch 270): Loss/seq after 02450 batchs: 417.0845947265625
INFO:root:Train (Epoch 270): Loss/seq after 02500 batchs: 410.45513916015625
INFO:root:Train (Epoch 270): Loss/seq after 02550 batchs: 405.1400146484375
INFO:root:Train (Epoch 270): Loss/seq after 02600 batchs: 401.8854675292969
INFO:root:Train (Epoch 270): Loss/seq after 02650 batchs: 398.79827880859375
INFO:root:Train (Epoch 270): Loss/seq after 02700 batchs: 396.6220397949219
INFO:root:Train (Epoch 270): Loss/seq after 02750 batchs: 392.6940002441406
INFO:root:Train (Epoch 270): Loss/seq after 02800 batchs: 391.74737548828125
INFO:root:Train (Epoch 270): Loss/seq after 02850 batchs: 391.83544921875
INFO:root:Train (Epoch 270): Loss/seq after 02900 batchs: 393.06146240234375
INFO:root:Train (Epoch 270): Loss/seq after 02950 batchs: 393.6290588378906
INFO:root:Train (Epoch 270): Loss/seq after 03000 batchs: 398.0539855957031
INFO:root:Train (Epoch 270): Loss/seq after 03050 batchs: 400.0798645019531
INFO:root:Train (Epoch 270): Loss/seq after 03100 batchs: 402.4485168457031
INFO:root:Train (Epoch 270): Loss/seq after 03150 batchs: 402.9085388183594
INFO:root:Train (Epoch 270): Loss/seq after 03200 batchs: 403.0965881347656
INFO:root:Train (Epoch 270): Loss/seq after 03250 batchs: 404.9449768066406
INFO:root:Train (Epoch 270): Loss/seq after 03300 batchs: 404.7237243652344
INFO:root:Train (Epoch 270): Loss/seq after 03350 batchs: 403.154052734375
INFO:root:Train (Epoch 270): Loss/seq after 03400 batchs: 400.72613525390625
INFO:root:Train (Epoch 270): Loss/seq after 03450 batchs: 399.651611328125
INFO:root:Train (Epoch 270): Loss/seq after 03500 batchs: 400.6980285644531
INFO:root:Train (Epoch 270): Loss/seq after 03550 batchs: 398.97113037109375
INFO:root:Train (Epoch 270): Loss/seq after 03600 batchs: 403.75469970703125
INFO:root:Train (Epoch 270): Loss/seq after 03650 batchs: 402.8697814941406
INFO:root:Train (Epoch 270): Loss/seq after 03700 batchs: 405.1744079589844
INFO:root:Train (Epoch 270): Loss/seq after 03750 batchs: 408.9743957519531
INFO:root:Train (Epoch 270): Loss/seq after 03800 batchs: 408.3357849121094
INFO:root:Train (Epoch 270): Loss/seq after 03850 batchs: 407.73114013671875
INFO:root:Train (Epoch 270): Loss/seq after 03900 batchs: 409.88238525390625
INFO:root:Train (Epoch 270): Loss/seq after 03950 batchs: 413.068115234375
INFO:root:Train (Epoch 270): Loss/seq after 04000 batchs: 410.5442810058594
INFO:root:Train (Epoch 270): Loss/seq after 04050 batchs: 408.2107849121094
INFO:root:Train (Epoch 270): Loss/seq after 04100 batchs: 407.6701965332031
INFO:root:Train (Epoch 270): Loss/seq after 04150 batchs: 407.70074462890625
INFO:root:Train (Epoch 270): Loss/seq after 04200 batchs: 406.62725830078125
INFO:root:Train (Epoch 270): Loss/seq after 04250 batchs: 405.4740905761719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 270): Loss/seq after 00000 batches: 382.21685791015625
INFO:root:# Valid (Epoch 270): Loss/seq after 00050 batches: 682.2838745117188
INFO:root:# Valid (Epoch 270): Loss/seq after 00100 batches: 669.3807983398438
INFO:root:# Valid (Epoch 270): Loss/seq after 00150 batches: 502.5298156738281
INFO:root:# Valid (Epoch 270): Loss/seq after 00200 batches: 461.05059814453125
INFO:root:Artifacts: Make stick videos for epoch 270
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_270_on_20220423_183558.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_270_index_1279_on_20220423_183558.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 271): Loss/seq after 00000 batchs: 849.4276733398438
INFO:root:Train (Epoch 271): Loss/seq after 00050 batchs: 591.5100708007812
INFO:root:Train (Epoch 271): Loss/seq after 00100 batchs: 603.125244140625
INFO:root:Train (Epoch 271): Loss/seq after 00150 batchs: 539.9345703125
INFO:root:Train (Epoch 271): Loss/seq after 00200 batchs: 608.4978637695312
INFO:root:Train (Epoch 271): Loss/seq after 00250 batchs: 629.841064453125
INFO:root:Train (Epoch 271): Loss/seq after 00300 batchs: 638.7286987304688
INFO:root:Train (Epoch 271): Loss/seq after 00350 batchs: 606.3765258789062
INFO:root:Train (Epoch 271): Loss/seq after 00400 batchs: 601.5369873046875
INFO:root:Train (Epoch 271): Loss/seq after 00450 batchs: 604.4274291992188
INFO:root:Train (Epoch 271): Loss/seq after 00500 batchs: 584.612060546875
INFO:root:Train (Epoch 271): Loss/seq after 00550 batchs: 570.1849365234375
INFO:root:Train (Epoch 271): Loss/seq after 00600 batchs: 550.3593139648438
INFO:root:Train (Epoch 271): Loss/seq after 00650 batchs: 534.7725830078125
INFO:root:Train (Epoch 271): Loss/seq after 00700 batchs: 516.3202514648438
INFO:root:Train (Epoch 271): Loss/seq after 00750 batchs: 513.1185913085938
INFO:root:Train (Epoch 271): Loss/seq after 00800 batchs: 513.8629150390625
INFO:root:Train (Epoch 271): Loss/seq after 00850 batchs: 498.56854248046875
INFO:root:Train (Epoch 271): Loss/seq after 00900 batchs: 485.3167724609375
INFO:root:Train (Epoch 271): Loss/seq after 00950 batchs: 482.4150695800781
INFO:root:Train (Epoch 271): Loss/seq after 01000 batchs: 474.7921447753906
INFO:root:Train (Epoch 271): Loss/seq after 01050 batchs: 464.575439453125
INFO:root:Train (Epoch 271): Loss/seq after 01100 batchs: 454.9806823730469
INFO:root:Train (Epoch 271): Loss/seq after 01150 batchs: 443.105712890625
INFO:root:Train (Epoch 271): Loss/seq after 01200 batchs: 445.2904968261719
INFO:root:Train (Epoch 271): Loss/seq after 01250 batchs: 444.2485656738281
INFO:root:Train (Epoch 271): Loss/seq after 01300 batchs: 435.0777282714844
INFO:root:Train (Epoch 271): Loss/seq after 01350 batchs: 426.4761047363281
INFO:root:Train (Epoch 271): Loss/seq after 01400 batchs: 428.0028076171875
INFO:root:Train (Epoch 271): Loss/seq after 01450 batchs: 431.4431457519531
INFO:root:Train (Epoch 271): Loss/seq after 01500 batchs: 437.24951171875
INFO:root:Train (Epoch 271): Loss/seq after 01550 batchs: 438.8240966796875
INFO:root:Train (Epoch 271): Loss/seq after 01600 batchs: 436.3289489746094
INFO:root:Train (Epoch 271): Loss/seq after 01650 batchs: 434.5179748535156
INFO:root:Train (Epoch 271): Loss/seq after 01700 batchs: 438.9988098144531
INFO:root:Train (Epoch 271): Loss/seq after 01750 batchs: 437.45550537109375
INFO:root:Train (Epoch 271): Loss/seq after 01800 batchs: 435.59344482421875
INFO:root:Train (Epoch 271): Loss/seq after 01850 batchs: 432.9639892578125
INFO:root:Train (Epoch 271): Loss/seq after 01900 batchs: 431.4952392578125
INFO:root:Train (Epoch 271): Loss/seq after 01950 batchs: 430.7414855957031
INFO:root:Train (Epoch 271): Loss/seq after 02000 batchs: 431.66937255859375
INFO:root:Train (Epoch 271): Loss/seq after 02050 batchs: 431.1394348144531
INFO:root:Train (Epoch 271): Loss/seq after 02100 batchs: 430.0039978027344
INFO:root:Train (Epoch 271): Loss/seq after 02150 batchs: 429.0840759277344
INFO:root:Train (Epoch 271): Loss/seq after 02200 batchs: 427.81378173828125
INFO:root:Train (Epoch 271): Loss/seq after 02250 batchs: 426.99365234375
INFO:root:Train (Epoch 271): Loss/seq after 02300 batchs: 425.4725646972656
INFO:root:Train (Epoch 271): Loss/seq after 02350 batchs: 422.5062561035156
INFO:root:Train (Epoch 271): Loss/seq after 02400 batchs: 423.92144775390625
INFO:root:Train (Epoch 271): Loss/seq after 02450 batchs: 420.5389099121094
INFO:root:Train (Epoch 271): Loss/seq after 02500 batchs: 413.89892578125
INFO:root:Train (Epoch 271): Loss/seq after 02550 batchs: 408.6336669921875
INFO:root:Train (Epoch 271): Loss/seq after 02600 batchs: 405.4273681640625
INFO:root:Train (Epoch 271): Loss/seq after 02650 batchs: 402.28521728515625
INFO:root:Train (Epoch 271): Loss/seq after 02700 batchs: 400.2424621582031
INFO:root:Train (Epoch 271): Loss/seq after 02750 batchs: 395.9173583984375
INFO:root:Train (Epoch 271): Loss/seq after 02800 batchs: 395.55499267578125
INFO:root:Train (Epoch 271): Loss/seq after 02850 batchs: 395.3726501464844
INFO:root:Train (Epoch 271): Loss/seq after 02900 batchs: 396.45361328125
INFO:root:Train (Epoch 271): Loss/seq after 02950 batchs: 396.9362487792969
INFO:root:Train (Epoch 271): Loss/seq after 03000 batchs: 401.0701599121094
INFO:root:Train (Epoch 271): Loss/seq after 03050 batchs: 403.13153076171875
INFO:root:Train (Epoch 271): Loss/seq after 03100 batchs: 404.74993896484375
INFO:root:Train (Epoch 271): Loss/seq after 03150 batchs: 405.62799072265625
INFO:root:Train (Epoch 271): Loss/seq after 03200 batchs: 405.6838684082031
INFO:root:Train (Epoch 271): Loss/seq after 03250 batchs: 406.23773193359375
INFO:root:Train (Epoch 271): Loss/seq after 03300 batchs: 405.566650390625
INFO:root:Train (Epoch 271): Loss/seq after 03350 batchs: 403.5252685546875
INFO:root:Train (Epoch 271): Loss/seq after 03400 batchs: 401.1505126953125
INFO:root:Train (Epoch 271): Loss/seq after 03450 batchs: 400.0334777832031
INFO:root:Train (Epoch 271): Loss/seq after 03500 batchs: 400.6247863769531
INFO:root:Train (Epoch 271): Loss/seq after 03550 batchs: 398.8664855957031
INFO:root:Train (Epoch 271): Loss/seq after 03600 batchs: 402.9689636230469
INFO:root:Train (Epoch 271): Loss/seq after 03650 batchs: 401.93731689453125
INFO:root:Train (Epoch 271): Loss/seq after 03700 batchs: 404.2184753417969
INFO:root:Train (Epoch 271): Loss/seq after 03750 batchs: 407.8648681640625
INFO:root:Train (Epoch 271): Loss/seq after 03800 batchs: 407.2418518066406
INFO:root:Train (Epoch 271): Loss/seq after 03850 batchs: 406.5414123535156
INFO:root:Train (Epoch 271): Loss/seq after 03900 batchs: 408.3887634277344
INFO:root:Train (Epoch 271): Loss/seq after 03950 batchs: 411.1563415527344
INFO:root:Train (Epoch 271): Loss/seq after 04000 batchs: 408.6452331542969
INFO:root:Train (Epoch 271): Loss/seq after 04050 batchs: 406.340087890625
INFO:root:Train (Epoch 271): Loss/seq after 04100 batchs: 405.8351135253906
INFO:root:Train (Epoch 271): Loss/seq after 04150 batchs: 405.82855224609375
INFO:root:Train (Epoch 271): Loss/seq after 04200 batchs: 404.7978820800781
INFO:root:Train (Epoch 271): Loss/seq after 04250 batchs: 403.5791015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 271): Loss/seq after 00000 batches: 407.79730224609375
INFO:root:# Valid (Epoch 271): Loss/seq after 00050 batches: 683.9418334960938
INFO:root:# Valid (Epoch 271): Loss/seq after 00100 batches: 688.5751953125
INFO:root:# Valid (Epoch 271): Loss/seq after 00150 batches: 514.5098876953125
INFO:root:# Valid (Epoch 271): Loss/seq after 00200 batches: 470.7069091796875
INFO:root:Artifacts: Make stick videos for epoch 271
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_271_on_20220423_184042.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_271_index_1317_on_20220423_184042.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 272): Loss/seq after 00000 batchs: 645.596435546875
INFO:root:Train (Epoch 272): Loss/seq after 00050 batchs: 549.7378540039062
INFO:root:Train (Epoch 272): Loss/seq after 00100 batchs: 624.8256225585938
INFO:root:Train (Epoch 272): Loss/seq after 00150 batchs: 557.4220581054688
INFO:root:Train (Epoch 272): Loss/seq after 00200 batchs: 631.1957397460938
INFO:root:Train (Epoch 272): Loss/seq after 00250 batchs: 650.8199462890625
INFO:root:Train (Epoch 272): Loss/seq after 00300 batchs: 655.4255981445312
INFO:root:Train (Epoch 272): Loss/seq after 00350 batchs: 621.691162109375
INFO:root:Train (Epoch 272): Loss/seq after 00400 batchs: 608.2125244140625
INFO:root:Train (Epoch 272): Loss/seq after 00450 batchs: 609.3817138671875
INFO:root:Train (Epoch 272): Loss/seq after 00500 batchs: 589.9140625
INFO:root:Train (Epoch 272): Loss/seq after 00550 batchs: 575.709228515625
INFO:root:Train (Epoch 272): Loss/seq after 00600 batchs: 557.2990112304688
INFO:root:Train (Epoch 272): Loss/seq after 00650 batchs: 536.9681396484375
INFO:root:Train (Epoch 272): Loss/seq after 00700 batchs: 515.0370483398438
INFO:root:Train (Epoch 272): Loss/seq after 00750 batchs: 512.0195922851562
INFO:root:Train (Epoch 272): Loss/seq after 00800 batchs: 513.0320434570312
INFO:root:Train (Epoch 272): Loss/seq after 00850 batchs: 497.1881408691406
INFO:root:Train (Epoch 272): Loss/seq after 00900 batchs: 483.76385498046875
INFO:root:Train (Epoch 272): Loss/seq after 00950 batchs: 480.6107177734375
INFO:root:Train (Epoch 272): Loss/seq after 01000 batchs: 473.2858581542969
INFO:root:Train (Epoch 272): Loss/seq after 01050 batchs: 464.2196960449219
INFO:root:Train (Epoch 272): Loss/seq after 01100 batchs: 454.527587890625
INFO:root:Train (Epoch 272): Loss/seq after 01150 batchs: 442.64154052734375
INFO:root:Train (Epoch 272): Loss/seq after 01200 batchs: 444.5731201171875
INFO:root:Train (Epoch 272): Loss/seq after 01250 batchs: 442.9381103515625
INFO:root:Train (Epoch 272): Loss/seq after 01300 batchs: 434.1228332519531
INFO:root:Train (Epoch 272): Loss/seq after 01350 batchs: 425.54681396484375
INFO:root:Train (Epoch 272): Loss/seq after 01400 batchs: 427.52618408203125
INFO:root:Train (Epoch 272): Loss/seq after 01450 batchs: 430.4676818847656
INFO:root:Train (Epoch 272): Loss/seq after 01500 batchs: 436.3750915527344
INFO:root:Train (Epoch 272): Loss/seq after 01550 batchs: 437.2933044433594
INFO:root:Train (Epoch 272): Loss/seq after 01600 batchs: 434.7116394042969
INFO:root:Train (Epoch 272): Loss/seq after 01650 batchs: 432.6324462890625
INFO:root:Train (Epoch 272): Loss/seq after 01700 batchs: 436.55218505859375
INFO:root:Train (Epoch 272): Loss/seq after 01750 batchs: 435.24627685546875
INFO:root:Train (Epoch 272): Loss/seq after 01800 batchs: 433.5034484863281
INFO:root:Train (Epoch 272): Loss/seq after 01850 batchs: 430.9516906738281
INFO:root:Train (Epoch 272): Loss/seq after 01900 batchs: 429.7618713378906
INFO:root:Train (Epoch 272): Loss/seq after 01950 batchs: 429.1740417480469
INFO:root:Train (Epoch 272): Loss/seq after 02000 batchs: 430.1905822753906
INFO:root:Train (Epoch 272): Loss/seq after 02050 batchs: 429.6120910644531
INFO:root:Train (Epoch 272): Loss/seq after 02100 batchs: 428.4316101074219
INFO:root:Train (Epoch 272): Loss/seq after 02150 batchs: 427.4517822265625
INFO:root:Train (Epoch 272): Loss/seq after 02200 batchs: 426.1940612792969
INFO:root:Train (Epoch 272): Loss/seq after 02250 batchs: 424.9283142089844
INFO:root:Train (Epoch 272): Loss/seq after 02300 batchs: 423.04168701171875
INFO:root:Train (Epoch 272): Loss/seq after 02350 batchs: 420.08782958984375
INFO:root:Train (Epoch 272): Loss/seq after 02400 batchs: 421.45135498046875
INFO:root:Train (Epoch 272): Loss/seq after 02450 batchs: 418.0819396972656
INFO:root:Train (Epoch 272): Loss/seq after 02500 batchs: 411.45928955078125
INFO:root:Train (Epoch 272): Loss/seq after 02550 batchs: 406.216552734375
INFO:root:Train (Epoch 272): Loss/seq after 02600 batchs: 402.9027404785156
INFO:root:Train (Epoch 272): Loss/seq after 02650 batchs: 399.91876220703125
INFO:root:Train (Epoch 272): Loss/seq after 02700 batchs: 397.6834716796875
INFO:root:Train (Epoch 272): Loss/seq after 02750 batchs: 393.500244140625
INFO:root:Train (Epoch 272): Loss/seq after 02800 batchs: 392.7882385253906
INFO:root:Train (Epoch 272): Loss/seq after 02850 batchs: 392.4634704589844
INFO:root:Train (Epoch 272): Loss/seq after 02900 batchs: 393.6025390625
INFO:root:Train (Epoch 272): Loss/seq after 02950 batchs: 393.9959411621094
INFO:root:Train (Epoch 272): Loss/seq after 03000 batchs: 398.407470703125
INFO:root:Train (Epoch 272): Loss/seq after 03050 batchs: 400.4228820800781
INFO:root:Train (Epoch 272): Loss/seq after 03100 batchs: 402.5185241699219
INFO:root:Train (Epoch 272): Loss/seq after 03150 batchs: 402.99688720703125
INFO:root:Train (Epoch 272): Loss/seq after 03200 batchs: 403.2882080078125
INFO:root:Train (Epoch 272): Loss/seq after 03250 batchs: 404.06573486328125
INFO:root:Train (Epoch 272): Loss/seq after 03300 batchs: 403.4477233886719
INFO:root:Train (Epoch 272): Loss/seq after 03350 batchs: 401.79058837890625
INFO:root:Train (Epoch 272): Loss/seq after 03400 batchs: 399.42340087890625
INFO:root:Train (Epoch 272): Loss/seq after 03450 batchs: 398.3790283203125
INFO:root:Train (Epoch 272): Loss/seq after 03500 batchs: 399.1492919921875
INFO:root:Train (Epoch 272): Loss/seq after 03550 batchs: 397.2785949707031
INFO:root:Train (Epoch 272): Loss/seq after 03600 batchs: 401.6290588378906
INFO:root:Train (Epoch 272): Loss/seq after 03650 batchs: 400.4004821777344
INFO:root:Train (Epoch 272): Loss/seq after 03700 batchs: 402.6367492675781
INFO:root:Train (Epoch 272): Loss/seq after 03750 batchs: 406.47137451171875
INFO:root:Train (Epoch 272): Loss/seq after 03800 batchs: 405.8671569824219
INFO:root:Train (Epoch 272): Loss/seq after 03850 batchs: 405.4879150390625
INFO:root:Train (Epoch 272): Loss/seq after 03900 batchs: 407.3569641113281
INFO:root:Train (Epoch 272): Loss/seq after 03950 batchs: 410.4557189941406
INFO:root:Train (Epoch 272): Loss/seq after 04000 batchs: 407.9377746582031
INFO:root:Train (Epoch 272): Loss/seq after 04050 batchs: 405.6013488769531
INFO:root:Train (Epoch 272): Loss/seq after 04100 batchs: 405.0295104980469
INFO:root:Train (Epoch 272): Loss/seq after 04150 batchs: 405.1807861328125
INFO:root:Train (Epoch 272): Loss/seq after 04200 batchs: 404.2058410644531
INFO:root:Train (Epoch 272): Loss/seq after 04250 batchs: 403.0339660644531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 272): Loss/seq after 00000 batches: 403.77215576171875
INFO:root:# Valid (Epoch 272): Loss/seq after 00050 batches: 696.0291137695312
INFO:root:# Valid (Epoch 272): Loss/seq after 00100 batches: 722.8566284179688
INFO:root:# Valid (Epoch 272): Loss/seq after 00150 batches: 536.9410400390625
INFO:root:# Valid (Epoch 272): Loss/seq after 00200 batches: 486.26519775390625
INFO:root:Artifacts: Make stick videos for epoch 272
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_272_on_20220423_184541.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_272_index_689_on_20220423_184541.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 273): Loss/seq after 00000 batchs: 635.558837890625
INFO:root:Train (Epoch 273): Loss/seq after 00050 batchs: 547.4140625
INFO:root:Train (Epoch 273): Loss/seq after 00100 batchs: 571.7913208007812
INFO:root:Train (Epoch 273): Loss/seq after 00150 batchs: 521.0874633789062
INFO:root:Train (Epoch 273): Loss/seq after 00200 batchs: 588.7637329101562
INFO:root:Train (Epoch 273): Loss/seq after 00250 batchs: 627.8118286132812
INFO:root:Train (Epoch 273): Loss/seq after 00300 batchs: 640.9934692382812
INFO:root:Train (Epoch 273): Loss/seq after 00350 batchs: 607.4839477539062
INFO:root:Train (Epoch 273): Loss/seq after 00400 batchs: 598.3755493164062
INFO:root:Train (Epoch 273): Loss/seq after 00450 batchs: 601.1815795898438
INFO:root:Train (Epoch 273): Loss/seq after 00500 batchs: 582.0758666992188
INFO:root:Train (Epoch 273): Loss/seq after 00550 batchs: 567.619384765625
INFO:root:Train (Epoch 273): Loss/seq after 00600 batchs: 548.4107055664062
INFO:root:Train (Epoch 273): Loss/seq after 00650 batchs: 530.4053344726562
INFO:root:Train (Epoch 273): Loss/seq after 00700 batchs: 511.4393005371094
INFO:root:Train (Epoch 273): Loss/seq after 00750 batchs: 507.83544921875
INFO:root:Train (Epoch 273): Loss/seq after 00800 batchs: 508.08935546875
INFO:root:Train (Epoch 273): Loss/seq after 00850 batchs: 492.669189453125
INFO:root:Train (Epoch 273): Loss/seq after 00900 batchs: 480.2880554199219
INFO:root:Train (Epoch 273): Loss/seq after 00950 batchs: 479.0366516113281
INFO:root:Train (Epoch 273): Loss/seq after 01000 batchs: 472.1788330078125
INFO:root:Train (Epoch 273): Loss/seq after 01050 batchs: 462.8565368652344
INFO:root:Train (Epoch 273): Loss/seq after 01100 batchs: 453.02386474609375
INFO:root:Train (Epoch 273): Loss/seq after 01150 batchs: 441.0179138183594
INFO:root:Train (Epoch 273): Loss/seq after 01200 batchs: 442.6050720214844
INFO:root:Train (Epoch 273): Loss/seq after 01250 batchs: 441.225830078125
INFO:root:Train (Epoch 273): Loss/seq after 01300 batchs: 432.7405700683594
INFO:root:Train (Epoch 273): Loss/seq after 01350 batchs: 424.2799072265625
INFO:root:Train (Epoch 273): Loss/seq after 01400 batchs: 426.4300842285156
INFO:root:Train (Epoch 273): Loss/seq after 01450 batchs: 429.6554870605469
INFO:root:Train (Epoch 273): Loss/seq after 01500 batchs: 435.10235595703125
INFO:root:Train (Epoch 273): Loss/seq after 01550 batchs: 436.2798156738281
INFO:root:Train (Epoch 273): Loss/seq after 01600 batchs: 433.5671691894531
INFO:root:Train (Epoch 273): Loss/seq after 01650 batchs: 431.80377197265625
INFO:root:Train (Epoch 273): Loss/seq after 01700 batchs: 435.75323486328125
INFO:root:Train (Epoch 273): Loss/seq after 01750 batchs: 434.4786682128906
INFO:root:Train (Epoch 273): Loss/seq after 01800 batchs: 432.59503173828125
INFO:root:Train (Epoch 273): Loss/seq after 01850 batchs: 430.0805969238281
INFO:root:Train (Epoch 273): Loss/seq after 01900 batchs: 428.78131103515625
INFO:root:Train (Epoch 273): Loss/seq after 01950 batchs: 428.44976806640625
INFO:root:Train (Epoch 273): Loss/seq after 02000 batchs: 429.4731750488281
INFO:root:Train (Epoch 273): Loss/seq after 02050 batchs: 428.8893127441406
INFO:root:Train (Epoch 273): Loss/seq after 02100 batchs: 427.6753845214844
INFO:root:Train (Epoch 273): Loss/seq after 02150 batchs: 426.8646545410156
INFO:root:Train (Epoch 273): Loss/seq after 02200 batchs: 425.5594787597656
INFO:root:Train (Epoch 273): Loss/seq after 02250 batchs: 424.8534851074219
INFO:root:Train (Epoch 273): Loss/seq after 02300 batchs: 423.740478515625
INFO:root:Train (Epoch 273): Loss/seq after 02350 batchs: 420.9324645996094
INFO:root:Train (Epoch 273): Loss/seq after 02400 batchs: 422.3067626953125
INFO:root:Train (Epoch 273): Loss/seq after 02450 batchs: 418.8072814941406
INFO:root:Train (Epoch 273): Loss/seq after 02500 batchs: 412.1150207519531
INFO:root:Train (Epoch 273): Loss/seq after 02550 batchs: 406.9085998535156
INFO:root:Train (Epoch 273): Loss/seq after 02600 batchs: 403.84942626953125
INFO:root:Train (Epoch 273): Loss/seq after 02650 batchs: 400.7803649902344
INFO:root:Train (Epoch 273): Loss/seq after 02700 batchs: 398.48968505859375
INFO:root:Train (Epoch 273): Loss/seq after 02750 batchs: 394.58758544921875
INFO:root:Train (Epoch 273): Loss/seq after 02800 batchs: 393.5129089355469
INFO:root:Train (Epoch 273): Loss/seq after 02850 batchs: 393.27459716796875
INFO:root:Train (Epoch 273): Loss/seq after 02900 batchs: 394.5517272949219
INFO:root:Train (Epoch 273): Loss/seq after 02950 batchs: 394.96978759765625
INFO:root:Train (Epoch 273): Loss/seq after 03000 batchs: 399.0099792480469
INFO:root:Train (Epoch 273): Loss/seq after 03050 batchs: 401.4617614746094
INFO:root:Train (Epoch 273): Loss/seq after 03100 batchs: 403.23394775390625
INFO:root:Train (Epoch 273): Loss/seq after 03150 batchs: 404.20697021484375
INFO:root:Train (Epoch 273): Loss/seq after 03200 batchs: 404.56524658203125
INFO:root:Train (Epoch 273): Loss/seq after 03250 batchs: 405.35369873046875
INFO:root:Train (Epoch 273): Loss/seq after 03300 batchs: 404.63311767578125
INFO:root:Train (Epoch 273): Loss/seq after 03350 batchs: 402.6739196777344
INFO:root:Train (Epoch 273): Loss/seq after 03400 batchs: 400.139404296875
INFO:root:Train (Epoch 273): Loss/seq after 03450 batchs: 398.980712890625
INFO:root:Train (Epoch 273): Loss/seq after 03500 batchs: 400.0262145996094
INFO:root:Train (Epoch 273): Loss/seq after 03550 batchs: 398.2433776855469
INFO:root:Train (Epoch 273): Loss/seq after 03600 batchs: 402.3438720703125
INFO:root:Train (Epoch 273): Loss/seq after 03650 batchs: 401.2497863769531
INFO:root:Train (Epoch 273): Loss/seq after 03700 batchs: 403.40631103515625
INFO:root:Train (Epoch 273): Loss/seq after 03750 batchs: 407.2290344238281
INFO:root:Train (Epoch 273): Loss/seq after 03800 batchs: 406.48748779296875
INFO:root:Train (Epoch 273): Loss/seq after 03850 batchs: 405.8255310058594
INFO:root:Train (Epoch 273): Loss/seq after 03900 batchs: 407.5321960449219
INFO:root:Train (Epoch 273): Loss/seq after 03950 batchs: 410.134033203125
INFO:root:Train (Epoch 273): Loss/seq after 04000 batchs: 407.59808349609375
INFO:root:Train (Epoch 273): Loss/seq after 04050 batchs: 405.2283935546875
INFO:root:Train (Epoch 273): Loss/seq after 04100 batchs: 404.7579345703125
INFO:root:Train (Epoch 273): Loss/seq after 04150 batchs: 404.79827880859375
INFO:root:Train (Epoch 273): Loss/seq after 04200 batchs: 403.7969055175781
INFO:root:Train (Epoch 273): Loss/seq after 04250 batchs: 402.6056213378906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 273): Loss/seq after 00000 batches: 416.7877502441406
INFO:root:# Valid (Epoch 273): Loss/seq after 00050 batches: 724.2694091796875
INFO:root:# Valid (Epoch 273): Loss/seq after 00100 batches: 764.7562255859375
INFO:root:# Valid (Epoch 273): Loss/seq after 00150 batches: 566.435546875
INFO:root:# Valid (Epoch 273): Loss/seq after 00200 batches: 507.16925048828125
INFO:root:Artifacts: Make stick videos for epoch 273
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_273_on_20220423_185034.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_273_index_1644_on_20220423_185034.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 274): Loss/seq after 00000 batchs: 650.7518920898438
INFO:root:Train (Epoch 274): Loss/seq after 00050 batchs: 527.9680786132812
INFO:root:Train (Epoch 274): Loss/seq after 00100 batchs: 535.982421875
INFO:root:Train (Epoch 274): Loss/seq after 00150 batchs: 493.8931579589844
INFO:root:Train (Epoch 274): Loss/seq after 00200 batchs: 568.9708251953125
INFO:root:Train (Epoch 274): Loss/seq after 00250 batchs: 614.8101196289062
INFO:root:Train (Epoch 274): Loss/seq after 00300 batchs: 626.9584350585938
INFO:root:Train (Epoch 274): Loss/seq after 00350 batchs: 595.3937377929688
INFO:root:Train (Epoch 274): Loss/seq after 00400 batchs: 596.6576538085938
INFO:root:Train (Epoch 274): Loss/seq after 00450 batchs: 600.2542724609375
INFO:root:Train (Epoch 274): Loss/seq after 00500 batchs: 585.3193969726562
INFO:root:Train (Epoch 274): Loss/seq after 00550 batchs: 571.3505249023438
INFO:root:Train (Epoch 274): Loss/seq after 00600 batchs: 553.88330078125
INFO:root:Train (Epoch 274): Loss/seq after 00650 batchs: 538.2697143554688
INFO:root:Train (Epoch 274): Loss/seq after 00700 batchs: 517.7775268554688
INFO:root:Train (Epoch 274): Loss/seq after 00750 batchs: 512.3444213867188
INFO:root:Train (Epoch 274): Loss/seq after 00800 batchs: 512.9961547851562
INFO:root:Train (Epoch 274): Loss/seq after 00850 batchs: 497.0408020019531
INFO:root:Train (Epoch 274): Loss/seq after 00900 batchs: 483.77301025390625
INFO:root:Train (Epoch 274): Loss/seq after 00950 batchs: 482.2658996582031
INFO:root:Train (Epoch 274): Loss/seq after 01000 batchs: 474.73797607421875
INFO:root:Train (Epoch 274): Loss/seq after 01050 batchs: 465.00689697265625
INFO:root:Train (Epoch 274): Loss/seq after 01100 batchs: 455.0316162109375
INFO:root:Train (Epoch 274): Loss/seq after 01150 batchs: 443.1661071777344
INFO:root:Train (Epoch 274): Loss/seq after 01200 batchs: 444.40594482421875
INFO:root:Train (Epoch 274): Loss/seq after 01250 batchs: 443.18939208984375
INFO:root:Train (Epoch 274): Loss/seq after 01300 batchs: 433.9141540527344
INFO:root:Train (Epoch 274): Loss/seq after 01350 batchs: 425.20367431640625
INFO:root:Train (Epoch 274): Loss/seq after 01400 batchs: 426.8067932128906
INFO:root:Train (Epoch 274): Loss/seq after 01450 batchs: 429.81201171875
INFO:root:Train (Epoch 274): Loss/seq after 01500 batchs: 435.1399230957031
INFO:root:Train (Epoch 274): Loss/seq after 01550 batchs: 436.05328369140625
INFO:root:Train (Epoch 274): Loss/seq after 01600 batchs: 433.32012939453125
INFO:root:Train (Epoch 274): Loss/seq after 01650 batchs: 431.1797180175781
INFO:root:Train (Epoch 274): Loss/seq after 01700 batchs: 434.7275390625
INFO:root:Train (Epoch 274): Loss/seq after 01750 batchs: 433.3150939941406
INFO:root:Train (Epoch 274): Loss/seq after 01800 batchs: 431.2969970703125
INFO:root:Train (Epoch 274): Loss/seq after 01850 batchs: 428.6564025878906
INFO:root:Train (Epoch 274): Loss/seq after 01900 batchs: 427.34991455078125
INFO:root:Train (Epoch 274): Loss/seq after 01950 batchs: 426.7118225097656
INFO:root:Train (Epoch 274): Loss/seq after 02000 batchs: 427.6952819824219
INFO:root:Train (Epoch 274): Loss/seq after 02050 batchs: 427.11590576171875
INFO:root:Train (Epoch 274): Loss/seq after 02100 batchs: 426.00048828125
INFO:root:Train (Epoch 274): Loss/seq after 02150 batchs: 425.1220397949219
INFO:root:Train (Epoch 274): Loss/seq after 02200 batchs: 423.85186767578125
INFO:root:Train (Epoch 274): Loss/seq after 02250 batchs: 422.97003173828125
INFO:root:Train (Epoch 274): Loss/seq after 02300 batchs: 420.82073974609375
INFO:root:Train (Epoch 274): Loss/seq after 02350 batchs: 418.3052673339844
INFO:root:Train (Epoch 274): Loss/seq after 02400 batchs: 419.8683166503906
INFO:root:Train (Epoch 274): Loss/seq after 02450 batchs: 416.4398498535156
INFO:root:Train (Epoch 274): Loss/seq after 02500 batchs: 409.7931823730469
INFO:root:Train (Epoch 274): Loss/seq after 02550 batchs: 404.5908203125
INFO:root:Train (Epoch 274): Loss/seq after 02600 batchs: 401.18701171875
INFO:root:Train (Epoch 274): Loss/seq after 02650 batchs: 398.1097717285156
INFO:root:Train (Epoch 274): Loss/seq after 02700 batchs: 395.8003234863281
INFO:root:Train (Epoch 274): Loss/seq after 02750 batchs: 391.80157470703125
INFO:root:Train (Epoch 274): Loss/seq after 02800 batchs: 390.5804748535156
INFO:root:Train (Epoch 274): Loss/seq after 02850 batchs: 390.4362487792969
INFO:root:Train (Epoch 274): Loss/seq after 02900 batchs: 391.41363525390625
INFO:root:Train (Epoch 274): Loss/seq after 02950 batchs: 391.92742919921875
INFO:root:Train (Epoch 274): Loss/seq after 03000 batchs: 396.1950378417969
INFO:root:Train (Epoch 274): Loss/seq after 03050 batchs: 398.7376403808594
INFO:root:Train (Epoch 274): Loss/seq after 03100 batchs: 400.9635925292969
INFO:root:Train (Epoch 274): Loss/seq after 03150 batchs: 401.90509033203125
INFO:root:Train (Epoch 274): Loss/seq after 03200 batchs: 403.9744567871094
INFO:root:Train (Epoch 274): Loss/seq after 03250 batchs: 406.3501281738281
INFO:root:Train (Epoch 274): Loss/seq after 03300 batchs: 406.1099548339844
INFO:root:Train (Epoch 274): Loss/seq after 03350 batchs: 404.2045593261719
INFO:root:Train (Epoch 274): Loss/seq after 03400 batchs: 401.6120910644531
INFO:root:Train (Epoch 274): Loss/seq after 03450 batchs: 400.5136413574219
INFO:root:Train (Epoch 274): Loss/seq after 03500 batchs: 401.5359802246094
INFO:root:Train (Epoch 274): Loss/seq after 03550 batchs: 399.9726867675781
INFO:root:Train (Epoch 274): Loss/seq after 03600 batchs: 404.2665710449219
INFO:root:Train (Epoch 274): Loss/seq after 03650 batchs: 403.536865234375
INFO:root:Train (Epoch 274): Loss/seq after 03700 batchs: 405.9898376464844
INFO:root:Train (Epoch 274): Loss/seq after 03750 batchs: 409.74822998046875
INFO:root:Train (Epoch 274): Loss/seq after 03800 batchs: 409.02288818359375
INFO:root:Train (Epoch 274): Loss/seq after 03850 batchs: 408.3406066894531
INFO:root:Train (Epoch 274): Loss/seq after 03900 batchs: 410.1905212402344
INFO:root:Train (Epoch 274): Loss/seq after 03950 batchs: 412.99578857421875
INFO:root:Train (Epoch 274): Loss/seq after 04000 batchs: 410.4783020019531
INFO:root:Train (Epoch 274): Loss/seq after 04050 batchs: 408.1569519042969
INFO:root:Train (Epoch 274): Loss/seq after 04100 batchs: 407.5937194824219
INFO:root:Train (Epoch 274): Loss/seq after 04150 batchs: 407.5859375
INFO:root:Train (Epoch 274): Loss/seq after 04200 batchs: 406.5261535644531
INFO:root:Train (Epoch 274): Loss/seq after 04250 batchs: 405.3529052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 274): Loss/seq after 00000 batches: 430.5372314453125
INFO:root:# Valid (Epoch 274): Loss/seq after 00050 batches: 741.6619262695312
INFO:root:# Valid (Epoch 274): Loss/seq after 00100 batches: 770.356201171875
INFO:root:# Valid (Epoch 274): Loss/seq after 00150 batches: 567.6927490234375
INFO:root:# Valid (Epoch 274): Loss/seq after 00200 batches: 510.3440856933594
INFO:root:Artifacts: Make stick videos for epoch 274
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_274_on_20220423_185538.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_274_index_880_on_20220423_185538.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 275): Loss/seq after 00000 batchs: 573.7327270507812
INFO:root:Train (Epoch 275): Loss/seq after 00050 batchs: 551.2527465820312
INFO:root:Train (Epoch 275): Loss/seq after 00100 batchs: 561.294921875
INFO:root:Train (Epoch 275): Loss/seq after 00150 batchs: 509.86993408203125
INFO:root:Train (Epoch 275): Loss/seq after 00200 batchs: 579.9891967773438
INFO:root:Train (Epoch 275): Loss/seq after 00250 batchs: 602.3056640625
INFO:root:Train (Epoch 275): Loss/seq after 00300 batchs: 615.7230834960938
INFO:root:Train (Epoch 275): Loss/seq after 00350 batchs: 585.83544921875
INFO:root:Train (Epoch 275): Loss/seq after 00400 batchs: 574.928466796875
INFO:root:Train (Epoch 275): Loss/seq after 00450 batchs: 580.1456909179688
INFO:root:Train (Epoch 275): Loss/seq after 00500 batchs: 564.2086181640625
INFO:root:Train (Epoch 275): Loss/seq after 00550 batchs: 551.4090576171875
INFO:root:Train (Epoch 275): Loss/seq after 00600 batchs: 534.7807006835938
INFO:root:Train (Epoch 275): Loss/seq after 00650 batchs: 520.2581787109375
INFO:root:Train (Epoch 275): Loss/seq after 00700 batchs: 501.8875427246094
INFO:root:Train (Epoch 275): Loss/seq after 00750 batchs: 499.61224365234375
INFO:root:Train (Epoch 275): Loss/seq after 00800 batchs: 501.0168151855469
INFO:root:Train (Epoch 275): Loss/seq after 00850 batchs: 486.1716613769531
INFO:root:Train (Epoch 275): Loss/seq after 00900 batchs: 473.40380859375
INFO:root:Train (Epoch 275): Loss/seq after 00950 batchs: 471.20477294921875
INFO:root:Train (Epoch 275): Loss/seq after 01000 batchs: 465.5822448730469
INFO:root:Train (Epoch 275): Loss/seq after 01050 batchs: 455.8453674316406
INFO:root:Train (Epoch 275): Loss/seq after 01100 batchs: 446.50579833984375
INFO:root:Train (Epoch 275): Loss/seq after 01150 batchs: 434.7681579589844
INFO:root:Train (Epoch 275): Loss/seq after 01200 batchs: 436.9398498535156
INFO:root:Train (Epoch 275): Loss/seq after 01250 batchs: 435.9202575683594
INFO:root:Train (Epoch 275): Loss/seq after 01300 batchs: 427.1512145996094
INFO:root:Train (Epoch 275): Loss/seq after 01350 batchs: 419.1123962402344
INFO:root:Train (Epoch 275): Loss/seq after 01400 batchs: 422.7458801269531
INFO:root:Train (Epoch 275): Loss/seq after 01450 batchs: 426.3360900878906
INFO:root:Train (Epoch 275): Loss/seq after 01500 batchs: 431.91552734375
INFO:root:Train (Epoch 275): Loss/seq after 01550 batchs: 433.2183532714844
INFO:root:Train (Epoch 275): Loss/seq after 01600 batchs: 430.6010437011719
INFO:root:Train (Epoch 275): Loss/seq after 01650 batchs: 428.49371337890625
INFO:root:Train (Epoch 275): Loss/seq after 01700 batchs: 432.30377197265625
INFO:root:Train (Epoch 275): Loss/seq after 01750 batchs: 430.8612365722656
INFO:root:Train (Epoch 275): Loss/seq after 01800 batchs: 429.18719482421875
INFO:root:Train (Epoch 275): Loss/seq after 01850 batchs: 426.7020263671875
INFO:root:Train (Epoch 275): Loss/seq after 01900 batchs: 425.48968505859375
INFO:root:Train (Epoch 275): Loss/seq after 01950 batchs: 424.7322082519531
INFO:root:Train (Epoch 275): Loss/seq after 02000 batchs: 425.6180114746094
INFO:root:Train (Epoch 275): Loss/seq after 02050 batchs: 425.1811828613281
INFO:root:Train (Epoch 275): Loss/seq after 02100 batchs: 424.09600830078125
INFO:root:Train (Epoch 275): Loss/seq after 02150 batchs: 423.1864318847656
INFO:root:Train (Epoch 275): Loss/seq after 02200 batchs: 422.0157470703125
INFO:root:Train (Epoch 275): Loss/seq after 02250 batchs: 421.3997497558594
INFO:root:Train (Epoch 275): Loss/seq after 02300 batchs: 419.02276611328125
INFO:root:Train (Epoch 275): Loss/seq after 02350 batchs: 416.2591552734375
INFO:root:Train (Epoch 275): Loss/seq after 02400 batchs: 417.7541809082031
INFO:root:Train (Epoch 275): Loss/seq after 02450 batchs: 414.3022766113281
INFO:root:Train (Epoch 275): Loss/seq after 02500 batchs: 407.7073974609375
INFO:root:Train (Epoch 275): Loss/seq after 02550 batchs: 402.7051696777344
INFO:root:Train (Epoch 275): Loss/seq after 02600 batchs: 399.442138671875
INFO:root:Train (Epoch 275): Loss/seq after 02650 batchs: 396.41253662109375
INFO:root:Train (Epoch 275): Loss/seq after 02700 batchs: 394.102294921875
INFO:root:Train (Epoch 275): Loss/seq after 02750 batchs: 390.090576171875
INFO:root:Train (Epoch 275): Loss/seq after 02800 batchs: 390.0194396972656
INFO:root:Train (Epoch 275): Loss/seq after 02850 batchs: 389.8897399902344
INFO:root:Train (Epoch 275): Loss/seq after 02900 batchs: 391.0919494628906
INFO:root:Train (Epoch 275): Loss/seq after 02950 batchs: 391.47760009765625
INFO:root:Train (Epoch 275): Loss/seq after 03000 batchs: 395.55609130859375
INFO:root:Train (Epoch 275): Loss/seq after 03050 batchs: 397.8067932128906
INFO:root:Train (Epoch 275): Loss/seq after 03100 batchs: 399.66033935546875
INFO:root:Train (Epoch 275): Loss/seq after 03150 batchs: 400.36224365234375
INFO:root:Train (Epoch 275): Loss/seq after 03200 batchs: 400.6834716796875
INFO:root:Train (Epoch 275): Loss/seq after 03250 batchs: 401.27447509765625
INFO:root:Train (Epoch 275): Loss/seq after 03300 batchs: 400.64678955078125
INFO:root:Train (Epoch 275): Loss/seq after 03350 batchs: 399.0827941894531
INFO:root:Train (Epoch 275): Loss/seq after 03400 batchs: 396.71478271484375
INFO:root:Train (Epoch 275): Loss/seq after 03450 batchs: 395.50531005859375
INFO:root:Train (Epoch 275): Loss/seq after 03500 batchs: 396.1769104003906
INFO:root:Train (Epoch 275): Loss/seq after 03550 batchs: 394.44720458984375
INFO:root:Train (Epoch 275): Loss/seq after 03600 batchs: 398.79229736328125
INFO:root:Train (Epoch 275): Loss/seq after 03650 batchs: 397.9806823730469
INFO:root:Train (Epoch 275): Loss/seq after 03700 batchs: 400.5660705566406
INFO:root:Train (Epoch 275): Loss/seq after 03750 batchs: 404.2566833496094
INFO:root:Train (Epoch 275): Loss/seq after 03800 batchs: 403.5542297363281
INFO:root:Train (Epoch 275): Loss/seq after 03850 batchs: 403.1021423339844
INFO:root:Train (Epoch 275): Loss/seq after 03900 batchs: 404.868408203125
INFO:root:Train (Epoch 275): Loss/seq after 03950 batchs: 407.5405578613281
INFO:root:Train (Epoch 275): Loss/seq after 04000 batchs: 405.0408630371094
INFO:root:Train (Epoch 275): Loss/seq after 04050 batchs: 402.76763916015625
INFO:root:Train (Epoch 275): Loss/seq after 04100 batchs: 402.3246154785156
INFO:root:Train (Epoch 275): Loss/seq after 04150 batchs: 402.3936767578125
INFO:root:Train (Epoch 275): Loss/seq after 04200 batchs: 401.33721923828125
INFO:root:Train (Epoch 275): Loss/seq after 04250 batchs: 400.1775817871094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 275): Loss/seq after 00000 batches: 441.9649658203125
INFO:root:# Valid (Epoch 275): Loss/seq after 00050 batches: 721.1242065429688
INFO:root:# Valid (Epoch 275): Loss/seq after 00100 batches: 736.2687377929688
INFO:root:# Valid (Epoch 275): Loss/seq after 00150 batches: 544.9601440429688
INFO:root:# Valid (Epoch 275): Loss/seq after 00200 batches: 492.17144775390625
INFO:root:Artifacts: Make stick videos for epoch 275
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_275_on_20220423_190034.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_275_index_1561_on_20220423_190034.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 276): Loss/seq after 00000 batchs: 583.1710205078125
INFO:root:Train (Epoch 276): Loss/seq after 00050 batchs: 562.922119140625
INFO:root:Train (Epoch 276): Loss/seq after 00100 batchs: 569.7840576171875
INFO:root:Train (Epoch 276): Loss/seq after 00150 batchs: 519.8483276367188
INFO:root:Train (Epoch 276): Loss/seq after 00200 batchs: 584.1057739257812
INFO:root:Train (Epoch 276): Loss/seq after 00250 batchs: 633.8065795898438
INFO:root:Train (Epoch 276): Loss/seq after 00300 batchs: 642.9882202148438
INFO:root:Train (Epoch 276): Loss/seq after 00350 batchs: 610.41552734375
INFO:root:Train (Epoch 276): Loss/seq after 00400 batchs: 600.9791870117188
INFO:root:Train (Epoch 276): Loss/seq after 00450 batchs: 603.296630859375
INFO:root:Train (Epoch 276): Loss/seq after 00500 batchs: 584.3348999023438
INFO:root:Train (Epoch 276): Loss/seq after 00550 batchs: 570.0985717773438
INFO:root:Train (Epoch 276): Loss/seq after 00600 batchs: 550.1893920898438
INFO:root:Train (Epoch 276): Loss/seq after 00650 batchs: 532.0762939453125
INFO:root:Train (Epoch 276): Loss/seq after 00700 batchs: 512.7277221679688
INFO:root:Train (Epoch 276): Loss/seq after 00750 batchs: 510.6034240722656
INFO:root:Train (Epoch 276): Loss/seq after 00800 batchs: 510.7088928222656
INFO:root:Train (Epoch 276): Loss/seq after 00850 batchs: 495.23101806640625
INFO:root:Train (Epoch 276): Loss/seq after 00900 batchs: 481.87066650390625
INFO:root:Train (Epoch 276): Loss/seq after 00950 batchs: 480.9328918457031
INFO:root:Train (Epoch 276): Loss/seq after 01000 batchs: 472.99725341796875
INFO:root:Train (Epoch 276): Loss/seq after 01050 batchs: 463.4104919433594
INFO:root:Train (Epoch 276): Loss/seq after 01100 batchs: 453.8681640625
INFO:root:Train (Epoch 276): Loss/seq after 01150 batchs: 441.3096008300781
INFO:root:Train (Epoch 276): Loss/seq after 01200 batchs: 442.6413879394531
INFO:root:Train (Epoch 276): Loss/seq after 01250 batchs: 441.37908935546875
INFO:root:Train (Epoch 276): Loss/seq after 01300 batchs: 432.29241943359375
INFO:root:Train (Epoch 276): Loss/seq after 01350 batchs: 423.5061950683594
INFO:root:Train (Epoch 276): Loss/seq after 01400 batchs: 424.45556640625
INFO:root:Train (Epoch 276): Loss/seq after 01450 batchs: 427.5483703613281
INFO:root:Train (Epoch 276): Loss/seq after 01500 batchs: 433.30169677734375
INFO:root:Train (Epoch 276): Loss/seq after 01550 batchs: 434.40985107421875
INFO:root:Train (Epoch 276): Loss/seq after 01600 batchs: 431.9104309082031
INFO:root:Train (Epoch 276): Loss/seq after 01650 batchs: 429.84747314453125
INFO:root:Train (Epoch 276): Loss/seq after 01700 batchs: 433.3582458496094
INFO:root:Train (Epoch 276): Loss/seq after 01750 batchs: 431.96173095703125
INFO:root:Train (Epoch 276): Loss/seq after 01800 batchs: 430.10540771484375
INFO:root:Train (Epoch 276): Loss/seq after 01850 batchs: 427.5445861816406
INFO:root:Train (Epoch 276): Loss/seq after 01900 batchs: 426.0268859863281
INFO:root:Train (Epoch 276): Loss/seq after 01950 batchs: 425.29364013671875
INFO:root:Train (Epoch 276): Loss/seq after 02000 batchs: 426.2279357910156
INFO:root:Train (Epoch 276): Loss/seq after 02050 batchs: 425.7826843261719
INFO:root:Train (Epoch 276): Loss/seq after 02100 batchs: 424.7049560546875
INFO:root:Train (Epoch 276): Loss/seq after 02150 batchs: 423.5547180175781
INFO:root:Train (Epoch 276): Loss/seq after 02200 batchs: 422.39501953125
INFO:root:Train (Epoch 276): Loss/seq after 02250 batchs: 421.31512451171875
INFO:root:Train (Epoch 276): Loss/seq after 02300 batchs: 418.5613098144531
INFO:root:Train (Epoch 276): Loss/seq after 02350 batchs: 415.7016906738281
INFO:root:Train (Epoch 276): Loss/seq after 02400 batchs: 417.2976989746094
INFO:root:Train (Epoch 276): Loss/seq after 02450 batchs: 413.9306640625
INFO:root:Train (Epoch 276): Loss/seq after 02500 batchs: 407.3877868652344
INFO:root:Train (Epoch 276): Loss/seq after 02550 batchs: 402.2330017089844
INFO:root:Train (Epoch 276): Loss/seq after 02600 batchs: 399.064208984375
INFO:root:Train (Epoch 276): Loss/seq after 02650 batchs: 395.6528625488281
INFO:root:Train (Epoch 276): Loss/seq after 02700 batchs: 393.3560485839844
INFO:root:Train (Epoch 276): Loss/seq after 02750 batchs: 389.06658935546875
INFO:root:Train (Epoch 276): Loss/seq after 02800 batchs: 387.5260009765625
INFO:root:Train (Epoch 276): Loss/seq after 02850 batchs: 387.3653259277344
INFO:root:Train (Epoch 276): Loss/seq after 02900 batchs: 388.4344177246094
INFO:root:Train (Epoch 276): Loss/seq after 02950 batchs: 388.88275146484375
INFO:root:Train (Epoch 276): Loss/seq after 03000 batchs: 392.840576171875
INFO:root:Train (Epoch 276): Loss/seq after 03050 batchs: 394.9396667480469
INFO:root:Train (Epoch 276): Loss/seq after 03100 batchs: 396.456787109375
INFO:root:Train (Epoch 276): Loss/seq after 03150 batchs: 397.4207763671875
INFO:root:Train (Epoch 276): Loss/seq after 03200 batchs: 397.426513671875
INFO:root:Train (Epoch 276): Loss/seq after 03250 batchs: 398.1635437011719
INFO:root:Train (Epoch 276): Loss/seq after 03300 batchs: 397.3747863769531
INFO:root:Train (Epoch 276): Loss/seq after 03350 batchs: 395.6494140625
INFO:root:Train (Epoch 276): Loss/seq after 03400 batchs: 393.431640625
INFO:root:Train (Epoch 276): Loss/seq after 03450 batchs: 392.28021240234375
INFO:root:Train (Epoch 276): Loss/seq after 03500 batchs: 393.1180725097656
INFO:root:Train (Epoch 276): Loss/seq after 03550 batchs: 391.5444641113281
INFO:root:Train (Epoch 276): Loss/seq after 03600 batchs: 395.4394226074219
INFO:root:Train (Epoch 276): Loss/seq after 03650 batchs: 394.527587890625
INFO:root:Train (Epoch 276): Loss/seq after 03700 batchs: 396.9472961425781
INFO:root:Train (Epoch 276): Loss/seq after 03750 batchs: 400.7523498535156
INFO:root:Train (Epoch 276): Loss/seq after 03800 batchs: 400.15997314453125
INFO:root:Train (Epoch 276): Loss/seq after 03850 batchs: 399.6311340332031
INFO:root:Train (Epoch 276): Loss/seq after 03900 batchs: 401.45306396484375
INFO:root:Train (Epoch 276): Loss/seq after 03950 batchs: 404.1302795410156
INFO:root:Train (Epoch 276): Loss/seq after 04000 batchs: 401.671142578125
INFO:root:Train (Epoch 276): Loss/seq after 04050 batchs: 399.4263000488281
INFO:root:Train (Epoch 276): Loss/seq after 04100 batchs: 399.05242919921875
INFO:root:Train (Epoch 276): Loss/seq after 04150 batchs: 399.1990661621094
INFO:root:Train (Epoch 276): Loss/seq after 04200 batchs: 398.23870849609375
INFO:root:Train (Epoch 276): Loss/seq after 04250 batchs: 397.1856689453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 276): Loss/seq after 00000 batches: 372.9763488769531
INFO:root:# Valid (Epoch 276): Loss/seq after 00050 batches: 769.266357421875
INFO:root:# Valid (Epoch 276): Loss/seq after 00100 batches: 778.1336669921875
INFO:root:# Valid (Epoch 276): Loss/seq after 00150 batches: 573.8909301757812
INFO:root:# Valid (Epoch 276): Loss/seq after 00200 batches: 514.9418334960938
INFO:root:Artifacts: Make stick videos for epoch 276
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_276_on_20220423_190538.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_276_index_1260_on_20220423_190538.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 277): Loss/seq after 00000 batchs: 563.4064331054688
INFO:root:Train (Epoch 277): Loss/seq after 00050 batchs: 519.6141967773438
INFO:root:Train (Epoch 277): Loss/seq after 00100 batchs: 530.4617919921875
INFO:root:Train (Epoch 277): Loss/seq after 00150 batchs: 486.96575927734375
INFO:root:Train (Epoch 277): Loss/seq after 00200 batchs: 557.4319458007812
INFO:root:Train (Epoch 277): Loss/seq after 00250 batchs: 592.9887084960938
INFO:root:Train (Epoch 277): Loss/seq after 00300 batchs: 607.1183471679688
INFO:root:Train (Epoch 277): Loss/seq after 00350 batchs: 577.9576416015625
INFO:root:Train (Epoch 277): Loss/seq after 00400 batchs: 569.9362182617188
INFO:root:Train (Epoch 277): Loss/seq after 00450 batchs: 575.8510131835938
INFO:root:Train (Epoch 277): Loss/seq after 00500 batchs: 557.1744995117188
INFO:root:Train (Epoch 277): Loss/seq after 00550 batchs: 546.3017578125
INFO:root:Train (Epoch 277): Loss/seq after 00600 batchs: 528.2000732421875
INFO:root:Train (Epoch 277): Loss/seq after 00650 batchs: 509.79345703125
INFO:root:Train (Epoch 277): Loss/seq after 00700 batchs: 489.1408386230469
INFO:root:Train (Epoch 277): Loss/seq after 00750 batchs: 483.7425842285156
INFO:root:Train (Epoch 277): Loss/seq after 00800 batchs: 485.5264892578125
INFO:root:Train (Epoch 277): Loss/seq after 00850 batchs: 471.25775146484375
INFO:root:Train (Epoch 277): Loss/seq after 00900 batchs: 459.2294921875
INFO:root:Train (Epoch 277): Loss/seq after 00950 batchs: 457.0650939941406
INFO:root:Train (Epoch 277): Loss/seq after 01000 batchs: 450.61834716796875
INFO:root:Train (Epoch 277): Loss/seq after 01050 batchs: 441.7901306152344
INFO:root:Train (Epoch 277): Loss/seq after 01100 batchs: 432.4963073730469
INFO:root:Train (Epoch 277): Loss/seq after 01150 batchs: 421.7886962890625
INFO:root:Train (Epoch 277): Loss/seq after 01200 batchs: 423.51220703125
INFO:root:Train (Epoch 277): Loss/seq after 01250 batchs: 422.6085510253906
INFO:root:Train (Epoch 277): Loss/seq after 01300 batchs: 414.20367431640625
INFO:root:Train (Epoch 277): Loss/seq after 01350 batchs: 406.2501220703125
INFO:root:Train (Epoch 277): Loss/seq after 01400 batchs: 408.9593200683594
INFO:root:Train (Epoch 277): Loss/seq after 01450 batchs: 412.5507507324219
INFO:root:Train (Epoch 277): Loss/seq after 01500 batchs: 418.6628112792969
INFO:root:Train (Epoch 277): Loss/seq after 01550 batchs: 419.7974853515625
INFO:root:Train (Epoch 277): Loss/seq after 01600 batchs: 417.6921691894531
INFO:root:Train (Epoch 277): Loss/seq after 01650 batchs: 416.1354064941406
INFO:root:Train (Epoch 277): Loss/seq after 01700 batchs: 419.9761657714844
INFO:root:Train (Epoch 277): Loss/seq after 01750 batchs: 419.0764465332031
INFO:root:Train (Epoch 277): Loss/seq after 01800 batchs: 417.44744873046875
INFO:root:Train (Epoch 277): Loss/seq after 01850 batchs: 415.0868835449219
INFO:root:Train (Epoch 277): Loss/seq after 01900 batchs: 413.9184875488281
INFO:root:Train (Epoch 277): Loss/seq after 01950 batchs: 413.4920959472656
INFO:root:Train (Epoch 277): Loss/seq after 02000 batchs: 414.5929260253906
INFO:root:Train (Epoch 277): Loss/seq after 02050 batchs: 414.1584777832031
INFO:root:Train (Epoch 277): Loss/seq after 02100 batchs: 413.1413879394531
INFO:root:Train (Epoch 277): Loss/seq after 02150 batchs: 412.4989929199219
INFO:root:Train (Epoch 277): Loss/seq after 02200 batchs: 411.5398254394531
INFO:root:Train (Epoch 277): Loss/seq after 02250 batchs: 410.9448547363281
INFO:root:Train (Epoch 277): Loss/seq after 02300 batchs: 408.7880554199219
INFO:root:Train (Epoch 277): Loss/seq after 02350 batchs: 406.06475830078125
INFO:root:Train (Epoch 277): Loss/seq after 02400 batchs: 407.68463134765625
INFO:root:Train (Epoch 277): Loss/seq after 02450 batchs: 404.6239318847656
INFO:root:Train (Epoch 277): Loss/seq after 02500 batchs: 398.1676940917969
INFO:root:Train (Epoch 277): Loss/seq after 02550 batchs: 393.2137451171875
INFO:root:Train (Epoch 277): Loss/seq after 02600 batchs: 390.095703125
INFO:root:Train (Epoch 277): Loss/seq after 02650 batchs: 386.98492431640625
INFO:root:Train (Epoch 277): Loss/seq after 02700 batchs: 384.85107421875
INFO:root:Train (Epoch 277): Loss/seq after 02750 batchs: 381.0206604003906
INFO:root:Train (Epoch 277): Loss/seq after 02800 batchs: 381.0406188964844
INFO:root:Train (Epoch 277): Loss/seq after 02850 batchs: 380.9982604980469
INFO:root:Train (Epoch 277): Loss/seq after 02900 batchs: 381.9945068359375
INFO:root:Train (Epoch 277): Loss/seq after 02950 batchs: 382.5321960449219
INFO:root:Train (Epoch 277): Loss/seq after 03000 batchs: 386.43206787109375
INFO:root:Train (Epoch 277): Loss/seq after 03050 batchs: 388.47760009765625
INFO:root:Train (Epoch 277): Loss/seq after 03100 batchs: 390.2011413574219
INFO:root:Train (Epoch 277): Loss/seq after 03150 batchs: 391.1161193847656
INFO:root:Train (Epoch 277): Loss/seq after 03200 batchs: 390.83123779296875
INFO:root:Train (Epoch 277): Loss/seq after 03250 batchs: 392.450927734375
INFO:root:Train (Epoch 277): Loss/seq after 03300 batchs: 392.23443603515625
INFO:root:Train (Epoch 277): Loss/seq after 03350 batchs: 390.6042175292969
INFO:root:Train (Epoch 277): Loss/seq after 03400 batchs: 388.2091369628906
INFO:root:Train (Epoch 277): Loss/seq after 03450 batchs: 387.1124267578125
INFO:root:Train (Epoch 277): Loss/seq after 03500 batchs: 387.9569396972656
INFO:root:Train (Epoch 277): Loss/seq after 03550 batchs: 386.1868591308594
INFO:root:Train (Epoch 277): Loss/seq after 03600 batchs: 390.291259765625
INFO:root:Train (Epoch 277): Loss/seq after 03650 batchs: 389.0778503417969
INFO:root:Train (Epoch 277): Loss/seq after 03700 batchs: 391.524658203125
INFO:root:Train (Epoch 277): Loss/seq after 03750 batchs: 394.96685791015625
INFO:root:Train (Epoch 277): Loss/seq after 03800 batchs: 394.5021667480469
INFO:root:Train (Epoch 277): Loss/seq after 03850 batchs: 394.1427307128906
INFO:root:Train (Epoch 277): Loss/seq after 03900 batchs: 396.29290771484375
INFO:root:Train (Epoch 277): Loss/seq after 03950 batchs: 399.1694030761719
INFO:root:Train (Epoch 277): Loss/seq after 04000 batchs: 396.772216796875
INFO:root:Train (Epoch 277): Loss/seq after 04050 batchs: 394.5492858886719
INFO:root:Train (Epoch 277): Loss/seq after 04100 batchs: 394.2308349609375
INFO:root:Train (Epoch 277): Loss/seq after 04150 batchs: 394.26239013671875
INFO:root:Train (Epoch 277): Loss/seq after 04200 batchs: 393.3554382324219
INFO:root:Train (Epoch 277): Loss/seq after 04250 batchs: 392.2881774902344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 277): Loss/seq after 00000 batches: 380.93756103515625
INFO:root:# Valid (Epoch 277): Loss/seq after 00050 batches: 681.6641845703125
INFO:root:# Valid (Epoch 277): Loss/seq after 00100 batches: 685.8848266601562
INFO:root:# Valid (Epoch 277): Loss/seq after 00150 batches: 514.7267456054688
INFO:root:# Valid (Epoch 277): Loss/seq after 00200 batches: 469.4067687988281
INFO:root:Artifacts: Make stick videos for epoch 277
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_277_on_20220423_191044.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_277_index_1249_on_20220423_191044.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 278): Loss/seq after 00000 batchs: 448.0998840332031
INFO:root:Train (Epoch 278): Loss/seq after 00050 batchs: 535.8344116210938
INFO:root:Train (Epoch 278): Loss/seq after 00100 batchs: 544.1556396484375
INFO:root:Train (Epoch 278): Loss/seq after 00150 batchs: 496.0252380371094
INFO:root:Train (Epoch 278): Loss/seq after 00200 batchs: 568.5609741210938
INFO:root:Train (Epoch 278): Loss/seq after 00250 batchs: 592.658935546875
INFO:root:Train (Epoch 278): Loss/seq after 00300 batchs: 610.1109008789062
INFO:root:Train (Epoch 278): Loss/seq after 00350 batchs: 580.2073974609375
INFO:root:Train (Epoch 278): Loss/seq after 00400 batchs: 566.179443359375
INFO:root:Train (Epoch 278): Loss/seq after 00450 batchs: 571.9891357421875
INFO:root:Train (Epoch 278): Loss/seq after 00500 batchs: 555.0176391601562
INFO:root:Train (Epoch 278): Loss/seq after 00550 batchs: 542.4991455078125
INFO:root:Train (Epoch 278): Loss/seq after 00600 batchs: 526.2741088867188
INFO:root:Train (Epoch 278): Loss/seq after 00650 batchs: 509.581787109375
INFO:root:Train (Epoch 278): Loss/seq after 00700 batchs: 489.65899658203125
INFO:root:Train (Epoch 278): Loss/seq after 00750 batchs: 487.2688293457031
INFO:root:Train (Epoch 278): Loss/seq after 00800 batchs: 488.6153869628906
INFO:root:Train (Epoch 278): Loss/seq after 00850 batchs: 473.6026306152344
INFO:root:Train (Epoch 278): Loss/seq after 00900 batchs: 461.31414794921875
INFO:root:Train (Epoch 278): Loss/seq after 00950 batchs: 459.0298156738281
INFO:root:Train (Epoch 278): Loss/seq after 01000 batchs: 452.3038024902344
INFO:root:Train (Epoch 278): Loss/seq after 01050 batchs: 443.4414367675781
INFO:root:Train (Epoch 278): Loss/seq after 01100 batchs: 434.66796875
INFO:root:Train (Epoch 278): Loss/seq after 01150 batchs: 423.1126708984375
INFO:root:Train (Epoch 278): Loss/seq after 01200 batchs: 424.84149169921875
INFO:root:Train (Epoch 278): Loss/seq after 01250 batchs: 423.6672668457031
INFO:root:Train (Epoch 278): Loss/seq after 01300 batchs: 414.9267272949219
INFO:root:Train (Epoch 278): Loss/seq after 01350 batchs: 407.210205078125
INFO:root:Train (Epoch 278): Loss/seq after 01400 batchs: 408.55596923828125
INFO:root:Train (Epoch 278): Loss/seq after 01450 batchs: 412.2732238769531
INFO:root:Train (Epoch 278): Loss/seq after 01500 batchs: 418.1419677734375
INFO:root:Train (Epoch 278): Loss/seq after 01550 batchs: 419.0398254394531
INFO:root:Train (Epoch 278): Loss/seq after 01600 batchs: 416.6650390625
INFO:root:Train (Epoch 278): Loss/seq after 01650 batchs: 415.1286315917969
INFO:root:Train (Epoch 278): Loss/seq after 01700 batchs: 419.2020263671875
INFO:root:Train (Epoch 278): Loss/seq after 01750 batchs: 418.2632751464844
INFO:root:Train (Epoch 278): Loss/seq after 01800 batchs: 416.7487487792969
INFO:root:Train (Epoch 278): Loss/seq after 01850 batchs: 414.5767517089844
INFO:root:Train (Epoch 278): Loss/seq after 01900 batchs: 413.682373046875
INFO:root:Train (Epoch 278): Loss/seq after 01950 batchs: 413.1819152832031
INFO:root:Train (Epoch 278): Loss/seq after 02000 batchs: 414.4935607910156
INFO:root:Train (Epoch 278): Loss/seq after 02050 batchs: 414.2045593261719
INFO:root:Train (Epoch 278): Loss/seq after 02100 batchs: 413.61566162109375
INFO:root:Train (Epoch 278): Loss/seq after 02150 batchs: 412.8450622558594
INFO:root:Train (Epoch 278): Loss/seq after 02200 batchs: 411.756103515625
INFO:root:Train (Epoch 278): Loss/seq after 02250 batchs: 410.7821044921875
INFO:root:Train (Epoch 278): Loss/seq after 02300 batchs: 408.7984313964844
INFO:root:Train (Epoch 278): Loss/seq after 02350 batchs: 405.99798583984375
INFO:root:Train (Epoch 278): Loss/seq after 02400 batchs: 407.6084899902344
INFO:root:Train (Epoch 278): Loss/seq after 02450 batchs: 404.4662780761719
INFO:root:Train (Epoch 278): Loss/seq after 02500 batchs: 398.03045654296875
INFO:root:Train (Epoch 278): Loss/seq after 02550 batchs: 393.0227966308594
INFO:root:Train (Epoch 278): Loss/seq after 02600 batchs: 389.798828125
INFO:root:Train (Epoch 278): Loss/seq after 02650 batchs: 387.2730712890625
INFO:root:Train (Epoch 278): Loss/seq after 02700 batchs: 385.26629638671875
INFO:root:Train (Epoch 278): Loss/seq after 02750 batchs: 380.8170471191406
INFO:root:Train (Epoch 278): Loss/seq after 02800 batchs: 379.37451171875
INFO:root:Train (Epoch 278): Loss/seq after 02850 batchs: 379.43170166015625
INFO:root:Train (Epoch 278): Loss/seq after 02900 batchs: 380.3739013671875
INFO:root:Train (Epoch 278): Loss/seq after 02950 batchs: 381.08038330078125
INFO:root:Train (Epoch 278): Loss/seq after 03000 batchs: 385.23992919921875
INFO:root:Train (Epoch 278): Loss/seq after 03050 batchs: 387.63885498046875
INFO:root:Train (Epoch 278): Loss/seq after 03100 batchs: 389.3763122558594
INFO:root:Train (Epoch 278): Loss/seq after 03150 batchs: 389.56787109375
INFO:root:Train (Epoch 278): Loss/seq after 03200 batchs: 389.3519592285156
INFO:root:Train (Epoch 278): Loss/seq after 03250 batchs: 390.52813720703125
INFO:root:Train (Epoch 278): Loss/seq after 03300 batchs: 390.1064147949219
INFO:root:Train (Epoch 278): Loss/seq after 03350 batchs: 388.2782897949219
INFO:root:Train (Epoch 278): Loss/seq after 03400 batchs: 385.8971252441406
INFO:root:Train (Epoch 278): Loss/seq after 03450 batchs: 384.9762268066406
INFO:root:Train (Epoch 278): Loss/seq after 03500 batchs: 385.76446533203125
INFO:root:Train (Epoch 278): Loss/seq after 03550 batchs: 384.1048278808594
INFO:root:Train (Epoch 278): Loss/seq after 03600 batchs: 387.88592529296875
INFO:root:Train (Epoch 278): Loss/seq after 03650 batchs: 386.98468017578125
INFO:root:Train (Epoch 278): Loss/seq after 03700 batchs: 388.94085693359375
INFO:root:Train (Epoch 278): Loss/seq after 03750 batchs: 392.8224792480469
INFO:root:Train (Epoch 278): Loss/seq after 03800 batchs: 392.3602294921875
INFO:root:Train (Epoch 278): Loss/seq after 03850 batchs: 391.9984130859375
INFO:root:Train (Epoch 278): Loss/seq after 03900 batchs: 394.5798645019531
INFO:root:Train (Epoch 278): Loss/seq after 03950 batchs: 397.72137451171875
INFO:root:Train (Epoch 278): Loss/seq after 04000 batchs: 395.367919921875
INFO:root:Train (Epoch 278): Loss/seq after 04050 batchs: 393.10784912109375
INFO:root:Train (Epoch 278): Loss/seq after 04100 batchs: 392.73333740234375
INFO:root:Train (Epoch 278): Loss/seq after 04150 batchs: 392.89569091796875
INFO:root:Train (Epoch 278): Loss/seq after 04200 batchs: 391.9821472167969
INFO:root:Train (Epoch 278): Loss/seq after 04250 batchs: 391.0248107910156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 278): Loss/seq after 00000 batches: 394.54315185546875
INFO:root:# Valid (Epoch 278): Loss/seq after 00050 batches: 710.0308227539062
INFO:root:# Valid (Epoch 278): Loss/seq after 00100 batches: 707.8224487304688
INFO:root:# Valid (Epoch 278): Loss/seq after 00150 batches: 525.5977172851562
INFO:root:# Valid (Epoch 278): Loss/seq after 00200 batches: 475.6564025878906
INFO:root:Artifacts: Make stick videos for epoch 278
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_278_on_20220423_191539.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_278_index_203_on_20220423_191539.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 279): Loss/seq after 00000 batchs: 537.3607788085938
INFO:root:Train (Epoch 279): Loss/seq after 00050 batchs: 504.62322998046875
INFO:root:Train (Epoch 279): Loss/seq after 00100 batchs: 535.8123168945312
INFO:root:Train (Epoch 279): Loss/seq after 00150 batchs: 492.8160095214844
INFO:root:Train (Epoch 279): Loss/seq after 00200 batchs: 551.973876953125
INFO:root:Train (Epoch 279): Loss/seq after 00250 batchs: 582.5414428710938
INFO:root:Train (Epoch 279): Loss/seq after 00300 batchs: 600.4264526367188
INFO:root:Train (Epoch 279): Loss/seq after 00350 batchs: 571.669921875
INFO:root:Train (Epoch 279): Loss/seq after 00400 batchs: 564.920654296875
INFO:root:Train (Epoch 279): Loss/seq after 00450 batchs: 570.8477783203125
INFO:root:Train (Epoch 279): Loss/seq after 00500 batchs: 553.3175048828125
INFO:root:Train (Epoch 279): Loss/seq after 00550 batchs: 541.6959228515625
INFO:root:Train (Epoch 279): Loss/seq after 00600 batchs: 523.6356201171875
INFO:root:Train (Epoch 279): Loss/seq after 00650 batchs: 505.8837890625
INFO:root:Train (Epoch 279): Loss/seq after 00700 batchs: 486.710693359375
INFO:root:Train (Epoch 279): Loss/seq after 00750 batchs: 485.3150634765625
INFO:root:Train (Epoch 279): Loss/seq after 00800 batchs: 486.4317932128906
INFO:root:Train (Epoch 279): Loss/seq after 00850 batchs: 471.8668518066406
INFO:root:Train (Epoch 279): Loss/seq after 00900 batchs: 459.6178283691406
INFO:root:Train (Epoch 279): Loss/seq after 00950 batchs: 459.730712890625
INFO:root:Train (Epoch 279): Loss/seq after 01000 batchs: 452.5617370605469
INFO:root:Train (Epoch 279): Loss/seq after 01050 batchs: 444.037841796875
INFO:root:Train (Epoch 279): Loss/seq after 01100 batchs: 436.2272033691406
INFO:root:Train (Epoch 279): Loss/seq after 01150 batchs: 425.38275146484375
INFO:root:Train (Epoch 279): Loss/seq after 01200 batchs: 427.85687255859375
INFO:root:Train (Epoch 279): Loss/seq after 01250 batchs: 427.0373229980469
INFO:root:Train (Epoch 279): Loss/seq after 01300 batchs: 419.3073425292969
INFO:root:Train (Epoch 279): Loss/seq after 01350 batchs: 410.9525146484375
INFO:root:Train (Epoch 279): Loss/seq after 01400 batchs: 412.5741882324219
INFO:root:Train (Epoch 279): Loss/seq after 01450 batchs: 416.1890869140625
INFO:root:Train (Epoch 279): Loss/seq after 01500 batchs: 421.8590087890625
INFO:root:Train (Epoch 279): Loss/seq after 01550 batchs: 423.0825500488281
INFO:root:Train (Epoch 279): Loss/seq after 01600 batchs: 420.7218322753906
INFO:root:Train (Epoch 279): Loss/seq after 01650 batchs: 418.8725891113281
INFO:root:Train (Epoch 279): Loss/seq after 01700 batchs: 422.86895751953125
INFO:root:Train (Epoch 279): Loss/seq after 01750 batchs: 421.75469970703125
INFO:root:Train (Epoch 279): Loss/seq after 01800 batchs: 420.1947326660156
INFO:root:Train (Epoch 279): Loss/seq after 01850 batchs: 417.84466552734375
INFO:root:Train (Epoch 279): Loss/seq after 01900 batchs: 416.47894287109375
INFO:root:Train (Epoch 279): Loss/seq after 01950 batchs: 415.7237854003906
INFO:root:Train (Epoch 279): Loss/seq after 02000 batchs: 416.7201232910156
INFO:root:Train (Epoch 279): Loss/seq after 02050 batchs: 416.26446533203125
INFO:root:Train (Epoch 279): Loss/seq after 02100 batchs: 415.02899169921875
INFO:root:Train (Epoch 279): Loss/seq after 02150 batchs: 414.2672424316406
INFO:root:Train (Epoch 279): Loss/seq after 02200 batchs: 413.275390625
INFO:root:Train (Epoch 279): Loss/seq after 02250 batchs: 412.4857482910156
INFO:root:Train (Epoch 279): Loss/seq after 02300 batchs: 409.8266296386719
INFO:root:Train (Epoch 279): Loss/seq after 02350 batchs: 407.080322265625
INFO:root:Train (Epoch 279): Loss/seq after 02400 batchs: 408.6231689453125
INFO:root:Train (Epoch 279): Loss/seq after 02450 batchs: 405.356201171875
INFO:root:Train (Epoch 279): Loss/seq after 02500 batchs: 398.91259765625
INFO:root:Train (Epoch 279): Loss/seq after 02550 batchs: 393.8531799316406
INFO:root:Train (Epoch 279): Loss/seq after 02600 batchs: 390.6791687011719
INFO:root:Train (Epoch 279): Loss/seq after 02650 batchs: 387.7256774902344
INFO:root:Train (Epoch 279): Loss/seq after 02700 batchs: 385.5329284667969
INFO:root:Train (Epoch 279): Loss/seq after 02750 batchs: 381.644775390625
INFO:root:Train (Epoch 279): Loss/seq after 02800 batchs: 381.0364990234375
INFO:root:Train (Epoch 279): Loss/seq after 02850 batchs: 380.9892272949219
INFO:root:Train (Epoch 279): Loss/seq after 02900 batchs: 382.0235595703125
INFO:root:Train (Epoch 279): Loss/seq after 02950 batchs: 382.6392822265625
INFO:root:Train (Epoch 279): Loss/seq after 03000 batchs: 386.3299865722656
INFO:root:Train (Epoch 279): Loss/seq after 03050 batchs: 388.320068359375
INFO:root:Train (Epoch 279): Loss/seq after 03100 batchs: 390.5425109863281
INFO:root:Train (Epoch 279): Loss/seq after 03150 batchs: 390.75543212890625
INFO:root:Train (Epoch 279): Loss/seq after 03200 batchs: 391.95965576171875
INFO:root:Train (Epoch 279): Loss/seq after 03250 batchs: 392.3464660644531
INFO:root:Train (Epoch 279): Loss/seq after 03300 batchs: 392.9807434082031
INFO:root:Train (Epoch 279): Loss/seq after 03350 batchs: 391.35089111328125
INFO:root:Train (Epoch 279): Loss/seq after 03400 batchs: 389.01666259765625
INFO:root:Train (Epoch 279): Loss/seq after 03450 batchs: 388.0204772949219
INFO:root:Train (Epoch 279): Loss/seq after 03500 batchs: 389.199951171875
INFO:root:Train (Epoch 279): Loss/seq after 03550 batchs: 387.6170349121094
INFO:root:Train (Epoch 279): Loss/seq after 03600 batchs: 392.02740478515625
INFO:root:Train (Epoch 279): Loss/seq after 03650 batchs: 391.3863830566406
INFO:root:Train (Epoch 279): Loss/seq after 03700 batchs: 393.6268615722656
INFO:root:Train (Epoch 279): Loss/seq after 03750 batchs: 397.3056335449219
INFO:root:Train (Epoch 279): Loss/seq after 03800 batchs: 396.7773132324219
INFO:root:Train (Epoch 279): Loss/seq after 03850 batchs: 396.2091369628906
INFO:root:Train (Epoch 279): Loss/seq after 03900 batchs: 397.6338806152344
INFO:root:Train (Epoch 279): Loss/seq after 03950 batchs: 400.6141662597656
INFO:root:Train (Epoch 279): Loss/seq after 04000 batchs: 398.2013244628906
INFO:root:Train (Epoch 279): Loss/seq after 04050 batchs: 395.9977722167969
INFO:root:Train (Epoch 279): Loss/seq after 04100 batchs: 395.59991455078125
INFO:root:Train (Epoch 279): Loss/seq after 04150 batchs: 395.681396484375
INFO:root:Train (Epoch 279): Loss/seq after 04200 batchs: 394.7591857910156
INFO:root:Train (Epoch 279): Loss/seq after 04250 batchs: 393.5901184082031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 279): Loss/seq after 00000 batches: 407.57330322265625
INFO:root:# Valid (Epoch 279): Loss/seq after 00050 batches: 751.4031372070312
INFO:root:# Valid (Epoch 279): Loss/seq after 00100 batches: 843.501220703125
INFO:root:# Valid (Epoch 279): Loss/seq after 00150 batches: 621.1396484375
INFO:root:# Valid (Epoch 279): Loss/seq after 00200 batches: 548.6758422851562
INFO:root:Artifacts: Make stick videos for epoch 279
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_279_on_20220423_192036.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_279_index_1821_on_20220423_192036.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 280): Loss/seq after 00000 batchs: 1109.0235595703125
INFO:root:Train (Epoch 280): Loss/seq after 00050 batchs: 561.8881225585938
INFO:root:Train (Epoch 280): Loss/seq after 00100 batchs: 566.3605346679688
INFO:root:Train (Epoch 280): Loss/seq after 00150 batchs: 514.04150390625
INFO:root:Train (Epoch 280): Loss/seq after 00200 batchs: 570.6419067382812
INFO:root:Train (Epoch 280): Loss/seq after 00250 batchs: 606.3890991210938
INFO:root:Train (Epoch 280): Loss/seq after 00300 batchs: 617.7265014648438
INFO:root:Train (Epoch 280): Loss/seq after 00350 batchs: 588.7969970703125
INFO:root:Train (Epoch 280): Loss/seq after 00400 batchs: 580.7517700195312
INFO:root:Train (Epoch 280): Loss/seq after 00450 batchs: 584.8072509765625
INFO:root:Train (Epoch 280): Loss/seq after 00500 batchs: 568.223388671875
INFO:root:Train (Epoch 280): Loss/seq after 00550 batchs: 554.3965454101562
INFO:root:Train (Epoch 280): Loss/seq after 00600 batchs: 535.9149169921875
INFO:root:Train (Epoch 280): Loss/seq after 00650 batchs: 517.393310546875
INFO:root:Train (Epoch 280): Loss/seq after 00700 batchs: 496.8577575683594
INFO:root:Train (Epoch 280): Loss/seq after 00750 batchs: 492.9351806640625
INFO:root:Train (Epoch 280): Loss/seq after 00800 batchs: 494.16876220703125
INFO:root:Train (Epoch 280): Loss/seq after 00850 batchs: 479.0020446777344
INFO:root:Train (Epoch 280): Loss/seq after 00900 batchs: 466.2773132324219
INFO:root:Train (Epoch 280): Loss/seq after 00950 batchs: 463.6509094238281
INFO:root:Train (Epoch 280): Loss/seq after 01000 batchs: 455.0548400878906
INFO:root:Train (Epoch 280): Loss/seq after 01050 batchs: 446.230224609375
INFO:root:Train (Epoch 280): Loss/seq after 01100 batchs: 436.9278869628906
INFO:root:Train (Epoch 280): Loss/seq after 01150 batchs: 425.60504150390625
INFO:root:Train (Epoch 280): Loss/seq after 01200 batchs: 427.0316467285156
INFO:root:Train (Epoch 280): Loss/seq after 01250 batchs: 426.0934143066406
INFO:root:Train (Epoch 280): Loss/seq after 01300 batchs: 417.4123840332031
INFO:root:Train (Epoch 280): Loss/seq after 01350 batchs: 408.6387634277344
INFO:root:Train (Epoch 280): Loss/seq after 01400 batchs: 410.0144958496094
INFO:root:Train (Epoch 280): Loss/seq after 01450 batchs: 413.654541015625
INFO:root:Train (Epoch 280): Loss/seq after 01500 batchs: 419.28851318359375
INFO:root:Train (Epoch 280): Loss/seq after 01550 batchs: 420.42266845703125
INFO:root:Train (Epoch 280): Loss/seq after 01600 batchs: 418.27288818359375
INFO:root:Train (Epoch 280): Loss/seq after 01650 batchs: 416.31427001953125
INFO:root:Train (Epoch 280): Loss/seq after 01700 batchs: 420.119873046875
INFO:root:Train (Epoch 280): Loss/seq after 01750 batchs: 419.0748596191406
INFO:root:Train (Epoch 280): Loss/seq after 01800 batchs: 417.57061767578125
INFO:root:Train (Epoch 280): Loss/seq after 01850 batchs: 415.3552551269531
INFO:root:Train (Epoch 280): Loss/seq after 01900 batchs: 414.2558898925781
INFO:root:Train (Epoch 280): Loss/seq after 01950 batchs: 413.7955627441406
INFO:root:Train (Epoch 280): Loss/seq after 02000 batchs: 414.96807861328125
INFO:root:Train (Epoch 280): Loss/seq after 02050 batchs: 414.5429382324219
INFO:root:Train (Epoch 280): Loss/seq after 02100 batchs: 413.4079895019531
INFO:root:Train (Epoch 280): Loss/seq after 02150 batchs: 412.67242431640625
INFO:root:Train (Epoch 280): Loss/seq after 02200 batchs: 411.6225280761719
INFO:root:Train (Epoch 280): Loss/seq after 02250 batchs: 410.70220947265625
INFO:root:Train (Epoch 280): Loss/seq after 02300 batchs: 408.4443664550781
INFO:root:Train (Epoch 280): Loss/seq after 02350 batchs: 405.8514709472656
INFO:root:Train (Epoch 280): Loss/seq after 02400 batchs: 407.52789306640625
INFO:root:Train (Epoch 280): Loss/seq after 02450 batchs: 404.2608337402344
INFO:root:Train (Epoch 280): Loss/seq after 02500 batchs: 397.8251647949219
INFO:root:Train (Epoch 280): Loss/seq after 02550 batchs: 392.8007507324219
INFO:root:Train (Epoch 280): Loss/seq after 02600 batchs: 389.50836181640625
INFO:root:Train (Epoch 280): Loss/seq after 02650 batchs: 386.4512023925781
INFO:root:Train (Epoch 280): Loss/seq after 02700 batchs: 384.1427001953125
INFO:root:Train (Epoch 280): Loss/seq after 02750 batchs: 379.96124267578125
INFO:root:Train (Epoch 280): Loss/seq after 02800 batchs: 378.8286437988281
INFO:root:Train (Epoch 280): Loss/seq after 02850 batchs: 378.7055969238281
INFO:root:Train (Epoch 280): Loss/seq after 02900 batchs: 379.8244323730469
INFO:root:Train (Epoch 280): Loss/seq after 02950 batchs: 380.419189453125
INFO:root:Train (Epoch 280): Loss/seq after 03000 batchs: 384.4864196777344
INFO:root:Train (Epoch 280): Loss/seq after 03050 batchs: 386.6927490234375
INFO:root:Train (Epoch 280): Loss/seq after 03100 batchs: 388.8443603515625
INFO:root:Train (Epoch 280): Loss/seq after 03150 batchs: 389.9739074707031
INFO:root:Train (Epoch 280): Loss/seq after 03200 batchs: 390.89410400390625
INFO:root:Train (Epoch 280): Loss/seq after 03250 batchs: 392.09283447265625
INFO:root:Train (Epoch 280): Loss/seq after 03300 batchs: 391.5732421875
INFO:root:Train (Epoch 280): Loss/seq after 03350 batchs: 389.7972106933594
INFO:root:Train (Epoch 280): Loss/seq after 03400 batchs: 387.5284423828125
INFO:root:Train (Epoch 280): Loss/seq after 03450 batchs: 386.4933166503906
INFO:root:Train (Epoch 280): Loss/seq after 03500 batchs: 387.318115234375
INFO:root:Train (Epoch 280): Loss/seq after 03550 batchs: 385.48626708984375
INFO:root:Train (Epoch 280): Loss/seq after 03600 batchs: 389.4488830566406
INFO:root:Train (Epoch 280): Loss/seq after 03650 batchs: 388.3245544433594
INFO:root:Train (Epoch 280): Loss/seq after 03700 batchs: 390.4116516113281
INFO:root:Train (Epoch 280): Loss/seq after 03750 batchs: 393.8338928222656
INFO:root:Train (Epoch 280): Loss/seq after 03800 batchs: 393.3331604003906
INFO:root:Train (Epoch 280): Loss/seq after 03850 batchs: 392.95361328125
INFO:root:Train (Epoch 280): Loss/seq after 03900 batchs: 394.9776611328125
INFO:root:Train (Epoch 280): Loss/seq after 03950 batchs: 398.0606689453125
INFO:root:Train (Epoch 280): Loss/seq after 04000 batchs: 395.7437438964844
INFO:root:Train (Epoch 280): Loss/seq after 04050 batchs: 393.60418701171875
INFO:root:Train (Epoch 280): Loss/seq after 04100 batchs: 393.297607421875
INFO:root:Train (Epoch 280): Loss/seq after 04150 batchs: 393.4917907714844
INFO:root:Train (Epoch 280): Loss/seq after 04200 batchs: 392.429443359375
INFO:root:Train (Epoch 280): Loss/seq after 04250 batchs: 391.2216796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 280): Loss/seq after 00000 batches: 429.3513488769531
INFO:root:# Valid (Epoch 280): Loss/seq after 00050 batches: 734.091552734375
INFO:root:# Valid (Epoch 280): Loss/seq after 00100 batches: 687.4063720703125
INFO:root:# Valid (Epoch 280): Loss/seq after 00150 batches: 514.123291015625
INFO:root:# Valid (Epoch 280): Loss/seq after 00200 batches: 468.37518310546875
INFO:root:Artifacts: Make stick videos for epoch 280
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_280_on_20220423_192520.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_280_index_854_on_20220423_192520.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 281): Loss/seq after 00000 batchs: 686.5479125976562
INFO:root:Train (Epoch 281): Loss/seq after 00050 batchs: 546.9755859375
INFO:root:Train (Epoch 281): Loss/seq after 00100 batchs: 568.8161010742188
INFO:root:Train (Epoch 281): Loss/seq after 00150 batchs: 515.253173828125
INFO:root:Train (Epoch 281): Loss/seq after 00200 batchs: 575.4223022460938
INFO:root:Train (Epoch 281): Loss/seq after 00250 batchs: 587.46826171875
INFO:root:Train (Epoch 281): Loss/seq after 00300 batchs: 601.666748046875
INFO:root:Train (Epoch 281): Loss/seq after 00350 batchs: 572.1717529296875
INFO:root:Train (Epoch 281): Loss/seq after 00400 batchs: 560.78515625
INFO:root:Train (Epoch 281): Loss/seq after 00450 batchs: 567.1040649414062
INFO:root:Train (Epoch 281): Loss/seq after 00500 batchs: 549.4376220703125
INFO:root:Train (Epoch 281): Loss/seq after 00550 batchs: 537.2614135742188
INFO:root:Train (Epoch 281): Loss/seq after 00600 batchs: 519.3599853515625
INFO:root:Train (Epoch 281): Loss/seq after 00650 batchs: 503.2638854980469
INFO:root:Train (Epoch 281): Loss/seq after 00700 batchs: 482.9979248046875
INFO:root:Train (Epoch 281): Loss/seq after 00750 batchs: 479.07952880859375
INFO:root:Train (Epoch 281): Loss/seq after 00800 batchs: 480.97845458984375
INFO:root:Train (Epoch 281): Loss/seq after 00850 batchs: 466.50543212890625
INFO:root:Train (Epoch 281): Loss/seq after 00900 batchs: 454.74285888671875
INFO:root:Train (Epoch 281): Loss/seq after 00950 batchs: 454.2864074707031
INFO:root:Train (Epoch 281): Loss/seq after 01000 batchs: 448.32421875
INFO:root:Train (Epoch 281): Loss/seq after 01050 batchs: 439.76165771484375
INFO:root:Train (Epoch 281): Loss/seq after 01100 batchs: 430.58056640625
INFO:root:Train (Epoch 281): Loss/seq after 01150 batchs: 419.5743713378906
INFO:root:Train (Epoch 281): Loss/seq after 01200 batchs: 421.3266906738281
INFO:root:Train (Epoch 281): Loss/seq after 01250 batchs: 420.2406005859375
INFO:root:Train (Epoch 281): Loss/seq after 01300 batchs: 412.12548828125
INFO:root:Train (Epoch 281): Loss/seq after 01350 batchs: 404.1829833984375
INFO:root:Train (Epoch 281): Loss/seq after 01400 batchs: 406.88360595703125
INFO:root:Train (Epoch 281): Loss/seq after 01450 batchs: 410.50054931640625
INFO:root:Train (Epoch 281): Loss/seq after 01500 batchs: 416.02764892578125
INFO:root:Train (Epoch 281): Loss/seq after 01550 batchs: 417.2300109863281
INFO:root:Train (Epoch 281): Loss/seq after 01600 batchs: 414.8501892089844
INFO:root:Train (Epoch 281): Loss/seq after 01650 batchs: 413.0785217285156
INFO:root:Train (Epoch 281): Loss/seq after 01700 batchs: 416.9870910644531
INFO:root:Train (Epoch 281): Loss/seq after 01750 batchs: 415.8961181640625
INFO:root:Train (Epoch 281): Loss/seq after 01800 batchs: 414.302490234375
INFO:root:Train (Epoch 281): Loss/seq after 01850 batchs: 412.1730041503906
INFO:root:Train (Epoch 281): Loss/seq after 01900 batchs: 410.9014587402344
INFO:root:Train (Epoch 281): Loss/seq after 01950 batchs: 410.33795166015625
INFO:root:Train (Epoch 281): Loss/seq after 02000 batchs: 411.4703674316406
INFO:root:Train (Epoch 281): Loss/seq after 02050 batchs: 411.0642395019531
INFO:root:Train (Epoch 281): Loss/seq after 02100 batchs: 410.00531005859375
INFO:root:Train (Epoch 281): Loss/seq after 02150 batchs: 409.3868103027344
INFO:root:Train (Epoch 281): Loss/seq after 02200 batchs: 408.0914306640625
INFO:root:Train (Epoch 281): Loss/seq after 02250 batchs: 407.0637512207031
INFO:root:Train (Epoch 281): Loss/seq after 02300 batchs: 405.1466369628906
INFO:root:Train (Epoch 281): Loss/seq after 02350 batchs: 402.43701171875
INFO:root:Train (Epoch 281): Loss/seq after 02400 batchs: 403.87969970703125
INFO:root:Train (Epoch 281): Loss/seq after 02450 batchs: 400.7790832519531
INFO:root:Train (Epoch 281): Loss/seq after 02500 batchs: 394.4187927246094
INFO:root:Train (Epoch 281): Loss/seq after 02550 batchs: 389.45404052734375
INFO:root:Train (Epoch 281): Loss/seq after 02600 batchs: 386.0664978027344
INFO:root:Train (Epoch 281): Loss/seq after 02650 batchs: 382.8716125488281
INFO:root:Train (Epoch 281): Loss/seq after 02700 batchs: 380.8949890136719
INFO:root:Train (Epoch 281): Loss/seq after 02750 batchs: 376.74725341796875
INFO:root:Train (Epoch 281): Loss/seq after 02800 batchs: 375.3193359375
INFO:root:Train (Epoch 281): Loss/seq after 02850 batchs: 375.25604248046875
INFO:root:Train (Epoch 281): Loss/seq after 02900 batchs: 376.2067565917969
INFO:root:Train (Epoch 281): Loss/seq after 02950 batchs: 376.8880310058594
INFO:root:Train (Epoch 281): Loss/seq after 03000 batchs: 381.0224609375
INFO:root:Train (Epoch 281): Loss/seq after 03050 batchs: 383.01837158203125
INFO:root:Train (Epoch 281): Loss/seq after 03100 batchs: 385.20721435546875
INFO:root:Train (Epoch 281): Loss/seq after 03150 batchs: 385.7502746582031
INFO:root:Train (Epoch 281): Loss/seq after 03200 batchs: 386.24468994140625
INFO:root:Train (Epoch 281): Loss/seq after 03250 batchs: 386.7745361328125
INFO:root:Train (Epoch 281): Loss/seq after 03300 batchs: 386.0374755859375
INFO:root:Train (Epoch 281): Loss/seq after 03350 batchs: 384.411376953125
INFO:root:Train (Epoch 281): Loss/seq after 03400 batchs: 382.05877685546875
INFO:root:Train (Epoch 281): Loss/seq after 03450 batchs: 381.1133117675781
INFO:root:Train (Epoch 281): Loss/seq after 03500 batchs: 381.69390869140625
INFO:root:Train (Epoch 281): Loss/seq after 03550 batchs: 380.011962890625
INFO:root:Train (Epoch 281): Loss/seq after 03600 batchs: 383.4512634277344
INFO:root:Train (Epoch 281): Loss/seq after 03650 batchs: 382.4688720703125
INFO:root:Train (Epoch 281): Loss/seq after 03700 batchs: 384.65020751953125
INFO:root:Train (Epoch 281): Loss/seq after 03750 batchs: 388.3033142089844
INFO:root:Train (Epoch 281): Loss/seq after 03800 batchs: 387.7903747558594
INFO:root:Train (Epoch 281): Loss/seq after 03850 batchs: 387.1701965332031
INFO:root:Train (Epoch 281): Loss/seq after 03900 batchs: 388.7806091308594
INFO:root:Train (Epoch 281): Loss/seq after 03950 batchs: 391.6914978027344
INFO:root:Train (Epoch 281): Loss/seq after 04000 batchs: 389.3501892089844
INFO:root:Train (Epoch 281): Loss/seq after 04050 batchs: 387.1451110839844
INFO:root:Train (Epoch 281): Loss/seq after 04100 batchs: 386.8212585449219
INFO:root:Train (Epoch 281): Loss/seq after 04150 batchs: 386.9387512207031
INFO:root:Train (Epoch 281): Loss/seq after 04200 batchs: 386.0062561035156
INFO:root:Train (Epoch 281): Loss/seq after 04250 batchs: 384.93243408203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 281): Loss/seq after 00000 batches: 441.11639404296875
INFO:root:# Valid (Epoch 281): Loss/seq after 00050 batches: 764.9647827148438
INFO:root:# Valid (Epoch 281): Loss/seq after 00100 batches: 777.7022705078125
INFO:root:# Valid (Epoch 281): Loss/seq after 00150 batches: 573.8241577148438
INFO:root:# Valid (Epoch 281): Loss/seq after 00200 batches: 514.21533203125
INFO:root:Artifacts: Make stick videos for epoch 281
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_281_on_20220423_193005.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_281_index_363_on_20220423_193005.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 282): Loss/seq after 00000 batchs: 907.1007080078125
INFO:root:Train (Epoch 282): Loss/seq after 00050 batchs: 511.9979553222656
INFO:root:Train (Epoch 282): Loss/seq after 00100 batchs: 529.0180053710938
INFO:root:Train (Epoch 282): Loss/seq after 00150 batchs: 486.5160827636719
INFO:root:Train (Epoch 282): Loss/seq after 00200 batchs: 546.53955078125
INFO:root:Train (Epoch 282): Loss/seq after 00250 batchs: 567.6654663085938
INFO:root:Train (Epoch 282): Loss/seq after 00300 batchs: 586.444580078125
INFO:root:Train (Epoch 282): Loss/seq after 00350 batchs: 560.4362182617188
INFO:root:Train (Epoch 282): Loss/seq after 00400 batchs: 549.6636352539062
INFO:root:Train (Epoch 282): Loss/seq after 00450 batchs: 556.5665893554688
INFO:root:Train (Epoch 282): Loss/seq after 00500 batchs: 539.9361572265625
INFO:root:Train (Epoch 282): Loss/seq after 00550 batchs: 528.9924926757812
INFO:root:Train (Epoch 282): Loss/seq after 00600 batchs: 512.4763793945312
INFO:root:Train (Epoch 282): Loss/seq after 00650 batchs: 496.7304992675781
INFO:root:Train (Epoch 282): Loss/seq after 00700 batchs: 477.146728515625
INFO:root:Train (Epoch 282): Loss/seq after 00750 batchs: 473.4402770996094
INFO:root:Train (Epoch 282): Loss/seq after 00800 batchs: 475.90771484375
INFO:root:Train (Epoch 282): Loss/seq after 00850 batchs: 461.38787841796875
INFO:root:Train (Epoch 282): Loss/seq after 00900 batchs: 449.5216979980469
INFO:root:Train (Epoch 282): Loss/seq after 00950 batchs: 448.1641845703125
INFO:root:Train (Epoch 282): Loss/seq after 01000 batchs: 441.7879333496094
INFO:root:Train (Epoch 282): Loss/seq after 01050 batchs: 432.9238586425781
INFO:root:Train (Epoch 282): Loss/seq after 01100 batchs: 424.0630187988281
INFO:root:Train (Epoch 282): Loss/seq after 01150 batchs: 413.3194580078125
INFO:root:Train (Epoch 282): Loss/seq after 01200 batchs: 414.93768310546875
INFO:root:Train (Epoch 282): Loss/seq after 01250 batchs: 414.3180236816406
INFO:root:Train (Epoch 282): Loss/seq after 01300 batchs: 405.6885070800781
INFO:root:Train (Epoch 282): Loss/seq after 01350 batchs: 398.0387878417969
INFO:root:Train (Epoch 282): Loss/seq after 01400 batchs: 400.4102478027344
INFO:root:Train (Epoch 282): Loss/seq after 01450 batchs: 404.0931701660156
INFO:root:Train (Epoch 282): Loss/seq after 01500 batchs: 409.851806640625
INFO:root:Train (Epoch 282): Loss/seq after 01550 batchs: 411.2902526855469
INFO:root:Train (Epoch 282): Loss/seq after 01600 batchs: 409.24163818359375
INFO:root:Train (Epoch 282): Loss/seq after 01650 batchs: 407.63299560546875
INFO:root:Train (Epoch 282): Loss/seq after 01700 batchs: 411.6872253417969
INFO:root:Train (Epoch 282): Loss/seq after 01750 batchs: 410.5809631347656
INFO:root:Train (Epoch 282): Loss/seq after 01800 batchs: 409.18572998046875
INFO:root:Train (Epoch 282): Loss/seq after 01850 batchs: 407.098388671875
INFO:root:Train (Epoch 282): Loss/seq after 01900 batchs: 406.0640869140625
INFO:root:Train (Epoch 282): Loss/seq after 01950 batchs: 405.5278625488281
INFO:root:Train (Epoch 282): Loss/seq after 02000 batchs: 406.7409973144531
INFO:root:Train (Epoch 282): Loss/seq after 02050 batchs: 406.36968994140625
INFO:root:Train (Epoch 282): Loss/seq after 02100 batchs: 405.3219299316406
INFO:root:Train (Epoch 282): Loss/seq after 02150 batchs: 404.6637268066406
INFO:root:Train (Epoch 282): Loss/seq after 02200 batchs: 403.6434326171875
INFO:root:Train (Epoch 282): Loss/seq after 02250 batchs: 402.8790283203125
INFO:root:Train (Epoch 282): Loss/seq after 02300 batchs: 400.74627685546875
INFO:root:Train (Epoch 282): Loss/seq after 02350 batchs: 398.1774597167969
INFO:root:Train (Epoch 282): Loss/seq after 02400 batchs: 399.54949951171875
INFO:root:Train (Epoch 282): Loss/seq after 02450 batchs: 396.446044921875
INFO:root:Train (Epoch 282): Loss/seq after 02500 batchs: 390.1191711425781
INFO:root:Train (Epoch 282): Loss/seq after 02550 batchs: 385.1311340332031
INFO:root:Train (Epoch 282): Loss/seq after 02600 batchs: 382.0038757324219
INFO:root:Train (Epoch 282): Loss/seq after 02650 batchs: 379.1906433105469
INFO:root:Train (Epoch 282): Loss/seq after 02700 batchs: 377.0379943847656
INFO:root:Train (Epoch 282): Loss/seq after 02750 batchs: 373.01708984375
INFO:root:Train (Epoch 282): Loss/seq after 02800 batchs: 372.3621520996094
INFO:root:Train (Epoch 282): Loss/seq after 02850 batchs: 372.5053405761719
INFO:root:Train (Epoch 282): Loss/seq after 02900 batchs: 373.4381408691406
INFO:root:Train (Epoch 282): Loss/seq after 02950 batchs: 374.2403869628906
INFO:root:Train (Epoch 282): Loss/seq after 03000 batchs: 378.281494140625
INFO:root:Train (Epoch 282): Loss/seq after 03050 batchs: 380.3902587890625
INFO:root:Train (Epoch 282): Loss/seq after 03100 batchs: 382.0804138183594
INFO:root:Train (Epoch 282): Loss/seq after 03150 batchs: 382.1682434082031
INFO:root:Train (Epoch 282): Loss/seq after 03200 batchs: 382.831298828125
INFO:root:Train (Epoch 282): Loss/seq after 03250 batchs: 383.1980895996094
INFO:root:Train (Epoch 282): Loss/seq after 03300 batchs: 382.6982421875
INFO:root:Train (Epoch 282): Loss/seq after 03350 batchs: 381.359619140625
INFO:root:Train (Epoch 282): Loss/seq after 03400 batchs: 379.1592102050781
INFO:root:Train (Epoch 282): Loss/seq after 03450 batchs: 378.0626525878906
INFO:root:Train (Epoch 282): Loss/seq after 03500 batchs: 378.90869140625
INFO:root:Train (Epoch 282): Loss/seq after 03550 batchs: 377.3440856933594
INFO:root:Train (Epoch 282): Loss/seq after 03600 batchs: 380.5627746582031
INFO:root:Train (Epoch 282): Loss/seq after 03650 batchs: 379.4147033691406
INFO:root:Train (Epoch 282): Loss/seq after 03700 batchs: 381.5889587402344
INFO:root:Train (Epoch 282): Loss/seq after 03750 batchs: 385.2048034667969
INFO:root:Train (Epoch 282): Loss/seq after 03800 batchs: 384.6957092285156
INFO:root:Train (Epoch 282): Loss/seq after 03850 batchs: 384.2054443359375
INFO:root:Train (Epoch 282): Loss/seq after 03900 batchs: 386.0660095214844
INFO:root:Train (Epoch 282): Loss/seq after 03950 batchs: 388.9380798339844
INFO:root:Train (Epoch 282): Loss/seq after 04000 batchs: 386.6483459472656
INFO:root:Train (Epoch 282): Loss/seq after 04050 batchs: 384.5356750488281
INFO:root:Train (Epoch 282): Loss/seq after 04100 batchs: 384.21234130859375
INFO:root:Train (Epoch 282): Loss/seq after 04150 batchs: 384.4579772949219
INFO:root:Train (Epoch 282): Loss/seq after 04200 batchs: 383.5117492675781
INFO:root:Train (Epoch 282): Loss/seq after 04250 batchs: 382.4537658691406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 282): Loss/seq after 00000 batches: 350.935546875
INFO:root:# Valid (Epoch 282): Loss/seq after 00050 batches: 714.6188354492188
INFO:root:# Valid (Epoch 282): Loss/seq after 00100 batches: 686.5198974609375
INFO:root:# Valid (Epoch 282): Loss/seq after 00150 batches: 511.9828796386719
INFO:root:# Valid (Epoch 282): Loss/seq after 00200 batches: 467.0570373535156
INFO:root:Artifacts: Make stick videos for epoch 282
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_282_on_20220423_193449.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_282_index_1578_on_20220423_193449.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 283): Loss/seq after 00000 batchs: 809.1329345703125
INFO:root:Train (Epoch 283): Loss/seq after 00050 batchs: 532.4847412109375
INFO:root:Train (Epoch 283): Loss/seq after 00100 batchs: 532.712890625
INFO:root:Train (Epoch 283): Loss/seq after 00150 batchs: 486.7685852050781
INFO:root:Train (Epoch 283): Loss/seq after 00200 batchs: 549.5119018554688
INFO:root:Train (Epoch 283): Loss/seq after 00250 batchs: 601.8611450195312
INFO:root:Train (Epoch 283): Loss/seq after 00300 batchs: 615.8031005859375
INFO:root:Train (Epoch 283): Loss/seq after 00350 batchs: 586.2930908203125
INFO:root:Train (Epoch 283): Loss/seq after 00400 batchs: 579.7423095703125
INFO:root:Train (Epoch 283): Loss/seq after 00450 batchs: 584.4157104492188
INFO:root:Train (Epoch 283): Loss/seq after 00500 batchs: 565.2908935546875
INFO:root:Train (Epoch 283): Loss/seq after 00550 batchs: 551.6762084960938
INFO:root:Train (Epoch 283): Loss/seq after 00600 batchs: 532.0393676757812
INFO:root:Train (Epoch 283): Loss/seq after 00650 batchs: 515.236328125
INFO:root:Train (Epoch 283): Loss/seq after 00700 batchs: 496.5855712890625
INFO:root:Train (Epoch 283): Loss/seq after 00750 batchs: 491.79803466796875
INFO:root:Train (Epoch 283): Loss/seq after 00800 batchs: 492.3626708984375
INFO:root:Train (Epoch 283): Loss/seq after 00850 batchs: 477.3576354980469
INFO:root:Train (Epoch 283): Loss/seq after 00900 batchs: 464.6091003417969
INFO:root:Train (Epoch 283): Loss/seq after 00950 batchs: 463.5611877441406
INFO:root:Train (Epoch 283): Loss/seq after 01000 batchs: 456.3197326660156
INFO:root:Train (Epoch 283): Loss/seq after 01050 batchs: 447.30877685546875
INFO:root:Train (Epoch 283): Loss/seq after 01100 batchs: 437.80645751953125
INFO:root:Train (Epoch 283): Loss/seq after 01150 batchs: 426.75689697265625
INFO:root:Train (Epoch 283): Loss/seq after 01200 batchs: 428.4544677734375
INFO:root:Train (Epoch 283): Loss/seq after 01250 batchs: 426.9326477050781
INFO:root:Train (Epoch 283): Loss/seq after 01300 batchs: 418.16717529296875
INFO:root:Train (Epoch 283): Loss/seq after 01350 batchs: 409.9158935546875
INFO:root:Train (Epoch 283): Loss/seq after 01400 batchs: 411.52734375
INFO:root:Train (Epoch 283): Loss/seq after 01450 batchs: 414.79461669921875
INFO:root:Train (Epoch 283): Loss/seq after 01500 batchs: 420.63525390625
INFO:root:Train (Epoch 283): Loss/seq after 01550 batchs: 421.15509033203125
INFO:root:Train (Epoch 283): Loss/seq after 01600 batchs: 418.65252685546875
INFO:root:Train (Epoch 283): Loss/seq after 01650 batchs: 416.5934143066406
INFO:root:Train (Epoch 283): Loss/seq after 01700 batchs: 420.4676513671875
INFO:root:Train (Epoch 283): Loss/seq after 01750 batchs: 419.3218078613281
INFO:root:Train (Epoch 283): Loss/seq after 01800 batchs: 417.5568542480469
INFO:root:Train (Epoch 283): Loss/seq after 01850 batchs: 415.16656494140625
INFO:root:Train (Epoch 283): Loss/seq after 01900 batchs: 413.74029541015625
INFO:root:Train (Epoch 283): Loss/seq after 01950 batchs: 413.05865478515625
INFO:root:Train (Epoch 283): Loss/seq after 02000 batchs: 414.06640625
INFO:root:Train (Epoch 283): Loss/seq after 02050 batchs: 413.57989501953125
INFO:root:Train (Epoch 283): Loss/seq after 02100 batchs: 412.36578369140625
INFO:root:Train (Epoch 283): Loss/seq after 02150 batchs: 411.6679992675781
INFO:root:Train (Epoch 283): Loss/seq after 02200 batchs: 410.5397033691406
INFO:root:Train (Epoch 283): Loss/seq after 02250 batchs: 409.5772705078125
INFO:root:Train (Epoch 283): Loss/seq after 02300 batchs: 407.1180419921875
INFO:root:Train (Epoch 283): Loss/seq after 02350 batchs: 404.40264892578125
INFO:root:Train (Epoch 283): Loss/seq after 02400 batchs: 405.6800842285156
INFO:root:Train (Epoch 283): Loss/seq after 02450 batchs: 402.3895263671875
INFO:root:Train (Epoch 283): Loss/seq after 02500 batchs: 395.97698974609375
INFO:root:Train (Epoch 283): Loss/seq after 02550 batchs: 390.8937683105469
INFO:root:Train (Epoch 283): Loss/seq after 02600 batchs: 387.66290283203125
INFO:root:Train (Epoch 283): Loss/seq after 02650 batchs: 384.57177734375
INFO:root:Train (Epoch 283): Loss/seq after 02700 batchs: 382.3531799316406
INFO:root:Train (Epoch 283): Loss/seq after 02750 batchs: 378.3016052246094
INFO:root:Train (Epoch 283): Loss/seq after 02800 batchs: 376.9092712402344
INFO:root:Train (Epoch 283): Loss/seq after 02850 batchs: 376.7186584472656
INFO:root:Train (Epoch 283): Loss/seq after 02900 batchs: 377.7655334472656
INFO:root:Train (Epoch 283): Loss/seq after 02950 batchs: 378.3203125
INFO:root:Train (Epoch 283): Loss/seq after 03000 batchs: 382.5376281738281
INFO:root:Train (Epoch 283): Loss/seq after 03050 batchs: 384.416015625
INFO:root:Train (Epoch 283): Loss/seq after 03100 batchs: 385.67279052734375
INFO:root:Train (Epoch 283): Loss/seq after 03150 batchs: 386.23541259765625
INFO:root:Train (Epoch 283): Loss/seq after 03200 batchs: 386.0547790527344
INFO:root:Train (Epoch 283): Loss/seq after 03250 batchs: 386.3323669433594
INFO:root:Train (Epoch 283): Loss/seq after 03300 batchs: 385.7026672363281
INFO:root:Train (Epoch 283): Loss/seq after 03350 batchs: 383.7696228027344
INFO:root:Train (Epoch 283): Loss/seq after 03400 batchs: 381.4742736816406
INFO:root:Train (Epoch 283): Loss/seq after 03450 batchs: 380.4383239746094
INFO:root:Train (Epoch 283): Loss/seq after 03500 batchs: 381.2117919921875
INFO:root:Train (Epoch 283): Loss/seq after 03550 batchs: 379.5623474121094
INFO:root:Train (Epoch 283): Loss/seq after 03600 batchs: 382.8885192871094
INFO:root:Train (Epoch 283): Loss/seq after 03650 batchs: 381.74066162109375
INFO:root:Train (Epoch 283): Loss/seq after 03700 batchs: 383.748046875
INFO:root:Train (Epoch 283): Loss/seq after 03750 batchs: 387.6286926269531
INFO:root:Train (Epoch 283): Loss/seq after 03800 batchs: 387.20233154296875
INFO:root:Train (Epoch 283): Loss/seq after 03850 batchs: 386.7470397949219
INFO:root:Train (Epoch 283): Loss/seq after 03900 batchs: 387.96246337890625
INFO:root:Train (Epoch 283): Loss/seq after 03950 batchs: 390.8992614746094
INFO:root:Train (Epoch 283): Loss/seq after 04000 batchs: 388.5647277832031
INFO:root:Train (Epoch 283): Loss/seq after 04050 batchs: 386.43939208984375
INFO:root:Train (Epoch 283): Loss/seq after 04100 batchs: 386.09600830078125
INFO:root:Train (Epoch 283): Loss/seq after 04150 batchs: 386.1794738769531
INFO:root:Train (Epoch 283): Loss/seq after 04200 batchs: 385.3713073730469
INFO:root:Train (Epoch 283): Loss/seq after 04250 batchs: 384.3033142089844
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 283): Loss/seq after 00000 batches: 397.8768615722656
INFO:root:# Valid (Epoch 283): Loss/seq after 00050 batches: 757.6817016601562
INFO:root:# Valid (Epoch 283): Loss/seq after 00100 batches: 731.3981323242188
INFO:root:# Valid (Epoch 283): Loss/seq after 00150 batches: 541.4240112304688
INFO:root:# Valid (Epoch 283): Loss/seq after 00200 batches: 487.4573059082031
INFO:root:Artifacts: Make stick videos for epoch 283
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_283_on_20220423_193943.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_283_index_376_on_20220423_193943.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 284): Loss/seq after 00000 batchs: 575.1131591796875
INFO:root:Train (Epoch 284): Loss/seq after 00050 batchs: 506.7237548828125
INFO:root:Train (Epoch 284): Loss/seq after 00100 batchs: 517.4439697265625
INFO:root:Train (Epoch 284): Loss/seq after 00150 batchs: 477.5232849121094
INFO:root:Train (Epoch 284): Loss/seq after 00200 batchs: 540.4345703125
INFO:root:Train (Epoch 284): Loss/seq after 00250 batchs: 572.1729125976562
INFO:root:Train (Epoch 284): Loss/seq after 00300 batchs: 587.7399291992188
INFO:root:Train (Epoch 284): Loss/seq after 00350 batchs: 560.930419921875
INFO:root:Train (Epoch 284): Loss/seq after 00400 batchs: 548.9443969726562
INFO:root:Train (Epoch 284): Loss/seq after 00450 batchs: 556.0721435546875
INFO:root:Train (Epoch 284): Loss/seq after 00500 batchs: 539.968505859375
INFO:root:Train (Epoch 284): Loss/seq after 00550 batchs: 528.616943359375
INFO:root:Train (Epoch 284): Loss/seq after 00600 batchs: 511.5800476074219
INFO:root:Train (Epoch 284): Loss/seq after 00650 batchs: 496.543212890625
INFO:root:Train (Epoch 284): Loss/seq after 00700 batchs: 476.4578552246094
INFO:root:Train (Epoch 284): Loss/seq after 00750 batchs: 474.20068359375
INFO:root:Train (Epoch 284): Loss/seq after 00800 batchs: 476.6795349121094
INFO:root:Train (Epoch 284): Loss/seq after 00850 batchs: 462.21319580078125
INFO:root:Train (Epoch 284): Loss/seq after 00900 batchs: 450.1385192871094
INFO:root:Train (Epoch 284): Loss/seq after 00950 batchs: 448.7616271972656
INFO:root:Train (Epoch 284): Loss/seq after 01000 batchs: 442.1143493652344
INFO:root:Train (Epoch 284): Loss/seq after 01050 batchs: 433.70184326171875
INFO:root:Train (Epoch 284): Loss/seq after 01100 batchs: 424.30462646484375
INFO:root:Train (Epoch 284): Loss/seq after 01150 batchs: 413.41778564453125
INFO:root:Train (Epoch 284): Loss/seq after 01200 batchs: 415.09259033203125
INFO:root:Train (Epoch 284): Loss/seq after 01250 batchs: 414.6106872558594
INFO:root:Train (Epoch 284): Loss/seq after 01300 batchs: 405.97039794921875
INFO:root:Train (Epoch 284): Loss/seq after 01350 batchs: 397.8443603515625
INFO:root:Train (Epoch 284): Loss/seq after 01400 batchs: 399.8049621582031
INFO:root:Train (Epoch 284): Loss/seq after 01450 batchs: 403.4041442871094
INFO:root:Train (Epoch 284): Loss/seq after 01500 batchs: 409.3692321777344
INFO:root:Train (Epoch 284): Loss/seq after 01550 batchs: 410.490234375
INFO:root:Train (Epoch 284): Loss/seq after 01600 batchs: 408.3700866699219
INFO:root:Train (Epoch 284): Loss/seq after 01650 batchs: 406.6265869140625
INFO:root:Train (Epoch 284): Loss/seq after 01700 batchs: 410.714111328125
INFO:root:Train (Epoch 284): Loss/seq after 01750 batchs: 409.769287109375
INFO:root:Train (Epoch 284): Loss/seq after 01800 batchs: 408.22784423828125
INFO:root:Train (Epoch 284): Loss/seq after 01850 batchs: 406.0148620605469
INFO:root:Train (Epoch 284): Loss/seq after 01900 batchs: 404.7784423828125
INFO:root:Train (Epoch 284): Loss/seq after 01950 batchs: 404.55731201171875
INFO:root:Train (Epoch 284): Loss/seq after 02000 batchs: 405.891357421875
INFO:root:Train (Epoch 284): Loss/seq after 02050 batchs: 405.527587890625
INFO:root:Train (Epoch 284): Loss/seq after 02100 batchs: 404.7914123535156
INFO:root:Train (Epoch 284): Loss/seq after 02150 batchs: 404.2520751953125
INFO:root:Train (Epoch 284): Loss/seq after 02200 batchs: 403.1370544433594
INFO:root:Train (Epoch 284): Loss/seq after 02250 batchs: 402.427001953125
INFO:root:Train (Epoch 284): Loss/seq after 02300 batchs: 399.74456787109375
INFO:root:Train (Epoch 284): Loss/seq after 02350 batchs: 397.1054382324219
INFO:root:Train (Epoch 284): Loss/seq after 02400 batchs: 398.60211181640625
INFO:root:Train (Epoch 284): Loss/seq after 02450 batchs: 395.4383850097656
INFO:root:Train (Epoch 284): Loss/seq after 02500 batchs: 389.13427734375
INFO:root:Train (Epoch 284): Loss/seq after 02550 batchs: 384.2305603027344
INFO:root:Train (Epoch 284): Loss/seq after 02600 batchs: 380.83367919921875
INFO:root:Train (Epoch 284): Loss/seq after 02650 batchs: 377.70941162109375
INFO:root:Train (Epoch 284): Loss/seq after 02700 batchs: 375.655029296875
INFO:root:Train (Epoch 284): Loss/seq after 02750 batchs: 372.3025817871094
INFO:root:Train (Epoch 284): Loss/seq after 02800 batchs: 371.294677734375
INFO:root:Train (Epoch 284): Loss/seq after 02850 batchs: 371.17596435546875
INFO:root:Train (Epoch 284): Loss/seq after 02900 batchs: 372.1156921386719
INFO:root:Train (Epoch 284): Loss/seq after 02950 batchs: 372.721435546875
INFO:root:Train (Epoch 284): Loss/seq after 03000 batchs: 376.5939025878906
INFO:root:Train (Epoch 284): Loss/seq after 03050 batchs: 378.4649353027344
INFO:root:Train (Epoch 284): Loss/seq after 03100 batchs: 381.12310791015625
INFO:root:Train (Epoch 284): Loss/seq after 03150 batchs: 381.3814392089844
INFO:root:Train (Epoch 284): Loss/seq after 03200 batchs: 381.2749938964844
INFO:root:Train (Epoch 284): Loss/seq after 03250 batchs: 381.9825134277344
INFO:root:Train (Epoch 284): Loss/seq after 03300 batchs: 381.61407470703125
INFO:root:Train (Epoch 284): Loss/seq after 03350 batchs: 379.912109375
INFO:root:Train (Epoch 284): Loss/seq after 03400 batchs: 377.7744140625
INFO:root:Train (Epoch 284): Loss/seq after 03450 batchs: 376.8543395996094
INFO:root:Train (Epoch 284): Loss/seq after 03500 batchs: 377.67901611328125
INFO:root:Train (Epoch 284): Loss/seq after 03550 batchs: 376.011962890625
INFO:root:Train (Epoch 284): Loss/seq after 03600 batchs: 379.684326171875
INFO:root:Train (Epoch 284): Loss/seq after 03650 batchs: 378.73236083984375
INFO:root:Train (Epoch 284): Loss/seq after 03700 batchs: 380.76129150390625
INFO:root:Train (Epoch 284): Loss/seq after 03750 batchs: 384.3233642578125
INFO:root:Train (Epoch 284): Loss/seq after 03800 batchs: 383.8134460449219
INFO:root:Train (Epoch 284): Loss/seq after 03850 batchs: 383.2496337890625
INFO:root:Train (Epoch 284): Loss/seq after 03900 batchs: 385.1893615722656
INFO:root:Train (Epoch 284): Loss/seq after 03950 batchs: 387.9122009277344
INFO:root:Train (Epoch 284): Loss/seq after 04000 batchs: 385.5985412597656
INFO:root:Train (Epoch 284): Loss/seq after 04050 batchs: 383.4989013671875
INFO:root:Train (Epoch 284): Loss/seq after 04100 batchs: 383.2178039550781
INFO:root:Train (Epoch 284): Loss/seq after 04150 batchs: 383.3243713378906
INFO:root:Train (Epoch 284): Loss/seq after 04200 batchs: 382.4184265136719
INFO:root:Train (Epoch 284): Loss/seq after 04250 batchs: 381.29888916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 284): Loss/seq after 00000 batches: 365.01776123046875
INFO:root:# Valid (Epoch 284): Loss/seq after 00050 batches: 709.4312744140625
INFO:root:# Valid (Epoch 284): Loss/seq after 00100 batches: 739.0052490234375
INFO:root:# Valid (Epoch 284): Loss/seq after 00150 batches: 547.7825927734375
INFO:root:# Valid (Epoch 284): Loss/seq after 00200 batches: 494.52044677734375
INFO:root:Artifacts: Make stick videos for epoch 284
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_284_on_20220423_194430.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_284_index_24_on_20220423_194430.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 285): Loss/seq after 00000 batchs: 795.5518188476562
INFO:root:Train (Epoch 285): Loss/seq after 00050 batchs: 513.8236694335938
INFO:root:Train (Epoch 285): Loss/seq after 00100 batchs: 516.7627563476562
INFO:root:Train (Epoch 285): Loss/seq after 00150 batchs: 476.9206848144531
INFO:root:Train (Epoch 285): Loss/seq after 00200 batchs: 546.29248046875
INFO:root:Train (Epoch 285): Loss/seq after 00250 batchs: 570.3028564453125
INFO:root:Train (Epoch 285): Loss/seq after 00300 batchs: 584.3272705078125
INFO:root:Train (Epoch 285): Loss/seq after 00350 batchs: 557.3375244140625
INFO:root:Train (Epoch 285): Loss/seq after 00400 batchs: 549.0690307617188
INFO:root:Train (Epoch 285): Loss/seq after 00450 batchs: 556.4768676757812
INFO:root:Train (Epoch 285): Loss/seq after 00500 batchs: 540.7357788085938
INFO:root:Train (Epoch 285): Loss/seq after 00550 batchs: 529.3080444335938
INFO:root:Train (Epoch 285): Loss/seq after 00600 batchs: 512.1487426757812
INFO:root:Train (Epoch 285): Loss/seq after 00650 batchs: 498.3701477050781
INFO:root:Train (Epoch 285): Loss/seq after 00700 batchs: 478.1737060546875
INFO:root:Train (Epoch 285): Loss/seq after 00750 batchs: 474.5665283203125
INFO:root:Train (Epoch 285): Loss/seq after 00800 batchs: 475.1334228515625
INFO:root:Train (Epoch 285): Loss/seq after 00850 batchs: 460.7777099609375
INFO:root:Train (Epoch 285): Loss/seq after 00900 batchs: 448.77606201171875
INFO:root:Train (Epoch 285): Loss/seq after 00950 batchs: 448.7584228515625
INFO:root:Train (Epoch 285): Loss/seq after 01000 batchs: 443.0537414550781
INFO:root:Train (Epoch 285): Loss/seq after 01050 batchs: 435.210205078125
INFO:root:Train (Epoch 285): Loss/seq after 01100 batchs: 426.0580749511719
INFO:root:Train (Epoch 285): Loss/seq after 01150 batchs: 415.5414733886719
INFO:root:Train (Epoch 285): Loss/seq after 01200 batchs: 418.2930603027344
INFO:root:Train (Epoch 285): Loss/seq after 01250 batchs: 417.4864196777344
INFO:root:Train (Epoch 285): Loss/seq after 01300 batchs: 408.92376708984375
INFO:root:Train (Epoch 285): Loss/seq after 01350 batchs: 400.4352111816406
INFO:root:Train (Epoch 285): Loss/seq after 01400 batchs: 401.20062255859375
INFO:root:Train (Epoch 285): Loss/seq after 01450 batchs: 404.7044372558594
INFO:root:Train (Epoch 285): Loss/seq after 01500 batchs: 410.65338134765625
INFO:root:Train (Epoch 285): Loss/seq after 01550 batchs: 412.0257263183594
INFO:root:Train (Epoch 285): Loss/seq after 01600 batchs: 409.8542785644531
INFO:root:Train (Epoch 285): Loss/seq after 01650 batchs: 408.18804931640625
INFO:root:Train (Epoch 285): Loss/seq after 01700 batchs: 412.55322265625
INFO:root:Train (Epoch 285): Loss/seq after 01750 batchs: 411.5440673828125
INFO:root:Train (Epoch 285): Loss/seq after 01800 batchs: 409.81451416015625
INFO:root:Train (Epoch 285): Loss/seq after 01850 batchs: 407.63421630859375
INFO:root:Train (Epoch 285): Loss/seq after 01900 batchs: 406.5076904296875
INFO:root:Train (Epoch 285): Loss/seq after 01950 batchs: 406.07720947265625
INFO:root:Train (Epoch 285): Loss/seq after 02000 batchs: 407.2115783691406
INFO:root:Train (Epoch 285): Loss/seq after 02050 batchs: 406.8753662109375
INFO:root:Train (Epoch 285): Loss/seq after 02100 batchs: 406.002685546875
INFO:root:Train (Epoch 285): Loss/seq after 02150 batchs: 405.3553466796875
INFO:root:Train (Epoch 285): Loss/seq after 02200 batchs: 404.3346862792969
INFO:root:Train (Epoch 285): Loss/seq after 02250 batchs: 403.3062744140625
INFO:root:Train (Epoch 285): Loss/seq after 02300 batchs: 400.88671875
INFO:root:Train (Epoch 285): Loss/seq after 02350 batchs: 398.4338684082031
INFO:root:Train (Epoch 285): Loss/seq after 02400 batchs: 400.0787048339844
INFO:root:Train (Epoch 285): Loss/seq after 02450 batchs: 397.0216064453125
INFO:root:Train (Epoch 285): Loss/seq after 02500 batchs: 390.65142822265625
INFO:root:Train (Epoch 285): Loss/seq after 02550 batchs: 385.70703125
INFO:root:Train (Epoch 285): Loss/seq after 02600 batchs: 382.32098388671875
INFO:root:Train (Epoch 285): Loss/seq after 02650 batchs: 379.339599609375
INFO:root:Train (Epoch 285): Loss/seq after 02700 batchs: 377.2793273925781
INFO:root:Train (Epoch 285): Loss/seq after 02750 batchs: 373.63409423828125
INFO:root:Train (Epoch 285): Loss/seq after 02800 batchs: 372.4812316894531
INFO:root:Train (Epoch 285): Loss/seq after 02850 batchs: 372.362060546875
INFO:root:Train (Epoch 285): Loss/seq after 02900 batchs: 373.3861083984375
INFO:root:Train (Epoch 285): Loss/seq after 02950 batchs: 374.06365966796875
INFO:root:Train (Epoch 285): Loss/seq after 03000 batchs: 377.79461669921875
INFO:root:Train (Epoch 285): Loss/seq after 03050 batchs: 379.5735168457031
INFO:root:Train (Epoch 285): Loss/seq after 03100 batchs: 381.9493713378906
INFO:root:Train (Epoch 285): Loss/seq after 03150 batchs: 382.1398010253906
INFO:root:Train (Epoch 285): Loss/seq after 03200 batchs: 382.9302978515625
INFO:root:Train (Epoch 285): Loss/seq after 03250 batchs: 383.71038818359375
INFO:root:Train (Epoch 285): Loss/seq after 03300 batchs: 383.3529357910156
INFO:root:Train (Epoch 285): Loss/seq after 03350 batchs: 381.60546875
INFO:root:Train (Epoch 285): Loss/seq after 03400 batchs: 379.2241516113281
INFO:root:Train (Epoch 285): Loss/seq after 03450 batchs: 378.2778625488281
INFO:root:Train (Epoch 285): Loss/seq after 03500 batchs: 379.2852783203125
INFO:root:Train (Epoch 285): Loss/seq after 03550 batchs: 377.6259765625
INFO:root:Train (Epoch 285): Loss/seq after 03600 batchs: 381.0826110839844
INFO:root:Train (Epoch 285): Loss/seq after 03650 batchs: 379.934326171875
INFO:root:Train (Epoch 285): Loss/seq after 03700 batchs: 381.80853271484375
INFO:root:Train (Epoch 285): Loss/seq after 03750 batchs: 385.47076416015625
INFO:root:Train (Epoch 285): Loss/seq after 03800 batchs: 384.9947814941406
INFO:root:Train (Epoch 285): Loss/seq after 03850 batchs: 384.75506591796875
INFO:root:Train (Epoch 285): Loss/seq after 03900 batchs: 386.23529052734375
INFO:root:Train (Epoch 285): Loss/seq after 03950 batchs: 389.2081298828125
INFO:root:Train (Epoch 285): Loss/seq after 04000 batchs: 386.8800964355469
INFO:root:Train (Epoch 285): Loss/seq after 04050 batchs: 384.7316589355469
INFO:root:Train (Epoch 285): Loss/seq after 04100 batchs: 384.40753173828125
INFO:root:Train (Epoch 285): Loss/seq after 04150 batchs: 384.4548034667969
INFO:root:Train (Epoch 285): Loss/seq after 04200 batchs: 383.5645751953125
INFO:root:Train (Epoch 285): Loss/seq after 04250 batchs: 382.4093933105469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 285): Loss/seq after 00000 batches: 391.01239013671875
INFO:root:# Valid (Epoch 285): Loss/seq after 00050 batches: 713.1900024414062
INFO:root:# Valid (Epoch 285): Loss/seq after 00100 batches: 673.020263671875
INFO:root:# Valid (Epoch 285): Loss/seq after 00150 batches: 502.659912109375
INFO:root:# Valid (Epoch 285): Loss/seq after 00200 batches: 461.8136291503906
INFO:root:Artifacts: Make stick videos for epoch 285
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_285_on_20220423_194918.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_285_index_149_on_20220423_194918.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 286): Loss/seq after 00000 batchs: 551.8853759765625
INFO:root:Train (Epoch 286): Loss/seq after 00050 batchs: 507.46661376953125
INFO:root:Train (Epoch 286): Loss/seq after 00100 batchs: 524.8359375
INFO:root:Train (Epoch 286): Loss/seq after 00150 batchs: 479.4543762207031
INFO:root:Train (Epoch 286): Loss/seq after 00200 batchs: 547.8492431640625
INFO:root:Train (Epoch 286): Loss/seq after 00250 batchs: 566.3480834960938
INFO:root:Train (Epoch 286): Loss/seq after 00300 batchs: 581.4166259765625
INFO:root:Train (Epoch 286): Loss/seq after 00350 batchs: 553.875732421875
INFO:root:Train (Epoch 286): Loss/seq after 00400 batchs: 544.8174438476562
INFO:root:Train (Epoch 286): Loss/seq after 00450 batchs: 552.3488159179688
INFO:root:Train (Epoch 286): Loss/seq after 00500 batchs: 535.2672119140625
INFO:root:Train (Epoch 286): Loss/seq after 00550 batchs: 524.1124877929688
INFO:root:Train (Epoch 286): Loss/seq after 00600 batchs: 507.32110595703125
INFO:root:Train (Epoch 286): Loss/seq after 00650 batchs: 490.9110412597656
INFO:root:Train (Epoch 286): Loss/seq after 00700 batchs: 472.3251647949219
INFO:root:Train (Epoch 286): Loss/seq after 00750 batchs: 468.7278137207031
INFO:root:Train (Epoch 286): Loss/seq after 00800 batchs: 470.3514709472656
INFO:root:Train (Epoch 286): Loss/seq after 00850 batchs: 456.3551330566406
INFO:root:Train (Epoch 286): Loss/seq after 00900 batchs: 444.7384338378906
INFO:root:Train (Epoch 286): Loss/seq after 00950 batchs: 441.9899597167969
INFO:root:Train (Epoch 286): Loss/seq after 01000 batchs: 435.73358154296875
INFO:root:Train (Epoch 286): Loss/seq after 01050 batchs: 427.2355041503906
INFO:root:Train (Epoch 286): Loss/seq after 01100 batchs: 417.8671569824219
INFO:root:Train (Epoch 286): Loss/seq after 01150 batchs: 407.0916442871094
INFO:root:Train (Epoch 286): Loss/seq after 01200 batchs: 408.1744384765625
INFO:root:Train (Epoch 286): Loss/seq after 01250 batchs: 407.4529724121094
INFO:root:Train (Epoch 286): Loss/seq after 01300 batchs: 399.4871826171875
INFO:root:Train (Epoch 286): Loss/seq after 01350 batchs: 391.5087890625
INFO:root:Train (Epoch 286): Loss/seq after 01400 batchs: 394.29296875
INFO:root:Train (Epoch 286): Loss/seq after 01450 batchs: 397.9526672363281
INFO:root:Train (Epoch 286): Loss/seq after 01500 batchs: 403.838623046875
INFO:root:Train (Epoch 286): Loss/seq after 01550 batchs: 405.577392578125
INFO:root:Train (Epoch 286): Loss/seq after 01600 batchs: 403.5508117675781
INFO:root:Train (Epoch 286): Loss/seq after 01650 batchs: 401.8470764160156
INFO:root:Train (Epoch 286): Loss/seq after 01700 batchs: 405.79150390625
INFO:root:Train (Epoch 286): Loss/seq after 01750 batchs: 404.8343200683594
INFO:root:Train (Epoch 286): Loss/seq after 01800 batchs: 403.2427978515625
INFO:root:Train (Epoch 286): Loss/seq after 01850 batchs: 401.1070251464844
INFO:root:Train (Epoch 286): Loss/seq after 01900 batchs: 400.1251220703125
INFO:root:Train (Epoch 286): Loss/seq after 01950 batchs: 399.9931640625
INFO:root:Train (Epoch 286): Loss/seq after 02000 batchs: 401.38214111328125
INFO:root:Train (Epoch 286): Loss/seq after 02050 batchs: 401.0538635253906
INFO:root:Train (Epoch 286): Loss/seq after 02100 batchs: 400.134765625
INFO:root:Train (Epoch 286): Loss/seq after 02150 batchs: 399.5692138671875
INFO:root:Train (Epoch 286): Loss/seq after 02200 batchs: 398.52166748046875
INFO:root:Train (Epoch 286): Loss/seq after 02250 batchs: 397.6043701171875
INFO:root:Train (Epoch 286): Loss/seq after 02300 batchs: 395.4090576171875
INFO:root:Train (Epoch 286): Loss/seq after 02350 batchs: 392.9435119628906
INFO:root:Train (Epoch 286): Loss/seq after 02400 batchs: 394.5180358886719
INFO:root:Train (Epoch 286): Loss/seq after 02450 batchs: 391.36126708984375
INFO:root:Train (Epoch 286): Loss/seq after 02500 batchs: 385.112060546875
INFO:root:Train (Epoch 286): Loss/seq after 02550 batchs: 380.150146484375
INFO:root:Train (Epoch 286): Loss/seq after 02600 batchs: 376.7723693847656
INFO:root:Train (Epoch 286): Loss/seq after 02650 batchs: 373.884521484375
INFO:root:Train (Epoch 286): Loss/seq after 02700 batchs: 371.85308837890625
INFO:root:Train (Epoch 286): Loss/seq after 02750 batchs: 367.8750915527344
INFO:root:Train (Epoch 286): Loss/seq after 02800 batchs: 366.3594970703125
INFO:root:Train (Epoch 286): Loss/seq after 02850 batchs: 366.3814697265625
INFO:root:Train (Epoch 286): Loss/seq after 02900 batchs: 367.44012451171875
INFO:root:Train (Epoch 286): Loss/seq after 02950 batchs: 368.2574157714844
INFO:root:Train (Epoch 286): Loss/seq after 03000 batchs: 371.961181640625
INFO:root:Train (Epoch 286): Loss/seq after 03050 batchs: 373.9735107421875
INFO:root:Train (Epoch 286): Loss/seq after 03100 batchs: 375.9579772949219
INFO:root:Train (Epoch 286): Loss/seq after 03150 batchs: 376.5794372558594
INFO:root:Train (Epoch 286): Loss/seq after 03200 batchs: 376.9699401855469
INFO:root:Train (Epoch 286): Loss/seq after 03250 batchs: 377.40228271484375
INFO:root:Train (Epoch 286): Loss/seq after 03300 batchs: 377.0379943847656
INFO:root:Train (Epoch 286): Loss/seq after 03350 batchs: 375.3094482421875
INFO:root:Train (Epoch 286): Loss/seq after 03400 batchs: 373.08837890625
INFO:root:Train (Epoch 286): Loss/seq after 03450 batchs: 372.1382141113281
INFO:root:Train (Epoch 286): Loss/seq after 03500 batchs: 372.9752197265625
INFO:root:Train (Epoch 286): Loss/seq after 03550 batchs: 371.32891845703125
INFO:root:Train (Epoch 286): Loss/seq after 03600 batchs: 374.86651611328125
INFO:root:Train (Epoch 286): Loss/seq after 03650 batchs: 373.78228759765625
INFO:root:Train (Epoch 286): Loss/seq after 03700 batchs: 375.8089599609375
INFO:root:Train (Epoch 286): Loss/seq after 03750 batchs: 379.3453369140625
INFO:root:Train (Epoch 286): Loss/seq after 03800 batchs: 378.9095764160156
INFO:root:Train (Epoch 286): Loss/seq after 03850 batchs: 378.3675842285156
INFO:root:Train (Epoch 286): Loss/seq after 03900 batchs: 380.0723571777344
INFO:root:Train (Epoch 286): Loss/seq after 03950 batchs: 383.1266174316406
INFO:root:Train (Epoch 286): Loss/seq after 04000 batchs: 380.88751220703125
INFO:root:Train (Epoch 286): Loss/seq after 04050 batchs: 378.7475280761719
INFO:root:Train (Epoch 286): Loss/seq after 04100 batchs: 378.44720458984375
INFO:root:Train (Epoch 286): Loss/seq after 04150 batchs: 378.74676513671875
INFO:root:Train (Epoch 286): Loss/seq after 04200 batchs: 377.9186706542969
INFO:root:Train (Epoch 286): Loss/seq after 04250 batchs: 376.82073974609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 286): Loss/seq after 00000 batches: 394.39373779296875
INFO:root:# Valid (Epoch 286): Loss/seq after 00050 batches: 723.49658203125
INFO:root:# Valid (Epoch 286): Loss/seq after 00100 batches: 752.3760986328125
INFO:root:# Valid (Epoch 286): Loss/seq after 00150 batches: 554.8880615234375
INFO:root:# Valid (Epoch 286): Loss/seq after 00200 batches: 498.6163330078125
INFO:root:Artifacts: Make stick videos for epoch 286
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_286_on_20220423_195402.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_286_index_1547_on_20220423_195402.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 287): Loss/seq after 00000 batchs: 588.5375366210938
INFO:root:Train (Epoch 287): Loss/seq after 00050 batchs: 528.7891845703125
INFO:root:Train (Epoch 287): Loss/seq after 00100 batchs: 540.02978515625
INFO:root:Train (Epoch 287): Loss/seq after 00150 batchs: 494.36712646484375
INFO:root:Train (Epoch 287): Loss/seq after 00200 batchs: 553.2807006835938
INFO:root:Train (Epoch 287): Loss/seq after 00250 batchs: 570.0936279296875
INFO:root:Train (Epoch 287): Loss/seq after 00300 batchs: 583.5927734375
INFO:root:Train (Epoch 287): Loss/seq after 00350 batchs: 555.3641357421875
INFO:root:Train (Epoch 287): Loss/seq after 00400 batchs: 544.0336303710938
INFO:root:Train (Epoch 287): Loss/seq after 00450 batchs: 551.3348999023438
INFO:root:Train (Epoch 287): Loss/seq after 00500 batchs: 533.8851928710938
INFO:root:Train (Epoch 287): Loss/seq after 00550 batchs: 522.8626098632812
INFO:root:Train (Epoch 287): Loss/seq after 00600 batchs: 506.5822448730469
INFO:root:Train (Epoch 287): Loss/seq after 00650 batchs: 488.53009033203125
INFO:root:Train (Epoch 287): Loss/seq after 00700 batchs: 469.3719787597656
INFO:root:Train (Epoch 287): Loss/seq after 00750 batchs: 464.6745910644531
INFO:root:Train (Epoch 287): Loss/seq after 00800 batchs: 465.37066650390625
INFO:root:Train (Epoch 287): Loss/seq after 00850 batchs: 451.4588928222656
INFO:root:Train (Epoch 287): Loss/seq after 00900 batchs: 439.836181640625
INFO:root:Train (Epoch 287): Loss/seq after 00950 batchs: 437.84429931640625
INFO:root:Train (Epoch 287): Loss/seq after 01000 batchs: 431.73565673828125
INFO:root:Train (Epoch 287): Loss/seq after 01050 batchs: 423.257080078125
INFO:root:Train (Epoch 287): Loss/seq after 01100 batchs: 414.556640625
INFO:root:Train (Epoch 287): Loss/seq after 01150 batchs: 404.00494384765625
INFO:root:Train (Epoch 287): Loss/seq after 01200 batchs: 405.5718688964844
INFO:root:Train (Epoch 287): Loss/seq after 01250 batchs: 404.5337219238281
INFO:root:Train (Epoch 287): Loss/seq after 01300 batchs: 396.29962158203125
INFO:root:Train (Epoch 287): Loss/seq after 01350 batchs: 388.24896240234375
INFO:root:Train (Epoch 287): Loss/seq after 01400 batchs: 389.9829406738281
INFO:root:Train (Epoch 287): Loss/seq after 01450 batchs: 393.7442321777344
INFO:root:Train (Epoch 287): Loss/seq after 01500 batchs: 399.4949645996094
INFO:root:Train (Epoch 287): Loss/seq after 01550 batchs: 400.684814453125
INFO:root:Train (Epoch 287): Loss/seq after 01600 batchs: 398.61688232421875
INFO:root:Train (Epoch 287): Loss/seq after 01650 batchs: 397.14825439453125
INFO:root:Train (Epoch 287): Loss/seq after 01700 batchs: 401.0344543457031
INFO:root:Train (Epoch 287): Loss/seq after 01750 batchs: 400.3172912597656
INFO:root:Train (Epoch 287): Loss/seq after 01800 batchs: 398.7607116699219
INFO:root:Train (Epoch 287): Loss/seq after 01850 batchs: 396.8266296386719
INFO:root:Train (Epoch 287): Loss/seq after 01900 batchs: 396.0126953125
INFO:root:Train (Epoch 287): Loss/seq after 01950 batchs: 395.63726806640625
INFO:root:Train (Epoch 287): Loss/seq after 02000 batchs: 396.9314880371094
INFO:root:Train (Epoch 287): Loss/seq after 02050 batchs: 396.7236022949219
INFO:root:Train (Epoch 287): Loss/seq after 02100 batchs: 395.7652893066406
INFO:root:Train (Epoch 287): Loss/seq after 02150 batchs: 395.31048583984375
INFO:root:Train (Epoch 287): Loss/seq after 02200 batchs: 394.5089111328125
INFO:root:Train (Epoch 287): Loss/seq after 02250 batchs: 393.8246765136719
INFO:root:Train (Epoch 287): Loss/seq after 02300 batchs: 391.1233215332031
INFO:root:Train (Epoch 287): Loss/seq after 02350 batchs: 388.6759033203125
INFO:root:Train (Epoch 287): Loss/seq after 02400 batchs: 390.470458984375
INFO:root:Train (Epoch 287): Loss/seq after 02450 batchs: 387.4689636230469
INFO:root:Train (Epoch 287): Loss/seq after 02500 batchs: 381.2261657714844
INFO:root:Train (Epoch 287): Loss/seq after 02550 batchs: 376.41204833984375
INFO:root:Train (Epoch 287): Loss/seq after 02600 batchs: 373.3725891113281
INFO:root:Train (Epoch 287): Loss/seq after 02650 batchs: 370.4884338378906
INFO:root:Train (Epoch 287): Loss/seq after 02700 batchs: 368.5544128417969
INFO:root:Train (Epoch 287): Loss/seq after 02750 batchs: 364.8806457519531
INFO:root:Train (Epoch 287): Loss/seq after 02800 batchs: 364.1983337402344
INFO:root:Train (Epoch 287): Loss/seq after 02850 batchs: 364.1783752441406
INFO:root:Train (Epoch 287): Loss/seq after 02900 batchs: 365.1673889160156
INFO:root:Train (Epoch 287): Loss/seq after 02950 batchs: 365.85174560546875
INFO:root:Train (Epoch 287): Loss/seq after 03000 batchs: 370.0426940917969
INFO:root:Train (Epoch 287): Loss/seq after 03050 batchs: 372.1344299316406
INFO:root:Train (Epoch 287): Loss/seq after 03100 batchs: 374.44915771484375
INFO:root:Train (Epoch 287): Loss/seq after 03150 batchs: 374.3366394042969
INFO:root:Train (Epoch 287): Loss/seq after 03200 batchs: 374.4192199707031
INFO:root:Train (Epoch 287): Loss/seq after 03250 batchs: 375.11279296875
INFO:root:Train (Epoch 287): Loss/seq after 03300 batchs: 374.72650146484375
INFO:root:Train (Epoch 287): Loss/seq after 03350 batchs: 372.8241271972656
INFO:root:Train (Epoch 287): Loss/seq after 03400 batchs: 370.71270751953125
INFO:root:Train (Epoch 287): Loss/seq after 03450 batchs: 369.73724365234375
INFO:root:Train (Epoch 287): Loss/seq after 03500 batchs: 370.32843017578125
INFO:root:Train (Epoch 287): Loss/seq after 03550 batchs: 368.7373962402344
INFO:root:Train (Epoch 287): Loss/seq after 03600 batchs: 372.15069580078125
INFO:root:Train (Epoch 287): Loss/seq after 03650 batchs: 371.06072998046875
INFO:root:Train (Epoch 287): Loss/seq after 03700 batchs: 373.0157470703125
INFO:root:Train (Epoch 287): Loss/seq after 03750 batchs: 376.5131530761719
INFO:root:Train (Epoch 287): Loss/seq after 03800 batchs: 376.0105285644531
INFO:root:Train (Epoch 287): Loss/seq after 03850 batchs: 375.5337219238281
INFO:root:Train (Epoch 287): Loss/seq after 03900 batchs: 377.15570068359375
INFO:root:Train (Epoch 287): Loss/seq after 03950 batchs: 379.6617431640625
INFO:root:Train (Epoch 287): Loss/seq after 04000 batchs: 377.46136474609375
INFO:root:Train (Epoch 287): Loss/seq after 04050 batchs: 375.41729736328125
INFO:root:Train (Epoch 287): Loss/seq after 04100 batchs: 375.182373046875
INFO:root:Train (Epoch 287): Loss/seq after 04150 batchs: 375.3153076171875
INFO:root:Train (Epoch 287): Loss/seq after 04200 batchs: 374.5233459472656
INFO:root:Train (Epoch 287): Loss/seq after 04250 batchs: 373.59698486328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 287): Loss/seq after 00000 batches: 409.3375244140625
INFO:root:# Valid (Epoch 287): Loss/seq after 00050 batches: 723.2642822265625
INFO:root:# Valid (Epoch 287): Loss/seq after 00100 batches: 838.5238647460938
INFO:root:# Valid (Epoch 287): Loss/seq after 00150 batches: 617.7385864257812
INFO:root:# Valid (Epoch 287): Loss/seq after 00200 batches: 547.8002319335938
INFO:root:Artifacts: Make stick videos for epoch 287
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_287_on_20220423_195846.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_287_index_451_on_20220423_195846.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 288): Loss/seq after 00000 batchs: 532.0198974609375
INFO:root:Train (Epoch 288): Loss/seq after 00050 batchs: 486.52423095703125
INFO:root:Train (Epoch 288): Loss/seq after 00100 batchs: 515.3338623046875
INFO:root:Train (Epoch 288): Loss/seq after 00150 batchs: 472.449462890625
INFO:root:Train (Epoch 288): Loss/seq after 00200 batchs: 540.3221435546875
INFO:root:Train (Epoch 288): Loss/seq after 00250 batchs: 554.8384399414062
INFO:root:Train (Epoch 288): Loss/seq after 00300 batchs: 573.1831665039062
INFO:root:Train (Epoch 288): Loss/seq after 00350 batchs: 546.5064086914062
INFO:root:Train (Epoch 288): Loss/seq after 00400 batchs: 541.0283203125
INFO:root:Train (Epoch 288): Loss/seq after 00450 batchs: 548.962646484375
INFO:root:Train (Epoch 288): Loss/seq after 00500 batchs: 532.8974609375
INFO:root:Train (Epoch 288): Loss/seq after 00550 batchs: 523.8101806640625
INFO:root:Train (Epoch 288): Loss/seq after 00600 batchs: 506.9315490722656
INFO:root:Train (Epoch 288): Loss/seq after 00650 batchs: 488.76934814453125
INFO:root:Train (Epoch 288): Loss/seq after 00700 batchs: 469.98748779296875
INFO:root:Train (Epoch 288): Loss/seq after 00750 batchs: 465.5888671875
INFO:root:Train (Epoch 288): Loss/seq after 00800 batchs: 467.1170654296875
INFO:root:Train (Epoch 288): Loss/seq after 00850 batchs: 453.3869323730469
INFO:root:Train (Epoch 288): Loss/seq after 00900 batchs: 441.7493896484375
INFO:root:Train (Epoch 288): Loss/seq after 00950 batchs: 440.2679443359375
INFO:root:Train (Epoch 288): Loss/seq after 01000 batchs: 432.8115539550781
INFO:root:Train (Epoch 288): Loss/seq after 01050 batchs: 424.2270812988281
INFO:root:Train (Epoch 288): Loss/seq after 01100 batchs: 414.9635009765625
INFO:root:Train (Epoch 288): Loss/seq after 01150 batchs: 404.1614685058594
INFO:root:Train (Epoch 288): Loss/seq after 01200 batchs: 405.3556823730469
INFO:root:Train (Epoch 288): Loss/seq after 01250 batchs: 404.4797058105469
INFO:root:Train (Epoch 288): Loss/seq after 01300 batchs: 396.5066833496094
INFO:root:Train (Epoch 288): Loss/seq after 01350 batchs: 388.67633056640625
INFO:root:Train (Epoch 288): Loss/seq after 01400 batchs: 390.86419677734375
INFO:root:Train (Epoch 288): Loss/seq after 01450 batchs: 394.7010498046875
INFO:root:Train (Epoch 288): Loss/seq after 01500 batchs: 401.042724609375
INFO:root:Train (Epoch 288): Loss/seq after 01550 batchs: 402.62518310546875
INFO:root:Train (Epoch 288): Loss/seq after 01600 batchs: 400.7819519042969
INFO:root:Train (Epoch 288): Loss/seq after 01650 batchs: 398.9926452636719
INFO:root:Train (Epoch 288): Loss/seq after 01700 batchs: 402.9393005371094
INFO:root:Train (Epoch 288): Loss/seq after 01750 batchs: 402.039794921875
INFO:root:Train (Epoch 288): Loss/seq after 01800 batchs: 400.5177307128906
INFO:root:Train (Epoch 288): Loss/seq after 01850 batchs: 398.42376708984375
INFO:root:Train (Epoch 288): Loss/seq after 01900 batchs: 397.5628967285156
INFO:root:Train (Epoch 288): Loss/seq after 01950 batchs: 397.2794189453125
INFO:root:Train (Epoch 288): Loss/seq after 02000 batchs: 398.7060852050781
INFO:root:Train (Epoch 288): Loss/seq after 02050 batchs: 398.8184509277344
INFO:root:Train (Epoch 288): Loss/seq after 02100 batchs: 398.19097900390625
INFO:root:Train (Epoch 288): Loss/seq after 02150 batchs: 397.5523986816406
INFO:root:Train (Epoch 288): Loss/seq after 02200 batchs: 396.66705322265625
INFO:root:Train (Epoch 288): Loss/seq after 02250 batchs: 395.77496337890625
INFO:root:Train (Epoch 288): Loss/seq after 02300 batchs: 393.32879638671875
INFO:root:Train (Epoch 288): Loss/seq after 02350 batchs: 390.8627014160156
INFO:root:Train (Epoch 288): Loss/seq after 02400 batchs: 392.38470458984375
INFO:root:Train (Epoch 288): Loss/seq after 02450 batchs: 389.2447814941406
INFO:root:Train (Epoch 288): Loss/seq after 02500 batchs: 383.0124816894531
INFO:root:Train (Epoch 288): Loss/seq after 02550 batchs: 378.0295715332031
INFO:root:Train (Epoch 288): Loss/seq after 02600 batchs: 374.7882385253906
INFO:root:Train (Epoch 288): Loss/seq after 02650 batchs: 371.5461730957031
INFO:root:Train (Epoch 288): Loss/seq after 02700 batchs: 369.3132019042969
INFO:root:Train (Epoch 288): Loss/seq after 02750 batchs: 365.20050048828125
INFO:root:Train (Epoch 288): Loss/seq after 02800 batchs: 364.30206298828125
INFO:root:Train (Epoch 288): Loss/seq after 02850 batchs: 364.1230773925781
INFO:root:Train (Epoch 288): Loss/seq after 02900 batchs: 365.1641540527344
INFO:root:Train (Epoch 288): Loss/seq after 02950 batchs: 365.9362487792969
INFO:root:Train (Epoch 288): Loss/seq after 03000 batchs: 369.61322021484375
INFO:root:Train (Epoch 288): Loss/seq after 03050 batchs: 371.4268798828125
INFO:root:Train (Epoch 288): Loss/seq after 03100 batchs: 373.379638671875
INFO:root:Train (Epoch 288): Loss/seq after 03150 batchs: 373.03399658203125
INFO:root:Train (Epoch 288): Loss/seq after 03200 batchs: 373.0809326171875
INFO:root:Train (Epoch 288): Loss/seq after 03250 batchs: 374.01068115234375
INFO:root:Train (Epoch 288): Loss/seq after 03300 batchs: 373.3406982421875
INFO:root:Train (Epoch 288): Loss/seq after 03350 batchs: 371.2602844238281
INFO:root:Train (Epoch 288): Loss/seq after 03400 batchs: 369.10235595703125
INFO:root:Train (Epoch 288): Loss/seq after 03450 batchs: 368.1815185546875
INFO:root:Train (Epoch 288): Loss/seq after 03500 batchs: 368.99957275390625
INFO:root:Train (Epoch 288): Loss/seq after 03550 batchs: 367.4858093261719
INFO:root:Train (Epoch 288): Loss/seq after 03600 batchs: 370.9557189941406
INFO:root:Train (Epoch 288): Loss/seq after 03650 batchs: 369.88531494140625
INFO:root:Train (Epoch 288): Loss/seq after 03700 batchs: 372.0127868652344
INFO:root:Train (Epoch 288): Loss/seq after 03750 batchs: 375.5452575683594
INFO:root:Train (Epoch 288): Loss/seq after 03800 batchs: 375.0915222167969
INFO:root:Train (Epoch 288): Loss/seq after 03850 batchs: 374.6177978515625
INFO:root:Train (Epoch 288): Loss/seq after 03900 batchs: 376.0340270996094
INFO:root:Train (Epoch 288): Loss/seq after 03950 batchs: 379.0429992675781
INFO:root:Train (Epoch 288): Loss/seq after 04000 batchs: 376.78253173828125
INFO:root:Train (Epoch 288): Loss/seq after 04050 batchs: 374.6662902832031
INFO:root:Train (Epoch 288): Loss/seq after 04100 batchs: 374.3972473144531
INFO:root:Train (Epoch 288): Loss/seq after 04150 batchs: 374.5626525878906
INFO:root:Train (Epoch 288): Loss/seq after 04200 batchs: 373.7354431152344
INFO:root:Train (Epoch 288): Loss/seq after 04250 batchs: 372.77044677734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 288): Loss/seq after 00000 batches: 397.0061340332031
INFO:root:# Valid (Epoch 288): Loss/seq after 00050 batches: 716.150146484375
INFO:root:# Valid (Epoch 288): Loss/seq after 00100 batches: 779.8848876953125
INFO:root:# Valid (Epoch 288): Loss/seq after 00150 batches: 572.8402709960938
INFO:root:# Valid (Epoch 288): Loss/seq after 00200 batches: 511.41363525390625
INFO:root:Artifacts: Make stick videos for epoch 288
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_288_on_20220423_200338.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_288_index_1314_on_20220423_200338.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 289): Loss/seq after 00000 batchs: 491.6394958496094
INFO:root:Train (Epoch 289): Loss/seq after 00050 batchs: 520.2694091796875
INFO:root:Train (Epoch 289): Loss/seq after 00100 batchs: 526.0826416015625
INFO:root:Train (Epoch 289): Loss/seq after 00150 batchs: 481.4403991699219
INFO:root:Train (Epoch 289): Loss/seq after 00200 batchs: 541.6781005859375
INFO:root:Train (Epoch 289): Loss/seq after 00250 batchs: 563.6271362304688
INFO:root:Train (Epoch 289): Loss/seq after 00300 batchs: 581.4904174804688
INFO:root:Train (Epoch 289): Loss/seq after 00350 batchs: 554.5698852539062
INFO:root:Train (Epoch 289): Loss/seq after 00400 batchs: 549.0848388671875
INFO:root:Train (Epoch 289): Loss/seq after 00450 batchs: 555.4022827148438
INFO:root:Train (Epoch 289): Loss/seq after 00500 batchs: 537.2640380859375
INFO:root:Train (Epoch 289): Loss/seq after 00550 batchs: 525.9585571289062
INFO:root:Train (Epoch 289): Loss/seq after 00600 batchs: 508.3901672363281
INFO:root:Train (Epoch 289): Loss/seq after 00650 batchs: 492.75994873046875
INFO:root:Train (Epoch 289): Loss/seq after 00700 batchs: 471.7738037109375
INFO:root:Train (Epoch 289): Loss/seq after 00750 batchs: 467.75042724609375
INFO:root:Train (Epoch 289): Loss/seq after 00800 batchs: 468.4394836425781
INFO:root:Train (Epoch 289): Loss/seq after 00850 batchs: 454.1817932128906
INFO:root:Train (Epoch 289): Loss/seq after 00900 batchs: 442.6978759765625
INFO:root:Train (Epoch 289): Loss/seq after 00950 batchs: 439.327880859375
INFO:root:Train (Epoch 289): Loss/seq after 01000 batchs: 432.89306640625
INFO:root:Train (Epoch 289): Loss/seq after 01050 batchs: 424.2790832519531
INFO:root:Train (Epoch 289): Loss/seq after 01100 batchs: 415.9930419921875
INFO:root:Train (Epoch 289): Loss/seq after 01150 batchs: 405.24273681640625
INFO:root:Train (Epoch 289): Loss/seq after 01200 batchs: 406.5677490234375
INFO:root:Train (Epoch 289): Loss/seq after 01250 batchs: 405.81719970703125
INFO:root:Train (Epoch 289): Loss/seq after 01300 batchs: 398.18072509765625
INFO:root:Train (Epoch 289): Loss/seq after 01350 batchs: 391.2379455566406
INFO:root:Train (Epoch 289): Loss/seq after 01400 batchs: 392.6884765625
INFO:root:Train (Epoch 289): Loss/seq after 01450 batchs: 396.3134460449219
INFO:root:Train (Epoch 289): Loss/seq after 01500 batchs: 402.2884826660156
INFO:root:Train (Epoch 289): Loss/seq after 01550 batchs: 403.2199401855469
INFO:root:Train (Epoch 289): Loss/seq after 01600 batchs: 401.07794189453125
INFO:root:Train (Epoch 289): Loss/seq after 01650 batchs: 399.08758544921875
INFO:root:Train (Epoch 289): Loss/seq after 01700 batchs: 403.1742248535156
INFO:root:Train (Epoch 289): Loss/seq after 01750 batchs: 402.27996826171875
INFO:root:Train (Epoch 289): Loss/seq after 01800 batchs: 400.76043701171875
INFO:root:Train (Epoch 289): Loss/seq after 01850 batchs: 398.7543029785156
INFO:root:Train (Epoch 289): Loss/seq after 01900 batchs: 397.5914306640625
INFO:root:Train (Epoch 289): Loss/seq after 01950 batchs: 396.9727783203125
INFO:root:Train (Epoch 289): Loss/seq after 02000 batchs: 398.2176818847656
INFO:root:Train (Epoch 289): Loss/seq after 02050 batchs: 397.9775695800781
INFO:root:Train (Epoch 289): Loss/seq after 02100 batchs: 397.2724914550781
INFO:root:Train (Epoch 289): Loss/seq after 02150 batchs: 396.80767822265625
INFO:root:Train (Epoch 289): Loss/seq after 02200 batchs: 395.902587890625
INFO:root:Train (Epoch 289): Loss/seq after 02250 batchs: 394.97369384765625
INFO:root:Train (Epoch 289): Loss/seq after 02300 batchs: 392.0635986328125
INFO:root:Train (Epoch 289): Loss/seq after 02350 batchs: 389.4886169433594
INFO:root:Train (Epoch 289): Loss/seq after 02400 batchs: 390.9648742675781
INFO:root:Train (Epoch 289): Loss/seq after 02450 batchs: 387.927490234375
INFO:root:Train (Epoch 289): Loss/seq after 02500 batchs: 381.7381286621094
INFO:root:Train (Epoch 289): Loss/seq after 02550 batchs: 376.84136962890625
INFO:root:Train (Epoch 289): Loss/seq after 02600 batchs: 373.4059143066406
INFO:root:Train (Epoch 289): Loss/seq after 02650 batchs: 370.4454345703125
INFO:root:Train (Epoch 289): Loss/seq after 02700 batchs: 368.1830139160156
INFO:root:Train (Epoch 289): Loss/seq after 02750 batchs: 364.3210144042969
INFO:root:Train (Epoch 289): Loss/seq after 02800 batchs: 363.05047607421875
INFO:root:Train (Epoch 289): Loss/seq after 02850 batchs: 362.99554443359375
INFO:root:Train (Epoch 289): Loss/seq after 02900 batchs: 364.2198791503906
INFO:root:Train (Epoch 289): Loss/seq after 02950 batchs: 365.0260925292969
INFO:root:Train (Epoch 289): Loss/seq after 03000 batchs: 368.81036376953125
INFO:root:Train (Epoch 289): Loss/seq after 03050 batchs: 370.74444580078125
INFO:root:Train (Epoch 289): Loss/seq after 03100 batchs: 372.357666015625
INFO:root:Train (Epoch 289): Loss/seq after 03150 batchs: 372.52166748046875
INFO:root:Train (Epoch 289): Loss/seq after 03200 batchs: 373.0428771972656
INFO:root:Train (Epoch 289): Loss/seq after 03250 batchs: 373.7882385253906
INFO:root:Train (Epoch 289): Loss/seq after 03300 batchs: 373.1623229980469
INFO:root:Train (Epoch 289): Loss/seq after 03350 batchs: 371.66534423828125
INFO:root:Train (Epoch 289): Loss/seq after 03400 batchs: 369.46759033203125
INFO:root:Train (Epoch 289): Loss/seq after 03450 batchs: 368.4609680175781
INFO:root:Train (Epoch 289): Loss/seq after 03500 batchs: 369.6423034667969
INFO:root:Train (Epoch 289): Loss/seq after 03550 batchs: 368.1675720214844
INFO:root:Train (Epoch 289): Loss/seq after 03600 batchs: 371.3265075683594
INFO:root:Train (Epoch 289): Loss/seq after 03650 batchs: 370.30340576171875
INFO:root:Train (Epoch 289): Loss/seq after 03700 batchs: 372.61114501953125
INFO:root:Train (Epoch 289): Loss/seq after 03750 batchs: 376.15142822265625
INFO:root:Train (Epoch 289): Loss/seq after 03800 batchs: 375.80133056640625
INFO:root:Train (Epoch 289): Loss/seq after 03850 batchs: 375.222900390625
INFO:root:Train (Epoch 289): Loss/seq after 03900 batchs: 376.5638427734375
INFO:root:Train (Epoch 289): Loss/seq after 03950 batchs: 379.29473876953125
INFO:root:Train (Epoch 289): Loss/seq after 04000 batchs: 377.0548095703125
INFO:root:Train (Epoch 289): Loss/seq after 04050 batchs: 374.9935607910156
INFO:root:Train (Epoch 289): Loss/seq after 04100 batchs: 374.6711120605469
INFO:root:Train (Epoch 289): Loss/seq after 04150 batchs: 374.7525634765625
INFO:root:Train (Epoch 289): Loss/seq after 04200 batchs: 373.91961669921875
INFO:root:Train (Epoch 289): Loss/seq after 04250 batchs: 372.89886474609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 289): Loss/seq after 00000 batches: 396.6032409667969
INFO:root:# Valid (Epoch 289): Loss/seq after 00050 batches: 724.2921752929688
INFO:root:# Valid (Epoch 289): Loss/seq after 00100 batches: 695.5044555664062
INFO:root:# Valid (Epoch 289): Loss/seq after 00150 batches: 518.8255004882812
INFO:root:# Valid (Epoch 289): Loss/seq after 00200 batches: 470.7422790527344
INFO:root:Artifacts: Make stick videos for epoch 289
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_289_on_20220423_200847.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_289_index_839_on_20220423_200847.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 290): Loss/seq after 00000 batchs: 773.8881225585938
INFO:root:Train (Epoch 290): Loss/seq after 00050 batchs: 488.9648132324219
INFO:root:Train (Epoch 290): Loss/seq after 00100 batchs: 510.8540344238281
INFO:root:Train (Epoch 290): Loss/seq after 00150 batchs: 471.2067565917969
INFO:root:Train (Epoch 290): Loss/seq after 00200 batchs: 542.1461791992188
INFO:root:Train (Epoch 290): Loss/seq after 00250 batchs: 575.0494384765625
INFO:root:Train (Epoch 290): Loss/seq after 00300 batchs: 588.790771484375
INFO:root:Train (Epoch 290): Loss/seq after 00350 batchs: 559.4729614257812
INFO:root:Train (Epoch 290): Loss/seq after 00400 batchs: 549.39892578125
INFO:root:Train (Epoch 290): Loss/seq after 00450 batchs: 556.2810668945312
INFO:root:Train (Epoch 290): Loss/seq after 00500 batchs: 540.1541748046875
INFO:root:Train (Epoch 290): Loss/seq after 00550 batchs: 528.6090698242188
INFO:root:Train (Epoch 290): Loss/seq after 00600 batchs: 511.22003173828125
INFO:root:Train (Epoch 290): Loss/seq after 00650 batchs: 493.171142578125
INFO:root:Train (Epoch 290): Loss/seq after 00700 batchs: 473.262451171875
INFO:root:Train (Epoch 290): Loss/seq after 00750 batchs: 468.59771728515625
INFO:root:Train (Epoch 290): Loss/seq after 00800 batchs: 470.0273132324219
INFO:root:Train (Epoch 290): Loss/seq after 00850 batchs: 455.55047607421875
INFO:root:Train (Epoch 290): Loss/seq after 00900 batchs: 444.0025939941406
INFO:root:Train (Epoch 290): Loss/seq after 00950 batchs: 442.6624450683594
INFO:root:Train (Epoch 290): Loss/seq after 01000 batchs: 436.4785461425781
INFO:root:Train (Epoch 290): Loss/seq after 01050 batchs: 427.9602966308594
INFO:root:Train (Epoch 290): Loss/seq after 01100 batchs: 419.24072265625
INFO:root:Train (Epoch 290): Loss/seq after 01150 batchs: 408.32269287109375
INFO:root:Train (Epoch 290): Loss/seq after 01200 batchs: 409.76031494140625
INFO:root:Train (Epoch 290): Loss/seq after 01250 batchs: 409.144287109375
INFO:root:Train (Epoch 290): Loss/seq after 01300 batchs: 401.0007019042969
INFO:root:Train (Epoch 290): Loss/seq after 01350 batchs: 393.3963623046875
INFO:root:Train (Epoch 290): Loss/seq after 01400 batchs: 395.71533203125
INFO:root:Train (Epoch 290): Loss/seq after 01450 batchs: 398.7117919921875
INFO:root:Train (Epoch 290): Loss/seq after 01500 batchs: 404.8384094238281
INFO:root:Train (Epoch 290): Loss/seq after 01550 batchs: 405.4768981933594
INFO:root:Train (Epoch 290): Loss/seq after 01600 batchs: 403.2344665527344
INFO:root:Train (Epoch 290): Loss/seq after 01650 batchs: 401.30120849609375
INFO:root:Train (Epoch 290): Loss/seq after 01700 batchs: 404.9803771972656
INFO:root:Train (Epoch 290): Loss/seq after 01750 batchs: 403.9142150878906
INFO:root:Train (Epoch 290): Loss/seq after 01800 batchs: 402.43658447265625
INFO:root:Train (Epoch 290): Loss/seq after 01850 batchs: 400.2216491699219
INFO:root:Train (Epoch 290): Loss/seq after 01900 batchs: 399.1275939941406
INFO:root:Train (Epoch 290): Loss/seq after 01950 batchs: 398.8116149902344
INFO:root:Train (Epoch 290): Loss/seq after 02000 batchs: 400.04351806640625
INFO:root:Train (Epoch 290): Loss/seq after 02050 batchs: 399.6704406738281
INFO:root:Train (Epoch 290): Loss/seq after 02100 batchs: 398.81024169921875
INFO:root:Train (Epoch 290): Loss/seq after 02150 batchs: 398.1276550292969
INFO:root:Train (Epoch 290): Loss/seq after 02200 batchs: 397.2142333984375
INFO:root:Train (Epoch 290): Loss/seq after 02250 batchs: 396.4654541015625
INFO:root:Train (Epoch 290): Loss/seq after 02300 batchs: 393.9292907714844
INFO:root:Train (Epoch 290): Loss/seq after 02350 batchs: 391.47747802734375
INFO:root:Train (Epoch 290): Loss/seq after 02400 batchs: 392.94482421875
INFO:root:Train (Epoch 290): Loss/seq after 02450 batchs: 389.8205261230469
INFO:root:Train (Epoch 290): Loss/seq after 02500 batchs: 383.59002685546875
INFO:root:Train (Epoch 290): Loss/seq after 02550 batchs: 378.6302490234375
INFO:root:Train (Epoch 290): Loss/seq after 02600 batchs: 375.3224182128906
INFO:root:Train (Epoch 290): Loss/seq after 02650 batchs: 372.0794372558594
INFO:root:Train (Epoch 290): Loss/seq after 02700 batchs: 370.01983642578125
INFO:root:Train (Epoch 290): Loss/seq after 02750 batchs: 366.2666320800781
INFO:root:Train (Epoch 290): Loss/seq after 02800 batchs: 364.6955871582031
INFO:root:Train (Epoch 290): Loss/seq after 02850 batchs: 364.33392333984375
INFO:root:Train (Epoch 290): Loss/seq after 02900 batchs: 365.2561340332031
INFO:root:Train (Epoch 290): Loss/seq after 02950 batchs: 366.1006774902344
INFO:root:Train (Epoch 290): Loss/seq after 03000 batchs: 369.6944885253906
INFO:root:Train (Epoch 290): Loss/seq after 03050 batchs: 371.6024475097656
INFO:root:Train (Epoch 290): Loss/seq after 03100 batchs: 373.84100341796875
INFO:root:Train (Epoch 290): Loss/seq after 03150 batchs: 373.7286682128906
INFO:root:Train (Epoch 290): Loss/seq after 03200 batchs: 373.8157653808594
INFO:root:Train (Epoch 290): Loss/seq after 03250 batchs: 374.8250732421875
INFO:root:Train (Epoch 290): Loss/seq after 03300 batchs: 374.5036315917969
INFO:root:Train (Epoch 290): Loss/seq after 03350 batchs: 372.99755859375
INFO:root:Train (Epoch 290): Loss/seq after 03400 batchs: 370.898681640625
INFO:root:Train (Epoch 290): Loss/seq after 03450 batchs: 369.7887268066406
INFO:root:Train (Epoch 290): Loss/seq after 03500 batchs: 371.3399353027344
INFO:root:Train (Epoch 290): Loss/seq after 03550 batchs: 369.8893737792969
INFO:root:Train (Epoch 290): Loss/seq after 03600 batchs: 372.9054260253906
INFO:root:Train (Epoch 290): Loss/seq after 03650 batchs: 371.6127624511719
INFO:root:Train (Epoch 290): Loss/seq after 03700 batchs: 373.5383605957031
INFO:root:Train (Epoch 290): Loss/seq after 03750 batchs: 377.0504455566406
INFO:root:Train (Epoch 290): Loss/seq after 03800 batchs: 376.5667419433594
INFO:root:Train (Epoch 290): Loss/seq after 03850 batchs: 376.0812072753906
INFO:root:Train (Epoch 290): Loss/seq after 03900 batchs: 377.7148742675781
INFO:root:Train (Epoch 290): Loss/seq after 03950 batchs: 381.0653991699219
INFO:root:Train (Epoch 290): Loss/seq after 04000 batchs: 378.85943603515625
INFO:root:Train (Epoch 290): Loss/seq after 04050 batchs: 376.8328857421875
INFO:root:Train (Epoch 290): Loss/seq after 04100 batchs: 376.54364013671875
INFO:root:Train (Epoch 290): Loss/seq after 04150 batchs: 376.555908203125
INFO:root:Train (Epoch 290): Loss/seq after 04200 batchs: 375.721435546875
INFO:root:Train (Epoch 290): Loss/seq after 04250 batchs: 374.6746520996094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 290): Loss/seq after 00000 batches: 400.6581115722656
INFO:root:# Valid (Epoch 290): Loss/seq after 00050 batches: 715.456298828125
INFO:root:# Valid (Epoch 290): Loss/seq after 00100 batches: 837.7936401367188
INFO:root:# Valid (Epoch 290): Loss/seq after 00150 batches: 616.0330200195312
INFO:root:# Valid (Epoch 290): Loss/seq after 00200 batches: 544.242919921875
INFO:root:Artifacts: Make stick videos for epoch 290
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_290_on_20220423_201343.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_290_index_662_on_20220423_201343.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 291): Loss/seq after 00000 batchs: 595.2396850585938
INFO:root:Train (Epoch 291): Loss/seq after 00050 batchs: 489.1914367675781
INFO:root:Train (Epoch 291): Loss/seq after 00100 batchs: 505.116455078125
INFO:root:Train (Epoch 291): Loss/seq after 00150 batchs: 467.7409362792969
INFO:root:Train (Epoch 291): Loss/seq after 00200 batchs: 540.9518432617188
INFO:root:Train (Epoch 291): Loss/seq after 00250 batchs: 573.1929321289062
INFO:root:Train (Epoch 291): Loss/seq after 00300 batchs: 588.905029296875
INFO:root:Train (Epoch 291): Loss/seq after 00350 batchs: 561.404541015625
INFO:root:Train (Epoch 291): Loss/seq after 00400 batchs: 552.4278564453125
INFO:root:Train (Epoch 291): Loss/seq after 00450 batchs: 558.7703247070312
INFO:root:Train (Epoch 291): Loss/seq after 00500 batchs: 543.599609375
INFO:root:Train (Epoch 291): Loss/seq after 00550 batchs: 531.7366333007812
INFO:root:Train (Epoch 291): Loss/seq after 00600 batchs: 513.7854614257812
INFO:root:Train (Epoch 291): Loss/seq after 00650 batchs: 496.60455322265625
INFO:root:Train (Epoch 291): Loss/seq after 00700 batchs: 478.23333740234375
INFO:root:Train (Epoch 291): Loss/seq after 00750 batchs: 473.93902587890625
INFO:root:Train (Epoch 291): Loss/seq after 00800 batchs: 474.4035949707031
INFO:root:Train (Epoch 291): Loss/seq after 00850 batchs: 459.8988342285156
INFO:root:Train (Epoch 291): Loss/seq after 00900 batchs: 448.4170227050781
INFO:root:Train (Epoch 291): Loss/seq after 00950 batchs: 446.2640075683594
INFO:root:Train (Epoch 291): Loss/seq after 01000 batchs: 439.0257568359375
INFO:root:Train (Epoch 291): Loss/seq after 01050 batchs: 430.25567626953125
INFO:root:Train (Epoch 291): Loss/seq after 01100 batchs: 421.23040771484375
INFO:root:Train (Epoch 291): Loss/seq after 01150 batchs: 410.2060546875
INFO:root:Train (Epoch 291): Loss/seq after 01200 batchs: 411.27716064453125
INFO:root:Train (Epoch 291): Loss/seq after 01250 batchs: 410.16192626953125
INFO:root:Train (Epoch 291): Loss/seq after 01300 batchs: 401.61639404296875
INFO:root:Train (Epoch 291): Loss/seq after 01350 batchs: 393.3775329589844
INFO:root:Train (Epoch 291): Loss/seq after 01400 batchs: 395.6092529296875
INFO:root:Train (Epoch 291): Loss/seq after 01450 batchs: 398.74395751953125
INFO:root:Train (Epoch 291): Loss/seq after 01500 batchs: 404.451171875
INFO:root:Train (Epoch 291): Loss/seq after 01550 batchs: 405.5332336425781
INFO:root:Train (Epoch 291): Loss/seq after 01600 batchs: 403.4027404785156
INFO:root:Train (Epoch 291): Loss/seq after 01650 batchs: 401.7449951171875
INFO:root:Train (Epoch 291): Loss/seq after 01700 batchs: 405.8383483886719
INFO:root:Train (Epoch 291): Loss/seq after 01750 batchs: 404.7571105957031
INFO:root:Train (Epoch 291): Loss/seq after 01800 batchs: 403.0999755859375
INFO:root:Train (Epoch 291): Loss/seq after 01850 batchs: 400.78521728515625
INFO:root:Train (Epoch 291): Loss/seq after 01900 batchs: 399.6146240234375
INFO:root:Train (Epoch 291): Loss/seq after 01950 batchs: 399.367919921875
INFO:root:Train (Epoch 291): Loss/seq after 02000 batchs: 400.5752258300781
INFO:root:Train (Epoch 291): Loss/seq after 02050 batchs: 400.0267028808594
INFO:root:Train (Epoch 291): Loss/seq after 02100 batchs: 399.0648498535156
INFO:root:Train (Epoch 291): Loss/seq after 02150 batchs: 398.5146789550781
INFO:root:Train (Epoch 291): Loss/seq after 02200 batchs: 397.421875
INFO:root:Train (Epoch 291): Loss/seq after 02250 batchs: 396.4747314453125
INFO:root:Train (Epoch 291): Loss/seq after 02300 batchs: 395.22857666015625
INFO:root:Train (Epoch 291): Loss/seq after 02350 batchs: 392.6158447265625
INFO:root:Train (Epoch 291): Loss/seq after 02400 batchs: 393.9685974121094
INFO:root:Train (Epoch 291): Loss/seq after 02450 batchs: 390.8334045410156
INFO:root:Train (Epoch 291): Loss/seq after 02500 batchs: 384.5715026855469
INFO:root:Train (Epoch 291): Loss/seq after 02550 batchs: 379.5940246582031
INFO:root:Train (Epoch 291): Loss/seq after 02600 batchs: 376.08612060546875
INFO:root:Train (Epoch 291): Loss/seq after 02650 batchs: 372.8508605957031
INFO:root:Train (Epoch 291): Loss/seq after 02700 batchs: 370.5151062011719
INFO:root:Train (Epoch 291): Loss/seq after 02750 batchs: 366.3694763183594
INFO:root:Train (Epoch 291): Loss/seq after 02800 batchs: 365.02618408203125
INFO:root:Train (Epoch 291): Loss/seq after 02850 batchs: 364.6549377441406
INFO:root:Train (Epoch 291): Loss/seq after 02900 batchs: 365.7259826660156
INFO:root:Train (Epoch 291): Loss/seq after 02950 batchs: 366.4103698730469
INFO:root:Train (Epoch 291): Loss/seq after 03000 batchs: 370.10406494140625
INFO:root:Train (Epoch 291): Loss/seq after 03050 batchs: 372.09063720703125
INFO:root:Train (Epoch 291): Loss/seq after 03100 batchs: 374.0788879394531
INFO:root:Train (Epoch 291): Loss/seq after 03150 batchs: 374.40802001953125
INFO:root:Train (Epoch 291): Loss/seq after 03200 batchs: 374.7696228027344
INFO:root:Train (Epoch 291): Loss/seq after 03250 batchs: 375.0868835449219
INFO:root:Train (Epoch 291): Loss/seq after 03300 batchs: 374.491455078125
INFO:root:Train (Epoch 291): Loss/seq after 03350 batchs: 372.55120849609375
INFO:root:Train (Epoch 291): Loss/seq after 03400 batchs: 370.41912841796875
INFO:root:Train (Epoch 291): Loss/seq after 03450 batchs: 369.33502197265625
INFO:root:Train (Epoch 291): Loss/seq after 03500 batchs: 369.9336853027344
INFO:root:Train (Epoch 291): Loss/seq after 03550 batchs: 368.2710266113281
INFO:root:Train (Epoch 291): Loss/seq after 03600 batchs: 371.48907470703125
INFO:root:Train (Epoch 291): Loss/seq after 03650 batchs: 370.32470703125
INFO:root:Train (Epoch 291): Loss/seq after 03700 batchs: 372.5429382324219
INFO:root:Train (Epoch 291): Loss/seq after 03750 batchs: 376.0040283203125
INFO:root:Train (Epoch 291): Loss/seq after 03800 batchs: 375.53118896484375
INFO:root:Train (Epoch 291): Loss/seq after 03850 batchs: 375.0871887207031
INFO:root:Train (Epoch 291): Loss/seq after 03900 batchs: 376.5883483886719
INFO:root:Train (Epoch 291): Loss/seq after 03950 batchs: 379.30712890625
INFO:root:Train (Epoch 291): Loss/seq after 04000 batchs: 377.138916015625
INFO:root:Train (Epoch 291): Loss/seq after 04050 batchs: 375.0764465332031
INFO:root:Train (Epoch 291): Loss/seq after 04100 batchs: 374.7891540527344
INFO:root:Train (Epoch 291): Loss/seq after 04150 batchs: 374.9027099609375
INFO:root:Train (Epoch 291): Loss/seq after 04200 batchs: 374.13604736328125
INFO:root:Train (Epoch 291): Loss/seq after 04250 batchs: 373.10699462890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 291): Loss/seq after 00000 batches: 403.83349609375
INFO:root:# Valid (Epoch 291): Loss/seq after 00050 batches: 736.3926391601562
INFO:root:# Valid (Epoch 291): Loss/seq after 00100 batches: 799.928466796875
INFO:root:# Valid (Epoch 291): Loss/seq after 00150 batches: 586.8711547851562
INFO:root:# Valid (Epoch 291): Loss/seq after 00200 batches: 523.5072021484375
INFO:root:Artifacts: Make stick videos for epoch 291
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_291_on_20220423_201830.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_291_index_1233_on_20220423_201830.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 292): Loss/seq after 00000 batchs: 547.3519897460938
INFO:root:Train (Epoch 292): Loss/seq after 00050 batchs: 488.8271484375
INFO:root:Train (Epoch 292): Loss/seq after 00100 batchs: 500.3415832519531
INFO:root:Train (Epoch 292): Loss/seq after 00150 batchs: 463.9223937988281
INFO:root:Train (Epoch 292): Loss/seq after 00200 batchs: 527.3760986328125
INFO:root:Train (Epoch 292): Loss/seq after 00250 batchs: 544.0338745117188
INFO:root:Train (Epoch 292): Loss/seq after 00300 batchs: 562.9404907226562
INFO:root:Train (Epoch 292): Loss/seq after 00350 batchs: 536.86572265625
INFO:root:Train (Epoch 292): Loss/seq after 00400 batchs: 532.58984375
INFO:root:Train (Epoch 292): Loss/seq after 00450 batchs: 541.5166015625
INFO:root:Train (Epoch 292): Loss/seq after 00500 batchs: 526.3121337890625
INFO:root:Train (Epoch 292): Loss/seq after 00550 batchs: 515.4337768554688
INFO:root:Train (Epoch 292): Loss/seq after 00600 batchs: 498.60064697265625
INFO:root:Train (Epoch 292): Loss/seq after 00650 batchs: 479.320556640625
INFO:root:Train (Epoch 292): Loss/seq after 00700 batchs: 461.59771728515625
INFO:root:Train (Epoch 292): Loss/seq after 00750 batchs: 457.69244384765625
INFO:root:Train (Epoch 292): Loss/seq after 00800 batchs: 459.4391174316406
INFO:root:Train (Epoch 292): Loss/seq after 00850 batchs: 445.5719299316406
INFO:root:Train (Epoch 292): Loss/seq after 00900 batchs: 434.079833984375
INFO:root:Train (Epoch 292): Loss/seq after 00950 batchs: 432.7035827636719
INFO:root:Train (Epoch 292): Loss/seq after 01000 batchs: 426.5958557128906
INFO:root:Train (Epoch 292): Loss/seq after 01050 batchs: 418.4188537597656
INFO:root:Train (Epoch 292): Loss/seq after 01100 batchs: 409.2725830078125
INFO:root:Train (Epoch 292): Loss/seq after 01150 batchs: 398.4416198730469
INFO:root:Train (Epoch 292): Loss/seq after 01200 batchs: 399.9020690917969
INFO:root:Train (Epoch 292): Loss/seq after 01250 batchs: 399.0618896484375
INFO:root:Train (Epoch 292): Loss/seq after 01300 batchs: 391.06060791015625
INFO:root:Train (Epoch 292): Loss/seq after 01350 batchs: 383.3837890625
INFO:root:Train (Epoch 292): Loss/seq after 01400 batchs: 385.3356628417969
INFO:root:Train (Epoch 292): Loss/seq after 01450 batchs: 389.33563232421875
INFO:root:Train (Epoch 292): Loss/seq after 01500 batchs: 395.4772033691406
INFO:root:Train (Epoch 292): Loss/seq after 01550 batchs: 396.5314636230469
INFO:root:Train (Epoch 292): Loss/seq after 01600 batchs: 394.4871826171875
INFO:root:Train (Epoch 292): Loss/seq after 01650 batchs: 392.8821716308594
INFO:root:Train (Epoch 292): Loss/seq after 01700 batchs: 396.7174377441406
INFO:root:Train (Epoch 292): Loss/seq after 01750 batchs: 396.01019287109375
INFO:root:Train (Epoch 292): Loss/seq after 01800 batchs: 394.4381103515625
INFO:root:Train (Epoch 292): Loss/seq after 01850 batchs: 392.3540954589844
INFO:root:Train (Epoch 292): Loss/seq after 01900 batchs: 391.4330749511719
INFO:root:Train (Epoch 292): Loss/seq after 01950 batchs: 391.3450927734375
INFO:root:Train (Epoch 292): Loss/seq after 02000 batchs: 392.7853088378906
INFO:root:Train (Epoch 292): Loss/seq after 02050 batchs: 392.70452880859375
INFO:root:Train (Epoch 292): Loss/seq after 02100 batchs: 391.8077392578125
INFO:root:Train (Epoch 292): Loss/seq after 02150 batchs: 391.28265380859375
INFO:root:Train (Epoch 292): Loss/seq after 02200 batchs: 390.38592529296875
INFO:root:Train (Epoch 292): Loss/seq after 02250 batchs: 389.75836181640625
INFO:root:Train (Epoch 292): Loss/seq after 02300 batchs: 388.11956787109375
INFO:root:Train (Epoch 292): Loss/seq after 02350 batchs: 385.7109375
INFO:root:Train (Epoch 292): Loss/seq after 02400 batchs: 387.1308898925781
INFO:root:Train (Epoch 292): Loss/seq after 02450 batchs: 384.08489990234375
INFO:root:Train (Epoch 292): Loss/seq after 02500 batchs: 377.90087890625
INFO:root:Train (Epoch 292): Loss/seq after 02550 batchs: 373.0609130859375
INFO:root:Train (Epoch 292): Loss/seq after 02600 batchs: 369.8519592285156
INFO:root:Train (Epoch 292): Loss/seq after 02650 batchs: 366.78973388671875
INFO:root:Train (Epoch 292): Loss/seq after 02700 batchs: 364.5816955566406
INFO:root:Train (Epoch 292): Loss/seq after 02750 batchs: 360.9361877441406
INFO:root:Train (Epoch 292): Loss/seq after 02800 batchs: 358.9703674316406
INFO:root:Train (Epoch 292): Loss/seq after 02850 batchs: 358.9115905761719
INFO:root:Train (Epoch 292): Loss/seq after 02900 batchs: 359.7151184082031
INFO:root:Train (Epoch 292): Loss/seq after 02950 batchs: 360.5447998046875
INFO:root:Train (Epoch 292): Loss/seq after 03000 batchs: 364.3083801269531
INFO:root:Train (Epoch 292): Loss/seq after 03050 batchs: 366.1941223144531
INFO:root:Train (Epoch 292): Loss/seq after 03100 batchs: 368.8645935058594
INFO:root:Train (Epoch 292): Loss/seq after 03150 batchs: 368.7665100097656
INFO:root:Train (Epoch 292): Loss/seq after 03200 batchs: 369.34832763671875
INFO:root:Train (Epoch 292): Loss/seq after 03250 batchs: 370.1661376953125
INFO:root:Train (Epoch 292): Loss/seq after 03300 batchs: 369.89599609375
INFO:root:Train (Epoch 292): Loss/seq after 03350 batchs: 368.17388916015625
INFO:root:Train (Epoch 292): Loss/seq after 03400 batchs: 366.0168762207031
INFO:root:Train (Epoch 292): Loss/seq after 03450 batchs: 365.1295471191406
INFO:root:Train (Epoch 292): Loss/seq after 03500 batchs: 366.66766357421875
INFO:root:Train (Epoch 292): Loss/seq after 03550 batchs: 365.1475830078125
INFO:root:Train (Epoch 292): Loss/seq after 03600 batchs: 368.04119873046875
INFO:root:Train (Epoch 292): Loss/seq after 03650 batchs: 366.8388671875
INFO:root:Train (Epoch 292): Loss/seq after 03700 batchs: 368.80230712890625
INFO:root:Train (Epoch 292): Loss/seq after 03750 batchs: 372.2898864746094
INFO:root:Train (Epoch 292): Loss/seq after 03800 batchs: 371.9331970214844
INFO:root:Train (Epoch 292): Loss/seq after 03850 batchs: 371.5997009277344
INFO:root:Train (Epoch 292): Loss/seq after 03900 batchs: 373.0263366699219
INFO:root:Train (Epoch 292): Loss/seq after 03950 batchs: 376.0768737792969
INFO:root:Train (Epoch 292): Loss/seq after 04000 batchs: 373.8992919921875
INFO:root:Train (Epoch 292): Loss/seq after 04050 batchs: 371.88153076171875
INFO:root:Train (Epoch 292): Loss/seq after 04100 batchs: 371.57611083984375
INFO:root:Train (Epoch 292): Loss/seq after 04150 batchs: 371.68426513671875
INFO:root:Train (Epoch 292): Loss/seq after 04200 batchs: 370.8544006347656
INFO:root:Train (Epoch 292): Loss/seq after 04250 batchs: 369.79302978515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 292): Loss/seq after 00000 batches: 378.48553466796875
INFO:root:# Valid (Epoch 292): Loss/seq after 00050 batches: 721.812744140625
INFO:root:# Valid (Epoch 292): Loss/seq after 00100 batches: 720.9925537109375
INFO:root:# Valid (Epoch 292): Loss/seq after 00150 batches: 535.076904296875
INFO:root:# Valid (Epoch 292): Loss/seq after 00200 batches: 483.2733459472656
INFO:root:Artifacts: Make stick videos for epoch 292
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_292_on_20220423_202322.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_292_index_1707_on_20220423_202322.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 293): Loss/seq after 00000 batchs: 546.161376953125
INFO:root:Train (Epoch 293): Loss/seq after 00050 batchs: 502.23095703125
INFO:root:Train (Epoch 293): Loss/seq after 00100 batchs: 518.3662719726562
INFO:root:Train (Epoch 293): Loss/seq after 00150 batchs: 472.7726135253906
INFO:root:Train (Epoch 293): Loss/seq after 00200 batchs: 548.246826171875
INFO:root:Train (Epoch 293): Loss/seq after 00250 batchs: 568.963134765625
INFO:root:Train (Epoch 293): Loss/seq after 00300 batchs: 583.287109375
INFO:root:Train (Epoch 293): Loss/seq after 00350 batchs: 555.1444091796875
INFO:root:Train (Epoch 293): Loss/seq after 00400 batchs: 545.9641723632812
INFO:root:Train (Epoch 293): Loss/seq after 00450 batchs: 553.2896118164062
INFO:root:Train (Epoch 293): Loss/seq after 00500 batchs: 539.4605102539062
INFO:root:Train (Epoch 293): Loss/seq after 00550 batchs: 527.8829345703125
INFO:root:Train (Epoch 293): Loss/seq after 00600 batchs: 510.845458984375
INFO:root:Train (Epoch 293): Loss/seq after 00650 batchs: 490.9904479980469
INFO:root:Train (Epoch 293): Loss/seq after 00700 batchs: 471.4062194824219
INFO:root:Train (Epoch 293): Loss/seq after 00750 batchs: 466.291015625
INFO:root:Train (Epoch 293): Loss/seq after 00800 batchs: 466.79681396484375
INFO:root:Train (Epoch 293): Loss/seq after 00850 batchs: 452.1398010253906
INFO:root:Train (Epoch 293): Loss/seq after 00900 batchs: 440.3128662109375
INFO:root:Train (Epoch 293): Loss/seq after 00950 batchs: 439.78912353515625
INFO:root:Train (Epoch 293): Loss/seq after 01000 batchs: 432.58526611328125
INFO:root:Train (Epoch 293): Loss/seq after 01050 batchs: 423.7533874511719
INFO:root:Train (Epoch 293): Loss/seq after 01100 batchs: 414.8449401855469
INFO:root:Train (Epoch 293): Loss/seq after 01150 batchs: 403.99652099609375
INFO:root:Train (Epoch 293): Loss/seq after 01200 batchs: 404.3435363769531
INFO:root:Train (Epoch 293): Loss/seq after 01250 batchs: 402.8315124511719
INFO:root:Train (Epoch 293): Loss/seq after 01300 batchs: 394.4128723144531
INFO:root:Train (Epoch 293): Loss/seq after 01350 batchs: 386.5245056152344
INFO:root:Train (Epoch 293): Loss/seq after 01400 batchs: 389.0777587890625
INFO:root:Train (Epoch 293): Loss/seq after 01450 batchs: 392.4205627441406
INFO:root:Train (Epoch 293): Loss/seq after 01500 batchs: 398.22686767578125
INFO:root:Train (Epoch 293): Loss/seq after 01550 batchs: 399.1162414550781
INFO:root:Train (Epoch 293): Loss/seq after 01600 batchs: 397.0103759765625
INFO:root:Train (Epoch 293): Loss/seq after 01650 batchs: 395.4405822753906
INFO:root:Train (Epoch 293): Loss/seq after 01700 batchs: 399.2960205078125
INFO:root:Train (Epoch 293): Loss/seq after 01750 batchs: 398.3770751953125
INFO:root:Train (Epoch 293): Loss/seq after 01800 batchs: 396.68988037109375
INFO:root:Train (Epoch 293): Loss/seq after 01850 batchs: 394.4407043457031
INFO:root:Train (Epoch 293): Loss/seq after 01900 batchs: 393.75518798828125
INFO:root:Train (Epoch 293): Loss/seq after 01950 batchs: 394.0613098144531
INFO:root:Train (Epoch 293): Loss/seq after 02000 batchs: 395.5365905761719
INFO:root:Train (Epoch 293): Loss/seq after 02050 batchs: 395.16607666015625
INFO:root:Train (Epoch 293): Loss/seq after 02100 batchs: 394.5278015136719
INFO:root:Train (Epoch 293): Loss/seq after 02150 batchs: 394.07562255859375
INFO:root:Train (Epoch 293): Loss/seq after 02200 batchs: 393.0888366699219
INFO:root:Train (Epoch 293): Loss/seq after 02250 batchs: 392.272705078125
INFO:root:Train (Epoch 293): Loss/seq after 02300 batchs: 390.4201965332031
INFO:root:Train (Epoch 293): Loss/seq after 02350 batchs: 387.85919189453125
INFO:root:Train (Epoch 293): Loss/seq after 02400 batchs: 389.2032165527344
INFO:root:Train (Epoch 293): Loss/seq after 02450 batchs: 386.0157775878906
INFO:root:Train (Epoch 293): Loss/seq after 02500 batchs: 379.8143310546875
INFO:root:Train (Epoch 293): Loss/seq after 02550 batchs: 374.93536376953125
INFO:root:Train (Epoch 293): Loss/seq after 02600 batchs: 371.3462829589844
INFO:root:Train (Epoch 293): Loss/seq after 02650 batchs: 368.31024169921875
INFO:root:Train (Epoch 293): Loss/seq after 02700 batchs: 366.1540222167969
INFO:root:Train (Epoch 293): Loss/seq after 02750 batchs: 362.45440673828125
INFO:root:Train (Epoch 293): Loss/seq after 02800 batchs: 361.22802734375
INFO:root:Train (Epoch 293): Loss/seq after 02850 batchs: 361.0501403808594
INFO:root:Train (Epoch 293): Loss/seq after 02900 batchs: 362.08477783203125
INFO:root:Train (Epoch 293): Loss/seq after 02950 batchs: 362.9051208496094
INFO:root:Train (Epoch 293): Loss/seq after 03000 batchs: 366.2925109863281
INFO:root:Train (Epoch 293): Loss/seq after 03050 batchs: 367.89337158203125
INFO:root:Train (Epoch 293): Loss/seq after 03100 batchs: 370.109619140625
INFO:root:Train (Epoch 293): Loss/seq after 03150 batchs: 369.5058288574219
INFO:root:Train (Epoch 293): Loss/seq after 03200 batchs: 369.4515686035156
INFO:root:Train (Epoch 293): Loss/seq after 03250 batchs: 370.1146545410156
INFO:root:Train (Epoch 293): Loss/seq after 03300 batchs: 369.2955322265625
INFO:root:Train (Epoch 293): Loss/seq after 03350 batchs: 367.395751953125
INFO:root:Train (Epoch 293): Loss/seq after 03400 batchs: 365.2752380371094
INFO:root:Train (Epoch 293): Loss/seq after 03450 batchs: 364.2937316894531
INFO:root:Train (Epoch 293): Loss/seq after 03500 batchs: 365.25439453125
INFO:root:Train (Epoch 293): Loss/seq after 03550 batchs: 363.7572937011719
INFO:root:Train (Epoch 293): Loss/seq after 03600 batchs: 367.283447265625
INFO:root:Train (Epoch 293): Loss/seq after 03650 batchs: 365.9359436035156
INFO:root:Train (Epoch 293): Loss/seq after 03700 batchs: 368.01397705078125
INFO:root:Train (Epoch 293): Loss/seq after 03750 batchs: 371.4945983886719
INFO:root:Train (Epoch 293): Loss/seq after 03800 batchs: 371.1705627441406
INFO:root:Train (Epoch 293): Loss/seq after 03850 batchs: 370.7485046386719
INFO:root:Train (Epoch 293): Loss/seq after 03900 batchs: 372.08074951171875
INFO:root:Train (Epoch 293): Loss/seq after 03950 batchs: 374.96990966796875
INFO:root:Train (Epoch 293): Loss/seq after 04000 batchs: 372.782958984375
INFO:root:Train (Epoch 293): Loss/seq after 04050 batchs: 370.7279052734375
INFO:root:Train (Epoch 293): Loss/seq after 04100 batchs: 370.4020080566406
INFO:root:Train (Epoch 293): Loss/seq after 04150 batchs: 370.57598876953125
INFO:root:Train (Epoch 293): Loss/seq after 04200 batchs: 369.70355224609375
INFO:root:Train (Epoch 293): Loss/seq after 04250 batchs: 368.81756591796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 293): Loss/seq after 00000 batches: 310.2506408691406
INFO:root:# Valid (Epoch 293): Loss/seq after 00050 batches: 732.912109375
INFO:root:# Valid (Epoch 293): Loss/seq after 00100 batches: 887.99560546875
INFO:root:# Valid (Epoch 293): Loss/seq after 00150 batches: 646.7093505859375
INFO:root:# Valid (Epoch 293): Loss/seq after 00200 batches: 567.1320190429688
INFO:root:Artifacts: Make stick videos for epoch 293
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_293_on_20220423_202818.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_293_index_1191_on_20220423_202818.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 294): Loss/seq after 00000 batchs: 597.3978881835938
INFO:root:Train (Epoch 294): Loss/seq after 00050 batchs: 489.6754150390625
INFO:root:Train (Epoch 294): Loss/seq after 00100 batchs: 505.6454772949219
INFO:root:Train (Epoch 294): Loss/seq after 00150 batchs: 466.3880920410156
INFO:root:Train (Epoch 294): Loss/seq after 00200 batchs: 531.9955444335938
INFO:root:Train (Epoch 294): Loss/seq after 00250 batchs: 562.4108276367188
INFO:root:Train (Epoch 294): Loss/seq after 00300 batchs: 575.5375366210938
INFO:root:Train (Epoch 294): Loss/seq after 00350 batchs: 546.3737182617188
INFO:root:Train (Epoch 294): Loss/seq after 00400 batchs: 531.7694702148438
INFO:root:Train (Epoch 294): Loss/seq after 00450 batchs: 540.4794921875
INFO:root:Train (Epoch 294): Loss/seq after 00500 batchs: 523.396484375
INFO:root:Train (Epoch 294): Loss/seq after 00550 batchs: 512.29150390625
INFO:root:Train (Epoch 294): Loss/seq after 00600 batchs: 496.01605224609375
INFO:root:Train (Epoch 294): Loss/seq after 00650 batchs: 479.19866943359375
INFO:root:Train (Epoch 294): Loss/seq after 00700 batchs: 460.8758544921875
INFO:root:Train (Epoch 294): Loss/seq after 00750 batchs: 456.03460693359375
INFO:root:Train (Epoch 294): Loss/seq after 00800 batchs: 456.94256591796875
INFO:root:Train (Epoch 294): Loss/seq after 00850 batchs: 442.9958801269531
INFO:root:Train (Epoch 294): Loss/seq after 00900 batchs: 431.8399353027344
INFO:root:Train (Epoch 294): Loss/seq after 00950 batchs: 430.8261413574219
INFO:root:Train (Epoch 294): Loss/seq after 01000 batchs: 423.5962219238281
INFO:root:Train (Epoch 294): Loss/seq after 01050 batchs: 415.2398681640625
INFO:root:Train (Epoch 294): Loss/seq after 01100 batchs: 406.5680236816406
INFO:root:Train (Epoch 294): Loss/seq after 01150 batchs: 396.02581787109375
INFO:root:Train (Epoch 294): Loss/seq after 01200 batchs: 397.5816955566406
INFO:root:Train (Epoch 294): Loss/seq after 01250 batchs: 397.1376953125
INFO:root:Train (Epoch 294): Loss/seq after 01300 batchs: 389.1950378417969
INFO:root:Train (Epoch 294): Loss/seq after 01350 batchs: 381.774169921875
INFO:root:Train (Epoch 294): Loss/seq after 01400 batchs: 384.6972351074219
INFO:root:Train (Epoch 294): Loss/seq after 01450 batchs: 388.23211669921875
INFO:root:Train (Epoch 294): Loss/seq after 01500 batchs: 394.01239013671875
INFO:root:Train (Epoch 294): Loss/seq after 01550 batchs: 395.21710205078125
INFO:root:Train (Epoch 294): Loss/seq after 01600 batchs: 393.7139587402344
INFO:root:Train (Epoch 294): Loss/seq after 01650 batchs: 391.9975280761719
INFO:root:Train (Epoch 294): Loss/seq after 01700 batchs: 396.0206298828125
INFO:root:Train (Epoch 294): Loss/seq after 01750 batchs: 395.3322448730469
INFO:root:Train (Epoch 294): Loss/seq after 01800 batchs: 393.9268798828125
INFO:root:Train (Epoch 294): Loss/seq after 01850 batchs: 391.6416015625
INFO:root:Train (Epoch 294): Loss/seq after 01900 batchs: 390.93133544921875
INFO:root:Train (Epoch 294): Loss/seq after 01950 batchs: 390.867919921875
INFO:root:Train (Epoch 294): Loss/seq after 02000 batchs: 392.33038330078125
INFO:root:Train (Epoch 294): Loss/seq after 02050 batchs: 392.2260437011719
INFO:root:Train (Epoch 294): Loss/seq after 02100 batchs: 391.2699279785156
INFO:root:Train (Epoch 294): Loss/seq after 02150 batchs: 390.672119140625
INFO:root:Train (Epoch 294): Loss/seq after 02200 batchs: 389.75885009765625
INFO:root:Train (Epoch 294): Loss/seq after 02250 batchs: 388.9422912597656
INFO:root:Train (Epoch 294): Loss/seq after 02300 batchs: 386.7573547363281
INFO:root:Train (Epoch 294): Loss/seq after 02350 batchs: 384.42510986328125
INFO:root:Train (Epoch 294): Loss/seq after 02400 batchs: 385.79730224609375
INFO:root:Train (Epoch 294): Loss/seq after 02450 batchs: 382.8652648925781
INFO:root:Train (Epoch 294): Loss/seq after 02500 batchs: 376.7579650878906
INFO:root:Train (Epoch 294): Loss/seq after 02550 batchs: 372.0039978027344
INFO:root:Train (Epoch 294): Loss/seq after 02600 batchs: 368.7319641113281
INFO:root:Train (Epoch 294): Loss/seq after 02650 batchs: 365.5370788574219
INFO:root:Train (Epoch 294): Loss/seq after 02700 batchs: 363.6402587890625
INFO:root:Train (Epoch 294): Loss/seq after 02750 batchs: 360.19793701171875
INFO:root:Train (Epoch 294): Loss/seq after 02800 batchs: 358.84576416015625
INFO:root:Train (Epoch 294): Loss/seq after 02850 batchs: 358.6646728515625
INFO:root:Train (Epoch 294): Loss/seq after 02900 batchs: 359.6707763671875
INFO:root:Train (Epoch 294): Loss/seq after 02950 batchs: 360.5049133300781
INFO:root:Train (Epoch 294): Loss/seq after 03000 batchs: 364.03778076171875
INFO:root:Train (Epoch 294): Loss/seq after 03050 batchs: 365.7926330566406
INFO:root:Train (Epoch 294): Loss/seq after 03100 batchs: 367.4367980957031
INFO:root:Train (Epoch 294): Loss/seq after 03150 batchs: 367.3505859375
INFO:root:Train (Epoch 294): Loss/seq after 03200 batchs: 367.48736572265625
INFO:root:Train (Epoch 294): Loss/seq after 03250 batchs: 367.4224548339844
INFO:root:Train (Epoch 294): Loss/seq after 03300 batchs: 366.70928955078125
INFO:root:Train (Epoch 294): Loss/seq after 03350 batchs: 365.12396240234375
INFO:root:Train (Epoch 294): Loss/seq after 03400 batchs: 362.9786682128906
INFO:root:Train (Epoch 294): Loss/seq after 03450 batchs: 362.0772399902344
INFO:root:Train (Epoch 294): Loss/seq after 03500 batchs: 363.0191345214844
INFO:root:Train (Epoch 294): Loss/seq after 03550 batchs: 361.5363464355469
INFO:root:Train (Epoch 294): Loss/seq after 03600 batchs: 364.84368896484375
INFO:root:Train (Epoch 294): Loss/seq after 03650 batchs: 363.8431701660156
INFO:root:Train (Epoch 294): Loss/seq after 03700 batchs: 366.058837890625
INFO:root:Train (Epoch 294): Loss/seq after 03750 batchs: 369.46282958984375
INFO:root:Train (Epoch 294): Loss/seq after 03800 batchs: 369.2201843261719
INFO:root:Train (Epoch 294): Loss/seq after 03850 batchs: 368.68048095703125
INFO:root:Train (Epoch 294): Loss/seq after 03900 batchs: 370.8375549316406
INFO:root:Train (Epoch 294): Loss/seq after 03950 batchs: 374.347900390625
INFO:root:Train (Epoch 294): Loss/seq after 04000 batchs: 372.1435852050781
INFO:root:Train (Epoch 294): Loss/seq after 04050 batchs: 370.1140441894531
INFO:root:Train (Epoch 294): Loss/seq after 04100 batchs: 369.86065673828125
INFO:root:Train (Epoch 294): Loss/seq after 04150 batchs: 369.98834228515625
INFO:root:Train (Epoch 294): Loss/seq after 04200 batchs: 369.1839294433594
INFO:root:Train (Epoch 294): Loss/seq after 04250 batchs: 368.2650451660156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 294): Loss/seq after 00000 batches: 352.0267333984375
INFO:root:# Valid (Epoch 294): Loss/seq after 00050 batches: 730.147216796875
INFO:root:# Valid (Epoch 294): Loss/seq after 00100 batches: 880.3854370117188
INFO:root:# Valid (Epoch 294): Loss/seq after 00150 batches: 640.3143920898438
INFO:root:# Valid (Epoch 294): Loss/seq after 00200 batches: 562.4855346679688
INFO:root:Artifacts: Make stick videos for epoch 294
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_294_on_20220423_203307.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_294_index_490_on_20220423_203307.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 295): Loss/seq after 00000 batchs: 533.7544555664062
INFO:root:Train (Epoch 295): Loss/seq after 00050 batchs: 508.6300048828125
INFO:root:Train (Epoch 295): Loss/seq after 00100 batchs: 528.7327270507812
INFO:root:Train (Epoch 295): Loss/seq after 00150 batchs: 481.7286376953125
INFO:root:Train (Epoch 295): Loss/seq after 00200 batchs: 539.8400268554688
INFO:root:Train (Epoch 295): Loss/seq after 00250 batchs: 565.8317260742188
INFO:root:Train (Epoch 295): Loss/seq after 00300 batchs: 579.336181640625
INFO:root:Train (Epoch 295): Loss/seq after 00350 batchs: 551.1004638671875
INFO:root:Train (Epoch 295): Loss/seq after 00400 batchs: 538.44482421875
INFO:root:Train (Epoch 295): Loss/seq after 00450 batchs: 545.9942016601562
INFO:root:Train (Epoch 295): Loss/seq after 00500 batchs: 529.1441040039062
INFO:root:Train (Epoch 295): Loss/seq after 00550 batchs: 516.8599243164062
INFO:root:Train (Epoch 295): Loss/seq after 00600 batchs: 500.5987243652344
INFO:root:Train (Epoch 295): Loss/seq after 00650 batchs: 486.04095458984375
INFO:root:Train (Epoch 295): Loss/seq after 00700 batchs: 467.1861877441406
INFO:root:Train (Epoch 295): Loss/seq after 00750 batchs: 463.7013244628906
INFO:root:Train (Epoch 295): Loss/seq after 00800 batchs: 464.41851806640625
INFO:root:Train (Epoch 295): Loss/seq after 00850 batchs: 450.0430603027344
INFO:root:Train (Epoch 295): Loss/seq after 00900 batchs: 438.1467590332031
INFO:root:Train (Epoch 295): Loss/seq after 00950 batchs: 436.8146057128906
INFO:root:Train (Epoch 295): Loss/seq after 01000 batchs: 430.88006591796875
INFO:root:Train (Epoch 295): Loss/seq after 01050 batchs: 425.338134765625
INFO:root:Train (Epoch 295): Loss/seq after 01100 batchs: 417.4736022949219
INFO:root:Train (Epoch 295): Loss/seq after 01150 batchs: 407.15447998046875
INFO:root:Train (Epoch 295): Loss/seq after 01200 batchs: 408.4588928222656
INFO:root:Train (Epoch 295): Loss/seq after 01250 batchs: 407.8487854003906
INFO:root:Train (Epoch 295): Loss/seq after 01300 batchs: 399.92791748046875
INFO:root:Train (Epoch 295): Loss/seq after 01350 batchs: 391.8406066894531
INFO:root:Train (Epoch 295): Loss/seq after 01400 batchs: 393.4641418457031
INFO:root:Train (Epoch 295): Loss/seq after 01450 batchs: 396.6291809082031
INFO:root:Train (Epoch 295): Loss/seq after 01500 batchs: 402.0639953613281
INFO:root:Train (Epoch 295): Loss/seq after 01550 batchs: 403.8037109375
INFO:root:Train (Epoch 295): Loss/seq after 01600 batchs: 401.966796875
INFO:root:Train (Epoch 295): Loss/seq after 01650 batchs: 400.710693359375
INFO:root:Train (Epoch 295): Loss/seq after 01700 batchs: 404.945556640625
INFO:root:Train (Epoch 295): Loss/seq after 01750 batchs: 404.0803527832031
INFO:root:Train (Epoch 295): Loss/seq after 01800 batchs: 402.3116149902344
INFO:root:Train (Epoch 295): Loss/seq after 01850 batchs: 399.9809265136719
INFO:root:Train (Epoch 295): Loss/seq after 01900 batchs: 399.44281005859375
INFO:root:Train (Epoch 295): Loss/seq after 01950 batchs: 399.3095703125
INFO:root:Train (Epoch 295): Loss/seq after 02000 batchs: 400.631103515625
INFO:root:Train (Epoch 295): Loss/seq after 02050 batchs: 400.35748291015625
INFO:root:Train (Epoch 295): Loss/seq after 02100 batchs: 399.38043212890625
INFO:root:Train (Epoch 295): Loss/seq after 02150 batchs: 398.5457763671875
INFO:root:Train (Epoch 295): Loss/seq after 02200 batchs: 397.42071533203125
INFO:root:Train (Epoch 295): Loss/seq after 02250 batchs: 396.426513671875
INFO:root:Train (Epoch 295): Loss/seq after 02300 batchs: 393.57464599609375
INFO:root:Train (Epoch 295): Loss/seq after 02350 batchs: 391.0051574707031
INFO:root:Train (Epoch 295): Loss/seq after 02400 batchs: 392.1689453125
INFO:root:Train (Epoch 295): Loss/seq after 02450 batchs: 388.92919921875
INFO:root:Train (Epoch 295): Loss/seq after 02500 batchs: 382.6712951660156
INFO:root:Train (Epoch 295): Loss/seq after 02550 batchs: 377.6685791015625
INFO:root:Train (Epoch 295): Loss/seq after 02600 batchs: 374.2416076660156
INFO:root:Train (Epoch 295): Loss/seq after 02650 batchs: 370.9876403808594
INFO:root:Train (Epoch 295): Loss/seq after 02700 batchs: 368.6539611816406
INFO:root:Train (Epoch 295): Loss/seq after 02750 batchs: 364.7575378417969
INFO:root:Train (Epoch 295): Loss/seq after 02800 batchs: 363.58294677734375
INFO:root:Train (Epoch 295): Loss/seq after 02850 batchs: 363.36859130859375
INFO:root:Train (Epoch 295): Loss/seq after 02900 batchs: 364.234130859375
INFO:root:Train (Epoch 295): Loss/seq after 02950 batchs: 365.0195617675781
INFO:root:Train (Epoch 295): Loss/seq after 03000 batchs: 368.5914001464844
INFO:root:Train (Epoch 295): Loss/seq after 03050 batchs: 370.0203857421875
INFO:root:Train (Epoch 295): Loss/seq after 03100 batchs: 371.3259582519531
INFO:root:Train (Epoch 295): Loss/seq after 03150 batchs: 371.728271484375
INFO:root:Train (Epoch 295): Loss/seq after 03200 batchs: 373.53826904296875
INFO:root:Train (Epoch 295): Loss/seq after 03250 batchs: 373.5124206542969
INFO:root:Train (Epoch 295): Loss/seq after 03300 batchs: 373.07464599609375
INFO:root:Train (Epoch 295): Loss/seq after 03350 batchs: 371.77923583984375
INFO:root:Train (Epoch 295): Loss/seq after 03400 batchs: 369.59112548828125
INFO:root:Train (Epoch 295): Loss/seq after 03450 batchs: 368.6650390625
INFO:root:Train (Epoch 295): Loss/seq after 03500 batchs: 369.8379821777344
INFO:root:Train (Epoch 295): Loss/seq after 03550 batchs: 368.2767639160156
INFO:root:Train (Epoch 295): Loss/seq after 03600 batchs: 371.5556640625
INFO:root:Train (Epoch 295): Loss/seq after 03650 batchs: 370.2806396484375
INFO:root:Train (Epoch 295): Loss/seq after 03700 batchs: 372.084716796875
INFO:root:Train (Epoch 295): Loss/seq after 03750 batchs: 375.39801025390625
INFO:root:Train (Epoch 295): Loss/seq after 03800 batchs: 374.95562744140625
INFO:root:Train (Epoch 295): Loss/seq after 03850 batchs: 374.42388916015625
INFO:root:Train (Epoch 295): Loss/seq after 03900 batchs: 375.8773498535156
INFO:root:Train (Epoch 295): Loss/seq after 03950 batchs: 378.4394836425781
INFO:root:Train (Epoch 295): Loss/seq after 04000 batchs: 376.2173156738281
INFO:root:Train (Epoch 295): Loss/seq after 04050 batchs: 374.12109375
INFO:root:Train (Epoch 295): Loss/seq after 04100 batchs: 373.8258056640625
INFO:root:Train (Epoch 295): Loss/seq after 04150 batchs: 373.79351806640625
INFO:root:Train (Epoch 295): Loss/seq after 04200 batchs: 372.8887023925781
INFO:root:Train (Epoch 295): Loss/seq after 04250 batchs: 371.8993835449219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 295): Loss/seq after 00000 batches: 398.0521545410156
INFO:root:# Valid (Epoch 295): Loss/seq after 00050 batches: 724.1943359375
INFO:root:# Valid (Epoch 295): Loss/seq after 00100 batches: 834.679931640625
INFO:root:# Valid (Epoch 295): Loss/seq after 00150 batches: 610.70703125
INFO:root:# Valid (Epoch 295): Loss/seq after 00200 batches: 540.7044677734375
INFO:root:Artifacts: Make stick videos for epoch 295
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_295_on_20220423_203751.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_295_index_1328_on_20220423_203751.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 296): Loss/seq after 00000 batchs: 715.7974243164062
INFO:root:Train (Epoch 296): Loss/seq after 00050 batchs: 511.4730529785156
INFO:root:Train (Epoch 296): Loss/seq after 00100 batchs: 527.1392822265625
INFO:root:Train (Epoch 296): Loss/seq after 00150 batchs: 481.2452392578125
INFO:root:Train (Epoch 296): Loss/seq after 00200 batchs: 543.0092163085938
INFO:root:Train (Epoch 296): Loss/seq after 00250 batchs: 557.15673828125
INFO:root:Train (Epoch 296): Loss/seq after 00300 batchs: 570.693115234375
INFO:root:Train (Epoch 296): Loss/seq after 00350 batchs: 542.8977661132812
INFO:root:Train (Epoch 296): Loss/seq after 00400 batchs: 534.3892211914062
INFO:root:Train (Epoch 296): Loss/seq after 00450 batchs: 542.6682739257812
INFO:root:Train (Epoch 296): Loss/seq after 00500 batchs: 526.867431640625
INFO:root:Train (Epoch 296): Loss/seq after 00550 batchs: 515.8102416992188
INFO:root:Train (Epoch 296): Loss/seq after 00600 batchs: 498.7484130859375
INFO:root:Train (Epoch 296): Loss/seq after 00650 batchs: 478.73004150390625
INFO:root:Train (Epoch 296): Loss/seq after 00700 batchs: 460.86358642578125
INFO:root:Train (Epoch 296): Loss/seq after 00750 batchs: 455.764892578125
INFO:root:Train (Epoch 296): Loss/seq after 00800 batchs: 456.71014404296875
INFO:root:Train (Epoch 296): Loss/seq after 00850 batchs: 442.7961120605469
INFO:root:Train (Epoch 296): Loss/seq after 00900 batchs: 431.69915771484375
INFO:root:Train (Epoch 296): Loss/seq after 00950 batchs: 430.0204772949219
INFO:root:Train (Epoch 296): Loss/seq after 01000 batchs: 423.4623718261719
INFO:root:Train (Epoch 296): Loss/seq after 01050 batchs: 416.57403564453125
INFO:root:Train (Epoch 296): Loss/seq after 01100 batchs: 407.8765563964844
INFO:root:Train (Epoch 296): Loss/seq after 01150 batchs: 397.3760986328125
INFO:root:Train (Epoch 296): Loss/seq after 01200 batchs: 398.61871337890625
INFO:root:Train (Epoch 296): Loss/seq after 01250 batchs: 398.1111755371094
INFO:root:Train (Epoch 296): Loss/seq after 01300 batchs: 390.0443420410156
INFO:root:Train (Epoch 296): Loss/seq after 01350 batchs: 381.6631774902344
INFO:root:Train (Epoch 296): Loss/seq after 01400 batchs: 383.677978515625
INFO:root:Train (Epoch 296): Loss/seq after 01450 batchs: 386.9712219238281
INFO:root:Train (Epoch 296): Loss/seq after 01500 batchs: 392.89288330078125
INFO:root:Train (Epoch 296): Loss/seq after 01550 batchs: 394.2871398925781
INFO:root:Train (Epoch 296): Loss/seq after 01600 batchs: 392.7457580566406
INFO:root:Train (Epoch 296): Loss/seq after 01650 batchs: 391.079833984375
INFO:root:Train (Epoch 296): Loss/seq after 01700 batchs: 394.8309326171875
INFO:root:Train (Epoch 296): Loss/seq after 01750 batchs: 393.8000183105469
INFO:root:Train (Epoch 296): Loss/seq after 01800 batchs: 392.2123107910156
INFO:root:Train (Epoch 296): Loss/seq after 01850 batchs: 390.097412109375
INFO:root:Train (Epoch 296): Loss/seq after 01900 batchs: 389.1537780761719
INFO:root:Train (Epoch 296): Loss/seq after 01950 batchs: 388.8876037597656
INFO:root:Train (Epoch 296): Loss/seq after 02000 batchs: 390.3775634765625
INFO:root:Train (Epoch 296): Loss/seq after 02050 batchs: 390.2376403808594
INFO:root:Train (Epoch 296): Loss/seq after 02100 batchs: 389.4385986328125
INFO:root:Train (Epoch 296): Loss/seq after 02150 batchs: 388.88409423828125
INFO:root:Train (Epoch 296): Loss/seq after 02200 batchs: 387.8864440917969
INFO:root:Train (Epoch 296): Loss/seq after 02250 batchs: 387.33953857421875
INFO:root:Train (Epoch 296): Loss/seq after 02300 batchs: 384.6240539550781
INFO:root:Train (Epoch 296): Loss/seq after 02350 batchs: 382.0561828613281
INFO:root:Train (Epoch 296): Loss/seq after 02400 batchs: 383.3986511230469
INFO:root:Train (Epoch 296): Loss/seq after 02450 batchs: 380.3237609863281
INFO:root:Train (Epoch 296): Loss/seq after 02500 batchs: 374.1995849609375
INFO:root:Train (Epoch 296): Loss/seq after 02550 batchs: 369.37322998046875
INFO:root:Train (Epoch 296): Loss/seq after 02600 batchs: 365.6018371582031
INFO:root:Train (Epoch 296): Loss/seq after 02650 batchs: 362.476318359375
INFO:root:Train (Epoch 296): Loss/seq after 02700 batchs: 360.3986511230469
INFO:root:Train (Epoch 296): Loss/seq after 02750 batchs: 356.59185791015625
INFO:root:Train (Epoch 296): Loss/seq after 02800 batchs: 355.287841796875
INFO:root:Train (Epoch 296): Loss/seq after 02850 batchs: 355.0621643066406
INFO:root:Train (Epoch 296): Loss/seq after 02900 batchs: 356.0349426269531
INFO:root:Train (Epoch 296): Loss/seq after 02950 batchs: 356.91961669921875
INFO:root:Train (Epoch 296): Loss/seq after 03000 batchs: 360.6710510253906
INFO:root:Train (Epoch 296): Loss/seq after 03050 batchs: 362.86822509765625
INFO:root:Train (Epoch 296): Loss/seq after 03100 batchs: 364.7665710449219
INFO:root:Train (Epoch 296): Loss/seq after 03150 batchs: 365.3744201660156
INFO:root:Train (Epoch 296): Loss/seq after 03200 batchs: 365.9773254394531
INFO:root:Train (Epoch 296): Loss/seq after 03250 batchs: 366.48779296875
INFO:root:Train (Epoch 296): Loss/seq after 03300 batchs: 366.1136169433594
INFO:root:Train (Epoch 296): Loss/seq after 03350 batchs: 364.3227233886719
INFO:root:Train (Epoch 296): Loss/seq after 03400 batchs: 362.27752685546875
INFO:root:Train (Epoch 296): Loss/seq after 03450 batchs: 361.32220458984375
INFO:root:Train (Epoch 296): Loss/seq after 03500 batchs: 362.45086669921875
INFO:root:Train (Epoch 296): Loss/seq after 03550 batchs: 361.0666198730469
INFO:root:Train (Epoch 296): Loss/seq after 03600 batchs: 364.27703857421875
INFO:root:Train (Epoch 296): Loss/seq after 03650 batchs: 363.1179504394531
INFO:root:Train (Epoch 296): Loss/seq after 03700 batchs: 365.1292419433594
INFO:root:Train (Epoch 296): Loss/seq after 03750 batchs: 370.34063720703125
INFO:root:Train (Epoch 296): Loss/seq after 03800 batchs: 370.2452087402344
INFO:root:Train (Epoch 296): Loss/seq after 03850 batchs: 370.843994140625
INFO:root:Train (Epoch 296): Loss/seq after 03900 batchs: 372.62347412109375
INFO:root:Train (Epoch 296): Loss/seq after 03950 batchs: 375.6698913574219
INFO:root:Train (Epoch 296): Loss/seq after 04000 batchs: 373.614013671875
INFO:root:Train (Epoch 296): Loss/seq after 04050 batchs: 371.7079772949219
INFO:root:Train (Epoch 296): Loss/seq after 04100 batchs: 371.5762939453125
INFO:root:Train (Epoch 296): Loss/seq after 04150 batchs: 371.7925109863281
INFO:root:Train (Epoch 296): Loss/seq after 04200 batchs: 371.0506286621094
INFO:root:Train (Epoch 296): Loss/seq after 04250 batchs: 370.2722473144531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 296): Loss/seq after 00000 batches: 412.8977355957031
INFO:root:# Valid (Epoch 296): Loss/seq after 00050 batches: 741.8619384765625
INFO:root:# Valid (Epoch 296): Loss/seq after 00100 batches: 751.4874267578125
INFO:root:# Valid (Epoch 296): Loss/seq after 00150 batches: 557.8770751953125
INFO:root:# Valid (Epoch 296): Loss/seq after 00200 batches: 501.8933410644531
INFO:root:Artifacts: Make stick videos for epoch 296
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_296_on_20220423_204257.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_296_index_702_on_20220423_204257.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 297): Loss/seq after 00000 batchs: 800.8156127929688
INFO:root:Train (Epoch 297): Loss/seq after 00050 batchs: 514.5770874023438
INFO:root:Train (Epoch 297): Loss/seq after 00100 batchs: 525.937744140625
INFO:root:Train (Epoch 297): Loss/seq after 00150 batchs: 479.3563232421875
INFO:root:Train (Epoch 297): Loss/seq after 00200 batchs: 538.20751953125
INFO:root:Train (Epoch 297): Loss/seq after 00250 batchs: 554.1287231445312
INFO:root:Train (Epoch 297): Loss/seq after 00300 batchs: 569.372314453125
INFO:root:Train (Epoch 297): Loss/seq after 00350 batchs: 542.2161865234375
INFO:root:Train (Epoch 297): Loss/seq after 00400 batchs: 529.2130737304688
INFO:root:Train (Epoch 297): Loss/seq after 00450 batchs: 537.9284057617188
INFO:root:Train (Epoch 297): Loss/seq after 00500 batchs: 521.904052734375
INFO:root:Train (Epoch 297): Loss/seq after 00550 batchs: 510.6896667480469
INFO:root:Train (Epoch 297): Loss/seq after 00600 batchs: 494.4058837890625
INFO:root:Train (Epoch 297): Loss/seq after 00650 batchs: 476.4207458496094
INFO:root:Train (Epoch 297): Loss/seq after 00700 batchs: 458.1193542480469
INFO:root:Train (Epoch 297): Loss/seq after 00750 batchs: 454.76123046875
INFO:root:Train (Epoch 297): Loss/seq after 00800 batchs: 455.9126281738281
INFO:root:Train (Epoch 297): Loss/seq after 00850 batchs: 442.2392272949219
INFO:root:Train (Epoch 297): Loss/seq after 00900 batchs: 431.4132995605469
INFO:root:Train (Epoch 297): Loss/seq after 00950 batchs: 429.3936462402344
INFO:root:Train (Epoch 297): Loss/seq after 01000 batchs: 424.6318664550781
INFO:root:Train (Epoch 297): Loss/seq after 01050 batchs: 416.37890625
INFO:root:Train (Epoch 297): Loss/seq after 01100 batchs: 407.3548278808594
INFO:root:Train (Epoch 297): Loss/seq after 01150 batchs: 396.9745178222656
INFO:root:Train (Epoch 297): Loss/seq after 01200 batchs: 397.8114013671875
INFO:root:Train (Epoch 297): Loss/seq after 01250 batchs: 396.8411865234375
INFO:root:Train (Epoch 297): Loss/seq after 01300 batchs: 388.7061767578125
INFO:root:Train (Epoch 297): Loss/seq after 01350 batchs: 381.16156005859375
INFO:root:Train (Epoch 297): Loss/seq after 01400 batchs: 382.7033386230469
INFO:root:Train (Epoch 297): Loss/seq after 01450 batchs: 385.8943786621094
INFO:root:Train (Epoch 297): Loss/seq after 01500 batchs: 391.0986022949219
INFO:root:Train (Epoch 297): Loss/seq after 01550 batchs: 391.69696044921875
INFO:root:Train (Epoch 297): Loss/seq after 01600 batchs: 389.68170166015625
INFO:root:Train (Epoch 297): Loss/seq after 01650 batchs: 388.123046875
INFO:root:Train (Epoch 297): Loss/seq after 01700 batchs: 392.1785583496094
INFO:root:Train (Epoch 297): Loss/seq after 01750 batchs: 391.4016418457031
INFO:root:Train (Epoch 297): Loss/seq after 01800 batchs: 389.8027648925781
INFO:root:Train (Epoch 297): Loss/seq after 01850 batchs: 387.8135986328125
INFO:root:Train (Epoch 297): Loss/seq after 01900 batchs: 386.911376953125
INFO:root:Train (Epoch 297): Loss/seq after 01950 batchs: 386.99053955078125
INFO:root:Train (Epoch 297): Loss/seq after 02000 batchs: 388.4472961425781
INFO:root:Train (Epoch 297): Loss/seq after 02050 batchs: 388.2872009277344
INFO:root:Train (Epoch 297): Loss/seq after 02100 batchs: 387.4709777832031
INFO:root:Train (Epoch 297): Loss/seq after 02150 batchs: 386.9890441894531
INFO:root:Train (Epoch 297): Loss/seq after 02200 batchs: 386.0446472167969
INFO:root:Train (Epoch 297): Loss/seq after 02250 batchs: 385.37176513671875
INFO:root:Train (Epoch 297): Loss/seq after 02300 batchs: 382.8290710449219
INFO:root:Train (Epoch 297): Loss/seq after 02350 batchs: 380.4604797363281
INFO:root:Train (Epoch 297): Loss/seq after 02400 batchs: 381.8538818359375
INFO:root:Train (Epoch 297): Loss/seq after 02450 batchs: 378.8663330078125
INFO:root:Train (Epoch 297): Loss/seq after 02500 batchs: 372.7716979980469
INFO:root:Train (Epoch 297): Loss/seq after 02550 batchs: 367.90911865234375
INFO:root:Train (Epoch 297): Loss/seq after 02600 batchs: 364.4619140625
INFO:root:Train (Epoch 297): Loss/seq after 02650 batchs: 361.2419738769531
INFO:root:Train (Epoch 297): Loss/seq after 02700 batchs: 359.16107177734375
INFO:root:Train (Epoch 297): Loss/seq after 02750 batchs: 355.4336853027344
INFO:root:Train (Epoch 297): Loss/seq after 02800 batchs: 354.78619384765625
INFO:root:Train (Epoch 297): Loss/seq after 02850 batchs: 354.5321350097656
INFO:root:Train (Epoch 297): Loss/seq after 02900 batchs: 355.8247985839844
INFO:root:Train (Epoch 297): Loss/seq after 02950 batchs: 356.73516845703125
INFO:root:Train (Epoch 297): Loss/seq after 03000 batchs: 360.3321533203125
INFO:root:Train (Epoch 297): Loss/seq after 03050 batchs: 362.0284118652344
INFO:root:Train (Epoch 297): Loss/seq after 03100 batchs: 364.9878845214844
INFO:root:Train (Epoch 297): Loss/seq after 03150 batchs: 366.7178039550781
INFO:root:Train (Epoch 297): Loss/seq after 03200 batchs: 368.4648742675781
INFO:root:Train (Epoch 297): Loss/seq after 03250 batchs: 368.53173828125
INFO:root:Train (Epoch 297): Loss/seq after 03300 batchs: 368.32806396484375
INFO:root:Train (Epoch 297): Loss/seq after 03350 batchs: 366.82867431640625
INFO:root:Train (Epoch 297): Loss/seq after 03400 batchs: 364.6065979003906
INFO:root:Train (Epoch 297): Loss/seq after 03450 batchs: 363.60675048828125
INFO:root:Train (Epoch 297): Loss/seq after 03500 batchs: 364.7164001464844
INFO:root:Train (Epoch 297): Loss/seq after 03550 batchs: 363.0494384765625
INFO:root:Train (Epoch 297): Loss/seq after 03600 batchs: 366.1009216308594
INFO:root:Train (Epoch 297): Loss/seq after 03650 batchs: 364.7709045410156
INFO:root:Train (Epoch 297): Loss/seq after 03700 batchs: 366.3243408203125
INFO:root:Train (Epoch 297): Loss/seq after 03750 batchs: 369.5834655761719
INFO:root:Train (Epoch 297): Loss/seq after 03800 batchs: 369.0726013183594
INFO:root:Train (Epoch 297): Loss/seq after 03850 batchs: 368.4930114746094
INFO:root:Train (Epoch 297): Loss/seq after 03900 batchs: 370.2434997558594
INFO:root:Train (Epoch 297): Loss/seq after 03950 batchs: 373.4454650878906
INFO:root:Train (Epoch 297): Loss/seq after 04000 batchs: 371.26568603515625
INFO:root:Train (Epoch 297): Loss/seq after 04050 batchs: 369.226806640625
INFO:root:Train (Epoch 297): Loss/seq after 04100 batchs: 368.799072265625
INFO:root:Train (Epoch 297): Loss/seq after 04150 batchs: 369.107177734375
INFO:root:Train (Epoch 297): Loss/seq after 04200 batchs: 368.4601135253906
INFO:root:Train (Epoch 297): Loss/seq after 04250 batchs: 367.5027770996094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 297): Loss/seq after 00000 batches: 391.8345947265625
INFO:root:# Valid (Epoch 297): Loss/seq after 00050 batches: 730.15966796875
INFO:root:# Valid (Epoch 297): Loss/seq after 00100 batches: 736.9436645507812
INFO:root:# Valid (Epoch 297): Loss/seq after 00150 batches: 543.8904418945312
INFO:root:# Valid (Epoch 297): Loss/seq after 00200 batches: 489.3774108886719
INFO:root:Artifacts: Make stick videos for epoch 297
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_297_on_20220423_204745.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_297_index_135_on_20220423_204745.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 298): Loss/seq after 00000 batchs: 638.6410522460938
INFO:root:Train (Epoch 298): Loss/seq after 00050 batchs: 512.7369384765625
INFO:root:Train (Epoch 298): Loss/seq after 00100 batchs: 518.7918701171875
INFO:root:Train (Epoch 298): Loss/seq after 00150 batchs: 472.4770202636719
INFO:root:Train (Epoch 298): Loss/seq after 00200 batchs: 534.8126220703125
INFO:root:Train (Epoch 298): Loss/seq after 00250 batchs: 563.1514892578125
INFO:root:Train (Epoch 298): Loss/seq after 00300 batchs: 576.25390625
INFO:root:Train (Epoch 298): Loss/seq after 00350 batchs: 547.9407348632812
INFO:root:Train (Epoch 298): Loss/seq after 00400 batchs: 541.7363891601562
INFO:root:Train (Epoch 298): Loss/seq after 00450 batchs: 548.8562622070312
INFO:root:Train (Epoch 298): Loss/seq after 00500 batchs: 534.4771118164062
INFO:root:Train (Epoch 298): Loss/seq after 00550 batchs: 524.2611083984375
INFO:root:Train (Epoch 298): Loss/seq after 00600 batchs: 508.08599853515625
INFO:root:Train (Epoch 298): Loss/seq after 00650 batchs: 490.2872619628906
INFO:root:Train (Epoch 298): Loss/seq after 00700 batchs: 471.219970703125
INFO:root:Train (Epoch 298): Loss/seq after 00750 batchs: 465.3359375
INFO:root:Train (Epoch 298): Loss/seq after 00800 batchs: 465.71173095703125
INFO:root:Train (Epoch 298): Loss/seq after 00850 batchs: 451.3686828613281
INFO:root:Train (Epoch 298): Loss/seq after 00900 batchs: 439.8183288574219
INFO:root:Train (Epoch 298): Loss/seq after 00950 batchs: 438.445068359375
INFO:root:Train (Epoch 298): Loss/seq after 01000 batchs: 431.0392150878906
INFO:root:Train (Epoch 298): Loss/seq after 01050 batchs: 421.9544677734375
INFO:root:Train (Epoch 298): Loss/seq after 01100 batchs: 412.4396057128906
INFO:root:Train (Epoch 298): Loss/seq after 01150 batchs: 401.31005859375
INFO:root:Train (Epoch 298): Loss/seq after 01200 batchs: 401.7327575683594
INFO:root:Train (Epoch 298): Loss/seq after 01250 batchs: 400.10626220703125
INFO:root:Train (Epoch 298): Loss/seq after 01300 batchs: 392.259033203125
INFO:root:Train (Epoch 298): Loss/seq after 01350 batchs: 384.3807373046875
INFO:root:Train (Epoch 298): Loss/seq after 01400 batchs: 385.30987548828125
INFO:root:Train (Epoch 298): Loss/seq after 01450 batchs: 388.477783203125
INFO:root:Train (Epoch 298): Loss/seq after 01500 batchs: 393.8844909667969
INFO:root:Train (Epoch 298): Loss/seq after 01550 batchs: 395.18560791015625
INFO:root:Train (Epoch 298): Loss/seq after 01600 batchs: 393.0278625488281
INFO:root:Train (Epoch 298): Loss/seq after 01650 batchs: 391.1180419921875
INFO:root:Train (Epoch 298): Loss/seq after 01700 batchs: 394.8133239746094
INFO:root:Train (Epoch 298): Loss/seq after 01750 batchs: 393.9994201660156
INFO:root:Train (Epoch 298): Loss/seq after 01800 batchs: 392.3536071777344
INFO:root:Train (Epoch 298): Loss/seq after 01850 batchs: 390.2900390625
INFO:root:Train (Epoch 298): Loss/seq after 01900 batchs: 389.16351318359375
INFO:root:Train (Epoch 298): Loss/seq after 01950 batchs: 388.9017639160156
INFO:root:Train (Epoch 298): Loss/seq after 02000 batchs: 390.14947509765625
INFO:root:Train (Epoch 298): Loss/seq after 02050 batchs: 389.9007568359375
INFO:root:Train (Epoch 298): Loss/seq after 02100 batchs: 389.0223083496094
INFO:root:Train (Epoch 298): Loss/seq after 02150 batchs: 388.4603271484375
INFO:root:Train (Epoch 298): Loss/seq after 02200 batchs: 387.561279296875
INFO:root:Train (Epoch 298): Loss/seq after 02250 batchs: 386.9795227050781
INFO:root:Train (Epoch 298): Loss/seq after 02300 batchs: 384.3824768066406
INFO:root:Train (Epoch 298): Loss/seq after 02350 batchs: 381.980712890625
INFO:root:Train (Epoch 298): Loss/seq after 02400 batchs: 383.3591613769531
INFO:root:Train (Epoch 298): Loss/seq after 02450 batchs: 380.2789001464844
INFO:root:Train (Epoch 298): Loss/seq after 02500 batchs: 374.1837463378906
INFO:root:Train (Epoch 298): Loss/seq after 02550 batchs: 369.3172607421875
INFO:root:Train (Epoch 298): Loss/seq after 02600 batchs: 365.9213562011719
INFO:root:Train (Epoch 298): Loss/seq after 02650 batchs: 362.49188232421875
INFO:root:Train (Epoch 298): Loss/seq after 02700 batchs: 360.3410949707031
INFO:root:Train (Epoch 298): Loss/seq after 02750 batchs: 356.1681213378906
INFO:root:Train (Epoch 298): Loss/seq after 02800 batchs: 355.5958251953125
INFO:root:Train (Epoch 298): Loss/seq after 02850 batchs: 355.59259033203125
INFO:root:Train (Epoch 298): Loss/seq after 02900 batchs: 356.496826171875
INFO:root:Train (Epoch 298): Loss/seq after 02950 batchs: 357.107177734375
INFO:root:Train (Epoch 298): Loss/seq after 03000 batchs: 360.6501159667969
INFO:root:Train (Epoch 298): Loss/seq after 03050 batchs: 362.4671936035156
INFO:root:Train (Epoch 298): Loss/seq after 03100 batchs: 364.0601806640625
INFO:root:Train (Epoch 298): Loss/seq after 03150 batchs: 363.90985107421875
INFO:root:Train (Epoch 298): Loss/seq after 03200 batchs: 364.5863037109375
INFO:root:Train (Epoch 298): Loss/seq after 03250 batchs: 364.8470153808594
INFO:root:Train (Epoch 298): Loss/seq after 03300 batchs: 364.2184143066406
INFO:root:Train (Epoch 298): Loss/seq after 03350 batchs: 362.4361572265625
INFO:root:Train (Epoch 298): Loss/seq after 03400 batchs: 360.378662109375
INFO:root:Train (Epoch 298): Loss/seq after 03450 batchs: 359.3487243652344
INFO:root:Train (Epoch 298): Loss/seq after 03500 batchs: 360.4908447265625
INFO:root:Train (Epoch 298): Loss/seq after 03550 batchs: 358.9908752441406
INFO:root:Train (Epoch 298): Loss/seq after 03600 batchs: 362.1255187988281
INFO:root:Train (Epoch 298): Loss/seq after 03650 batchs: 360.9385070800781
INFO:root:Train (Epoch 298): Loss/seq after 03700 batchs: 362.7906494140625
INFO:root:Train (Epoch 298): Loss/seq after 03750 batchs: 366.2072448730469
INFO:root:Train (Epoch 298): Loss/seq after 03800 batchs: 365.898681640625
INFO:root:Train (Epoch 298): Loss/seq after 03850 batchs: 365.45751953125
INFO:root:Train (Epoch 298): Loss/seq after 03900 batchs: 366.9657897949219
INFO:root:Train (Epoch 298): Loss/seq after 03950 batchs: 369.7801513671875
INFO:root:Train (Epoch 298): Loss/seq after 04000 batchs: 367.63238525390625
INFO:root:Train (Epoch 298): Loss/seq after 04050 batchs: 365.6679382324219
INFO:root:Train (Epoch 298): Loss/seq after 04100 batchs: 365.3313293457031
INFO:root:Train (Epoch 298): Loss/seq after 04150 batchs: 365.6023864746094
INFO:root:Train (Epoch 298): Loss/seq after 04200 batchs: 364.940673828125
INFO:root:Train (Epoch 298): Loss/seq after 04250 batchs: 363.8322448730469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 298): Loss/seq after 00000 batches: 396.487548828125
INFO:root:# Valid (Epoch 298): Loss/seq after 00050 batches: 712.3902587890625
INFO:root:# Valid (Epoch 298): Loss/seq after 00100 batches: 744.7479248046875
INFO:root:# Valid (Epoch 298): Loss/seq after 00150 batches: 548.9861450195312
INFO:root:# Valid (Epoch 298): Loss/seq after 00200 batches: 492.00457763671875
INFO:root:Artifacts: Make stick videos for epoch 298
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_298_on_20220423_205233.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_298_index_665_on_20220423_205233.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 299): Loss/seq after 00000 batchs: 793.3663330078125
INFO:root:Train (Epoch 299): Loss/seq after 00050 batchs: 503.6354064941406
INFO:root:Train (Epoch 299): Loss/seq after 00100 batchs: 509.6116943359375
INFO:root:Train (Epoch 299): Loss/seq after 00150 batchs: 470.2719421386719
INFO:root:Train (Epoch 299): Loss/seq after 00200 batchs: 523.4288940429688
INFO:root:Train (Epoch 299): Loss/seq after 00250 batchs: 546.9985961914062
INFO:root:Train (Epoch 299): Loss/seq after 00300 batchs: 566.0803833007812
INFO:root:Train (Epoch 299): Loss/seq after 00350 batchs: 538.9103393554688
INFO:root:Train (Epoch 299): Loss/seq after 00400 batchs: 528.8115234375
INFO:root:Train (Epoch 299): Loss/seq after 00450 batchs: 536.7774047851562
INFO:root:Train (Epoch 299): Loss/seq after 00500 batchs: 520.0093994140625
INFO:root:Train (Epoch 299): Loss/seq after 00550 batchs: 509.22613525390625
INFO:root:Train (Epoch 299): Loss/seq after 00600 batchs: 494.0472412109375
INFO:root:Train (Epoch 299): Loss/seq after 00650 batchs: 478.9976806640625
INFO:root:Train (Epoch 299): Loss/seq after 00700 batchs: 461.370361328125
INFO:root:Train (Epoch 299): Loss/seq after 00750 batchs: 454.5963134765625
INFO:root:Train (Epoch 299): Loss/seq after 00800 batchs: 455.43597412109375
INFO:root:Train (Epoch 299): Loss/seq after 00850 batchs: 441.7667236328125
INFO:root:Train (Epoch 299): Loss/seq after 00900 batchs: 430.2105712890625
INFO:root:Train (Epoch 299): Loss/seq after 00950 batchs: 428.4997253417969
INFO:root:Train (Epoch 299): Loss/seq after 01000 batchs: 423.424560546875
INFO:root:Train (Epoch 299): Loss/seq after 01050 batchs: 415.01953125
INFO:root:Train (Epoch 299): Loss/seq after 01100 batchs: 406.6961975097656
INFO:root:Train (Epoch 299): Loss/seq after 01150 batchs: 396.0956115722656
INFO:root:Train (Epoch 299): Loss/seq after 01200 batchs: 397.0602722167969
INFO:root:Train (Epoch 299): Loss/seq after 01250 batchs: 396.24945068359375
INFO:root:Train (Epoch 299): Loss/seq after 01300 batchs: 388.17578125
INFO:root:Train (Epoch 299): Loss/seq after 01350 batchs: 380.0903625488281
INFO:root:Train (Epoch 299): Loss/seq after 01400 batchs: 381.6908874511719
INFO:root:Train (Epoch 299): Loss/seq after 01450 batchs: 385.119873046875
INFO:root:Train (Epoch 299): Loss/seq after 01500 batchs: 390.7303466796875
INFO:root:Train (Epoch 299): Loss/seq after 01550 batchs: 391.7490539550781
INFO:root:Train (Epoch 299): Loss/seq after 01600 batchs: 389.9469909667969
INFO:root:Train (Epoch 299): Loss/seq after 01650 batchs: 388.3136291503906
INFO:root:Train (Epoch 299): Loss/seq after 01700 batchs: 391.598388671875
INFO:root:Train (Epoch 299): Loss/seq after 01750 batchs: 390.72735595703125
INFO:root:Train (Epoch 299): Loss/seq after 01800 batchs: 389.32159423828125
INFO:root:Train (Epoch 299): Loss/seq after 01850 batchs: 387.216552734375
INFO:root:Train (Epoch 299): Loss/seq after 01900 batchs: 386.2238464355469
INFO:root:Train (Epoch 299): Loss/seq after 01950 batchs: 385.923828125
INFO:root:Train (Epoch 299): Loss/seq after 02000 batchs: 387.4115295410156
INFO:root:Train (Epoch 299): Loss/seq after 02050 batchs: 387.1163635253906
INFO:root:Train (Epoch 299): Loss/seq after 02100 batchs: 386.34332275390625
INFO:root:Train (Epoch 299): Loss/seq after 02150 batchs: 385.4769287109375
INFO:root:Train (Epoch 299): Loss/seq after 02200 batchs: 384.6787414550781
INFO:root:Train (Epoch 299): Loss/seq after 02250 batchs: 383.9347839355469
INFO:root:Train (Epoch 299): Loss/seq after 02300 batchs: 381.4115905761719
INFO:root:Train (Epoch 299): Loss/seq after 02350 batchs: 379.009033203125
INFO:root:Train (Epoch 299): Loss/seq after 02400 batchs: 380.3323059082031
INFO:root:Train (Epoch 299): Loss/seq after 02450 batchs: 377.21844482421875
INFO:root:Train (Epoch 299): Loss/seq after 02500 batchs: 371.1335144042969
INFO:root:Train (Epoch 299): Loss/seq after 02550 batchs: 366.2705383300781
INFO:root:Train (Epoch 299): Loss/seq after 02600 batchs: 362.8059997558594
INFO:root:Train (Epoch 299): Loss/seq after 02650 batchs: 359.4916076660156
INFO:root:Train (Epoch 299): Loss/seq after 02700 batchs: 357.3417053222656
INFO:root:Train (Epoch 299): Loss/seq after 02750 batchs: 353.3715515136719
INFO:root:Train (Epoch 299): Loss/seq after 02800 batchs: 352.8759460449219
INFO:root:Train (Epoch 299): Loss/seq after 02850 batchs: 352.69549560546875
INFO:root:Train (Epoch 299): Loss/seq after 02900 batchs: 353.5386657714844
INFO:root:Train (Epoch 299): Loss/seq after 02950 batchs: 354.4191589355469
INFO:root:Train (Epoch 299): Loss/seq after 03000 batchs: 357.864501953125
INFO:root:Train (Epoch 299): Loss/seq after 03050 batchs: 359.59613037109375
INFO:root:Train (Epoch 299): Loss/seq after 03100 batchs: 361.2102966308594
INFO:root:Train (Epoch 299): Loss/seq after 03150 batchs: 360.9859619140625
INFO:root:Train (Epoch 299): Loss/seq after 03200 batchs: 361.52667236328125
INFO:root:Train (Epoch 299): Loss/seq after 03250 batchs: 361.9122009277344
INFO:root:Train (Epoch 299): Loss/seq after 03300 batchs: 361.7042541503906
INFO:root:Train (Epoch 299): Loss/seq after 03350 batchs: 360.36248779296875
INFO:root:Train (Epoch 299): Loss/seq after 03400 batchs: 358.4031677246094
INFO:root:Train (Epoch 299): Loss/seq after 03450 batchs: 357.6966552734375
INFO:root:Train (Epoch 299): Loss/seq after 03500 batchs: 358.6251525878906
INFO:root:Train (Epoch 299): Loss/seq after 03550 batchs: 357.1157531738281
INFO:root:Train (Epoch 299): Loss/seq after 03600 batchs: 360.51495361328125
INFO:root:Train (Epoch 299): Loss/seq after 03650 batchs: 359.5276184082031
INFO:root:Train (Epoch 299): Loss/seq after 03700 batchs: 362.46026611328125
INFO:root:Train (Epoch 299): Loss/seq after 03750 batchs: 366.5227966308594
INFO:root:Train (Epoch 299): Loss/seq after 03800 batchs: 366.1404113769531
INFO:root:Train (Epoch 299): Loss/seq after 03850 batchs: 365.9284973144531
INFO:root:Train (Epoch 299): Loss/seq after 03900 batchs: 367.63458251953125
INFO:root:Train (Epoch 299): Loss/seq after 03950 batchs: 370.5092468261719
INFO:root:Train (Epoch 299): Loss/seq after 04000 batchs: 368.3670349121094
INFO:root:Train (Epoch 299): Loss/seq after 04050 batchs: 366.3394775390625
INFO:root:Train (Epoch 299): Loss/seq after 04100 batchs: 365.94134521484375
INFO:root:Train (Epoch 299): Loss/seq after 04150 batchs: 366.1511535644531
INFO:root:Train (Epoch 299): Loss/seq after 04200 batchs: 365.4934997558594
INFO:root:Train (Epoch 299): Loss/seq after 04250 batchs: 364.5846252441406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 299): Loss/seq after 00000 batches: 382.7642822265625
INFO:root:# Valid (Epoch 299): Loss/seq after 00050 batches: 708.6231079101562
INFO:root:# Valid (Epoch 299): Loss/seq after 00100 batches: 683.8909912109375
INFO:root:# Valid (Epoch 299): Loss/seq after 00150 batches: 510.0215759277344
INFO:root:# Valid (Epoch 299): Loss/seq after 00200 batches: 464.29150390625
INFO:root:Artifacts: Make stick videos for epoch 299
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_299_on_20220423_205720.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_299_index_1783_on_20220423_205720.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 300): Loss/seq after 00000 batchs: 717.9345092773438
INFO:root:Train (Epoch 300): Loss/seq after 00050 batchs: 501.7236328125
INFO:root:Train (Epoch 300): Loss/seq after 00100 batchs: 494.27032470703125
INFO:root:Train (Epoch 300): Loss/seq after 00150 batchs: 461.3760986328125
INFO:root:Train (Epoch 300): Loss/seq after 00200 batchs: 523.7291259765625
INFO:root:Train (Epoch 300): Loss/seq after 00250 batchs: 527.9556884765625
INFO:root:Train (Epoch 300): Loss/seq after 00300 batchs: 551.5282592773438
INFO:root:Train (Epoch 300): Loss/seq after 00350 batchs: 527.819091796875
INFO:root:Train (Epoch 300): Loss/seq after 00400 batchs: 515.900390625
INFO:root:Train (Epoch 300): Loss/seq after 00450 batchs: 525.224609375
INFO:root:Train (Epoch 300): Loss/seq after 00500 batchs: 510.5401306152344
INFO:root:Train (Epoch 300): Loss/seq after 00550 batchs: 500.2891845703125
INFO:root:Train (Epoch 300): Loss/seq after 00600 batchs: 484.2491455078125
INFO:root:Train (Epoch 300): Loss/seq after 00650 batchs: 470.48358154296875
INFO:root:Train (Epoch 300): Loss/seq after 00700 batchs: 451.859619140625
INFO:root:Train (Epoch 300): Loss/seq after 00750 batchs: 445.8541259765625
INFO:root:Train (Epoch 300): Loss/seq after 00800 batchs: 447.61993408203125
INFO:root:Train (Epoch 300): Loss/seq after 00850 batchs: 434.4410400390625
INFO:root:Train (Epoch 300): Loss/seq after 00900 batchs: 423.4053649902344
INFO:root:Train (Epoch 300): Loss/seq after 00950 batchs: 421.0889587402344
INFO:root:Train (Epoch 300): Loss/seq after 01000 batchs: 414.4391784667969
INFO:root:Train (Epoch 300): Loss/seq after 01050 batchs: 406.88177490234375
INFO:root:Train (Epoch 300): Loss/seq after 01100 batchs: 398.0143127441406
INFO:root:Train (Epoch 300): Loss/seq after 01150 batchs: 387.54913330078125
INFO:root:Train (Epoch 300): Loss/seq after 01200 batchs: 388.4234313964844
INFO:root:Train (Epoch 300): Loss/seq after 01250 batchs: 387.655517578125
INFO:root:Train (Epoch 300): Loss/seq after 01300 batchs: 379.80938720703125
INFO:root:Train (Epoch 300): Loss/seq after 01350 batchs: 372.3470764160156
INFO:root:Train (Epoch 300): Loss/seq after 01400 batchs: 374.4249572753906
INFO:root:Train (Epoch 300): Loss/seq after 01450 batchs: 377.9409484863281
INFO:root:Train (Epoch 300): Loss/seq after 01500 batchs: 383.53387451171875
INFO:root:Train (Epoch 300): Loss/seq after 01550 batchs: 384.8996887207031
INFO:root:Train (Epoch 300): Loss/seq after 01600 batchs: 382.877685546875
INFO:root:Train (Epoch 300): Loss/seq after 01650 batchs: 381.5447692871094
INFO:root:Train (Epoch 300): Loss/seq after 01700 batchs: 385.4653015136719
INFO:root:Train (Epoch 300): Loss/seq after 01750 batchs: 384.7148132324219
INFO:root:Train (Epoch 300): Loss/seq after 01800 batchs: 383.2723388671875
INFO:root:Train (Epoch 300): Loss/seq after 01850 batchs: 381.2453918457031
INFO:root:Train (Epoch 300): Loss/seq after 01900 batchs: 380.31829833984375
INFO:root:Train (Epoch 300): Loss/seq after 01950 batchs: 380.3834228515625
INFO:root:Train (Epoch 300): Loss/seq after 02000 batchs: 381.8412170410156
INFO:root:Train (Epoch 300): Loss/seq after 02050 batchs: 381.9342041015625
INFO:root:Train (Epoch 300): Loss/seq after 02100 batchs: 381.3020324707031
INFO:root:Train (Epoch 300): Loss/seq after 02150 batchs: 380.83563232421875
INFO:root:Train (Epoch 300): Loss/seq after 02200 batchs: 380.0783386230469
INFO:root:Train (Epoch 300): Loss/seq after 02250 batchs: 379.43109130859375
INFO:root:Train (Epoch 300): Loss/seq after 02300 batchs: 376.7163391113281
INFO:root:Train (Epoch 300): Loss/seq after 02350 batchs: 374.393798828125
INFO:root:Train (Epoch 300): Loss/seq after 02400 batchs: 375.6704406738281
INFO:root:Train (Epoch 300): Loss/seq after 02450 batchs: 372.6930236816406
INFO:root:Train (Epoch 300): Loss/seq after 02500 batchs: 366.7371520996094
INFO:root:Train (Epoch 300): Loss/seq after 02550 batchs: 361.9822692871094
INFO:root:Train (Epoch 300): Loss/seq after 02600 batchs: 358.8331298828125
INFO:root:Train (Epoch 300): Loss/seq after 02650 batchs: 355.8158264160156
INFO:root:Train (Epoch 300): Loss/seq after 02700 batchs: 353.7224426269531
INFO:root:Train (Epoch 300): Loss/seq after 02750 batchs: 349.7101745605469
INFO:root:Train (Epoch 300): Loss/seq after 02800 batchs: 349.204833984375
INFO:root:Train (Epoch 300): Loss/seq after 02850 batchs: 349.186279296875
INFO:root:Train (Epoch 300): Loss/seq after 02900 batchs: 349.9956970214844
INFO:root:Train (Epoch 300): Loss/seq after 02950 batchs: 351.1054382324219
INFO:root:Train (Epoch 300): Loss/seq after 03000 batchs: 355.0138854980469
INFO:root:Train (Epoch 300): Loss/seq after 03050 batchs: 356.6231689453125
INFO:root:Train (Epoch 300): Loss/seq after 03100 batchs: 358.132568359375
INFO:root:Train (Epoch 300): Loss/seq after 03150 batchs: 358.5369873046875
INFO:root:Train (Epoch 300): Loss/seq after 03200 batchs: 358.8914489746094
INFO:root:Train (Epoch 300): Loss/seq after 03250 batchs: 359.4034729003906
INFO:root:Train (Epoch 300): Loss/seq after 03300 batchs: 359.3294982910156
INFO:root:Train (Epoch 300): Loss/seq after 03350 batchs: 358.4299011230469
INFO:root:Train (Epoch 300): Loss/seq after 03400 batchs: 356.4632568359375
INFO:root:Train (Epoch 300): Loss/seq after 03450 batchs: 355.57757568359375
INFO:root:Train (Epoch 300): Loss/seq after 03500 batchs: 356.5150451660156
INFO:root:Train (Epoch 300): Loss/seq after 03550 batchs: 355.1839599609375
INFO:root:Train (Epoch 300): Loss/seq after 03600 batchs: 358.4788818359375
INFO:root:Train (Epoch 300): Loss/seq after 03650 batchs: 357.27337646484375
INFO:root:Train (Epoch 300): Loss/seq after 03700 batchs: 359.2138366699219
INFO:root:Train (Epoch 300): Loss/seq after 03750 batchs: 362.5859680175781
INFO:root:Train (Epoch 300): Loss/seq after 03800 batchs: 362.2865905761719
INFO:root:Train (Epoch 300): Loss/seq after 03850 batchs: 361.96014404296875
INFO:root:Train (Epoch 300): Loss/seq after 03900 batchs: 363.8875732421875
INFO:root:Train (Epoch 300): Loss/seq after 03950 batchs: 366.7259216308594
INFO:root:Train (Epoch 300): Loss/seq after 04000 batchs: 364.6177978515625
INFO:root:Train (Epoch 300): Loss/seq after 04050 batchs: 362.63006591796875
INFO:root:Train (Epoch 300): Loss/seq after 04100 batchs: 362.3497314453125
INFO:root:Train (Epoch 300): Loss/seq after 04150 batchs: 362.4788818359375
INFO:root:Train (Epoch 300): Loss/seq after 04200 batchs: 361.93304443359375
INFO:root:Train (Epoch 300): Loss/seq after 04250 batchs: 361.06024169921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 300): Loss/seq after 00000 batches: 378.7896423339844
INFO:root:# Valid (Epoch 300): Loss/seq after 00050 batches: 677.0446166992188
INFO:root:# Valid (Epoch 300): Loss/seq after 00100 batches: 735.3113403320312
INFO:root:# Valid (Epoch 300): Loss/seq after 00150 batches: 544.7449951171875
INFO:root:# Valid (Epoch 300): Loss/seq after 00200 batches: 490.1828918457031
INFO:root:Artifacts: Make stick videos for epoch 300
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_300_on_20220423_210216.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_300_index_378_on_20220423_210216.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 301): Loss/seq after 00000 batchs: 533.5916137695312
INFO:root:Train (Epoch 301): Loss/seq after 00050 batchs: 496.9190979003906
INFO:root:Train (Epoch 301): Loss/seq after 00100 batchs: 527.8243408203125
INFO:root:Train (Epoch 301): Loss/seq after 00150 batchs: 476.1363220214844
INFO:root:Train (Epoch 301): Loss/seq after 00200 batchs: 538.421142578125
INFO:root:Train (Epoch 301): Loss/seq after 00250 batchs: 544.6231079101562
INFO:root:Train (Epoch 301): Loss/seq after 00300 batchs: 557.2792358398438
INFO:root:Train (Epoch 301): Loss/seq after 00350 batchs: 529.6985473632812
INFO:root:Train (Epoch 301): Loss/seq after 00400 batchs: 518.5037841796875
INFO:root:Train (Epoch 301): Loss/seq after 00450 batchs: 527.631591796875
INFO:root:Train (Epoch 301): Loss/seq after 00500 batchs: 511.33770751953125
INFO:root:Train (Epoch 301): Loss/seq after 00550 batchs: 500.277099609375
INFO:root:Train (Epoch 301): Loss/seq after 00600 batchs: 482.9919738769531
INFO:root:Train (Epoch 301): Loss/seq after 00650 batchs: 464.9079895019531
INFO:root:Train (Epoch 301): Loss/seq after 00700 batchs: 446.7540283203125
INFO:root:Train (Epoch 301): Loss/seq after 00750 batchs: 441.8283386230469
INFO:root:Train (Epoch 301): Loss/seq after 00800 batchs: 443.6085510253906
INFO:root:Train (Epoch 301): Loss/seq after 00850 batchs: 430.5528259277344
INFO:root:Train (Epoch 301): Loss/seq after 00900 batchs: 419.8744812011719
INFO:root:Train (Epoch 301): Loss/seq after 00950 batchs: 418.3102111816406
INFO:root:Train (Epoch 301): Loss/seq after 01000 batchs: 411.5657043457031
INFO:root:Train (Epoch 301): Loss/seq after 01050 batchs: 403.3610534667969
INFO:root:Train (Epoch 301): Loss/seq after 01100 batchs: 394.69732666015625
INFO:root:Train (Epoch 301): Loss/seq after 01150 batchs: 384.32257080078125
INFO:root:Train (Epoch 301): Loss/seq after 01200 batchs: 385.4804382324219
INFO:root:Train (Epoch 301): Loss/seq after 01250 batchs: 385.0647888183594
INFO:root:Train (Epoch 301): Loss/seq after 01300 batchs: 377.2814025878906
INFO:root:Train (Epoch 301): Loss/seq after 01350 batchs: 369.3685607910156
INFO:root:Train (Epoch 301): Loss/seq after 01400 batchs: 371.13238525390625
INFO:root:Train (Epoch 301): Loss/seq after 01450 batchs: 374.84039306640625
INFO:root:Train (Epoch 301): Loss/seq after 01500 batchs: 380.74609375
INFO:root:Train (Epoch 301): Loss/seq after 01550 batchs: 381.8005676269531
INFO:root:Train (Epoch 301): Loss/seq after 01600 batchs: 379.6853942871094
INFO:root:Train (Epoch 301): Loss/seq after 01650 batchs: 377.9243469238281
INFO:root:Train (Epoch 301): Loss/seq after 01700 batchs: 381.7802734375
INFO:root:Train (Epoch 301): Loss/seq after 01750 batchs: 381.2316589355469
INFO:root:Train (Epoch 301): Loss/seq after 01800 batchs: 379.70587158203125
INFO:root:Train (Epoch 301): Loss/seq after 01850 batchs: 378.0150451660156
INFO:root:Train (Epoch 301): Loss/seq after 01900 batchs: 377.30108642578125
INFO:root:Train (Epoch 301): Loss/seq after 01950 batchs: 377.32928466796875
INFO:root:Train (Epoch 301): Loss/seq after 02000 batchs: 379.0035095214844
INFO:root:Train (Epoch 301): Loss/seq after 02050 batchs: 379.01123046875
INFO:root:Train (Epoch 301): Loss/seq after 02100 batchs: 378.2444763183594
INFO:root:Train (Epoch 301): Loss/seq after 02150 batchs: 377.9627990722656
INFO:root:Train (Epoch 301): Loss/seq after 02200 batchs: 377.2742919921875
INFO:root:Train (Epoch 301): Loss/seq after 02250 batchs: 376.50701904296875
INFO:root:Train (Epoch 301): Loss/seq after 02300 batchs: 374.0745849609375
INFO:root:Train (Epoch 301): Loss/seq after 02350 batchs: 371.9501953125
INFO:root:Train (Epoch 301): Loss/seq after 02400 batchs: 373.2412414550781
INFO:root:Train (Epoch 301): Loss/seq after 02450 batchs: 370.2864685058594
INFO:root:Train (Epoch 301): Loss/seq after 02500 batchs: 364.31256103515625
INFO:root:Train (Epoch 301): Loss/seq after 02550 batchs: 359.4736633300781
INFO:root:Train (Epoch 301): Loss/seq after 02600 batchs: 356.3368225097656
INFO:root:Train (Epoch 301): Loss/seq after 02650 batchs: 353.43194580078125
INFO:root:Train (Epoch 301): Loss/seq after 02700 batchs: 351.6244812011719
INFO:root:Train (Epoch 301): Loss/seq after 02750 batchs: 347.6207580566406
INFO:root:Train (Epoch 301): Loss/seq after 02800 batchs: 346.28118896484375
INFO:root:Train (Epoch 301): Loss/seq after 02850 batchs: 346.24908447265625
INFO:root:Train (Epoch 301): Loss/seq after 02900 batchs: 347.4018859863281
INFO:root:Train (Epoch 301): Loss/seq after 02950 batchs: 348.3486022949219
INFO:root:Train (Epoch 301): Loss/seq after 03000 batchs: 351.9770202636719
INFO:root:Train (Epoch 301): Loss/seq after 03050 batchs: 353.9866027832031
INFO:root:Train (Epoch 301): Loss/seq after 03100 batchs: 355.5362548828125
INFO:root:Train (Epoch 301): Loss/seq after 03150 batchs: 355.9755859375
INFO:root:Train (Epoch 301): Loss/seq after 03200 batchs: 356.5815124511719
INFO:root:Train (Epoch 301): Loss/seq after 03250 batchs: 356.8668518066406
INFO:root:Train (Epoch 301): Loss/seq after 03300 batchs: 356.7632141113281
INFO:root:Train (Epoch 301): Loss/seq after 03350 batchs: 355.07305908203125
INFO:root:Train (Epoch 301): Loss/seq after 03400 batchs: 353.14947509765625
INFO:root:Train (Epoch 301): Loss/seq after 03450 batchs: 352.3633117675781
INFO:root:Train (Epoch 301): Loss/seq after 03500 batchs: 353.3308410644531
INFO:root:Train (Epoch 301): Loss/seq after 03550 batchs: 351.8319091796875
INFO:root:Train (Epoch 301): Loss/seq after 03600 batchs: 355.0211486816406
INFO:root:Train (Epoch 301): Loss/seq after 03650 batchs: 353.956787109375
INFO:root:Train (Epoch 301): Loss/seq after 03700 batchs: 356.3365173339844
INFO:root:Train (Epoch 301): Loss/seq after 03750 batchs: 359.91015625
INFO:root:Train (Epoch 301): Loss/seq after 03800 batchs: 359.6181640625
INFO:root:Train (Epoch 301): Loss/seq after 03850 batchs: 359.14300537109375
INFO:root:Train (Epoch 301): Loss/seq after 03900 batchs: 360.5087585449219
INFO:root:Train (Epoch 301): Loss/seq after 03950 batchs: 363.0663146972656
INFO:root:Train (Epoch 301): Loss/seq after 04000 batchs: 361.0166320800781
INFO:root:Train (Epoch 301): Loss/seq after 04050 batchs: 359.1187438964844
INFO:root:Train (Epoch 301): Loss/seq after 04100 batchs: 358.97393798828125
INFO:root:Train (Epoch 301): Loss/seq after 04150 batchs: 359.2001037597656
INFO:root:Train (Epoch 301): Loss/seq after 04200 batchs: 358.47900390625
INFO:root:Train (Epoch 301): Loss/seq after 04250 batchs: 357.5078430175781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 301): Loss/seq after 00000 batches: 435.36981201171875
INFO:root:# Valid (Epoch 301): Loss/seq after 00050 batches: 696.1575927734375
INFO:root:# Valid (Epoch 301): Loss/seq after 00100 batches: 674.8509521484375
INFO:root:# Valid (Epoch 301): Loss/seq after 00150 batches: 502.7025451660156
INFO:root:# Valid (Epoch 301): Loss/seq after 00200 batches: 458.9849548339844
INFO:root:Artifacts: Make stick videos for epoch 301
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_301_on_20220423_210700.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_301_index_154_on_20220423_210700.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 302): Loss/seq after 00000 batchs: 696.9115600585938
INFO:root:Train (Epoch 302): Loss/seq after 00050 batchs: 482.0272216796875
INFO:root:Train (Epoch 302): Loss/seq after 00100 batchs: 495.8863525390625
INFO:root:Train (Epoch 302): Loss/seq after 00150 batchs: 457.1186218261719
INFO:root:Train (Epoch 302): Loss/seq after 00200 batchs: 505.9389953613281
INFO:root:Train (Epoch 302): Loss/seq after 00250 batchs: 528.0975341796875
INFO:root:Train (Epoch 302): Loss/seq after 00300 batchs: 545.5706787109375
INFO:root:Train (Epoch 302): Loss/seq after 00350 batchs: 519.9205322265625
INFO:root:Train (Epoch 302): Loss/seq after 00400 batchs: 506.3082580566406
INFO:root:Train (Epoch 302): Loss/seq after 00450 batchs: 516.3975830078125
INFO:root:Train (Epoch 302): Loss/seq after 00500 batchs: 500.3038024902344
INFO:root:Train (Epoch 302): Loss/seq after 00550 batchs: 490.6424255371094
INFO:root:Train (Epoch 302): Loss/seq after 00600 batchs: 475.09613037109375
INFO:root:Train (Epoch 302): Loss/seq after 00650 batchs: 461.09173583984375
INFO:root:Train (Epoch 302): Loss/seq after 00700 batchs: 443.3250732421875
INFO:root:Train (Epoch 302): Loss/seq after 00750 batchs: 438.2362976074219
INFO:root:Train (Epoch 302): Loss/seq after 00800 batchs: 440.071044921875
INFO:root:Train (Epoch 302): Loss/seq after 00850 batchs: 427.1074523925781
INFO:root:Train (Epoch 302): Loss/seq after 00900 batchs: 416.7096862792969
INFO:root:Train (Epoch 302): Loss/seq after 00950 batchs: 415.2180480957031
INFO:root:Train (Epoch 302): Loss/seq after 01000 batchs: 408.5614929199219
INFO:root:Train (Epoch 302): Loss/seq after 01050 batchs: 400.3272399902344
INFO:root:Train (Epoch 302): Loss/seq after 01100 batchs: 391.4999084472656
INFO:root:Train (Epoch 302): Loss/seq after 01150 batchs: 381.4920349121094
INFO:root:Train (Epoch 302): Loss/seq after 01200 batchs: 382.4081726074219
INFO:root:Train (Epoch 302): Loss/seq after 01250 batchs: 381.57635498046875
INFO:root:Train (Epoch 302): Loss/seq after 01300 batchs: 373.6451110839844
INFO:root:Train (Epoch 302): Loss/seq after 01350 batchs: 366.51788330078125
INFO:root:Train (Epoch 302): Loss/seq after 01400 batchs: 367.6358947753906
INFO:root:Train (Epoch 302): Loss/seq after 01450 batchs: 371.3783874511719
INFO:root:Train (Epoch 302): Loss/seq after 01500 batchs: 377.0647277832031
INFO:root:Train (Epoch 302): Loss/seq after 01550 batchs: 378.4723815917969
INFO:root:Train (Epoch 302): Loss/seq after 01600 batchs: 377.0196228027344
INFO:root:Train (Epoch 302): Loss/seq after 01650 batchs: 375.3775634765625
INFO:root:Train (Epoch 302): Loss/seq after 01700 batchs: 379.57720947265625
INFO:root:Train (Epoch 302): Loss/seq after 01750 batchs: 378.99383544921875
INFO:root:Train (Epoch 302): Loss/seq after 01800 batchs: 377.3451232910156
INFO:root:Train (Epoch 302): Loss/seq after 01850 batchs: 375.57257080078125
INFO:root:Train (Epoch 302): Loss/seq after 01900 batchs: 375.1375427246094
INFO:root:Train (Epoch 302): Loss/seq after 01950 batchs: 375.0181579589844
INFO:root:Train (Epoch 302): Loss/seq after 02000 batchs: 376.68341064453125
INFO:root:Train (Epoch 302): Loss/seq after 02050 batchs: 376.6347351074219
INFO:root:Train (Epoch 302): Loss/seq after 02100 batchs: 375.94683837890625
INFO:root:Train (Epoch 302): Loss/seq after 02150 batchs: 375.64154052734375
INFO:root:Train (Epoch 302): Loss/seq after 02200 batchs: 374.9749450683594
INFO:root:Train (Epoch 302): Loss/seq after 02250 batchs: 374.0692443847656
INFO:root:Train (Epoch 302): Loss/seq after 02300 batchs: 371.7677001953125
INFO:root:Train (Epoch 302): Loss/seq after 02350 batchs: 369.54547119140625
INFO:root:Train (Epoch 302): Loss/seq after 02400 batchs: 370.9703369140625
INFO:root:Train (Epoch 302): Loss/seq after 02450 batchs: 368.0988464355469
INFO:root:Train (Epoch 302): Loss/seq after 02500 batchs: 362.2754211425781
INFO:root:Train (Epoch 302): Loss/seq after 02550 batchs: 357.4635314941406
INFO:root:Train (Epoch 302): Loss/seq after 02600 batchs: 354.0018615722656
INFO:root:Train (Epoch 302): Loss/seq after 02650 batchs: 350.8214416503906
INFO:root:Train (Epoch 302): Loss/seq after 02700 batchs: 348.7548522949219
INFO:root:Train (Epoch 302): Loss/seq after 02750 batchs: 344.6741638183594
INFO:root:Train (Epoch 302): Loss/seq after 02800 batchs: 343.54510498046875
INFO:root:Train (Epoch 302): Loss/seq after 02850 batchs: 343.4581604003906
INFO:root:Train (Epoch 302): Loss/seq after 02900 batchs: 344.4543762207031
INFO:root:Train (Epoch 302): Loss/seq after 02950 batchs: 345.3690490722656
INFO:root:Train (Epoch 302): Loss/seq after 03000 batchs: 349.0902099609375
INFO:root:Train (Epoch 302): Loss/seq after 03050 batchs: 350.849365234375
INFO:root:Train (Epoch 302): Loss/seq after 03100 batchs: 352.8463439941406
INFO:root:Train (Epoch 302): Loss/seq after 03150 batchs: 352.9548645019531
INFO:root:Train (Epoch 302): Loss/seq after 03200 batchs: 353.4276428222656
INFO:root:Train (Epoch 302): Loss/seq after 03250 batchs: 353.2612609863281
INFO:root:Train (Epoch 302): Loss/seq after 03300 batchs: 352.5167541503906
INFO:root:Train (Epoch 302): Loss/seq after 03350 batchs: 350.83343505859375
INFO:root:Train (Epoch 302): Loss/seq after 03400 batchs: 348.8362731933594
INFO:root:Train (Epoch 302): Loss/seq after 03450 batchs: 347.95245361328125
INFO:root:Train (Epoch 302): Loss/seq after 03500 batchs: 348.82550048828125
INFO:root:Train (Epoch 302): Loss/seq after 03550 batchs: 347.4665222167969
INFO:root:Train (Epoch 302): Loss/seq after 03600 batchs: 350.445068359375
INFO:root:Train (Epoch 302): Loss/seq after 03650 batchs: 349.3648376464844
INFO:root:Train (Epoch 302): Loss/seq after 03700 batchs: 351.2549133300781
INFO:root:Train (Epoch 302): Loss/seq after 03750 batchs: 354.89794921875
INFO:root:Train (Epoch 302): Loss/seq after 03800 batchs: 354.75927734375
INFO:root:Train (Epoch 302): Loss/seq after 03850 batchs: 354.539794921875
INFO:root:Train (Epoch 302): Loss/seq after 03900 batchs: 356.5318908691406
INFO:root:Train (Epoch 302): Loss/seq after 03950 batchs: 359.6056823730469
INFO:root:Train (Epoch 302): Loss/seq after 04000 batchs: 357.5912170410156
INFO:root:Train (Epoch 302): Loss/seq after 04050 batchs: 355.7097473144531
INFO:root:Train (Epoch 302): Loss/seq after 04100 batchs: 355.3547668457031
INFO:root:Train (Epoch 302): Loss/seq after 04150 batchs: 355.7057189941406
INFO:root:Train (Epoch 302): Loss/seq after 04200 batchs: 355.1790466308594
INFO:root:Train (Epoch 302): Loss/seq after 04250 batchs: 354.4747314453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 302): Loss/seq after 00000 batches: 385.5747985839844
INFO:root:# Valid (Epoch 302): Loss/seq after 00050 batches: 739.8141479492188
INFO:root:# Valid (Epoch 302): Loss/seq after 00100 batches: 769.4833374023438
INFO:root:# Valid (Epoch 302): Loss/seq after 00150 batches: 568.0292358398438
INFO:root:# Valid (Epoch 302): Loss/seq after 00200 batches: 507.34381103515625
INFO:root:Artifacts: Make stick videos for epoch 302
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_302_on_20220423_211145.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_302_index_104_on_20220423_211145.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 303): Loss/seq after 00000 batchs: 644.743896484375
INFO:root:Train (Epoch 303): Loss/seq after 00050 batchs: 473.2065734863281
INFO:root:Train (Epoch 303): Loss/seq after 00100 batchs: 477.5744934082031
INFO:root:Train (Epoch 303): Loss/seq after 00150 batchs: 444.38018798828125
INFO:root:Train (Epoch 303): Loss/seq after 00200 batchs: 497.9220886230469
INFO:root:Train (Epoch 303): Loss/seq after 00250 batchs: 536.5645141601562
INFO:root:Train (Epoch 303): Loss/seq after 00300 batchs: 550.75341796875
INFO:root:Train (Epoch 303): Loss/seq after 00350 batchs: 524.7111206054688
INFO:root:Train (Epoch 303): Loss/seq after 00400 batchs: 518.1620483398438
INFO:root:Train (Epoch 303): Loss/seq after 00450 batchs: 527.7911987304688
INFO:root:Train (Epoch 303): Loss/seq after 00500 batchs: 513.5916137695312
INFO:root:Train (Epoch 303): Loss/seq after 00550 batchs: 503.4735107421875
INFO:root:Train (Epoch 303): Loss/seq after 00600 batchs: 487.2633361816406
INFO:root:Train (Epoch 303): Loss/seq after 00650 batchs: 469.5288391113281
INFO:root:Train (Epoch 303): Loss/seq after 00700 batchs: 450.0091552734375
INFO:root:Train (Epoch 303): Loss/seq after 00750 batchs: 442.81610107421875
INFO:root:Train (Epoch 303): Loss/seq after 00800 batchs: 443.7594299316406
INFO:root:Train (Epoch 303): Loss/seq after 00850 batchs: 430.4342346191406
INFO:root:Train (Epoch 303): Loss/seq after 00900 batchs: 419.3544006347656
INFO:root:Train (Epoch 303): Loss/seq after 00950 batchs: 416.97540283203125
INFO:root:Train (Epoch 303): Loss/seq after 01000 batchs: 410.271484375
INFO:root:Train (Epoch 303): Loss/seq after 01050 batchs: 403.6932678222656
INFO:root:Train (Epoch 303): Loss/seq after 01100 batchs: 395.68792724609375
INFO:root:Train (Epoch 303): Loss/seq after 01150 batchs: 385.7391052246094
INFO:root:Train (Epoch 303): Loss/seq after 01200 batchs: 387.27740478515625
INFO:root:Train (Epoch 303): Loss/seq after 01250 batchs: 386.36444091796875
INFO:root:Train (Epoch 303): Loss/seq after 01300 batchs: 378.6453552246094
INFO:root:Train (Epoch 303): Loss/seq after 01350 batchs: 370.82659912109375
INFO:root:Train (Epoch 303): Loss/seq after 01400 batchs: 372.4432373046875
INFO:root:Train (Epoch 303): Loss/seq after 01450 batchs: 375.8551330566406
INFO:root:Train (Epoch 303): Loss/seq after 01500 batchs: 381.51263427734375
INFO:root:Train (Epoch 303): Loss/seq after 01550 batchs: 382.81744384765625
INFO:root:Train (Epoch 303): Loss/seq after 01600 batchs: 381.0027160644531
INFO:root:Train (Epoch 303): Loss/seq after 01650 batchs: 379.4051513671875
INFO:root:Train (Epoch 303): Loss/seq after 01700 batchs: 382.9735412597656
INFO:root:Train (Epoch 303): Loss/seq after 01750 batchs: 382.5694885253906
INFO:root:Train (Epoch 303): Loss/seq after 01800 batchs: 381.0249328613281
INFO:root:Train (Epoch 303): Loss/seq after 01850 batchs: 379.16455078125
INFO:root:Train (Epoch 303): Loss/seq after 01900 batchs: 378.1866760253906
INFO:root:Train (Epoch 303): Loss/seq after 01950 batchs: 378.28363037109375
INFO:root:Train (Epoch 303): Loss/seq after 02000 batchs: 379.9256896972656
INFO:root:Train (Epoch 303): Loss/seq after 02050 batchs: 379.7446594238281
INFO:root:Train (Epoch 303): Loss/seq after 02100 batchs: 378.9680480957031
INFO:root:Train (Epoch 303): Loss/seq after 02150 batchs: 378.5440979003906
INFO:root:Train (Epoch 303): Loss/seq after 02200 batchs: 377.6770935058594
INFO:root:Train (Epoch 303): Loss/seq after 02250 batchs: 377.1274719238281
INFO:root:Train (Epoch 303): Loss/seq after 02300 batchs: 374.7655944824219
INFO:root:Train (Epoch 303): Loss/seq after 02350 batchs: 372.29901123046875
INFO:root:Train (Epoch 303): Loss/seq after 02400 batchs: 373.5965881347656
INFO:root:Train (Epoch 303): Loss/seq after 02450 batchs: 370.7384033203125
INFO:root:Train (Epoch 303): Loss/seq after 02500 batchs: 364.87493896484375
INFO:root:Train (Epoch 303): Loss/seq after 02550 batchs: 360.06201171875
INFO:root:Train (Epoch 303): Loss/seq after 02600 batchs: 356.5757751464844
INFO:root:Train (Epoch 303): Loss/seq after 02650 batchs: 353.7925720214844
INFO:root:Train (Epoch 303): Loss/seq after 02700 batchs: 351.6091003417969
INFO:root:Train (Epoch 303): Loss/seq after 02750 batchs: 347.919921875
INFO:root:Train (Epoch 303): Loss/seq after 02800 batchs: 346.7720947265625
INFO:root:Train (Epoch 303): Loss/seq after 02850 batchs: 346.70556640625
INFO:root:Train (Epoch 303): Loss/seq after 02900 batchs: 347.46600341796875
INFO:root:Train (Epoch 303): Loss/seq after 02950 batchs: 348.3323974609375
INFO:root:Train (Epoch 303): Loss/seq after 03000 batchs: 351.9560241699219
INFO:root:Train (Epoch 303): Loss/seq after 03050 batchs: 353.6315612792969
INFO:root:Train (Epoch 303): Loss/seq after 03100 batchs: 355.5541687011719
INFO:root:Train (Epoch 303): Loss/seq after 03150 batchs: 355.6215515136719
INFO:root:Train (Epoch 303): Loss/seq after 03200 batchs: 356.8228759765625
INFO:root:Train (Epoch 303): Loss/seq after 03250 batchs: 357.0561828613281
INFO:root:Train (Epoch 303): Loss/seq after 03300 batchs: 356.446533203125
INFO:root:Train (Epoch 303): Loss/seq after 03350 batchs: 354.6131286621094
INFO:root:Train (Epoch 303): Loss/seq after 03400 batchs: 352.4877014160156
INFO:root:Train (Epoch 303): Loss/seq after 03450 batchs: 351.5361328125
INFO:root:Train (Epoch 303): Loss/seq after 03500 batchs: 352.3386535644531
INFO:root:Train (Epoch 303): Loss/seq after 03550 batchs: 350.85919189453125
INFO:root:Train (Epoch 303): Loss/seq after 03600 batchs: 353.5149841308594
INFO:root:Train (Epoch 303): Loss/seq after 03650 batchs: 352.1740417480469
INFO:root:Train (Epoch 303): Loss/seq after 03700 batchs: 353.96026611328125
INFO:root:Train (Epoch 303): Loss/seq after 03750 batchs: 357.3608703613281
INFO:root:Train (Epoch 303): Loss/seq after 03800 batchs: 357.0944519042969
INFO:root:Train (Epoch 303): Loss/seq after 03850 batchs: 356.8572692871094
INFO:root:Train (Epoch 303): Loss/seq after 03900 batchs: 358.55242919921875
INFO:root:Train (Epoch 303): Loss/seq after 03950 batchs: 361.7607727050781
INFO:root:Train (Epoch 303): Loss/seq after 04000 batchs: 359.7611389160156
INFO:root:Train (Epoch 303): Loss/seq after 04050 batchs: 357.86688232421875
INFO:root:Train (Epoch 303): Loss/seq after 04100 batchs: 357.3456726074219
INFO:root:Train (Epoch 303): Loss/seq after 04150 batchs: 357.775390625
INFO:root:Train (Epoch 303): Loss/seq after 04200 batchs: 357.17437744140625
INFO:root:Train (Epoch 303): Loss/seq after 04250 batchs: 356.3019104003906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 303): Loss/seq after 00000 batches: 397.647216796875
INFO:root:# Valid (Epoch 303): Loss/seq after 00050 batches: 719.836181640625
INFO:root:# Valid (Epoch 303): Loss/seq after 00100 batches: 771.0261840820312
INFO:root:# Valid (Epoch 303): Loss/seq after 00150 batches: 566.2955322265625
INFO:root:# Valid (Epoch 303): Loss/seq after 00200 batches: 507.35614013671875
INFO:root:Artifacts: Make stick videos for epoch 303
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_303_on_20220423_211645.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_303_index_1202_on_20220423_211645.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 304): Loss/seq after 00000 batchs: 595.9448852539062
INFO:root:Train (Epoch 304): Loss/seq after 00050 batchs: 476.5558166503906
INFO:root:Train (Epoch 304): Loss/seq after 00100 batchs: 488.1232604980469
INFO:root:Train (Epoch 304): Loss/seq after 00150 batchs: 451.5541687011719
INFO:root:Train (Epoch 304): Loss/seq after 00200 batchs: 517.0783081054688
INFO:root:Train (Epoch 304): Loss/seq after 00250 batchs: 546.0427856445312
INFO:root:Train (Epoch 304): Loss/seq after 00300 batchs: 564.134033203125
INFO:root:Train (Epoch 304): Loss/seq after 00350 batchs: 538.460205078125
INFO:root:Train (Epoch 304): Loss/seq after 00400 batchs: 523.9923706054688
INFO:root:Train (Epoch 304): Loss/seq after 00450 batchs: 533.0820922851562
INFO:root:Train (Epoch 304): Loss/seq after 00500 batchs: 517.4756469726562
INFO:root:Train (Epoch 304): Loss/seq after 00550 batchs: 506.53704833984375
INFO:root:Train (Epoch 304): Loss/seq after 00600 batchs: 490.325439453125
INFO:root:Train (Epoch 304): Loss/seq after 00650 batchs: 472.48944091796875
INFO:root:Train (Epoch 304): Loss/seq after 00700 batchs: 455.0511474609375
INFO:root:Train (Epoch 304): Loss/seq after 00750 batchs: 450.2397766113281
INFO:root:Train (Epoch 304): Loss/seq after 00800 batchs: 450.9673767089844
INFO:root:Train (Epoch 304): Loss/seq after 00850 batchs: 436.78436279296875
INFO:root:Train (Epoch 304): Loss/seq after 00900 batchs: 425.39605712890625
INFO:root:Train (Epoch 304): Loss/seq after 00950 batchs: 422.79840087890625
INFO:root:Train (Epoch 304): Loss/seq after 01000 batchs: 416.084716796875
INFO:root:Train (Epoch 304): Loss/seq after 01050 batchs: 407.9836120605469
INFO:root:Train (Epoch 304): Loss/seq after 01100 batchs: 398.85772705078125
INFO:root:Train (Epoch 304): Loss/seq after 01150 batchs: 388.3334655761719
INFO:root:Train (Epoch 304): Loss/seq after 01200 batchs: 389.3001708984375
INFO:root:Train (Epoch 304): Loss/seq after 01250 batchs: 388.3300476074219
INFO:root:Train (Epoch 304): Loss/seq after 01300 batchs: 380.3583679199219
INFO:root:Train (Epoch 304): Loss/seq after 01350 batchs: 372.7913513183594
INFO:root:Train (Epoch 304): Loss/seq after 01400 batchs: 374.2878723144531
INFO:root:Train (Epoch 304): Loss/seq after 01450 batchs: 377.28326416015625
INFO:root:Train (Epoch 304): Loss/seq after 01500 batchs: 383.2153625488281
INFO:root:Train (Epoch 304): Loss/seq after 01550 batchs: 383.88702392578125
INFO:root:Train (Epoch 304): Loss/seq after 01600 batchs: 382.07720947265625
INFO:root:Train (Epoch 304): Loss/seq after 01650 batchs: 380.4952087402344
INFO:root:Train (Epoch 304): Loss/seq after 01700 batchs: 383.9712219238281
INFO:root:Train (Epoch 304): Loss/seq after 01750 batchs: 383.1955261230469
INFO:root:Train (Epoch 304): Loss/seq after 01800 batchs: 381.91815185546875
INFO:root:Train (Epoch 304): Loss/seq after 01850 batchs: 380.01739501953125
INFO:root:Train (Epoch 304): Loss/seq after 01900 batchs: 378.9366149902344
INFO:root:Train (Epoch 304): Loss/seq after 01950 batchs: 378.59326171875
INFO:root:Train (Epoch 304): Loss/seq after 02000 batchs: 379.9881896972656
INFO:root:Train (Epoch 304): Loss/seq after 02050 batchs: 379.9031677246094
INFO:root:Train (Epoch 304): Loss/seq after 02100 batchs: 379.0882263183594
INFO:root:Train (Epoch 304): Loss/seq after 02150 batchs: 378.57037353515625
INFO:root:Train (Epoch 304): Loss/seq after 02200 batchs: 377.6981506347656
INFO:root:Train (Epoch 304): Loss/seq after 02250 batchs: 376.875
INFO:root:Train (Epoch 304): Loss/seq after 02300 batchs: 374.115234375
INFO:root:Train (Epoch 304): Loss/seq after 02350 batchs: 371.7398986816406
INFO:root:Train (Epoch 304): Loss/seq after 02400 batchs: 372.943115234375
INFO:root:Train (Epoch 304): Loss/seq after 02450 batchs: 370.0843200683594
INFO:root:Train (Epoch 304): Loss/seq after 02500 batchs: 364.1042175292969
INFO:root:Train (Epoch 304): Loss/seq after 02550 batchs: 359.2830810546875
INFO:root:Train (Epoch 304): Loss/seq after 02600 batchs: 356.02294921875
INFO:root:Train (Epoch 304): Loss/seq after 02650 batchs: 352.8306884765625
INFO:root:Train (Epoch 304): Loss/seq after 02700 batchs: 350.7114562988281
INFO:root:Train (Epoch 304): Loss/seq after 02750 batchs: 347.2891845703125
INFO:root:Train (Epoch 304): Loss/seq after 02800 batchs: 345.8785095214844
INFO:root:Train (Epoch 304): Loss/seq after 02850 batchs: 345.6875
INFO:root:Train (Epoch 304): Loss/seq after 02900 batchs: 346.4661865234375
INFO:root:Train (Epoch 304): Loss/seq after 02950 batchs: 347.3547668457031
INFO:root:Train (Epoch 304): Loss/seq after 03000 batchs: 350.9646911621094
INFO:root:Train (Epoch 304): Loss/seq after 03050 batchs: 352.520263671875
INFO:root:Train (Epoch 304): Loss/seq after 03100 batchs: 354.2887268066406
INFO:root:Train (Epoch 304): Loss/seq after 03150 batchs: 354.07867431640625
INFO:root:Train (Epoch 304): Loss/seq after 03200 batchs: 354.40765380859375
INFO:root:Train (Epoch 304): Loss/seq after 03250 batchs: 354.65301513671875
INFO:root:Train (Epoch 304): Loss/seq after 03300 batchs: 354.5875244140625
INFO:root:Train (Epoch 304): Loss/seq after 03350 batchs: 353.1250305175781
INFO:root:Train (Epoch 304): Loss/seq after 03400 batchs: 351.10748291015625
INFO:root:Train (Epoch 304): Loss/seq after 03450 batchs: 350.2720642089844
INFO:root:Train (Epoch 304): Loss/seq after 03500 batchs: 351.31231689453125
INFO:root:Train (Epoch 304): Loss/seq after 03550 batchs: 349.96051025390625
INFO:root:Train (Epoch 304): Loss/seq after 03600 batchs: 353.0425109863281
INFO:root:Train (Epoch 304): Loss/seq after 03650 batchs: 351.8082275390625
INFO:root:Train (Epoch 304): Loss/seq after 03700 batchs: 353.5868835449219
INFO:root:Train (Epoch 304): Loss/seq after 03750 batchs: 356.7956237792969
INFO:root:Train (Epoch 304): Loss/seq after 03800 batchs: 356.5214538574219
INFO:root:Train (Epoch 304): Loss/seq after 03850 batchs: 356.1083068847656
INFO:root:Train (Epoch 304): Loss/seq after 03900 batchs: 357.48321533203125
INFO:root:Train (Epoch 304): Loss/seq after 03950 batchs: 360.2047424316406
INFO:root:Train (Epoch 304): Loss/seq after 04000 batchs: 358.1595764160156
INFO:root:Train (Epoch 304): Loss/seq after 04050 batchs: 356.24810791015625
INFO:root:Train (Epoch 304): Loss/seq after 04100 batchs: 355.6314392089844
INFO:root:Train (Epoch 304): Loss/seq after 04150 batchs: 355.98248291015625
INFO:root:Train (Epoch 304): Loss/seq after 04200 batchs: 355.40814208984375
INFO:root:Train (Epoch 304): Loss/seq after 04250 batchs: 354.6356201171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 304): Loss/seq after 00000 batches: 410.9287414550781
INFO:root:# Valid (Epoch 304): Loss/seq after 00050 batches: 724.3546752929688
INFO:root:# Valid (Epoch 304): Loss/seq after 00100 batches: 794.97119140625
INFO:root:# Valid (Epoch 304): Loss/seq after 00150 batches: 590.526611328125
INFO:root:# Valid (Epoch 304): Loss/seq after 00200 batches: 526.22705078125
INFO:root:Artifacts: Make stick videos for epoch 304
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_304_on_20220423_212150.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_304_index_833_on_20220423_212150.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 305): Loss/seq after 00000 batchs: 630.2741088867188
INFO:root:Train (Epoch 305): Loss/seq after 00050 batchs: 506.0674133300781
INFO:root:Train (Epoch 305): Loss/seq after 00100 batchs: 504.78314208984375
INFO:root:Train (Epoch 305): Loss/seq after 00150 batchs: 463.3015441894531
INFO:root:Train (Epoch 305): Loss/seq after 00200 batchs: 525.3129272460938
INFO:root:Train (Epoch 305): Loss/seq after 00250 batchs: 544.4215698242188
INFO:root:Train (Epoch 305): Loss/seq after 00300 batchs: 557.7337646484375
INFO:root:Train (Epoch 305): Loss/seq after 00350 batchs: 531.9247436523438
INFO:root:Train (Epoch 305): Loss/seq after 00400 batchs: 519.8314819335938
INFO:root:Train (Epoch 305): Loss/seq after 00450 batchs: 529.09521484375
INFO:root:Train (Epoch 305): Loss/seq after 00500 batchs: 512.6143798828125
INFO:root:Train (Epoch 305): Loss/seq after 00550 batchs: 502.2803955078125
INFO:root:Train (Epoch 305): Loss/seq after 00600 batchs: 485.5069580078125
INFO:root:Train (Epoch 305): Loss/seq after 00650 batchs: 470.5277099609375
INFO:root:Train (Epoch 305): Loss/seq after 00700 batchs: 451.3928527832031
INFO:root:Train (Epoch 305): Loss/seq after 00750 batchs: 446.28912353515625
INFO:root:Train (Epoch 305): Loss/seq after 00800 batchs: 446.9096984863281
INFO:root:Train (Epoch 305): Loss/seq after 00850 batchs: 433.2002258300781
INFO:root:Train (Epoch 305): Loss/seq after 00900 batchs: 422.1046447753906
INFO:root:Train (Epoch 305): Loss/seq after 00950 batchs: 419.5126647949219
INFO:root:Train (Epoch 305): Loss/seq after 01000 batchs: 413.28759765625
INFO:root:Train (Epoch 305): Loss/seq after 01050 batchs: 405.28887939453125
INFO:root:Train (Epoch 305): Loss/seq after 01100 batchs: 396.66949462890625
INFO:root:Train (Epoch 305): Loss/seq after 01150 batchs: 386.2907409667969
INFO:root:Train (Epoch 305): Loss/seq after 01200 batchs: 386.69439697265625
INFO:root:Train (Epoch 305): Loss/seq after 01250 batchs: 386.00616455078125
INFO:root:Train (Epoch 305): Loss/seq after 01300 batchs: 378.04571533203125
INFO:root:Train (Epoch 305): Loss/seq after 01350 batchs: 370.2569274902344
INFO:root:Train (Epoch 305): Loss/seq after 01400 batchs: 371.382080078125
INFO:root:Train (Epoch 305): Loss/seq after 01450 batchs: 374.5272216796875
INFO:root:Train (Epoch 305): Loss/seq after 01500 batchs: 380.2986755371094
INFO:root:Train (Epoch 305): Loss/seq after 01550 batchs: 380.8375244140625
INFO:root:Train (Epoch 305): Loss/seq after 01600 batchs: 378.90594482421875
INFO:root:Train (Epoch 305): Loss/seq after 01650 batchs: 377.0245666503906
INFO:root:Train (Epoch 305): Loss/seq after 01700 batchs: 380.31158447265625
INFO:root:Train (Epoch 305): Loss/seq after 01750 batchs: 379.55340576171875
INFO:root:Train (Epoch 305): Loss/seq after 01800 batchs: 377.9368896484375
INFO:root:Train (Epoch 305): Loss/seq after 01850 batchs: 375.9573059082031
INFO:root:Train (Epoch 305): Loss/seq after 01900 batchs: 375.1417236328125
INFO:root:Train (Epoch 305): Loss/seq after 01950 batchs: 375.2354431152344
INFO:root:Train (Epoch 305): Loss/seq after 02000 batchs: 376.80950927734375
INFO:root:Train (Epoch 305): Loss/seq after 02050 batchs: 376.72882080078125
INFO:root:Train (Epoch 305): Loss/seq after 02100 batchs: 375.9796142578125
INFO:root:Train (Epoch 305): Loss/seq after 02150 batchs: 375.78045654296875
INFO:root:Train (Epoch 305): Loss/seq after 02200 batchs: 375.0352478027344
INFO:root:Train (Epoch 305): Loss/seq after 02250 batchs: 374.3672180175781
INFO:root:Train (Epoch 305): Loss/seq after 02300 batchs: 372.0156555175781
INFO:root:Train (Epoch 305): Loss/seq after 02350 batchs: 369.7032165527344
INFO:root:Train (Epoch 305): Loss/seq after 02400 batchs: 370.9133605957031
INFO:root:Train (Epoch 305): Loss/seq after 02450 batchs: 368.08636474609375
INFO:root:Train (Epoch 305): Loss/seq after 02500 batchs: 362.2068176269531
INFO:root:Train (Epoch 305): Loss/seq after 02550 batchs: 357.4503479003906
INFO:root:Train (Epoch 305): Loss/seq after 02600 batchs: 354.1272888183594
INFO:root:Train (Epoch 305): Loss/seq after 02650 batchs: 351.0629577636719
INFO:root:Train (Epoch 305): Loss/seq after 02700 batchs: 348.97393798828125
INFO:root:Train (Epoch 305): Loss/seq after 02750 batchs: 345.50726318359375
INFO:root:Train (Epoch 305): Loss/seq after 02800 batchs: 344.76275634765625
INFO:root:Train (Epoch 305): Loss/seq after 02850 batchs: 344.5816650390625
INFO:root:Train (Epoch 305): Loss/seq after 02900 batchs: 345.4974365234375
INFO:root:Train (Epoch 305): Loss/seq after 02950 batchs: 346.285888671875
INFO:root:Train (Epoch 305): Loss/seq after 03000 batchs: 350.0437316894531
INFO:root:Train (Epoch 305): Loss/seq after 03050 batchs: 351.74542236328125
INFO:root:Train (Epoch 305): Loss/seq after 03100 batchs: 353.7846984863281
INFO:root:Train (Epoch 305): Loss/seq after 03150 batchs: 353.77294921875
INFO:root:Train (Epoch 305): Loss/seq after 03200 batchs: 354.0445251464844
INFO:root:Train (Epoch 305): Loss/seq after 03250 batchs: 353.95355224609375
INFO:root:Train (Epoch 305): Loss/seq after 03300 batchs: 353.5505676269531
INFO:root:Train (Epoch 305): Loss/seq after 03350 batchs: 352.3843078613281
INFO:root:Train (Epoch 305): Loss/seq after 03400 batchs: 350.3548278808594
INFO:root:Train (Epoch 305): Loss/seq after 03450 batchs: 349.51739501953125
INFO:root:Train (Epoch 305): Loss/seq after 03500 batchs: 350.40582275390625
INFO:root:Train (Epoch 305): Loss/seq after 03550 batchs: 349.0146789550781
INFO:root:Train (Epoch 305): Loss/seq after 03600 batchs: 352.11468505859375
INFO:root:Train (Epoch 305): Loss/seq after 03650 batchs: 351.15667724609375
INFO:root:Train (Epoch 305): Loss/seq after 03700 batchs: 353.26910400390625
INFO:root:Train (Epoch 305): Loss/seq after 03750 batchs: 356.6372375488281
INFO:root:Train (Epoch 305): Loss/seq after 03800 batchs: 356.3177185058594
INFO:root:Train (Epoch 305): Loss/seq after 03850 batchs: 355.8897705078125
INFO:root:Train (Epoch 305): Loss/seq after 03900 batchs: 357.226318359375
INFO:root:Train (Epoch 305): Loss/seq after 03950 batchs: 359.5329284667969
INFO:root:Train (Epoch 305): Loss/seq after 04000 batchs: 357.525146484375
INFO:root:Train (Epoch 305): Loss/seq after 04050 batchs: 355.61260986328125
INFO:root:Train (Epoch 305): Loss/seq after 04100 batchs: 354.9713134765625
INFO:root:Train (Epoch 305): Loss/seq after 04150 batchs: 355.45025634765625
INFO:root:Train (Epoch 305): Loss/seq after 04200 batchs: 355.10260009765625
INFO:root:Train (Epoch 305): Loss/seq after 04250 batchs: 354.26007080078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 305): Loss/seq after 00000 batches: 456.0346374511719
INFO:root:# Valid (Epoch 305): Loss/seq after 00050 batches: 737.0584106445312
INFO:root:# Valid (Epoch 305): Loss/seq after 00100 batches: 691.352294921875
INFO:root:# Valid (Epoch 305): Loss/seq after 00150 batches: 515.9216918945312
INFO:root:# Valid (Epoch 305): Loss/seq after 00200 batches: 469.9129638671875
INFO:root:Artifacts: Make stick videos for epoch 305
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_305_on_20220423_212636.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_305_index_491_on_20220423_212636.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 306): Loss/seq after 00000 batchs: 592.3853759765625
INFO:root:Train (Epoch 306): Loss/seq after 00050 batchs: 478.4859313964844
INFO:root:Train (Epoch 306): Loss/seq after 00100 batchs: 512.5353393554688
INFO:root:Train (Epoch 306): Loss/seq after 00150 batchs: 469.13848876953125
INFO:root:Train (Epoch 306): Loss/seq after 00200 batchs: 530.009033203125
INFO:root:Train (Epoch 306): Loss/seq after 00250 batchs: 550.405517578125
INFO:root:Train (Epoch 306): Loss/seq after 00300 batchs: 564.1198120117188
INFO:root:Train (Epoch 306): Loss/seq after 00350 batchs: 537.9242553710938
INFO:root:Train (Epoch 306): Loss/seq after 00400 batchs: 526.5814819335938
INFO:root:Train (Epoch 306): Loss/seq after 00450 batchs: 534.3431396484375
INFO:root:Train (Epoch 306): Loss/seq after 00500 batchs: 518.2639770507812
INFO:root:Train (Epoch 306): Loss/seq after 00550 batchs: 507.3685302734375
INFO:root:Train (Epoch 306): Loss/seq after 00600 batchs: 490.17059326171875
INFO:root:Train (Epoch 306): Loss/seq after 00650 batchs: 474.21746826171875
INFO:root:Train (Epoch 306): Loss/seq after 00700 batchs: 456.66522216796875
INFO:root:Train (Epoch 306): Loss/seq after 00750 batchs: 449.2066345214844
INFO:root:Train (Epoch 306): Loss/seq after 00800 batchs: 450.3775634765625
INFO:root:Train (Epoch 306): Loss/seq after 00850 batchs: 436.47027587890625
INFO:root:Train (Epoch 306): Loss/seq after 00900 batchs: 425.0936279296875
INFO:root:Train (Epoch 306): Loss/seq after 00950 batchs: 423.5375061035156
INFO:root:Train (Epoch 306): Loss/seq after 01000 batchs: 417.1201477050781
INFO:root:Train (Epoch 306): Loss/seq after 01050 batchs: 408.7317199707031
INFO:root:Train (Epoch 306): Loss/seq after 01100 batchs: 399.69964599609375
INFO:root:Train (Epoch 306): Loss/seq after 01150 batchs: 389.4069519042969
INFO:root:Train (Epoch 306): Loss/seq after 01200 batchs: 389.8733215332031
INFO:root:Train (Epoch 306): Loss/seq after 01250 batchs: 388.7861328125
INFO:root:Train (Epoch 306): Loss/seq after 01300 batchs: 380.7796630859375
INFO:root:Train (Epoch 306): Loss/seq after 01350 batchs: 373.1338806152344
INFO:root:Train (Epoch 306): Loss/seq after 01400 batchs: 373.56536865234375
INFO:root:Train (Epoch 306): Loss/seq after 01450 batchs: 376.75067138671875
INFO:root:Train (Epoch 306): Loss/seq after 01500 batchs: 382.2060241699219
INFO:root:Train (Epoch 306): Loss/seq after 01550 batchs: 382.97625732421875
INFO:root:Train (Epoch 306): Loss/seq after 01600 batchs: 381.05975341796875
INFO:root:Train (Epoch 306): Loss/seq after 01650 batchs: 379.1943359375
INFO:root:Train (Epoch 306): Loss/seq after 01700 batchs: 382.22357177734375
INFO:root:Train (Epoch 306): Loss/seq after 01750 batchs: 381.5809631347656
INFO:root:Train (Epoch 306): Loss/seq after 01800 batchs: 380.3623352050781
INFO:root:Train (Epoch 306): Loss/seq after 01850 batchs: 378.3304748535156
INFO:root:Train (Epoch 306): Loss/seq after 01900 batchs: 377.3859558105469
INFO:root:Train (Epoch 306): Loss/seq after 01950 batchs: 377.09332275390625
INFO:root:Train (Epoch 306): Loss/seq after 02000 batchs: 378.56915283203125
INFO:root:Train (Epoch 306): Loss/seq after 02050 batchs: 378.4862060546875
INFO:root:Train (Epoch 306): Loss/seq after 02100 batchs: 377.72564697265625
INFO:root:Train (Epoch 306): Loss/seq after 02150 batchs: 377.24322509765625
INFO:root:Train (Epoch 306): Loss/seq after 02200 batchs: 376.334228515625
INFO:root:Train (Epoch 306): Loss/seq after 02250 batchs: 375.60614013671875
INFO:root:Train (Epoch 306): Loss/seq after 02300 batchs: 372.99981689453125
INFO:root:Train (Epoch 306): Loss/seq after 02350 batchs: 370.73846435546875
INFO:root:Train (Epoch 306): Loss/seq after 02400 batchs: 371.8610534667969
INFO:root:Train (Epoch 306): Loss/seq after 02450 batchs: 368.88482666015625
INFO:root:Train (Epoch 306): Loss/seq after 02500 batchs: 362.9251403808594
INFO:root:Train (Epoch 306): Loss/seq after 02550 batchs: 358.2283020019531
INFO:root:Train (Epoch 306): Loss/seq after 02600 batchs: 354.720458984375
INFO:root:Train (Epoch 306): Loss/seq after 02650 batchs: 351.40972900390625
INFO:root:Train (Epoch 306): Loss/seq after 02700 batchs: 349.19891357421875
INFO:root:Train (Epoch 306): Loss/seq after 02750 batchs: 345.4703369140625
INFO:root:Train (Epoch 306): Loss/seq after 02800 batchs: 344.8563537597656
INFO:root:Train (Epoch 306): Loss/seq after 02850 batchs: 344.56976318359375
INFO:root:Train (Epoch 306): Loss/seq after 02900 batchs: 345.3138732910156
INFO:root:Train (Epoch 306): Loss/seq after 02950 batchs: 346.0810852050781
INFO:root:Train (Epoch 306): Loss/seq after 03000 batchs: 349.6333923339844
INFO:root:Train (Epoch 306): Loss/seq after 03050 batchs: 351.3019714355469
INFO:root:Train (Epoch 306): Loss/seq after 03100 batchs: 353.7742919921875
INFO:root:Train (Epoch 306): Loss/seq after 03150 batchs: 354.47021484375
INFO:root:Train (Epoch 306): Loss/seq after 03200 batchs: 354.7107238769531
INFO:root:Train (Epoch 306): Loss/seq after 03250 batchs: 355.0121765136719
INFO:root:Train (Epoch 306): Loss/seq after 03300 batchs: 354.7232666015625
INFO:root:Train (Epoch 306): Loss/seq after 03350 batchs: 352.8255615234375
INFO:root:Train (Epoch 306): Loss/seq after 03400 batchs: 350.8663330078125
INFO:root:Train (Epoch 306): Loss/seq after 03450 batchs: 349.9512939453125
INFO:root:Train (Epoch 306): Loss/seq after 03500 batchs: 350.8443908691406
INFO:root:Train (Epoch 306): Loss/seq after 03550 batchs: 349.4466247558594
INFO:root:Train (Epoch 306): Loss/seq after 03600 batchs: 352.1705322265625
INFO:root:Train (Epoch 306): Loss/seq after 03650 batchs: 350.9756164550781
INFO:root:Train (Epoch 306): Loss/seq after 03700 batchs: 352.9101867675781
INFO:root:Train (Epoch 306): Loss/seq after 03750 batchs: 356.22186279296875
INFO:root:Train (Epoch 306): Loss/seq after 03800 batchs: 355.929443359375
INFO:root:Train (Epoch 306): Loss/seq after 03850 batchs: 355.4729309082031
INFO:root:Train (Epoch 306): Loss/seq after 03900 batchs: 357.4378967285156
INFO:root:Train (Epoch 306): Loss/seq after 03950 batchs: 360.5909118652344
INFO:root:Train (Epoch 306): Loss/seq after 04000 batchs: 358.56005859375
INFO:root:Train (Epoch 306): Loss/seq after 04050 batchs: 356.59967041015625
INFO:root:Train (Epoch 306): Loss/seq after 04100 batchs: 355.9393310546875
INFO:root:Train (Epoch 306): Loss/seq after 04150 batchs: 356.2488708496094
INFO:root:Train (Epoch 306): Loss/seq after 04200 batchs: 355.73779296875
INFO:root:Train (Epoch 306): Loss/seq after 04250 batchs: 354.8583679199219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 306): Loss/seq after 00000 batches: 351.1846008300781
INFO:root:# Valid (Epoch 306): Loss/seq after 00050 batches: 668.219482421875
INFO:root:# Valid (Epoch 306): Loss/seq after 00100 batches: 679.9848022460938
INFO:root:# Valid (Epoch 306): Loss/seq after 00150 batches: 505.4537048339844
INFO:root:# Valid (Epoch 306): Loss/seq after 00200 batches: 459.43572998046875
INFO:root:Artifacts: Make stick videos for epoch 306
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_306_on_20220423_213122.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_306_index_139_on_20220423_213122.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 307): Loss/seq after 00000 batchs: 589.9630737304688
INFO:root:Train (Epoch 307): Loss/seq after 00050 batchs: 469.4170227050781
INFO:root:Train (Epoch 307): Loss/seq after 00100 batchs: 495.08917236328125
INFO:root:Train (Epoch 307): Loss/seq after 00150 batchs: 454.80804443359375
INFO:root:Train (Epoch 307): Loss/seq after 00200 batchs: 517.8078002929688
INFO:root:Train (Epoch 307): Loss/seq after 00250 batchs: 535.4736938476562
INFO:root:Train (Epoch 307): Loss/seq after 00300 batchs: 549.9435424804688
INFO:root:Train (Epoch 307): Loss/seq after 00350 batchs: 524.7084350585938
INFO:root:Train (Epoch 307): Loss/seq after 00400 batchs: 517.5714721679688
INFO:root:Train (Epoch 307): Loss/seq after 00450 batchs: 526.52490234375
INFO:root:Train (Epoch 307): Loss/seq after 00500 batchs: 508.7458190917969
INFO:root:Train (Epoch 307): Loss/seq after 00550 batchs: 497.6889343261719
INFO:root:Train (Epoch 307): Loss/seq after 00600 batchs: 480.742919921875
INFO:root:Train (Epoch 307): Loss/seq after 00650 batchs: 461.888916015625
INFO:root:Train (Epoch 307): Loss/seq after 00700 batchs: 444.3664855957031
INFO:root:Train (Epoch 307): Loss/seq after 00750 batchs: 440.0165710449219
INFO:root:Train (Epoch 307): Loss/seq after 00800 batchs: 441.01507568359375
INFO:root:Train (Epoch 307): Loss/seq after 00850 batchs: 427.8341979980469
INFO:root:Train (Epoch 307): Loss/seq after 00900 batchs: 417.1091613769531
INFO:root:Train (Epoch 307): Loss/seq after 00950 batchs: 415.687255859375
INFO:root:Train (Epoch 307): Loss/seq after 01000 batchs: 408.818115234375
INFO:root:Train (Epoch 307): Loss/seq after 01050 batchs: 400.1416320800781
INFO:root:Train (Epoch 307): Loss/seq after 01100 batchs: 391.5362243652344
INFO:root:Train (Epoch 307): Loss/seq after 01150 batchs: 381.23046875
INFO:root:Train (Epoch 307): Loss/seq after 01200 batchs: 382.608642578125
INFO:root:Train (Epoch 307): Loss/seq after 01250 batchs: 382.0462341308594
INFO:root:Train (Epoch 307): Loss/seq after 01300 batchs: 374.1610412597656
INFO:root:Train (Epoch 307): Loss/seq after 01350 batchs: 367.0835876464844
INFO:root:Train (Epoch 307): Loss/seq after 01400 batchs: 368.8905944824219
INFO:root:Train (Epoch 307): Loss/seq after 01450 batchs: 372.13226318359375
INFO:root:Train (Epoch 307): Loss/seq after 01500 batchs: 378.08099365234375
INFO:root:Train (Epoch 307): Loss/seq after 01550 batchs: 378.5098876953125
INFO:root:Train (Epoch 307): Loss/seq after 01600 batchs: 376.8149108886719
INFO:root:Train (Epoch 307): Loss/seq after 01650 batchs: 375.1392822265625
INFO:root:Train (Epoch 307): Loss/seq after 01700 batchs: 378.2444152832031
INFO:root:Train (Epoch 307): Loss/seq after 01750 batchs: 377.5694885253906
INFO:root:Train (Epoch 307): Loss/seq after 01800 batchs: 376.2549133300781
INFO:root:Train (Epoch 307): Loss/seq after 01850 batchs: 374.4804992675781
INFO:root:Train (Epoch 307): Loss/seq after 01900 batchs: 373.6114196777344
INFO:root:Train (Epoch 307): Loss/seq after 01950 batchs: 373.3726806640625
INFO:root:Train (Epoch 307): Loss/seq after 02000 batchs: 375.0678405761719
INFO:root:Train (Epoch 307): Loss/seq after 02050 batchs: 374.96661376953125
INFO:root:Train (Epoch 307): Loss/seq after 02100 batchs: 374.31365966796875
INFO:root:Train (Epoch 307): Loss/seq after 02150 batchs: 373.944580078125
INFO:root:Train (Epoch 307): Loss/seq after 02200 batchs: 373.23870849609375
INFO:root:Train (Epoch 307): Loss/seq after 02250 batchs: 372.3956604003906
INFO:root:Train (Epoch 307): Loss/seq after 02300 batchs: 369.8260803222656
INFO:root:Train (Epoch 307): Loss/seq after 02350 batchs: 367.4342346191406
INFO:root:Train (Epoch 307): Loss/seq after 02400 batchs: 368.5643615722656
INFO:root:Train (Epoch 307): Loss/seq after 02450 batchs: 365.7685546875
INFO:root:Train (Epoch 307): Loss/seq after 02500 batchs: 359.93231201171875
INFO:root:Train (Epoch 307): Loss/seq after 02550 batchs: 355.0650939941406
INFO:root:Train (Epoch 307): Loss/seq after 02600 batchs: 351.69622802734375
INFO:root:Train (Epoch 307): Loss/seq after 02650 batchs: 348.43255615234375
INFO:root:Train (Epoch 307): Loss/seq after 02700 batchs: 346.4607238769531
INFO:root:Train (Epoch 307): Loss/seq after 02750 batchs: 342.85174560546875
INFO:root:Train (Epoch 307): Loss/seq after 02800 batchs: 341.3702087402344
INFO:root:Train (Epoch 307): Loss/seq after 02850 batchs: 340.9911804199219
INFO:root:Train (Epoch 307): Loss/seq after 02900 batchs: 341.6094665527344
INFO:root:Train (Epoch 307): Loss/seq after 02950 batchs: 342.44970703125
INFO:root:Train (Epoch 307): Loss/seq after 03000 batchs: 346.00079345703125
INFO:root:Train (Epoch 307): Loss/seq after 03050 batchs: 347.6549987792969
INFO:root:Train (Epoch 307): Loss/seq after 03100 batchs: 349.4467468261719
INFO:root:Train (Epoch 307): Loss/seq after 03150 batchs: 349.7414245605469
INFO:root:Train (Epoch 307): Loss/seq after 03200 batchs: 350.0252685546875
INFO:root:Train (Epoch 307): Loss/seq after 03250 batchs: 350.6838073730469
INFO:root:Train (Epoch 307): Loss/seq after 03300 batchs: 350.175537109375
INFO:root:Train (Epoch 307): Loss/seq after 03350 batchs: 348.63421630859375
INFO:root:Train (Epoch 307): Loss/seq after 03400 batchs: 346.5950012207031
INFO:root:Train (Epoch 307): Loss/seq after 03450 batchs: 345.7620849609375
INFO:root:Train (Epoch 307): Loss/seq after 03500 batchs: 347.0802917480469
INFO:root:Train (Epoch 307): Loss/seq after 03550 batchs: 345.76885986328125
INFO:root:Train (Epoch 307): Loss/seq after 03600 batchs: 348.8931884765625
INFO:root:Train (Epoch 307): Loss/seq after 03650 batchs: 348.0288391113281
INFO:root:Train (Epoch 307): Loss/seq after 03700 batchs: 350.0252380371094
INFO:root:Train (Epoch 307): Loss/seq after 03750 batchs: 353.64019775390625
INFO:root:Train (Epoch 307): Loss/seq after 03800 batchs: 353.4947204589844
INFO:root:Train (Epoch 307): Loss/seq after 03850 batchs: 353.61505126953125
INFO:root:Train (Epoch 307): Loss/seq after 03900 batchs: 355.7953186035156
INFO:root:Train (Epoch 307): Loss/seq after 03950 batchs: 358.40753173828125
INFO:root:Train (Epoch 307): Loss/seq after 04000 batchs: 356.4684143066406
INFO:root:Train (Epoch 307): Loss/seq after 04050 batchs: 354.6098327636719
INFO:root:Train (Epoch 307): Loss/seq after 04100 batchs: 354.2060852050781
INFO:root:Train (Epoch 307): Loss/seq after 04150 batchs: 354.4535827636719
INFO:root:Train (Epoch 307): Loss/seq after 04200 batchs: 353.8878479003906
INFO:root:Train (Epoch 307): Loss/seq after 04250 batchs: 353.0505065917969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 307): Loss/seq after 00000 batches: 295.0950012207031
INFO:root:# Valid (Epoch 307): Loss/seq after 00050 batches: 698.8529663085938
INFO:root:# Valid (Epoch 307): Loss/seq after 00100 batches: 619.29931640625
INFO:root:# Valid (Epoch 307): Loss/seq after 00150 batches: 467.51385498046875
INFO:root:# Valid (Epoch 307): Loss/seq after 00200 batches: 434.2736511230469
INFO:root:Artifacts: Make stick videos for epoch 307
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_307_on_20220423_213630.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_307_index_922_on_20220423_213630.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 308): Loss/seq after 00000 batchs: 665.9421997070312
INFO:root:Train (Epoch 308): Loss/seq after 00050 batchs: 470.4573059082031
INFO:root:Train (Epoch 308): Loss/seq after 00100 batchs: 489.3173522949219
INFO:root:Train (Epoch 308): Loss/seq after 00150 batchs: 452.666748046875
INFO:root:Train (Epoch 308): Loss/seq after 00200 batchs: 512.7144165039062
INFO:root:Train (Epoch 308): Loss/seq after 00250 batchs: 532.4208984375
INFO:root:Train (Epoch 308): Loss/seq after 00300 batchs: 552.980712890625
INFO:root:Train (Epoch 308): Loss/seq after 00350 batchs: 528.1571655273438
INFO:root:Train (Epoch 308): Loss/seq after 00400 batchs: 516.5807495117188
INFO:root:Train (Epoch 308): Loss/seq after 00450 batchs: 525.9336547851562
INFO:root:Train (Epoch 308): Loss/seq after 00500 batchs: 510.02783203125
INFO:root:Train (Epoch 308): Loss/seq after 00550 batchs: 499.9978332519531
INFO:root:Train (Epoch 308): Loss/seq after 00600 batchs: 483.8101501464844
INFO:root:Train (Epoch 308): Loss/seq after 00650 batchs: 466.3357849121094
INFO:root:Train (Epoch 308): Loss/seq after 00700 batchs: 446.9588623046875
INFO:root:Train (Epoch 308): Loss/seq after 00750 batchs: 439.5129089355469
INFO:root:Train (Epoch 308): Loss/seq after 00800 batchs: 441.9442138671875
INFO:root:Train (Epoch 308): Loss/seq after 00850 batchs: 429.47406005859375
INFO:root:Train (Epoch 308): Loss/seq after 00900 batchs: 419.68072509765625
INFO:root:Train (Epoch 308): Loss/seq after 00950 batchs: 417.5318908691406
INFO:root:Train (Epoch 308): Loss/seq after 01000 batchs: 411.0902404785156
INFO:root:Train (Epoch 308): Loss/seq after 01050 batchs: 402.9168395996094
INFO:root:Train (Epoch 308): Loss/seq after 01100 batchs: 393.536865234375
INFO:root:Train (Epoch 308): Loss/seq after 01150 batchs: 383.3659973144531
INFO:root:Train (Epoch 308): Loss/seq after 01200 batchs: 383.2889099121094
INFO:root:Train (Epoch 308): Loss/seq after 01250 batchs: 382.2739562988281
INFO:root:Train (Epoch 308): Loss/seq after 01300 batchs: 374.6493835449219
INFO:root:Train (Epoch 308): Loss/seq after 01350 batchs: 366.9853820800781
INFO:root:Train (Epoch 308): Loss/seq after 01400 batchs: 369.0224914550781
INFO:root:Train (Epoch 308): Loss/seq after 01450 batchs: 371.9986267089844
INFO:root:Train (Epoch 308): Loss/seq after 01500 batchs: 377.40191650390625
INFO:root:Train (Epoch 308): Loss/seq after 01550 batchs: 378.4817810058594
INFO:root:Train (Epoch 308): Loss/seq after 01600 batchs: 376.442626953125
INFO:root:Train (Epoch 308): Loss/seq after 01650 batchs: 374.71221923828125
INFO:root:Train (Epoch 308): Loss/seq after 01700 batchs: 377.8868713378906
INFO:root:Train (Epoch 308): Loss/seq after 01750 batchs: 377.1288757324219
INFO:root:Train (Epoch 308): Loss/seq after 01800 batchs: 375.7952880859375
INFO:root:Train (Epoch 308): Loss/seq after 01850 batchs: 373.8624572753906
INFO:root:Train (Epoch 308): Loss/seq after 01900 batchs: 373.1549987792969
INFO:root:Train (Epoch 308): Loss/seq after 01950 batchs: 372.8050537109375
INFO:root:Train (Epoch 308): Loss/seq after 02000 batchs: 374.3179931640625
INFO:root:Train (Epoch 308): Loss/seq after 02050 batchs: 374.3001708984375
INFO:root:Train (Epoch 308): Loss/seq after 02100 batchs: 373.716796875
INFO:root:Train (Epoch 308): Loss/seq after 02150 batchs: 373.2173156738281
INFO:root:Train (Epoch 308): Loss/seq after 02200 batchs: 372.2908630371094
INFO:root:Train (Epoch 308): Loss/seq after 02250 batchs: 371.5033874511719
INFO:root:Train (Epoch 308): Loss/seq after 02300 batchs: 369.5780029296875
INFO:root:Train (Epoch 308): Loss/seq after 02350 batchs: 367.35528564453125
INFO:root:Train (Epoch 308): Loss/seq after 02400 batchs: 368.43914794921875
INFO:root:Train (Epoch 308): Loss/seq after 02450 batchs: 365.6001892089844
INFO:root:Train (Epoch 308): Loss/seq after 02500 batchs: 359.73651123046875
INFO:root:Train (Epoch 308): Loss/seq after 02550 batchs: 355.04638671875
INFO:root:Train (Epoch 308): Loss/seq after 02600 batchs: 351.6003112792969
INFO:root:Train (Epoch 308): Loss/seq after 02650 batchs: 348.5219421386719
INFO:root:Train (Epoch 308): Loss/seq after 02700 batchs: 346.3975830078125
INFO:root:Train (Epoch 308): Loss/seq after 02750 batchs: 342.9423522949219
INFO:root:Train (Epoch 308): Loss/seq after 02800 batchs: 341.8304748535156
INFO:root:Train (Epoch 308): Loss/seq after 02850 batchs: 341.7207336425781
INFO:root:Train (Epoch 308): Loss/seq after 02900 batchs: 342.5125732421875
INFO:root:Train (Epoch 308): Loss/seq after 02950 batchs: 343.1440124511719
INFO:root:Train (Epoch 308): Loss/seq after 03000 batchs: 346.8821105957031
INFO:root:Train (Epoch 308): Loss/seq after 03050 batchs: 348.3533020019531
INFO:root:Train (Epoch 308): Loss/seq after 03100 batchs: 350.0737609863281
INFO:root:Train (Epoch 308): Loss/seq after 03150 batchs: 350.3023986816406
INFO:root:Train (Epoch 308): Loss/seq after 03200 batchs: 350.07244873046875
INFO:root:Train (Epoch 308): Loss/seq after 03250 batchs: 350.037353515625
INFO:root:Train (Epoch 308): Loss/seq after 03300 batchs: 349.4579772949219
INFO:root:Train (Epoch 308): Loss/seq after 03350 batchs: 347.6417236328125
INFO:root:Train (Epoch 308): Loss/seq after 03400 batchs: 345.64178466796875
INFO:root:Train (Epoch 308): Loss/seq after 03450 batchs: 344.779296875
INFO:root:Train (Epoch 308): Loss/seq after 03500 batchs: 345.6042175292969
INFO:root:Train (Epoch 308): Loss/seq after 03550 batchs: 344.21630859375
INFO:root:Train (Epoch 308): Loss/seq after 03600 batchs: 347.1947021484375
INFO:root:Train (Epoch 308): Loss/seq after 03650 batchs: 346.13970947265625
INFO:root:Train (Epoch 308): Loss/seq after 03700 batchs: 347.9521789550781
INFO:root:Train (Epoch 308): Loss/seq after 03750 batchs: 351.1710205078125
INFO:root:Train (Epoch 308): Loss/seq after 03800 batchs: 350.9287109375
INFO:root:Train (Epoch 308): Loss/seq after 03850 batchs: 350.4406433105469
INFO:root:Train (Epoch 308): Loss/seq after 03900 batchs: 351.74078369140625
INFO:root:Train (Epoch 308): Loss/seq after 03950 batchs: 354.1601257324219
INFO:root:Train (Epoch 308): Loss/seq after 04000 batchs: 352.1921081542969
INFO:root:Train (Epoch 308): Loss/seq after 04050 batchs: 350.3655090332031
INFO:root:Train (Epoch 308): Loss/seq after 04100 batchs: 349.6021728515625
INFO:root:Train (Epoch 308): Loss/seq after 04150 batchs: 349.92633056640625
INFO:root:Train (Epoch 308): Loss/seq after 04200 batchs: 349.4615478515625
INFO:root:Train (Epoch 308): Loss/seq after 04250 batchs: 348.6784362792969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 308): Loss/seq after 00000 batches: 351.8191223144531
INFO:root:# Valid (Epoch 308): Loss/seq after 00050 batches: 690.5330200195312
INFO:root:# Valid (Epoch 308): Loss/seq after 00100 batches: 647.7669067382812
INFO:root:# Valid (Epoch 308): Loss/seq after 00150 batches: 486.67047119140625
INFO:root:# Valid (Epoch 308): Loss/seq after 00200 batches: 447.0363464355469
INFO:root:Artifacts: Make stick videos for epoch 308
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_308_on_20220423_214131.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_308_index_1412_on_20220423_214131.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 309): Loss/seq after 00000 batchs: 661.239990234375
INFO:root:Train (Epoch 309): Loss/seq after 00050 batchs: 479.97906494140625
INFO:root:Train (Epoch 309): Loss/seq after 00100 batchs: 488.7087707519531
INFO:root:Train (Epoch 309): Loss/seq after 00150 batchs: 449.9017333984375
INFO:root:Train (Epoch 309): Loss/seq after 00200 batchs: 503.4632873535156
INFO:root:Train (Epoch 309): Loss/seq after 00250 batchs: 514.3071899414062
INFO:root:Train (Epoch 309): Loss/seq after 00300 batchs: 532.4066772460938
INFO:root:Train (Epoch 309): Loss/seq after 00350 batchs: 507.1228942871094
INFO:root:Train (Epoch 309): Loss/seq after 00400 batchs: 493.8334045410156
INFO:root:Train (Epoch 309): Loss/seq after 00450 batchs: 504.91595458984375
INFO:root:Train (Epoch 309): Loss/seq after 00500 batchs: 490.5649719238281
INFO:root:Train (Epoch 309): Loss/seq after 00550 batchs: 481.0137939453125
INFO:root:Train (Epoch 309): Loss/seq after 00600 batchs: 465.80853271484375
INFO:root:Train (Epoch 309): Loss/seq after 00650 batchs: 447.539794921875
INFO:root:Train (Epoch 309): Loss/seq after 00700 batchs: 431.0162048339844
INFO:root:Train (Epoch 309): Loss/seq after 00750 batchs: 426.0838623046875
INFO:root:Train (Epoch 309): Loss/seq after 00800 batchs: 428.4367370605469
INFO:root:Train (Epoch 309): Loss/seq after 00850 batchs: 415.9323425292969
INFO:root:Train (Epoch 309): Loss/seq after 00900 batchs: 405.22833251953125
INFO:root:Train (Epoch 309): Loss/seq after 00950 batchs: 405.0250549316406
INFO:root:Train (Epoch 309): Loss/seq after 01000 batchs: 399.1227111816406
INFO:root:Train (Epoch 309): Loss/seq after 01050 batchs: 393.3607177734375
INFO:root:Train (Epoch 309): Loss/seq after 01100 batchs: 385.128173828125
INFO:root:Train (Epoch 309): Loss/seq after 01150 batchs: 375.3982238769531
INFO:root:Train (Epoch 309): Loss/seq after 01200 batchs: 376.3450622558594
INFO:root:Train (Epoch 309): Loss/seq after 01250 batchs: 375.7039794921875
INFO:root:Train (Epoch 309): Loss/seq after 01300 batchs: 367.8885803222656
INFO:root:Train (Epoch 309): Loss/seq after 01350 batchs: 360.20794677734375
INFO:root:Train (Epoch 309): Loss/seq after 01400 batchs: 361.9002990722656
INFO:root:Train (Epoch 309): Loss/seq after 01450 batchs: 365.2569274902344
INFO:root:Train (Epoch 309): Loss/seq after 01500 batchs: 371.2519226074219
INFO:root:Train (Epoch 309): Loss/seq after 01550 batchs: 372.5951232910156
INFO:root:Train (Epoch 309): Loss/seq after 01600 batchs: 371.09405517578125
INFO:root:Train (Epoch 309): Loss/seq after 01650 batchs: 370.05816650390625
INFO:root:Train (Epoch 309): Loss/seq after 01700 batchs: 373.46405029296875
INFO:root:Train (Epoch 309): Loss/seq after 01750 batchs: 372.897705078125
INFO:root:Train (Epoch 309): Loss/seq after 01800 batchs: 371.3692932128906
INFO:root:Train (Epoch 309): Loss/seq after 01850 batchs: 369.5213623046875
INFO:root:Train (Epoch 309): Loss/seq after 01900 batchs: 368.7163391113281
INFO:root:Train (Epoch 309): Loss/seq after 01950 batchs: 368.64703369140625
INFO:root:Train (Epoch 309): Loss/seq after 02000 batchs: 370.5062561035156
INFO:root:Train (Epoch 309): Loss/seq after 02050 batchs: 370.5415344238281
INFO:root:Train (Epoch 309): Loss/seq after 02100 batchs: 369.96356201171875
INFO:root:Train (Epoch 309): Loss/seq after 02150 batchs: 369.68890380859375
INFO:root:Train (Epoch 309): Loss/seq after 02200 batchs: 368.9068298339844
INFO:root:Train (Epoch 309): Loss/seq after 02250 batchs: 367.97967529296875
INFO:root:Train (Epoch 309): Loss/seq after 02300 batchs: 365.5624694824219
INFO:root:Train (Epoch 309): Loss/seq after 02350 batchs: 363.2559814453125
INFO:root:Train (Epoch 309): Loss/seq after 02400 batchs: 364.4635314941406
INFO:root:Train (Epoch 309): Loss/seq after 02450 batchs: 361.72564697265625
INFO:root:Train (Epoch 309): Loss/seq after 02500 batchs: 355.86102294921875
INFO:root:Train (Epoch 309): Loss/seq after 02550 batchs: 351.16094970703125
INFO:root:Train (Epoch 309): Loss/seq after 02600 batchs: 347.6528015136719
INFO:root:Train (Epoch 309): Loss/seq after 02650 batchs: 344.49127197265625
INFO:root:Train (Epoch 309): Loss/seq after 02700 batchs: 342.4640197753906
INFO:root:Train (Epoch 309): Loss/seq after 02750 batchs: 338.801025390625
INFO:root:Train (Epoch 309): Loss/seq after 02800 batchs: 337.43280029296875
INFO:root:Train (Epoch 309): Loss/seq after 02850 batchs: 337.42218017578125
INFO:root:Train (Epoch 309): Loss/seq after 02900 batchs: 338.1165466308594
INFO:root:Train (Epoch 309): Loss/seq after 02950 batchs: 339.02703857421875
INFO:root:Train (Epoch 309): Loss/seq after 03000 batchs: 342.33917236328125
INFO:root:Train (Epoch 309): Loss/seq after 03050 batchs: 343.8722229003906
INFO:root:Train (Epoch 309): Loss/seq after 03100 batchs: 345.28131103515625
INFO:root:Train (Epoch 309): Loss/seq after 03150 batchs: 344.9443664550781
INFO:root:Train (Epoch 309): Loss/seq after 03200 batchs: 344.90167236328125
INFO:root:Train (Epoch 309): Loss/seq after 03250 batchs: 345.1018371582031
INFO:root:Train (Epoch 309): Loss/seq after 03300 batchs: 344.4285888671875
INFO:root:Train (Epoch 309): Loss/seq after 03350 batchs: 342.7327880859375
INFO:root:Train (Epoch 309): Loss/seq after 03400 batchs: 340.8221130371094
INFO:root:Train (Epoch 309): Loss/seq after 03450 batchs: 340.08746337890625
INFO:root:Train (Epoch 309): Loss/seq after 03500 batchs: 340.9320983886719
INFO:root:Train (Epoch 309): Loss/seq after 03550 batchs: 339.46710205078125
INFO:root:Train (Epoch 309): Loss/seq after 03600 batchs: 342.19927978515625
INFO:root:Train (Epoch 309): Loss/seq after 03650 batchs: 340.8961486816406
INFO:root:Train (Epoch 309): Loss/seq after 03700 batchs: 342.534912109375
INFO:root:Train (Epoch 309): Loss/seq after 03750 batchs: 345.6968078613281
INFO:root:Train (Epoch 309): Loss/seq after 03800 batchs: 345.54925537109375
INFO:root:Train (Epoch 309): Loss/seq after 03850 batchs: 345.2542419433594
INFO:root:Train (Epoch 309): Loss/seq after 03900 batchs: 346.87451171875
INFO:root:Train (Epoch 309): Loss/seq after 03950 batchs: 350.0347900390625
INFO:root:Train (Epoch 309): Loss/seq after 04000 batchs: 348.1706848144531
INFO:root:Train (Epoch 309): Loss/seq after 04050 batchs: 346.3434143066406
INFO:root:Train (Epoch 309): Loss/seq after 04100 batchs: 345.59600830078125
INFO:root:Train (Epoch 309): Loss/seq after 04150 batchs: 346.0401611328125
INFO:root:Train (Epoch 309): Loss/seq after 04200 batchs: 345.5638427734375
INFO:root:Train (Epoch 309): Loss/seq after 04250 batchs: 344.8203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 309): Loss/seq after 00000 batches: 384.6418762207031
INFO:root:# Valid (Epoch 309): Loss/seq after 00050 batches: 691.7787475585938
INFO:root:# Valid (Epoch 309): Loss/seq after 00100 batches: 707.2353515625
INFO:root:# Valid (Epoch 309): Loss/seq after 00150 batches: 523.479248046875
INFO:root:# Valid (Epoch 309): Loss/seq after 00200 batches: 476.4305725097656
INFO:root:Artifacts: Make stick videos for epoch 309
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_309_on_20220423_214627.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_309_index_1735_on_20220423_214627.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 310): Loss/seq after 00000 batchs: 485.9530029296875
INFO:root:Train (Epoch 310): Loss/seq after 00050 batchs: 484.5309143066406
INFO:root:Train (Epoch 310): Loss/seq after 00100 batchs: 481.5554504394531
INFO:root:Train (Epoch 310): Loss/seq after 00150 batchs: 447.0697326660156
INFO:root:Train (Epoch 310): Loss/seq after 00200 batchs: 509.2502136230469
INFO:root:Train (Epoch 310): Loss/seq after 00250 batchs: 538.9019165039062
INFO:root:Train (Epoch 310): Loss/seq after 00300 batchs: 554.3779296875
INFO:root:Train (Epoch 310): Loss/seq after 00350 batchs: 526.9551391601562
INFO:root:Train (Epoch 310): Loss/seq after 00400 batchs: 519.0215454101562
INFO:root:Train (Epoch 310): Loss/seq after 00450 batchs: 528.5549926757812
INFO:root:Train (Epoch 310): Loss/seq after 00500 batchs: 514.3970947265625
INFO:root:Train (Epoch 310): Loss/seq after 00550 batchs: 502.8601379394531
INFO:root:Train (Epoch 310): Loss/seq after 00600 batchs: 486.70855712890625
INFO:root:Train (Epoch 310): Loss/seq after 00650 batchs: 468.5992736816406
INFO:root:Train (Epoch 310): Loss/seq after 00700 batchs: 450.8723449707031
INFO:root:Train (Epoch 310): Loss/seq after 00750 batchs: 443.7573547363281
INFO:root:Train (Epoch 310): Loss/seq after 00800 batchs: 445.4230651855469
INFO:root:Train (Epoch 310): Loss/seq after 00850 batchs: 431.63665771484375
INFO:root:Train (Epoch 310): Loss/seq after 00900 batchs: 420.1763000488281
INFO:root:Train (Epoch 310): Loss/seq after 00950 batchs: 418.86968994140625
INFO:root:Train (Epoch 310): Loss/seq after 01000 batchs: 412.35540771484375
INFO:root:Train (Epoch 310): Loss/seq after 01050 batchs: 405.638427734375
INFO:root:Train (Epoch 310): Loss/seq after 01100 batchs: 396.7877502441406
INFO:root:Train (Epoch 310): Loss/seq after 01150 batchs: 386.3209228515625
INFO:root:Train (Epoch 310): Loss/seq after 01200 batchs: 386.7914123535156
INFO:root:Train (Epoch 310): Loss/seq after 01250 batchs: 385.36602783203125
INFO:root:Train (Epoch 310): Loss/seq after 01300 batchs: 377.5602111816406
INFO:root:Train (Epoch 310): Loss/seq after 01350 batchs: 369.6527404785156
INFO:root:Train (Epoch 310): Loss/seq after 01400 batchs: 371.4708251953125
INFO:root:Train (Epoch 310): Loss/seq after 01450 batchs: 374.5817565917969
INFO:root:Train (Epoch 310): Loss/seq after 01500 batchs: 380.0834655761719
INFO:root:Train (Epoch 310): Loss/seq after 01550 batchs: 380.93096923828125
INFO:root:Train (Epoch 310): Loss/seq after 01600 batchs: 379.2669677734375
INFO:root:Train (Epoch 310): Loss/seq after 01650 batchs: 377.5663757324219
INFO:root:Train (Epoch 310): Loss/seq after 01700 batchs: 380.6607360839844
INFO:root:Train (Epoch 310): Loss/seq after 01750 batchs: 379.8915100097656
INFO:root:Train (Epoch 310): Loss/seq after 01800 batchs: 378.1841125488281
INFO:root:Train (Epoch 310): Loss/seq after 01850 batchs: 376.1199645996094
INFO:root:Train (Epoch 310): Loss/seq after 01900 batchs: 375.221923828125
INFO:root:Train (Epoch 310): Loss/seq after 01950 batchs: 375.1506042480469
INFO:root:Train (Epoch 310): Loss/seq after 02000 batchs: 376.6752624511719
INFO:root:Train (Epoch 310): Loss/seq after 02050 batchs: 376.6482849121094
INFO:root:Train (Epoch 310): Loss/seq after 02100 batchs: 375.8342590332031
INFO:root:Train (Epoch 310): Loss/seq after 02150 batchs: 375.2995300292969
INFO:root:Train (Epoch 310): Loss/seq after 02200 batchs: 374.4636535644531
INFO:root:Train (Epoch 310): Loss/seq after 02250 batchs: 373.9795837402344
INFO:root:Train (Epoch 310): Loss/seq after 02300 batchs: 371.3834533691406
INFO:root:Train (Epoch 310): Loss/seq after 02350 batchs: 369.0828552246094
INFO:root:Train (Epoch 310): Loss/seq after 02400 batchs: 370.09112548828125
INFO:root:Train (Epoch 310): Loss/seq after 02450 batchs: 367.10174560546875
INFO:root:Train (Epoch 310): Loss/seq after 02500 batchs: 361.1621398925781
INFO:root:Train (Epoch 310): Loss/seq after 02550 batchs: 356.4976806640625
INFO:root:Train (Epoch 310): Loss/seq after 02600 batchs: 352.9601745605469
INFO:root:Train (Epoch 310): Loss/seq after 02650 batchs: 349.67633056640625
INFO:root:Train (Epoch 310): Loss/seq after 02700 batchs: 347.4117736816406
INFO:root:Train (Epoch 310): Loss/seq after 02750 batchs: 343.7430419921875
INFO:root:Train (Epoch 310): Loss/seq after 02800 batchs: 342.4029846191406
INFO:root:Train (Epoch 310): Loss/seq after 02850 batchs: 342.10443115234375
INFO:root:Train (Epoch 310): Loss/seq after 02900 batchs: 342.90655517578125
INFO:root:Train (Epoch 310): Loss/seq after 02950 batchs: 343.6640319824219
INFO:root:Train (Epoch 310): Loss/seq after 03000 batchs: 347.0528869628906
INFO:root:Train (Epoch 310): Loss/seq after 03050 batchs: 349.0187072753906
INFO:root:Train (Epoch 310): Loss/seq after 03100 batchs: 350.3486633300781
INFO:root:Train (Epoch 310): Loss/seq after 03150 batchs: 350.0661315917969
INFO:root:Train (Epoch 310): Loss/seq after 03200 batchs: 349.73431396484375
INFO:root:Train (Epoch 310): Loss/seq after 03250 batchs: 349.42181396484375
INFO:root:Train (Epoch 310): Loss/seq after 03300 batchs: 348.7911682128906
INFO:root:Train (Epoch 310): Loss/seq after 03350 batchs: 347.2001647949219
INFO:root:Train (Epoch 310): Loss/seq after 03400 batchs: 345.22216796875
INFO:root:Train (Epoch 310): Loss/seq after 03450 batchs: 344.42626953125
INFO:root:Train (Epoch 310): Loss/seq after 03500 batchs: 345.37548828125
INFO:root:Train (Epoch 310): Loss/seq after 03550 batchs: 344.009521484375
INFO:root:Train (Epoch 310): Loss/seq after 03600 batchs: 347.389892578125
INFO:root:Train (Epoch 310): Loss/seq after 03650 batchs: 346.5549621582031
INFO:root:Train (Epoch 310): Loss/seq after 03700 batchs: 349.1845397949219
INFO:root:Train (Epoch 310): Loss/seq after 03750 batchs: 352.9070129394531
INFO:root:Train (Epoch 310): Loss/seq after 03800 batchs: 352.6251525878906
INFO:root:Train (Epoch 310): Loss/seq after 03850 batchs: 352.8544006347656
INFO:root:Train (Epoch 310): Loss/seq after 03900 batchs: 354.0646057128906
INFO:root:Train (Epoch 310): Loss/seq after 03950 batchs: 356.789306640625
INFO:root:Train (Epoch 310): Loss/seq after 04000 batchs: 354.8223571777344
INFO:root:Train (Epoch 310): Loss/seq after 04050 batchs: 352.9726867675781
INFO:root:Train (Epoch 310): Loss/seq after 04100 batchs: 352.33331298828125
INFO:root:Train (Epoch 310): Loss/seq after 04150 batchs: 352.5190124511719
INFO:root:Train (Epoch 310): Loss/seq after 04200 batchs: 351.91925048828125
INFO:root:Train (Epoch 310): Loss/seq after 04250 batchs: 351.15673828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 310): Loss/seq after 00000 batches: 393.31787109375
INFO:root:# Valid (Epoch 310): Loss/seq after 00050 batches: 721.9544677734375
INFO:root:# Valid (Epoch 310): Loss/seq after 00100 batches: 675.59765625
INFO:root:# Valid (Epoch 310): Loss/seq after 00150 batches: 503.2151794433594
INFO:root:# Valid (Epoch 310): Loss/seq after 00200 batches: 459.16094970703125
INFO:root:Artifacts: Make stick videos for epoch 310
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_310_on_20220423_215116.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_310_index_889_on_20220423_215116.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 311): Loss/seq after 00000 batchs: 555.1981201171875
INFO:root:Train (Epoch 311): Loss/seq after 00050 batchs: 460.5833435058594
INFO:root:Train (Epoch 311): Loss/seq after 00100 batchs: 468.55938720703125
INFO:root:Train (Epoch 311): Loss/seq after 00150 batchs: 438.9215087890625
INFO:root:Train (Epoch 311): Loss/seq after 00200 batchs: 501.7270812988281
INFO:root:Train (Epoch 311): Loss/seq after 00250 batchs: 521.526611328125
INFO:root:Train (Epoch 311): Loss/seq after 00300 batchs: 538.8842163085938
INFO:root:Train (Epoch 311): Loss/seq after 00350 batchs: 512.494140625
INFO:root:Train (Epoch 311): Loss/seq after 00400 batchs: 503.462158203125
INFO:root:Train (Epoch 311): Loss/seq after 00450 batchs: 514.3648681640625
INFO:root:Train (Epoch 311): Loss/seq after 00500 batchs: 501.2691345214844
INFO:root:Train (Epoch 311): Loss/seq after 00550 batchs: 491.7274169921875
INFO:root:Train (Epoch 311): Loss/seq after 00600 batchs: 475.64630126953125
INFO:root:Train (Epoch 311): Loss/seq after 00650 batchs: 457.85076904296875
INFO:root:Train (Epoch 311): Loss/seq after 00700 batchs: 438.941162109375
INFO:root:Train (Epoch 311): Loss/seq after 00750 batchs: 432.8294982910156
INFO:root:Train (Epoch 311): Loss/seq after 00800 batchs: 434.64483642578125
INFO:root:Train (Epoch 311): Loss/seq after 00850 batchs: 421.5633850097656
INFO:root:Train (Epoch 311): Loss/seq after 00900 batchs: 411.189453125
INFO:root:Train (Epoch 311): Loss/seq after 00950 batchs: 409.31158447265625
INFO:root:Train (Epoch 311): Loss/seq after 01000 batchs: 402.1781311035156
INFO:root:Train (Epoch 311): Loss/seq after 01050 batchs: 395.2990417480469
INFO:root:Train (Epoch 311): Loss/seq after 01100 batchs: 386.7742919921875
INFO:root:Train (Epoch 311): Loss/seq after 01150 batchs: 376.70111083984375
INFO:root:Train (Epoch 311): Loss/seq after 01200 batchs: 378.6289367675781
INFO:root:Train (Epoch 311): Loss/seq after 01250 batchs: 377.5946350097656
INFO:root:Train (Epoch 311): Loss/seq after 01300 batchs: 369.8369445800781
INFO:root:Train (Epoch 311): Loss/seq after 01350 batchs: 362.0686340332031
INFO:root:Train (Epoch 311): Loss/seq after 01400 batchs: 363.8558044433594
INFO:root:Train (Epoch 311): Loss/seq after 01450 batchs: 367.2144470214844
INFO:root:Train (Epoch 311): Loss/seq after 01500 batchs: 372.7940368652344
INFO:root:Train (Epoch 311): Loss/seq after 01550 batchs: 374.2109375
INFO:root:Train (Epoch 311): Loss/seq after 01600 batchs: 372.5381164550781
INFO:root:Train (Epoch 311): Loss/seq after 01650 batchs: 371.0638732910156
INFO:root:Train (Epoch 311): Loss/seq after 01700 batchs: 374.3413391113281
INFO:root:Train (Epoch 311): Loss/seq after 01750 batchs: 373.5196533203125
INFO:root:Train (Epoch 311): Loss/seq after 01800 batchs: 372.0140075683594
INFO:root:Train (Epoch 311): Loss/seq after 01850 batchs: 370.0617370605469
INFO:root:Train (Epoch 311): Loss/seq after 01900 batchs: 369.2313537597656
INFO:root:Train (Epoch 311): Loss/seq after 01950 batchs: 369.090576171875
INFO:root:Train (Epoch 311): Loss/seq after 02000 batchs: 370.7555236816406
INFO:root:Train (Epoch 311): Loss/seq after 02050 batchs: 370.64971923828125
INFO:root:Train (Epoch 311): Loss/seq after 02100 batchs: 369.90087890625
INFO:root:Train (Epoch 311): Loss/seq after 02150 batchs: 369.5526123046875
INFO:root:Train (Epoch 311): Loss/seq after 02200 batchs: 368.8127136230469
INFO:root:Train (Epoch 311): Loss/seq after 02250 batchs: 368.352783203125
INFO:root:Train (Epoch 311): Loss/seq after 02300 batchs: 365.72625732421875
INFO:root:Train (Epoch 311): Loss/seq after 02350 batchs: 363.862060546875
INFO:root:Train (Epoch 311): Loss/seq after 02400 batchs: 365.0229187011719
INFO:root:Train (Epoch 311): Loss/seq after 02450 batchs: 362.21881103515625
INFO:root:Train (Epoch 311): Loss/seq after 02500 batchs: 356.4006042480469
INFO:root:Train (Epoch 311): Loss/seq after 02550 batchs: 351.80633544921875
INFO:root:Train (Epoch 311): Loss/seq after 02600 batchs: 348.11236572265625
INFO:root:Train (Epoch 311): Loss/seq after 02650 batchs: 344.7875671386719
INFO:root:Train (Epoch 311): Loss/seq after 02700 batchs: 342.8215026855469
INFO:root:Train (Epoch 311): Loss/seq after 02750 batchs: 339.31988525390625
INFO:root:Train (Epoch 311): Loss/seq after 02800 batchs: 337.7394714355469
INFO:root:Train (Epoch 311): Loss/seq after 02850 batchs: 337.54779052734375
INFO:root:Train (Epoch 311): Loss/seq after 02900 batchs: 338.2162170410156
INFO:root:Train (Epoch 311): Loss/seq after 02950 batchs: 339.06524658203125
INFO:root:Train (Epoch 311): Loss/seq after 03000 batchs: 342.8997802734375
INFO:root:Train (Epoch 311): Loss/seq after 03050 batchs: 344.60418701171875
INFO:root:Train (Epoch 311): Loss/seq after 03100 batchs: 345.5741882324219
INFO:root:Train (Epoch 311): Loss/seq after 03150 batchs: 345.2414245605469
INFO:root:Train (Epoch 311): Loss/seq after 03200 batchs: 344.92962646484375
INFO:root:Train (Epoch 311): Loss/seq after 03250 batchs: 344.74310302734375
INFO:root:Train (Epoch 311): Loss/seq after 03300 batchs: 344.1542663574219
INFO:root:Train (Epoch 311): Loss/seq after 03350 batchs: 342.40911865234375
INFO:root:Train (Epoch 311): Loss/seq after 03400 batchs: 340.4295654296875
INFO:root:Train (Epoch 311): Loss/seq after 03450 batchs: 339.6199035644531
INFO:root:Train (Epoch 311): Loss/seq after 03500 batchs: 340.7278747558594
INFO:root:Train (Epoch 311): Loss/seq after 03550 batchs: 339.4029846191406
INFO:root:Train (Epoch 311): Loss/seq after 03600 batchs: 342.1224670410156
INFO:root:Train (Epoch 311): Loss/seq after 03650 batchs: 340.87115478515625
INFO:root:Train (Epoch 311): Loss/seq after 03700 batchs: 342.68267822265625
INFO:root:Train (Epoch 311): Loss/seq after 03750 batchs: 346.12506103515625
INFO:root:Train (Epoch 311): Loss/seq after 03800 batchs: 345.9305725097656
INFO:root:Train (Epoch 311): Loss/seq after 03850 batchs: 345.5646057128906
INFO:root:Train (Epoch 311): Loss/seq after 03900 batchs: 346.8534851074219
INFO:root:Train (Epoch 311): Loss/seq after 03950 batchs: 349.6282043457031
INFO:root:Train (Epoch 311): Loss/seq after 04000 batchs: 347.6861572265625
INFO:root:Train (Epoch 311): Loss/seq after 04050 batchs: 345.8795471191406
INFO:root:Train (Epoch 311): Loss/seq after 04100 batchs: 345.0471496582031
INFO:root:Train (Epoch 311): Loss/seq after 04150 batchs: 345.28662109375
INFO:root:Train (Epoch 311): Loss/seq after 04200 batchs: 344.70233154296875
INFO:root:Train (Epoch 311): Loss/seq after 04250 batchs: 343.8913879394531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 311): Loss/seq after 00000 batches: 322.0592346191406
INFO:root:# Valid (Epoch 311): Loss/seq after 00050 batches: 684.9341430664062
INFO:root:# Valid (Epoch 311): Loss/seq after 00100 batches: 656.322265625
INFO:root:# Valid (Epoch 311): Loss/seq after 00150 batches: 489.2095947265625
INFO:root:# Valid (Epoch 311): Loss/seq after 00200 batches: 448.7804870605469
INFO:root:Artifacts: Make stick videos for epoch 311
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_311_on_20220423_215620.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_311_index_1487_on_20220423_215620.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 312): Loss/seq after 00000 batchs: 443.7876281738281
INFO:root:Train (Epoch 312): Loss/seq after 00050 batchs: 453.6144714355469
INFO:root:Train (Epoch 312): Loss/seq after 00100 batchs: 464.8765869140625
INFO:root:Train (Epoch 312): Loss/seq after 00150 batchs: 433.1192321777344
INFO:root:Train (Epoch 312): Loss/seq after 00200 batchs: 502.828857421875
INFO:root:Train (Epoch 312): Loss/seq after 00250 batchs: 524.7753295898438
INFO:root:Train (Epoch 312): Loss/seq after 00300 batchs: 539.2509765625
INFO:root:Train (Epoch 312): Loss/seq after 00350 batchs: 513.3128051757812
INFO:root:Train (Epoch 312): Loss/seq after 00400 batchs: 504.6592712402344
INFO:root:Train (Epoch 312): Loss/seq after 00450 batchs: 515.240478515625
INFO:root:Train (Epoch 312): Loss/seq after 00500 batchs: 502.52252197265625
INFO:root:Train (Epoch 312): Loss/seq after 00550 batchs: 492.93414306640625
INFO:root:Train (Epoch 312): Loss/seq after 00600 batchs: 476.6564025878906
INFO:root:Train (Epoch 312): Loss/seq after 00650 batchs: 460.0876159667969
INFO:root:Train (Epoch 312): Loss/seq after 00700 batchs: 441.5943908691406
INFO:root:Train (Epoch 312): Loss/seq after 00750 batchs: 437.0860290527344
INFO:root:Train (Epoch 312): Loss/seq after 00800 batchs: 437.8924560546875
INFO:root:Train (Epoch 312): Loss/seq after 00850 batchs: 424.2241516113281
INFO:root:Train (Epoch 312): Loss/seq after 00900 batchs: 413.37066650390625
INFO:root:Train (Epoch 312): Loss/seq after 00950 batchs: 410.99432373046875
INFO:root:Train (Epoch 312): Loss/seq after 01000 batchs: 405.0752258300781
INFO:root:Train (Epoch 312): Loss/seq after 01050 batchs: 396.91607666015625
INFO:root:Train (Epoch 312): Loss/seq after 01100 batchs: 388.0586242675781
INFO:root:Train (Epoch 312): Loss/seq after 01150 batchs: 377.8786926269531
INFO:root:Train (Epoch 312): Loss/seq after 01200 batchs: 378.79144287109375
INFO:root:Train (Epoch 312): Loss/seq after 01250 batchs: 378.0083312988281
INFO:root:Train (Epoch 312): Loss/seq after 01300 batchs: 370.0114440917969
INFO:root:Train (Epoch 312): Loss/seq after 01350 batchs: 361.94891357421875
INFO:root:Train (Epoch 312): Loss/seq after 01400 batchs: 363.40802001953125
INFO:root:Train (Epoch 312): Loss/seq after 01450 batchs: 366.668701171875
INFO:root:Train (Epoch 312): Loss/seq after 01500 batchs: 372.24871826171875
INFO:root:Train (Epoch 312): Loss/seq after 01550 batchs: 372.6148681640625
INFO:root:Train (Epoch 312): Loss/seq after 01600 batchs: 370.8521423339844
INFO:root:Train (Epoch 312): Loss/seq after 01650 batchs: 369.26708984375
INFO:root:Train (Epoch 312): Loss/seq after 01700 batchs: 373.4917297363281
INFO:root:Train (Epoch 312): Loss/seq after 01750 batchs: 373.113037109375
INFO:root:Train (Epoch 312): Loss/seq after 01800 batchs: 371.615478515625
INFO:root:Train (Epoch 312): Loss/seq after 01850 batchs: 369.7185363769531
INFO:root:Train (Epoch 312): Loss/seq after 01900 batchs: 368.89642333984375
INFO:root:Train (Epoch 312): Loss/seq after 01950 batchs: 368.7841491699219
INFO:root:Train (Epoch 312): Loss/seq after 02000 batchs: 370.46600341796875
INFO:root:Train (Epoch 312): Loss/seq after 02050 batchs: 370.5032653808594
INFO:root:Train (Epoch 312): Loss/seq after 02100 batchs: 369.7769775390625
INFO:root:Train (Epoch 312): Loss/seq after 02150 batchs: 369.3408203125
INFO:root:Train (Epoch 312): Loss/seq after 02200 batchs: 368.69134521484375
INFO:root:Train (Epoch 312): Loss/seq after 02250 batchs: 367.8421936035156
INFO:root:Train (Epoch 312): Loss/seq after 02300 batchs: 365.46533203125
INFO:root:Train (Epoch 312): Loss/seq after 02350 batchs: 363.1258239746094
INFO:root:Train (Epoch 312): Loss/seq after 02400 batchs: 364.1035461425781
INFO:root:Train (Epoch 312): Loss/seq after 02450 batchs: 361.239013671875
INFO:root:Train (Epoch 312): Loss/seq after 02500 batchs: 355.3861083984375
INFO:root:Train (Epoch 312): Loss/seq after 02550 batchs: 350.6575012207031
INFO:root:Train (Epoch 312): Loss/seq after 02600 batchs: 347.2460021972656
INFO:root:Train (Epoch 312): Loss/seq after 02650 batchs: 344.0979309082031
INFO:root:Train (Epoch 312): Loss/seq after 02700 batchs: 342.0565185546875
INFO:root:Train (Epoch 312): Loss/seq after 02750 batchs: 338.3297424316406
INFO:root:Train (Epoch 312): Loss/seq after 02800 batchs: 336.9680480957031
INFO:root:Train (Epoch 312): Loss/seq after 02850 batchs: 336.6097106933594
INFO:root:Train (Epoch 312): Loss/seq after 02900 batchs: 337.06866455078125
INFO:root:Train (Epoch 312): Loss/seq after 02950 batchs: 337.9177551269531
INFO:root:Train (Epoch 312): Loss/seq after 03000 batchs: 341.7064514160156
INFO:root:Train (Epoch 312): Loss/seq after 03050 batchs: 343.4251403808594
INFO:root:Train (Epoch 312): Loss/seq after 03100 batchs: 345.4654541015625
INFO:root:Train (Epoch 312): Loss/seq after 03150 batchs: 345.3737487792969
INFO:root:Train (Epoch 312): Loss/seq after 03200 batchs: 345.0912170410156
INFO:root:Train (Epoch 312): Loss/seq after 03250 batchs: 344.955078125
INFO:root:Train (Epoch 312): Loss/seq after 03300 batchs: 344.3659362792969
INFO:root:Train (Epoch 312): Loss/seq after 03350 batchs: 342.54974365234375
INFO:root:Train (Epoch 312): Loss/seq after 03400 batchs: 340.5584411621094
INFO:root:Train (Epoch 312): Loss/seq after 03450 batchs: 339.817626953125
INFO:root:Train (Epoch 312): Loss/seq after 03500 batchs: 341.15771484375
INFO:root:Train (Epoch 312): Loss/seq after 03550 batchs: 339.9001770019531
INFO:root:Train (Epoch 312): Loss/seq after 03600 batchs: 342.42938232421875
INFO:root:Train (Epoch 312): Loss/seq after 03650 batchs: 341.09429931640625
INFO:root:Train (Epoch 312): Loss/seq after 03700 batchs: 343.0854187011719
INFO:root:Train (Epoch 312): Loss/seq after 03750 batchs: 346.3070373535156
INFO:root:Train (Epoch 312): Loss/seq after 03800 batchs: 346.11669921875
INFO:root:Train (Epoch 312): Loss/seq after 03850 batchs: 345.8816223144531
INFO:root:Train (Epoch 312): Loss/seq after 03900 batchs: 346.8822937011719
INFO:root:Train (Epoch 312): Loss/seq after 03950 batchs: 349.41802978515625
INFO:root:Train (Epoch 312): Loss/seq after 04000 batchs: 347.5115966796875
INFO:root:Train (Epoch 312): Loss/seq after 04050 batchs: 345.71881103515625
INFO:root:Train (Epoch 312): Loss/seq after 04100 batchs: 344.8817443847656
INFO:root:Train (Epoch 312): Loss/seq after 04150 batchs: 345.25128173828125
INFO:root:Train (Epoch 312): Loss/seq after 04200 batchs: 344.6966857910156
INFO:root:Train (Epoch 312): Loss/seq after 04250 batchs: 343.8489074707031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 312): Loss/seq after 00000 batches: 433.6890563964844
INFO:root:# Valid (Epoch 312): Loss/seq after 00050 batches: 687.3057250976562
INFO:root:# Valid (Epoch 312): Loss/seq after 00100 batches: 655.0486450195312
INFO:root:# Valid (Epoch 312): Loss/seq after 00150 batches: 490.9272155761719
INFO:root:# Valid (Epoch 312): Loss/seq after 00200 batches: 451.5240173339844
INFO:root:Artifacts: Make stick videos for epoch 312
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_312_on_20220423_220107.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_312_index_1895_on_20220423_220107.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 313): Loss/seq after 00000 batchs: 546.20751953125
INFO:root:Train (Epoch 313): Loss/seq after 00050 batchs: 482.46368408203125
INFO:root:Train (Epoch 313): Loss/seq after 00100 batchs: 482.2059020996094
INFO:root:Train (Epoch 313): Loss/seq after 00150 batchs: 443.86041259765625
INFO:root:Train (Epoch 313): Loss/seq after 00200 batchs: 506.6081237792969
INFO:root:Train (Epoch 313): Loss/seq after 00250 batchs: 529.7149047851562
INFO:root:Train (Epoch 313): Loss/seq after 00300 batchs: 543.9503784179688
INFO:root:Train (Epoch 313): Loss/seq after 00350 batchs: 517.1193237304688
INFO:root:Train (Epoch 313): Loss/seq after 00400 batchs: 503.6124267578125
INFO:root:Train (Epoch 313): Loss/seq after 00450 batchs: 513.7453002929688
INFO:root:Train (Epoch 313): Loss/seq after 00500 batchs: 495.7354431152344
INFO:root:Train (Epoch 313): Loss/seq after 00550 batchs: 484.878173828125
INFO:root:Train (Epoch 313): Loss/seq after 00600 batchs: 468.5563049316406
INFO:root:Train (Epoch 313): Loss/seq after 00650 batchs: 450.3897705078125
INFO:root:Train (Epoch 313): Loss/seq after 00700 batchs: 431.54351806640625
INFO:root:Train (Epoch 313): Loss/seq after 00750 batchs: 427.912109375
INFO:root:Train (Epoch 313): Loss/seq after 00800 batchs: 431.0086669921875
INFO:root:Train (Epoch 313): Loss/seq after 00850 batchs: 417.7751770019531
INFO:root:Train (Epoch 313): Loss/seq after 00900 batchs: 407.0014953613281
INFO:root:Train (Epoch 313): Loss/seq after 00950 batchs: 404.7084655761719
INFO:root:Train (Epoch 313): Loss/seq after 01000 batchs: 397.8665466308594
INFO:root:Train (Epoch 313): Loss/seq after 01050 batchs: 389.8224792480469
INFO:root:Train (Epoch 313): Loss/seq after 01100 batchs: 381.2579650878906
INFO:root:Train (Epoch 313): Loss/seq after 01150 batchs: 371.26202392578125
INFO:root:Train (Epoch 313): Loss/seq after 01200 batchs: 371.8736267089844
INFO:root:Train (Epoch 313): Loss/seq after 01250 batchs: 371.2566833496094
INFO:root:Train (Epoch 313): Loss/seq after 01300 batchs: 364.04266357421875
INFO:root:Train (Epoch 313): Loss/seq after 01350 batchs: 356.2646179199219
INFO:root:Train (Epoch 313): Loss/seq after 01400 batchs: 356.82745361328125
INFO:root:Train (Epoch 313): Loss/seq after 01450 batchs: 360.03564453125
INFO:root:Train (Epoch 313): Loss/seq after 01500 batchs: 365.9418029785156
INFO:root:Train (Epoch 313): Loss/seq after 01550 batchs: 367.0995178222656
INFO:root:Train (Epoch 313): Loss/seq after 01600 batchs: 365.424072265625
INFO:root:Train (Epoch 313): Loss/seq after 01650 batchs: 363.99908447265625
INFO:root:Train (Epoch 313): Loss/seq after 01700 batchs: 367.12506103515625
INFO:root:Train (Epoch 313): Loss/seq after 01750 batchs: 366.8330993652344
INFO:root:Train (Epoch 313): Loss/seq after 01800 batchs: 365.67706298828125
INFO:root:Train (Epoch 313): Loss/seq after 01850 batchs: 364.0672302246094
INFO:root:Train (Epoch 313): Loss/seq after 01900 batchs: 363.3476867675781
INFO:root:Train (Epoch 313): Loss/seq after 01950 batchs: 363.57501220703125
INFO:root:Train (Epoch 313): Loss/seq after 02000 batchs: 365.2493591308594
INFO:root:Train (Epoch 313): Loss/seq after 02050 batchs: 365.4454345703125
INFO:root:Train (Epoch 313): Loss/seq after 02100 batchs: 364.9001159667969
INFO:root:Train (Epoch 313): Loss/seq after 02150 batchs: 364.5326843261719
INFO:root:Train (Epoch 313): Loss/seq after 02200 batchs: 363.88055419921875
INFO:root:Train (Epoch 313): Loss/seq after 02250 batchs: 363.05682373046875
INFO:root:Train (Epoch 313): Loss/seq after 02300 batchs: 361.05889892578125
INFO:root:Train (Epoch 313): Loss/seq after 02350 batchs: 359.0116271972656
INFO:root:Train (Epoch 313): Loss/seq after 02400 batchs: 360.09765625
INFO:root:Train (Epoch 313): Loss/seq after 02450 batchs: 357.292236328125
INFO:root:Train (Epoch 313): Loss/seq after 02500 batchs: 351.5453186035156
INFO:root:Train (Epoch 313): Loss/seq after 02550 batchs: 346.97320556640625
INFO:root:Train (Epoch 313): Loss/seq after 02600 batchs: 343.35693359375
INFO:root:Train (Epoch 313): Loss/seq after 02650 batchs: 340.0673522949219
INFO:root:Train (Epoch 313): Loss/seq after 02700 batchs: 338.14764404296875
INFO:root:Train (Epoch 313): Loss/seq after 02750 batchs: 334.4877014160156
INFO:root:Train (Epoch 313): Loss/seq after 02800 batchs: 334.1495056152344
INFO:root:Train (Epoch 313): Loss/seq after 02850 batchs: 333.81231689453125
INFO:root:Train (Epoch 313): Loss/seq after 02900 batchs: 334.59686279296875
INFO:root:Train (Epoch 313): Loss/seq after 02950 batchs: 335.4151306152344
INFO:root:Train (Epoch 313): Loss/seq after 03000 batchs: 338.75665283203125
INFO:root:Train (Epoch 313): Loss/seq after 03050 batchs: 340.5924377441406
INFO:root:Train (Epoch 313): Loss/seq after 03100 batchs: 342.1665954589844
INFO:root:Train (Epoch 313): Loss/seq after 03150 batchs: 342.23858642578125
INFO:root:Train (Epoch 313): Loss/seq after 03200 batchs: 342.1123962402344
INFO:root:Train (Epoch 313): Loss/seq after 03250 batchs: 342.0966491699219
INFO:root:Train (Epoch 313): Loss/seq after 03300 batchs: 341.4892578125
INFO:root:Train (Epoch 313): Loss/seq after 03350 batchs: 340.13934326171875
INFO:root:Train (Epoch 313): Loss/seq after 03400 batchs: 338.2086181640625
INFO:root:Train (Epoch 313): Loss/seq after 03450 batchs: 337.4648742675781
INFO:root:Train (Epoch 313): Loss/seq after 03500 batchs: 338.58001708984375
INFO:root:Train (Epoch 313): Loss/seq after 03550 batchs: 337.33465576171875
INFO:root:Train (Epoch 313): Loss/seq after 03600 batchs: 340.0886535644531
INFO:root:Train (Epoch 313): Loss/seq after 03650 batchs: 338.9028625488281
INFO:root:Train (Epoch 313): Loss/seq after 03700 batchs: 341.177001953125
INFO:root:Train (Epoch 313): Loss/seq after 03750 batchs: 344.66094970703125
INFO:root:Train (Epoch 313): Loss/seq after 03800 batchs: 344.4437561035156
INFO:root:Train (Epoch 313): Loss/seq after 03850 batchs: 344.0699462890625
INFO:root:Train (Epoch 313): Loss/seq after 03900 batchs: 345.1575927734375
INFO:root:Train (Epoch 313): Loss/seq after 03950 batchs: 347.40655517578125
INFO:root:Train (Epoch 313): Loss/seq after 04000 batchs: 345.5235595703125
INFO:root:Train (Epoch 313): Loss/seq after 04050 batchs: 343.7165832519531
INFO:root:Train (Epoch 313): Loss/seq after 04100 batchs: 342.80780029296875
INFO:root:Train (Epoch 313): Loss/seq after 04150 batchs: 343.0277404785156
INFO:root:Train (Epoch 313): Loss/seq after 04200 batchs: 342.6144104003906
INFO:root:Train (Epoch 313): Loss/seq after 04250 batchs: 341.9012756347656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 313): Loss/seq after 00000 batches: 436.3490905761719
INFO:root:# Valid (Epoch 313): Loss/seq after 00050 batches: 731.0375366210938
INFO:root:# Valid (Epoch 313): Loss/seq after 00100 batches: 731.7224731445312
INFO:root:# Valid (Epoch 313): Loss/seq after 00150 batches: 541.9189453125
INFO:root:# Valid (Epoch 313): Loss/seq after 00200 batches: 489.34075927734375
INFO:root:Artifacts: Make stick videos for epoch 313
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_313_on_20220423_220608.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_313_index_504_on_20220423_220608.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 314): Loss/seq after 00000 batchs: 652.533935546875
INFO:root:Train (Epoch 314): Loss/seq after 00050 batchs: 462.84576416015625
INFO:root:Train (Epoch 314): Loss/seq after 00100 batchs: 473.67724609375
INFO:root:Train (Epoch 314): Loss/seq after 00150 batchs: 437.06182861328125
INFO:root:Train (Epoch 314): Loss/seq after 00200 batchs: 502.51031494140625
INFO:root:Train (Epoch 314): Loss/seq after 00250 batchs: 518.767333984375
INFO:root:Train (Epoch 314): Loss/seq after 00300 batchs: 535.5263671875
INFO:root:Train (Epoch 314): Loss/seq after 00350 batchs: 510.60101318359375
INFO:root:Train (Epoch 314): Loss/seq after 00400 batchs: 501.9533996582031
INFO:root:Train (Epoch 314): Loss/seq after 00450 batchs: 512.0584716796875
INFO:root:Train (Epoch 314): Loss/seq after 00500 batchs: 495.4998779296875
INFO:root:Train (Epoch 314): Loss/seq after 00550 batchs: 486.1264343261719
INFO:root:Train (Epoch 314): Loss/seq after 00600 batchs: 469.2412109375
INFO:root:Train (Epoch 314): Loss/seq after 00650 batchs: 451.8432312011719
INFO:root:Train (Epoch 314): Loss/seq after 00700 batchs: 433.1658020019531
INFO:root:Train (Epoch 314): Loss/seq after 00750 batchs: 426.7055358886719
INFO:root:Train (Epoch 314): Loss/seq after 00800 batchs: 428.37506103515625
INFO:root:Train (Epoch 314): Loss/seq after 00850 batchs: 415.53497314453125
INFO:root:Train (Epoch 314): Loss/seq after 00900 batchs: 405.27423095703125
INFO:root:Train (Epoch 314): Loss/seq after 00950 batchs: 402.7550048828125
INFO:root:Train (Epoch 314): Loss/seq after 01000 batchs: 396.27752685546875
INFO:root:Train (Epoch 314): Loss/seq after 01050 batchs: 388.0348205566406
INFO:root:Train (Epoch 314): Loss/seq after 01100 batchs: 378.74102783203125
INFO:root:Train (Epoch 314): Loss/seq after 01150 batchs: 368.99871826171875
INFO:root:Train (Epoch 314): Loss/seq after 01200 batchs: 370.9327087402344
INFO:root:Train (Epoch 314): Loss/seq after 01250 batchs: 370.1313171386719
INFO:root:Train (Epoch 314): Loss/seq after 01300 batchs: 362.8614807128906
INFO:root:Train (Epoch 314): Loss/seq after 01350 batchs: 355.0732421875
INFO:root:Train (Epoch 314): Loss/seq after 01400 batchs: 355.9036560058594
INFO:root:Train (Epoch 314): Loss/seq after 01450 batchs: 359.27081298828125
INFO:root:Train (Epoch 314): Loss/seq after 01500 batchs: 365.5202941894531
INFO:root:Train (Epoch 314): Loss/seq after 01550 batchs: 366.93756103515625
INFO:root:Train (Epoch 314): Loss/seq after 01600 batchs: 365.44610595703125
INFO:root:Train (Epoch 314): Loss/seq after 01650 batchs: 363.74481201171875
INFO:root:Train (Epoch 314): Loss/seq after 01700 batchs: 367.906982421875
INFO:root:Train (Epoch 314): Loss/seq after 01750 batchs: 368.0477294921875
INFO:root:Train (Epoch 314): Loss/seq after 01800 batchs: 367.1365661621094
INFO:root:Train (Epoch 314): Loss/seq after 01850 batchs: 365.37213134765625
INFO:root:Train (Epoch 314): Loss/seq after 01900 batchs: 364.7299499511719
INFO:root:Train (Epoch 314): Loss/seq after 01950 batchs: 364.5658264160156
INFO:root:Train (Epoch 314): Loss/seq after 02000 batchs: 366.20819091796875
INFO:root:Train (Epoch 314): Loss/seq after 02050 batchs: 366.1501159667969
INFO:root:Train (Epoch 314): Loss/seq after 02100 batchs: 365.51080322265625
INFO:root:Train (Epoch 314): Loss/seq after 02150 batchs: 365.34619140625
INFO:root:Train (Epoch 314): Loss/seq after 02200 batchs: 364.59716796875
INFO:root:Train (Epoch 314): Loss/seq after 02250 batchs: 363.7275085449219
INFO:root:Train (Epoch 314): Loss/seq after 02300 batchs: 360.9205627441406
INFO:root:Train (Epoch 314): Loss/seq after 02350 batchs: 358.6426696777344
INFO:root:Train (Epoch 314): Loss/seq after 02400 batchs: 359.86138916015625
INFO:root:Train (Epoch 314): Loss/seq after 02450 batchs: 357.0081481933594
INFO:root:Train (Epoch 314): Loss/seq after 02500 batchs: 351.2669982910156
INFO:root:Train (Epoch 314): Loss/seq after 02550 batchs: 346.6575012207031
INFO:root:Train (Epoch 314): Loss/seq after 02600 batchs: 343.0980224609375
INFO:root:Train (Epoch 314): Loss/seq after 02650 batchs: 339.8265075683594
INFO:root:Train (Epoch 314): Loss/seq after 02700 batchs: 337.9520263671875
INFO:root:Train (Epoch 314): Loss/seq after 02750 batchs: 334.0416259765625
INFO:root:Train (Epoch 314): Loss/seq after 02800 batchs: 332.347900390625
INFO:root:Train (Epoch 314): Loss/seq after 02850 batchs: 332.2962951660156
INFO:root:Train (Epoch 314): Loss/seq after 02900 batchs: 332.9497375488281
INFO:root:Train (Epoch 314): Loss/seq after 02950 batchs: 333.7940673828125
INFO:root:Train (Epoch 314): Loss/seq after 03000 batchs: 337.31927490234375
INFO:root:Train (Epoch 314): Loss/seq after 03050 batchs: 338.79248046875
INFO:root:Train (Epoch 314): Loss/seq after 03100 batchs: 340.8060607910156
INFO:root:Train (Epoch 314): Loss/seq after 03150 batchs: 341.0310974121094
INFO:root:Train (Epoch 314): Loss/seq after 03200 batchs: 340.7171630859375
INFO:root:Train (Epoch 314): Loss/seq after 03250 batchs: 340.71112060546875
INFO:root:Train (Epoch 314): Loss/seq after 03300 batchs: 340.35205078125
INFO:root:Train (Epoch 314): Loss/seq after 03350 batchs: 338.9444580078125
INFO:root:Train (Epoch 314): Loss/seq after 03400 batchs: 337.15289306640625
INFO:root:Train (Epoch 314): Loss/seq after 03450 batchs: 336.4061279296875
INFO:root:Train (Epoch 314): Loss/seq after 03500 batchs: 337.4016418457031
INFO:root:Train (Epoch 314): Loss/seq after 03550 batchs: 336.1825866699219
INFO:root:Train (Epoch 314): Loss/seq after 03600 batchs: 338.78729248046875
INFO:root:Train (Epoch 314): Loss/seq after 03650 batchs: 337.5570983886719
INFO:root:Train (Epoch 314): Loss/seq after 03700 batchs: 339.2464294433594
INFO:root:Train (Epoch 314): Loss/seq after 03750 batchs: 342.4659423828125
INFO:root:Train (Epoch 314): Loss/seq after 03800 batchs: 342.25494384765625
INFO:root:Train (Epoch 314): Loss/seq after 03850 batchs: 341.8970642089844
INFO:root:Train (Epoch 314): Loss/seq after 03900 batchs: 343.2520751953125
INFO:root:Train (Epoch 314): Loss/seq after 03950 batchs: 345.59918212890625
INFO:root:Train (Epoch 314): Loss/seq after 04000 batchs: 343.7318115234375
INFO:root:Train (Epoch 314): Loss/seq after 04050 batchs: 341.927734375
INFO:root:Train (Epoch 314): Loss/seq after 04100 batchs: 341.0644836425781
INFO:root:Train (Epoch 314): Loss/seq after 04150 batchs: 341.2815856933594
INFO:root:Train (Epoch 314): Loss/seq after 04200 batchs: 340.7974548339844
INFO:root:Train (Epoch 314): Loss/seq after 04250 batchs: 340.029052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 314): Loss/seq after 00000 batches: 383.5909729003906
INFO:root:# Valid (Epoch 314): Loss/seq after 00050 batches: 710.7290649414062
INFO:root:# Valid (Epoch 314): Loss/seq after 00100 batches: 685.4627075195312
INFO:root:# Valid (Epoch 314): Loss/seq after 00150 batches: 514.884765625
INFO:root:# Valid (Epoch 314): Loss/seq after 00200 batches: 470.5389709472656
INFO:root:Artifacts: Make stick videos for epoch 314
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_314_on_20220423_221057.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_314_index_305_on_20220423_221057.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 315): Loss/seq after 00000 batchs: 461.4653625488281
INFO:root:Train (Epoch 315): Loss/seq after 00050 batchs: 480.1564636230469
INFO:root:Train (Epoch 315): Loss/seq after 00100 batchs: 468.8602294921875
INFO:root:Train (Epoch 315): Loss/seq after 00150 batchs: 434.8551330566406
INFO:root:Train (Epoch 315): Loss/seq after 00200 batchs: 486.05035400390625
INFO:root:Train (Epoch 315): Loss/seq after 00250 batchs: 499.59429931640625
INFO:root:Train (Epoch 315): Loss/seq after 00300 batchs: 519.104248046875
INFO:root:Train (Epoch 315): Loss/seq after 00350 batchs: 496.58685302734375
INFO:root:Train (Epoch 315): Loss/seq after 00400 batchs: 487.68011474609375
INFO:root:Train (Epoch 315): Loss/seq after 00450 batchs: 499.54437255859375
INFO:root:Train (Epoch 315): Loss/seq after 00500 batchs: 483.5487365722656
INFO:root:Train (Epoch 315): Loss/seq after 00550 batchs: 475.0881042480469
INFO:root:Train (Epoch 315): Loss/seq after 00600 batchs: 460.0887451171875
INFO:root:Train (Epoch 315): Loss/seq after 00650 batchs: 445.71746826171875
INFO:root:Train (Epoch 315): Loss/seq after 00700 batchs: 427.7625427246094
INFO:root:Train (Epoch 315): Loss/seq after 00750 batchs: 421.7986755371094
INFO:root:Train (Epoch 315): Loss/seq after 00800 batchs: 425.1033630371094
INFO:root:Train (Epoch 315): Loss/seq after 00850 batchs: 412.5352478027344
INFO:root:Train (Epoch 315): Loss/seq after 00900 batchs: 402.6227722167969
INFO:root:Train (Epoch 315): Loss/seq after 00950 batchs: 400.93658447265625
INFO:root:Train (Epoch 315): Loss/seq after 01000 batchs: 394.46905517578125
INFO:root:Train (Epoch 315): Loss/seq after 01050 batchs: 386.5424499511719
INFO:root:Train (Epoch 315): Loss/seq after 01100 batchs: 377.7808837890625
INFO:root:Train (Epoch 315): Loss/seq after 01150 batchs: 368.0054016113281
INFO:root:Train (Epoch 315): Loss/seq after 01200 batchs: 368.2615051269531
INFO:root:Train (Epoch 315): Loss/seq after 01250 batchs: 367.83795166015625
INFO:root:Train (Epoch 315): Loss/seq after 01300 batchs: 360.1957092285156
INFO:root:Train (Epoch 315): Loss/seq after 01350 batchs: 352.97698974609375
INFO:root:Train (Epoch 315): Loss/seq after 01400 batchs: 354.69586181640625
INFO:root:Train (Epoch 315): Loss/seq after 01450 batchs: 357.84429931640625
INFO:root:Train (Epoch 315): Loss/seq after 01500 batchs: 364.0315246582031
INFO:root:Train (Epoch 315): Loss/seq after 01550 batchs: 364.8197021484375
INFO:root:Train (Epoch 315): Loss/seq after 01600 batchs: 363.8554992675781
INFO:root:Train (Epoch 315): Loss/seq after 01650 batchs: 362.2198181152344
INFO:root:Train (Epoch 315): Loss/seq after 01700 batchs: 365.5779724121094
INFO:root:Train (Epoch 315): Loss/seq after 01750 batchs: 365.1647033691406
INFO:root:Train (Epoch 315): Loss/seq after 01800 batchs: 363.923095703125
INFO:root:Train (Epoch 315): Loss/seq after 01850 batchs: 362.2764892578125
INFO:root:Train (Epoch 315): Loss/seq after 01900 batchs: 361.6357421875
INFO:root:Train (Epoch 315): Loss/seq after 01950 batchs: 361.9881896972656
INFO:root:Train (Epoch 315): Loss/seq after 02000 batchs: 363.68890380859375
INFO:root:Train (Epoch 315): Loss/seq after 02050 batchs: 364.02642822265625
INFO:root:Train (Epoch 315): Loss/seq after 02100 batchs: 363.56787109375
INFO:root:Train (Epoch 315): Loss/seq after 02150 batchs: 363.37042236328125
INFO:root:Train (Epoch 315): Loss/seq after 02200 batchs: 362.6834716796875
INFO:root:Train (Epoch 315): Loss/seq after 02250 batchs: 361.86199951171875
INFO:root:Train (Epoch 315): Loss/seq after 02300 batchs: 359.548095703125
INFO:root:Train (Epoch 315): Loss/seq after 02350 batchs: 357.2896728515625
INFO:root:Train (Epoch 315): Loss/seq after 02400 batchs: 358.3460693359375
INFO:root:Train (Epoch 315): Loss/seq after 02450 batchs: 355.6165466308594
INFO:root:Train (Epoch 315): Loss/seq after 02500 batchs: 349.9791564941406
INFO:root:Train (Epoch 315): Loss/seq after 02550 batchs: 345.3956604003906
INFO:root:Train (Epoch 315): Loss/seq after 02600 batchs: 341.8304138183594
INFO:root:Train (Epoch 315): Loss/seq after 02650 batchs: 338.5113525390625
INFO:root:Train (Epoch 315): Loss/seq after 02700 batchs: 336.30096435546875
INFO:root:Train (Epoch 315): Loss/seq after 02750 batchs: 332.7125244140625
INFO:root:Train (Epoch 315): Loss/seq after 02800 batchs: 331.32623291015625
INFO:root:Train (Epoch 315): Loss/seq after 02850 batchs: 331.0172424316406
INFO:root:Train (Epoch 315): Loss/seq after 02900 batchs: 331.8357238769531
INFO:root:Train (Epoch 315): Loss/seq after 02950 batchs: 332.9747619628906
INFO:root:Train (Epoch 315): Loss/seq after 03000 batchs: 336.36248779296875
INFO:root:Train (Epoch 315): Loss/seq after 03050 batchs: 337.83001708984375
INFO:root:Train (Epoch 315): Loss/seq after 03100 batchs: 339.7861022949219
INFO:root:Train (Epoch 315): Loss/seq after 03150 batchs: 340.1103820800781
INFO:root:Train (Epoch 315): Loss/seq after 03200 batchs: 339.96636962890625
INFO:root:Train (Epoch 315): Loss/seq after 03250 batchs: 340.0168762207031
INFO:root:Train (Epoch 315): Loss/seq after 03300 batchs: 340.1712951660156
INFO:root:Train (Epoch 315): Loss/seq after 03350 batchs: 338.4942626953125
INFO:root:Train (Epoch 315): Loss/seq after 03400 batchs: 336.5934143066406
INFO:root:Train (Epoch 315): Loss/seq after 03450 batchs: 335.77740478515625
INFO:root:Train (Epoch 315): Loss/seq after 03500 batchs: 337.1047058105469
INFO:root:Train (Epoch 315): Loss/seq after 03550 batchs: 335.86279296875
INFO:root:Train (Epoch 315): Loss/seq after 03600 batchs: 338.621826171875
INFO:root:Train (Epoch 315): Loss/seq after 03650 batchs: 337.402099609375
INFO:root:Train (Epoch 315): Loss/seq after 03700 batchs: 339.19720458984375
INFO:root:Train (Epoch 315): Loss/seq after 03750 batchs: 342.4838562011719
INFO:root:Train (Epoch 315): Loss/seq after 03800 batchs: 342.347900390625
INFO:root:Train (Epoch 315): Loss/seq after 03850 batchs: 341.99114990234375
INFO:root:Train (Epoch 315): Loss/seq after 03900 batchs: 343.41278076171875
INFO:root:Train (Epoch 315): Loss/seq after 03950 batchs: 346.10107421875
INFO:root:Train (Epoch 315): Loss/seq after 04000 batchs: 344.23455810546875
INFO:root:Train (Epoch 315): Loss/seq after 04050 batchs: 342.4277038574219
INFO:root:Train (Epoch 315): Loss/seq after 04100 batchs: 341.5551452636719
INFO:root:Train (Epoch 315): Loss/seq after 04150 batchs: 341.8387756347656
INFO:root:Train (Epoch 315): Loss/seq after 04200 batchs: 341.2768249511719
INFO:root:Train (Epoch 315): Loss/seq after 04250 batchs: 340.44873046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 315): Loss/seq after 00000 batches: 409.60675048828125
INFO:root:# Valid (Epoch 315): Loss/seq after 00050 batches: 690.3784790039062
INFO:root:# Valid (Epoch 315): Loss/seq after 00100 batches: 656.8275146484375
INFO:root:# Valid (Epoch 315): Loss/seq after 00150 batches: 489.9997863769531
INFO:root:# Valid (Epoch 315): Loss/seq after 00200 batches: 450.6056213378906
INFO:root:Artifacts: Make stick videos for epoch 315
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_315_on_20220423_221551.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_315_index_1599_on_20220423_221551.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 316): Loss/seq after 00000 batchs: 534.3272705078125
INFO:root:Train (Epoch 316): Loss/seq after 00050 batchs: 438.2615051269531
INFO:root:Train (Epoch 316): Loss/seq after 00100 batchs: 463.814208984375
INFO:root:Train (Epoch 316): Loss/seq after 00150 batchs: 432.396484375
INFO:root:Train (Epoch 316): Loss/seq after 00200 batchs: 499.8045654296875
INFO:root:Train (Epoch 316): Loss/seq after 00250 batchs: 526.4568481445312
INFO:root:Train (Epoch 316): Loss/seq after 00300 batchs: 540.0277709960938
INFO:root:Train (Epoch 316): Loss/seq after 00350 batchs: 513.2905883789062
INFO:root:Train (Epoch 316): Loss/seq after 00400 batchs: 506.626953125
INFO:root:Train (Epoch 316): Loss/seq after 00450 batchs: 516.8115844726562
INFO:root:Train (Epoch 316): Loss/seq after 00500 batchs: 501.6678466796875
INFO:root:Train (Epoch 316): Loss/seq after 00550 batchs: 492.0507507324219
INFO:root:Train (Epoch 316): Loss/seq after 00600 batchs: 475.3297424316406
INFO:root:Train (Epoch 316): Loss/seq after 00650 batchs: 457.5505065917969
INFO:root:Train (Epoch 316): Loss/seq after 00700 batchs: 439.5840759277344
INFO:root:Train (Epoch 316): Loss/seq after 00750 batchs: 434.15106201171875
INFO:root:Train (Epoch 316): Loss/seq after 00800 batchs: 436.5032043457031
INFO:root:Train (Epoch 316): Loss/seq after 00850 batchs: 423.1383361816406
INFO:root:Train (Epoch 316): Loss/seq after 00900 batchs: 411.828857421875
INFO:root:Train (Epoch 316): Loss/seq after 00950 batchs: 410.04327392578125
INFO:root:Train (Epoch 316): Loss/seq after 01000 batchs: 402.669921875
INFO:root:Train (Epoch 316): Loss/seq after 01050 batchs: 394.24322509765625
INFO:root:Train (Epoch 316): Loss/seq after 01100 batchs: 385.20849609375
INFO:root:Train (Epoch 316): Loss/seq after 01150 batchs: 375.1443176269531
INFO:root:Train (Epoch 316): Loss/seq after 01200 batchs: 375.269287109375
INFO:root:Train (Epoch 316): Loss/seq after 01250 batchs: 374.27044677734375
INFO:root:Train (Epoch 316): Loss/seq after 01300 batchs: 366.5179443359375
INFO:root:Train (Epoch 316): Loss/seq after 01350 batchs: 358.7996520996094
INFO:root:Train (Epoch 316): Loss/seq after 01400 batchs: 360.509033203125
INFO:root:Train (Epoch 316): Loss/seq after 01450 batchs: 363.840576171875
INFO:root:Train (Epoch 316): Loss/seq after 01500 batchs: 369.7891845703125
INFO:root:Train (Epoch 316): Loss/seq after 01550 batchs: 370.54541015625
INFO:root:Train (Epoch 316): Loss/seq after 01600 batchs: 368.8215026855469
INFO:root:Train (Epoch 316): Loss/seq after 01650 batchs: 367.34454345703125
INFO:root:Train (Epoch 316): Loss/seq after 01700 batchs: 370.78985595703125
INFO:root:Train (Epoch 316): Loss/seq after 01750 batchs: 370.09002685546875
INFO:root:Train (Epoch 316): Loss/seq after 01800 batchs: 368.5660400390625
INFO:root:Train (Epoch 316): Loss/seq after 01850 batchs: 366.6639099121094
INFO:root:Train (Epoch 316): Loss/seq after 01900 batchs: 365.8279724121094
INFO:root:Train (Epoch 316): Loss/seq after 01950 batchs: 366.2622985839844
INFO:root:Train (Epoch 316): Loss/seq after 02000 batchs: 367.7992248535156
INFO:root:Train (Epoch 316): Loss/seq after 02050 batchs: 367.8767395019531
INFO:root:Train (Epoch 316): Loss/seq after 02100 batchs: 367.3319091796875
INFO:root:Train (Epoch 316): Loss/seq after 02150 batchs: 367.1402587890625
INFO:root:Train (Epoch 316): Loss/seq after 02200 batchs: 366.4383850097656
INFO:root:Train (Epoch 316): Loss/seq after 02250 batchs: 365.5753173828125
INFO:root:Train (Epoch 316): Loss/seq after 02300 batchs: 362.92889404296875
INFO:root:Train (Epoch 316): Loss/seq after 02350 batchs: 360.62744140625
INFO:root:Train (Epoch 316): Loss/seq after 02400 batchs: 361.6371765136719
INFO:root:Train (Epoch 316): Loss/seq after 02450 batchs: 358.7991638183594
INFO:root:Train (Epoch 316): Loss/seq after 02500 batchs: 353.0185546875
INFO:root:Train (Epoch 316): Loss/seq after 02550 batchs: 348.26129150390625
INFO:root:Train (Epoch 316): Loss/seq after 02600 batchs: 344.6376953125
INFO:root:Train (Epoch 316): Loss/seq after 02650 batchs: 341.6065979003906
INFO:root:Train (Epoch 316): Loss/seq after 02700 batchs: 339.52862548828125
INFO:root:Train (Epoch 316): Loss/seq after 02750 batchs: 335.4676208496094
INFO:root:Train (Epoch 316): Loss/seq after 02800 batchs: 333.96807861328125
INFO:root:Train (Epoch 316): Loss/seq after 02850 batchs: 333.6966857910156
INFO:root:Train (Epoch 316): Loss/seq after 02900 batchs: 334.32342529296875
INFO:root:Train (Epoch 316): Loss/seq after 02950 batchs: 335.24029541015625
INFO:root:Train (Epoch 316): Loss/seq after 03000 batchs: 338.2923889160156
INFO:root:Train (Epoch 316): Loss/seq after 03050 batchs: 339.5340881347656
INFO:root:Train (Epoch 316): Loss/seq after 03100 batchs: 342.00140380859375
INFO:root:Train (Epoch 316): Loss/seq after 03150 batchs: 342.1161193847656
INFO:root:Train (Epoch 316): Loss/seq after 03200 batchs: 342.174560546875
INFO:root:Train (Epoch 316): Loss/seq after 03250 batchs: 342.3504638671875
INFO:root:Train (Epoch 316): Loss/seq after 03300 batchs: 342.4143981933594
INFO:root:Train (Epoch 316): Loss/seq after 03350 batchs: 340.6903991699219
INFO:root:Train (Epoch 316): Loss/seq after 03400 batchs: 338.74493408203125
INFO:root:Train (Epoch 316): Loss/seq after 03450 batchs: 337.9220275878906
INFO:root:Train (Epoch 316): Loss/seq after 03500 batchs: 338.5586853027344
INFO:root:Train (Epoch 316): Loss/seq after 03550 batchs: 337.1065673828125
INFO:root:Train (Epoch 316): Loss/seq after 03600 batchs: 339.5117492675781
INFO:root:Train (Epoch 316): Loss/seq after 03650 batchs: 338.64544677734375
INFO:root:Train (Epoch 316): Loss/seq after 03700 batchs: 340.44976806640625
INFO:root:Train (Epoch 316): Loss/seq after 03750 batchs: 343.6576843261719
INFO:root:Train (Epoch 316): Loss/seq after 03800 batchs: 343.4217529296875
INFO:root:Train (Epoch 316): Loss/seq after 03850 batchs: 343.0136413574219
INFO:root:Train (Epoch 316): Loss/seq after 03900 batchs: 344.2516784667969
INFO:root:Train (Epoch 316): Loss/seq after 03950 batchs: 346.74822998046875
INFO:root:Train (Epoch 316): Loss/seq after 04000 batchs: 344.8901062011719
INFO:root:Train (Epoch 316): Loss/seq after 04050 batchs: 343.08184814453125
INFO:root:Train (Epoch 316): Loss/seq after 04100 batchs: 342.1222229003906
INFO:root:Train (Epoch 316): Loss/seq after 04150 batchs: 342.3121337890625
INFO:root:Train (Epoch 316): Loss/seq after 04200 batchs: 341.9515380859375
INFO:root:Train (Epoch 316): Loss/seq after 04250 batchs: 341.1826477050781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 316): Loss/seq after 00000 batches: 402.5011291503906
INFO:root:# Valid (Epoch 316): Loss/seq after 00050 batches: 702.238525390625
INFO:root:# Valid (Epoch 316): Loss/seq after 00100 batches: 770.9571533203125
INFO:root:# Valid (Epoch 316): Loss/seq after 00150 batches: 567.123779296875
INFO:root:# Valid (Epoch 316): Loss/seq after 00200 batches: 508.9970703125
INFO:root:Artifacts: Make stick videos for epoch 316
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_316_on_20220423_222055.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_316_index_133_on_20220423_222055.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 317): Loss/seq after 00000 batchs: 482.17071533203125
INFO:root:Train (Epoch 317): Loss/seq after 00050 batchs: 442.10211181640625
INFO:root:Train (Epoch 317): Loss/seq after 00100 batchs: 442.26763916015625
INFO:root:Train (Epoch 317): Loss/seq after 00150 batchs: 415.697998046875
INFO:root:Train (Epoch 317): Loss/seq after 00200 batchs: 475.2082824707031
INFO:root:Train (Epoch 317): Loss/seq after 00250 batchs: 500.20135498046875
INFO:root:Train (Epoch 317): Loss/seq after 00300 batchs: 520.7828979492188
INFO:root:Train (Epoch 317): Loss/seq after 00350 batchs: 499.00372314453125
INFO:root:Train (Epoch 317): Loss/seq after 00400 batchs: 488.376220703125
INFO:root:Train (Epoch 317): Loss/seq after 00450 batchs: 500.36474609375
INFO:root:Train (Epoch 317): Loss/seq after 00500 batchs: 486.7051086425781
INFO:root:Train (Epoch 317): Loss/seq after 00550 batchs: 477.6670837402344
INFO:root:Train (Epoch 317): Loss/seq after 00600 batchs: 461.5319519042969
INFO:root:Train (Epoch 317): Loss/seq after 00650 batchs: 443.9110107421875
INFO:root:Train (Epoch 317): Loss/seq after 00700 batchs: 426.45892333984375
INFO:root:Train (Epoch 317): Loss/seq after 00750 batchs: 421.1277770996094
INFO:root:Train (Epoch 317): Loss/seq after 00800 batchs: 422.4892578125
INFO:root:Train (Epoch 317): Loss/seq after 00850 batchs: 409.4916076660156
INFO:root:Train (Epoch 317): Loss/seq after 00900 batchs: 399.07513427734375
INFO:root:Train (Epoch 317): Loss/seq after 00950 batchs: 397.69415283203125
INFO:root:Train (Epoch 317): Loss/seq after 01000 batchs: 391.12066650390625
INFO:root:Train (Epoch 317): Loss/seq after 01050 batchs: 383.7766418457031
INFO:root:Train (Epoch 317): Loss/seq after 01100 batchs: 375.3539733886719
INFO:root:Train (Epoch 317): Loss/seq after 01150 batchs: 365.72735595703125
INFO:root:Train (Epoch 317): Loss/seq after 01200 batchs: 366.5679626464844
INFO:root:Train (Epoch 317): Loss/seq after 01250 batchs: 365.9552001953125
INFO:root:Train (Epoch 317): Loss/seq after 01300 batchs: 358.2767333984375
INFO:root:Train (Epoch 317): Loss/seq after 01350 batchs: 350.7953796386719
INFO:root:Train (Epoch 317): Loss/seq after 01400 batchs: 353.1073913574219
INFO:root:Train (Epoch 317): Loss/seq after 01450 batchs: 356.6344909667969
INFO:root:Train (Epoch 317): Loss/seq after 01500 batchs: 362.3390808105469
INFO:root:Train (Epoch 317): Loss/seq after 01550 batchs: 363.2163391113281
INFO:root:Train (Epoch 317): Loss/seq after 01600 batchs: 361.6632385253906
INFO:root:Train (Epoch 317): Loss/seq after 01650 batchs: 360.244384765625
INFO:root:Train (Epoch 317): Loss/seq after 01700 batchs: 363.1693115234375
INFO:root:Train (Epoch 317): Loss/seq after 01750 batchs: 362.60540771484375
INFO:root:Train (Epoch 317): Loss/seq after 01800 batchs: 361.1688537597656
INFO:root:Train (Epoch 317): Loss/seq after 01850 batchs: 359.5914306640625
INFO:root:Train (Epoch 317): Loss/seq after 01900 batchs: 358.9395446777344
INFO:root:Train (Epoch 317): Loss/seq after 01950 batchs: 358.99786376953125
INFO:root:Train (Epoch 317): Loss/seq after 02000 batchs: 360.8897705078125
INFO:root:Train (Epoch 317): Loss/seq after 02050 batchs: 361.1671447753906
INFO:root:Train (Epoch 317): Loss/seq after 02100 batchs: 360.6377868652344
INFO:root:Train (Epoch 317): Loss/seq after 02150 batchs: 360.488037109375
INFO:root:Train (Epoch 317): Loss/seq after 02200 batchs: 359.875732421875
INFO:root:Train (Epoch 317): Loss/seq after 02250 batchs: 359.2649230957031
INFO:root:Train (Epoch 317): Loss/seq after 02300 batchs: 356.97332763671875
INFO:root:Train (Epoch 317): Loss/seq after 02350 batchs: 354.810302734375
INFO:root:Train (Epoch 317): Loss/seq after 02400 batchs: 355.8883361816406
INFO:root:Train (Epoch 317): Loss/seq after 02450 batchs: 353.2416076660156
INFO:root:Train (Epoch 317): Loss/seq after 02500 batchs: 347.5436706542969
INFO:root:Train (Epoch 317): Loss/seq after 02550 batchs: 342.89056396484375
INFO:root:Train (Epoch 317): Loss/seq after 02600 batchs: 339.4490966796875
INFO:root:Train (Epoch 317): Loss/seq after 02650 batchs: 336.1482849121094
INFO:root:Train (Epoch 317): Loss/seq after 02700 batchs: 334.0635681152344
INFO:root:Train (Epoch 317): Loss/seq after 02750 batchs: 330.4572448730469
INFO:root:Train (Epoch 317): Loss/seq after 02800 batchs: 329.4915771484375
INFO:root:Train (Epoch 317): Loss/seq after 02850 batchs: 329.32366943359375
INFO:root:Train (Epoch 317): Loss/seq after 02900 batchs: 329.9920959472656
INFO:root:Train (Epoch 317): Loss/seq after 02950 batchs: 330.908935546875
INFO:root:Train (Epoch 317): Loss/seq after 03000 batchs: 334.374267578125
INFO:root:Train (Epoch 317): Loss/seq after 03050 batchs: 335.8584289550781
INFO:root:Train (Epoch 317): Loss/seq after 03100 batchs: 337.5616149902344
INFO:root:Train (Epoch 317): Loss/seq after 03150 batchs: 337.08929443359375
INFO:root:Train (Epoch 317): Loss/seq after 03200 batchs: 336.8872375488281
INFO:root:Train (Epoch 317): Loss/seq after 03250 batchs: 336.9636535644531
INFO:root:Train (Epoch 317): Loss/seq after 03300 batchs: 336.4764099121094
INFO:root:Train (Epoch 317): Loss/seq after 03350 batchs: 335.1997985839844
INFO:root:Train (Epoch 317): Loss/seq after 03400 batchs: 333.3150939941406
INFO:root:Train (Epoch 317): Loss/seq after 03450 batchs: 332.6055603027344
INFO:root:Train (Epoch 317): Loss/seq after 03500 batchs: 333.4864807128906
INFO:root:Train (Epoch 317): Loss/seq after 03550 batchs: 332.1822204589844
INFO:root:Train (Epoch 317): Loss/seq after 03600 batchs: 334.6517333984375
INFO:root:Train (Epoch 317): Loss/seq after 03650 batchs: 333.55206298828125
INFO:root:Train (Epoch 317): Loss/seq after 03700 batchs: 335.1376647949219
INFO:root:Train (Epoch 317): Loss/seq after 03750 batchs: 338.4255676269531
INFO:root:Train (Epoch 317): Loss/seq after 03800 batchs: 338.3894348144531
INFO:root:Train (Epoch 317): Loss/seq after 03850 batchs: 338.0072021484375
INFO:root:Train (Epoch 317): Loss/seq after 03900 batchs: 339.09808349609375
INFO:root:Train (Epoch 317): Loss/seq after 03950 batchs: 341.67022705078125
INFO:root:Train (Epoch 317): Loss/seq after 04000 batchs: 339.8450927734375
INFO:root:Train (Epoch 317): Loss/seq after 04050 batchs: 338.0871887207031
INFO:root:Train (Epoch 317): Loss/seq after 04100 batchs: 337.3345642089844
INFO:root:Train (Epoch 317): Loss/seq after 04150 batchs: 337.6152038574219
INFO:root:Train (Epoch 317): Loss/seq after 04200 batchs: 337.1895751953125
INFO:root:Train (Epoch 317): Loss/seq after 04250 batchs: 336.4482116699219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 317): Loss/seq after 00000 batches: 372.37841796875
INFO:root:# Valid (Epoch 317): Loss/seq after 00050 batches: 688.41552734375
INFO:root:# Valid (Epoch 317): Loss/seq after 00100 batches: 719.229248046875
INFO:root:# Valid (Epoch 317): Loss/seq after 00150 batches: 533.3859252929688
INFO:root:# Valid (Epoch 317): Loss/seq after 00200 batches: 482.594970703125
INFO:root:Artifacts: Make stick videos for epoch 317
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_317_on_20220423_222558.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_317_index_1683_on_20220423_222558.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 318): Loss/seq after 00000 batchs: 480.8916931152344
INFO:root:Train (Epoch 318): Loss/seq after 00050 batchs: 462.46295166015625
INFO:root:Train (Epoch 318): Loss/seq after 00100 batchs: 472.56817626953125
INFO:root:Train (Epoch 318): Loss/seq after 00150 batchs: 437.7997131347656
INFO:root:Train (Epoch 318): Loss/seq after 00200 batchs: 492.2919006347656
INFO:root:Train (Epoch 318): Loss/seq after 00250 batchs: 503.2281188964844
INFO:root:Train (Epoch 318): Loss/seq after 00300 batchs: 519.165283203125
INFO:root:Train (Epoch 318): Loss/seq after 00350 batchs: 495.4358825683594
INFO:root:Train (Epoch 318): Loss/seq after 00400 batchs: 482.03021240234375
INFO:root:Train (Epoch 318): Loss/seq after 00450 batchs: 493.9725341796875
INFO:root:Train (Epoch 318): Loss/seq after 00500 batchs: 480.0402526855469
INFO:root:Train (Epoch 318): Loss/seq after 00550 batchs: 471.729248046875
INFO:root:Train (Epoch 318): Loss/seq after 00600 batchs: 456.1272888183594
INFO:root:Train (Epoch 318): Loss/seq after 00650 batchs: 439.7445373535156
INFO:root:Train (Epoch 318): Loss/seq after 00700 batchs: 421.55645751953125
INFO:root:Train (Epoch 318): Loss/seq after 00750 batchs: 414.63372802734375
INFO:root:Train (Epoch 318): Loss/seq after 00800 batchs: 416.9949951171875
INFO:root:Train (Epoch 318): Loss/seq after 00850 batchs: 403.9480285644531
INFO:root:Train (Epoch 318): Loss/seq after 00900 batchs: 393.712158203125
INFO:root:Train (Epoch 318): Loss/seq after 00950 batchs: 392.0987854003906
INFO:root:Train (Epoch 318): Loss/seq after 01000 batchs: 385.98870849609375
INFO:root:Train (Epoch 318): Loss/seq after 01050 batchs: 378.0010070800781
INFO:root:Train (Epoch 318): Loss/seq after 01100 batchs: 369.2057800292969
INFO:root:Train (Epoch 318): Loss/seq after 01150 batchs: 359.5453796386719
INFO:root:Train (Epoch 318): Loss/seq after 01200 batchs: 359.32049560546875
INFO:root:Train (Epoch 318): Loss/seq after 01250 batchs: 358.8260498046875
INFO:root:Train (Epoch 318): Loss/seq after 01300 batchs: 351.646484375
INFO:root:Train (Epoch 318): Loss/seq after 01350 batchs: 344.5350646972656
INFO:root:Train (Epoch 318): Loss/seq after 01400 batchs: 346.6116027832031
INFO:root:Train (Epoch 318): Loss/seq after 01450 batchs: 349.7693786621094
INFO:root:Train (Epoch 318): Loss/seq after 01500 batchs: 355.8078308105469
INFO:root:Train (Epoch 318): Loss/seq after 01550 batchs: 356.9794921875
INFO:root:Train (Epoch 318): Loss/seq after 01600 batchs: 355.65887451171875
INFO:root:Train (Epoch 318): Loss/seq after 01650 batchs: 354.51617431640625
INFO:root:Train (Epoch 318): Loss/seq after 01700 batchs: 356.8718566894531
INFO:root:Train (Epoch 318): Loss/seq after 01750 batchs: 356.634033203125
INFO:root:Train (Epoch 318): Loss/seq after 01800 batchs: 355.45623779296875
INFO:root:Train (Epoch 318): Loss/seq after 01850 batchs: 353.9571228027344
INFO:root:Train (Epoch 318): Loss/seq after 01900 batchs: 353.3913269042969
INFO:root:Train (Epoch 318): Loss/seq after 01950 batchs: 353.7012939453125
INFO:root:Train (Epoch 318): Loss/seq after 02000 batchs: 355.569580078125
INFO:root:Train (Epoch 318): Loss/seq after 02050 batchs: 355.8258361816406
INFO:root:Train (Epoch 318): Loss/seq after 02100 batchs: 355.5385437011719
INFO:root:Train (Epoch 318): Loss/seq after 02150 batchs: 355.3639831542969
INFO:root:Train (Epoch 318): Loss/seq after 02200 batchs: 354.8169250488281
INFO:root:Train (Epoch 318): Loss/seq after 02250 batchs: 354.4243469238281
INFO:root:Train (Epoch 318): Loss/seq after 02300 batchs: 352.23162841796875
INFO:root:Train (Epoch 318): Loss/seq after 02350 batchs: 350.1888122558594
INFO:root:Train (Epoch 318): Loss/seq after 02400 batchs: 351.3418273925781
INFO:root:Train (Epoch 318): Loss/seq after 02450 batchs: 348.739013671875
INFO:root:Train (Epoch 318): Loss/seq after 02500 batchs: 343.21234130859375
INFO:root:Train (Epoch 318): Loss/seq after 02550 batchs: 338.7067565917969
INFO:root:Train (Epoch 318): Loss/seq after 02600 batchs: 335.3456726074219
INFO:root:Train (Epoch 318): Loss/seq after 02650 batchs: 332.1120910644531
INFO:root:Train (Epoch 318): Loss/seq after 02700 batchs: 330.1459655761719
INFO:root:Train (Epoch 318): Loss/seq after 02750 batchs: 326.5680236816406
INFO:root:Train (Epoch 318): Loss/seq after 02800 batchs: 325.5039367675781
INFO:root:Train (Epoch 318): Loss/seq after 02850 batchs: 325.32171630859375
INFO:root:Train (Epoch 318): Loss/seq after 02900 batchs: 325.8836669921875
INFO:root:Train (Epoch 318): Loss/seq after 02950 batchs: 326.8221740722656
INFO:root:Train (Epoch 318): Loss/seq after 03000 batchs: 330.26220703125
INFO:root:Train (Epoch 318): Loss/seq after 03050 batchs: 331.659912109375
INFO:root:Train (Epoch 318): Loss/seq after 03100 batchs: 333.3049011230469
INFO:root:Train (Epoch 318): Loss/seq after 03150 batchs: 333.4292907714844
INFO:root:Train (Epoch 318): Loss/seq after 03200 batchs: 333.36431884765625
INFO:root:Train (Epoch 318): Loss/seq after 03250 batchs: 333.4908142089844
INFO:root:Train (Epoch 318): Loss/seq after 03300 batchs: 333.1719665527344
INFO:root:Train (Epoch 318): Loss/seq after 03350 batchs: 331.4831848144531
INFO:root:Train (Epoch 318): Loss/seq after 03400 batchs: 329.7469482421875
INFO:root:Train (Epoch 318): Loss/seq after 03450 batchs: 328.8632507324219
INFO:root:Train (Epoch 318): Loss/seq after 03500 batchs: 330.29046630859375
INFO:root:Train (Epoch 318): Loss/seq after 03550 batchs: 329.171630859375
INFO:root:Train (Epoch 318): Loss/seq after 03600 batchs: 332.0266418457031
INFO:root:Train (Epoch 318): Loss/seq after 03650 batchs: 330.8349304199219
INFO:root:Train (Epoch 318): Loss/seq after 03700 batchs: 332.6878356933594
INFO:root:Train (Epoch 318): Loss/seq after 03750 batchs: 335.85504150390625
INFO:root:Train (Epoch 318): Loss/seq after 03800 batchs: 335.8204345703125
INFO:root:Train (Epoch 318): Loss/seq after 03850 batchs: 335.506591796875
INFO:root:Train (Epoch 318): Loss/seq after 03900 batchs: 337.0191650390625
INFO:root:Train (Epoch 318): Loss/seq after 03950 batchs: 339.2558288574219
INFO:root:Train (Epoch 318): Loss/seq after 04000 batchs: 337.4674377441406
INFO:root:Train (Epoch 318): Loss/seq after 04050 batchs: 335.7622375488281
INFO:root:Train (Epoch 318): Loss/seq after 04100 batchs: 335.01953125
INFO:root:Train (Epoch 318): Loss/seq after 04150 batchs: 335.3124084472656
INFO:root:Train (Epoch 318): Loss/seq after 04200 batchs: 334.8985900878906
INFO:root:Train (Epoch 318): Loss/seq after 04250 batchs: 334.15789794921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 318): Loss/seq after 00000 batches: 376.9801025390625
INFO:root:# Valid (Epoch 318): Loss/seq after 00050 batches: 694.2330932617188
INFO:root:# Valid (Epoch 318): Loss/seq after 00100 batches: 739.7998657226562
INFO:root:# Valid (Epoch 318): Loss/seq after 00150 batches: 544.6004638671875
INFO:root:# Valid (Epoch 318): Loss/seq after 00200 batches: 492.4857482910156
INFO:root:Artifacts: Make stick videos for epoch 318
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_318_on_20220423_223101.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_318_index_217_on_20220423_223101.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 319): Loss/seq after 00000 batchs: 595.3043212890625
INFO:root:Train (Epoch 319): Loss/seq after 00050 batchs: 460.5052185058594
INFO:root:Train (Epoch 319): Loss/seq after 00100 batchs: 467.970458984375
INFO:root:Train (Epoch 319): Loss/seq after 00150 batchs: 434.5785827636719
INFO:root:Train (Epoch 319): Loss/seq after 00200 batchs: 483.7651062011719
INFO:root:Train (Epoch 319): Loss/seq after 00250 batchs: 495.25543212890625
INFO:root:Train (Epoch 319): Loss/seq after 00300 batchs: 516.5977783203125
INFO:root:Train (Epoch 319): Loss/seq after 00350 batchs: 492.97894287109375
INFO:root:Train (Epoch 319): Loss/seq after 00400 batchs: 481.1481628417969
INFO:root:Train (Epoch 319): Loss/seq after 00450 batchs: 493.1944885253906
INFO:root:Train (Epoch 319): Loss/seq after 00500 batchs: 477.0750427246094
INFO:root:Train (Epoch 319): Loss/seq after 00550 batchs: 468.77606201171875
INFO:root:Train (Epoch 319): Loss/seq after 00600 batchs: 453.93853759765625
INFO:root:Train (Epoch 319): Loss/seq after 00650 batchs: 436.3654479980469
INFO:root:Train (Epoch 319): Loss/seq after 00700 batchs: 417.92333984375
INFO:root:Train (Epoch 319): Loss/seq after 00750 batchs: 412.541259765625
INFO:root:Train (Epoch 319): Loss/seq after 00800 batchs: 414.7239685058594
INFO:root:Train (Epoch 319): Loss/seq after 00850 batchs: 402.10455322265625
INFO:root:Train (Epoch 319): Loss/seq after 00900 batchs: 391.88287353515625
INFO:root:Train (Epoch 319): Loss/seq after 00950 batchs: 391.5889587402344
INFO:root:Train (Epoch 319): Loss/seq after 01000 batchs: 386.15655517578125
INFO:root:Train (Epoch 319): Loss/seq after 01050 batchs: 379.1666564941406
INFO:root:Train (Epoch 319): Loss/seq after 01100 batchs: 371.1795349121094
INFO:root:Train (Epoch 319): Loss/seq after 01150 batchs: 361.5643005371094
INFO:root:Train (Epoch 319): Loss/seq after 01200 batchs: 362.2085266113281
INFO:root:Train (Epoch 319): Loss/seq after 01250 batchs: 361.7518310546875
INFO:root:Train (Epoch 319): Loss/seq after 01300 batchs: 354.13140869140625
INFO:root:Train (Epoch 319): Loss/seq after 01350 batchs: 346.78436279296875
INFO:root:Train (Epoch 319): Loss/seq after 01400 batchs: 348.6209716796875
INFO:root:Train (Epoch 319): Loss/seq after 01450 batchs: 351.8821105957031
INFO:root:Train (Epoch 319): Loss/seq after 01500 batchs: 357.5926513671875
INFO:root:Train (Epoch 319): Loss/seq after 01550 batchs: 359.0710754394531
INFO:root:Train (Epoch 319): Loss/seq after 01600 batchs: 357.9593505859375
INFO:root:Train (Epoch 319): Loss/seq after 01650 batchs: 356.9051818847656
INFO:root:Train (Epoch 319): Loss/seq after 01700 batchs: 359.7095947265625
INFO:root:Train (Epoch 319): Loss/seq after 01750 batchs: 359.1396484375
INFO:root:Train (Epoch 319): Loss/seq after 01800 batchs: 358.01641845703125
INFO:root:Train (Epoch 319): Loss/seq after 01850 batchs: 356.426513671875
INFO:root:Train (Epoch 319): Loss/seq after 01900 batchs: 356.0667724609375
INFO:root:Train (Epoch 319): Loss/seq after 01950 batchs: 355.99639892578125
INFO:root:Train (Epoch 319): Loss/seq after 02000 batchs: 357.88775634765625
INFO:root:Train (Epoch 319): Loss/seq after 02050 batchs: 358.0523681640625
INFO:root:Train (Epoch 319): Loss/seq after 02100 batchs: 357.5787048339844
INFO:root:Train (Epoch 319): Loss/seq after 02150 batchs: 357.4765319824219
INFO:root:Train (Epoch 319): Loss/seq after 02200 batchs: 356.7687683105469
INFO:root:Train (Epoch 319): Loss/seq after 02250 batchs: 355.9125061035156
INFO:root:Train (Epoch 319): Loss/seq after 02300 batchs: 353.61865234375
INFO:root:Train (Epoch 319): Loss/seq after 02350 batchs: 351.57879638671875
INFO:root:Train (Epoch 319): Loss/seq after 02400 batchs: 352.2554931640625
INFO:root:Train (Epoch 319): Loss/seq after 02450 batchs: 349.5736083984375
INFO:root:Train (Epoch 319): Loss/seq after 02500 batchs: 343.95660400390625
INFO:root:Train (Epoch 319): Loss/seq after 02550 batchs: 339.3254699707031
INFO:root:Train (Epoch 319): Loss/seq after 02600 batchs: 335.8658752441406
INFO:root:Train (Epoch 319): Loss/seq after 02650 batchs: 332.73876953125
INFO:root:Train (Epoch 319): Loss/seq after 02700 batchs: 330.5756530761719
INFO:root:Train (Epoch 319): Loss/seq after 02750 batchs: 326.9377136230469
INFO:root:Train (Epoch 319): Loss/seq after 02800 batchs: 325.39849853515625
INFO:root:Train (Epoch 319): Loss/seq after 02850 batchs: 325.1888122558594
INFO:root:Train (Epoch 319): Loss/seq after 02900 batchs: 325.7880859375
INFO:root:Train (Epoch 319): Loss/seq after 02950 batchs: 326.880859375
INFO:root:Train (Epoch 319): Loss/seq after 03000 batchs: 330.1388854980469
INFO:root:Train (Epoch 319): Loss/seq after 03050 batchs: 331.6531982421875
INFO:root:Train (Epoch 319): Loss/seq after 03100 batchs: 333.5258483886719
INFO:root:Train (Epoch 319): Loss/seq after 03150 batchs: 334.02197265625
INFO:root:Train (Epoch 319): Loss/seq after 03200 batchs: 334.3101806640625
INFO:root:Train (Epoch 319): Loss/seq after 03250 batchs: 335.1833190917969
INFO:root:Train (Epoch 319): Loss/seq after 03300 batchs: 334.7656555175781
INFO:root:Train (Epoch 319): Loss/seq after 03350 batchs: 333.3048400878906
INFO:root:Train (Epoch 319): Loss/seq after 03400 batchs: 331.3758850097656
INFO:root:Train (Epoch 319): Loss/seq after 03450 batchs: 330.5965881347656
INFO:root:Train (Epoch 319): Loss/seq after 03500 batchs: 331.7689208984375
INFO:root:Train (Epoch 319): Loss/seq after 03550 batchs: 330.5053405761719
INFO:root:Train (Epoch 319): Loss/seq after 03600 batchs: 333.19049072265625
INFO:root:Train (Epoch 319): Loss/seq after 03650 batchs: 332.1863098144531
INFO:root:Train (Epoch 319): Loss/seq after 03700 batchs: 334.13275146484375
INFO:root:Train (Epoch 319): Loss/seq after 03750 batchs: 337.45208740234375
INFO:root:Train (Epoch 319): Loss/seq after 03800 batchs: 337.3052978515625
INFO:root:Train (Epoch 319): Loss/seq after 03850 batchs: 336.8759765625
INFO:root:Train (Epoch 319): Loss/seq after 03900 batchs: 337.8884582519531
INFO:root:Train (Epoch 319): Loss/seq after 03950 batchs: 340.4796447753906
INFO:root:Train (Epoch 319): Loss/seq after 04000 batchs: 338.64715576171875
INFO:root:Train (Epoch 319): Loss/seq after 04050 batchs: 336.8463439941406
INFO:root:Train (Epoch 319): Loss/seq after 04100 batchs: 335.97705078125
INFO:root:Train (Epoch 319): Loss/seq after 04150 batchs: 336.17706298828125
INFO:root:Train (Epoch 319): Loss/seq after 04200 batchs: 335.57916259765625
INFO:root:Train (Epoch 319): Loss/seq after 04250 batchs: 334.86871337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 319): Loss/seq after 00000 batches: 323.40325927734375
INFO:root:# Valid (Epoch 319): Loss/seq after 00050 batches: 684.48828125
INFO:root:# Valid (Epoch 319): Loss/seq after 00100 batches: 744.318603515625
INFO:root:# Valid (Epoch 319): Loss/seq after 00150 batches: 548.4133911132812
INFO:root:# Valid (Epoch 319): Loss/seq after 00200 batches: 495.22052001953125
INFO:root:Artifacts: Make stick videos for epoch 319
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_319_on_20220423_223549.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_319_index_1759_on_20220423_223549.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 320): Loss/seq after 00000 batchs: 497.7499084472656
INFO:root:Train (Epoch 320): Loss/seq after 00050 batchs: 464.7730407714844
INFO:root:Train (Epoch 320): Loss/seq after 00100 batchs: 460.21148681640625
INFO:root:Train (Epoch 320): Loss/seq after 00150 batchs: 428.46185302734375
INFO:root:Train (Epoch 320): Loss/seq after 00200 batchs: 493.1399841308594
INFO:root:Train (Epoch 320): Loss/seq after 00250 batchs: 513.7272338867188
INFO:root:Train (Epoch 320): Loss/seq after 00300 batchs: 527.2567749023438
INFO:root:Train (Epoch 320): Loss/seq after 00350 batchs: 503.1553649902344
INFO:root:Train (Epoch 320): Loss/seq after 00400 batchs: 493.0775451660156
INFO:root:Train (Epoch 320): Loss/seq after 00450 batchs: 503.9136047363281
INFO:root:Train (Epoch 320): Loss/seq after 00500 batchs: 488.74371337890625
INFO:root:Train (Epoch 320): Loss/seq after 00550 batchs: 479.14837646484375
INFO:root:Train (Epoch 320): Loss/seq after 00600 batchs: 463.7328796386719
INFO:root:Train (Epoch 320): Loss/seq after 00650 batchs: 446.70440673828125
INFO:root:Train (Epoch 320): Loss/seq after 00700 batchs: 429.37158203125
INFO:root:Train (Epoch 320): Loss/seq after 00750 batchs: 422.85638427734375
INFO:root:Train (Epoch 320): Loss/seq after 00800 batchs: 424.116455078125
INFO:root:Train (Epoch 320): Loss/seq after 00850 batchs: 410.6539001464844
INFO:root:Train (Epoch 320): Loss/seq after 00900 batchs: 400.1353454589844
INFO:root:Train (Epoch 320): Loss/seq after 00950 batchs: 399.7503967285156
INFO:root:Train (Epoch 320): Loss/seq after 01000 batchs: 393.1368408203125
INFO:root:Train (Epoch 320): Loss/seq after 01050 batchs: 385.25665283203125
INFO:root:Train (Epoch 320): Loss/seq after 01100 batchs: 376.67144775390625
INFO:root:Train (Epoch 320): Loss/seq after 01150 batchs: 366.8356628417969
INFO:root:Train (Epoch 320): Loss/seq after 01200 batchs: 367.57586669921875
INFO:root:Train (Epoch 320): Loss/seq after 01250 batchs: 366.9237976074219
INFO:root:Train (Epoch 320): Loss/seq after 01300 batchs: 359.0877990722656
INFO:root:Train (Epoch 320): Loss/seq after 01350 batchs: 351.9228820800781
INFO:root:Train (Epoch 320): Loss/seq after 01400 batchs: 353.770751953125
INFO:root:Train (Epoch 320): Loss/seq after 01450 batchs: 356.6344299316406
INFO:root:Train (Epoch 320): Loss/seq after 01500 batchs: 362.4551696777344
INFO:root:Train (Epoch 320): Loss/seq after 01550 batchs: 363.34326171875
INFO:root:Train (Epoch 320): Loss/seq after 01600 batchs: 362.0206298828125
INFO:root:Train (Epoch 320): Loss/seq after 01650 batchs: 360.3378601074219
INFO:root:Train (Epoch 320): Loss/seq after 01700 batchs: 362.9287109375
INFO:root:Train (Epoch 320): Loss/seq after 01750 batchs: 362.07684326171875
INFO:root:Train (Epoch 320): Loss/seq after 01800 batchs: 360.6649475097656
INFO:root:Train (Epoch 320): Loss/seq after 01850 batchs: 359.1180114746094
INFO:root:Train (Epoch 320): Loss/seq after 01900 batchs: 358.3563232421875
INFO:root:Train (Epoch 320): Loss/seq after 01950 batchs: 358.59039306640625
INFO:root:Train (Epoch 320): Loss/seq after 02000 batchs: 360.3618469238281
INFO:root:Train (Epoch 320): Loss/seq after 02050 batchs: 360.4040222167969
INFO:root:Train (Epoch 320): Loss/seq after 02100 batchs: 359.8682556152344
INFO:root:Train (Epoch 320): Loss/seq after 02150 batchs: 359.6858825683594
INFO:root:Train (Epoch 320): Loss/seq after 02200 batchs: 358.87353515625
INFO:root:Train (Epoch 320): Loss/seq after 02250 batchs: 358.1576232910156
INFO:root:Train (Epoch 320): Loss/seq after 02300 batchs: 355.8597412109375
INFO:root:Train (Epoch 320): Loss/seq after 02350 batchs: 353.7963562011719
INFO:root:Train (Epoch 320): Loss/seq after 02400 batchs: 354.6700439453125
INFO:root:Train (Epoch 320): Loss/seq after 02450 batchs: 351.91497802734375
INFO:root:Train (Epoch 320): Loss/seq after 02500 batchs: 346.2182922363281
INFO:root:Train (Epoch 320): Loss/seq after 02550 batchs: 341.72332763671875
INFO:root:Train (Epoch 320): Loss/seq after 02600 batchs: 338.3427734375
INFO:root:Train (Epoch 320): Loss/seq after 02650 batchs: 335.1238098144531
INFO:root:Train (Epoch 320): Loss/seq after 02700 batchs: 332.9850769042969
INFO:root:Train (Epoch 320): Loss/seq after 02750 batchs: 329.3094177246094
INFO:root:Train (Epoch 320): Loss/seq after 02800 batchs: 327.8945007324219
INFO:root:Train (Epoch 320): Loss/seq after 02850 batchs: 327.79791259765625
INFO:root:Train (Epoch 320): Loss/seq after 02900 batchs: 328.8294982910156
INFO:root:Train (Epoch 320): Loss/seq after 02950 batchs: 329.6833190917969
INFO:root:Train (Epoch 320): Loss/seq after 03000 batchs: 333.02911376953125
INFO:root:Train (Epoch 320): Loss/seq after 03050 batchs: 334.4046630859375
INFO:root:Train (Epoch 320): Loss/seq after 03100 batchs: 335.7236022949219
INFO:root:Train (Epoch 320): Loss/seq after 03150 batchs: 335.73052978515625
INFO:root:Train (Epoch 320): Loss/seq after 03200 batchs: 335.77960205078125
INFO:root:Train (Epoch 320): Loss/seq after 03250 batchs: 336.9117126464844
INFO:root:Train (Epoch 320): Loss/seq after 03300 batchs: 336.33740234375
INFO:root:Train (Epoch 320): Loss/seq after 03350 batchs: 334.44921875
INFO:root:Train (Epoch 320): Loss/seq after 03400 batchs: 332.5865783691406
INFO:root:Train (Epoch 320): Loss/seq after 03450 batchs: 331.6828308105469
INFO:root:Train (Epoch 320): Loss/seq after 03500 batchs: 332.4134521484375
INFO:root:Train (Epoch 320): Loss/seq after 03550 batchs: 331.05682373046875
INFO:root:Train (Epoch 320): Loss/seq after 03600 batchs: 333.6307373046875
INFO:root:Train (Epoch 320): Loss/seq after 03650 batchs: 332.5049133300781
INFO:root:Train (Epoch 320): Loss/seq after 03700 batchs: 334.09442138671875
INFO:root:Train (Epoch 320): Loss/seq after 03750 batchs: 337.3014221191406
INFO:root:Train (Epoch 320): Loss/seq after 03800 batchs: 337.15777587890625
INFO:root:Train (Epoch 320): Loss/seq after 03850 batchs: 336.6288146972656
INFO:root:Train (Epoch 320): Loss/seq after 03900 batchs: 337.7794189453125
INFO:root:Train (Epoch 320): Loss/seq after 03950 batchs: 340.26202392578125
INFO:root:Train (Epoch 320): Loss/seq after 04000 batchs: 338.4411315917969
INFO:root:Train (Epoch 320): Loss/seq after 04050 batchs: 336.6900329589844
INFO:root:Train (Epoch 320): Loss/seq after 04100 batchs: 335.77679443359375
INFO:root:Train (Epoch 320): Loss/seq after 04150 batchs: 335.843505859375
INFO:root:Train (Epoch 320): Loss/seq after 04200 batchs: 335.3394775390625
INFO:root:Train (Epoch 320): Loss/seq after 04250 batchs: 334.5714111328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 320): Loss/seq after 00000 batches: 372.56671142578125
INFO:root:# Valid (Epoch 320): Loss/seq after 00050 batches: 717.994873046875
INFO:root:# Valid (Epoch 320): Loss/seq after 00100 batches: 843.6300659179688
INFO:root:# Valid (Epoch 320): Loss/seq after 00150 batches: 619.861572265625
INFO:root:# Valid (Epoch 320): Loss/seq after 00200 batches: 550.1648559570312
INFO:root:Artifacts: Make stick videos for epoch 320
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_320_on_20220423_224038.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_320_index_163_on_20220423_224038.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 321): Loss/seq after 00000 batchs: 499.1500549316406
INFO:root:Train (Epoch 321): Loss/seq after 00050 batchs: 440.1443786621094
INFO:root:Train (Epoch 321): Loss/seq after 00100 batchs: 471.9119567871094
INFO:root:Train (Epoch 321): Loss/seq after 00150 batchs: 439.2236022949219
INFO:root:Train (Epoch 321): Loss/seq after 00200 batchs: 496.1231689453125
INFO:root:Train (Epoch 321): Loss/seq after 00250 batchs: 511.58746337890625
INFO:root:Train (Epoch 321): Loss/seq after 00300 batchs: 528.2125854492188
INFO:root:Train (Epoch 321): Loss/seq after 00350 batchs: 502.2774963378906
INFO:root:Train (Epoch 321): Loss/seq after 00400 batchs: 491.3652038574219
INFO:root:Train (Epoch 321): Loss/seq after 00450 batchs: 503.2444152832031
INFO:root:Train (Epoch 321): Loss/seq after 00500 batchs: 489.329833984375
INFO:root:Train (Epoch 321): Loss/seq after 00550 batchs: 480.31884765625
INFO:root:Train (Epoch 321): Loss/seq after 00600 batchs: 466.7370300292969
INFO:root:Train (Epoch 321): Loss/seq after 00650 batchs: 451.3283996582031
INFO:root:Train (Epoch 321): Loss/seq after 00700 batchs: 434.66107177734375
INFO:root:Train (Epoch 321): Loss/seq after 00750 batchs: 430.02166748046875
INFO:root:Train (Epoch 321): Loss/seq after 00800 batchs: 429.78277587890625
INFO:root:Train (Epoch 321): Loss/seq after 00850 batchs: 416.4217529296875
INFO:root:Train (Epoch 321): Loss/seq after 00900 batchs: 405.5353088378906
INFO:root:Train (Epoch 321): Loss/seq after 00950 batchs: 404.1092529296875
INFO:root:Train (Epoch 321): Loss/seq after 01000 batchs: 397.7059326171875
INFO:root:Train (Epoch 321): Loss/seq after 01050 batchs: 391.3724060058594
INFO:root:Train (Epoch 321): Loss/seq after 01100 batchs: 383.0998840332031
INFO:root:Train (Epoch 321): Loss/seq after 01150 batchs: 373.4898681640625
INFO:root:Train (Epoch 321): Loss/seq after 01200 batchs: 373.7640380859375
INFO:root:Train (Epoch 321): Loss/seq after 01250 batchs: 372.83575439453125
INFO:root:Train (Epoch 321): Loss/seq after 01300 batchs: 364.7909851074219
INFO:root:Train (Epoch 321): Loss/seq after 01350 batchs: 357.3052062988281
INFO:root:Train (Epoch 321): Loss/seq after 01400 batchs: 357.3113708496094
INFO:root:Train (Epoch 321): Loss/seq after 01450 batchs: 360.3896484375
INFO:root:Train (Epoch 321): Loss/seq after 01500 batchs: 365.9014892578125
INFO:root:Train (Epoch 321): Loss/seq after 01550 batchs: 366.4721984863281
INFO:root:Train (Epoch 321): Loss/seq after 01600 batchs: 364.973388671875
INFO:root:Train (Epoch 321): Loss/seq after 01650 batchs: 363.873046875
INFO:root:Train (Epoch 321): Loss/seq after 01700 batchs: 366.00830078125
INFO:root:Train (Epoch 321): Loss/seq after 01750 batchs: 364.9897766113281
INFO:root:Train (Epoch 321): Loss/seq after 01800 batchs: 363.5488586425781
INFO:root:Train (Epoch 321): Loss/seq after 01850 batchs: 361.8329772949219
INFO:root:Train (Epoch 321): Loss/seq after 01900 batchs: 361.0157775878906
INFO:root:Train (Epoch 321): Loss/seq after 01950 batchs: 360.703125
INFO:root:Train (Epoch 321): Loss/seq after 02000 batchs: 362.4066162109375
INFO:root:Train (Epoch 321): Loss/seq after 02050 batchs: 362.29681396484375
INFO:root:Train (Epoch 321): Loss/seq after 02100 batchs: 361.75347900390625
INFO:root:Train (Epoch 321): Loss/seq after 02150 batchs: 361.4985046386719
INFO:root:Train (Epoch 321): Loss/seq after 02200 batchs: 360.6260070800781
INFO:root:Train (Epoch 321): Loss/seq after 02250 batchs: 359.63897705078125
INFO:root:Train (Epoch 321): Loss/seq after 02300 batchs: 357.5052795410156
INFO:root:Train (Epoch 321): Loss/seq after 02350 batchs: 355.2801208496094
INFO:root:Train (Epoch 321): Loss/seq after 02400 batchs: 356.2527770996094
INFO:root:Train (Epoch 321): Loss/seq after 02450 batchs: 353.5225524902344
INFO:root:Train (Epoch 321): Loss/seq after 02500 batchs: 347.8334045410156
INFO:root:Train (Epoch 321): Loss/seq after 02550 batchs: 343.2284851074219
INFO:root:Train (Epoch 321): Loss/seq after 02600 batchs: 339.7004089355469
INFO:root:Train (Epoch 321): Loss/seq after 02650 batchs: 336.9024658203125
INFO:root:Train (Epoch 321): Loss/seq after 02700 batchs: 334.73992919921875
INFO:root:Train (Epoch 321): Loss/seq after 02750 batchs: 331.2959289550781
INFO:root:Train (Epoch 321): Loss/seq after 02800 batchs: 330.2018127441406
INFO:root:Train (Epoch 321): Loss/seq after 02850 batchs: 329.9032897949219
INFO:root:Train (Epoch 321): Loss/seq after 02900 batchs: 330.7925720214844
INFO:root:Train (Epoch 321): Loss/seq after 02950 batchs: 331.5856628417969
INFO:root:Train (Epoch 321): Loss/seq after 03000 batchs: 335.04815673828125
INFO:root:Train (Epoch 321): Loss/seq after 03050 batchs: 336.593017578125
INFO:root:Train (Epoch 321): Loss/seq after 03100 batchs: 338.87506103515625
INFO:root:Train (Epoch 321): Loss/seq after 03150 batchs: 338.88262939453125
INFO:root:Train (Epoch 321): Loss/seq after 03200 batchs: 339.12451171875
INFO:root:Train (Epoch 321): Loss/seq after 03250 batchs: 339.2618408203125
INFO:root:Train (Epoch 321): Loss/seq after 03300 batchs: 338.7662658691406
INFO:root:Train (Epoch 321): Loss/seq after 03350 batchs: 337.1817932128906
INFO:root:Train (Epoch 321): Loss/seq after 03400 batchs: 335.21868896484375
INFO:root:Train (Epoch 321): Loss/seq after 03450 batchs: 334.333251953125
INFO:root:Train (Epoch 321): Loss/seq after 03500 batchs: 335.20806884765625
INFO:root:Train (Epoch 321): Loss/seq after 03550 batchs: 333.7940979003906
INFO:root:Train (Epoch 321): Loss/seq after 03600 batchs: 336.668212890625
INFO:root:Train (Epoch 321): Loss/seq after 03650 batchs: 335.6297607421875
INFO:root:Train (Epoch 321): Loss/seq after 03700 batchs: 337.6612243652344
INFO:root:Train (Epoch 321): Loss/seq after 03750 batchs: 341.0193176269531
INFO:root:Train (Epoch 321): Loss/seq after 03800 batchs: 340.84808349609375
INFO:root:Train (Epoch 321): Loss/seq after 03850 batchs: 340.4821472167969
INFO:root:Train (Epoch 321): Loss/seq after 03900 batchs: 341.3797607421875
INFO:root:Train (Epoch 321): Loss/seq after 03950 batchs: 343.71893310546875
INFO:root:Train (Epoch 321): Loss/seq after 04000 batchs: 341.8686218261719
INFO:root:Train (Epoch 321): Loss/seq after 04050 batchs: 340.0918884277344
INFO:root:Train (Epoch 321): Loss/seq after 04100 batchs: 339.1214599609375
INFO:root:Train (Epoch 321): Loss/seq after 04150 batchs: 339.35321044921875
INFO:root:Train (Epoch 321): Loss/seq after 04200 batchs: 338.78778076171875
INFO:root:Train (Epoch 321): Loss/seq after 04250 batchs: 337.9510803222656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 321): Loss/seq after 00000 batches: 430.06561279296875
INFO:root:# Valid (Epoch 321): Loss/seq after 00050 batches: 668.2967529296875
INFO:root:# Valid (Epoch 321): Loss/seq after 00100 batches: 686.7685546875
INFO:root:# Valid (Epoch 321): Loss/seq after 00150 batches: 511.5863952636719
INFO:root:# Valid (Epoch 321): Loss/seq after 00200 batches: 467.2216491699219
INFO:root:Artifacts: Make stick videos for epoch 321
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_321_on_20220423_224523.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_321_index_340_on_20220423_224523.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 322): Loss/seq after 00000 batchs: 560.6033935546875
INFO:root:Train (Epoch 322): Loss/seq after 00050 batchs: 464.1252136230469
INFO:root:Train (Epoch 322): Loss/seq after 00100 batchs: 475.5411682128906
INFO:root:Train (Epoch 322): Loss/seq after 00150 batchs: 440.1111755371094
INFO:root:Train (Epoch 322): Loss/seq after 00200 batchs: 490.04351806640625
INFO:root:Train (Epoch 322): Loss/seq after 00250 batchs: 520.68017578125
INFO:root:Train (Epoch 322): Loss/seq after 00300 batchs: 536.5296020507812
INFO:root:Train (Epoch 322): Loss/seq after 00350 batchs: 510.4102478027344
INFO:root:Train (Epoch 322): Loss/seq after 00400 batchs: 499.1353454589844
INFO:root:Train (Epoch 322): Loss/seq after 00450 batchs: 509.5523376464844
INFO:root:Train (Epoch 322): Loss/seq after 00500 batchs: 492.9603271484375
INFO:root:Train (Epoch 322): Loss/seq after 00550 batchs: 484.33795166015625
INFO:root:Train (Epoch 322): Loss/seq after 00600 batchs: 468.8630676269531
INFO:root:Train (Epoch 322): Loss/seq after 00650 batchs: 450.5560607910156
INFO:root:Train (Epoch 322): Loss/seq after 00700 batchs: 432.1911315917969
INFO:root:Train (Epoch 322): Loss/seq after 00750 batchs: 427.56451416015625
INFO:root:Train (Epoch 322): Loss/seq after 00800 batchs: 427.981201171875
INFO:root:Train (Epoch 322): Loss/seq after 00850 batchs: 415.3448181152344
INFO:root:Train (Epoch 322): Loss/seq after 00900 batchs: 404.2996826171875
INFO:root:Train (Epoch 322): Loss/seq after 00950 batchs: 403.87811279296875
INFO:root:Train (Epoch 322): Loss/seq after 01000 batchs: 396.91534423828125
INFO:root:Train (Epoch 322): Loss/seq after 01050 batchs: 388.69775390625
INFO:root:Train (Epoch 322): Loss/seq after 01100 batchs: 379.9171142578125
INFO:root:Train (Epoch 322): Loss/seq after 01150 batchs: 369.6161193847656
INFO:root:Train (Epoch 322): Loss/seq after 01200 batchs: 369.259765625
INFO:root:Train (Epoch 322): Loss/seq after 01250 batchs: 368.3648681640625
INFO:root:Train (Epoch 322): Loss/seq after 01300 batchs: 360.5933532714844
INFO:root:Train (Epoch 322): Loss/seq after 01350 batchs: 353.1345520019531
INFO:root:Train (Epoch 322): Loss/seq after 01400 batchs: 353.534912109375
INFO:root:Train (Epoch 322): Loss/seq after 01450 batchs: 356.7405700683594
INFO:root:Train (Epoch 322): Loss/seq after 01500 batchs: 361.8307189941406
INFO:root:Train (Epoch 322): Loss/seq after 01550 batchs: 362.482666015625
INFO:root:Train (Epoch 322): Loss/seq after 01600 batchs: 360.7774658203125
INFO:root:Train (Epoch 322): Loss/seq after 01650 batchs: 359.2726745605469
INFO:root:Train (Epoch 322): Loss/seq after 01700 batchs: 361.79803466796875
INFO:root:Train (Epoch 322): Loss/seq after 01750 batchs: 361.1117248535156
INFO:root:Train (Epoch 322): Loss/seq after 01800 batchs: 359.57598876953125
INFO:root:Train (Epoch 322): Loss/seq after 01850 batchs: 357.95184326171875
INFO:root:Train (Epoch 322): Loss/seq after 01900 batchs: 357.13092041015625
INFO:root:Train (Epoch 322): Loss/seq after 01950 batchs: 356.96539306640625
INFO:root:Train (Epoch 322): Loss/seq after 02000 batchs: 358.7748107910156
INFO:root:Train (Epoch 322): Loss/seq after 02050 batchs: 358.9866943359375
INFO:root:Train (Epoch 322): Loss/seq after 02100 batchs: 358.3245849609375
INFO:root:Train (Epoch 322): Loss/seq after 02150 batchs: 358.15509033203125
INFO:root:Train (Epoch 322): Loss/seq after 02200 batchs: 357.4539794921875
INFO:root:Train (Epoch 322): Loss/seq after 02250 batchs: 356.731201171875
INFO:root:Train (Epoch 322): Loss/seq after 02300 batchs: 354.17919921875
INFO:root:Train (Epoch 322): Loss/seq after 02350 batchs: 351.95831298828125
INFO:root:Train (Epoch 322): Loss/seq after 02400 batchs: 352.5661926269531
INFO:root:Train (Epoch 322): Loss/seq after 02450 batchs: 349.75250244140625
INFO:root:Train (Epoch 322): Loss/seq after 02500 batchs: 344.0775146484375
INFO:root:Train (Epoch 322): Loss/seq after 02550 batchs: 339.3609619140625
INFO:root:Train (Epoch 322): Loss/seq after 02600 batchs: 335.6927795410156
INFO:root:Train (Epoch 322): Loss/seq after 02650 batchs: 332.41168212890625
INFO:root:Train (Epoch 322): Loss/seq after 02700 batchs: 330.17822265625
INFO:root:Train (Epoch 322): Loss/seq after 02750 batchs: 326.4551696777344
INFO:root:Train (Epoch 322): Loss/seq after 02800 batchs: 325.40142822265625
INFO:root:Train (Epoch 322): Loss/seq after 02850 batchs: 325.0822448730469
INFO:root:Train (Epoch 322): Loss/seq after 02900 batchs: 325.5035400390625
INFO:root:Train (Epoch 322): Loss/seq after 02950 batchs: 326.2444763183594
INFO:root:Train (Epoch 322): Loss/seq after 03000 batchs: 329.3913879394531
INFO:root:Train (Epoch 322): Loss/seq after 03050 batchs: 330.6463317871094
INFO:root:Train (Epoch 322): Loss/seq after 03100 batchs: 332.0492248535156
INFO:root:Train (Epoch 322): Loss/seq after 03150 batchs: 331.9037170410156
INFO:root:Train (Epoch 322): Loss/seq after 03200 batchs: 331.92779541015625
INFO:root:Train (Epoch 322): Loss/seq after 03250 batchs: 331.3790283203125
INFO:root:Train (Epoch 322): Loss/seq after 03300 batchs: 331.0802001953125
INFO:root:Train (Epoch 322): Loss/seq after 03350 batchs: 329.376953125
INFO:root:Train (Epoch 322): Loss/seq after 03400 batchs: 327.4873352050781
INFO:root:Train (Epoch 322): Loss/seq after 03450 batchs: 326.6955261230469
INFO:root:Train (Epoch 322): Loss/seq after 03500 batchs: 327.62969970703125
INFO:root:Train (Epoch 322): Loss/seq after 03550 batchs: 326.4785461425781
INFO:root:Train (Epoch 322): Loss/seq after 03600 batchs: 328.8567199707031
INFO:root:Train (Epoch 322): Loss/seq after 03650 batchs: 327.581787109375
INFO:root:Train (Epoch 322): Loss/seq after 03700 batchs: 329.24700927734375
INFO:root:Train (Epoch 322): Loss/seq after 03750 batchs: 332.3967590332031
INFO:root:Train (Epoch 322): Loss/seq after 03800 batchs: 332.35284423828125
INFO:root:Train (Epoch 322): Loss/seq after 03850 batchs: 332.08929443359375
INFO:root:Train (Epoch 322): Loss/seq after 03900 batchs: 333.3544616699219
INFO:root:Train (Epoch 322): Loss/seq after 03950 batchs: 336.0333557128906
INFO:root:Train (Epoch 322): Loss/seq after 04000 batchs: 334.2555236816406
INFO:root:Train (Epoch 322): Loss/seq after 04050 batchs: 332.5075378417969
INFO:root:Train (Epoch 322): Loss/seq after 04100 batchs: 331.486328125
INFO:root:Train (Epoch 322): Loss/seq after 04150 batchs: 331.5278015136719
INFO:root:Train (Epoch 322): Loss/seq after 04200 batchs: 331.01275634765625
INFO:root:Train (Epoch 322): Loss/seq after 04250 batchs: 330.2121887207031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 322): Loss/seq after 00000 batches: 341.377197265625
INFO:root:# Valid (Epoch 322): Loss/seq after 00050 batches: 702.7332763671875
INFO:root:# Valid (Epoch 322): Loss/seq after 00100 batches: 743.1826782226562
INFO:root:# Valid (Epoch 322): Loss/seq after 00150 batches: 549.6988525390625
INFO:root:# Valid (Epoch 322): Loss/seq after 00200 batches: 496.5852355957031
INFO:root:Artifacts: Make stick videos for epoch 322
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_322_on_20220423_225033.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_322_index_1806_on_20220423_225033.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 323): Loss/seq after 00000 batchs: 576.3604125976562
INFO:root:Train (Epoch 323): Loss/seq after 00050 batchs: 478.86724853515625
INFO:root:Train (Epoch 323): Loss/seq after 00100 batchs: 473.6689147949219
INFO:root:Train (Epoch 323): Loss/seq after 00150 batchs: 435.9910583496094
INFO:root:Train (Epoch 323): Loss/seq after 00200 batchs: 487.91937255859375
INFO:root:Train (Epoch 323): Loss/seq after 00250 batchs: 511.5220642089844
INFO:root:Train (Epoch 323): Loss/seq after 00300 batchs: 534.2169799804688
INFO:root:Train (Epoch 323): Loss/seq after 00350 batchs: 508.6183776855469
INFO:root:Train (Epoch 323): Loss/seq after 00400 batchs: 497.3388977050781
INFO:root:Train (Epoch 323): Loss/seq after 00450 batchs: 508.935791015625
INFO:root:Train (Epoch 323): Loss/seq after 00500 batchs: 493.32977294921875
INFO:root:Train (Epoch 323): Loss/seq after 00550 batchs: 484.27008056640625
INFO:root:Train (Epoch 323): Loss/seq after 00600 batchs: 467.41741943359375
INFO:root:Train (Epoch 323): Loss/seq after 00650 batchs: 447.9827575683594
INFO:root:Train (Epoch 323): Loss/seq after 00700 batchs: 429.16607666015625
INFO:root:Train (Epoch 323): Loss/seq after 00750 batchs: 422.9234313964844
INFO:root:Train (Epoch 323): Loss/seq after 00800 batchs: 423.7877197265625
INFO:root:Train (Epoch 323): Loss/seq after 00850 batchs: 410.5338134765625
INFO:root:Train (Epoch 323): Loss/seq after 00900 batchs: 399.46209716796875
INFO:root:Train (Epoch 323): Loss/seq after 00950 batchs: 397.95391845703125
INFO:root:Train (Epoch 323): Loss/seq after 01000 batchs: 391.67523193359375
INFO:root:Train (Epoch 323): Loss/seq after 01050 batchs: 384.1430969238281
INFO:root:Train (Epoch 323): Loss/seq after 01100 batchs: 375.2379455566406
INFO:root:Train (Epoch 323): Loss/seq after 01150 batchs: 365.3841552734375
INFO:root:Train (Epoch 323): Loss/seq after 01200 batchs: 364.3348693847656
INFO:root:Train (Epoch 323): Loss/seq after 01250 batchs: 363.3038635253906
INFO:root:Train (Epoch 323): Loss/seq after 01300 batchs: 355.6150817871094
INFO:root:Train (Epoch 323): Loss/seq after 01350 batchs: 347.7228088378906
INFO:root:Train (Epoch 323): Loss/seq after 01400 batchs: 348.4561767578125
INFO:root:Train (Epoch 323): Loss/seq after 01450 batchs: 351.37420654296875
INFO:root:Train (Epoch 323): Loss/seq after 01500 batchs: 356.69171142578125
INFO:root:Train (Epoch 323): Loss/seq after 01550 batchs: 357.4640808105469
INFO:root:Train (Epoch 323): Loss/seq after 01600 batchs: 356.1326904296875
INFO:root:Train (Epoch 323): Loss/seq after 01650 batchs: 354.5145568847656
INFO:root:Train (Epoch 323): Loss/seq after 01700 batchs: 357.27813720703125
INFO:root:Train (Epoch 323): Loss/seq after 01750 batchs: 356.635986328125
INFO:root:Train (Epoch 323): Loss/seq after 01800 batchs: 355.0970764160156
INFO:root:Train (Epoch 323): Loss/seq after 01850 batchs: 353.4495544433594
INFO:root:Train (Epoch 323): Loss/seq after 01900 batchs: 353.2576904296875
INFO:root:Train (Epoch 323): Loss/seq after 01950 batchs: 353.9729919433594
INFO:root:Train (Epoch 323): Loss/seq after 02000 batchs: 355.8330078125
INFO:root:Train (Epoch 323): Loss/seq after 02050 batchs: 356.0880432128906
INFO:root:Train (Epoch 323): Loss/seq after 02100 batchs: 355.6526794433594
INFO:root:Train (Epoch 323): Loss/seq after 02150 batchs: 355.4553527832031
INFO:root:Train (Epoch 323): Loss/seq after 02200 batchs: 354.9544372558594
INFO:root:Train (Epoch 323): Loss/seq after 02250 batchs: 354.5143127441406
INFO:root:Train (Epoch 323): Loss/seq after 02300 batchs: 352.7977294921875
INFO:root:Train (Epoch 323): Loss/seq after 02350 batchs: 350.74591064453125
INFO:root:Train (Epoch 323): Loss/seq after 02400 batchs: 351.4660949707031
INFO:root:Train (Epoch 323): Loss/seq after 02450 batchs: 348.7434387207031
INFO:root:Train (Epoch 323): Loss/seq after 02500 batchs: 343.1451110839844
INFO:root:Train (Epoch 323): Loss/seq after 02550 batchs: 338.57659912109375
INFO:root:Train (Epoch 323): Loss/seq after 02600 batchs: 335.05316162109375
INFO:root:Train (Epoch 323): Loss/seq after 02650 batchs: 331.7783203125
INFO:root:Train (Epoch 323): Loss/seq after 02700 batchs: 329.75860595703125
INFO:root:Train (Epoch 323): Loss/seq after 02750 batchs: 326.4580383300781
INFO:root:Train (Epoch 323): Loss/seq after 02800 batchs: 325.559326171875
INFO:root:Train (Epoch 323): Loss/seq after 02850 batchs: 325.18756103515625
INFO:root:Train (Epoch 323): Loss/seq after 02900 batchs: 325.58050537109375
INFO:root:Train (Epoch 323): Loss/seq after 02950 batchs: 326.4250793457031
INFO:root:Train (Epoch 323): Loss/seq after 03000 batchs: 329.5657958984375
INFO:root:Train (Epoch 323): Loss/seq after 03050 batchs: 331.0437316894531
INFO:root:Train (Epoch 323): Loss/seq after 03100 batchs: 332.7823181152344
INFO:root:Train (Epoch 323): Loss/seq after 03150 batchs: 332.5045166015625
INFO:root:Train (Epoch 323): Loss/seq after 03200 batchs: 332.589599609375
INFO:root:Train (Epoch 323): Loss/seq after 03250 batchs: 332.3941345214844
INFO:root:Train (Epoch 323): Loss/seq after 03300 batchs: 331.7707214355469
INFO:root:Train (Epoch 323): Loss/seq after 03350 batchs: 329.9222106933594
INFO:root:Train (Epoch 323): Loss/seq after 03400 batchs: 328.06402587890625
INFO:root:Train (Epoch 323): Loss/seq after 03450 batchs: 327.2525939941406
INFO:root:Train (Epoch 323): Loss/seq after 03500 batchs: 328.1951599121094
INFO:root:Train (Epoch 323): Loss/seq after 03550 batchs: 326.91943359375
INFO:root:Train (Epoch 323): Loss/seq after 03600 batchs: 329.6601867675781
INFO:root:Train (Epoch 323): Loss/seq after 03650 batchs: 328.82147216796875
INFO:root:Train (Epoch 323): Loss/seq after 03700 batchs: 330.724853515625
INFO:root:Train (Epoch 323): Loss/seq after 03750 batchs: 333.94598388671875
INFO:root:Train (Epoch 323): Loss/seq after 03800 batchs: 333.7953796386719
INFO:root:Train (Epoch 323): Loss/seq after 03850 batchs: 333.3916015625
INFO:root:Train (Epoch 323): Loss/seq after 03900 batchs: 334.54754638671875
INFO:root:Train (Epoch 323): Loss/seq after 03950 batchs: 336.8789367675781
INFO:root:Train (Epoch 323): Loss/seq after 04000 batchs: 335.0833740234375
INFO:root:Train (Epoch 323): Loss/seq after 04050 batchs: 333.3236083984375
INFO:root:Train (Epoch 323): Loss/seq after 04100 batchs: 332.36297607421875
INFO:root:Train (Epoch 323): Loss/seq after 04150 batchs: 332.5264892578125
INFO:root:Train (Epoch 323): Loss/seq after 04200 batchs: 331.9800109863281
INFO:root:Train (Epoch 323): Loss/seq after 04250 batchs: 331.1271667480469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 323): Loss/seq after 00000 batches: 349.14666748046875
INFO:root:# Valid (Epoch 323): Loss/seq after 00050 batches: 746.9837036132812
INFO:root:# Valid (Epoch 323): Loss/seq after 00100 batches: 791.6913452148438
INFO:root:# Valid (Epoch 323): Loss/seq after 00150 batches: 582.59423828125
INFO:root:# Valid (Epoch 323): Loss/seq after 00200 batches: 524.51318359375
INFO:root:Artifacts: Make stick videos for epoch 323
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_323_on_20220423_225521.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_323_index_475_on_20220423_225521.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 324): Loss/seq after 00000 batchs: 613.2590942382812
INFO:root:Train (Epoch 324): Loss/seq after 00050 batchs: 459.43365478515625
INFO:root:Train (Epoch 324): Loss/seq after 00100 batchs: 465.4032287597656
INFO:root:Train (Epoch 324): Loss/seq after 00150 batchs: 432.19036865234375
INFO:root:Train (Epoch 324): Loss/seq after 00200 batchs: 502.7306823730469
INFO:root:Train (Epoch 324): Loss/seq after 00250 batchs: 512.0881958007812
INFO:root:Train (Epoch 324): Loss/seq after 00300 batchs: 526.3178100585938
INFO:root:Train (Epoch 324): Loss/seq after 00350 batchs: 501.1016845703125
INFO:root:Train (Epoch 324): Loss/seq after 00400 batchs: 493.5400390625
INFO:root:Train (Epoch 324): Loss/seq after 00450 batchs: 504.0944519042969
INFO:root:Train (Epoch 324): Loss/seq after 00500 batchs: 490.1790771484375
INFO:root:Train (Epoch 324): Loss/seq after 00550 batchs: 480.2777404785156
INFO:root:Train (Epoch 324): Loss/seq after 00600 batchs: 464.07196044921875
INFO:root:Train (Epoch 324): Loss/seq after 00650 batchs: 446.4456481933594
INFO:root:Train (Epoch 324): Loss/seq after 00700 batchs: 429.2505798339844
INFO:root:Train (Epoch 324): Loss/seq after 00750 batchs: 423.8646240234375
INFO:root:Train (Epoch 324): Loss/seq after 00800 batchs: 424.36187744140625
INFO:root:Train (Epoch 324): Loss/seq after 00850 batchs: 410.7967834472656
INFO:root:Train (Epoch 324): Loss/seq after 00900 batchs: 399.552001953125
INFO:root:Train (Epoch 324): Loss/seq after 00950 batchs: 399.0544128417969
INFO:root:Train (Epoch 324): Loss/seq after 01000 batchs: 393.4928283691406
INFO:root:Train (Epoch 324): Loss/seq after 01050 batchs: 385.3503723144531
INFO:root:Train (Epoch 324): Loss/seq after 01100 batchs: 376.37042236328125
INFO:root:Train (Epoch 324): Loss/seq after 01150 batchs: 366.56573486328125
INFO:root:Train (Epoch 324): Loss/seq after 01200 batchs: 365.7132873535156
INFO:root:Train (Epoch 324): Loss/seq after 01250 batchs: 364.4377746582031
INFO:root:Train (Epoch 324): Loss/seq after 01300 batchs: 357.0596008300781
INFO:root:Train (Epoch 324): Loss/seq after 01350 batchs: 350.1230773925781
INFO:root:Train (Epoch 324): Loss/seq after 01400 batchs: 351.0721130371094
INFO:root:Train (Epoch 324): Loss/seq after 01450 batchs: 354.0382080078125
INFO:root:Train (Epoch 324): Loss/seq after 01500 batchs: 359.4646911621094
INFO:root:Train (Epoch 324): Loss/seq after 01550 batchs: 360.35845947265625
INFO:root:Train (Epoch 324): Loss/seq after 01600 batchs: 358.90496826171875
INFO:root:Train (Epoch 324): Loss/seq after 01650 batchs: 357.4767150878906
INFO:root:Train (Epoch 324): Loss/seq after 01700 batchs: 359.3556213378906
INFO:root:Train (Epoch 324): Loss/seq after 01750 batchs: 358.9458312988281
INFO:root:Train (Epoch 324): Loss/seq after 01800 batchs: 357.47021484375
INFO:root:Train (Epoch 324): Loss/seq after 01850 batchs: 355.68255615234375
INFO:root:Train (Epoch 324): Loss/seq after 01900 batchs: 354.7804260253906
INFO:root:Train (Epoch 324): Loss/seq after 01950 batchs: 355.2481994628906
INFO:root:Train (Epoch 324): Loss/seq after 02000 batchs: 357.2747802734375
INFO:root:Train (Epoch 324): Loss/seq after 02050 batchs: 357.4237060546875
INFO:root:Train (Epoch 324): Loss/seq after 02100 batchs: 357.16058349609375
INFO:root:Train (Epoch 324): Loss/seq after 02150 batchs: 356.97021484375
INFO:root:Train (Epoch 324): Loss/seq after 02200 batchs: 356.2013244628906
INFO:root:Train (Epoch 324): Loss/seq after 02250 batchs: 355.6539306640625
INFO:root:Train (Epoch 324): Loss/seq after 02300 batchs: 353.4344177246094
INFO:root:Train (Epoch 324): Loss/seq after 02350 batchs: 351.29010009765625
INFO:root:Train (Epoch 324): Loss/seq after 02400 batchs: 351.9873962402344
INFO:root:Train (Epoch 324): Loss/seq after 02450 batchs: 349.3207702636719
INFO:root:Train (Epoch 324): Loss/seq after 02500 batchs: 343.7039794921875
INFO:root:Train (Epoch 324): Loss/seq after 02550 batchs: 339.06890869140625
INFO:root:Train (Epoch 324): Loss/seq after 02600 batchs: 335.3299255371094
INFO:root:Train (Epoch 324): Loss/seq after 02650 batchs: 332.0906982421875
INFO:root:Train (Epoch 324): Loss/seq after 02700 batchs: 329.84429931640625
INFO:root:Train (Epoch 324): Loss/seq after 02750 batchs: 325.9979553222656
INFO:root:Train (Epoch 324): Loss/seq after 02800 batchs: 324.55340576171875
INFO:root:Train (Epoch 324): Loss/seq after 02850 batchs: 324.2235107421875
INFO:root:Train (Epoch 324): Loss/seq after 02900 batchs: 324.57421875
INFO:root:Train (Epoch 324): Loss/seq after 02950 batchs: 325.6230163574219
INFO:root:Train (Epoch 324): Loss/seq after 03000 batchs: 329.12939453125
INFO:root:Train (Epoch 324): Loss/seq after 03050 batchs: 330.5675354003906
INFO:root:Train (Epoch 324): Loss/seq after 03100 batchs: 331.6762390136719
INFO:root:Train (Epoch 324): Loss/seq after 03150 batchs: 331.2974853515625
INFO:root:Train (Epoch 324): Loss/seq after 03200 batchs: 331.2977600097656
INFO:root:Train (Epoch 324): Loss/seq after 03250 batchs: 330.7422180175781
INFO:root:Train (Epoch 324): Loss/seq after 03300 batchs: 330.3536071777344
INFO:root:Train (Epoch 324): Loss/seq after 03350 batchs: 328.6651916503906
INFO:root:Train (Epoch 324): Loss/seq after 03400 batchs: 326.8101806640625
INFO:root:Train (Epoch 324): Loss/seq after 03450 batchs: 326.0714111328125
INFO:root:Train (Epoch 324): Loss/seq after 03500 batchs: 326.8385314941406
INFO:root:Train (Epoch 324): Loss/seq after 03550 batchs: 325.6034240722656
INFO:root:Train (Epoch 324): Loss/seq after 03600 batchs: 328.07220458984375
INFO:root:Train (Epoch 324): Loss/seq after 03650 batchs: 326.8717956542969
INFO:root:Train (Epoch 324): Loss/seq after 03700 batchs: 328.6031188964844
INFO:root:Train (Epoch 324): Loss/seq after 03750 batchs: 331.8384094238281
INFO:root:Train (Epoch 324): Loss/seq after 03800 batchs: 331.6979675292969
INFO:root:Train (Epoch 324): Loss/seq after 03850 batchs: 331.31103515625
INFO:root:Train (Epoch 324): Loss/seq after 03900 batchs: 332.2898254394531
INFO:root:Train (Epoch 324): Loss/seq after 03950 batchs: 334.6220703125
INFO:root:Train (Epoch 324): Loss/seq after 04000 batchs: 332.9045104980469
INFO:root:Train (Epoch 324): Loss/seq after 04050 batchs: 331.1785583496094
INFO:root:Train (Epoch 324): Loss/seq after 04100 batchs: 330.2350769042969
INFO:root:Train (Epoch 324): Loss/seq after 04150 batchs: 330.4224853515625
INFO:root:Train (Epoch 324): Loss/seq after 04200 batchs: 329.9288330078125
INFO:root:Train (Epoch 324): Loss/seq after 04250 batchs: 329.18023681640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 324): Loss/seq after 00000 batches: 358.1272277832031
INFO:root:# Valid (Epoch 324): Loss/seq after 00050 batches: 701.2753295898438
INFO:root:# Valid (Epoch 324): Loss/seq after 00100 batches: 688.5819702148438
INFO:root:# Valid (Epoch 324): Loss/seq after 00150 batches: 510.80706787109375
INFO:root:# Valid (Epoch 324): Loss/seq after 00200 batches: 467.6778259277344
INFO:root:Artifacts: Make stick videos for epoch 324
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_324_on_20220423_230004.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_324_index_906_on_20220423_230004.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 325): Loss/seq after 00000 batchs: 506.7693176269531
INFO:root:Train (Epoch 325): Loss/seq after 00050 batchs: 463.10528564453125
INFO:root:Train (Epoch 325): Loss/seq after 00100 batchs: 463.0030212402344
INFO:root:Train (Epoch 325): Loss/seq after 00150 batchs: 430.5595397949219
INFO:root:Train (Epoch 325): Loss/seq after 00200 batchs: 479.1628112792969
INFO:root:Train (Epoch 325): Loss/seq after 00250 batchs: 495.5522155761719
INFO:root:Train (Epoch 325): Loss/seq after 00300 batchs: 518.5864868164062
INFO:root:Train (Epoch 325): Loss/seq after 00350 batchs: 499.4568176269531
INFO:root:Train (Epoch 325): Loss/seq after 00400 batchs: 487.5848693847656
INFO:root:Train (Epoch 325): Loss/seq after 00450 batchs: 499.3284606933594
INFO:root:Train (Epoch 325): Loss/seq after 00500 batchs: 483.98004150390625
INFO:root:Train (Epoch 325): Loss/seq after 00550 batchs: 474.1830749511719
INFO:root:Train (Epoch 325): Loss/seq after 00600 batchs: 459.5260925292969
INFO:root:Train (Epoch 325): Loss/seq after 00650 batchs: 441.0767517089844
INFO:root:Train (Epoch 325): Loss/seq after 00700 batchs: 421.9573974609375
INFO:root:Train (Epoch 325): Loss/seq after 00750 batchs: 414.1638488769531
INFO:root:Train (Epoch 325): Loss/seq after 00800 batchs: 415.2857971191406
INFO:root:Train (Epoch 325): Loss/seq after 00850 batchs: 402.547607421875
INFO:root:Train (Epoch 325): Loss/seq after 00900 batchs: 392.4107360839844
INFO:root:Train (Epoch 325): Loss/seq after 00950 batchs: 390.01605224609375
INFO:root:Train (Epoch 325): Loss/seq after 01000 batchs: 384.81109619140625
INFO:root:Train (Epoch 325): Loss/seq after 01050 batchs: 377.1844787597656
INFO:root:Train (Epoch 325): Loss/seq after 01100 batchs: 368.3629455566406
INFO:root:Train (Epoch 325): Loss/seq after 01150 batchs: 358.85980224609375
INFO:root:Train (Epoch 325): Loss/seq after 01200 batchs: 358.8236999511719
INFO:root:Train (Epoch 325): Loss/seq after 01250 batchs: 357.81939697265625
INFO:root:Train (Epoch 325): Loss/seq after 01300 batchs: 350.2992858886719
INFO:root:Train (Epoch 325): Loss/seq after 01350 batchs: 342.5611267089844
INFO:root:Train (Epoch 325): Loss/seq after 01400 batchs: 342.89739990234375
INFO:root:Train (Epoch 325): Loss/seq after 01450 batchs: 346.2268981933594
INFO:root:Train (Epoch 325): Loss/seq after 01500 batchs: 352.1692199707031
INFO:root:Train (Epoch 325): Loss/seq after 01550 batchs: 353.3023376464844
INFO:root:Train (Epoch 325): Loss/seq after 01600 batchs: 351.7977600097656
INFO:root:Train (Epoch 325): Loss/seq after 01650 batchs: 350.6927795410156
INFO:root:Train (Epoch 325): Loss/seq after 01700 batchs: 353.0444030761719
INFO:root:Train (Epoch 325): Loss/seq after 01750 batchs: 352.3742980957031
INFO:root:Train (Epoch 325): Loss/seq after 01800 batchs: 351.2063293457031
INFO:root:Train (Epoch 325): Loss/seq after 01850 batchs: 349.71044921875
INFO:root:Train (Epoch 325): Loss/seq after 01900 batchs: 349.1646728515625
INFO:root:Train (Epoch 325): Loss/seq after 01950 batchs: 349.5253601074219
INFO:root:Train (Epoch 325): Loss/seq after 02000 batchs: 351.4851379394531
INFO:root:Train (Epoch 325): Loss/seq after 02050 batchs: 352.4559326171875
INFO:root:Train (Epoch 325): Loss/seq after 02100 batchs: 352.4217224121094
INFO:root:Train (Epoch 325): Loss/seq after 02150 batchs: 352.3412780761719
INFO:root:Train (Epoch 325): Loss/seq after 02200 batchs: 351.7048034667969
INFO:root:Train (Epoch 325): Loss/seq after 02250 batchs: 350.9414978027344
INFO:root:Train (Epoch 325): Loss/seq after 02300 batchs: 348.6656188964844
INFO:root:Train (Epoch 325): Loss/seq after 02350 batchs: 346.43646240234375
INFO:root:Train (Epoch 325): Loss/seq after 02400 batchs: 347.1934509277344
INFO:root:Train (Epoch 325): Loss/seq after 02450 batchs: 344.5208435058594
INFO:root:Train (Epoch 325): Loss/seq after 02500 batchs: 339.03076171875
INFO:root:Train (Epoch 325): Loss/seq after 02550 batchs: 334.47088623046875
INFO:root:Train (Epoch 325): Loss/seq after 02600 batchs: 330.9642333984375
INFO:root:Train (Epoch 325): Loss/seq after 02650 batchs: 327.71435546875
INFO:root:Train (Epoch 325): Loss/seq after 02700 batchs: 325.675048828125
INFO:root:Train (Epoch 325): Loss/seq after 02750 batchs: 322.12017822265625
INFO:root:Train (Epoch 325): Loss/seq after 02800 batchs: 321.1739807128906
INFO:root:Train (Epoch 325): Loss/seq after 02850 batchs: 320.82757568359375
INFO:root:Train (Epoch 325): Loss/seq after 02900 batchs: 321.4148254394531
INFO:root:Train (Epoch 325): Loss/seq after 02950 batchs: 322.2755126953125
INFO:root:Train (Epoch 325): Loss/seq after 03000 batchs: 325.5013122558594
INFO:root:Train (Epoch 325): Loss/seq after 03050 batchs: 327.053955078125
INFO:root:Train (Epoch 325): Loss/seq after 03100 batchs: 328.9639892578125
INFO:root:Train (Epoch 325): Loss/seq after 03150 batchs: 328.7262268066406
INFO:root:Train (Epoch 325): Loss/seq after 03200 batchs: 329.0019226074219
INFO:root:Train (Epoch 325): Loss/seq after 03250 batchs: 328.63555908203125
INFO:root:Train (Epoch 325): Loss/seq after 03300 batchs: 328.2164611816406
INFO:root:Train (Epoch 325): Loss/seq after 03350 batchs: 326.25628662109375
INFO:root:Train (Epoch 325): Loss/seq after 03400 batchs: 324.4059143066406
INFO:root:Train (Epoch 325): Loss/seq after 03450 batchs: 323.5162048339844
INFO:root:Train (Epoch 325): Loss/seq after 03500 batchs: 324.4010009765625
INFO:root:Train (Epoch 325): Loss/seq after 03550 batchs: 323.11737060546875
INFO:root:Train (Epoch 325): Loss/seq after 03600 batchs: 325.4695129394531
INFO:root:Train (Epoch 325): Loss/seq after 03650 batchs: 324.4872741699219
INFO:root:Train (Epoch 325): Loss/seq after 03700 batchs: 326.294189453125
INFO:root:Train (Epoch 325): Loss/seq after 03750 batchs: 329.59478759765625
INFO:root:Train (Epoch 325): Loss/seq after 03800 batchs: 329.4588317871094
INFO:root:Train (Epoch 325): Loss/seq after 03850 batchs: 329.1445617675781
INFO:root:Train (Epoch 325): Loss/seq after 03900 batchs: 330.42474365234375
INFO:root:Train (Epoch 325): Loss/seq after 03950 batchs: 332.3649597167969
INFO:root:Train (Epoch 325): Loss/seq after 04000 batchs: 330.646728515625
INFO:root:Train (Epoch 325): Loss/seq after 04050 batchs: 328.9478759765625
INFO:root:Train (Epoch 325): Loss/seq after 04100 batchs: 328.0594177246094
INFO:root:Train (Epoch 325): Loss/seq after 04150 batchs: 328.20782470703125
INFO:root:Train (Epoch 325): Loss/seq after 04200 batchs: 327.6859436035156
INFO:root:Train (Epoch 325): Loss/seq after 04250 batchs: 326.8997497558594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 325): Loss/seq after 00000 batches: 381.16119384765625
INFO:root:# Valid (Epoch 325): Loss/seq after 00050 batches: 716.4927978515625
INFO:root:# Valid (Epoch 325): Loss/seq after 00100 batches: 750.0176391601562
INFO:root:# Valid (Epoch 325): Loss/seq after 00150 batches: 553.1028442382812
INFO:root:# Valid (Epoch 325): Loss/seq after 00200 batches: 499.6902160644531
INFO:root:Artifacts: Make stick videos for epoch 325
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_325_on_20220423_230500.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_325_index_1836_on_20220423_230500.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 326): Loss/seq after 00000 batchs: 650.740478515625
INFO:root:Train (Epoch 326): Loss/seq after 00050 batchs: 432.5287780761719
INFO:root:Train (Epoch 326): Loss/seq after 00100 batchs: 445.6034240722656
INFO:root:Train (Epoch 326): Loss/seq after 00150 batchs: 414.88336181640625
INFO:root:Train (Epoch 326): Loss/seq after 00200 batchs: 469.9239501953125
INFO:root:Train (Epoch 326): Loss/seq after 00250 batchs: 486.63995361328125
INFO:root:Train (Epoch 326): Loss/seq after 00300 batchs: 506.5533142089844
INFO:root:Train (Epoch 326): Loss/seq after 00350 batchs: 483.3010559082031
INFO:root:Train (Epoch 326): Loss/seq after 00400 batchs: 475.39990234375
INFO:root:Train (Epoch 326): Loss/seq after 00450 batchs: 487.93426513671875
INFO:root:Train (Epoch 326): Loss/seq after 00500 batchs: 473.77587890625
INFO:root:Train (Epoch 326): Loss/seq after 00550 batchs: 465.9056701660156
INFO:root:Train (Epoch 326): Loss/seq after 00600 batchs: 450.6522216796875
INFO:root:Train (Epoch 326): Loss/seq after 00650 batchs: 434.0589904785156
INFO:root:Train (Epoch 326): Loss/seq after 00700 batchs: 416.2306213378906
INFO:root:Train (Epoch 326): Loss/seq after 00750 batchs: 410.3921203613281
INFO:root:Train (Epoch 326): Loss/seq after 00800 batchs: 411.3863830566406
INFO:root:Train (Epoch 326): Loss/seq after 00850 batchs: 398.68341064453125
INFO:root:Train (Epoch 326): Loss/seq after 00900 batchs: 388.82208251953125
INFO:root:Train (Epoch 326): Loss/seq after 00950 batchs: 388.6314392089844
INFO:root:Train (Epoch 326): Loss/seq after 01000 batchs: 383.14202880859375
INFO:root:Train (Epoch 326): Loss/seq after 01050 batchs: 375.77264404296875
INFO:root:Train (Epoch 326): Loss/seq after 01100 batchs: 367.44158935546875
INFO:root:Train (Epoch 326): Loss/seq after 01150 batchs: 357.6990661621094
INFO:root:Train (Epoch 326): Loss/seq after 01200 batchs: 358.9518737792969
INFO:root:Train (Epoch 326): Loss/seq after 01250 batchs: 358.2131042480469
INFO:root:Train (Epoch 326): Loss/seq after 01300 batchs: 350.7424011230469
INFO:root:Train (Epoch 326): Loss/seq after 01350 batchs: 343.92822265625
INFO:root:Train (Epoch 326): Loss/seq after 01400 batchs: 349.4678649902344
INFO:root:Train (Epoch 326): Loss/seq after 01450 batchs: 352.4199523925781
INFO:root:Train (Epoch 326): Loss/seq after 01500 batchs: 358.57220458984375
INFO:root:Train (Epoch 326): Loss/seq after 01550 batchs: 359.529052734375
INFO:root:Train (Epoch 326): Loss/seq after 01600 batchs: 357.9800720214844
INFO:root:Train (Epoch 326): Loss/seq after 01650 batchs: 356.2137451171875
INFO:root:Train (Epoch 326): Loss/seq after 01700 batchs: 358.2414245605469
INFO:root:Train (Epoch 326): Loss/seq after 01750 batchs: 357.40093994140625
INFO:root:Train (Epoch 326): Loss/seq after 01800 batchs: 355.89306640625
INFO:root:Train (Epoch 326): Loss/seq after 01850 batchs: 354.1769714355469
INFO:root:Train (Epoch 326): Loss/seq after 01900 batchs: 353.56292724609375
INFO:root:Train (Epoch 326): Loss/seq after 01950 batchs: 353.5090637207031
INFO:root:Train (Epoch 326): Loss/seq after 02000 batchs: 355.28662109375
INFO:root:Train (Epoch 326): Loss/seq after 02050 batchs: 355.5281677246094
INFO:root:Train (Epoch 326): Loss/seq after 02100 batchs: 354.98626708984375
INFO:root:Train (Epoch 326): Loss/seq after 02150 batchs: 354.85882568359375
INFO:root:Train (Epoch 326): Loss/seq after 02200 batchs: 354.3416442871094
INFO:root:Train (Epoch 326): Loss/seq after 02250 batchs: 353.4748840332031
INFO:root:Train (Epoch 326): Loss/seq after 02300 batchs: 351.248291015625
INFO:root:Train (Epoch 326): Loss/seq after 02350 batchs: 348.985107421875
INFO:root:Train (Epoch 326): Loss/seq after 02400 batchs: 349.7803649902344
INFO:root:Train (Epoch 326): Loss/seq after 02450 batchs: 346.96295166015625
INFO:root:Train (Epoch 326): Loss/seq after 02500 batchs: 341.38165283203125
INFO:root:Train (Epoch 326): Loss/seq after 02550 batchs: 336.68817138671875
INFO:root:Train (Epoch 326): Loss/seq after 02600 batchs: 333.21636962890625
INFO:root:Train (Epoch 326): Loss/seq after 02650 batchs: 329.8341064453125
INFO:root:Train (Epoch 326): Loss/seq after 02700 batchs: 327.74737548828125
INFO:root:Train (Epoch 326): Loss/seq after 02750 batchs: 324.0467529296875
INFO:root:Train (Epoch 326): Loss/seq after 02800 batchs: 322.3764343261719
INFO:root:Train (Epoch 326): Loss/seq after 02850 batchs: 322.1562194824219
INFO:root:Train (Epoch 326): Loss/seq after 02900 batchs: 322.4089050292969
INFO:root:Train (Epoch 326): Loss/seq after 02950 batchs: 323.43157958984375
INFO:root:Train (Epoch 326): Loss/seq after 03000 batchs: 327.1397399902344
INFO:root:Train (Epoch 326): Loss/seq after 03050 batchs: 328.64349365234375
INFO:root:Train (Epoch 326): Loss/seq after 03100 batchs: 330.2701721191406
INFO:root:Train (Epoch 326): Loss/seq after 03150 batchs: 330.8421325683594
INFO:root:Train (Epoch 326): Loss/seq after 03200 batchs: 331.1270446777344
INFO:root:Train (Epoch 326): Loss/seq after 03250 batchs: 330.91802978515625
INFO:root:Train (Epoch 326): Loss/seq after 03300 batchs: 330.6432189941406
INFO:root:Train (Epoch 326): Loss/seq after 03350 batchs: 329.02545166015625
INFO:root:Train (Epoch 326): Loss/seq after 03400 batchs: 327.1125793457031
INFO:root:Train (Epoch 326): Loss/seq after 03450 batchs: 326.12396240234375
INFO:root:Train (Epoch 326): Loss/seq after 03500 batchs: 326.6827697753906
INFO:root:Train (Epoch 326): Loss/seq after 03550 batchs: 325.255859375
INFO:root:Train (Epoch 326): Loss/seq after 03600 batchs: 327.6899108886719
INFO:root:Train (Epoch 326): Loss/seq after 03650 batchs: 326.5509033203125
INFO:root:Train (Epoch 326): Loss/seq after 03700 batchs: 327.9700622558594
INFO:root:Train (Epoch 326): Loss/seq after 03750 batchs: 331.3443298339844
INFO:root:Train (Epoch 326): Loss/seq after 03800 batchs: 331.2098083496094
INFO:root:Train (Epoch 326): Loss/seq after 03850 batchs: 330.8116760253906
INFO:root:Train (Epoch 326): Loss/seq after 03900 batchs: 331.8401794433594
INFO:root:Train (Epoch 326): Loss/seq after 03950 batchs: 333.9339904785156
INFO:root:Train (Epoch 326): Loss/seq after 04000 batchs: 332.17620849609375
INFO:root:Train (Epoch 326): Loss/seq after 04050 batchs: 330.4383850097656
INFO:root:Train (Epoch 326): Loss/seq after 04100 batchs: 329.4935607910156
INFO:root:Train (Epoch 326): Loss/seq after 04150 batchs: 329.5389709472656
INFO:root:Train (Epoch 326): Loss/seq after 04200 batchs: 329.0369567871094
INFO:root:Train (Epoch 326): Loss/seq after 04250 batchs: 328.2174987792969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 326): Loss/seq after 00000 batches: 337.38043212890625
INFO:root:# Valid (Epoch 326): Loss/seq after 00050 batches: 678.276123046875
INFO:root:# Valid (Epoch 326): Loss/seq after 00100 batches: 652.6028442382812
INFO:root:# Valid (Epoch 326): Loss/seq after 00150 batches: 491.0898742675781
INFO:root:# Valid (Epoch 326): Loss/seq after 00200 batches: 454.0633544921875
INFO:root:Artifacts: Make stick videos for epoch 326
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_326_on_20220423_231007.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_326_index_1063_on_20220423_231007.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 327): Loss/seq after 00000 batchs: 571.7855224609375
INFO:root:Train (Epoch 327): Loss/seq after 00050 batchs: 436.95550537109375
INFO:root:Train (Epoch 327): Loss/seq after 00100 batchs: 423.62615966796875
INFO:root:Train (Epoch 327): Loss/seq after 00150 batchs: 401.1720275878906
INFO:root:Train (Epoch 327): Loss/seq after 00200 batchs: 462.1439208984375
INFO:root:Train (Epoch 327): Loss/seq after 00250 batchs: 482.0798645019531
INFO:root:Train (Epoch 327): Loss/seq after 00300 batchs: 500.4051513671875
INFO:root:Train (Epoch 327): Loss/seq after 00350 batchs: 478.89031982421875
INFO:root:Train (Epoch 327): Loss/seq after 00400 batchs: 470.082275390625
INFO:root:Train (Epoch 327): Loss/seq after 00450 batchs: 483.3258972167969
INFO:root:Train (Epoch 327): Loss/seq after 00500 batchs: 470.0171203613281
INFO:root:Train (Epoch 327): Loss/seq after 00550 batchs: 461.8255310058594
INFO:root:Train (Epoch 327): Loss/seq after 00600 batchs: 446.7347412109375
INFO:root:Train (Epoch 327): Loss/seq after 00650 batchs: 430.95953369140625
INFO:root:Train (Epoch 327): Loss/seq after 00700 batchs: 415.11529541015625
INFO:root:Train (Epoch 327): Loss/seq after 00750 batchs: 408.1791687011719
INFO:root:Train (Epoch 327): Loss/seq after 00800 batchs: 410.42706298828125
INFO:root:Train (Epoch 327): Loss/seq after 00850 batchs: 397.3138122558594
INFO:root:Train (Epoch 327): Loss/seq after 00900 batchs: 386.9657897949219
INFO:root:Train (Epoch 327): Loss/seq after 00950 batchs: 387.35955810546875
INFO:root:Train (Epoch 327): Loss/seq after 01000 batchs: 380.6873474121094
INFO:root:Train (Epoch 327): Loss/seq after 01050 batchs: 372.9144287109375
INFO:root:Train (Epoch 327): Loss/seq after 01100 batchs: 364.38739013671875
INFO:root:Train (Epoch 327): Loss/seq after 01150 batchs: 354.85406494140625
INFO:root:Train (Epoch 327): Loss/seq after 01200 batchs: 354.5394287109375
INFO:root:Train (Epoch 327): Loss/seq after 01250 batchs: 353.6221618652344
INFO:root:Train (Epoch 327): Loss/seq after 01300 batchs: 346.30181884765625
INFO:root:Train (Epoch 327): Loss/seq after 01350 batchs: 339.67706298828125
INFO:root:Train (Epoch 327): Loss/seq after 01400 batchs: 340.9815368652344
INFO:root:Train (Epoch 327): Loss/seq after 01450 batchs: 344.09185791015625
INFO:root:Train (Epoch 327): Loss/seq after 01500 batchs: 349.68658447265625
INFO:root:Train (Epoch 327): Loss/seq after 01550 batchs: 350.32080078125
INFO:root:Train (Epoch 327): Loss/seq after 01600 batchs: 348.8781433105469
INFO:root:Train (Epoch 327): Loss/seq after 01650 batchs: 347.468994140625
INFO:root:Train (Epoch 327): Loss/seq after 01700 batchs: 349.24530029296875
INFO:root:Train (Epoch 327): Loss/seq after 01750 batchs: 348.6869812011719
INFO:root:Train (Epoch 327): Loss/seq after 01800 batchs: 347.3394470214844
INFO:root:Train (Epoch 327): Loss/seq after 01850 batchs: 345.9214782714844
INFO:root:Train (Epoch 327): Loss/seq after 01900 batchs: 345.2698059082031
INFO:root:Train (Epoch 327): Loss/seq after 01950 batchs: 345.3786315917969
INFO:root:Train (Epoch 327): Loss/seq after 02000 batchs: 347.41644287109375
INFO:root:Train (Epoch 327): Loss/seq after 02050 batchs: 347.72515869140625
INFO:root:Train (Epoch 327): Loss/seq after 02100 batchs: 347.4381103515625
INFO:root:Train (Epoch 327): Loss/seq after 02150 batchs: 347.4207763671875
INFO:root:Train (Epoch 327): Loss/seq after 02200 batchs: 346.94305419921875
INFO:root:Train (Epoch 327): Loss/seq after 02250 batchs: 346.5611877441406
INFO:root:Train (Epoch 327): Loss/seq after 02300 batchs: 344.0263977050781
INFO:root:Train (Epoch 327): Loss/seq after 02350 batchs: 341.9581604003906
INFO:root:Train (Epoch 327): Loss/seq after 02400 batchs: 342.8128356933594
INFO:root:Train (Epoch 327): Loss/seq after 02450 batchs: 340.17425537109375
INFO:root:Train (Epoch 327): Loss/seq after 02500 batchs: 334.703369140625
INFO:root:Train (Epoch 327): Loss/seq after 02550 batchs: 330.96588134765625
INFO:root:Train (Epoch 327): Loss/seq after 02600 batchs: 328.0934753417969
INFO:root:Train (Epoch 327): Loss/seq after 02650 batchs: 325.52264404296875
INFO:root:Train (Epoch 327): Loss/seq after 02700 batchs: 323.7166748046875
INFO:root:Train (Epoch 327): Loss/seq after 02750 batchs: 320.27313232421875
INFO:root:Train (Epoch 327): Loss/seq after 02800 batchs: 319.2820129394531
INFO:root:Train (Epoch 327): Loss/seq after 02850 batchs: 319.2367858886719
INFO:root:Train (Epoch 327): Loss/seq after 02900 batchs: 319.6705627441406
INFO:root:Train (Epoch 327): Loss/seq after 02950 batchs: 320.5827331542969
INFO:root:Train (Epoch 327): Loss/seq after 03000 batchs: 323.9329833984375
INFO:root:Train (Epoch 327): Loss/seq after 03050 batchs: 325.0982666015625
INFO:root:Train (Epoch 327): Loss/seq after 03100 batchs: 326.5942687988281
INFO:root:Train (Epoch 327): Loss/seq after 03150 batchs: 326.3932189941406
INFO:root:Train (Epoch 327): Loss/seq after 03200 batchs: 327.127685546875
INFO:root:Train (Epoch 327): Loss/seq after 03250 batchs: 326.5848083496094
INFO:root:Train (Epoch 327): Loss/seq after 03300 batchs: 326.45684814453125
INFO:root:Train (Epoch 327): Loss/seq after 03350 batchs: 325.11163330078125
INFO:root:Train (Epoch 327): Loss/seq after 03400 batchs: 323.280517578125
INFO:root:Train (Epoch 327): Loss/seq after 03450 batchs: 322.51873779296875
INFO:root:Train (Epoch 327): Loss/seq after 03500 batchs: 323.5629577636719
INFO:root:Train (Epoch 327): Loss/seq after 03550 batchs: 322.288330078125
INFO:root:Train (Epoch 327): Loss/seq after 03600 batchs: 324.91815185546875
INFO:root:Train (Epoch 327): Loss/seq after 03650 batchs: 323.99896240234375
INFO:root:Train (Epoch 327): Loss/seq after 03700 batchs: 325.7154235839844
INFO:root:Train (Epoch 327): Loss/seq after 03750 batchs: 328.8258361816406
INFO:root:Train (Epoch 327): Loss/seq after 03800 batchs: 328.783447265625
INFO:root:Train (Epoch 327): Loss/seq after 03850 batchs: 328.46173095703125
INFO:root:Train (Epoch 327): Loss/seq after 03900 batchs: 329.70562744140625
INFO:root:Train (Epoch 327): Loss/seq after 03950 batchs: 331.6947937011719
INFO:root:Train (Epoch 327): Loss/seq after 04000 batchs: 329.9866027832031
INFO:root:Train (Epoch 327): Loss/seq after 04050 batchs: 328.3095703125
INFO:root:Train (Epoch 327): Loss/seq after 04100 batchs: 327.3935241699219
INFO:root:Train (Epoch 327): Loss/seq after 04150 batchs: 327.5225830078125
INFO:root:Train (Epoch 327): Loss/seq after 04200 batchs: 326.99139404296875
INFO:root:Train (Epoch 327): Loss/seq after 04250 batchs: 326.3007507324219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 327): Loss/seq after 00000 batches: 340.71710205078125
INFO:root:# Valid (Epoch 327): Loss/seq after 00050 batches: 679.40576171875
INFO:root:# Valid (Epoch 327): Loss/seq after 00100 batches: 724.84326171875
INFO:root:# Valid (Epoch 327): Loss/seq after 00150 batches: 535.16357421875
INFO:root:# Valid (Epoch 327): Loss/seq after 00200 batches: 485.56976318359375
INFO:root:Artifacts: Make stick videos for epoch 327
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_327_on_20220423_231458.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_327_index_782_on_20220423_231458.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 328): Loss/seq after 00000 batchs: 728.3128662109375
INFO:root:Train (Epoch 328): Loss/seq after 00050 batchs: 449.3438415527344
INFO:root:Train (Epoch 328): Loss/seq after 00100 batchs: 441.9288330078125
INFO:root:Train (Epoch 328): Loss/seq after 00150 batchs: 414.79547119140625
INFO:root:Train (Epoch 328): Loss/seq after 00200 batchs: 465.78753662109375
INFO:root:Train (Epoch 328): Loss/seq after 00250 batchs: 475.5574035644531
INFO:root:Train (Epoch 328): Loss/seq after 00300 batchs: 495.16314697265625
INFO:root:Train (Epoch 328): Loss/seq after 00350 batchs: 473.62908935546875
INFO:root:Train (Epoch 328): Loss/seq after 00400 batchs: 467.41082763671875
INFO:root:Train (Epoch 328): Loss/seq after 00450 batchs: 481.5932312011719
INFO:root:Train (Epoch 328): Loss/seq after 00500 batchs: 467.47796630859375
INFO:root:Train (Epoch 328): Loss/seq after 00550 batchs: 459.822998046875
INFO:root:Train (Epoch 328): Loss/seq after 00600 batchs: 444.5614013671875
INFO:root:Train (Epoch 328): Loss/seq after 00650 batchs: 427.1446838378906
INFO:root:Train (Epoch 328): Loss/seq after 00700 batchs: 411.149169921875
INFO:root:Train (Epoch 328): Loss/seq after 00750 batchs: 403.9785461425781
INFO:root:Train (Epoch 328): Loss/seq after 00800 batchs: 404.5841064453125
INFO:root:Train (Epoch 328): Loss/seq after 00850 batchs: 392.03900146484375
INFO:root:Train (Epoch 328): Loss/seq after 00900 batchs: 382.0380554199219
INFO:root:Train (Epoch 328): Loss/seq after 00950 batchs: 380.4184265136719
INFO:root:Train (Epoch 328): Loss/seq after 01000 batchs: 374.4918518066406
INFO:root:Train (Epoch 328): Loss/seq after 01050 batchs: 367.58135986328125
INFO:root:Train (Epoch 328): Loss/seq after 01100 batchs: 359.341796875
INFO:root:Train (Epoch 328): Loss/seq after 01150 batchs: 350.1699523925781
INFO:root:Train (Epoch 328): Loss/seq after 01200 batchs: 350.62255859375
INFO:root:Train (Epoch 328): Loss/seq after 01250 batchs: 350.0071716308594
INFO:root:Train (Epoch 328): Loss/seq after 01300 batchs: 342.6027526855469
INFO:root:Train (Epoch 328): Loss/seq after 01350 batchs: 335.3045654296875
INFO:root:Train (Epoch 328): Loss/seq after 01400 batchs: 336.4508056640625
INFO:root:Train (Epoch 328): Loss/seq after 01450 batchs: 339.5871887207031
INFO:root:Train (Epoch 328): Loss/seq after 01500 batchs: 344.93231201171875
INFO:root:Train (Epoch 328): Loss/seq after 01550 batchs: 345.9114074707031
INFO:root:Train (Epoch 328): Loss/seq after 01600 batchs: 344.74310302734375
INFO:root:Train (Epoch 328): Loss/seq after 01650 batchs: 343.79376220703125
INFO:root:Train (Epoch 328): Loss/seq after 01700 batchs: 346.0099182128906
INFO:root:Train (Epoch 328): Loss/seq after 01750 batchs: 345.4189147949219
INFO:root:Train (Epoch 328): Loss/seq after 01800 batchs: 344.2583312988281
INFO:root:Train (Epoch 328): Loss/seq after 01850 batchs: 342.8962707519531
INFO:root:Train (Epoch 328): Loss/seq after 01900 batchs: 342.34149169921875
INFO:root:Train (Epoch 328): Loss/seq after 01950 batchs: 342.53790283203125
INFO:root:Train (Epoch 328): Loss/seq after 02000 batchs: 344.56085205078125
INFO:root:Train (Epoch 328): Loss/seq after 02050 batchs: 344.84442138671875
INFO:root:Train (Epoch 328): Loss/seq after 02100 batchs: 344.6699523925781
INFO:root:Train (Epoch 328): Loss/seq after 02150 batchs: 344.57269287109375
INFO:root:Train (Epoch 328): Loss/seq after 02200 batchs: 344.1718444824219
INFO:root:Train (Epoch 328): Loss/seq after 02250 batchs: 343.4436950683594
INFO:root:Train (Epoch 328): Loss/seq after 02300 batchs: 341.1108703613281
INFO:root:Train (Epoch 328): Loss/seq after 02350 batchs: 339.1464538574219
INFO:root:Train (Epoch 328): Loss/seq after 02400 batchs: 339.8856201171875
INFO:root:Train (Epoch 328): Loss/seq after 02450 batchs: 337.24835205078125
INFO:root:Train (Epoch 328): Loss/seq after 02500 batchs: 331.81036376953125
INFO:root:Train (Epoch 328): Loss/seq after 02550 batchs: 327.3469543457031
INFO:root:Train (Epoch 328): Loss/seq after 02600 batchs: 323.86248779296875
INFO:root:Train (Epoch 328): Loss/seq after 02650 batchs: 320.7602844238281
INFO:root:Train (Epoch 328): Loss/seq after 02700 batchs: 318.7890625
INFO:root:Train (Epoch 328): Loss/seq after 02750 batchs: 315.1170959472656
INFO:root:Train (Epoch 328): Loss/seq after 02800 batchs: 313.61407470703125
INFO:root:Train (Epoch 328): Loss/seq after 02850 batchs: 313.4351806640625
INFO:root:Train (Epoch 328): Loss/seq after 02900 batchs: 313.790283203125
INFO:root:Train (Epoch 328): Loss/seq after 02950 batchs: 314.84783935546875
INFO:root:Train (Epoch 328): Loss/seq after 03000 batchs: 318.3565368652344
INFO:root:Train (Epoch 328): Loss/seq after 03050 batchs: 320.0016174316406
INFO:root:Train (Epoch 328): Loss/seq after 03100 batchs: 321.1695251464844
INFO:root:Train (Epoch 328): Loss/seq after 03150 batchs: 321.47454833984375
INFO:root:Train (Epoch 328): Loss/seq after 03200 batchs: 321.5995178222656
INFO:root:Train (Epoch 328): Loss/seq after 03250 batchs: 321.4398498535156
INFO:root:Train (Epoch 328): Loss/seq after 03300 batchs: 320.7845458984375
INFO:root:Train (Epoch 328): Loss/seq after 03350 batchs: 319.3348693847656
INFO:root:Train (Epoch 328): Loss/seq after 03400 batchs: 317.61370849609375
INFO:root:Train (Epoch 328): Loss/seq after 03450 batchs: 317.04913330078125
INFO:root:Train (Epoch 328): Loss/seq after 03500 batchs: 317.7922058105469
INFO:root:Train (Epoch 328): Loss/seq after 03550 batchs: 316.5719909667969
INFO:root:Train (Epoch 328): Loss/seq after 03600 batchs: 319.05126953125
INFO:root:Train (Epoch 328): Loss/seq after 03650 batchs: 317.9798278808594
INFO:root:Train (Epoch 328): Loss/seq after 03700 batchs: 319.5655212402344
INFO:root:Train (Epoch 328): Loss/seq after 03750 batchs: 322.65185546875
INFO:root:Train (Epoch 328): Loss/seq after 03800 batchs: 322.6401672363281
INFO:root:Train (Epoch 328): Loss/seq after 03850 batchs: 322.3377990722656
INFO:root:Train (Epoch 328): Loss/seq after 03900 batchs: 323.34259033203125
INFO:root:Train (Epoch 328): Loss/seq after 03950 batchs: 325.5316467285156
INFO:root:Train (Epoch 328): Loss/seq after 04000 batchs: 323.8617858886719
INFO:root:Train (Epoch 328): Loss/seq after 04050 batchs: 322.1637878417969
INFO:root:Train (Epoch 328): Loss/seq after 04100 batchs: 321.2686767578125
INFO:root:Train (Epoch 328): Loss/seq after 04150 batchs: 321.60345458984375
INFO:root:Train (Epoch 328): Loss/seq after 04200 batchs: 321.115478515625
INFO:root:Train (Epoch 328): Loss/seq after 04250 batchs: 320.3895568847656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 328): Loss/seq after 00000 batches: 289.06927490234375
INFO:root:# Valid (Epoch 328): Loss/seq after 00050 batches: 686.4902954101562
INFO:root:# Valid (Epoch 328): Loss/seq after 00100 batches: 720.998291015625
INFO:root:# Valid (Epoch 328): Loss/seq after 00150 batches: 533.0255737304688
INFO:root:# Valid (Epoch 328): Loss/seq after 00200 batches: 481.37225341796875
INFO:root:Artifacts: Make stick videos for epoch 328
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_328_on_20220423_231947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_328_index_1510_on_20220423_231947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 329): Loss/seq after 00000 batchs: 504.15106201171875
INFO:root:Train (Epoch 329): Loss/seq after 00050 batchs: 415.3819580078125
INFO:root:Train (Epoch 329): Loss/seq after 00100 batchs: 420.53167724609375
INFO:root:Train (Epoch 329): Loss/seq after 00150 batchs: 399.6025695800781
INFO:root:Train (Epoch 329): Loss/seq after 00200 batchs: 459.955810546875
INFO:root:Train (Epoch 329): Loss/seq after 00250 batchs: 483.7840881347656
INFO:root:Train (Epoch 329): Loss/seq after 00300 batchs: 501.9482727050781
INFO:root:Train (Epoch 329): Loss/seq after 00350 batchs: 477.9551696777344
INFO:root:Train (Epoch 329): Loss/seq after 00400 batchs: 467.6507263183594
INFO:root:Train (Epoch 329): Loss/seq after 00450 batchs: 481.59832763671875
INFO:root:Train (Epoch 329): Loss/seq after 00500 batchs: 467.6045227050781
INFO:root:Train (Epoch 329): Loss/seq after 00550 batchs: 459.7976379394531
INFO:root:Train (Epoch 329): Loss/seq after 00600 batchs: 444.35943603515625
INFO:root:Train (Epoch 329): Loss/seq after 00650 batchs: 427.33453369140625
INFO:root:Train (Epoch 329): Loss/seq after 00700 batchs: 409.75054931640625
INFO:root:Train (Epoch 329): Loss/seq after 00750 batchs: 404.7227783203125
INFO:root:Train (Epoch 329): Loss/seq after 00800 batchs: 406.1205139160156
INFO:root:Train (Epoch 329): Loss/seq after 00850 batchs: 392.87213134765625
INFO:root:Train (Epoch 329): Loss/seq after 00900 batchs: 382.91876220703125
INFO:root:Train (Epoch 329): Loss/seq after 00950 batchs: 381.6120910644531
INFO:root:Train (Epoch 329): Loss/seq after 01000 batchs: 377.2710266113281
INFO:root:Train (Epoch 329): Loss/seq after 01050 batchs: 372.197265625
INFO:root:Train (Epoch 329): Loss/seq after 01100 batchs: 364.20184326171875
INFO:root:Train (Epoch 329): Loss/seq after 01150 batchs: 354.84722900390625
INFO:root:Train (Epoch 329): Loss/seq after 01200 batchs: 355.2756042480469
INFO:root:Train (Epoch 329): Loss/seq after 01250 batchs: 354.68072509765625
INFO:root:Train (Epoch 329): Loss/seq after 01300 batchs: 347.31689453125
INFO:root:Train (Epoch 329): Loss/seq after 01350 batchs: 340.14862060546875
INFO:root:Train (Epoch 329): Loss/seq after 01400 batchs: 340.4431457519531
INFO:root:Train (Epoch 329): Loss/seq after 01450 batchs: 343.4372863769531
INFO:root:Train (Epoch 329): Loss/seq after 01500 batchs: 349.0245056152344
INFO:root:Train (Epoch 329): Loss/seq after 01550 batchs: 350.2960205078125
INFO:root:Train (Epoch 329): Loss/seq after 01600 batchs: 349.2378845214844
INFO:root:Train (Epoch 329): Loss/seq after 01650 batchs: 347.856201171875
INFO:root:Train (Epoch 329): Loss/seq after 01700 batchs: 349.866455078125
INFO:root:Train (Epoch 329): Loss/seq after 01750 batchs: 349.3818359375
INFO:root:Train (Epoch 329): Loss/seq after 01800 batchs: 348.17156982421875
INFO:root:Train (Epoch 329): Loss/seq after 01850 batchs: 346.491455078125
INFO:root:Train (Epoch 329): Loss/seq after 01900 batchs: 345.9324951171875
INFO:root:Train (Epoch 329): Loss/seq after 01950 batchs: 346.2452087402344
INFO:root:Train (Epoch 329): Loss/seq after 02000 batchs: 348.1055908203125
INFO:root:Train (Epoch 329): Loss/seq after 02050 batchs: 348.2636413574219
INFO:root:Train (Epoch 329): Loss/seq after 02100 batchs: 347.8779602050781
INFO:root:Train (Epoch 329): Loss/seq after 02150 batchs: 347.8294677734375
INFO:root:Train (Epoch 329): Loss/seq after 02200 batchs: 347.1780090332031
INFO:root:Train (Epoch 329): Loss/seq after 02250 batchs: 346.6803283691406
INFO:root:Train (Epoch 329): Loss/seq after 02300 batchs: 344.2538757324219
INFO:root:Train (Epoch 329): Loss/seq after 02350 batchs: 342.1361083984375
INFO:root:Train (Epoch 329): Loss/seq after 02400 batchs: 342.8223876953125
INFO:root:Train (Epoch 329): Loss/seq after 02450 batchs: 340.1919250488281
INFO:root:Train (Epoch 329): Loss/seq after 02500 batchs: 334.75048828125
INFO:root:Train (Epoch 329): Loss/seq after 02550 batchs: 330.30084228515625
INFO:root:Train (Epoch 329): Loss/seq after 02600 batchs: 326.95245361328125
INFO:root:Train (Epoch 329): Loss/seq after 02650 batchs: 323.8566589355469
INFO:root:Train (Epoch 329): Loss/seq after 02700 batchs: 321.84527587890625
INFO:root:Train (Epoch 329): Loss/seq after 02750 batchs: 317.98516845703125
INFO:root:Train (Epoch 329): Loss/seq after 02800 batchs: 316.38031005859375
INFO:root:Train (Epoch 329): Loss/seq after 02850 batchs: 316.13372802734375
INFO:root:Train (Epoch 329): Loss/seq after 02900 batchs: 316.6707763671875
INFO:root:Train (Epoch 329): Loss/seq after 02950 batchs: 317.66558837890625
INFO:root:Train (Epoch 329): Loss/seq after 03000 batchs: 321.06396484375
INFO:root:Train (Epoch 329): Loss/seq after 03050 batchs: 322.5045471191406
INFO:root:Train (Epoch 329): Loss/seq after 03100 batchs: 323.8507995605469
INFO:root:Train (Epoch 329): Loss/seq after 03150 batchs: 323.7597961425781
INFO:root:Train (Epoch 329): Loss/seq after 03200 batchs: 323.7984313964844
INFO:root:Train (Epoch 329): Loss/seq after 03250 batchs: 323.88446044921875
INFO:root:Train (Epoch 329): Loss/seq after 03300 batchs: 323.44561767578125
INFO:root:Train (Epoch 329): Loss/seq after 03350 batchs: 322.0968933105469
INFO:root:Train (Epoch 329): Loss/seq after 03400 batchs: 320.28680419921875
INFO:root:Train (Epoch 329): Loss/seq after 03450 batchs: 319.5068664550781
INFO:root:Train (Epoch 329): Loss/seq after 03500 batchs: 320.18890380859375
INFO:root:Train (Epoch 329): Loss/seq after 03550 batchs: 319.0997009277344
INFO:root:Train (Epoch 329): Loss/seq after 03600 batchs: 321.8169860839844
INFO:root:Train (Epoch 329): Loss/seq after 03650 batchs: 320.5338134765625
INFO:root:Train (Epoch 329): Loss/seq after 03700 batchs: 321.98651123046875
INFO:root:Train (Epoch 329): Loss/seq after 03750 batchs: 324.9906921386719
INFO:root:Train (Epoch 329): Loss/seq after 03800 batchs: 324.9554138183594
INFO:root:Train (Epoch 329): Loss/seq after 03850 batchs: 324.57086181640625
INFO:root:Train (Epoch 329): Loss/seq after 03900 batchs: 325.5991516113281
INFO:root:Train (Epoch 329): Loss/seq after 03950 batchs: 328.1017761230469
INFO:root:Train (Epoch 329): Loss/seq after 04000 batchs: 326.4083251953125
INFO:root:Train (Epoch 329): Loss/seq after 04050 batchs: 324.74267578125
INFO:root:Train (Epoch 329): Loss/seq after 04100 batchs: 323.8880920410156
INFO:root:Train (Epoch 329): Loss/seq after 04150 batchs: 324.0699768066406
INFO:root:Train (Epoch 329): Loss/seq after 04200 batchs: 323.6264343261719
INFO:root:Train (Epoch 329): Loss/seq after 04250 batchs: 322.80853271484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 329): Loss/seq after 00000 batches: 301.2253723144531
INFO:root:# Valid (Epoch 329): Loss/seq after 00050 batches: 655.3470458984375
INFO:root:# Valid (Epoch 329): Loss/seq after 00100 batches: 658.50634765625
INFO:root:# Valid (Epoch 329): Loss/seq after 00150 batches: 491.1254577636719
INFO:root:# Valid (Epoch 329): Loss/seq after 00200 batches: 453.0097961425781
INFO:root:Artifacts: Make stick videos for epoch 329
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_329_on_20220423_232436.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_329_index_1343_on_20220423_232436.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 330): Loss/seq after 00000 batchs: 434.4399719238281
INFO:root:Train (Epoch 330): Loss/seq after 00050 batchs: 423.735107421875
INFO:root:Train (Epoch 330): Loss/seq after 00100 batchs: 448.29547119140625
INFO:root:Train (Epoch 330): Loss/seq after 00150 batchs: 418.2103576660156
INFO:root:Train (Epoch 330): Loss/seq after 00200 batchs: 465.1854553222656
INFO:root:Train (Epoch 330): Loss/seq after 00250 batchs: 475.45074462890625
INFO:root:Train (Epoch 330): Loss/seq after 00300 batchs: 495.013427734375
INFO:root:Train (Epoch 330): Loss/seq after 00350 batchs: 472.6207580566406
INFO:root:Train (Epoch 330): Loss/seq after 00400 batchs: 464.9540100097656
INFO:root:Train (Epoch 330): Loss/seq after 00450 batchs: 478.7896423339844
INFO:root:Train (Epoch 330): Loss/seq after 00500 batchs: 463.4256591796875
INFO:root:Train (Epoch 330): Loss/seq after 00550 batchs: 456.3484802246094
INFO:root:Train (Epoch 330): Loss/seq after 00600 batchs: 441.6148986816406
INFO:root:Train (Epoch 330): Loss/seq after 00650 batchs: 425.849609375
INFO:root:Train (Epoch 330): Loss/seq after 00700 batchs: 409.7426452636719
INFO:root:Train (Epoch 330): Loss/seq after 00750 batchs: 402.1273498535156
INFO:root:Train (Epoch 330): Loss/seq after 00800 batchs: 404.3598937988281
INFO:root:Train (Epoch 330): Loss/seq after 00850 batchs: 391.63006591796875
INFO:root:Train (Epoch 330): Loss/seq after 00900 batchs: 381.7955322265625
INFO:root:Train (Epoch 330): Loss/seq after 00950 batchs: 380.026611328125
INFO:root:Train (Epoch 330): Loss/seq after 01000 batchs: 373.4543762207031
INFO:root:Train (Epoch 330): Loss/seq after 01050 batchs: 366.8269958496094
INFO:root:Train (Epoch 330): Loss/seq after 01100 batchs: 358.7490234375
INFO:root:Train (Epoch 330): Loss/seq after 01150 batchs: 349.5334777832031
INFO:root:Train (Epoch 330): Loss/seq after 01200 batchs: 350.0666198730469
INFO:root:Train (Epoch 330): Loss/seq after 01250 batchs: 349.5328369140625
INFO:root:Train (Epoch 330): Loss/seq after 01300 batchs: 342.1240539550781
INFO:root:Train (Epoch 330): Loss/seq after 01350 batchs: 335.2906188964844
INFO:root:Train (Epoch 330): Loss/seq after 01400 batchs: 336.472412109375
INFO:root:Train (Epoch 330): Loss/seq after 01450 batchs: 339.329345703125
INFO:root:Train (Epoch 330): Loss/seq after 01500 batchs: 345.34979248046875
INFO:root:Train (Epoch 330): Loss/seq after 01550 batchs: 346.6959228515625
INFO:root:Train (Epoch 330): Loss/seq after 01600 batchs: 345.646728515625
INFO:root:Train (Epoch 330): Loss/seq after 01650 batchs: 344.3664245605469
INFO:root:Train (Epoch 330): Loss/seq after 01700 batchs: 346.42498779296875
INFO:root:Train (Epoch 330): Loss/seq after 01750 batchs: 346.1120300292969
INFO:root:Train (Epoch 330): Loss/seq after 01800 batchs: 345.0421447753906
INFO:root:Train (Epoch 330): Loss/seq after 01850 batchs: 343.5627136230469
INFO:root:Train (Epoch 330): Loss/seq after 01900 batchs: 343.08984375
INFO:root:Train (Epoch 330): Loss/seq after 01950 batchs: 343.1387939453125
INFO:root:Train (Epoch 330): Loss/seq after 02000 batchs: 345.1817626953125
INFO:root:Train (Epoch 330): Loss/seq after 02050 batchs: 345.41644287109375
INFO:root:Train (Epoch 330): Loss/seq after 02100 batchs: 345.44720458984375
INFO:root:Train (Epoch 330): Loss/seq after 02150 batchs: 345.421630859375
INFO:root:Train (Epoch 330): Loss/seq after 02200 batchs: 344.95587158203125
INFO:root:Train (Epoch 330): Loss/seq after 02250 batchs: 344.397705078125
INFO:root:Train (Epoch 330): Loss/seq after 02300 batchs: 342.4287109375
INFO:root:Train (Epoch 330): Loss/seq after 02350 batchs: 340.44781494140625
INFO:root:Train (Epoch 330): Loss/seq after 02400 batchs: 341.034912109375
INFO:root:Train (Epoch 330): Loss/seq after 02450 batchs: 338.3980712890625
INFO:root:Train (Epoch 330): Loss/seq after 02500 batchs: 332.9739990234375
INFO:root:Train (Epoch 330): Loss/seq after 02550 batchs: 328.4856262207031
INFO:root:Train (Epoch 330): Loss/seq after 02600 batchs: 324.9734802246094
INFO:root:Train (Epoch 330): Loss/seq after 02650 batchs: 321.7440490722656
INFO:root:Train (Epoch 330): Loss/seq after 02700 batchs: 319.7209167480469
INFO:root:Train (Epoch 330): Loss/seq after 02750 batchs: 315.8424987792969
INFO:root:Train (Epoch 330): Loss/seq after 02800 batchs: 314.5209655761719
INFO:root:Train (Epoch 330): Loss/seq after 02850 batchs: 314.2867126464844
INFO:root:Train (Epoch 330): Loss/seq after 02900 batchs: 314.5567932128906
INFO:root:Train (Epoch 330): Loss/seq after 02950 batchs: 315.5417175292969
INFO:root:Train (Epoch 330): Loss/seq after 03000 batchs: 319.01446533203125
INFO:root:Train (Epoch 330): Loss/seq after 03050 batchs: 320.44879150390625
INFO:root:Train (Epoch 330): Loss/seq after 03100 batchs: 321.55255126953125
INFO:root:Train (Epoch 330): Loss/seq after 03150 batchs: 321.3076171875
INFO:root:Train (Epoch 330): Loss/seq after 03200 batchs: 320.9750671386719
INFO:root:Train (Epoch 330): Loss/seq after 03250 batchs: 320.921875
INFO:root:Train (Epoch 330): Loss/seq after 03300 batchs: 320.3260498046875
INFO:root:Train (Epoch 330): Loss/seq after 03350 batchs: 318.625244140625
INFO:root:Train (Epoch 330): Loss/seq after 03400 batchs: 316.7431335449219
INFO:root:Train (Epoch 330): Loss/seq after 03450 batchs: 315.8849792480469
INFO:root:Train (Epoch 330): Loss/seq after 03500 batchs: 316.4243469238281
INFO:root:Train (Epoch 330): Loss/seq after 03550 batchs: 315.2230529785156
INFO:root:Train (Epoch 330): Loss/seq after 03600 batchs: 317.8811950683594
INFO:root:Train (Epoch 330): Loss/seq after 03650 batchs: 316.7724609375
INFO:root:Train (Epoch 330): Loss/seq after 03700 batchs: 318.3665466308594
INFO:root:Train (Epoch 330): Loss/seq after 03750 batchs: 321.5046691894531
INFO:root:Train (Epoch 330): Loss/seq after 03800 batchs: 321.4742126464844
INFO:root:Train (Epoch 330): Loss/seq after 03850 batchs: 321.14178466796875
INFO:root:Train (Epoch 330): Loss/seq after 03900 batchs: 322.2009582519531
INFO:root:Train (Epoch 330): Loss/seq after 03950 batchs: 324.36859130859375
INFO:root:Train (Epoch 330): Loss/seq after 04000 batchs: 322.7403259277344
INFO:root:Train (Epoch 330): Loss/seq after 04050 batchs: 321.0854187011719
INFO:root:Train (Epoch 330): Loss/seq after 04100 batchs: 320.2235412597656
INFO:root:Train (Epoch 330): Loss/seq after 04150 batchs: 320.3336181640625
INFO:root:Train (Epoch 330): Loss/seq after 04200 batchs: 319.92449951171875
INFO:root:Train (Epoch 330): Loss/seq after 04250 batchs: 319.1191101074219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 330): Loss/seq after 00000 batches: 344.3114929199219
INFO:root:# Valid (Epoch 330): Loss/seq after 00050 batches: 671.5635375976562
INFO:root:# Valid (Epoch 330): Loss/seq after 00100 batches: 663.4905395507812
INFO:root:# Valid (Epoch 330): Loss/seq after 00150 batches: 496.2950744628906
INFO:root:# Valid (Epoch 330): Loss/seq after 00200 batches: 456.76776123046875
INFO:root:Artifacts: Make stick videos for epoch 330
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_330_on_20220423_232939.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_330_index_286_on_20220423_232939.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 331): Loss/seq after 00000 batchs: 435.0272216796875
INFO:root:Train (Epoch 331): Loss/seq after 00050 batchs: 439.7626647949219
INFO:root:Train (Epoch 331): Loss/seq after 00100 batchs: 434.4804382324219
INFO:root:Train (Epoch 331): Loss/seq after 00150 batchs: 408.99407958984375
INFO:root:Train (Epoch 331): Loss/seq after 00200 batchs: 462.1313781738281
INFO:root:Train (Epoch 331): Loss/seq after 00250 batchs: 471.8852844238281
INFO:root:Train (Epoch 331): Loss/seq after 00300 batchs: 490.0107421875
INFO:root:Train (Epoch 331): Loss/seq after 00350 batchs: 468.1294860839844
INFO:root:Train (Epoch 331): Loss/seq after 00400 batchs: 458.4772644042969
INFO:root:Train (Epoch 331): Loss/seq after 00450 batchs: 472.9195556640625
INFO:root:Train (Epoch 331): Loss/seq after 00500 batchs: 460.5110168457031
INFO:root:Train (Epoch 331): Loss/seq after 00550 batchs: 453.47894287109375
INFO:root:Train (Epoch 331): Loss/seq after 00600 batchs: 439.3802490234375
INFO:root:Train (Epoch 331): Loss/seq after 00650 batchs: 422.2568054199219
INFO:root:Train (Epoch 331): Loss/seq after 00700 batchs: 406.2162780761719
INFO:root:Train (Epoch 331): Loss/seq after 00750 batchs: 400.5201721191406
INFO:root:Train (Epoch 331): Loss/seq after 00800 batchs: 402.899658203125
INFO:root:Train (Epoch 331): Loss/seq after 00850 batchs: 390.8909606933594
INFO:root:Train (Epoch 331): Loss/seq after 00900 batchs: 381.6239013671875
INFO:root:Train (Epoch 331): Loss/seq after 00950 batchs: 381.54095458984375
INFO:root:Train (Epoch 331): Loss/seq after 01000 batchs: 375.5580139160156
INFO:root:Train (Epoch 331): Loss/seq after 01050 batchs: 369.82830810546875
INFO:root:Train (Epoch 331): Loss/seq after 01100 batchs: 362.1148986816406
INFO:root:Train (Epoch 331): Loss/seq after 01150 batchs: 352.8570556640625
INFO:root:Train (Epoch 331): Loss/seq after 01200 batchs: 352.74713134765625
INFO:root:Train (Epoch 331): Loss/seq after 01250 batchs: 352.680419921875
INFO:root:Train (Epoch 331): Loss/seq after 01300 batchs: 345.1639404296875
INFO:root:Train (Epoch 331): Loss/seq after 01350 batchs: 337.75213623046875
INFO:root:Train (Epoch 331): Loss/seq after 01400 batchs: 338.60107421875
INFO:root:Train (Epoch 331): Loss/seq after 01450 batchs: 342.0724182128906
INFO:root:Train (Epoch 331): Loss/seq after 01500 batchs: 348.03704833984375
INFO:root:Train (Epoch 331): Loss/seq after 01550 batchs: 349.4683532714844
INFO:root:Train (Epoch 331): Loss/seq after 01600 batchs: 349.1051330566406
INFO:root:Train (Epoch 331): Loss/seq after 01650 batchs: 347.9975280761719
INFO:root:Train (Epoch 331): Loss/seq after 01700 batchs: 350.0993347167969
INFO:root:Train (Epoch 331): Loss/seq after 01750 batchs: 349.8677673339844
INFO:root:Train (Epoch 331): Loss/seq after 01800 batchs: 348.8289794921875
INFO:root:Train (Epoch 331): Loss/seq after 01850 batchs: 347.4781799316406
INFO:root:Train (Epoch 331): Loss/seq after 01900 batchs: 346.7242126464844
INFO:root:Train (Epoch 331): Loss/seq after 01950 batchs: 346.5912780761719
INFO:root:Train (Epoch 331): Loss/seq after 02000 batchs: 348.4917907714844
INFO:root:Train (Epoch 331): Loss/seq after 02050 batchs: 348.890625
INFO:root:Train (Epoch 331): Loss/seq after 02100 batchs: 348.4515686035156
INFO:root:Train (Epoch 331): Loss/seq after 02150 batchs: 348.40399169921875
INFO:root:Train (Epoch 331): Loss/seq after 02200 batchs: 347.94049072265625
INFO:root:Train (Epoch 331): Loss/seq after 02250 batchs: 347.2501525878906
INFO:root:Train (Epoch 331): Loss/seq after 02300 batchs: 345.2064208984375
INFO:root:Train (Epoch 331): Loss/seq after 02350 batchs: 343.1874694824219
INFO:root:Train (Epoch 331): Loss/seq after 02400 batchs: 343.65875244140625
INFO:root:Train (Epoch 331): Loss/seq after 02450 batchs: 340.892578125
INFO:root:Train (Epoch 331): Loss/seq after 02500 batchs: 335.4526672363281
INFO:root:Train (Epoch 331): Loss/seq after 02550 batchs: 331.3841247558594
INFO:root:Train (Epoch 331): Loss/seq after 02600 batchs: 328.0031433105469
INFO:root:Train (Epoch 331): Loss/seq after 02650 batchs: 324.648681640625
INFO:root:Train (Epoch 331): Loss/seq after 02700 batchs: 322.60931396484375
INFO:root:Train (Epoch 331): Loss/seq after 02750 batchs: 318.8794860839844
INFO:root:Train (Epoch 331): Loss/seq after 02800 batchs: 317.36883544921875
INFO:root:Train (Epoch 331): Loss/seq after 02850 batchs: 316.9412536621094
INFO:root:Train (Epoch 331): Loss/seq after 02900 batchs: 317.3608093261719
INFO:root:Train (Epoch 331): Loss/seq after 02950 batchs: 318.3213806152344
INFO:root:Train (Epoch 331): Loss/seq after 03000 batchs: 321.27130126953125
INFO:root:Train (Epoch 331): Loss/seq after 03050 batchs: 322.2989807128906
INFO:root:Train (Epoch 331): Loss/seq after 03100 batchs: 323.49951171875
INFO:root:Train (Epoch 331): Loss/seq after 03150 batchs: 323.14141845703125
INFO:root:Train (Epoch 331): Loss/seq after 03200 batchs: 322.593505859375
INFO:root:Train (Epoch 331): Loss/seq after 03250 batchs: 322.30743408203125
INFO:root:Train (Epoch 331): Loss/seq after 03300 batchs: 321.673095703125
INFO:root:Train (Epoch 331): Loss/seq after 03350 batchs: 319.9620361328125
INFO:root:Train (Epoch 331): Loss/seq after 03400 batchs: 318.11260986328125
INFO:root:Train (Epoch 331): Loss/seq after 03450 batchs: 317.3512878417969
INFO:root:Train (Epoch 331): Loss/seq after 03500 batchs: 318.0386657714844
INFO:root:Train (Epoch 331): Loss/seq after 03550 batchs: 316.8059387207031
INFO:root:Train (Epoch 331): Loss/seq after 03600 batchs: 318.930419921875
INFO:root:Train (Epoch 331): Loss/seq after 03650 batchs: 317.7850036621094
INFO:root:Train (Epoch 331): Loss/seq after 03700 batchs: 319.2530517578125
INFO:root:Train (Epoch 331): Loss/seq after 03750 batchs: 322.216064453125
INFO:root:Train (Epoch 331): Loss/seq after 03800 batchs: 322.1936340332031
INFO:root:Train (Epoch 331): Loss/seq after 03850 batchs: 321.8155822753906
INFO:root:Train (Epoch 331): Loss/seq after 03900 batchs: 323.4543151855469
INFO:root:Train (Epoch 331): Loss/seq after 03950 batchs: 325.49395751953125
INFO:root:Train (Epoch 331): Loss/seq after 04000 batchs: 323.83856201171875
INFO:root:Train (Epoch 331): Loss/seq after 04050 batchs: 322.2093505859375
INFO:root:Train (Epoch 331): Loss/seq after 04100 batchs: 321.3540954589844
INFO:root:Train (Epoch 331): Loss/seq after 04150 batchs: 321.4394226074219
INFO:root:Train (Epoch 331): Loss/seq after 04200 batchs: 320.9109191894531
INFO:root:Train (Epoch 331): Loss/seq after 04250 batchs: 320.12109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 331): Loss/seq after 00000 batches: 327.22064208984375
INFO:root:# Valid (Epoch 331): Loss/seq after 00050 batches: 662.8309326171875
INFO:root:# Valid (Epoch 331): Loss/seq after 00100 batches: 658.9783935546875
INFO:root:# Valid (Epoch 331): Loss/seq after 00150 batches: 491.5089111328125
INFO:root:# Valid (Epoch 331): Loss/seq after 00200 batches: 452.65496826171875
INFO:root:Artifacts: Make stick videos for epoch 331
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_331_on_20220423_233436.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_331_index_10_on_20220423_233436.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 332): Loss/seq after 00000 batchs: 577.638427734375
INFO:root:Train (Epoch 332): Loss/seq after 00050 batchs: 426.72576904296875
INFO:root:Train (Epoch 332): Loss/seq after 00100 batchs: 425.49700927734375
INFO:root:Train (Epoch 332): Loss/seq after 00150 batchs: 400.0713195800781
INFO:root:Train (Epoch 332): Loss/seq after 00200 batchs: 450.30133056640625
INFO:root:Train (Epoch 332): Loss/seq after 00250 batchs: 452.939697265625
INFO:root:Train (Epoch 332): Loss/seq after 00300 batchs: 473.0644226074219
INFO:root:Train (Epoch 332): Loss/seq after 00350 batchs: 453.5291442871094
INFO:root:Train (Epoch 332): Loss/seq after 00400 batchs: 444.9596862792969
INFO:root:Train (Epoch 332): Loss/seq after 00450 batchs: 459.9378967285156
INFO:root:Train (Epoch 332): Loss/seq after 00500 batchs: 446.9154052734375
INFO:root:Train (Epoch 332): Loss/seq after 00550 batchs: 441.3457946777344
INFO:root:Train (Epoch 332): Loss/seq after 00600 batchs: 427.80010986328125
INFO:root:Train (Epoch 332): Loss/seq after 00650 batchs: 409.50518798828125
INFO:root:Train (Epoch 332): Loss/seq after 00700 batchs: 392.41558837890625
INFO:root:Train (Epoch 332): Loss/seq after 00750 batchs: 386.21502685546875
INFO:root:Train (Epoch 332): Loss/seq after 00800 batchs: 388.4240417480469
INFO:root:Train (Epoch 332): Loss/seq after 00850 batchs: 376.8306579589844
INFO:root:Train (Epoch 332): Loss/seq after 00900 batchs: 367.8612365722656
INFO:root:Train (Epoch 332): Loss/seq after 00950 batchs: 366.6611022949219
INFO:root:Train (Epoch 332): Loss/seq after 01000 batchs: 359.9210205078125
INFO:root:Train (Epoch 332): Loss/seq after 01050 batchs: 353.2294616699219
INFO:root:Train (Epoch 332): Loss/seq after 01100 batchs: 345.0251159667969
INFO:root:Train (Epoch 332): Loss/seq after 01150 batchs: 336.0487365722656
INFO:root:Train (Epoch 332): Loss/seq after 01200 batchs: 338.000732421875
INFO:root:Train (Epoch 332): Loss/seq after 01250 batchs: 337.5355224609375
INFO:root:Train (Epoch 332): Loss/seq after 01300 batchs: 330.2375183105469
INFO:root:Train (Epoch 332): Loss/seq after 01350 batchs: 323.43121337890625
INFO:root:Train (Epoch 332): Loss/seq after 01400 batchs: 324.5008850097656
INFO:root:Train (Epoch 332): Loss/seq after 01450 batchs: 328.23846435546875
INFO:root:Train (Epoch 332): Loss/seq after 01500 batchs: 335.52581787109375
INFO:root:Train (Epoch 332): Loss/seq after 01550 batchs: 336.7043762207031
INFO:root:Train (Epoch 332): Loss/seq after 01600 batchs: 336.01702880859375
INFO:root:Train (Epoch 332): Loss/seq after 01650 batchs: 334.8786315917969
INFO:root:Train (Epoch 332): Loss/seq after 01700 batchs: 337.0909423828125
INFO:root:Train (Epoch 332): Loss/seq after 01750 batchs: 336.720458984375
INFO:root:Train (Epoch 332): Loss/seq after 01800 batchs: 335.8540344238281
INFO:root:Train (Epoch 332): Loss/seq after 01850 batchs: 334.7191467285156
INFO:root:Train (Epoch 332): Loss/seq after 01900 batchs: 334.6531982421875
INFO:root:Train (Epoch 332): Loss/seq after 01950 batchs: 335.13427734375
INFO:root:Train (Epoch 332): Loss/seq after 02000 batchs: 337.41217041015625
INFO:root:Train (Epoch 332): Loss/seq after 02050 batchs: 338.05609130859375
INFO:root:Train (Epoch 332): Loss/seq after 02100 batchs: 338.2033996582031
INFO:root:Train (Epoch 332): Loss/seq after 02150 batchs: 338.21728515625
INFO:root:Train (Epoch 332): Loss/seq after 02200 batchs: 337.7413024902344
INFO:root:Train (Epoch 332): Loss/seq after 02250 batchs: 337.3208312988281
INFO:root:Train (Epoch 332): Loss/seq after 02300 batchs: 335.1319885253906
INFO:root:Train (Epoch 332): Loss/seq after 02350 batchs: 333.2802734375
INFO:root:Train (Epoch 332): Loss/seq after 02400 batchs: 333.9234619140625
INFO:root:Train (Epoch 332): Loss/seq after 02450 batchs: 331.5130920410156
INFO:root:Train (Epoch 332): Loss/seq after 02500 batchs: 326.24371337890625
INFO:root:Train (Epoch 332): Loss/seq after 02550 batchs: 321.7942810058594
INFO:root:Train (Epoch 332): Loss/seq after 02600 batchs: 318.4510192871094
INFO:root:Train (Epoch 332): Loss/seq after 02650 batchs: 315.2428894042969
INFO:root:Train (Epoch 332): Loss/seq after 02700 batchs: 313.2408142089844
INFO:root:Train (Epoch 332): Loss/seq after 02750 batchs: 309.6202392578125
INFO:root:Train (Epoch 332): Loss/seq after 02800 batchs: 307.8623352050781
INFO:root:Train (Epoch 332): Loss/seq after 02850 batchs: 307.7085876464844
INFO:root:Train (Epoch 332): Loss/seq after 02900 batchs: 308.17474365234375
INFO:root:Train (Epoch 332): Loss/seq after 02950 batchs: 309.28094482421875
INFO:root:Train (Epoch 332): Loss/seq after 03000 batchs: 312.5213928222656
INFO:root:Train (Epoch 332): Loss/seq after 03050 batchs: 313.7428894042969
INFO:root:Train (Epoch 332): Loss/seq after 03100 batchs: 315.2319641113281
INFO:root:Train (Epoch 332): Loss/seq after 03150 batchs: 315.0565490722656
INFO:root:Train (Epoch 332): Loss/seq after 03200 batchs: 315.07611083984375
INFO:root:Train (Epoch 332): Loss/seq after 03250 batchs: 314.21087646484375
INFO:root:Train (Epoch 332): Loss/seq after 03300 batchs: 313.9018249511719
INFO:root:Train (Epoch 332): Loss/seq after 03350 batchs: 312.38800048828125
INFO:root:Train (Epoch 332): Loss/seq after 03400 batchs: 310.7924499511719
INFO:root:Train (Epoch 332): Loss/seq after 03450 batchs: 310.18585205078125
INFO:root:Train (Epoch 332): Loss/seq after 03500 batchs: 311.6084289550781
INFO:root:Train (Epoch 332): Loss/seq after 03550 batchs: 310.7081604003906
INFO:root:Train (Epoch 332): Loss/seq after 03600 batchs: 313.2304382324219
INFO:root:Train (Epoch 332): Loss/seq after 03650 batchs: 312.1372375488281
INFO:root:Train (Epoch 332): Loss/seq after 03700 batchs: 313.8955078125
INFO:root:Train (Epoch 332): Loss/seq after 03750 batchs: 316.9591979980469
INFO:root:Train (Epoch 332): Loss/seq after 03800 batchs: 316.98663330078125
INFO:root:Train (Epoch 332): Loss/seq after 03850 batchs: 316.6496276855469
INFO:root:Train (Epoch 332): Loss/seq after 03900 batchs: 317.9541931152344
INFO:root:Train (Epoch 332): Loss/seq after 03950 batchs: 320.20343017578125
INFO:root:Train (Epoch 332): Loss/seq after 04000 batchs: 318.6457824707031
INFO:root:Train (Epoch 332): Loss/seq after 04050 batchs: 317.0409851074219
INFO:root:Train (Epoch 332): Loss/seq after 04100 batchs: 316.12493896484375
INFO:root:Train (Epoch 332): Loss/seq after 04150 batchs: 316.333984375
INFO:root:Train (Epoch 332): Loss/seq after 04200 batchs: 315.8740539550781
INFO:root:Train (Epoch 332): Loss/seq after 04250 batchs: 315.1531982421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 332): Loss/seq after 00000 batches: 363.7900390625
INFO:root:# Valid (Epoch 332): Loss/seq after 00050 batches: 689.3031616210938
INFO:root:# Valid (Epoch 332): Loss/seq after 00100 batches: 693.9161376953125
INFO:root:# Valid (Epoch 332): Loss/seq after 00150 batches: 520.8408203125
INFO:root:# Valid (Epoch 332): Loss/seq after 00200 batches: 477.60870361328125
INFO:root:Artifacts: Make stick videos for epoch 332
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_332_on_20220423_233931.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_332_index_1849_on_20220423_233931.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 333): Loss/seq after 00000 batchs: 496.7594909667969
INFO:root:Train (Epoch 333): Loss/seq after 00050 batchs: 430.0793151855469
INFO:root:Train (Epoch 333): Loss/seq after 00100 batchs: 420.7767639160156
INFO:root:Train (Epoch 333): Loss/seq after 00150 batchs: 398.5685729980469
INFO:root:Train (Epoch 333): Loss/seq after 00200 batchs: 450.8997497558594
INFO:root:Train (Epoch 333): Loss/seq after 00250 batchs: 468.8148498535156
INFO:root:Train (Epoch 333): Loss/seq after 00300 batchs: 487.5068359375
INFO:root:Train (Epoch 333): Loss/seq after 00350 batchs: 466.7997131347656
INFO:root:Train (Epoch 333): Loss/seq after 00400 batchs: 454.991455078125
INFO:root:Train (Epoch 333): Loss/seq after 00450 batchs: 469.13427734375
INFO:root:Train (Epoch 333): Loss/seq after 00500 batchs: 455.6019592285156
INFO:root:Train (Epoch 333): Loss/seq after 00550 batchs: 449.04388427734375
INFO:root:Train (Epoch 333): Loss/seq after 00600 batchs: 434.2542419433594
INFO:root:Train (Epoch 333): Loss/seq after 00650 batchs: 417.5641784667969
INFO:root:Train (Epoch 333): Loss/seq after 00700 batchs: 402.35321044921875
INFO:root:Train (Epoch 333): Loss/seq after 00750 batchs: 395.8169250488281
INFO:root:Train (Epoch 333): Loss/seq after 00800 batchs: 397.35040283203125
INFO:root:Train (Epoch 333): Loss/seq after 00850 batchs: 385.284423828125
INFO:root:Train (Epoch 333): Loss/seq after 00900 batchs: 375.4455871582031
INFO:root:Train (Epoch 333): Loss/seq after 00950 batchs: 375.4652404785156
INFO:root:Train (Epoch 333): Loss/seq after 01000 batchs: 370.1736145019531
INFO:root:Train (Epoch 333): Loss/seq after 01050 batchs: 363.26068115234375
INFO:root:Train (Epoch 333): Loss/seq after 01100 batchs: 355.1237487792969
INFO:root:Train (Epoch 333): Loss/seq after 01150 batchs: 345.8479309082031
INFO:root:Train (Epoch 333): Loss/seq after 01200 batchs: 346.1684265136719
INFO:root:Train (Epoch 333): Loss/seq after 01250 batchs: 345.6941833496094
INFO:root:Train (Epoch 333): Loss/seq after 01300 batchs: 338.7519226074219
INFO:root:Train (Epoch 333): Loss/seq after 01350 batchs: 331.50103759765625
INFO:root:Train (Epoch 333): Loss/seq after 01400 batchs: 332.409423828125
INFO:root:Train (Epoch 333): Loss/seq after 01450 batchs: 335.22869873046875
INFO:root:Train (Epoch 333): Loss/seq after 01500 batchs: 341.0944519042969
INFO:root:Train (Epoch 333): Loss/seq after 01550 batchs: 342.0404052734375
INFO:root:Train (Epoch 333): Loss/seq after 01600 batchs: 340.9772033691406
INFO:root:Train (Epoch 333): Loss/seq after 01650 batchs: 339.9307861328125
INFO:root:Train (Epoch 333): Loss/seq after 01700 batchs: 342.2078857421875
INFO:root:Train (Epoch 333): Loss/seq after 01750 batchs: 341.77813720703125
INFO:root:Train (Epoch 333): Loss/seq after 01800 batchs: 340.8501892089844
INFO:root:Train (Epoch 333): Loss/seq after 01850 batchs: 339.43035888671875
INFO:root:Train (Epoch 333): Loss/seq after 01900 batchs: 339.0753479003906
INFO:root:Train (Epoch 333): Loss/seq after 01950 batchs: 339.3514099121094
INFO:root:Train (Epoch 333): Loss/seq after 02000 batchs: 341.30316162109375
INFO:root:Train (Epoch 333): Loss/seq after 02050 batchs: 341.698486328125
INFO:root:Train (Epoch 333): Loss/seq after 02100 batchs: 341.4552001953125
INFO:root:Train (Epoch 333): Loss/seq after 02150 batchs: 341.5306701660156
INFO:root:Train (Epoch 333): Loss/seq after 02200 batchs: 341.09527587890625
INFO:root:Train (Epoch 333): Loss/seq after 02250 batchs: 340.53265380859375
INFO:root:Train (Epoch 333): Loss/seq after 02300 batchs: 338.6012268066406
INFO:root:Train (Epoch 333): Loss/seq after 02350 batchs: 336.6016540527344
INFO:root:Train (Epoch 333): Loss/seq after 02400 batchs: 337.3144836425781
INFO:root:Train (Epoch 333): Loss/seq after 02450 batchs: 334.7574768066406
INFO:root:Train (Epoch 333): Loss/seq after 02500 batchs: 329.3183288574219
INFO:root:Train (Epoch 333): Loss/seq after 02550 batchs: 324.7921142578125
INFO:root:Train (Epoch 333): Loss/seq after 02600 batchs: 321.3797607421875
INFO:root:Train (Epoch 333): Loss/seq after 02650 batchs: 318.2878723144531
INFO:root:Train (Epoch 333): Loss/seq after 02700 batchs: 316.3485412597656
INFO:root:Train (Epoch 333): Loss/seq after 02750 batchs: 312.9813537597656
INFO:root:Train (Epoch 333): Loss/seq after 02800 batchs: 311.6095886230469
INFO:root:Train (Epoch 333): Loss/seq after 02850 batchs: 311.4995422363281
INFO:root:Train (Epoch 333): Loss/seq after 02900 batchs: 311.9131164550781
INFO:root:Train (Epoch 333): Loss/seq after 02950 batchs: 313.0794677734375
INFO:root:Train (Epoch 333): Loss/seq after 03000 batchs: 316.3379211425781
INFO:root:Train (Epoch 333): Loss/seq after 03050 batchs: 317.83648681640625
INFO:root:Train (Epoch 333): Loss/seq after 03100 batchs: 319.3348693847656
INFO:root:Train (Epoch 333): Loss/seq after 03150 batchs: 320.7078857421875
INFO:root:Train (Epoch 333): Loss/seq after 03200 batchs: 321.35650634765625
INFO:root:Train (Epoch 333): Loss/seq after 03250 batchs: 321.5214538574219
INFO:root:Train (Epoch 333): Loss/seq after 03300 batchs: 321.34332275390625
INFO:root:Train (Epoch 333): Loss/seq after 03350 batchs: 320.1036682128906
INFO:root:Train (Epoch 333): Loss/seq after 03400 batchs: 318.3280944824219
INFO:root:Train (Epoch 333): Loss/seq after 03450 batchs: 317.6475830078125
INFO:root:Train (Epoch 333): Loss/seq after 03500 batchs: 319.38427734375
INFO:root:Train (Epoch 333): Loss/seq after 03550 batchs: 318.32958984375
INFO:root:Train (Epoch 333): Loss/seq after 03600 batchs: 321.0925598144531
INFO:root:Train (Epoch 333): Loss/seq after 03650 batchs: 320.2442321777344
INFO:root:Train (Epoch 333): Loss/seq after 03700 batchs: 322.3686828613281
INFO:root:Train (Epoch 333): Loss/seq after 03750 batchs: 325.6184997558594
INFO:root:Train (Epoch 333): Loss/seq after 03800 batchs: 325.5129089355469
INFO:root:Train (Epoch 333): Loss/seq after 03850 batchs: 325.2946472167969
INFO:root:Train (Epoch 333): Loss/seq after 03900 batchs: 326.3453063964844
INFO:root:Train (Epoch 333): Loss/seq after 03950 batchs: 328.7526550292969
INFO:root:Train (Epoch 333): Loss/seq after 04000 batchs: 327.06195068359375
INFO:root:Train (Epoch 333): Loss/seq after 04050 batchs: 325.3802490234375
INFO:root:Train (Epoch 333): Loss/seq after 04100 batchs: 324.38446044921875
INFO:root:Train (Epoch 333): Loss/seq after 04150 batchs: 324.444091796875
INFO:root:Train (Epoch 333): Loss/seq after 04200 batchs: 323.972900390625
INFO:root:Train (Epoch 333): Loss/seq after 04250 batchs: 323.160400390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 333): Loss/seq after 00000 batches: 288.36749267578125
INFO:root:# Valid (Epoch 333): Loss/seq after 00050 batches: 678.4293823242188
INFO:root:# Valid (Epoch 333): Loss/seq after 00100 batches: 721.2274780273438
INFO:root:# Valid (Epoch 333): Loss/seq after 00150 batches: 536.9227294921875
INFO:root:# Valid (Epoch 333): Loss/seq after 00200 batches: 489.81353759765625
INFO:root:Artifacts: Make stick videos for epoch 333
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_333_on_20220423_234435.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_333_index_635_on_20220423_234435.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 334): Loss/seq after 00000 batchs: 619.1422729492188
INFO:root:Train (Epoch 334): Loss/seq after 00050 batchs: 460.2066955566406
INFO:root:Train (Epoch 334): Loss/seq after 00100 batchs: 466.0042724609375
INFO:root:Train (Epoch 334): Loss/seq after 00150 batchs: 430.0875549316406
INFO:root:Train (Epoch 334): Loss/seq after 00200 batchs: 477.3752746582031
INFO:root:Train (Epoch 334): Loss/seq after 00250 batchs: 492.77508544921875
INFO:root:Train (Epoch 334): Loss/seq after 00300 batchs: 510.0072021484375
INFO:root:Train (Epoch 334): Loss/seq after 00350 batchs: 484.6845703125
INFO:root:Train (Epoch 334): Loss/seq after 00400 batchs: 474.09295654296875
INFO:root:Train (Epoch 334): Loss/seq after 00450 batchs: 485.469482421875
INFO:root:Train (Epoch 334): Loss/seq after 00500 batchs: 471.0384216308594
INFO:root:Train (Epoch 334): Loss/seq after 00550 batchs: 461.5859680175781
INFO:root:Train (Epoch 334): Loss/seq after 00600 batchs: 446.1112976074219
INFO:root:Train (Epoch 334): Loss/seq after 00650 batchs: 428.55194091796875
INFO:root:Train (Epoch 334): Loss/seq after 00700 batchs: 412.42578125
INFO:root:Train (Epoch 334): Loss/seq after 00750 batchs: 406.7981262207031
INFO:root:Train (Epoch 334): Loss/seq after 00800 batchs: 408.185546875
INFO:root:Train (Epoch 334): Loss/seq after 00850 batchs: 395.328369140625
INFO:root:Train (Epoch 334): Loss/seq after 00900 batchs: 384.796875
INFO:root:Train (Epoch 334): Loss/seq after 00950 batchs: 384.1344909667969
INFO:root:Train (Epoch 334): Loss/seq after 01000 batchs: 378.6117248535156
INFO:root:Train (Epoch 334): Loss/seq after 01050 batchs: 373.16015625
INFO:root:Train (Epoch 334): Loss/seq after 01100 batchs: 364.95001220703125
INFO:root:Train (Epoch 334): Loss/seq after 01150 batchs: 355.6252136230469
INFO:root:Train (Epoch 334): Loss/seq after 01200 batchs: 356.0238952636719
INFO:root:Train (Epoch 334): Loss/seq after 01250 batchs: 354.9560852050781
INFO:root:Train (Epoch 334): Loss/seq after 01300 batchs: 347.6384582519531
INFO:root:Train (Epoch 334): Loss/seq after 01350 batchs: 340.3663330078125
INFO:root:Train (Epoch 334): Loss/seq after 01400 batchs: 341.66693115234375
INFO:root:Train (Epoch 334): Loss/seq after 01450 batchs: 344.41693115234375
INFO:root:Train (Epoch 334): Loss/seq after 01500 batchs: 349.6647033691406
INFO:root:Train (Epoch 334): Loss/seq after 01550 batchs: 350.35028076171875
INFO:root:Train (Epoch 334): Loss/seq after 01600 batchs: 349.0189514160156
INFO:root:Train (Epoch 334): Loss/seq after 01650 batchs: 347.64178466796875
INFO:root:Train (Epoch 334): Loss/seq after 01700 batchs: 349.2603454589844
INFO:root:Train (Epoch 334): Loss/seq after 01750 batchs: 348.75341796875
INFO:root:Train (Epoch 334): Loss/seq after 01800 batchs: 347.4295349121094
INFO:root:Train (Epoch 334): Loss/seq after 01850 batchs: 345.9075927734375
INFO:root:Train (Epoch 334): Loss/seq after 01900 batchs: 345.31414794921875
INFO:root:Train (Epoch 334): Loss/seq after 01950 batchs: 345.38934326171875
INFO:root:Train (Epoch 334): Loss/seq after 02000 batchs: 347.069580078125
INFO:root:Train (Epoch 334): Loss/seq after 02050 batchs: 347.4609375
INFO:root:Train (Epoch 334): Loss/seq after 02100 batchs: 347.4938659667969
INFO:root:Train (Epoch 334): Loss/seq after 02150 batchs: 347.35711669921875
INFO:root:Train (Epoch 334): Loss/seq after 02200 batchs: 346.6485900878906
INFO:root:Train (Epoch 334): Loss/seq after 02250 batchs: 345.9002990722656
INFO:root:Train (Epoch 334): Loss/seq after 02300 batchs: 343.6784362792969
INFO:root:Train (Epoch 334): Loss/seq after 02350 batchs: 341.5881042480469
INFO:root:Train (Epoch 334): Loss/seq after 02400 batchs: 342.2025451660156
INFO:root:Train (Epoch 334): Loss/seq after 02450 batchs: 339.60009765625
INFO:root:Train (Epoch 334): Loss/seq after 02500 batchs: 334.1814270019531
INFO:root:Train (Epoch 334): Loss/seq after 02550 batchs: 329.59222412109375
INFO:root:Train (Epoch 334): Loss/seq after 02600 batchs: 325.80413818359375
INFO:root:Train (Epoch 334): Loss/seq after 02650 batchs: 322.52288818359375
INFO:root:Train (Epoch 334): Loss/seq after 02700 batchs: 320.2774353027344
INFO:root:Train (Epoch 334): Loss/seq after 02750 batchs: 316.4032287597656
INFO:root:Train (Epoch 334): Loss/seq after 02800 batchs: 314.8777160644531
INFO:root:Train (Epoch 334): Loss/seq after 02850 batchs: 314.534912109375
INFO:root:Train (Epoch 334): Loss/seq after 02900 batchs: 315.1136474609375
INFO:root:Train (Epoch 334): Loss/seq after 02950 batchs: 316.1092529296875
INFO:root:Train (Epoch 334): Loss/seq after 03000 batchs: 319.1375427246094
INFO:root:Train (Epoch 334): Loss/seq after 03050 batchs: 320.9154357910156
INFO:root:Train (Epoch 334): Loss/seq after 03100 batchs: 323.4903564453125
INFO:root:Train (Epoch 334): Loss/seq after 03150 batchs: 323.5937194824219
INFO:root:Train (Epoch 334): Loss/seq after 03200 batchs: 323.6802673339844
INFO:root:Train (Epoch 334): Loss/seq after 03250 batchs: 323.6227111816406
INFO:root:Train (Epoch 334): Loss/seq after 03300 batchs: 323.50799560546875
INFO:root:Train (Epoch 334): Loss/seq after 03350 batchs: 322.100830078125
INFO:root:Train (Epoch 334): Loss/seq after 03400 batchs: 320.30096435546875
INFO:root:Train (Epoch 334): Loss/seq after 03450 batchs: 319.342041015625
INFO:root:Train (Epoch 334): Loss/seq after 03500 batchs: 320.5472412109375
INFO:root:Train (Epoch 334): Loss/seq after 03550 batchs: 319.4300231933594
INFO:root:Train (Epoch 334): Loss/seq after 03600 batchs: 321.8468017578125
INFO:root:Train (Epoch 334): Loss/seq after 03650 batchs: 320.7087097167969
INFO:root:Train (Epoch 334): Loss/seq after 03700 batchs: 322.4836730957031
INFO:root:Train (Epoch 334): Loss/seq after 03750 batchs: 325.4677429199219
INFO:root:Train (Epoch 334): Loss/seq after 03800 batchs: 325.44232177734375
INFO:root:Train (Epoch 334): Loss/seq after 03850 batchs: 325.0359802246094
INFO:root:Train (Epoch 334): Loss/seq after 03900 batchs: 326.2537536621094
INFO:root:Train (Epoch 334): Loss/seq after 03950 batchs: 328.21087646484375
INFO:root:Train (Epoch 334): Loss/seq after 04000 batchs: 326.5241394042969
INFO:root:Train (Epoch 334): Loss/seq after 04050 batchs: 324.80987548828125
INFO:root:Train (Epoch 334): Loss/seq after 04100 batchs: 323.8939514160156
INFO:root:Train (Epoch 334): Loss/seq after 04150 batchs: 323.9397277832031
INFO:root:Train (Epoch 334): Loss/seq after 04200 batchs: 323.42864990234375
INFO:root:Train (Epoch 334): Loss/seq after 04250 batchs: 322.5884704589844
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 334): Loss/seq after 00000 batches: 299.63482666015625
INFO:root:# Valid (Epoch 334): Loss/seq after 00050 batches: 699.0803833007812
INFO:root:# Valid (Epoch 334): Loss/seq after 00100 batches: 816.8521118164062
INFO:root:# Valid (Epoch 334): Loss/seq after 00150 batches: 597.113525390625
INFO:root:# Valid (Epoch 334): Loss/seq after 00200 batches: 533.8468017578125
INFO:root:Artifacts: Make stick videos for epoch 334
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_334_on_20220423_234927.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_334_index_26_on_20220423_234927.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 335): Loss/seq after 00000 batchs: 513.82763671875
INFO:root:Train (Epoch 335): Loss/seq after 00050 batchs: 437.80572509765625
INFO:root:Train (Epoch 335): Loss/seq after 00100 batchs: 424.5199890136719
INFO:root:Train (Epoch 335): Loss/seq after 00150 batchs: 398.2596740722656
INFO:root:Train (Epoch 335): Loss/seq after 00200 batchs: 451.5497741699219
INFO:root:Train (Epoch 335): Loss/seq after 00250 batchs: 460.35986328125
INFO:root:Train (Epoch 335): Loss/seq after 00300 batchs: 482.452392578125
INFO:root:Train (Epoch 335): Loss/seq after 00350 batchs: 462.6203308105469
INFO:root:Train (Epoch 335): Loss/seq after 00400 batchs: 457.1303405761719
INFO:root:Train (Epoch 335): Loss/seq after 00450 batchs: 472.0669860839844
INFO:root:Train (Epoch 335): Loss/seq after 00500 batchs: 458.2353820800781
INFO:root:Train (Epoch 335): Loss/seq after 00550 batchs: 451.3270568847656
INFO:root:Train (Epoch 335): Loss/seq after 00600 batchs: 435.4040222167969
INFO:root:Train (Epoch 335): Loss/seq after 00650 batchs: 418.5106506347656
INFO:root:Train (Epoch 335): Loss/seq after 00700 batchs: 401.7503662109375
INFO:root:Train (Epoch 335): Loss/seq after 00750 batchs: 394.69647216796875
INFO:root:Train (Epoch 335): Loss/seq after 00800 batchs: 395.6021728515625
INFO:root:Train (Epoch 335): Loss/seq after 00850 batchs: 383.3787841796875
INFO:root:Train (Epoch 335): Loss/seq after 00900 batchs: 374.2186279296875
INFO:root:Train (Epoch 335): Loss/seq after 00950 batchs: 372.889892578125
INFO:root:Train (Epoch 335): Loss/seq after 01000 batchs: 366.7860107421875
INFO:root:Train (Epoch 335): Loss/seq after 01050 batchs: 359.7301025390625
INFO:root:Train (Epoch 335): Loss/seq after 01100 batchs: 351.89959716796875
INFO:root:Train (Epoch 335): Loss/seq after 01150 batchs: 342.53961181640625
INFO:root:Train (Epoch 335): Loss/seq after 01200 batchs: 342.1291198730469
INFO:root:Train (Epoch 335): Loss/seq after 01250 batchs: 340.9956970214844
INFO:root:Train (Epoch 335): Loss/seq after 01300 batchs: 334.0196533203125
INFO:root:Train (Epoch 335): Loss/seq after 01350 batchs: 327.0262451171875
INFO:root:Train (Epoch 335): Loss/seq after 01400 batchs: 328.93255615234375
INFO:root:Train (Epoch 335): Loss/seq after 01450 batchs: 331.6270751953125
INFO:root:Train (Epoch 335): Loss/seq after 01500 batchs: 337.15234375
INFO:root:Train (Epoch 335): Loss/seq after 01550 batchs: 337.5924377441406
INFO:root:Train (Epoch 335): Loss/seq after 01600 batchs: 336.3857421875
INFO:root:Train (Epoch 335): Loss/seq after 01650 batchs: 335.05010986328125
INFO:root:Train (Epoch 335): Loss/seq after 01700 batchs: 337.11114501953125
INFO:root:Train (Epoch 335): Loss/seq after 01750 batchs: 336.6638488769531
INFO:root:Train (Epoch 335): Loss/seq after 01800 batchs: 335.6831970214844
INFO:root:Train (Epoch 335): Loss/seq after 01850 batchs: 334.375
INFO:root:Train (Epoch 335): Loss/seq after 01900 batchs: 333.8257751464844
INFO:root:Train (Epoch 335): Loss/seq after 01950 batchs: 333.8452453613281
INFO:root:Train (Epoch 335): Loss/seq after 02000 batchs: 335.82666015625
INFO:root:Train (Epoch 335): Loss/seq after 02050 batchs: 336.2798156738281
INFO:root:Train (Epoch 335): Loss/seq after 02100 batchs: 336.1907653808594
INFO:root:Train (Epoch 335): Loss/seq after 02150 batchs: 336.3592529296875
INFO:root:Train (Epoch 335): Loss/seq after 02200 batchs: 335.9202880859375
INFO:root:Train (Epoch 335): Loss/seq after 02250 batchs: 335.66217041015625
INFO:root:Train (Epoch 335): Loss/seq after 02300 batchs: 333.4609069824219
INFO:root:Train (Epoch 335): Loss/seq after 02350 batchs: 331.5875244140625
INFO:root:Train (Epoch 335): Loss/seq after 02400 batchs: 332.1948547363281
INFO:root:Train (Epoch 335): Loss/seq after 02450 batchs: 329.74920654296875
INFO:root:Train (Epoch 335): Loss/seq after 02500 batchs: 324.4647521972656
INFO:root:Train (Epoch 335): Loss/seq after 02550 batchs: 320.0022888183594
INFO:root:Train (Epoch 335): Loss/seq after 02600 batchs: 316.5418701171875
INFO:root:Train (Epoch 335): Loss/seq after 02650 batchs: 313.406005859375
INFO:root:Train (Epoch 335): Loss/seq after 02700 batchs: 311.5461730957031
INFO:root:Train (Epoch 335): Loss/seq after 02750 batchs: 308.0619812011719
INFO:root:Train (Epoch 335): Loss/seq after 02800 batchs: 306.6662902832031
INFO:root:Train (Epoch 335): Loss/seq after 02850 batchs: 306.5832214355469
INFO:root:Train (Epoch 335): Loss/seq after 02900 batchs: 306.85577392578125
INFO:root:Train (Epoch 335): Loss/seq after 02950 batchs: 307.8207092285156
INFO:root:Train (Epoch 335): Loss/seq after 03000 batchs: 310.9360656738281
INFO:root:Train (Epoch 335): Loss/seq after 03050 batchs: 312.250244140625
INFO:root:Train (Epoch 335): Loss/seq after 03100 batchs: 313.7342224121094
INFO:root:Train (Epoch 335): Loss/seq after 03150 batchs: 313.671142578125
INFO:root:Train (Epoch 335): Loss/seq after 03200 batchs: 313.47576904296875
INFO:root:Train (Epoch 335): Loss/seq after 03250 batchs: 313.21063232421875
INFO:root:Train (Epoch 335): Loss/seq after 03300 batchs: 312.91595458984375
INFO:root:Train (Epoch 335): Loss/seq after 03350 batchs: 311.18701171875
INFO:root:Train (Epoch 335): Loss/seq after 03400 batchs: 309.43829345703125
INFO:root:Train (Epoch 335): Loss/seq after 03450 batchs: 308.6649169921875
INFO:root:Train (Epoch 335): Loss/seq after 03500 batchs: 309.55035400390625
INFO:root:Train (Epoch 335): Loss/seq after 03550 batchs: 308.35418701171875
INFO:root:Train (Epoch 335): Loss/seq after 03600 batchs: 310.7826843261719
INFO:root:Train (Epoch 335): Loss/seq after 03650 batchs: 309.6269226074219
INFO:root:Train (Epoch 335): Loss/seq after 03700 batchs: 311.1277160644531
INFO:root:Train (Epoch 335): Loss/seq after 03750 batchs: 314.2084655761719
INFO:root:Train (Epoch 335): Loss/seq after 03800 batchs: 314.3215026855469
INFO:root:Train (Epoch 335): Loss/seq after 03850 batchs: 314.0041809082031
INFO:root:Train (Epoch 335): Loss/seq after 03900 batchs: 315.4417419433594
INFO:root:Train (Epoch 335): Loss/seq after 03950 batchs: 317.3935852050781
INFO:root:Train (Epoch 335): Loss/seq after 04000 batchs: 315.8128356933594
INFO:root:Train (Epoch 335): Loss/seq after 04050 batchs: 314.2223815917969
INFO:root:Train (Epoch 335): Loss/seq after 04100 batchs: 313.3351135253906
INFO:root:Train (Epoch 335): Loss/seq after 04150 batchs: 313.4057922363281
INFO:root:Train (Epoch 335): Loss/seq after 04200 batchs: 313.0107116699219
INFO:root:Train (Epoch 335): Loss/seq after 04250 batchs: 312.3043518066406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 335): Loss/seq after 00000 batches: 315.73370361328125
INFO:root:# Valid (Epoch 335): Loss/seq after 00050 batches: 667.0438232421875
INFO:root:# Valid (Epoch 335): Loss/seq after 00100 batches: 730.247802734375
INFO:root:# Valid (Epoch 335): Loss/seq after 00150 batches: 540.7786254882812
INFO:root:# Valid (Epoch 335): Loss/seq after 00200 batches: 497.7337951660156
INFO:root:Artifacts: Make stick videos for epoch 335
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_335_on_20220423_235411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_335_index_1108_on_20220423_235411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 336): Loss/seq after 00000 batchs: 520.4305419921875
INFO:root:Train (Epoch 336): Loss/seq after 00050 batchs: 426.95672607421875
INFO:root:Train (Epoch 336): Loss/seq after 00100 batchs: 423.72845458984375
INFO:root:Train (Epoch 336): Loss/seq after 00150 batchs: 402.9964904785156
INFO:root:Train (Epoch 336): Loss/seq after 00200 batchs: 450.19403076171875
INFO:root:Train (Epoch 336): Loss/seq after 00250 batchs: 468.1815490722656
INFO:root:Train (Epoch 336): Loss/seq after 00300 batchs: 487.91827392578125
INFO:root:Train (Epoch 336): Loss/seq after 00350 batchs: 466.6253662109375
INFO:root:Train (Epoch 336): Loss/seq after 00400 batchs: 457.7823486328125
INFO:root:Train (Epoch 336): Loss/seq after 00450 batchs: 472.7973327636719
INFO:root:Train (Epoch 336): Loss/seq after 00500 batchs: 458.3456726074219
INFO:root:Train (Epoch 336): Loss/seq after 00550 batchs: 450.3697814941406
INFO:root:Train (Epoch 336): Loss/seq after 00600 batchs: 435.0942077636719
INFO:root:Train (Epoch 336): Loss/seq after 00650 batchs: 417.62493896484375
INFO:root:Train (Epoch 336): Loss/seq after 00700 batchs: 401.609375
INFO:root:Train (Epoch 336): Loss/seq after 00750 batchs: 395.7086181640625
INFO:root:Train (Epoch 336): Loss/seq after 00800 batchs: 396.74090576171875
INFO:root:Train (Epoch 336): Loss/seq after 00850 batchs: 384.7881774902344
INFO:root:Train (Epoch 336): Loss/seq after 00900 batchs: 374.8725280761719
INFO:root:Train (Epoch 336): Loss/seq after 00950 batchs: 372.8782958984375
INFO:root:Train (Epoch 336): Loss/seq after 01000 batchs: 366.7464294433594
INFO:root:Train (Epoch 336): Loss/seq after 01050 batchs: 359.2988586425781
INFO:root:Train (Epoch 336): Loss/seq after 01100 batchs: 350.88336181640625
INFO:root:Train (Epoch 336): Loss/seq after 01150 batchs: 341.5653381347656
INFO:root:Train (Epoch 336): Loss/seq after 01200 batchs: 340.6429443359375
INFO:root:Train (Epoch 336): Loss/seq after 01250 batchs: 339.8476867675781
INFO:root:Train (Epoch 336): Loss/seq after 01300 batchs: 333.0484619140625
INFO:root:Train (Epoch 336): Loss/seq after 01350 batchs: 326.22979736328125
INFO:root:Train (Epoch 336): Loss/seq after 01400 batchs: 327.5340270996094
INFO:root:Train (Epoch 336): Loss/seq after 01450 batchs: 330.4293518066406
INFO:root:Train (Epoch 336): Loss/seq after 01500 batchs: 336.3501281738281
INFO:root:Train (Epoch 336): Loss/seq after 01550 batchs: 337.22515869140625
INFO:root:Train (Epoch 336): Loss/seq after 01600 batchs: 336.29620361328125
INFO:root:Train (Epoch 336): Loss/seq after 01650 batchs: 335.1973571777344
INFO:root:Train (Epoch 336): Loss/seq after 01700 batchs: 336.46337890625
INFO:root:Train (Epoch 336): Loss/seq after 01750 batchs: 336.06689453125
INFO:root:Train (Epoch 336): Loss/seq after 01800 batchs: 335.0145568847656
INFO:root:Train (Epoch 336): Loss/seq after 01850 batchs: 333.9180603027344
INFO:root:Train (Epoch 336): Loss/seq after 01900 batchs: 333.7142639160156
INFO:root:Train (Epoch 336): Loss/seq after 01950 batchs: 334.3482971191406
INFO:root:Train (Epoch 336): Loss/seq after 02000 batchs: 336.62017822265625
INFO:root:Train (Epoch 336): Loss/seq after 02050 batchs: 337.1764221191406
INFO:root:Train (Epoch 336): Loss/seq after 02100 batchs: 337.01971435546875
INFO:root:Train (Epoch 336): Loss/seq after 02150 batchs: 337.1686706542969
INFO:root:Train (Epoch 336): Loss/seq after 02200 batchs: 336.576171875
INFO:root:Train (Epoch 336): Loss/seq after 02250 batchs: 335.9478454589844
INFO:root:Train (Epoch 336): Loss/seq after 02300 batchs: 333.69183349609375
INFO:root:Train (Epoch 336): Loss/seq after 02350 batchs: 331.7471008300781
INFO:root:Train (Epoch 336): Loss/seq after 02400 batchs: 332.31500244140625
INFO:root:Train (Epoch 336): Loss/seq after 02450 batchs: 329.9715881347656
INFO:root:Train (Epoch 336): Loss/seq after 02500 batchs: 324.7596740722656
INFO:root:Train (Epoch 336): Loss/seq after 02550 batchs: 320.25177001953125
INFO:root:Train (Epoch 336): Loss/seq after 02600 batchs: 316.8524169921875
INFO:root:Train (Epoch 336): Loss/seq after 02650 batchs: 313.6719665527344
INFO:root:Train (Epoch 336): Loss/seq after 02700 batchs: 311.634033203125
INFO:root:Train (Epoch 336): Loss/seq after 02750 batchs: 307.9888610839844
INFO:root:Train (Epoch 336): Loss/seq after 02800 batchs: 307.3515930175781
INFO:root:Train (Epoch 336): Loss/seq after 02850 batchs: 307.167724609375
INFO:root:Train (Epoch 336): Loss/seq after 02900 batchs: 307.6706237792969
INFO:root:Train (Epoch 336): Loss/seq after 02950 batchs: 308.8018798828125
INFO:root:Train (Epoch 336): Loss/seq after 03000 batchs: 311.8105163574219
INFO:root:Train (Epoch 336): Loss/seq after 03050 batchs: 313.1866455078125
INFO:root:Train (Epoch 336): Loss/seq after 03100 batchs: 314.63037109375
INFO:root:Train (Epoch 336): Loss/seq after 03150 batchs: 314.398681640625
INFO:root:Train (Epoch 336): Loss/seq after 03200 batchs: 314.5776062011719
INFO:root:Train (Epoch 336): Loss/seq after 03250 batchs: 314.8475646972656
INFO:root:Train (Epoch 336): Loss/seq after 03300 batchs: 314.4769287109375
INFO:root:Train (Epoch 336): Loss/seq after 03350 batchs: 312.7324523925781
INFO:root:Train (Epoch 336): Loss/seq after 03400 batchs: 311.0863342285156
INFO:root:Train (Epoch 336): Loss/seq after 03450 batchs: 310.28564453125
INFO:root:Train (Epoch 336): Loss/seq after 03500 batchs: 311.4356689453125
INFO:root:Train (Epoch 336): Loss/seq after 03550 batchs: 310.32879638671875
INFO:root:Train (Epoch 336): Loss/seq after 03600 batchs: 312.7469787597656
INFO:root:Train (Epoch 336): Loss/seq after 03650 batchs: 311.69647216796875
INFO:root:Train (Epoch 336): Loss/seq after 03700 batchs: 313.51641845703125
INFO:root:Train (Epoch 336): Loss/seq after 03750 batchs: 316.6752014160156
INFO:root:Train (Epoch 336): Loss/seq after 03800 batchs: 316.6929016113281
INFO:root:Train (Epoch 336): Loss/seq after 03850 batchs: 316.4305725097656
INFO:root:Train (Epoch 336): Loss/seq after 03900 batchs: 317.5550537109375
INFO:root:Train (Epoch 336): Loss/seq after 03950 batchs: 319.3225402832031
INFO:root:Train (Epoch 336): Loss/seq after 04000 batchs: 317.7182922363281
INFO:root:Train (Epoch 336): Loss/seq after 04050 batchs: 316.1008605957031
INFO:root:Train (Epoch 336): Loss/seq after 04100 batchs: 315.0997314453125
INFO:root:Train (Epoch 336): Loss/seq after 04150 batchs: 315.14190673828125
INFO:root:Train (Epoch 336): Loss/seq after 04200 batchs: 314.6323547363281
INFO:root:Train (Epoch 336): Loss/seq after 04250 batchs: 313.8446350097656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 336): Loss/seq after 00000 batches: 310.462890625
INFO:root:# Valid (Epoch 336): Loss/seq after 00050 batches: 690.1697387695312
INFO:root:# Valid (Epoch 336): Loss/seq after 00100 batches: 661.243896484375
INFO:root:# Valid (Epoch 336): Loss/seq after 00150 batches: 493.9737243652344
INFO:root:# Valid (Epoch 336): Loss/seq after 00200 batches: 456.31622314453125
INFO:root:Artifacts: Make stick videos for epoch 336
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_336_on_20220423_235903.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_336_index_1699_on_20220423_235903.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 337): Loss/seq after 00000 batchs: 462.38226318359375
INFO:root:Train (Epoch 337): Loss/seq after 00050 batchs: 442.3318786621094
INFO:root:Train (Epoch 337): Loss/seq after 00100 batchs: 434.0328674316406
INFO:root:Train (Epoch 337): Loss/seq after 00150 batchs: 405.94097900390625
INFO:root:Train (Epoch 337): Loss/seq after 00200 batchs: 462.4599914550781
INFO:root:Train (Epoch 337): Loss/seq after 00250 batchs: 481.5235290527344
INFO:root:Train (Epoch 337): Loss/seq after 00300 batchs: 498.2960205078125
INFO:root:Train (Epoch 337): Loss/seq after 00350 batchs: 475.1731262207031
INFO:root:Train (Epoch 337): Loss/seq after 00400 batchs: 461.6663513183594
INFO:root:Train (Epoch 337): Loss/seq after 00450 batchs: 475.91009521484375
INFO:root:Train (Epoch 337): Loss/seq after 00500 batchs: 461.6002502441406
INFO:root:Train (Epoch 337): Loss/seq after 00550 batchs: 453.4444274902344
INFO:root:Train (Epoch 337): Loss/seq after 00600 batchs: 438.08026123046875
INFO:root:Train (Epoch 337): Loss/seq after 00650 batchs: 420.5383605957031
INFO:root:Train (Epoch 337): Loss/seq after 00700 batchs: 404.3579406738281
INFO:root:Train (Epoch 337): Loss/seq after 00750 batchs: 398.628173828125
INFO:root:Train (Epoch 337): Loss/seq after 00800 batchs: 400.5945739746094
INFO:root:Train (Epoch 337): Loss/seq after 00850 batchs: 388.0069274902344
INFO:root:Train (Epoch 337): Loss/seq after 00900 batchs: 377.9261169433594
INFO:root:Train (Epoch 337): Loss/seq after 00950 batchs: 376.5835876464844
INFO:root:Train (Epoch 337): Loss/seq after 01000 batchs: 371.06219482421875
INFO:root:Train (Epoch 337): Loss/seq after 01050 batchs: 363.4131774902344
INFO:root:Train (Epoch 337): Loss/seq after 01100 batchs: 355.70220947265625
INFO:root:Train (Epoch 337): Loss/seq after 01150 batchs: 346.3541564941406
INFO:root:Train (Epoch 337): Loss/seq after 01200 batchs: 345.6153869628906
INFO:root:Train (Epoch 337): Loss/seq after 01250 batchs: 344.4723815917969
INFO:root:Train (Epoch 337): Loss/seq after 01300 batchs: 337.5703430175781
INFO:root:Train (Epoch 337): Loss/seq after 01350 batchs: 330.1669921875
INFO:root:Train (Epoch 337): Loss/seq after 01400 batchs: 331.69439697265625
INFO:root:Train (Epoch 337): Loss/seq after 01450 batchs: 334.2133483886719
INFO:root:Train (Epoch 337): Loss/seq after 01500 batchs: 339.9902038574219
INFO:root:Train (Epoch 337): Loss/seq after 01550 batchs: 340.6158447265625
INFO:root:Train (Epoch 337): Loss/seq after 01600 batchs: 339.5165710449219
INFO:root:Train (Epoch 337): Loss/seq after 01650 batchs: 338.2562255859375
INFO:root:Train (Epoch 337): Loss/seq after 01700 batchs: 339.5108642578125
INFO:root:Train (Epoch 337): Loss/seq after 01750 batchs: 338.7566223144531
INFO:root:Train (Epoch 337): Loss/seq after 01800 batchs: 337.5375061035156
INFO:root:Train (Epoch 337): Loss/seq after 01850 batchs: 336.22003173828125
INFO:root:Train (Epoch 337): Loss/seq after 01900 batchs: 335.819091796875
INFO:root:Train (Epoch 337): Loss/seq after 01950 batchs: 335.8655700683594
INFO:root:Train (Epoch 337): Loss/seq after 02000 batchs: 337.8770751953125
INFO:root:Train (Epoch 337): Loss/seq after 02050 batchs: 338.3746032714844
INFO:root:Train (Epoch 337): Loss/seq after 02100 batchs: 338.14556884765625
INFO:root:Train (Epoch 337): Loss/seq after 02150 batchs: 338.11517333984375
INFO:root:Train (Epoch 337): Loss/seq after 02200 batchs: 337.5328674316406
INFO:root:Train (Epoch 337): Loss/seq after 02250 batchs: 336.9716796875
INFO:root:Train (Epoch 337): Loss/seq after 02300 batchs: 335.00408935546875
INFO:root:Train (Epoch 337): Loss/seq after 02350 batchs: 333.1830139160156
INFO:root:Train (Epoch 337): Loss/seq after 02400 batchs: 333.56427001953125
INFO:root:Train (Epoch 337): Loss/seq after 02450 batchs: 331.0707702636719
INFO:root:Train (Epoch 337): Loss/seq after 02500 batchs: 325.7612609863281
INFO:root:Train (Epoch 337): Loss/seq after 02550 batchs: 321.34783935546875
INFO:root:Train (Epoch 337): Loss/seq after 02600 batchs: 317.7310485839844
INFO:root:Train (Epoch 337): Loss/seq after 02650 batchs: 314.6161804199219
INFO:root:Train (Epoch 337): Loss/seq after 02700 batchs: 312.5898742675781
INFO:root:Train (Epoch 337): Loss/seq after 02750 batchs: 309.1396789550781
INFO:root:Train (Epoch 337): Loss/seq after 02800 batchs: 307.24365234375
INFO:root:Train (Epoch 337): Loss/seq after 02850 batchs: 307.0151672363281
INFO:root:Train (Epoch 337): Loss/seq after 02900 batchs: 307.3865051269531
INFO:root:Train (Epoch 337): Loss/seq after 02950 batchs: 308.6360778808594
INFO:root:Train (Epoch 337): Loss/seq after 03000 batchs: 312.85552978515625
INFO:root:Train (Epoch 337): Loss/seq after 03050 batchs: 314.2032165527344
INFO:root:Train (Epoch 337): Loss/seq after 03100 batchs: 315.8742370605469
INFO:root:Train (Epoch 337): Loss/seq after 03150 batchs: 316.1570129394531
INFO:root:Train (Epoch 337): Loss/seq after 03200 batchs: 315.6347961425781
INFO:root:Train (Epoch 337): Loss/seq after 03250 batchs: 315.7676696777344
INFO:root:Train (Epoch 337): Loss/seq after 03300 batchs: 315.18878173828125
INFO:root:Train (Epoch 337): Loss/seq after 03350 batchs: 313.6962585449219
INFO:root:Train (Epoch 337): Loss/seq after 03400 batchs: 311.89349365234375
INFO:root:Train (Epoch 337): Loss/seq after 03450 batchs: 310.9853210449219
INFO:root:Train (Epoch 337): Loss/seq after 03500 batchs: 311.70318603515625
INFO:root:Train (Epoch 337): Loss/seq after 03550 batchs: 310.6325988769531
INFO:root:Train (Epoch 337): Loss/seq after 03600 batchs: 312.8744812011719
INFO:root:Train (Epoch 337): Loss/seq after 03650 batchs: 311.703857421875
INFO:root:Train (Epoch 337): Loss/seq after 03700 batchs: 313.05963134765625
INFO:root:Train (Epoch 337): Loss/seq after 03750 batchs: 315.95989990234375
INFO:root:Train (Epoch 337): Loss/seq after 03800 batchs: 315.9556579589844
INFO:root:Train (Epoch 337): Loss/seq after 03850 batchs: 315.5201416015625
INFO:root:Train (Epoch 337): Loss/seq after 03900 batchs: 316.548095703125
INFO:root:Train (Epoch 337): Loss/seq after 03950 batchs: 318.56536865234375
INFO:root:Train (Epoch 337): Loss/seq after 04000 batchs: 316.9600830078125
INFO:root:Train (Epoch 337): Loss/seq after 04050 batchs: 315.3666687011719
INFO:root:Train (Epoch 337): Loss/seq after 04100 batchs: 314.41766357421875
INFO:root:Train (Epoch 337): Loss/seq after 04150 batchs: 314.4009094238281
INFO:root:Train (Epoch 337): Loss/seq after 04200 batchs: 314.0228271484375
INFO:root:Train (Epoch 337): Loss/seq after 04250 batchs: 313.2488098144531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 337): Loss/seq after 00000 batches: 320.0368347167969
INFO:root:# Valid (Epoch 337): Loss/seq after 00050 batches: 680.7100219726562
INFO:root:# Valid (Epoch 337): Loss/seq after 00100 batches: 729.7314453125
INFO:root:# Valid (Epoch 337): Loss/seq after 00150 batches: 539.3452758789062
INFO:root:# Valid (Epoch 337): Loss/seq after 00200 batches: 490.2469177246094
INFO:root:Artifacts: Make stick videos for epoch 337
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_337_on_20220424_000404.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_337_index_87_on_20220424_000404.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 338): Loss/seq after 00000 batchs: 677.84912109375
INFO:root:Train (Epoch 338): Loss/seq after 00050 batchs: 435.9539794921875
INFO:root:Train (Epoch 338): Loss/seq after 00100 batchs: 431.9083251953125
INFO:root:Train (Epoch 338): Loss/seq after 00150 batchs: 401.787109375
INFO:root:Train (Epoch 338): Loss/seq after 00200 batchs: 447.3182067871094
INFO:root:Train (Epoch 338): Loss/seq after 00250 batchs: 455.7218322753906
INFO:root:Train (Epoch 338): Loss/seq after 00300 batchs: 476.1012268066406
INFO:root:Train (Epoch 338): Loss/seq after 00350 batchs: 456.51446533203125
INFO:root:Train (Epoch 338): Loss/seq after 00400 batchs: 444.47943115234375
INFO:root:Train (Epoch 338): Loss/seq after 00450 batchs: 458.74652099609375
INFO:root:Train (Epoch 338): Loss/seq after 00500 batchs: 443.8298645019531
INFO:root:Train (Epoch 338): Loss/seq after 00550 batchs: 438.3149719238281
INFO:root:Train (Epoch 338): Loss/seq after 00600 batchs: 423.5064392089844
INFO:root:Train (Epoch 338): Loss/seq after 00650 batchs: 406.22216796875
INFO:root:Train (Epoch 338): Loss/seq after 00700 batchs: 390.19219970703125
INFO:root:Train (Epoch 338): Loss/seq after 00750 batchs: 384.1917419433594
INFO:root:Train (Epoch 338): Loss/seq after 00800 batchs: 385.8975524902344
INFO:root:Train (Epoch 338): Loss/seq after 00850 batchs: 373.5338134765625
INFO:root:Train (Epoch 338): Loss/seq after 00900 batchs: 364.20819091796875
INFO:root:Train (Epoch 338): Loss/seq after 00950 batchs: 363.5396728515625
INFO:root:Train (Epoch 338): Loss/seq after 01000 batchs: 357.7544860839844
INFO:root:Train (Epoch 338): Loss/seq after 01050 batchs: 351.9114685058594
INFO:root:Train (Epoch 338): Loss/seq after 01100 batchs: 344.1268005371094
INFO:root:Train (Epoch 338): Loss/seq after 01150 batchs: 334.97845458984375
INFO:root:Train (Epoch 338): Loss/seq after 01200 batchs: 335.2101745605469
INFO:root:Train (Epoch 338): Loss/seq after 01250 batchs: 334.5044860839844
INFO:root:Train (Epoch 338): Loss/seq after 01300 batchs: 327.562744140625
INFO:root:Train (Epoch 338): Loss/seq after 01350 batchs: 320.7315368652344
INFO:root:Train (Epoch 338): Loss/seq after 01400 batchs: 321.9143981933594
INFO:root:Train (Epoch 338): Loss/seq after 01450 batchs: 324.5474548339844
INFO:root:Train (Epoch 338): Loss/seq after 01500 batchs: 330.2481994628906
INFO:root:Train (Epoch 338): Loss/seq after 01550 batchs: 331.100341796875
INFO:root:Train (Epoch 338): Loss/seq after 01600 batchs: 330.19488525390625
INFO:root:Train (Epoch 338): Loss/seq after 01650 batchs: 328.9796447753906
INFO:root:Train (Epoch 338): Loss/seq after 01700 batchs: 331.007568359375
INFO:root:Train (Epoch 338): Loss/seq after 01750 batchs: 331.1335144042969
INFO:root:Train (Epoch 338): Loss/seq after 01800 batchs: 330.24774169921875
INFO:root:Train (Epoch 338): Loss/seq after 01850 batchs: 329.0863037109375
INFO:root:Train (Epoch 338): Loss/seq after 01900 batchs: 328.7672424316406
INFO:root:Train (Epoch 338): Loss/seq after 01950 batchs: 329.04522705078125
INFO:root:Train (Epoch 338): Loss/seq after 02000 batchs: 331.2809143066406
INFO:root:Train (Epoch 338): Loss/seq after 02050 batchs: 332.0723876953125
INFO:root:Train (Epoch 338): Loss/seq after 02100 batchs: 332.1470947265625
INFO:root:Train (Epoch 338): Loss/seq after 02150 batchs: 332.1048278808594
INFO:root:Train (Epoch 338): Loss/seq after 02200 batchs: 331.62945556640625
INFO:root:Train (Epoch 338): Loss/seq after 02250 batchs: 331.23944091796875
INFO:root:Train (Epoch 338): Loss/seq after 02300 batchs: 329.0022888183594
INFO:root:Train (Epoch 338): Loss/seq after 02350 batchs: 327.2231750488281
INFO:root:Train (Epoch 338): Loss/seq after 02400 batchs: 328.0109558105469
INFO:root:Train (Epoch 338): Loss/seq after 02450 batchs: 325.4982604980469
INFO:root:Train (Epoch 338): Loss/seq after 02500 batchs: 320.31640625
INFO:root:Train (Epoch 338): Loss/seq after 02550 batchs: 316.0103759765625
INFO:root:Train (Epoch 338): Loss/seq after 02600 batchs: 312.5401611328125
INFO:root:Train (Epoch 338): Loss/seq after 02650 batchs: 309.410400390625
INFO:root:Train (Epoch 338): Loss/seq after 02700 batchs: 307.3846130371094
INFO:root:Train (Epoch 338): Loss/seq after 02750 batchs: 303.85528564453125
INFO:root:Train (Epoch 338): Loss/seq after 02800 batchs: 302.4918212890625
INFO:root:Train (Epoch 338): Loss/seq after 02850 batchs: 302.4539794921875
INFO:root:Train (Epoch 338): Loss/seq after 02900 batchs: 302.60028076171875
INFO:root:Train (Epoch 338): Loss/seq after 02950 batchs: 303.6730651855469
INFO:root:Train (Epoch 338): Loss/seq after 03000 batchs: 306.7843322753906
INFO:root:Train (Epoch 338): Loss/seq after 03050 batchs: 308.2782897949219
INFO:root:Train (Epoch 338): Loss/seq after 03100 batchs: 310.40374755859375
INFO:root:Train (Epoch 338): Loss/seq after 03150 batchs: 310.5172119140625
INFO:root:Train (Epoch 338): Loss/seq after 03200 batchs: 310.7861022949219
INFO:root:Train (Epoch 338): Loss/seq after 03250 batchs: 310.2572937011719
INFO:root:Train (Epoch 338): Loss/seq after 03300 batchs: 310.0527648925781
INFO:root:Train (Epoch 338): Loss/seq after 03350 batchs: 308.7760925292969
INFO:root:Train (Epoch 338): Loss/seq after 03400 batchs: 307.04681396484375
INFO:root:Train (Epoch 338): Loss/seq after 03450 batchs: 306.3697509765625
INFO:root:Train (Epoch 338): Loss/seq after 03500 batchs: 307.32501220703125
INFO:root:Train (Epoch 338): Loss/seq after 03550 batchs: 306.27374267578125
INFO:root:Train (Epoch 338): Loss/seq after 03600 batchs: 309.12310791015625
INFO:root:Train (Epoch 338): Loss/seq after 03650 batchs: 308.2524719238281
INFO:root:Train (Epoch 338): Loss/seq after 03700 batchs: 309.9702453613281
INFO:root:Train (Epoch 338): Loss/seq after 03750 batchs: 313.03350830078125
INFO:root:Train (Epoch 338): Loss/seq after 03800 batchs: 313.11395263671875
INFO:root:Train (Epoch 338): Loss/seq after 03850 batchs: 312.79779052734375
INFO:root:Train (Epoch 338): Loss/seq after 03900 batchs: 314.0225830078125
INFO:root:Train (Epoch 338): Loss/seq after 03950 batchs: 316.3623962402344
INFO:root:Train (Epoch 338): Loss/seq after 04000 batchs: 314.87847900390625
INFO:root:Train (Epoch 338): Loss/seq after 04050 batchs: 313.2876281738281
INFO:root:Train (Epoch 338): Loss/seq after 04100 batchs: 312.3734436035156
INFO:root:Train (Epoch 338): Loss/seq after 04150 batchs: 312.487060546875
INFO:root:Train (Epoch 338): Loss/seq after 04200 batchs: 312.03485107421875
INFO:root:Train (Epoch 338): Loss/seq after 04250 batchs: 311.28302001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 338): Loss/seq after 00000 batches: 294.2366943359375
INFO:root:# Valid (Epoch 338): Loss/seq after 00050 batches: 711.2886352539062
INFO:root:# Valid (Epoch 338): Loss/seq after 00100 batches: 709.0885009765625
INFO:root:# Valid (Epoch 338): Loss/seq after 00150 batches: 526.255859375
INFO:root:# Valid (Epoch 338): Loss/seq after 00200 batches: 479.3647155761719
INFO:root:Artifacts: Make stick videos for epoch 338
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_338_on_20220424_000903.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_338_index_989_on_20220424_000903.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 339): Loss/seq after 00000 batchs: 393.5862121582031
INFO:root:Train (Epoch 339): Loss/seq after 00050 batchs: 417.9010925292969
INFO:root:Train (Epoch 339): Loss/seq after 00100 batchs: 422.9273681640625
INFO:root:Train (Epoch 339): Loss/seq after 00150 batchs: 400.48590087890625
INFO:root:Train (Epoch 339): Loss/seq after 00200 batchs: 458.527587890625
INFO:root:Train (Epoch 339): Loss/seq after 00250 batchs: 459.3233947753906
INFO:root:Train (Epoch 339): Loss/seq after 00300 batchs: 477.4268493652344
INFO:root:Train (Epoch 339): Loss/seq after 00350 batchs: 457.4366455078125
INFO:root:Train (Epoch 339): Loss/seq after 00400 batchs: 447.0967712402344
INFO:root:Train (Epoch 339): Loss/seq after 00450 batchs: 461.0840759277344
INFO:root:Train (Epoch 339): Loss/seq after 00500 batchs: 449.59674072265625
INFO:root:Train (Epoch 339): Loss/seq after 00550 batchs: 442.7502136230469
INFO:root:Train (Epoch 339): Loss/seq after 00600 batchs: 428.3502502441406
INFO:root:Train (Epoch 339): Loss/seq after 00650 batchs: 410.9676818847656
INFO:root:Train (Epoch 339): Loss/seq after 00700 batchs: 393.81304931640625
INFO:root:Train (Epoch 339): Loss/seq after 00750 batchs: 386.8553466796875
INFO:root:Train (Epoch 339): Loss/seq after 00800 batchs: 388.0853576660156
INFO:root:Train (Epoch 339): Loss/seq after 00850 batchs: 375.786865234375
INFO:root:Train (Epoch 339): Loss/seq after 00900 batchs: 366.2215576171875
INFO:root:Train (Epoch 339): Loss/seq after 00950 batchs: 364.9919738769531
INFO:root:Train (Epoch 339): Loss/seq after 01000 batchs: 358.896728515625
INFO:root:Train (Epoch 339): Loss/seq after 01050 batchs: 352.6877136230469
INFO:root:Train (Epoch 339): Loss/seq after 01100 batchs: 344.8399963378906
INFO:root:Train (Epoch 339): Loss/seq after 01150 batchs: 336.0679016113281
INFO:root:Train (Epoch 339): Loss/seq after 01200 batchs: 335.9951477050781
INFO:root:Train (Epoch 339): Loss/seq after 01250 batchs: 335.1575927734375
INFO:root:Train (Epoch 339): Loss/seq after 01300 batchs: 328.168701171875
INFO:root:Train (Epoch 339): Loss/seq after 01350 batchs: 321.2226257324219
INFO:root:Train (Epoch 339): Loss/seq after 01400 batchs: 322.5072326660156
INFO:root:Train (Epoch 339): Loss/seq after 01450 batchs: 324.8183898925781
INFO:root:Train (Epoch 339): Loss/seq after 01500 batchs: 330.3272399902344
INFO:root:Train (Epoch 339): Loss/seq after 01550 batchs: 331.1992492675781
INFO:root:Train (Epoch 339): Loss/seq after 01600 batchs: 330.3043212890625
INFO:root:Train (Epoch 339): Loss/seq after 01650 batchs: 329.30615234375
INFO:root:Train (Epoch 339): Loss/seq after 01700 batchs: 331.08734130859375
INFO:root:Train (Epoch 339): Loss/seq after 01750 batchs: 330.5301818847656
INFO:root:Train (Epoch 339): Loss/seq after 01800 batchs: 329.7168273925781
INFO:root:Train (Epoch 339): Loss/seq after 01850 batchs: 328.5238037109375
INFO:root:Train (Epoch 339): Loss/seq after 01900 batchs: 327.9695129394531
INFO:root:Train (Epoch 339): Loss/seq after 01950 batchs: 328.1648254394531
INFO:root:Train (Epoch 339): Loss/seq after 02000 batchs: 330.4197082519531
INFO:root:Train (Epoch 339): Loss/seq after 02050 batchs: 330.8340759277344
INFO:root:Train (Epoch 339): Loss/seq after 02100 batchs: 330.67572021484375
INFO:root:Train (Epoch 339): Loss/seq after 02150 batchs: 330.8661193847656
INFO:root:Train (Epoch 339): Loss/seq after 02200 batchs: 330.49285888671875
INFO:root:Train (Epoch 339): Loss/seq after 02250 batchs: 330.1484375
INFO:root:Train (Epoch 339): Loss/seq after 02300 batchs: 327.72735595703125
INFO:root:Train (Epoch 339): Loss/seq after 02350 batchs: 325.8923034667969
INFO:root:Train (Epoch 339): Loss/seq after 02400 batchs: 326.3378601074219
INFO:root:Train (Epoch 339): Loss/seq after 02450 batchs: 324.0034484863281
INFO:root:Train (Epoch 339): Loss/seq after 02500 batchs: 318.7734069824219
INFO:root:Train (Epoch 339): Loss/seq after 02550 batchs: 314.4720764160156
INFO:root:Train (Epoch 339): Loss/seq after 02600 batchs: 311.13909912109375
INFO:root:Train (Epoch 339): Loss/seq after 02650 batchs: 307.9239501953125
INFO:root:Train (Epoch 339): Loss/seq after 02700 batchs: 305.91497802734375
INFO:root:Train (Epoch 339): Loss/seq after 02750 batchs: 302.52099609375
INFO:root:Train (Epoch 339): Loss/seq after 02800 batchs: 300.8499755859375
INFO:root:Train (Epoch 339): Loss/seq after 02850 batchs: 300.6568908691406
INFO:root:Train (Epoch 339): Loss/seq after 02900 batchs: 300.6023864746094
INFO:root:Train (Epoch 339): Loss/seq after 02950 batchs: 301.6539611816406
INFO:root:Train (Epoch 339): Loss/seq after 03000 batchs: 305.2761535644531
INFO:root:Train (Epoch 339): Loss/seq after 03050 batchs: 306.5882263183594
INFO:root:Train (Epoch 339): Loss/seq after 03100 batchs: 308.3692932128906
INFO:root:Train (Epoch 339): Loss/seq after 03150 batchs: 309.0185852050781
INFO:root:Train (Epoch 339): Loss/seq after 03200 batchs: 309.5776062011719
INFO:root:Train (Epoch 339): Loss/seq after 03250 batchs: 310.2803039550781
INFO:root:Train (Epoch 339): Loss/seq after 03300 batchs: 310.795166015625
INFO:root:Train (Epoch 339): Loss/seq after 03350 batchs: 309.7650146484375
INFO:root:Train (Epoch 339): Loss/seq after 03400 batchs: 308.2013854980469
INFO:root:Train (Epoch 339): Loss/seq after 03450 batchs: 307.65850830078125
INFO:root:Train (Epoch 339): Loss/seq after 03500 batchs: 308.6979064941406
INFO:root:Train (Epoch 339): Loss/seq after 03550 batchs: 307.7844543457031
INFO:root:Train (Epoch 339): Loss/seq after 03600 batchs: 310.5503845214844
INFO:root:Train (Epoch 339): Loss/seq after 03650 batchs: 309.7165222167969
INFO:root:Train (Epoch 339): Loss/seq after 03700 batchs: 311.243408203125
INFO:root:Train (Epoch 339): Loss/seq after 03750 batchs: 314.2846374511719
INFO:root:Train (Epoch 339): Loss/seq after 03800 batchs: 314.353515625
INFO:root:Train (Epoch 339): Loss/seq after 03850 batchs: 313.9450378417969
INFO:root:Train (Epoch 339): Loss/seq after 03900 batchs: 314.9195251464844
INFO:root:Train (Epoch 339): Loss/seq after 03950 batchs: 317.30865478515625
INFO:root:Train (Epoch 339): Loss/seq after 04000 batchs: 315.7537536621094
INFO:root:Train (Epoch 339): Loss/seq after 04050 batchs: 314.1282043457031
INFO:root:Train (Epoch 339): Loss/seq after 04100 batchs: 313.1603088378906
INFO:root:Train (Epoch 339): Loss/seq after 04150 batchs: 313.2767028808594
INFO:root:Train (Epoch 339): Loss/seq after 04200 batchs: 312.85546875
INFO:root:Train (Epoch 339): Loss/seq after 04250 batchs: 312.0846862792969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 339): Loss/seq after 00000 batches: 358.54156494140625
INFO:root:# Valid (Epoch 339): Loss/seq after 00050 batches: 643.1358032226562
INFO:root:# Valid (Epoch 339): Loss/seq after 00100 batches: 663.974365234375
INFO:root:# Valid (Epoch 339): Loss/seq after 00150 batches: 496.2514343261719
INFO:root:# Valid (Epoch 339): Loss/seq after 00200 batches: 459.72686767578125
INFO:root:Artifacts: Make stick videos for epoch 339
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_339_on_20220424_001409.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_339_index_1795_on_20220424_001409.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 340): Loss/seq after 00000 batchs: 641.058837890625
INFO:root:Train (Epoch 340): Loss/seq after 00050 batchs: 437.95391845703125
INFO:root:Train (Epoch 340): Loss/seq after 00100 batchs: 445.21990966796875
INFO:root:Train (Epoch 340): Loss/seq after 00150 batchs: 411.9592590332031
INFO:root:Train (Epoch 340): Loss/seq after 00200 batchs: 463.52386474609375
INFO:root:Train (Epoch 340): Loss/seq after 00250 batchs: 480.4017028808594
INFO:root:Train (Epoch 340): Loss/seq after 00300 batchs: 497.5532531738281
INFO:root:Train (Epoch 340): Loss/seq after 00350 batchs: 475.1458435058594
INFO:root:Train (Epoch 340): Loss/seq after 00400 batchs: 468.1190490722656
INFO:root:Train (Epoch 340): Loss/seq after 00450 batchs: 481.12249755859375
INFO:root:Train (Epoch 340): Loss/seq after 00500 batchs: 466.4016418457031
INFO:root:Train (Epoch 340): Loss/seq after 00550 batchs: 458.5965576171875
INFO:root:Train (Epoch 340): Loss/seq after 00600 batchs: 443.0655517578125
INFO:root:Train (Epoch 340): Loss/seq after 00650 batchs: 425.01373291015625
INFO:root:Train (Epoch 340): Loss/seq after 00700 batchs: 407.32904052734375
INFO:root:Train (Epoch 340): Loss/seq after 00750 batchs: 399.2080078125
INFO:root:Train (Epoch 340): Loss/seq after 00800 batchs: 399.92291259765625
INFO:root:Train (Epoch 340): Loss/seq after 00850 batchs: 387.4461669921875
INFO:root:Train (Epoch 340): Loss/seq after 00900 batchs: 377.0553894042969
INFO:root:Train (Epoch 340): Loss/seq after 00950 batchs: 376.2568359375
INFO:root:Train (Epoch 340): Loss/seq after 01000 batchs: 369.16253662109375
INFO:root:Train (Epoch 340): Loss/seq after 01050 batchs: 364.3178405761719
INFO:root:Train (Epoch 340): Loss/seq after 01100 batchs: 358.2088928222656
INFO:root:Train (Epoch 340): Loss/seq after 01150 batchs: 348.6418762207031
INFO:root:Train (Epoch 340): Loss/seq after 01200 batchs: 348.3238220214844
INFO:root:Train (Epoch 340): Loss/seq after 01250 batchs: 347.5589294433594
INFO:root:Train (Epoch 340): Loss/seq after 01300 batchs: 339.92584228515625
INFO:root:Train (Epoch 340): Loss/seq after 01350 batchs: 332.4284973144531
INFO:root:Train (Epoch 340): Loss/seq after 01400 batchs: 334.1086120605469
INFO:root:Train (Epoch 340): Loss/seq after 01450 batchs: 336.6153564453125
INFO:root:Train (Epoch 340): Loss/seq after 01500 batchs: 342.5883483886719
INFO:root:Train (Epoch 340): Loss/seq after 01550 batchs: 343.2239685058594
INFO:root:Train (Epoch 340): Loss/seq after 01600 batchs: 341.99676513671875
INFO:root:Train (Epoch 340): Loss/seq after 01650 batchs: 340.73419189453125
INFO:root:Train (Epoch 340): Loss/seq after 01700 batchs: 342.0567932128906
INFO:root:Train (Epoch 340): Loss/seq after 01750 batchs: 341.7099609375
INFO:root:Train (Epoch 340): Loss/seq after 01800 batchs: 340.709228515625
INFO:root:Train (Epoch 340): Loss/seq after 01850 batchs: 339.2663879394531
INFO:root:Train (Epoch 340): Loss/seq after 01900 batchs: 338.68975830078125
INFO:root:Train (Epoch 340): Loss/seq after 01950 batchs: 338.7095642089844
INFO:root:Train (Epoch 340): Loss/seq after 02000 batchs: 340.5715026855469
INFO:root:Train (Epoch 340): Loss/seq after 02050 batchs: 340.9142150878906
INFO:root:Train (Epoch 340): Loss/seq after 02100 batchs: 340.605712890625
INFO:root:Train (Epoch 340): Loss/seq after 02150 batchs: 340.5940856933594
INFO:root:Train (Epoch 340): Loss/seq after 02200 batchs: 339.9090576171875
INFO:root:Train (Epoch 340): Loss/seq after 02250 batchs: 339.0610656738281
INFO:root:Train (Epoch 340): Loss/seq after 02300 batchs: 337.16766357421875
INFO:root:Train (Epoch 340): Loss/seq after 02350 batchs: 335.1283874511719
INFO:root:Train (Epoch 340): Loss/seq after 02400 batchs: 335.21734619140625
INFO:root:Train (Epoch 340): Loss/seq after 02450 batchs: 332.5234680175781
INFO:root:Train (Epoch 340): Loss/seq after 02500 batchs: 327.1839904785156
INFO:root:Train (Epoch 340): Loss/seq after 02550 batchs: 322.5574035644531
INFO:root:Train (Epoch 340): Loss/seq after 02600 batchs: 319.23602294921875
INFO:root:Train (Epoch 340): Loss/seq after 02650 batchs: 316.0284423828125
INFO:root:Train (Epoch 340): Loss/seq after 02700 batchs: 313.9458312988281
INFO:root:Train (Epoch 340): Loss/seq after 02750 batchs: 310.4837951660156
INFO:root:Train (Epoch 340): Loss/seq after 02800 batchs: 308.75250244140625
INFO:root:Train (Epoch 340): Loss/seq after 02850 batchs: 308.55767822265625
INFO:root:Train (Epoch 340): Loss/seq after 02900 batchs: 308.91864013671875
INFO:root:Train (Epoch 340): Loss/seq after 02950 batchs: 309.7603454589844
INFO:root:Train (Epoch 340): Loss/seq after 03000 batchs: 312.66766357421875
INFO:root:Train (Epoch 340): Loss/seq after 03050 batchs: 314.0987548828125
INFO:root:Train (Epoch 340): Loss/seq after 03100 batchs: 315.3678283691406
INFO:root:Train (Epoch 340): Loss/seq after 03150 batchs: 315.1459655761719
INFO:root:Train (Epoch 340): Loss/seq after 03200 batchs: 315.5394592285156
INFO:root:Train (Epoch 340): Loss/seq after 03250 batchs: 316.02532958984375
INFO:root:Train (Epoch 340): Loss/seq after 03300 batchs: 315.8750915527344
INFO:root:Train (Epoch 340): Loss/seq after 03350 batchs: 314.4697265625
INFO:root:Train (Epoch 340): Loss/seq after 03400 batchs: 312.7166748046875
INFO:root:Train (Epoch 340): Loss/seq after 03450 batchs: 311.94122314453125
INFO:root:Train (Epoch 340): Loss/seq after 03500 batchs: 312.6117858886719
INFO:root:Train (Epoch 340): Loss/seq after 03550 batchs: 311.45806884765625
INFO:root:Train (Epoch 340): Loss/seq after 03600 batchs: 313.8972473144531
INFO:root:Train (Epoch 340): Loss/seq after 03650 batchs: 312.9793395996094
INFO:root:Train (Epoch 340): Loss/seq after 03700 batchs: 314.5977783203125
INFO:root:Train (Epoch 340): Loss/seq after 03750 batchs: 317.5165100097656
INFO:root:Train (Epoch 340): Loss/seq after 03800 batchs: 317.47021484375
INFO:root:Train (Epoch 340): Loss/seq after 03850 batchs: 317.0788879394531
INFO:root:Train (Epoch 340): Loss/seq after 03900 batchs: 317.85113525390625
INFO:root:Train (Epoch 340): Loss/seq after 03950 batchs: 319.7696838378906
INFO:root:Train (Epoch 340): Loss/seq after 04000 batchs: 318.1341857910156
INFO:root:Train (Epoch 340): Loss/seq after 04050 batchs: 316.5196533203125
INFO:root:Train (Epoch 340): Loss/seq after 04100 batchs: 315.6378173828125
INFO:root:Train (Epoch 340): Loss/seq after 04150 batchs: 315.7961120605469
INFO:root:Train (Epoch 340): Loss/seq after 04200 batchs: 315.41790771484375
INFO:root:Train (Epoch 340): Loss/seq after 04250 batchs: 314.5682373046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 340): Loss/seq after 00000 batches: 278.034912109375
INFO:root:# Valid (Epoch 340): Loss/seq after 00050 batches: 660.2479858398438
INFO:root:# Valid (Epoch 340): Loss/seq after 00100 batches: 675.35107421875
INFO:root:# Valid (Epoch 340): Loss/seq after 00150 batches: 505.972412109375
INFO:root:# Valid (Epoch 340): Loss/seq after 00200 batches: 466.16046142578125
INFO:root:Artifacts: Make stick videos for epoch 340
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_340_on_20220424_001901.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_340_index_209_on_20220424_001901.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 341): Loss/seq after 00000 batchs: 501.5032958984375
INFO:root:Train (Epoch 341): Loss/seq after 00050 batchs: 403.2228698730469
INFO:root:Train (Epoch 341): Loss/seq after 00100 batchs: 396.25579833984375
INFO:root:Train (Epoch 341): Loss/seq after 00150 batchs: 376.9126281738281
INFO:root:Train (Epoch 341): Loss/seq after 00200 batchs: 429.2637634277344
INFO:root:Train (Epoch 341): Loss/seq after 00250 batchs: 434.5891418457031
INFO:root:Train (Epoch 341): Loss/seq after 00300 batchs: 455.3366394042969
INFO:root:Train (Epoch 341): Loss/seq after 00350 batchs: 436.13671875
INFO:root:Train (Epoch 341): Loss/seq after 00400 batchs: 427.6366271972656
INFO:root:Train (Epoch 341): Loss/seq after 00450 batchs: 444.8890380859375
INFO:root:Train (Epoch 341): Loss/seq after 00500 batchs: 433.5818176269531
INFO:root:Train (Epoch 341): Loss/seq after 00550 batchs: 428.3680419921875
INFO:root:Train (Epoch 341): Loss/seq after 00600 batchs: 413.9856262207031
INFO:root:Train (Epoch 341): Loss/seq after 00650 batchs: 399.02276611328125
INFO:root:Train (Epoch 341): Loss/seq after 00700 batchs: 382.1828308105469
INFO:root:Train (Epoch 341): Loss/seq after 00750 batchs: 376.31390380859375
INFO:root:Train (Epoch 341): Loss/seq after 00800 batchs: 378.0263977050781
INFO:root:Train (Epoch 341): Loss/seq after 00850 batchs: 366.83636474609375
INFO:root:Train (Epoch 341): Loss/seq after 00900 batchs: 357.7489318847656
INFO:root:Train (Epoch 341): Loss/seq after 00950 batchs: 356.33526611328125
INFO:root:Train (Epoch 341): Loss/seq after 01000 batchs: 350.626708984375
INFO:root:Train (Epoch 341): Loss/seq after 01050 batchs: 343.4902648925781
INFO:root:Train (Epoch 341): Loss/seq after 01100 batchs: 335.97943115234375
INFO:root:Train (Epoch 341): Loss/seq after 01150 batchs: 327.40032958984375
INFO:root:Train (Epoch 341): Loss/seq after 01200 batchs: 327.1258544921875
INFO:root:Train (Epoch 341): Loss/seq after 01250 batchs: 326.30718994140625
INFO:root:Train (Epoch 341): Loss/seq after 01300 batchs: 319.7647399902344
INFO:root:Train (Epoch 341): Loss/seq after 01350 batchs: 313.4281311035156
INFO:root:Train (Epoch 341): Loss/seq after 01400 batchs: 314.72821044921875
INFO:root:Train (Epoch 341): Loss/seq after 01450 batchs: 317.3335266113281
INFO:root:Train (Epoch 341): Loss/seq after 01500 batchs: 323.5294189453125
INFO:root:Train (Epoch 341): Loss/seq after 01550 batchs: 324.616455078125
INFO:root:Train (Epoch 341): Loss/seq after 01600 batchs: 323.75823974609375
INFO:root:Train (Epoch 341): Loss/seq after 01650 batchs: 322.9978942871094
INFO:root:Train (Epoch 341): Loss/seq after 01700 batchs: 324.6999206542969
INFO:root:Train (Epoch 341): Loss/seq after 01750 batchs: 324.0975036621094
INFO:root:Train (Epoch 341): Loss/seq after 01800 batchs: 323.30224609375
INFO:root:Train (Epoch 341): Loss/seq after 01850 batchs: 322.1873474121094
INFO:root:Train (Epoch 341): Loss/seq after 01900 batchs: 321.9879455566406
INFO:root:Train (Epoch 341): Loss/seq after 01950 batchs: 322.3400573730469
INFO:root:Train (Epoch 341): Loss/seq after 02000 batchs: 324.7216491699219
INFO:root:Train (Epoch 341): Loss/seq after 02050 batchs: 325.3781433105469
INFO:root:Train (Epoch 341): Loss/seq after 02100 batchs: 325.43914794921875
INFO:root:Train (Epoch 341): Loss/seq after 02150 batchs: 325.6065368652344
INFO:root:Train (Epoch 341): Loss/seq after 02200 batchs: 325.2542724609375
INFO:root:Train (Epoch 341): Loss/seq after 02250 batchs: 324.57537841796875
INFO:root:Train (Epoch 341): Loss/seq after 02300 batchs: 322.5546875
INFO:root:Train (Epoch 341): Loss/seq after 02350 batchs: 320.70098876953125
INFO:root:Train (Epoch 341): Loss/seq after 02400 batchs: 320.8934631347656
INFO:root:Train (Epoch 341): Loss/seq after 02450 batchs: 318.5990295410156
INFO:root:Train (Epoch 341): Loss/seq after 02500 batchs: 313.5049133300781
INFO:root:Train (Epoch 341): Loss/seq after 02550 batchs: 309.12640380859375
INFO:root:Train (Epoch 341): Loss/seq after 02600 batchs: 305.83721923828125
INFO:root:Train (Epoch 341): Loss/seq after 02650 batchs: 302.7748107910156
INFO:root:Train (Epoch 341): Loss/seq after 02700 batchs: 300.99090576171875
INFO:root:Train (Epoch 341): Loss/seq after 02750 batchs: 297.6240234375
INFO:root:Train (Epoch 341): Loss/seq after 02800 batchs: 296.148681640625
INFO:root:Train (Epoch 341): Loss/seq after 02850 batchs: 296.0652160644531
INFO:root:Train (Epoch 341): Loss/seq after 02900 batchs: 296.28948974609375
INFO:root:Train (Epoch 341): Loss/seq after 02950 batchs: 297.45849609375
INFO:root:Train (Epoch 341): Loss/seq after 03000 batchs: 300.8609619140625
INFO:root:Train (Epoch 341): Loss/seq after 03050 batchs: 302.20233154296875
INFO:root:Train (Epoch 341): Loss/seq after 03100 batchs: 303.3797607421875
INFO:root:Train (Epoch 341): Loss/seq after 03150 batchs: 305.2890930175781
INFO:root:Train (Epoch 341): Loss/seq after 03200 batchs: 306.03759765625
INFO:root:Train (Epoch 341): Loss/seq after 03250 batchs: 306.16802978515625
INFO:root:Train (Epoch 341): Loss/seq after 03300 batchs: 305.5350646972656
INFO:root:Train (Epoch 341): Loss/seq after 03350 batchs: 304.1830749511719
INFO:root:Train (Epoch 341): Loss/seq after 03400 batchs: 302.47979736328125
INFO:root:Train (Epoch 341): Loss/seq after 03450 batchs: 301.6777038574219
INFO:root:Train (Epoch 341): Loss/seq after 03500 batchs: 302.4543762207031
INFO:root:Train (Epoch 341): Loss/seq after 03550 batchs: 301.3541259765625
INFO:root:Train (Epoch 341): Loss/seq after 03600 batchs: 303.91265869140625
INFO:root:Train (Epoch 341): Loss/seq after 03650 batchs: 302.8156433105469
INFO:root:Train (Epoch 341): Loss/seq after 03700 batchs: 304.3834228515625
INFO:root:Train (Epoch 341): Loss/seq after 03750 batchs: 307.51934814453125
INFO:root:Train (Epoch 341): Loss/seq after 03800 batchs: 307.5607604980469
INFO:root:Train (Epoch 341): Loss/seq after 03850 batchs: 307.29412841796875
INFO:root:Train (Epoch 341): Loss/seq after 03900 batchs: 308.3850402832031
INFO:root:Train (Epoch 341): Loss/seq after 03950 batchs: 310.4817199707031
INFO:root:Train (Epoch 341): Loss/seq after 04000 batchs: 309.0050964355469
INFO:root:Train (Epoch 341): Loss/seq after 04050 batchs: 307.4799499511719
INFO:root:Train (Epoch 341): Loss/seq after 04100 batchs: 306.6842041015625
INFO:root:Train (Epoch 341): Loss/seq after 04150 batchs: 306.7709045410156
INFO:root:Train (Epoch 341): Loss/seq after 04200 batchs: 306.3981628417969
INFO:root:Train (Epoch 341): Loss/seq after 04250 batchs: 305.6931457519531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 341): Loss/seq after 00000 batches: 242.7359161376953
INFO:root:# Valid (Epoch 341): Loss/seq after 00050 batches: 696.7801513671875
INFO:root:# Valid (Epoch 341): Loss/seq after 00100 batches: 693.8895874023438
INFO:root:# Valid (Epoch 341): Loss/seq after 00150 batches: 514.8671875
INFO:root:# Valid (Epoch 341): Loss/seq after 00200 batches: 471.3322448730469
INFO:root:Artifacts: Make stick videos for epoch 341
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_341_on_20220424_002344.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_341_index_1185_on_20220424_002344.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 342): Loss/seq after 00000 batchs: 424.9436340332031
INFO:root:Train (Epoch 342): Loss/seq after 00050 batchs: 404.3499450683594
INFO:root:Train (Epoch 342): Loss/seq after 00100 batchs: 407.3810119628906
INFO:root:Train (Epoch 342): Loss/seq after 00150 batchs: 384.6318359375
INFO:root:Train (Epoch 342): Loss/seq after 00200 batchs: 430.4599609375
INFO:root:Train (Epoch 342): Loss/seq after 00250 batchs: 437.7420349121094
INFO:root:Train (Epoch 342): Loss/seq after 00300 batchs: 461.34222412109375
INFO:root:Train (Epoch 342): Loss/seq after 00350 batchs: 443.07330322265625
INFO:root:Train (Epoch 342): Loss/seq after 00400 batchs: 434.7980651855469
INFO:root:Train (Epoch 342): Loss/seq after 00450 batchs: 450.71331787109375
INFO:root:Train (Epoch 342): Loss/seq after 00500 batchs: 438.49041748046875
INFO:root:Train (Epoch 342): Loss/seq after 00550 batchs: 431.69598388671875
INFO:root:Train (Epoch 342): Loss/seq after 00600 batchs: 417.9849548339844
INFO:root:Train (Epoch 342): Loss/seq after 00650 batchs: 404.0954895019531
INFO:root:Train (Epoch 342): Loss/seq after 00700 batchs: 390.6619567871094
INFO:root:Train (Epoch 342): Loss/seq after 00750 batchs: 384.9078063964844
INFO:root:Train (Epoch 342): Loss/seq after 00800 batchs: 385.728759765625
INFO:root:Train (Epoch 342): Loss/seq after 00850 batchs: 373.53875732421875
INFO:root:Train (Epoch 342): Loss/seq after 00900 batchs: 363.9571228027344
INFO:root:Train (Epoch 342): Loss/seq after 00950 batchs: 363.16754150390625
INFO:root:Train (Epoch 342): Loss/seq after 01000 batchs: 356.72100830078125
INFO:root:Train (Epoch 342): Loss/seq after 01050 batchs: 349.9732971191406
INFO:root:Train (Epoch 342): Loss/seq after 01100 batchs: 342.1897277832031
INFO:root:Train (Epoch 342): Loss/seq after 01150 batchs: 333.1620178222656
INFO:root:Train (Epoch 342): Loss/seq after 01200 batchs: 332.65191650390625
INFO:root:Train (Epoch 342): Loss/seq after 01250 batchs: 331.7469482421875
INFO:root:Train (Epoch 342): Loss/seq after 01300 batchs: 324.5671691894531
INFO:root:Train (Epoch 342): Loss/seq after 01350 batchs: 317.5632629394531
INFO:root:Train (Epoch 342): Loss/seq after 01400 batchs: 319.19232177734375
INFO:root:Train (Epoch 342): Loss/seq after 01450 batchs: 321.8240966796875
INFO:root:Train (Epoch 342): Loss/seq after 01500 batchs: 327.1632080078125
INFO:root:Train (Epoch 342): Loss/seq after 01550 batchs: 328.3934020996094
INFO:root:Train (Epoch 342): Loss/seq after 01600 batchs: 327.57745361328125
INFO:root:Train (Epoch 342): Loss/seq after 01650 batchs: 326.5162353515625
INFO:root:Train (Epoch 342): Loss/seq after 01700 batchs: 328.1388854980469
INFO:root:Train (Epoch 342): Loss/seq after 01750 batchs: 327.5453186035156
INFO:root:Train (Epoch 342): Loss/seq after 01800 batchs: 326.5791015625
INFO:root:Train (Epoch 342): Loss/seq after 01850 batchs: 325.4786682128906
INFO:root:Train (Epoch 342): Loss/seq after 01900 batchs: 324.8977966308594
INFO:root:Train (Epoch 342): Loss/seq after 01950 batchs: 325.1906433105469
INFO:root:Train (Epoch 342): Loss/seq after 02000 batchs: 327.4154357910156
INFO:root:Train (Epoch 342): Loss/seq after 02050 batchs: 327.8045349121094
INFO:root:Train (Epoch 342): Loss/seq after 02100 batchs: 327.6604919433594
INFO:root:Train (Epoch 342): Loss/seq after 02150 batchs: 327.794677734375
INFO:root:Train (Epoch 342): Loss/seq after 02200 batchs: 327.3289794921875
INFO:root:Train (Epoch 342): Loss/seq after 02250 batchs: 326.4371337890625
INFO:root:Train (Epoch 342): Loss/seq after 02300 batchs: 324.2347412109375
INFO:root:Train (Epoch 342): Loss/seq after 02350 batchs: 322.3789367675781
INFO:root:Train (Epoch 342): Loss/seq after 02400 batchs: 322.40509033203125
INFO:root:Train (Epoch 342): Loss/seq after 02450 batchs: 319.9587707519531
INFO:root:Train (Epoch 342): Loss/seq after 02500 batchs: 314.8360290527344
INFO:root:Train (Epoch 342): Loss/seq after 02550 batchs: 310.393798828125
INFO:root:Train (Epoch 342): Loss/seq after 02600 batchs: 307.0857238769531
INFO:root:Train (Epoch 342): Loss/seq after 02650 batchs: 304.07086181640625
INFO:root:Train (Epoch 342): Loss/seq after 02700 batchs: 302.0526123046875
INFO:root:Train (Epoch 342): Loss/seq after 02750 batchs: 298.63006591796875
INFO:root:Train (Epoch 342): Loss/seq after 02800 batchs: 297.1019287109375
INFO:root:Train (Epoch 342): Loss/seq after 02850 batchs: 297.013671875
INFO:root:Train (Epoch 342): Loss/seq after 02900 batchs: 297.24786376953125
INFO:root:Train (Epoch 342): Loss/seq after 02950 batchs: 298.2404479980469
INFO:root:Train (Epoch 342): Loss/seq after 03000 batchs: 301.266845703125
INFO:root:Train (Epoch 342): Loss/seq after 03050 batchs: 302.54534912109375
INFO:root:Train (Epoch 342): Loss/seq after 03100 batchs: 303.8050231933594
INFO:root:Train (Epoch 342): Loss/seq after 03150 batchs: 305.2181091308594
INFO:root:Train (Epoch 342): Loss/seq after 03200 batchs: 305.6551513671875
INFO:root:Train (Epoch 342): Loss/seq after 03250 batchs: 305.8775939941406
INFO:root:Train (Epoch 342): Loss/seq after 03300 batchs: 305.9521789550781
INFO:root:Train (Epoch 342): Loss/seq after 03350 batchs: 304.27667236328125
INFO:root:Train (Epoch 342): Loss/seq after 03400 batchs: 302.5576477050781
INFO:root:Train (Epoch 342): Loss/seq after 03450 batchs: 301.74554443359375
INFO:root:Train (Epoch 342): Loss/seq after 03500 batchs: 303.0745544433594
INFO:root:Train (Epoch 342): Loss/seq after 03550 batchs: 302.1310729980469
INFO:root:Train (Epoch 342): Loss/seq after 03600 batchs: 304.7048034667969
INFO:root:Train (Epoch 342): Loss/seq after 03650 batchs: 303.7762756347656
INFO:root:Train (Epoch 342): Loss/seq after 03700 batchs: 305.7508544921875
INFO:root:Train (Epoch 342): Loss/seq after 03750 batchs: 309.09283447265625
INFO:root:Train (Epoch 342): Loss/seq after 03800 batchs: 309.2138671875
INFO:root:Train (Epoch 342): Loss/seq after 03850 batchs: 309.01531982421875
INFO:root:Train (Epoch 342): Loss/seq after 03900 batchs: 310.1539611816406
INFO:root:Train (Epoch 342): Loss/seq after 03950 batchs: 312.26287841796875
INFO:root:Train (Epoch 342): Loss/seq after 04000 batchs: 310.73736572265625
INFO:root:Train (Epoch 342): Loss/seq after 04050 batchs: 309.2001647949219
INFO:root:Train (Epoch 342): Loss/seq after 04100 batchs: 308.4475402832031
INFO:root:Train (Epoch 342): Loss/seq after 04150 batchs: 308.53399658203125
INFO:root:Train (Epoch 342): Loss/seq after 04200 batchs: 308.23028564453125
INFO:root:Train (Epoch 342): Loss/seq after 04250 batchs: 307.5570068359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 342): Loss/seq after 00000 batches: 270.8444519042969
INFO:root:# Valid (Epoch 342): Loss/seq after 00050 batches: 636.1929321289062
INFO:root:# Valid (Epoch 342): Loss/seq after 00100 batches: 645.8098754882812
INFO:root:# Valid (Epoch 342): Loss/seq after 00150 batches: 482.8433837890625
INFO:root:# Valid (Epoch 342): Loss/seq after 00200 batches: 444.0372009277344
INFO:root:Artifacts: Make stick videos for epoch 342
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_342_on_20220424_002828.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_342_index_1396_on_20220424_002828.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 343): Loss/seq after 00000 batchs: 616.9801635742188
INFO:root:Train (Epoch 343): Loss/seq after 00050 batchs: 429.59161376953125
INFO:root:Train (Epoch 343): Loss/seq after 00100 batchs: 424.28717041015625
INFO:root:Train (Epoch 343): Loss/seq after 00150 batchs: 399.9989013671875
INFO:root:Train (Epoch 343): Loss/seq after 00200 batchs: 447.043701171875
INFO:root:Train (Epoch 343): Loss/seq after 00250 batchs: 460.21929931640625
INFO:root:Train (Epoch 343): Loss/seq after 00300 batchs: 480.3351135253906
INFO:root:Train (Epoch 343): Loss/seq after 00350 batchs: 461.044677734375
INFO:root:Train (Epoch 343): Loss/seq after 00400 batchs: 449.779541015625
INFO:root:Train (Epoch 343): Loss/seq after 00450 batchs: 464.50665283203125
INFO:root:Train (Epoch 343): Loss/seq after 00500 batchs: 451.7435607910156
INFO:root:Train (Epoch 343): Loss/seq after 00550 batchs: 444.31048583984375
INFO:root:Train (Epoch 343): Loss/seq after 00600 batchs: 429.37286376953125
INFO:root:Train (Epoch 343): Loss/seq after 00650 batchs: 413.2813415527344
INFO:root:Train (Epoch 343): Loss/seq after 00700 batchs: 396.1386413574219
INFO:root:Train (Epoch 343): Loss/seq after 00750 batchs: 389.4895935058594
INFO:root:Train (Epoch 343): Loss/seq after 00800 batchs: 390.22198486328125
INFO:root:Train (Epoch 343): Loss/seq after 00850 batchs: 378.0249938964844
INFO:root:Train (Epoch 343): Loss/seq after 00900 batchs: 368.24200439453125
INFO:root:Train (Epoch 343): Loss/seq after 00950 batchs: 367.5721130371094
INFO:root:Train (Epoch 343): Loss/seq after 01000 batchs: 361.28851318359375
INFO:root:Train (Epoch 343): Loss/seq after 01050 batchs: 355.9521484375
INFO:root:Train (Epoch 343): Loss/seq after 01100 batchs: 348.27685546875
INFO:root:Train (Epoch 343): Loss/seq after 01150 batchs: 339.0602722167969
INFO:root:Train (Epoch 343): Loss/seq after 01200 batchs: 339.123291015625
INFO:root:Train (Epoch 343): Loss/seq after 01250 batchs: 338.499267578125
INFO:root:Train (Epoch 343): Loss/seq after 01300 batchs: 331.40350341796875
INFO:root:Train (Epoch 343): Loss/seq after 01350 batchs: 324.53326416015625
INFO:root:Train (Epoch 343): Loss/seq after 01400 batchs: 325.6330261230469
INFO:root:Train (Epoch 343): Loss/seq after 01450 batchs: 328.253173828125
INFO:root:Train (Epoch 343): Loss/seq after 01500 batchs: 334.0291442871094
INFO:root:Train (Epoch 343): Loss/seq after 01550 batchs: 335.0998840332031
INFO:root:Train (Epoch 343): Loss/seq after 01600 batchs: 334.8108825683594
INFO:root:Train (Epoch 343): Loss/seq after 01650 batchs: 333.6396789550781
INFO:root:Train (Epoch 343): Loss/seq after 01700 batchs: 335.6890563964844
INFO:root:Train (Epoch 343): Loss/seq after 01750 batchs: 335.1441955566406
INFO:root:Train (Epoch 343): Loss/seq after 01800 batchs: 333.8941345214844
INFO:root:Train (Epoch 343): Loss/seq after 01850 batchs: 332.6613464355469
INFO:root:Train (Epoch 343): Loss/seq after 01900 batchs: 332.0123596191406
INFO:root:Train (Epoch 343): Loss/seq after 01950 batchs: 332.1211242675781
INFO:root:Train (Epoch 343): Loss/seq after 02000 batchs: 334.018310546875
INFO:root:Train (Epoch 343): Loss/seq after 02050 batchs: 334.415283203125
INFO:root:Train (Epoch 343): Loss/seq after 02100 batchs: 334.1537170410156
INFO:root:Train (Epoch 343): Loss/seq after 02150 batchs: 334.1105041503906
INFO:root:Train (Epoch 343): Loss/seq after 02200 batchs: 333.6629333496094
INFO:root:Train (Epoch 343): Loss/seq after 02250 batchs: 333.0650329589844
INFO:root:Train (Epoch 343): Loss/seq after 02300 batchs: 331.1141357421875
INFO:root:Train (Epoch 343): Loss/seq after 02350 batchs: 329.0852355957031
INFO:root:Train (Epoch 343): Loss/seq after 02400 batchs: 329.0556945800781
INFO:root:Train (Epoch 343): Loss/seq after 02450 batchs: 326.5753173828125
INFO:root:Train (Epoch 343): Loss/seq after 02500 batchs: 321.32562255859375
INFO:root:Train (Epoch 343): Loss/seq after 02550 batchs: 316.9599609375
INFO:root:Train (Epoch 343): Loss/seq after 02600 batchs: 313.4312744140625
INFO:root:Train (Epoch 343): Loss/seq after 02650 batchs: 310.1790771484375
INFO:root:Train (Epoch 343): Loss/seq after 02700 batchs: 308.3262023925781
INFO:root:Train (Epoch 343): Loss/seq after 02750 batchs: 304.8739318847656
INFO:root:Train (Epoch 343): Loss/seq after 02800 batchs: 303.5281982421875
INFO:root:Train (Epoch 343): Loss/seq after 02850 batchs: 303.2450256347656
INFO:root:Train (Epoch 343): Loss/seq after 02900 batchs: 303.40423583984375
INFO:root:Train (Epoch 343): Loss/seq after 02950 batchs: 304.3094787597656
INFO:root:Train (Epoch 343): Loss/seq after 03000 batchs: 307.9601135253906
INFO:root:Train (Epoch 343): Loss/seq after 03050 batchs: 309.5471496582031
INFO:root:Train (Epoch 343): Loss/seq after 03100 batchs: 310.84075927734375
INFO:root:Train (Epoch 343): Loss/seq after 03150 batchs: 310.4756164550781
INFO:root:Train (Epoch 343): Loss/seq after 03200 batchs: 311.2699890136719
INFO:root:Train (Epoch 343): Loss/seq after 03250 batchs: 310.96832275390625
INFO:root:Train (Epoch 343): Loss/seq after 03300 batchs: 310.91815185546875
INFO:root:Train (Epoch 343): Loss/seq after 03350 batchs: 309.2359619140625
INFO:root:Train (Epoch 343): Loss/seq after 03400 batchs: 307.48321533203125
INFO:root:Train (Epoch 343): Loss/seq after 03450 batchs: 306.62939453125
INFO:root:Train (Epoch 343): Loss/seq after 03500 batchs: 307.8224792480469
INFO:root:Train (Epoch 343): Loss/seq after 03550 batchs: 306.7043151855469
INFO:root:Train (Epoch 343): Loss/seq after 03600 batchs: 309.0090637207031
INFO:root:Train (Epoch 343): Loss/seq after 03650 batchs: 308.1542053222656
INFO:root:Train (Epoch 343): Loss/seq after 03700 batchs: 309.6862487792969
INFO:root:Train (Epoch 343): Loss/seq after 03750 batchs: 312.73602294921875
INFO:root:Train (Epoch 343): Loss/seq after 03800 batchs: 312.86260986328125
INFO:root:Train (Epoch 343): Loss/seq after 03850 batchs: 312.4464416503906
INFO:root:Train (Epoch 343): Loss/seq after 03900 batchs: 313.23828125
INFO:root:Train (Epoch 343): Loss/seq after 03950 batchs: 314.83319091796875
INFO:root:Train (Epoch 343): Loss/seq after 04000 batchs: 313.2603454589844
INFO:root:Train (Epoch 343): Loss/seq after 04050 batchs: 311.676025390625
INFO:root:Train (Epoch 343): Loss/seq after 04100 batchs: 310.7449951171875
INFO:root:Train (Epoch 343): Loss/seq after 04150 batchs: 310.7204895019531
INFO:root:Train (Epoch 343): Loss/seq after 04200 batchs: 310.2553405761719
INFO:root:Train (Epoch 343): Loss/seq after 04250 batchs: 309.498046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 343): Loss/seq after 00000 batches: 261.23699951171875
INFO:root:# Valid (Epoch 343): Loss/seq after 00050 batches: 653.9473876953125
INFO:root:# Valid (Epoch 343): Loss/seq after 00100 batches: 678.5532836914062
INFO:root:# Valid (Epoch 343): Loss/seq after 00150 batches: 506.67706298828125
INFO:root:# Valid (Epoch 343): Loss/seq after 00200 batches: 464.03369140625
INFO:root:Artifacts: Make stick videos for epoch 343
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_343_on_20220424_003327.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_343_index_1680_on_20220424_003327.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 344): Loss/seq after 00000 batchs: 514.3308715820312
INFO:root:Train (Epoch 344): Loss/seq after 00050 batchs: 404.7224426269531
INFO:root:Train (Epoch 344): Loss/seq after 00100 batchs: 412.47833251953125
INFO:root:Train (Epoch 344): Loss/seq after 00150 batchs: 390.5634460449219
INFO:root:Train (Epoch 344): Loss/seq after 00200 batchs: 459.31451416015625
INFO:root:Train (Epoch 344): Loss/seq after 00250 batchs: 475.4164733886719
INFO:root:Train (Epoch 344): Loss/seq after 00300 batchs: 490.8748474121094
INFO:root:Train (Epoch 344): Loss/seq after 00350 batchs: 469.87066650390625
INFO:root:Train (Epoch 344): Loss/seq after 00400 batchs: 463.19317626953125
INFO:root:Train (Epoch 344): Loss/seq after 00450 batchs: 475.9617919921875
INFO:root:Train (Epoch 344): Loss/seq after 00500 batchs: 464.4637756347656
INFO:root:Train (Epoch 344): Loss/seq after 00550 batchs: 456.5369873046875
INFO:root:Train (Epoch 344): Loss/seq after 00600 batchs: 440.9295959472656
INFO:root:Train (Epoch 344): Loss/seq after 00650 batchs: 426.69647216796875
INFO:root:Train (Epoch 344): Loss/seq after 00700 batchs: 409.6388244628906
INFO:root:Train (Epoch 344): Loss/seq after 00750 batchs: 403.32867431640625
INFO:root:Train (Epoch 344): Loss/seq after 00800 batchs: 403.742919921875
INFO:root:Train (Epoch 344): Loss/seq after 00850 batchs: 390.8799133300781
INFO:root:Train (Epoch 344): Loss/seq after 00900 batchs: 380.56536865234375
INFO:root:Train (Epoch 344): Loss/seq after 00950 batchs: 378.7364196777344
INFO:root:Train (Epoch 344): Loss/seq after 01000 batchs: 372.3586120605469
INFO:root:Train (Epoch 344): Loss/seq after 01050 batchs: 365.17108154296875
INFO:root:Train (Epoch 344): Loss/seq after 01100 batchs: 356.1516418457031
INFO:root:Train (Epoch 344): Loss/seq after 01150 batchs: 346.4971618652344
INFO:root:Train (Epoch 344): Loss/seq after 01200 batchs: 345.66278076171875
INFO:root:Train (Epoch 344): Loss/seq after 01250 batchs: 344.0256652832031
INFO:root:Train (Epoch 344): Loss/seq after 01300 batchs: 336.54888916015625
INFO:root:Train (Epoch 344): Loss/seq after 01350 batchs: 329.2337341308594
INFO:root:Train (Epoch 344): Loss/seq after 01400 batchs: 329.5503234863281
INFO:root:Train (Epoch 344): Loss/seq after 01450 batchs: 331.5494079589844
INFO:root:Train (Epoch 344): Loss/seq after 01500 batchs: 337.0085144042969
INFO:root:Train (Epoch 344): Loss/seq after 01550 batchs: 337.69525146484375
INFO:root:Train (Epoch 344): Loss/seq after 01600 batchs: 336.3546447753906
INFO:root:Train (Epoch 344): Loss/seq after 01650 batchs: 335.0782470703125
INFO:root:Train (Epoch 344): Loss/seq after 01700 batchs: 336.1419677734375
INFO:root:Train (Epoch 344): Loss/seq after 01750 batchs: 335.1590576171875
INFO:root:Train (Epoch 344): Loss/seq after 01800 batchs: 333.8433532714844
INFO:root:Train (Epoch 344): Loss/seq after 01850 batchs: 332.51031494140625
INFO:root:Train (Epoch 344): Loss/seq after 01900 batchs: 331.9670715332031
INFO:root:Train (Epoch 344): Loss/seq after 01950 batchs: 332.2326354980469
INFO:root:Train (Epoch 344): Loss/seq after 02000 batchs: 334.4632568359375
INFO:root:Train (Epoch 344): Loss/seq after 02050 batchs: 334.99310302734375
INFO:root:Train (Epoch 344): Loss/seq after 02100 batchs: 334.8197021484375
INFO:root:Train (Epoch 344): Loss/seq after 02150 batchs: 334.8622131347656
INFO:root:Train (Epoch 344): Loss/seq after 02200 batchs: 334.2552795410156
INFO:root:Train (Epoch 344): Loss/seq after 02250 batchs: 333.6204528808594
INFO:root:Train (Epoch 344): Loss/seq after 02300 batchs: 331.53131103515625
INFO:root:Train (Epoch 344): Loss/seq after 02350 batchs: 329.59808349609375
INFO:root:Train (Epoch 344): Loss/seq after 02400 batchs: 329.62542724609375
INFO:root:Train (Epoch 344): Loss/seq after 02450 batchs: 327.10223388671875
INFO:root:Train (Epoch 344): Loss/seq after 02500 batchs: 321.8717956542969
INFO:root:Train (Epoch 344): Loss/seq after 02550 batchs: 317.3536682128906
INFO:root:Train (Epoch 344): Loss/seq after 02600 batchs: 313.73284912109375
INFO:root:Train (Epoch 344): Loss/seq after 02650 batchs: 310.4238586425781
INFO:root:Train (Epoch 344): Loss/seq after 02700 batchs: 308.4567565917969
INFO:root:Train (Epoch 344): Loss/seq after 02750 batchs: 304.8792724609375
INFO:root:Train (Epoch 344): Loss/seq after 02800 batchs: 303.6287841796875
INFO:root:Train (Epoch 344): Loss/seq after 02850 batchs: 303.367431640625
INFO:root:Train (Epoch 344): Loss/seq after 02900 batchs: 303.5212707519531
INFO:root:Train (Epoch 344): Loss/seq after 02950 batchs: 304.3694152832031
INFO:root:Train (Epoch 344): Loss/seq after 03000 batchs: 307.09765625
INFO:root:Train (Epoch 344): Loss/seq after 03050 batchs: 308.10650634765625
INFO:root:Train (Epoch 344): Loss/seq after 03100 batchs: 309.33685302734375
INFO:root:Train (Epoch 344): Loss/seq after 03150 batchs: 309.1299743652344
INFO:root:Train (Epoch 344): Loss/seq after 03200 batchs: 308.6813049316406
INFO:root:Train (Epoch 344): Loss/seq after 03250 batchs: 308.39105224609375
INFO:root:Train (Epoch 344): Loss/seq after 03300 batchs: 307.81549072265625
INFO:root:Train (Epoch 344): Loss/seq after 03350 batchs: 306.39776611328125
INFO:root:Train (Epoch 344): Loss/seq after 03400 batchs: 304.65838623046875
INFO:root:Train (Epoch 344): Loss/seq after 03450 batchs: 303.8188171386719
INFO:root:Train (Epoch 344): Loss/seq after 03500 batchs: 304.7001953125
INFO:root:Train (Epoch 344): Loss/seq after 03550 batchs: 303.61181640625
INFO:root:Train (Epoch 344): Loss/seq after 03600 batchs: 306.0156555175781
INFO:root:Train (Epoch 344): Loss/seq after 03650 batchs: 304.8890380859375
INFO:root:Train (Epoch 344): Loss/seq after 03700 batchs: 306.2652587890625
INFO:root:Train (Epoch 344): Loss/seq after 03750 batchs: 309.1566162109375
INFO:root:Train (Epoch 344): Loss/seq after 03800 batchs: 309.1838684082031
INFO:root:Train (Epoch 344): Loss/seq after 03850 batchs: 308.8735046386719
INFO:root:Train (Epoch 344): Loss/seq after 03900 batchs: 310.1712951660156
INFO:root:Train (Epoch 344): Loss/seq after 03950 batchs: 312.1363830566406
INFO:root:Train (Epoch 344): Loss/seq after 04000 batchs: 310.5885314941406
INFO:root:Train (Epoch 344): Loss/seq after 04050 batchs: 309.0516357421875
INFO:root:Train (Epoch 344): Loss/seq after 04100 batchs: 308.1256408691406
INFO:root:Train (Epoch 344): Loss/seq after 04150 batchs: 308.1066589355469
INFO:root:Train (Epoch 344): Loss/seq after 04200 batchs: 307.6500549316406
INFO:root:Train (Epoch 344): Loss/seq after 04250 batchs: 306.794189453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 344): Loss/seq after 00000 batches: 253.93399047851562
INFO:root:# Valid (Epoch 344): Loss/seq after 00050 batches: 709.8038940429688
INFO:root:# Valid (Epoch 344): Loss/seq after 00100 batches: 719.74169921875
INFO:root:# Valid (Epoch 344): Loss/seq after 00150 batches: 534.6742553710938
INFO:root:# Valid (Epoch 344): Loss/seq after 00200 batches: 487.9988708496094
INFO:root:Artifacts: Make stick videos for epoch 344
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_344_on_20220424_003818.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_344_index_1848_on_20220424_003818.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 345): Loss/seq after 00000 batchs: 450.25531005859375
INFO:root:Train (Epoch 345): Loss/seq after 00050 batchs: 416.77191162109375
INFO:root:Train (Epoch 345): Loss/seq after 00100 batchs: 421.23883056640625
INFO:root:Train (Epoch 345): Loss/seq after 00150 batchs: 395.34881591796875
INFO:root:Train (Epoch 345): Loss/seq after 00200 batchs: 439.301025390625
INFO:root:Train (Epoch 345): Loss/seq after 00250 batchs: 459.9902038574219
INFO:root:Train (Epoch 345): Loss/seq after 00300 batchs: 483.17144775390625
INFO:root:Train (Epoch 345): Loss/seq after 00350 batchs: 463.9523620605469
INFO:root:Train (Epoch 345): Loss/seq after 00400 batchs: 455.88421630859375
INFO:root:Train (Epoch 345): Loss/seq after 00450 batchs: 469.6986083984375
INFO:root:Train (Epoch 345): Loss/seq after 00500 batchs: 452.9683837890625
INFO:root:Train (Epoch 345): Loss/seq after 00550 batchs: 444.2738952636719
INFO:root:Train (Epoch 345): Loss/seq after 00600 batchs: 429.4057312011719
INFO:root:Train (Epoch 345): Loss/seq after 00650 batchs: 411.41754150390625
INFO:root:Train (Epoch 345): Loss/seq after 00700 batchs: 393.92730712890625
INFO:root:Train (Epoch 345): Loss/seq after 00750 batchs: 386.80499267578125
INFO:root:Train (Epoch 345): Loss/seq after 00800 batchs: 387.6780090332031
INFO:root:Train (Epoch 345): Loss/seq after 00850 batchs: 375.3130798339844
INFO:root:Train (Epoch 345): Loss/seq after 00900 batchs: 365.8633728027344
INFO:root:Train (Epoch 345): Loss/seq after 00950 batchs: 364.29931640625
INFO:root:Train (Epoch 345): Loss/seq after 01000 batchs: 358.0892639160156
INFO:root:Train (Epoch 345): Loss/seq after 01050 batchs: 352.5269775390625
INFO:root:Train (Epoch 345): Loss/seq after 01100 batchs: 344.3450012207031
INFO:root:Train (Epoch 345): Loss/seq after 01150 batchs: 335.4268798828125
INFO:root:Train (Epoch 345): Loss/seq after 01200 batchs: 334.71563720703125
INFO:root:Train (Epoch 345): Loss/seq after 01250 batchs: 334.91448974609375
INFO:root:Train (Epoch 345): Loss/seq after 01300 batchs: 328.20611572265625
INFO:root:Train (Epoch 345): Loss/seq after 01350 batchs: 321.2235412597656
INFO:root:Train (Epoch 345): Loss/seq after 01400 batchs: 321.85546875
INFO:root:Train (Epoch 345): Loss/seq after 01450 batchs: 324.7994384765625
INFO:root:Train (Epoch 345): Loss/seq after 01500 batchs: 330.72491455078125
INFO:root:Train (Epoch 345): Loss/seq after 01550 batchs: 332.2561950683594
INFO:root:Train (Epoch 345): Loss/seq after 01600 batchs: 331.55731201171875
INFO:root:Train (Epoch 345): Loss/seq after 01650 batchs: 330.92822265625
INFO:root:Train (Epoch 345): Loss/seq after 01700 batchs: 332.3641357421875
INFO:root:Train (Epoch 345): Loss/seq after 01750 batchs: 331.78900146484375
INFO:root:Train (Epoch 345): Loss/seq after 01800 batchs: 330.74560546875
INFO:root:Train (Epoch 345): Loss/seq after 01850 batchs: 329.5392150878906
INFO:root:Train (Epoch 345): Loss/seq after 01900 batchs: 329.2126159667969
INFO:root:Train (Epoch 345): Loss/seq after 01950 batchs: 329.4774169921875
INFO:root:Train (Epoch 345): Loss/seq after 02000 batchs: 331.944091796875
INFO:root:Train (Epoch 345): Loss/seq after 02050 batchs: 332.474609375
INFO:root:Train (Epoch 345): Loss/seq after 02100 batchs: 332.13470458984375
INFO:root:Train (Epoch 345): Loss/seq after 02150 batchs: 332.1324462890625
INFO:root:Train (Epoch 345): Loss/seq after 02200 batchs: 331.63385009765625
INFO:root:Train (Epoch 345): Loss/seq after 02250 batchs: 331.1055603027344
INFO:root:Train (Epoch 345): Loss/seq after 02300 batchs: 328.9801940917969
INFO:root:Train (Epoch 345): Loss/seq after 02350 batchs: 327.1340026855469
INFO:root:Train (Epoch 345): Loss/seq after 02400 batchs: 327.2599792480469
INFO:root:Train (Epoch 345): Loss/seq after 02450 batchs: 324.8631286621094
INFO:root:Train (Epoch 345): Loss/seq after 02500 batchs: 319.6375732421875
INFO:root:Train (Epoch 345): Loss/seq after 02550 batchs: 315.1191101074219
INFO:root:Train (Epoch 345): Loss/seq after 02600 batchs: 311.61578369140625
INFO:root:Train (Epoch 345): Loss/seq after 02650 batchs: 308.4452209472656
INFO:root:Train (Epoch 345): Loss/seq after 02700 batchs: 306.26580810546875
INFO:root:Train (Epoch 345): Loss/seq after 02750 batchs: 302.8159484863281
INFO:root:Train (Epoch 345): Loss/seq after 02800 batchs: 301.8450012207031
INFO:root:Train (Epoch 345): Loss/seq after 02850 batchs: 301.5680847167969
INFO:root:Train (Epoch 345): Loss/seq after 02900 batchs: 301.72845458984375
INFO:root:Train (Epoch 345): Loss/seq after 02950 batchs: 302.7924499511719
INFO:root:Train (Epoch 345): Loss/seq after 03000 batchs: 305.7591247558594
INFO:root:Train (Epoch 345): Loss/seq after 03050 batchs: 307.4747009277344
INFO:root:Train (Epoch 345): Loss/seq after 03100 batchs: 308.7764892578125
INFO:root:Train (Epoch 345): Loss/seq after 03150 batchs: 308.85919189453125
INFO:root:Train (Epoch 345): Loss/seq after 03200 batchs: 308.7140197753906
INFO:root:Train (Epoch 345): Loss/seq after 03250 batchs: 307.9793701171875
INFO:root:Train (Epoch 345): Loss/seq after 03300 batchs: 307.1840515136719
INFO:root:Train (Epoch 345): Loss/seq after 03350 batchs: 305.39825439453125
INFO:root:Train (Epoch 345): Loss/seq after 03400 batchs: 303.75921630859375
INFO:root:Train (Epoch 345): Loss/seq after 03450 batchs: 302.9378356933594
INFO:root:Train (Epoch 345): Loss/seq after 03500 batchs: 303.7101135253906
INFO:root:Train (Epoch 345): Loss/seq after 03550 batchs: 302.6607360839844
INFO:root:Train (Epoch 345): Loss/seq after 03600 batchs: 304.8874816894531
INFO:root:Train (Epoch 345): Loss/seq after 03650 batchs: 303.78076171875
INFO:root:Train (Epoch 345): Loss/seq after 03700 batchs: 305.3810119628906
INFO:root:Train (Epoch 345): Loss/seq after 03750 batchs: 308.353759765625
INFO:root:Train (Epoch 345): Loss/seq after 03800 batchs: 308.4015197753906
INFO:root:Train (Epoch 345): Loss/seq after 03850 batchs: 307.91204833984375
INFO:root:Train (Epoch 345): Loss/seq after 03900 batchs: 309.1410827636719
INFO:root:Train (Epoch 345): Loss/seq after 03950 batchs: 310.89788818359375
INFO:root:Train (Epoch 345): Loss/seq after 04000 batchs: 309.3549499511719
INFO:root:Train (Epoch 345): Loss/seq after 04050 batchs: 307.79547119140625
INFO:root:Train (Epoch 345): Loss/seq after 04100 batchs: 306.8708801269531
INFO:root:Train (Epoch 345): Loss/seq after 04150 batchs: 306.72235107421875
INFO:root:Train (Epoch 345): Loss/seq after 04200 batchs: 306.1961975097656
INFO:root:Train (Epoch 345): Loss/seq after 04250 batchs: 305.4005432128906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 345): Loss/seq after 00000 batches: 366.66650390625
INFO:root:# Valid (Epoch 345): Loss/seq after 00050 batches: 678.8345947265625
INFO:root:# Valid (Epoch 345): Loss/seq after 00100 batches: 706.5827026367188
INFO:root:# Valid (Epoch 345): Loss/seq after 00150 batches: 521.8704223632812
INFO:root:# Valid (Epoch 345): Loss/seq after 00200 batches: 477.02569580078125
INFO:root:Artifacts: Make stick videos for epoch 345
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_345_on_20220424_004312.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_345_index_1880_on_20220424_004312.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 346): Loss/seq after 00000 batchs: 397.7608337402344
INFO:root:Train (Epoch 346): Loss/seq after 00050 batchs: 396.9349060058594
INFO:root:Train (Epoch 346): Loss/seq after 00100 batchs: 409.61419677734375
INFO:root:Train (Epoch 346): Loss/seq after 00150 batchs: 385.5190734863281
INFO:root:Train (Epoch 346): Loss/seq after 00200 batchs: 440.10369873046875
INFO:root:Train (Epoch 346): Loss/seq after 00250 batchs: 469.4103088378906
INFO:root:Train (Epoch 346): Loss/seq after 00300 batchs: 498.5566711425781
INFO:root:Train (Epoch 346): Loss/seq after 00350 batchs: 480.98052978515625
INFO:root:Train (Epoch 346): Loss/seq after 00400 batchs: 474.48272705078125
INFO:root:Train (Epoch 346): Loss/seq after 00450 batchs: 487.6856384277344
INFO:root:Train (Epoch 346): Loss/seq after 00500 batchs: 472.7308044433594
INFO:root:Train (Epoch 346): Loss/seq after 00550 batchs: 464.1153259277344
INFO:root:Train (Epoch 346): Loss/seq after 00600 batchs: 447.7039794921875
INFO:root:Train (Epoch 346): Loss/seq after 00650 batchs: 428.27496337890625
INFO:root:Train (Epoch 346): Loss/seq after 00700 batchs: 410.1452941894531
INFO:root:Train (Epoch 346): Loss/seq after 00750 batchs: 402.6246032714844
INFO:root:Train (Epoch 346): Loss/seq after 00800 batchs: 402.48529052734375
INFO:root:Train (Epoch 346): Loss/seq after 00850 batchs: 389.9898681640625
INFO:root:Train (Epoch 346): Loss/seq after 00900 batchs: 380.140869140625
INFO:root:Train (Epoch 346): Loss/seq after 00950 batchs: 380.1467590332031
INFO:root:Train (Epoch 346): Loss/seq after 01000 batchs: 372.8563232421875
INFO:root:Train (Epoch 346): Loss/seq after 01050 batchs: 365.3438720703125
INFO:root:Train (Epoch 346): Loss/seq after 01100 batchs: 356.9526672363281
INFO:root:Train (Epoch 346): Loss/seq after 01150 batchs: 347.24041748046875
INFO:root:Train (Epoch 346): Loss/seq after 01200 batchs: 346.03961181640625
INFO:root:Train (Epoch 346): Loss/seq after 01250 batchs: 345.0239562988281
INFO:root:Train (Epoch 346): Loss/seq after 01300 batchs: 337.68121337890625
INFO:root:Train (Epoch 346): Loss/seq after 01350 batchs: 330.4917297363281
INFO:root:Train (Epoch 346): Loss/seq after 01400 batchs: 331.231201171875
INFO:root:Train (Epoch 346): Loss/seq after 01450 batchs: 333.1109619140625
INFO:root:Train (Epoch 346): Loss/seq after 01500 batchs: 338.2970886230469
INFO:root:Train (Epoch 346): Loss/seq after 01550 batchs: 338.4692687988281
INFO:root:Train (Epoch 346): Loss/seq after 01600 batchs: 337.44671630859375
INFO:root:Train (Epoch 346): Loss/seq after 01650 batchs: 335.9709777832031
INFO:root:Train (Epoch 346): Loss/seq after 01700 batchs: 338.56842041015625
INFO:root:Train (Epoch 346): Loss/seq after 01750 batchs: 338.0716857910156
INFO:root:Train (Epoch 346): Loss/seq after 01800 batchs: 336.92767333984375
INFO:root:Train (Epoch 346): Loss/seq after 01850 batchs: 335.6787414550781
INFO:root:Train (Epoch 346): Loss/seq after 01900 batchs: 335.0389099121094
INFO:root:Train (Epoch 346): Loss/seq after 01950 batchs: 335.21856689453125
INFO:root:Train (Epoch 346): Loss/seq after 02000 batchs: 337.1907043457031
INFO:root:Train (Epoch 346): Loss/seq after 02050 batchs: 337.4791259765625
INFO:root:Train (Epoch 346): Loss/seq after 02100 batchs: 337.13031005859375
INFO:root:Train (Epoch 346): Loss/seq after 02150 batchs: 336.9221496582031
INFO:root:Train (Epoch 346): Loss/seq after 02200 batchs: 336.2275695800781
INFO:root:Train (Epoch 346): Loss/seq after 02250 batchs: 335.39984130859375
INFO:root:Train (Epoch 346): Loss/seq after 02300 batchs: 333.0461730957031
INFO:root:Train (Epoch 346): Loss/seq after 02350 batchs: 331.1339416503906
INFO:root:Train (Epoch 346): Loss/seq after 02400 batchs: 331.0113220214844
INFO:root:Train (Epoch 346): Loss/seq after 02450 batchs: 328.3249206542969
INFO:root:Train (Epoch 346): Loss/seq after 02500 batchs: 322.9964294433594
INFO:root:Train (Epoch 346): Loss/seq after 02550 batchs: 318.4004211425781
INFO:root:Train (Epoch 346): Loss/seq after 02600 batchs: 314.88397216796875
INFO:root:Train (Epoch 346): Loss/seq after 02650 batchs: 311.5758972167969
INFO:root:Train (Epoch 346): Loss/seq after 02700 batchs: 309.3706970214844
INFO:root:Train (Epoch 346): Loss/seq after 02750 batchs: 306.02764892578125
INFO:root:Train (Epoch 346): Loss/seq after 02800 batchs: 304.65234375
INFO:root:Train (Epoch 346): Loss/seq after 02850 batchs: 304.2971496582031
INFO:root:Train (Epoch 346): Loss/seq after 02900 batchs: 304.42987060546875
INFO:root:Train (Epoch 346): Loss/seq after 02950 batchs: 305.31427001953125
INFO:root:Train (Epoch 346): Loss/seq after 03000 batchs: 308.3409423828125
INFO:root:Train (Epoch 346): Loss/seq after 03050 batchs: 309.5372009277344
INFO:root:Train (Epoch 346): Loss/seq after 03100 batchs: 310.6070251464844
INFO:root:Train (Epoch 346): Loss/seq after 03150 batchs: 310.7532653808594
INFO:root:Train (Epoch 346): Loss/seq after 03200 batchs: 310.3209228515625
INFO:root:Train (Epoch 346): Loss/seq after 03250 batchs: 309.85870361328125
INFO:root:Train (Epoch 346): Loss/seq after 03300 batchs: 309.0686340332031
INFO:root:Train (Epoch 346): Loss/seq after 03350 batchs: 307.59393310546875
INFO:root:Train (Epoch 346): Loss/seq after 03400 batchs: 305.881591796875
INFO:root:Train (Epoch 346): Loss/seq after 03450 batchs: 305.0545349121094
INFO:root:Train (Epoch 346): Loss/seq after 03500 batchs: 305.8019104003906
INFO:root:Train (Epoch 346): Loss/seq after 03550 batchs: 304.7257995605469
INFO:root:Train (Epoch 346): Loss/seq after 03600 batchs: 307.0968933105469
INFO:root:Train (Epoch 346): Loss/seq after 03650 batchs: 305.99652099609375
INFO:root:Train (Epoch 346): Loss/seq after 03700 batchs: 307.3744201660156
INFO:root:Train (Epoch 346): Loss/seq after 03750 batchs: 310.33111572265625
INFO:root:Train (Epoch 346): Loss/seq after 03800 batchs: 310.4032287597656
INFO:root:Train (Epoch 346): Loss/seq after 03850 batchs: 310.0832214355469
INFO:root:Train (Epoch 346): Loss/seq after 03900 batchs: 310.779541015625
INFO:root:Train (Epoch 346): Loss/seq after 03950 batchs: 312.76007080078125
INFO:root:Train (Epoch 346): Loss/seq after 04000 batchs: 311.2294616699219
INFO:root:Train (Epoch 346): Loss/seq after 04050 batchs: 309.6784362792969
INFO:root:Train (Epoch 346): Loss/seq after 04100 batchs: 308.7621154785156
INFO:root:Train (Epoch 346): Loss/seq after 04150 batchs: 308.86322021484375
INFO:root:Train (Epoch 346): Loss/seq after 04200 batchs: 308.41693115234375
INFO:root:Train (Epoch 346): Loss/seq after 04250 batchs: 307.6206970214844
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 346): Loss/seq after 00000 batches: 299.51904296875
INFO:root:# Valid (Epoch 346): Loss/seq after 00050 batches: 687.5498046875
INFO:root:# Valid (Epoch 346): Loss/seq after 00100 batches: 735.7604370117188
INFO:root:# Valid (Epoch 346): Loss/seq after 00150 batches: 543.9995727539062
INFO:root:# Valid (Epoch 346): Loss/seq after 00200 batches: 493.0262145996094
INFO:root:Artifacts: Make stick videos for epoch 346
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_346_on_20220424_004758.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_346_index_192_on_20220424_004758.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 347): Loss/seq after 00000 batchs: 508.92388916015625
INFO:root:Train (Epoch 347): Loss/seq after 00050 batchs: 410.300537109375
INFO:root:Train (Epoch 347): Loss/seq after 00100 batchs: 397.4558410644531
INFO:root:Train (Epoch 347): Loss/seq after 00150 batchs: 378.04254150390625
INFO:root:Train (Epoch 347): Loss/seq after 00200 batchs: 434.11724853515625
INFO:root:Train (Epoch 347): Loss/seq after 00250 batchs: 451.53094482421875
INFO:root:Train (Epoch 347): Loss/seq after 00300 batchs: 472.9612731933594
INFO:root:Train (Epoch 347): Loss/seq after 00350 batchs: 453.46575927734375
INFO:root:Train (Epoch 347): Loss/seq after 00400 batchs: 444.3570251464844
INFO:root:Train (Epoch 347): Loss/seq after 00450 batchs: 458.8941955566406
INFO:root:Train (Epoch 347): Loss/seq after 00500 batchs: 444.445556640625
INFO:root:Train (Epoch 347): Loss/seq after 00550 batchs: 436.80413818359375
INFO:root:Train (Epoch 347): Loss/seq after 00600 batchs: 421.8265075683594
INFO:root:Train (Epoch 347): Loss/seq after 00650 batchs: 404.8132629394531
INFO:root:Train (Epoch 347): Loss/seq after 00700 batchs: 388.111328125
INFO:root:Train (Epoch 347): Loss/seq after 00750 batchs: 382.3722839355469
INFO:root:Train (Epoch 347): Loss/seq after 00800 batchs: 383.1139221191406
INFO:root:Train (Epoch 347): Loss/seq after 00850 batchs: 371.5474853515625
INFO:root:Train (Epoch 347): Loss/seq after 00900 batchs: 362.9320373535156
INFO:root:Train (Epoch 347): Loss/seq after 00950 batchs: 361.88226318359375
INFO:root:Train (Epoch 347): Loss/seq after 01000 batchs: 356.1590881347656
INFO:root:Train (Epoch 347): Loss/seq after 01050 batchs: 349.6514892578125
INFO:root:Train (Epoch 347): Loss/seq after 01100 batchs: 341.6170654296875
INFO:root:Train (Epoch 347): Loss/seq after 01150 batchs: 332.6946716308594
INFO:root:Train (Epoch 347): Loss/seq after 01200 batchs: 331.3522033691406
INFO:root:Train (Epoch 347): Loss/seq after 01250 batchs: 330.891357421875
INFO:root:Train (Epoch 347): Loss/seq after 01300 batchs: 323.8597412109375
INFO:root:Train (Epoch 347): Loss/seq after 01350 batchs: 317.0503234863281
INFO:root:Train (Epoch 347): Loss/seq after 01400 batchs: 317.9289855957031
INFO:root:Train (Epoch 347): Loss/seq after 01450 batchs: 320.70062255859375
INFO:root:Train (Epoch 347): Loss/seq after 01500 batchs: 326.2850341796875
INFO:root:Train (Epoch 347): Loss/seq after 01550 batchs: 326.91754150390625
INFO:root:Train (Epoch 347): Loss/seq after 01600 batchs: 325.743408203125
INFO:root:Train (Epoch 347): Loss/seq after 01650 batchs: 324.417236328125
INFO:root:Train (Epoch 347): Loss/seq after 01700 batchs: 325.42559814453125
INFO:root:Train (Epoch 347): Loss/seq after 01750 batchs: 324.8012390136719
INFO:root:Train (Epoch 347): Loss/seq after 01800 batchs: 323.6942443847656
INFO:root:Train (Epoch 347): Loss/seq after 01850 batchs: 322.5912780761719
INFO:root:Train (Epoch 347): Loss/seq after 01900 batchs: 322.4129943847656
INFO:root:Train (Epoch 347): Loss/seq after 01950 batchs: 322.67974853515625
INFO:root:Train (Epoch 347): Loss/seq after 02000 batchs: 324.87188720703125
INFO:root:Train (Epoch 347): Loss/seq after 02050 batchs: 325.36431884765625
INFO:root:Train (Epoch 347): Loss/seq after 02100 batchs: 325.35260009765625
INFO:root:Train (Epoch 347): Loss/seq after 02150 batchs: 325.5527038574219
INFO:root:Train (Epoch 347): Loss/seq after 02200 batchs: 325.00225830078125
INFO:root:Train (Epoch 347): Loss/seq after 02250 batchs: 324.21624755859375
INFO:root:Train (Epoch 347): Loss/seq after 02300 batchs: 322.1514587402344
INFO:root:Train (Epoch 347): Loss/seq after 02350 batchs: 320.25689697265625
INFO:root:Train (Epoch 347): Loss/seq after 02400 batchs: 320.2889099121094
INFO:root:Train (Epoch 347): Loss/seq after 02450 batchs: 317.9289245605469
INFO:root:Train (Epoch 347): Loss/seq after 02500 batchs: 312.7671813964844
INFO:root:Train (Epoch 347): Loss/seq after 02550 batchs: 308.46807861328125
INFO:root:Train (Epoch 347): Loss/seq after 02600 batchs: 304.95001220703125
INFO:root:Train (Epoch 347): Loss/seq after 02650 batchs: 301.9960021972656
INFO:root:Train (Epoch 347): Loss/seq after 02700 batchs: 299.9254455566406
INFO:root:Train (Epoch 347): Loss/seq after 02750 batchs: 296.8310852050781
INFO:root:Train (Epoch 347): Loss/seq after 02800 batchs: 295.3005676269531
INFO:root:Train (Epoch 347): Loss/seq after 02850 batchs: 295.0870361328125
INFO:root:Train (Epoch 347): Loss/seq after 02900 batchs: 295.2789306640625
INFO:root:Train (Epoch 347): Loss/seq after 02950 batchs: 296.4455871582031
INFO:root:Train (Epoch 347): Loss/seq after 03000 batchs: 299.2626647949219
INFO:root:Train (Epoch 347): Loss/seq after 03050 batchs: 300.84747314453125
INFO:root:Train (Epoch 347): Loss/seq after 03100 batchs: 302.1003723144531
INFO:root:Train (Epoch 347): Loss/seq after 03150 batchs: 301.7117614746094
INFO:root:Train (Epoch 347): Loss/seq after 03200 batchs: 301.49603271484375
INFO:root:Train (Epoch 347): Loss/seq after 03250 batchs: 301.0836486816406
INFO:root:Train (Epoch 347): Loss/seq after 03300 batchs: 300.5891418457031
INFO:root:Train (Epoch 347): Loss/seq after 03350 batchs: 299.13702392578125
INFO:root:Train (Epoch 347): Loss/seq after 03400 batchs: 297.5682067871094
INFO:root:Train (Epoch 347): Loss/seq after 03450 batchs: 296.7577819824219
INFO:root:Train (Epoch 347): Loss/seq after 03500 batchs: 297.64703369140625
INFO:root:Train (Epoch 347): Loss/seq after 03550 batchs: 296.6191101074219
INFO:root:Train (Epoch 347): Loss/seq after 03600 batchs: 298.9828186035156
INFO:root:Train (Epoch 347): Loss/seq after 03650 batchs: 297.913330078125
INFO:root:Train (Epoch 347): Loss/seq after 03700 batchs: 299.2916259765625
INFO:root:Train (Epoch 347): Loss/seq after 03750 batchs: 302.2373046875
INFO:root:Train (Epoch 347): Loss/seq after 03800 batchs: 302.3948974609375
INFO:root:Train (Epoch 347): Loss/seq after 03850 batchs: 302.0164794921875
INFO:root:Train (Epoch 347): Loss/seq after 03900 batchs: 302.87030029296875
INFO:root:Train (Epoch 347): Loss/seq after 03950 batchs: 304.4123229980469
INFO:root:Train (Epoch 347): Loss/seq after 04000 batchs: 302.97869873046875
INFO:root:Train (Epoch 347): Loss/seq after 04050 batchs: 301.45916748046875
INFO:root:Train (Epoch 347): Loss/seq after 04100 batchs: 300.56231689453125
INFO:root:Train (Epoch 347): Loss/seq after 04150 batchs: 300.6217346191406
INFO:root:Train (Epoch 347): Loss/seq after 04200 batchs: 300.2098693847656
INFO:root:Train (Epoch 347): Loss/seq after 04250 batchs: 299.5362548828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 347): Loss/seq after 00000 batches: 315.6876220703125
INFO:root:# Valid (Epoch 347): Loss/seq after 00050 batches: 656.1618041992188
INFO:root:# Valid (Epoch 347): Loss/seq after 00100 batches: 698.3810424804688
INFO:root:# Valid (Epoch 347): Loss/seq after 00150 batches: 521.8927001953125
INFO:root:# Valid (Epoch 347): Loss/seq after 00200 batches: 479.2729187011719
INFO:root:Artifacts: Make stick videos for epoch 347
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_347_on_20220424_005246.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_347_index_316_on_20220424_005246.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 348): Loss/seq after 00000 batchs: 584.9976196289062
INFO:root:Train (Epoch 348): Loss/seq after 00050 batchs: 417.7901916503906
INFO:root:Train (Epoch 348): Loss/seq after 00100 batchs: 424.47222900390625
INFO:root:Train (Epoch 348): Loss/seq after 00150 batchs: 398.8263244628906
INFO:root:Train (Epoch 348): Loss/seq after 00200 batchs: 448.8782043457031
INFO:root:Train (Epoch 348): Loss/seq after 00250 batchs: 460.0099792480469
INFO:root:Train (Epoch 348): Loss/seq after 00300 batchs: 475.3215637207031
INFO:root:Train (Epoch 348): Loss/seq after 00350 batchs: 453.410888671875
INFO:root:Train (Epoch 348): Loss/seq after 00400 batchs: 445.37847900390625
INFO:root:Train (Epoch 348): Loss/seq after 00450 batchs: 459.61187744140625
INFO:root:Train (Epoch 348): Loss/seq after 00500 batchs: 445.6194152832031
INFO:root:Train (Epoch 348): Loss/seq after 00550 batchs: 439.9874572753906
INFO:root:Train (Epoch 348): Loss/seq after 00600 batchs: 424.3979797363281
INFO:root:Train (Epoch 348): Loss/seq after 00650 batchs: 407.46746826171875
INFO:root:Train (Epoch 348): Loss/seq after 00700 batchs: 390.4788818359375
INFO:root:Train (Epoch 348): Loss/seq after 00750 batchs: 384.3958435058594
INFO:root:Train (Epoch 348): Loss/seq after 00800 batchs: 385.3214111328125
INFO:root:Train (Epoch 348): Loss/seq after 00850 batchs: 373.414306640625
INFO:root:Train (Epoch 348): Loss/seq after 00900 batchs: 364.0740661621094
INFO:root:Train (Epoch 348): Loss/seq after 00950 batchs: 364.9366455078125
INFO:root:Train (Epoch 348): Loss/seq after 01000 batchs: 358.48175048828125
INFO:root:Train (Epoch 348): Loss/seq after 01050 batchs: 351.597900390625
INFO:root:Train (Epoch 348): Loss/seq after 01100 batchs: 343.1671447753906
INFO:root:Train (Epoch 348): Loss/seq after 01150 batchs: 334.0907287597656
INFO:root:Train (Epoch 348): Loss/seq after 01200 batchs: 332.8160095214844
INFO:root:Train (Epoch 348): Loss/seq after 01250 batchs: 331.8338623046875
INFO:root:Train (Epoch 348): Loss/seq after 01300 batchs: 324.7098083496094
INFO:root:Train (Epoch 348): Loss/seq after 01350 batchs: 317.8017883300781
INFO:root:Train (Epoch 348): Loss/seq after 01400 batchs: 319.58154296875
INFO:root:Train (Epoch 348): Loss/seq after 01450 batchs: 322.010498046875
INFO:root:Train (Epoch 348): Loss/seq after 01500 batchs: 327.677978515625
INFO:root:Train (Epoch 348): Loss/seq after 01550 batchs: 328.776123046875
INFO:root:Train (Epoch 348): Loss/seq after 01600 batchs: 327.7780456542969
INFO:root:Train (Epoch 348): Loss/seq after 01650 batchs: 326.2922668457031
INFO:root:Train (Epoch 348): Loss/seq after 01700 batchs: 327.4562072753906
INFO:root:Train (Epoch 348): Loss/seq after 01750 batchs: 326.7946472167969
INFO:root:Train (Epoch 348): Loss/seq after 01800 batchs: 325.80059814453125
INFO:root:Train (Epoch 348): Loss/seq after 01850 batchs: 324.6811218261719
INFO:root:Train (Epoch 348): Loss/seq after 01900 batchs: 324.3699645996094
INFO:root:Train (Epoch 348): Loss/seq after 01950 batchs: 324.8443908691406
INFO:root:Train (Epoch 348): Loss/seq after 02000 batchs: 326.90704345703125
INFO:root:Train (Epoch 348): Loss/seq after 02050 batchs: 327.5259704589844
INFO:root:Train (Epoch 348): Loss/seq after 02100 batchs: 327.35174560546875
INFO:root:Train (Epoch 348): Loss/seq after 02150 batchs: 327.3656311035156
INFO:root:Train (Epoch 348): Loss/seq after 02200 batchs: 326.8351745605469
INFO:root:Train (Epoch 348): Loss/seq after 02250 batchs: 326.166259765625
INFO:root:Train (Epoch 348): Loss/seq after 02300 batchs: 324.0475158691406
INFO:root:Train (Epoch 348): Loss/seq after 02350 batchs: 322.0827941894531
INFO:root:Train (Epoch 348): Loss/seq after 02400 batchs: 321.94268798828125
INFO:root:Train (Epoch 348): Loss/seq after 02450 batchs: 319.4593200683594
INFO:root:Train (Epoch 348): Loss/seq after 02500 batchs: 314.22406005859375
INFO:root:Train (Epoch 348): Loss/seq after 02550 batchs: 309.8468933105469
INFO:root:Train (Epoch 348): Loss/seq after 02600 batchs: 306.4063415527344
INFO:root:Train (Epoch 348): Loss/seq after 02650 batchs: 303.26605224609375
INFO:root:Train (Epoch 348): Loss/seq after 02700 batchs: 301.2198791503906
INFO:root:Train (Epoch 348): Loss/seq after 02750 batchs: 297.98492431640625
INFO:root:Train (Epoch 348): Loss/seq after 02800 batchs: 296.93084716796875
INFO:root:Train (Epoch 348): Loss/seq after 02850 batchs: 296.6592102050781
INFO:root:Train (Epoch 348): Loss/seq after 02900 batchs: 296.76324462890625
INFO:root:Train (Epoch 348): Loss/seq after 02950 batchs: 297.8398742675781
INFO:root:Train (Epoch 348): Loss/seq after 03000 batchs: 300.57275390625
INFO:root:Train (Epoch 348): Loss/seq after 03050 batchs: 301.836669921875
INFO:root:Train (Epoch 348): Loss/seq after 03100 batchs: 303.3103942871094
INFO:root:Train (Epoch 348): Loss/seq after 03150 batchs: 304.22967529296875
INFO:root:Train (Epoch 348): Loss/seq after 03200 batchs: 303.9129943847656
INFO:root:Train (Epoch 348): Loss/seq after 03250 batchs: 303.6218566894531
INFO:root:Train (Epoch 348): Loss/seq after 03300 batchs: 303.72174072265625
INFO:root:Train (Epoch 348): Loss/seq after 03350 batchs: 302.6770935058594
INFO:root:Train (Epoch 348): Loss/seq after 03400 batchs: 300.91839599609375
INFO:root:Train (Epoch 348): Loss/seq after 03450 batchs: 300.1731262207031
INFO:root:Train (Epoch 348): Loss/seq after 03500 batchs: 301.2176513671875
INFO:root:Train (Epoch 348): Loss/seq after 03550 batchs: 300.19598388671875
INFO:root:Train (Epoch 348): Loss/seq after 03600 batchs: 302.6956787109375
INFO:root:Train (Epoch 348): Loss/seq after 03650 batchs: 301.9687805175781
INFO:root:Train (Epoch 348): Loss/seq after 03700 batchs: 303.5416564941406
INFO:root:Train (Epoch 348): Loss/seq after 03750 batchs: 306.67474365234375
INFO:root:Train (Epoch 348): Loss/seq after 03800 batchs: 306.7756042480469
INFO:root:Train (Epoch 348): Loss/seq after 03850 batchs: 306.4886169433594
INFO:root:Train (Epoch 348): Loss/seq after 03900 batchs: 307.4532165527344
INFO:root:Train (Epoch 348): Loss/seq after 03950 batchs: 309.1904296875
INFO:root:Train (Epoch 348): Loss/seq after 04000 batchs: 307.7226257324219
INFO:root:Train (Epoch 348): Loss/seq after 04050 batchs: 306.18402099609375
INFO:root:Train (Epoch 348): Loss/seq after 04100 batchs: 305.2790222167969
INFO:root:Train (Epoch 348): Loss/seq after 04150 batchs: 305.36431884765625
INFO:root:Train (Epoch 348): Loss/seq after 04200 batchs: 304.904296875
INFO:root:Train (Epoch 348): Loss/seq after 04250 batchs: 304.256103515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 348): Loss/seq after 00000 batches: 299.9120178222656
INFO:root:# Valid (Epoch 348): Loss/seq after 00050 batches: 683.7618408203125
INFO:root:# Valid (Epoch 348): Loss/seq after 00100 batches: 695.8751220703125
INFO:root:# Valid (Epoch 348): Loss/seq after 00150 batches: 515.9974975585938
INFO:root:# Valid (Epoch 348): Loss/seq after 00200 batches: 470.73468017578125
INFO:root:Artifacts: Make stick videos for epoch 348
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_348_on_20220424_005755.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_348_index_673_on_20220424_005755.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 349): Loss/seq after 00000 batchs: 580.0523681640625
INFO:root:Train (Epoch 349): Loss/seq after 00050 batchs: 428.3215637207031
INFO:root:Train (Epoch 349): Loss/seq after 00100 batchs: 446.3590087890625
INFO:root:Train (Epoch 349): Loss/seq after 00150 batchs: 410.8513488769531
INFO:root:Train (Epoch 349): Loss/seq after 00200 batchs: 471.1263427734375
INFO:root:Train (Epoch 349): Loss/seq after 00250 batchs: 497.6216125488281
INFO:root:Train (Epoch 349): Loss/seq after 00300 batchs: 508.10968017578125
INFO:root:Train (Epoch 349): Loss/seq after 00350 batchs: 483.12945556640625
INFO:root:Train (Epoch 349): Loss/seq after 00400 batchs: 472.7370910644531
INFO:root:Train (Epoch 349): Loss/seq after 00450 batchs: 484.94140625
INFO:root:Train (Epoch 349): Loss/seq after 00500 batchs: 471.1835021972656
INFO:root:Train (Epoch 349): Loss/seq after 00550 batchs: 461.8558654785156
INFO:root:Train (Epoch 349): Loss/seq after 00600 batchs: 444.9793395996094
INFO:root:Train (Epoch 349): Loss/seq after 00650 batchs: 426.84686279296875
INFO:root:Train (Epoch 349): Loss/seq after 00700 batchs: 408.9277038574219
INFO:root:Train (Epoch 349): Loss/seq after 00750 batchs: 402.2099914550781
INFO:root:Train (Epoch 349): Loss/seq after 00800 batchs: 402.01983642578125
INFO:root:Train (Epoch 349): Loss/seq after 00850 batchs: 389.02008056640625
INFO:root:Train (Epoch 349): Loss/seq after 00900 batchs: 378.63623046875
INFO:root:Train (Epoch 349): Loss/seq after 00950 batchs: 377.16986083984375
INFO:root:Train (Epoch 349): Loss/seq after 01000 batchs: 370.27008056640625
INFO:root:Train (Epoch 349): Loss/seq after 01050 batchs: 362.66339111328125
INFO:root:Train (Epoch 349): Loss/seq after 01100 batchs: 354.0057373046875
INFO:root:Train (Epoch 349): Loss/seq after 01150 batchs: 344.4140930175781
INFO:root:Train (Epoch 349): Loss/seq after 01200 batchs: 343.5198059082031
INFO:root:Train (Epoch 349): Loss/seq after 01250 batchs: 342.47357177734375
INFO:root:Train (Epoch 349): Loss/seq after 01300 batchs: 334.92669677734375
INFO:root:Train (Epoch 349): Loss/seq after 01350 batchs: 327.3177490234375
INFO:root:Train (Epoch 349): Loss/seq after 01400 batchs: 327.65966796875
INFO:root:Train (Epoch 349): Loss/seq after 01450 batchs: 329.6239013671875
INFO:root:Train (Epoch 349): Loss/seq after 01500 batchs: 334.5185241699219
INFO:root:Train (Epoch 349): Loss/seq after 01550 batchs: 334.5110778808594
INFO:root:Train (Epoch 349): Loss/seq after 01600 batchs: 333.0873718261719
INFO:root:Train (Epoch 349): Loss/seq after 01650 batchs: 331.3835144042969
INFO:root:Train (Epoch 349): Loss/seq after 01700 batchs: 332.2712707519531
INFO:root:Train (Epoch 349): Loss/seq after 01750 batchs: 331.255126953125
INFO:root:Train (Epoch 349): Loss/seq after 01800 batchs: 329.9706115722656
INFO:root:Train (Epoch 349): Loss/seq after 01850 batchs: 328.7522888183594
INFO:root:Train (Epoch 349): Loss/seq after 01900 batchs: 328.0201110839844
INFO:root:Train (Epoch 349): Loss/seq after 01950 batchs: 328.1923828125
INFO:root:Train (Epoch 349): Loss/seq after 02000 batchs: 330.2638244628906
INFO:root:Train (Epoch 349): Loss/seq after 02050 batchs: 330.70947265625
INFO:root:Train (Epoch 349): Loss/seq after 02100 batchs: 330.55908203125
INFO:root:Train (Epoch 349): Loss/seq after 02150 batchs: 330.69158935546875
INFO:root:Train (Epoch 349): Loss/seq after 02200 batchs: 330.1884460449219
INFO:root:Train (Epoch 349): Loss/seq after 02250 batchs: 329.4974060058594
INFO:root:Train (Epoch 349): Loss/seq after 02300 batchs: 327.1031188964844
INFO:root:Train (Epoch 349): Loss/seq after 02350 batchs: 325.2613525390625
INFO:root:Train (Epoch 349): Loss/seq after 02400 batchs: 325.2101745605469
INFO:root:Train (Epoch 349): Loss/seq after 02450 batchs: 322.6783142089844
INFO:root:Train (Epoch 349): Loss/seq after 02500 batchs: 317.4573974609375
INFO:root:Train (Epoch 349): Loss/seq after 02550 batchs: 313.0294494628906
INFO:root:Train (Epoch 349): Loss/seq after 02600 batchs: 309.46270751953125
INFO:root:Train (Epoch 349): Loss/seq after 02650 batchs: 306.2531433105469
INFO:root:Train (Epoch 349): Loss/seq after 02700 batchs: 304.1106872558594
INFO:root:Train (Epoch 349): Loss/seq after 02750 batchs: 300.5721435546875
INFO:root:Train (Epoch 349): Loss/seq after 02800 batchs: 298.6568298339844
INFO:root:Train (Epoch 349): Loss/seq after 02850 batchs: 298.5056457519531
INFO:root:Train (Epoch 349): Loss/seq after 02900 batchs: 298.8058776855469
INFO:root:Train (Epoch 349): Loss/seq after 02950 batchs: 299.900146484375
INFO:root:Train (Epoch 349): Loss/seq after 03000 batchs: 302.8781433105469
INFO:root:Train (Epoch 349): Loss/seq after 03050 batchs: 304.83636474609375
INFO:root:Train (Epoch 349): Loss/seq after 03100 batchs: 306.4930725097656
INFO:root:Train (Epoch 349): Loss/seq after 03150 batchs: 307.0351867675781
INFO:root:Train (Epoch 349): Loss/seq after 03200 batchs: 307.3582458496094
INFO:root:Train (Epoch 349): Loss/seq after 03250 batchs: 306.9975891113281
INFO:root:Train (Epoch 349): Loss/seq after 03300 batchs: 306.97491455078125
INFO:root:Train (Epoch 349): Loss/seq after 03350 batchs: 305.7161560058594
INFO:root:Train (Epoch 349): Loss/seq after 03400 batchs: 304.09283447265625
INFO:root:Train (Epoch 349): Loss/seq after 03450 batchs: 303.24481201171875
INFO:root:Train (Epoch 349): Loss/seq after 03500 batchs: 304.92962646484375
INFO:root:Train (Epoch 349): Loss/seq after 03550 batchs: 304.0285949707031
INFO:root:Train (Epoch 349): Loss/seq after 03600 batchs: 306.8223571777344
INFO:root:Train (Epoch 349): Loss/seq after 03650 batchs: 306.0170593261719
INFO:root:Train (Epoch 349): Loss/seq after 03700 batchs: 308.1871337890625
INFO:root:Train (Epoch 349): Loss/seq after 03750 batchs: 311.3031311035156
INFO:root:Train (Epoch 349): Loss/seq after 03800 batchs: 311.2854309082031
INFO:root:Train (Epoch 349): Loss/seq after 03850 batchs: 311.21240234375
INFO:root:Train (Epoch 349): Loss/seq after 03900 batchs: 312.6205749511719
INFO:root:Train (Epoch 349): Loss/seq after 03950 batchs: 314.554443359375
INFO:root:Train (Epoch 349): Loss/seq after 04000 batchs: 313.0134582519531
INFO:root:Train (Epoch 349): Loss/seq after 04050 batchs: 311.4338684082031
INFO:root:Train (Epoch 349): Loss/seq after 04100 batchs: 310.50775146484375
INFO:root:Train (Epoch 349): Loss/seq after 04150 batchs: 310.4992370605469
INFO:root:Train (Epoch 349): Loss/seq after 04200 batchs: 310.0484313964844
INFO:root:Train (Epoch 349): Loss/seq after 04250 batchs: 309.228271484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 349): Loss/seq after 00000 batches: 263.500732421875
INFO:root:# Valid (Epoch 349): Loss/seq after 00050 batches: 642.4966430664062
INFO:root:# Valid (Epoch 349): Loss/seq after 00100 batches: 616.5652465820312
INFO:root:# Valid (Epoch 349): Loss/seq after 00150 batches: 465.4144287109375
INFO:root:# Valid (Epoch 349): Loss/seq after 00200 batches: 440.9456481933594
INFO:root:Artifacts: Make stick videos for epoch 349
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_349_on_20220424_010259.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_349_index_1131_on_20220424_010259.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 350): Loss/seq after 00000 batchs: 548.4379272460938
INFO:root:Train (Epoch 350): Loss/seq after 00050 batchs: 428.1726989746094
INFO:root:Train (Epoch 350): Loss/seq after 00100 batchs: 440.38543701171875
INFO:root:Train (Epoch 350): Loss/seq after 00150 batchs: 407.2198791503906
INFO:root:Train (Epoch 350): Loss/seq after 00200 batchs: 451.8755187988281
INFO:root:Train (Epoch 350): Loss/seq after 00250 batchs: 476.01025390625
INFO:root:Train (Epoch 350): Loss/seq after 00300 batchs: 497.984619140625
INFO:root:Train (Epoch 350): Loss/seq after 00350 batchs: 475.7738037109375
INFO:root:Train (Epoch 350): Loss/seq after 00400 batchs: 467.69915771484375
INFO:root:Train (Epoch 350): Loss/seq after 00450 batchs: 479.2805480957031
INFO:root:Train (Epoch 350): Loss/seq after 00500 batchs: 464.9764709472656
INFO:root:Train (Epoch 350): Loss/seq after 00550 batchs: 456.76611328125
INFO:root:Train (Epoch 350): Loss/seq after 00600 batchs: 443.03961181640625
INFO:root:Train (Epoch 350): Loss/seq after 00650 batchs: 424.8470764160156
INFO:root:Train (Epoch 350): Loss/seq after 00700 batchs: 406.5472106933594
INFO:root:Train (Epoch 350): Loss/seq after 00750 batchs: 399.2254638671875
INFO:root:Train (Epoch 350): Loss/seq after 00800 batchs: 399.5333557128906
INFO:root:Train (Epoch 350): Loss/seq after 00850 batchs: 387.3688659667969
INFO:root:Train (Epoch 350): Loss/seq after 00900 batchs: 377.42626953125
INFO:root:Train (Epoch 350): Loss/seq after 00950 batchs: 377.98992919921875
INFO:root:Train (Epoch 350): Loss/seq after 01000 batchs: 371.4936828613281
INFO:root:Train (Epoch 350): Loss/seq after 01050 batchs: 365.94476318359375
INFO:root:Train (Epoch 350): Loss/seq after 01100 batchs: 358.24627685546875
INFO:root:Train (Epoch 350): Loss/seq after 01150 batchs: 348.33782958984375
INFO:root:Train (Epoch 350): Loss/seq after 01200 batchs: 348.4969787597656
INFO:root:Train (Epoch 350): Loss/seq after 01250 batchs: 347.5426940917969
INFO:root:Train (Epoch 350): Loss/seq after 01300 batchs: 340.0170593261719
INFO:root:Train (Epoch 350): Loss/seq after 01350 batchs: 332.5073547363281
INFO:root:Train (Epoch 350): Loss/seq after 01400 batchs: 332.05889892578125
INFO:root:Train (Epoch 350): Loss/seq after 01450 batchs: 334.1552734375
INFO:root:Train (Epoch 350): Loss/seq after 01500 batchs: 339.85113525390625
INFO:root:Train (Epoch 350): Loss/seq after 01550 batchs: 340.5451354980469
INFO:root:Train (Epoch 350): Loss/seq after 01600 batchs: 339.2372131347656
INFO:root:Train (Epoch 350): Loss/seq after 01650 batchs: 337.6465148925781
INFO:root:Train (Epoch 350): Loss/seq after 01700 batchs: 338.9706726074219
INFO:root:Train (Epoch 350): Loss/seq after 01750 batchs: 338.0171813964844
INFO:root:Train (Epoch 350): Loss/seq after 01800 batchs: 336.833251953125
INFO:root:Train (Epoch 350): Loss/seq after 01850 batchs: 335.4219055175781
INFO:root:Train (Epoch 350): Loss/seq after 01900 batchs: 335.0381164550781
INFO:root:Train (Epoch 350): Loss/seq after 01950 batchs: 335.1841735839844
INFO:root:Train (Epoch 350): Loss/seq after 02000 batchs: 336.8594665527344
INFO:root:Train (Epoch 350): Loss/seq after 02050 batchs: 337.20947265625
INFO:root:Train (Epoch 350): Loss/seq after 02100 batchs: 336.9684143066406
INFO:root:Train (Epoch 350): Loss/seq after 02150 batchs: 336.7906799316406
INFO:root:Train (Epoch 350): Loss/seq after 02200 batchs: 336.11724853515625
INFO:root:Train (Epoch 350): Loss/seq after 02250 batchs: 335.3471984863281
INFO:root:Train (Epoch 350): Loss/seq after 02300 batchs: 332.7498779296875
INFO:root:Train (Epoch 350): Loss/seq after 02350 batchs: 330.6536865234375
INFO:root:Train (Epoch 350): Loss/seq after 02400 batchs: 330.31982421875
INFO:root:Train (Epoch 350): Loss/seq after 02450 batchs: 327.7242431640625
INFO:root:Train (Epoch 350): Loss/seq after 02500 batchs: 322.3477478027344
INFO:root:Train (Epoch 350): Loss/seq after 02550 batchs: 317.8358154296875
INFO:root:Train (Epoch 350): Loss/seq after 02600 batchs: 314.4502868652344
INFO:root:Train (Epoch 350): Loss/seq after 02650 batchs: 311.01727294921875
INFO:root:Train (Epoch 350): Loss/seq after 02700 batchs: 309.0086975097656
INFO:root:Train (Epoch 350): Loss/seq after 02750 batchs: 305.9244079589844
INFO:root:Train (Epoch 350): Loss/seq after 02800 batchs: 304.02789306640625
INFO:root:Train (Epoch 350): Loss/seq after 02850 batchs: 303.5159912109375
INFO:root:Train (Epoch 350): Loss/seq after 02900 batchs: 303.4917297363281
INFO:root:Train (Epoch 350): Loss/seq after 02950 batchs: 304.3182373046875
INFO:root:Train (Epoch 350): Loss/seq after 03000 batchs: 306.99127197265625
INFO:root:Train (Epoch 350): Loss/seq after 03050 batchs: 308.22674560546875
INFO:root:Train (Epoch 350): Loss/seq after 03100 batchs: 310.853515625
INFO:root:Train (Epoch 350): Loss/seq after 03150 batchs: 310.43011474609375
INFO:root:Train (Epoch 350): Loss/seq after 03200 batchs: 310.4371337890625
INFO:root:Train (Epoch 350): Loss/seq after 03250 batchs: 310.0582580566406
INFO:root:Train (Epoch 350): Loss/seq after 03300 batchs: 309.7796325683594
INFO:root:Train (Epoch 350): Loss/seq after 03350 batchs: 308.14324951171875
INFO:root:Train (Epoch 350): Loss/seq after 03400 batchs: 306.4749450683594
INFO:root:Train (Epoch 350): Loss/seq after 03450 batchs: 305.5901794433594
INFO:root:Train (Epoch 350): Loss/seq after 03500 batchs: 306.4519348144531
INFO:root:Train (Epoch 350): Loss/seq after 03550 batchs: 305.3779602050781
INFO:root:Train (Epoch 350): Loss/seq after 03600 batchs: 307.5223083496094
INFO:root:Train (Epoch 350): Loss/seq after 03650 batchs: 306.2855529785156
INFO:root:Train (Epoch 350): Loss/seq after 03700 batchs: 307.666259765625
INFO:root:Train (Epoch 350): Loss/seq after 03750 batchs: 310.71923828125
INFO:root:Train (Epoch 350): Loss/seq after 03800 batchs: 310.7521667480469
INFO:root:Train (Epoch 350): Loss/seq after 03850 batchs: 310.29302978515625
INFO:root:Train (Epoch 350): Loss/seq after 03900 batchs: 311.52734375
INFO:root:Train (Epoch 350): Loss/seq after 03950 batchs: 313.6329345703125
INFO:root:Train (Epoch 350): Loss/seq after 04000 batchs: 312.08428955078125
INFO:root:Train (Epoch 350): Loss/seq after 04050 batchs: 310.42138671875
INFO:root:Train (Epoch 350): Loss/seq after 04100 batchs: 309.5086364746094
INFO:root:Train (Epoch 350): Loss/seq after 04150 batchs: 309.4480285644531
INFO:root:Train (Epoch 350): Loss/seq after 04200 batchs: 309.0048522949219
INFO:root:Train (Epoch 350): Loss/seq after 04250 batchs: 308.1873779296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 350): Loss/seq after 00000 batches: 296.4211120605469
INFO:root:# Valid (Epoch 350): Loss/seq after 00050 batches: 673.0028076171875
INFO:root:# Valid (Epoch 350): Loss/seq after 00100 batches: 747.3541259765625
INFO:root:# Valid (Epoch 350): Loss/seq after 00150 batches: 548.5189208984375
INFO:root:# Valid (Epoch 350): Loss/seq after 00200 batches: 497.1885070800781
INFO:root:Artifacts: Make stick videos for epoch 350
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_350_on_20220424_010749.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_350_index_264_on_20220424_010749.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 351): Loss/seq after 00000 batchs: 477.1991882324219
INFO:root:Train (Epoch 351): Loss/seq after 00050 batchs: 408.4286804199219
INFO:root:Train (Epoch 351): Loss/seq after 00100 batchs: 415.9615478515625
INFO:root:Train (Epoch 351): Loss/seq after 00150 batchs: 391.5805969238281
INFO:root:Train (Epoch 351): Loss/seq after 00200 batchs: 443.67333984375
INFO:root:Train (Epoch 351): Loss/seq after 00250 batchs: 461.9653015136719
INFO:root:Train (Epoch 351): Loss/seq after 00300 batchs: 477.7626953125
INFO:root:Train (Epoch 351): Loss/seq after 00350 batchs: 456.8843994140625
INFO:root:Train (Epoch 351): Loss/seq after 00400 batchs: 451.8619079589844
INFO:root:Train (Epoch 351): Loss/seq after 00450 batchs: 465.7937927246094
INFO:root:Train (Epoch 351): Loss/seq after 00500 batchs: 452.5711975097656
INFO:root:Train (Epoch 351): Loss/seq after 00550 batchs: 445.0093688964844
INFO:root:Train (Epoch 351): Loss/seq after 00600 batchs: 429.37841796875
INFO:root:Train (Epoch 351): Loss/seq after 00650 batchs: 410.87994384765625
INFO:root:Train (Epoch 351): Loss/seq after 00700 batchs: 393.7195739746094
INFO:root:Train (Epoch 351): Loss/seq after 00750 batchs: 387.75103759765625
INFO:root:Train (Epoch 351): Loss/seq after 00800 batchs: 388.4267272949219
INFO:root:Train (Epoch 351): Loss/seq after 00850 batchs: 376.1147766113281
INFO:root:Train (Epoch 351): Loss/seq after 00900 batchs: 366.7931213378906
INFO:root:Train (Epoch 351): Loss/seq after 00950 batchs: 366.1029968261719
INFO:root:Train (Epoch 351): Loss/seq after 01000 batchs: 360.02154541015625
INFO:root:Train (Epoch 351): Loss/seq after 01050 batchs: 352.74981689453125
INFO:root:Train (Epoch 351): Loss/seq after 01100 batchs: 344.4981689453125
INFO:root:Train (Epoch 351): Loss/seq after 01150 batchs: 335.1923522949219
INFO:root:Train (Epoch 351): Loss/seq after 01200 batchs: 334.0135498046875
INFO:root:Train (Epoch 351): Loss/seq after 01250 batchs: 333.55926513671875
INFO:root:Train (Epoch 351): Loss/seq after 01300 batchs: 326.3385925292969
INFO:root:Train (Epoch 351): Loss/seq after 01350 batchs: 320.1402587890625
INFO:root:Train (Epoch 351): Loss/seq after 01400 batchs: 321.6690979003906
INFO:root:Train (Epoch 351): Loss/seq after 01450 batchs: 323.5966491699219
INFO:root:Train (Epoch 351): Loss/seq after 01500 batchs: 328.9657897949219
INFO:root:Train (Epoch 351): Loss/seq after 01550 batchs: 329.45159912109375
INFO:root:Train (Epoch 351): Loss/seq after 01600 batchs: 327.8387756347656
INFO:root:Train (Epoch 351): Loss/seq after 01650 batchs: 326.50555419921875
INFO:root:Train (Epoch 351): Loss/seq after 01700 batchs: 328.2165832519531
INFO:root:Train (Epoch 351): Loss/seq after 01750 batchs: 327.203857421875
INFO:root:Train (Epoch 351): Loss/seq after 01800 batchs: 326.1265869140625
INFO:root:Train (Epoch 351): Loss/seq after 01850 batchs: 324.9327087402344
INFO:root:Train (Epoch 351): Loss/seq after 01900 batchs: 324.36090087890625
INFO:root:Train (Epoch 351): Loss/seq after 01950 batchs: 324.549072265625
INFO:root:Train (Epoch 351): Loss/seq after 02000 batchs: 326.73248291015625
INFO:root:Train (Epoch 351): Loss/seq after 02050 batchs: 327.1542663574219
INFO:root:Train (Epoch 351): Loss/seq after 02100 batchs: 327.11077880859375
INFO:root:Train (Epoch 351): Loss/seq after 02150 batchs: 327.18011474609375
INFO:root:Train (Epoch 351): Loss/seq after 02200 batchs: 326.6062316894531
INFO:root:Train (Epoch 351): Loss/seq after 02250 batchs: 326.0457763671875
INFO:root:Train (Epoch 351): Loss/seq after 02300 batchs: 324.1120300292969
INFO:root:Train (Epoch 351): Loss/seq after 02350 batchs: 322.1752624511719
INFO:root:Train (Epoch 351): Loss/seq after 02400 batchs: 322.0650939941406
INFO:root:Train (Epoch 351): Loss/seq after 02450 batchs: 319.6601257324219
INFO:root:Train (Epoch 351): Loss/seq after 02500 batchs: 314.4169006347656
INFO:root:Train (Epoch 351): Loss/seq after 02550 batchs: 310.0020751953125
INFO:root:Train (Epoch 351): Loss/seq after 02600 batchs: 306.46630859375
INFO:root:Train (Epoch 351): Loss/seq after 02650 batchs: 303.24774169921875
INFO:root:Train (Epoch 351): Loss/seq after 02700 batchs: 301.095947265625
INFO:root:Train (Epoch 351): Loss/seq after 02750 batchs: 297.7834167480469
INFO:root:Train (Epoch 351): Loss/seq after 02800 batchs: 296.25933837890625
INFO:root:Train (Epoch 351): Loss/seq after 02850 batchs: 295.9102478027344
INFO:root:Train (Epoch 351): Loss/seq after 02900 batchs: 295.97637939453125
INFO:root:Train (Epoch 351): Loss/seq after 02950 batchs: 296.8669738769531
INFO:root:Train (Epoch 351): Loss/seq after 03000 batchs: 299.5194091796875
INFO:root:Train (Epoch 351): Loss/seq after 03050 batchs: 301.2884216308594
INFO:root:Train (Epoch 351): Loss/seq after 03100 batchs: 302.86871337890625
INFO:root:Train (Epoch 351): Loss/seq after 03150 batchs: 302.562255859375
INFO:root:Train (Epoch 351): Loss/seq after 03200 batchs: 303.02947998046875
INFO:root:Train (Epoch 351): Loss/seq after 03250 batchs: 302.8055419921875
INFO:root:Train (Epoch 351): Loss/seq after 03300 batchs: 302.8625793457031
INFO:root:Train (Epoch 351): Loss/seq after 03350 batchs: 301.2569580078125
INFO:root:Train (Epoch 351): Loss/seq after 03400 batchs: 299.64776611328125
INFO:root:Train (Epoch 351): Loss/seq after 03450 batchs: 298.8421630859375
INFO:root:Train (Epoch 351): Loss/seq after 03500 batchs: 299.8788757324219
INFO:root:Train (Epoch 351): Loss/seq after 03550 batchs: 298.790283203125
INFO:root:Train (Epoch 351): Loss/seq after 03600 batchs: 301.0538024902344
INFO:root:Train (Epoch 351): Loss/seq after 03650 batchs: 300.0132141113281
INFO:root:Train (Epoch 351): Loss/seq after 03700 batchs: 301.542236328125
INFO:root:Train (Epoch 351): Loss/seq after 03750 batchs: 304.42340087890625
INFO:root:Train (Epoch 351): Loss/seq after 03800 batchs: 304.60089111328125
INFO:root:Train (Epoch 351): Loss/seq after 03850 batchs: 304.2249755859375
INFO:root:Train (Epoch 351): Loss/seq after 03900 batchs: 305.2410888671875
INFO:root:Train (Epoch 351): Loss/seq after 03950 batchs: 307.0462646484375
INFO:root:Train (Epoch 351): Loss/seq after 04000 batchs: 305.5807189941406
INFO:root:Train (Epoch 351): Loss/seq after 04050 batchs: 304.02606201171875
INFO:root:Train (Epoch 351): Loss/seq after 04100 batchs: 303.1498107910156
INFO:root:Train (Epoch 351): Loss/seq after 04150 batchs: 303.01995849609375
INFO:root:Train (Epoch 351): Loss/seq after 04200 batchs: 302.63299560546875
INFO:root:Train (Epoch 351): Loss/seq after 04250 batchs: 301.8292236328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 351): Loss/seq after 00000 batches: 254.3185272216797
INFO:root:# Valid (Epoch 351): Loss/seq after 00050 batches: 665.4325561523438
INFO:root:# Valid (Epoch 351): Loss/seq after 00100 batches: 668.1117553710938
INFO:root:# Valid (Epoch 351): Loss/seq after 00150 batches: 497.32781982421875
INFO:root:# Valid (Epoch 351): Loss/seq after 00200 batches: 456.4212341308594
INFO:root:Artifacts: Make stick videos for epoch 351
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_351_on_20220424_011258.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_351_index_948_on_20220424_011258.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 352): Loss/seq after 00000 batchs: 355.01800537109375
INFO:root:Train (Epoch 352): Loss/seq after 00050 batchs: 396.3312072753906
INFO:root:Train (Epoch 352): Loss/seq after 00100 batchs: 404.27813720703125
INFO:root:Train (Epoch 352): Loss/seq after 00150 batchs: 383.2857360839844
INFO:root:Train (Epoch 352): Loss/seq after 00200 batchs: 438.523193359375
INFO:root:Train (Epoch 352): Loss/seq after 00250 batchs: 449.85418701171875
INFO:root:Train (Epoch 352): Loss/seq after 00300 batchs: 468.3448791503906
INFO:root:Train (Epoch 352): Loss/seq after 00350 batchs: 448.2555236816406
INFO:root:Train (Epoch 352): Loss/seq after 00400 batchs: 438.551513671875
INFO:root:Train (Epoch 352): Loss/seq after 00450 batchs: 453.4161682128906
INFO:root:Train (Epoch 352): Loss/seq after 00500 batchs: 438.47869873046875
INFO:root:Train (Epoch 352): Loss/seq after 00550 batchs: 432.04473876953125
INFO:root:Train (Epoch 352): Loss/seq after 00600 batchs: 417.2139587402344
INFO:root:Train (Epoch 352): Loss/seq after 00650 batchs: 402.23162841796875
INFO:root:Train (Epoch 352): Loss/seq after 00700 batchs: 385.39013671875
INFO:root:Train (Epoch 352): Loss/seq after 00750 batchs: 380.6663513183594
INFO:root:Train (Epoch 352): Loss/seq after 00800 batchs: 380.9430236816406
INFO:root:Train (Epoch 352): Loss/seq after 00850 batchs: 368.6429443359375
INFO:root:Train (Epoch 352): Loss/seq after 00900 batchs: 358.7471618652344
INFO:root:Train (Epoch 352): Loss/seq after 00950 batchs: 357.7586669921875
INFO:root:Train (Epoch 352): Loss/seq after 01000 batchs: 352.6687316894531
INFO:root:Train (Epoch 352): Loss/seq after 01050 batchs: 345.5452880859375
INFO:root:Train (Epoch 352): Loss/seq after 01100 batchs: 338.2396240234375
INFO:root:Train (Epoch 352): Loss/seq after 01150 batchs: 329.391845703125
INFO:root:Train (Epoch 352): Loss/seq after 01200 batchs: 328.6559753417969
INFO:root:Train (Epoch 352): Loss/seq after 01250 batchs: 327.68756103515625
INFO:root:Train (Epoch 352): Loss/seq after 01300 batchs: 321.21551513671875
INFO:root:Train (Epoch 352): Loss/seq after 01350 batchs: 314.6003112792969
INFO:root:Train (Epoch 352): Loss/seq after 01400 batchs: 315.2297058105469
INFO:root:Train (Epoch 352): Loss/seq after 01450 batchs: 317.1467590332031
INFO:root:Train (Epoch 352): Loss/seq after 01500 batchs: 322.3373107910156
INFO:root:Train (Epoch 352): Loss/seq after 01550 batchs: 322.9112548828125
INFO:root:Train (Epoch 352): Loss/seq after 01600 batchs: 321.86724853515625
INFO:root:Train (Epoch 352): Loss/seq after 01650 batchs: 320.6358947753906
INFO:root:Train (Epoch 352): Loss/seq after 01700 batchs: 321.5753479003906
INFO:root:Train (Epoch 352): Loss/seq after 01750 batchs: 321.1051940917969
INFO:root:Train (Epoch 352): Loss/seq after 01800 batchs: 320.3085021972656
INFO:root:Train (Epoch 352): Loss/seq after 01850 batchs: 319.3403015136719
INFO:root:Train (Epoch 352): Loss/seq after 01900 batchs: 318.85577392578125
INFO:root:Train (Epoch 352): Loss/seq after 01950 batchs: 319.1972351074219
INFO:root:Train (Epoch 352): Loss/seq after 02000 batchs: 321.2883605957031
INFO:root:Train (Epoch 352): Loss/seq after 02050 batchs: 321.9205322265625
INFO:root:Train (Epoch 352): Loss/seq after 02100 batchs: 321.7920227050781
INFO:root:Train (Epoch 352): Loss/seq after 02150 batchs: 321.8939208984375
INFO:root:Train (Epoch 352): Loss/seq after 02200 batchs: 321.51025390625
INFO:root:Train (Epoch 352): Loss/seq after 02250 batchs: 321.03582763671875
INFO:root:Train (Epoch 352): Loss/seq after 02300 batchs: 319.0608215332031
INFO:root:Train (Epoch 352): Loss/seq after 02350 batchs: 317.26373291015625
INFO:root:Train (Epoch 352): Loss/seq after 02400 batchs: 317.21160888671875
INFO:root:Train (Epoch 352): Loss/seq after 02450 batchs: 314.7746887207031
INFO:root:Train (Epoch 352): Loss/seq after 02500 batchs: 309.6706848144531
INFO:root:Train (Epoch 352): Loss/seq after 02550 batchs: 305.4413757324219
INFO:root:Train (Epoch 352): Loss/seq after 02600 batchs: 302.009521484375
INFO:root:Train (Epoch 352): Loss/seq after 02650 batchs: 298.9415283203125
INFO:root:Train (Epoch 352): Loss/seq after 02700 batchs: 296.8879699707031
INFO:root:Train (Epoch 352): Loss/seq after 02750 batchs: 293.7765808105469
INFO:root:Train (Epoch 352): Loss/seq after 02800 batchs: 292.3358154296875
INFO:root:Train (Epoch 352): Loss/seq after 02850 batchs: 292.1770324707031
INFO:root:Train (Epoch 352): Loss/seq after 02900 batchs: 292.39569091796875
INFO:root:Train (Epoch 352): Loss/seq after 02950 batchs: 293.4296875
INFO:root:Train (Epoch 352): Loss/seq after 03000 batchs: 296.3662414550781
INFO:root:Train (Epoch 352): Loss/seq after 03050 batchs: 297.6070861816406
INFO:root:Train (Epoch 352): Loss/seq after 03100 batchs: 299.00225830078125
INFO:root:Train (Epoch 352): Loss/seq after 03150 batchs: 299.05035400390625
INFO:root:Train (Epoch 352): Loss/seq after 03200 batchs: 298.9524841308594
INFO:root:Train (Epoch 352): Loss/seq after 03250 batchs: 298.83074951171875
INFO:root:Train (Epoch 352): Loss/seq after 03300 batchs: 298.4852294921875
INFO:root:Train (Epoch 352): Loss/seq after 03350 batchs: 296.9119873046875
INFO:root:Train (Epoch 352): Loss/seq after 03400 batchs: 295.298583984375
INFO:root:Train (Epoch 352): Loss/seq after 03450 batchs: 294.4618835449219
INFO:root:Train (Epoch 352): Loss/seq after 03500 batchs: 295.55804443359375
INFO:root:Train (Epoch 352): Loss/seq after 03550 batchs: 294.4868469238281
INFO:root:Train (Epoch 352): Loss/seq after 03600 batchs: 296.7110290527344
INFO:root:Train (Epoch 352): Loss/seq after 03650 batchs: 295.76983642578125
INFO:root:Train (Epoch 352): Loss/seq after 03700 batchs: 297.39697265625
INFO:root:Train (Epoch 352): Loss/seq after 03750 batchs: 300.5267639160156
INFO:root:Train (Epoch 352): Loss/seq after 03800 batchs: 300.7242431640625
INFO:root:Train (Epoch 352): Loss/seq after 03850 batchs: 300.29400634765625
INFO:root:Train (Epoch 352): Loss/seq after 03900 batchs: 301.2603759765625
INFO:root:Train (Epoch 352): Loss/seq after 03950 batchs: 303.36663818359375
INFO:root:Train (Epoch 352): Loss/seq after 04000 batchs: 301.9053039550781
INFO:root:Train (Epoch 352): Loss/seq after 04050 batchs: 300.3777160644531
INFO:root:Train (Epoch 352): Loss/seq after 04100 batchs: 299.52008056640625
INFO:root:Train (Epoch 352): Loss/seq after 04150 batchs: 299.4610595703125
INFO:root:Train (Epoch 352): Loss/seq after 04200 batchs: 299.02532958984375
INFO:root:Train (Epoch 352): Loss/seq after 04250 batchs: 298.2195739746094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 352): Loss/seq after 00000 batches: 316.66864013671875
INFO:root:# Valid (Epoch 352): Loss/seq after 00050 batches: 643.2061157226562
INFO:root:# Valid (Epoch 352): Loss/seq after 00100 batches: 624.6063232421875
INFO:root:# Valid (Epoch 352): Loss/seq after 00150 batches: 467.9376525878906
INFO:root:# Valid (Epoch 352): Loss/seq after 00200 batches: 440.2135314941406
INFO:root:Artifacts: Make stick videos for epoch 352
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_352_on_20220424_011755.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_352_index_293_on_20220424_011755.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 353): Loss/seq after 00000 batchs: 503.8526916503906
INFO:root:Train (Epoch 353): Loss/seq after 00050 batchs: 411.4593811035156
INFO:root:Train (Epoch 353): Loss/seq after 00100 batchs: 406.94305419921875
INFO:root:Train (Epoch 353): Loss/seq after 00150 batchs: 382.5234375
INFO:root:Train (Epoch 353): Loss/seq after 00200 batchs: 432.0230712890625
INFO:root:Train (Epoch 353): Loss/seq after 00250 batchs: 444.55218505859375
INFO:root:Train (Epoch 353): Loss/seq after 00300 batchs: 464.46771240234375
INFO:root:Train (Epoch 353): Loss/seq after 00350 batchs: 445.3087158203125
INFO:root:Train (Epoch 353): Loss/seq after 00400 batchs: 433.3931579589844
INFO:root:Train (Epoch 353): Loss/seq after 00450 batchs: 448.20306396484375
INFO:root:Train (Epoch 353): Loss/seq after 00500 batchs: 433.4568176269531
INFO:root:Train (Epoch 353): Loss/seq after 00550 batchs: 427.2725524902344
INFO:root:Train (Epoch 353): Loss/seq after 00600 batchs: 412.10772705078125
INFO:root:Train (Epoch 353): Loss/seq after 00650 batchs: 394.75726318359375
INFO:root:Train (Epoch 353): Loss/seq after 00700 batchs: 378.5474853515625
INFO:root:Train (Epoch 353): Loss/seq after 00750 batchs: 373.4130554199219
INFO:root:Train (Epoch 353): Loss/seq after 00800 batchs: 374.6133728027344
INFO:root:Train (Epoch 353): Loss/seq after 00850 batchs: 363.31097412109375
INFO:root:Train (Epoch 353): Loss/seq after 00900 batchs: 354.140380859375
INFO:root:Train (Epoch 353): Loss/seq after 00950 batchs: 352.75274658203125
INFO:root:Train (Epoch 353): Loss/seq after 01000 batchs: 347.3548278808594
INFO:root:Train (Epoch 353): Loss/seq after 01050 batchs: 340.4619140625
INFO:root:Train (Epoch 353): Loss/seq after 01100 batchs: 332.9405212402344
INFO:root:Train (Epoch 353): Loss/seq after 01150 batchs: 324.68328857421875
INFO:root:Train (Epoch 353): Loss/seq after 01200 batchs: 323.4762878417969
INFO:root:Train (Epoch 353): Loss/seq after 01250 batchs: 322.5724792480469
INFO:root:Train (Epoch 353): Loss/seq after 01300 batchs: 316.0860595703125
INFO:root:Train (Epoch 353): Loss/seq after 01350 batchs: 309.287109375
INFO:root:Train (Epoch 353): Loss/seq after 01400 batchs: 310.0712890625
INFO:root:Train (Epoch 353): Loss/seq after 01450 batchs: 312.5506896972656
INFO:root:Train (Epoch 353): Loss/seq after 01500 batchs: 318.0313415527344
INFO:root:Train (Epoch 353): Loss/seq after 01550 batchs: 318.4979248046875
INFO:root:Train (Epoch 353): Loss/seq after 01600 batchs: 317.3481750488281
INFO:root:Train (Epoch 353): Loss/seq after 01650 batchs: 316.2572937011719
INFO:root:Train (Epoch 353): Loss/seq after 01700 batchs: 317.9288635253906
INFO:root:Train (Epoch 353): Loss/seq after 01750 batchs: 317.3195495605469
INFO:root:Train (Epoch 353): Loss/seq after 01800 batchs: 316.5008239746094
INFO:root:Train (Epoch 353): Loss/seq after 01850 batchs: 315.62164306640625
INFO:root:Train (Epoch 353): Loss/seq after 01900 batchs: 315.3385925292969
INFO:root:Train (Epoch 353): Loss/seq after 01950 batchs: 315.79852294921875
INFO:root:Train (Epoch 353): Loss/seq after 02000 batchs: 318.1082763671875
INFO:root:Train (Epoch 353): Loss/seq after 02050 batchs: 318.7001953125
INFO:root:Train (Epoch 353): Loss/seq after 02100 batchs: 318.71734619140625
INFO:root:Train (Epoch 353): Loss/seq after 02150 batchs: 318.93115234375
INFO:root:Train (Epoch 353): Loss/seq after 02200 batchs: 318.6123962402344
INFO:root:Train (Epoch 353): Loss/seq after 02250 batchs: 317.8875427246094
INFO:root:Train (Epoch 353): Loss/seq after 02300 batchs: 316.0126953125
INFO:root:Train (Epoch 353): Loss/seq after 02350 batchs: 314.23577880859375
INFO:root:Train (Epoch 353): Loss/seq after 02400 batchs: 314.1547546386719
INFO:root:Train (Epoch 353): Loss/seq after 02450 batchs: 311.86590576171875
INFO:root:Train (Epoch 353): Loss/seq after 02500 batchs: 306.782958984375
INFO:root:Train (Epoch 353): Loss/seq after 02550 batchs: 302.43328857421875
INFO:root:Train (Epoch 353): Loss/seq after 02600 batchs: 298.92852783203125
INFO:root:Train (Epoch 353): Loss/seq after 02650 batchs: 295.7628173828125
INFO:root:Train (Epoch 353): Loss/seq after 02700 batchs: 293.7947998046875
INFO:root:Train (Epoch 353): Loss/seq after 02750 batchs: 290.83013916015625
INFO:root:Train (Epoch 353): Loss/seq after 02800 batchs: 289.46600341796875
INFO:root:Train (Epoch 353): Loss/seq after 02850 batchs: 289.2137756347656
INFO:root:Train (Epoch 353): Loss/seq after 02900 batchs: 289.5410461425781
INFO:root:Train (Epoch 353): Loss/seq after 02950 batchs: 290.6896057128906
INFO:root:Train (Epoch 353): Loss/seq after 03000 batchs: 293.4470520019531
INFO:root:Train (Epoch 353): Loss/seq after 03050 batchs: 294.6817626953125
INFO:root:Train (Epoch 353): Loss/seq after 03100 batchs: 296.18182373046875
INFO:root:Train (Epoch 353): Loss/seq after 03150 batchs: 296.1116943359375
INFO:root:Train (Epoch 353): Loss/seq after 03200 batchs: 296.4148864746094
INFO:root:Train (Epoch 353): Loss/seq after 03250 batchs: 295.99774169921875
INFO:root:Train (Epoch 353): Loss/seq after 03300 batchs: 295.3647155761719
INFO:root:Train (Epoch 353): Loss/seq after 03350 batchs: 293.8697204589844
INFO:root:Train (Epoch 353): Loss/seq after 03400 batchs: 292.24310302734375
INFO:root:Train (Epoch 353): Loss/seq after 03450 batchs: 291.44854736328125
INFO:root:Train (Epoch 353): Loss/seq after 03500 batchs: 292.4138488769531
INFO:root:Train (Epoch 353): Loss/seq after 03550 batchs: 291.40289306640625
INFO:root:Train (Epoch 353): Loss/seq after 03600 batchs: 293.7379455566406
INFO:root:Train (Epoch 353): Loss/seq after 03650 batchs: 292.9704895019531
INFO:root:Train (Epoch 353): Loss/seq after 03700 batchs: 294.3890686035156
INFO:root:Train (Epoch 353): Loss/seq after 03750 batchs: 297.4714050292969
INFO:root:Train (Epoch 353): Loss/seq after 03800 batchs: 297.5706481933594
INFO:root:Train (Epoch 353): Loss/seq after 03850 batchs: 297.33282470703125
INFO:root:Train (Epoch 353): Loss/seq after 03900 batchs: 299.1109924316406
INFO:root:Train (Epoch 353): Loss/seq after 03950 batchs: 300.804931640625
INFO:root:Train (Epoch 353): Loss/seq after 04000 batchs: 299.3824768066406
INFO:root:Train (Epoch 353): Loss/seq after 04050 batchs: 297.88427734375
INFO:root:Train (Epoch 353): Loss/seq after 04100 batchs: 297.0061950683594
INFO:root:Train (Epoch 353): Loss/seq after 04150 batchs: 297.0680236816406
INFO:root:Train (Epoch 353): Loss/seq after 04200 batchs: 296.65966796875
INFO:root:Train (Epoch 353): Loss/seq after 04250 batchs: 295.8500671386719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 353): Loss/seq after 00000 batches: 275.6845703125
INFO:root:# Valid (Epoch 353): Loss/seq after 00050 batches: 670.95263671875
INFO:root:# Valid (Epoch 353): Loss/seq after 00100 batches: 699.7275390625
INFO:root:# Valid (Epoch 353): Loss/seq after 00150 batches: 519.8782958984375
INFO:root:# Valid (Epoch 353): Loss/seq after 00200 batches: 477.1342468261719
INFO:root:Artifacts: Make stick videos for epoch 353
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_353_on_20220424_012250.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_353_index_1002_on_20220424_012250.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 354): Loss/seq after 00000 batchs: 408.26129150390625
INFO:root:Train (Epoch 354): Loss/seq after 00050 batchs: 398.54791259765625
INFO:root:Train (Epoch 354): Loss/seq after 00100 batchs: 413.1650695800781
INFO:root:Train (Epoch 354): Loss/seq after 00150 batchs: 389.2926330566406
INFO:root:Train (Epoch 354): Loss/seq after 00200 batchs: 438.851318359375
INFO:root:Train (Epoch 354): Loss/seq after 00250 batchs: 473.3415832519531
INFO:root:Train (Epoch 354): Loss/seq after 00300 batchs: 488.7261657714844
INFO:root:Train (Epoch 354): Loss/seq after 00350 batchs: 465.2286682128906
INFO:root:Train (Epoch 354): Loss/seq after 00400 batchs: 460.32080078125
INFO:root:Train (Epoch 354): Loss/seq after 00450 batchs: 473.22271728515625
INFO:root:Train (Epoch 354): Loss/seq after 00500 batchs: 460.9854431152344
INFO:root:Train (Epoch 354): Loss/seq after 00550 batchs: 453.2182312011719
INFO:root:Train (Epoch 354): Loss/seq after 00600 batchs: 437.9077453613281
INFO:root:Train (Epoch 354): Loss/seq after 00650 batchs: 422.38226318359375
INFO:root:Train (Epoch 354): Loss/seq after 00700 batchs: 404.6480712890625
INFO:root:Train (Epoch 354): Loss/seq after 00750 batchs: 397.13641357421875
INFO:root:Train (Epoch 354): Loss/seq after 00800 batchs: 399.8145446777344
INFO:root:Train (Epoch 354): Loss/seq after 00850 batchs: 388.7579345703125
INFO:root:Train (Epoch 354): Loss/seq after 00900 batchs: 385.99993896484375
INFO:root:Train (Epoch 354): Loss/seq after 00950 batchs: 384.5506896972656
INFO:root:Train (Epoch 354): Loss/seq after 01000 batchs: 378.0303039550781
INFO:root:Train (Epoch 354): Loss/seq after 01050 batchs: 370.46746826171875
INFO:root:Train (Epoch 354): Loss/seq after 01100 batchs: 363.7957458496094
INFO:root:Train (Epoch 354): Loss/seq after 01150 batchs: 354.7050476074219
INFO:root:Train (Epoch 354): Loss/seq after 01200 batchs: 353.0684509277344
INFO:root:Train (Epoch 354): Loss/seq after 01250 batchs: 351.6269226074219
INFO:root:Train (Epoch 354): Loss/seq after 01300 batchs: 344.1694030761719
INFO:root:Train (Epoch 354): Loss/seq after 01350 batchs: 336.0472106933594
INFO:root:Train (Epoch 354): Loss/seq after 01400 batchs: 336.03350830078125
INFO:root:Train (Epoch 354): Loss/seq after 01450 batchs: 337.7378845214844
INFO:root:Train (Epoch 354): Loss/seq after 01500 batchs: 343.0356140136719
INFO:root:Train (Epoch 354): Loss/seq after 01550 batchs: 343.7711181640625
INFO:root:Train (Epoch 354): Loss/seq after 01600 batchs: 342.0364074707031
INFO:root:Train (Epoch 354): Loss/seq after 01650 batchs: 340.67388916015625
INFO:root:Train (Epoch 354): Loss/seq after 01700 batchs: 341.13330078125
INFO:root:Train (Epoch 354): Loss/seq after 01750 batchs: 340.0058898925781
INFO:root:Train (Epoch 354): Loss/seq after 01800 batchs: 338.47113037109375
INFO:root:Train (Epoch 354): Loss/seq after 01850 batchs: 336.9318542480469
INFO:root:Train (Epoch 354): Loss/seq after 01900 batchs: 335.9884338378906
INFO:root:Train (Epoch 354): Loss/seq after 01950 batchs: 335.7393798828125
INFO:root:Train (Epoch 354): Loss/seq after 02000 batchs: 337.26983642578125
INFO:root:Train (Epoch 354): Loss/seq after 02050 batchs: 337.44873046875
INFO:root:Train (Epoch 354): Loss/seq after 02100 batchs: 337.40191650390625
INFO:root:Train (Epoch 354): Loss/seq after 02150 batchs: 337.17840576171875
INFO:root:Train (Epoch 354): Loss/seq after 02200 batchs: 336.26397705078125
INFO:root:Train (Epoch 354): Loss/seq after 02250 batchs: 335.106201171875
INFO:root:Train (Epoch 354): Loss/seq after 02300 batchs: 332.84002685546875
INFO:root:Train (Epoch 354): Loss/seq after 02350 batchs: 330.725830078125
INFO:root:Train (Epoch 354): Loss/seq after 02400 batchs: 330.3811340332031
INFO:root:Train (Epoch 354): Loss/seq after 02450 batchs: 327.78265380859375
INFO:root:Train (Epoch 354): Loss/seq after 02500 batchs: 322.5015563964844
INFO:root:Train (Epoch 354): Loss/seq after 02550 batchs: 317.9786071777344
INFO:root:Train (Epoch 354): Loss/seq after 02600 batchs: 314.5222473144531
INFO:root:Train (Epoch 354): Loss/seq after 02650 batchs: 311.1662292480469
INFO:root:Train (Epoch 354): Loss/seq after 02700 batchs: 308.93475341796875
INFO:root:Train (Epoch 354): Loss/seq after 02750 batchs: 305.91961669921875
INFO:root:Train (Epoch 354): Loss/seq after 02800 batchs: 304.20233154296875
INFO:root:Train (Epoch 354): Loss/seq after 02850 batchs: 303.7803955078125
INFO:root:Train (Epoch 354): Loss/seq after 02900 batchs: 303.8987731933594
INFO:root:Train (Epoch 354): Loss/seq after 02950 batchs: 304.8895568847656
INFO:root:Train (Epoch 354): Loss/seq after 03000 batchs: 307.39190673828125
INFO:root:Train (Epoch 354): Loss/seq after 03050 batchs: 308.35772705078125
INFO:root:Train (Epoch 354): Loss/seq after 03100 batchs: 309.5309143066406
INFO:root:Train (Epoch 354): Loss/seq after 03150 batchs: 309.0005187988281
INFO:root:Train (Epoch 354): Loss/seq after 03200 batchs: 308.9889221191406
INFO:root:Train (Epoch 354): Loss/seq after 03250 batchs: 308.3460998535156
INFO:root:Train (Epoch 354): Loss/seq after 03300 batchs: 307.5255126953125
INFO:root:Train (Epoch 354): Loss/seq after 03350 batchs: 305.8332824707031
INFO:root:Train (Epoch 354): Loss/seq after 03400 batchs: 304.0793151855469
INFO:root:Train (Epoch 354): Loss/seq after 03450 batchs: 302.9871520996094
INFO:root:Train (Epoch 354): Loss/seq after 03500 batchs: 303.6809387207031
INFO:root:Train (Epoch 354): Loss/seq after 03550 batchs: 302.6058044433594
INFO:root:Train (Epoch 354): Loss/seq after 03600 batchs: 304.8622741699219
INFO:root:Train (Epoch 354): Loss/seq after 03650 batchs: 303.8310546875
INFO:root:Train (Epoch 354): Loss/seq after 03700 batchs: 305.2192687988281
INFO:root:Train (Epoch 354): Loss/seq after 03750 batchs: 308.1920471191406
INFO:root:Train (Epoch 354): Loss/seq after 03800 batchs: 308.186279296875
INFO:root:Train (Epoch 354): Loss/seq after 03850 batchs: 307.64447021484375
INFO:root:Train (Epoch 354): Loss/seq after 03900 batchs: 308.2685241699219
INFO:root:Train (Epoch 354): Loss/seq after 03950 batchs: 309.9248046875
INFO:root:Train (Epoch 354): Loss/seq after 04000 batchs: 308.3917236328125
INFO:root:Train (Epoch 354): Loss/seq after 04050 batchs: 306.8287658691406
INFO:root:Train (Epoch 354): Loss/seq after 04100 batchs: 305.8938293457031
INFO:root:Train (Epoch 354): Loss/seq after 04150 batchs: 305.7469482421875
INFO:root:Train (Epoch 354): Loss/seq after 04200 batchs: 305.29840087890625
INFO:root:Train (Epoch 354): Loss/seq after 04250 batchs: 304.48114013671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 354): Loss/seq after 00000 batches: 357.85455322265625
INFO:root:# Valid (Epoch 354): Loss/seq after 00050 batches: 668.300048828125
INFO:root:# Valid (Epoch 354): Loss/seq after 00100 batches: 677.7662353515625
INFO:root:# Valid (Epoch 354): Loss/seq after 00150 batches: 506.88922119140625
INFO:root:# Valid (Epoch 354): Loss/seq after 00200 batches: 465.413818359375
INFO:root:Artifacts: Make stick videos for epoch 354
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_354_on_20220424_012736.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_354_index_1797_on_20220424_012736.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 355): Loss/seq after 00000 batchs: 905.3948974609375
INFO:root:Train (Epoch 355): Loss/seq after 00050 batchs: 425.72900390625
INFO:root:Train (Epoch 355): Loss/seq after 00100 batchs: 416.92047119140625
INFO:root:Train (Epoch 355): Loss/seq after 00150 batchs: 392.0601501464844
INFO:root:Train (Epoch 355): Loss/seq after 00200 batchs: 432.2528991699219
INFO:root:Train (Epoch 355): Loss/seq after 00250 batchs: 456.4070739746094
INFO:root:Train (Epoch 355): Loss/seq after 00300 batchs: 473.1406555175781
INFO:root:Train (Epoch 355): Loss/seq after 00350 batchs: 451.63616943359375
INFO:root:Train (Epoch 355): Loss/seq after 00400 batchs: 440.7720642089844
INFO:root:Train (Epoch 355): Loss/seq after 00450 batchs: 456.3977355957031
INFO:root:Train (Epoch 355): Loss/seq after 00500 batchs: 442.7970886230469
INFO:root:Train (Epoch 355): Loss/seq after 00550 batchs: 435.67401123046875
INFO:root:Train (Epoch 355): Loss/seq after 00600 batchs: 419.9508361816406
INFO:root:Train (Epoch 355): Loss/seq after 00650 batchs: 405.20880126953125
INFO:root:Train (Epoch 355): Loss/seq after 00700 batchs: 387.66064453125
INFO:root:Train (Epoch 355): Loss/seq after 00750 batchs: 384.3846740722656
INFO:root:Train (Epoch 355): Loss/seq after 00800 batchs: 384.451171875
INFO:root:Train (Epoch 355): Loss/seq after 00850 batchs: 372.1974792480469
INFO:root:Train (Epoch 355): Loss/seq after 00900 batchs: 363.60205078125
INFO:root:Train (Epoch 355): Loss/seq after 00950 batchs: 363.78173828125
INFO:root:Train (Epoch 355): Loss/seq after 01000 batchs: 357.31610107421875
INFO:root:Train (Epoch 355): Loss/seq after 01050 batchs: 350.4917907714844
INFO:root:Train (Epoch 355): Loss/seq after 01100 batchs: 342.5080871582031
INFO:root:Train (Epoch 355): Loss/seq after 01150 batchs: 333.1461486816406
INFO:root:Train (Epoch 355): Loss/seq after 01200 batchs: 332.1844177246094
INFO:root:Train (Epoch 355): Loss/seq after 01250 batchs: 331.5380859375
INFO:root:Train (Epoch 355): Loss/seq after 01300 batchs: 324.5821533203125
INFO:root:Train (Epoch 355): Loss/seq after 01350 batchs: 317.49346923828125
INFO:root:Train (Epoch 355): Loss/seq after 01400 batchs: 318.9371643066406
INFO:root:Train (Epoch 355): Loss/seq after 01450 batchs: 321.10791015625
INFO:root:Train (Epoch 355): Loss/seq after 01500 batchs: 326.674072265625
INFO:root:Train (Epoch 355): Loss/seq after 01550 batchs: 327.5880432128906
INFO:root:Train (Epoch 355): Loss/seq after 01600 batchs: 326.5497741699219
INFO:root:Train (Epoch 355): Loss/seq after 01650 batchs: 325.1159362792969
INFO:root:Train (Epoch 355): Loss/seq after 01700 batchs: 325.9722900390625
INFO:root:Train (Epoch 355): Loss/seq after 01750 batchs: 325.2424011230469
INFO:root:Train (Epoch 355): Loss/seq after 01800 batchs: 324.19866943359375
INFO:root:Train (Epoch 355): Loss/seq after 01850 batchs: 322.95867919921875
INFO:root:Train (Epoch 355): Loss/seq after 01900 batchs: 322.579345703125
INFO:root:Train (Epoch 355): Loss/seq after 01950 batchs: 322.7752380371094
INFO:root:Train (Epoch 355): Loss/seq after 02000 batchs: 324.6563415527344
INFO:root:Train (Epoch 355): Loss/seq after 02050 batchs: 324.9380187988281
INFO:root:Train (Epoch 355): Loss/seq after 02100 batchs: 324.7776184082031
INFO:root:Train (Epoch 355): Loss/seq after 02150 batchs: 324.9746398925781
INFO:root:Train (Epoch 355): Loss/seq after 02200 batchs: 324.5573425292969
INFO:root:Train (Epoch 355): Loss/seq after 02250 batchs: 324.357666015625
INFO:root:Train (Epoch 355): Loss/seq after 02300 batchs: 322.3553161621094
INFO:root:Train (Epoch 355): Loss/seq after 02350 batchs: 320.51812744140625
INFO:root:Train (Epoch 355): Loss/seq after 02400 batchs: 320.2763977050781
INFO:root:Train (Epoch 355): Loss/seq after 02450 batchs: 317.84906005859375
INFO:root:Train (Epoch 355): Loss/seq after 02500 batchs: 312.6910095214844
INFO:root:Train (Epoch 355): Loss/seq after 02550 batchs: 308.2052307128906
INFO:root:Train (Epoch 355): Loss/seq after 02600 batchs: 304.490478515625
INFO:root:Train (Epoch 355): Loss/seq after 02650 batchs: 301.26324462890625
INFO:root:Train (Epoch 355): Loss/seq after 02700 batchs: 299.2169189453125
INFO:root:Train (Epoch 355): Loss/seq after 02750 batchs: 296.1662292480469
INFO:root:Train (Epoch 355): Loss/seq after 02800 batchs: 294.3497314453125
INFO:root:Train (Epoch 355): Loss/seq after 02850 batchs: 293.9445495605469
INFO:root:Train (Epoch 355): Loss/seq after 02900 batchs: 294.1860656738281
INFO:root:Train (Epoch 355): Loss/seq after 02950 batchs: 295.12890625
INFO:root:Train (Epoch 355): Loss/seq after 03000 batchs: 298.1004638671875
INFO:root:Train (Epoch 355): Loss/seq after 03050 batchs: 299.5055236816406
INFO:root:Train (Epoch 355): Loss/seq after 03100 batchs: 300.5840148925781
INFO:root:Train (Epoch 355): Loss/seq after 03150 batchs: 300.43212890625
INFO:root:Train (Epoch 355): Loss/seq after 03200 batchs: 300.298828125
INFO:root:Train (Epoch 355): Loss/seq after 03250 batchs: 300.2432556152344
INFO:root:Train (Epoch 355): Loss/seq after 03300 batchs: 299.5174560546875
INFO:root:Train (Epoch 355): Loss/seq after 03350 batchs: 297.9906921386719
INFO:root:Train (Epoch 355): Loss/seq after 03400 batchs: 296.3050842285156
INFO:root:Train (Epoch 355): Loss/seq after 03450 batchs: 295.5474548339844
INFO:root:Train (Epoch 355): Loss/seq after 03500 batchs: 296.4288330078125
INFO:root:Train (Epoch 355): Loss/seq after 03550 batchs: 295.3696594238281
INFO:root:Train (Epoch 355): Loss/seq after 03600 batchs: 297.5394287109375
INFO:root:Train (Epoch 355): Loss/seq after 03650 batchs: 296.2842712402344
INFO:root:Train (Epoch 355): Loss/seq after 03700 batchs: 297.7220153808594
INFO:root:Train (Epoch 355): Loss/seq after 03750 batchs: 300.6826477050781
INFO:root:Train (Epoch 355): Loss/seq after 03800 batchs: 300.90338134765625
INFO:root:Train (Epoch 355): Loss/seq after 03850 batchs: 300.5448913574219
INFO:root:Train (Epoch 355): Loss/seq after 03900 batchs: 301.24591064453125
INFO:root:Train (Epoch 355): Loss/seq after 03950 batchs: 302.82574462890625
INFO:root:Train (Epoch 355): Loss/seq after 04000 batchs: 301.3682861328125
INFO:root:Train (Epoch 355): Loss/seq after 04050 batchs: 299.85174560546875
INFO:root:Train (Epoch 355): Loss/seq after 04100 batchs: 298.8714904785156
INFO:root:Train (Epoch 355): Loss/seq after 04150 batchs: 298.8210144042969
INFO:root:Train (Epoch 355): Loss/seq after 04200 batchs: 298.5384216308594
INFO:root:Train (Epoch 355): Loss/seq after 04250 batchs: 297.74078369140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 355): Loss/seq after 00000 batches: 231.96737670898438
INFO:root:# Valid (Epoch 355): Loss/seq after 00050 batches: 629.1248168945312
INFO:root:# Valid (Epoch 355): Loss/seq after 00100 batches: 610.552490234375
INFO:root:# Valid (Epoch 355): Loss/seq after 00150 batches: 460.1219482421875
INFO:root:# Valid (Epoch 355): Loss/seq after 00200 batches: 428.940673828125
INFO:root:Artifacts: Make stick videos for epoch 355
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_355_on_20220424_013226.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_355_index_355_on_20220424_013226.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 356): Loss/seq after 00000 batchs: 409.92242431640625
INFO:root:Train (Epoch 356): Loss/seq after 00050 batchs: 386.9829406738281
INFO:root:Train (Epoch 356): Loss/seq after 00100 batchs: 395.7179260253906
INFO:root:Train (Epoch 356): Loss/seq after 00150 batchs: 370.7151184082031
INFO:root:Train (Epoch 356): Loss/seq after 00200 batchs: 414.297607421875
INFO:root:Train (Epoch 356): Loss/seq after 00250 batchs: 423.417236328125
INFO:root:Train (Epoch 356): Loss/seq after 00300 batchs: 441.4767761230469
INFO:root:Train (Epoch 356): Loss/seq after 00350 batchs: 423.8130798339844
INFO:root:Train (Epoch 356): Loss/seq after 00400 batchs: 419.3919372558594
INFO:root:Train (Epoch 356): Loss/seq after 00450 batchs: 435.05926513671875
INFO:root:Train (Epoch 356): Loss/seq after 00500 batchs: 422.35748291015625
INFO:root:Train (Epoch 356): Loss/seq after 00550 batchs: 417.63677978515625
INFO:root:Train (Epoch 356): Loss/seq after 00600 batchs: 403.56304931640625
INFO:root:Train (Epoch 356): Loss/seq after 00650 batchs: 390.3069152832031
INFO:root:Train (Epoch 356): Loss/seq after 00700 batchs: 373.7827453613281
INFO:root:Train (Epoch 356): Loss/seq after 00750 batchs: 367.1065368652344
INFO:root:Train (Epoch 356): Loss/seq after 00800 batchs: 368.3052673339844
INFO:root:Train (Epoch 356): Loss/seq after 00850 batchs: 356.8083190917969
INFO:root:Train (Epoch 356): Loss/seq after 00900 batchs: 347.9641418457031
INFO:root:Train (Epoch 356): Loss/seq after 00950 batchs: 347.868896484375
INFO:root:Train (Epoch 356): Loss/seq after 01000 batchs: 341.4593811035156
INFO:root:Train (Epoch 356): Loss/seq after 01050 batchs: 335.28472900390625
INFO:root:Train (Epoch 356): Loss/seq after 01100 batchs: 327.6318359375
INFO:root:Train (Epoch 356): Loss/seq after 01150 batchs: 318.9151306152344
INFO:root:Train (Epoch 356): Loss/seq after 01200 batchs: 318.3554992675781
INFO:root:Train (Epoch 356): Loss/seq after 01250 batchs: 318.808837890625
INFO:root:Train (Epoch 356): Loss/seq after 01300 batchs: 312.24237060546875
INFO:root:Train (Epoch 356): Loss/seq after 01350 batchs: 305.447998046875
INFO:root:Train (Epoch 356): Loss/seq after 01400 batchs: 306.048583984375
INFO:root:Train (Epoch 356): Loss/seq after 01450 batchs: 309.08734130859375
INFO:root:Train (Epoch 356): Loss/seq after 01500 batchs: 314.8529052734375
INFO:root:Train (Epoch 356): Loss/seq after 01550 batchs: 315.9930114746094
INFO:root:Train (Epoch 356): Loss/seq after 01600 batchs: 315.2152404785156
INFO:root:Train (Epoch 356): Loss/seq after 01650 batchs: 314.45458984375
INFO:root:Train (Epoch 356): Loss/seq after 01700 batchs: 316.0180358886719
INFO:root:Train (Epoch 356): Loss/seq after 01750 batchs: 315.21563720703125
INFO:root:Train (Epoch 356): Loss/seq after 01800 batchs: 314.49456787109375
INFO:root:Train (Epoch 356): Loss/seq after 01850 batchs: 313.56756591796875
INFO:root:Train (Epoch 356): Loss/seq after 01900 batchs: 313.61322021484375
INFO:root:Train (Epoch 356): Loss/seq after 01950 batchs: 313.9760437011719
INFO:root:Train (Epoch 356): Loss/seq after 02000 batchs: 316.20184326171875
INFO:root:Train (Epoch 356): Loss/seq after 02050 batchs: 316.74249267578125
INFO:root:Train (Epoch 356): Loss/seq after 02100 batchs: 316.92974853515625
INFO:root:Train (Epoch 356): Loss/seq after 02150 batchs: 317.2694091796875
INFO:root:Train (Epoch 356): Loss/seq after 02200 batchs: 316.801513671875
INFO:root:Train (Epoch 356): Loss/seq after 02250 batchs: 316.3778381347656
INFO:root:Train (Epoch 356): Loss/seq after 02300 batchs: 314.3512268066406
INFO:root:Train (Epoch 356): Loss/seq after 02350 batchs: 312.6246032714844
INFO:root:Train (Epoch 356): Loss/seq after 02400 batchs: 312.50225830078125
INFO:root:Train (Epoch 356): Loss/seq after 02450 batchs: 310.2713623046875
INFO:root:Train (Epoch 356): Loss/seq after 02500 batchs: 305.2216491699219
INFO:root:Train (Epoch 356): Loss/seq after 02550 batchs: 300.97015380859375
INFO:root:Train (Epoch 356): Loss/seq after 02600 batchs: 297.6730651855469
INFO:root:Train (Epoch 356): Loss/seq after 02650 batchs: 294.655517578125
INFO:root:Train (Epoch 356): Loss/seq after 02700 batchs: 292.7207946777344
INFO:root:Train (Epoch 356): Loss/seq after 02750 batchs: 289.6864929199219
INFO:root:Train (Epoch 356): Loss/seq after 02800 batchs: 288.0023193359375
INFO:root:Train (Epoch 356): Loss/seq after 02850 batchs: 287.8323974609375
INFO:root:Train (Epoch 356): Loss/seq after 02900 batchs: 288.1856689453125
INFO:root:Train (Epoch 356): Loss/seq after 02950 batchs: 289.24090576171875
INFO:root:Train (Epoch 356): Loss/seq after 03000 batchs: 291.55828857421875
INFO:root:Train (Epoch 356): Loss/seq after 03050 batchs: 292.4649353027344
INFO:root:Train (Epoch 356): Loss/seq after 03100 batchs: 293.76507568359375
INFO:root:Train (Epoch 356): Loss/seq after 03150 batchs: 293.5299072265625
INFO:root:Train (Epoch 356): Loss/seq after 03200 batchs: 293.4068603515625
INFO:root:Train (Epoch 356): Loss/seq after 03250 batchs: 293.29443359375
INFO:root:Train (Epoch 356): Loss/seq after 03300 batchs: 292.66162109375
INFO:root:Train (Epoch 356): Loss/seq after 03350 batchs: 291.2079772949219
INFO:root:Train (Epoch 356): Loss/seq after 03400 batchs: 289.5664978027344
INFO:root:Train (Epoch 356): Loss/seq after 03450 batchs: 288.7008361816406
INFO:root:Train (Epoch 356): Loss/seq after 03500 batchs: 289.5916748046875
INFO:root:Train (Epoch 356): Loss/seq after 03550 batchs: 288.67144775390625
INFO:root:Train (Epoch 356): Loss/seq after 03600 batchs: 290.9956359863281
INFO:root:Train (Epoch 356): Loss/seq after 03650 batchs: 289.8968200683594
INFO:root:Train (Epoch 356): Loss/seq after 03700 batchs: 291.4830627441406
INFO:root:Train (Epoch 356): Loss/seq after 03750 batchs: 294.8062438964844
INFO:root:Train (Epoch 356): Loss/seq after 03800 batchs: 295.0303649902344
INFO:root:Train (Epoch 356): Loss/seq after 03850 batchs: 294.7929382324219
INFO:root:Train (Epoch 356): Loss/seq after 03900 batchs: 295.71087646484375
INFO:root:Train (Epoch 356): Loss/seq after 03950 batchs: 297.9942932128906
INFO:root:Train (Epoch 356): Loss/seq after 04000 batchs: 296.6222229003906
INFO:root:Train (Epoch 356): Loss/seq after 04050 batchs: 295.1573486328125
INFO:root:Train (Epoch 356): Loss/seq after 04100 batchs: 294.3190002441406
INFO:root:Train (Epoch 356): Loss/seq after 04150 batchs: 294.4254455566406
INFO:root:Train (Epoch 356): Loss/seq after 04200 batchs: 294.1015930175781
INFO:root:Train (Epoch 356): Loss/seq after 04250 batchs: 293.38970947265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 356): Loss/seq after 00000 batches: 229.59840393066406
INFO:root:# Valid (Epoch 356): Loss/seq after 00050 batches: 666.8397216796875
INFO:root:# Valid (Epoch 356): Loss/seq after 00100 batches: 691.1585083007812
INFO:root:# Valid (Epoch 356): Loss/seq after 00150 batches: 520.8389282226562
INFO:root:# Valid (Epoch 356): Loss/seq after 00200 batches: 487.036376953125
INFO:root:Artifacts: Make stick videos for epoch 356
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_356_on_20220424_013710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_356_index_825_on_20220424_013710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 357): Loss/seq after 00000 batchs: 406.2442626953125
INFO:root:Train (Epoch 357): Loss/seq after 00050 batchs: 411.3338317871094
INFO:root:Train (Epoch 357): Loss/seq after 00100 batchs: 407.59649658203125
INFO:root:Train (Epoch 357): Loss/seq after 00150 batchs: 382.4250183105469
INFO:root:Train (Epoch 357): Loss/seq after 00200 batchs: 423.73272705078125
INFO:root:Train (Epoch 357): Loss/seq after 00250 batchs: 430.46295166015625
INFO:root:Train (Epoch 357): Loss/seq after 00300 batchs: 450.0710144042969
INFO:root:Train (Epoch 357): Loss/seq after 00350 batchs: 431.8297119140625
INFO:root:Train (Epoch 357): Loss/seq after 00400 batchs: 424.473388671875
INFO:root:Train (Epoch 357): Loss/seq after 00450 batchs: 440.0236511230469
INFO:root:Train (Epoch 357): Loss/seq after 00500 batchs: 428.09808349609375
INFO:root:Train (Epoch 357): Loss/seq after 00550 batchs: 422.97955322265625
INFO:root:Train (Epoch 357): Loss/seq after 00600 batchs: 408.9195556640625
INFO:root:Train (Epoch 357): Loss/seq after 00650 batchs: 392.013427734375
INFO:root:Train (Epoch 357): Loss/seq after 00700 batchs: 377.1028137207031
INFO:root:Train (Epoch 357): Loss/seq after 00750 batchs: 372.1457824707031
INFO:root:Train (Epoch 357): Loss/seq after 00800 batchs: 372.88067626953125
INFO:root:Train (Epoch 357): Loss/seq after 00850 batchs: 361.2996826171875
INFO:root:Train (Epoch 357): Loss/seq after 00900 batchs: 352.3179016113281
INFO:root:Train (Epoch 357): Loss/seq after 00950 batchs: 352.30279541015625
INFO:root:Train (Epoch 357): Loss/seq after 01000 batchs: 346.0289001464844
INFO:root:Train (Epoch 357): Loss/seq after 01050 batchs: 339.4437255859375
INFO:root:Train (Epoch 357): Loss/seq after 01100 batchs: 332.0000305175781
INFO:root:Train (Epoch 357): Loss/seq after 01150 batchs: 322.9327697753906
INFO:root:Train (Epoch 357): Loss/seq after 01200 batchs: 321.4340515136719
INFO:root:Train (Epoch 357): Loss/seq after 01250 batchs: 320.8159484863281
INFO:root:Train (Epoch 357): Loss/seq after 01300 batchs: 313.9989013671875
INFO:root:Train (Epoch 357): Loss/seq after 01350 batchs: 307.34967041015625
INFO:root:Train (Epoch 357): Loss/seq after 01400 batchs: 307.6579284667969
INFO:root:Train (Epoch 357): Loss/seq after 01450 batchs: 309.96087646484375
INFO:root:Train (Epoch 357): Loss/seq after 01500 batchs: 315.9433288574219
INFO:root:Train (Epoch 357): Loss/seq after 01550 batchs: 317.2720642089844
INFO:root:Train (Epoch 357): Loss/seq after 01600 batchs: 316.4150390625
INFO:root:Train (Epoch 357): Loss/seq after 01650 batchs: 315.4398193359375
INFO:root:Train (Epoch 357): Loss/seq after 01700 batchs: 316.28350830078125
INFO:root:Train (Epoch 357): Loss/seq after 01750 batchs: 315.920166015625
INFO:root:Train (Epoch 357): Loss/seq after 01800 batchs: 315.06109619140625
INFO:root:Train (Epoch 357): Loss/seq after 01850 batchs: 314.24456787109375
INFO:root:Train (Epoch 357): Loss/seq after 01900 batchs: 314.24664306640625
INFO:root:Train (Epoch 357): Loss/seq after 01950 batchs: 315.0049743652344
INFO:root:Train (Epoch 357): Loss/seq after 02000 batchs: 317.2578125
INFO:root:Train (Epoch 357): Loss/seq after 02050 batchs: 317.9779052734375
INFO:root:Train (Epoch 357): Loss/seq after 02100 batchs: 317.9350891113281
INFO:root:Train (Epoch 357): Loss/seq after 02150 batchs: 318.07965087890625
INFO:root:Train (Epoch 357): Loss/seq after 02200 batchs: 317.74310302734375
INFO:root:Train (Epoch 357): Loss/seq after 02250 batchs: 317.09552001953125
INFO:root:Train (Epoch 357): Loss/seq after 02300 batchs: 315.21734619140625
INFO:root:Train (Epoch 357): Loss/seq after 02350 batchs: 313.57049560546875
INFO:root:Train (Epoch 357): Loss/seq after 02400 batchs: 313.68951416015625
INFO:root:Train (Epoch 357): Loss/seq after 02450 batchs: 311.37744140625
INFO:root:Train (Epoch 357): Loss/seq after 02500 batchs: 306.34954833984375
INFO:root:Train (Epoch 357): Loss/seq after 02550 batchs: 302.07135009765625
INFO:root:Train (Epoch 357): Loss/seq after 02600 batchs: 298.6205139160156
INFO:root:Train (Epoch 357): Loss/seq after 02650 batchs: 295.50360107421875
INFO:root:Train (Epoch 357): Loss/seq after 02700 batchs: 293.4695129394531
INFO:root:Train (Epoch 357): Loss/seq after 02750 batchs: 290.2486267089844
INFO:root:Train (Epoch 357): Loss/seq after 02800 batchs: 288.42840576171875
INFO:root:Train (Epoch 357): Loss/seq after 02850 batchs: 288.3575744628906
INFO:root:Train (Epoch 357): Loss/seq after 02900 batchs: 288.3415222167969
INFO:root:Train (Epoch 357): Loss/seq after 02950 batchs: 289.3901672363281
INFO:root:Train (Epoch 357): Loss/seq after 03000 batchs: 291.76983642578125
INFO:root:Train (Epoch 357): Loss/seq after 03050 batchs: 292.9551086425781
INFO:root:Train (Epoch 357): Loss/seq after 03100 batchs: 294.4530334472656
INFO:root:Train (Epoch 357): Loss/seq after 03150 batchs: 295.06591796875
INFO:root:Train (Epoch 357): Loss/seq after 03200 batchs: 295.0565185546875
INFO:root:Train (Epoch 357): Loss/seq after 03250 batchs: 295.1986389160156
INFO:root:Train (Epoch 357): Loss/seq after 03300 batchs: 295.375
INFO:root:Train (Epoch 357): Loss/seq after 03350 batchs: 294.1536560058594
INFO:root:Train (Epoch 357): Loss/seq after 03400 batchs: 292.5936279296875
INFO:root:Train (Epoch 357): Loss/seq after 03450 batchs: 291.73193359375
INFO:root:Train (Epoch 357): Loss/seq after 03500 batchs: 292.6908874511719
INFO:root:Train (Epoch 357): Loss/seq after 03550 batchs: 291.79193115234375
INFO:root:Train (Epoch 357): Loss/seq after 03600 batchs: 294.2548522949219
INFO:root:Train (Epoch 357): Loss/seq after 03650 batchs: 293.36248779296875
INFO:root:Train (Epoch 357): Loss/seq after 03700 batchs: 294.9489440917969
INFO:root:Train (Epoch 357): Loss/seq after 03750 batchs: 297.9794006347656
INFO:root:Train (Epoch 357): Loss/seq after 03800 batchs: 298.218017578125
INFO:root:Train (Epoch 357): Loss/seq after 03850 batchs: 297.9159240722656
INFO:root:Train (Epoch 357): Loss/seq after 03900 batchs: 298.739013671875
INFO:root:Train (Epoch 357): Loss/seq after 03950 batchs: 301.150146484375
INFO:root:Train (Epoch 357): Loss/seq after 04000 batchs: 299.74639892578125
INFO:root:Train (Epoch 357): Loss/seq after 04050 batchs: 298.28668212890625
INFO:root:Train (Epoch 357): Loss/seq after 04100 batchs: 297.3196716308594
INFO:root:Train (Epoch 357): Loss/seq after 04150 batchs: 297.23724365234375
INFO:root:Train (Epoch 357): Loss/seq after 04200 batchs: 296.9365539550781
INFO:root:Train (Epoch 357): Loss/seq after 04250 batchs: 296.1137390136719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 357): Loss/seq after 00000 batches: 330.89862060546875
INFO:root:# Valid (Epoch 357): Loss/seq after 00050 batches: 658.2532348632812
INFO:root:# Valid (Epoch 357): Loss/seq after 00100 batches: 707.1867065429688
INFO:root:# Valid (Epoch 357): Loss/seq after 00150 batches: 523.7034301757812
INFO:root:# Valid (Epoch 357): Loss/seq after 00200 batches: 478.94293212890625
INFO:root:Artifacts: Make stick videos for epoch 357
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_357_on_20220424_014219.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_357_index_120_on_20220424_014219.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 358): Loss/seq after 00000 batchs: 456.74224853515625
INFO:root:Train (Epoch 358): Loss/seq after 00050 batchs: 403.85736083984375
INFO:root:Train (Epoch 358): Loss/seq after 00100 batchs: 396.0403747558594
INFO:root:Train (Epoch 358): Loss/seq after 00150 batchs: 373.6593322753906
INFO:root:Train (Epoch 358): Loss/seq after 00200 batchs: 424.64971923828125
INFO:root:Train (Epoch 358): Loss/seq after 00250 batchs: 463.1109619140625
INFO:root:Train (Epoch 358): Loss/seq after 00300 batchs: 484.4552001953125
INFO:root:Train (Epoch 358): Loss/seq after 00350 batchs: 462.3553161621094
INFO:root:Train (Epoch 358): Loss/seq after 00400 batchs: 459.7560119628906
INFO:root:Train (Epoch 358): Loss/seq after 00450 batchs: 472.1794128417969
INFO:root:Train (Epoch 358): Loss/seq after 00500 batchs: 461.32000732421875
INFO:root:Train (Epoch 358): Loss/seq after 00550 batchs: 453.228759765625
INFO:root:Train (Epoch 358): Loss/seq after 00600 batchs: 438.2170715332031
INFO:root:Train (Epoch 358): Loss/seq after 00650 batchs: 422.3320007324219
INFO:root:Train (Epoch 358): Loss/seq after 00700 batchs: 403.77899169921875
INFO:root:Train (Epoch 358): Loss/seq after 00750 batchs: 395.06475830078125
INFO:root:Train (Epoch 358): Loss/seq after 00800 batchs: 395.413818359375
INFO:root:Train (Epoch 358): Loss/seq after 00850 batchs: 382.2862854003906
INFO:root:Train (Epoch 358): Loss/seq after 00900 batchs: 372.68994140625
INFO:root:Train (Epoch 358): Loss/seq after 00950 batchs: 371.0946044921875
INFO:root:Train (Epoch 358): Loss/seq after 01000 batchs: 364.2257995605469
INFO:root:Train (Epoch 358): Loss/seq after 01050 batchs: 357.12890625
INFO:root:Train (Epoch 358): Loss/seq after 01100 batchs: 349.3763732910156
INFO:root:Train (Epoch 358): Loss/seq after 01150 batchs: 339.9512023925781
INFO:root:Train (Epoch 358): Loss/seq after 01200 batchs: 338.2652282714844
INFO:root:Train (Epoch 358): Loss/seq after 01250 batchs: 336.859375
INFO:root:Train (Epoch 358): Loss/seq after 01300 batchs: 329.4320983886719
INFO:root:Train (Epoch 358): Loss/seq after 01350 batchs: 322.7263488769531
INFO:root:Train (Epoch 358): Loss/seq after 01400 batchs: 323.8600158691406
INFO:root:Train (Epoch 358): Loss/seq after 01450 batchs: 325.0752258300781
INFO:root:Train (Epoch 358): Loss/seq after 01500 batchs: 330.0142517089844
INFO:root:Train (Epoch 358): Loss/seq after 01550 batchs: 330.8294677734375
INFO:root:Train (Epoch 358): Loss/seq after 01600 batchs: 329.5811767578125
INFO:root:Train (Epoch 358): Loss/seq after 01650 batchs: 328.12078857421875
INFO:root:Train (Epoch 358): Loss/seq after 01700 batchs: 328.6411437988281
INFO:root:Train (Epoch 358): Loss/seq after 01750 batchs: 327.51177978515625
INFO:root:Train (Epoch 358): Loss/seq after 01800 batchs: 326.3501281738281
INFO:root:Train (Epoch 358): Loss/seq after 01850 batchs: 325.1262512207031
INFO:root:Train (Epoch 358): Loss/seq after 01900 batchs: 324.2627258300781
INFO:root:Train (Epoch 358): Loss/seq after 01950 batchs: 324.3184509277344
INFO:root:Train (Epoch 358): Loss/seq after 02000 batchs: 326.29278564453125
INFO:root:Train (Epoch 358): Loss/seq after 02050 batchs: 326.3526916503906
INFO:root:Train (Epoch 358): Loss/seq after 02100 batchs: 326.0660400390625
INFO:root:Train (Epoch 358): Loss/seq after 02150 batchs: 326.0420227050781
INFO:root:Train (Epoch 358): Loss/seq after 02200 batchs: 325.494384765625
INFO:root:Train (Epoch 358): Loss/seq after 02250 batchs: 325.013671875
INFO:root:Train (Epoch 358): Loss/seq after 02300 batchs: 322.66632080078125
INFO:root:Train (Epoch 358): Loss/seq after 02350 batchs: 320.6774597167969
INFO:root:Train (Epoch 358): Loss/seq after 02400 batchs: 320.30694580078125
INFO:root:Train (Epoch 358): Loss/seq after 02450 batchs: 317.9093017578125
INFO:root:Train (Epoch 358): Loss/seq after 02500 batchs: 312.72283935546875
INFO:root:Train (Epoch 358): Loss/seq after 02550 batchs: 308.210205078125
INFO:root:Train (Epoch 358): Loss/seq after 02600 batchs: 304.54547119140625
INFO:root:Train (Epoch 358): Loss/seq after 02650 batchs: 301.31048583984375
INFO:root:Train (Epoch 358): Loss/seq after 02700 batchs: 299.1556396484375
INFO:root:Train (Epoch 358): Loss/seq after 02750 batchs: 295.955810546875
INFO:root:Train (Epoch 358): Loss/seq after 02800 batchs: 294.13299560546875
INFO:root:Train (Epoch 358): Loss/seq after 02850 batchs: 293.693359375
INFO:root:Train (Epoch 358): Loss/seq after 02900 batchs: 293.7089538574219
INFO:root:Train (Epoch 358): Loss/seq after 02950 batchs: 294.7071533203125
INFO:root:Train (Epoch 358): Loss/seq after 03000 batchs: 297.2509460449219
INFO:root:Train (Epoch 358): Loss/seq after 03050 batchs: 298.36895751953125
INFO:root:Train (Epoch 358): Loss/seq after 03100 batchs: 299.8067932128906
INFO:root:Train (Epoch 358): Loss/seq after 03150 batchs: 299.6480712890625
INFO:root:Train (Epoch 358): Loss/seq after 03200 batchs: 299.7244873046875
INFO:root:Train (Epoch 358): Loss/seq after 03250 batchs: 299.3467102050781
INFO:root:Train (Epoch 358): Loss/seq after 03300 batchs: 298.777587890625
INFO:root:Train (Epoch 358): Loss/seq after 03350 batchs: 297.5614929199219
INFO:root:Train (Epoch 358): Loss/seq after 03400 batchs: 295.90203857421875
INFO:root:Train (Epoch 358): Loss/seq after 03450 batchs: 294.9310607910156
INFO:root:Train (Epoch 358): Loss/seq after 03500 batchs: 296.26019287109375
INFO:root:Train (Epoch 358): Loss/seq after 03550 batchs: 295.3746032714844
INFO:root:Train (Epoch 358): Loss/seq after 03600 batchs: 297.6023864746094
INFO:root:Train (Epoch 358): Loss/seq after 03650 batchs: 296.81658935546875
INFO:root:Train (Epoch 358): Loss/seq after 03700 batchs: 298.4639892578125
INFO:root:Train (Epoch 358): Loss/seq after 03750 batchs: 301.7278747558594
INFO:root:Train (Epoch 358): Loss/seq after 03800 batchs: 301.9212951660156
INFO:root:Train (Epoch 358): Loss/seq after 03850 batchs: 301.4891052246094
INFO:root:Train (Epoch 358): Loss/seq after 03900 batchs: 302.3015441894531
INFO:root:Train (Epoch 358): Loss/seq after 03950 batchs: 304.0381774902344
INFO:root:Train (Epoch 358): Loss/seq after 04000 batchs: 302.628173828125
INFO:root:Train (Epoch 358): Loss/seq after 04050 batchs: 301.1206359863281
INFO:root:Train (Epoch 358): Loss/seq after 04100 batchs: 300.1509704589844
INFO:root:Train (Epoch 358): Loss/seq after 04150 batchs: 300.0216979980469
INFO:root:Train (Epoch 358): Loss/seq after 04200 batchs: 299.548095703125
INFO:root:Train (Epoch 358): Loss/seq after 04250 batchs: 298.7837219238281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 358): Loss/seq after 00000 batches: 295.0753479003906
INFO:root:# Valid (Epoch 358): Loss/seq after 00050 batches: 679.5653686523438
INFO:root:# Valid (Epoch 358): Loss/seq after 00100 batches: 671.18359375
INFO:root:# Valid (Epoch 358): Loss/seq after 00150 batches: 503.24493408203125
INFO:root:# Valid (Epoch 358): Loss/seq after 00200 batches: 462.70953369140625
INFO:root:Artifacts: Make stick videos for epoch 358
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_358_on_20220424_014703.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_358_index_1714_on_20220424_014703.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 359): Loss/seq after 00000 batchs: 407.5657043457031
INFO:root:Train (Epoch 359): Loss/seq after 00050 batchs: 406.15411376953125
INFO:root:Train (Epoch 359): Loss/seq after 00100 batchs: 405.7236022949219
INFO:root:Train (Epoch 359): Loss/seq after 00150 batchs: 380.8443603515625
INFO:root:Train (Epoch 359): Loss/seq after 00200 batchs: 431.9692077636719
INFO:root:Train (Epoch 359): Loss/seq after 00250 batchs: 444.23956298828125
INFO:root:Train (Epoch 359): Loss/seq after 00300 batchs: 460.26934814453125
INFO:root:Train (Epoch 359): Loss/seq after 00350 batchs: 440.64361572265625
INFO:root:Train (Epoch 359): Loss/seq after 00400 batchs: 430.7677001953125
INFO:root:Train (Epoch 359): Loss/seq after 00450 batchs: 445.6308898925781
INFO:root:Train (Epoch 359): Loss/seq after 00500 batchs: 431.2430419921875
INFO:root:Train (Epoch 359): Loss/seq after 00550 batchs: 425.12957763671875
INFO:root:Train (Epoch 359): Loss/seq after 00600 batchs: 411.23419189453125
INFO:root:Train (Epoch 359): Loss/seq after 00650 batchs: 394.2374572753906
INFO:root:Train (Epoch 359): Loss/seq after 00700 batchs: 377.98101806640625
INFO:root:Train (Epoch 359): Loss/seq after 00750 batchs: 370.9600830078125
INFO:root:Train (Epoch 359): Loss/seq after 00800 batchs: 372.36614990234375
INFO:root:Train (Epoch 359): Loss/seq after 00850 batchs: 361.0305480957031
INFO:root:Train (Epoch 359): Loss/seq after 00900 batchs: 352.8919982910156
INFO:root:Train (Epoch 359): Loss/seq after 00950 batchs: 351.3604431152344
INFO:root:Train (Epoch 359): Loss/seq after 01000 batchs: 345.44970703125
INFO:root:Train (Epoch 359): Loss/seq after 01050 batchs: 339.0998229980469
INFO:root:Train (Epoch 359): Loss/seq after 01100 batchs: 331.3639831542969
INFO:root:Train (Epoch 359): Loss/seq after 01150 batchs: 322.69683837890625
INFO:root:Train (Epoch 359): Loss/seq after 01200 batchs: 321.91790771484375
INFO:root:Train (Epoch 359): Loss/seq after 01250 batchs: 321.26123046875
INFO:root:Train (Epoch 359): Loss/seq after 01300 batchs: 314.86724853515625
INFO:root:Train (Epoch 359): Loss/seq after 01350 batchs: 308.46112060546875
INFO:root:Train (Epoch 359): Loss/seq after 01400 batchs: 309.0784606933594
INFO:root:Train (Epoch 359): Loss/seq after 01450 batchs: 311.06207275390625
INFO:root:Train (Epoch 359): Loss/seq after 01500 batchs: 316.5810852050781
INFO:root:Train (Epoch 359): Loss/seq after 01550 batchs: 317.42266845703125
INFO:root:Train (Epoch 359): Loss/seq after 01600 batchs: 316.6451416015625
INFO:root:Train (Epoch 359): Loss/seq after 01650 batchs: 315.3558044433594
INFO:root:Train (Epoch 359): Loss/seq after 01700 batchs: 316.0540466308594
INFO:root:Train (Epoch 359): Loss/seq after 01750 batchs: 315.2178649902344
INFO:root:Train (Epoch 359): Loss/seq after 01800 batchs: 314.31036376953125
INFO:root:Train (Epoch 359): Loss/seq after 01850 batchs: 313.3141174316406
INFO:root:Train (Epoch 359): Loss/seq after 01900 batchs: 312.9397277832031
INFO:root:Train (Epoch 359): Loss/seq after 01950 batchs: 312.9775085449219
INFO:root:Train (Epoch 359): Loss/seq after 02000 batchs: 315.1375427246094
INFO:root:Train (Epoch 359): Loss/seq after 02050 batchs: 315.62176513671875
INFO:root:Train (Epoch 359): Loss/seq after 02100 batchs: 315.7803955078125
INFO:root:Train (Epoch 359): Loss/seq after 02150 batchs: 315.8912658691406
INFO:root:Train (Epoch 359): Loss/seq after 02200 batchs: 315.4958801269531
INFO:root:Train (Epoch 359): Loss/seq after 02250 batchs: 314.8896789550781
INFO:root:Train (Epoch 359): Loss/seq after 02300 batchs: 312.8992919921875
INFO:root:Train (Epoch 359): Loss/seq after 02350 batchs: 311.1127014160156
INFO:root:Train (Epoch 359): Loss/seq after 02400 batchs: 311.0618896484375
INFO:root:Train (Epoch 359): Loss/seq after 02450 batchs: 308.8218688964844
INFO:root:Train (Epoch 359): Loss/seq after 02500 batchs: 303.8292236328125
INFO:root:Train (Epoch 359): Loss/seq after 02550 batchs: 299.5796813964844
INFO:root:Train (Epoch 359): Loss/seq after 02600 batchs: 296.07049560546875
INFO:root:Train (Epoch 359): Loss/seq after 02650 batchs: 292.993408203125
INFO:root:Train (Epoch 359): Loss/seq after 02700 batchs: 291.05523681640625
INFO:root:Train (Epoch 359): Loss/seq after 02750 batchs: 287.7422180175781
INFO:root:Train (Epoch 359): Loss/seq after 02800 batchs: 286.25738525390625
INFO:root:Train (Epoch 359): Loss/seq after 02850 batchs: 286.1427917480469
INFO:root:Train (Epoch 359): Loss/seq after 02900 batchs: 286.10076904296875
INFO:root:Train (Epoch 359): Loss/seq after 02950 batchs: 287.21197509765625
INFO:root:Train (Epoch 359): Loss/seq after 03000 batchs: 290.1285095214844
INFO:root:Train (Epoch 359): Loss/seq after 03050 batchs: 292.10162353515625
INFO:root:Train (Epoch 359): Loss/seq after 03100 batchs: 293.25701904296875
INFO:root:Train (Epoch 359): Loss/seq after 03150 batchs: 293.3068542480469
INFO:root:Train (Epoch 359): Loss/seq after 03200 batchs: 293.3009948730469
INFO:root:Train (Epoch 359): Loss/seq after 03250 batchs: 293.0516052246094
INFO:root:Train (Epoch 359): Loss/seq after 03300 batchs: 292.6392822265625
INFO:root:Train (Epoch 359): Loss/seq after 03350 batchs: 291.3459777832031
INFO:root:Train (Epoch 359): Loss/seq after 03400 batchs: 289.8331604003906
INFO:root:Train (Epoch 359): Loss/seq after 03450 batchs: 289.0623779296875
INFO:root:Train (Epoch 359): Loss/seq after 03500 batchs: 289.9668273925781
INFO:root:Train (Epoch 359): Loss/seq after 03550 batchs: 288.9131164550781
INFO:root:Train (Epoch 359): Loss/seq after 03600 batchs: 291.25494384765625
INFO:root:Train (Epoch 359): Loss/seq after 03650 batchs: 290.32464599609375
INFO:root:Train (Epoch 359): Loss/seq after 03700 batchs: 291.5951843261719
INFO:root:Train (Epoch 359): Loss/seq after 03750 batchs: 294.4408874511719
INFO:root:Train (Epoch 359): Loss/seq after 03800 batchs: 294.61871337890625
INFO:root:Train (Epoch 359): Loss/seq after 03850 batchs: 294.3208923339844
INFO:root:Train (Epoch 359): Loss/seq after 03900 batchs: 294.90606689453125
INFO:root:Train (Epoch 359): Loss/seq after 03950 batchs: 296.4061279296875
INFO:root:Train (Epoch 359): Loss/seq after 04000 batchs: 295.03350830078125
INFO:root:Train (Epoch 359): Loss/seq after 04050 batchs: 293.57568359375
INFO:root:Train (Epoch 359): Loss/seq after 04100 batchs: 292.70318603515625
INFO:root:Train (Epoch 359): Loss/seq after 04150 batchs: 292.6790466308594
INFO:root:Train (Epoch 359): Loss/seq after 04200 batchs: 292.31005859375
INFO:root:Train (Epoch 359): Loss/seq after 04250 batchs: 291.4860534667969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 359): Loss/seq after 00000 batches: 235.85409545898438
INFO:root:# Valid (Epoch 359): Loss/seq after 00050 batches: 625.490966796875
INFO:root:# Valid (Epoch 359): Loss/seq after 00100 batches: 589.44091796875
INFO:root:# Valid (Epoch 359): Loss/seq after 00150 batches: 444.7730712890625
INFO:root:# Valid (Epoch 359): Loss/seq after 00200 batches: 416.2244873046875
INFO:root:Artifacts: Make stick videos for epoch 359
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_359_on_20220424_015150.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_359_index_381_on_20220424_015150.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 360): Loss/seq after 00000 batchs: 568.7069702148438
INFO:root:Train (Epoch 360): Loss/seq after 00050 batchs: 396.49603271484375
INFO:root:Train (Epoch 360): Loss/seq after 00100 batchs: 402.68756103515625
INFO:root:Train (Epoch 360): Loss/seq after 00150 batchs: 381.7138977050781
INFO:root:Train (Epoch 360): Loss/seq after 00200 batchs: 442.2965393066406
INFO:root:Train (Epoch 360): Loss/seq after 00250 batchs: 469.2443542480469
INFO:root:Train (Epoch 360): Loss/seq after 00300 batchs: 483.6028747558594
INFO:root:Train (Epoch 360): Loss/seq after 00350 batchs: 459.78106689453125
INFO:root:Train (Epoch 360): Loss/seq after 00400 batchs: 449.8849792480469
INFO:root:Train (Epoch 360): Loss/seq after 00450 batchs: 462.73419189453125
INFO:root:Train (Epoch 360): Loss/seq after 00500 batchs: 446.2039794921875
INFO:root:Train (Epoch 360): Loss/seq after 00550 batchs: 437.7577819824219
INFO:root:Train (Epoch 360): Loss/seq after 00600 batchs: 422.5198974609375
INFO:root:Train (Epoch 360): Loss/seq after 00650 batchs: 404.5592346191406
INFO:root:Train (Epoch 360): Loss/seq after 00700 batchs: 388.86328125
INFO:root:Train (Epoch 360): Loss/seq after 00750 batchs: 382.57958984375
INFO:root:Train (Epoch 360): Loss/seq after 00800 batchs: 381.45684814453125
INFO:root:Train (Epoch 360): Loss/seq after 00850 batchs: 369.0126037597656
INFO:root:Train (Epoch 360): Loss/seq after 00900 batchs: 359.5164794921875
INFO:root:Train (Epoch 360): Loss/seq after 00950 batchs: 359.21270751953125
INFO:root:Train (Epoch 360): Loss/seq after 01000 batchs: 352.1270751953125
INFO:root:Train (Epoch 360): Loss/seq after 01050 batchs: 348.5054626464844
INFO:root:Train (Epoch 360): Loss/seq after 01100 batchs: 341.119873046875
INFO:root:Train (Epoch 360): Loss/seq after 01150 batchs: 331.9389953613281
INFO:root:Train (Epoch 360): Loss/seq after 01200 batchs: 330.7451171875
INFO:root:Train (Epoch 360): Loss/seq after 01250 batchs: 329.748779296875
INFO:root:Train (Epoch 360): Loss/seq after 01300 batchs: 322.88861083984375
INFO:root:Train (Epoch 360): Loss/seq after 01350 batchs: 316.1500549316406
INFO:root:Train (Epoch 360): Loss/seq after 01400 batchs: 317.0069885253906
INFO:root:Train (Epoch 360): Loss/seq after 01450 batchs: 318.9228210449219
INFO:root:Train (Epoch 360): Loss/seq after 01500 batchs: 323.42694091796875
INFO:root:Train (Epoch 360): Loss/seq after 01550 batchs: 323.8648681640625
INFO:root:Train (Epoch 360): Loss/seq after 01600 batchs: 322.6798400878906
INFO:root:Train (Epoch 360): Loss/seq after 01650 batchs: 321.2237243652344
INFO:root:Train (Epoch 360): Loss/seq after 01700 batchs: 321.96551513671875
INFO:root:Train (Epoch 360): Loss/seq after 01750 batchs: 320.8879699707031
INFO:root:Train (Epoch 360): Loss/seq after 01800 batchs: 319.78167724609375
INFO:root:Train (Epoch 360): Loss/seq after 01850 batchs: 318.6245422363281
INFO:root:Train (Epoch 360): Loss/seq after 01900 batchs: 317.98773193359375
INFO:root:Train (Epoch 360): Loss/seq after 01950 batchs: 317.7918395996094
INFO:root:Train (Epoch 360): Loss/seq after 02000 batchs: 319.7559814453125
INFO:root:Train (Epoch 360): Loss/seq after 02050 batchs: 320.04925537109375
INFO:root:Train (Epoch 360): Loss/seq after 02100 batchs: 320.11334228515625
INFO:root:Train (Epoch 360): Loss/seq after 02150 batchs: 320.1387634277344
INFO:root:Train (Epoch 360): Loss/seq after 02200 batchs: 319.5613708496094
INFO:root:Train (Epoch 360): Loss/seq after 02250 batchs: 318.8763732910156
INFO:root:Train (Epoch 360): Loss/seq after 02300 batchs: 316.7217102050781
INFO:root:Train (Epoch 360): Loss/seq after 02350 batchs: 314.8262023925781
INFO:root:Train (Epoch 360): Loss/seq after 02400 batchs: 314.422607421875
INFO:root:Train (Epoch 360): Loss/seq after 02450 batchs: 312.05084228515625
INFO:root:Train (Epoch 360): Loss/seq after 02500 batchs: 306.9510192871094
INFO:root:Train (Epoch 360): Loss/seq after 02550 batchs: 302.6139831542969
INFO:root:Train (Epoch 360): Loss/seq after 02600 batchs: 299.0021667480469
INFO:root:Train (Epoch 360): Loss/seq after 02650 batchs: 295.7732849121094
INFO:root:Train (Epoch 360): Loss/seq after 02700 batchs: 293.6507263183594
INFO:root:Train (Epoch 360): Loss/seq after 02750 batchs: 290.41888427734375
INFO:root:Train (Epoch 360): Loss/seq after 02800 batchs: 288.8963623046875
INFO:root:Train (Epoch 360): Loss/seq after 02850 batchs: 288.6949157714844
INFO:root:Train (Epoch 360): Loss/seq after 02900 batchs: 288.8500061035156
INFO:root:Train (Epoch 360): Loss/seq after 02950 batchs: 289.7808837890625
INFO:root:Train (Epoch 360): Loss/seq after 03000 batchs: 292.44580078125
INFO:root:Train (Epoch 360): Loss/seq after 03050 batchs: 293.7596740722656
INFO:root:Train (Epoch 360): Loss/seq after 03100 batchs: 294.67291259765625
INFO:root:Train (Epoch 360): Loss/seq after 03150 batchs: 294.1907653808594
INFO:root:Train (Epoch 360): Loss/seq after 03200 batchs: 294.1615905761719
INFO:root:Train (Epoch 360): Loss/seq after 03250 batchs: 293.9520568847656
INFO:root:Train (Epoch 360): Loss/seq after 03300 batchs: 293.147705078125
INFO:root:Train (Epoch 360): Loss/seq after 03350 batchs: 291.6252136230469
INFO:root:Train (Epoch 360): Loss/seq after 03400 batchs: 290.0309753417969
INFO:root:Train (Epoch 360): Loss/seq after 03450 batchs: 289.10198974609375
INFO:root:Train (Epoch 360): Loss/seq after 03500 batchs: 289.85406494140625
INFO:root:Train (Epoch 360): Loss/seq after 03550 batchs: 288.858642578125
INFO:root:Train (Epoch 360): Loss/seq after 03600 batchs: 291.0371398925781
INFO:root:Train (Epoch 360): Loss/seq after 03650 batchs: 289.82763671875
INFO:root:Train (Epoch 360): Loss/seq after 03700 batchs: 291.2069396972656
INFO:root:Train (Epoch 360): Loss/seq after 03750 batchs: 294.2123718261719
INFO:root:Train (Epoch 360): Loss/seq after 03800 batchs: 294.3886413574219
INFO:root:Train (Epoch 360): Loss/seq after 03850 batchs: 294.1004943847656
INFO:root:Train (Epoch 360): Loss/seq after 03900 batchs: 294.91485595703125
INFO:root:Train (Epoch 360): Loss/seq after 03950 batchs: 296.49835205078125
INFO:root:Train (Epoch 360): Loss/seq after 04000 batchs: 295.1318359375
INFO:root:Train (Epoch 360): Loss/seq after 04050 batchs: 293.6160888671875
INFO:root:Train (Epoch 360): Loss/seq after 04100 batchs: 292.6828308105469
INFO:root:Train (Epoch 360): Loss/seq after 04150 batchs: 292.5614929199219
INFO:root:Train (Epoch 360): Loss/seq after 04200 batchs: 292.1925354003906
INFO:root:Train (Epoch 360): Loss/seq after 04250 batchs: 291.4044494628906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 360): Loss/seq after 00000 batches: 285.4874572753906
INFO:root:# Valid (Epoch 360): Loss/seq after 00050 batches: 682.3397216796875
INFO:root:# Valid (Epoch 360): Loss/seq after 00100 batches: 705.451904296875
INFO:root:# Valid (Epoch 360): Loss/seq after 00150 batches: 523.4158325195312
INFO:root:# Valid (Epoch 360): Loss/seq after 00200 batches: 480.5174865722656
INFO:root:Artifacts: Make stick videos for epoch 360
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_360_on_20220424_015629.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_360_index_93_on_20220424_015629.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 361): Loss/seq after 00000 batchs: 333.65301513671875
INFO:root:Train (Epoch 361): Loss/seq after 00050 batchs: 396.2570495605469
INFO:root:Train (Epoch 361): Loss/seq after 00100 batchs: 391.48211669921875
INFO:root:Train (Epoch 361): Loss/seq after 00150 batchs: 368.1439514160156
INFO:root:Train (Epoch 361): Loss/seq after 00200 batchs: 415.3183898925781
INFO:root:Train (Epoch 361): Loss/seq after 00250 batchs: 435.72137451171875
INFO:root:Train (Epoch 361): Loss/seq after 00300 batchs: 455.63226318359375
INFO:root:Train (Epoch 361): Loss/seq after 00350 batchs: 437.4006042480469
INFO:root:Train (Epoch 361): Loss/seq after 00400 batchs: 427.96832275390625
INFO:root:Train (Epoch 361): Loss/seq after 00450 batchs: 443.66876220703125
INFO:root:Train (Epoch 361): Loss/seq after 00500 batchs: 429.4204406738281
INFO:root:Train (Epoch 361): Loss/seq after 00550 batchs: 423.2139892578125
INFO:root:Train (Epoch 361): Loss/seq after 00600 batchs: 409.408935546875
INFO:root:Train (Epoch 361): Loss/seq after 00650 batchs: 393.1120300292969
INFO:root:Train (Epoch 361): Loss/seq after 00700 batchs: 375.9077453613281
INFO:root:Train (Epoch 361): Loss/seq after 00750 batchs: 369.6393127441406
INFO:root:Train (Epoch 361): Loss/seq after 00800 batchs: 369.71685791015625
INFO:root:Train (Epoch 361): Loss/seq after 00850 batchs: 357.6037292480469
INFO:root:Train (Epoch 361): Loss/seq after 00900 batchs: 348.5208435058594
INFO:root:Train (Epoch 361): Loss/seq after 00950 batchs: 347.6020202636719
INFO:root:Train (Epoch 361): Loss/seq after 01000 batchs: 341.2125244140625
INFO:root:Train (Epoch 361): Loss/seq after 01050 batchs: 334.8646240234375
INFO:root:Train (Epoch 361): Loss/seq after 01100 batchs: 327.03167724609375
INFO:root:Train (Epoch 361): Loss/seq after 01150 batchs: 318.5968017578125
INFO:root:Train (Epoch 361): Loss/seq after 01200 batchs: 317.4109802246094
INFO:root:Train (Epoch 361): Loss/seq after 01250 batchs: 316.31658935546875
INFO:root:Train (Epoch 361): Loss/seq after 01300 batchs: 309.5977478027344
INFO:root:Train (Epoch 361): Loss/seq after 01350 batchs: 303.0500793457031
INFO:root:Train (Epoch 361): Loss/seq after 01400 batchs: 303.2478332519531
INFO:root:Train (Epoch 361): Loss/seq after 01450 batchs: 305.18841552734375
INFO:root:Train (Epoch 361): Loss/seq after 01500 batchs: 310.58026123046875
INFO:root:Train (Epoch 361): Loss/seq after 01550 batchs: 311.60986328125
INFO:root:Train (Epoch 361): Loss/seq after 01600 batchs: 310.9671936035156
INFO:root:Train (Epoch 361): Loss/seq after 01650 batchs: 309.84613037109375
INFO:root:Train (Epoch 361): Loss/seq after 01700 batchs: 310.8865051269531
INFO:root:Train (Epoch 361): Loss/seq after 01750 batchs: 310.55926513671875
INFO:root:Train (Epoch 361): Loss/seq after 01800 batchs: 309.6886901855469
INFO:root:Train (Epoch 361): Loss/seq after 01850 batchs: 308.8476257324219
INFO:root:Train (Epoch 361): Loss/seq after 01900 batchs: 308.6273498535156
INFO:root:Train (Epoch 361): Loss/seq after 01950 batchs: 308.8837585449219
INFO:root:Train (Epoch 361): Loss/seq after 02000 batchs: 311.1202697753906
INFO:root:Train (Epoch 361): Loss/seq after 02050 batchs: 311.767822265625
INFO:root:Train (Epoch 361): Loss/seq after 02100 batchs: 311.69000244140625
INFO:root:Train (Epoch 361): Loss/seq after 02150 batchs: 311.92901611328125
INFO:root:Train (Epoch 361): Loss/seq after 02200 batchs: 311.697998046875
INFO:root:Train (Epoch 361): Loss/seq after 02250 batchs: 311.2666931152344
INFO:root:Train (Epoch 361): Loss/seq after 02300 batchs: 309.2039489746094
INFO:root:Train (Epoch 361): Loss/seq after 02350 batchs: 307.6023254394531
INFO:root:Train (Epoch 361): Loss/seq after 02400 batchs: 307.7764892578125
INFO:root:Train (Epoch 361): Loss/seq after 02450 batchs: 305.54443359375
INFO:root:Train (Epoch 361): Loss/seq after 02500 batchs: 300.5786437988281
INFO:root:Train (Epoch 361): Loss/seq after 02550 batchs: 296.3446044921875
INFO:root:Train (Epoch 361): Loss/seq after 02600 batchs: 292.9530029296875
INFO:root:Train (Epoch 361): Loss/seq after 02650 batchs: 289.8482360839844
INFO:root:Train (Epoch 361): Loss/seq after 02700 batchs: 287.9211730957031
INFO:root:Train (Epoch 361): Loss/seq after 02750 batchs: 284.8873291015625
INFO:root:Train (Epoch 361): Loss/seq after 02800 batchs: 283.4962158203125
INFO:root:Train (Epoch 361): Loss/seq after 02850 batchs: 283.3807373046875
INFO:root:Train (Epoch 361): Loss/seq after 02900 batchs: 283.78582763671875
INFO:root:Train (Epoch 361): Loss/seq after 02950 batchs: 284.89019775390625
INFO:root:Train (Epoch 361): Loss/seq after 03000 batchs: 287.5598449707031
INFO:root:Train (Epoch 361): Loss/seq after 03050 batchs: 288.7516784667969
INFO:root:Train (Epoch 361): Loss/seq after 03100 batchs: 289.9479064941406
INFO:root:Train (Epoch 361): Loss/seq after 03150 batchs: 289.42315673828125
INFO:root:Train (Epoch 361): Loss/seq after 03200 batchs: 289.1153869628906
INFO:root:Train (Epoch 361): Loss/seq after 03250 batchs: 288.56317138671875
INFO:root:Train (Epoch 361): Loss/seq after 03300 batchs: 288.12725830078125
INFO:root:Train (Epoch 361): Loss/seq after 03350 batchs: 286.92047119140625
INFO:root:Train (Epoch 361): Loss/seq after 03400 batchs: 285.39215087890625
INFO:root:Train (Epoch 361): Loss/seq after 03450 batchs: 284.54388427734375
INFO:root:Train (Epoch 361): Loss/seq after 03500 batchs: 285.1961669921875
INFO:root:Train (Epoch 361): Loss/seq after 03550 batchs: 284.21051025390625
INFO:root:Train (Epoch 361): Loss/seq after 03600 batchs: 286.5081481933594
INFO:root:Train (Epoch 361): Loss/seq after 03650 batchs: 285.66925048828125
INFO:root:Train (Epoch 361): Loss/seq after 03700 batchs: 286.85369873046875
INFO:root:Train (Epoch 361): Loss/seq after 03750 batchs: 289.6888427734375
INFO:root:Train (Epoch 361): Loss/seq after 03800 batchs: 290.03515625
INFO:root:Train (Epoch 361): Loss/seq after 03850 batchs: 289.84930419921875
INFO:root:Train (Epoch 361): Loss/seq after 03900 batchs: 290.7591247558594
INFO:root:Train (Epoch 361): Loss/seq after 03950 batchs: 292.3584289550781
INFO:root:Train (Epoch 361): Loss/seq after 04000 batchs: 291.0340270996094
INFO:root:Train (Epoch 361): Loss/seq after 04050 batchs: 289.6171875
INFO:root:Train (Epoch 361): Loss/seq after 04100 batchs: 288.7086486816406
INFO:root:Train (Epoch 361): Loss/seq after 04150 batchs: 288.6347351074219
INFO:root:Train (Epoch 361): Loss/seq after 04200 batchs: 288.3390808105469
INFO:root:Train (Epoch 361): Loss/seq after 04250 batchs: 287.57196044921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 361): Loss/seq after 00000 batches: 296.8221740722656
INFO:root:# Valid (Epoch 361): Loss/seq after 00050 batches: 672.3770141601562
INFO:root:# Valid (Epoch 361): Loss/seq after 00100 batches: 661.8217163085938
INFO:root:# Valid (Epoch 361): Loss/seq after 00150 batches: 496.27618408203125
INFO:root:# Valid (Epoch 361): Loss/seq after 00200 batches: 460.9154052734375
INFO:root:Artifacts: Make stick videos for epoch 361
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_361_on_20220424_020118.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_361_index_1116_on_20220424_020118.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 362): Loss/seq after 00000 batchs: 487.3287353515625
INFO:root:Train (Epoch 362): Loss/seq after 00050 batchs: 367.820556640625
INFO:root:Train (Epoch 362): Loss/seq after 00100 batchs: 357.57281494140625
INFO:root:Train (Epoch 362): Loss/seq after 00150 batchs: 345.4267578125
INFO:root:Train (Epoch 362): Loss/seq after 00200 batchs: 394.2914123535156
INFO:root:Train (Epoch 362): Loss/seq after 00250 batchs: 411.18121337890625
INFO:root:Train (Epoch 362): Loss/seq after 00300 batchs: 432.1274719238281
INFO:root:Train (Epoch 362): Loss/seq after 00350 batchs: 414.5306396484375
INFO:root:Train (Epoch 362): Loss/seq after 00400 batchs: 408.2490539550781
INFO:root:Train (Epoch 362): Loss/seq after 00450 batchs: 425.32720947265625
INFO:root:Train (Epoch 362): Loss/seq after 00500 batchs: 414.0389404296875
INFO:root:Train (Epoch 362): Loss/seq after 00550 batchs: 408.3954772949219
INFO:root:Train (Epoch 362): Loss/seq after 00600 batchs: 394.42626953125
INFO:root:Train (Epoch 362): Loss/seq after 00650 batchs: 377.7294616699219
INFO:root:Train (Epoch 362): Loss/seq after 00700 batchs: 361.5718688964844
INFO:root:Train (Epoch 362): Loss/seq after 00750 batchs: 355.6386413574219
INFO:root:Train (Epoch 362): Loss/seq after 00800 batchs: 355.9798889160156
INFO:root:Train (Epoch 362): Loss/seq after 00850 batchs: 345.0111083984375
INFO:root:Train (Epoch 362): Loss/seq after 00900 batchs: 337.08648681640625
INFO:root:Train (Epoch 362): Loss/seq after 00950 batchs: 336.5213928222656
INFO:root:Train (Epoch 362): Loss/seq after 01000 batchs: 332.338623046875
INFO:root:Train (Epoch 362): Loss/seq after 01050 batchs: 327.54302978515625
INFO:root:Train (Epoch 362): Loss/seq after 01100 batchs: 320.43231201171875
INFO:root:Train (Epoch 362): Loss/seq after 01150 batchs: 312.00457763671875
INFO:root:Train (Epoch 362): Loss/seq after 01200 batchs: 311.7558898925781
INFO:root:Train (Epoch 362): Loss/seq after 01250 batchs: 311.55328369140625
INFO:root:Train (Epoch 362): Loss/seq after 01300 batchs: 305.18731689453125
INFO:root:Train (Epoch 362): Loss/seq after 01350 batchs: 298.6253356933594
INFO:root:Train (Epoch 362): Loss/seq after 01400 batchs: 300.2284240722656
INFO:root:Train (Epoch 362): Loss/seq after 01450 batchs: 302.8036804199219
INFO:root:Train (Epoch 362): Loss/seq after 01500 batchs: 308.0455322265625
INFO:root:Train (Epoch 362): Loss/seq after 01550 batchs: 309.57086181640625
INFO:root:Train (Epoch 362): Loss/seq after 01600 batchs: 308.763427734375
INFO:root:Train (Epoch 362): Loss/seq after 01650 batchs: 307.7726135253906
INFO:root:Train (Epoch 362): Loss/seq after 01700 batchs: 308.7855529785156
INFO:root:Train (Epoch 362): Loss/seq after 01750 batchs: 308.188720703125
INFO:root:Train (Epoch 362): Loss/seq after 01800 batchs: 307.4097900390625
INFO:root:Train (Epoch 362): Loss/seq after 01850 batchs: 306.6332092285156
INFO:root:Train (Epoch 362): Loss/seq after 01900 batchs: 306.4585876464844
INFO:root:Train (Epoch 362): Loss/seq after 01950 batchs: 306.9888000488281
INFO:root:Train (Epoch 362): Loss/seq after 02000 batchs: 309.2513122558594
INFO:root:Train (Epoch 362): Loss/seq after 02050 batchs: 310.12738037109375
INFO:root:Train (Epoch 362): Loss/seq after 02100 batchs: 310.124267578125
INFO:root:Train (Epoch 362): Loss/seq after 02150 batchs: 310.4079284667969
INFO:root:Train (Epoch 362): Loss/seq after 02200 batchs: 309.99468994140625
INFO:root:Train (Epoch 362): Loss/seq after 02250 batchs: 309.446533203125
INFO:root:Train (Epoch 362): Loss/seq after 02300 batchs: 307.4659423828125
INFO:root:Train (Epoch 362): Loss/seq after 02350 batchs: 305.79522705078125
INFO:root:Train (Epoch 362): Loss/seq after 02400 batchs: 305.59649658203125
INFO:root:Train (Epoch 362): Loss/seq after 02450 batchs: 303.371826171875
INFO:root:Train (Epoch 362): Loss/seq after 02500 batchs: 298.4775085449219
INFO:root:Train (Epoch 362): Loss/seq after 02550 batchs: 294.6444091796875
INFO:root:Train (Epoch 362): Loss/seq after 02600 batchs: 291.4967346191406
INFO:root:Train (Epoch 362): Loss/seq after 02650 batchs: 288.7667236328125
INFO:root:Train (Epoch 362): Loss/seq after 02700 batchs: 286.9130859375
INFO:root:Train (Epoch 362): Loss/seq after 02750 batchs: 284.1031799316406
INFO:root:Train (Epoch 362): Loss/seq after 02800 batchs: 282.8671569824219
INFO:root:Train (Epoch 362): Loss/seq after 02850 batchs: 282.5830993652344
INFO:root:Train (Epoch 362): Loss/seq after 02900 batchs: 282.9045104980469
INFO:root:Train (Epoch 362): Loss/seq after 02950 batchs: 283.9984130859375
INFO:root:Train (Epoch 362): Loss/seq after 03000 batchs: 286.7605895996094
INFO:root:Train (Epoch 362): Loss/seq after 03050 batchs: 287.989990234375
INFO:root:Train (Epoch 362): Loss/seq after 03100 batchs: 289.55645751953125
INFO:root:Train (Epoch 362): Loss/seq after 03150 batchs: 289.4017333984375
INFO:root:Train (Epoch 362): Loss/seq after 03200 batchs: 289.2386169433594
INFO:root:Train (Epoch 362): Loss/seq after 03250 batchs: 288.7087097167969
INFO:root:Train (Epoch 362): Loss/seq after 03300 batchs: 288.2916564941406
INFO:root:Train (Epoch 362): Loss/seq after 03350 batchs: 287.1407775878906
INFO:root:Train (Epoch 362): Loss/seq after 03400 batchs: 285.5636291503906
INFO:root:Train (Epoch 362): Loss/seq after 03450 batchs: 284.6714172363281
INFO:root:Train (Epoch 362): Loss/seq after 03500 batchs: 285.60296630859375
INFO:root:Train (Epoch 362): Loss/seq after 03550 batchs: 284.81219482421875
INFO:root:Train (Epoch 362): Loss/seq after 03600 batchs: 287.1115417480469
INFO:root:Train (Epoch 362): Loss/seq after 03650 batchs: 286.0748291015625
INFO:root:Train (Epoch 362): Loss/seq after 03700 batchs: 287.46209716796875
INFO:root:Train (Epoch 362): Loss/seq after 03750 batchs: 290.4693298339844
INFO:root:Train (Epoch 362): Loss/seq after 03800 batchs: 290.7208557128906
INFO:root:Train (Epoch 362): Loss/seq after 03850 batchs: 290.53594970703125
INFO:root:Train (Epoch 362): Loss/seq after 03900 batchs: 292.28204345703125
INFO:root:Train (Epoch 362): Loss/seq after 03950 batchs: 294.6951904296875
INFO:root:Train (Epoch 362): Loss/seq after 04000 batchs: 293.39422607421875
INFO:root:Train (Epoch 362): Loss/seq after 04050 batchs: 291.9254455566406
INFO:root:Train (Epoch 362): Loss/seq after 04100 batchs: 291.06341552734375
INFO:root:Train (Epoch 362): Loss/seq after 04150 batchs: 291.07415771484375
INFO:root:Train (Epoch 362): Loss/seq after 04200 batchs: 290.8028869628906
INFO:root:Train (Epoch 362): Loss/seq after 04250 batchs: 290.0945739746094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 362): Loss/seq after 00000 batches: 319.38775634765625
INFO:root:# Valid (Epoch 362): Loss/seq after 00050 batches: 668.120361328125
INFO:root:# Valid (Epoch 362): Loss/seq after 00100 batches: 721.1314697265625
INFO:root:# Valid (Epoch 362): Loss/seq after 00150 batches: 532.883056640625
INFO:root:# Valid (Epoch 362): Loss/seq after 00200 batches: 483.878173828125
INFO:root:Artifacts: Make stick videos for epoch 362
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_362_on_20220424_020618.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_362_index_381_on_20220424_020618.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 363): Loss/seq after 00000 batchs: 427.2574157714844
INFO:root:Train (Epoch 363): Loss/seq after 00050 batchs: 402.6067199707031
INFO:root:Train (Epoch 363): Loss/seq after 00100 batchs: 425.1505432128906
INFO:root:Train (Epoch 363): Loss/seq after 00150 batchs: 392.1910095214844
INFO:root:Train (Epoch 363): Loss/seq after 00200 batchs: 438.95587158203125
INFO:root:Train (Epoch 363): Loss/seq after 00250 batchs: 459.8712463378906
INFO:root:Train (Epoch 363): Loss/seq after 00300 batchs: 471.54119873046875
INFO:root:Train (Epoch 363): Loss/seq after 00350 batchs: 449.9237365722656
INFO:root:Train (Epoch 363): Loss/seq after 00400 batchs: 437.9725036621094
INFO:root:Train (Epoch 363): Loss/seq after 00450 batchs: 452.48492431640625
INFO:root:Train (Epoch 363): Loss/seq after 00500 batchs: 438.2980041503906
INFO:root:Train (Epoch 363): Loss/seq after 00550 batchs: 430.38116455078125
INFO:root:Train (Epoch 363): Loss/seq after 00600 batchs: 414.4095458984375
INFO:root:Train (Epoch 363): Loss/seq after 00650 batchs: 396.6938781738281
INFO:root:Train (Epoch 363): Loss/seq after 00700 batchs: 379.1702575683594
INFO:root:Train (Epoch 363): Loss/seq after 00750 batchs: 371.2279357910156
INFO:root:Train (Epoch 363): Loss/seq after 00800 batchs: 371.54541015625
INFO:root:Train (Epoch 363): Loss/seq after 00850 batchs: 359.3800354003906
INFO:root:Train (Epoch 363): Loss/seq after 00900 batchs: 350.2430725097656
INFO:root:Train (Epoch 363): Loss/seq after 00950 batchs: 348.32073974609375
INFO:root:Train (Epoch 363): Loss/seq after 01000 batchs: 342.0621337890625
INFO:root:Train (Epoch 363): Loss/seq after 01050 batchs: 334.9836730957031
INFO:root:Train (Epoch 363): Loss/seq after 01100 batchs: 327.1788330078125
INFO:root:Train (Epoch 363): Loss/seq after 01150 batchs: 318.5555419921875
INFO:root:Train (Epoch 363): Loss/seq after 01200 batchs: 316.9838562011719
INFO:root:Train (Epoch 363): Loss/seq after 01250 batchs: 315.79150390625
INFO:root:Train (Epoch 363): Loss/seq after 01300 batchs: 309.10040283203125
INFO:root:Train (Epoch 363): Loss/seq after 01350 batchs: 302.62548828125
INFO:root:Train (Epoch 363): Loss/seq after 01400 batchs: 303.8211364746094
INFO:root:Train (Epoch 363): Loss/seq after 01450 batchs: 305.85986328125
INFO:root:Train (Epoch 363): Loss/seq after 01500 batchs: 311.4632873535156
INFO:root:Train (Epoch 363): Loss/seq after 01550 batchs: 312.2962341308594
INFO:root:Train (Epoch 363): Loss/seq after 01600 batchs: 311.31658935546875
INFO:root:Train (Epoch 363): Loss/seq after 01650 batchs: 310.32635498046875
INFO:root:Train (Epoch 363): Loss/seq after 01700 batchs: 311.12396240234375
INFO:root:Train (Epoch 363): Loss/seq after 01750 batchs: 310.6435852050781
INFO:root:Train (Epoch 363): Loss/seq after 01800 batchs: 309.7535400390625
INFO:root:Train (Epoch 363): Loss/seq after 01850 batchs: 308.72283935546875
INFO:root:Train (Epoch 363): Loss/seq after 01900 batchs: 308.321533203125
INFO:root:Train (Epoch 363): Loss/seq after 01950 batchs: 308.7123107910156
INFO:root:Train (Epoch 363): Loss/seq after 02000 batchs: 310.91741943359375
INFO:root:Train (Epoch 363): Loss/seq after 02050 batchs: 311.6021423339844
INFO:root:Train (Epoch 363): Loss/seq after 02100 batchs: 311.5616760253906
INFO:root:Train (Epoch 363): Loss/seq after 02150 batchs: 311.6960754394531
INFO:root:Train (Epoch 363): Loss/seq after 02200 batchs: 311.3349304199219
INFO:root:Train (Epoch 363): Loss/seq after 02250 batchs: 311.0828857421875
INFO:root:Train (Epoch 363): Loss/seq after 02300 batchs: 309.3681945800781
INFO:root:Train (Epoch 363): Loss/seq after 02350 batchs: 307.5724792480469
INFO:root:Train (Epoch 363): Loss/seq after 02400 batchs: 307.38702392578125
INFO:root:Train (Epoch 363): Loss/seq after 02450 batchs: 305.2002258300781
INFO:root:Train (Epoch 363): Loss/seq after 02500 batchs: 300.26849365234375
INFO:root:Train (Epoch 363): Loss/seq after 02550 batchs: 296.0369567871094
INFO:root:Train (Epoch 363): Loss/seq after 02600 batchs: 292.59442138671875
INFO:root:Train (Epoch 363): Loss/seq after 02650 batchs: 289.58245849609375
INFO:root:Train (Epoch 363): Loss/seq after 02700 batchs: 287.6944580078125
INFO:root:Train (Epoch 363): Loss/seq after 02750 batchs: 284.53985595703125
INFO:root:Train (Epoch 363): Loss/seq after 02800 batchs: 282.94964599609375
INFO:root:Train (Epoch 363): Loss/seq after 02850 batchs: 282.7955017089844
INFO:root:Train (Epoch 363): Loss/seq after 02900 batchs: 282.9492492675781
INFO:root:Train (Epoch 363): Loss/seq after 02950 batchs: 284.014404296875
INFO:root:Train (Epoch 363): Loss/seq after 03000 batchs: 286.6138916015625
INFO:root:Train (Epoch 363): Loss/seq after 03050 batchs: 287.8775329589844
INFO:root:Train (Epoch 363): Loss/seq after 03100 batchs: 289.5883483886719
INFO:root:Train (Epoch 363): Loss/seq after 03150 batchs: 290.42425537109375
INFO:root:Train (Epoch 363): Loss/seq after 03200 batchs: 290.27777099609375
INFO:root:Train (Epoch 363): Loss/seq after 03250 batchs: 289.5828552246094
INFO:root:Train (Epoch 363): Loss/seq after 03300 batchs: 289.348876953125
INFO:root:Train (Epoch 363): Loss/seq after 03350 batchs: 288.3069152832031
INFO:root:Train (Epoch 363): Loss/seq after 03400 batchs: 286.7145690917969
INFO:root:Train (Epoch 363): Loss/seq after 03450 batchs: 285.85205078125
INFO:root:Train (Epoch 363): Loss/seq after 03500 batchs: 287.54278564453125
INFO:root:Train (Epoch 363): Loss/seq after 03550 batchs: 286.8063049316406
INFO:root:Train (Epoch 363): Loss/seq after 03600 batchs: 289.0948181152344
INFO:root:Train (Epoch 363): Loss/seq after 03650 batchs: 288.098388671875
INFO:root:Train (Epoch 363): Loss/seq after 03700 batchs: 289.6819763183594
INFO:root:Train (Epoch 363): Loss/seq after 03750 batchs: 292.5563049316406
INFO:root:Train (Epoch 363): Loss/seq after 03800 batchs: 292.7479248046875
INFO:root:Train (Epoch 363): Loss/seq after 03850 batchs: 292.4913635253906
INFO:root:Train (Epoch 363): Loss/seq after 03900 batchs: 293.7722473144531
INFO:root:Train (Epoch 363): Loss/seq after 03950 batchs: 295.4990539550781
INFO:root:Train (Epoch 363): Loss/seq after 04000 batchs: 294.16510009765625
INFO:root:Train (Epoch 363): Loss/seq after 04050 batchs: 292.6444396972656
INFO:root:Train (Epoch 363): Loss/seq after 04100 batchs: 291.7220764160156
INFO:root:Train (Epoch 363): Loss/seq after 04150 batchs: 291.6585998535156
INFO:root:Train (Epoch 363): Loss/seq after 04200 batchs: 291.32708740234375
INFO:root:Train (Epoch 363): Loss/seq after 04250 batchs: 290.5567321777344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 363): Loss/seq after 00000 batches: 221.14002990722656
INFO:root:# Valid (Epoch 363): Loss/seq after 00050 batches: 653.4557495117188
INFO:root:# Valid (Epoch 363): Loss/seq after 00100 batches: 666.3289184570312
INFO:root:# Valid (Epoch 363): Loss/seq after 00150 batches: 497.4482727050781
INFO:root:# Valid (Epoch 363): Loss/seq after 00200 batches: 459.6327209472656
INFO:root:Artifacts: Make stick videos for epoch 363
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_363_on_20220424_021115.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_363_index_848_on_20220424_021115.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 364): Loss/seq after 00000 batchs: 503.0078430175781
INFO:root:Train (Epoch 364): Loss/seq after 00050 batchs: 381.2405090332031
INFO:root:Train (Epoch 364): Loss/seq after 00100 batchs: 401.12896728515625
INFO:root:Train (Epoch 364): Loss/seq after 00150 batchs: 374.906494140625
INFO:root:Train (Epoch 364): Loss/seq after 00200 batchs: 419.6798095703125
INFO:root:Train (Epoch 364): Loss/seq after 00250 batchs: 451.960205078125
INFO:root:Train (Epoch 364): Loss/seq after 00300 batchs: 466.8878173828125
INFO:root:Train (Epoch 364): Loss/seq after 00350 batchs: 446.3068542480469
INFO:root:Train (Epoch 364): Loss/seq after 00400 batchs: 438.40057373046875
INFO:root:Train (Epoch 364): Loss/seq after 00450 batchs: 452.9201354980469
INFO:root:Train (Epoch 364): Loss/seq after 00500 batchs: 439.087158203125
INFO:root:Train (Epoch 364): Loss/seq after 00550 batchs: 432.4393310546875
INFO:root:Train (Epoch 364): Loss/seq after 00600 batchs: 416.44854736328125
INFO:root:Train (Epoch 364): Loss/seq after 00650 batchs: 399.2300720214844
INFO:root:Train (Epoch 364): Loss/seq after 00700 batchs: 382.7210388183594
INFO:root:Train (Epoch 364): Loss/seq after 00750 batchs: 378.2677001953125
INFO:root:Train (Epoch 364): Loss/seq after 00800 batchs: 378.6002502441406
INFO:root:Train (Epoch 364): Loss/seq after 00850 batchs: 365.98974609375
INFO:root:Train (Epoch 364): Loss/seq after 00900 batchs: 356.7969970703125
INFO:root:Train (Epoch 364): Loss/seq after 00950 batchs: 355.30157470703125
INFO:root:Train (Epoch 364): Loss/seq after 01000 batchs: 349.51611328125
INFO:root:Train (Epoch 364): Loss/seq after 01050 batchs: 343.64947509765625
INFO:root:Train (Epoch 364): Loss/seq after 01100 batchs: 336.1712951660156
INFO:root:Train (Epoch 364): Loss/seq after 01150 batchs: 327.2505187988281
INFO:root:Train (Epoch 364): Loss/seq after 01200 batchs: 325.7830810546875
INFO:root:Train (Epoch 364): Loss/seq after 01250 batchs: 324.9616394042969
INFO:root:Train (Epoch 364): Loss/seq after 01300 batchs: 318.0152282714844
INFO:root:Train (Epoch 364): Loss/seq after 01350 batchs: 311.1649169921875
INFO:root:Train (Epoch 364): Loss/seq after 01400 batchs: 312.11505126953125
INFO:root:Train (Epoch 364): Loss/seq after 01450 batchs: 313.75537109375
INFO:root:Train (Epoch 364): Loss/seq after 01500 batchs: 318.75799560546875
INFO:root:Train (Epoch 364): Loss/seq after 01550 batchs: 320.1007080078125
INFO:root:Train (Epoch 364): Loss/seq after 01600 batchs: 319.3440246582031
INFO:root:Train (Epoch 364): Loss/seq after 01650 batchs: 318.050537109375
INFO:root:Train (Epoch 364): Loss/seq after 01700 batchs: 318.7446594238281
INFO:root:Train (Epoch 364): Loss/seq after 01750 batchs: 317.70947265625
INFO:root:Train (Epoch 364): Loss/seq after 01800 batchs: 316.8664245605469
INFO:root:Train (Epoch 364): Loss/seq after 01850 batchs: 315.7794189453125
INFO:root:Train (Epoch 364): Loss/seq after 01900 batchs: 315.2811279296875
INFO:root:Train (Epoch 364): Loss/seq after 01950 batchs: 315.2103576660156
INFO:root:Train (Epoch 364): Loss/seq after 02000 batchs: 317.31207275390625
INFO:root:Train (Epoch 364): Loss/seq after 02050 batchs: 317.64007568359375
INFO:root:Train (Epoch 364): Loss/seq after 02100 batchs: 317.55169677734375
INFO:root:Train (Epoch 364): Loss/seq after 02150 batchs: 317.5882263183594
INFO:root:Train (Epoch 364): Loss/seq after 02200 batchs: 317.17535400390625
INFO:root:Train (Epoch 364): Loss/seq after 02250 batchs: 316.51104736328125
INFO:root:Train (Epoch 364): Loss/seq after 02300 batchs: 314.4626770019531
INFO:root:Train (Epoch 364): Loss/seq after 02350 batchs: 312.600341796875
INFO:root:Train (Epoch 364): Loss/seq after 02400 batchs: 312.3078308105469
INFO:root:Train (Epoch 364): Loss/seq after 02450 batchs: 310.0644226074219
INFO:root:Train (Epoch 364): Loss/seq after 02500 batchs: 304.9638671875
INFO:root:Train (Epoch 364): Loss/seq after 02550 batchs: 300.640869140625
INFO:root:Train (Epoch 364): Loss/seq after 02600 batchs: 296.9664611816406
INFO:root:Train (Epoch 364): Loss/seq after 02650 batchs: 293.7572021484375
INFO:root:Train (Epoch 364): Loss/seq after 02700 batchs: 291.7647705078125
INFO:root:Train (Epoch 364): Loss/seq after 02750 batchs: 288.85284423828125
INFO:root:Train (Epoch 364): Loss/seq after 02800 batchs: 287.26763916015625
INFO:root:Train (Epoch 364): Loss/seq after 02850 batchs: 286.8746643066406
INFO:root:Train (Epoch 364): Loss/seq after 02900 batchs: 287.061279296875
INFO:root:Train (Epoch 364): Loss/seq after 02950 batchs: 288.1036682128906
INFO:root:Train (Epoch 364): Loss/seq after 03000 batchs: 290.9979553222656
INFO:root:Train (Epoch 364): Loss/seq after 03050 batchs: 292.131103515625
INFO:root:Train (Epoch 364): Loss/seq after 03100 batchs: 294.07269287109375
INFO:root:Train (Epoch 364): Loss/seq after 03150 batchs: 293.7258605957031
INFO:root:Train (Epoch 364): Loss/seq after 03200 batchs: 293.42962646484375
INFO:root:Train (Epoch 364): Loss/seq after 03250 batchs: 292.9011535644531
INFO:root:Train (Epoch 364): Loss/seq after 03300 batchs: 292.8656311035156
INFO:root:Train (Epoch 364): Loss/seq after 03350 batchs: 291.6006164550781
INFO:root:Train (Epoch 364): Loss/seq after 03400 batchs: 289.97637939453125
INFO:root:Train (Epoch 364): Loss/seq after 03450 batchs: 289.01251220703125
INFO:root:Train (Epoch 364): Loss/seq after 03500 batchs: 290.3229064941406
INFO:root:Train (Epoch 364): Loss/seq after 03550 batchs: 289.4174499511719
INFO:root:Train (Epoch 364): Loss/seq after 03600 batchs: 292.34674072265625
INFO:root:Train (Epoch 364): Loss/seq after 03650 batchs: 291.6625671386719
INFO:root:Train (Epoch 364): Loss/seq after 03700 batchs: 293.61474609375
INFO:root:Train (Epoch 364): Loss/seq after 03750 batchs: 296.547607421875
INFO:root:Train (Epoch 364): Loss/seq after 03800 batchs: 296.6854248046875
INFO:root:Train (Epoch 364): Loss/seq after 03850 batchs: 296.33984375
INFO:root:Train (Epoch 364): Loss/seq after 03900 batchs: 297.6982727050781
INFO:root:Train (Epoch 364): Loss/seq after 03950 batchs: 299.94818115234375
INFO:root:Train (Epoch 364): Loss/seq after 04000 batchs: 298.6051025390625
INFO:root:Train (Epoch 364): Loss/seq after 04050 batchs: 297.08734130859375
INFO:root:Train (Epoch 364): Loss/seq after 04100 batchs: 296.33221435546875
INFO:root:Train (Epoch 364): Loss/seq after 04150 batchs: 296.2126770019531
INFO:root:Train (Epoch 364): Loss/seq after 04200 batchs: 295.7754211425781
INFO:root:Train (Epoch 364): Loss/seq after 04250 batchs: 295.0057373046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 364): Loss/seq after 00000 batches: 352.28472900390625
INFO:root:# Valid (Epoch 364): Loss/seq after 00050 batches: 634.0681762695312
INFO:root:# Valid (Epoch 364): Loss/seq after 00100 batches: 740.565673828125
INFO:root:# Valid (Epoch 364): Loss/seq after 00150 batches: 545.5134887695312
INFO:root:# Valid (Epoch 364): Loss/seq after 00200 batches: 494.3669128417969
INFO:root:Artifacts: Make stick videos for epoch 364
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_364_on_20220424_021603.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_364_index_1566_on_20220424_021603.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 365): Loss/seq after 00000 batchs: 419.2977294921875
INFO:root:Train (Epoch 365): Loss/seq after 00050 batchs: 395.8815002441406
INFO:root:Train (Epoch 365): Loss/seq after 00100 batchs: 407.05633544921875
INFO:root:Train (Epoch 365): Loss/seq after 00150 batchs: 379.6209716796875
INFO:root:Train (Epoch 365): Loss/seq after 00200 batchs: 433.16168212890625
INFO:root:Train (Epoch 365): Loss/seq after 00250 batchs: 442.1749267578125
INFO:root:Train (Epoch 365): Loss/seq after 00300 batchs: 458.9537353515625
INFO:root:Train (Epoch 365): Loss/seq after 00350 batchs: 439.2212829589844
INFO:root:Train (Epoch 365): Loss/seq after 00400 batchs: 427.8763427734375
INFO:root:Train (Epoch 365): Loss/seq after 00450 batchs: 441.5735778808594
INFO:root:Train (Epoch 365): Loss/seq after 00500 batchs: 427.61383056640625
INFO:root:Train (Epoch 365): Loss/seq after 00550 batchs: 420.9526062011719
INFO:root:Train (Epoch 365): Loss/seq after 00600 batchs: 405.9640808105469
INFO:root:Train (Epoch 365): Loss/seq after 00650 batchs: 390.1927795410156
INFO:root:Train (Epoch 365): Loss/seq after 00700 batchs: 374.1050720214844
INFO:root:Train (Epoch 365): Loss/seq after 00750 batchs: 369.32904052734375
INFO:root:Train (Epoch 365): Loss/seq after 00800 batchs: 369.2350769042969
INFO:root:Train (Epoch 365): Loss/seq after 00850 batchs: 357.537109375
INFO:root:Train (Epoch 365): Loss/seq after 00900 batchs: 348.0274963378906
INFO:root:Train (Epoch 365): Loss/seq after 00950 batchs: 347.46307373046875
INFO:root:Train (Epoch 365): Loss/seq after 01000 batchs: 341.21337890625
INFO:root:Train (Epoch 365): Loss/seq after 01050 batchs: 336.63983154296875
INFO:root:Train (Epoch 365): Loss/seq after 01100 batchs: 328.947509765625
INFO:root:Train (Epoch 365): Loss/seq after 01150 batchs: 320.3818054199219
INFO:root:Train (Epoch 365): Loss/seq after 01200 batchs: 319.15252685546875
INFO:root:Train (Epoch 365): Loss/seq after 01250 batchs: 318.2457275390625
INFO:root:Train (Epoch 365): Loss/seq after 01300 batchs: 311.60894775390625
INFO:root:Train (Epoch 365): Loss/seq after 01350 batchs: 304.947265625
INFO:root:Train (Epoch 365): Loss/seq after 01400 batchs: 306.6181945800781
INFO:root:Train (Epoch 365): Loss/seq after 01450 batchs: 308.0518493652344
INFO:root:Train (Epoch 365): Loss/seq after 01500 batchs: 312.54132080078125
INFO:root:Train (Epoch 365): Loss/seq after 01550 batchs: 312.8967590332031
INFO:root:Train (Epoch 365): Loss/seq after 01600 batchs: 311.8278503417969
INFO:root:Train (Epoch 365): Loss/seq after 01650 batchs: 310.3428955078125
INFO:root:Train (Epoch 365): Loss/seq after 01700 batchs: 311.12091064453125
INFO:root:Train (Epoch 365): Loss/seq after 01750 batchs: 310.2957458496094
INFO:root:Train (Epoch 365): Loss/seq after 01800 batchs: 309.40008544921875
INFO:root:Train (Epoch 365): Loss/seq after 01850 batchs: 308.47259521484375
INFO:root:Train (Epoch 365): Loss/seq after 01900 batchs: 308.1663818359375
INFO:root:Train (Epoch 365): Loss/seq after 01950 batchs: 308.8409423828125
INFO:root:Train (Epoch 365): Loss/seq after 02000 batchs: 311.02447509765625
INFO:root:Train (Epoch 365): Loss/seq after 02050 batchs: 311.4893798828125
INFO:root:Train (Epoch 365): Loss/seq after 02100 batchs: 311.52777099609375
INFO:root:Train (Epoch 365): Loss/seq after 02150 batchs: 311.6927795410156
INFO:root:Train (Epoch 365): Loss/seq after 02200 batchs: 311.334228515625
INFO:root:Train (Epoch 365): Loss/seq after 02250 batchs: 310.5534362792969
INFO:root:Train (Epoch 365): Loss/seq after 02300 batchs: 308.6614990234375
INFO:root:Train (Epoch 365): Loss/seq after 02350 batchs: 306.8778381347656
INFO:root:Train (Epoch 365): Loss/seq after 02400 batchs: 306.7281494140625
INFO:root:Train (Epoch 365): Loss/seq after 02450 batchs: 304.3854675292969
INFO:root:Train (Epoch 365): Loss/seq after 02500 batchs: 299.4192810058594
INFO:root:Train (Epoch 365): Loss/seq after 02550 batchs: 295.1244201660156
INFO:root:Train (Epoch 365): Loss/seq after 02600 batchs: 291.6546936035156
INFO:root:Train (Epoch 365): Loss/seq after 02650 batchs: 288.5657958984375
INFO:root:Train (Epoch 365): Loss/seq after 02700 batchs: 286.579345703125
INFO:root:Train (Epoch 365): Loss/seq after 02750 batchs: 283.28033447265625
INFO:root:Train (Epoch 365): Loss/seq after 02800 batchs: 281.74273681640625
INFO:root:Train (Epoch 365): Loss/seq after 02850 batchs: 281.5470275878906
INFO:root:Train (Epoch 365): Loss/seq after 02900 batchs: 281.5649108886719
INFO:root:Train (Epoch 365): Loss/seq after 02950 batchs: 282.5337829589844
INFO:root:Train (Epoch 365): Loss/seq after 03000 batchs: 285.25
INFO:root:Train (Epoch 365): Loss/seq after 03050 batchs: 287.083984375
INFO:root:Train (Epoch 365): Loss/seq after 03100 batchs: 288.2495422363281
INFO:root:Train (Epoch 365): Loss/seq after 03150 batchs: 287.72998046875
INFO:root:Train (Epoch 365): Loss/seq after 03200 batchs: 287.4854431152344
INFO:root:Train (Epoch 365): Loss/seq after 03250 batchs: 287.31439208984375
INFO:root:Train (Epoch 365): Loss/seq after 03300 batchs: 286.7999267578125
INFO:root:Train (Epoch 365): Loss/seq after 03350 batchs: 285.3382873535156
INFO:root:Train (Epoch 365): Loss/seq after 03400 batchs: 283.8795471191406
INFO:root:Train (Epoch 365): Loss/seq after 03450 batchs: 282.8797912597656
INFO:root:Train (Epoch 365): Loss/seq after 03500 batchs: 283.5924987792969
INFO:root:Train (Epoch 365): Loss/seq after 03550 batchs: 282.5451354980469
INFO:root:Train (Epoch 365): Loss/seq after 03600 batchs: 284.7290344238281
INFO:root:Train (Epoch 365): Loss/seq after 03650 batchs: 283.7810363769531
INFO:root:Train (Epoch 365): Loss/seq after 03700 batchs: 285.33953857421875
INFO:root:Train (Epoch 365): Loss/seq after 03750 batchs: 288.2209167480469
INFO:root:Train (Epoch 365): Loss/seq after 03800 batchs: 288.44000244140625
INFO:root:Train (Epoch 365): Loss/seq after 03850 batchs: 288.1104431152344
INFO:root:Train (Epoch 365): Loss/seq after 03900 batchs: 289.3192138671875
INFO:root:Train (Epoch 365): Loss/seq after 03950 batchs: 291.0586242675781
INFO:root:Train (Epoch 365): Loss/seq after 04000 batchs: 289.70941162109375
INFO:root:Train (Epoch 365): Loss/seq after 04050 batchs: 288.3098449707031
INFO:root:Train (Epoch 365): Loss/seq after 04100 batchs: 287.4174499511719
INFO:root:Train (Epoch 365): Loss/seq after 04150 batchs: 287.4559020996094
INFO:root:Train (Epoch 365): Loss/seq after 04200 batchs: 287.0534973144531
INFO:root:Train (Epoch 365): Loss/seq after 04250 batchs: 286.284912109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 365): Loss/seq after 00000 batches: 272.33172607421875
INFO:root:# Valid (Epoch 365): Loss/seq after 00050 batches: 638.966552734375
INFO:root:# Valid (Epoch 365): Loss/seq after 00100 batches: 661.2410888671875
INFO:root:# Valid (Epoch 365): Loss/seq after 00150 batches: 491.99652099609375
INFO:root:# Valid (Epoch 365): Loss/seq after 00200 batches: 457.8837585449219
INFO:root:Artifacts: Make stick videos for epoch 365
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_365_on_20220424_022106.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_365_index_1031_on_20220424_022106.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 366): Loss/seq after 00000 batchs: 416.6471252441406
INFO:root:Train (Epoch 366): Loss/seq after 00050 batchs: 385.5241394042969
INFO:root:Train (Epoch 366): Loss/seq after 00100 batchs: 390.5691223144531
INFO:root:Train (Epoch 366): Loss/seq after 00150 batchs: 369.365234375
INFO:root:Train (Epoch 366): Loss/seq after 00200 batchs: 407.12750244140625
INFO:root:Train (Epoch 366): Loss/seq after 00250 batchs: 424.75390625
INFO:root:Train (Epoch 366): Loss/seq after 00300 batchs: 441.834228515625
INFO:root:Train (Epoch 366): Loss/seq after 00350 batchs: 423.0396728515625
INFO:root:Train (Epoch 366): Loss/seq after 00400 batchs: 416.3910827636719
INFO:root:Train (Epoch 366): Loss/seq after 00450 batchs: 431.7250061035156
INFO:root:Train (Epoch 366): Loss/seq after 00500 batchs: 417.8978271484375
INFO:root:Train (Epoch 366): Loss/seq after 00550 batchs: 411.2108154296875
INFO:root:Train (Epoch 366): Loss/seq after 00600 batchs: 396.7310485839844
INFO:root:Train (Epoch 366): Loss/seq after 00650 batchs: 380.20892333984375
INFO:root:Train (Epoch 366): Loss/seq after 00700 batchs: 364.0323181152344
INFO:root:Train (Epoch 366): Loss/seq after 00750 batchs: 357.602294921875
INFO:root:Train (Epoch 366): Loss/seq after 00800 batchs: 357.4353942871094
INFO:root:Train (Epoch 366): Loss/seq after 00850 batchs: 346.49102783203125
INFO:root:Train (Epoch 366): Loss/seq after 00900 batchs: 338.1408996582031
INFO:root:Train (Epoch 366): Loss/seq after 00950 batchs: 337.7859191894531
INFO:root:Train (Epoch 366): Loss/seq after 01000 batchs: 331.56646728515625
INFO:root:Train (Epoch 366): Loss/seq after 01050 batchs: 327.8944091796875
INFO:root:Train (Epoch 366): Loss/seq after 01100 batchs: 320.0400085449219
INFO:root:Train (Epoch 366): Loss/seq after 01150 batchs: 311.6058654785156
INFO:root:Train (Epoch 366): Loss/seq after 01200 batchs: 310.0929870605469
INFO:root:Train (Epoch 366): Loss/seq after 01250 batchs: 309.1912841796875
INFO:root:Train (Epoch 366): Loss/seq after 01300 batchs: 302.8461608886719
INFO:root:Train (Epoch 366): Loss/seq after 01350 batchs: 296.4047546386719
INFO:root:Train (Epoch 366): Loss/seq after 01400 batchs: 297.4457092285156
INFO:root:Train (Epoch 366): Loss/seq after 01450 batchs: 299.3685302734375
INFO:root:Train (Epoch 366): Loss/seq after 01500 batchs: 304.50506591796875
INFO:root:Train (Epoch 366): Loss/seq after 01550 batchs: 305.385009765625
INFO:root:Train (Epoch 366): Loss/seq after 01600 batchs: 304.6892395019531
INFO:root:Train (Epoch 366): Loss/seq after 01650 batchs: 303.75634765625
INFO:root:Train (Epoch 366): Loss/seq after 01700 batchs: 304.6654968261719
INFO:root:Train (Epoch 366): Loss/seq after 01750 batchs: 304.07965087890625
INFO:root:Train (Epoch 366): Loss/seq after 01800 batchs: 303.4317626953125
INFO:root:Train (Epoch 366): Loss/seq after 01850 batchs: 302.75250244140625
INFO:root:Train (Epoch 366): Loss/seq after 01900 batchs: 302.3619384765625
INFO:root:Train (Epoch 366): Loss/seq after 01950 batchs: 302.57391357421875
INFO:root:Train (Epoch 366): Loss/seq after 02000 batchs: 304.9404602050781
INFO:root:Train (Epoch 366): Loss/seq after 02050 batchs: 305.7176513671875
INFO:root:Train (Epoch 366): Loss/seq after 02100 batchs: 305.7759094238281
INFO:root:Train (Epoch 366): Loss/seq after 02150 batchs: 306.0201416015625
INFO:root:Train (Epoch 366): Loss/seq after 02200 batchs: 305.7553405761719
INFO:root:Train (Epoch 366): Loss/seq after 02250 batchs: 305.3121643066406
INFO:root:Train (Epoch 366): Loss/seq after 02300 batchs: 303.4642639160156
INFO:root:Train (Epoch 366): Loss/seq after 02350 batchs: 301.7140808105469
INFO:root:Train (Epoch 366): Loss/seq after 02400 batchs: 301.4142150878906
INFO:root:Train (Epoch 366): Loss/seq after 02450 batchs: 299.3345947265625
INFO:root:Train (Epoch 366): Loss/seq after 02500 batchs: 294.4391784667969
INFO:root:Train (Epoch 366): Loss/seq after 02550 batchs: 290.268310546875
INFO:root:Train (Epoch 366): Loss/seq after 02600 batchs: 286.8414306640625
INFO:root:Train (Epoch 366): Loss/seq after 02650 batchs: 283.8976135253906
INFO:root:Train (Epoch 366): Loss/seq after 02700 batchs: 282.03741455078125
INFO:root:Train (Epoch 366): Loss/seq after 02750 batchs: 278.99407958984375
INFO:root:Train (Epoch 366): Loss/seq after 02800 batchs: 277.3124084472656
INFO:root:Train (Epoch 366): Loss/seq after 02850 batchs: 277.076171875
INFO:root:Train (Epoch 366): Loss/seq after 02900 batchs: 277.3061828613281
INFO:root:Train (Epoch 366): Loss/seq after 02950 batchs: 278.2380676269531
INFO:root:Train (Epoch 366): Loss/seq after 03000 batchs: 280.96502685546875
INFO:root:Train (Epoch 366): Loss/seq after 03050 batchs: 282.2759094238281
INFO:root:Train (Epoch 366): Loss/seq after 03100 batchs: 283.5768127441406
INFO:root:Train (Epoch 366): Loss/seq after 03150 batchs: 283.495361328125
INFO:root:Train (Epoch 366): Loss/seq after 03200 batchs: 283.42138671875
INFO:root:Train (Epoch 366): Loss/seq after 03250 batchs: 282.88702392578125
INFO:root:Train (Epoch 366): Loss/seq after 03300 batchs: 282.17816162109375
INFO:root:Train (Epoch 366): Loss/seq after 03350 batchs: 280.6357421875
INFO:root:Train (Epoch 366): Loss/seq after 03400 batchs: 279.10406494140625
INFO:root:Train (Epoch 366): Loss/seq after 03450 batchs: 278.2038269042969
INFO:root:Train (Epoch 366): Loss/seq after 03500 batchs: 279.1150817871094
INFO:root:Train (Epoch 366): Loss/seq after 03550 batchs: 278.16802978515625
INFO:root:Train (Epoch 366): Loss/seq after 03600 batchs: 280.4747314453125
INFO:root:Train (Epoch 366): Loss/seq after 03650 batchs: 279.54095458984375
INFO:root:Train (Epoch 366): Loss/seq after 03700 batchs: 280.81475830078125
INFO:root:Train (Epoch 366): Loss/seq after 03750 batchs: 283.5803527832031
INFO:root:Train (Epoch 366): Loss/seq after 03800 batchs: 283.8689270019531
INFO:root:Train (Epoch 366): Loss/seq after 03850 batchs: 283.52764892578125
INFO:root:Train (Epoch 366): Loss/seq after 03900 batchs: 284.38531494140625
INFO:root:Train (Epoch 366): Loss/seq after 03950 batchs: 286.1836242675781
INFO:root:Train (Epoch 366): Loss/seq after 04000 batchs: 284.9176025390625
INFO:root:Train (Epoch 366): Loss/seq after 04050 batchs: 283.540771484375
INFO:root:Train (Epoch 366): Loss/seq after 04100 batchs: 282.7220458984375
INFO:root:Train (Epoch 366): Loss/seq after 04150 batchs: 282.6937255859375
INFO:root:Train (Epoch 366): Loss/seq after 04200 batchs: 282.25885009765625
INFO:root:Train (Epoch 366): Loss/seq after 04250 batchs: 281.49566650390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 366): Loss/seq after 00000 batches: 223.85313415527344
INFO:root:# Valid (Epoch 366): Loss/seq after 00050 batches: 653.1948852539062
INFO:root:# Valid (Epoch 366): Loss/seq after 00100 batches: 612.2713623046875
INFO:root:# Valid (Epoch 366): Loss/seq after 00150 batches: 460.52789306640625
INFO:root:# Valid (Epoch 366): Loss/seq after 00200 batches: 430.2887878417969
INFO:root:Artifacts: Make stick videos for epoch 366
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_366_on_20220424_022550.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_366_index_1394_on_20220424_022550.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 367): Loss/seq after 00000 batchs: 427.8603820800781
INFO:root:Train (Epoch 367): Loss/seq after 00050 batchs: 387.6283874511719
INFO:root:Train (Epoch 367): Loss/seq after 00100 batchs: 385.70440673828125
INFO:root:Train (Epoch 367): Loss/seq after 00150 batchs: 364.08245849609375
INFO:root:Train (Epoch 367): Loss/seq after 00200 batchs: 404.4256896972656
INFO:root:Train (Epoch 367): Loss/seq after 00250 batchs: 422.0962829589844
INFO:root:Train (Epoch 367): Loss/seq after 00300 batchs: 445.3147277832031
INFO:root:Train (Epoch 367): Loss/seq after 00350 batchs: 429.2173156738281
INFO:root:Train (Epoch 367): Loss/seq after 00400 batchs: 422.9176940917969
INFO:root:Train (Epoch 367): Loss/seq after 00450 batchs: 438.27825927734375
INFO:root:Train (Epoch 367): Loss/seq after 00500 batchs: 424.11114501953125
INFO:root:Train (Epoch 367): Loss/seq after 00550 batchs: 418.0506591796875
INFO:root:Train (Epoch 367): Loss/seq after 00600 batchs: 402.82635498046875
INFO:root:Train (Epoch 367): Loss/seq after 00650 batchs: 386.10821533203125
INFO:root:Train (Epoch 367): Loss/seq after 00700 batchs: 370.0183410644531
INFO:root:Train (Epoch 367): Loss/seq after 00750 batchs: 363.8024597167969
INFO:root:Train (Epoch 367): Loss/seq after 00800 batchs: 363.3314208984375
INFO:root:Train (Epoch 367): Loss/seq after 00850 batchs: 351.484130859375
INFO:root:Train (Epoch 367): Loss/seq after 00900 batchs: 342.5926513671875
INFO:root:Train (Epoch 367): Loss/seq after 00950 batchs: 341.6990051269531
INFO:root:Train (Epoch 367): Loss/seq after 01000 batchs: 335.57293701171875
INFO:root:Train (Epoch 367): Loss/seq after 01050 batchs: 328.76593017578125
INFO:root:Train (Epoch 367): Loss/seq after 01100 batchs: 320.68408203125
INFO:root:Train (Epoch 367): Loss/seq after 01150 batchs: 312.2301330566406
INFO:root:Train (Epoch 367): Loss/seq after 01200 batchs: 311.1568298339844
INFO:root:Train (Epoch 367): Loss/seq after 01250 batchs: 310.3021545410156
INFO:root:Train (Epoch 367): Loss/seq after 01300 batchs: 303.68212890625
INFO:root:Train (Epoch 367): Loss/seq after 01350 batchs: 298.0416564941406
INFO:root:Train (Epoch 367): Loss/seq after 01400 batchs: 300.51361083984375
INFO:root:Train (Epoch 367): Loss/seq after 01450 batchs: 302.3003845214844
INFO:root:Train (Epoch 367): Loss/seq after 01500 batchs: 307.5353698730469
INFO:root:Train (Epoch 367): Loss/seq after 01550 batchs: 308.0001220703125
INFO:root:Train (Epoch 367): Loss/seq after 01600 batchs: 307.0252685546875
INFO:root:Train (Epoch 367): Loss/seq after 01650 batchs: 305.9573974609375
INFO:root:Train (Epoch 367): Loss/seq after 01700 batchs: 306.9658508300781
INFO:root:Train (Epoch 367): Loss/seq after 01750 batchs: 306.79296875
INFO:root:Train (Epoch 367): Loss/seq after 01800 batchs: 306.4241943359375
INFO:root:Train (Epoch 367): Loss/seq after 01850 batchs: 305.5513610839844
INFO:root:Train (Epoch 367): Loss/seq after 01900 batchs: 305.1748352050781
INFO:root:Train (Epoch 367): Loss/seq after 01950 batchs: 305.7052307128906
INFO:root:Train (Epoch 367): Loss/seq after 02000 batchs: 308.00775146484375
INFO:root:Train (Epoch 367): Loss/seq after 02050 batchs: 308.5997314453125
INFO:root:Train (Epoch 367): Loss/seq after 02100 batchs: 308.4797058105469
INFO:root:Train (Epoch 367): Loss/seq after 02150 batchs: 308.81280517578125
INFO:root:Train (Epoch 367): Loss/seq after 02200 batchs: 308.4542236328125
INFO:root:Train (Epoch 367): Loss/seq after 02250 batchs: 307.59906005859375
INFO:root:Train (Epoch 367): Loss/seq after 02300 batchs: 305.37420654296875
INFO:root:Train (Epoch 367): Loss/seq after 02350 batchs: 303.6856994628906
INFO:root:Train (Epoch 367): Loss/seq after 02400 batchs: 303.3551025390625
INFO:root:Train (Epoch 367): Loss/seq after 02450 batchs: 301.0994567871094
INFO:root:Train (Epoch 367): Loss/seq after 02500 batchs: 296.20135498046875
INFO:root:Train (Epoch 367): Loss/seq after 02550 batchs: 291.9878234863281
INFO:root:Train (Epoch 367): Loss/seq after 02600 batchs: 288.6641540527344
INFO:root:Train (Epoch 367): Loss/seq after 02650 batchs: 285.66412353515625
INFO:root:Train (Epoch 367): Loss/seq after 02700 batchs: 283.7480163574219
INFO:root:Train (Epoch 367): Loss/seq after 02750 batchs: 280.5572509765625
INFO:root:Train (Epoch 367): Loss/seq after 02800 batchs: 279.0602111816406
INFO:root:Train (Epoch 367): Loss/seq after 02850 batchs: 278.83355712890625
INFO:root:Train (Epoch 367): Loss/seq after 02900 batchs: 278.8243103027344
INFO:root:Train (Epoch 367): Loss/seq after 02950 batchs: 279.97601318359375
INFO:root:Train (Epoch 367): Loss/seq after 03000 batchs: 282.4798583984375
INFO:root:Train (Epoch 367): Loss/seq after 03050 batchs: 283.6230163574219
INFO:root:Train (Epoch 367): Loss/seq after 03100 batchs: 284.719970703125
INFO:root:Train (Epoch 367): Loss/seq after 03150 batchs: 285.6026916503906
INFO:root:Train (Epoch 367): Loss/seq after 03200 batchs: 285.39404296875
INFO:root:Train (Epoch 367): Loss/seq after 03250 batchs: 285.19158935546875
INFO:root:Train (Epoch 367): Loss/seq after 03300 batchs: 284.5248107910156
INFO:root:Train (Epoch 367): Loss/seq after 03350 batchs: 283.1296691894531
INFO:root:Train (Epoch 367): Loss/seq after 03400 batchs: 281.5198059082031
INFO:root:Train (Epoch 367): Loss/seq after 03450 batchs: 280.5146179199219
INFO:root:Train (Epoch 367): Loss/seq after 03500 batchs: 281.2944641113281
INFO:root:Train (Epoch 367): Loss/seq after 03550 batchs: 280.27191162109375
INFO:root:Train (Epoch 367): Loss/seq after 03600 batchs: 282.4709167480469
INFO:root:Train (Epoch 367): Loss/seq after 03650 batchs: 281.4129333496094
INFO:root:Train (Epoch 367): Loss/seq after 03700 batchs: 282.4964294433594
INFO:root:Train (Epoch 367): Loss/seq after 03750 batchs: 285.4583740234375
INFO:root:Train (Epoch 367): Loss/seq after 03800 batchs: 285.6409606933594
INFO:root:Train (Epoch 367): Loss/seq after 03850 batchs: 285.3028259277344
INFO:root:Train (Epoch 367): Loss/seq after 03900 batchs: 286.5006408691406
INFO:root:Train (Epoch 367): Loss/seq after 03950 batchs: 288.09039306640625
INFO:root:Train (Epoch 367): Loss/seq after 04000 batchs: 286.8022766113281
INFO:root:Train (Epoch 367): Loss/seq after 04050 batchs: 285.36358642578125
INFO:root:Train (Epoch 367): Loss/seq after 04100 batchs: 284.50537109375
INFO:root:Train (Epoch 367): Loss/seq after 04150 batchs: 284.3907775878906
INFO:root:Train (Epoch 367): Loss/seq after 04200 batchs: 283.9542236328125
INFO:root:Train (Epoch 367): Loss/seq after 04250 batchs: 283.2000732421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 367): Loss/seq after 00000 batches: 294.24176025390625
INFO:root:# Valid (Epoch 367): Loss/seq after 00050 batches: 678.0706176757812
INFO:root:# Valid (Epoch 367): Loss/seq after 00100 batches: 672.6668090820312
INFO:root:# Valid (Epoch 367): Loss/seq after 00150 batches: 501.7685852050781
INFO:root:# Valid (Epoch 367): Loss/seq after 00200 batches: 463.6069641113281
INFO:root:Artifacts: Make stick videos for epoch 367
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_367_on_20220424_023040.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_367_index_1812_on_20220424_023040.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 368): Loss/seq after 00000 batchs: 365.38916015625
INFO:root:Train (Epoch 368): Loss/seq after 00050 batchs: 372.6424865722656
INFO:root:Train (Epoch 368): Loss/seq after 00100 batchs: 381.0723571777344
INFO:root:Train (Epoch 368): Loss/seq after 00150 batchs: 359.3298645019531
INFO:root:Train (Epoch 368): Loss/seq after 00200 batchs: 402.05499267578125
INFO:root:Train (Epoch 368): Loss/seq after 00250 batchs: 415.3230285644531
INFO:root:Train (Epoch 368): Loss/seq after 00300 batchs: 439.8066101074219
INFO:root:Train (Epoch 368): Loss/seq after 00350 batchs: 421.9422302246094
INFO:root:Train (Epoch 368): Loss/seq after 00400 batchs: 408.6314392089844
INFO:root:Train (Epoch 368): Loss/seq after 00450 batchs: 425.2350769042969
INFO:root:Train (Epoch 368): Loss/seq after 00500 batchs: 411.1022644042969
INFO:root:Train (Epoch 368): Loss/seq after 00550 batchs: 404.47418212890625
INFO:root:Train (Epoch 368): Loss/seq after 00600 batchs: 390.56158447265625
INFO:root:Train (Epoch 368): Loss/seq after 00650 batchs: 374.0025634765625
INFO:root:Train (Epoch 368): Loss/seq after 00700 batchs: 359.83001708984375
INFO:root:Train (Epoch 368): Loss/seq after 00750 batchs: 352.325927734375
INFO:root:Train (Epoch 368): Loss/seq after 00800 batchs: 352.3611755371094
INFO:root:Train (Epoch 368): Loss/seq after 00850 batchs: 341.009033203125
INFO:root:Train (Epoch 368): Loss/seq after 00900 batchs: 332.1381530761719
INFO:root:Train (Epoch 368): Loss/seq after 00950 batchs: 330.6427307128906
INFO:root:Train (Epoch 368): Loss/seq after 01000 batchs: 324.6463317871094
INFO:root:Train (Epoch 368): Loss/seq after 01050 batchs: 319.0340270996094
INFO:root:Train (Epoch 368): Loss/seq after 01100 batchs: 311.8918151855469
INFO:root:Train (Epoch 368): Loss/seq after 01150 batchs: 303.44940185546875
INFO:root:Train (Epoch 368): Loss/seq after 01200 batchs: 302.6357116699219
INFO:root:Train (Epoch 368): Loss/seq after 01250 batchs: 301.8348693847656
INFO:root:Train (Epoch 368): Loss/seq after 01300 batchs: 295.5334167480469
INFO:root:Train (Epoch 368): Loss/seq after 01350 batchs: 289.4071350097656
INFO:root:Train (Epoch 368): Loss/seq after 01400 batchs: 290.8901062011719
INFO:root:Train (Epoch 368): Loss/seq after 01450 batchs: 292.48663330078125
INFO:root:Train (Epoch 368): Loss/seq after 01500 batchs: 298.45220947265625
INFO:root:Train (Epoch 368): Loss/seq after 01550 batchs: 300.6373291015625
INFO:root:Train (Epoch 368): Loss/seq after 01600 batchs: 300.18035888671875
INFO:root:Train (Epoch 368): Loss/seq after 01650 batchs: 299.3380432128906
INFO:root:Train (Epoch 368): Loss/seq after 01700 batchs: 300.6885681152344
INFO:root:Train (Epoch 368): Loss/seq after 01750 batchs: 300.12200927734375
INFO:root:Train (Epoch 368): Loss/seq after 01800 batchs: 299.37017822265625
INFO:root:Train (Epoch 368): Loss/seq after 01850 batchs: 298.5371398925781
INFO:root:Train (Epoch 368): Loss/seq after 01900 batchs: 298.4608154296875
INFO:root:Train (Epoch 368): Loss/seq after 01950 batchs: 299.12030029296875
INFO:root:Train (Epoch 368): Loss/seq after 02000 batchs: 301.34869384765625
INFO:root:Train (Epoch 368): Loss/seq after 02050 batchs: 302.1260070800781
INFO:root:Train (Epoch 368): Loss/seq after 02100 batchs: 302.2513122558594
INFO:root:Train (Epoch 368): Loss/seq after 02150 batchs: 302.525146484375
INFO:root:Train (Epoch 368): Loss/seq after 02200 batchs: 302.24560546875
INFO:root:Train (Epoch 368): Loss/seq after 02250 batchs: 301.8596496582031
INFO:root:Train (Epoch 368): Loss/seq after 02300 batchs: 300.0183410644531
INFO:root:Train (Epoch 368): Loss/seq after 02350 batchs: 298.48651123046875
INFO:root:Train (Epoch 368): Loss/seq after 02400 batchs: 298.1073303222656
INFO:root:Train (Epoch 368): Loss/seq after 02450 batchs: 296.0174255371094
INFO:root:Train (Epoch 368): Loss/seq after 02500 batchs: 291.1955871582031
INFO:root:Train (Epoch 368): Loss/seq after 02550 batchs: 287.0444030761719
INFO:root:Train (Epoch 368): Loss/seq after 02600 batchs: 283.794677734375
INFO:root:Train (Epoch 368): Loss/seq after 02650 batchs: 280.9076232910156
INFO:root:Train (Epoch 368): Loss/seq after 02700 batchs: 279.0018615722656
INFO:root:Train (Epoch 368): Loss/seq after 02750 batchs: 276.3701171875
INFO:root:Train (Epoch 368): Loss/seq after 02800 batchs: 274.8082275390625
INFO:root:Train (Epoch 368): Loss/seq after 02850 batchs: 274.67364501953125
INFO:root:Train (Epoch 368): Loss/seq after 02900 batchs: 274.8225402832031
INFO:root:Train (Epoch 368): Loss/seq after 02950 batchs: 275.97088623046875
INFO:root:Train (Epoch 368): Loss/seq after 03000 batchs: 279.17822265625
INFO:root:Train (Epoch 368): Loss/seq after 03050 batchs: 280.6107177734375
INFO:root:Train (Epoch 368): Loss/seq after 03100 batchs: 282.0875549316406
INFO:root:Train (Epoch 368): Loss/seq after 03150 batchs: 281.8384094238281
INFO:root:Train (Epoch 368): Loss/seq after 03200 batchs: 283.05364990234375
INFO:root:Train (Epoch 368): Loss/seq after 03250 batchs: 283.330322265625
INFO:root:Train (Epoch 368): Loss/seq after 03300 batchs: 282.8578796386719
INFO:root:Train (Epoch 368): Loss/seq after 03350 batchs: 281.231201171875
INFO:root:Train (Epoch 368): Loss/seq after 03400 batchs: 279.63812255859375
INFO:root:Train (Epoch 368): Loss/seq after 03450 batchs: 278.6819763183594
INFO:root:Train (Epoch 368): Loss/seq after 03500 batchs: 279.44952392578125
INFO:root:Train (Epoch 368): Loss/seq after 03550 batchs: 278.41375732421875
INFO:root:Train (Epoch 368): Loss/seq after 03600 batchs: 280.4053955078125
INFO:root:Train (Epoch 368): Loss/seq after 03650 batchs: 279.1244201660156
INFO:root:Train (Epoch 368): Loss/seq after 03700 batchs: 280.4028015136719
INFO:root:Train (Epoch 368): Loss/seq after 03750 batchs: 283.28240966796875
INFO:root:Train (Epoch 368): Loss/seq after 03800 batchs: 283.5185852050781
INFO:root:Train (Epoch 368): Loss/seq after 03850 batchs: 283.32342529296875
INFO:root:Train (Epoch 368): Loss/seq after 03900 batchs: 284.3690185546875
INFO:root:Train (Epoch 368): Loss/seq after 03950 batchs: 286.4115295410156
INFO:root:Train (Epoch 368): Loss/seq after 04000 batchs: 285.1375427246094
INFO:root:Train (Epoch 368): Loss/seq after 04050 batchs: 283.724365234375
INFO:root:Train (Epoch 368): Loss/seq after 04100 batchs: 282.77618408203125
INFO:root:Train (Epoch 368): Loss/seq after 04150 batchs: 282.6776123046875
INFO:root:Train (Epoch 368): Loss/seq after 04200 batchs: 282.3323669433594
INFO:root:Train (Epoch 368): Loss/seq after 04250 batchs: 281.5303649902344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 368): Loss/seq after 00000 batches: 320.9248046875
INFO:root:# Valid (Epoch 368): Loss/seq after 00050 batches: 617.9906616210938
INFO:root:# Valid (Epoch 368): Loss/seq after 00100 batches: 625.72412109375
INFO:root:# Valid (Epoch 368): Loss/seq after 00150 batches: 467.92694091796875
INFO:root:# Valid (Epoch 368): Loss/seq after 00200 batches: 437.72503662109375
INFO:root:Artifacts: Make stick videos for epoch 368
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_368_on_20220424_023547.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_368_index_1323_on_20220424_023547.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 369): Loss/seq after 00000 batchs: 458.1286926269531
INFO:root:Train (Epoch 369): Loss/seq after 00050 batchs: 373.99945068359375
INFO:root:Train (Epoch 369): Loss/seq after 00100 batchs: 403.5514831542969
INFO:root:Train (Epoch 369): Loss/seq after 00150 batchs: 375.33575439453125
INFO:root:Train (Epoch 369): Loss/seq after 00200 batchs: 417.90484619140625
INFO:root:Train (Epoch 369): Loss/seq after 00250 batchs: 436.79364013671875
INFO:root:Train (Epoch 369): Loss/seq after 00300 batchs: 453.35198974609375
INFO:root:Train (Epoch 369): Loss/seq after 00350 batchs: 433.5551452636719
INFO:root:Train (Epoch 369): Loss/seq after 00400 batchs: 426.85546875
INFO:root:Train (Epoch 369): Loss/seq after 00450 batchs: 440.9789733886719
INFO:root:Train (Epoch 369): Loss/seq after 00500 batchs: 425.747802734375
INFO:root:Train (Epoch 369): Loss/seq after 00550 batchs: 418.6903991699219
INFO:root:Train (Epoch 369): Loss/seq after 00600 batchs: 402.98638916015625
INFO:root:Train (Epoch 369): Loss/seq after 00650 batchs: 385.62255859375
INFO:root:Train (Epoch 369): Loss/seq after 00700 batchs: 372.6219482421875
INFO:root:Train (Epoch 369): Loss/seq after 00750 batchs: 366.1513977050781
INFO:root:Train (Epoch 369): Loss/seq after 00800 batchs: 365.6268310546875
INFO:root:Train (Epoch 369): Loss/seq after 00850 batchs: 353.75274658203125
INFO:root:Train (Epoch 369): Loss/seq after 00900 batchs: 344.9574279785156
INFO:root:Train (Epoch 369): Loss/seq after 00950 batchs: 344.7218933105469
INFO:root:Train (Epoch 369): Loss/seq after 01000 batchs: 338.3049011230469
INFO:root:Train (Epoch 369): Loss/seq after 01050 batchs: 331.5961608886719
INFO:root:Train (Epoch 369): Loss/seq after 01100 batchs: 324.1844787597656
INFO:root:Train (Epoch 369): Loss/seq after 01150 batchs: 315.53375244140625
INFO:root:Train (Epoch 369): Loss/seq after 01200 batchs: 313.3144836425781
INFO:root:Train (Epoch 369): Loss/seq after 01250 batchs: 312.6357727050781
INFO:root:Train (Epoch 369): Loss/seq after 01300 batchs: 305.9980163574219
INFO:root:Train (Epoch 369): Loss/seq after 01350 batchs: 299.5367431640625
INFO:root:Train (Epoch 369): Loss/seq after 01400 batchs: 300.0230712890625
INFO:root:Train (Epoch 369): Loss/seq after 01450 batchs: 301.64837646484375
INFO:root:Train (Epoch 369): Loss/seq after 01500 batchs: 306.89141845703125
INFO:root:Train (Epoch 369): Loss/seq after 01550 batchs: 308.5409240722656
INFO:root:Train (Epoch 369): Loss/seq after 01600 batchs: 307.60845947265625
INFO:root:Train (Epoch 369): Loss/seq after 01650 batchs: 306.6181640625
INFO:root:Train (Epoch 369): Loss/seq after 01700 batchs: 307.7260437011719
INFO:root:Train (Epoch 369): Loss/seq after 01750 batchs: 307.250732421875
INFO:root:Train (Epoch 369): Loss/seq after 01800 batchs: 306.43109130859375
INFO:root:Train (Epoch 369): Loss/seq after 01850 batchs: 305.45623779296875
INFO:root:Train (Epoch 369): Loss/seq after 01900 batchs: 305.2232971191406
INFO:root:Train (Epoch 369): Loss/seq after 01950 batchs: 305.4823913574219
INFO:root:Train (Epoch 369): Loss/seq after 02000 batchs: 307.7665710449219
INFO:root:Train (Epoch 369): Loss/seq after 02050 batchs: 308.2614440917969
INFO:root:Train (Epoch 369): Loss/seq after 02100 batchs: 308.13409423828125
INFO:root:Train (Epoch 369): Loss/seq after 02150 batchs: 308.4256591796875
INFO:root:Train (Epoch 369): Loss/seq after 02200 batchs: 308.1099853515625
INFO:root:Train (Epoch 369): Loss/seq after 02250 batchs: 307.7569885253906
INFO:root:Train (Epoch 369): Loss/seq after 02300 batchs: 306.1117858886719
INFO:root:Train (Epoch 369): Loss/seq after 02350 batchs: 304.35333251953125
INFO:root:Train (Epoch 369): Loss/seq after 02400 batchs: 304.150146484375
INFO:root:Train (Epoch 369): Loss/seq after 02450 batchs: 301.95709228515625
INFO:root:Train (Epoch 369): Loss/seq after 02500 batchs: 296.9898376464844
INFO:root:Train (Epoch 369): Loss/seq after 02550 batchs: 292.9051818847656
INFO:root:Train (Epoch 369): Loss/seq after 02600 batchs: 289.3992004394531
INFO:root:Train (Epoch 369): Loss/seq after 02650 batchs: 286.3389587402344
INFO:root:Train (Epoch 369): Loss/seq after 02700 batchs: 284.2710876464844
INFO:root:Train (Epoch 369): Loss/seq after 02750 batchs: 281.5362548828125
INFO:root:Train (Epoch 369): Loss/seq after 02800 batchs: 280.1452941894531
INFO:root:Train (Epoch 369): Loss/seq after 02850 batchs: 279.876220703125
INFO:root:Train (Epoch 369): Loss/seq after 02900 batchs: 280.0550537109375
INFO:root:Train (Epoch 369): Loss/seq after 02950 batchs: 281.3312072753906
INFO:root:Train (Epoch 369): Loss/seq after 03000 batchs: 284.05340576171875
INFO:root:Train (Epoch 369): Loss/seq after 03050 batchs: 285.4394836425781
INFO:root:Train (Epoch 369): Loss/seq after 03100 batchs: 286.4101257324219
INFO:root:Train (Epoch 369): Loss/seq after 03150 batchs: 286.42510986328125
INFO:root:Train (Epoch 369): Loss/seq after 03200 batchs: 286.2276916503906
INFO:root:Train (Epoch 369): Loss/seq after 03250 batchs: 286.3038330078125
INFO:root:Train (Epoch 369): Loss/seq after 03300 batchs: 286.0860900878906
INFO:root:Train (Epoch 369): Loss/seq after 03350 batchs: 284.8498840332031
INFO:root:Train (Epoch 369): Loss/seq after 03400 batchs: 283.2265625
INFO:root:Train (Epoch 369): Loss/seq after 03450 batchs: 282.39337158203125
INFO:root:Train (Epoch 369): Loss/seq after 03500 batchs: 283.7008361816406
INFO:root:Train (Epoch 369): Loss/seq after 03550 batchs: 282.876220703125
INFO:root:Train (Epoch 369): Loss/seq after 03600 batchs: 285.2829895019531
INFO:root:Train (Epoch 369): Loss/seq after 03650 batchs: 284.39520263671875
INFO:root:Train (Epoch 369): Loss/seq after 03700 batchs: 285.77783203125
INFO:root:Train (Epoch 369): Loss/seq after 03750 batchs: 288.8646545410156
INFO:root:Train (Epoch 369): Loss/seq after 03800 batchs: 289.12158203125
INFO:root:Train (Epoch 369): Loss/seq after 03850 batchs: 288.7644348144531
INFO:root:Train (Epoch 369): Loss/seq after 03900 batchs: 289.5298767089844
INFO:root:Train (Epoch 369): Loss/seq after 03950 batchs: 291.6618957519531
INFO:root:Train (Epoch 369): Loss/seq after 04000 batchs: 290.3647155761719
INFO:root:Train (Epoch 369): Loss/seq after 04050 batchs: 288.8896179199219
INFO:root:Train (Epoch 369): Loss/seq after 04100 batchs: 287.9427490234375
INFO:root:Train (Epoch 369): Loss/seq after 04150 batchs: 287.7952575683594
INFO:root:Train (Epoch 369): Loss/seq after 04200 batchs: 287.51104736328125
INFO:root:Train (Epoch 369): Loss/seq after 04250 batchs: 286.6141357421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 369): Loss/seq after 00000 batches: 240.59446716308594
INFO:root:# Valid (Epoch 369): Loss/seq after 00050 batches: 623.23046875
INFO:root:# Valid (Epoch 369): Loss/seq after 00100 batches: 651.0519409179688
INFO:root:# Valid (Epoch 369): Loss/seq after 00150 batches: 486.0571594238281
INFO:root:# Valid (Epoch 369): Loss/seq after 00200 batches: 449.90191650390625
INFO:root:Artifacts: Make stick videos for epoch 369
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_369_on_20220424_024040.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_369_index_1072_on_20220424_024040.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 370): Loss/seq after 00000 batchs: 368.06719970703125
INFO:root:Train (Epoch 370): Loss/seq after 00050 batchs: 404.30767822265625
INFO:root:Train (Epoch 370): Loss/seq after 00100 batchs: 416.44537353515625
INFO:root:Train (Epoch 370): Loss/seq after 00150 batchs: 385.0011901855469
INFO:root:Train (Epoch 370): Loss/seq after 00200 batchs: 426.24591064453125
INFO:root:Train (Epoch 370): Loss/seq after 00250 batchs: 446.8834533691406
INFO:root:Train (Epoch 370): Loss/seq after 00300 batchs: 462.5254211425781
INFO:root:Train (Epoch 370): Loss/seq after 00350 batchs: 442.4791564941406
INFO:root:Train (Epoch 370): Loss/seq after 00400 batchs: 433.3293762207031
INFO:root:Train (Epoch 370): Loss/seq after 00450 batchs: 446.72601318359375
INFO:root:Train (Epoch 370): Loss/seq after 00500 batchs: 432.1959533691406
INFO:root:Train (Epoch 370): Loss/seq after 00550 batchs: 426.10760498046875
INFO:root:Train (Epoch 370): Loss/seq after 00600 batchs: 410.86810302734375
INFO:root:Train (Epoch 370): Loss/seq after 00650 batchs: 394.7778015136719
INFO:root:Train (Epoch 370): Loss/seq after 00700 batchs: 379.812255859375
INFO:root:Train (Epoch 370): Loss/seq after 00750 batchs: 373.4042663574219
INFO:root:Train (Epoch 370): Loss/seq after 00800 batchs: 372.79742431640625
INFO:root:Train (Epoch 370): Loss/seq after 00850 batchs: 361.22918701171875
INFO:root:Train (Epoch 370): Loss/seq after 00900 batchs: 351.71221923828125
INFO:root:Train (Epoch 370): Loss/seq after 00950 batchs: 349.5931396484375
INFO:root:Train (Epoch 370): Loss/seq after 01000 batchs: 342.7090759277344
INFO:root:Train (Epoch 370): Loss/seq after 01050 batchs: 335.33349609375
INFO:root:Train (Epoch 370): Loss/seq after 01100 batchs: 327.1958923339844
INFO:root:Train (Epoch 370): Loss/seq after 01150 batchs: 318.59716796875
INFO:root:Train (Epoch 370): Loss/seq after 01200 batchs: 316.815673828125
INFO:root:Train (Epoch 370): Loss/seq after 01250 batchs: 315.5994873046875
INFO:root:Train (Epoch 370): Loss/seq after 01300 batchs: 308.8920593261719
INFO:root:Train (Epoch 370): Loss/seq after 01350 batchs: 302.2298583984375
INFO:root:Train (Epoch 370): Loss/seq after 01400 batchs: 302.6189880371094
INFO:root:Train (Epoch 370): Loss/seq after 01450 batchs: 304.1261901855469
INFO:root:Train (Epoch 370): Loss/seq after 01500 batchs: 308.9620666503906
INFO:root:Train (Epoch 370): Loss/seq after 01550 batchs: 309.807373046875
INFO:root:Train (Epoch 370): Loss/seq after 01600 batchs: 308.8833923339844
INFO:root:Train (Epoch 370): Loss/seq after 01650 batchs: 307.6550598144531
INFO:root:Train (Epoch 370): Loss/seq after 01700 batchs: 308.104248046875
INFO:root:Train (Epoch 370): Loss/seq after 01750 batchs: 307.33258056640625
INFO:root:Train (Epoch 370): Loss/seq after 01800 batchs: 306.4130554199219
INFO:root:Train (Epoch 370): Loss/seq after 01850 batchs: 305.32366943359375
INFO:root:Train (Epoch 370): Loss/seq after 01900 batchs: 304.85186767578125
INFO:root:Train (Epoch 370): Loss/seq after 01950 batchs: 304.92681884765625
INFO:root:Train (Epoch 370): Loss/seq after 02000 batchs: 307.0155334472656
INFO:root:Train (Epoch 370): Loss/seq after 02050 batchs: 307.4365234375
INFO:root:Train (Epoch 370): Loss/seq after 02100 batchs: 307.3795166015625
INFO:root:Train (Epoch 370): Loss/seq after 02150 batchs: 307.6515808105469
INFO:root:Train (Epoch 370): Loss/seq after 02200 batchs: 307.2798156738281
INFO:root:Train (Epoch 370): Loss/seq after 02250 batchs: 306.7000427246094
INFO:root:Train (Epoch 370): Loss/seq after 02300 batchs: 305.07330322265625
INFO:root:Train (Epoch 370): Loss/seq after 02350 batchs: 303.4112548828125
INFO:root:Train (Epoch 370): Loss/seq after 02400 batchs: 302.9218444824219
INFO:root:Train (Epoch 370): Loss/seq after 02450 batchs: 300.6815490722656
INFO:root:Train (Epoch 370): Loss/seq after 02500 batchs: 295.7569580078125
INFO:root:Train (Epoch 370): Loss/seq after 02550 batchs: 291.5226135253906
INFO:root:Train (Epoch 370): Loss/seq after 02600 batchs: 288.0614013671875
INFO:root:Train (Epoch 370): Loss/seq after 02650 batchs: 284.93743896484375
INFO:root:Train (Epoch 370): Loss/seq after 02700 batchs: 282.92144775390625
INFO:root:Train (Epoch 370): Loss/seq after 02750 batchs: 279.73236083984375
INFO:root:Train (Epoch 370): Loss/seq after 02800 batchs: 277.9580993652344
INFO:root:Train (Epoch 370): Loss/seq after 02850 batchs: 277.6399230957031
INFO:root:Train (Epoch 370): Loss/seq after 02900 batchs: 277.7213439941406
INFO:root:Train (Epoch 370): Loss/seq after 02950 batchs: 278.7437744140625
INFO:root:Train (Epoch 370): Loss/seq after 03000 batchs: 281.5978088378906
INFO:root:Train (Epoch 370): Loss/seq after 03050 batchs: 282.8703308105469
INFO:root:Train (Epoch 370): Loss/seq after 03100 batchs: 284.0205078125
INFO:root:Train (Epoch 370): Loss/seq after 03150 batchs: 283.3080139160156
INFO:root:Train (Epoch 370): Loss/seq after 03200 batchs: 283.4676208496094
INFO:root:Train (Epoch 370): Loss/seq after 03250 batchs: 282.8485107421875
INFO:root:Train (Epoch 370): Loss/seq after 03300 batchs: 282.1567077636719
INFO:root:Train (Epoch 370): Loss/seq after 03350 batchs: 281.0299377441406
INFO:root:Train (Epoch 370): Loss/seq after 03400 batchs: 279.4250183105469
INFO:root:Train (Epoch 370): Loss/seq after 03450 batchs: 278.4044189453125
INFO:root:Train (Epoch 370): Loss/seq after 03500 batchs: 279.4842529296875
INFO:root:Train (Epoch 370): Loss/seq after 03550 batchs: 278.56951904296875
INFO:root:Train (Epoch 370): Loss/seq after 03600 batchs: 280.6315612792969
INFO:root:Train (Epoch 370): Loss/seq after 03650 batchs: 279.9373779296875
INFO:root:Train (Epoch 370): Loss/seq after 03700 batchs: 281.35491943359375
INFO:root:Train (Epoch 370): Loss/seq after 03750 batchs: 284.1983642578125
INFO:root:Train (Epoch 370): Loss/seq after 03800 batchs: 284.4274597167969
INFO:root:Train (Epoch 370): Loss/seq after 03850 batchs: 284.0882568359375
INFO:root:Train (Epoch 370): Loss/seq after 03900 batchs: 285.19287109375
INFO:root:Train (Epoch 370): Loss/seq after 03950 batchs: 286.830078125
INFO:root:Train (Epoch 370): Loss/seq after 04000 batchs: 285.5943298339844
INFO:root:Train (Epoch 370): Loss/seq after 04050 batchs: 284.16485595703125
INFO:root:Train (Epoch 370): Loss/seq after 04100 batchs: 283.25799560546875
INFO:root:Train (Epoch 370): Loss/seq after 04150 batchs: 283.12896728515625
INFO:root:Train (Epoch 370): Loss/seq after 04200 batchs: 282.8334655761719
INFO:root:Train (Epoch 370): Loss/seq after 04250 batchs: 282.0714111328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 370): Loss/seq after 00000 batches: 260.34283447265625
INFO:root:# Valid (Epoch 370): Loss/seq after 00050 batches: 668.3370971679688
INFO:root:# Valid (Epoch 370): Loss/seq after 00100 batches: 712.8038330078125
INFO:root:# Valid (Epoch 370): Loss/seq after 00150 batches: 530.8474731445312
INFO:root:# Valid (Epoch 370): Loss/seq after 00200 batches: 492.87286376953125
INFO:root:Artifacts: Make stick videos for epoch 370
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_370_on_20220424_024531.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_370_index_584_on_20220424_024531.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 371): Loss/seq after 00000 batchs: 292.2336730957031
INFO:root:Train (Epoch 371): Loss/seq after 00050 batchs: 383.86798095703125
INFO:root:Train (Epoch 371): Loss/seq after 00100 batchs: 372.0240173339844
INFO:root:Train (Epoch 371): Loss/seq after 00150 batchs: 353.0736389160156
INFO:root:Train (Epoch 371): Loss/seq after 00200 batchs: 391.71624755859375
INFO:root:Train (Epoch 371): Loss/seq after 00250 batchs: 402.1264343261719
INFO:root:Train (Epoch 371): Loss/seq after 00300 batchs: 422.2190856933594
INFO:root:Train (Epoch 371): Loss/seq after 00350 batchs: 407.14306640625
INFO:root:Train (Epoch 371): Loss/seq after 00400 batchs: 398.8052978515625
INFO:root:Train (Epoch 371): Loss/seq after 00450 batchs: 415.6488342285156
INFO:root:Train (Epoch 371): Loss/seq after 00500 batchs: 402.4915466308594
INFO:root:Train (Epoch 371): Loss/seq after 00550 batchs: 397.8028564453125
INFO:root:Train (Epoch 371): Loss/seq after 00600 batchs: 383.7989807128906
INFO:root:Train (Epoch 371): Loss/seq after 00650 batchs: 367.5588684082031
INFO:root:Train (Epoch 371): Loss/seq after 00700 batchs: 351.67327880859375
INFO:root:Train (Epoch 371): Loss/seq after 00750 batchs: 346.04168701171875
INFO:root:Train (Epoch 371): Loss/seq after 00800 batchs: 345.5807189941406
INFO:root:Train (Epoch 371): Loss/seq after 00850 batchs: 334.6429138183594
INFO:root:Train (Epoch 371): Loss/seq after 00900 batchs: 326.45062255859375
INFO:root:Train (Epoch 371): Loss/seq after 00950 batchs: 325.0242614746094
INFO:root:Train (Epoch 371): Loss/seq after 01000 batchs: 319.5884704589844
INFO:root:Train (Epoch 371): Loss/seq after 01050 batchs: 313.7337951660156
INFO:root:Train (Epoch 371): Loss/seq after 01100 batchs: 306.5689697265625
INFO:root:Train (Epoch 371): Loss/seq after 01150 batchs: 298.34613037109375
INFO:root:Train (Epoch 371): Loss/seq after 01200 batchs: 297.7658386230469
INFO:root:Train (Epoch 371): Loss/seq after 01250 batchs: 297.1160583496094
INFO:root:Train (Epoch 371): Loss/seq after 01300 batchs: 291.1304626464844
INFO:root:Train (Epoch 371): Loss/seq after 01350 batchs: 285.4748840332031
INFO:root:Train (Epoch 371): Loss/seq after 01400 batchs: 286.42437744140625
INFO:root:Train (Epoch 371): Loss/seq after 01450 batchs: 288.2171325683594
INFO:root:Train (Epoch 371): Loss/seq after 01500 batchs: 293.6254577636719
INFO:root:Train (Epoch 371): Loss/seq after 01550 batchs: 295.0763854980469
INFO:root:Train (Epoch 371): Loss/seq after 01600 batchs: 294.6132507324219
INFO:root:Train (Epoch 371): Loss/seq after 01650 batchs: 293.9703369140625
INFO:root:Train (Epoch 371): Loss/seq after 01700 batchs: 294.9686279296875
INFO:root:Train (Epoch 371): Loss/seq after 01750 batchs: 294.4522399902344
INFO:root:Train (Epoch 371): Loss/seq after 01800 batchs: 293.9285583496094
INFO:root:Train (Epoch 371): Loss/seq after 01850 batchs: 293.38671875
INFO:root:Train (Epoch 371): Loss/seq after 01900 batchs: 293.2932434082031
INFO:root:Train (Epoch 371): Loss/seq after 01950 batchs: 293.72314453125
INFO:root:Train (Epoch 371): Loss/seq after 02000 batchs: 296.1501159667969
INFO:root:Train (Epoch 371): Loss/seq after 02050 batchs: 296.93463134765625
INFO:root:Train (Epoch 371): Loss/seq after 02100 batchs: 296.9832458496094
INFO:root:Train (Epoch 371): Loss/seq after 02150 batchs: 297.3989562988281
INFO:root:Train (Epoch 371): Loss/seq after 02200 batchs: 297.1269836425781
INFO:root:Train (Epoch 371): Loss/seq after 02250 batchs: 296.587158203125
INFO:root:Train (Epoch 371): Loss/seq after 02300 batchs: 294.8878173828125
INFO:root:Train (Epoch 371): Loss/seq after 02350 batchs: 293.39990234375
INFO:root:Train (Epoch 371): Loss/seq after 02400 batchs: 293.427001953125
INFO:root:Train (Epoch 371): Loss/seq after 02450 batchs: 291.5216064453125
INFO:root:Train (Epoch 371): Loss/seq after 02500 batchs: 286.7608642578125
INFO:root:Train (Epoch 371): Loss/seq after 02550 batchs: 282.7286682128906
INFO:root:Train (Epoch 371): Loss/seq after 02600 batchs: 279.3243103027344
INFO:root:Train (Epoch 371): Loss/seq after 02650 batchs: 276.3645935058594
INFO:root:Train (Epoch 371): Loss/seq after 02700 batchs: 274.56689453125
INFO:root:Train (Epoch 371): Loss/seq after 02750 batchs: 271.3855285644531
INFO:root:Train (Epoch 371): Loss/seq after 02800 batchs: 269.7682189941406
INFO:root:Train (Epoch 371): Loss/seq after 02850 batchs: 269.637451171875
INFO:root:Train (Epoch 371): Loss/seq after 02900 batchs: 269.69110107421875
INFO:root:Train (Epoch 371): Loss/seq after 02950 batchs: 270.72723388671875
INFO:root:Train (Epoch 371): Loss/seq after 03000 batchs: 273.1124572753906
INFO:root:Train (Epoch 371): Loss/seq after 03050 batchs: 274.0848083496094
INFO:root:Train (Epoch 371): Loss/seq after 03100 batchs: 275.5872802734375
INFO:root:Train (Epoch 371): Loss/seq after 03150 batchs: 275.3126220703125
INFO:root:Train (Epoch 371): Loss/seq after 03200 batchs: 275.9855041503906
INFO:root:Train (Epoch 371): Loss/seq after 03250 batchs: 276.1002197265625
INFO:root:Train (Epoch 371): Loss/seq after 03300 batchs: 276.13482666015625
INFO:root:Train (Epoch 371): Loss/seq after 03350 batchs: 275.5120544433594
INFO:root:Train (Epoch 371): Loss/seq after 03400 batchs: 274.02447509765625
INFO:root:Train (Epoch 371): Loss/seq after 03450 batchs: 273.08251953125
INFO:root:Train (Epoch 371): Loss/seq after 03500 batchs: 274.36285400390625
INFO:root:Train (Epoch 371): Loss/seq after 03550 batchs: 273.4731750488281
INFO:root:Train (Epoch 371): Loss/seq after 03600 batchs: 275.6632080078125
INFO:root:Train (Epoch 371): Loss/seq after 03650 batchs: 274.747802734375
INFO:root:Train (Epoch 371): Loss/seq after 03700 batchs: 276.1126708984375
INFO:root:Train (Epoch 371): Loss/seq after 03750 batchs: 279.0478210449219
INFO:root:Train (Epoch 371): Loss/seq after 03800 batchs: 279.33087158203125
INFO:root:Train (Epoch 371): Loss/seq after 03850 batchs: 279.0349426269531
INFO:root:Train (Epoch 371): Loss/seq after 03900 batchs: 280.0517578125
INFO:root:Train (Epoch 371): Loss/seq after 03950 batchs: 281.52337646484375
INFO:root:Train (Epoch 371): Loss/seq after 04000 batchs: 280.3372497558594
INFO:root:Train (Epoch 371): Loss/seq after 04050 batchs: 278.9437561035156
INFO:root:Train (Epoch 371): Loss/seq after 04100 batchs: 278.0468444824219
INFO:root:Train (Epoch 371): Loss/seq after 04150 batchs: 277.95391845703125
INFO:root:Train (Epoch 371): Loss/seq after 04200 batchs: 277.66339111328125
INFO:root:Train (Epoch 371): Loss/seq after 04250 batchs: 276.9840087890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 371): Loss/seq after 00000 batches: 269.85589599609375
INFO:root:# Valid (Epoch 371): Loss/seq after 00050 batches: 650.3814086914062
INFO:root:# Valid (Epoch 371): Loss/seq after 00100 batches: 691.0997924804688
INFO:root:# Valid (Epoch 371): Loss/seq after 00150 batches: 514.4943237304688
INFO:root:# Valid (Epoch 371): Loss/seq after 00200 batches: 472.288818359375
INFO:root:Artifacts: Make stick videos for epoch 371
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_371_on_20220424_025021.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_371_index_1179_on_20220424_025021.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 372): Loss/seq after 00000 batchs: 539.0477294921875
INFO:root:Train (Epoch 372): Loss/seq after 00050 batchs: 384.9028625488281
INFO:root:Train (Epoch 372): Loss/seq after 00100 batchs: 378.4728698730469
INFO:root:Train (Epoch 372): Loss/seq after 00150 batchs: 356.2048034667969
INFO:root:Train (Epoch 372): Loss/seq after 00200 batchs: 404.0285949707031
INFO:root:Train (Epoch 372): Loss/seq after 00250 batchs: 423.0451965332031
INFO:root:Train (Epoch 372): Loss/seq after 00300 batchs: 440.4658203125
INFO:root:Train (Epoch 372): Loss/seq after 00350 batchs: 421.18634033203125
INFO:root:Train (Epoch 372): Loss/seq after 00400 batchs: 411.9860534667969
INFO:root:Train (Epoch 372): Loss/seq after 00450 batchs: 427.94281005859375
INFO:root:Train (Epoch 372): Loss/seq after 00500 batchs: 414.6758728027344
INFO:root:Train (Epoch 372): Loss/seq after 00550 batchs: 408.51251220703125
INFO:root:Train (Epoch 372): Loss/seq after 00600 batchs: 393.0858154296875
INFO:root:Train (Epoch 372): Loss/seq after 00650 batchs: 376.8402404785156
INFO:root:Train (Epoch 372): Loss/seq after 00700 batchs: 360.8011169433594
INFO:root:Train (Epoch 372): Loss/seq after 00750 batchs: 356.335205078125
INFO:root:Train (Epoch 372): Loss/seq after 00800 batchs: 354.46728515625
INFO:root:Train (Epoch 372): Loss/seq after 00850 batchs: 342.9263916015625
INFO:root:Train (Epoch 372): Loss/seq after 00900 batchs: 334.2925109863281
INFO:root:Train (Epoch 372): Loss/seq after 00950 batchs: 333.9344177246094
INFO:root:Train (Epoch 372): Loss/seq after 01000 batchs: 328.1477966308594
INFO:root:Train (Epoch 372): Loss/seq after 01050 batchs: 323.53790283203125
INFO:root:Train (Epoch 372): Loss/seq after 01100 batchs: 316.43011474609375
INFO:root:Train (Epoch 372): Loss/seq after 01150 batchs: 308.16021728515625
INFO:root:Train (Epoch 372): Loss/seq after 01200 batchs: 307.9964599609375
INFO:root:Train (Epoch 372): Loss/seq after 01250 batchs: 307.97967529296875
INFO:root:Train (Epoch 372): Loss/seq after 01300 batchs: 301.4695739746094
INFO:root:Train (Epoch 372): Loss/seq after 01350 batchs: 295.1142883300781
INFO:root:Train (Epoch 372): Loss/seq after 01400 batchs: 296.4378662109375
INFO:root:Train (Epoch 372): Loss/seq after 01450 batchs: 298.0845642089844
INFO:root:Train (Epoch 372): Loss/seq after 01500 batchs: 302.7771911621094
INFO:root:Train (Epoch 372): Loss/seq after 01550 batchs: 303.5361022949219
INFO:root:Train (Epoch 372): Loss/seq after 01600 batchs: 302.6794128417969
INFO:root:Train (Epoch 372): Loss/seq after 01650 batchs: 301.65386962890625
INFO:root:Train (Epoch 372): Loss/seq after 01700 batchs: 302.5536804199219
INFO:root:Train (Epoch 372): Loss/seq after 01750 batchs: 302.09033203125
INFO:root:Train (Epoch 372): Loss/seq after 01800 batchs: 301.3779296875
INFO:root:Train (Epoch 372): Loss/seq after 01850 batchs: 300.567138671875
INFO:root:Train (Epoch 372): Loss/seq after 01900 batchs: 300.2861633300781
INFO:root:Train (Epoch 372): Loss/seq after 01950 batchs: 300.4546203613281
INFO:root:Train (Epoch 372): Loss/seq after 02000 batchs: 302.920654296875
INFO:root:Train (Epoch 372): Loss/seq after 02050 batchs: 303.4194641113281
INFO:root:Train (Epoch 372): Loss/seq after 02100 batchs: 303.4347229003906
INFO:root:Train (Epoch 372): Loss/seq after 02150 batchs: 303.703125
INFO:root:Train (Epoch 372): Loss/seq after 02200 batchs: 303.4772644042969
INFO:root:Train (Epoch 372): Loss/seq after 02250 batchs: 303.3537902832031
INFO:root:Train (Epoch 372): Loss/seq after 02300 batchs: 301.6094055175781
INFO:root:Train (Epoch 372): Loss/seq after 02350 batchs: 300.0706481933594
INFO:root:Train (Epoch 372): Loss/seq after 02400 batchs: 299.75177001953125
INFO:root:Train (Epoch 372): Loss/seq after 02450 batchs: 297.5372314453125
INFO:root:Train (Epoch 372): Loss/seq after 02500 batchs: 292.7031555175781
INFO:root:Train (Epoch 372): Loss/seq after 02550 batchs: 288.55877685546875
INFO:root:Train (Epoch 372): Loss/seq after 02600 batchs: 285.1116638183594
INFO:root:Train (Epoch 372): Loss/seq after 02650 batchs: 282.0994567871094
INFO:root:Train (Epoch 372): Loss/seq after 02700 batchs: 280.1205749511719
INFO:root:Train (Epoch 372): Loss/seq after 02750 batchs: 276.8883056640625
INFO:root:Train (Epoch 372): Loss/seq after 02800 batchs: 275.5225830078125
INFO:root:Train (Epoch 372): Loss/seq after 02850 batchs: 275.1298828125
INFO:root:Train (Epoch 372): Loss/seq after 02900 batchs: 275.6073913574219
INFO:root:Train (Epoch 372): Loss/seq after 02950 batchs: 276.7958984375
INFO:root:Train (Epoch 372): Loss/seq after 03000 batchs: 279.4771728515625
INFO:root:Train (Epoch 372): Loss/seq after 03050 batchs: 280.49346923828125
INFO:root:Train (Epoch 372): Loss/seq after 03100 batchs: 282.3355407714844
INFO:root:Train (Epoch 372): Loss/seq after 03150 batchs: 282.9385681152344
INFO:root:Train (Epoch 372): Loss/seq after 03200 batchs: 283.5420837402344
INFO:root:Train (Epoch 372): Loss/seq after 03250 batchs: 283.213134765625
INFO:root:Train (Epoch 372): Loss/seq after 03300 batchs: 283.1318359375
INFO:root:Train (Epoch 372): Loss/seq after 03350 batchs: 282.3414001464844
INFO:root:Train (Epoch 372): Loss/seq after 03400 batchs: 280.7104797363281
INFO:root:Train (Epoch 372): Loss/seq after 03450 batchs: 279.67535400390625
INFO:root:Train (Epoch 372): Loss/seq after 03500 batchs: 281.3084716796875
INFO:root:Train (Epoch 372): Loss/seq after 03550 batchs: 280.4566345214844
INFO:root:Train (Epoch 372): Loss/seq after 03600 batchs: 283.3421630859375
INFO:root:Train (Epoch 372): Loss/seq after 03650 batchs: 282.7268371582031
INFO:root:Train (Epoch 372): Loss/seq after 03700 batchs: 284.5218505859375
INFO:root:Train (Epoch 372): Loss/seq after 03750 batchs: 287.6994934082031
INFO:root:Train (Epoch 372): Loss/seq after 03800 batchs: 287.9511413574219
INFO:root:Train (Epoch 372): Loss/seq after 03850 batchs: 287.53155517578125
INFO:root:Train (Epoch 372): Loss/seq after 03900 batchs: 289.10137939453125
INFO:root:Train (Epoch 372): Loss/seq after 03950 batchs: 291.03326416015625
INFO:root:Train (Epoch 372): Loss/seq after 04000 batchs: 289.7460632324219
INFO:root:Train (Epoch 372): Loss/seq after 04050 batchs: 288.3117980957031
INFO:root:Train (Epoch 372): Loss/seq after 04100 batchs: 287.44873046875
INFO:root:Train (Epoch 372): Loss/seq after 04150 batchs: 287.2652587890625
INFO:root:Train (Epoch 372): Loss/seq after 04200 batchs: 286.88800048828125
INFO:root:Train (Epoch 372): Loss/seq after 04250 batchs: 285.9918212890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 372): Loss/seq after 00000 batches: 229.12979125976562
INFO:root:# Valid (Epoch 372): Loss/seq after 00050 batches: 643.8629150390625
INFO:root:# Valid (Epoch 372): Loss/seq after 00100 batches: 637.4122314453125
INFO:root:# Valid (Epoch 372): Loss/seq after 00150 batches: 481.34710693359375
INFO:root:# Valid (Epoch 372): Loss/seq after 00200 batches: 448.5709533691406
INFO:root:Artifacts: Make stick videos for epoch 372
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_372_on_20220424_025520.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_372_index_6_on_20220424_025520.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 373): Loss/seq after 00000 batchs: 882.885986328125
INFO:root:Train (Epoch 373): Loss/seq after 00050 batchs: 427.88995361328125
INFO:root:Train (Epoch 373): Loss/seq after 00100 batchs: 430.13568115234375
INFO:root:Train (Epoch 373): Loss/seq after 00150 batchs: 391.887451171875
INFO:root:Train (Epoch 373): Loss/seq after 00200 batchs: 433.8453063964844
INFO:root:Train (Epoch 373): Loss/seq after 00250 batchs: 437.5128479003906
INFO:root:Train (Epoch 373): Loss/seq after 00300 batchs: 453.3088073730469
INFO:root:Train (Epoch 373): Loss/seq after 00350 batchs: 433.4597473144531
INFO:root:Train (Epoch 373): Loss/seq after 00400 batchs: 428.4735107421875
INFO:root:Train (Epoch 373): Loss/seq after 00450 batchs: 442.29254150390625
INFO:root:Train (Epoch 373): Loss/seq after 00500 batchs: 428.02703857421875
INFO:root:Train (Epoch 373): Loss/seq after 00550 batchs: 423.04461669921875
INFO:root:Train (Epoch 373): Loss/seq after 00600 batchs: 407.4070129394531
INFO:root:Train (Epoch 373): Loss/seq after 00650 batchs: 393.15087890625
INFO:root:Train (Epoch 373): Loss/seq after 00700 batchs: 376.5281982421875
INFO:root:Train (Epoch 373): Loss/seq after 00750 batchs: 369.41680908203125
INFO:root:Train (Epoch 373): Loss/seq after 00800 batchs: 369.9312438964844
INFO:root:Train (Epoch 373): Loss/seq after 00850 batchs: 357.7816467285156
INFO:root:Train (Epoch 373): Loss/seq after 00900 batchs: 348.28717041015625
INFO:root:Train (Epoch 373): Loss/seq after 00950 batchs: 347.83331298828125
INFO:root:Train (Epoch 373): Loss/seq after 01000 batchs: 341.5503234863281
INFO:root:Train (Epoch 373): Loss/seq after 01050 batchs: 334.01129150390625
INFO:root:Train (Epoch 373): Loss/seq after 01100 batchs: 325.8031005859375
INFO:root:Train (Epoch 373): Loss/seq after 01150 batchs: 316.75341796875
INFO:root:Train (Epoch 373): Loss/seq after 01200 batchs: 315.1976013183594
INFO:root:Train (Epoch 373): Loss/seq after 01250 batchs: 313.8276672363281
INFO:root:Train (Epoch 373): Loss/seq after 01300 batchs: 307.4364013671875
INFO:root:Train (Epoch 373): Loss/seq after 01350 batchs: 300.6814880371094
INFO:root:Train (Epoch 373): Loss/seq after 01400 batchs: 300.8980712890625
INFO:root:Train (Epoch 373): Loss/seq after 01450 batchs: 302.1761169433594
INFO:root:Train (Epoch 373): Loss/seq after 01500 batchs: 307.0657043457031
INFO:root:Train (Epoch 373): Loss/seq after 01550 batchs: 307.5596008300781
INFO:root:Train (Epoch 373): Loss/seq after 01600 batchs: 306.709228515625
INFO:root:Train (Epoch 373): Loss/seq after 01650 batchs: 305.3209228515625
INFO:root:Train (Epoch 373): Loss/seq after 01700 batchs: 305.5806884765625
INFO:root:Train (Epoch 373): Loss/seq after 01750 batchs: 304.70770263671875
INFO:root:Train (Epoch 373): Loss/seq after 01800 batchs: 303.7386779785156
INFO:root:Train (Epoch 373): Loss/seq after 01850 batchs: 302.8133850097656
INFO:root:Train (Epoch 373): Loss/seq after 01900 batchs: 302.53363037109375
INFO:root:Train (Epoch 373): Loss/seq after 01950 batchs: 302.8210754394531
INFO:root:Train (Epoch 373): Loss/seq after 02000 batchs: 305.1385498046875
INFO:root:Train (Epoch 373): Loss/seq after 02050 batchs: 305.75030517578125
INFO:root:Train (Epoch 373): Loss/seq after 02100 batchs: 305.60992431640625
INFO:root:Train (Epoch 373): Loss/seq after 02150 batchs: 305.6551513671875
INFO:root:Train (Epoch 373): Loss/seq after 02200 batchs: 305.30029296875
INFO:root:Train (Epoch 373): Loss/seq after 02250 batchs: 304.4486389160156
INFO:root:Train (Epoch 373): Loss/seq after 02300 batchs: 302.3078918457031
INFO:root:Train (Epoch 373): Loss/seq after 02350 batchs: 300.6461181640625
INFO:root:Train (Epoch 373): Loss/seq after 02400 batchs: 300.1734619140625
INFO:root:Train (Epoch 373): Loss/seq after 02450 batchs: 298.1502685546875
INFO:root:Train (Epoch 373): Loss/seq after 02500 batchs: 293.2613220214844
INFO:root:Train (Epoch 373): Loss/seq after 02550 batchs: 289.0886535644531
INFO:root:Train (Epoch 373): Loss/seq after 02600 batchs: 285.72607421875
INFO:root:Train (Epoch 373): Loss/seq after 02650 batchs: 282.7249755859375
INFO:root:Train (Epoch 373): Loss/seq after 02700 batchs: 280.888916015625
INFO:root:Train (Epoch 373): Loss/seq after 02750 batchs: 277.6794738769531
INFO:root:Train (Epoch 373): Loss/seq after 02800 batchs: 276.0495910644531
INFO:root:Train (Epoch 373): Loss/seq after 02850 batchs: 275.765380859375
INFO:root:Train (Epoch 373): Loss/seq after 02900 batchs: 275.7438659667969
INFO:root:Train (Epoch 373): Loss/seq after 02950 batchs: 276.6755065917969
INFO:root:Train (Epoch 373): Loss/seq after 03000 batchs: 279.1860046386719
INFO:root:Train (Epoch 373): Loss/seq after 03050 batchs: 280.4752502441406
INFO:root:Train (Epoch 373): Loss/seq after 03100 batchs: 281.94720458984375
INFO:root:Train (Epoch 373): Loss/seq after 03150 batchs: 281.68408203125
INFO:root:Train (Epoch 373): Loss/seq after 03200 batchs: 281.3843688964844
INFO:root:Train (Epoch 373): Loss/seq after 03250 batchs: 280.77655029296875
INFO:root:Train (Epoch 373): Loss/seq after 03300 batchs: 280.8251037597656
INFO:root:Train (Epoch 373): Loss/seq after 03350 batchs: 279.75921630859375
INFO:root:Train (Epoch 373): Loss/seq after 03400 batchs: 278.20159912109375
INFO:root:Train (Epoch 373): Loss/seq after 03450 batchs: 277.2214660644531
INFO:root:Train (Epoch 373): Loss/seq after 03500 batchs: 278.608642578125
INFO:root:Train (Epoch 373): Loss/seq after 03550 batchs: 277.705810546875
INFO:root:Train (Epoch 373): Loss/seq after 03600 batchs: 280.166748046875
INFO:root:Train (Epoch 373): Loss/seq after 03650 batchs: 279.2916564941406
INFO:root:Train (Epoch 373): Loss/seq after 03700 batchs: 281.0995178222656
INFO:root:Train (Epoch 373): Loss/seq after 03750 batchs: 283.9903869628906
INFO:root:Train (Epoch 373): Loss/seq after 03800 batchs: 284.3185119628906
INFO:root:Train (Epoch 373): Loss/seq after 03850 batchs: 284.1195373535156
INFO:root:Train (Epoch 373): Loss/seq after 03900 batchs: 285.27069091796875
INFO:root:Train (Epoch 373): Loss/seq after 03950 batchs: 287.0729064941406
INFO:root:Train (Epoch 373): Loss/seq after 04000 batchs: 285.8206787109375
INFO:root:Train (Epoch 373): Loss/seq after 04050 batchs: 284.4255676269531
INFO:root:Train (Epoch 373): Loss/seq after 04100 batchs: 283.5881652832031
INFO:root:Train (Epoch 373): Loss/seq after 04150 batchs: 283.41265869140625
INFO:root:Train (Epoch 373): Loss/seq after 04200 batchs: 283.0613708496094
INFO:root:Train (Epoch 373): Loss/seq after 04250 batchs: 282.27191162109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 373): Loss/seq after 00000 batches: 309.88348388671875
INFO:root:# Valid (Epoch 373): Loss/seq after 00050 batches: 639.3355102539062
INFO:root:# Valid (Epoch 373): Loss/seq after 00100 batches: 678.9656372070312
INFO:root:# Valid (Epoch 373): Loss/seq after 00150 batches: 503.26129150390625
INFO:root:# Valid (Epoch 373): Loss/seq after 00200 batches: 465.14410400390625
INFO:root:Artifacts: Make stick videos for epoch 373
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_373_on_20220424_030005.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_373_index_490_on_20220424_030005.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 374): Loss/seq after 00000 batchs: 320.9611511230469
INFO:root:Train (Epoch 374): Loss/seq after 00050 batchs: 377.7513427734375
INFO:root:Train (Epoch 374): Loss/seq after 00100 batchs: 381.1656494140625
INFO:root:Train (Epoch 374): Loss/seq after 00150 batchs: 358.1693115234375
INFO:root:Train (Epoch 374): Loss/seq after 00200 batchs: 408.9446105957031
INFO:root:Train (Epoch 374): Loss/seq after 00250 batchs: 421.7494201660156
INFO:root:Train (Epoch 374): Loss/seq after 00300 batchs: 439.904541015625
INFO:root:Train (Epoch 374): Loss/seq after 00350 batchs: 420.3930358886719
INFO:root:Train (Epoch 374): Loss/seq after 00400 batchs: 410.76934814453125
INFO:root:Train (Epoch 374): Loss/seq after 00450 batchs: 426.2625427246094
INFO:root:Train (Epoch 374): Loss/seq after 00500 batchs: 411.9522399902344
INFO:root:Train (Epoch 374): Loss/seq after 00550 batchs: 406.6080322265625
INFO:root:Train (Epoch 374): Loss/seq after 00600 batchs: 393.0157470703125
INFO:root:Train (Epoch 374): Loss/seq after 00650 batchs: 375.7843017578125
INFO:root:Train (Epoch 374): Loss/seq after 00700 batchs: 359.4915771484375
INFO:root:Train (Epoch 374): Loss/seq after 00750 batchs: 353.29632568359375
INFO:root:Train (Epoch 374): Loss/seq after 00800 batchs: 353.4117431640625
INFO:root:Train (Epoch 374): Loss/seq after 00850 batchs: 342.3044128417969
INFO:root:Train (Epoch 374): Loss/seq after 00900 batchs: 334.03021240234375
INFO:root:Train (Epoch 374): Loss/seq after 00950 batchs: 333.6723327636719
INFO:root:Train (Epoch 374): Loss/seq after 01000 batchs: 327.6453552246094
INFO:root:Train (Epoch 374): Loss/seq after 01050 batchs: 320.7113342285156
INFO:root:Train (Epoch 374): Loss/seq after 01100 batchs: 313.18829345703125
INFO:root:Train (Epoch 374): Loss/seq after 01150 batchs: 304.8559265136719
INFO:root:Train (Epoch 374): Loss/seq after 01200 batchs: 304.05352783203125
INFO:root:Train (Epoch 374): Loss/seq after 01250 batchs: 303.7403869628906
INFO:root:Train (Epoch 374): Loss/seq after 01300 batchs: 298.3593444824219
INFO:root:Train (Epoch 374): Loss/seq after 01350 batchs: 292.660888671875
INFO:root:Train (Epoch 374): Loss/seq after 01400 batchs: 293.45098876953125
INFO:root:Train (Epoch 374): Loss/seq after 01450 batchs: 295.3958740234375
INFO:root:Train (Epoch 374): Loss/seq after 01500 batchs: 300.6701965332031
INFO:root:Train (Epoch 374): Loss/seq after 01550 batchs: 301.0148620605469
INFO:root:Train (Epoch 374): Loss/seq after 01600 batchs: 300.3234558105469
INFO:root:Train (Epoch 374): Loss/seq after 01650 batchs: 299.24066162109375
INFO:root:Train (Epoch 374): Loss/seq after 01700 batchs: 299.7479248046875
INFO:root:Train (Epoch 374): Loss/seq after 01750 batchs: 298.8477783203125
INFO:root:Train (Epoch 374): Loss/seq after 01800 batchs: 298.1080017089844
INFO:root:Train (Epoch 374): Loss/seq after 01850 batchs: 297.35205078125
INFO:root:Train (Epoch 374): Loss/seq after 01900 batchs: 297.0342712402344
INFO:root:Train (Epoch 374): Loss/seq after 01950 batchs: 297.3357238769531
INFO:root:Train (Epoch 374): Loss/seq after 02000 batchs: 299.6151428222656
INFO:root:Train (Epoch 374): Loss/seq after 02050 batchs: 300.22711181640625
INFO:root:Train (Epoch 374): Loss/seq after 02100 batchs: 300.3698425292969
INFO:root:Train (Epoch 374): Loss/seq after 02150 batchs: 300.7035217285156
INFO:root:Train (Epoch 374): Loss/seq after 02200 batchs: 300.4002685546875
INFO:root:Train (Epoch 374): Loss/seq after 02250 batchs: 299.6697998046875
INFO:root:Train (Epoch 374): Loss/seq after 02300 batchs: 298.0172424316406
INFO:root:Train (Epoch 374): Loss/seq after 02350 batchs: 296.29888916015625
INFO:root:Train (Epoch 374): Loss/seq after 02400 batchs: 295.7154541015625
INFO:root:Train (Epoch 374): Loss/seq after 02450 batchs: 293.5525207519531
INFO:root:Train (Epoch 374): Loss/seq after 02500 batchs: 288.73846435546875
INFO:root:Train (Epoch 374): Loss/seq after 02550 batchs: 284.57794189453125
INFO:root:Train (Epoch 374): Loss/seq after 02600 batchs: 281.2695617675781
INFO:root:Train (Epoch 374): Loss/seq after 02650 batchs: 278.2767028808594
INFO:root:Train (Epoch 374): Loss/seq after 02700 batchs: 276.3731384277344
INFO:root:Train (Epoch 374): Loss/seq after 02750 batchs: 273.1589660644531
INFO:root:Train (Epoch 374): Loss/seq after 02800 batchs: 272.0958557128906
INFO:root:Train (Epoch 374): Loss/seq after 02850 batchs: 271.8014221191406
INFO:root:Train (Epoch 374): Loss/seq after 02900 batchs: 272.1328430175781
INFO:root:Train (Epoch 374): Loss/seq after 02950 batchs: 273.3547668457031
INFO:root:Train (Epoch 374): Loss/seq after 03000 batchs: 276.133544921875
INFO:root:Train (Epoch 374): Loss/seq after 03050 batchs: 277.11236572265625
INFO:root:Train (Epoch 374): Loss/seq after 03100 batchs: 278.6161804199219
INFO:root:Train (Epoch 374): Loss/seq after 03150 batchs: 278.0393371582031
INFO:root:Train (Epoch 374): Loss/seq after 03200 batchs: 277.5231628417969
INFO:root:Train (Epoch 374): Loss/seq after 03250 batchs: 277.11456298828125
INFO:root:Train (Epoch 374): Loss/seq after 03300 batchs: 276.5227355957031
INFO:root:Train (Epoch 374): Loss/seq after 03350 batchs: 275.03228759765625
INFO:root:Train (Epoch 374): Loss/seq after 03400 batchs: 273.5030212402344
INFO:root:Train (Epoch 374): Loss/seq after 03450 batchs: 272.54937744140625
INFO:root:Train (Epoch 374): Loss/seq after 03500 batchs: 273.46533203125
INFO:root:Train (Epoch 374): Loss/seq after 03550 batchs: 272.5449523925781
INFO:root:Train (Epoch 374): Loss/seq after 03600 batchs: 274.6419982910156
INFO:root:Train (Epoch 374): Loss/seq after 03650 batchs: 273.7063293457031
INFO:root:Train (Epoch 374): Loss/seq after 03700 batchs: 275.0099792480469
INFO:root:Train (Epoch 374): Loss/seq after 03750 batchs: 278.03631591796875
INFO:root:Train (Epoch 374): Loss/seq after 03800 batchs: 278.33331298828125
INFO:root:Train (Epoch 374): Loss/seq after 03850 batchs: 278.0489196777344
INFO:root:Train (Epoch 374): Loss/seq after 03900 batchs: 278.8995361328125
INFO:root:Train (Epoch 374): Loss/seq after 03950 batchs: 280.723876953125
INFO:root:Train (Epoch 374): Loss/seq after 04000 batchs: 279.49700927734375
INFO:root:Train (Epoch 374): Loss/seq after 04050 batchs: 278.1434631347656
INFO:root:Train (Epoch 374): Loss/seq after 04100 batchs: 277.38287353515625
INFO:root:Train (Epoch 374): Loss/seq after 04150 batchs: 277.51995849609375
INFO:root:Train (Epoch 374): Loss/seq after 04200 batchs: 277.16510009765625
INFO:root:Train (Epoch 374): Loss/seq after 04250 batchs: 276.4584655761719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 374): Loss/seq after 00000 batches: 277.8567199707031
INFO:root:# Valid (Epoch 374): Loss/seq after 00050 batches: 634.8251342773438
INFO:root:# Valid (Epoch 374): Loss/seq after 00100 batches: 652.6686401367188
INFO:root:# Valid (Epoch 374): Loss/seq after 00150 batches: 487.867919921875
INFO:root:# Valid (Epoch 374): Loss/seq after 00200 batches: 453.0070495605469
INFO:root:Artifacts: Make stick videos for epoch 374
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_374_on_20220424_030450.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_374_index_1567_on_20220424_030450.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 375): Loss/seq after 00000 batchs: 576.1677856445312
INFO:root:Train (Epoch 375): Loss/seq after 00050 batchs: 369.3360595703125
INFO:root:Train (Epoch 375): Loss/seq after 00100 batchs: 365.9959716796875
INFO:root:Train (Epoch 375): Loss/seq after 00150 batchs: 347.5496826171875
INFO:root:Train (Epoch 375): Loss/seq after 00200 batchs: 391.7384338378906
INFO:root:Train (Epoch 375): Loss/seq after 00250 batchs: 420.7728271484375
INFO:root:Train (Epoch 375): Loss/seq after 00300 batchs: 440.9397888183594
INFO:root:Train (Epoch 375): Loss/seq after 00350 batchs: 421.7575988769531
INFO:root:Train (Epoch 375): Loss/seq after 00400 batchs: 415.7081604003906
INFO:root:Train (Epoch 375): Loss/seq after 00450 batchs: 429.8791198730469
INFO:root:Train (Epoch 375): Loss/seq after 00500 batchs: 420.3476257324219
INFO:root:Train (Epoch 375): Loss/seq after 00550 batchs: 414.1456604003906
INFO:root:Train (Epoch 375): Loss/seq after 00600 batchs: 399.0798645019531
INFO:root:Train (Epoch 375): Loss/seq after 00650 batchs: 382.8313903808594
INFO:root:Train (Epoch 375): Loss/seq after 00700 batchs: 366.7898254394531
INFO:root:Train (Epoch 375): Loss/seq after 00750 batchs: 359.8008728027344
INFO:root:Train (Epoch 375): Loss/seq after 00800 batchs: 359.2577209472656
INFO:root:Train (Epoch 375): Loss/seq after 00850 batchs: 347.17669677734375
INFO:root:Train (Epoch 375): Loss/seq after 00900 batchs: 338.32940673828125
INFO:root:Train (Epoch 375): Loss/seq after 00950 batchs: 337.8482666015625
INFO:root:Train (Epoch 375): Loss/seq after 01000 batchs: 331.9236145019531
INFO:root:Train (Epoch 375): Loss/seq after 01050 batchs: 325.6754150390625
INFO:root:Train (Epoch 375): Loss/seq after 01100 batchs: 317.959716796875
INFO:root:Train (Epoch 375): Loss/seq after 01150 batchs: 309.4456787109375
INFO:root:Train (Epoch 375): Loss/seq after 01200 batchs: 308.36749267578125
INFO:root:Train (Epoch 375): Loss/seq after 01250 batchs: 307.31475830078125
INFO:root:Train (Epoch 375): Loss/seq after 01300 batchs: 300.89190673828125
INFO:root:Train (Epoch 375): Loss/seq after 01350 batchs: 294.3752136230469
INFO:root:Train (Epoch 375): Loss/seq after 01400 batchs: 294.76263427734375
INFO:root:Train (Epoch 375): Loss/seq after 01450 batchs: 296.1455078125
INFO:root:Train (Epoch 375): Loss/seq after 01500 batchs: 301.3379211425781
INFO:root:Train (Epoch 375): Loss/seq after 01550 batchs: 301.9031066894531
INFO:root:Train (Epoch 375): Loss/seq after 01600 batchs: 300.9629821777344
INFO:root:Train (Epoch 375): Loss/seq after 01650 batchs: 299.97174072265625
INFO:root:Train (Epoch 375): Loss/seq after 01700 batchs: 300.9167785644531
INFO:root:Train (Epoch 375): Loss/seq after 01750 batchs: 300.1787414550781
INFO:root:Train (Epoch 375): Loss/seq after 01800 batchs: 299.4088134765625
INFO:root:Train (Epoch 375): Loss/seq after 01850 batchs: 298.5627136230469
INFO:root:Train (Epoch 375): Loss/seq after 01900 batchs: 298.37750244140625
INFO:root:Train (Epoch 375): Loss/seq after 01950 batchs: 298.68212890625
INFO:root:Train (Epoch 375): Loss/seq after 02000 batchs: 300.8854064941406
INFO:root:Train (Epoch 375): Loss/seq after 02050 batchs: 301.390869140625
INFO:root:Train (Epoch 375): Loss/seq after 02100 batchs: 301.4907531738281
INFO:root:Train (Epoch 375): Loss/seq after 02150 batchs: 301.61212158203125
INFO:root:Train (Epoch 375): Loss/seq after 02200 batchs: 301.2254943847656
INFO:root:Train (Epoch 375): Loss/seq after 02250 batchs: 300.92559814453125
INFO:root:Train (Epoch 375): Loss/seq after 02300 batchs: 299.0470886230469
INFO:root:Train (Epoch 375): Loss/seq after 02350 batchs: 297.3855895996094
INFO:root:Train (Epoch 375): Loss/seq after 02400 batchs: 296.895263671875
INFO:root:Train (Epoch 375): Loss/seq after 02450 batchs: 294.6856384277344
INFO:root:Train (Epoch 375): Loss/seq after 02500 batchs: 289.8397521972656
INFO:root:Train (Epoch 375): Loss/seq after 02550 batchs: 285.68341064453125
INFO:root:Train (Epoch 375): Loss/seq after 02600 batchs: 282.3050842285156
INFO:root:Train (Epoch 375): Loss/seq after 02650 batchs: 279.2588806152344
INFO:root:Train (Epoch 375): Loss/seq after 02700 batchs: 277.2958984375
INFO:root:Train (Epoch 375): Loss/seq after 02750 batchs: 274.28338623046875
INFO:root:Train (Epoch 375): Loss/seq after 02800 batchs: 272.6792297363281
INFO:root:Train (Epoch 375): Loss/seq after 02850 batchs: 272.3197326660156
INFO:root:Train (Epoch 375): Loss/seq after 02900 batchs: 272.5053405761719
INFO:root:Train (Epoch 375): Loss/seq after 02950 batchs: 273.5977783203125
INFO:root:Train (Epoch 375): Loss/seq after 03000 batchs: 276.1633605957031
INFO:root:Train (Epoch 375): Loss/seq after 03050 batchs: 277.3081359863281
INFO:root:Train (Epoch 375): Loss/seq after 03100 batchs: 279.11859130859375
INFO:root:Train (Epoch 375): Loss/seq after 03150 batchs: 279.238525390625
INFO:root:Train (Epoch 375): Loss/seq after 03200 batchs: 279.24188232421875
INFO:root:Train (Epoch 375): Loss/seq after 03250 batchs: 279.1311950683594
INFO:root:Train (Epoch 375): Loss/seq after 03300 batchs: 278.26361083984375
INFO:root:Train (Epoch 375): Loss/seq after 03350 batchs: 276.8241271972656
INFO:root:Train (Epoch 375): Loss/seq after 03400 batchs: 275.3412170410156
INFO:root:Train (Epoch 375): Loss/seq after 03450 batchs: 274.3298034667969
INFO:root:Train (Epoch 375): Loss/seq after 03500 batchs: 275.1224060058594
INFO:root:Train (Epoch 375): Loss/seq after 03550 batchs: 274.1421203613281
INFO:root:Train (Epoch 375): Loss/seq after 03600 batchs: 276.2207946777344
INFO:root:Train (Epoch 375): Loss/seq after 03650 batchs: 275.23175048828125
INFO:root:Train (Epoch 375): Loss/seq after 03700 batchs: 276.5080261230469
INFO:root:Train (Epoch 375): Loss/seq after 03750 batchs: 279.22412109375
INFO:root:Train (Epoch 375): Loss/seq after 03800 batchs: 279.46051025390625
INFO:root:Train (Epoch 375): Loss/seq after 03850 batchs: 279.0622253417969
INFO:root:Train (Epoch 375): Loss/seq after 03900 batchs: 279.9234619140625
INFO:root:Train (Epoch 375): Loss/seq after 03950 batchs: 281.7607421875
INFO:root:Train (Epoch 375): Loss/seq after 04000 batchs: 280.60430908203125
INFO:root:Train (Epoch 375): Loss/seq after 04050 batchs: 279.24822998046875
INFO:root:Train (Epoch 375): Loss/seq after 04100 batchs: 278.4988708496094
INFO:root:Train (Epoch 375): Loss/seq after 04150 batchs: 278.38006591796875
INFO:root:Train (Epoch 375): Loss/seq after 04200 batchs: 277.99957275390625
INFO:root:Train (Epoch 375): Loss/seq after 04250 batchs: 277.18475341796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 375): Loss/seq after 00000 batches: 236.4100341796875
INFO:root:# Valid (Epoch 375): Loss/seq after 00050 batches: 622.3712768554688
INFO:root:# Valid (Epoch 375): Loss/seq after 00100 batches: 624.6207885742188
INFO:root:# Valid (Epoch 375): Loss/seq after 00150 batches: 468.8551940917969
INFO:root:# Valid (Epoch 375): Loss/seq after 00200 batches: 439.1874084472656
INFO:root:Artifacts: Make stick videos for epoch 375
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_375_on_20220424_030935.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_375_index_312_on_20220424_030935.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 376): Loss/seq after 00000 batchs: 400.0472412109375
INFO:root:Train (Epoch 376): Loss/seq after 00050 batchs: 367.91632080078125
INFO:root:Train (Epoch 376): Loss/seq after 00100 batchs: 381.6014099121094
INFO:root:Train (Epoch 376): Loss/seq after 00150 batchs: 362.9096984863281
INFO:root:Train (Epoch 376): Loss/seq after 00200 batchs: 405.08636474609375
INFO:root:Train (Epoch 376): Loss/seq after 00250 batchs: 428.28973388671875
INFO:root:Train (Epoch 376): Loss/seq after 00300 batchs: 443.32037353515625
INFO:root:Train (Epoch 376): Loss/seq after 00350 batchs: 423.582763671875
INFO:root:Train (Epoch 376): Loss/seq after 00400 batchs: 416.6259460449219
INFO:root:Train (Epoch 376): Loss/seq after 00450 batchs: 431.66455078125
INFO:root:Train (Epoch 376): Loss/seq after 00500 batchs: 418.6139831542969
INFO:root:Train (Epoch 376): Loss/seq after 00550 batchs: 411.5511474609375
INFO:root:Train (Epoch 376): Loss/seq after 00600 batchs: 396.4030456542969
INFO:root:Train (Epoch 376): Loss/seq after 00650 batchs: 379.0547790527344
INFO:root:Train (Epoch 376): Loss/seq after 00700 batchs: 365.70977783203125
INFO:root:Train (Epoch 376): Loss/seq after 00750 batchs: 358.45916748046875
INFO:root:Train (Epoch 376): Loss/seq after 00800 batchs: 357.49639892578125
INFO:root:Train (Epoch 376): Loss/seq after 00850 batchs: 346.2559814453125
INFO:root:Train (Epoch 376): Loss/seq after 00900 batchs: 337.0075378417969
INFO:root:Train (Epoch 376): Loss/seq after 00950 batchs: 336.7850646972656
INFO:root:Train (Epoch 376): Loss/seq after 01000 batchs: 331.1966552734375
INFO:root:Train (Epoch 376): Loss/seq after 01050 batchs: 323.9742126464844
INFO:root:Train (Epoch 376): Loss/seq after 01100 batchs: 315.7201232910156
INFO:root:Train (Epoch 376): Loss/seq after 01150 batchs: 307.2970275878906
INFO:root:Train (Epoch 376): Loss/seq after 01200 batchs: 306.54669189453125
INFO:root:Train (Epoch 376): Loss/seq after 01250 batchs: 305.4786071777344
INFO:root:Train (Epoch 376): Loss/seq after 01300 batchs: 298.9993896484375
INFO:root:Train (Epoch 376): Loss/seq after 01350 batchs: 292.7632141113281
INFO:root:Train (Epoch 376): Loss/seq after 01400 batchs: 293.75360107421875
INFO:root:Train (Epoch 376): Loss/seq after 01450 batchs: 295.13153076171875
INFO:root:Train (Epoch 376): Loss/seq after 01500 batchs: 300.1435241699219
INFO:root:Train (Epoch 376): Loss/seq after 01550 batchs: 300.2471618652344
INFO:root:Train (Epoch 376): Loss/seq after 01600 batchs: 299.19189453125
INFO:root:Train (Epoch 376): Loss/seq after 01650 batchs: 297.9945068359375
INFO:root:Train (Epoch 376): Loss/seq after 01700 batchs: 298.543701171875
INFO:root:Train (Epoch 376): Loss/seq after 01750 batchs: 297.5167236328125
INFO:root:Train (Epoch 376): Loss/seq after 01800 batchs: 296.71990966796875
INFO:root:Train (Epoch 376): Loss/seq after 01850 batchs: 296.09033203125
INFO:root:Train (Epoch 376): Loss/seq after 01900 batchs: 295.9339294433594
INFO:root:Train (Epoch 376): Loss/seq after 01950 batchs: 296.48675537109375
INFO:root:Train (Epoch 376): Loss/seq after 02000 batchs: 298.8411560058594
INFO:root:Train (Epoch 376): Loss/seq after 02050 batchs: 299.4942321777344
INFO:root:Train (Epoch 376): Loss/seq after 02100 batchs: 299.525146484375
INFO:root:Train (Epoch 376): Loss/seq after 02150 batchs: 299.6983642578125
INFO:root:Train (Epoch 376): Loss/seq after 02200 batchs: 299.5036315917969
INFO:root:Train (Epoch 376): Loss/seq after 02250 batchs: 298.67041015625
INFO:root:Train (Epoch 376): Loss/seq after 02300 batchs: 296.763916015625
INFO:root:Train (Epoch 376): Loss/seq after 02350 batchs: 295.1483459472656
INFO:root:Train (Epoch 376): Loss/seq after 02400 batchs: 294.616455078125
INFO:root:Train (Epoch 376): Loss/seq after 02450 batchs: 292.4515380859375
INFO:root:Train (Epoch 376): Loss/seq after 02500 batchs: 287.6672058105469
INFO:root:Train (Epoch 376): Loss/seq after 02550 batchs: 283.54669189453125
INFO:root:Train (Epoch 376): Loss/seq after 02600 batchs: 280.09124755859375
INFO:root:Train (Epoch 376): Loss/seq after 02650 batchs: 277.067626953125
INFO:root:Train (Epoch 376): Loss/seq after 02700 batchs: 275.1155090332031
INFO:root:Train (Epoch 376): Loss/seq after 02750 batchs: 272.0393981933594
INFO:root:Train (Epoch 376): Loss/seq after 02800 batchs: 270.283935546875
INFO:root:Train (Epoch 376): Loss/seq after 02850 batchs: 269.985107421875
INFO:root:Train (Epoch 376): Loss/seq after 02900 batchs: 270.13372802734375
INFO:root:Train (Epoch 376): Loss/seq after 02950 batchs: 271.39520263671875
INFO:root:Train (Epoch 376): Loss/seq after 03000 batchs: 273.9925231933594
INFO:root:Train (Epoch 376): Loss/seq after 03050 batchs: 275.38641357421875
INFO:root:Train (Epoch 376): Loss/seq after 03100 batchs: 277.22052001953125
INFO:root:Train (Epoch 376): Loss/seq after 03150 batchs: 277.21649169921875
INFO:root:Train (Epoch 376): Loss/seq after 03200 batchs: 277.3944091796875
INFO:root:Train (Epoch 376): Loss/seq after 03250 batchs: 277.0902404785156
INFO:root:Train (Epoch 376): Loss/seq after 03300 batchs: 276.64385986328125
INFO:root:Train (Epoch 376): Loss/seq after 03350 batchs: 275.5182800292969
INFO:root:Train (Epoch 376): Loss/seq after 03400 batchs: 273.9613952636719
INFO:root:Train (Epoch 376): Loss/seq after 03450 batchs: 272.9029846191406
INFO:root:Train (Epoch 376): Loss/seq after 03500 batchs: 273.85821533203125
INFO:root:Train (Epoch 376): Loss/seq after 03550 batchs: 273.0277099609375
INFO:root:Train (Epoch 376): Loss/seq after 03600 batchs: 275.0405578613281
INFO:root:Train (Epoch 376): Loss/seq after 03650 batchs: 274.1380920410156
INFO:root:Train (Epoch 376): Loss/seq after 03700 batchs: 275.5506286621094
INFO:root:Train (Epoch 376): Loss/seq after 03750 batchs: 278.4594421386719
INFO:root:Train (Epoch 376): Loss/seq after 03800 batchs: 278.7085876464844
INFO:root:Train (Epoch 376): Loss/seq after 03850 batchs: 278.38873291015625
INFO:root:Train (Epoch 376): Loss/seq after 03900 batchs: 278.97723388671875
INFO:root:Train (Epoch 376): Loss/seq after 03950 batchs: 280.2022705078125
INFO:root:Train (Epoch 376): Loss/seq after 04000 batchs: 279.01751708984375
INFO:root:Train (Epoch 376): Loss/seq after 04050 batchs: 277.7400207519531
INFO:root:Train (Epoch 376): Loss/seq after 04100 batchs: 276.8975524902344
INFO:root:Train (Epoch 376): Loss/seq after 04150 batchs: 276.8044128417969
INFO:root:Train (Epoch 376): Loss/seq after 04200 batchs: 276.5413818359375
INFO:root:Train (Epoch 376): Loss/seq after 04250 batchs: 275.7871398925781
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 376): Loss/seq after 00000 batches: 290.8226623535156
INFO:root:# Valid (Epoch 376): Loss/seq after 00050 batches: 617.9458618164062
INFO:root:# Valid (Epoch 376): Loss/seq after 00100 batches: 609.35888671875
INFO:root:# Valid (Epoch 376): Loss/seq after 00150 batches: 456.990478515625
INFO:root:# Valid (Epoch 376): Loss/seq after 00200 batches: 428.95013427734375
INFO:root:Artifacts: Make stick videos for epoch 376
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_376_on_20220424_031419.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_376_index_1033_on_20220424_031419.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 377): Loss/seq after 00000 batchs: 467.9023742675781
INFO:root:Train (Epoch 377): Loss/seq after 00050 batchs: 398.1666564941406
INFO:root:Train (Epoch 377): Loss/seq after 00100 batchs: 405.01422119140625
INFO:root:Train (Epoch 377): Loss/seq after 00150 batchs: 373.1687316894531
INFO:root:Train (Epoch 377): Loss/seq after 00200 batchs: 417.41802978515625
INFO:root:Train (Epoch 377): Loss/seq after 00250 batchs: 434.54718017578125
INFO:root:Train (Epoch 377): Loss/seq after 00300 batchs: 449.5854187011719
INFO:root:Train (Epoch 377): Loss/seq after 00350 batchs: 429.18096923828125
INFO:root:Train (Epoch 377): Loss/seq after 00400 batchs: 418.9847412109375
INFO:root:Train (Epoch 377): Loss/seq after 00450 batchs: 433.1488952636719
INFO:root:Train (Epoch 377): Loss/seq after 00500 batchs: 419.0821533203125
INFO:root:Train (Epoch 377): Loss/seq after 00550 batchs: 412.3298034667969
INFO:root:Train (Epoch 377): Loss/seq after 00600 batchs: 396.6207275390625
INFO:root:Train (Epoch 377): Loss/seq after 00650 batchs: 380.5658264160156
INFO:root:Train (Epoch 377): Loss/seq after 00700 batchs: 363.6441650390625
INFO:root:Train (Epoch 377): Loss/seq after 00750 batchs: 358.8426208496094
INFO:root:Train (Epoch 377): Loss/seq after 00800 batchs: 358.69659423828125
INFO:root:Train (Epoch 377): Loss/seq after 00850 batchs: 346.6813659667969
INFO:root:Train (Epoch 377): Loss/seq after 00900 batchs: 337.3484802246094
INFO:root:Train (Epoch 377): Loss/seq after 00950 batchs: 337.28240966796875
INFO:root:Train (Epoch 377): Loss/seq after 01000 batchs: 331.1460876464844
INFO:root:Train (Epoch 377): Loss/seq after 01050 batchs: 325.0982666015625
INFO:root:Train (Epoch 377): Loss/seq after 01100 batchs: 317.5049743652344
INFO:root:Train (Epoch 377): Loss/seq after 01150 batchs: 309.2817077636719
INFO:root:Train (Epoch 377): Loss/seq after 01200 batchs: 308.190185546875
INFO:root:Train (Epoch 377): Loss/seq after 01250 batchs: 307.57318115234375
INFO:root:Train (Epoch 377): Loss/seq after 01300 batchs: 301.54132080078125
INFO:root:Train (Epoch 377): Loss/seq after 01350 batchs: 295.1833801269531
INFO:root:Train (Epoch 377): Loss/seq after 01400 batchs: 295.23162841796875
INFO:root:Train (Epoch 377): Loss/seq after 01450 batchs: 296.8561706542969
INFO:root:Train (Epoch 377): Loss/seq after 01500 batchs: 302.2917175292969
INFO:root:Train (Epoch 377): Loss/seq after 01550 batchs: 303.2631530761719
INFO:root:Train (Epoch 377): Loss/seq after 01600 batchs: 301.9887390136719
INFO:root:Train (Epoch 377): Loss/seq after 01650 batchs: 300.8810119628906
INFO:root:Train (Epoch 377): Loss/seq after 01700 batchs: 301.4498291015625
INFO:root:Train (Epoch 377): Loss/seq after 01750 batchs: 300.5404968261719
INFO:root:Train (Epoch 377): Loss/seq after 01800 batchs: 299.6611633300781
INFO:root:Train (Epoch 377): Loss/seq after 01850 batchs: 298.80242919921875
INFO:root:Train (Epoch 377): Loss/seq after 01900 batchs: 298.6417541503906
INFO:root:Train (Epoch 377): Loss/seq after 01950 batchs: 298.9784240722656
INFO:root:Train (Epoch 377): Loss/seq after 02000 batchs: 301.15887451171875
INFO:root:Train (Epoch 377): Loss/seq after 02050 batchs: 301.7543640136719
INFO:root:Train (Epoch 377): Loss/seq after 02100 batchs: 301.60888671875
INFO:root:Train (Epoch 377): Loss/seq after 02150 batchs: 301.7766418457031
INFO:root:Train (Epoch 377): Loss/seq after 02200 batchs: 301.3807067871094
INFO:root:Train (Epoch 377): Loss/seq after 02250 batchs: 300.8059387207031
INFO:root:Train (Epoch 377): Loss/seq after 02300 batchs: 298.7554931640625
INFO:root:Train (Epoch 377): Loss/seq after 02350 batchs: 297.0879821777344
INFO:root:Train (Epoch 377): Loss/seq after 02400 batchs: 296.4493408203125
INFO:root:Train (Epoch 377): Loss/seq after 02450 batchs: 294.2539367675781
INFO:root:Train (Epoch 377): Loss/seq after 02500 batchs: 289.4208068847656
INFO:root:Train (Epoch 377): Loss/seq after 02550 batchs: 285.2416687011719
INFO:root:Train (Epoch 377): Loss/seq after 02600 batchs: 281.9934387207031
INFO:root:Train (Epoch 377): Loss/seq after 02650 batchs: 278.9637756347656
INFO:root:Train (Epoch 377): Loss/seq after 02700 batchs: 277.0788879394531
INFO:root:Train (Epoch 377): Loss/seq after 02750 batchs: 273.95660400390625
INFO:root:Train (Epoch 377): Loss/seq after 02800 batchs: 272.410888671875
INFO:root:Train (Epoch 377): Loss/seq after 02850 batchs: 271.9271240234375
INFO:root:Train (Epoch 377): Loss/seq after 02900 batchs: 271.98028564453125
INFO:root:Train (Epoch 377): Loss/seq after 02950 batchs: 272.9425964355469
INFO:root:Train (Epoch 377): Loss/seq after 03000 batchs: 275.6519775390625
INFO:root:Train (Epoch 377): Loss/seq after 03050 batchs: 276.85186767578125
INFO:root:Train (Epoch 377): Loss/seq after 03100 batchs: 278.1498107910156
INFO:root:Train (Epoch 377): Loss/seq after 03150 batchs: 277.8055725097656
INFO:root:Train (Epoch 377): Loss/seq after 03200 batchs: 278.2268371582031
INFO:root:Train (Epoch 377): Loss/seq after 03250 batchs: 277.9527282714844
INFO:root:Train (Epoch 377): Loss/seq after 03300 batchs: 277.6570739746094
INFO:root:Train (Epoch 377): Loss/seq after 03350 batchs: 276.8169860839844
INFO:root:Train (Epoch 377): Loss/seq after 03400 batchs: 275.33380126953125
INFO:root:Train (Epoch 377): Loss/seq after 03450 batchs: 274.3184509277344
INFO:root:Train (Epoch 377): Loss/seq after 03500 batchs: 275.0491638183594
INFO:root:Train (Epoch 377): Loss/seq after 03550 batchs: 274.1332702636719
INFO:root:Train (Epoch 377): Loss/seq after 03600 batchs: 276.4844665527344
INFO:root:Train (Epoch 377): Loss/seq after 03650 batchs: 275.53857421875
INFO:root:Train (Epoch 377): Loss/seq after 03700 batchs: 277.5343933105469
INFO:root:Train (Epoch 377): Loss/seq after 03750 batchs: 280.6289978027344
INFO:root:Train (Epoch 377): Loss/seq after 03800 batchs: 280.9667663574219
INFO:root:Train (Epoch 377): Loss/seq after 03850 batchs: 280.7596130371094
INFO:root:Train (Epoch 377): Loss/seq after 03900 batchs: 281.9214782714844
INFO:root:Train (Epoch 377): Loss/seq after 03950 batchs: 283.77313232421875
INFO:root:Train (Epoch 377): Loss/seq after 04000 batchs: 282.54278564453125
INFO:root:Train (Epoch 377): Loss/seq after 04050 batchs: 281.2056884765625
INFO:root:Train (Epoch 377): Loss/seq after 04100 batchs: 280.3338317871094
INFO:root:Train (Epoch 377): Loss/seq after 04150 batchs: 280.2101745605469
INFO:root:Train (Epoch 377): Loss/seq after 04200 batchs: 279.8178405761719
INFO:root:Train (Epoch 377): Loss/seq after 04250 batchs: 278.9833068847656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 377): Loss/seq after 00000 batches: 229.1722412109375
INFO:root:# Valid (Epoch 377): Loss/seq after 00050 batches: 648.215576171875
INFO:root:# Valid (Epoch 377): Loss/seq after 00100 batches: 637.099609375
INFO:root:# Valid (Epoch 377): Loss/seq after 00150 batches: 477.8231201171875
INFO:root:# Valid (Epoch 377): Loss/seq after 00200 batches: 448.513916015625
INFO:root:Artifacts: Make stick videos for epoch 377
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_377_on_20220424_031903.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_377_index_283_on_20220424_031903.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 378): Loss/seq after 00000 batchs: 387.5764465332031
INFO:root:Train (Epoch 378): Loss/seq after 00050 batchs: 370.2149963378906
INFO:root:Train (Epoch 378): Loss/seq after 00100 batchs: 364.3887939453125
INFO:root:Train (Epoch 378): Loss/seq after 00150 batchs: 347.9182434082031
INFO:root:Train (Epoch 378): Loss/seq after 00200 batchs: 386.5227355957031
INFO:root:Train (Epoch 378): Loss/seq after 00250 batchs: 402.39208984375
INFO:root:Train (Epoch 378): Loss/seq after 00300 batchs: 420.2549743652344
INFO:root:Train (Epoch 378): Loss/seq after 00350 batchs: 404.40576171875
INFO:root:Train (Epoch 378): Loss/seq after 00400 batchs: 403.9841613769531
INFO:root:Train (Epoch 378): Loss/seq after 00450 batchs: 420.4778137207031
INFO:root:Train (Epoch 378): Loss/seq after 00500 batchs: 407.35699462890625
INFO:root:Train (Epoch 378): Loss/seq after 00550 batchs: 401.9911193847656
INFO:root:Train (Epoch 378): Loss/seq after 00600 batchs: 387.3340759277344
INFO:root:Train (Epoch 378): Loss/seq after 00650 batchs: 371.62005615234375
INFO:root:Train (Epoch 378): Loss/seq after 00700 batchs: 356.4664306640625
INFO:root:Train (Epoch 378): Loss/seq after 00750 batchs: 350.7967529296875
INFO:root:Train (Epoch 378): Loss/seq after 00800 batchs: 349.446044921875
INFO:root:Train (Epoch 378): Loss/seq after 00850 batchs: 338.07318115234375
INFO:root:Train (Epoch 378): Loss/seq after 00900 batchs: 329.6759948730469
INFO:root:Train (Epoch 378): Loss/seq after 00950 batchs: 330.4841003417969
INFO:root:Train (Epoch 378): Loss/seq after 01000 batchs: 324.2793273925781
INFO:root:Train (Epoch 378): Loss/seq after 01050 batchs: 317.27679443359375
INFO:root:Train (Epoch 378): Loss/seq after 01100 batchs: 309.658447265625
INFO:root:Train (Epoch 378): Loss/seq after 01150 batchs: 301.4167785644531
INFO:root:Train (Epoch 378): Loss/seq after 01200 batchs: 300.3893737792969
INFO:root:Train (Epoch 378): Loss/seq after 01250 batchs: 299.6947937011719
INFO:root:Train (Epoch 378): Loss/seq after 01300 batchs: 293.6266174316406
INFO:root:Train (Epoch 378): Loss/seq after 01350 batchs: 287.8420104980469
INFO:root:Train (Epoch 378): Loss/seq after 01400 batchs: 289.1925964355469
INFO:root:Train (Epoch 378): Loss/seq after 01450 batchs: 290.7527770996094
INFO:root:Train (Epoch 378): Loss/seq after 01500 batchs: 295.617919921875
INFO:root:Train (Epoch 378): Loss/seq after 01550 batchs: 296.39794921875
INFO:root:Train (Epoch 378): Loss/seq after 01600 batchs: 295.62060546875
INFO:root:Train (Epoch 378): Loss/seq after 01650 batchs: 294.6057434082031
INFO:root:Train (Epoch 378): Loss/seq after 01700 batchs: 295.2349548339844
INFO:root:Train (Epoch 378): Loss/seq after 01750 batchs: 294.7430419921875
INFO:root:Train (Epoch 378): Loss/seq after 01800 batchs: 293.8525390625
INFO:root:Train (Epoch 378): Loss/seq after 01850 batchs: 293.17901611328125
INFO:root:Train (Epoch 378): Loss/seq after 01900 batchs: 292.9922790527344
INFO:root:Train (Epoch 378): Loss/seq after 01950 batchs: 293.2276306152344
INFO:root:Train (Epoch 378): Loss/seq after 02000 batchs: 295.54486083984375
INFO:root:Train (Epoch 378): Loss/seq after 02050 batchs: 296.3500061035156
INFO:root:Train (Epoch 378): Loss/seq after 02100 batchs: 296.3090515136719
INFO:root:Train (Epoch 378): Loss/seq after 02150 batchs: 296.6603698730469
INFO:root:Train (Epoch 378): Loss/seq after 02200 batchs: 296.3375549316406
INFO:root:Train (Epoch 378): Loss/seq after 02250 batchs: 295.63177490234375
INFO:root:Train (Epoch 378): Loss/seq after 02300 batchs: 293.75628662109375
INFO:root:Train (Epoch 378): Loss/seq after 02350 batchs: 292.0889587402344
INFO:root:Train (Epoch 378): Loss/seq after 02400 batchs: 291.6585693359375
INFO:root:Train (Epoch 378): Loss/seq after 02450 batchs: 289.5796203613281
INFO:root:Train (Epoch 378): Loss/seq after 02500 batchs: 284.84991455078125
INFO:root:Train (Epoch 378): Loss/seq after 02550 batchs: 280.7084655761719
INFO:root:Train (Epoch 378): Loss/seq after 02600 batchs: 277.3119201660156
INFO:root:Train (Epoch 378): Loss/seq after 02650 batchs: 274.2947082519531
INFO:root:Train (Epoch 378): Loss/seq after 02700 batchs: 272.3786315917969
INFO:root:Train (Epoch 378): Loss/seq after 02750 batchs: 269.45263671875
INFO:root:Train (Epoch 378): Loss/seq after 02800 batchs: 268.1318359375
INFO:root:Train (Epoch 378): Loss/seq after 02850 batchs: 267.8116760253906
INFO:root:Train (Epoch 378): Loss/seq after 02900 batchs: 268.0149230957031
INFO:root:Train (Epoch 378): Loss/seq after 02950 batchs: 268.9981994628906
INFO:root:Train (Epoch 378): Loss/seq after 03000 batchs: 271.41461181640625
INFO:root:Train (Epoch 378): Loss/seq after 03050 batchs: 272.7115478515625
INFO:root:Train (Epoch 378): Loss/seq after 03100 batchs: 274.0959167480469
INFO:root:Train (Epoch 378): Loss/seq after 03150 batchs: 273.2740173339844
INFO:root:Train (Epoch 378): Loss/seq after 03200 batchs: 273.3095703125
INFO:root:Train (Epoch 378): Loss/seq after 03250 batchs: 272.91180419921875
INFO:root:Train (Epoch 378): Loss/seq after 03300 batchs: 272.4566650390625
INFO:root:Train (Epoch 378): Loss/seq after 03350 batchs: 271.1930236816406
INFO:root:Train (Epoch 378): Loss/seq after 03400 batchs: 269.5993347167969
INFO:root:Train (Epoch 378): Loss/seq after 03450 batchs: 268.49603271484375
INFO:root:Train (Epoch 378): Loss/seq after 03500 batchs: 269.13409423828125
INFO:root:Train (Epoch 378): Loss/seq after 03550 batchs: 268.255615234375
INFO:root:Train (Epoch 378): Loss/seq after 03600 batchs: 270.2024841308594
INFO:root:Train (Epoch 378): Loss/seq after 03650 batchs: 269.38006591796875
INFO:root:Train (Epoch 378): Loss/seq after 03700 batchs: 270.74237060546875
INFO:root:Train (Epoch 378): Loss/seq after 03750 batchs: 273.5429382324219
INFO:root:Train (Epoch 378): Loss/seq after 03800 batchs: 273.8755798339844
INFO:root:Train (Epoch 378): Loss/seq after 03850 batchs: 273.6589050292969
INFO:root:Train (Epoch 378): Loss/seq after 03900 batchs: 274.4178161621094
INFO:root:Train (Epoch 378): Loss/seq after 03950 batchs: 276.0186462402344
INFO:root:Train (Epoch 378): Loss/seq after 04000 batchs: 274.8612060546875
INFO:root:Train (Epoch 378): Loss/seq after 04050 batchs: 273.5563659667969
INFO:root:Train (Epoch 378): Loss/seq after 04100 batchs: 272.78009033203125
INFO:root:Train (Epoch 378): Loss/seq after 04150 batchs: 272.66357421875
INFO:root:Train (Epoch 378): Loss/seq after 04200 batchs: 272.34954833984375
INFO:root:Train (Epoch 378): Loss/seq after 04250 batchs: 271.68865966796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 378): Loss/seq after 00000 batches: 276.4136962890625
INFO:root:# Valid (Epoch 378): Loss/seq after 00050 batches: 652.3653564453125
INFO:root:# Valid (Epoch 378): Loss/seq after 00100 batches: 652.6826171875
INFO:root:# Valid (Epoch 378): Loss/seq after 00150 batches: 488.13116455078125
INFO:root:# Valid (Epoch 378): Loss/seq after 00200 batches: 452.1238708496094
INFO:root:Artifacts: Make stick videos for epoch 378
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_378_on_20220424_032401.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_378_index_532_on_20220424_032401.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 379): Loss/seq after 00000 batchs: 521.0733032226562
INFO:root:Train (Epoch 379): Loss/seq after 00050 batchs: 351.6199951171875
INFO:root:Train (Epoch 379): Loss/seq after 00100 batchs: 357.1319274902344
INFO:root:Train (Epoch 379): Loss/seq after 00150 batchs: 344.0189208984375
INFO:root:Train (Epoch 379): Loss/seq after 00200 batchs: 392.0369567871094
INFO:root:Train (Epoch 379): Loss/seq after 00250 batchs: 414.03741455078125
INFO:root:Train (Epoch 379): Loss/seq after 00300 batchs: 429.4984130859375
INFO:root:Train (Epoch 379): Loss/seq after 00350 batchs: 412.0853271484375
INFO:root:Train (Epoch 379): Loss/seq after 00400 batchs: 403.09521484375
INFO:root:Train (Epoch 379): Loss/seq after 00450 batchs: 418.3804626464844
INFO:root:Train (Epoch 379): Loss/seq after 00500 batchs: 404.46173095703125
INFO:root:Train (Epoch 379): Loss/seq after 00550 batchs: 398.7364196777344
INFO:root:Train (Epoch 379): Loss/seq after 00600 batchs: 383.7396240234375
INFO:root:Train (Epoch 379): Loss/seq after 00650 batchs: 369.3154296875
INFO:root:Train (Epoch 379): Loss/seq after 00700 batchs: 354.0896301269531
INFO:root:Train (Epoch 379): Loss/seq after 00750 batchs: 348.7381896972656
INFO:root:Train (Epoch 379): Loss/seq after 00800 batchs: 347.2260437011719
INFO:root:Train (Epoch 379): Loss/seq after 00850 batchs: 335.5875244140625
INFO:root:Train (Epoch 379): Loss/seq after 00900 batchs: 326.6965637207031
INFO:root:Train (Epoch 379): Loss/seq after 00950 batchs: 325.7119445800781
INFO:root:Train (Epoch 379): Loss/seq after 01000 batchs: 318.8105773925781
INFO:root:Train (Epoch 379): Loss/seq after 01050 batchs: 311.9765625
INFO:root:Train (Epoch 379): Loss/seq after 01100 batchs: 304.52874755859375
INFO:root:Train (Epoch 379): Loss/seq after 01150 batchs: 296.6239013671875
INFO:root:Train (Epoch 379): Loss/seq after 01200 batchs: 295.33123779296875
INFO:root:Train (Epoch 379): Loss/seq after 01250 batchs: 295.1998291015625
INFO:root:Train (Epoch 379): Loss/seq after 01300 batchs: 289.39337158203125
INFO:root:Train (Epoch 379): Loss/seq after 01350 batchs: 282.99761962890625
INFO:root:Train (Epoch 379): Loss/seq after 01400 batchs: 284.0151062011719
INFO:root:Train (Epoch 379): Loss/seq after 01450 batchs: 285.7900695800781
INFO:root:Train (Epoch 379): Loss/seq after 01500 batchs: 291.45458984375
INFO:root:Train (Epoch 379): Loss/seq after 01550 batchs: 292.0972595214844
INFO:root:Train (Epoch 379): Loss/seq after 01600 batchs: 291.3594055175781
INFO:root:Train (Epoch 379): Loss/seq after 01650 batchs: 290.1870422363281
INFO:root:Train (Epoch 379): Loss/seq after 01700 batchs: 290.7861633300781
INFO:root:Train (Epoch 379): Loss/seq after 01750 batchs: 289.9908752441406
INFO:root:Train (Epoch 379): Loss/seq after 01800 batchs: 289.2959899902344
INFO:root:Train (Epoch 379): Loss/seq after 01850 batchs: 288.6134033203125
INFO:root:Train (Epoch 379): Loss/seq after 01900 batchs: 288.39080810546875
INFO:root:Train (Epoch 379): Loss/seq after 01950 batchs: 288.7831726074219
INFO:root:Train (Epoch 379): Loss/seq after 02000 batchs: 291.22149658203125
INFO:root:Train (Epoch 379): Loss/seq after 02050 batchs: 292.08819580078125
INFO:root:Train (Epoch 379): Loss/seq after 02100 batchs: 292.38336181640625
INFO:root:Train (Epoch 379): Loss/seq after 02150 batchs: 292.8974609375
INFO:root:Train (Epoch 379): Loss/seq after 02200 batchs: 292.7073059082031
INFO:root:Train (Epoch 379): Loss/seq after 02250 batchs: 292.20745849609375
INFO:root:Train (Epoch 379): Loss/seq after 02300 batchs: 290.4859313964844
INFO:root:Train (Epoch 379): Loss/seq after 02350 batchs: 288.99981689453125
INFO:root:Train (Epoch 379): Loss/seq after 02400 batchs: 288.65570068359375
INFO:root:Train (Epoch 379): Loss/seq after 02450 batchs: 286.7184143066406
INFO:root:Train (Epoch 379): Loss/seq after 02500 batchs: 282.1060485839844
INFO:root:Train (Epoch 379): Loss/seq after 02550 batchs: 278.052978515625
INFO:root:Train (Epoch 379): Loss/seq after 02600 batchs: 274.76422119140625
INFO:root:Train (Epoch 379): Loss/seq after 02650 batchs: 271.8275451660156
INFO:root:Train (Epoch 379): Loss/seq after 02700 batchs: 270.09716796875
INFO:root:Train (Epoch 379): Loss/seq after 02750 batchs: 266.9358825683594
INFO:root:Train (Epoch 379): Loss/seq after 02800 batchs: 265.5179443359375
INFO:root:Train (Epoch 379): Loss/seq after 02850 batchs: 265.3988342285156
INFO:root:Train (Epoch 379): Loss/seq after 02900 batchs: 265.4566345214844
INFO:root:Train (Epoch 379): Loss/seq after 02950 batchs: 266.6143798828125
INFO:root:Train (Epoch 379): Loss/seq after 03000 batchs: 268.90557861328125
INFO:root:Train (Epoch 379): Loss/seq after 03050 batchs: 269.9075927734375
INFO:root:Train (Epoch 379): Loss/seq after 03100 batchs: 271.1445617675781
INFO:root:Train (Epoch 379): Loss/seq after 03150 batchs: 271.65740966796875
INFO:root:Train (Epoch 379): Loss/seq after 03200 batchs: 271.7362060546875
INFO:root:Train (Epoch 379): Loss/seq after 03250 batchs: 271.5115051269531
INFO:root:Train (Epoch 379): Loss/seq after 03300 batchs: 271.1697998046875
INFO:root:Train (Epoch 379): Loss/seq after 03350 batchs: 269.65728759765625
INFO:root:Train (Epoch 379): Loss/seq after 03400 batchs: 268.0909423828125
INFO:root:Train (Epoch 379): Loss/seq after 03450 batchs: 267.1468505859375
INFO:root:Train (Epoch 379): Loss/seq after 03500 batchs: 267.86572265625
INFO:root:Train (Epoch 379): Loss/seq after 03550 batchs: 266.93408203125
INFO:root:Train (Epoch 379): Loss/seq after 03600 batchs: 268.997314453125
INFO:root:Train (Epoch 379): Loss/seq after 03650 batchs: 268.3720703125
INFO:root:Train (Epoch 379): Loss/seq after 03700 batchs: 269.70849609375
INFO:root:Train (Epoch 379): Loss/seq after 03750 batchs: 272.5813293457031
INFO:root:Train (Epoch 379): Loss/seq after 03800 batchs: 272.9968566894531
INFO:root:Train (Epoch 379): Loss/seq after 03850 batchs: 272.8061828613281
INFO:root:Train (Epoch 379): Loss/seq after 03900 batchs: 274.39178466796875
INFO:root:Train (Epoch 379): Loss/seq after 03950 batchs: 276.3072509765625
INFO:root:Train (Epoch 379): Loss/seq after 04000 batchs: 275.17193603515625
INFO:root:Train (Epoch 379): Loss/seq after 04050 batchs: 273.8296813964844
INFO:root:Train (Epoch 379): Loss/seq after 04100 batchs: 272.9434814453125
INFO:root:Train (Epoch 379): Loss/seq after 04150 batchs: 272.818115234375
INFO:root:Train (Epoch 379): Loss/seq after 04200 batchs: 272.43804931640625
INFO:root:Train (Epoch 379): Loss/seq after 04250 batchs: 271.6722106933594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 379): Loss/seq after 00000 batches: 218.35203552246094
INFO:root:# Valid (Epoch 379): Loss/seq after 00050 batches: 638.629638671875
INFO:root:# Valid (Epoch 379): Loss/seq after 00100 batches: 615.4078369140625
INFO:root:# Valid (Epoch 379): Loss/seq after 00150 batches: 463.23712158203125
INFO:root:# Valid (Epoch 379): Loss/seq after 00200 batches: 435.0350036621094
INFO:root:Artifacts: Make stick videos for epoch 379
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_379_on_20220424_032852.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_379_index_284_on_20220424_032852.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 380): Loss/seq after 00000 batchs: 526.3403930664062
INFO:root:Train (Epoch 380): Loss/seq after 00050 batchs: 368.7814025878906
INFO:root:Train (Epoch 380): Loss/seq after 00100 batchs: 386.6633605957031
INFO:root:Train (Epoch 380): Loss/seq after 00150 batchs: 362.6479187011719
INFO:root:Train (Epoch 380): Loss/seq after 00200 batchs: 414.7621154785156
INFO:root:Train (Epoch 380): Loss/seq after 00250 batchs: 430.4260559082031
INFO:root:Train (Epoch 380): Loss/seq after 00300 batchs: 447.6598815917969
INFO:root:Train (Epoch 380): Loss/seq after 00350 batchs: 428.5426025390625
INFO:root:Train (Epoch 380): Loss/seq after 00400 batchs: 419.2691345214844
INFO:root:Train (Epoch 380): Loss/seq after 00450 batchs: 433.8958435058594
INFO:root:Train (Epoch 380): Loss/seq after 00500 batchs: 420.17572021484375
INFO:root:Train (Epoch 380): Loss/seq after 00550 batchs: 412.17669677734375
INFO:root:Train (Epoch 380): Loss/seq after 00600 batchs: 397.1192626953125
INFO:root:Train (Epoch 380): Loss/seq after 00650 batchs: 381.1214599609375
INFO:root:Train (Epoch 380): Loss/seq after 00700 batchs: 364.6070556640625
INFO:root:Train (Epoch 380): Loss/seq after 00750 batchs: 361.2796630859375
INFO:root:Train (Epoch 380): Loss/seq after 00800 batchs: 360.44244384765625
INFO:root:Train (Epoch 380): Loss/seq after 00850 batchs: 348.35333251953125
INFO:root:Train (Epoch 380): Loss/seq after 00900 batchs: 339.4102478027344
INFO:root:Train (Epoch 380): Loss/seq after 00950 batchs: 338.583740234375
INFO:root:Train (Epoch 380): Loss/seq after 01000 batchs: 332.00933837890625
INFO:root:Train (Epoch 380): Loss/seq after 01050 batchs: 325.07073974609375
INFO:root:Train (Epoch 380): Loss/seq after 01100 batchs: 317.4072265625
INFO:root:Train (Epoch 380): Loss/seq after 01150 batchs: 308.96075439453125
INFO:root:Train (Epoch 380): Loss/seq after 01200 batchs: 307.1147155761719
INFO:root:Train (Epoch 380): Loss/seq after 01250 batchs: 306.10992431640625
INFO:root:Train (Epoch 380): Loss/seq after 01300 batchs: 300.1853332519531
INFO:root:Train (Epoch 380): Loss/seq after 01350 batchs: 293.6949157714844
INFO:root:Train (Epoch 380): Loss/seq after 01400 batchs: 294.2704772949219
INFO:root:Train (Epoch 380): Loss/seq after 01450 batchs: 295.2659912109375
INFO:root:Train (Epoch 380): Loss/seq after 01500 batchs: 299.7747802734375
INFO:root:Train (Epoch 380): Loss/seq after 01550 batchs: 300.6264953613281
INFO:root:Train (Epoch 380): Loss/seq after 01600 batchs: 299.7917785644531
INFO:root:Train (Epoch 380): Loss/seq after 01650 batchs: 298.7410888671875
INFO:root:Train (Epoch 380): Loss/seq after 01700 batchs: 299.29150390625
INFO:root:Train (Epoch 380): Loss/seq after 01750 batchs: 298.27117919921875
INFO:root:Train (Epoch 380): Loss/seq after 01800 batchs: 297.3852233886719
INFO:root:Train (Epoch 380): Loss/seq after 01850 batchs: 296.4780578613281
INFO:root:Train (Epoch 380): Loss/seq after 01900 batchs: 296.0677490234375
INFO:root:Train (Epoch 380): Loss/seq after 01950 batchs: 296.2640686035156
INFO:root:Train (Epoch 380): Loss/seq after 02000 batchs: 298.2002868652344
INFO:root:Train (Epoch 380): Loss/seq after 02050 batchs: 298.80169677734375
INFO:root:Train (Epoch 380): Loss/seq after 02100 batchs: 298.8175964355469
INFO:root:Train (Epoch 380): Loss/seq after 02150 batchs: 298.98394775390625
INFO:root:Train (Epoch 380): Loss/seq after 02200 batchs: 298.61700439453125
INFO:root:Train (Epoch 380): Loss/seq after 02250 batchs: 297.7587585449219
INFO:root:Train (Epoch 380): Loss/seq after 02300 batchs: 296.4179382324219
INFO:root:Train (Epoch 380): Loss/seq after 02350 batchs: 294.82147216796875
INFO:root:Train (Epoch 380): Loss/seq after 02400 batchs: 294.35589599609375
INFO:root:Train (Epoch 380): Loss/seq after 02450 batchs: 292.1980285644531
INFO:root:Train (Epoch 380): Loss/seq after 02500 batchs: 287.35369873046875
INFO:root:Train (Epoch 380): Loss/seq after 02550 batchs: 283.315673828125
INFO:root:Train (Epoch 380): Loss/seq after 02600 batchs: 279.9344787597656
INFO:root:Train (Epoch 380): Loss/seq after 02650 batchs: 276.9042663574219
INFO:root:Train (Epoch 380): Loss/seq after 02700 batchs: 274.90875244140625
INFO:root:Train (Epoch 380): Loss/seq after 02750 batchs: 271.9580078125
INFO:root:Train (Epoch 380): Loss/seq after 02800 batchs: 270.8912658691406
INFO:root:Train (Epoch 380): Loss/seq after 02850 batchs: 270.513671875
INFO:root:Train (Epoch 380): Loss/seq after 02900 batchs: 270.3554992675781
INFO:root:Train (Epoch 380): Loss/seq after 02950 batchs: 271.3779296875
INFO:root:Train (Epoch 380): Loss/seq after 03000 batchs: 273.55322265625
INFO:root:Train (Epoch 380): Loss/seq after 03050 batchs: 274.346435546875
INFO:root:Train (Epoch 380): Loss/seq after 03100 batchs: 275.4011535644531
INFO:root:Train (Epoch 380): Loss/seq after 03150 batchs: 275.8696594238281
INFO:root:Train (Epoch 380): Loss/seq after 03200 batchs: 276.1012878417969
INFO:root:Train (Epoch 380): Loss/seq after 03250 batchs: 275.2574768066406
INFO:root:Train (Epoch 380): Loss/seq after 03300 batchs: 275.19659423828125
INFO:root:Train (Epoch 380): Loss/seq after 03350 batchs: 274.3026123046875
INFO:root:Train (Epoch 380): Loss/seq after 03400 batchs: 272.6715393066406
INFO:root:Train (Epoch 380): Loss/seq after 03450 batchs: 271.7947082519531
INFO:root:Train (Epoch 380): Loss/seq after 03500 batchs: 272.5369873046875
INFO:root:Train (Epoch 380): Loss/seq after 03550 batchs: 271.6325988769531
INFO:root:Train (Epoch 380): Loss/seq after 03600 batchs: 273.499755859375
INFO:root:Train (Epoch 380): Loss/seq after 03650 batchs: 272.5646667480469
INFO:root:Train (Epoch 380): Loss/seq after 03700 batchs: 273.9809265136719
INFO:root:Train (Epoch 380): Loss/seq after 03750 batchs: 276.91644287109375
INFO:root:Train (Epoch 380): Loss/seq after 03800 batchs: 277.1842041015625
INFO:root:Train (Epoch 380): Loss/seq after 03850 batchs: 276.8189392089844
INFO:root:Train (Epoch 380): Loss/seq after 03900 batchs: 277.57501220703125
INFO:root:Train (Epoch 380): Loss/seq after 03950 batchs: 280.2717590332031
INFO:root:Train (Epoch 380): Loss/seq after 04000 batchs: 279.0764465332031
INFO:root:Train (Epoch 380): Loss/seq after 04050 batchs: 277.73956298828125
INFO:root:Train (Epoch 380): Loss/seq after 04100 batchs: 276.8798828125
INFO:root:Train (Epoch 380): Loss/seq after 04150 batchs: 276.6845703125
INFO:root:Train (Epoch 380): Loss/seq after 04200 batchs: 276.32916259765625
INFO:root:Train (Epoch 380): Loss/seq after 04250 batchs: 275.52508544921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 380): Loss/seq after 00000 batches: 211.8411407470703
INFO:root:# Valid (Epoch 380): Loss/seq after 00050 batches: 624.725830078125
INFO:root:# Valid (Epoch 380): Loss/seq after 00100 batches: 628.6353149414062
INFO:root:# Valid (Epoch 380): Loss/seq after 00150 batches: 471.6556701660156
INFO:root:# Valid (Epoch 380): Loss/seq after 00200 batches: 438.6912536621094
INFO:root:Artifacts: Make stick videos for epoch 380
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_380_on_20220424_033358.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_380_index_1134_on_20220424_033358.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 381): Loss/seq after 00000 batchs: 335.21356201171875
INFO:root:Train (Epoch 381): Loss/seq after 00050 batchs: 366.03076171875
INFO:root:Train (Epoch 381): Loss/seq after 00100 batchs: 368.17315673828125
INFO:root:Train (Epoch 381): Loss/seq after 00150 batchs: 347.74652099609375
INFO:root:Train (Epoch 381): Loss/seq after 00200 batchs: 396.1695861816406
INFO:root:Train (Epoch 381): Loss/seq after 00250 batchs: 401.5291442871094
INFO:root:Train (Epoch 381): Loss/seq after 00300 batchs: 417.1842346191406
INFO:root:Train (Epoch 381): Loss/seq after 00350 batchs: 400.8636474609375
INFO:root:Train (Epoch 381): Loss/seq after 00400 batchs: 393.0203552246094
INFO:root:Train (Epoch 381): Loss/seq after 00450 batchs: 409.0728759765625
INFO:root:Train (Epoch 381): Loss/seq after 00500 batchs: 395.57818603515625
INFO:root:Train (Epoch 381): Loss/seq after 00550 batchs: 390.3440856933594
INFO:root:Train (Epoch 381): Loss/seq after 00600 batchs: 376.5284423828125
INFO:root:Train (Epoch 381): Loss/seq after 00650 batchs: 361.6820983886719
INFO:root:Train (Epoch 381): Loss/seq after 00700 batchs: 345.95684814453125
INFO:root:Train (Epoch 381): Loss/seq after 00750 batchs: 340.1153564453125
INFO:root:Train (Epoch 381): Loss/seq after 00800 batchs: 340.0360412597656
INFO:root:Train (Epoch 381): Loss/seq after 00850 batchs: 329.4009704589844
INFO:root:Train (Epoch 381): Loss/seq after 00900 batchs: 321.6894226074219
INFO:root:Train (Epoch 381): Loss/seq after 00950 batchs: 322.1921081542969
INFO:root:Train (Epoch 381): Loss/seq after 01000 batchs: 316.03656005859375
INFO:root:Train (Epoch 381): Loss/seq after 01050 batchs: 310.851318359375
INFO:root:Train (Epoch 381): Loss/seq after 01100 batchs: 303.48809814453125
INFO:root:Train (Epoch 381): Loss/seq after 01150 batchs: 295.76214599609375
INFO:root:Train (Epoch 381): Loss/seq after 01200 batchs: 294.81243896484375
INFO:root:Train (Epoch 381): Loss/seq after 01250 batchs: 295.0611572265625
INFO:root:Train (Epoch 381): Loss/seq after 01300 batchs: 289.10675048828125
INFO:root:Train (Epoch 381): Loss/seq after 01350 batchs: 283.06866455078125
INFO:root:Train (Epoch 381): Loss/seq after 01400 batchs: 285.1824645996094
INFO:root:Train (Epoch 381): Loss/seq after 01450 batchs: 287.1241455078125
INFO:root:Train (Epoch 381): Loss/seq after 01500 batchs: 292.52618408203125
INFO:root:Train (Epoch 381): Loss/seq after 01550 batchs: 293.898681640625
INFO:root:Train (Epoch 381): Loss/seq after 01600 batchs: 293.1891784667969
INFO:root:Train (Epoch 381): Loss/seq after 01650 batchs: 292.4786682128906
INFO:root:Train (Epoch 381): Loss/seq after 01700 batchs: 293.4462585449219
INFO:root:Train (Epoch 381): Loss/seq after 01750 batchs: 292.795166015625
INFO:root:Train (Epoch 381): Loss/seq after 01800 batchs: 291.96661376953125
INFO:root:Train (Epoch 381): Loss/seq after 01850 batchs: 291.22332763671875
INFO:root:Train (Epoch 381): Loss/seq after 01900 batchs: 290.9918518066406
INFO:root:Train (Epoch 381): Loss/seq after 01950 batchs: 291.5263671875
INFO:root:Train (Epoch 381): Loss/seq after 02000 batchs: 293.9227294921875
INFO:root:Train (Epoch 381): Loss/seq after 02050 batchs: 294.7075500488281
INFO:root:Train (Epoch 381): Loss/seq after 02100 batchs: 294.66796875
INFO:root:Train (Epoch 381): Loss/seq after 02150 batchs: 294.9319152832031
INFO:root:Train (Epoch 381): Loss/seq after 02200 batchs: 294.6379699707031
INFO:root:Train (Epoch 381): Loss/seq after 02250 batchs: 294.0418701171875
INFO:root:Train (Epoch 381): Loss/seq after 02300 batchs: 291.9837951660156
INFO:root:Train (Epoch 381): Loss/seq after 02350 batchs: 290.36737060546875
INFO:root:Train (Epoch 381): Loss/seq after 02400 batchs: 289.8831787109375
INFO:root:Train (Epoch 381): Loss/seq after 02450 batchs: 287.6585388183594
INFO:root:Train (Epoch 381): Loss/seq after 02500 batchs: 282.94781494140625
INFO:root:Train (Epoch 381): Loss/seq after 02550 batchs: 278.83087158203125
INFO:root:Train (Epoch 381): Loss/seq after 02600 batchs: 275.59381103515625
INFO:root:Train (Epoch 381): Loss/seq after 02650 batchs: 272.677001953125
INFO:root:Train (Epoch 381): Loss/seq after 02700 batchs: 270.75872802734375
INFO:root:Train (Epoch 381): Loss/seq after 02750 batchs: 267.78204345703125
INFO:root:Train (Epoch 381): Loss/seq after 02800 batchs: 266.6275329589844
INFO:root:Train (Epoch 381): Loss/seq after 02850 batchs: 266.2069091796875
INFO:root:Train (Epoch 381): Loss/seq after 02900 batchs: 266.1628112792969
INFO:root:Train (Epoch 381): Loss/seq after 02950 batchs: 267.2528076171875
INFO:root:Train (Epoch 381): Loss/seq after 03000 batchs: 269.58453369140625
INFO:root:Train (Epoch 381): Loss/seq after 03050 batchs: 270.7049865722656
INFO:root:Train (Epoch 381): Loss/seq after 03100 batchs: 271.95147705078125
INFO:root:Train (Epoch 381): Loss/seq after 03150 batchs: 272.7887878417969
INFO:root:Train (Epoch 381): Loss/seq after 03200 batchs: 273.45245361328125
INFO:root:Train (Epoch 381): Loss/seq after 03250 batchs: 272.97802734375
INFO:root:Train (Epoch 381): Loss/seq after 03300 batchs: 273.0252990722656
INFO:root:Train (Epoch 381): Loss/seq after 03350 batchs: 272.0350646972656
INFO:root:Train (Epoch 381): Loss/seq after 03400 batchs: 270.5015563964844
INFO:root:Train (Epoch 381): Loss/seq after 03450 batchs: 269.41558837890625
INFO:root:Train (Epoch 381): Loss/seq after 03500 batchs: 270.5653381347656
INFO:root:Train (Epoch 381): Loss/seq after 03550 batchs: 269.6625671386719
INFO:root:Train (Epoch 381): Loss/seq after 03600 batchs: 271.70843505859375
INFO:root:Train (Epoch 381): Loss/seq after 03650 batchs: 270.83941650390625
INFO:root:Train (Epoch 381): Loss/seq after 03700 batchs: 272.23101806640625
INFO:root:Train (Epoch 381): Loss/seq after 03750 batchs: 275.1177673339844
INFO:root:Train (Epoch 381): Loss/seq after 03800 batchs: 275.334228515625
INFO:root:Train (Epoch 381): Loss/seq after 03850 batchs: 275.1061706542969
INFO:root:Train (Epoch 381): Loss/seq after 03900 batchs: 276.5990295410156
INFO:root:Train (Epoch 381): Loss/seq after 03950 batchs: 279.33575439453125
INFO:root:Train (Epoch 381): Loss/seq after 04000 batchs: 278.15234375
INFO:root:Train (Epoch 381): Loss/seq after 04050 batchs: 276.8116149902344
INFO:root:Train (Epoch 381): Loss/seq after 04100 batchs: 275.915283203125
INFO:root:Train (Epoch 381): Loss/seq after 04150 batchs: 275.8093566894531
INFO:root:Train (Epoch 381): Loss/seq after 04200 batchs: 275.4264221191406
INFO:root:Train (Epoch 381): Loss/seq after 04250 batchs: 274.694580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 381): Loss/seq after 00000 batches: 290.1958923339844
INFO:root:# Valid (Epoch 381): Loss/seq after 00050 batches: 652.8248291015625
INFO:root:# Valid (Epoch 381): Loss/seq after 00100 batches: 651.8478393554688
INFO:root:# Valid (Epoch 381): Loss/seq after 00150 batches: 485.8422546386719
INFO:root:# Valid (Epoch 381): Loss/seq after 00200 batches: 447.6513366699219
INFO:root:Artifacts: Make stick videos for epoch 381
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_381_on_20220424_033842.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_381_index_1183_on_20220424_033842.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 382): Loss/seq after 00000 batchs: 393.7165832519531
INFO:root:Train (Epoch 382): Loss/seq after 00050 batchs: 418.0171813964844
INFO:root:Train (Epoch 382): Loss/seq after 00100 batchs: 412.9220886230469
INFO:root:Train (Epoch 382): Loss/seq after 00150 batchs: 379.17535400390625
INFO:root:Train (Epoch 382): Loss/seq after 00200 batchs: 415.2093200683594
INFO:root:Train (Epoch 382): Loss/seq after 00250 batchs: 420.0413818359375
INFO:root:Train (Epoch 382): Loss/seq after 00300 batchs: 434.9834899902344
INFO:root:Train (Epoch 382): Loss/seq after 00350 batchs: 414.5640563964844
INFO:root:Train (Epoch 382): Loss/seq after 00400 batchs: 404.1363830566406
INFO:root:Train (Epoch 382): Loss/seq after 00450 batchs: 420.2934265136719
INFO:root:Train (Epoch 382): Loss/seq after 00500 batchs: 405.1197204589844
INFO:root:Train (Epoch 382): Loss/seq after 00550 batchs: 399.0911865234375
INFO:root:Train (Epoch 382): Loss/seq after 00600 batchs: 384.197998046875
INFO:root:Train (Epoch 382): Loss/seq after 00650 batchs: 370.0762023925781
INFO:root:Train (Epoch 382): Loss/seq after 00700 batchs: 355.0287780761719
INFO:root:Train (Epoch 382): Loss/seq after 00750 batchs: 352.2386779785156
INFO:root:Train (Epoch 382): Loss/seq after 00800 batchs: 351.44793701171875
INFO:root:Train (Epoch 382): Loss/seq after 00850 batchs: 340.155029296875
INFO:root:Train (Epoch 382): Loss/seq after 00900 batchs: 331.949951171875
INFO:root:Train (Epoch 382): Loss/seq after 00950 batchs: 331.3699035644531
INFO:root:Train (Epoch 382): Loss/seq after 01000 batchs: 324.67474365234375
INFO:root:Train (Epoch 382): Loss/seq after 01050 batchs: 319.340576171875
INFO:root:Train (Epoch 382): Loss/seq after 01100 batchs: 312.7611083984375
INFO:root:Train (Epoch 382): Loss/seq after 01150 batchs: 304.4537048339844
INFO:root:Train (Epoch 382): Loss/seq after 01200 batchs: 303.03363037109375
INFO:root:Train (Epoch 382): Loss/seq after 01250 batchs: 302.2584228515625
INFO:root:Train (Epoch 382): Loss/seq after 01300 batchs: 296.3996887207031
INFO:root:Train (Epoch 382): Loss/seq after 01350 batchs: 290.2757568359375
INFO:root:Train (Epoch 382): Loss/seq after 01400 batchs: 291.49456787109375
INFO:root:Train (Epoch 382): Loss/seq after 01450 batchs: 293.33001708984375
INFO:root:Train (Epoch 382): Loss/seq after 01500 batchs: 298.1538391113281
INFO:root:Train (Epoch 382): Loss/seq after 01550 batchs: 299.9114074707031
INFO:root:Train (Epoch 382): Loss/seq after 01600 batchs: 299.9268798828125
INFO:root:Train (Epoch 382): Loss/seq after 01650 batchs: 298.9185485839844
INFO:root:Train (Epoch 382): Loss/seq after 01700 batchs: 299.43841552734375
INFO:root:Train (Epoch 382): Loss/seq after 01750 batchs: 298.47900390625
INFO:root:Train (Epoch 382): Loss/seq after 01800 batchs: 297.6365966796875
INFO:root:Train (Epoch 382): Loss/seq after 01850 batchs: 296.9344787597656
INFO:root:Train (Epoch 382): Loss/seq after 01900 batchs: 296.52313232421875
INFO:root:Train (Epoch 382): Loss/seq after 01950 batchs: 296.64923095703125
INFO:root:Train (Epoch 382): Loss/seq after 02000 batchs: 298.8233642578125
INFO:root:Train (Epoch 382): Loss/seq after 02050 batchs: 299.4270324707031
INFO:root:Train (Epoch 382): Loss/seq after 02100 batchs: 299.3058776855469
INFO:root:Train (Epoch 382): Loss/seq after 02150 batchs: 299.49169921875
INFO:root:Train (Epoch 382): Loss/seq after 02200 batchs: 299.09051513671875
INFO:root:Train (Epoch 382): Loss/seq after 02250 batchs: 298.4446105957031
INFO:root:Train (Epoch 382): Loss/seq after 02300 batchs: 296.8735656738281
INFO:root:Train (Epoch 382): Loss/seq after 02350 batchs: 295.1523742675781
INFO:root:Train (Epoch 382): Loss/seq after 02400 batchs: 294.576416015625
INFO:root:Train (Epoch 382): Loss/seq after 02450 batchs: 292.4061279296875
INFO:root:Train (Epoch 382): Loss/seq after 02500 batchs: 287.572509765625
INFO:root:Train (Epoch 382): Loss/seq after 02550 batchs: 283.4071044921875
INFO:root:Train (Epoch 382): Loss/seq after 02600 batchs: 280.0729675292969
INFO:root:Train (Epoch 382): Loss/seq after 02650 batchs: 276.98345947265625
INFO:root:Train (Epoch 382): Loss/seq after 02700 batchs: 275.03076171875
INFO:root:Train (Epoch 382): Loss/seq after 02750 batchs: 272.0084228515625
INFO:root:Train (Epoch 382): Loss/seq after 02800 batchs: 270.810302734375
INFO:root:Train (Epoch 382): Loss/seq after 02850 batchs: 270.42083740234375
INFO:root:Train (Epoch 382): Loss/seq after 02900 batchs: 270.3238525390625
INFO:root:Train (Epoch 382): Loss/seq after 02950 batchs: 271.22381591796875
INFO:root:Train (Epoch 382): Loss/seq after 03000 batchs: 273.7645263671875
INFO:root:Train (Epoch 382): Loss/seq after 03050 batchs: 275.7975769042969
INFO:root:Train (Epoch 382): Loss/seq after 03100 batchs: 277.5721740722656
INFO:root:Train (Epoch 382): Loss/seq after 03150 batchs: 277.8443908691406
INFO:root:Train (Epoch 382): Loss/seq after 03200 batchs: 277.6662292480469
INFO:root:Train (Epoch 382): Loss/seq after 03250 batchs: 277.46820068359375
INFO:root:Train (Epoch 382): Loss/seq after 03300 batchs: 277.14892578125
INFO:root:Train (Epoch 382): Loss/seq after 03350 batchs: 276.0767822265625
INFO:root:Train (Epoch 382): Loss/seq after 03400 batchs: 274.4554138183594
INFO:root:Train (Epoch 382): Loss/seq after 03450 batchs: 273.38043212890625
INFO:root:Train (Epoch 382): Loss/seq after 03500 batchs: 274.4046936035156
INFO:root:Train (Epoch 382): Loss/seq after 03550 batchs: 273.5289306640625
INFO:root:Train (Epoch 382): Loss/seq after 03600 batchs: 275.7696228027344
INFO:root:Train (Epoch 382): Loss/seq after 03650 batchs: 275.0498962402344
INFO:root:Train (Epoch 382): Loss/seq after 03700 batchs: 276.3406066894531
INFO:root:Train (Epoch 382): Loss/seq after 03750 batchs: 279.1662292480469
INFO:root:Train (Epoch 382): Loss/seq after 03800 batchs: 279.42138671875
INFO:root:Train (Epoch 382): Loss/seq after 03850 batchs: 278.98431396484375
INFO:root:Train (Epoch 382): Loss/seq after 03900 batchs: 280.7096252441406
INFO:root:Train (Epoch 382): Loss/seq after 03950 batchs: 283.75347900390625
INFO:root:Train (Epoch 382): Loss/seq after 04000 batchs: 282.52069091796875
INFO:root:Train (Epoch 382): Loss/seq after 04050 batchs: 281.10943603515625
INFO:root:Train (Epoch 382): Loss/seq after 04100 batchs: 280.2898254394531
INFO:root:Train (Epoch 382): Loss/seq after 04150 batchs: 280.0457763671875
INFO:root:Train (Epoch 382): Loss/seq after 04200 batchs: 279.66693115234375
INFO:root:Train (Epoch 382): Loss/seq after 04250 batchs: 278.9383239746094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 382): Loss/seq after 00000 batches: 212.0335693359375
INFO:root:# Valid (Epoch 382): Loss/seq after 00050 batches: 630.8641967773438
INFO:root:# Valid (Epoch 382): Loss/seq after 00100 batches: 641.1521606445312
INFO:root:# Valid (Epoch 382): Loss/seq after 00150 batches: 481.5814208984375
INFO:root:# Valid (Epoch 382): Loss/seq after 00200 batches: 446.78570556640625
INFO:root:Artifacts: Make stick videos for epoch 382
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_382_on_20220424_034330.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_382_index_1134_on_20220424_034330.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 383): Loss/seq after 00000 batchs: 1234.4169921875
INFO:root:Train (Epoch 383): Loss/seq after 00050 batchs: 371.9911193847656
INFO:root:Train (Epoch 383): Loss/seq after 00100 batchs: 369.4554138183594
INFO:root:Train (Epoch 383): Loss/seq after 00150 batchs: 350.9454345703125
INFO:root:Train (Epoch 383): Loss/seq after 00200 batchs: 389.5517578125
INFO:root:Train (Epoch 383): Loss/seq after 00250 batchs: 422.0071716308594
INFO:root:Train (Epoch 383): Loss/seq after 00300 batchs: 439.36212158203125
INFO:root:Train (Epoch 383): Loss/seq after 00350 batchs: 421.6412353515625
INFO:root:Train (Epoch 383): Loss/seq after 00400 batchs: 420.64532470703125
INFO:root:Train (Epoch 383): Loss/seq after 00450 batchs: 434.6060791015625
INFO:root:Train (Epoch 383): Loss/seq after 00500 batchs: 422.9082946777344
INFO:root:Train (Epoch 383): Loss/seq after 00550 batchs: 415.0768127441406
INFO:root:Train (Epoch 383): Loss/seq after 00600 batchs: 398.64312744140625
INFO:root:Train (Epoch 383): Loss/seq after 00650 batchs: 382.6503601074219
INFO:root:Train (Epoch 383): Loss/seq after 00700 batchs: 366.6827392578125
INFO:root:Train (Epoch 383): Loss/seq after 00750 batchs: 360.8225402832031
INFO:root:Train (Epoch 383): Loss/seq after 00800 batchs: 359.3341979980469
INFO:root:Train (Epoch 383): Loss/seq after 00850 batchs: 346.8680419921875
INFO:root:Train (Epoch 383): Loss/seq after 00900 batchs: 337.9591064453125
INFO:root:Train (Epoch 383): Loss/seq after 00950 batchs: 339.10906982421875
INFO:root:Train (Epoch 383): Loss/seq after 01000 batchs: 333.26544189453125
INFO:root:Train (Epoch 383): Loss/seq after 01050 batchs: 327.2247009277344
INFO:root:Train (Epoch 383): Loss/seq after 01100 batchs: 319.3910217285156
INFO:root:Train (Epoch 383): Loss/seq after 01150 batchs: 310.9748840332031
INFO:root:Train (Epoch 383): Loss/seq after 01200 batchs: 309.4759521484375
INFO:root:Train (Epoch 383): Loss/seq after 01250 batchs: 308.38677978515625
INFO:root:Train (Epoch 383): Loss/seq after 01300 batchs: 301.8983459472656
INFO:root:Train (Epoch 383): Loss/seq after 01350 batchs: 295.593017578125
INFO:root:Train (Epoch 383): Loss/seq after 01400 batchs: 297.66278076171875
INFO:root:Train (Epoch 383): Loss/seq after 01450 batchs: 298.3333435058594
INFO:root:Train (Epoch 383): Loss/seq after 01500 batchs: 302.5799255371094
INFO:root:Train (Epoch 383): Loss/seq after 01550 batchs: 303.4089050292969
INFO:root:Train (Epoch 383): Loss/seq after 01600 batchs: 302.2900085449219
INFO:root:Train (Epoch 383): Loss/seq after 01650 batchs: 301.0103759765625
INFO:root:Train (Epoch 383): Loss/seq after 01700 batchs: 301.5036315917969
INFO:root:Train (Epoch 383): Loss/seq after 01750 batchs: 300.2470397949219
INFO:root:Train (Epoch 383): Loss/seq after 01800 batchs: 299.1369323730469
INFO:root:Train (Epoch 383): Loss/seq after 01850 batchs: 298.171630859375
INFO:root:Train (Epoch 383): Loss/seq after 01900 batchs: 297.65106201171875
INFO:root:Train (Epoch 383): Loss/seq after 01950 batchs: 297.8388977050781
INFO:root:Train (Epoch 383): Loss/seq after 02000 batchs: 299.8557434082031
INFO:root:Train (Epoch 383): Loss/seq after 02050 batchs: 300.26611328125
INFO:root:Train (Epoch 383): Loss/seq after 02100 batchs: 300.0102233886719
INFO:root:Train (Epoch 383): Loss/seq after 02150 batchs: 300.058837890625
INFO:root:Train (Epoch 383): Loss/seq after 02200 batchs: 299.6953430175781
INFO:root:Train (Epoch 383): Loss/seq after 02250 batchs: 299.0080871582031
INFO:root:Train (Epoch 383): Loss/seq after 02300 batchs: 296.8991394042969
INFO:root:Train (Epoch 383): Loss/seq after 02350 batchs: 295.1728820800781
INFO:root:Train (Epoch 383): Loss/seq after 02400 batchs: 294.57720947265625
INFO:root:Train (Epoch 383): Loss/seq after 02450 batchs: 292.43719482421875
INFO:root:Train (Epoch 383): Loss/seq after 02500 batchs: 287.6668701171875
INFO:root:Train (Epoch 383): Loss/seq after 02550 batchs: 283.53985595703125
INFO:root:Train (Epoch 383): Loss/seq after 02600 batchs: 280.17095947265625
INFO:root:Train (Epoch 383): Loss/seq after 02650 batchs: 277.03131103515625
INFO:root:Train (Epoch 383): Loss/seq after 02700 batchs: 275.0620422363281
INFO:root:Train (Epoch 383): Loss/seq after 02750 batchs: 271.889892578125
INFO:root:Train (Epoch 383): Loss/seq after 02800 batchs: 270.9983825683594
INFO:root:Train (Epoch 383): Loss/seq after 02850 batchs: 270.6481018066406
INFO:root:Train (Epoch 383): Loss/seq after 02900 batchs: 270.5830993652344
INFO:root:Train (Epoch 383): Loss/seq after 02950 batchs: 271.54803466796875
INFO:root:Train (Epoch 383): Loss/seq after 03000 batchs: 273.9081115722656
INFO:root:Train (Epoch 383): Loss/seq after 03050 batchs: 275.0284423828125
INFO:root:Train (Epoch 383): Loss/seq after 03100 batchs: 276.36016845703125
INFO:root:Train (Epoch 383): Loss/seq after 03150 batchs: 276.9017639160156
INFO:root:Train (Epoch 383): Loss/seq after 03200 batchs: 277.1929016113281
INFO:root:Train (Epoch 383): Loss/seq after 03250 batchs: 276.7108154296875
INFO:root:Train (Epoch 383): Loss/seq after 03300 batchs: 276.66796875
INFO:root:Train (Epoch 383): Loss/seq after 03350 batchs: 275.3868103027344
INFO:root:Train (Epoch 383): Loss/seq after 03400 batchs: 273.8779602050781
INFO:root:Train (Epoch 383): Loss/seq after 03450 batchs: 272.7204284667969
INFO:root:Train (Epoch 383): Loss/seq after 03500 batchs: 273.5
INFO:root:Train (Epoch 383): Loss/seq after 03550 batchs: 272.6067810058594
INFO:root:Train (Epoch 383): Loss/seq after 03600 batchs: 274.5498046875
INFO:root:Train (Epoch 383): Loss/seq after 03650 batchs: 273.59100341796875
INFO:root:Train (Epoch 383): Loss/seq after 03700 batchs: 275.1832275390625
INFO:root:Train (Epoch 383): Loss/seq after 03750 batchs: 278.26593017578125
INFO:root:Train (Epoch 383): Loss/seq after 03800 batchs: 278.5182189941406
INFO:root:Train (Epoch 383): Loss/seq after 03850 batchs: 278.3633728027344
INFO:root:Train (Epoch 383): Loss/seq after 03900 batchs: 279.0906677246094
INFO:root:Train (Epoch 383): Loss/seq after 03950 batchs: 280.7501525878906
INFO:root:Train (Epoch 383): Loss/seq after 04000 batchs: 279.5586242675781
INFO:root:Train (Epoch 383): Loss/seq after 04050 batchs: 278.2740783691406
INFO:root:Train (Epoch 383): Loss/seq after 04100 batchs: 277.364990234375
INFO:root:Train (Epoch 383): Loss/seq after 04150 batchs: 277.2607727050781
INFO:root:Train (Epoch 383): Loss/seq after 04200 batchs: 276.83990478515625
INFO:root:Train (Epoch 383): Loss/seq after 04250 batchs: 275.9713134765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 383): Loss/seq after 00000 batches: 262.35870361328125
INFO:root:# Valid (Epoch 383): Loss/seq after 00050 batches: 661.5988159179688
INFO:root:# Valid (Epoch 383): Loss/seq after 00100 batches: 651.6124877929688
INFO:root:# Valid (Epoch 383): Loss/seq after 00150 batches: 484.238037109375
INFO:root:# Valid (Epoch 383): Loss/seq after 00200 batches: 445.4549560546875
INFO:root:Artifacts: Make stick videos for epoch 383
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_383_on_20220424_034830.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_383_index_724_on_20220424_034830.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 384): Loss/seq after 00000 batchs: 624.3078002929688
INFO:root:Train (Epoch 384): Loss/seq after 00050 batchs: 355.888671875
INFO:root:Train (Epoch 384): Loss/seq after 00100 batchs: 397.33477783203125
INFO:root:Train (Epoch 384): Loss/seq after 00150 batchs: 368.8932189941406
INFO:root:Train (Epoch 384): Loss/seq after 00200 batchs: 402.5091247558594
INFO:root:Train (Epoch 384): Loss/seq after 00250 batchs: 407.78955078125
INFO:root:Train (Epoch 384): Loss/seq after 00300 batchs: 423.9645080566406
INFO:root:Train (Epoch 384): Loss/seq after 00350 batchs: 408.2483825683594
INFO:root:Train (Epoch 384): Loss/seq after 00400 batchs: 398.6891174316406
INFO:root:Train (Epoch 384): Loss/seq after 00450 batchs: 415.3955383300781
INFO:root:Train (Epoch 384): Loss/seq after 00500 batchs: 401.0026550292969
INFO:root:Train (Epoch 384): Loss/seq after 00550 batchs: 395.6402282714844
INFO:root:Train (Epoch 384): Loss/seq after 00600 batchs: 380.8480224609375
INFO:root:Train (Epoch 384): Loss/seq after 00650 batchs: 365.12408447265625
INFO:root:Train (Epoch 384): Loss/seq after 00700 batchs: 349.6210632324219
INFO:root:Train (Epoch 384): Loss/seq after 00750 batchs: 344.1752014160156
INFO:root:Train (Epoch 384): Loss/seq after 00800 batchs: 343.2048034667969
INFO:root:Train (Epoch 384): Loss/seq after 00850 batchs: 332.0645751953125
INFO:root:Train (Epoch 384): Loss/seq after 00900 batchs: 323.54302978515625
INFO:root:Train (Epoch 384): Loss/seq after 00950 batchs: 323.775146484375
INFO:root:Train (Epoch 384): Loss/seq after 01000 batchs: 317.9007568359375
INFO:root:Train (Epoch 384): Loss/seq after 01050 batchs: 312.4074401855469
INFO:root:Train (Epoch 384): Loss/seq after 01100 batchs: 305.07568359375
INFO:root:Train (Epoch 384): Loss/seq after 01150 batchs: 297.02447509765625
INFO:root:Train (Epoch 384): Loss/seq after 01200 batchs: 295.1448059082031
INFO:root:Train (Epoch 384): Loss/seq after 01250 batchs: 294.4180908203125
INFO:root:Train (Epoch 384): Loss/seq after 01300 batchs: 288.5372009277344
INFO:root:Train (Epoch 384): Loss/seq after 01350 batchs: 282.6602783203125
INFO:root:Train (Epoch 384): Loss/seq after 01400 batchs: 284.0333557128906
INFO:root:Train (Epoch 384): Loss/seq after 01450 batchs: 285.22027587890625
INFO:root:Train (Epoch 384): Loss/seq after 01500 batchs: 289.5975646972656
INFO:root:Train (Epoch 384): Loss/seq after 01550 batchs: 290.1375732421875
INFO:root:Train (Epoch 384): Loss/seq after 01600 batchs: 289.11737060546875
INFO:root:Train (Epoch 384): Loss/seq after 01650 batchs: 287.8770446777344
INFO:root:Train (Epoch 384): Loss/seq after 01700 batchs: 288.44049072265625
INFO:root:Train (Epoch 384): Loss/seq after 01750 batchs: 287.5241394042969
INFO:root:Train (Epoch 384): Loss/seq after 01800 batchs: 286.7214050292969
INFO:root:Train (Epoch 384): Loss/seq after 01850 batchs: 286.01043701171875
INFO:root:Train (Epoch 384): Loss/seq after 01900 batchs: 285.6548156738281
INFO:root:Train (Epoch 384): Loss/seq after 01950 batchs: 286.0400390625
INFO:root:Train (Epoch 384): Loss/seq after 02000 batchs: 288.27471923828125
INFO:root:Train (Epoch 384): Loss/seq after 02050 batchs: 288.9761657714844
INFO:root:Train (Epoch 384): Loss/seq after 02100 batchs: 289.0061340332031
INFO:root:Train (Epoch 384): Loss/seq after 02150 batchs: 289.43115234375
INFO:root:Train (Epoch 384): Loss/seq after 02200 batchs: 289.37847900390625
INFO:root:Train (Epoch 384): Loss/seq after 02250 batchs: 288.8470153808594
INFO:root:Train (Epoch 384): Loss/seq after 02300 batchs: 287.0690002441406
INFO:root:Train (Epoch 384): Loss/seq after 02350 batchs: 285.5368347167969
INFO:root:Train (Epoch 384): Loss/seq after 02400 batchs: 285.04632568359375
INFO:root:Train (Epoch 384): Loss/seq after 02450 batchs: 283.1593933105469
INFO:root:Train (Epoch 384): Loss/seq after 02500 batchs: 278.51483154296875
INFO:root:Train (Epoch 384): Loss/seq after 02550 batchs: 274.53985595703125
INFO:root:Train (Epoch 384): Loss/seq after 02600 batchs: 271.2396545410156
INFO:root:Train (Epoch 384): Loss/seq after 02650 batchs: 268.20849609375
INFO:root:Train (Epoch 384): Loss/seq after 02700 batchs: 266.2805480957031
INFO:root:Train (Epoch 384): Loss/seq after 02750 batchs: 263.34735107421875
INFO:root:Train (Epoch 384): Loss/seq after 02800 batchs: 261.72222900390625
INFO:root:Train (Epoch 384): Loss/seq after 02850 batchs: 261.3191833496094
INFO:root:Train (Epoch 384): Loss/seq after 02900 batchs: 261.2717590332031
INFO:root:Train (Epoch 384): Loss/seq after 02950 batchs: 262.16607666015625
INFO:root:Train (Epoch 384): Loss/seq after 03000 batchs: 265.1111145019531
INFO:root:Train (Epoch 384): Loss/seq after 03050 batchs: 266.36859130859375
INFO:root:Train (Epoch 384): Loss/seq after 03100 batchs: 267.4549560546875
INFO:root:Train (Epoch 384): Loss/seq after 03150 batchs: 266.76727294921875
INFO:root:Train (Epoch 384): Loss/seq after 03200 batchs: 266.76727294921875
INFO:root:Train (Epoch 384): Loss/seq after 03250 batchs: 266.3753356933594
INFO:root:Train (Epoch 384): Loss/seq after 03300 batchs: 265.69476318359375
INFO:root:Train (Epoch 384): Loss/seq after 03350 batchs: 264.4065246582031
INFO:root:Train (Epoch 384): Loss/seq after 03400 batchs: 262.8861083984375
INFO:root:Train (Epoch 384): Loss/seq after 03450 batchs: 261.7774963378906
INFO:root:Train (Epoch 384): Loss/seq after 03500 batchs: 262.5613708496094
INFO:root:Train (Epoch 384): Loss/seq after 03550 batchs: 261.75335693359375
INFO:root:Train (Epoch 384): Loss/seq after 03600 batchs: 263.94219970703125
INFO:root:Train (Epoch 384): Loss/seq after 03650 batchs: 262.94854736328125
INFO:root:Train (Epoch 384): Loss/seq after 03700 batchs: 264.1407775878906
INFO:root:Train (Epoch 384): Loss/seq after 03750 batchs: 266.9320373535156
INFO:root:Train (Epoch 384): Loss/seq after 03800 batchs: 267.4012145996094
INFO:root:Train (Epoch 384): Loss/seq after 03850 batchs: 267.2532958984375
INFO:root:Train (Epoch 384): Loss/seq after 03900 batchs: 268.06695556640625
INFO:root:Train (Epoch 384): Loss/seq after 03950 batchs: 270.5376892089844
INFO:root:Train (Epoch 384): Loss/seq after 04000 batchs: 269.4720458984375
INFO:root:Train (Epoch 384): Loss/seq after 04050 batchs: 268.22076416015625
INFO:root:Train (Epoch 384): Loss/seq after 04100 batchs: 267.4010314941406
INFO:root:Train (Epoch 384): Loss/seq after 04150 batchs: 267.3463134765625
INFO:root:Train (Epoch 384): Loss/seq after 04200 batchs: 267.0619201660156
INFO:root:Train (Epoch 384): Loss/seq after 04250 batchs: 266.3707275390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 384): Loss/seq after 00000 batches: 178.2371063232422
INFO:root:# Valid (Epoch 384): Loss/seq after 00050 batches: 619.78076171875
INFO:root:# Valid (Epoch 384): Loss/seq after 00100 batches: 614.5261840820312
INFO:root:# Valid (Epoch 384): Loss/seq after 00150 batches: 465.65960693359375
INFO:root:# Valid (Epoch 384): Loss/seq after 00200 batches: 434.8863830566406
INFO:root:Artifacts: Make stick videos for epoch 384
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_384_on_20220424_035336.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_384_index_841_on_20220424_035336.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 385): Loss/seq after 00000 batchs: 530.3818969726562
INFO:root:Train (Epoch 385): Loss/seq after 00050 batchs: 370.7093811035156
INFO:root:Train (Epoch 385): Loss/seq after 00100 batchs: 365.22283935546875
INFO:root:Train (Epoch 385): Loss/seq after 00150 batchs: 344.98699951171875
INFO:root:Train (Epoch 385): Loss/seq after 00200 batchs: 387.8817443847656
INFO:root:Train (Epoch 385): Loss/seq after 00250 batchs: 391.2311706542969
INFO:root:Train (Epoch 385): Loss/seq after 00300 batchs: 407.8426208496094
INFO:root:Train (Epoch 385): Loss/seq after 00350 batchs: 391.4489440917969
INFO:root:Train (Epoch 385): Loss/seq after 00400 batchs: 383.4374084472656
INFO:root:Train (Epoch 385): Loss/seq after 00450 batchs: 400.5899963378906
INFO:root:Train (Epoch 385): Loss/seq after 00500 batchs: 388.6548767089844
INFO:root:Train (Epoch 385): Loss/seq after 00550 batchs: 384.1468505859375
INFO:root:Train (Epoch 385): Loss/seq after 00600 batchs: 370.9937744140625
INFO:root:Train (Epoch 385): Loss/seq after 00650 batchs: 356.81768798828125
INFO:root:Train (Epoch 385): Loss/seq after 00700 batchs: 342.49383544921875
INFO:root:Train (Epoch 385): Loss/seq after 00750 batchs: 337.7608337402344
INFO:root:Train (Epoch 385): Loss/seq after 00800 batchs: 337.5464172363281
INFO:root:Train (Epoch 385): Loss/seq after 00850 batchs: 327.04498291015625
INFO:root:Train (Epoch 385): Loss/seq after 00900 batchs: 318.5959167480469
INFO:root:Train (Epoch 385): Loss/seq after 00950 batchs: 318.1449890136719
INFO:root:Train (Epoch 385): Loss/seq after 01000 batchs: 311.65557861328125
INFO:root:Train (Epoch 385): Loss/seq after 01050 batchs: 305.50494384765625
INFO:root:Train (Epoch 385): Loss/seq after 01100 batchs: 298.7828063964844
INFO:root:Train (Epoch 385): Loss/seq after 01150 batchs: 290.9297790527344
INFO:root:Train (Epoch 385): Loss/seq after 01200 batchs: 289.54632568359375
INFO:root:Train (Epoch 385): Loss/seq after 01250 batchs: 289.1209411621094
INFO:root:Train (Epoch 385): Loss/seq after 01300 batchs: 283.2982482910156
INFO:root:Train (Epoch 385): Loss/seq after 01350 batchs: 277.1808166503906
INFO:root:Train (Epoch 385): Loss/seq after 01400 batchs: 277.95550537109375
INFO:root:Train (Epoch 385): Loss/seq after 01450 batchs: 279.42059326171875
INFO:root:Train (Epoch 385): Loss/seq after 01500 batchs: 284.66607666015625
INFO:root:Train (Epoch 385): Loss/seq after 01550 batchs: 285.7284851074219
INFO:root:Train (Epoch 385): Loss/seq after 01600 batchs: 285.10052490234375
INFO:root:Train (Epoch 385): Loss/seq after 01650 batchs: 284.10247802734375
INFO:root:Train (Epoch 385): Loss/seq after 01700 batchs: 284.7051086425781
INFO:root:Train (Epoch 385): Loss/seq after 01750 batchs: 283.94281005859375
INFO:root:Train (Epoch 385): Loss/seq after 01800 batchs: 283.3355712890625
INFO:root:Train (Epoch 385): Loss/seq after 01850 batchs: 282.78167724609375
INFO:root:Train (Epoch 385): Loss/seq after 01900 batchs: 282.5780334472656
INFO:root:Train (Epoch 385): Loss/seq after 01950 batchs: 282.71417236328125
INFO:root:Train (Epoch 385): Loss/seq after 02000 batchs: 284.96923828125
INFO:root:Train (Epoch 385): Loss/seq after 02050 batchs: 285.7059631347656
INFO:root:Train (Epoch 385): Loss/seq after 02100 batchs: 285.867919921875
INFO:root:Train (Epoch 385): Loss/seq after 02150 batchs: 286.3248291015625
INFO:root:Train (Epoch 385): Loss/seq after 02200 batchs: 286.07220458984375
INFO:root:Train (Epoch 385): Loss/seq after 02250 batchs: 285.3603820800781
INFO:root:Train (Epoch 385): Loss/seq after 02300 batchs: 283.6316223144531
INFO:root:Train (Epoch 385): Loss/seq after 02350 batchs: 282.0958557128906
INFO:root:Train (Epoch 385): Loss/seq after 02400 batchs: 281.7998046875
INFO:root:Train (Epoch 385): Loss/seq after 02450 batchs: 279.8456115722656
INFO:root:Train (Epoch 385): Loss/seq after 02500 batchs: 275.28277587890625
INFO:root:Train (Epoch 385): Loss/seq after 02550 batchs: 271.3010559082031
INFO:root:Train (Epoch 385): Loss/seq after 02600 batchs: 268.07080078125
INFO:root:Train (Epoch 385): Loss/seq after 02650 batchs: 265.1976013183594
INFO:root:Train (Epoch 385): Loss/seq after 02700 batchs: 263.4214172363281
INFO:root:Train (Epoch 385): Loss/seq after 02750 batchs: 260.3169250488281
INFO:root:Train (Epoch 385): Loss/seq after 02800 batchs: 258.69915771484375
INFO:root:Train (Epoch 385): Loss/seq after 02850 batchs: 258.453369140625
INFO:root:Train (Epoch 385): Loss/seq after 02900 batchs: 258.6075744628906
INFO:root:Train (Epoch 385): Loss/seq after 02950 batchs: 259.9013977050781
INFO:root:Train (Epoch 385): Loss/seq after 03000 batchs: 262.6316833496094
INFO:root:Train (Epoch 385): Loss/seq after 03050 batchs: 264.14501953125
INFO:root:Train (Epoch 385): Loss/seq after 03100 batchs: 265.3154602050781
INFO:root:Train (Epoch 385): Loss/seq after 03150 batchs: 265.2225036621094
INFO:root:Train (Epoch 385): Loss/seq after 03200 batchs: 265.4052429199219
INFO:root:Train (Epoch 385): Loss/seq after 03250 batchs: 264.8731994628906
INFO:root:Train (Epoch 385): Loss/seq after 03300 batchs: 264.2734069824219
INFO:root:Train (Epoch 385): Loss/seq after 03350 batchs: 262.79779052734375
INFO:root:Train (Epoch 385): Loss/seq after 03400 batchs: 261.3138122558594
INFO:root:Train (Epoch 385): Loss/seq after 03450 batchs: 260.2699279785156
INFO:root:Train (Epoch 385): Loss/seq after 03500 batchs: 261.2088623046875
INFO:root:Train (Epoch 385): Loss/seq after 03550 batchs: 260.3119812011719
INFO:root:Train (Epoch 385): Loss/seq after 03600 batchs: 262.47857666015625
INFO:root:Train (Epoch 385): Loss/seq after 03650 batchs: 261.6118469238281
INFO:root:Train (Epoch 385): Loss/seq after 03700 batchs: 262.88543701171875
INFO:root:Train (Epoch 385): Loss/seq after 03750 batchs: 265.7093200683594
INFO:root:Train (Epoch 385): Loss/seq after 03800 batchs: 266.0307922363281
INFO:root:Train (Epoch 385): Loss/seq after 03850 batchs: 265.7289733886719
INFO:root:Train (Epoch 385): Loss/seq after 03900 batchs: 266.898681640625
INFO:root:Train (Epoch 385): Loss/seq after 03950 batchs: 268.75885009765625
INFO:root:Train (Epoch 385): Loss/seq after 04000 batchs: 267.6645812988281
INFO:root:Train (Epoch 385): Loss/seq after 04050 batchs: 266.3643798828125
INFO:root:Train (Epoch 385): Loss/seq after 04100 batchs: 265.54522705078125
INFO:root:Train (Epoch 385): Loss/seq after 04150 batchs: 265.41790771484375
INFO:root:Train (Epoch 385): Loss/seq after 04200 batchs: 265.11773681640625
INFO:root:Train (Epoch 385): Loss/seq after 04250 batchs: 264.4173889160156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 385): Loss/seq after 00000 batches: 239.05084228515625
INFO:root:# Valid (Epoch 385): Loss/seq after 00050 batches: 638.2197875976562
INFO:root:# Valid (Epoch 385): Loss/seq after 00100 batches: 622.0672607421875
INFO:root:# Valid (Epoch 385): Loss/seq after 00150 batches: 469.3874206542969
INFO:root:# Valid (Epoch 385): Loss/seq after 00200 batches: 439.3527526855469
INFO:root:Artifacts: Make stick videos for epoch 385
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_385_on_20220424_035829.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_385_index_1712_on_20220424_035829.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 386): Loss/seq after 00000 batchs: 579.8092041015625
INFO:root:Train (Epoch 386): Loss/seq after 00050 batchs: 368.0897521972656
INFO:root:Train (Epoch 386): Loss/seq after 00100 batchs: 367.7212219238281
INFO:root:Train (Epoch 386): Loss/seq after 00150 batchs: 344.3736572265625
INFO:root:Train (Epoch 386): Loss/seq after 00200 batchs: 382.31036376953125
INFO:root:Train (Epoch 386): Loss/seq after 00250 batchs: 391.23162841796875
INFO:root:Train (Epoch 386): Loss/seq after 00300 batchs: 408.2510070800781
INFO:root:Train (Epoch 386): Loss/seq after 00350 batchs: 391.801513671875
INFO:root:Train (Epoch 386): Loss/seq after 00400 batchs: 382.3922424316406
INFO:root:Train (Epoch 386): Loss/seq after 00450 batchs: 399.08148193359375
INFO:root:Train (Epoch 386): Loss/seq after 00500 batchs: 385.4085388183594
INFO:root:Train (Epoch 386): Loss/seq after 00550 batchs: 382.0729064941406
INFO:root:Train (Epoch 386): Loss/seq after 00600 batchs: 368.315185546875
INFO:root:Train (Epoch 386): Loss/seq after 00650 batchs: 353.5723571777344
INFO:root:Train (Epoch 386): Loss/seq after 00700 batchs: 339.6443176269531
INFO:root:Train (Epoch 386): Loss/seq after 00750 batchs: 335.3140563964844
INFO:root:Train (Epoch 386): Loss/seq after 00800 batchs: 334.8803405761719
INFO:root:Train (Epoch 386): Loss/seq after 00850 batchs: 323.6376037597656
INFO:root:Train (Epoch 386): Loss/seq after 00900 batchs: 316.0751037597656
INFO:root:Train (Epoch 386): Loss/seq after 00950 batchs: 315.5574035644531
INFO:root:Train (Epoch 386): Loss/seq after 01000 batchs: 309.7696533203125
INFO:root:Train (Epoch 386): Loss/seq after 01050 batchs: 303.4291076660156
INFO:root:Train (Epoch 386): Loss/seq after 01100 batchs: 296.6933288574219
INFO:root:Train (Epoch 386): Loss/seq after 01150 batchs: 288.9445495605469
INFO:root:Train (Epoch 386): Loss/seq after 01200 batchs: 287.9010314941406
INFO:root:Train (Epoch 386): Loss/seq after 01250 batchs: 287.6064758300781
INFO:root:Train (Epoch 386): Loss/seq after 01300 batchs: 281.8154296875
INFO:root:Train (Epoch 386): Loss/seq after 01350 batchs: 275.62481689453125
INFO:root:Train (Epoch 386): Loss/seq after 01400 batchs: 276.3558044433594
INFO:root:Train (Epoch 386): Loss/seq after 01450 batchs: 278.0004577636719
INFO:root:Train (Epoch 386): Loss/seq after 01500 batchs: 283.5738830566406
INFO:root:Train (Epoch 386): Loss/seq after 01550 batchs: 284.81103515625
INFO:root:Train (Epoch 386): Loss/seq after 01600 batchs: 284.2764587402344
INFO:root:Train (Epoch 386): Loss/seq after 01650 batchs: 284.0468444824219
INFO:root:Train (Epoch 386): Loss/seq after 01700 batchs: 284.72308349609375
INFO:root:Train (Epoch 386): Loss/seq after 01750 batchs: 284.2115783691406
INFO:root:Train (Epoch 386): Loss/seq after 01800 batchs: 283.5832824707031
INFO:root:Train (Epoch 386): Loss/seq after 01850 batchs: 283.0958557128906
INFO:root:Train (Epoch 386): Loss/seq after 01900 batchs: 283.079833984375
INFO:root:Train (Epoch 386): Loss/seq after 01950 batchs: 283.4635009765625
INFO:root:Train (Epoch 386): Loss/seq after 02000 batchs: 285.82281494140625
INFO:root:Train (Epoch 386): Loss/seq after 02050 batchs: 286.6891174316406
INFO:root:Train (Epoch 386): Loss/seq after 02100 batchs: 286.7909851074219
INFO:root:Train (Epoch 386): Loss/seq after 02150 batchs: 287.34246826171875
INFO:root:Train (Epoch 386): Loss/seq after 02200 batchs: 287.07196044921875
INFO:root:Train (Epoch 386): Loss/seq after 02250 batchs: 286.6066589355469
INFO:root:Train (Epoch 386): Loss/seq after 02300 batchs: 285.2213134765625
INFO:root:Train (Epoch 386): Loss/seq after 02350 batchs: 283.6599426269531
INFO:root:Train (Epoch 386): Loss/seq after 02400 batchs: 283.30035400390625
INFO:root:Train (Epoch 386): Loss/seq after 02450 batchs: 281.2621765136719
INFO:root:Train (Epoch 386): Loss/seq after 02500 batchs: 276.65277099609375
INFO:root:Train (Epoch 386): Loss/seq after 02550 batchs: 272.691650390625
INFO:root:Train (Epoch 386): Loss/seq after 02600 batchs: 269.4296569824219
INFO:root:Train (Epoch 386): Loss/seq after 02650 batchs: 267.1585998535156
INFO:root:Train (Epoch 386): Loss/seq after 02700 batchs: 265.4349365234375
INFO:root:Train (Epoch 386): Loss/seq after 02750 batchs: 262.4021911621094
INFO:root:Train (Epoch 386): Loss/seq after 02800 batchs: 260.9304504394531
INFO:root:Train (Epoch 386): Loss/seq after 02850 batchs: 260.83953857421875
INFO:root:Train (Epoch 386): Loss/seq after 02900 batchs: 260.9912109375
INFO:root:Train (Epoch 386): Loss/seq after 02950 batchs: 262.1092834472656
INFO:root:Train (Epoch 386): Loss/seq after 03000 batchs: 264.71710205078125
INFO:root:Train (Epoch 386): Loss/seq after 03050 batchs: 265.85211181640625
INFO:root:Train (Epoch 386): Loss/seq after 03100 batchs: 266.6050720214844
INFO:root:Train (Epoch 386): Loss/seq after 03150 batchs: 266.72955322265625
INFO:root:Train (Epoch 386): Loss/seq after 03200 batchs: 266.1942138671875
INFO:root:Train (Epoch 386): Loss/seq after 03250 batchs: 265.732177734375
INFO:root:Train (Epoch 386): Loss/seq after 03300 batchs: 265.2968444824219
INFO:root:Train (Epoch 386): Loss/seq after 03350 batchs: 263.9140625
INFO:root:Train (Epoch 386): Loss/seq after 03400 batchs: 262.39825439453125
INFO:root:Train (Epoch 386): Loss/seq after 03450 batchs: 261.48077392578125
INFO:root:Train (Epoch 386): Loss/seq after 03500 batchs: 262.2744445800781
INFO:root:Train (Epoch 386): Loss/seq after 03550 batchs: 261.41912841796875
INFO:root:Train (Epoch 386): Loss/seq after 03600 batchs: 263.71197509765625
INFO:root:Train (Epoch 386): Loss/seq after 03650 batchs: 262.8743896484375
INFO:root:Train (Epoch 386): Loss/seq after 03700 batchs: 264.1029357910156
INFO:root:Train (Epoch 386): Loss/seq after 03750 batchs: 266.8114013671875
INFO:root:Train (Epoch 386): Loss/seq after 03800 batchs: 267.09869384765625
INFO:root:Train (Epoch 386): Loss/seq after 03850 batchs: 266.8310241699219
INFO:root:Train (Epoch 386): Loss/seq after 03900 batchs: 267.4855651855469
INFO:root:Train (Epoch 386): Loss/seq after 03950 batchs: 269.0650939941406
INFO:root:Train (Epoch 386): Loss/seq after 04000 batchs: 267.9774475097656
INFO:root:Train (Epoch 386): Loss/seq after 04050 batchs: 266.73040771484375
INFO:root:Train (Epoch 386): Loss/seq after 04100 batchs: 265.8937072753906
INFO:root:Train (Epoch 386): Loss/seq after 04150 batchs: 265.73345947265625
INFO:root:Train (Epoch 386): Loss/seq after 04200 batchs: 265.4637451171875
INFO:root:Train (Epoch 386): Loss/seq after 04250 batchs: 264.7135009765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 386): Loss/seq after 00000 batches: 209.17750549316406
INFO:root:# Valid (Epoch 386): Loss/seq after 00050 batches: 617.3485717773438
INFO:root:# Valid (Epoch 386): Loss/seq after 00100 batches: 623.4407958984375
INFO:root:# Valid (Epoch 386): Loss/seq after 00150 batches: 468.3884582519531
INFO:root:# Valid (Epoch 386): Loss/seq after 00200 batches: 438.3419494628906
INFO:root:Artifacts: Make stick videos for epoch 386
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_386_on_20220424_040314.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_386_index_1087_on_20220424_040314.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 387): Loss/seq after 00000 batchs: 360.4710693359375
INFO:root:Train (Epoch 387): Loss/seq after 00050 batchs: 334.81024169921875
INFO:root:Train (Epoch 387): Loss/seq after 00100 batchs: 327.88409423828125
INFO:root:Train (Epoch 387): Loss/seq after 00150 batchs: 315.84552001953125
INFO:root:Train (Epoch 387): Loss/seq after 00200 batchs: 347.9183349609375
INFO:root:Train (Epoch 387): Loss/seq after 00250 batchs: 368.07159423828125
INFO:root:Train (Epoch 387): Loss/seq after 00300 batchs: 390.0550842285156
INFO:root:Train (Epoch 387): Loss/seq after 00350 batchs: 378.3788146972656
INFO:root:Train (Epoch 387): Loss/seq after 00400 batchs: 373.9656982421875
INFO:root:Train (Epoch 387): Loss/seq after 00450 batchs: 392.2767639160156
INFO:root:Train (Epoch 387): Loss/seq after 00500 batchs: 380.66357421875
INFO:root:Train (Epoch 387): Loss/seq after 00550 batchs: 376.6784362792969
INFO:root:Train (Epoch 387): Loss/seq after 00600 batchs: 362.7897033691406
INFO:root:Train (Epoch 387): Loss/seq after 00650 batchs: 348.43475341796875
INFO:root:Train (Epoch 387): Loss/seq after 00700 batchs: 333.63616943359375
INFO:root:Train (Epoch 387): Loss/seq after 00750 batchs: 328.5899353027344
INFO:root:Train (Epoch 387): Loss/seq after 00800 batchs: 327.6564636230469
INFO:root:Train (Epoch 387): Loss/seq after 00850 batchs: 317.14727783203125
INFO:root:Train (Epoch 387): Loss/seq after 00900 batchs: 309.4576416015625
INFO:root:Train (Epoch 387): Loss/seq after 00950 batchs: 310.5820007324219
INFO:root:Train (Epoch 387): Loss/seq after 01000 batchs: 305.00579833984375
INFO:root:Train (Epoch 387): Loss/seq after 01050 batchs: 299.35809326171875
INFO:root:Train (Epoch 387): Loss/seq after 01100 batchs: 292.50567626953125
INFO:root:Train (Epoch 387): Loss/seq after 01150 batchs: 284.80255126953125
INFO:root:Train (Epoch 387): Loss/seq after 01200 batchs: 286.38934326171875
INFO:root:Train (Epoch 387): Loss/seq after 01250 batchs: 286.29229736328125
INFO:root:Train (Epoch 387): Loss/seq after 01300 batchs: 281.08349609375
INFO:root:Train (Epoch 387): Loss/seq after 01350 batchs: 274.655029296875
INFO:root:Train (Epoch 387): Loss/seq after 01400 batchs: 276.1138916015625
INFO:root:Train (Epoch 387): Loss/seq after 01450 batchs: 278.4349060058594
INFO:root:Train (Epoch 387): Loss/seq after 01500 batchs: 283.5690002441406
INFO:root:Train (Epoch 387): Loss/seq after 01550 batchs: 284.43438720703125
INFO:root:Train (Epoch 387): Loss/seq after 01600 batchs: 284.329345703125
INFO:root:Train (Epoch 387): Loss/seq after 01650 batchs: 283.75439453125
INFO:root:Train (Epoch 387): Loss/seq after 01700 batchs: 285.38494873046875
INFO:root:Train (Epoch 387): Loss/seq after 01750 batchs: 285.0537109375
INFO:root:Train (Epoch 387): Loss/seq after 01800 batchs: 284.595947265625
INFO:root:Train (Epoch 387): Loss/seq after 01850 batchs: 284.17169189453125
INFO:root:Train (Epoch 387): Loss/seq after 01900 batchs: 284.3766784667969
INFO:root:Train (Epoch 387): Loss/seq after 01950 batchs: 284.83209228515625
INFO:root:Train (Epoch 387): Loss/seq after 02000 batchs: 287.0534973144531
INFO:root:Train (Epoch 387): Loss/seq after 02050 batchs: 287.7159729003906
INFO:root:Train (Epoch 387): Loss/seq after 02100 batchs: 287.8357238769531
INFO:root:Train (Epoch 387): Loss/seq after 02150 batchs: 288.1802978515625
INFO:root:Train (Epoch 387): Loss/seq after 02200 batchs: 287.86090087890625
INFO:root:Train (Epoch 387): Loss/seq after 02250 batchs: 287.4033203125
INFO:root:Train (Epoch 387): Loss/seq after 02300 batchs: 285.7201843261719
INFO:root:Train (Epoch 387): Loss/seq after 02350 batchs: 284.3135070800781
INFO:root:Train (Epoch 387): Loss/seq after 02400 batchs: 283.9002990722656
INFO:root:Train (Epoch 387): Loss/seq after 02450 batchs: 281.8922424316406
INFO:root:Train (Epoch 387): Loss/seq after 02500 batchs: 277.2508239746094
INFO:root:Train (Epoch 387): Loss/seq after 02550 batchs: 273.218017578125
INFO:root:Train (Epoch 387): Loss/seq after 02600 batchs: 270.006591796875
INFO:root:Train (Epoch 387): Loss/seq after 02650 batchs: 267.1807556152344
INFO:root:Train (Epoch 387): Loss/seq after 02700 batchs: 265.3921813964844
INFO:root:Train (Epoch 387): Loss/seq after 02750 batchs: 262.4418640136719
INFO:root:Train (Epoch 387): Loss/seq after 02800 batchs: 260.72149658203125
INFO:root:Train (Epoch 387): Loss/seq after 02850 batchs: 260.4309997558594
INFO:root:Train (Epoch 387): Loss/seq after 02900 batchs: 260.4332580566406
INFO:root:Train (Epoch 387): Loss/seq after 02950 batchs: 261.51165771484375
INFO:root:Train (Epoch 387): Loss/seq after 03000 batchs: 264.235107421875
INFO:root:Train (Epoch 387): Loss/seq after 03050 batchs: 265.5091552734375
INFO:root:Train (Epoch 387): Loss/seq after 03100 batchs: 266.8907470703125
INFO:root:Train (Epoch 387): Loss/seq after 03150 batchs: 267.40203857421875
INFO:root:Train (Epoch 387): Loss/seq after 03200 batchs: 267.6567077636719
INFO:root:Train (Epoch 387): Loss/seq after 03250 batchs: 267.583740234375
INFO:root:Train (Epoch 387): Loss/seq after 03300 batchs: 267.4124450683594
INFO:root:Train (Epoch 387): Loss/seq after 03350 batchs: 266.4134826660156
INFO:root:Train (Epoch 387): Loss/seq after 03400 batchs: 264.87738037109375
INFO:root:Train (Epoch 387): Loss/seq after 03450 batchs: 263.8299255371094
INFO:root:Train (Epoch 387): Loss/seq after 03500 batchs: 264.4294738769531
INFO:root:Train (Epoch 387): Loss/seq after 03550 batchs: 263.5375671386719
INFO:root:Train (Epoch 387): Loss/seq after 03600 batchs: 265.66680908203125
INFO:root:Train (Epoch 387): Loss/seq after 03650 batchs: 264.7179260253906
INFO:root:Train (Epoch 387): Loss/seq after 03700 batchs: 265.9688415527344
INFO:root:Train (Epoch 387): Loss/seq after 03750 batchs: 268.76361083984375
INFO:root:Train (Epoch 387): Loss/seq after 03800 batchs: 269.1663818359375
INFO:root:Train (Epoch 387): Loss/seq after 03850 batchs: 268.8627014160156
INFO:root:Train (Epoch 387): Loss/seq after 03900 batchs: 269.5629577636719
INFO:root:Train (Epoch 387): Loss/seq after 03950 batchs: 270.73681640625
INFO:root:Train (Epoch 387): Loss/seq after 04000 batchs: 269.61187744140625
INFO:root:Train (Epoch 387): Loss/seq after 04050 batchs: 268.27850341796875
INFO:root:Train (Epoch 387): Loss/seq after 04100 batchs: 267.52301025390625
INFO:root:Train (Epoch 387): Loss/seq after 04150 batchs: 267.45758056640625
INFO:root:Train (Epoch 387): Loss/seq after 04200 batchs: 267.0696105957031
INFO:root:Train (Epoch 387): Loss/seq after 04250 batchs: 266.31243896484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 387): Loss/seq after 00000 batches: 219.2729034423828
INFO:root:# Valid (Epoch 387): Loss/seq after 00050 batches: 659.0690307617188
INFO:root:# Valid (Epoch 387): Loss/seq after 00100 batches: 648.1242065429688
INFO:root:# Valid (Epoch 387): Loss/seq after 00150 batches: 485.8044738769531
INFO:root:# Valid (Epoch 387): Loss/seq after 00200 batches: 450.0028991699219
INFO:root:Artifacts: Make stick videos for epoch 387
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_387_on_20220424_040803.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_387_index_788_on_20220424_040803.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 388): Loss/seq after 00000 batchs: 387.3751525878906
INFO:root:Train (Epoch 388): Loss/seq after 00050 batchs: 330.3035888671875
INFO:root:Train (Epoch 388): Loss/seq after 00100 batchs: 333.0909118652344
INFO:root:Train (Epoch 388): Loss/seq after 00150 batchs: 320.69970703125
INFO:root:Train (Epoch 388): Loss/seq after 00200 batchs: 368.2312927246094
INFO:root:Train (Epoch 388): Loss/seq after 00250 batchs: 394.39569091796875
INFO:root:Train (Epoch 388): Loss/seq after 00300 batchs: 412.2210388183594
INFO:root:Train (Epoch 388): Loss/seq after 00350 batchs: 397.6776123046875
INFO:root:Train (Epoch 388): Loss/seq after 00400 batchs: 396.139404296875
INFO:root:Train (Epoch 388): Loss/seq after 00450 batchs: 412.0860900878906
INFO:root:Train (Epoch 388): Loss/seq after 00500 batchs: 398.94354248046875
INFO:root:Train (Epoch 388): Loss/seq after 00550 batchs: 393.0904235839844
INFO:root:Train (Epoch 388): Loss/seq after 00600 batchs: 379.614990234375
INFO:root:Train (Epoch 388): Loss/seq after 00650 batchs: 364.6033630371094
INFO:root:Train (Epoch 388): Loss/seq after 00700 batchs: 349.4270324707031
INFO:root:Train (Epoch 388): Loss/seq after 00750 batchs: 343.86138916015625
INFO:root:Train (Epoch 388): Loss/seq after 00800 batchs: 342.8550109863281
INFO:root:Train (Epoch 388): Loss/seq after 00850 batchs: 331.6328125
INFO:root:Train (Epoch 388): Loss/seq after 00900 batchs: 322.8319396972656
INFO:root:Train (Epoch 388): Loss/seq after 00950 batchs: 323.2292785644531
INFO:root:Train (Epoch 388): Loss/seq after 01000 batchs: 318.089599609375
INFO:root:Train (Epoch 388): Loss/seq after 01050 batchs: 311.8626403808594
INFO:root:Train (Epoch 388): Loss/seq after 01100 batchs: 304.6072082519531
INFO:root:Train (Epoch 388): Loss/seq after 01150 batchs: 296.49530029296875
INFO:root:Train (Epoch 388): Loss/seq after 01200 batchs: 295.1133117675781
INFO:root:Train (Epoch 388): Loss/seq after 01250 batchs: 294.5224304199219
INFO:root:Train (Epoch 388): Loss/seq after 01300 batchs: 288.3895263671875
INFO:root:Train (Epoch 388): Loss/seq after 01350 batchs: 282.0414733886719
INFO:root:Train (Epoch 388): Loss/seq after 01400 batchs: 284.1844482421875
INFO:root:Train (Epoch 388): Loss/seq after 01450 batchs: 285.8354797363281
INFO:root:Train (Epoch 388): Loss/seq after 01500 batchs: 290.0346374511719
INFO:root:Train (Epoch 388): Loss/seq after 01550 batchs: 290.1943664550781
INFO:root:Train (Epoch 388): Loss/seq after 01600 batchs: 289.3816833496094
INFO:root:Train (Epoch 388): Loss/seq after 01650 batchs: 288.45269775390625
INFO:root:Train (Epoch 388): Loss/seq after 01700 batchs: 289.3031005859375
INFO:root:Train (Epoch 388): Loss/seq after 01750 batchs: 288.4143981933594
INFO:root:Train (Epoch 388): Loss/seq after 01800 batchs: 287.7044372558594
INFO:root:Train (Epoch 388): Loss/seq after 01850 batchs: 286.92584228515625
INFO:root:Train (Epoch 388): Loss/seq after 01900 batchs: 286.75933837890625
INFO:root:Train (Epoch 388): Loss/seq after 01950 batchs: 287.017333984375
INFO:root:Train (Epoch 388): Loss/seq after 02000 batchs: 289.1631164550781
INFO:root:Train (Epoch 388): Loss/seq after 02050 batchs: 289.7861328125
INFO:root:Train (Epoch 388): Loss/seq after 02100 batchs: 289.6218566894531
INFO:root:Train (Epoch 388): Loss/seq after 02150 batchs: 289.79827880859375
INFO:root:Train (Epoch 388): Loss/seq after 02200 batchs: 289.4305114746094
INFO:root:Train (Epoch 388): Loss/seq after 02250 batchs: 288.9206848144531
INFO:root:Train (Epoch 388): Loss/seq after 02300 batchs: 287.36163330078125
INFO:root:Train (Epoch 388): Loss/seq after 02350 batchs: 285.7224426269531
INFO:root:Train (Epoch 388): Loss/seq after 02400 batchs: 285.16241455078125
INFO:root:Train (Epoch 388): Loss/seq after 02450 batchs: 283.09576416015625
INFO:root:Train (Epoch 388): Loss/seq after 02500 batchs: 278.42840576171875
INFO:root:Train (Epoch 388): Loss/seq after 02550 batchs: 274.36181640625
INFO:root:Train (Epoch 388): Loss/seq after 02600 batchs: 271.1455078125
INFO:root:Train (Epoch 388): Loss/seq after 02650 batchs: 268.2662658691406
INFO:root:Train (Epoch 388): Loss/seq after 02700 batchs: 266.4661865234375
INFO:root:Train (Epoch 388): Loss/seq after 02750 batchs: 263.98236083984375
INFO:root:Train (Epoch 388): Loss/seq after 02800 batchs: 262.64691162109375
INFO:root:Train (Epoch 388): Loss/seq after 02850 batchs: 262.26751708984375
INFO:root:Train (Epoch 388): Loss/seq after 02900 batchs: 262.31365966796875
INFO:root:Train (Epoch 388): Loss/seq after 02950 batchs: 263.498291015625
INFO:root:Train (Epoch 388): Loss/seq after 03000 batchs: 266.4327392578125
INFO:root:Train (Epoch 388): Loss/seq after 03050 batchs: 267.8463439941406
INFO:root:Train (Epoch 388): Loss/seq after 03100 batchs: 268.86663818359375
INFO:root:Train (Epoch 388): Loss/seq after 03150 batchs: 268.6205139160156
INFO:root:Train (Epoch 388): Loss/seq after 03200 batchs: 269.14056396484375
INFO:root:Train (Epoch 388): Loss/seq after 03250 batchs: 268.9752197265625
INFO:root:Train (Epoch 388): Loss/seq after 03300 batchs: 268.35162353515625
INFO:root:Train (Epoch 388): Loss/seq after 03350 batchs: 266.7881164550781
INFO:root:Train (Epoch 388): Loss/seq after 03400 batchs: 265.2065124511719
INFO:root:Train (Epoch 388): Loss/seq after 03450 batchs: 264.0146179199219
INFO:root:Train (Epoch 388): Loss/seq after 03500 batchs: 264.68707275390625
INFO:root:Train (Epoch 388): Loss/seq after 03550 batchs: 263.8395080566406
INFO:root:Train (Epoch 388): Loss/seq after 03600 batchs: 265.9212951660156
INFO:root:Train (Epoch 388): Loss/seq after 03650 batchs: 264.9161376953125
INFO:root:Train (Epoch 388): Loss/seq after 03700 batchs: 266.0400390625
INFO:root:Train (Epoch 388): Loss/seq after 03750 batchs: 268.6310729980469
INFO:root:Train (Epoch 388): Loss/seq after 03800 batchs: 268.9958190917969
INFO:root:Train (Epoch 388): Loss/seq after 03850 batchs: 268.6120300292969
INFO:root:Train (Epoch 388): Loss/seq after 03900 batchs: 269.4053955078125
INFO:root:Train (Epoch 388): Loss/seq after 03950 batchs: 271.9223937988281
INFO:root:Train (Epoch 388): Loss/seq after 04000 batchs: 270.79339599609375
INFO:root:Train (Epoch 388): Loss/seq after 04050 batchs: 269.4606018066406
INFO:root:Train (Epoch 388): Loss/seq after 04100 batchs: 268.5763244628906
INFO:root:Train (Epoch 388): Loss/seq after 04150 batchs: 268.3446960449219
INFO:root:Train (Epoch 388): Loss/seq after 04200 batchs: 267.9739074707031
INFO:root:Train (Epoch 388): Loss/seq after 04250 batchs: 267.1589660644531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 388): Loss/seq after 00000 batches: 231.2470703125
INFO:root:# Valid (Epoch 388): Loss/seq after 00050 batches: 619.1688232421875
INFO:root:# Valid (Epoch 388): Loss/seq after 00100 batches: 609.019287109375
INFO:root:# Valid (Epoch 388): Loss/seq after 00150 batches: 456.7392272949219
INFO:root:# Valid (Epoch 388): Loss/seq after 00200 batches: 428.19482421875
INFO:root:Artifacts: Make stick videos for epoch 388
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_388_on_20220424_041302.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_388_index_1709_on_20220424_041302.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 389): Loss/seq after 00000 batchs: 405.4007263183594
INFO:root:Train (Epoch 389): Loss/seq after 00050 batchs: 338.77008056640625
INFO:root:Train (Epoch 389): Loss/seq after 00100 batchs: 343.0609130859375
INFO:root:Train (Epoch 389): Loss/seq after 00150 batchs: 325.5865478515625
INFO:root:Train (Epoch 389): Loss/seq after 00200 batchs: 366.43719482421875
INFO:root:Train (Epoch 389): Loss/seq after 00250 batchs: 376.4584655761719
INFO:root:Train (Epoch 389): Loss/seq after 00300 batchs: 397.0534362792969
INFO:root:Train (Epoch 389): Loss/seq after 00350 batchs: 383.5194396972656
INFO:root:Train (Epoch 389): Loss/seq after 00400 batchs: 376.0238342285156
INFO:root:Train (Epoch 389): Loss/seq after 00450 batchs: 393.62017822265625
INFO:root:Train (Epoch 389): Loss/seq after 00500 batchs: 382.9371337890625
INFO:root:Train (Epoch 389): Loss/seq after 00550 batchs: 378.5323791503906
INFO:root:Train (Epoch 389): Loss/seq after 00600 batchs: 364.25897216796875
INFO:root:Train (Epoch 389): Loss/seq after 00650 batchs: 351.5427551269531
INFO:root:Train (Epoch 389): Loss/seq after 00700 batchs: 337.0434875488281
INFO:root:Train (Epoch 389): Loss/seq after 00750 batchs: 331.1975402832031
INFO:root:Train (Epoch 389): Loss/seq after 00800 batchs: 330.1493225097656
INFO:root:Train (Epoch 389): Loss/seq after 00850 batchs: 319.4204406738281
INFO:root:Train (Epoch 389): Loss/seq after 00900 batchs: 311.49859619140625
INFO:root:Train (Epoch 389): Loss/seq after 00950 batchs: 311.4011535644531
INFO:root:Train (Epoch 389): Loss/seq after 01000 batchs: 306.07464599609375
INFO:root:Train (Epoch 389): Loss/seq after 01050 batchs: 299.6642150878906
INFO:root:Train (Epoch 389): Loss/seq after 01100 batchs: 292.14752197265625
INFO:root:Train (Epoch 389): Loss/seq after 01150 batchs: 284.35870361328125
INFO:root:Train (Epoch 389): Loss/seq after 01200 batchs: 282.5044860839844
INFO:root:Train (Epoch 389): Loss/seq after 01250 batchs: 281.73443603515625
INFO:root:Train (Epoch 389): Loss/seq after 01300 batchs: 275.7757873535156
INFO:root:Train (Epoch 389): Loss/seq after 01350 batchs: 269.84771728515625
INFO:root:Train (Epoch 389): Loss/seq after 01400 batchs: 271.0650329589844
INFO:root:Train (Epoch 389): Loss/seq after 01450 batchs: 272.61492919921875
INFO:root:Train (Epoch 389): Loss/seq after 01500 batchs: 277.7918395996094
INFO:root:Train (Epoch 389): Loss/seq after 01550 batchs: 278.6530456542969
INFO:root:Train (Epoch 389): Loss/seq after 01600 batchs: 278.2691345214844
INFO:root:Train (Epoch 389): Loss/seq after 01650 batchs: 277.6107482910156
INFO:root:Train (Epoch 389): Loss/seq after 01700 batchs: 278.49822998046875
INFO:root:Train (Epoch 389): Loss/seq after 01750 batchs: 277.7633361816406
INFO:root:Train (Epoch 389): Loss/seq after 01800 batchs: 277.2271728515625
INFO:root:Train (Epoch 389): Loss/seq after 01850 batchs: 276.855224609375
INFO:root:Train (Epoch 389): Loss/seq after 01900 batchs: 276.81207275390625
INFO:root:Train (Epoch 389): Loss/seq after 01950 batchs: 277.3443298339844
INFO:root:Train (Epoch 389): Loss/seq after 02000 batchs: 279.73431396484375
INFO:root:Train (Epoch 389): Loss/seq after 02050 batchs: 280.661376953125
INFO:root:Train (Epoch 389): Loss/seq after 02100 batchs: 280.67132568359375
INFO:root:Train (Epoch 389): Loss/seq after 02150 batchs: 281.07421875
INFO:root:Train (Epoch 389): Loss/seq after 02200 batchs: 280.9407043457031
INFO:root:Train (Epoch 389): Loss/seq after 02250 batchs: 280.4381103515625
INFO:root:Train (Epoch 389): Loss/seq after 02300 batchs: 278.8017578125
INFO:root:Train (Epoch 389): Loss/seq after 02350 batchs: 277.4624328613281
INFO:root:Train (Epoch 389): Loss/seq after 02400 batchs: 277.0912780761719
INFO:root:Train (Epoch 389): Loss/seq after 02450 batchs: 275.1517333984375
INFO:root:Train (Epoch 389): Loss/seq after 02500 batchs: 270.66748046875
INFO:root:Train (Epoch 389): Loss/seq after 02550 batchs: 266.8136291503906
INFO:root:Train (Epoch 389): Loss/seq after 02600 batchs: 263.63427734375
INFO:root:Train (Epoch 389): Loss/seq after 02650 batchs: 260.7955627441406
INFO:root:Train (Epoch 389): Loss/seq after 02700 batchs: 258.9582824707031
INFO:root:Train (Epoch 389): Loss/seq after 02750 batchs: 256.374755859375
INFO:root:Train (Epoch 389): Loss/seq after 02800 batchs: 254.8923797607422
INFO:root:Train (Epoch 389): Loss/seq after 02850 batchs: 254.58457946777344
INFO:root:Train (Epoch 389): Loss/seq after 02900 batchs: 254.80630493164062
INFO:root:Train (Epoch 389): Loss/seq after 02950 batchs: 255.92955017089844
INFO:root:Train (Epoch 389): Loss/seq after 03000 batchs: 258.6094970703125
INFO:root:Train (Epoch 389): Loss/seq after 03050 batchs: 259.828369140625
INFO:root:Train (Epoch 389): Loss/seq after 03100 batchs: 261.120361328125
INFO:root:Train (Epoch 389): Loss/seq after 03150 batchs: 260.5133056640625
INFO:root:Train (Epoch 389): Loss/seq after 03200 batchs: 260.42974853515625
INFO:root:Train (Epoch 389): Loss/seq after 03250 batchs: 260.618408203125
INFO:root:Train (Epoch 389): Loss/seq after 03300 batchs: 259.954345703125
INFO:root:Train (Epoch 389): Loss/seq after 03350 batchs: 258.6523742675781
INFO:root:Train (Epoch 389): Loss/seq after 03400 batchs: 257.2406005859375
INFO:root:Train (Epoch 389): Loss/seq after 03450 batchs: 256.1341552734375
INFO:root:Train (Epoch 389): Loss/seq after 03500 batchs: 257.0785217285156
INFO:root:Train (Epoch 389): Loss/seq after 03550 batchs: 256.36553955078125
INFO:root:Train (Epoch 389): Loss/seq after 03600 batchs: 258.5191650390625
INFO:root:Train (Epoch 389): Loss/seq after 03650 batchs: 257.87493896484375
INFO:root:Train (Epoch 389): Loss/seq after 03700 batchs: 259.4025573730469
INFO:root:Train (Epoch 389): Loss/seq after 03750 batchs: 262.4949645996094
INFO:root:Train (Epoch 389): Loss/seq after 03800 batchs: 262.95245361328125
INFO:root:Train (Epoch 389): Loss/seq after 03850 batchs: 262.6495056152344
INFO:root:Train (Epoch 389): Loss/seq after 03900 batchs: 263.6277160644531
INFO:root:Train (Epoch 389): Loss/seq after 03950 batchs: 266.748291015625
INFO:root:Train (Epoch 389): Loss/seq after 04000 batchs: 265.7337646484375
INFO:root:Train (Epoch 389): Loss/seq after 04050 batchs: 264.4697570800781
INFO:root:Train (Epoch 389): Loss/seq after 04100 batchs: 263.6521911621094
INFO:root:Train (Epoch 389): Loss/seq after 04150 batchs: 263.52069091796875
INFO:root:Train (Epoch 389): Loss/seq after 04200 batchs: 263.1410827636719
INFO:root:Train (Epoch 389): Loss/seq after 04250 batchs: 262.4103698730469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 389): Loss/seq after 00000 batches: 231.9311981201172
INFO:root:# Valid (Epoch 389): Loss/seq after 00050 batches: 645.061279296875
INFO:root:# Valid (Epoch 389): Loss/seq after 00100 batches: 627.5335693359375
INFO:root:# Valid (Epoch 389): Loss/seq after 00150 batches: 471.0304260253906
INFO:root:# Valid (Epoch 389): Loss/seq after 00200 batches: 440.84716796875
INFO:root:Artifacts: Make stick videos for epoch 389
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_389_on_20220424_041754.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_389_index_283_on_20220424_041754.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 390): Loss/seq after 00000 batchs: 407.1875
INFO:root:Train (Epoch 390): Loss/seq after 00050 batchs: 385.8246154785156
INFO:root:Train (Epoch 390): Loss/seq after 00100 batchs: 390.0181579589844
INFO:root:Train (Epoch 390): Loss/seq after 00150 batchs: 364.187255859375
INFO:root:Train (Epoch 390): Loss/seq after 00200 batchs: 410.19091796875
INFO:root:Train (Epoch 390): Loss/seq after 00250 batchs: 405.8977355957031
INFO:root:Train (Epoch 390): Loss/seq after 00300 batchs: 419.3343811035156
INFO:root:Train (Epoch 390): Loss/seq after 00350 batchs: 400.5285339355469
INFO:root:Train (Epoch 390): Loss/seq after 00400 batchs: 389.84051513671875
INFO:root:Train (Epoch 390): Loss/seq after 00450 batchs: 405.64971923828125
INFO:root:Train (Epoch 390): Loss/seq after 00500 batchs: 391.21234130859375
INFO:root:Train (Epoch 390): Loss/seq after 00550 batchs: 385.85089111328125
INFO:root:Train (Epoch 390): Loss/seq after 00600 batchs: 371.6428527832031
INFO:root:Train (Epoch 390): Loss/seq after 00650 batchs: 357.7982177734375
INFO:root:Train (Epoch 390): Loss/seq after 00700 batchs: 344.3243103027344
INFO:root:Train (Epoch 390): Loss/seq after 00750 batchs: 337.60845947265625
INFO:root:Train (Epoch 390): Loss/seq after 00800 batchs: 337.0241394042969
INFO:root:Train (Epoch 390): Loss/seq after 00850 batchs: 325.66046142578125
INFO:root:Train (Epoch 390): Loss/seq after 00900 batchs: 317.5006103515625
INFO:root:Train (Epoch 390): Loss/seq after 00950 batchs: 317.7149963378906
INFO:root:Train (Epoch 390): Loss/seq after 01000 batchs: 311.3944396972656
INFO:root:Train (Epoch 390): Loss/seq after 01050 batchs: 305.2274169921875
INFO:root:Train (Epoch 390): Loss/seq after 01100 batchs: 298.06805419921875
INFO:root:Train (Epoch 390): Loss/seq after 01150 batchs: 290.1399230957031
INFO:root:Train (Epoch 390): Loss/seq after 01200 batchs: 289.1700134277344
INFO:root:Train (Epoch 390): Loss/seq after 01250 batchs: 288.6073303222656
INFO:root:Train (Epoch 390): Loss/seq after 01300 batchs: 283.1308288574219
INFO:root:Train (Epoch 390): Loss/seq after 01350 batchs: 277.1101989746094
INFO:root:Train (Epoch 390): Loss/seq after 01400 batchs: 277.9591064453125
INFO:root:Train (Epoch 390): Loss/seq after 01450 batchs: 279.1515197753906
INFO:root:Train (Epoch 390): Loss/seq after 01500 batchs: 283.66302490234375
INFO:root:Train (Epoch 390): Loss/seq after 01550 batchs: 284.1408386230469
INFO:root:Train (Epoch 390): Loss/seq after 01600 batchs: 283.1897888183594
INFO:root:Train (Epoch 390): Loss/seq after 01650 batchs: 282.1819152832031
INFO:root:Train (Epoch 390): Loss/seq after 01700 batchs: 282.6938781738281
INFO:root:Train (Epoch 390): Loss/seq after 01750 batchs: 281.750732421875
INFO:root:Train (Epoch 390): Loss/seq after 01800 batchs: 281.2769775390625
INFO:root:Train (Epoch 390): Loss/seq after 01850 batchs: 280.7503967285156
INFO:root:Train (Epoch 390): Loss/seq after 01900 batchs: 280.57183837890625
INFO:root:Train (Epoch 390): Loss/seq after 01950 batchs: 281.024658203125
INFO:root:Train (Epoch 390): Loss/seq after 02000 batchs: 283.27020263671875
INFO:root:Train (Epoch 390): Loss/seq after 02050 batchs: 284.1670227050781
INFO:root:Train (Epoch 390): Loss/seq after 02100 batchs: 284.3697509765625
INFO:root:Train (Epoch 390): Loss/seq after 02150 batchs: 284.771240234375
INFO:root:Train (Epoch 390): Loss/seq after 02200 batchs: 284.62615966796875
INFO:root:Train (Epoch 390): Loss/seq after 02250 batchs: 283.99847412109375
INFO:root:Train (Epoch 390): Loss/seq after 02300 batchs: 281.8807678222656
INFO:root:Train (Epoch 390): Loss/seq after 02350 batchs: 280.3482971191406
INFO:root:Train (Epoch 390): Loss/seq after 02400 batchs: 279.9472961425781
INFO:root:Train (Epoch 390): Loss/seq after 02450 batchs: 277.832275390625
INFO:root:Train (Epoch 390): Loss/seq after 02500 batchs: 273.22698974609375
INFO:root:Train (Epoch 390): Loss/seq after 02550 batchs: 269.2838134765625
INFO:root:Train (Epoch 390): Loss/seq after 02600 batchs: 266.1184997558594
INFO:root:Train (Epoch 390): Loss/seq after 02650 batchs: 263.18218994140625
INFO:root:Train (Epoch 390): Loss/seq after 02700 batchs: 261.28326416015625
INFO:root:Train (Epoch 390): Loss/seq after 02750 batchs: 258.4241943359375
INFO:root:Train (Epoch 390): Loss/seq after 02800 batchs: 257.0260009765625
INFO:root:Train (Epoch 390): Loss/seq after 02850 batchs: 256.8130187988281
INFO:root:Train (Epoch 390): Loss/seq after 02900 batchs: 256.7592468261719
INFO:root:Train (Epoch 390): Loss/seq after 02950 batchs: 257.737548828125
INFO:root:Train (Epoch 390): Loss/seq after 03000 batchs: 260.224853515625
INFO:root:Train (Epoch 390): Loss/seq after 03050 batchs: 261.3340148925781
INFO:root:Train (Epoch 390): Loss/seq after 03100 batchs: 262.1728210449219
INFO:root:Train (Epoch 390): Loss/seq after 03150 batchs: 261.4854736328125
INFO:root:Train (Epoch 390): Loss/seq after 03200 batchs: 261.3485412597656
INFO:root:Train (Epoch 390): Loss/seq after 03250 batchs: 261.2773742675781
INFO:root:Train (Epoch 390): Loss/seq after 03300 batchs: 260.8008728027344
INFO:root:Train (Epoch 390): Loss/seq after 03350 batchs: 259.4101257324219
INFO:root:Train (Epoch 390): Loss/seq after 03400 batchs: 257.9238586425781
INFO:root:Train (Epoch 390): Loss/seq after 03450 batchs: 256.79046630859375
INFO:root:Train (Epoch 390): Loss/seq after 03500 batchs: 257.6139221191406
INFO:root:Train (Epoch 390): Loss/seq after 03550 batchs: 256.900390625
INFO:root:Train (Epoch 390): Loss/seq after 03600 batchs: 258.84429931640625
INFO:root:Train (Epoch 390): Loss/seq after 03650 batchs: 257.8846435546875
INFO:root:Train (Epoch 390): Loss/seq after 03700 batchs: 258.9148254394531
INFO:root:Train (Epoch 390): Loss/seq after 03750 batchs: 261.5853271484375
INFO:root:Train (Epoch 390): Loss/seq after 03800 batchs: 261.9494934082031
INFO:root:Train (Epoch 390): Loss/seq after 03850 batchs: 261.7154235839844
INFO:root:Train (Epoch 390): Loss/seq after 03900 batchs: 262.5823059082031
INFO:root:Train (Epoch 390): Loss/seq after 03950 batchs: 264.6667785644531
INFO:root:Train (Epoch 390): Loss/seq after 04000 batchs: 263.64532470703125
INFO:root:Train (Epoch 390): Loss/seq after 04050 batchs: 262.3945617675781
INFO:root:Train (Epoch 390): Loss/seq after 04100 batchs: 261.5888366699219
INFO:root:Train (Epoch 390): Loss/seq after 04150 batchs: 261.4540710449219
INFO:root:Train (Epoch 390): Loss/seq after 04200 batchs: 261.15447998046875
INFO:root:Train (Epoch 390): Loss/seq after 04250 batchs: 260.49127197265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 390): Loss/seq after 00000 batches: 251.6326904296875
INFO:root:# Valid (Epoch 390): Loss/seq after 00050 batches: 646.3388061523438
INFO:root:# Valid (Epoch 390): Loss/seq after 00100 batches: 651.3765869140625
INFO:root:# Valid (Epoch 390): Loss/seq after 00150 batches: 488.8745422363281
INFO:root:# Valid (Epoch 390): Loss/seq after 00200 batches: 452.93609619140625
INFO:root:Artifacts: Make stick videos for epoch 390
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_390_on_20220424_042241.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_390_index_232_on_20220424_042241.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 391): Loss/seq after 00000 batchs: 317.2052917480469
INFO:root:Train (Epoch 391): Loss/seq after 00050 batchs: 349.74981689453125
INFO:root:Train (Epoch 391): Loss/seq after 00100 batchs: 372.9111633300781
INFO:root:Train (Epoch 391): Loss/seq after 00150 batchs: 349.3226318359375
INFO:root:Train (Epoch 391): Loss/seq after 00200 batchs: 387.0918884277344
INFO:root:Train (Epoch 391): Loss/seq after 00250 batchs: 392.76776123046875
INFO:root:Train (Epoch 391): Loss/seq after 00300 batchs: 407.3771057128906
INFO:root:Train (Epoch 391): Loss/seq after 00350 batchs: 390.69818115234375
INFO:root:Train (Epoch 391): Loss/seq after 00400 batchs: 385.1742248535156
INFO:root:Train (Epoch 391): Loss/seq after 00450 batchs: 401.5840759277344
INFO:root:Train (Epoch 391): Loss/seq after 00500 batchs: 390.0368957519531
INFO:root:Train (Epoch 391): Loss/seq after 00550 batchs: 386.1913146972656
INFO:root:Train (Epoch 391): Loss/seq after 00600 batchs: 373.1144714355469
INFO:root:Train (Epoch 391): Loss/seq after 00650 batchs: 356.6773376464844
INFO:root:Train (Epoch 391): Loss/seq after 00700 batchs: 341.1648254394531
INFO:root:Train (Epoch 391): Loss/seq after 00750 batchs: 335.8800964355469
INFO:root:Train (Epoch 391): Loss/seq after 00800 batchs: 335.307373046875
INFO:root:Train (Epoch 391): Loss/seq after 00850 batchs: 324.4384460449219
INFO:root:Train (Epoch 391): Loss/seq after 00900 batchs: 316.16864013671875
INFO:root:Train (Epoch 391): Loss/seq after 00950 batchs: 315.67144775390625
INFO:root:Train (Epoch 391): Loss/seq after 01000 batchs: 309.8172302246094
INFO:root:Train (Epoch 391): Loss/seq after 01050 batchs: 303.2493591308594
INFO:root:Train (Epoch 391): Loss/seq after 01100 batchs: 295.6703186035156
INFO:root:Train (Epoch 391): Loss/seq after 01150 batchs: 287.72613525390625
INFO:root:Train (Epoch 391): Loss/seq after 01200 batchs: 286.05194091796875
INFO:root:Train (Epoch 391): Loss/seq after 01250 batchs: 285.5517272949219
INFO:root:Train (Epoch 391): Loss/seq after 01300 batchs: 280.0614013671875
INFO:root:Train (Epoch 391): Loss/seq after 01350 batchs: 274.5695495605469
INFO:root:Train (Epoch 391): Loss/seq after 01400 batchs: 277.8377380371094
INFO:root:Train (Epoch 391): Loss/seq after 01450 batchs: 279.3323974609375
INFO:root:Train (Epoch 391): Loss/seq after 01500 batchs: 285.8361511230469
INFO:root:Train (Epoch 391): Loss/seq after 01550 batchs: 287.3093566894531
INFO:root:Train (Epoch 391): Loss/seq after 01600 batchs: 286.6449279785156
INFO:root:Train (Epoch 391): Loss/seq after 01650 batchs: 285.6964416503906
INFO:root:Train (Epoch 391): Loss/seq after 01700 batchs: 286.25543212890625
INFO:root:Train (Epoch 391): Loss/seq after 01750 batchs: 285.1892395019531
INFO:root:Train (Epoch 391): Loss/seq after 01800 batchs: 284.4306335449219
INFO:root:Train (Epoch 391): Loss/seq after 01850 batchs: 283.6556396484375
INFO:root:Train (Epoch 391): Loss/seq after 01900 batchs: 283.5287780761719
INFO:root:Train (Epoch 391): Loss/seq after 01950 batchs: 283.7274475097656
INFO:root:Train (Epoch 391): Loss/seq after 02000 batchs: 285.8808898925781
INFO:root:Train (Epoch 391): Loss/seq after 02050 batchs: 286.6143798828125
INFO:root:Train (Epoch 391): Loss/seq after 02100 batchs: 286.72357177734375
INFO:root:Train (Epoch 391): Loss/seq after 02150 batchs: 287.0970458984375
INFO:root:Train (Epoch 391): Loss/seq after 02200 batchs: 286.8876037597656
INFO:root:Train (Epoch 391): Loss/seq after 02250 batchs: 286.43798828125
INFO:root:Train (Epoch 391): Loss/seq after 02300 batchs: 284.859130859375
INFO:root:Train (Epoch 391): Loss/seq after 02350 batchs: 283.28082275390625
INFO:root:Train (Epoch 391): Loss/seq after 02400 batchs: 282.6641845703125
INFO:root:Train (Epoch 391): Loss/seq after 02450 batchs: 280.5876159667969
INFO:root:Train (Epoch 391): Loss/seq after 02500 batchs: 276.00518798828125
INFO:root:Train (Epoch 391): Loss/seq after 02550 batchs: 272.04193115234375
INFO:root:Train (Epoch 391): Loss/seq after 02600 batchs: 268.7335510253906
INFO:root:Train (Epoch 391): Loss/seq after 02650 batchs: 265.8012390136719
INFO:root:Train (Epoch 391): Loss/seq after 02700 batchs: 263.92779541015625
INFO:root:Train (Epoch 391): Loss/seq after 02750 batchs: 261.0853271484375
INFO:root:Train (Epoch 391): Loss/seq after 02800 batchs: 259.9279479980469
INFO:root:Train (Epoch 391): Loss/seq after 02850 batchs: 259.7091064453125
INFO:root:Train (Epoch 391): Loss/seq after 02900 batchs: 259.73358154296875
INFO:root:Train (Epoch 391): Loss/seq after 02950 batchs: 260.7838439941406
INFO:root:Train (Epoch 391): Loss/seq after 03000 batchs: 263.5347900390625
INFO:root:Train (Epoch 391): Loss/seq after 03050 batchs: 264.96197509765625
INFO:root:Train (Epoch 391): Loss/seq after 03100 batchs: 265.907470703125
INFO:root:Train (Epoch 391): Loss/seq after 03150 batchs: 265.4783630371094
INFO:root:Train (Epoch 391): Loss/seq after 03200 batchs: 265.5896911621094
INFO:root:Train (Epoch 391): Loss/seq after 03250 batchs: 265.11944580078125
INFO:root:Train (Epoch 391): Loss/seq after 03300 batchs: 264.4393310546875
INFO:root:Train (Epoch 391): Loss/seq after 03350 batchs: 263.07293701171875
INFO:root:Train (Epoch 391): Loss/seq after 03400 batchs: 261.51800537109375
INFO:root:Train (Epoch 391): Loss/seq after 03450 batchs: 260.4294738769531
INFO:root:Train (Epoch 391): Loss/seq after 03500 batchs: 261.4583435058594
INFO:root:Train (Epoch 391): Loss/seq after 03550 batchs: 260.7148742675781
INFO:root:Train (Epoch 391): Loss/seq after 03600 batchs: 262.96697998046875
INFO:root:Train (Epoch 391): Loss/seq after 03650 batchs: 262.1424560546875
INFO:root:Train (Epoch 391): Loss/seq after 03700 batchs: 263.7838439941406
INFO:root:Train (Epoch 391): Loss/seq after 03750 batchs: 266.751953125
INFO:root:Train (Epoch 391): Loss/seq after 03800 batchs: 267.1625671386719
INFO:root:Train (Epoch 391): Loss/seq after 03850 batchs: 267.1739501953125
INFO:root:Train (Epoch 391): Loss/seq after 03900 batchs: 268.0161437988281
INFO:root:Train (Epoch 391): Loss/seq after 03950 batchs: 269.8775634765625
INFO:root:Train (Epoch 391): Loss/seq after 04000 batchs: 268.7861022949219
INFO:root:Train (Epoch 391): Loss/seq after 04050 batchs: 267.4922180175781
INFO:root:Train (Epoch 391): Loss/seq after 04100 batchs: 266.71209716796875
INFO:root:Train (Epoch 391): Loss/seq after 04150 batchs: 266.4879455566406
INFO:root:Train (Epoch 391): Loss/seq after 04200 batchs: 266.06500244140625
INFO:root:Train (Epoch 391): Loss/seq after 04250 batchs: 265.2961120605469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 391): Loss/seq after 00000 batches: 210.8728790283203
INFO:root:# Valid (Epoch 391): Loss/seq after 00050 batches: 669.4968872070312
INFO:root:# Valid (Epoch 391): Loss/seq after 00100 batches: 637.6385498046875
INFO:root:# Valid (Epoch 391): Loss/seq after 00150 batches: 475.51385498046875
INFO:root:# Valid (Epoch 391): Loss/seq after 00200 batches: 441.1108703613281
INFO:root:Artifacts: Make stick videos for epoch 391
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_391_on_20220424_042728.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_391_index_330_on_20220424_042728.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 392): Loss/seq after 00000 batchs: 361.86822509765625
INFO:root:Train (Epoch 392): Loss/seq after 00050 batchs: 341.0982666015625
INFO:root:Train (Epoch 392): Loss/seq after 00100 batchs: 362.0820617675781
INFO:root:Train (Epoch 392): Loss/seq after 00150 batchs: 337.958984375
INFO:root:Train (Epoch 392): Loss/seq after 00200 batchs: 384.04852294921875
INFO:root:Train (Epoch 392): Loss/seq after 00250 batchs: 402.498291015625
INFO:root:Train (Epoch 392): Loss/seq after 00300 batchs: 421.958984375
INFO:root:Train (Epoch 392): Loss/seq after 00350 batchs: 404.0760192871094
INFO:root:Train (Epoch 392): Loss/seq after 00400 batchs: 393.0759582519531
INFO:root:Train (Epoch 392): Loss/seq after 00450 batchs: 407.7487487792969
INFO:root:Train (Epoch 392): Loss/seq after 00500 batchs: 395.9341735839844
INFO:root:Train (Epoch 392): Loss/seq after 00550 batchs: 390.2616271972656
INFO:root:Train (Epoch 392): Loss/seq after 00600 batchs: 375.250732421875
INFO:root:Train (Epoch 392): Loss/seq after 00650 batchs: 361.5698547363281
INFO:root:Train (Epoch 392): Loss/seq after 00700 batchs: 347.2934875488281
INFO:root:Train (Epoch 392): Loss/seq after 00750 batchs: 341.4305419921875
INFO:root:Train (Epoch 392): Loss/seq after 00800 batchs: 340.563232421875
INFO:root:Train (Epoch 392): Loss/seq after 00850 batchs: 329.0953369140625
INFO:root:Train (Epoch 392): Loss/seq after 00900 batchs: 320.3623046875
INFO:root:Train (Epoch 392): Loss/seq after 00950 batchs: 321.12646484375
INFO:root:Train (Epoch 392): Loss/seq after 01000 batchs: 315.81170654296875
INFO:root:Train (Epoch 392): Loss/seq after 01050 batchs: 310.0877990722656
INFO:root:Train (Epoch 392): Loss/seq after 01100 batchs: 302.7980651855469
INFO:root:Train (Epoch 392): Loss/seq after 01150 batchs: 294.8175354003906
INFO:root:Train (Epoch 392): Loss/seq after 01200 batchs: 294.539306640625
INFO:root:Train (Epoch 392): Loss/seq after 01250 batchs: 293.6541748046875
INFO:root:Train (Epoch 392): Loss/seq after 01300 batchs: 287.6138610839844
INFO:root:Train (Epoch 392): Loss/seq after 01350 batchs: 281.60479736328125
INFO:root:Train (Epoch 392): Loss/seq after 01400 batchs: 282.31951904296875
INFO:root:Train (Epoch 392): Loss/seq after 01450 batchs: 283.7437438964844
INFO:root:Train (Epoch 392): Loss/seq after 01500 batchs: 288.4951477050781
INFO:root:Train (Epoch 392): Loss/seq after 01550 batchs: 288.50201416015625
INFO:root:Train (Epoch 392): Loss/seq after 01600 batchs: 287.456298828125
INFO:root:Train (Epoch 392): Loss/seq after 01650 batchs: 286.2076416015625
INFO:root:Train (Epoch 392): Loss/seq after 01700 batchs: 286.8548278808594
INFO:root:Train (Epoch 392): Loss/seq after 01750 batchs: 285.96893310546875
INFO:root:Train (Epoch 392): Loss/seq after 01800 batchs: 284.9944152832031
INFO:root:Train (Epoch 392): Loss/seq after 01850 batchs: 284.1932067871094
INFO:root:Train (Epoch 392): Loss/seq after 01900 batchs: 284.0091857910156
INFO:root:Train (Epoch 392): Loss/seq after 01950 batchs: 284.1667785644531
INFO:root:Train (Epoch 392): Loss/seq after 02000 batchs: 286.2458801269531
INFO:root:Train (Epoch 392): Loss/seq after 02050 batchs: 286.95947265625
INFO:root:Train (Epoch 392): Loss/seq after 02100 batchs: 287.0641174316406
INFO:root:Train (Epoch 392): Loss/seq after 02150 batchs: 287.3476257324219
INFO:root:Train (Epoch 392): Loss/seq after 02200 batchs: 287.0874938964844
INFO:root:Train (Epoch 392): Loss/seq after 02250 batchs: 286.60052490234375
INFO:root:Train (Epoch 392): Loss/seq after 02300 batchs: 284.805419921875
INFO:root:Train (Epoch 392): Loss/seq after 02350 batchs: 283.2835998535156
INFO:root:Train (Epoch 392): Loss/seq after 02400 batchs: 282.8511047363281
INFO:root:Train (Epoch 392): Loss/seq after 02450 batchs: 280.8220520019531
INFO:root:Train (Epoch 392): Loss/seq after 02500 batchs: 276.1498107910156
INFO:root:Train (Epoch 392): Loss/seq after 02550 batchs: 272.1007080078125
INFO:root:Train (Epoch 392): Loss/seq after 02600 batchs: 268.7491455078125
INFO:root:Train (Epoch 392): Loss/seq after 02650 batchs: 265.863525390625
INFO:root:Train (Epoch 392): Loss/seq after 02700 batchs: 264.0623779296875
INFO:root:Train (Epoch 392): Loss/seq after 02750 batchs: 261.1850280761719
INFO:root:Train (Epoch 392): Loss/seq after 02800 batchs: 259.8113708496094
INFO:root:Train (Epoch 392): Loss/seq after 02850 batchs: 259.41357421875
INFO:root:Train (Epoch 392): Loss/seq after 02900 batchs: 259.255126953125
INFO:root:Train (Epoch 392): Loss/seq after 02950 batchs: 260.3125915527344
INFO:root:Train (Epoch 392): Loss/seq after 03000 batchs: 263.08905029296875
INFO:root:Train (Epoch 392): Loss/seq after 03050 batchs: 264.11639404296875
INFO:root:Train (Epoch 392): Loss/seq after 03100 batchs: 265.5293273925781
INFO:root:Train (Epoch 392): Loss/seq after 03150 batchs: 265.1481628417969
INFO:root:Train (Epoch 392): Loss/seq after 03200 batchs: 265.0849304199219
INFO:root:Train (Epoch 392): Loss/seq after 03250 batchs: 264.52801513671875
INFO:root:Train (Epoch 392): Loss/seq after 03300 batchs: 264.0199890136719
INFO:root:Train (Epoch 392): Loss/seq after 03350 batchs: 262.7557373046875
INFO:root:Train (Epoch 392): Loss/seq after 03400 batchs: 261.19354248046875
INFO:root:Train (Epoch 392): Loss/seq after 03450 batchs: 259.99456787109375
INFO:root:Train (Epoch 392): Loss/seq after 03500 batchs: 261.05047607421875
INFO:root:Train (Epoch 392): Loss/seq after 03550 batchs: 260.2559509277344
INFO:root:Train (Epoch 392): Loss/seq after 03600 batchs: 262.22698974609375
INFO:root:Train (Epoch 392): Loss/seq after 03650 batchs: 261.2515563964844
INFO:root:Train (Epoch 392): Loss/seq after 03700 batchs: 262.3949279785156
INFO:root:Train (Epoch 392): Loss/seq after 03750 batchs: 265.17901611328125
INFO:root:Train (Epoch 392): Loss/seq after 03800 batchs: 265.546630859375
INFO:root:Train (Epoch 392): Loss/seq after 03850 batchs: 265.2044677734375
INFO:root:Train (Epoch 392): Loss/seq after 03900 batchs: 266.2176513671875
INFO:root:Train (Epoch 392): Loss/seq after 03950 batchs: 268.1748962402344
INFO:root:Train (Epoch 392): Loss/seq after 04000 batchs: 267.09063720703125
INFO:root:Train (Epoch 392): Loss/seq after 04050 batchs: 265.8065185546875
INFO:root:Train (Epoch 392): Loss/seq after 04100 batchs: 264.9834289550781
INFO:root:Train (Epoch 392): Loss/seq after 04150 batchs: 264.8443603515625
INFO:root:Train (Epoch 392): Loss/seq after 04200 batchs: 264.54644775390625
INFO:root:Train (Epoch 392): Loss/seq after 04250 batchs: 263.7950439453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 392): Loss/seq after 00000 batches: 208.52120971679688
INFO:root:# Valid (Epoch 392): Loss/seq after 00050 batches: 650.4265747070312
INFO:root:# Valid (Epoch 392): Loss/seq after 00100 batches: 663.3035888671875
INFO:root:# Valid (Epoch 392): Loss/seq after 00150 batches: 494.1332702636719
INFO:root:# Valid (Epoch 392): Loss/seq after 00200 batches: 456.12347412109375
INFO:root:Artifacts: Make stick videos for epoch 392
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_392_on_20220424_043215.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_392_index_1121_on_20220424_043215.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 393): Loss/seq after 00000 batchs: 612.97998046875
INFO:root:Train (Epoch 393): Loss/seq after 00050 batchs: 359.3492431640625
INFO:root:Train (Epoch 393): Loss/seq after 00100 batchs: 350.9570007324219
INFO:root:Train (Epoch 393): Loss/seq after 00150 batchs: 333.2691345214844
INFO:root:Train (Epoch 393): Loss/seq after 00200 batchs: 370.7862548828125
INFO:root:Train (Epoch 393): Loss/seq after 00250 batchs: 393.0143127441406
INFO:root:Train (Epoch 393): Loss/seq after 00300 batchs: 411.06182861328125
INFO:root:Train (Epoch 393): Loss/seq after 00350 batchs: 393.6936340332031
INFO:root:Train (Epoch 393): Loss/seq after 00400 batchs: 383.91693115234375
INFO:root:Train (Epoch 393): Loss/seq after 00450 batchs: 401.6684875488281
INFO:root:Train (Epoch 393): Loss/seq after 00500 batchs: 388.76953125
INFO:root:Train (Epoch 393): Loss/seq after 00550 batchs: 383.8171081542969
INFO:root:Train (Epoch 393): Loss/seq after 00600 batchs: 370.0962219238281
INFO:root:Train (Epoch 393): Loss/seq after 00650 batchs: 354.523681640625
INFO:root:Train (Epoch 393): Loss/seq after 00700 batchs: 340.0694580078125
INFO:root:Train (Epoch 393): Loss/seq after 00750 batchs: 333.8358154296875
INFO:root:Train (Epoch 393): Loss/seq after 00800 batchs: 331.885009765625
INFO:root:Train (Epoch 393): Loss/seq after 00850 batchs: 320.8394470214844
INFO:root:Train (Epoch 393): Loss/seq after 00900 batchs: 312.4486389160156
INFO:root:Train (Epoch 393): Loss/seq after 00950 batchs: 311.734619140625
INFO:root:Train (Epoch 393): Loss/seq after 01000 batchs: 305.7914733886719
INFO:root:Train (Epoch 393): Loss/seq after 01050 batchs: 299.6472473144531
INFO:root:Train (Epoch 393): Loss/seq after 01100 batchs: 293.1549377441406
INFO:root:Train (Epoch 393): Loss/seq after 01150 batchs: 285.3882141113281
INFO:root:Train (Epoch 393): Loss/seq after 01200 batchs: 284.03204345703125
INFO:root:Train (Epoch 393): Loss/seq after 01250 batchs: 283.18829345703125
INFO:root:Train (Epoch 393): Loss/seq after 01300 batchs: 277.452880859375
INFO:root:Train (Epoch 393): Loss/seq after 01350 batchs: 271.44561767578125
INFO:root:Train (Epoch 393): Loss/seq after 01400 batchs: 272.1217956542969
INFO:root:Train (Epoch 393): Loss/seq after 01450 batchs: 273.71343994140625
INFO:root:Train (Epoch 393): Loss/seq after 01500 batchs: 278.67755126953125
INFO:root:Train (Epoch 393): Loss/seq after 01550 batchs: 279.1142578125
INFO:root:Train (Epoch 393): Loss/seq after 01600 batchs: 278.3393249511719
INFO:root:Train (Epoch 393): Loss/seq after 01650 batchs: 277.5523681640625
INFO:root:Train (Epoch 393): Loss/seq after 01700 batchs: 278.40411376953125
INFO:root:Train (Epoch 393): Loss/seq after 01750 batchs: 277.858642578125
INFO:root:Train (Epoch 393): Loss/seq after 01800 batchs: 277.396484375
INFO:root:Train (Epoch 393): Loss/seq after 01850 batchs: 276.90692138671875
INFO:root:Train (Epoch 393): Loss/seq after 01900 batchs: 276.8648376464844
INFO:root:Train (Epoch 393): Loss/seq after 01950 batchs: 277.14324951171875
INFO:root:Train (Epoch 393): Loss/seq after 02000 batchs: 279.3032531738281
INFO:root:Train (Epoch 393): Loss/seq after 02050 batchs: 280.2069091796875
INFO:root:Train (Epoch 393): Loss/seq after 02100 batchs: 280.2520446777344
INFO:root:Train (Epoch 393): Loss/seq after 02150 batchs: 280.6087951660156
INFO:root:Train (Epoch 393): Loss/seq after 02200 batchs: 280.6064758300781
INFO:root:Train (Epoch 393): Loss/seq after 02250 batchs: 280.0116882324219
INFO:root:Train (Epoch 393): Loss/seq after 02300 batchs: 278.0509948730469
INFO:root:Train (Epoch 393): Loss/seq after 02350 batchs: 276.6582946777344
INFO:root:Train (Epoch 393): Loss/seq after 02400 batchs: 276.20684814453125
INFO:root:Train (Epoch 393): Loss/seq after 02450 batchs: 274.1903381347656
INFO:root:Train (Epoch 393): Loss/seq after 02500 batchs: 269.65234375
INFO:root:Train (Epoch 393): Loss/seq after 02550 batchs: 265.6866149902344
INFO:root:Train (Epoch 393): Loss/seq after 02600 batchs: 262.45880126953125
INFO:root:Train (Epoch 393): Loss/seq after 02650 batchs: 259.6082763671875
INFO:root:Train (Epoch 393): Loss/seq after 02700 batchs: 257.7762451171875
INFO:root:Train (Epoch 393): Loss/seq after 02750 batchs: 254.97373962402344
INFO:root:Train (Epoch 393): Loss/seq after 02800 batchs: 253.62977600097656
INFO:root:Train (Epoch 393): Loss/seq after 02850 batchs: 253.4512939453125
INFO:root:Train (Epoch 393): Loss/seq after 02900 batchs: 253.6439666748047
INFO:root:Train (Epoch 393): Loss/seq after 02950 batchs: 254.68031311035156
INFO:root:Train (Epoch 393): Loss/seq after 03000 batchs: 257.3879089355469
INFO:root:Train (Epoch 393): Loss/seq after 03050 batchs: 258.9274597167969
INFO:root:Train (Epoch 393): Loss/seq after 03100 batchs: 260.3912048339844
INFO:root:Train (Epoch 393): Loss/seq after 03150 batchs: 260.4803771972656
INFO:root:Train (Epoch 393): Loss/seq after 03200 batchs: 260.5270690917969
INFO:root:Train (Epoch 393): Loss/seq after 03250 batchs: 260.65911865234375
INFO:root:Train (Epoch 393): Loss/seq after 03300 batchs: 260.76025390625
INFO:root:Train (Epoch 393): Loss/seq after 03350 batchs: 259.4005432128906
INFO:root:Train (Epoch 393): Loss/seq after 03400 batchs: 257.8515625
INFO:root:Train (Epoch 393): Loss/seq after 03450 batchs: 256.6744079589844
INFO:root:Train (Epoch 393): Loss/seq after 03500 batchs: 257.7501525878906
INFO:root:Train (Epoch 393): Loss/seq after 03550 batchs: 257.069091796875
INFO:root:Train (Epoch 393): Loss/seq after 03600 batchs: 259.4542541503906
INFO:root:Train (Epoch 393): Loss/seq after 03650 batchs: 258.9393310546875
INFO:root:Train (Epoch 393): Loss/seq after 03700 batchs: 259.9368591308594
INFO:root:Train (Epoch 393): Loss/seq after 03750 batchs: 262.79132080078125
INFO:root:Train (Epoch 393): Loss/seq after 03800 batchs: 263.2304992675781
INFO:root:Train (Epoch 393): Loss/seq after 03850 batchs: 262.9570007324219
INFO:root:Train (Epoch 393): Loss/seq after 03900 batchs: 264.2539978027344
INFO:root:Train (Epoch 393): Loss/seq after 03950 batchs: 265.6123046875
INFO:root:Train (Epoch 393): Loss/seq after 04000 batchs: 264.5448303222656
INFO:root:Train (Epoch 393): Loss/seq after 04050 batchs: 263.3014221191406
INFO:root:Train (Epoch 393): Loss/seq after 04100 batchs: 262.54241943359375
INFO:root:Train (Epoch 393): Loss/seq after 04150 batchs: 262.4300842285156
INFO:root:Train (Epoch 393): Loss/seq after 04200 batchs: 262.1722412109375
INFO:root:Train (Epoch 393): Loss/seq after 04250 batchs: 261.4801330566406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 393): Loss/seq after 00000 batches: 170.30630493164062
INFO:root:# Valid (Epoch 393): Loss/seq after 00050 batches: 669.3217163085938
INFO:root:# Valid (Epoch 393): Loss/seq after 00100 batches: 623.3363037109375
INFO:root:# Valid (Epoch 393): Loss/seq after 00150 batches: 468.3839111328125
INFO:root:# Valid (Epoch 393): Loss/seq after 00200 batches: 439.5267639160156
INFO:root:Artifacts: Make stick videos for epoch 393
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_393_on_20220424_043710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_393_index_845_on_20220424_043710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 394): Loss/seq after 00000 batchs: 321.2642517089844
INFO:root:Train (Epoch 394): Loss/seq after 00050 batchs: 337.5824890136719
INFO:root:Train (Epoch 394): Loss/seq after 00100 batchs: 342.8198547363281
INFO:root:Train (Epoch 394): Loss/seq after 00150 batchs: 325.1856689453125
INFO:root:Train (Epoch 394): Loss/seq after 00200 batchs: 361.7979431152344
INFO:root:Train (Epoch 394): Loss/seq after 00250 batchs: 371.8337707519531
INFO:root:Train (Epoch 394): Loss/seq after 00300 batchs: 393.24951171875
INFO:root:Train (Epoch 394): Loss/seq after 00350 batchs: 378.304931640625
INFO:root:Train (Epoch 394): Loss/seq after 00400 batchs: 376.54583740234375
INFO:root:Train (Epoch 394): Loss/seq after 00450 batchs: 393.7348937988281
INFO:root:Train (Epoch 394): Loss/seq after 00500 batchs: 379.6893615722656
INFO:root:Train (Epoch 394): Loss/seq after 00550 batchs: 375.0436096191406
INFO:root:Train (Epoch 394): Loss/seq after 00600 batchs: 360.9054260253906
INFO:root:Train (Epoch 394): Loss/seq after 00650 batchs: 346.2654724121094
INFO:root:Train (Epoch 394): Loss/seq after 00700 batchs: 332.2272644042969
INFO:root:Train (Epoch 394): Loss/seq after 00750 batchs: 327.35675048828125
INFO:root:Train (Epoch 394): Loss/seq after 00800 batchs: 326.42437744140625
INFO:root:Train (Epoch 394): Loss/seq after 00850 batchs: 315.913818359375
INFO:root:Train (Epoch 394): Loss/seq after 00900 batchs: 308.22412109375
INFO:root:Train (Epoch 394): Loss/seq after 00950 batchs: 308.46441650390625
INFO:root:Train (Epoch 394): Loss/seq after 01000 batchs: 303.0154724121094
INFO:root:Train (Epoch 394): Loss/seq after 01050 batchs: 298.1795654296875
INFO:root:Train (Epoch 394): Loss/seq after 01100 batchs: 291.1184387207031
INFO:root:Train (Epoch 394): Loss/seq after 01150 batchs: 283.4341125488281
INFO:root:Train (Epoch 394): Loss/seq after 01200 batchs: 282.26666259765625
INFO:root:Train (Epoch 394): Loss/seq after 01250 batchs: 282.2153625488281
INFO:root:Train (Epoch 394): Loss/seq after 01300 batchs: 276.5221252441406
INFO:root:Train (Epoch 394): Loss/seq after 01350 batchs: 270.9294738769531
INFO:root:Train (Epoch 394): Loss/seq after 01400 batchs: 272.80804443359375
INFO:root:Train (Epoch 394): Loss/seq after 01450 batchs: 274.4466857910156
INFO:root:Train (Epoch 394): Loss/seq after 01500 batchs: 278.7635192871094
INFO:root:Train (Epoch 394): Loss/seq after 01550 batchs: 279.77484130859375
INFO:root:Train (Epoch 394): Loss/seq after 01600 batchs: 279.3472900390625
INFO:root:Train (Epoch 394): Loss/seq after 01650 batchs: 278.35723876953125
INFO:root:Train (Epoch 394): Loss/seq after 01700 batchs: 278.9907531738281
INFO:root:Train (Epoch 394): Loss/seq after 01750 batchs: 278.2143859863281
INFO:root:Train (Epoch 394): Loss/seq after 01800 batchs: 277.6910400390625
INFO:root:Train (Epoch 394): Loss/seq after 01850 batchs: 277.1617736816406
INFO:root:Train (Epoch 394): Loss/seq after 01900 batchs: 276.95361328125
INFO:root:Train (Epoch 394): Loss/seq after 01950 batchs: 277.3415222167969
INFO:root:Train (Epoch 394): Loss/seq after 02000 batchs: 279.5095520019531
INFO:root:Train (Epoch 394): Loss/seq after 02050 batchs: 280.2216796875
INFO:root:Train (Epoch 394): Loss/seq after 02100 batchs: 280.1412353515625
INFO:root:Train (Epoch 394): Loss/seq after 02150 batchs: 280.6394958496094
INFO:root:Train (Epoch 394): Loss/seq after 02200 batchs: 280.54974365234375
INFO:root:Train (Epoch 394): Loss/seq after 02250 batchs: 280.1410217285156
INFO:root:Train (Epoch 394): Loss/seq after 02300 batchs: 278.28985595703125
INFO:root:Train (Epoch 394): Loss/seq after 02350 batchs: 276.86126708984375
INFO:root:Train (Epoch 394): Loss/seq after 02400 batchs: 276.2743225097656
INFO:root:Train (Epoch 394): Loss/seq after 02450 batchs: 274.33526611328125
INFO:root:Train (Epoch 394): Loss/seq after 02500 batchs: 269.78466796875
INFO:root:Train (Epoch 394): Loss/seq after 02550 batchs: 265.80499267578125
INFO:root:Train (Epoch 394): Loss/seq after 02600 batchs: 262.5661926269531
INFO:root:Train (Epoch 394): Loss/seq after 02650 batchs: 259.7475280761719
INFO:root:Train (Epoch 394): Loss/seq after 02700 batchs: 257.8443298339844
INFO:root:Train (Epoch 394): Loss/seq after 02750 batchs: 254.97052001953125
INFO:root:Train (Epoch 394): Loss/seq after 02800 batchs: 253.95166015625
INFO:root:Train (Epoch 394): Loss/seq after 02850 batchs: 253.78524780273438
INFO:root:Train (Epoch 394): Loss/seq after 02900 batchs: 253.79379272460938
INFO:root:Train (Epoch 394): Loss/seq after 02950 batchs: 254.85784912109375
INFO:root:Train (Epoch 394): Loss/seq after 03000 batchs: 257.66754150390625
INFO:root:Train (Epoch 394): Loss/seq after 03050 batchs: 259.4090881347656
INFO:root:Train (Epoch 394): Loss/seq after 03100 batchs: 260.5637512207031
INFO:root:Train (Epoch 394): Loss/seq after 03150 batchs: 260.5261535644531
INFO:root:Train (Epoch 394): Loss/seq after 03200 batchs: 261.23138427734375
INFO:root:Train (Epoch 394): Loss/seq after 03250 batchs: 261.2182922363281
INFO:root:Train (Epoch 394): Loss/seq after 03300 batchs: 260.6728820800781
INFO:root:Train (Epoch 394): Loss/seq after 03350 batchs: 259.4559326171875
INFO:root:Train (Epoch 394): Loss/seq after 03400 batchs: 257.974609375
INFO:root:Train (Epoch 394): Loss/seq after 03450 batchs: 256.87933349609375
INFO:root:Train (Epoch 394): Loss/seq after 03500 batchs: 257.8818054199219
INFO:root:Train (Epoch 394): Loss/seq after 03550 batchs: 257.09112548828125
INFO:root:Train (Epoch 394): Loss/seq after 03600 batchs: 259.3061218261719
INFO:root:Train (Epoch 394): Loss/seq after 03650 batchs: 258.46832275390625
INFO:root:Train (Epoch 394): Loss/seq after 03700 batchs: 259.94219970703125
INFO:root:Train (Epoch 394): Loss/seq after 03750 batchs: 262.740478515625
INFO:root:Train (Epoch 394): Loss/seq after 03800 batchs: 263.2193908691406
INFO:root:Train (Epoch 394): Loss/seq after 03850 batchs: 262.9883117675781
INFO:root:Train (Epoch 394): Loss/seq after 03900 batchs: 264.09649658203125
INFO:root:Train (Epoch 394): Loss/seq after 03950 batchs: 265.4961853027344
INFO:root:Train (Epoch 394): Loss/seq after 04000 batchs: 264.5345153808594
INFO:root:Train (Epoch 394): Loss/seq after 04050 batchs: 263.33685302734375
INFO:root:Train (Epoch 394): Loss/seq after 04100 batchs: 262.4667053222656
INFO:root:Train (Epoch 394): Loss/seq after 04150 batchs: 262.20404052734375
INFO:root:Train (Epoch 394): Loss/seq after 04200 batchs: 261.9480895996094
INFO:root:Train (Epoch 394): Loss/seq after 04250 batchs: 261.14404296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 394): Loss/seq after 00000 batches: 187.90859985351562
INFO:root:# Valid (Epoch 394): Loss/seq after 00050 batches: 597.9054565429688
INFO:root:# Valid (Epoch 394): Loss/seq after 00100 batches: 573.564453125
INFO:root:# Valid (Epoch 394): Loss/seq after 00150 batches: 432.7937316894531
INFO:root:# Valid (Epoch 394): Loss/seq after 00200 batches: 412.6795349121094
INFO:root:Artifacts: Make stick videos for epoch 394
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_394_on_20220424_044158.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_394_index_1316_on_20220424_044158.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 395): Loss/seq after 00000 batchs: 738.5186767578125
INFO:root:Train (Epoch 395): Loss/seq after 00050 batchs: 345.5679626464844
INFO:root:Train (Epoch 395): Loss/seq after 00100 batchs: 352.0245666503906
INFO:root:Train (Epoch 395): Loss/seq after 00150 batchs: 330.9924621582031
INFO:root:Train (Epoch 395): Loss/seq after 00200 batchs: 373.4868469238281
INFO:root:Train (Epoch 395): Loss/seq after 00250 batchs: 372.19219970703125
INFO:root:Train (Epoch 395): Loss/seq after 00300 batchs: 391.968017578125
INFO:root:Train (Epoch 395): Loss/seq after 00350 batchs: 378.2806701660156
INFO:root:Train (Epoch 395): Loss/seq after 00400 batchs: 373.494873046875
INFO:root:Train (Epoch 395): Loss/seq after 00450 batchs: 390.8943176269531
INFO:root:Train (Epoch 395): Loss/seq after 00500 batchs: 379.1867980957031
INFO:root:Train (Epoch 395): Loss/seq after 00550 batchs: 375.18023681640625
INFO:root:Train (Epoch 395): Loss/seq after 00600 batchs: 361.6339416503906
INFO:root:Train (Epoch 395): Loss/seq after 00650 batchs: 347.3966064453125
INFO:root:Train (Epoch 395): Loss/seq after 00700 batchs: 331.9889831542969
INFO:root:Train (Epoch 395): Loss/seq after 00750 batchs: 325.7557678222656
INFO:root:Train (Epoch 395): Loss/seq after 00800 batchs: 324.7542419433594
INFO:root:Train (Epoch 395): Loss/seq after 00850 batchs: 314.2448425292969
INFO:root:Train (Epoch 395): Loss/seq after 00900 batchs: 306.7347717285156
INFO:root:Train (Epoch 395): Loss/seq after 00950 batchs: 308.6801452636719
INFO:root:Train (Epoch 395): Loss/seq after 01000 batchs: 302.74237060546875
INFO:root:Train (Epoch 395): Loss/seq after 01050 batchs: 298.94915771484375
INFO:root:Train (Epoch 395): Loss/seq after 01100 batchs: 292.56463623046875
INFO:root:Train (Epoch 395): Loss/seq after 01150 batchs: 284.8552551269531
INFO:root:Train (Epoch 395): Loss/seq after 01200 batchs: 283.89398193359375
INFO:root:Train (Epoch 395): Loss/seq after 01250 batchs: 283.5573425292969
INFO:root:Train (Epoch 395): Loss/seq after 01300 batchs: 277.8923645019531
INFO:root:Train (Epoch 395): Loss/seq after 01350 batchs: 272.353515625
INFO:root:Train (Epoch 395): Loss/seq after 01400 batchs: 273.3797607421875
INFO:root:Train (Epoch 395): Loss/seq after 01450 batchs: 275.8602600097656
INFO:root:Train (Epoch 395): Loss/seq after 01500 batchs: 280.62603759765625
INFO:root:Train (Epoch 395): Loss/seq after 01550 batchs: 281.8411560058594
INFO:root:Train (Epoch 395): Loss/seq after 01600 batchs: 281.3862609863281
INFO:root:Train (Epoch 395): Loss/seq after 01650 batchs: 280.52520751953125
INFO:root:Train (Epoch 395): Loss/seq after 01700 batchs: 280.7845153808594
INFO:root:Train (Epoch 395): Loss/seq after 01750 batchs: 280.0871276855469
INFO:root:Train (Epoch 395): Loss/seq after 01800 batchs: 279.4857177734375
INFO:root:Train (Epoch 395): Loss/seq after 01850 batchs: 278.8653564453125
INFO:root:Train (Epoch 395): Loss/seq after 01900 batchs: 278.7388000488281
INFO:root:Train (Epoch 395): Loss/seq after 01950 batchs: 279.13385009765625
INFO:root:Train (Epoch 395): Loss/seq after 02000 batchs: 281.4093322753906
INFO:root:Train (Epoch 395): Loss/seq after 02050 batchs: 282.2379150390625
INFO:root:Train (Epoch 395): Loss/seq after 02100 batchs: 282.5332946777344
INFO:root:Train (Epoch 395): Loss/seq after 02150 batchs: 282.83953857421875
INFO:root:Train (Epoch 395): Loss/seq after 02200 batchs: 282.6732482910156
INFO:root:Train (Epoch 395): Loss/seq after 02250 batchs: 282.4595642089844
INFO:root:Train (Epoch 395): Loss/seq after 02300 batchs: 280.8835144042969
INFO:root:Train (Epoch 395): Loss/seq after 02350 batchs: 279.3975524902344
INFO:root:Train (Epoch 395): Loss/seq after 02400 batchs: 278.8160705566406
INFO:root:Train (Epoch 395): Loss/seq after 02450 batchs: 276.942138671875
INFO:root:Train (Epoch 395): Loss/seq after 02500 batchs: 272.4265441894531
INFO:root:Train (Epoch 395): Loss/seq after 02550 batchs: 268.43994140625
INFO:root:Train (Epoch 395): Loss/seq after 02600 batchs: 265.1371154785156
INFO:root:Train (Epoch 395): Loss/seq after 02650 batchs: 262.2110290527344
INFO:root:Train (Epoch 395): Loss/seq after 02700 batchs: 260.3257141113281
INFO:root:Train (Epoch 395): Loss/seq after 02750 batchs: 257.4396057128906
INFO:root:Train (Epoch 395): Loss/seq after 02800 batchs: 256.2771911621094
INFO:root:Train (Epoch 395): Loss/seq after 02850 batchs: 255.98553466796875
INFO:root:Train (Epoch 395): Loss/seq after 02900 batchs: 256.2554931640625
INFO:root:Train (Epoch 395): Loss/seq after 02950 batchs: 257.33966064453125
INFO:root:Train (Epoch 395): Loss/seq after 03000 batchs: 259.6933898925781
INFO:root:Train (Epoch 395): Loss/seq after 03050 batchs: 260.7056884765625
INFO:root:Train (Epoch 395): Loss/seq after 03100 batchs: 262.04705810546875
INFO:root:Train (Epoch 395): Loss/seq after 03150 batchs: 262.9654235839844
INFO:root:Train (Epoch 395): Loss/seq after 03200 batchs: 263.4054870605469
INFO:root:Train (Epoch 395): Loss/seq after 03250 batchs: 262.7832946777344
INFO:root:Train (Epoch 395): Loss/seq after 03300 batchs: 263.6140441894531
INFO:root:Train (Epoch 395): Loss/seq after 03350 batchs: 262.26739501953125
INFO:root:Train (Epoch 395): Loss/seq after 03400 batchs: 260.7014465332031
INFO:root:Train (Epoch 395): Loss/seq after 03450 batchs: 259.6480712890625
INFO:root:Train (Epoch 395): Loss/seq after 03500 batchs: 260.77166748046875
INFO:root:Train (Epoch 395): Loss/seq after 03550 batchs: 260.01220703125
INFO:root:Train (Epoch 395): Loss/seq after 03600 batchs: 261.9751281738281
INFO:root:Train (Epoch 395): Loss/seq after 03650 batchs: 261.21685791015625
INFO:root:Train (Epoch 395): Loss/seq after 03700 batchs: 262.63787841796875
INFO:root:Train (Epoch 395): Loss/seq after 03750 batchs: 265.48822021484375
INFO:root:Train (Epoch 395): Loss/seq after 03800 batchs: 265.86181640625
INFO:root:Train (Epoch 395): Loss/seq after 03850 batchs: 265.53106689453125
INFO:root:Train (Epoch 395): Loss/seq after 03900 batchs: 266.274658203125
INFO:root:Train (Epoch 395): Loss/seq after 03950 batchs: 267.84478759765625
INFO:root:Train (Epoch 395): Loss/seq after 04000 batchs: 266.7751159667969
INFO:root:Train (Epoch 395): Loss/seq after 04050 batchs: 265.4928894042969
INFO:root:Train (Epoch 395): Loss/seq after 04100 batchs: 264.5965576171875
INFO:root:Train (Epoch 395): Loss/seq after 04150 batchs: 264.4232482910156
INFO:root:Train (Epoch 395): Loss/seq after 04200 batchs: 264.1298522949219
INFO:root:Train (Epoch 395): Loss/seq after 04250 batchs: 263.40765380859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 395): Loss/seq after 00000 batches: 240.1249542236328
INFO:root:# Valid (Epoch 395): Loss/seq after 00050 batches: 647.0155029296875
INFO:root:# Valid (Epoch 395): Loss/seq after 00100 batches: 618.0845947265625
INFO:root:# Valid (Epoch 395): Loss/seq after 00150 batches: 464.3381042480469
INFO:root:# Valid (Epoch 395): Loss/seq after 00200 batches: 434.51873779296875
INFO:root:Artifacts: Make stick videos for epoch 395
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_395_on_20220424_044706.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_395_index_430_on_20220424_044706.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 396): Loss/seq after 00000 batchs: 482.4474792480469
INFO:root:Train (Epoch 396): Loss/seq after 00050 batchs: 356.9978332519531
INFO:root:Train (Epoch 396): Loss/seq after 00100 batchs: 351.94384765625
INFO:root:Train (Epoch 396): Loss/seq after 00150 batchs: 336.371337890625
INFO:root:Train (Epoch 396): Loss/seq after 00200 batchs: 375.1122131347656
INFO:root:Train (Epoch 396): Loss/seq after 00250 batchs: 393.7693176269531
INFO:root:Train (Epoch 396): Loss/seq after 00300 batchs: 414.0364685058594
INFO:root:Train (Epoch 396): Loss/seq after 00350 batchs: 396.8430480957031
INFO:root:Train (Epoch 396): Loss/seq after 00400 batchs: 389.65179443359375
INFO:root:Train (Epoch 396): Loss/seq after 00450 batchs: 405.521240234375
INFO:root:Train (Epoch 396): Loss/seq after 00500 batchs: 393.54327392578125
INFO:root:Train (Epoch 396): Loss/seq after 00550 batchs: 387.92303466796875
INFO:root:Train (Epoch 396): Loss/seq after 00600 batchs: 373.9981689453125
INFO:root:Train (Epoch 396): Loss/seq after 00650 batchs: 358.6784362792969
INFO:root:Train (Epoch 396): Loss/seq after 00700 batchs: 342.65582275390625
INFO:root:Train (Epoch 396): Loss/seq after 00750 batchs: 336.05682373046875
INFO:root:Train (Epoch 396): Loss/seq after 00800 batchs: 334.7179260253906
INFO:root:Train (Epoch 396): Loss/seq after 00850 batchs: 324.50079345703125
INFO:root:Train (Epoch 396): Loss/seq after 00900 batchs: 316.8428649902344
INFO:root:Train (Epoch 396): Loss/seq after 00950 batchs: 317.247314453125
INFO:root:Train (Epoch 396): Loss/seq after 01000 batchs: 311.0683898925781
INFO:root:Train (Epoch 396): Loss/seq after 01050 batchs: 304.55438232421875
INFO:root:Train (Epoch 396): Loss/seq after 01100 batchs: 297.1837463378906
INFO:root:Train (Epoch 396): Loss/seq after 01150 batchs: 289.2377624511719
INFO:root:Train (Epoch 396): Loss/seq after 01200 batchs: 288.0520324707031
INFO:root:Train (Epoch 396): Loss/seq after 01250 batchs: 287.098876953125
INFO:root:Train (Epoch 396): Loss/seq after 01300 batchs: 281.2071533203125
INFO:root:Train (Epoch 396): Loss/seq after 01350 batchs: 275.3712158203125
INFO:root:Train (Epoch 396): Loss/seq after 01400 batchs: 276.2777099609375
INFO:root:Train (Epoch 396): Loss/seq after 01450 batchs: 277.6509704589844
INFO:root:Train (Epoch 396): Loss/seq after 01500 batchs: 282.3061828613281
INFO:root:Train (Epoch 396): Loss/seq after 01550 batchs: 283.6298522949219
INFO:root:Train (Epoch 396): Loss/seq after 01600 batchs: 282.8032531738281
INFO:root:Train (Epoch 396): Loss/seq after 01650 batchs: 281.7449035644531
INFO:root:Train (Epoch 396): Loss/seq after 01700 batchs: 281.93023681640625
INFO:root:Train (Epoch 396): Loss/seq after 01750 batchs: 280.8564758300781
INFO:root:Train (Epoch 396): Loss/seq after 01800 batchs: 280.3460998535156
INFO:root:Train (Epoch 396): Loss/seq after 01850 batchs: 279.7129821777344
INFO:root:Train (Epoch 396): Loss/seq after 01900 batchs: 279.765625
INFO:root:Train (Epoch 396): Loss/seq after 01950 batchs: 280.7236633300781
INFO:root:Train (Epoch 396): Loss/seq after 02000 batchs: 283.056884765625
INFO:root:Train (Epoch 396): Loss/seq after 02050 batchs: 283.69549560546875
INFO:root:Train (Epoch 396): Loss/seq after 02100 batchs: 283.6706848144531
INFO:root:Train (Epoch 396): Loss/seq after 02150 batchs: 283.9408264160156
INFO:root:Train (Epoch 396): Loss/seq after 02200 batchs: 283.7381896972656
INFO:root:Train (Epoch 396): Loss/seq after 02250 batchs: 283.21124267578125
INFO:root:Train (Epoch 396): Loss/seq after 02300 batchs: 281.6148986816406
INFO:root:Train (Epoch 396): Loss/seq after 02350 batchs: 280.15985107421875
INFO:root:Train (Epoch 396): Loss/seq after 02400 batchs: 279.771484375
INFO:root:Train (Epoch 396): Loss/seq after 02450 batchs: 277.85833740234375
INFO:root:Train (Epoch 396): Loss/seq after 02500 batchs: 273.2736511230469
INFO:root:Train (Epoch 396): Loss/seq after 02550 batchs: 269.34228515625
INFO:root:Train (Epoch 396): Loss/seq after 02600 batchs: 266.0895690917969
INFO:root:Train (Epoch 396): Loss/seq after 02650 batchs: 263.10992431640625
INFO:root:Train (Epoch 396): Loss/seq after 02700 batchs: 261.3728942871094
INFO:root:Train (Epoch 396): Loss/seq after 02750 batchs: 258.8318176269531
INFO:root:Train (Epoch 396): Loss/seq after 02800 batchs: 257.4883117675781
INFO:root:Train (Epoch 396): Loss/seq after 02850 batchs: 257.2498474121094
INFO:root:Train (Epoch 396): Loss/seq after 02900 batchs: 257.06903076171875
INFO:root:Train (Epoch 396): Loss/seq after 02950 batchs: 258.08245849609375
INFO:root:Train (Epoch 396): Loss/seq after 03000 batchs: 260.7179260253906
INFO:root:Train (Epoch 396): Loss/seq after 03050 batchs: 262.3807373046875
INFO:root:Train (Epoch 396): Loss/seq after 03100 batchs: 263.6357116699219
INFO:root:Train (Epoch 396): Loss/seq after 03150 batchs: 263.63140869140625
INFO:root:Train (Epoch 396): Loss/seq after 03200 batchs: 264.2149353027344
INFO:root:Train (Epoch 396): Loss/seq after 03250 batchs: 264.0971374511719
INFO:root:Train (Epoch 396): Loss/seq after 03300 batchs: 263.5911560058594
INFO:root:Train (Epoch 396): Loss/seq after 03350 batchs: 262.4207763671875
INFO:root:Train (Epoch 396): Loss/seq after 03400 batchs: 260.91650390625
INFO:root:Train (Epoch 396): Loss/seq after 03450 batchs: 259.7325439453125
INFO:root:Train (Epoch 396): Loss/seq after 03500 batchs: 260.42242431640625
INFO:root:Train (Epoch 396): Loss/seq after 03550 batchs: 259.5318603515625
INFO:root:Train (Epoch 396): Loss/seq after 03600 batchs: 261.5647888183594
INFO:root:Train (Epoch 396): Loss/seq after 03650 batchs: 260.5697937011719
INFO:root:Train (Epoch 396): Loss/seq after 03700 batchs: 261.6077880859375
INFO:root:Train (Epoch 396): Loss/seq after 03750 batchs: 264.14483642578125
INFO:root:Train (Epoch 396): Loss/seq after 03800 batchs: 264.5472412109375
INFO:root:Train (Epoch 396): Loss/seq after 03850 batchs: 264.22625732421875
INFO:root:Train (Epoch 396): Loss/seq after 03900 batchs: 265.2538146972656
INFO:root:Train (Epoch 396): Loss/seq after 03950 batchs: 267.6458435058594
INFO:root:Train (Epoch 396): Loss/seq after 04000 batchs: 266.5885925292969
INFO:root:Train (Epoch 396): Loss/seq after 04050 batchs: 265.32427978515625
INFO:root:Train (Epoch 396): Loss/seq after 04100 batchs: 264.4324035644531
INFO:root:Train (Epoch 396): Loss/seq after 04150 batchs: 264.2157897949219
INFO:root:Train (Epoch 396): Loss/seq after 04200 batchs: 263.8126525878906
INFO:root:Train (Epoch 396): Loss/seq after 04250 batchs: 263.02886962890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 396): Loss/seq after 00000 batches: 196.6394805908203
INFO:root:# Valid (Epoch 396): Loss/seq after 00050 batches: 681.5452270507812
INFO:root:# Valid (Epoch 396): Loss/seq after 00100 batches: 666.9476318359375
INFO:root:# Valid (Epoch 396): Loss/seq after 00150 batches: 497.58319091796875
INFO:root:# Valid (Epoch 396): Loss/seq after 00200 batches: 459.3587951660156
INFO:root:Artifacts: Make stick videos for epoch 396
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_396_on_20220424_045150.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_396_index_1679_on_20220424_045150.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 397): Loss/seq after 00000 batchs: 681.5906982421875
INFO:root:Train (Epoch 397): Loss/seq after 00050 batchs: 355.75457763671875
INFO:root:Train (Epoch 397): Loss/seq after 00100 batchs: 348.552001953125
INFO:root:Train (Epoch 397): Loss/seq after 00150 batchs: 331.6066589355469
INFO:root:Train (Epoch 397): Loss/seq after 00200 batchs: 380.7734375
INFO:root:Train (Epoch 397): Loss/seq after 00250 batchs: 384.1736145019531
INFO:root:Train (Epoch 397): Loss/seq after 00300 batchs: 400.7590637207031
INFO:root:Train (Epoch 397): Loss/seq after 00350 batchs: 384.456298828125
INFO:root:Train (Epoch 397): Loss/seq after 00400 batchs: 383.5019226074219
INFO:root:Train (Epoch 397): Loss/seq after 00450 batchs: 400.18756103515625
INFO:root:Train (Epoch 397): Loss/seq after 00500 batchs: 392.820068359375
INFO:root:Train (Epoch 397): Loss/seq after 00550 batchs: 388.7108459472656
INFO:root:Train (Epoch 397): Loss/seq after 00600 batchs: 374.2696533203125
INFO:root:Train (Epoch 397): Loss/seq after 00650 batchs: 360.5792541503906
INFO:root:Train (Epoch 397): Loss/seq after 00700 batchs: 345.7711486816406
INFO:root:Train (Epoch 397): Loss/seq after 00750 batchs: 340.05694580078125
INFO:root:Train (Epoch 397): Loss/seq after 00800 batchs: 339.00372314453125
INFO:root:Train (Epoch 397): Loss/seq after 00850 batchs: 327.5587158203125
INFO:root:Train (Epoch 397): Loss/seq after 00900 batchs: 319.24151611328125
INFO:root:Train (Epoch 397): Loss/seq after 00950 batchs: 318.17242431640625
INFO:root:Train (Epoch 397): Loss/seq after 01000 batchs: 311.9743957519531
INFO:root:Train (Epoch 397): Loss/seq after 01050 batchs: 305.344970703125
INFO:root:Train (Epoch 397): Loss/seq after 01100 batchs: 297.8246765136719
INFO:root:Train (Epoch 397): Loss/seq after 01150 batchs: 289.5432434082031
INFO:root:Train (Epoch 397): Loss/seq after 01200 batchs: 287.3799743652344
INFO:root:Train (Epoch 397): Loss/seq after 01250 batchs: 286.5816345214844
INFO:root:Train (Epoch 397): Loss/seq after 01300 batchs: 280.2589416503906
INFO:root:Train (Epoch 397): Loss/seq after 01350 batchs: 274.1081848144531
INFO:root:Train (Epoch 397): Loss/seq after 01400 batchs: 275.74627685546875
INFO:root:Train (Epoch 397): Loss/seq after 01450 batchs: 276.9378662109375
INFO:root:Train (Epoch 397): Loss/seq after 01500 batchs: 281.2604064941406
INFO:root:Train (Epoch 397): Loss/seq after 01550 batchs: 281.8846740722656
INFO:root:Train (Epoch 397): Loss/seq after 01600 batchs: 281.01220703125
INFO:root:Train (Epoch 397): Loss/seq after 01650 batchs: 280.1360168457031
INFO:root:Train (Epoch 397): Loss/seq after 01700 batchs: 280.5162353515625
INFO:root:Train (Epoch 397): Loss/seq after 01750 batchs: 279.81195068359375
INFO:root:Train (Epoch 397): Loss/seq after 01800 batchs: 279.0791015625
INFO:root:Train (Epoch 397): Loss/seq after 01850 batchs: 278.57415771484375
INFO:root:Train (Epoch 397): Loss/seq after 01900 batchs: 278.53326416015625
INFO:root:Train (Epoch 397): Loss/seq after 01950 batchs: 278.8251953125
INFO:root:Train (Epoch 397): Loss/seq after 02000 batchs: 280.7378845214844
INFO:root:Train (Epoch 397): Loss/seq after 02050 batchs: 281.5559387207031
INFO:root:Train (Epoch 397): Loss/seq after 02100 batchs: 281.5386047363281
INFO:root:Train (Epoch 397): Loss/seq after 02150 batchs: 281.8385314941406
INFO:root:Train (Epoch 397): Loss/seq after 02200 batchs: 281.65338134765625
INFO:root:Train (Epoch 397): Loss/seq after 02250 batchs: 281.4439392089844
INFO:root:Train (Epoch 397): Loss/seq after 02300 batchs: 279.848388671875
INFO:root:Train (Epoch 397): Loss/seq after 02350 batchs: 278.40972900390625
INFO:root:Train (Epoch 397): Loss/seq after 02400 batchs: 277.7077941894531
INFO:root:Train (Epoch 397): Loss/seq after 02450 batchs: 275.633544921875
INFO:root:Train (Epoch 397): Loss/seq after 02500 batchs: 271.0638732910156
INFO:root:Train (Epoch 397): Loss/seq after 02550 batchs: 267.10186767578125
INFO:root:Train (Epoch 397): Loss/seq after 02600 batchs: 263.8929138183594
INFO:root:Train (Epoch 397): Loss/seq after 02650 batchs: 260.98114013671875
INFO:root:Train (Epoch 397): Loss/seq after 02700 batchs: 259.16204833984375
INFO:root:Train (Epoch 397): Loss/seq after 02750 batchs: 256.7394714355469
INFO:root:Train (Epoch 397): Loss/seq after 02800 batchs: 255.4488067626953
INFO:root:Train (Epoch 397): Loss/seq after 02850 batchs: 255.1172637939453
INFO:root:Train (Epoch 397): Loss/seq after 02900 batchs: 255.23599243164062
INFO:root:Train (Epoch 397): Loss/seq after 02950 batchs: 256.35345458984375
INFO:root:Train (Epoch 397): Loss/seq after 03000 batchs: 258.7294921875
INFO:root:Train (Epoch 397): Loss/seq after 03050 batchs: 259.6773376464844
INFO:root:Train (Epoch 397): Loss/seq after 03100 batchs: 260.97161865234375
INFO:root:Train (Epoch 397): Loss/seq after 03150 batchs: 260.76531982421875
INFO:root:Train (Epoch 397): Loss/seq after 03200 batchs: 261.40887451171875
INFO:root:Train (Epoch 397): Loss/seq after 03250 batchs: 261.0704650878906
INFO:root:Train (Epoch 397): Loss/seq after 03300 batchs: 260.7876892089844
INFO:root:Train (Epoch 397): Loss/seq after 03350 batchs: 259.6759948730469
INFO:root:Train (Epoch 397): Loss/seq after 03400 batchs: 258.0029296875
INFO:root:Train (Epoch 397): Loss/seq after 03450 batchs: 256.7903747558594
INFO:root:Train (Epoch 397): Loss/seq after 03500 batchs: 258.2956848144531
INFO:root:Train (Epoch 397): Loss/seq after 03550 batchs: 257.5296325683594
INFO:root:Train (Epoch 397): Loss/seq after 03600 batchs: 259.7318420410156
INFO:root:Train (Epoch 397): Loss/seq after 03650 batchs: 258.7768249511719
INFO:root:Train (Epoch 397): Loss/seq after 03700 batchs: 259.99578857421875
INFO:root:Train (Epoch 397): Loss/seq after 03750 batchs: 262.5907897949219
INFO:root:Train (Epoch 397): Loss/seq after 03800 batchs: 262.95697021484375
INFO:root:Train (Epoch 397): Loss/seq after 03850 batchs: 262.7510070800781
INFO:root:Train (Epoch 397): Loss/seq after 03900 batchs: 263.8613586425781
INFO:root:Train (Epoch 397): Loss/seq after 03950 batchs: 265.690185546875
INFO:root:Train (Epoch 397): Loss/seq after 04000 batchs: 264.61724853515625
INFO:root:Train (Epoch 397): Loss/seq after 04050 batchs: 263.3137512207031
INFO:root:Train (Epoch 397): Loss/seq after 04100 batchs: 262.4707946777344
INFO:root:Train (Epoch 397): Loss/seq after 04150 batchs: 262.19293212890625
INFO:root:Train (Epoch 397): Loss/seq after 04200 batchs: 261.858154296875
INFO:root:Train (Epoch 397): Loss/seq after 04250 batchs: 261.0953369140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 397): Loss/seq after 00000 batches: 178.85533142089844
INFO:root:# Valid (Epoch 397): Loss/seq after 00050 batches: 624.2758178710938
INFO:root:# Valid (Epoch 397): Loss/seq after 00100 batches: 613.6422119140625
INFO:root:# Valid (Epoch 397): Loss/seq after 00150 batches: 461.9488220214844
INFO:root:# Valid (Epoch 397): Loss/seq after 00200 batches: 435.97174072265625
INFO:root:Artifacts: Make stick videos for epoch 397
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_397_on_20220424_045634.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_397_index_23_on_20220424_045634.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 398): Loss/seq after 00000 batchs: 414.34619140625
INFO:root:Train (Epoch 398): Loss/seq after 00050 batchs: 371.74322509765625
INFO:root:Train (Epoch 398): Loss/seq after 00100 batchs: 351.24755859375
INFO:root:Train (Epoch 398): Loss/seq after 00150 batchs: 330.9346923828125
INFO:root:Train (Epoch 398): Loss/seq after 00200 batchs: 374.4971923828125
INFO:root:Train (Epoch 398): Loss/seq after 00250 batchs: 384.0037841796875
INFO:root:Train (Epoch 398): Loss/seq after 00300 batchs: 399.2955017089844
INFO:root:Train (Epoch 398): Loss/seq after 00350 batchs: 382.2384338378906
INFO:root:Train (Epoch 398): Loss/seq after 00400 batchs: 376.9995422363281
INFO:root:Train (Epoch 398): Loss/seq after 00450 batchs: 393.8437805175781
INFO:root:Train (Epoch 398): Loss/seq after 00500 batchs: 380.23614501953125
INFO:root:Train (Epoch 398): Loss/seq after 00550 batchs: 374.7669677734375
INFO:root:Train (Epoch 398): Loss/seq after 00600 batchs: 361.19207763671875
INFO:root:Train (Epoch 398): Loss/seq after 00650 batchs: 347.2823181152344
INFO:root:Train (Epoch 398): Loss/seq after 00700 batchs: 332.021728515625
INFO:root:Train (Epoch 398): Loss/seq after 00750 batchs: 326.084228515625
INFO:root:Train (Epoch 398): Loss/seq after 00800 batchs: 325.07025146484375
INFO:root:Train (Epoch 398): Loss/seq after 00850 batchs: 314.3721008300781
INFO:root:Train (Epoch 398): Loss/seq after 00900 batchs: 306.8106384277344
INFO:root:Train (Epoch 398): Loss/seq after 00950 batchs: 306.7813415527344
INFO:root:Train (Epoch 398): Loss/seq after 01000 batchs: 301.3846740722656
INFO:root:Train (Epoch 398): Loss/seq after 01050 batchs: 295.2750244140625
INFO:root:Train (Epoch 398): Loss/seq after 01100 batchs: 288.13482666015625
INFO:root:Train (Epoch 398): Loss/seq after 01150 batchs: 280.5196228027344
INFO:root:Train (Epoch 398): Loss/seq after 01200 batchs: 279.0646057128906
INFO:root:Train (Epoch 398): Loss/seq after 01250 batchs: 278.4829406738281
INFO:root:Train (Epoch 398): Loss/seq after 01300 batchs: 272.714111328125
INFO:root:Train (Epoch 398): Loss/seq after 01350 batchs: 267.0265808105469
INFO:root:Train (Epoch 398): Loss/seq after 01400 batchs: 269.8703918457031
INFO:root:Train (Epoch 398): Loss/seq after 01450 batchs: 271.4900817871094
INFO:root:Train (Epoch 398): Loss/seq after 01500 batchs: 276.1955261230469
INFO:root:Train (Epoch 398): Loss/seq after 01550 batchs: 277.3523254394531
INFO:root:Train (Epoch 398): Loss/seq after 01600 batchs: 276.40966796875
INFO:root:Train (Epoch 398): Loss/seq after 01650 batchs: 275.5498962402344
INFO:root:Train (Epoch 398): Loss/seq after 01700 batchs: 276.1996154785156
INFO:root:Train (Epoch 398): Loss/seq after 01750 batchs: 275.3959045410156
INFO:root:Train (Epoch 398): Loss/seq after 01800 batchs: 274.80218505859375
INFO:root:Train (Epoch 398): Loss/seq after 01850 batchs: 274.547607421875
INFO:root:Train (Epoch 398): Loss/seq after 01900 batchs: 274.5072937011719
INFO:root:Train (Epoch 398): Loss/seq after 01950 batchs: 274.94171142578125
INFO:root:Train (Epoch 398): Loss/seq after 02000 batchs: 277.1463928222656
INFO:root:Train (Epoch 398): Loss/seq after 02050 batchs: 277.8121032714844
INFO:root:Train (Epoch 398): Loss/seq after 02100 batchs: 277.93145751953125
INFO:root:Train (Epoch 398): Loss/seq after 02150 batchs: 278.23779296875
INFO:root:Train (Epoch 398): Loss/seq after 02200 batchs: 278.1880187988281
INFO:root:Train (Epoch 398): Loss/seq after 02250 batchs: 277.73675537109375
INFO:root:Train (Epoch 398): Loss/seq after 02300 batchs: 276.0335693359375
INFO:root:Train (Epoch 398): Loss/seq after 02350 batchs: 274.6416015625
INFO:root:Train (Epoch 398): Loss/seq after 02400 batchs: 274.16546630859375
INFO:root:Train (Epoch 398): Loss/seq after 02450 batchs: 272.24493408203125
INFO:root:Train (Epoch 398): Loss/seq after 02500 batchs: 267.7142333984375
INFO:root:Train (Epoch 398): Loss/seq after 02550 batchs: 263.85784912109375
INFO:root:Train (Epoch 398): Loss/seq after 02600 batchs: 260.7593994140625
INFO:root:Train (Epoch 398): Loss/seq after 02650 batchs: 258.6533203125
INFO:root:Train (Epoch 398): Loss/seq after 02700 batchs: 257.02880859375
INFO:root:Train (Epoch 398): Loss/seq after 02750 batchs: 254.3950653076172
INFO:root:Train (Epoch 398): Loss/seq after 02800 batchs: 253.19561767578125
INFO:root:Train (Epoch 398): Loss/seq after 02850 batchs: 253.1167755126953
INFO:root:Train (Epoch 398): Loss/seq after 02900 batchs: 253.16860961914062
INFO:root:Train (Epoch 398): Loss/seq after 02950 batchs: 254.35116577148438
INFO:root:Train (Epoch 398): Loss/seq after 03000 batchs: 256.60809326171875
INFO:root:Train (Epoch 398): Loss/seq after 03050 batchs: 257.62664794921875
INFO:root:Train (Epoch 398): Loss/seq after 03100 batchs: 258.6148376464844
INFO:root:Train (Epoch 398): Loss/seq after 03150 batchs: 258.13873291015625
INFO:root:Train (Epoch 398): Loss/seq after 03200 batchs: 259.0670471191406
INFO:root:Train (Epoch 398): Loss/seq after 03250 batchs: 258.5683288574219
INFO:root:Train (Epoch 398): Loss/seq after 03300 batchs: 258.20440673828125
INFO:root:Train (Epoch 398): Loss/seq after 03350 batchs: 256.7016906738281
INFO:root:Train (Epoch 398): Loss/seq after 03400 batchs: 255.1380615234375
INFO:root:Train (Epoch 398): Loss/seq after 03450 batchs: 254.03001403808594
INFO:root:Train (Epoch 398): Loss/seq after 03500 batchs: 254.87680053710938
INFO:root:Train (Epoch 398): Loss/seq after 03550 batchs: 254.0896453857422
INFO:root:Train (Epoch 398): Loss/seq after 03600 batchs: 256.0281677246094
INFO:root:Train (Epoch 398): Loss/seq after 03650 batchs: 254.9539794921875
INFO:root:Train (Epoch 398): Loss/seq after 03700 batchs: 256.0386962890625
INFO:root:Train (Epoch 398): Loss/seq after 03750 batchs: 258.7235107421875
INFO:root:Train (Epoch 398): Loss/seq after 03800 batchs: 259.1285400390625
INFO:root:Train (Epoch 398): Loss/seq after 03850 batchs: 258.8023376464844
INFO:root:Train (Epoch 398): Loss/seq after 03900 batchs: 259.9745788574219
INFO:root:Train (Epoch 398): Loss/seq after 03950 batchs: 261.90045166015625
INFO:root:Train (Epoch 398): Loss/seq after 04000 batchs: 260.9024353027344
INFO:root:Train (Epoch 398): Loss/seq after 04050 batchs: 259.6730651855469
INFO:root:Train (Epoch 398): Loss/seq after 04100 batchs: 258.8581848144531
INFO:root:Train (Epoch 398): Loss/seq after 04150 batchs: 258.7391662597656
INFO:root:Train (Epoch 398): Loss/seq after 04200 batchs: 258.48333740234375
INFO:root:Train (Epoch 398): Loss/seq after 04250 batchs: 257.7669677734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 398): Loss/seq after 00000 batches: 221.6215057373047
INFO:root:# Valid (Epoch 398): Loss/seq after 00050 batches: 620.6586303710938
INFO:root:# Valid (Epoch 398): Loss/seq after 00100 batches: 637.718994140625
INFO:root:# Valid (Epoch 398): Loss/seq after 00150 batches: 476.6971130371094
INFO:root:# Valid (Epoch 398): Loss/seq after 00200 batches: 442.727783203125
INFO:root:Artifacts: Make stick videos for epoch 398
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_398_on_20220424_050126.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_398_index_1037_on_20220424_050126.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 399): Loss/seq after 00000 batchs: 513.3916015625
INFO:root:Train (Epoch 399): Loss/seq after 00050 batchs: 343.7023010253906
INFO:root:Train (Epoch 399): Loss/seq after 00100 batchs: 351.609130859375
INFO:root:Train (Epoch 399): Loss/seq after 00150 batchs: 333.7025146484375
INFO:root:Train (Epoch 399): Loss/seq after 00200 batchs: 366.1606750488281
INFO:root:Train (Epoch 399): Loss/seq after 00250 batchs: 374.5155029296875
INFO:root:Train (Epoch 399): Loss/seq after 00300 batchs: 393.15484619140625
INFO:root:Train (Epoch 399): Loss/seq after 00350 batchs: 377.2216491699219
INFO:root:Train (Epoch 399): Loss/seq after 00400 batchs: 374.530517578125
INFO:root:Train (Epoch 399): Loss/seq after 00450 batchs: 390.96240234375
INFO:root:Train (Epoch 399): Loss/seq after 00500 batchs: 380.48590087890625
INFO:root:Train (Epoch 399): Loss/seq after 00550 batchs: 376.44158935546875
INFO:root:Train (Epoch 399): Loss/seq after 00600 batchs: 362.24237060546875
INFO:root:Train (Epoch 399): Loss/seq after 00650 batchs: 347.9817810058594
INFO:root:Train (Epoch 399): Loss/seq after 00700 batchs: 334.12701416015625
INFO:root:Train (Epoch 399): Loss/seq after 00750 batchs: 329.1769714355469
INFO:root:Train (Epoch 399): Loss/seq after 00800 batchs: 327.9925537109375
INFO:root:Train (Epoch 399): Loss/seq after 00850 batchs: 317.0980529785156
INFO:root:Train (Epoch 399): Loss/seq after 00900 batchs: 308.8831481933594
INFO:root:Train (Epoch 399): Loss/seq after 00950 batchs: 308.936279296875
INFO:root:Train (Epoch 399): Loss/seq after 01000 batchs: 302.85101318359375
INFO:root:Train (Epoch 399): Loss/seq after 01050 batchs: 296.24169921875
INFO:root:Train (Epoch 399): Loss/seq after 01100 batchs: 288.8283996582031
INFO:root:Train (Epoch 399): Loss/seq after 01150 batchs: 280.80987548828125
INFO:root:Train (Epoch 399): Loss/seq after 01200 batchs: 279.8911437988281
INFO:root:Train (Epoch 399): Loss/seq after 01250 batchs: 279.19873046875
INFO:root:Train (Epoch 399): Loss/seq after 01300 batchs: 273.4405822753906
INFO:root:Train (Epoch 399): Loss/seq after 01350 batchs: 267.4932861328125
INFO:root:Train (Epoch 399): Loss/seq after 01400 batchs: 268.8582763671875
INFO:root:Train (Epoch 399): Loss/seq after 01450 batchs: 270.2002868652344
INFO:root:Train (Epoch 399): Loss/seq after 01500 batchs: 274.6592712402344
INFO:root:Train (Epoch 399): Loss/seq after 01550 batchs: 275.4433288574219
INFO:root:Train (Epoch 399): Loss/seq after 01600 batchs: 274.7925720214844
INFO:root:Train (Epoch 399): Loss/seq after 01650 batchs: 273.9593811035156
INFO:root:Train (Epoch 399): Loss/seq after 01700 batchs: 274.4931640625
INFO:root:Train (Epoch 399): Loss/seq after 01750 batchs: 273.7768249511719
INFO:root:Train (Epoch 399): Loss/seq after 01800 batchs: 273.1468505859375
INFO:root:Train (Epoch 399): Loss/seq after 01850 batchs: 272.65997314453125
INFO:root:Train (Epoch 399): Loss/seq after 01900 batchs: 272.6478576660156
INFO:root:Train (Epoch 399): Loss/seq after 01950 batchs: 273.2001647949219
INFO:root:Train (Epoch 399): Loss/seq after 02000 batchs: 275.2958068847656
INFO:root:Train (Epoch 399): Loss/seq after 02050 batchs: 276.2196960449219
INFO:root:Train (Epoch 399): Loss/seq after 02100 batchs: 276.1605529785156
INFO:root:Train (Epoch 399): Loss/seq after 02150 batchs: 276.59222412109375
INFO:root:Train (Epoch 399): Loss/seq after 02200 batchs: 276.37225341796875
INFO:root:Train (Epoch 399): Loss/seq after 02250 batchs: 275.8130187988281
INFO:root:Train (Epoch 399): Loss/seq after 02300 batchs: 274.27130126953125
INFO:root:Train (Epoch 399): Loss/seq after 02350 batchs: 272.7859191894531
INFO:root:Train (Epoch 399): Loss/seq after 02400 batchs: 272.2196350097656
INFO:root:Train (Epoch 399): Loss/seq after 02450 batchs: 270.43450927734375
INFO:root:Train (Epoch 399): Loss/seq after 02500 batchs: 265.9625549316406
INFO:root:Train (Epoch 399): Loss/seq after 02550 batchs: 262.0604248046875
INFO:root:Train (Epoch 399): Loss/seq after 02600 batchs: 258.92205810546875
INFO:root:Train (Epoch 399): Loss/seq after 02650 batchs: 256.1214599609375
INFO:root:Train (Epoch 399): Loss/seq after 02700 batchs: 254.2427978515625
INFO:root:Train (Epoch 399): Loss/seq after 02750 batchs: 251.364990234375
INFO:root:Train (Epoch 399): Loss/seq after 02800 batchs: 250.02064514160156
INFO:root:Train (Epoch 399): Loss/seq after 02850 batchs: 249.6492919921875
INFO:root:Train (Epoch 399): Loss/seq after 02900 batchs: 249.8094940185547
INFO:root:Train (Epoch 399): Loss/seq after 02950 batchs: 250.91555786132812
INFO:root:Train (Epoch 399): Loss/seq after 03000 batchs: 253.40478515625
INFO:root:Train (Epoch 399): Loss/seq after 03050 batchs: 254.42337036132812
INFO:root:Train (Epoch 399): Loss/seq after 03100 batchs: 256.2597351074219
INFO:root:Train (Epoch 399): Loss/seq after 03150 batchs: 256.1593933105469
INFO:root:Train (Epoch 399): Loss/seq after 03200 batchs: 255.9213409423828
INFO:root:Train (Epoch 399): Loss/seq after 03250 batchs: 255.65533447265625
INFO:root:Train (Epoch 399): Loss/seq after 03300 batchs: 255.61178588867188
INFO:root:Train (Epoch 399): Loss/seq after 03350 batchs: 254.61495971679688
INFO:root:Train (Epoch 399): Loss/seq after 03400 batchs: 253.116455078125
INFO:root:Train (Epoch 399): Loss/seq after 03450 batchs: 251.85818481445312
INFO:root:Train (Epoch 399): Loss/seq after 03500 batchs: 252.8324737548828
INFO:root:Train (Epoch 399): Loss/seq after 03550 batchs: 252.17431640625
INFO:root:Train (Epoch 399): Loss/seq after 03600 batchs: 254.2174835205078
INFO:root:Train (Epoch 399): Loss/seq after 03650 batchs: 253.41102600097656
INFO:root:Train (Epoch 399): Loss/seq after 03700 batchs: 254.5306854248047
INFO:root:Train (Epoch 399): Loss/seq after 03750 batchs: 257.09344482421875
INFO:root:Train (Epoch 399): Loss/seq after 03800 batchs: 257.5707702636719
INFO:root:Train (Epoch 399): Loss/seq after 03850 batchs: 257.354248046875
INFO:root:Train (Epoch 399): Loss/seq after 03900 batchs: 258.4519958496094
INFO:root:Train (Epoch 399): Loss/seq after 03950 batchs: 260.51898193359375
INFO:root:Train (Epoch 399): Loss/seq after 04000 batchs: 259.515380859375
INFO:root:Train (Epoch 399): Loss/seq after 04050 batchs: 258.2803955078125
INFO:root:Train (Epoch 399): Loss/seq after 04100 batchs: 257.505126953125
INFO:root:Train (Epoch 399): Loss/seq after 04150 batchs: 257.2873840332031
INFO:root:Train (Epoch 399): Loss/seq after 04200 batchs: 256.91644287109375
INFO:root:Train (Epoch 399): Loss/seq after 04250 batchs: 256.17132568359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 399): Loss/seq after 00000 batches: 186.84872436523438
INFO:root:# Valid (Epoch 399): Loss/seq after 00050 batches: 629.8702392578125
INFO:root:# Valid (Epoch 399): Loss/seq after 00100 batches: 631.4772338867188
INFO:root:# Valid (Epoch 399): Loss/seq after 00150 batches: 470.56036376953125
INFO:root:# Valid (Epoch 399): Loss/seq after 00200 batches: 441.22003173828125
INFO:root:Artifacts: Make stick videos for epoch 399
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_399_on_20220424_050609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_399_index_333_on_20220424_050609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Done training.
wandb: Waiting for W&B process to finish... (success).
wandb: - 775.501 MB of 775.501 MB uploaded (0.000 MB deduped)wandb: \ 775.501 MB of 775.501 MB uploaded (0.000 MB deduped)wandb: | 775.501 MB of 775.501 MB uploaded (0.000 MB deduped)wandb: / 775.501 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: - 775.501 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: \ 776.145 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: | 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: / 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: - 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: \ 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: | 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: / 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: - 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: \ 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb: | 778.471 MB of 778.471 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       loss █▆▅▅▅▅▅▅▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▃▂▂▂▂▁▁▁▁▁▁▁▂▂▁▁
wandb: valid_loss ▅▇▆▆█▅▆█▅▆▆▅▆▆▅▆▃▃▄▃▃▄▃▃▄▂▄▂▃▄▁▃▄▃▃▄▂▃▁▃
wandb: 
wandb: Run summary:
wandb:      epoch 399
wandb:       loss 256.17133
wandb: valid_loss 441.22003
wandb: 
wandb: Synced fine-wave-14: https://wandb.ai/bioshape-lab/move/runs/3dzw8hg1
wandb: Synced 6 W&B file(s), 0 media file(s), 800 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220422_203716-3dzw8hg1/logs

