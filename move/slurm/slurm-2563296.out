wandb: Starting wandb agent 🕵️
2022-04-12 18:24:40,583 - wandb.wandb_agent - INFO - Running runs: []
2022-04-12 18:24:40,871 - wandb.wandb_agent - INFO - Agent received command: run
2022-04-12 18:24:40,871 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 8
	learning_rate: 1e-05
2022-04-12 18:24:41,702 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python main.py --batch_size=8 --learning_rate=1e-05
2022-04-12 18:24:46,742 - wandb.wandb_agent - INFO - Running runs: ['pdklsq2h']
INFO:root:Using device cuda
wandb: Currently logged in as: mathildepapillon (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
TORCH
1.10.0+cu102
wandb: wandb version 0.12.14 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run polished-sweep-2
wandb: ⭐️ View project at https://wandb.ai/mathildepapillon/move-move
wandb: 🧹 View sweep at https://wandb.ai/mathildepapillon/move-move/sweeps/tld50t54
wandb: 🚀 View run at https://wandb.ai/mathildepapillon/move-move/runs/pdklsq2h
wandb: Run data is saved locally in /home/papillon/move/move/wandb/run-20220412_182535-pdklsq2h
wandb: Run `wandb offline` to turn off syncing.
INFO:root:Config: {config}
INFO:root:Run server specific commands
INFO:root:Initialize model
INFO:root:Loading raw datasets:
INFO:root:- data/mariel_betternot_and_retrograde.npy of shape (9925, 53, 3)
INFO:root:- data/mariel_beyond.npy of shape (5803, 53, 3)
INFO:root:- data/mariel_chunli.npy of shape (3866, 53, 3)
INFO:root:- data/mariel_honey.npy of shape (5309, 53, 3)
INFO:root:- data/mariel_knownbetter.npy of shape (6649, 53, 3)
INFO:root:- data/mariel_penelope.npy of shape (6757, 53, 3)
INFO:root:Preprocessing: Load seq_data of shape (38181, 128, 159)
INFO:root:>> Train ds has shape (34363, 128, 159)
INFO:root:>> Valid ds has shape (1909, 128, 159)
INFO:root:>> Test ds has shape (1909, 128, 159)
INFO:root:Preprocessing: Convert into torch dataloader
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 0): Loss/seq after 00000 batchs: 3881.903564453125
INFO:root:Train (Epoch 0): Loss/seq after 00050 batchs: 7162.7900390625
INFO:root:Train (Epoch 0): Loss/seq after 00100 batchs: 6188.20849609375
INFO:root:Train (Epoch 0): Loss/seq after 00150 batchs: 6225.9833984375
INFO:root:Train (Epoch 0): Loss/seq after 00200 batchs: 5328.00537109375
INFO:root:Train (Epoch 0): Loss/seq after 00250 batchs: 4884.568359375
INFO:root:Train (Epoch 0): Loss/seq after 00300 batchs: 4373.05078125
INFO:root:Train (Epoch 0): Loss/seq after 00350 batchs: 3918.8330078125
INFO:root:Train (Epoch 0): Loss/seq after 00400 batchs: 3898.361083984375
INFO:root:Train (Epoch 0): Loss/seq after 00450 batchs: 3624.689208984375
INFO:root:Train (Epoch 0): Loss/seq after 00500 batchs: 3536.6455078125
INFO:root:Train (Epoch 0): Loss/seq after 00550 batchs: 3336.3310546875
INFO:root:Train (Epoch 0): Loss/seq after 00600 batchs: 3183.512939453125
INFO:root:Train (Epoch 0): Loss/seq after 00650 batchs: 3167.20849609375
INFO:root:Train (Epoch 0): Loss/seq after 00700 batchs: 3149.926025390625
INFO:root:Train (Epoch 0): Loss/seq after 00750 batchs: 3095.13671875
INFO:root:Train (Epoch 0): Loss/seq after 00800 batchs: 3038.593505859375
INFO:root:Train (Epoch 0): Loss/seq after 00850 batchs: 2927.321533203125
INFO:root:Train (Epoch 0): Loss/seq after 00900 batchs: 2877.8779296875
INFO:root:Train (Epoch 0): Loss/seq after 00950 batchs: 2938.74169921875
INFO:root:Train (Epoch 0): Loss/seq after 01000 batchs: 2900.68896484375
INFO:root:Train (Epoch 0): Loss/seq after 01050 batchs: 2844.39404296875
INFO:root:Train (Epoch 0): Loss/seq after 01100 batchs: 2805.87060546875
INFO:root:Train (Epoch 0): Loss/seq after 01150 batchs: 2735.15966796875
INFO:root:Train (Epoch 0): Loss/seq after 01200 batchs: 2676.797119140625
INFO:root:Train (Epoch 0): Loss/seq after 01250 batchs: 2632.348388671875
INFO:root:Train (Epoch 0): Loss/seq after 01300 batchs: 2609.653564453125
INFO:root:Train (Epoch 0): Loss/seq after 01350 batchs: 2575.9453125
INFO:root:Train (Epoch 0): Loss/seq after 01400 batchs: 2600.626953125
INFO:root:Train (Epoch 0): Loss/seq after 01450 batchs: 2562.815185546875
INFO:root:Train (Epoch 0): Loss/seq after 01500 batchs: 2519.215087890625
INFO:root:Train (Epoch 0): Loss/seq after 01550 batchs: 2501.029296875
INFO:root:Train (Epoch 0): Loss/seq after 01600 batchs: 2453.905517578125
INFO:root:Train (Epoch 0): Loss/seq after 01650 batchs: 2425.038330078125
INFO:root:Train (Epoch 0): Loss/seq after 01700 batchs: 2388.564208984375
INFO:root:Train (Epoch 0): Loss/seq after 01750 batchs: 2351.456298828125
INFO:root:Train (Epoch 0): Loss/seq after 01800 batchs: 2313.487060546875
INFO:root:Train (Epoch 0): Loss/seq after 01850 batchs: 2276.4326171875
INFO:root:Train (Epoch 0): Loss/seq after 01900 batchs: 2253.636962890625
INFO:root:Train (Epoch 0): Loss/seq after 01950 batchs: 2227.2392578125
INFO:root:Train (Epoch 0): Loss/seq after 02000 batchs: 2197.873779296875
INFO:root:Train (Epoch 0): Loss/seq after 02050 batchs: 2170.3466796875
INFO:root:Train (Epoch 0): Loss/seq after 02100 batchs: 2140.83935546875
INFO:root:Train (Epoch 0): Loss/seq after 02150 batchs: 2113.14697265625
INFO:root:Train (Epoch 0): Loss/seq after 02200 batchs: 2084.9140625
INFO:root:Train (Epoch 0): Loss/seq after 02250 batchs: 2080.36083984375
INFO:root:Train (Epoch 0): Loss/seq after 02300 batchs: 2073.8623046875
INFO:root:Train (Epoch 0): Loss/seq after 02350 batchs: 2051.15625
INFO:root:Train (Epoch 0): Loss/seq after 02400 batchs: 2033.7642822265625
INFO:root:Train (Epoch 0): Loss/seq after 02450 batchs: 2008.39697265625
INFO:root:Train (Epoch 0): Loss/seq after 02500 batchs: 1977.8580322265625
INFO:root:Train (Epoch 0): Loss/seq after 02550 batchs: 1957.02783203125
INFO:root:Train (Epoch 0): Loss/seq after 02600 batchs: 1946.482666015625
INFO:root:Train (Epoch 0): Loss/seq after 02650 batchs: 1931.8641357421875
INFO:root:Train (Epoch 0): Loss/seq after 02700 batchs: 1919.7406005859375
INFO:root:Train (Epoch 0): Loss/seq after 02750 batchs: 1943.07568359375
INFO:root:Train (Epoch 0): Loss/seq after 02800 batchs: 1947.98486328125
INFO:root:Train (Epoch 0): Loss/seq after 02850 batchs: 1942.87060546875
INFO:root:Train (Epoch 0): Loss/seq after 02900 batchs: 1932.9002685546875
INFO:root:Train (Epoch 0): Loss/seq after 02950 batchs: 1916.4173583984375
INFO:root:Train (Epoch 0): Loss/seq after 03000 batchs: 1904.372802734375
INFO:root:Train (Epoch 0): Loss/seq after 03050 batchs: 1897.4412841796875
INFO:root:Train (Epoch 0): Loss/seq after 03100 batchs: 1910.505126953125
INFO:root:Train (Epoch 0): Loss/seq after 03150 batchs: 1925.9595947265625
INFO:root:Train (Epoch 0): Loss/seq after 03200 batchs: 1931.927978515625
INFO:root:Train (Epoch 0): Loss/seq after 03250 batchs: 1936.90673828125
INFO:root:Train (Epoch 0): Loss/seq after 03300 batchs: 1932.345703125
INFO:root:Train (Epoch 0): Loss/seq after 03350 batchs: 1925.8218994140625
INFO:root:Train (Epoch 0): Loss/seq after 03400 batchs: 1908.55224609375
INFO:root:Train (Epoch 0): Loss/seq after 03450 batchs: 1896.7255859375
INFO:root:Train (Epoch 0): Loss/seq after 03500 batchs: 1892.464111328125
INFO:root:Train (Epoch 0): Loss/seq after 03550 batchs: 1883.6405029296875
INFO:root:Train (Epoch 0): Loss/seq after 03600 batchs: 1883.2894287109375
INFO:root:Train (Epoch 0): Loss/seq after 03650 batchs: 1873.04443359375
INFO:root:Train (Epoch 0): Loss/seq after 03700 batchs: 1865.69775390625
INFO:root:Train (Epoch 0): Loss/seq after 03750 batchs: 1858.3409423828125
INFO:root:Train (Epoch 0): Loss/seq after 03800 batchs: 1844.43798828125
INFO:root:Train (Epoch 0): Loss/seq after 03850 batchs: 1833.5340576171875
INFO:root:Train (Epoch 0): Loss/seq after 03900 batchs: 1839.915771484375
INFO:root:Train (Epoch 0): Loss/seq after 03950 batchs: 1843.614990234375
INFO:root:Train (Epoch 0): Loss/seq after 04000 batchs: 1828.8424072265625
INFO:root:Train (Epoch 0): Loss/seq after 04050 batchs: 1814.3848876953125
INFO:root:Train (Epoch 0): Loss/seq after 04100 batchs: 1805.52783203125
INFO:root:Train (Epoch 0): Loss/seq after 04150 batchs: 1794.5728759765625
INFO:root:Train (Epoch 0): Loss/seq after 04200 batchs: 1785.3577880859375
INFO:root:Train (Epoch 0): Loss/seq after 04250 batchs: 1775.5799560546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 0): Loss/seq after 00000 batches: 1106.6143798828125
INFO:root:# Valid (Epoch 0): Loss/seq after 00050 batches: 1246.4117431640625
INFO:root:# Valid (Epoch 0): Loss/seq after 00100 batches: 1627.5457763671875
INFO:root:# Valid (Epoch 0): Loss/seq after 00150 batches: 1342.3182373046875
INFO:root:# Valid (Epoch 0): Loss/seq after 00200 batches: 1211.6895751953125
INFO:root:Artifacts: Make stick videos for epoch 0
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_0_on_20220412_183126.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_0_index_1516_on_20220412_183126.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 1): Loss/seq after 00000 batchs: 2485.516845703125
INFO:root:Train (Epoch 1): Loss/seq after 00050 batchs: 2035.9520263671875
INFO:root:Train (Epoch 1): Loss/seq after 00100 batchs: 1975.9273681640625
INFO:root:Train (Epoch 1): Loss/seq after 00150 batchs: 1747.4681396484375
INFO:root:Train (Epoch 1): Loss/seq after 00200 batchs: 1862.5142822265625
INFO:root:Train (Epoch 1): Loss/seq after 00250 batchs: 1977.557861328125
INFO:root:Train (Epoch 1): Loss/seq after 00300 batchs: 1858.6976318359375
INFO:root:Train (Epoch 1): Loss/seq after 00350 batchs: 1733.4818115234375
INFO:root:Train (Epoch 1): Loss/seq after 00400 batchs: 1808.012939453125
INFO:root:Train (Epoch 1): Loss/seq after 00450 batchs: 1716.53173828125
INFO:root:Train (Epoch 1): Loss/seq after 00500 batchs: 1814.11767578125
INFO:root:Train (Epoch 1): Loss/seq after 00550 batchs: 1746.0040283203125
INFO:root:Train (Epoch 1): Loss/seq after 00600 batchs: 1714.1761474609375
INFO:root:Train (Epoch 1): Loss/seq after 00650 batchs: 1764.8760986328125
INFO:root:Train (Epoch 1): Loss/seq after 00700 batchs: 1837.806884765625
INFO:root:Train (Epoch 1): Loss/seq after 00750 batchs: 1867.2703857421875
INFO:root:Train (Epoch 1): Loss/seq after 00800 batchs: 1845.500732421875
INFO:root:Train (Epoch 1): Loss/seq after 00850 batchs: 1797.5577392578125
INFO:root:Train (Epoch 1): Loss/seq after 00900 batchs: 1800.76416015625
INFO:root:Train (Epoch 1): Loss/seq after 00950 batchs: 1902.5699462890625
INFO:root:Train (Epoch 1): Loss/seq after 01000 batchs: 1902.894287109375
INFO:root:Train (Epoch 1): Loss/seq after 01050 batchs: 1880.47021484375
INFO:root:Train (Epoch 1): Loss/seq after 01100 batchs: 1873.652587890625
INFO:root:Train (Epoch 1): Loss/seq after 01150 batchs: 1838.9224853515625
INFO:root:Train (Epoch 1): Loss/seq after 01200 batchs: 1813.9708251953125
INFO:root:Train (Epoch 1): Loss/seq after 01250 batchs: 1798.6417236328125
INFO:root:Train (Epoch 1): Loss/seq after 01300 batchs: 1803.6688232421875
INFO:root:Train (Epoch 1): Loss/seq after 01350 batchs: 1796.7821044921875
INFO:root:Train (Epoch 1): Loss/seq after 01400 batchs: 1847.2401123046875
INFO:root:Train (Epoch 1): Loss/seq after 01450 batchs: 1828.6055908203125
INFO:root:Train (Epoch 1): Loss/seq after 01500 batchs: 1806.17626953125
INFO:root:Train (Epoch 1): Loss/seq after 01550 batchs: 1804.4771728515625
INFO:root:Train (Epoch 1): Loss/seq after 01600 batchs: 1775.93701171875
INFO:root:Train (Epoch 1): Loss/seq after 01650 batchs: 1764.8916015625
INFO:root:Train (Epoch 1): Loss/seq after 01700 batchs: 1745.8353271484375
INFO:root:Train (Epoch 1): Loss/seq after 01750 batchs: 1724.410400390625
INFO:root:Train (Epoch 1): Loss/seq after 01800 batchs: 1701.419189453125
INFO:root:Train (Epoch 1): Loss/seq after 01850 batchs: 1678.645263671875
INFO:root:Train (Epoch 1): Loss/seq after 01900 batchs: 1669.3839111328125
INFO:root:Train (Epoch 1): Loss/seq after 01950 batchs: 1656.132080078125
INFO:root:Train (Epoch 1): Loss/seq after 02000 batchs: 1638.9930419921875
INFO:root:Train (Epoch 1): Loss/seq after 02050 batchs: 1623.4522705078125
INFO:root:Train (Epoch 1): Loss/seq after 02100 batchs: 1605.102294921875
INFO:root:Train (Epoch 1): Loss/seq after 02150 batchs: 1588.360107421875
INFO:root:Train (Epoch 1): Loss/seq after 02200 batchs: 1570.5472412109375
INFO:root:Train (Epoch 1): Loss/seq after 02250 batchs: 1574.844482421875
INFO:root:Train (Epoch 1): Loss/seq after 02300 batchs: 1575.64892578125
INFO:root:Train (Epoch 1): Loss/seq after 02350 batchs: 1562.227783203125
INFO:root:Train (Epoch 1): Loss/seq after 02400 batchs: 1553.5379638671875
INFO:root:Train (Epoch 1): Loss/seq after 02450 batchs: 1536.747802734375
INFO:root:Train (Epoch 1): Loss/seq after 02500 batchs: 1514.287841796875
INFO:root:Train (Epoch 1): Loss/seq after 02550 batchs: 1502.908203125
INFO:root:Train (Epoch 1): Loss/seq after 02600 batchs: 1499.482666015625
INFO:root:Train (Epoch 1): Loss/seq after 02650 batchs: 1492.3319091796875
INFO:root:Train (Epoch 1): Loss/seq after 02700 batchs: 1488.55859375
INFO:root:Train (Epoch 1): Loss/seq after 02750 batchs: 1519.11669921875
INFO:root:Train (Epoch 1): Loss/seq after 02800 batchs: 1528.0845947265625
INFO:root:Train (Epoch 1): Loss/seq after 02850 batchs: 1525.353759765625
INFO:root:Train (Epoch 1): Loss/seq after 02900 batchs: 1521.9708251953125
INFO:root:Train (Epoch 1): Loss/seq after 02950 batchs: 1511.604248046875
INFO:root:Train (Epoch 1): Loss/seq after 03000 batchs: 1505.4456787109375
INFO:root:Train (Epoch 1): Loss/seq after 03050 batchs: 1504.106201171875
INFO:root:Train (Epoch 1): Loss/seq after 03100 batchs: 1522.351318359375
INFO:root:Train (Epoch 1): Loss/seq after 03150 batchs: 1543.1982421875
INFO:root:Train (Epoch 1): Loss/seq after 03200 batchs: 1554.8258056640625
INFO:root:Train (Epoch 1): Loss/seq after 03250 batchs: 1565.2835693359375
INFO:root:Train (Epoch 1): Loss/seq after 03300 batchs: 1564.6947021484375
INFO:root:Train (Epoch 1): Loss/seq after 03350 batchs: 1562.5247802734375
INFO:root:Train (Epoch 1): Loss/seq after 03400 batchs: 1549.785400390625
INFO:root:Train (Epoch 1): Loss/seq after 03450 batchs: 1541.5164794921875
INFO:root:Train (Epoch 1): Loss/seq after 03500 batchs: 1538.9801025390625
INFO:root:Train (Epoch 1): Loss/seq after 03550 batchs: 1531.88232421875
INFO:root:Train (Epoch 1): Loss/seq after 03600 batchs: 1535.4505615234375
INFO:root:Train (Epoch 1): Loss/seq after 03650 batchs: 1529.4503173828125
INFO:root:Train (Epoch 1): Loss/seq after 03700 batchs: 1526.1688232421875
INFO:root:Train (Epoch 1): Loss/seq after 03750 batchs: 1522.7364501953125
INFO:root:Train (Epoch 1): Loss/seq after 03800 batchs: 1512.666748046875
INFO:root:Train (Epoch 1): Loss/seq after 03850 batchs: 1505.459716796875
INFO:root:Train (Epoch 1): Loss/seq after 03900 batchs: 1516.213134765625
INFO:root:Train (Epoch 1): Loss/seq after 03950 batchs: 1523.0926513671875
INFO:root:Train (Epoch 1): Loss/seq after 04000 batchs: 1511.2392578125
INFO:root:Train (Epoch 1): Loss/seq after 04050 batchs: 1500.1251220703125
INFO:root:Train (Epoch 1): Loss/seq after 04100 batchs: 1494.5252685546875
INFO:root:Train (Epoch 1): Loss/seq after 04150 batchs: 1486.738525390625
INFO:root:Train (Epoch 1): Loss/seq after 04200 batchs: 1481.113525390625
INFO:root:Train (Epoch 1): Loss/seq after 04250 batchs: 1474.2857666015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 1): Loss/seq after 00000 batches: 1038.7860107421875
INFO:root:# Valid (Epoch 1): Loss/seq after 00050 batches: 1193.1536865234375
INFO:root:# Valid (Epoch 1): Loss/seq after 00100 batches: 1550.518798828125
INFO:root:# Valid (Epoch 1): Loss/seq after 00150 batches: 1275.5166015625
INFO:root:# Valid (Epoch 1): Loss/seq after 00200 batches: 1150.717041015625
INFO:root:Artifacts: Make stick videos for epoch 1
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_1_on_20220412_183651.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_1_index_181_on_20220412_183651.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 2): Loss/seq after 00000 batchs: 2445.211669921875
INFO:root:Train (Epoch 2): Loss/seq after 00050 batchs: 1888.3497314453125
INFO:root:Train (Epoch 2): Loss/seq after 00100 batchs: 1892.5968017578125
INFO:root:Train (Epoch 2): Loss/seq after 00150 batchs: 1682.880126953125
INFO:root:Train (Epoch 2): Loss/seq after 00200 batchs: 1796.5389404296875
INFO:root:Train (Epoch 2): Loss/seq after 00250 batchs: 1929.3253173828125
INFO:root:Train (Epoch 2): Loss/seq after 00300 batchs: 1801.6903076171875
INFO:root:Train (Epoch 2): Loss/seq after 00350 batchs: 1679.27490234375
INFO:root:Train (Epoch 2): Loss/seq after 00400 batchs: 1765.8572998046875
INFO:root:Train (Epoch 2): Loss/seq after 00450 batchs: 1674.0
INFO:root:Train (Epoch 2): Loss/seq after 00500 batchs: 1718.640625
INFO:root:Train (Epoch 2): Loss/seq after 00550 batchs: 1646.2744140625
INFO:root:Train (Epoch 2): Loss/seq after 00600 batchs: 1614.21484375
INFO:root:Train (Epoch 2): Loss/seq after 00650 batchs: 1672.384033203125
INFO:root:Train (Epoch 2): Loss/seq after 00700 batchs: 1750.6678466796875
INFO:root:Train (Epoch 2): Loss/seq after 00750 batchs: 1784.7576904296875
INFO:root:Train (Epoch 2): Loss/seq after 00800 batchs: 1763.3953857421875
INFO:root:Train (Epoch 2): Loss/seq after 00850 batchs: 1718.5743408203125
INFO:root:Train (Epoch 2): Loss/seq after 00900 batchs: 1723.1885986328125
INFO:root:Train (Epoch 2): Loss/seq after 00950 batchs: 1822.096435546875
INFO:root:Train (Epoch 2): Loss/seq after 01000 batchs: 1820.47021484375
INFO:root:Train (Epoch 2): Loss/seq after 01050 batchs: 1798.0631103515625
INFO:root:Train (Epoch 2): Loss/seq after 01100 batchs: 1781.6922607421875
INFO:root:Train (Epoch 2): Loss/seq after 01150 batchs: 1751.845703125
INFO:root:Train (Epoch 2): Loss/seq after 01200 batchs: 1730.5380859375
INFO:root:Train (Epoch 2): Loss/seq after 01250 batchs: 1727.9423828125
INFO:root:Train (Epoch 2): Loss/seq after 01300 batchs: 1734.6593017578125
INFO:root:Train (Epoch 2): Loss/seq after 01350 batchs: 1729.8416748046875
INFO:root:Train (Epoch 2): Loss/seq after 01400 batchs: 1780.096923828125
INFO:root:Train (Epoch 2): Loss/seq after 01450 batchs: 1766.525146484375
INFO:root:Train (Epoch 2): Loss/seq after 01500 batchs: 1744.6585693359375
INFO:root:Train (Epoch 2): Loss/seq after 01550 batchs: 1746.737548828125
INFO:root:Train (Epoch 2): Loss/seq after 01600 batchs: 1719.7474365234375
INFO:root:Train (Epoch 2): Loss/seq after 01650 batchs: 1709.2642822265625
INFO:root:Train (Epoch 2): Loss/seq after 01700 batchs: 1691.25732421875
INFO:root:Train (Epoch 2): Loss/seq after 01750 batchs: 1670.5618896484375
INFO:root:Train (Epoch 2): Loss/seq after 01800 batchs: 1648.248046875
INFO:root:Train (Epoch 2): Loss/seq after 01850 batchs: 1626.041015625
INFO:root:Train (Epoch 2): Loss/seq after 01900 batchs: 1617.300537109375
INFO:root:Train (Epoch 2): Loss/seq after 01950 batchs: 1604.814453125
INFO:root:Train (Epoch 2): Loss/seq after 02000 batchs: 1588.1961669921875
INFO:root:Train (Epoch 2): Loss/seq after 02050 batchs: 1573.34619140625
INFO:root:Train (Epoch 2): Loss/seq after 02100 batchs: 1555.50537109375
INFO:root:Train (Epoch 2): Loss/seq after 02150 batchs: 1539.3087158203125
INFO:root:Train (Epoch 2): Loss/seq after 02200 batchs: 1522.02880859375
INFO:root:Train (Epoch 2): Loss/seq after 02250 batchs: 1529.283447265625
INFO:root:Train (Epoch 2): Loss/seq after 02300 batchs: 1534.0150146484375
INFO:root:Train (Epoch 2): Loss/seq after 02350 batchs: 1521.6492919921875
INFO:root:Train (Epoch 2): Loss/seq after 02400 batchs: 1513.4742431640625
INFO:root:Train (Epoch 2): Loss/seq after 02450 batchs: 1497.1787109375
INFO:root:Train (Epoch 2): Loss/seq after 02500 batchs: 1475.0662841796875
INFO:root:Train (Epoch 2): Loss/seq after 02550 batchs: 1464.755859375
INFO:root:Train (Epoch 2): Loss/seq after 02600 batchs: 1461.6817626953125
INFO:root:Train (Epoch 2): Loss/seq after 02650 batchs: 1454.952880859375
INFO:root:Train (Epoch 2): Loss/seq after 02700 batchs: 1452.356201171875
INFO:root:Train (Epoch 2): Loss/seq after 02750 batchs: 1485.6590576171875
INFO:root:Train (Epoch 2): Loss/seq after 02800 batchs: 1495.8175048828125
INFO:root:Train (Epoch 2): Loss/seq after 02850 batchs: 1494.715576171875
INFO:root:Train (Epoch 2): Loss/seq after 02900 batchs: 1490.7607421875
INFO:root:Train (Epoch 2): Loss/seq after 02950 batchs: 1480.530029296875
INFO:root:Train (Epoch 2): Loss/seq after 03000 batchs: 1474.4755859375
INFO:root:Train (Epoch 2): Loss/seq after 03050 batchs: 1473.2432861328125
INFO:root:Train (Epoch 2): Loss/seq after 03100 batchs: 1491.1934814453125
INFO:root:Train (Epoch 2): Loss/seq after 03150 batchs: 1512.57080078125
INFO:root:Train (Epoch 2): Loss/seq after 03200 batchs: 1524.4971923828125
INFO:root:Train (Epoch 2): Loss/seq after 03250 batchs: 1535.325439453125
INFO:root:Train (Epoch 2): Loss/seq after 03300 batchs: 1535.6337890625
INFO:root:Train (Epoch 2): Loss/seq after 03350 batchs: 1533.6485595703125
INFO:root:Train (Epoch 2): Loss/seq after 03400 batchs: 1521.1248779296875
INFO:root:Train (Epoch 2): Loss/seq after 03450 batchs: 1512.3499755859375
INFO:root:Train (Epoch 2): Loss/seq after 03500 batchs: 1511.8675537109375
INFO:root:Train (Epoch 2): Loss/seq after 03550 batchs: 1504.9044189453125
INFO:root:Train (Epoch 2): Loss/seq after 03600 batchs: 1508.169921875
INFO:root:Train (Epoch 2): Loss/seq after 03650 batchs: 1502.3155517578125
INFO:root:Train (Epoch 2): Loss/seq after 03700 batchs: 1499.2408447265625
INFO:root:Train (Epoch 2): Loss/seq after 03750 batchs: 1495.9217529296875
INFO:root:Train (Epoch 2): Loss/seq after 03800 batchs: 1486.0079345703125
INFO:root:Train (Epoch 2): Loss/seq after 03850 batchs: 1478.9156494140625
INFO:root:Train (Epoch 2): Loss/seq after 03900 batchs: 1489.122802734375
INFO:root:Train (Epoch 2): Loss/seq after 03950 batchs: 1496.1676025390625
INFO:root:Train (Epoch 2): Loss/seq after 04000 batchs: 1484.38671875
INFO:root:Train (Epoch 2): Loss/seq after 04050 batchs: 1473.3931884765625
INFO:root:Train (Epoch 2): Loss/seq after 04100 batchs: 1467.790283203125
INFO:root:Train (Epoch 2): Loss/seq after 04150 batchs: 1460.0810546875
INFO:root:Train (Epoch 2): Loss/seq after 04200 batchs: 1453.9061279296875
INFO:root:Train (Epoch 2): Loss/seq after 04250 batchs: 1447.3504638671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 2): Loss/seq after 00000 batches: 1046.0218505859375
INFO:root:# Valid (Epoch 2): Loss/seq after 00050 batches: 1177.4002685546875
INFO:root:# Valid (Epoch 2): Loss/seq after 00100 batches: 1532.8045654296875
INFO:root:# Valid (Epoch 2): Loss/seq after 00150 batches: 1260.4757080078125
INFO:root:# Valid (Epoch 2): Loss/seq after 00200 batches: 1135.07470703125
INFO:root:Artifacts: Make stick videos for epoch 2
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_2_on_20220412_184213.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_2_index_1077_on_20220412_184213.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 3): Loss/seq after 00000 batchs: 2426.908447265625
INFO:root:Train (Epoch 3): Loss/seq after 00050 batchs: 1965.9129638671875
INFO:root:Train (Epoch 3): Loss/seq after 00100 batchs: 1980.40478515625
INFO:root:Train (Epoch 3): Loss/seq after 00150 batchs: 1733.7108154296875
INFO:root:Train (Epoch 3): Loss/seq after 00200 batchs: 1867.4962158203125
INFO:root:Train (Epoch 3): Loss/seq after 00250 batchs: 2016.191162109375
INFO:root:Train (Epoch 3): Loss/seq after 00300 batchs: 1908.849365234375
INFO:root:Train (Epoch 3): Loss/seq after 00350 batchs: 1770.74267578125
INFO:root:Train (Epoch 3): Loss/seq after 00400 batchs: 1872.7969970703125
INFO:root:Train (Epoch 3): Loss/seq after 00450 batchs: 1774.201171875
INFO:root:Train (Epoch 3): Loss/seq after 00500 batchs: 1833.01220703125
INFO:root:Train (Epoch 3): Loss/seq after 00550 batchs: 1756.613037109375
INFO:root:Train (Epoch 3): Loss/seq after 00600 batchs: 1714.282958984375
INFO:root:Train (Epoch 3): Loss/seq after 00650 batchs: 1763.8203125
INFO:root:Train (Epoch 3): Loss/seq after 00700 batchs: 1834.158447265625
INFO:root:Train (Epoch 3): Loss/seq after 00750 batchs: 1862.3504638671875
INFO:root:Train (Epoch 3): Loss/seq after 00800 batchs: 1836.1317138671875
INFO:root:Train (Epoch 3): Loss/seq after 00850 batchs: 1785.9949951171875
INFO:root:Train (Epoch 3): Loss/seq after 00900 batchs: 1791.1654052734375
INFO:root:Train (Epoch 3): Loss/seq after 00950 batchs: 1891.6844482421875
INFO:root:Train (Epoch 3): Loss/seq after 01000 batchs: 1891.447998046875
INFO:root:Train (Epoch 3): Loss/seq after 01050 batchs: 1874.8265380859375
INFO:root:Train (Epoch 3): Loss/seq after 01100 batchs: 1860.1922607421875
INFO:root:Train (Epoch 3): Loss/seq after 01150 batchs: 1825.2515869140625
INFO:root:Train (Epoch 3): Loss/seq after 01200 batchs: 1799.11962890625
INFO:root:Train (Epoch 3): Loss/seq after 01250 batchs: 1785.828369140625
INFO:root:Train (Epoch 3): Loss/seq after 01300 batchs: 1790.582275390625
INFO:root:Train (Epoch 3): Loss/seq after 01350 batchs: 1783.48583984375
INFO:root:Train (Epoch 3): Loss/seq after 01400 batchs: 1833.51171875
INFO:root:Train (Epoch 3): Loss/seq after 01450 batchs: 1814.578369140625
INFO:root:Train (Epoch 3): Loss/seq after 01500 batchs: 1791.1273193359375
INFO:root:Train (Epoch 3): Loss/seq after 01550 batchs: 1789.8411865234375
INFO:root:Train (Epoch 3): Loss/seq after 01600 batchs: 1760.5281982421875
INFO:root:Train (Epoch 3): Loss/seq after 01650 batchs: 1746.5809326171875
INFO:root:Train (Epoch 3): Loss/seq after 01700 batchs: 1727.948974609375
INFO:root:Train (Epoch 3): Loss/seq after 01750 batchs: 1705.5255126953125
INFO:root:Train (Epoch 3): Loss/seq after 01800 batchs: 1681.8516845703125
INFO:root:Train (Epoch 3): Loss/seq after 01850 batchs: 1658.3507080078125
INFO:root:Train (Epoch 3): Loss/seq after 01900 batchs: 1648.34619140625
INFO:root:Train (Epoch 3): Loss/seq after 01950 batchs: 1634.7841796875
INFO:root:Train (Epoch 3): Loss/seq after 02000 batchs: 1617.06591796875
INFO:root:Train (Epoch 3): Loss/seq after 02050 batchs: 1601.228271484375
INFO:root:Train (Epoch 3): Loss/seq after 02100 batchs: 1582.4482421875
INFO:root:Train (Epoch 3): Loss/seq after 02150 batchs: 1565.3260498046875
INFO:root:Train (Epoch 3): Loss/seq after 02200 batchs: 1547.2099609375
INFO:root:Train (Epoch 3): Loss/seq after 02250 batchs: 1551.601806640625
INFO:root:Train (Epoch 3): Loss/seq after 02300 batchs: 1553.606201171875
INFO:root:Train (Epoch 3): Loss/seq after 02350 batchs: 1539.726318359375
INFO:root:Train (Epoch 3): Loss/seq after 02400 batchs: 1530.76953125
INFO:root:Train (Epoch 3): Loss/seq after 02450 batchs: 1513.8111572265625
INFO:root:Train (Epoch 3): Loss/seq after 02500 batchs: 1491.174560546875
INFO:root:Train (Epoch 3): Loss/seq after 02550 batchs: 1478.8392333984375
INFO:root:Train (Epoch 3): Loss/seq after 02600 batchs: 1474.2327880859375
INFO:root:Train (Epoch 3): Loss/seq after 02650 batchs: 1465.61376953125
INFO:root:Train (Epoch 3): Loss/seq after 02700 batchs: 1460.4613037109375
INFO:root:Train (Epoch 3): Loss/seq after 02750 batchs: 1493.847412109375
INFO:root:Train (Epoch 3): Loss/seq after 02800 batchs: 1502.70703125
INFO:root:Train (Epoch 3): Loss/seq after 02850 batchs: 1498.2056884765625
INFO:root:Train (Epoch 3): Loss/seq after 02900 batchs: 1494.161376953125
INFO:root:Train (Epoch 3): Loss/seq after 02950 batchs: 1483.3536376953125
INFO:root:Train (Epoch 3): Loss/seq after 03000 batchs: 1477.0679931640625
INFO:root:Train (Epoch 3): Loss/seq after 03050 batchs: 1475.7529296875
INFO:root:Train (Epoch 3): Loss/seq after 03100 batchs: 1494.5172119140625
INFO:root:Train (Epoch 3): Loss/seq after 03150 batchs: 1514.4315185546875
INFO:root:Train (Epoch 3): Loss/seq after 03200 batchs: 1526.0704345703125
INFO:root:Train (Epoch 3): Loss/seq after 03250 batchs: 1536.951416015625
INFO:root:Train (Epoch 3): Loss/seq after 03300 batchs: 1536.8543701171875
INFO:root:Train (Epoch 3): Loss/seq after 03350 batchs: 1535.520751953125
INFO:root:Train (Epoch 3): Loss/seq after 03400 batchs: 1522.781005859375
INFO:root:Train (Epoch 3): Loss/seq after 03450 batchs: 1514.3619384765625
INFO:root:Train (Epoch 3): Loss/seq after 03500 batchs: 1513.175537109375
INFO:root:Train (Epoch 3): Loss/seq after 03550 batchs: 1506.0494384765625
INFO:root:Train (Epoch 3): Loss/seq after 03600 batchs: 1509.61474609375
INFO:root:Train (Epoch 3): Loss/seq after 03650 batchs: 1503.514404296875
INFO:root:Train (Epoch 3): Loss/seq after 03700 batchs: 1500.4019775390625
INFO:root:Train (Epoch 3): Loss/seq after 03750 batchs: 1496.97509765625
INFO:root:Train (Epoch 3): Loss/seq after 03800 batchs: 1486.99365234375
INFO:root:Train (Epoch 3): Loss/seq after 03850 batchs: 1479.7928466796875
INFO:root:Train (Epoch 3): Loss/seq after 03900 batchs: 1488.3447265625
INFO:root:Train (Epoch 3): Loss/seq after 03950 batchs: 1495.8660888671875
INFO:root:Train (Epoch 3): Loss/seq after 04000 batchs: 1484.0047607421875
INFO:root:Train (Epoch 3): Loss/seq after 04050 batchs: 1472.9036865234375
INFO:root:Train (Epoch 3): Loss/seq after 04100 batchs: 1467.207275390625
INFO:root:Train (Epoch 3): Loss/seq after 04150 batchs: 1459.3912353515625
INFO:root:Train (Epoch 3): Loss/seq after 04200 batchs: 1453.1453857421875
INFO:root:Train (Epoch 3): Loss/seq after 04250 batchs: 1446.524658203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 3): Loss/seq after 00000 batches: 1035.6851806640625
INFO:root:# Valid (Epoch 3): Loss/seq after 00050 batches: 1169.1092529296875
INFO:root:# Valid (Epoch 3): Loss/seq after 00100 batches: 1534.570068359375
INFO:root:# Valid (Epoch 3): Loss/seq after 00150 batches: 1257.5330810546875
INFO:root:# Valid (Epoch 3): Loss/seq after 00200 batches: 1130.7772216796875
INFO:root:Artifacts: Make stick videos for epoch 3
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_3_on_20220412_184737.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_3_index_576_on_20220412_184737.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 4): Loss/seq after 00000 batchs: 2367.244384765625
INFO:root:Train (Epoch 4): Loss/seq after 00050 batchs: 1927.7208251953125
INFO:root:Train (Epoch 4): Loss/seq after 00100 batchs: 1909.3021240234375
INFO:root:Train (Epoch 4): Loss/seq after 00150 batchs: 1691.1473388671875
INFO:root:Train (Epoch 4): Loss/seq after 00200 batchs: 1794.869384765625
INFO:root:Train (Epoch 4): Loss/seq after 00250 batchs: 1899.32177734375
INFO:root:Train (Epoch 4): Loss/seq after 00300 batchs: 1783.2701416015625
INFO:root:Train (Epoch 4): Loss/seq after 00350 batchs: 1660.1964111328125
INFO:root:Train (Epoch 4): Loss/seq after 00400 batchs: 1736.3638916015625
INFO:root:Train (Epoch 4): Loss/seq after 00450 batchs: 1644.736572265625
INFO:root:Train (Epoch 4): Loss/seq after 00500 batchs: 1696.6253662109375
INFO:root:Train (Epoch 4): Loss/seq after 00550 batchs: 1623.190673828125
INFO:root:Train (Epoch 4): Loss/seq after 00600 batchs: 1583.6400146484375
INFO:root:Train (Epoch 4): Loss/seq after 00650 batchs: 1642.6243896484375
INFO:root:Train (Epoch 4): Loss/seq after 00700 batchs: 1722.9755859375
INFO:root:Train (Epoch 4): Loss/seq after 00750 batchs: 1758.0120849609375
INFO:root:Train (Epoch 4): Loss/seq after 00800 batchs: 1735.82177734375
INFO:root:Train (Epoch 4): Loss/seq after 00850 batchs: 1691.55419921875
INFO:root:Train (Epoch 4): Loss/seq after 00900 batchs: 1699.7496337890625
INFO:root:Train (Epoch 4): Loss/seq after 00950 batchs: 1799.716552734375
INFO:root:Train (Epoch 4): Loss/seq after 01000 batchs: 1800.653564453125
INFO:root:Train (Epoch 4): Loss/seq after 01050 batchs: 1782.550048828125
INFO:root:Train (Epoch 4): Loss/seq after 01100 batchs: 1770.0269775390625
INFO:root:Train (Epoch 4): Loss/seq after 01150 batchs: 1738.11669921875
INFO:root:Train (Epoch 4): Loss/seq after 01200 batchs: 1715.177001953125
INFO:root:Train (Epoch 4): Loss/seq after 01250 batchs: 1700.67529296875
INFO:root:Train (Epoch 4): Loss/seq after 01300 batchs: 1708.0078125
INFO:root:Train (Epoch 4): Loss/seq after 01350 batchs: 1703.4449462890625
INFO:root:Train (Epoch 4): Loss/seq after 01400 batchs: 1754.401611328125
INFO:root:Train (Epoch 4): Loss/seq after 01450 batchs: 1734.66845703125
INFO:root:Train (Epoch 4): Loss/seq after 01500 batchs: 1712.962890625
INFO:root:Train (Epoch 4): Loss/seq after 01550 batchs: 1711.05517578125
INFO:root:Train (Epoch 4): Loss/seq after 01600 batchs: 1683.528076171875
INFO:root:Train (Epoch 4): Loss/seq after 01650 batchs: 1670.62744140625
INFO:root:Train (Epoch 4): Loss/seq after 01700 batchs: 1652.8350830078125
INFO:root:Train (Epoch 4): Loss/seq after 01750 batchs: 1632.3626708984375
INFO:root:Train (Epoch 4): Loss/seq after 01800 batchs: 1610.4940185546875
INFO:root:Train (Epoch 4): Loss/seq after 01850 batchs: 1588.7255859375
INFO:root:Train (Epoch 4): Loss/seq after 01900 batchs: 1580.295166015625
INFO:root:Train (Epoch 4): Loss/seq after 01950 batchs: 1568.287841796875
INFO:root:Train (Epoch 4): Loss/seq after 02000 batchs: 1551.9500732421875
INFO:root:Train (Epoch 4): Loss/seq after 02050 batchs: 1537.6982421875
INFO:root:Train (Epoch 4): Loss/seq after 02100 batchs: 1520.252685546875
INFO:root:Train (Epoch 4): Loss/seq after 02150 batchs: 1504.4852294921875
INFO:root:Train (Epoch 4): Loss/seq after 02200 batchs: 1487.598876953125
INFO:root:Train (Epoch 4): Loss/seq after 02250 batchs: 1491.9959716796875
INFO:root:Train (Epoch 4): Loss/seq after 02300 batchs: 1494.3157958984375
INFO:root:Train (Epoch 4): Loss/seq after 02350 batchs: 1481.73828125
INFO:root:Train (Epoch 4): Loss/seq after 02400 batchs: 1473.849609375
INFO:root:Train (Epoch 4): Loss/seq after 02450 batchs: 1457.9627685546875
INFO:root:Train (Epoch 4): Loss/seq after 02500 batchs: 1436.3646240234375
INFO:root:Train (Epoch 4): Loss/seq after 02550 batchs: 1424.7479248046875
INFO:root:Train (Epoch 4): Loss/seq after 02600 batchs: 1421.540771484375
INFO:root:Train (Epoch 4): Loss/seq after 02650 batchs: 1413.6588134765625
INFO:root:Train (Epoch 4): Loss/seq after 02700 batchs: 1408.2061767578125
INFO:root:Train (Epoch 4): Loss/seq after 02750 batchs: 1439.236083984375
INFO:root:Train (Epoch 4): Loss/seq after 02800 batchs: 1447.6923828125
INFO:root:Train (Epoch 4): Loss/seq after 02850 batchs: 1443.361328125
INFO:root:Train (Epoch 4): Loss/seq after 02900 batchs: 1439.220947265625
INFO:root:Train (Epoch 4): Loss/seq after 02950 batchs: 1428.7838134765625
INFO:root:Train (Epoch 4): Loss/seq after 03000 batchs: 1423.2528076171875
INFO:root:Train (Epoch 4): Loss/seq after 03050 batchs: 1422.7064208984375
INFO:root:Train (Epoch 4): Loss/seq after 03100 batchs: 1440.6573486328125
INFO:root:Train (Epoch 4): Loss/seq after 03150 batchs: 1460.2320556640625
INFO:root:Train (Epoch 4): Loss/seq after 03200 batchs: 1472.5860595703125
INFO:root:Train (Epoch 4): Loss/seq after 03250 batchs: 1483.99072265625
INFO:root:Train (Epoch 4): Loss/seq after 03300 batchs: 1482.0582275390625
INFO:root:Train (Epoch 4): Loss/seq after 03350 batchs: 1480.248779296875
INFO:root:Train (Epoch 4): Loss/seq after 03400 batchs: 1468.2509765625
INFO:root:Train (Epoch 4): Loss/seq after 03450 batchs: 1459.6741943359375
INFO:root:Train (Epoch 4): Loss/seq after 03500 batchs: 1457.119140625
INFO:root:Train (Epoch 4): Loss/seq after 03550 batchs: 1449.8834228515625
INFO:root:Train (Epoch 4): Loss/seq after 03600 batchs: 1453.1834716796875
INFO:root:Train (Epoch 4): Loss/seq after 03650 batchs: 1447.1031494140625
INFO:root:Train (Epoch 4): Loss/seq after 03700 batchs: 1444.17138671875
INFO:root:Train (Epoch 4): Loss/seq after 03750 batchs: 1441.3380126953125
INFO:root:Train (Epoch 4): Loss/seq after 03800 batchs: 1431.8197021484375
INFO:root:Train (Epoch 4): Loss/seq after 03850 batchs: 1425.0377197265625
INFO:root:Train (Epoch 4): Loss/seq after 03900 batchs: 1431.47021484375
INFO:root:Train (Epoch 4): Loss/seq after 03950 batchs: 1438.866943359375
INFO:root:Train (Epoch 4): Loss/seq after 04000 batchs: 1427.3409423828125
INFO:root:Train (Epoch 4): Loss/seq after 04050 batchs: 1416.856689453125
INFO:root:Train (Epoch 4): Loss/seq after 04100 batchs: 1411.4034423828125
INFO:root:Train (Epoch 4): Loss/seq after 04150 batchs: 1404.25048828125
INFO:root:Train (Epoch 4): Loss/seq after 04200 batchs: 1397.5555419921875
INFO:root:Train (Epoch 4): Loss/seq after 04250 batchs: 1391.2574462890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 4): Loss/seq after 00000 batches: 963.958740234375
INFO:root:# Valid (Epoch 4): Loss/seq after 00050 batches: 1134.1717529296875
INFO:root:# Valid (Epoch 4): Loss/seq after 00100 batches: 1481.207275390625
INFO:root:# Valid (Epoch 4): Loss/seq after 00150 batches: 1234.991455078125
INFO:root:# Valid (Epoch 4): Loss/seq after 00200 batches: 1119.4471435546875
INFO:root:Artifacts: Make stick videos for epoch 4
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_4_on_20220412_185301.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_4_index_1029_on_20220412_185301.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 5): Loss/seq after 00000 batchs: 2370.30078125
INFO:root:Train (Epoch 5): Loss/seq after 00050 batchs: 1853.4388427734375
INFO:root:Train (Epoch 5): Loss/seq after 00100 batchs: 1838.941162109375
INFO:root:Train (Epoch 5): Loss/seq after 00150 batchs: 1605.1280517578125
INFO:root:Train (Epoch 5): Loss/seq after 00200 batchs: 1732.334228515625
INFO:root:Train (Epoch 5): Loss/seq after 00250 batchs: 1849.501953125
INFO:root:Train (Epoch 5): Loss/seq after 00300 batchs: 1731.0958251953125
INFO:root:Train (Epoch 5): Loss/seq after 00350 batchs: 1611.4449462890625
INFO:root:Train (Epoch 5): Loss/seq after 00400 batchs: 1671.6754150390625
INFO:root:Train (Epoch 5): Loss/seq after 00450 batchs: 1584.7109375
INFO:root:Train (Epoch 5): Loss/seq after 00500 batchs: 1625.3787841796875
INFO:root:Train (Epoch 5): Loss/seq after 00550 batchs: 1554.047119140625
INFO:root:Train (Epoch 5): Loss/seq after 00600 batchs: 1517.1328125
INFO:root:Train (Epoch 5): Loss/seq after 00650 batchs: 1579.193603515625
INFO:root:Train (Epoch 5): Loss/seq after 00700 batchs: 1663.1163330078125
INFO:root:Train (Epoch 5): Loss/seq after 00750 batchs: 1698.7354736328125
INFO:root:Train (Epoch 5): Loss/seq after 00800 batchs: 1678.7159423828125
INFO:root:Train (Epoch 5): Loss/seq after 00850 batchs: 1638.0948486328125
INFO:root:Train (Epoch 5): Loss/seq after 00900 batchs: 1634.6142578125
INFO:root:Train (Epoch 5): Loss/seq after 00950 batchs: 1731.6490478515625
INFO:root:Train (Epoch 5): Loss/seq after 01000 batchs: 1731.83154296875
INFO:root:Train (Epoch 5): Loss/seq after 01050 batchs: 1705.5302734375
INFO:root:Train (Epoch 5): Loss/seq after 01100 batchs: 1691.341064453125
INFO:root:Train (Epoch 5): Loss/seq after 01150 batchs: 1663.079833984375
INFO:root:Train (Epoch 5): Loss/seq after 01200 batchs: 1643.2486572265625
INFO:root:Train (Epoch 5): Loss/seq after 01250 batchs: 1630.4212646484375
INFO:root:Train (Epoch 5): Loss/seq after 01300 batchs: 1640.01953125
INFO:root:Train (Epoch 5): Loss/seq after 01350 batchs: 1637.4161376953125
INFO:root:Train (Epoch 5): Loss/seq after 01400 batchs: 1689.5501708984375
INFO:root:Train (Epoch 5): Loss/seq after 01450 batchs: 1670.5172119140625
INFO:root:Train (Epoch 5): Loss/seq after 01500 batchs: 1650.9407958984375
INFO:root:Train (Epoch 5): Loss/seq after 01550 batchs: 1647.82861328125
INFO:root:Train (Epoch 5): Loss/seq after 01600 batchs: 1622.416015625
INFO:root:Train (Epoch 5): Loss/seq after 01650 batchs: 1610.7166748046875
INFO:root:Train (Epoch 5): Loss/seq after 01700 batchs: 1594.58642578125
INFO:root:Train (Epoch 5): Loss/seq after 01750 batchs: 1575.6744384765625
INFO:root:Train (Epoch 5): Loss/seq after 01800 batchs: 1555.255126953125
INFO:root:Train (Epoch 5): Loss/seq after 01850 batchs: 1534.8741455078125
INFO:root:Train (Epoch 5): Loss/seq after 01900 batchs: 1527.7491455078125
INFO:root:Train (Epoch 5): Loss/seq after 01950 batchs: 1517.190185546875
INFO:root:Train (Epoch 5): Loss/seq after 02000 batchs: 1502.11328125
INFO:root:Train (Epoch 5): Loss/seq after 02050 batchs: 1488.8988037109375
INFO:root:Train (Epoch 5): Loss/seq after 02100 batchs: 1472.5604248046875
INFO:root:Train (Epoch 5): Loss/seq after 02150 batchs: 1457.795654296875
INFO:root:Train (Epoch 5): Loss/seq after 02200 batchs: 1441.89404296875
INFO:root:Train (Epoch 5): Loss/seq after 02250 batchs: 1443.23828125
INFO:root:Train (Epoch 5): Loss/seq after 02300 batchs: 1446.2412109375
INFO:root:Train (Epoch 5): Loss/seq after 02350 batchs: 1434.52587890625
INFO:root:Train (Epoch 5): Loss/seq after 02400 batchs: 1427.5325927734375
INFO:root:Train (Epoch 5): Loss/seq after 02450 batchs: 1412.02490234375
INFO:root:Train (Epoch 5): Loss/seq after 02500 batchs: 1391.265625
INFO:root:Train (Epoch 5): Loss/seq after 02550 batchs: 1378.5987548828125
INFO:root:Train (Epoch 5): Loss/seq after 02600 batchs: 1375.0841064453125
INFO:root:Train (Epoch 5): Loss/seq after 02650 batchs: 1367.5673828125
INFO:root:Train (Epoch 5): Loss/seq after 02700 batchs: 1363.6812744140625
INFO:root:Train (Epoch 5): Loss/seq after 02750 batchs: 1393.0528564453125
INFO:root:Train (Epoch 5): Loss/seq after 02800 batchs: 1401.4161376953125
INFO:root:Train (Epoch 5): Loss/seq after 02850 batchs: 1397.0447998046875
INFO:root:Train (Epoch 5): Loss/seq after 02900 batchs: 1392.967041015625
INFO:root:Train (Epoch 5): Loss/seq after 02950 batchs: 1383.2269287109375
INFO:root:Train (Epoch 5): Loss/seq after 03000 batchs: 1378.381103515625
INFO:root:Train (Epoch 5): Loss/seq after 03050 batchs: 1378.4945068359375
INFO:root:Train (Epoch 5): Loss/seq after 03100 batchs: 1397.1429443359375
INFO:root:Train (Epoch 5): Loss/seq after 03150 batchs: 1416.6845703125
INFO:root:Train (Epoch 5): Loss/seq after 03200 batchs: 1429.6854248046875
INFO:root:Train (Epoch 5): Loss/seq after 03250 batchs: 1441.5888671875
INFO:root:Train (Epoch 5): Loss/seq after 03300 batchs: 1439.7659912109375
INFO:root:Train (Epoch 5): Loss/seq after 03350 batchs: 1437.84375
INFO:root:Train (Epoch 5): Loss/seq after 03400 batchs: 1426.4344482421875
INFO:root:Train (Epoch 5): Loss/seq after 03450 batchs: 1418.3670654296875
INFO:root:Train (Epoch 5): Loss/seq after 03500 batchs: 1416.462158203125
INFO:root:Train (Epoch 5): Loss/seq after 03550 batchs: 1409.8294677734375
INFO:root:Train (Epoch 5): Loss/seq after 03600 batchs: 1414.2579345703125
INFO:root:Train (Epoch 5): Loss/seq after 03650 batchs: 1408.4010009765625
INFO:root:Train (Epoch 5): Loss/seq after 03700 batchs: 1406.3505859375
INFO:root:Train (Epoch 5): Loss/seq after 03750 batchs: 1404.11865234375
INFO:root:Train (Epoch 5): Loss/seq after 03800 batchs: 1395.1571044921875
INFO:root:Train (Epoch 5): Loss/seq after 03850 batchs: 1388.9765625
INFO:root:Train (Epoch 5): Loss/seq after 03900 batchs: 1395.828857421875
INFO:root:Train (Epoch 5): Loss/seq after 03950 batchs: 1403.864501953125
INFO:root:Train (Epoch 5): Loss/seq after 04000 batchs: 1392.717529296875
INFO:root:Train (Epoch 5): Loss/seq after 04050 batchs: 1382.634033203125
INFO:root:Train (Epoch 5): Loss/seq after 04100 batchs: 1377.7017822265625
INFO:root:Train (Epoch 5): Loss/seq after 04150 batchs: 1370.914306640625
INFO:root:Train (Epoch 5): Loss/seq after 04200 batchs: 1365.2796630859375
INFO:root:Train (Epoch 5): Loss/seq after 04250 batchs: 1359.6212158203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 5): Loss/seq after 00000 batches: 991.8091430664062
INFO:root:# Valid (Epoch 5): Loss/seq after 00050 batches: 1146.12109375
INFO:root:# Valid (Epoch 5): Loss/seq after 00100 batches: 1468.70263671875
INFO:root:# Valid (Epoch 5): Loss/seq after 00150 batches: 1204.0037841796875
INFO:root:# Valid (Epoch 5): Loss/seq after 00200 batches: 1085.7158203125
INFO:root:Artifacts: Make stick videos for epoch 5
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_5_on_20220412_185824.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_5_index_1501_on_20220412_185824.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 6): Loss/seq after 00000 batchs: 2456.03125
INFO:root:Train (Epoch 6): Loss/seq after 00050 batchs: 1807.12939453125
INFO:root:Train (Epoch 6): Loss/seq after 00100 batchs: 1831.5982666015625
INFO:root:Train (Epoch 6): Loss/seq after 00150 batchs: 1635.8441162109375
INFO:root:Train (Epoch 6): Loss/seq after 00200 batchs: 1741.3897705078125
INFO:root:Train (Epoch 6): Loss/seq after 00250 batchs: 1843.734130859375
INFO:root:Train (Epoch 6): Loss/seq after 00300 batchs: 1727.7537841796875
INFO:root:Train (Epoch 6): Loss/seq after 00350 batchs: 1610.8536376953125
INFO:root:Train (Epoch 6): Loss/seq after 00400 batchs: 1676.92138671875
INFO:root:Train (Epoch 6): Loss/seq after 00450 batchs: 1589.5343017578125
INFO:root:Train (Epoch 6): Loss/seq after 00500 batchs: 1636.68212890625
INFO:root:Train (Epoch 6): Loss/seq after 00550 batchs: 1567.16162109375
INFO:root:Train (Epoch 6): Loss/seq after 00600 batchs: 1528.5389404296875
INFO:root:Train (Epoch 6): Loss/seq after 00650 batchs: 1588.4703369140625
INFO:root:Train (Epoch 6): Loss/seq after 00700 batchs: 1670.806884765625
INFO:root:Train (Epoch 6): Loss/seq after 00750 batchs: 1704.7034912109375
INFO:root:Train (Epoch 6): Loss/seq after 00800 batchs: 1685.7315673828125
INFO:root:Train (Epoch 6): Loss/seq after 00850 batchs: 1644.17724609375
INFO:root:Train (Epoch 6): Loss/seq after 00900 batchs: 1641.3125
INFO:root:Train (Epoch 6): Loss/seq after 00950 batchs: 1733.9757080078125
INFO:root:Train (Epoch 6): Loss/seq after 01000 batchs: 1732.9759521484375
INFO:root:Train (Epoch 6): Loss/seq after 01050 batchs: 1708.2547607421875
INFO:root:Train (Epoch 6): Loss/seq after 01100 batchs: 1700.356689453125
INFO:root:Train (Epoch 6): Loss/seq after 01150 batchs: 1672.66259765625
INFO:root:Train (Epoch 6): Loss/seq after 01200 batchs: 1653.321533203125
INFO:root:Train (Epoch 6): Loss/seq after 01250 batchs: 1644.3543701171875
INFO:root:Train (Epoch 6): Loss/seq after 01300 batchs: 1653.583740234375
INFO:root:Train (Epoch 6): Loss/seq after 01350 batchs: 1650.502197265625
INFO:root:Train (Epoch 6): Loss/seq after 01400 batchs: 1701.2098388671875
INFO:root:Train (Epoch 6): Loss/seq after 01450 batchs: 1681.9754638671875
INFO:root:Train (Epoch 6): Loss/seq after 01500 batchs: 1661.8116455078125
INFO:root:Train (Epoch 6): Loss/seq after 01550 batchs: 1657.5419921875
INFO:root:Train (Epoch 6): Loss/seq after 01600 batchs: 1632.1207275390625
INFO:root:Train (Epoch 6): Loss/seq after 01650 batchs: 1620.239013671875
INFO:root:Train (Epoch 6): Loss/seq after 01700 batchs: 1603.7784423828125
INFO:root:Train (Epoch 6): Loss/seq after 01750 batchs: 1584.474365234375
INFO:root:Train (Epoch 6): Loss/seq after 01800 batchs: 1563.72021484375
INFO:root:Train (Epoch 6): Loss/seq after 01850 batchs: 1542.9835205078125
INFO:root:Train (Epoch 6): Loss/seq after 01900 batchs: 1535.5986328125
INFO:root:Train (Epoch 6): Loss/seq after 01950 batchs: 1524.52783203125
INFO:root:Train (Epoch 6): Loss/seq after 02000 batchs: 1509.1832275390625
INFO:root:Train (Epoch 6): Loss/seq after 02050 batchs: 1495.7662353515625
INFO:root:Train (Epoch 6): Loss/seq after 02100 batchs: 1479.2620849609375
INFO:root:Train (Epoch 6): Loss/seq after 02150 batchs: 1464.35205078125
INFO:root:Train (Epoch 6): Loss/seq after 02200 batchs: 1448.2430419921875
INFO:root:Train (Epoch 6): Loss/seq after 02250 batchs: 1451.0162353515625
INFO:root:Train (Epoch 6): Loss/seq after 02300 batchs: 1453.12451171875
INFO:root:Train (Epoch 6): Loss/seq after 02350 batchs: 1441.65380859375
INFO:root:Train (Epoch 6): Loss/seq after 02400 batchs: 1434.486572265625
INFO:root:Train (Epoch 6): Loss/seq after 02450 batchs: 1419.30859375
INFO:root:Train (Epoch 6): Loss/seq after 02500 batchs: 1398.3944091796875
INFO:root:Train (Epoch 6): Loss/seq after 02550 batchs: 1386.966796875
INFO:root:Train (Epoch 6): Loss/seq after 02600 batchs: 1384.057373046875
INFO:root:Train (Epoch 6): Loss/seq after 02650 batchs: 1376.3988037109375
INFO:root:Train (Epoch 6): Loss/seq after 02700 batchs: 1371.1185302734375
INFO:root:Train (Epoch 6): Loss/seq after 02750 batchs: 1400.631103515625
INFO:root:Train (Epoch 6): Loss/seq after 02800 batchs: 1409.020263671875
INFO:root:Train (Epoch 6): Loss/seq after 02850 batchs: 1404.8524169921875
INFO:root:Train (Epoch 6): Loss/seq after 02900 batchs: 1402.524169921875
INFO:root:Train (Epoch 6): Loss/seq after 02950 batchs: 1392.6519775390625
INFO:root:Train (Epoch 6): Loss/seq after 03000 batchs: 1387.62841796875
INFO:root:Train (Epoch 6): Loss/seq after 03050 batchs: 1387.5606689453125
INFO:root:Train (Epoch 6): Loss/seq after 03100 batchs: 1403.8985595703125
INFO:root:Train (Epoch 6): Loss/seq after 03150 batchs: 1424.7989501953125
INFO:root:Train (Epoch 6): Loss/seq after 03200 batchs: 1437.3909912109375
INFO:root:Train (Epoch 6): Loss/seq after 03250 batchs: 1449.1629638671875
INFO:root:Train (Epoch 6): Loss/seq after 03300 batchs: 1448.8140869140625
INFO:root:Train (Epoch 6): Loss/seq after 03350 batchs: 1447.44091796875
INFO:root:Train (Epoch 6): Loss/seq after 03400 batchs: 1435.946533203125
INFO:root:Train (Epoch 6): Loss/seq after 03450 batchs: 1427.5797119140625
INFO:root:Train (Epoch 6): Loss/seq after 03500 batchs: 1425.663330078125
INFO:root:Train (Epoch 6): Loss/seq after 03550 batchs: 1418.78515625
INFO:root:Train (Epoch 6): Loss/seq after 03600 batchs: 1422.5760498046875
INFO:root:Train (Epoch 6): Loss/seq after 03650 batchs: 1417.072021484375
INFO:root:Train (Epoch 6): Loss/seq after 03700 batchs: 1414.899169921875
INFO:root:Train (Epoch 6): Loss/seq after 03750 batchs: 1412.3931884765625
INFO:root:Train (Epoch 6): Loss/seq after 03800 batchs: 1403.2952880859375
INFO:root:Train (Epoch 6): Loss/seq after 03850 batchs: 1396.969970703125
INFO:root:Train (Epoch 6): Loss/seq after 03900 batchs: 1403.60400390625
INFO:root:Train (Epoch 6): Loss/seq after 03950 batchs: 1411.3330078125
INFO:root:Train (Epoch 6): Loss/seq after 04000 batchs: 1400.11669921875
INFO:root:Train (Epoch 6): Loss/seq after 04050 batchs: 1389.9259033203125
INFO:root:Train (Epoch 6): Loss/seq after 04100 batchs: 1384.9464111328125
INFO:root:Train (Epoch 6): Loss/seq after 04150 batchs: 1378.0328369140625
INFO:root:Train (Epoch 6): Loss/seq after 04200 batchs: 1371.779052734375
INFO:root:Train (Epoch 6): Loss/seq after 04250 batchs: 1366.065673828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 6): Loss/seq after 00000 batches: 1009.2244873046875
INFO:root:# Valid (Epoch 6): Loss/seq after 00050 batches: 1148.405517578125
INFO:root:# Valid (Epoch 6): Loss/seq after 00100 batches: 1494.9300537109375
INFO:root:# Valid (Epoch 6): Loss/seq after 00150 batches: 1230.2978515625
INFO:root:# Valid (Epoch 6): Loss/seq after 00200 batches: 1109.167236328125
INFO:root:Artifacts: Make stick videos for epoch 6
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_6_on_20220412_190346.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_6_index_342_on_20220412_190346.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 7): Loss/seq after 00000 batchs: 2453.518310546875
INFO:root:Train (Epoch 7): Loss/seq after 00050 batchs: 1849.42041015625
INFO:root:Train (Epoch 7): Loss/seq after 00100 batchs: 1795.307861328125
INFO:root:Train (Epoch 7): Loss/seq after 00150 batchs: 1585.593017578125
INFO:root:Train (Epoch 7): Loss/seq after 00200 batchs: 1698.9066162109375
INFO:root:Train (Epoch 7): Loss/seq after 00250 batchs: 1806.7906494140625
INFO:root:Train (Epoch 7): Loss/seq after 00300 batchs: 1694.954833984375
INFO:root:Train (Epoch 7): Loss/seq after 00350 batchs: 1581.213134765625
INFO:root:Train (Epoch 7): Loss/seq after 00400 batchs: 1639.4017333984375
INFO:root:Train (Epoch 7): Loss/seq after 00450 batchs: 1555.4324951171875
INFO:root:Train (Epoch 7): Loss/seq after 00500 batchs: 1587.8214111328125
INFO:root:Train (Epoch 7): Loss/seq after 00550 batchs: 1527.6402587890625
INFO:root:Train (Epoch 7): Loss/seq after 00600 batchs: 1500.0615234375
INFO:root:Train (Epoch 7): Loss/seq after 00650 batchs: 1562.0985107421875
INFO:root:Train (Epoch 7): Loss/seq after 00700 batchs: 1645.916259765625
INFO:root:Train (Epoch 7): Loss/seq after 00750 batchs: 1683.06982421875
INFO:root:Train (Epoch 7): Loss/seq after 00800 batchs: 1665.5040283203125
INFO:root:Train (Epoch 7): Loss/seq after 00850 batchs: 1624.76318359375
INFO:root:Train (Epoch 7): Loss/seq after 00900 batchs: 1623.8604736328125
INFO:root:Train (Epoch 7): Loss/seq after 00950 batchs: 1718.186279296875
INFO:root:Train (Epoch 7): Loss/seq after 01000 batchs: 1717.970458984375
INFO:root:Train (Epoch 7): Loss/seq after 01050 batchs: 1693.343505859375
INFO:root:Train (Epoch 7): Loss/seq after 01100 batchs: 1675.1951904296875
INFO:root:Train (Epoch 7): Loss/seq after 01150 batchs: 1647.07666015625
INFO:root:Train (Epoch 7): Loss/seq after 01200 batchs: 1627.73583984375
INFO:root:Train (Epoch 7): Loss/seq after 01250 batchs: 1615.9273681640625
INFO:root:Train (Epoch 7): Loss/seq after 01300 batchs: 1625.934814453125
INFO:root:Train (Epoch 7): Loss/seq after 01350 batchs: 1624.3211669921875
INFO:root:Train (Epoch 7): Loss/seq after 01400 batchs: 1676.0208740234375
INFO:root:Train (Epoch 7): Loss/seq after 01450 batchs: 1657.808349609375
INFO:root:Train (Epoch 7): Loss/seq after 01500 batchs: 1638.37646484375
INFO:root:Train (Epoch 7): Loss/seq after 01550 batchs: 1634.4688720703125
INFO:root:Train (Epoch 7): Loss/seq after 01600 batchs: 1609.53564453125
INFO:root:Train (Epoch 7): Loss/seq after 01650 batchs: 1599.0830078125
INFO:root:Train (Epoch 7): Loss/seq after 01700 batchs: 1583.4833984375
INFO:root:Train (Epoch 7): Loss/seq after 01750 batchs: 1564.8214111328125
INFO:root:Train (Epoch 7): Loss/seq after 01800 batchs: 1544.5816650390625
INFO:root:Train (Epoch 7): Loss/seq after 01850 batchs: 1524.357421875
INFO:root:Train (Epoch 7): Loss/seq after 01900 batchs: 1517.4764404296875
INFO:root:Train (Epoch 7): Loss/seq after 01950 batchs: 1506.97802734375
INFO:root:Train (Epoch 7): Loss/seq after 02000 batchs: 1492.141845703125
INFO:root:Train (Epoch 7): Loss/seq after 02050 batchs: 1479.0582275390625
INFO:root:Train (Epoch 7): Loss/seq after 02100 batchs: 1462.852783203125
INFO:root:Train (Epoch 7): Loss/seq after 02150 batchs: 1448.239990234375
INFO:root:Train (Epoch 7): Loss/seq after 02200 batchs: 1432.4844970703125
INFO:root:Train (Epoch 7): Loss/seq after 02250 batchs: 1436.3841552734375
INFO:root:Train (Epoch 7): Loss/seq after 02300 batchs: 1440.7344970703125
INFO:root:Train (Epoch 7): Loss/seq after 02350 batchs: 1429.2957763671875
INFO:root:Train (Epoch 7): Loss/seq after 02400 batchs: 1422.3436279296875
INFO:root:Train (Epoch 7): Loss/seq after 02450 batchs: 1407.393798828125
INFO:root:Train (Epoch 7): Loss/seq after 02500 batchs: 1386.691650390625
INFO:root:Train (Epoch 7): Loss/seq after 02550 batchs: 1376.9747314453125
INFO:root:Train (Epoch 7): Loss/seq after 02600 batchs: 1375.597412109375
INFO:root:Train (Epoch 7): Loss/seq after 02650 batchs: 1369.981201171875
INFO:root:Train (Epoch 7): Loss/seq after 02700 batchs: 1367.39453125
INFO:root:Train (Epoch 7): Loss/seq after 02750 batchs: 1396.832763671875
INFO:root:Train (Epoch 7): Loss/seq after 02800 batchs: 1405.68505859375
INFO:root:Train (Epoch 7): Loss/seq after 02850 batchs: 1401.7679443359375
INFO:root:Train (Epoch 7): Loss/seq after 02900 batchs: 1398.849365234375
INFO:root:Train (Epoch 7): Loss/seq after 02950 batchs: 1389.13671875
INFO:root:Train (Epoch 7): Loss/seq after 03000 batchs: 1384.1688232421875
INFO:root:Train (Epoch 7): Loss/seq after 03050 batchs: 1384.1329345703125
INFO:root:Train (Epoch 7): Loss/seq after 03100 batchs: 1400.44287109375
INFO:root:Train (Epoch 7): Loss/seq after 03150 batchs: 1421.547607421875
INFO:root:Train (Epoch 7): Loss/seq after 03200 batchs: 1433.8779296875
INFO:root:Train (Epoch 7): Loss/seq after 03250 batchs: 1445.543212890625
INFO:root:Train (Epoch 7): Loss/seq after 03300 batchs: 1444.0784912109375
INFO:root:Train (Epoch 7): Loss/seq after 03350 batchs: 1442.51318359375
INFO:root:Train (Epoch 7): Loss/seq after 03400 batchs: 1430.9813232421875
INFO:root:Train (Epoch 7): Loss/seq after 03450 batchs: 1422.3125
INFO:root:Train (Epoch 7): Loss/seq after 03500 batchs: 1420.620849609375
INFO:root:Train (Epoch 7): Loss/seq after 03550 batchs: 1414.2396240234375
INFO:root:Train (Epoch 7): Loss/seq after 03600 batchs: 1418.405029296875
INFO:root:Train (Epoch 7): Loss/seq after 03650 batchs: 1413.58984375
INFO:root:Train (Epoch 7): Loss/seq after 03700 batchs: 1411.4813232421875
INFO:root:Train (Epoch 7): Loss/seq after 03750 batchs: 1408.9881591796875
INFO:root:Train (Epoch 7): Loss/seq after 03800 batchs: 1399.919189453125
INFO:root:Train (Epoch 7): Loss/seq after 03850 batchs: 1393.5733642578125
INFO:root:Train (Epoch 7): Loss/seq after 03900 batchs: 1399.832763671875
INFO:root:Train (Epoch 7): Loss/seq after 03950 batchs: 1407.5543212890625
INFO:root:Train (Epoch 7): Loss/seq after 04000 batchs: 1396.3800048828125
INFO:root:Train (Epoch 7): Loss/seq after 04050 batchs: 1386.234619140625
INFO:root:Train (Epoch 7): Loss/seq after 04100 batchs: 1381.195068359375
INFO:root:Train (Epoch 7): Loss/seq after 04150 batchs: 1374.3211669921875
INFO:root:Train (Epoch 7): Loss/seq after 04200 batchs: 1368.48681640625
INFO:root:Train (Epoch 7): Loss/seq after 04250 batchs: 1362.70751953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 7): Loss/seq after 00000 batches: 1005.93310546875
INFO:root:# Valid (Epoch 7): Loss/seq after 00050 batches: 1149.8221435546875
INFO:root:# Valid (Epoch 7): Loss/seq after 00100 batches: 1468.9345703125
INFO:root:# Valid (Epoch 7): Loss/seq after 00150 batches: 1200.24560546875
INFO:root:# Valid (Epoch 7): Loss/seq after 00200 batches: 1081.5035400390625
INFO:root:Artifacts: Make stick videos for epoch 7
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_7_on_20220412_190908.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_7_index_452_on_20220412_190908.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 8): Loss/seq after 00000 batchs: 2556.884033203125
INFO:root:Train (Epoch 8): Loss/seq after 00050 batchs: 1793.995361328125
INFO:root:Train (Epoch 8): Loss/seq after 00100 batchs: 1773.4375
INFO:root:Train (Epoch 8): Loss/seq after 00150 batchs: 1596.7608642578125
INFO:root:Train (Epoch 8): Loss/seq after 00200 batchs: 1706.9251708984375
INFO:root:Train (Epoch 8): Loss/seq after 00250 batchs: 1809.5147705078125
INFO:root:Train (Epoch 8): Loss/seq after 00300 batchs: 1699.59619140625
INFO:root:Train (Epoch 8): Loss/seq after 00350 batchs: 1586.5899658203125
INFO:root:Train (Epoch 8): Loss/seq after 00400 batchs: 1645.1700439453125
INFO:root:Train (Epoch 8): Loss/seq after 00450 batchs: 1560.48095703125
INFO:root:Train (Epoch 8): Loss/seq after 00500 batchs: 1591.1409912109375
INFO:root:Train (Epoch 8): Loss/seq after 00550 batchs: 1523.1839599609375
INFO:root:Train (Epoch 8): Loss/seq after 00600 batchs: 1487.156005859375
INFO:root:Train (Epoch 8): Loss/seq after 00650 batchs: 1549.0032958984375
INFO:root:Train (Epoch 8): Loss/seq after 00700 batchs: 1632.3759765625
INFO:root:Train (Epoch 8): Loss/seq after 00750 batchs: 1666.2432861328125
INFO:root:Train (Epoch 8): Loss/seq after 00800 batchs: 1648.7393798828125
INFO:root:Train (Epoch 8): Loss/seq after 00850 batchs: 1609.159912109375
INFO:root:Train (Epoch 8): Loss/seq after 00900 batchs: 1610.7908935546875
INFO:root:Train (Epoch 8): Loss/seq after 00950 batchs: 1704.0762939453125
INFO:root:Train (Epoch 8): Loss/seq after 01000 batchs: 1703.276123046875
INFO:root:Train (Epoch 8): Loss/seq after 01050 batchs: 1678.9927978515625
INFO:root:Train (Epoch 8): Loss/seq after 01100 batchs: 1662.4822998046875
INFO:root:Train (Epoch 8): Loss/seq after 01150 batchs: 1633.893798828125
INFO:root:Train (Epoch 8): Loss/seq after 01200 batchs: 1614.843505859375
INFO:root:Train (Epoch 8): Loss/seq after 01250 batchs: 1605.1436767578125
INFO:root:Train (Epoch 8): Loss/seq after 01300 batchs: 1615.094482421875
INFO:root:Train (Epoch 8): Loss/seq after 01350 batchs: 1613.5380859375
INFO:root:Train (Epoch 8): Loss/seq after 01400 batchs: 1664.584228515625
INFO:root:Train (Epoch 8): Loss/seq after 01450 batchs: 1647.06298828125
INFO:root:Train (Epoch 8): Loss/seq after 01500 batchs: 1627.9202880859375
INFO:root:Train (Epoch 8): Loss/seq after 01550 batchs: 1625.83935546875
INFO:root:Train (Epoch 8): Loss/seq after 01600 batchs: 1601.67138671875
INFO:root:Train (Epoch 8): Loss/seq after 01650 batchs: 1590.95556640625
INFO:root:Train (Epoch 8): Loss/seq after 01700 batchs: 1575.3265380859375
INFO:root:Train (Epoch 8): Loss/seq after 01750 batchs: 1556.6766357421875
INFO:root:Train (Epoch 8): Loss/seq after 01800 batchs: 1536.57763671875
INFO:root:Train (Epoch 8): Loss/seq after 01850 batchs: 1516.5419921875
INFO:root:Train (Epoch 8): Loss/seq after 01900 batchs: 1509.77197265625
INFO:root:Train (Epoch 8): Loss/seq after 01950 batchs: 1499.4144287109375
INFO:root:Train (Epoch 8): Loss/seq after 02000 batchs: 1484.6236572265625
INFO:root:Train (Epoch 8): Loss/seq after 02050 batchs: 1471.570068359375
INFO:root:Train (Epoch 8): Loss/seq after 02100 batchs: 1455.482421875
INFO:root:Train (Epoch 8): Loss/seq after 02150 batchs: 1440.9044189453125
INFO:root:Train (Epoch 8): Loss/seq after 02200 batchs: 1425.2413330078125
INFO:root:Train (Epoch 8): Loss/seq after 02250 batchs: 1426.9295654296875
INFO:root:Train (Epoch 8): Loss/seq after 02300 batchs: 1429.4866943359375
INFO:root:Train (Epoch 8): Loss/seq after 02350 batchs: 1417.3953857421875
INFO:root:Train (Epoch 8): Loss/seq after 02400 batchs: 1410.92333984375
INFO:root:Train (Epoch 8): Loss/seq after 02450 batchs: 1396.2532958984375
INFO:root:Train (Epoch 8): Loss/seq after 02500 batchs: 1375.7740478515625
INFO:root:Train (Epoch 8): Loss/seq after 02550 batchs: 1367.25390625
INFO:root:Train (Epoch 8): Loss/seq after 02600 batchs: 1366.1182861328125
INFO:root:Train (Epoch 8): Loss/seq after 02650 batchs: 1360.7095947265625
INFO:root:Train (Epoch 8): Loss/seq after 02700 batchs: 1359.521728515625
INFO:root:Train (Epoch 8): Loss/seq after 02750 batchs: 1394.087890625
INFO:root:Train (Epoch 8): Loss/seq after 02800 batchs: 1410.1181640625
INFO:root:Train (Epoch 8): Loss/seq after 02850 batchs: 1410.50048828125
INFO:root:Train (Epoch 8): Loss/seq after 02900 batchs: 1411.1236572265625
INFO:root:Train (Epoch 8): Loss/seq after 02950 batchs: 1403.0716552734375
INFO:root:Train (Epoch 8): Loss/seq after 03000 batchs: 1398.2711181640625
INFO:root:Train (Epoch 8): Loss/seq after 03050 batchs: 1397.8975830078125
INFO:root:Train (Epoch 8): Loss/seq after 03100 batchs: 1416.9422607421875
INFO:root:Train (Epoch 8): Loss/seq after 03150 batchs: 1438.1734619140625
INFO:root:Train (Epoch 8): Loss/seq after 03200 batchs: 1450.6424560546875
INFO:root:Train (Epoch 8): Loss/seq after 03250 batchs: 1462.249755859375
INFO:root:Train (Epoch 8): Loss/seq after 03300 batchs: 1459.759521484375
INFO:root:Train (Epoch 8): Loss/seq after 03350 batchs: 1457.4722900390625
INFO:root:Train (Epoch 8): Loss/seq after 03400 batchs: 1445.721435546875
INFO:root:Train (Epoch 8): Loss/seq after 03450 batchs: 1437.5479736328125
INFO:root:Train (Epoch 8): Loss/seq after 03500 batchs: 1435.1492919921875
INFO:root:Train (Epoch 8): Loss/seq after 03550 batchs: 1427.9495849609375
INFO:root:Train (Epoch 8): Loss/seq after 03600 batchs: 1431.3209228515625
INFO:root:Train (Epoch 8): Loss/seq after 03650 batchs: 1424.8380126953125
INFO:root:Train (Epoch 8): Loss/seq after 03700 batchs: 1422.328369140625
INFO:root:Train (Epoch 8): Loss/seq after 03750 batchs: 1419.604248046875
INFO:root:Train (Epoch 8): Loss/seq after 03800 batchs: 1410.2843017578125
INFO:root:Train (Epoch 8): Loss/seq after 03850 batchs: 1403.619873046875
INFO:root:Train (Epoch 8): Loss/seq after 03900 batchs: 1410.1947021484375
INFO:root:Train (Epoch 8): Loss/seq after 03950 batchs: 1418.8836669921875
INFO:root:Train (Epoch 8): Loss/seq after 04000 batchs: 1407.6534423828125
INFO:root:Train (Epoch 8): Loss/seq after 04050 batchs: 1397.38720703125
INFO:root:Train (Epoch 8): Loss/seq after 04100 batchs: 1392.1318359375
INFO:root:Train (Epoch 8): Loss/seq after 04150 batchs: 1385.13623046875
INFO:root:Train (Epoch 8): Loss/seq after 04200 batchs: 1378.4056396484375
INFO:root:Train (Epoch 8): Loss/seq after 04250 batchs: 1372.4256591796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 8): Loss/seq after 00000 batches: 957.4985961914062
INFO:root:# Valid (Epoch 8): Loss/seq after 00050 batches: 1125.2298583984375
INFO:root:# Valid (Epoch 8): Loss/seq after 00100 batches: 1466.928955078125
INFO:root:# Valid (Epoch 8): Loss/seq after 00150 batches: 1221.41650390625
INFO:root:# Valid (Epoch 8): Loss/seq after 00200 batches: 1109.4312744140625
INFO:root:Artifacts: Make stick videos for epoch 8
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_8_on_20220412_191431.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_8_index_1305_on_20220412_191431.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 9): Loss/seq after 00000 batchs: 2397.25
INFO:root:Train (Epoch 9): Loss/seq after 00050 batchs: 1835.584716796875
INFO:root:Train (Epoch 9): Loss/seq after 00100 batchs: 1810.8167724609375
INFO:root:Train (Epoch 9): Loss/seq after 00150 batchs: 1604.9669189453125
INFO:root:Train (Epoch 9): Loss/seq after 00200 batchs: 1712.510498046875
INFO:root:Train (Epoch 9): Loss/seq after 00250 batchs: 1815.708251953125
INFO:root:Train (Epoch 9): Loss/seq after 00300 batchs: 1701.0264892578125
INFO:root:Train (Epoch 9): Loss/seq after 00350 batchs: 1584.2159423828125
INFO:root:Train (Epoch 9): Loss/seq after 00400 batchs: 1643.629150390625
INFO:root:Train (Epoch 9): Loss/seq after 00450 batchs: 1558.88525390625
INFO:root:Train (Epoch 9): Loss/seq after 00500 batchs: 1601.545654296875
INFO:root:Train (Epoch 9): Loss/seq after 00550 batchs: 1533.9144287109375
INFO:root:Train (Epoch 9): Loss/seq after 00600 batchs: 1497.085693359375
INFO:root:Train (Epoch 9): Loss/seq after 00650 batchs: 1555.56591796875
INFO:root:Train (Epoch 9): Loss/seq after 00700 batchs: 1637.3428955078125
INFO:root:Train (Epoch 9): Loss/seq after 00750 batchs: 1669.9478759765625
INFO:root:Train (Epoch 9): Loss/seq after 00800 batchs: 1652.05126953125
INFO:root:Train (Epoch 9): Loss/seq after 00850 batchs: 1612.3035888671875
INFO:root:Train (Epoch 9): Loss/seq after 00900 batchs: 1613.3076171875
INFO:root:Train (Epoch 9): Loss/seq after 00950 batchs: 1708.0250244140625
INFO:root:Train (Epoch 9): Loss/seq after 01000 batchs: 1705.9876708984375
INFO:root:Train (Epoch 9): Loss/seq after 01050 batchs: 1680.9068603515625
INFO:root:Train (Epoch 9): Loss/seq after 01100 batchs: 1662.9998779296875
INFO:root:Train (Epoch 9): Loss/seq after 01150 batchs: 1634.9423828125
INFO:root:Train (Epoch 9): Loss/seq after 01200 batchs: 1614.158447265625
INFO:root:Train (Epoch 9): Loss/seq after 01250 batchs: 1603.008056640625
INFO:root:Train (Epoch 9): Loss/seq after 01300 batchs: 1613.5245361328125
INFO:root:Train (Epoch 9): Loss/seq after 01350 batchs: 1612.3282470703125
INFO:root:Train (Epoch 9): Loss/seq after 01400 batchs: 1664.0169677734375
INFO:root:Train (Epoch 9): Loss/seq after 01450 batchs: 1644.2550048828125
INFO:root:Train (Epoch 9): Loss/seq after 01500 batchs: 1625.46435546875
INFO:root:Train (Epoch 9): Loss/seq after 01550 batchs: 1623.8858642578125
INFO:root:Train (Epoch 9): Loss/seq after 01600 batchs: 1598.5592041015625
INFO:root:Train (Epoch 9): Loss/seq after 01650 batchs: 1586.1634521484375
INFO:root:Train (Epoch 9): Loss/seq after 01700 batchs: 1570.739501953125
INFO:root:Train (Epoch 9): Loss/seq after 01750 batchs: 1552.1341552734375
INFO:root:Train (Epoch 9): Loss/seq after 01800 batchs: 1532.1790771484375
INFO:root:Train (Epoch 9): Loss/seq after 01850 batchs: 1512.2269287109375
INFO:root:Train (Epoch 9): Loss/seq after 01900 batchs: 1505.547119140625
INFO:root:Train (Epoch 9): Loss/seq after 01950 batchs: 1495.3402099609375
INFO:root:Train (Epoch 9): Loss/seq after 02000 batchs: 1480.7286376953125
INFO:root:Train (Epoch 9): Loss/seq after 02050 batchs: 1467.90869140625
INFO:root:Train (Epoch 9): Loss/seq after 02100 batchs: 1451.951904296875
INFO:root:Train (Epoch 9): Loss/seq after 02150 batchs: 1437.5916748046875
INFO:root:Train (Epoch 9): Loss/seq after 02200 batchs: 1422.068115234375
INFO:root:Train (Epoch 9): Loss/seq after 02250 batchs: 1423.564453125
INFO:root:Train (Epoch 9): Loss/seq after 02300 batchs: 1425.4312744140625
INFO:root:Train (Epoch 9): Loss/seq after 02350 batchs: 1414.1826171875
INFO:root:Train (Epoch 9): Loss/seq after 02400 batchs: 1407.0772705078125
INFO:root:Train (Epoch 9): Loss/seq after 02450 batchs: 1391.5335693359375
INFO:root:Train (Epoch 9): Loss/seq after 02500 batchs: 1371.135986328125
INFO:root:Train (Epoch 9): Loss/seq after 02550 batchs: 1357.6485595703125
INFO:root:Train (Epoch 9): Loss/seq after 02600 batchs: 1354.109619140625
INFO:root:Train (Epoch 9): Loss/seq after 02650 batchs: 1346.8236083984375
INFO:root:Train (Epoch 9): Loss/seq after 02700 batchs: 1341.8243408203125
INFO:root:Train (Epoch 9): Loss/seq after 02750 batchs: 1371.4490966796875
INFO:root:Train (Epoch 9): Loss/seq after 02800 batchs: 1379.6318359375
INFO:root:Train (Epoch 9): Loss/seq after 02850 batchs: 1375.6358642578125
INFO:root:Train (Epoch 9): Loss/seq after 02900 batchs: 1372.1793212890625
INFO:root:Train (Epoch 9): Loss/seq after 02950 batchs: 1362.56689453125
INFO:root:Train (Epoch 9): Loss/seq after 03000 batchs: 1357.998291015625
INFO:root:Train (Epoch 9): Loss/seq after 03050 batchs: 1358.37451171875
INFO:root:Train (Epoch 9): Loss/seq after 03100 batchs: 1375.0328369140625
INFO:root:Train (Epoch 9): Loss/seq after 03150 batchs: 1393.72509765625
INFO:root:Train (Epoch 9): Loss/seq after 03200 batchs: 1406.2100830078125
INFO:root:Train (Epoch 9): Loss/seq after 03250 batchs: 1418.4990234375
INFO:root:Train (Epoch 9): Loss/seq after 03300 batchs: 1419.3070068359375
INFO:root:Train (Epoch 9): Loss/seq after 03350 batchs: 1418.381591796875
INFO:root:Train (Epoch 9): Loss/seq after 03400 batchs: 1407.2705078125
INFO:root:Train (Epoch 9): Loss/seq after 03450 batchs: 1399.797607421875
INFO:root:Train (Epoch 9): Loss/seq after 03500 batchs: 1398.759765625
INFO:root:Train (Epoch 9): Loss/seq after 03550 batchs: 1392.4501953125
INFO:root:Train (Epoch 9): Loss/seq after 03600 batchs: 1396.3453369140625
INFO:root:Train (Epoch 9): Loss/seq after 03650 batchs: 1390.7138671875
INFO:root:Train (Epoch 9): Loss/seq after 03700 batchs: 1388.8291015625
INFO:root:Train (Epoch 9): Loss/seq after 03750 batchs: 1386.7354736328125
INFO:root:Train (Epoch 9): Loss/seq after 03800 batchs: 1377.8277587890625
INFO:root:Train (Epoch 9): Loss/seq after 03850 batchs: 1371.5938720703125
INFO:root:Train (Epoch 9): Loss/seq after 03900 batchs: 1378.9193115234375
INFO:root:Train (Epoch 9): Loss/seq after 03950 batchs: 1387.9727783203125
INFO:root:Train (Epoch 9): Loss/seq after 04000 batchs: 1377.1026611328125
INFO:root:Train (Epoch 9): Loss/seq after 04050 batchs: 1367.2042236328125
INFO:root:Train (Epoch 9): Loss/seq after 04100 batchs: 1362.2371826171875
INFO:root:Train (Epoch 9): Loss/seq after 04150 batchs: 1355.6141357421875
INFO:root:Train (Epoch 9): Loss/seq after 04200 batchs: 1349.7454833984375
INFO:root:Train (Epoch 9): Loss/seq after 04250 batchs: 1344.2564697265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 9): Loss/seq after 00000 batches: 994.9293823242188
INFO:root:# Valid (Epoch 9): Loss/seq after 00050 batches: 1141.128173828125
INFO:root:# Valid (Epoch 9): Loss/seq after 00100 batches: 1477.406494140625
INFO:root:# Valid (Epoch 9): Loss/seq after 00150 batches: 1220.6185302734375
INFO:root:# Valid (Epoch 9): Loss/seq after 00200 batches: 1103.0706787109375
INFO:root:Artifacts: Make stick videos for epoch 9
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_9_on_20220412_191956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_9_index_1867_on_20220412_191956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 10): Loss/seq after 00000 batchs: 2493.4453125
INFO:root:Train (Epoch 10): Loss/seq after 00050 batchs: 1809.814453125
INFO:root:Train (Epoch 10): Loss/seq after 00100 batchs: 1777.9212646484375
INFO:root:Train (Epoch 10): Loss/seq after 00150 batchs: 1565.9453125
INFO:root:Train (Epoch 10): Loss/seq after 00200 batchs: 1681.7476806640625
INFO:root:Train (Epoch 10): Loss/seq after 00250 batchs: 1786.3988037109375
INFO:root:Train (Epoch 10): Loss/seq after 00300 batchs: 1676.08837890625
INFO:root:Train (Epoch 10): Loss/seq after 00350 batchs: 1562.9952392578125
INFO:root:Train (Epoch 10): Loss/seq after 00400 batchs: 1624.1383056640625
INFO:root:Train (Epoch 10): Loss/seq after 00450 batchs: 1541.511962890625
INFO:root:Train (Epoch 10): Loss/seq after 00500 batchs: 1577.064208984375
INFO:root:Train (Epoch 10): Loss/seq after 00550 batchs: 1510.8382568359375
INFO:root:Train (Epoch 10): Loss/seq after 00600 batchs: 1475.4061279296875
INFO:root:Train (Epoch 10): Loss/seq after 00650 batchs: 1536.6026611328125
INFO:root:Train (Epoch 10): Loss/seq after 00700 batchs: 1616.839599609375
INFO:root:Train (Epoch 10): Loss/seq after 00750 batchs: 1649.858154296875
INFO:root:Train (Epoch 10): Loss/seq after 00800 batchs: 1633.1622314453125
INFO:root:Train (Epoch 10): Loss/seq after 00850 batchs: 1594.5953369140625
INFO:root:Train (Epoch 10): Loss/seq after 00900 batchs: 1592.874267578125
INFO:root:Train (Epoch 10): Loss/seq after 00950 batchs: 1685.7889404296875
INFO:root:Train (Epoch 10): Loss/seq after 01000 batchs: 1683.8616943359375
INFO:root:Train (Epoch 10): Loss/seq after 01050 batchs: 1660.200439453125
INFO:root:Train (Epoch 10): Loss/seq after 01100 batchs: 1647.343994140625
INFO:root:Train (Epoch 10): Loss/seq after 01150 batchs: 1621.0322265625
INFO:root:Train (Epoch 10): Loss/seq after 01200 batchs: 1602.4212646484375
INFO:root:Train (Epoch 10): Loss/seq after 01250 batchs: 1591.7364501953125
INFO:root:Train (Epoch 10): Loss/seq after 01300 batchs: 1602.3345947265625
INFO:root:Train (Epoch 10): Loss/seq after 01350 batchs: 1601.24365234375
INFO:root:Train (Epoch 10): Loss/seq after 01400 batchs: 1650.828125
INFO:root:Train (Epoch 10): Loss/seq after 01450 batchs: 1632.14501953125
INFO:root:Train (Epoch 10): Loss/seq after 01500 batchs: 1613.496337890625
INFO:root:Train (Epoch 10): Loss/seq after 01550 batchs: 1609.759765625
INFO:root:Train (Epoch 10): Loss/seq after 01600 batchs: 1584.9571533203125
INFO:root:Train (Epoch 10): Loss/seq after 01650 batchs: 1572.79638671875
INFO:root:Train (Epoch 10): Loss/seq after 01700 batchs: 1557.3502197265625
INFO:root:Train (Epoch 10): Loss/seq after 01750 batchs: 1539.2071533203125
INFO:root:Train (Epoch 10): Loss/seq after 01800 batchs: 1519.6806640625
INFO:root:Train (Epoch 10): Loss/seq after 01850 batchs: 1500.06689453125
INFO:root:Train (Epoch 10): Loss/seq after 01900 batchs: 1493.6319580078125
INFO:root:Train (Epoch 10): Loss/seq after 01950 batchs: 1483.5941162109375
INFO:root:Train (Epoch 10): Loss/seq after 02000 batchs: 1469.20458984375
INFO:root:Train (Epoch 10): Loss/seq after 02050 batchs: 1456.6285400390625
INFO:root:Train (Epoch 10): Loss/seq after 02100 batchs: 1440.910888671875
INFO:root:Train (Epoch 10): Loss/seq after 02150 batchs: 1426.816162109375
INFO:root:Train (Epoch 10): Loss/seq after 02200 batchs: 1411.517822265625
INFO:root:Train (Epoch 10): Loss/seq after 02250 batchs: 1412.5970458984375
INFO:root:Train (Epoch 10): Loss/seq after 02300 batchs: 1414.453125
INFO:root:Train (Epoch 10): Loss/seq after 02350 batchs: 1402.2645263671875
INFO:root:Train (Epoch 10): Loss/seq after 02400 batchs: 1395.5860595703125
INFO:root:Train (Epoch 10): Loss/seq after 02450 batchs: 1380.6807861328125
INFO:root:Train (Epoch 10): Loss/seq after 02500 batchs: 1360.6014404296875
INFO:root:Train (Epoch 10): Loss/seq after 02550 batchs: 1347.632080078125
INFO:root:Train (Epoch 10): Loss/seq after 02600 batchs: 1345.6064453125
INFO:root:Train (Epoch 10): Loss/seq after 02650 batchs: 1339.5511474609375
INFO:root:Train (Epoch 10): Loss/seq after 02700 batchs: 1335.5877685546875
INFO:root:Train (Epoch 10): Loss/seq after 02750 batchs: 1365.47705078125
INFO:root:Train (Epoch 10): Loss/seq after 02800 batchs: 1373.8585205078125
INFO:root:Train (Epoch 10): Loss/seq after 02850 batchs: 1369.89990234375
INFO:root:Train (Epoch 10): Loss/seq after 02900 batchs: 1366.5521240234375
INFO:root:Train (Epoch 10): Loss/seq after 02950 batchs: 1357.0980224609375
INFO:root:Train (Epoch 10): Loss/seq after 03000 batchs: 1352.6324462890625
INFO:root:Train (Epoch 10): Loss/seq after 03050 batchs: 1353.09326171875
INFO:root:Train (Epoch 10): Loss/seq after 03100 batchs: 1369.0946044921875
INFO:root:Train (Epoch 10): Loss/seq after 03150 batchs: 1388.4892578125
INFO:root:Train (Epoch 10): Loss/seq after 03200 batchs: 1401.6708984375
INFO:root:Train (Epoch 10): Loss/seq after 03250 batchs: 1414.958740234375
INFO:root:Train (Epoch 10): Loss/seq after 03300 batchs: 1416.1810302734375
INFO:root:Train (Epoch 10): Loss/seq after 03350 batchs: 1414.9132080078125
INFO:root:Train (Epoch 10): Loss/seq after 03400 batchs: 1403.674560546875
INFO:root:Train (Epoch 10): Loss/seq after 03450 batchs: 1394.8695068359375
INFO:root:Train (Epoch 10): Loss/seq after 03500 batchs: 1393.4090576171875
INFO:root:Train (Epoch 10): Loss/seq after 03550 batchs: 1387.552001953125
INFO:root:Train (Epoch 10): Loss/seq after 03600 batchs: 1391.8643798828125
INFO:root:Train (Epoch 10): Loss/seq after 03650 batchs: 1385.762451171875
INFO:root:Train (Epoch 10): Loss/seq after 03700 batchs: 1383.580078125
INFO:root:Train (Epoch 10): Loss/seq after 03750 batchs: 1381.3397216796875
INFO:root:Train (Epoch 10): Loss/seq after 03800 batchs: 1372.4755859375
INFO:root:Train (Epoch 10): Loss/seq after 03850 batchs: 1366.2742919921875
INFO:root:Train (Epoch 10): Loss/seq after 03900 batchs: 1373.514892578125
INFO:root:Train (Epoch 10): Loss/seq after 03950 batchs: 1381.220703125
INFO:root:Train (Epoch 10): Loss/seq after 04000 batchs: 1370.3961181640625
INFO:root:Train (Epoch 10): Loss/seq after 04050 batchs: 1360.56396484375
INFO:root:Train (Epoch 10): Loss/seq after 04100 batchs: 1355.240234375
INFO:root:Train (Epoch 10): Loss/seq after 04150 batchs: 1348.199462890625
INFO:root:Train (Epoch 10): Loss/seq after 04200 batchs: 1342.0439453125
INFO:root:Train (Epoch 10): Loss/seq after 04250 batchs: 1336.4278564453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 10): Loss/seq after 00000 batches: 947.0859375
INFO:root:# Valid (Epoch 10): Loss/seq after 00050 batches: 1119.1636962890625
INFO:root:# Valid (Epoch 10): Loss/seq after 00100 batches: 1468.9010009765625
INFO:root:# Valid (Epoch 10): Loss/seq after 00150 batches: 1230.1083984375
INFO:root:# Valid (Epoch 10): Loss/seq after 00200 batches: 1120.178466796875
INFO:root:Artifacts: Make stick videos for epoch 10
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_10_on_20220412_192524.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_10_index_801_on_20220412_192524.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 11): Loss/seq after 00000 batchs: 2719.6318359375
INFO:root:Train (Epoch 11): Loss/seq after 00050 batchs: 1803.3651123046875
INFO:root:Train (Epoch 11): Loss/seq after 00100 batchs: 1755.736083984375
INFO:root:Train (Epoch 11): Loss/seq after 00150 batchs: 1582.3968505859375
INFO:root:Train (Epoch 11): Loss/seq after 00200 batchs: 1697.4451904296875
INFO:root:Train (Epoch 11): Loss/seq after 00250 batchs: 1797.5028076171875
INFO:root:Train (Epoch 11): Loss/seq after 00300 batchs: 1685.9725341796875
INFO:root:Train (Epoch 11): Loss/seq after 00350 batchs: 1571.3843994140625
INFO:root:Train (Epoch 11): Loss/seq after 00400 batchs: 1630.58935546875
INFO:root:Train (Epoch 11): Loss/seq after 00450 batchs: 1547.2686767578125
INFO:root:Train (Epoch 11): Loss/seq after 00500 batchs: 1580.7470703125
INFO:root:Train (Epoch 11): Loss/seq after 00550 batchs: 1513.4715576171875
INFO:root:Train (Epoch 11): Loss/seq after 00600 batchs: 1477.8240966796875
INFO:root:Train (Epoch 11): Loss/seq after 00650 batchs: 1537.0699462890625
INFO:root:Train (Epoch 11): Loss/seq after 00700 batchs: 1617.207275390625
INFO:root:Train (Epoch 11): Loss/seq after 00750 batchs: 1650.258544921875
INFO:root:Train (Epoch 11): Loss/seq after 00800 batchs: 1632.4520263671875
INFO:root:Train (Epoch 11): Loss/seq after 00850 batchs: 1594.6092529296875
INFO:root:Train (Epoch 11): Loss/seq after 00900 batchs: 1592.7088623046875
INFO:root:Train (Epoch 11): Loss/seq after 00950 batchs: 1682.3018798828125
INFO:root:Train (Epoch 11): Loss/seq after 01000 batchs: 1679.568115234375
INFO:root:Train (Epoch 11): Loss/seq after 01050 batchs: 1655.4776611328125
INFO:root:Train (Epoch 11): Loss/seq after 01100 batchs: 1637.2530517578125
INFO:root:Train (Epoch 11): Loss/seq after 01150 batchs: 1610.257080078125
INFO:root:Train (Epoch 11): Loss/seq after 01200 batchs: 1590.217041015625
INFO:root:Train (Epoch 11): Loss/seq after 01250 batchs: 1580.1529541015625
INFO:root:Train (Epoch 11): Loss/seq after 01300 batchs: 1590.974853515625
INFO:root:Train (Epoch 11): Loss/seq after 01350 batchs: 1590.1800537109375
INFO:root:Train (Epoch 11): Loss/seq after 01400 batchs: 1638.8834228515625
INFO:root:Train (Epoch 11): Loss/seq after 01450 batchs: 1619.6043701171875
INFO:root:Train (Epoch 11): Loss/seq after 01500 batchs: 1601.7435302734375
INFO:root:Train (Epoch 11): Loss/seq after 01550 batchs: 1598.3896484375
INFO:root:Train (Epoch 11): Loss/seq after 01600 batchs: 1573.74267578125
INFO:root:Train (Epoch 11): Loss/seq after 01650 batchs: 1562.0869140625
INFO:root:Train (Epoch 11): Loss/seq after 01700 batchs: 1547.512939453125
INFO:root:Train (Epoch 11): Loss/seq after 01750 batchs: 1529.419677734375
INFO:root:Train (Epoch 11): Loss/seq after 01800 batchs: 1509.8345947265625
INFO:root:Train (Epoch 11): Loss/seq after 01850 batchs: 1490.5421142578125
INFO:root:Train (Epoch 11): Loss/seq after 01900 batchs: 1484.185791015625
INFO:root:Train (Epoch 11): Loss/seq after 01950 batchs: 1474.489013671875
INFO:root:Train (Epoch 11): Loss/seq after 02000 batchs: 1460.1790771484375
INFO:root:Train (Epoch 11): Loss/seq after 02050 batchs: 1447.7020263671875
INFO:root:Train (Epoch 11): Loss/seq after 02100 batchs: 1432.140869140625
INFO:root:Train (Epoch 11): Loss/seq after 02150 batchs: 1418.31103515625
INFO:root:Train (Epoch 11): Loss/seq after 02200 batchs: 1403.259765625
INFO:root:Train (Epoch 11): Loss/seq after 02250 batchs: 1405.181640625
INFO:root:Train (Epoch 11): Loss/seq after 02300 batchs: 1407.2139892578125
INFO:root:Train (Epoch 11): Loss/seq after 02350 batchs: 1395.255615234375
INFO:root:Train (Epoch 11): Loss/seq after 02400 batchs: 1388.3375244140625
INFO:root:Train (Epoch 11): Loss/seq after 02450 batchs: 1372.84521484375
INFO:root:Train (Epoch 11): Loss/seq after 02500 batchs: 1352.804443359375
INFO:root:Train (Epoch 11): Loss/seq after 02550 batchs: 1339.589111328125
INFO:root:Train (Epoch 11): Loss/seq after 02600 batchs: 1335.537109375
INFO:root:Train (Epoch 11): Loss/seq after 02650 batchs: 1328.6817626953125
INFO:root:Train (Epoch 11): Loss/seq after 02700 batchs: 1324.223388671875
INFO:root:Train (Epoch 11): Loss/seq after 02750 batchs: 1354.5623779296875
INFO:root:Train (Epoch 11): Loss/seq after 02800 batchs: 1363.0107421875
INFO:root:Train (Epoch 11): Loss/seq after 02850 batchs: 1358.8792724609375
INFO:root:Train (Epoch 11): Loss/seq after 02900 batchs: 1355.3831787109375
INFO:root:Train (Epoch 11): Loss/seq after 02950 batchs: 1346.040771484375
INFO:root:Train (Epoch 11): Loss/seq after 03000 batchs: 1341.741943359375
INFO:root:Train (Epoch 11): Loss/seq after 03050 batchs: 1342.3856201171875
INFO:root:Train (Epoch 11): Loss/seq after 03100 batchs: 1359.6326904296875
INFO:root:Train (Epoch 11): Loss/seq after 03150 batchs: 1379.9295654296875
INFO:root:Train (Epoch 11): Loss/seq after 03200 batchs: 1393.053466796875
INFO:root:Train (Epoch 11): Loss/seq after 03250 batchs: 1405.361083984375
INFO:root:Train (Epoch 11): Loss/seq after 03300 batchs: 1404.216796875
INFO:root:Train (Epoch 11): Loss/seq after 03350 batchs: 1402.628662109375
INFO:root:Train (Epoch 11): Loss/seq after 03400 batchs: 1391.593017578125
INFO:root:Train (Epoch 11): Loss/seq after 03450 batchs: 1383.4464111328125
INFO:root:Train (Epoch 11): Loss/seq after 03500 batchs: 1382.2100830078125
INFO:root:Train (Epoch 11): Loss/seq after 03550 batchs: 1376.189453125
INFO:root:Train (Epoch 11): Loss/seq after 03600 batchs: 1380.268310546875
INFO:root:Train (Epoch 11): Loss/seq after 03650 batchs: 1374.2635498046875
INFO:root:Train (Epoch 11): Loss/seq after 03700 batchs: 1372.62255859375
INFO:root:Train (Epoch 11): Loss/seq after 03750 batchs: 1370.5870361328125
INFO:root:Train (Epoch 11): Loss/seq after 03800 batchs: 1361.9766845703125
INFO:root:Train (Epoch 11): Loss/seq after 03850 batchs: 1355.911376953125
INFO:root:Train (Epoch 11): Loss/seq after 03900 batchs: 1362.6407470703125
INFO:root:Train (Epoch 11): Loss/seq after 03950 batchs: 1371.1209716796875
INFO:root:Train (Epoch 11): Loss/seq after 04000 batchs: 1360.4232177734375
INFO:root:Train (Epoch 11): Loss/seq after 04050 batchs: 1350.7037353515625
INFO:root:Train (Epoch 11): Loss/seq after 04100 batchs: 1345.534423828125
INFO:root:Train (Epoch 11): Loss/seq after 04150 batchs: 1339.101318359375
INFO:root:Train (Epoch 11): Loss/seq after 04200 batchs: 1332.7891845703125
INFO:root:Train (Epoch 11): Loss/seq after 04250 batchs: 1327.1617431640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 11): Loss/seq after 00000 batches: 938.7978515625
INFO:root:# Valid (Epoch 11): Loss/seq after 00050 batches: 1116.366943359375
INFO:root:# Valid (Epoch 11): Loss/seq after 00100 batches: 1436.7874755859375
INFO:root:# Valid (Epoch 11): Loss/seq after 00150 batches: 1201.4847412109375
INFO:root:# Valid (Epoch 11): Loss/seq after 00200 batches: 1093.3369140625
INFO:root:Artifacts: Make stick videos for epoch 11
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_11_on_20220412_193047.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_11_index_1867_on_20220412_193047.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 12): Loss/seq after 00000 batchs: 2437.346923828125
INFO:root:Train (Epoch 12): Loss/seq after 00050 batchs: 1772.5560302734375
INFO:root:Train (Epoch 12): Loss/seq after 00100 batchs: 1708.6324462890625
INFO:root:Train (Epoch 12): Loss/seq after 00150 batchs: 1513.9886474609375
INFO:root:Train (Epoch 12): Loss/seq after 00200 batchs: 1638.879638671875
INFO:root:Train (Epoch 12): Loss/seq after 00250 batchs: 1752.4912109375
INFO:root:Train (Epoch 12): Loss/seq after 00300 batchs: 1646.3349609375
INFO:root:Train (Epoch 12): Loss/seq after 00350 batchs: 1537.286376953125
INFO:root:Train (Epoch 12): Loss/seq after 00400 batchs: 1598.520263671875
INFO:root:Train (Epoch 12): Loss/seq after 00450 batchs: 1518.6025390625
INFO:root:Train (Epoch 12): Loss/seq after 00500 batchs: 1550.9454345703125
INFO:root:Train (Epoch 12): Loss/seq after 00550 batchs: 1486.3482666015625
INFO:root:Train (Epoch 12): Loss/seq after 00600 batchs: 1452.76513671875
INFO:root:Train (Epoch 12): Loss/seq after 00650 batchs: 1512.5692138671875
INFO:root:Train (Epoch 12): Loss/seq after 00700 batchs: 1594.93994140625
INFO:root:Train (Epoch 12): Loss/seq after 00750 batchs: 1629.920166015625
INFO:root:Train (Epoch 12): Loss/seq after 00800 batchs: 1614.18017578125
INFO:root:Train (Epoch 12): Loss/seq after 00850 batchs: 1578.852783203125
INFO:root:Train (Epoch 12): Loss/seq after 00900 batchs: 1578.5755615234375
INFO:root:Train (Epoch 12): Loss/seq after 00950 batchs: 1661.4320068359375
INFO:root:Train (Epoch 12): Loss/seq after 01000 batchs: 1656.74365234375
INFO:root:Train (Epoch 12): Loss/seq after 01050 batchs: 1633.9908447265625
INFO:root:Train (Epoch 12): Loss/seq after 01100 batchs: 1622.02294921875
INFO:root:Train (Epoch 12): Loss/seq after 01150 batchs: 1594.99853515625
INFO:root:Train (Epoch 12): Loss/seq after 01200 batchs: 1575.2021484375
INFO:root:Train (Epoch 12): Loss/seq after 01250 batchs: 1564.4298095703125
INFO:root:Train (Epoch 12): Loss/seq after 01300 batchs: 1575.8248291015625
INFO:root:Train (Epoch 12): Loss/seq after 01350 batchs: 1575.587158203125
INFO:root:Train (Epoch 12): Loss/seq after 01400 batchs: 1616.5919189453125
INFO:root:Train (Epoch 12): Loss/seq after 01450 batchs: 1597.7099609375
INFO:root:Train (Epoch 12): Loss/seq after 01500 batchs: 1579.9801025390625
INFO:root:Train (Epoch 12): Loss/seq after 01550 batchs: 1578.3453369140625
INFO:root:Train (Epoch 12): Loss/seq after 01600 batchs: 1554.6864013671875
INFO:root:Train (Epoch 12): Loss/seq after 01650 batchs: 1543.315673828125
INFO:root:Train (Epoch 12): Loss/seq after 01700 batchs: 1528.6566162109375
INFO:root:Train (Epoch 12): Loss/seq after 01750 batchs: 1511.286865234375
INFO:root:Train (Epoch 12): Loss/seq after 01800 batchs: 1492.5166015625
INFO:root:Train (Epoch 12): Loss/seq after 01850 batchs: 1473.63427734375
INFO:root:Train (Epoch 12): Loss/seq after 01900 batchs: 1467.96484375
INFO:root:Train (Epoch 12): Loss/seq after 01950 batchs: 1458.7777099609375
INFO:root:Train (Epoch 12): Loss/seq after 02000 batchs: 1445.0628662109375
INFO:root:Train (Epoch 12): Loss/seq after 02050 batchs: 1433.11376953125
INFO:root:Train (Epoch 12): Loss/seq after 02100 batchs: 1417.97021484375
INFO:root:Train (Epoch 12): Loss/seq after 02150 batchs: 1404.3934326171875
INFO:root:Train (Epoch 12): Loss/seq after 02200 batchs: 1389.599365234375
INFO:root:Train (Epoch 12): Loss/seq after 02250 batchs: 1391.4725341796875
INFO:root:Train (Epoch 12): Loss/seq after 02300 batchs: 1393.415283203125
INFO:root:Train (Epoch 12): Loss/seq after 02350 batchs: 1381.6318359375
INFO:root:Train (Epoch 12): Loss/seq after 02400 batchs: 1375.0706787109375
INFO:root:Train (Epoch 12): Loss/seq after 02450 batchs: 1359.9552001953125
INFO:root:Train (Epoch 12): Loss/seq after 02500 batchs: 1340.17431640625
INFO:root:Train (Epoch 12): Loss/seq after 02550 batchs: 1327.0052490234375
INFO:root:Train (Epoch 12): Loss/seq after 02600 batchs: 1323.6326904296875
INFO:root:Train (Epoch 12): Loss/seq after 02650 batchs: 1316.873046875
INFO:root:Train (Epoch 12): Loss/seq after 02700 batchs: 1313.0452880859375
INFO:root:Train (Epoch 12): Loss/seq after 02750 batchs: 1343.0113525390625
INFO:root:Train (Epoch 12): Loss/seq after 02800 batchs: 1351.899658203125
INFO:root:Train (Epoch 12): Loss/seq after 02850 batchs: 1348.07421875
INFO:root:Train (Epoch 12): Loss/seq after 02900 batchs: 1344.671630859375
INFO:root:Train (Epoch 12): Loss/seq after 02950 batchs: 1335.4425048828125
INFO:root:Train (Epoch 12): Loss/seq after 03000 batchs: 1331.31591796875
INFO:root:Train (Epoch 12): Loss/seq after 03050 batchs: 1332.118408203125
INFO:root:Train (Epoch 12): Loss/seq after 03100 batchs: 1348.2099609375
INFO:root:Train (Epoch 12): Loss/seq after 03150 batchs: 1364.649658203125
INFO:root:Train (Epoch 12): Loss/seq after 03200 batchs: 1374.1268310546875
INFO:root:Train (Epoch 12): Loss/seq after 03250 batchs: 1385.184814453125
INFO:root:Train (Epoch 12): Loss/seq after 03300 batchs: 1385.9525146484375
INFO:root:Train (Epoch 12): Loss/seq after 03350 batchs: 1384.85205078125
INFO:root:Train (Epoch 12): Loss/seq after 03400 batchs: 1374.1591796875
INFO:root:Train (Epoch 12): Loss/seq after 03450 batchs: 1366.6475830078125
INFO:root:Train (Epoch 12): Loss/seq after 03500 batchs: 1365.228515625
INFO:root:Train (Epoch 12): Loss/seq after 03550 batchs: 1359.2403564453125
INFO:root:Train (Epoch 12): Loss/seq after 03600 batchs: 1363.78955078125
INFO:root:Train (Epoch 12): Loss/seq after 03650 batchs: 1358.92578125
INFO:root:Train (Epoch 12): Loss/seq after 03700 batchs: 1357.1348876953125
INFO:root:Train (Epoch 12): Loss/seq after 03750 batchs: 1355.32666015625
INFO:root:Train (Epoch 12): Loss/seq after 03800 batchs: 1346.9097900390625
INFO:root:Train (Epoch 12): Loss/seq after 03850 batchs: 1341.196533203125
INFO:root:Train (Epoch 12): Loss/seq after 03900 batchs: 1347.733642578125
INFO:root:Train (Epoch 12): Loss/seq after 03950 batchs: 1354.04541015625
INFO:root:Train (Epoch 12): Loss/seq after 04000 batchs: 1343.57666015625
INFO:root:Train (Epoch 12): Loss/seq after 04050 batchs: 1334.087646484375
INFO:root:Train (Epoch 12): Loss/seq after 04100 batchs: 1329.3729248046875
INFO:root:Train (Epoch 12): Loss/seq after 04150 batchs: 1323.1190185546875
INFO:root:Train (Epoch 12): Loss/seq after 04200 batchs: 1317.221923828125
INFO:root:Train (Epoch 12): Loss/seq after 04250 batchs: 1311.93994140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 12): Loss/seq after 00000 batches: 951.0296020507812
INFO:root:# Valid (Epoch 12): Loss/seq after 00050 batches: 1121.78662109375
INFO:root:# Valid (Epoch 12): Loss/seq after 00100 batches: 1455.9921875
INFO:root:# Valid (Epoch 12): Loss/seq after 00150 batches: 1215.8406982421875
INFO:root:# Valid (Epoch 12): Loss/seq after 00200 batches: 1107.102783203125
INFO:root:Artifacts: Make stick videos for epoch 12
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_12_on_20220412_193611.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_12_index_1708_on_20220412_193611.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 13): Loss/seq after 00000 batchs: 2410.78466796875
INFO:root:Train (Epoch 13): Loss/seq after 00050 batchs: 1797.0771484375
INFO:root:Train (Epoch 13): Loss/seq after 00100 batchs: 1764.3582763671875
INFO:root:Train (Epoch 13): Loss/seq after 00150 batchs: 1591.79296875
INFO:root:Train (Epoch 13): Loss/seq after 00200 batchs: 1705.8160400390625
INFO:root:Train (Epoch 13): Loss/seq after 00250 batchs: 1806.912841796875
INFO:root:Train (Epoch 13): Loss/seq after 00300 batchs: 1693.3328857421875
INFO:root:Train (Epoch 13): Loss/seq after 00350 batchs: 1577.4620361328125
INFO:root:Train (Epoch 13): Loss/seq after 00400 batchs: 1629.92041015625
INFO:root:Train (Epoch 13): Loss/seq after 00450 batchs: 1546.593994140625
INFO:root:Train (Epoch 13): Loss/seq after 00500 batchs: 1576.958251953125
INFO:root:Train (Epoch 13): Loss/seq after 00550 batchs: 1509.2742919921875
INFO:root:Train (Epoch 13): Loss/seq after 00600 batchs: 1472.93212890625
INFO:root:Train (Epoch 13): Loss/seq after 00650 batchs: 1517.4647216796875
INFO:root:Train (Epoch 13): Loss/seq after 00700 batchs: 1566.683349609375
INFO:root:Train (Epoch 13): Loss/seq after 00750 batchs: 1600.2672119140625
INFO:root:Train (Epoch 13): Loss/seq after 00800 batchs: 1586.215576171875
INFO:root:Train (Epoch 13): Loss/seq after 00850 batchs: 1550.9107666015625
INFO:root:Train (Epoch 13): Loss/seq after 00900 batchs: 1552.3546142578125
INFO:root:Train (Epoch 13): Loss/seq after 00950 batchs: 1627.8468017578125
INFO:root:Train (Epoch 13): Loss/seq after 01000 batchs: 1622.4075927734375
INFO:root:Train (Epoch 13): Loss/seq after 01050 batchs: 1601.43994140625
INFO:root:Train (Epoch 13): Loss/seq after 01100 batchs: 1589.988525390625
INFO:root:Train (Epoch 13): Loss/seq after 01150 batchs: 1564.5272216796875
INFO:root:Train (Epoch 13): Loss/seq after 01200 batchs: 1546.187255859375
INFO:root:Train (Epoch 13): Loss/seq after 01250 batchs: 1537.0054931640625
INFO:root:Train (Epoch 13): Loss/seq after 01300 batchs: 1543.7288818359375
INFO:root:Train (Epoch 13): Loss/seq after 01350 batchs: 1542.9678955078125
INFO:root:Train (Epoch 13): Loss/seq after 01400 batchs: 1582.6549072265625
INFO:root:Train (Epoch 13): Loss/seq after 01450 batchs: 1565.4488525390625
INFO:root:Train (Epoch 13): Loss/seq after 01500 batchs: 1549.3388671875
INFO:root:Train (Epoch 13): Loss/seq after 01550 batchs: 1548.924072265625
INFO:root:Train (Epoch 13): Loss/seq after 01600 batchs: 1525.9569091796875
INFO:root:Train (Epoch 13): Loss/seq after 01650 batchs: 1515.5740966796875
INFO:root:Train (Epoch 13): Loss/seq after 01700 batchs: 1501.8087158203125
INFO:root:Train (Epoch 13): Loss/seq after 01750 batchs: 1485.23291015625
INFO:root:Train (Epoch 13): Loss/seq after 01800 batchs: 1467.1221923828125
INFO:root:Train (Epoch 13): Loss/seq after 01850 batchs: 1448.9072265625
INFO:root:Train (Epoch 13): Loss/seq after 01900 batchs: 1443.9307861328125
INFO:root:Train (Epoch 13): Loss/seq after 01950 batchs: 1435.255859375
INFO:root:Train (Epoch 13): Loss/seq after 02000 batchs: 1422.12451171875
INFO:root:Train (Epoch 13): Loss/seq after 02050 batchs: 1410.67333984375
INFO:root:Train (Epoch 13): Loss/seq after 02100 batchs: 1396.0521240234375
INFO:root:Train (Epoch 13): Loss/seq after 02150 batchs: 1382.999755859375
INFO:root:Train (Epoch 13): Loss/seq after 02200 batchs: 1368.6776123046875
INFO:root:Train (Epoch 13): Loss/seq after 02250 batchs: 1371.46240234375
INFO:root:Train (Epoch 13): Loss/seq after 02300 batchs: 1374.0782470703125
INFO:root:Train (Epoch 13): Loss/seq after 02350 batchs: 1362.8436279296875
INFO:root:Train (Epoch 13): Loss/seq after 02400 batchs: 1356.7359619140625
INFO:root:Train (Epoch 13): Loss/seq after 02450 batchs: 1341.9906005859375
INFO:root:Train (Epoch 13): Loss/seq after 02500 batchs: 1322.580322265625
INFO:root:Train (Epoch 13): Loss/seq after 02550 batchs: 1309.952880859375
INFO:root:Train (Epoch 13): Loss/seq after 02600 batchs: 1306.937744140625
INFO:root:Train (Epoch 13): Loss/seq after 02650 batchs: 1301.0037841796875
INFO:root:Train (Epoch 13): Loss/seq after 02700 batchs: 1297.1536865234375
INFO:root:Train (Epoch 13): Loss/seq after 02750 batchs: 1328.138671875
INFO:root:Train (Epoch 13): Loss/seq after 02800 batchs: 1336.3385009765625
INFO:root:Train (Epoch 13): Loss/seq after 02850 batchs: 1332.7491455078125
INFO:root:Train (Epoch 13): Loss/seq after 02900 batchs: 1330.12646484375
INFO:root:Train (Epoch 13): Loss/seq after 02950 batchs: 1321.0654296875
INFO:root:Train (Epoch 13): Loss/seq after 03000 batchs: 1317.1959228515625
INFO:root:Train (Epoch 13): Loss/seq after 03050 batchs: 1318.23583984375
INFO:root:Train (Epoch 13): Loss/seq after 03100 batchs: 1333.123046875
INFO:root:Train (Epoch 13): Loss/seq after 03150 batchs: 1350.0865478515625
INFO:root:Train (Epoch 13): Loss/seq after 03200 batchs: 1360.388916015625
INFO:root:Train (Epoch 13): Loss/seq after 03250 batchs: 1368.7047119140625
INFO:root:Train (Epoch 13): Loss/seq after 03300 batchs: 1367.6456298828125
INFO:root:Train (Epoch 13): Loss/seq after 03350 batchs: 1366.876953125
INFO:root:Train (Epoch 13): Loss/seq after 03400 batchs: 1356.3853759765625
INFO:root:Train (Epoch 13): Loss/seq after 03450 batchs: 1349.546630859375
INFO:root:Train (Epoch 13): Loss/seq after 03500 batchs: 1348.46533203125
INFO:root:Train (Epoch 13): Loss/seq after 03550 batchs: 1342.6392822265625
INFO:root:Train (Epoch 13): Loss/seq after 03600 batchs: 1347.2364501953125
INFO:root:Train (Epoch 13): Loss/seq after 03650 batchs: 1341.7572021484375
INFO:root:Train (Epoch 13): Loss/seq after 03700 batchs: 1340.5093994140625
INFO:root:Train (Epoch 13): Loss/seq after 03750 batchs: 1338.93408203125
INFO:root:Train (Epoch 13): Loss/seq after 03800 batchs: 1330.7015380859375
INFO:root:Train (Epoch 13): Loss/seq after 03850 batchs: 1324.965087890625
INFO:root:Train (Epoch 13): Loss/seq after 03900 batchs: 1330.934326171875
INFO:root:Train (Epoch 13): Loss/seq after 03950 batchs: 1337.843994140625
INFO:root:Train (Epoch 13): Loss/seq after 04000 batchs: 1327.5416259765625
INFO:root:Train (Epoch 13): Loss/seq after 04050 batchs: 1318.2408447265625
INFO:root:Train (Epoch 13): Loss/seq after 04100 batchs: 1313.040283203125
INFO:root:Train (Epoch 13): Loss/seq after 04150 batchs: 1306.6068115234375
INFO:root:Train (Epoch 13): Loss/seq after 04200 batchs: 1300.843994140625
INFO:root:Train (Epoch 13): Loss/seq after 04250 batchs: 1295.69189453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 13): Loss/seq after 00000 batches: 926.4346923828125
INFO:root:# Valid (Epoch 13): Loss/seq after 00050 batches: 1113.1795654296875
INFO:root:# Valid (Epoch 13): Loss/seq after 00100 batches: 1445.5662841796875
INFO:root:# Valid (Epoch 13): Loss/seq after 00150 batches: 1225.0751953125
INFO:root:# Valid (Epoch 13): Loss/seq after 00200 batches: 1121.0888671875
INFO:root:Artifacts: Make stick videos for epoch 13
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_13_on_20220412_194133.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_13_index_1843_on_20220412_194133.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 14): Loss/seq after 00000 batchs: 1765.5029296875
INFO:root:Train (Epoch 14): Loss/seq after 00050 batchs: 1782.204833984375
INFO:root:Train (Epoch 14): Loss/seq after 00100 batchs: 1766.9696044921875
INFO:root:Train (Epoch 14): Loss/seq after 00150 batchs: 1582.265625
INFO:root:Train (Epoch 14): Loss/seq after 00200 batchs: 1704.6610107421875
INFO:root:Train (Epoch 14): Loss/seq after 00250 batchs: 1806.878173828125
INFO:root:Train (Epoch 14): Loss/seq after 00300 batchs: 1692.64306640625
INFO:root:Train (Epoch 14): Loss/seq after 00350 batchs: 1576.725830078125
INFO:root:Train (Epoch 14): Loss/seq after 00400 batchs: 1626.3592529296875
INFO:root:Train (Epoch 14): Loss/seq after 00450 batchs: 1543.33837890625
INFO:root:Train (Epoch 14): Loss/seq after 00500 batchs: 1572.93310546875
INFO:root:Train (Epoch 14): Loss/seq after 00550 batchs: 1506.22607421875
INFO:root:Train (Epoch 14): Loss/seq after 00600 batchs: 1470.1942138671875
INFO:root:Train (Epoch 14): Loss/seq after 00650 batchs: 1516.689453125
INFO:root:Train (Epoch 14): Loss/seq after 00700 batchs: 1565.322265625
INFO:root:Train (Epoch 14): Loss/seq after 00750 batchs: 1604.590087890625
INFO:root:Train (Epoch 14): Loss/seq after 00800 batchs: 1590.010986328125
INFO:root:Train (Epoch 14): Loss/seq after 00850 batchs: 1554.4892578125
INFO:root:Train (Epoch 14): Loss/seq after 00900 batchs: 1555.783447265625
INFO:root:Train (Epoch 14): Loss/seq after 00950 batchs: 1627.24462890625
INFO:root:Train (Epoch 14): Loss/seq after 01000 batchs: 1625.0465087890625
INFO:root:Train (Epoch 14): Loss/seq after 01050 batchs: 1602.814697265625
INFO:root:Train (Epoch 14): Loss/seq after 01100 batchs: 1589.376708984375
INFO:root:Train (Epoch 14): Loss/seq after 01150 batchs: 1563.7125244140625
INFO:root:Train (Epoch 14): Loss/seq after 01200 batchs: 1545.2105712890625
INFO:root:Train (Epoch 14): Loss/seq after 01250 batchs: 1535.0391845703125
INFO:root:Train (Epoch 14): Loss/seq after 01300 batchs: 1543.2523193359375
INFO:root:Train (Epoch 14): Loss/seq after 01350 batchs: 1543.2989501953125
INFO:root:Train (Epoch 14): Loss/seq after 01400 batchs: 1585.52099609375
INFO:root:Train (Epoch 14): Loss/seq after 01450 batchs: 1567.81396484375
INFO:root:Train (Epoch 14): Loss/seq after 01500 batchs: 1551.8463134765625
INFO:root:Train (Epoch 14): Loss/seq after 01550 batchs: 1551.0836181640625
INFO:root:Train (Epoch 14): Loss/seq after 01600 batchs: 1528.08935546875
INFO:root:Train (Epoch 14): Loss/seq after 01650 batchs: 1518.0794677734375
INFO:root:Train (Epoch 14): Loss/seq after 01700 batchs: 1503.9417724609375
INFO:root:Train (Epoch 14): Loss/seq after 01750 batchs: 1487.3170166015625
INFO:root:Train (Epoch 14): Loss/seq after 01800 batchs: 1469.213134765625
INFO:root:Train (Epoch 14): Loss/seq after 01850 batchs: 1450.9609375
INFO:root:Train (Epoch 14): Loss/seq after 01900 batchs: 1445.885009765625
INFO:root:Train (Epoch 14): Loss/seq after 01950 batchs: 1437.197998046875
INFO:root:Train (Epoch 14): Loss/seq after 02000 batchs: 1424.041748046875
INFO:root:Train (Epoch 14): Loss/seq after 02050 batchs: 1412.6549072265625
INFO:root:Train (Epoch 14): Loss/seq after 02100 batchs: 1397.9791259765625
INFO:root:Train (Epoch 14): Loss/seq after 02150 batchs: 1384.8729248046875
INFO:root:Train (Epoch 14): Loss/seq after 02200 batchs: 1370.5390625
INFO:root:Train (Epoch 14): Loss/seq after 02250 batchs: 1373.90234375
INFO:root:Train (Epoch 14): Loss/seq after 02300 batchs: 1377.001220703125
INFO:root:Train (Epoch 14): Loss/seq after 02350 batchs: 1365.9376220703125
INFO:root:Train (Epoch 14): Loss/seq after 02400 batchs: 1359.7779541015625
INFO:root:Train (Epoch 14): Loss/seq after 02450 batchs: 1345.10009765625
INFO:root:Train (Epoch 14): Loss/seq after 02500 batchs: 1325.6046142578125
INFO:root:Train (Epoch 14): Loss/seq after 02550 batchs: 1312.7935791015625
INFO:root:Train (Epoch 14): Loss/seq after 02600 batchs: 1309.8173828125
INFO:root:Train (Epoch 14): Loss/seq after 02650 batchs: 1303.8148193359375
INFO:root:Train (Epoch 14): Loss/seq after 02700 batchs: 1299.8609619140625
INFO:root:Train (Epoch 14): Loss/seq after 02750 batchs: 1330.869873046875
INFO:root:Train (Epoch 14): Loss/seq after 02800 batchs: 1338.4671630859375
INFO:root:Train (Epoch 14): Loss/seq after 02850 batchs: 1334.9132080078125
INFO:root:Train (Epoch 14): Loss/seq after 02900 batchs: 1331.7017822265625
INFO:root:Train (Epoch 14): Loss/seq after 02950 batchs: 1322.567138671875
INFO:root:Train (Epoch 14): Loss/seq after 03000 batchs: 1318.67138671875
INFO:root:Train (Epoch 14): Loss/seq after 03050 batchs: 1319.6929931640625
INFO:root:Train (Epoch 14): Loss/seq after 03100 batchs: 1334.7276611328125
INFO:root:Train (Epoch 14): Loss/seq after 03150 batchs: 1349.954345703125
INFO:root:Train (Epoch 14): Loss/seq after 03200 batchs: 1360.6329345703125
INFO:root:Train (Epoch 14): Loss/seq after 03250 batchs: 1367.872314453125
INFO:root:Train (Epoch 14): Loss/seq after 03300 batchs: 1366.5745849609375
INFO:root:Train (Epoch 14): Loss/seq after 03350 batchs: 1367.3258056640625
INFO:root:Train (Epoch 14): Loss/seq after 03400 batchs: 1356.991455078125
INFO:root:Train (Epoch 14): Loss/seq after 03450 batchs: 1349.249267578125
INFO:root:Train (Epoch 14): Loss/seq after 03500 batchs: 1348.855224609375
INFO:root:Train (Epoch 14): Loss/seq after 03550 batchs: 1342.8082275390625
INFO:root:Train (Epoch 14): Loss/seq after 03600 batchs: 1347.31982421875
INFO:root:Train (Epoch 14): Loss/seq after 03650 batchs: 1342.9276123046875
INFO:root:Train (Epoch 14): Loss/seq after 03700 batchs: 1341.95361328125
INFO:root:Train (Epoch 14): Loss/seq after 03750 batchs: 1340.3636474609375
INFO:root:Train (Epoch 14): Loss/seq after 03800 batchs: 1332.0123291015625
INFO:root:Train (Epoch 14): Loss/seq after 03850 batchs: 1326.2352294921875
INFO:root:Train (Epoch 14): Loss/seq after 03900 batchs: 1333.56396484375
INFO:root:Train (Epoch 14): Loss/seq after 03950 batchs: 1340.361083984375
INFO:root:Train (Epoch 14): Loss/seq after 04000 batchs: 1330.025390625
INFO:root:Train (Epoch 14): Loss/seq after 04050 batchs: 1320.6810302734375
INFO:root:Train (Epoch 14): Loss/seq after 04100 batchs: 1315.1607666015625
INFO:root:Train (Epoch 14): Loss/seq after 04150 batchs: 1308.326904296875
INFO:root:Train (Epoch 14): Loss/seq after 04200 batchs: 1302.723876953125
INFO:root:Train (Epoch 14): Loss/seq after 04250 batchs: 1297.629150390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 14): Loss/seq after 00000 batches: 900.0684204101562
INFO:root:# Valid (Epoch 14): Loss/seq after 00050 batches: 1104.7437744140625
INFO:root:# Valid (Epoch 14): Loss/seq after 00100 batches: 1420.9652099609375
INFO:root:# Valid (Epoch 14): Loss/seq after 00150 batches: 1173.5230712890625
INFO:root:# Valid (Epoch 14): Loss/seq after 00200 batches: 1064.9522705078125
INFO:root:Artifacts: Make stick videos for epoch 14
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_14_on_20220412_194655.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_14_index_108_on_20220412_194655.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 15): Loss/seq after 00000 batchs: 2443.243408203125
INFO:root:Train (Epoch 15): Loss/seq after 00050 batchs: 1843.4818115234375
INFO:root:Train (Epoch 15): Loss/seq after 00100 batchs: 1839.5029296875
INFO:root:Train (Epoch 15): Loss/seq after 00150 batchs: 1609.4765625
INFO:root:Train (Epoch 15): Loss/seq after 00200 batchs: 1725.5826416015625
INFO:root:Train (Epoch 15): Loss/seq after 00250 batchs: 1824.9215087890625
INFO:root:Train (Epoch 15): Loss/seq after 00300 batchs: 1707.6405029296875
INFO:root:Train (Epoch 15): Loss/seq after 00350 batchs: 1589.701416015625
INFO:root:Train (Epoch 15): Loss/seq after 00400 batchs: 1647.21875
INFO:root:Train (Epoch 15): Loss/seq after 00450 batchs: 1561.838134765625
INFO:root:Train (Epoch 15): Loss/seq after 00500 batchs: 1589.9605712890625
INFO:root:Train (Epoch 15): Loss/seq after 00550 batchs: 1521.161376953125
INFO:root:Train (Epoch 15): Loss/seq after 00600 batchs: 1482.6368408203125
INFO:root:Train (Epoch 15): Loss/seq after 00650 batchs: 1515.1649169921875
INFO:root:Train (Epoch 15): Loss/seq after 00700 batchs: 1565.1656494140625
INFO:root:Train (Epoch 15): Loss/seq after 00750 batchs: 1602.0001220703125
INFO:root:Train (Epoch 15): Loss/seq after 00800 batchs: 1586.710693359375
INFO:root:Train (Epoch 15): Loss/seq after 00850 batchs: 1550.496337890625
INFO:root:Train (Epoch 15): Loss/seq after 00900 batchs: 1552.0693359375
INFO:root:Train (Epoch 15): Loss/seq after 00950 batchs: 1617.8621826171875
INFO:root:Train (Epoch 15): Loss/seq after 01000 batchs: 1613.959228515625
INFO:root:Train (Epoch 15): Loss/seq after 01050 batchs: 1591.8804931640625
INFO:root:Train (Epoch 15): Loss/seq after 01100 batchs: 1578.06591796875
INFO:root:Train (Epoch 15): Loss/seq after 01150 batchs: 1552.3253173828125
INFO:root:Train (Epoch 15): Loss/seq after 01200 batchs: 1533.947021484375
INFO:root:Train (Epoch 15): Loss/seq after 01250 batchs: 1524.888916015625
INFO:root:Train (Epoch 15): Loss/seq after 01300 batchs: 1528.3538818359375
INFO:root:Train (Epoch 15): Loss/seq after 01350 batchs: 1524.802001953125
INFO:root:Train (Epoch 15): Loss/seq after 01400 batchs: 1565.9630126953125
INFO:root:Train (Epoch 15): Loss/seq after 01450 batchs: 1549.4384765625
INFO:root:Train (Epoch 15): Loss/seq after 01500 batchs: 1534.1527099609375
INFO:root:Train (Epoch 15): Loss/seq after 01550 batchs: 1533.7154541015625
INFO:root:Train (Epoch 15): Loss/seq after 01600 batchs: 1511.672607421875
INFO:root:Train (Epoch 15): Loss/seq after 01650 batchs: 1502.0047607421875
INFO:root:Train (Epoch 15): Loss/seq after 01700 batchs: 1488.335205078125
INFO:root:Train (Epoch 15): Loss/seq after 01750 batchs: 1471.948486328125
INFO:root:Train (Epoch 15): Loss/seq after 01800 batchs: 1454.227783203125
INFO:root:Train (Epoch 15): Loss/seq after 01850 batchs: 1436.3927001953125
INFO:root:Train (Epoch 15): Loss/seq after 01900 batchs: 1431.736328125
INFO:root:Train (Epoch 15): Loss/seq after 01950 batchs: 1423.4002685546875
INFO:root:Train (Epoch 15): Loss/seq after 02000 batchs: 1410.5745849609375
INFO:root:Train (Epoch 15): Loss/seq after 02050 batchs: 1399.4752197265625
INFO:root:Train (Epoch 15): Loss/seq after 02100 batchs: 1385.1123046875
INFO:root:Train (Epoch 15): Loss/seq after 02150 batchs: 1372.277587890625
INFO:root:Train (Epoch 15): Loss/seq after 02200 batchs: 1358.231201171875
INFO:root:Train (Epoch 15): Loss/seq after 02250 batchs: 1360.9599609375
INFO:root:Train (Epoch 15): Loss/seq after 02300 batchs: 1364.1241455078125
INFO:root:Train (Epoch 15): Loss/seq after 02350 batchs: 1352.8721923828125
INFO:root:Train (Epoch 15): Loss/seq after 02400 batchs: 1346.8687744140625
INFO:root:Train (Epoch 15): Loss/seq after 02450 batchs: 1332.3795166015625
INFO:root:Train (Epoch 15): Loss/seq after 02500 batchs: 1313.0623779296875
INFO:root:Train (Epoch 15): Loss/seq after 02550 batchs: 1300.40966796875
INFO:root:Train (Epoch 15): Loss/seq after 02600 batchs: 1296.9942626953125
INFO:root:Train (Epoch 15): Loss/seq after 02650 batchs: 1290.433837890625
INFO:root:Train (Epoch 15): Loss/seq after 02700 batchs: 1286.26806640625
INFO:root:Train (Epoch 15): Loss/seq after 02750 batchs: 1316.8668212890625
INFO:root:Train (Epoch 15): Loss/seq after 02800 batchs: 1324.5389404296875
INFO:root:Train (Epoch 15): Loss/seq after 02850 batchs: 1320.985595703125
INFO:root:Train (Epoch 15): Loss/seq after 02900 batchs: 1318.336669921875
INFO:root:Train (Epoch 15): Loss/seq after 02950 batchs: 1309.228759765625
INFO:root:Train (Epoch 15): Loss/seq after 03000 batchs: 1305.5255126953125
INFO:root:Train (Epoch 15): Loss/seq after 03050 batchs: 1306.664306640625
INFO:root:Train (Epoch 15): Loss/seq after 03100 batchs: 1322.607666015625
INFO:root:Train (Epoch 15): Loss/seq after 03150 batchs: 1339.1844482421875
INFO:root:Train (Epoch 15): Loss/seq after 03200 batchs: 1348.05078125
INFO:root:Train (Epoch 15): Loss/seq after 03250 batchs: 1355.7486572265625
INFO:root:Train (Epoch 15): Loss/seq after 03300 batchs: 1357.16162109375
INFO:root:Train (Epoch 15): Loss/seq after 03350 batchs: 1357.3023681640625
INFO:root:Train (Epoch 15): Loss/seq after 03400 batchs: 1347.040771484375
INFO:root:Train (Epoch 15): Loss/seq after 03450 batchs: 1338.8463134765625
INFO:root:Train (Epoch 15): Loss/seq after 03500 batchs: 1338.156494140625
INFO:root:Train (Epoch 15): Loss/seq after 03550 batchs: 1331.885498046875
INFO:root:Train (Epoch 15): Loss/seq after 03600 batchs: 1336.3551025390625
INFO:root:Train (Epoch 15): Loss/seq after 03650 batchs: 1330.8251953125
INFO:root:Train (Epoch 15): Loss/seq after 03700 batchs: 1329.3917236328125
INFO:root:Train (Epoch 15): Loss/seq after 03750 batchs: 1328.0220947265625
INFO:root:Train (Epoch 15): Loss/seq after 03800 batchs: 1319.8336181640625
INFO:root:Train (Epoch 15): Loss/seq after 03850 batchs: 1314.20947265625
INFO:root:Train (Epoch 15): Loss/seq after 03900 batchs: 1321.1134033203125
INFO:root:Train (Epoch 15): Loss/seq after 03950 batchs: 1326.8419189453125
INFO:root:Train (Epoch 15): Loss/seq after 04000 batchs: 1316.62451171875
INFO:root:Train (Epoch 15): Loss/seq after 04050 batchs: 1307.428955078125
INFO:root:Train (Epoch 15): Loss/seq after 04100 batchs: 1301.9298095703125
INFO:root:Train (Epoch 15): Loss/seq after 04150 batchs: 1295.233642578125
INFO:root:Train (Epoch 15): Loss/seq after 04200 batchs: 1289.295654296875
INFO:root:Train (Epoch 15): Loss/seq after 04250 batchs: 1284.3746337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 15): Loss/seq after 00000 batches: 891.6826782226562
INFO:root:# Valid (Epoch 15): Loss/seq after 00050 batches: 1102.3685302734375
INFO:root:# Valid (Epoch 15): Loss/seq after 00100 batches: 1415.7193603515625
INFO:root:# Valid (Epoch 15): Loss/seq after 00150 batches: 1164.51513671875
INFO:root:# Valid (Epoch 15): Loss/seq after 00200 batches: 1053.017822265625
INFO:root:Artifacts: Make stick videos for epoch 15
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_15_on_20220412_195218.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_15_index_188_on_20220412_195218.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 16): Loss/seq after 00000 batchs: 2094.739013671875
INFO:root:Train (Epoch 16): Loss/seq after 00050 batchs: 1720.9215087890625
INFO:root:Train (Epoch 16): Loss/seq after 00100 batchs: 1702.44287109375
INFO:root:Train (Epoch 16): Loss/seq after 00150 batchs: 1508.3851318359375
INFO:root:Train (Epoch 16): Loss/seq after 00200 batchs: 1618.3968505859375
INFO:root:Train (Epoch 16): Loss/seq after 00250 batchs: 1734.3543701171875
INFO:root:Train (Epoch 16): Loss/seq after 00300 batchs: 1630.482421875
INFO:root:Train (Epoch 16): Loss/seq after 00350 batchs: 1523.378173828125
INFO:root:Train (Epoch 16): Loss/seq after 00400 batchs: 1578.0638427734375
INFO:root:Train (Epoch 16): Loss/seq after 00450 batchs: 1500.4000244140625
INFO:root:Train (Epoch 16): Loss/seq after 00500 batchs: 1532.031005859375
INFO:root:Train (Epoch 16): Loss/seq after 00550 batchs: 1468.9146728515625
INFO:root:Train (Epoch 16): Loss/seq after 00600 batchs: 1434.2889404296875
INFO:root:Train (Epoch 16): Loss/seq after 00650 batchs: 1470.69580078125
INFO:root:Train (Epoch 16): Loss/seq after 00700 batchs: 1517.5628662109375
INFO:root:Train (Epoch 16): Loss/seq after 00750 batchs: 1553.3642578125
INFO:root:Train (Epoch 16): Loss/seq after 00800 batchs: 1541.1070556640625
INFO:root:Train (Epoch 16): Loss/seq after 00850 batchs: 1506.8055419921875
INFO:root:Train (Epoch 16): Loss/seq after 00900 batchs: 1510.770751953125
INFO:root:Train (Epoch 16): Loss/seq after 00950 batchs: 1577.3360595703125
INFO:root:Train (Epoch 16): Loss/seq after 01000 batchs: 1574.9259033203125
INFO:root:Train (Epoch 16): Loss/seq after 01050 batchs: 1553.5244140625
INFO:root:Train (Epoch 16): Loss/seq after 01100 batchs: 1541.2686767578125
INFO:root:Train (Epoch 16): Loss/seq after 01150 batchs: 1517.05517578125
INFO:root:Train (Epoch 16): Loss/seq after 01200 batchs: 1499.973388671875
INFO:root:Train (Epoch 16): Loss/seq after 01250 batchs: 1490.2481689453125
INFO:root:Train (Epoch 16): Loss/seq after 01300 batchs: 1493.3614501953125
INFO:root:Train (Epoch 16): Loss/seq after 01350 batchs: 1492.531982421875
INFO:root:Train (Epoch 16): Loss/seq after 01400 batchs: 1528.2203369140625
INFO:root:Train (Epoch 16): Loss/seq after 01450 batchs: 1512.6865234375
INFO:root:Train (Epoch 16): Loss/seq after 01500 batchs: 1498.94677734375
INFO:root:Train (Epoch 16): Loss/seq after 01550 batchs: 1499.0052490234375
INFO:root:Train (Epoch 16): Loss/seq after 01600 batchs: 1477.656494140625
INFO:root:Train (Epoch 16): Loss/seq after 01650 batchs: 1468.6456298828125
INFO:root:Train (Epoch 16): Loss/seq after 01700 batchs: 1455.88134765625
INFO:root:Train (Epoch 16): Loss/seq after 01750 batchs: 1440.431396484375
INFO:root:Train (Epoch 16): Loss/seq after 01800 batchs: 1423.596435546875
INFO:root:Train (Epoch 16): Loss/seq after 01850 batchs: 1406.6015625
INFO:root:Train (Epoch 16): Loss/seq after 01900 batchs: 1402.7059326171875
INFO:root:Train (Epoch 16): Loss/seq after 01950 batchs: 1395.1142578125
INFO:root:Train (Epoch 16): Loss/seq after 02000 batchs: 1382.9954833984375
INFO:root:Train (Epoch 16): Loss/seq after 02050 batchs: 1372.5938720703125
INFO:root:Train (Epoch 16): Loss/seq after 02100 batchs: 1358.8702392578125
INFO:root:Train (Epoch 16): Loss/seq after 02150 batchs: 1346.645751953125
INFO:root:Train (Epoch 16): Loss/seq after 02200 batchs: 1333.1641845703125
INFO:root:Train (Epoch 16): Loss/seq after 02250 batchs: 1336.358642578125
INFO:root:Train (Epoch 16): Loss/seq after 02300 batchs: 1342.2899169921875
INFO:root:Train (Epoch 16): Loss/seq after 02350 batchs: 1331.385986328125
INFO:root:Train (Epoch 16): Loss/seq after 02400 batchs: 1325.9266357421875
INFO:root:Train (Epoch 16): Loss/seq after 02450 batchs: 1311.8336181640625
INFO:root:Train (Epoch 16): Loss/seq after 02500 batchs: 1292.951171875
INFO:root:Train (Epoch 16): Loss/seq after 02550 batchs: 1280.783447265625
INFO:root:Train (Epoch 16): Loss/seq after 02600 batchs: 1277.748779296875
INFO:root:Train (Epoch 16): Loss/seq after 02650 batchs: 1271.682861328125
INFO:root:Train (Epoch 16): Loss/seq after 02700 batchs: 1267.641845703125
INFO:root:Train (Epoch 16): Loss/seq after 02750 batchs: 1298.939453125
INFO:root:Train (Epoch 16): Loss/seq after 02800 batchs: 1305.8870849609375
INFO:root:Train (Epoch 16): Loss/seq after 02850 batchs: 1302.7950439453125
INFO:root:Train (Epoch 16): Loss/seq after 02900 batchs: 1300.3345947265625
INFO:root:Train (Epoch 16): Loss/seq after 02950 batchs: 1291.9822998046875
INFO:root:Train (Epoch 16): Loss/seq after 03000 batchs: 1288.5986328125
INFO:root:Train (Epoch 16): Loss/seq after 03050 batchs: 1290.104248046875
INFO:root:Train (Epoch 16): Loss/seq after 03100 batchs: 1305.109375
INFO:root:Train (Epoch 16): Loss/seq after 03150 batchs: 1321.8326416015625
INFO:root:Train (Epoch 16): Loss/seq after 03200 batchs: 1330.6805419921875
INFO:root:Train (Epoch 16): Loss/seq after 03250 batchs: 1337.0850830078125
INFO:root:Train (Epoch 16): Loss/seq after 03300 batchs: 1335.7279052734375
INFO:root:Train (Epoch 16): Loss/seq after 03350 batchs: 1335.280517578125
INFO:root:Train (Epoch 16): Loss/seq after 03400 batchs: 1325.2655029296875
INFO:root:Train (Epoch 16): Loss/seq after 03450 batchs: 1317.779296875
INFO:root:Train (Epoch 16): Loss/seq after 03500 batchs: 1317.729736328125
INFO:root:Train (Epoch 16): Loss/seq after 03550 batchs: 1312.1182861328125
INFO:root:Train (Epoch 16): Loss/seq after 03600 batchs: 1317.0186767578125
INFO:root:Train (Epoch 16): Loss/seq after 03650 batchs: 1311.9049072265625
INFO:root:Train (Epoch 16): Loss/seq after 03700 batchs: 1310.723388671875
INFO:root:Train (Epoch 16): Loss/seq after 03750 batchs: 1309.5526123046875
INFO:root:Train (Epoch 16): Loss/seq after 03800 batchs: 1301.678955078125
INFO:root:Train (Epoch 16): Loss/seq after 03850 batchs: 1296.3076171875
INFO:root:Train (Epoch 16): Loss/seq after 03900 batchs: 1302.8787841796875
INFO:root:Train (Epoch 16): Loss/seq after 03950 batchs: 1309.4775390625
INFO:root:Train (Epoch 16): Loss/seq after 04000 batchs: 1299.4991455078125
INFO:root:Train (Epoch 16): Loss/seq after 04050 batchs: 1290.53271484375
INFO:root:Train (Epoch 16): Loss/seq after 04100 batchs: 1285.3740234375
INFO:root:Train (Epoch 16): Loss/seq after 04150 batchs: 1279.0548095703125
INFO:root:Train (Epoch 16): Loss/seq after 04200 batchs: 1273.3890380859375
INFO:root:Train (Epoch 16): Loss/seq after 04250 batchs: 1268.376220703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 16): Loss/seq after 00000 batches: 913.7357788085938
INFO:root:# Valid (Epoch 16): Loss/seq after 00050 batches: 1109.8636474609375
INFO:root:# Valid (Epoch 16): Loss/seq after 00100 batches: 1426.986083984375
INFO:root:# Valid (Epoch 16): Loss/seq after 00150 batches: 1204.3814697265625
INFO:root:# Valid (Epoch 16): Loss/seq after 00200 batches: 1097.699951171875
INFO:root:Artifacts: Make stick videos for epoch 16
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_16_on_20220412_195741.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_16_index_1559_on_20220412_195741.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 17): Loss/seq after 00000 batchs: 2840.3134765625
INFO:root:Train (Epoch 17): Loss/seq after 00050 batchs: 1729.2122802734375
INFO:root:Train (Epoch 17): Loss/seq after 00100 batchs: 1691.9210205078125
INFO:root:Train (Epoch 17): Loss/seq after 00150 batchs: 1503.9776611328125
INFO:root:Train (Epoch 17): Loss/seq after 00200 batchs: 1630.392822265625
INFO:root:Train (Epoch 17): Loss/seq after 00250 batchs: 1747.12646484375
INFO:root:Train (Epoch 17): Loss/seq after 00300 batchs: 1641.17626953125
INFO:root:Train (Epoch 17): Loss/seq after 00350 batchs: 1532.7293701171875
INFO:root:Train (Epoch 17): Loss/seq after 00400 batchs: 1588.9996337890625
INFO:root:Train (Epoch 17): Loss/seq after 00450 batchs: 1510.161376953125
INFO:root:Train (Epoch 17): Loss/seq after 00500 batchs: 1546.088623046875
INFO:root:Train (Epoch 17): Loss/seq after 00550 batchs: 1484.0145263671875
INFO:root:Train (Epoch 17): Loss/seq after 00600 batchs: 1449.68408203125
INFO:root:Train (Epoch 17): Loss/seq after 00650 batchs: 1482.356689453125
INFO:root:Train (Epoch 17): Loss/seq after 00700 batchs: 1522.7066650390625
INFO:root:Train (Epoch 17): Loss/seq after 00750 batchs: 1558.6988525390625
INFO:root:Train (Epoch 17): Loss/seq after 00800 batchs: 1547.2379150390625
INFO:root:Train (Epoch 17): Loss/seq after 00850 batchs: 1516.7066650390625
INFO:root:Train (Epoch 17): Loss/seq after 00900 batchs: 1519.7982177734375
INFO:root:Train (Epoch 17): Loss/seq after 00950 batchs: 1580.067138671875
INFO:root:Train (Epoch 17): Loss/seq after 01000 batchs: 1575.94873046875
INFO:root:Train (Epoch 17): Loss/seq after 01050 batchs: 1555.789794921875
INFO:root:Train (Epoch 17): Loss/seq after 01100 batchs: 1544.0338134765625
INFO:root:Train (Epoch 17): Loss/seq after 01150 batchs: 1520.4212646484375
INFO:root:Train (Epoch 17): Loss/seq after 01200 batchs: 1505.021484375
INFO:root:Train (Epoch 17): Loss/seq after 01250 batchs: 1496.0291748046875
INFO:root:Train (Epoch 17): Loss/seq after 01300 batchs: 1502.69140625
INFO:root:Train (Epoch 17): Loss/seq after 01350 batchs: 1503.3682861328125
INFO:root:Train (Epoch 17): Loss/seq after 01400 batchs: 1535.680419921875
INFO:root:Train (Epoch 17): Loss/seq after 01450 batchs: 1520.0015869140625
INFO:root:Train (Epoch 17): Loss/seq after 01500 batchs: 1505.0738525390625
INFO:root:Train (Epoch 17): Loss/seq after 01550 batchs: 1506.1190185546875
INFO:root:Train (Epoch 17): Loss/seq after 01600 batchs: 1484.3365478515625
INFO:root:Train (Epoch 17): Loss/seq after 01650 batchs: 1475.3455810546875
INFO:root:Train (Epoch 17): Loss/seq after 01700 batchs: 1462.13134765625
INFO:root:Train (Epoch 17): Loss/seq after 01750 batchs: 1446.27734375
INFO:root:Train (Epoch 17): Loss/seq after 01800 batchs: 1428.703125
INFO:root:Train (Epoch 17): Loss/seq after 01850 batchs: 1411.5418701171875
INFO:root:Train (Epoch 17): Loss/seq after 01900 batchs: 1407.2567138671875
INFO:root:Train (Epoch 17): Loss/seq after 01950 batchs: 1399.7730712890625
INFO:root:Train (Epoch 17): Loss/seq after 02000 batchs: 1387.3294677734375
INFO:root:Train (Epoch 17): Loss/seq after 02050 batchs: 1376.6241455078125
INFO:root:Train (Epoch 17): Loss/seq after 02100 batchs: 1362.781494140625
INFO:root:Train (Epoch 17): Loss/seq after 02150 batchs: 1350.1536865234375
INFO:root:Train (Epoch 17): Loss/seq after 02200 batchs: 1336.520751953125
INFO:root:Train (Epoch 17): Loss/seq after 02250 batchs: 1339.309326171875
INFO:root:Train (Epoch 17): Loss/seq after 02300 batchs: 1344.2103271484375
INFO:root:Train (Epoch 17): Loss/seq after 02350 batchs: 1333.2689208984375
INFO:root:Train (Epoch 17): Loss/seq after 02400 batchs: 1328.05224609375
INFO:root:Train (Epoch 17): Loss/seq after 02450 batchs: 1314.3721923828125
INFO:root:Train (Epoch 17): Loss/seq after 02500 batchs: 1295.5262451171875
INFO:root:Train (Epoch 17): Loss/seq after 02550 batchs: 1283.840087890625
INFO:root:Train (Epoch 17): Loss/seq after 02600 batchs: 1283.4697265625
INFO:root:Train (Epoch 17): Loss/seq after 02650 batchs: 1278.7088623046875
INFO:root:Train (Epoch 17): Loss/seq after 02700 batchs: 1275.7410888671875
INFO:root:Train (Epoch 17): Loss/seq after 02750 batchs: 1305.9598388671875
INFO:root:Train (Epoch 17): Loss/seq after 02800 batchs: 1314.7242431640625
INFO:root:Train (Epoch 17): Loss/seq after 02850 batchs: 1311.339599609375
INFO:root:Train (Epoch 17): Loss/seq after 02900 batchs: 1308.4949951171875
INFO:root:Train (Epoch 17): Loss/seq after 02950 batchs: 1299.911376953125
INFO:root:Train (Epoch 17): Loss/seq after 03000 batchs: 1296.3863525390625
INFO:root:Train (Epoch 17): Loss/seq after 03050 batchs: 1297.7415771484375
INFO:root:Train (Epoch 17): Loss/seq after 03100 batchs: 1312.38818359375
INFO:root:Train (Epoch 17): Loss/seq after 03150 batchs: 1324.224609375
INFO:root:Train (Epoch 17): Loss/seq after 03200 batchs: 1331.3841552734375
INFO:root:Train (Epoch 17): Loss/seq after 03250 batchs: 1339.0736083984375
INFO:root:Train (Epoch 17): Loss/seq after 03300 batchs: 1337.282958984375
INFO:root:Train (Epoch 17): Loss/seq after 03350 batchs: 1336.732177734375
INFO:root:Train (Epoch 17): Loss/seq after 03400 batchs: 1326.673095703125
INFO:root:Train (Epoch 17): Loss/seq after 03450 batchs: 1318.990966796875
INFO:root:Train (Epoch 17): Loss/seq after 03500 batchs: 1318.79052734375
INFO:root:Train (Epoch 17): Loss/seq after 03550 batchs: 1313.320068359375
INFO:root:Train (Epoch 17): Loss/seq after 03600 batchs: 1318.1146240234375
INFO:root:Train (Epoch 17): Loss/seq after 03650 batchs: 1312.9105224609375
INFO:root:Train (Epoch 17): Loss/seq after 03700 batchs: 1311.582763671875
INFO:root:Train (Epoch 17): Loss/seq after 03750 batchs: 1310.2713623046875
INFO:root:Train (Epoch 17): Loss/seq after 03800 batchs: 1302.299072265625
INFO:root:Train (Epoch 17): Loss/seq after 03850 batchs: 1296.890869140625
INFO:root:Train (Epoch 17): Loss/seq after 03900 batchs: 1302.640625
INFO:root:Train (Epoch 17): Loss/seq after 03950 batchs: 1308.0810546875
INFO:root:Train (Epoch 17): Loss/seq after 04000 batchs: 1298.1063232421875
INFO:root:Train (Epoch 17): Loss/seq after 04050 batchs: 1289.1463623046875
INFO:root:Train (Epoch 17): Loss/seq after 04100 batchs: 1283.8038330078125
INFO:root:Train (Epoch 17): Loss/seq after 04150 batchs: 1277.300048828125
INFO:root:Train (Epoch 17): Loss/seq after 04200 batchs: 1271.6583251953125
INFO:root:Train (Epoch 17): Loss/seq after 04250 batchs: 1266.646728515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 17): Loss/seq after 00000 batches: 905.7794189453125
INFO:root:# Valid (Epoch 17): Loss/seq after 00050 batches: 1106.0382080078125
INFO:root:# Valid (Epoch 17): Loss/seq after 00100 batches: 1412.161376953125
INFO:root:# Valid (Epoch 17): Loss/seq after 00150 batches: 1146.756103515625
INFO:root:# Valid (Epoch 17): Loss/seq after 00200 batches: 1034.83251953125
INFO:root:Artifacts: Make stick videos for epoch 17
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_17_on_20220412_200308.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_17_index_1843_on_20220412_200308.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 18): Loss/seq after 00000 batchs: 3761.497802734375
INFO:root:Train (Epoch 18): Loss/seq after 00050 batchs: 1746.744873046875
INFO:root:Train (Epoch 18): Loss/seq after 00100 batchs: 1712.2099609375
INFO:root:Train (Epoch 18): Loss/seq after 00150 batchs: 1519.3431396484375
INFO:root:Train (Epoch 18): Loss/seq after 00200 batchs: 1619.9420166015625
INFO:root:Train (Epoch 18): Loss/seq after 00250 batchs: 1737.5357666015625
INFO:root:Train (Epoch 18): Loss/seq after 00300 batchs: 1633.2166748046875
INFO:root:Train (Epoch 18): Loss/seq after 00350 batchs: 1525.4879150390625
INFO:root:Train (Epoch 18): Loss/seq after 00400 batchs: 1578.3201904296875
INFO:root:Train (Epoch 18): Loss/seq after 00450 batchs: 1500.570068359375
INFO:root:Train (Epoch 18): Loss/seq after 00500 batchs: 1530.985595703125
INFO:root:Train (Epoch 18): Loss/seq after 00550 batchs: 1467.6966552734375
INFO:root:Train (Epoch 18): Loss/seq after 00600 batchs: 1431.5064697265625
INFO:root:Train (Epoch 18): Loss/seq after 00650 batchs: 1461.885498046875
INFO:root:Train (Epoch 18): Loss/seq after 00700 batchs: 1501.3746337890625
INFO:root:Train (Epoch 18): Loss/seq after 00750 batchs: 1534.496826171875
INFO:root:Train (Epoch 18): Loss/seq after 00800 batchs: 1523.496826171875
INFO:root:Train (Epoch 18): Loss/seq after 00850 batchs: 1489.738525390625
INFO:root:Train (Epoch 18): Loss/seq after 00900 batchs: 1494.912841796875
INFO:root:Train (Epoch 18): Loss/seq after 00950 batchs: 1554.185791015625
INFO:root:Train (Epoch 18): Loss/seq after 01000 batchs: 1552.017822265625
INFO:root:Train (Epoch 18): Loss/seq after 01050 batchs: 1532.2322998046875
INFO:root:Train (Epoch 18): Loss/seq after 01100 batchs: 1523.2587890625
INFO:root:Train (Epoch 18): Loss/seq after 01150 batchs: 1500.7347412109375
INFO:root:Train (Epoch 18): Loss/seq after 01200 batchs: 1484.8843994140625
INFO:root:Train (Epoch 18): Loss/seq after 01250 batchs: 1476.896240234375
INFO:root:Train (Epoch 18): Loss/seq after 01300 batchs: 1483.4400634765625
INFO:root:Train (Epoch 18): Loss/seq after 01350 batchs: 1482.294677734375
INFO:root:Train (Epoch 18): Loss/seq after 01400 batchs: 1518.960693359375
INFO:root:Train (Epoch 18): Loss/seq after 01450 batchs: 1503.6593017578125
INFO:root:Train (Epoch 18): Loss/seq after 01500 batchs: 1490.23291015625
INFO:root:Train (Epoch 18): Loss/seq after 01550 batchs: 1491.224853515625
INFO:root:Train (Epoch 18): Loss/seq after 01600 batchs: 1470.388671875
INFO:root:Train (Epoch 18): Loss/seq after 01650 batchs: 1461.7608642578125
INFO:root:Train (Epoch 18): Loss/seq after 01700 batchs: 1449.0213623046875
INFO:root:Train (Epoch 18): Loss/seq after 01750 batchs: 1433.8983154296875
INFO:root:Train (Epoch 18): Loss/seq after 01800 batchs: 1417.3089599609375
INFO:root:Train (Epoch 18): Loss/seq after 01850 batchs: 1400.4468994140625
INFO:root:Train (Epoch 18): Loss/seq after 01900 batchs: 1396.682373046875
INFO:root:Train (Epoch 18): Loss/seq after 01950 batchs: 1389.2554931640625
INFO:root:Train (Epoch 18): Loss/seq after 02000 batchs: 1377.028076171875
INFO:root:Train (Epoch 18): Loss/seq after 02050 batchs: 1366.5421142578125
INFO:root:Train (Epoch 18): Loss/seq after 02100 batchs: 1352.8641357421875
INFO:root:Train (Epoch 18): Loss/seq after 02150 batchs: 1340.49072265625
INFO:root:Train (Epoch 18): Loss/seq after 02200 batchs: 1327.0621337890625
INFO:root:Train (Epoch 18): Loss/seq after 02250 batchs: 1330.9476318359375
INFO:root:Train (Epoch 18): Loss/seq after 02300 batchs: 1335.8040771484375
INFO:root:Train (Epoch 18): Loss/seq after 02350 batchs: 1325.57373046875
INFO:root:Train (Epoch 18): Loss/seq after 02400 batchs: 1320.357177734375
INFO:root:Train (Epoch 18): Loss/seq after 02450 batchs: 1306.84765625
INFO:root:Train (Epoch 18): Loss/seq after 02500 batchs: 1288.1676025390625
INFO:root:Train (Epoch 18): Loss/seq after 02550 batchs: 1276.111572265625
INFO:root:Train (Epoch 18): Loss/seq after 02600 batchs: 1273.4395751953125
INFO:root:Train (Epoch 18): Loss/seq after 02650 batchs: 1267.412353515625
INFO:root:Train (Epoch 18): Loss/seq after 02700 batchs: 1263.4207763671875
INFO:root:Train (Epoch 18): Loss/seq after 02750 batchs: 1295.1021728515625
INFO:root:Train (Epoch 18): Loss/seq after 02800 batchs: 1303.177734375
INFO:root:Train (Epoch 18): Loss/seq after 02850 batchs: 1299.178955078125
INFO:root:Train (Epoch 18): Loss/seq after 02900 batchs: 1296.2860107421875
INFO:root:Train (Epoch 18): Loss/seq after 02950 batchs: 1287.304443359375
INFO:root:Train (Epoch 18): Loss/seq after 03000 batchs: 1283.97900390625
INFO:root:Train (Epoch 18): Loss/seq after 03050 batchs: 1285.376220703125
INFO:root:Train (Epoch 18): Loss/seq after 03100 batchs: 1300.451416015625
INFO:root:Train (Epoch 18): Loss/seq after 03150 batchs: 1314.277587890625
INFO:root:Train (Epoch 18): Loss/seq after 03200 batchs: 1322.974853515625
INFO:root:Train (Epoch 18): Loss/seq after 03250 batchs: 1329.0078125
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 18): Loss/seq after 03300 batchs: 1327.8985595703125
INFO:root:Train (Epoch 18): Loss/seq after 03350 batchs: 1327.2586669921875
INFO:root:Train (Epoch 18): Loss/seq after 03400 batchs: 1317.312255859375
INFO:root:Train (Epoch 18): Loss/seq after 03450 batchs: 1310.6500244140625
INFO:root:Train (Epoch 18): Loss/seq after 03500 batchs: 1310.6346435546875
INFO:root:Train (Epoch 18): Loss/seq after 03550 batchs: 1305.4744873046875
INFO:root:Train (Epoch 18): Loss/seq after 03600 batchs: 1310.4970703125
INFO:root:Train (Epoch 18): Loss/seq after 03650 batchs: 1305.4361572265625
INFO:root:Train (Epoch 18): Loss/seq after 03700 batchs: 1304.478271484375
INFO:root:Train (Epoch 18): Loss/seq after 03750 batchs: 1303.338623046875
INFO:root:Train (Epoch 18): Loss/seq after 03800 batchs: 1295.417236328125
INFO:root:Train (Epoch 18): Loss/seq after 03850 batchs: 1290.0687255859375
INFO:root:Train (Epoch 18): Loss/seq after 03900 batchs: 1296.44140625
INFO:root:Train (Epoch 18): Loss/seq after 03950 batchs: 1302.38037109375
INFO:root:Train (Epoch 18): Loss/seq after 04000 batchs: 1292.503662109375
INFO:root:Train (Epoch 18): Loss/seq after 04050 batchs: 1283.6134033203125
INFO:root:Train (Epoch 18): Loss/seq after 04100 batchs: 1278.9501953125
INFO:root:Train (Epoch 18): Loss/seq after 04150 batchs: 1273.2691650390625
INFO:root:Train (Epoch 18): Loss/seq after 04200 batchs: 1267.7974853515625
INFO:root:Train (Epoch 18): Loss/seq after 04250 batchs: 1262.7994384765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 18): Loss/seq after 00000 batches: 938.9594116210938
INFO:root:# Valid (Epoch 18): Loss/seq after 00050 batches: 1116.88818359375
INFO:root:# Valid (Epoch 18): Loss/seq after 00100 batches: 1438.09130859375
INFO:root:# Valid (Epoch 18): Loss/seq after 00150 batches: 1213.2037353515625
INFO:root:# Valid (Epoch 18): Loss/seq after 00200 batches: 1108.68603515625
INFO:root:Artifacts: Make stick videos for epoch 18
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_18_on_20220412_200832.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_18_index_926_on_20220412_200832.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 19): Loss/seq after 00000 batchs: 2119.389892578125
INFO:root:Train (Epoch 19): Loss/seq after 00050 batchs: 1749.4263916015625
INFO:root:Train (Epoch 19): Loss/seq after 00100 batchs: 1709.5897216796875
INFO:root:Train (Epoch 19): Loss/seq after 00150 batchs: 1520.614013671875
INFO:root:Train (Epoch 19): Loss/seq after 00200 batchs: 1648.540283203125
INFO:root:Train (Epoch 19): Loss/seq after 00250 batchs: 1758.5755615234375
INFO:root:Train (Epoch 19): Loss/seq after 00300 batchs: 1652.025146484375
INFO:root:Train (Epoch 19): Loss/seq after 00350 batchs: 1541.87255859375
INFO:root:Train (Epoch 19): Loss/seq after 00400 batchs: 1596.0380859375
INFO:root:Train (Epoch 19): Loss/seq after 00450 batchs: 1516.52734375
INFO:root:Train (Epoch 19): Loss/seq after 00500 batchs: 1548.10107421875
INFO:root:Train (Epoch 19): Loss/seq after 00550 batchs: 1483.2059326171875
INFO:root:Train (Epoch 19): Loss/seq after 00600 batchs: 1446.078369140625
INFO:root:Train (Epoch 19): Loss/seq after 00650 batchs: 1475.595947265625
INFO:root:Train (Epoch 19): Loss/seq after 00700 batchs: 1506.52734375
INFO:root:Train (Epoch 19): Loss/seq after 00750 batchs: 1538.21337890625
INFO:root:Train (Epoch 19): Loss/seq after 00800 batchs: 1527.97509765625
INFO:root:Train (Epoch 19): Loss/seq after 00850 batchs: 1492.40478515625
INFO:root:Train (Epoch 19): Loss/seq after 00900 batchs: 1495.893798828125
INFO:root:Train (Epoch 19): Loss/seq after 00950 batchs: 1544.745361328125
INFO:root:Train (Epoch 19): Loss/seq after 01000 batchs: 1539.5728759765625
INFO:root:Train (Epoch 19): Loss/seq after 01050 batchs: 1519.357177734375
INFO:root:Train (Epoch 19): Loss/seq after 01100 batchs: 1506.913818359375
INFO:root:Train (Epoch 19): Loss/seq after 01150 batchs: 1483.760986328125
INFO:root:Train (Epoch 19): Loss/seq after 01200 batchs: 1467.7196044921875
INFO:root:Train (Epoch 19): Loss/seq after 01250 batchs: 1457.63623046875
INFO:root:Train (Epoch 19): Loss/seq after 01300 batchs: 1462.283447265625
INFO:root:Train (Epoch 19): Loss/seq after 01350 batchs: 1461.0802001953125
INFO:root:Train (Epoch 19): Loss/seq after 01400 batchs: 1495.814697265625
INFO:root:Train (Epoch 19): Loss/seq after 01450 batchs: 1481.261474609375
INFO:root:Train (Epoch 19): Loss/seq after 01500 batchs: 1467.2811279296875
INFO:root:Train (Epoch 19): Loss/seq after 01550 batchs: 1467.775634765625
INFO:root:Train (Epoch 19): Loss/seq after 01600 batchs: 1446.9918212890625
INFO:root:Train (Epoch 19): Loss/seq after 01650 batchs: 1438.400634765625
INFO:root:Train (Epoch 19): Loss/seq after 01700 batchs: 1426.237060546875
INFO:root:Train (Epoch 19): Loss/seq after 01750 batchs: 1411.1163330078125
INFO:root:Train (Epoch 19): Loss/seq after 01800 batchs: 1394.2794189453125
INFO:root:Train (Epoch 19): Loss/seq after 01850 batchs: 1377.9739990234375
INFO:root:Train (Epoch 19): Loss/seq after 01900 batchs: 1374.396240234375
INFO:root:Train (Epoch 19): Loss/seq after 01950 batchs: 1367.5457763671875
INFO:root:Train (Epoch 19): Loss/seq after 02000 batchs: 1355.73095703125
INFO:root:Train (Epoch 19): Loss/seq after 02050 batchs: 1345.6448974609375
INFO:root:Train (Epoch 19): Loss/seq after 02100 batchs: 1332.3660888671875
INFO:root:Train (Epoch 19): Loss/seq after 02150 batchs: 1320.0733642578125
INFO:root:Train (Epoch 19): Loss/seq after 02200 batchs: 1307.0733642578125
INFO:root:Train (Epoch 19): Loss/seq after 02250 batchs: 1310.1719970703125
INFO:root:Train (Epoch 19): Loss/seq after 02300 batchs: 1315.833984375
INFO:root:Train (Epoch 19): Loss/seq after 02350 batchs: 1305.5989990234375
INFO:root:Train (Epoch 19): Loss/seq after 02400 batchs: 1301.1175537109375
INFO:root:Train (Epoch 19): Loss/seq after 02450 batchs: 1288.1622314453125
INFO:root:Train (Epoch 19): Loss/seq after 02500 batchs: 1269.7904052734375
INFO:root:Train (Epoch 19): Loss/seq after 02550 batchs: 1259.21533203125
INFO:root:Train (Epoch 19): Loss/seq after 02600 batchs: 1256.945556640625
INFO:root:Train (Epoch 19): Loss/seq after 02650 batchs: 1252.1046142578125
INFO:root:Train (Epoch 19): Loss/seq after 02700 batchs: 1249.896240234375
INFO:root:Train (Epoch 19): Loss/seq after 02750 batchs: 1280.906005859375
INFO:root:Train (Epoch 19): Loss/seq after 02800 batchs: 1287.98779296875
INFO:root:Train (Epoch 19): Loss/seq after 02850 batchs: 1284.5494384765625
INFO:root:Train (Epoch 19): Loss/seq after 02900 batchs: 1282.127685546875
INFO:root:Train (Epoch 19): Loss/seq after 02950 batchs: 1273.48291015625
INFO:root:Train (Epoch 19): Loss/seq after 03000 batchs: 1270.41259765625
INFO:root:Train (Epoch 19): Loss/seq after 03050 batchs: 1272.04541015625
INFO:root:Train (Epoch 19): Loss/seq after 03100 batchs: 1285.74365234375
INFO:root:Train (Epoch 19): Loss/seq after 03150 batchs: 1300.6033935546875
INFO:root:Train (Epoch 19): Loss/seq after 03200 batchs: 1308.2623291015625
INFO:root:Train (Epoch 19): Loss/seq after 03250 batchs: 1312.89599609375
INFO:root:Train (Epoch 19): Loss/seq after 03300 batchs: 1311.886474609375
INFO:root:Train (Epoch 19): Loss/seq after 03350 batchs: 1310.9749755859375
INFO:root:Train (Epoch 19): Loss/seq after 03400 batchs: 1301.2764892578125
INFO:root:Train (Epoch 19): Loss/seq after 03450 batchs: 1294.047607421875
INFO:root:Train (Epoch 19): Loss/seq after 03500 batchs: 1293.46337890625
INFO:root:Train (Epoch 19): Loss/seq after 03550 batchs: 1287.8326416015625
INFO:root:Train (Epoch 19): Loss/seq after 03600 batchs: 1292.8585205078125
INFO:root:Train (Epoch 19): Loss/seq after 03650 batchs: 1287.8419189453125
INFO:root:Train (Epoch 19): Loss/seq after 03700 batchs: 1286.7640380859375
INFO:root:Train (Epoch 19): Loss/seq after 03750 batchs: 1285.833251953125
INFO:root:Train (Epoch 19): Loss/seq after 03800 batchs: 1278.1795654296875
INFO:root:Train (Epoch 19): Loss/seq after 03850 batchs: 1273.008056640625
INFO:root:Train (Epoch 19): Loss/seq after 03900 batchs: 1279.65380859375
INFO:root:Train (Epoch 19): Loss/seq after 03950 batchs: 1285.6025390625
INFO:root:Train (Epoch 19): Loss/seq after 04000 batchs: 1275.883056640625
INFO:root:Train (Epoch 19): Loss/seq after 04050 batchs: 1267.1861572265625
INFO:root:Train (Epoch 19): Loss/seq after 04100 batchs: 1261.6324462890625
INFO:root:Train (Epoch 19): Loss/seq after 04150 batchs: 1255.3619384765625
INFO:root:Train (Epoch 19): Loss/seq after 04200 batchs: 1249.94873046875
INFO:root:Train (Epoch 19): Loss/seq after 04250 batchs: 1245.1976318359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 19): Loss/seq after 00000 batches: 886.7886352539062
INFO:root:# Valid (Epoch 19): Loss/seq after 00050 batches: 1101.56787109375
INFO:root:# Valid (Epoch 19): Loss/seq after 00100 batches: 1420.5694580078125
INFO:root:# Valid (Epoch 19): Loss/seq after 00150 batches: 1153.62158203125
INFO:root:# Valid (Epoch 19): Loss/seq after 00200 batches: 1041.8497314453125
INFO:root:Artifacts: Make stick videos for epoch 19
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_19_on_20220412_201358.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_19_index_674_on_20220412_201358.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 20): Loss/seq after 00000 batchs: 2564.9970703125
INFO:root:Train (Epoch 20): Loss/seq after 00050 batchs: 1749.53173828125
INFO:root:Train (Epoch 20): Loss/seq after 00100 batchs: 1698.6680908203125
INFO:root:Train (Epoch 20): Loss/seq after 00150 batchs: 1513.0986328125
INFO:root:Train (Epoch 20): Loss/seq after 00200 batchs: 1627.6712646484375
INFO:root:Train (Epoch 20): Loss/seq after 00250 batchs: 1736.0635986328125
INFO:root:Train (Epoch 20): Loss/seq after 00300 batchs: 1631.5057373046875
INFO:root:Train (Epoch 20): Loss/seq after 00350 batchs: 1523.168212890625
INFO:root:Train (Epoch 20): Loss/seq after 00400 batchs: 1575.7899169921875
INFO:root:Train (Epoch 20): Loss/seq after 00450 batchs: 1498.280517578125
INFO:root:Train (Epoch 20): Loss/seq after 00500 batchs: 1526.8515625
INFO:root:Train (Epoch 20): Loss/seq after 00550 batchs: 1463.1297607421875
INFO:root:Train (Epoch 20): Loss/seq after 00600 batchs: 1429.53369140625
INFO:root:Train (Epoch 20): Loss/seq after 00650 batchs: 1463.9139404296875
INFO:root:Train (Epoch 20): Loss/seq after 00700 batchs: 1494.19775390625
INFO:root:Train (Epoch 20): Loss/seq after 00750 batchs: 1526.691650390625
INFO:root:Train (Epoch 20): Loss/seq after 00800 batchs: 1515.57861328125
INFO:root:Train (Epoch 20): Loss/seq after 00850 batchs: 1480.8201904296875
INFO:root:Train (Epoch 20): Loss/seq after 00900 batchs: 1485.1580810546875
INFO:root:Train (Epoch 20): Loss/seq after 00950 batchs: 1539.4036865234375
INFO:root:Train (Epoch 20): Loss/seq after 01000 batchs: 1531.931396484375
INFO:root:Train (Epoch 20): Loss/seq after 01050 batchs: 1511.8463134765625
INFO:root:Train (Epoch 20): Loss/seq after 01100 batchs: 1499.760009765625
INFO:root:Train (Epoch 20): Loss/seq after 01150 batchs: 1476.7265625
INFO:root:Train (Epoch 20): Loss/seq after 01200 batchs: 1461.5491943359375
INFO:root:Train (Epoch 20): Loss/seq after 01250 batchs: 1453.8203125
INFO:root:Train (Epoch 20): Loss/seq after 01300 batchs: 1460.1883544921875
INFO:root:Train (Epoch 20): Loss/seq after 01350 batchs: 1462.3433837890625
INFO:root:Train (Epoch 20): Loss/seq after 01400 batchs: 1497.2596435546875
INFO:root:Train (Epoch 20): Loss/seq after 01450 batchs: 1482.951416015625
INFO:root:Train (Epoch 20): Loss/seq after 01500 batchs: 1468.7864990234375
INFO:root:Train (Epoch 20): Loss/seq after 01550 batchs: 1469.36376953125
INFO:root:Train (Epoch 20): Loss/seq after 01600 batchs: 1449.1864013671875
INFO:root:Train (Epoch 20): Loss/seq after 01650 batchs: 1440.993896484375
INFO:root:Train (Epoch 20): Loss/seq after 01700 batchs: 1429.156494140625
INFO:root:Train (Epoch 20): Loss/seq after 01750 batchs: 1414.134521484375
INFO:root:Train (Epoch 20): Loss/seq after 01800 batchs: 1397.41650390625
INFO:root:Train (Epoch 20): Loss/seq after 01850 batchs: 1381.055908203125
INFO:root:Train (Epoch 20): Loss/seq after 01900 batchs: 1377.474365234375
INFO:root:Train (Epoch 20): Loss/seq after 01950 batchs: 1370.3343505859375
INFO:root:Train (Epoch 20): Loss/seq after 02000 batchs: 1358.448486328125
INFO:root:Train (Epoch 20): Loss/seq after 02050 batchs: 1348.2872314453125
INFO:root:Train (Epoch 20): Loss/seq after 02100 batchs: 1334.9732666015625
INFO:root:Train (Epoch 20): Loss/seq after 02150 batchs: 1322.646728515625
INFO:root:Train (Epoch 20): Loss/seq after 02200 batchs: 1309.6224365234375
INFO:root:Train (Epoch 20): Loss/seq after 02250 batchs: 1312.901123046875
INFO:root:Train (Epoch 20): Loss/seq after 02300 batchs: 1317.267822265625
INFO:root:Train (Epoch 20): Loss/seq after 02350 batchs: 1307.0267333984375
INFO:root:Train (Epoch 20): Loss/seq after 02400 batchs: 1302.6131591796875
INFO:root:Train (Epoch 20): Loss/seq after 02450 batchs: 1289.8751220703125
INFO:root:Train (Epoch 20): Loss/seq after 02500 batchs: 1271.479248046875
INFO:root:Train (Epoch 20): Loss/seq after 02550 batchs: 1260.227294921875
INFO:root:Train (Epoch 20): Loss/seq after 02600 batchs: 1257.3602294921875
INFO:root:Train (Epoch 20): Loss/seq after 02650 batchs: 1252.0872802734375
INFO:root:Train (Epoch 20): Loss/seq after 02700 batchs: 1247.9964599609375
INFO:root:Train (Epoch 20): Loss/seq after 02750 batchs: 1278.830810546875
INFO:root:Train (Epoch 20): Loss/seq after 02800 batchs: 1287.165771484375
INFO:root:Train (Epoch 20): Loss/seq after 02850 batchs: 1283.50537109375
INFO:root:Train (Epoch 20): Loss/seq after 02900 batchs: 1280.8592529296875
INFO:root:Train (Epoch 20): Loss/seq after 02950 batchs: 1272.06298828125
INFO:root:Train (Epoch 20): Loss/seq after 03000 batchs: 1269.0096435546875
INFO:root:Train (Epoch 20): Loss/seq after 03050 batchs: 1270.67333984375
INFO:root:Train (Epoch 20): Loss/seq after 03100 batchs: 1284.6854248046875
INFO:root:Train (Epoch 20): Loss/seq after 03150 batchs: 1298.281982421875
INFO:root:Train (Epoch 20): Loss/seq after 03200 batchs: 1308.05908203125
INFO:root:Train (Epoch 20): Loss/seq after 03250 batchs: 1314.32958984375
INFO:root:Train (Epoch 20): Loss/seq after 03300 batchs: 1313.17724609375
INFO:root:Train (Epoch 20): Loss/seq after 03350 batchs: 1312.488525390625
INFO:root:Train (Epoch 20): Loss/seq after 03400 batchs: 1302.730712890625
INFO:root:Train (Epoch 20): Loss/seq after 03450 batchs: 1294.8226318359375
INFO:root:Train (Epoch 20): Loss/seq after 03500 batchs: 1294.0369873046875
INFO:root:Train (Epoch 20): Loss/seq after 03550 batchs: 1288.2593994140625
INFO:root:Train (Epoch 20): Loss/seq after 03600 batchs: 1293.2774658203125
INFO:root:Train (Epoch 20): Loss/seq after 03650 batchs: 1288.2647705078125
INFO:root:Train (Epoch 20): Loss/seq after 03700 batchs: 1287.355224609375
INFO:root:Train (Epoch 20): Loss/seq after 03750 batchs: 1286.487060546875
INFO:root:Train (Epoch 20): Loss/seq after 03800 batchs: 1278.8394775390625
INFO:root:Train (Epoch 20): Loss/seq after 03850 batchs: 1273.6939697265625
INFO:root:Train (Epoch 20): Loss/seq after 03900 batchs: 1279.5157470703125
INFO:root:Train (Epoch 20): Loss/seq after 03950 batchs: 1285.4832763671875
INFO:root:Train (Epoch 20): Loss/seq after 04000 batchs: 1275.7310791015625
INFO:root:Train (Epoch 20): Loss/seq after 04050 batchs: 1267.0294189453125
INFO:root:Train (Epoch 20): Loss/seq after 04100 batchs: 1261.3607177734375
INFO:root:Train (Epoch 20): Loss/seq after 04150 batchs: 1255.0589599609375
INFO:root:Train (Epoch 20): Loss/seq after 04200 batchs: 1249.603759765625
INFO:root:Train (Epoch 20): Loss/seq after 04250 batchs: 1244.9671630859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 20): Loss/seq after 00000 batches: 886.3378295898438
INFO:root:# Valid (Epoch 20): Loss/seq after 00050 batches: 1102.98583984375
INFO:root:# Valid (Epoch 20): Loss/seq after 00100 batches: 1419.2501220703125
INFO:root:# Valid (Epoch 20): Loss/seq after 00150 batches: 1152.1612548828125
INFO:root:# Valid (Epoch 20): Loss/seq after 00200 batches: 1039.557373046875
INFO:root:Artifacts: Make stick videos for epoch 20
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_20_on_20220412_201920.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_20_index_1244_on_20220412_201920.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 21): Loss/seq after 00000 batchs: 1729.48876953125
INFO:root:Train (Epoch 21): Loss/seq after 00050 batchs: 1659.46875
INFO:root:Train (Epoch 21): Loss/seq after 00100 batchs: 1638.9163818359375
INFO:root:Train (Epoch 21): Loss/seq after 00150 batchs: 1474.927734375
INFO:root:Train (Epoch 21): Loss/seq after 00200 batchs: 1597.693359375
INFO:root:Train (Epoch 21): Loss/seq after 00250 batchs: 1714.4598388671875
INFO:root:Train (Epoch 21): Loss/seq after 00300 batchs: 1613.781494140625
INFO:root:Train (Epoch 21): Loss/seq after 00350 batchs: 1508.7864990234375
INFO:root:Train (Epoch 21): Loss/seq after 00400 batchs: 1560.183837890625
INFO:root:Train (Epoch 21): Loss/seq after 00450 batchs: 1484.453125
INFO:root:Train (Epoch 21): Loss/seq after 00500 batchs: 1513.3353271484375
INFO:root:Train (Epoch 21): Loss/seq after 00550 batchs: 1450.561767578125
INFO:root:Train (Epoch 21): Loss/seq after 00600 batchs: 1416.2264404296875
INFO:root:Train (Epoch 21): Loss/seq after 00650 batchs: 1450.548828125
INFO:root:Train (Epoch 21): Loss/seq after 00700 batchs: 1494.5841064453125
INFO:root:Train (Epoch 21): Loss/seq after 00750 batchs: 1528.947509765625
INFO:root:Train (Epoch 21): Loss/seq after 00800 batchs: 1518.25390625
INFO:root:Train (Epoch 21): Loss/seq after 00850 batchs: 1484.5118408203125
INFO:root:Train (Epoch 21): Loss/seq after 00900 batchs: 1489.193359375
INFO:root:Train (Epoch 21): Loss/seq after 00950 batchs: 1552.710693359375
INFO:root:Train (Epoch 21): Loss/seq after 01000 batchs: 1544.4072265625
INFO:root:Train (Epoch 21): Loss/seq after 01050 batchs: 1522.807861328125
INFO:root:Train (Epoch 21): Loss/seq after 01100 batchs: 1510.97412109375
INFO:root:Train (Epoch 21): Loss/seq after 01150 batchs: 1487.7392578125
INFO:root:Train (Epoch 21): Loss/seq after 01200 batchs: 1471.55419921875
INFO:root:Train (Epoch 21): Loss/seq after 01250 batchs: 1462.0546875
INFO:root:Train (Epoch 21): Loss/seq after 01300 batchs: 1465.181396484375
INFO:root:Train (Epoch 21): Loss/seq after 01350 batchs: 1463.70361328125
INFO:root:Train (Epoch 21): Loss/seq after 01400 batchs: 1498.2666015625
INFO:root:Train (Epoch 21): Loss/seq after 01450 batchs: 1483.53515625
INFO:root:Train (Epoch 21): Loss/seq after 01500 batchs: 1469.6514892578125
INFO:root:Train (Epoch 21): Loss/seq after 01550 batchs: 1471.32763671875
INFO:root:Train (Epoch 21): Loss/seq after 01600 batchs: 1450.50537109375
INFO:root:Train (Epoch 21): Loss/seq after 01650 batchs: 1442.7630615234375
INFO:root:Train (Epoch 21): Loss/seq after 01700 batchs: 1430.524658203125
INFO:root:Train (Epoch 21): Loss/seq after 01750 batchs: 1415.4273681640625
INFO:root:Train (Epoch 21): Loss/seq after 01800 batchs: 1398.5491943359375
INFO:root:Train (Epoch 21): Loss/seq after 01850 batchs: 1382.14453125
INFO:root:Train (Epoch 21): Loss/seq after 01900 batchs: 1378.5604248046875
INFO:root:Train (Epoch 21): Loss/seq after 01950 batchs: 1371.9769287109375
INFO:root:Train (Epoch 21): Loss/seq after 02000 batchs: 1360.3438720703125
INFO:root:Train (Epoch 21): Loss/seq after 02050 batchs: 1350.238037109375
INFO:root:Train (Epoch 21): Loss/seq after 02100 batchs: 1336.911865234375
INFO:root:Train (Epoch 21): Loss/seq after 02150 batchs: 1324.7003173828125
INFO:root:Train (Epoch 21): Loss/seq after 02200 batchs: 1311.6334228515625
INFO:root:Train (Epoch 21): Loss/seq after 02250 batchs: 1314.8680419921875
INFO:root:Train (Epoch 21): Loss/seq after 02300 batchs: 1318.899658203125
INFO:root:Train (Epoch 21): Loss/seq after 02350 batchs: 1308.6959228515625
INFO:root:Train (Epoch 21): Loss/seq after 02400 batchs: 1303.6212158203125
INFO:root:Train (Epoch 21): Loss/seq after 02450 batchs: 1289.719482421875
INFO:root:Train (Epoch 21): Loss/seq after 02500 batchs: 1271.2252197265625
INFO:root:Train (Epoch 21): Loss/seq after 02550 batchs: 1259.3302001953125
INFO:root:Train (Epoch 21): Loss/seq after 02600 batchs: 1256.4638671875
INFO:root:Train (Epoch 21): Loss/seq after 02650 batchs: 1250.8082275390625
INFO:root:Train (Epoch 21): Loss/seq after 02700 batchs: 1246.3824462890625
INFO:root:Train (Epoch 21): Loss/seq after 02750 batchs: 1277.54443359375
INFO:root:Train (Epoch 21): Loss/seq after 02800 batchs: 1283.8631591796875
INFO:root:Train (Epoch 21): Loss/seq after 02850 batchs: 1280.2916259765625
INFO:root:Train (Epoch 21): Loss/seq after 02900 batchs: 1277.6220703125
INFO:root:Train (Epoch 21): Loss/seq after 02950 batchs: 1268.8883056640625
INFO:root:Train (Epoch 21): Loss/seq after 03000 batchs: 1265.874755859375
INFO:root:Train (Epoch 21): Loss/seq after 03050 batchs: 1267.7386474609375
INFO:root:Train (Epoch 21): Loss/seq after 03100 batchs: 1281.9820556640625
INFO:root:Train (Epoch 21): Loss/seq after 03150 batchs: 1293.3671875
INFO:root:Train (Epoch 21): Loss/seq after 03200 batchs: 1302.3009033203125
INFO:root:Train (Epoch 21): Loss/seq after 03250 batchs: 1309.506103515625
INFO:root:Train (Epoch 21): Loss/seq after 03300 batchs: 1308.908447265625
INFO:root:Train (Epoch 21): Loss/seq after 03350 batchs: 1310.777099609375
INFO:root:Train (Epoch 21): Loss/seq after 03400 batchs: 1300.99072265625
INFO:root:Train (Epoch 21): Loss/seq after 03450 batchs: 1293.70458984375
INFO:root:Train (Epoch 21): Loss/seq after 03500 batchs: 1293.1661376953125
INFO:root:Train (Epoch 21): Loss/seq after 03550 batchs: 1287.7056884765625
INFO:root:Train (Epoch 21): Loss/seq after 03600 batchs: 1292.7137451171875
INFO:root:Train (Epoch 21): Loss/seq after 03650 batchs: 1287.7950439453125
INFO:root:Train (Epoch 21): Loss/seq after 03700 batchs: 1286.7720947265625
INFO:root:Train (Epoch 21): Loss/seq after 03750 batchs: 1285.83935546875
INFO:root:Train (Epoch 21): Loss/seq after 03800 batchs: 1278.137939453125
INFO:root:Train (Epoch 21): Loss/seq after 03850 batchs: 1272.999267578125
INFO:root:Train (Epoch 21): Loss/seq after 03900 batchs: 1280.8037109375
INFO:root:Train (Epoch 21): Loss/seq after 03950 batchs: 1286.66357421875
INFO:root:Train (Epoch 21): Loss/seq after 04000 batchs: 1276.93212890625
INFO:root:Train (Epoch 21): Loss/seq after 04050 batchs: 1268.216552734375
INFO:root:Train (Epoch 21): Loss/seq after 04100 batchs: 1262.1068115234375
INFO:root:Train (Epoch 21): Loss/seq after 04150 batchs: 1255.754150390625
INFO:root:Train (Epoch 21): Loss/seq after 04200 batchs: 1250.35546875
INFO:root:Train (Epoch 21): Loss/seq after 04250 batchs: 1245.601318359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 21): Loss/seq after 00000 batches: 920.2080078125
INFO:root:# Valid (Epoch 21): Loss/seq after 00050 batches: 1118.0205078125
INFO:root:# Valid (Epoch 21): Loss/seq after 00100 batches: 1421.7569580078125
INFO:root:# Valid (Epoch 21): Loss/seq after 00150 batches: 1148.6298828125
INFO:root:# Valid (Epoch 21): Loss/seq after 00200 batches: 1034.03173828125
INFO:root:Artifacts: Make stick videos for epoch 21
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_21_on_20220412_202442.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_21_index_645_on_20220412_202442.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 22): Loss/seq after 00000 batchs: 2243.364013671875
INFO:root:Train (Epoch 22): Loss/seq after 00050 batchs: 1693.015869140625
INFO:root:Train (Epoch 22): Loss/seq after 00100 batchs: 1657.0341796875
INFO:root:Train (Epoch 22): Loss/seq after 00150 batchs: 1480.0947265625
INFO:root:Train (Epoch 22): Loss/seq after 00200 batchs: 1586.557373046875
INFO:root:Train (Epoch 22): Loss/seq after 00250 batchs: 1698.506103515625
INFO:root:Train (Epoch 22): Loss/seq after 00300 batchs: 1600.591552734375
INFO:root:Train (Epoch 22): Loss/seq after 00350 batchs: 1497.1800537109375
INFO:root:Train (Epoch 22): Loss/seq after 00400 batchs: 1553.1875
INFO:root:Train (Epoch 22): Loss/seq after 00450 batchs: 1478.212890625
INFO:root:Train (Epoch 22): Loss/seq after 00500 batchs: 1509.23583984375
INFO:root:Train (Epoch 22): Loss/seq after 00550 batchs: 1446.4720458984375
INFO:root:Train (Epoch 22): Loss/seq after 00600 batchs: 1412.1312255859375
INFO:root:Train (Epoch 22): Loss/seq after 00650 batchs: 1441.6270751953125
INFO:root:Train (Epoch 22): Loss/seq after 00700 batchs: 1472.353759765625
INFO:root:Train (Epoch 22): Loss/seq after 00750 batchs: 1505.63330078125
INFO:root:Train (Epoch 22): Loss/seq after 00800 batchs: 1496.0562744140625
INFO:root:Train (Epoch 22): Loss/seq after 00850 batchs: 1462.363525390625
INFO:root:Train (Epoch 22): Loss/seq after 00900 batchs: 1466.8021240234375
INFO:root:Train (Epoch 22): Loss/seq after 00950 batchs: 1530.1358642578125
INFO:root:Train (Epoch 22): Loss/seq after 01000 batchs: 1524.7843017578125
INFO:root:Train (Epoch 22): Loss/seq after 01050 batchs: 1504.1148681640625
INFO:root:Train (Epoch 22): Loss/seq after 01100 batchs: 1492.5345458984375
INFO:root:Train (Epoch 22): Loss/seq after 01150 batchs: 1469.814208984375
INFO:root:Train (Epoch 22): Loss/seq after 01200 batchs: 1454.2587890625
INFO:root:Train (Epoch 22): Loss/seq after 01250 batchs: 1445.2960205078125
INFO:root:Train (Epoch 22): Loss/seq after 01300 batchs: 1448.1502685546875
INFO:root:Train (Epoch 22): Loss/seq after 01350 batchs: 1448.2379150390625
INFO:root:Train (Epoch 22): Loss/seq after 01400 batchs: 1482.02099609375
INFO:root:Train (Epoch 22): Loss/seq after 01450 batchs: 1467.91796875
INFO:root:Train (Epoch 22): Loss/seq after 01500 batchs: 1454.76123046875
INFO:root:Train (Epoch 22): Loss/seq after 01550 batchs: 1456.1634521484375
INFO:root:Train (Epoch 22): Loss/seq after 01600 batchs: 1435.880126953125
INFO:root:Train (Epoch 22): Loss/seq after 01650 batchs: 1427.5614013671875
INFO:root:Train (Epoch 22): Loss/seq after 01700 batchs: 1415.8162841796875
INFO:root:Train (Epoch 22): Loss/seq after 01750 batchs: 1401.0103759765625
INFO:root:Train (Epoch 22): Loss/seq after 01800 batchs: 1384.4361572265625
INFO:root:Train (Epoch 22): Loss/seq after 01850 batchs: 1368.35986328125
INFO:root:Train (Epoch 22): Loss/seq after 01900 batchs: 1365.1260986328125
INFO:root:Train (Epoch 22): Loss/seq after 01950 batchs: 1358.393798828125
INFO:root:Train (Epoch 22): Loss/seq after 02000 batchs: 1346.8056640625
INFO:root:Train (Epoch 22): Loss/seq after 02050 batchs: 1337.002685546875
INFO:root:Train (Epoch 22): Loss/seq after 02100 batchs: 1323.96875
INFO:root:Train (Epoch 22): Loss/seq after 02150 batchs: 1311.951416015625
INFO:root:Train (Epoch 22): Loss/seq after 02200 batchs: 1299.1114501953125
INFO:root:Train (Epoch 22): Loss/seq after 02250 batchs: 1302.4134521484375
INFO:root:Train (Epoch 22): Loss/seq after 02300 batchs: 1306.379638671875
INFO:root:Train (Epoch 22): Loss/seq after 02350 batchs: 1296.077880859375
INFO:root:Train (Epoch 22): Loss/seq after 02400 batchs: 1291.6470947265625
INFO:root:Train (Epoch 22): Loss/seq after 02450 batchs: 1278.585205078125
INFO:root:Train (Epoch 22): Loss/seq after 02500 batchs: 1260.3154296875
INFO:root:Train (Epoch 22): Loss/seq after 02550 batchs: 1248.7337646484375
INFO:root:Train (Epoch 22): Loss/seq after 02600 batchs: 1245.9959716796875
INFO:root:Train (Epoch 22): Loss/seq after 02650 batchs: 1240.738525390625
INFO:root:Train (Epoch 22): Loss/seq after 02700 batchs: 1236.470703125
INFO:root:Train (Epoch 22): Loss/seq after 02750 batchs: 1267.2183837890625
INFO:root:Train (Epoch 22): Loss/seq after 02800 batchs: 1274.5142822265625
INFO:root:Train (Epoch 22): Loss/seq after 02850 batchs: 1271.3087158203125
INFO:root:Train (Epoch 22): Loss/seq after 02900 batchs: 1269.076904296875
INFO:root:Train (Epoch 22): Loss/seq after 02950 batchs: 1260.3782958984375
INFO:root:Train (Epoch 22): Loss/seq after 03000 batchs: 1257.5113525390625
INFO:root:Train (Epoch 22): Loss/seq after 03050 batchs: 1259.37353515625
INFO:root:Train (Epoch 22): Loss/seq after 03100 batchs: 1273.7490234375
INFO:root:Train (Epoch 22): Loss/seq after 03150 batchs: 1287.8939208984375
INFO:root:Train (Epoch 22): Loss/seq after 03200 batchs: 1296.99951171875
INFO:root:Train (Epoch 22): Loss/seq after 03250 batchs: 1303.543212890625
INFO:root:Train (Epoch 22): Loss/seq after 03300 batchs: 1302.1201171875
INFO:root:Train (Epoch 22): Loss/seq after 03350 batchs: 1301.8138427734375
INFO:root:Train (Epoch 22): Loss/seq after 03400 batchs: 1292.2763671875
INFO:root:Train (Epoch 22): Loss/seq after 03450 batchs: 1284.944580078125
INFO:root:Train (Epoch 22): Loss/seq after 03500 batchs: 1284.3558349609375
INFO:root:Train (Epoch 22): Loss/seq after 03550 batchs: 1278.8089599609375
INFO:root:Train (Epoch 22): Loss/seq after 03600 batchs: 1283.893310546875
INFO:root:Train (Epoch 22): Loss/seq after 03650 batchs: 1278.97265625
INFO:root:Train (Epoch 22): Loss/seq after 03700 batchs: 1278.186767578125
INFO:root:Train (Epoch 22): Loss/seq after 03750 batchs: 1277.4278564453125
INFO:root:Train (Epoch 22): Loss/seq after 03800 batchs: 1269.9384765625
INFO:root:Train (Epoch 22): Loss/seq after 03850 batchs: 1264.883056640625
INFO:root:Train (Epoch 22): Loss/seq after 03900 batchs: 1270.7840576171875
INFO:root:Train (Epoch 22): Loss/seq after 03950 batchs: 1276.9794921875
INFO:root:Train (Epoch 22): Loss/seq after 04000 batchs: 1267.3465576171875
INFO:root:Train (Epoch 22): Loss/seq after 04050 batchs: 1258.747802734375
INFO:root:Train (Epoch 22): Loss/seq after 04100 batchs: 1252.7523193359375
INFO:root:Train (Epoch 22): Loss/seq after 04150 batchs: 1246.47802734375
INFO:root:Train (Epoch 22): Loss/seq after 04200 batchs: 1241.09423828125
INFO:root:Train (Epoch 22): Loss/seq after 04250 batchs: 1236.3070068359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 22): Loss/seq after 00000 batches: 876.4073486328125
INFO:root:# Valid (Epoch 22): Loss/seq after 00050 batches: 1141.961181640625
INFO:root:# Valid (Epoch 22): Loss/seq after 00100 batches: 1458.979736328125
INFO:root:# Valid (Epoch 22): Loss/seq after 00150 batches: 1255.6636962890625
INFO:root:# Valid (Epoch 22): Loss/seq after 00200 batches: 1160.21435546875
INFO:root:Artifacts: Make stick videos for epoch 22
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_22_on_20220412_203003.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_22_index_537_on_20220412_203003.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 23): Loss/seq after 00000 batchs: 2413.064208984375
INFO:root:Train (Epoch 23): Loss/seq after 00050 batchs: 1671.828857421875
INFO:root:Train (Epoch 23): Loss/seq after 00100 batchs: 1654.1978759765625
INFO:root:Train (Epoch 23): Loss/seq after 00150 batchs: 1476.6417236328125
INFO:root:Train (Epoch 23): Loss/seq after 00200 batchs: 1585.74853515625
INFO:root:Train (Epoch 23): Loss/seq after 00250 batchs: 1702.11376953125
INFO:root:Train (Epoch 23): Loss/seq after 00300 batchs: 1603.57861328125
INFO:root:Train (Epoch 23): Loss/seq after 00350 batchs: 1499.201416015625
INFO:root:Train (Epoch 23): Loss/seq after 00400 batchs: 1552.8594970703125
INFO:root:Train (Epoch 23): Loss/seq after 00450 batchs: 1477.85791015625
INFO:root:Train (Epoch 23): Loss/seq after 00500 batchs: 1505.8638916015625
INFO:root:Train (Epoch 23): Loss/seq after 00550 batchs: 1443.2476806640625
INFO:root:Train (Epoch 23): Loss/seq after 00600 batchs: 1407.172607421875
INFO:root:Train (Epoch 23): Loss/seq after 00650 batchs: 1435.0543212890625
INFO:root:Train (Epoch 23): Loss/seq after 00700 batchs: 1475.514892578125
INFO:root:Train (Epoch 23): Loss/seq after 00750 batchs: 1510.3604736328125
INFO:root:Train (Epoch 23): Loss/seq after 00800 batchs: 1500.6048583984375
INFO:root:Train (Epoch 23): Loss/seq after 00850 batchs: 1466.4002685546875
INFO:root:Train (Epoch 23): Loss/seq after 00900 batchs: 1470.4588623046875
INFO:root:Train (Epoch 23): Loss/seq after 00950 batchs: 1531.564208984375
INFO:root:Train (Epoch 23): Loss/seq after 01000 batchs: 1526.232421875
INFO:root:Train (Epoch 23): Loss/seq after 01050 batchs: 1504.8936767578125
INFO:root:Train (Epoch 23): Loss/seq after 01100 batchs: 1493.1463623046875
INFO:root:Train (Epoch 23): Loss/seq after 01150 batchs: 1470.213134765625
INFO:root:Train (Epoch 23): Loss/seq after 01200 batchs: 1454.751708984375
INFO:root:Train (Epoch 23): Loss/seq after 01250 batchs: 1444.38232421875
INFO:root:Train (Epoch 23): Loss/seq after 01300 batchs: 1450.176513671875
INFO:root:Train (Epoch 23): Loss/seq after 01350 batchs: 1448.298583984375
INFO:root:Train (Epoch 23): Loss/seq after 01400 batchs: 1483.1492919921875
INFO:root:Train (Epoch 23): Loss/seq after 01450 batchs: 1468.4599609375
INFO:root:Train (Epoch 23): Loss/seq after 01500 batchs: 1454.8233642578125
INFO:root:Train (Epoch 23): Loss/seq after 01550 batchs: 1456.83935546875
INFO:root:Train (Epoch 23): Loss/seq after 01600 batchs: 1436.394775390625
INFO:root:Train (Epoch 23): Loss/seq after 01650 batchs: 1428.6055908203125
INFO:root:Train (Epoch 23): Loss/seq after 01700 batchs: 1416.8011474609375
INFO:root:Train (Epoch 23): Loss/seq after 01750 batchs: 1402.000244140625
INFO:root:Train (Epoch 23): Loss/seq after 01800 batchs: 1385.4676513671875
INFO:root:Train (Epoch 23): Loss/seq after 01850 batchs: 1369.4649658203125
INFO:root:Train (Epoch 23): Loss/seq after 01900 batchs: 1366.1668701171875
INFO:root:Train (Epoch 23): Loss/seq after 01950 batchs: 1359.3875732421875
INFO:root:Train (Epoch 23): Loss/seq after 02000 batchs: 1347.748046875
INFO:root:Train (Epoch 23): Loss/seq after 02050 batchs: 1337.836669921875
INFO:root:Train (Epoch 23): Loss/seq after 02100 batchs: 1324.7718505859375
INFO:root:Train (Epoch 23): Loss/seq after 02150 batchs: 1312.63330078125
INFO:root:Train (Epoch 23): Loss/seq after 02200 batchs: 1299.776611328125
INFO:root:Train (Epoch 23): Loss/seq after 02250 batchs: 1302.8194580078125
INFO:root:Train (Epoch 23): Loss/seq after 02300 batchs: 1306.9354248046875
INFO:root:Train (Epoch 23): Loss/seq after 02350 batchs: 1297.0606689453125
INFO:root:Train (Epoch 23): Loss/seq after 02400 batchs: 1292.9500732421875
INFO:root:Train (Epoch 23): Loss/seq after 02450 batchs: 1280.6304931640625
INFO:root:Train (Epoch 23): Loss/seq after 02500 batchs: 1262.3984375
INFO:root:Train (Epoch 23): Loss/seq after 02550 batchs: 1252.339111328125
INFO:root:Train (Epoch 23): Loss/seq after 02600 batchs: 1253.1461181640625
INFO:root:Train (Epoch 23): Loss/seq after 02650 batchs: 1249.2308349609375
INFO:root:Train (Epoch 23): Loss/seq after 02700 batchs: 1247.74560546875
INFO:root:Train (Epoch 23): Loss/seq after 02750 batchs: 1279.75439453125
INFO:root:Train (Epoch 23): Loss/seq after 02800 batchs: 1287.7186279296875
INFO:root:Train (Epoch 23): Loss/seq after 02850 batchs: 1285.427978515625
INFO:root:Train (Epoch 23): Loss/seq after 02900 batchs: 1282.9801025390625
INFO:root:Train (Epoch 23): Loss/seq after 02950 batchs: 1275.1422119140625
INFO:root:Train (Epoch 23): Loss/seq after 03000 batchs: 1272.0611572265625
INFO:root:Train (Epoch 23): Loss/seq after 03050 batchs: 1273.8048095703125
INFO:root:Train (Epoch 23): Loss/seq after 03100 batchs: 1288.1903076171875
INFO:root:Train (Epoch 23): Loss/seq after 03150 batchs: 1301.011474609375
INFO:root:Train (Epoch 23): Loss/seq after 03200 batchs: 1308.843017578125
INFO:root:Train (Epoch 23): Loss/seq after 03250 batchs: 1314.2733154296875
INFO:root:Train (Epoch 23): Loss/seq after 03300 batchs: 1312.8560791015625
INFO:root:Train (Epoch 23): Loss/seq after 03350 batchs: 1312.1883544921875
INFO:root:Train (Epoch 23): Loss/seq after 03400 batchs: 1302.4375
INFO:root:Train (Epoch 23): Loss/seq after 03450 batchs: 1295.7335205078125
INFO:root:Train (Epoch 23): Loss/seq after 03500 batchs: 1295.8536376953125
INFO:root:Train (Epoch 23): Loss/seq after 03550 batchs: 1290.723876953125
INFO:root:Train (Epoch 23): Loss/seq after 03600 batchs: 1295.946044921875
INFO:root:Train (Epoch 23): Loss/seq after 03650 batchs: 1291.118408203125
INFO:root:Train (Epoch 23): Loss/seq after 03700 batchs: 1290.2364501953125
INFO:root:Train (Epoch 23): Loss/seq after 03750 batchs: 1289.31494140625
INFO:root:Train (Epoch 23): Loss/seq after 03800 batchs: 1281.7647705078125
INFO:root:Train (Epoch 23): Loss/seq after 03850 batchs: 1276.8690185546875
INFO:root:Train (Epoch 23): Loss/seq after 03900 batchs: 1283.619384765625
INFO:root:Train (Epoch 23): Loss/seq after 03950 batchs: 1289.459228515625
INFO:root:Train (Epoch 23): Loss/seq after 04000 batchs: 1279.696044921875
INFO:root:Train (Epoch 23): Loss/seq after 04050 batchs: 1270.9600830078125
INFO:root:Train (Epoch 23): Loss/seq after 04100 batchs: 1266.69482421875
INFO:root:Train (Epoch 23): Loss/seq after 04150 batchs: 1261.2637939453125
INFO:root:Train (Epoch 23): Loss/seq after 04200 batchs: 1257.62109375
INFO:root:Train (Epoch 23): Loss/seq after 04250 batchs: 1253.121826171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 23): Loss/seq after 00000 batches: 985.4903564453125
INFO:root:# Valid (Epoch 23): Loss/seq after 00050 batches: 1137.986083984375
INFO:root:# Valid (Epoch 23): Loss/seq after 00100 batches: 1466.397705078125
INFO:root:# Valid (Epoch 23): Loss/seq after 00150 batches: 1221.027099609375
INFO:root:# Valid (Epoch 23): Loss/seq after 00200 batches: 1105.8349609375
INFO:root:Artifacts: Make stick videos for epoch 23
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_23_on_20220412_203526.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_23_index_1505_on_20220412_203526.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 24): Loss/seq after 00000 batchs: 2081.105224609375
INFO:root:Train (Epoch 24): Loss/seq after 00050 batchs: 1702.13134765625
INFO:root:Train (Epoch 24): Loss/seq after 00100 batchs: 1680.5147705078125
INFO:root:Train (Epoch 24): Loss/seq after 00150 batchs: 1516.087158203125
INFO:root:Train (Epoch 24): Loss/seq after 00200 batchs: 1616.2830810546875
INFO:root:Train (Epoch 24): Loss/seq after 00250 batchs: 1736.2965087890625
INFO:root:Train (Epoch 24): Loss/seq after 00300 batchs: 1633.4476318359375
INFO:root:Train (Epoch 24): Loss/seq after 00350 batchs: 1526.397216796875
INFO:root:Train (Epoch 24): Loss/seq after 00400 batchs: 1578.58154296875
INFO:root:Train (Epoch 24): Loss/seq after 00450 batchs: 1500.8883056640625
INFO:root:Train (Epoch 24): Loss/seq after 00500 batchs: 1530.3572998046875
INFO:root:Train (Epoch 24): Loss/seq after 00550 batchs: 1469.43408203125
INFO:root:Train (Epoch 24): Loss/seq after 00600 batchs: 1432.8983154296875
INFO:root:Train (Epoch 24): Loss/seq after 00650 batchs: 1459.2044677734375
INFO:root:Train (Epoch 24): Loss/seq after 00700 batchs: 1489.5377197265625
INFO:root:Train (Epoch 24): Loss/seq after 00750 batchs: 1518.7401123046875
INFO:root:Train (Epoch 24): Loss/seq after 00800 batchs: 1509.496337890625
INFO:root:Train (Epoch 24): Loss/seq after 00850 batchs: 1478.842529296875
INFO:root:Train (Epoch 24): Loss/seq after 00900 batchs: 1482.947021484375
INFO:root:Train (Epoch 24): Loss/seq after 00950 batchs: 1540.0220947265625
INFO:root:Train (Epoch 24): Loss/seq after 01000 batchs: 1537.0338134765625
INFO:root:Train (Epoch 24): Loss/seq after 01050 batchs: 1519.6265869140625
INFO:root:Train (Epoch 24): Loss/seq after 01100 batchs: 1506.9927978515625
INFO:root:Train (Epoch 24): Loss/seq after 01150 batchs: 1483.665283203125
INFO:root:Train (Epoch 24): Loss/seq after 01200 batchs: 1468.755859375
INFO:root:Train (Epoch 24): Loss/seq after 01250 batchs: 1458.8995361328125
INFO:root:Train (Epoch 24): Loss/seq after 01300 batchs: 1462.25146484375
INFO:root:Train (Epoch 24): Loss/seq after 01350 batchs: 1460.644775390625
INFO:root:Train (Epoch 24): Loss/seq after 01400 batchs: 1495.2672119140625
INFO:root:Train (Epoch 24): Loss/seq after 01450 batchs: 1481.1728515625
INFO:root:Train (Epoch 24): Loss/seq after 01500 batchs: 1468.174560546875
INFO:root:Train (Epoch 24): Loss/seq after 01550 batchs: 1468.798095703125
INFO:root:Train (Epoch 24): Loss/seq after 01600 batchs: 1448.6221923828125
INFO:root:Train (Epoch 24): Loss/seq after 01650 batchs: 1440.874267578125
INFO:root:Train (Epoch 24): Loss/seq after 01700 batchs: 1428.633056640625
INFO:root:Train (Epoch 24): Loss/seq after 01750 batchs: 1413.8768310546875
INFO:root:Train (Epoch 24): Loss/seq after 01800 batchs: 1397.493408203125
INFO:root:Train (Epoch 24): Loss/seq after 01850 batchs: 1381.2352294921875
INFO:root:Train (Epoch 24): Loss/seq after 01900 batchs: 1377.787353515625
INFO:root:Train (Epoch 24): Loss/seq after 01950 batchs: 1370.8245849609375
INFO:root:Train (Epoch 24): Loss/seq after 02000 batchs: 1359.1239013671875
INFO:root:Train (Epoch 24): Loss/seq after 02050 batchs: 1349.1358642578125
INFO:root:Train (Epoch 24): Loss/seq after 02100 batchs: 1335.9215087890625
INFO:root:Train (Epoch 24): Loss/seq after 02150 batchs: 1323.8466796875
INFO:root:Train (Epoch 24): Loss/seq after 02200 batchs: 1310.78515625
INFO:root:Train (Epoch 24): Loss/seq after 02250 batchs: 1313.538330078125
INFO:root:Train (Epoch 24): Loss/seq after 02300 batchs: 1317.744140625
INFO:root:Train (Epoch 24): Loss/seq after 02350 batchs: 1307.4461669921875
INFO:root:Train (Epoch 24): Loss/seq after 02400 batchs: 1302.6583251953125
INFO:root:Train (Epoch 24): Loss/seq after 02450 batchs: 1289.624267578125
INFO:root:Train (Epoch 24): Loss/seq after 02500 batchs: 1271.2122802734375
INFO:root:Train (Epoch 24): Loss/seq after 02550 batchs: 1259.4561767578125
INFO:root:Train (Epoch 24): Loss/seq after 02600 batchs: 1257.9676513671875
INFO:root:Train (Epoch 24): Loss/seq after 02650 batchs: 1253.066650390625
INFO:root:Train (Epoch 24): Loss/seq after 02700 batchs: 1250.084716796875
INFO:root:Train (Epoch 24): Loss/seq after 02750 batchs: 1280.424072265625
INFO:root:Train (Epoch 24): Loss/seq after 02800 batchs: 1286.674072265625
INFO:root:Train (Epoch 24): Loss/seq after 02850 batchs: 1283.5142822265625
INFO:root:Train (Epoch 24): Loss/seq after 02900 batchs: 1281.2982177734375
INFO:root:Train (Epoch 24): Loss/seq after 02950 batchs: 1272.744873046875
INFO:root:Train (Epoch 24): Loss/seq after 03000 batchs: 1269.6737060546875
INFO:root:Train (Epoch 24): Loss/seq after 03050 batchs: 1271.341796875
INFO:root:Train (Epoch 24): Loss/seq after 03100 batchs: 1284.72412109375
INFO:root:Train (Epoch 24): Loss/seq after 03150 batchs: 1295.60009765625
INFO:root:Train (Epoch 24): Loss/seq after 03200 batchs: 1302.0416259765625
INFO:root:Train (Epoch 24): Loss/seq after 03250 batchs: 1309.268798828125
INFO:root:Train (Epoch 24): Loss/seq after 03300 batchs: 1308.1790771484375
INFO:root:Train (Epoch 24): Loss/seq after 03350 batchs: 1307.4473876953125
INFO:root:Train (Epoch 24): Loss/seq after 03400 batchs: 1297.7520751953125
INFO:root:Train (Epoch 24): Loss/seq after 03450 batchs: 1291.3328857421875
INFO:root:Train (Epoch 24): Loss/seq after 03500 batchs: 1291.5045166015625
INFO:root:Train (Epoch 24): Loss/seq after 03550 batchs: 1286.7666015625
INFO:root:Train (Epoch 24): Loss/seq after 03600 batchs: 1292.0828857421875
INFO:root:Train (Epoch 24): Loss/seq after 03650 batchs: 1287.41845703125
INFO:root:Train (Epoch 24): Loss/seq after 03700 batchs: 1286.506103515625
INFO:root:Train (Epoch 24): Loss/seq after 03750 batchs: 1285.674072265625
INFO:root:Train (Epoch 24): Loss/seq after 03800 batchs: 1278.067138671875
INFO:root:Train (Epoch 24): Loss/seq after 03850 batchs: 1272.90771484375
INFO:root:Train (Epoch 24): Loss/seq after 03900 batchs: 1278.6536865234375
INFO:root:Train (Epoch 24): Loss/seq after 03950 batchs: 1283.2318115234375
INFO:root:Train (Epoch 24): Loss/seq after 04000 batchs: 1273.611328125
INFO:root:Train (Epoch 24): Loss/seq after 04050 batchs: 1264.94580078125
INFO:root:Train (Epoch 24): Loss/seq after 04100 batchs: 1260.148193359375
INFO:root:Train (Epoch 24): Loss/seq after 04150 batchs: 1254.3525390625
INFO:root:Train (Epoch 24): Loss/seq after 04200 batchs: 1249.8868408203125
INFO:root:Train (Epoch 24): Loss/seq after 04250 batchs: 1245.1749267578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 24): Loss/seq after 00000 batches: 926.4160766601562
INFO:root:# Valid (Epoch 24): Loss/seq after 00050 batches: 1111.9677734375
INFO:root:# Valid (Epoch 24): Loss/seq after 00100 batches: 1433.1041259765625
INFO:root:# Valid (Epoch 24): Loss/seq after 00150 batches: 1203.9488525390625
INFO:root:# Valid (Epoch 24): Loss/seq after 00200 batches: 1100.5880126953125
INFO:root:Artifacts: Make stick videos for epoch 24
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_24_on_20220412_204048.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_24_index_115_on_20220412_204048.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 25): Loss/seq after 00000 batchs: 1562.6575927734375
INFO:root:Train (Epoch 25): Loss/seq after 00050 batchs: 1704.0931396484375
INFO:root:Train (Epoch 25): Loss/seq after 00100 batchs: 1640.8946533203125
INFO:root:Train (Epoch 25): Loss/seq after 00150 batchs: 1470.6773681640625
INFO:root:Train (Epoch 25): Loss/seq after 00200 batchs: 1576.6451416015625
INFO:root:Train (Epoch 25): Loss/seq after 00250 batchs: 1711.0882568359375
INFO:root:Train (Epoch 25): Loss/seq after 00300 batchs: 1611.4625244140625
INFO:root:Train (Epoch 25): Loss/seq after 00350 batchs: 1507.140625
INFO:root:Train (Epoch 25): Loss/seq after 00400 batchs: 1558.591796875
INFO:root:Train (Epoch 25): Loss/seq after 00450 batchs: 1483.2354736328125
INFO:root:Train (Epoch 25): Loss/seq after 00500 batchs: 1517.3876953125
INFO:root:Train (Epoch 25): Loss/seq after 00550 batchs: 1463.1707763671875
INFO:root:Train (Epoch 25): Loss/seq after 00600 batchs: 1432.0953369140625
INFO:root:Train (Epoch 25): Loss/seq after 00650 batchs: 1460.932373046875
INFO:root:Train (Epoch 25): Loss/seq after 00700 batchs: 1487.5736083984375
INFO:root:Train (Epoch 25): Loss/seq after 00750 batchs: 1515.913330078125
INFO:root:Train (Epoch 25): Loss/seq after 00800 batchs: 1508.527099609375
INFO:root:Train (Epoch 25): Loss/seq after 00850 batchs: 1476.4041748046875
INFO:root:Train (Epoch 25): Loss/seq after 00900 batchs: 1484.2803955078125
INFO:root:Train (Epoch 25): Loss/seq after 00950 batchs: 1532.963134765625
INFO:root:Train (Epoch 25): Loss/seq after 01000 batchs: 1526.0567626953125
INFO:root:Train (Epoch 25): Loss/seq after 01050 batchs: 1506.7369384765625
INFO:root:Train (Epoch 25): Loss/seq after 01100 batchs: 1493.7135009765625
INFO:root:Train (Epoch 25): Loss/seq after 01150 batchs: 1471.62451171875
INFO:root:Train (Epoch 25): Loss/seq after 01200 batchs: 1456.2568359375
INFO:root:Train (Epoch 25): Loss/seq after 01250 batchs: 1446.97998046875
INFO:root:Train (Epoch 25): Loss/seq after 01300 batchs: 1449.4622802734375
INFO:root:Train (Epoch 25): Loss/seq after 01350 batchs: 1446.73046875
INFO:root:Train (Epoch 25): Loss/seq after 01400 batchs: 1478.3438720703125
INFO:root:Train (Epoch 25): Loss/seq after 01450 batchs: 1464.59375
INFO:root:Train (Epoch 25): Loss/seq after 01500 batchs: 1451.1771240234375
INFO:root:Train (Epoch 25): Loss/seq after 01550 batchs: 1451.6904296875
INFO:root:Train (Epoch 25): Loss/seq after 01600 batchs: 1431.9053955078125
INFO:root:Train (Epoch 25): Loss/seq after 01650 batchs: 1423.652099609375
INFO:root:Train (Epoch 25): Loss/seq after 01700 batchs: 1411.85888671875
INFO:root:Train (Epoch 25): Loss/seq after 01750 batchs: 1397.206787109375
INFO:root:Train (Epoch 25): Loss/seq after 01800 batchs: 1380.794921875
INFO:root:Train (Epoch 25): Loss/seq after 01850 batchs: 1364.8447265625
INFO:root:Train (Epoch 25): Loss/seq after 01900 batchs: 1361.5870361328125
INFO:root:Train (Epoch 25): Loss/seq after 01950 batchs: 1354.724365234375
INFO:root:Train (Epoch 25): Loss/seq after 02000 batchs: 1343.1800537109375
INFO:root:Train (Epoch 25): Loss/seq after 02050 batchs: 1333.3912353515625
INFO:root:Train (Epoch 25): Loss/seq after 02100 batchs: 1320.429443359375
INFO:root:Train (Epoch 25): Loss/seq after 02150 batchs: 1308.3670654296875
INFO:root:Train (Epoch 25): Loss/seq after 02200 batchs: 1295.597900390625
INFO:root:Train (Epoch 25): Loss/seq after 02250 batchs: 1298.4093017578125
INFO:root:Train (Epoch 25): Loss/seq after 02300 batchs: 1302.6220703125
INFO:root:Train (Epoch 25): Loss/seq after 02350 batchs: 1292.8984375
INFO:root:Train (Epoch 25): Loss/seq after 02400 batchs: 1287.97021484375
INFO:root:Train (Epoch 25): Loss/seq after 02450 batchs: 1274.7188720703125
INFO:root:Train (Epoch 25): Loss/seq after 02500 batchs: 1256.5855712890625
INFO:root:Train (Epoch 25): Loss/seq after 02550 batchs: 1244.9510498046875
INFO:root:Train (Epoch 25): Loss/seq after 02600 batchs: 1241.8289794921875
INFO:root:Train (Epoch 25): Loss/seq after 02650 batchs: 1236.36376953125
INFO:root:Train (Epoch 25): Loss/seq after 02700 batchs: 1231.8204345703125
INFO:root:Train (Epoch 25): Loss/seq after 02750 batchs: 1262.4510498046875
INFO:root:Train (Epoch 25): Loss/seq after 02800 batchs: 1270.040771484375
INFO:root:Train (Epoch 25): Loss/seq after 02850 batchs: 1266.3294677734375
INFO:root:Train (Epoch 25): Loss/seq after 02900 batchs: 1263.5166015625
INFO:root:Train (Epoch 25): Loss/seq after 02950 batchs: 1255.1094970703125
INFO:root:Train (Epoch 25): Loss/seq after 03000 batchs: 1252.289794921875
INFO:root:Train (Epoch 25): Loss/seq after 03050 batchs: 1254.18359375
INFO:root:Train (Epoch 25): Loss/seq after 03100 batchs: 1268.7374267578125
INFO:root:Train (Epoch 25): Loss/seq after 03150 batchs: 1280.9039306640625
INFO:root:Train (Epoch 25): Loss/seq after 03200 batchs: 1289.962158203125
INFO:root:Train (Epoch 25): Loss/seq after 03250 batchs: 1295.8922119140625
INFO:root:Train (Epoch 25): Loss/seq after 03300 batchs: 1294.6710205078125
INFO:root:Train (Epoch 25): Loss/seq after 03350 batchs: 1293.2388916015625
INFO:root:Train (Epoch 25): Loss/seq after 03400 batchs: 1283.87060546875
INFO:root:Train (Epoch 25): Loss/seq after 03450 batchs: 1276.675537109375
INFO:root:Train (Epoch 25): Loss/seq after 03500 batchs: 1276.4337158203125
INFO:root:Train (Epoch 25): Loss/seq after 03550 batchs: 1271.0166015625
INFO:root:Train (Epoch 25): Loss/seq after 03600 batchs: 1276.259521484375
INFO:root:Train (Epoch 25): Loss/seq after 03650 batchs: 1271.286376953125
INFO:root:Train (Epoch 25): Loss/seq after 03700 batchs: 1270.6964111328125
INFO:root:Train (Epoch 25): Loss/seq after 03750 batchs: 1270.119384765625
INFO:root:Train (Epoch 25): Loss/seq after 03800 batchs: 1262.6724853515625
INFO:root:Train (Epoch 25): Loss/seq after 03850 batchs: 1257.6956787109375
INFO:root:Train (Epoch 25): Loss/seq after 03900 batchs: 1264.245361328125
INFO:root:Train (Epoch 25): Loss/seq after 03950 batchs: 1270.164306640625
INFO:root:Train (Epoch 25): Loss/seq after 04000 batchs: 1260.6202392578125
INFO:root:Train (Epoch 25): Loss/seq after 04050 batchs: 1252.1123046875
INFO:root:Train (Epoch 25): Loss/seq after 04100 batchs: 1246.4539794921875
INFO:root:Train (Epoch 25): Loss/seq after 04150 batchs: 1240.298828125
INFO:root:Train (Epoch 25): Loss/seq after 04200 batchs: 1234.828857421875
INFO:root:Train (Epoch 25): Loss/seq after 04250 batchs: 1230.22607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 25): Loss/seq after 00000 batches: 872.4111328125
INFO:root:# Valid (Epoch 25): Loss/seq after 00050 batches: 1129.829833984375
INFO:root:# Valid (Epoch 25): Loss/seq after 00100 batches: 1464.93896484375
INFO:root:# Valid (Epoch 25): Loss/seq after 00150 batches: 1287.264404296875
INFO:root:# Valid (Epoch 25): Loss/seq after 00200 batches: 1191.0191650390625
INFO:root:Artifacts: Make stick videos for epoch 25
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_25_on_20220412_204610.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_25_index_43_on_20220412_204610.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 26): Loss/seq after 00000 batchs: 1874.1563720703125
INFO:root:Train (Epoch 26): Loss/seq after 00050 batchs: 1622.9588623046875
INFO:root:Train (Epoch 26): Loss/seq after 00100 batchs: 1597.273681640625
INFO:root:Train (Epoch 26): Loss/seq after 00150 batchs: 1439.6929931640625
INFO:root:Train (Epoch 26): Loss/seq after 00200 batchs: 1551.5772705078125
INFO:root:Train (Epoch 26): Loss/seq after 00250 batchs: 1672.737548828125
INFO:root:Train (Epoch 26): Loss/seq after 00300 batchs: 1579.5147705078125
INFO:root:Train (Epoch 26): Loss/seq after 00350 batchs: 1478.115478515625
INFO:root:Train (Epoch 26): Loss/seq after 00400 batchs: 1528.0089111328125
INFO:root:Train (Epoch 26): Loss/seq after 00450 batchs: 1455.896728515625
INFO:root:Train (Epoch 26): Loss/seq after 00500 batchs: 1486.3841552734375
INFO:root:Train (Epoch 26): Loss/seq after 00550 batchs: 1430.6595458984375
INFO:root:Train (Epoch 26): Loss/seq after 00600 batchs: 1396.0816650390625
INFO:root:Train (Epoch 26): Loss/seq after 00650 batchs: 1411.626708984375
INFO:root:Train (Epoch 26): Loss/seq after 00700 batchs: 1428.669921875
INFO:root:Train (Epoch 26): Loss/seq after 00750 batchs: 1462.2266845703125
INFO:root:Train (Epoch 26): Loss/seq after 00800 batchs: 1457.757568359375
INFO:root:Train (Epoch 26): Loss/seq after 00850 batchs: 1427.448974609375
INFO:root:Train (Epoch 26): Loss/seq after 00900 batchs: 1436.6124267578125
INFO:root:Train (Epoch 26): Loss/seq after 00950 batchs: 1490.726806640625
INFO:root:Train (Epoch 26): Loss/seq after 01000 batchs: 1484.2144775390625
INFO:root:Train (Epoch 26): Loss/seq after 01050 batchs: 1462.602294921875
INFO:root:Train (Epoch 26): Loss/seq after 01100 batchs: 1452.9388427734375
INFO:root:Train (Epoch 26): Loss/seq after 01150 batchs: 1432.408447265625
INFO:root:Train (Epoch 26): Loss/seq after 01200 batchs: 1419.021240234375
INFO:root:Train (Epoch 26): Loss/seq after 01250 batchs: 1410.8558349609375
INFO:root:Train (Epoch 26): Loss/seq after 01300 batchs: 1414.6219482421875
INFO:root:Train (Epoch 26): Loss/seq after 01350 batchs: 1412.0572509765625
INFO:root:Train (Epoch 26): Loss/seq after 01400 batchs: 1444.506591796875
INFO:root:Train (Epoch 26): Loss/seq after 01450 batchs: 1431.5833740234375
INFO:root:Train (Epoch 26): Loss/seq after 01500 batchs: 1419.268310546875
INFO:root:Train (Epoch 26): Loss/seq after 01550 batchs: 1420.45751953125
INFO:root:Train (Epoch 26): Loss/seq after 01600 batchs: 1401.390625
INFO:root:Train (Epoch 26): Loss/seq after 01650 batchs: 1394.548583984375
INFO:root:Train (Epoch 26): Loss/seq after 01700 batchs: 1383.6951904296875
INFO:root:Train (Epoch 26): Loss/seq after 01750 batchs: 1370.15283203125
INFO:root:Train (Epoch 26): Loss/seq after 01800 batchs: 1354.6796875
INFO:root:Train (Epoch 26): Loss/seq after 01850 batchs: 1339.502685546875
INFO:root:Train (Epoch 26): Loss/seq after 01900 batchs: 1336.9012451171875
INFO:root:Train (Epoch 26): Loss/seq after 01950 batchs: 1330.4617919921875
INFO:root:Train (Epoch 26): Loss/seq after 02000 batchs: 1319.540771484375
INFO:root:Train (Epoch 26): Loss/seq after 02050 batchs: 1310.21435546875
INFO:root:Train (Epoch 26): Loss/seq after 02100 batchs: 1297.7265625
INFO:root:Train (Epoch 26): Loss/seq after 02150 batchs: 1286.253662109375
INFO:root:Train (Epoch 26): Loss/seq after 02200 batchs: 1273.97802734375
INFO:root:Train (Epoch 26): Loss/seq after 02250 batchs: 1276.64794921875
INFO:root:Train (Epoch 26): Loss/seq after 02300 batchs: 1280.7642822265625
INFO:root:Train (Epoch 26): Loss/seq after 02350 batchs: 1271.8126220703125
INFO:root:Train (Epoch 26): Loss/seq after 02400 batchs: 1268.0211181640625
INFO:root:Train (Epoch 26): Loss/seq after 02450 batchs: 1255.1358642578125
INFO:root:Train (Epoch 26): Loss/seq after 02500 batchs: 1237.3887939453125
INFO:root:Train (Epoch 26): Loss/seq after 02550 batchs: 1226.0706787109375
INFO:root:Train (Epoch 26): Loss/seq after 02600 batchs: 1224.13427734375
INFO:root:Train (Epoch 26): Loss/seq after 02650 batchs: 1219.1160888671875
INFO:root:Train (Epoch 26): Loss/seq after 02700 batchs: 1214.8067626953125
INFO:root:Train (Epoch 26): Loss/seq after 02750 batchs: 1245.4576416015625
INFO:root:Train (Epoch 26): Loss/seq after 02800 batchs: 1251.02392578125
INFO:root:Train (Epoch 26): Loss/seq after 02850 batchs: 1247.476318359375
INFO:root:Train (Epoch 26): Loss/seq after 02900 batchs: 1245.001220703125
INFO:root:Train (Epoch 26): Loss/seq after 02950 batchs: 1236.903564453125
INFO:root:Train (Epoch 26): Loss/seq after 03000 batchs: 1234.394775390625
INFO:root:Train (Epoch 26): Loss/seq after 03050 batchs: 1236.625244140625
INFO:root:Train (Epoch 26): Loss/seq after 03100 batchs: 1250.3060302734375
INFO:root:Train (Epoch 26): Loss/seq after 03150 batchs: 1262.90087890625
INFO:root:Train (Epoch 26): Loss/seq after 03200 batchs: 1271.6595458984375
INFO:root:Train (Epoch 26): Loss/seq after 03250 batchs: 1277.75927734375
INFO:root:Train (Epoch 26): Loss/seq after 03300 batchs: 1277.3896484375
INFO:root:Train (Epoch 26): Loss/seq after 03350 batchs: 1276.4915771484375
INFO:root:Train (Epoch 26): Loss/seq after 03400 batchs: 1267.2508544921875
INFO:root:Train (Epoch 26): Loss/seq after 03450 batchs: 1259.9898681640625
INFO:root:Train (Epoch 26): Loss/seq after 03500 batchs: 1259.29248046875
INFO:root:Train (Epoch 26): Loss/seq after 03550 batchs: 1253.8909912109375
INFO:root:Train (Epoch 26): Loss/seq after 03600 batchs: 1259.3797607421875
INFO:root:Train (Epoch 26): Loss/seq after 03650 batchs: 1255.013427734375
INFO:root:Train (Epoch 26): Loss/seq after 03700 batchs: 1254.306396484375
INFO:root:Train (Epoch 26): Loss/seq after 03750 batchs: 1253.8636474609375
INFO:root:Train (Epoch 26): Loss/seq after 03800 batchs: 1246.7447509765625
INFO:root:Train (Epoch 26): Loss/seq after 03850 batchs: 1242.1634521484375
INFO:root:Train (Epoch 26): Loss/seq after 03900 batchs: 1247.8358154296875
INFO:root:Train (Epoch 26): Loss/seq after 03950 batchs: 1254.0318603515625
INFO:root:Train (Epoch 26): Loss/seq after 04000 batchs: 1244.7261962890625
INFO:root:Train (Epoch 26): Loss/seq after 04050 batchs: 1236.4112548828125
INFO:root:Train (Epoch 26): Loss/seq after 04100 batchs: 1231.1912841796875
INFO:root:Train (Epoch 26): Loss/seq after 04150 batchs: 1225.28515625
INFO:root:Train (Epoch 26): Loss/seq after 04200 batchs: 1219.857666015625
INFO:root:Train (Epoch 26): Loss/seq after 04250 batchs: 1215.3306884765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 26): Loss/seq after 00000 batches: 878.778076171875
INFO:root:# Valid (Epoch 26): Loss/seq after 00050 batches: 1098.2037353515625
INFO:root:# Valid (Epoch 26): Loss/seq after 00100 batches: 1404.684326171875
INFO:root:# Valid (Epoch 26): Loss/seq after 00150 batches: 1134.3907470703125
INFO:root:# Valid (Epoch 26): Loss/seq after 00200 batches: 1024.16943359375
INFO:root:Artifacts: Make stick videos for epoch 26
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_26_on_20220412_205132.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_26_index_1_on_20220412_205132.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 27): Loss/seq after 00000 batchs: 1721.0140380859375
INFO:root:Train (Epoch 27): Loss/seq after 00050 batchs: 1567.0748291015625
INFO:root:Train (Epoch 27): Loss/seq after 00100 batchs: 1562.995361328125
INFO:root:Train (Epoch 27): Loss/seq after 00150 batchs: 1413.5328369140625
INFO:root:Train (Epoch 27): Loss/seq after 00200 batchs: 1526.6431884765625
INFO:root:Train (Epoch 27): Loss/seq after 00250 batchs: 1649.656005859375
INFO:root:Train (Epoch 27): Loss/seq after 00300 batchs: 1558.994873046875
INFO:root:Train (Epoch 27): Loss/seq after 00350 batchs: 1458.703125
INFO:root:Train (Epoch 27): Loss/seq after 00400 batchs: 1513.82373046875
INFO:root:Train (Epoch 27): Loss/seq after 00450 batchs: 1443.260498046875
INFO:root:Train (Epoch 27): Loss/seq after 00500 batchs: 1469.835693359375
INFO:root:Train (Epoch 27): Loss/seq after 00550 batchs: 1409.22216796875
INFO:root:Train (Epoch 27): Loss/seq after 00600 batchs: 1371.7147216796875
INFO:root:Train (Epoch 27): Loss/seq after 00650 batchs: 1392.55419921875
INFO:root:Train (Epoch 27): Loss/seq after 00700 batchs: 1412.55224609375
INFO:root:Train (Epoch 27): Loss/seq after 00750 batchs: 1444.3594970703125
INFO:root:Train (Epoch 27): Loss/seq after 00800 batchs: 1437.3328857421875
INFO:root:Train (Epoch 27): Loss/seq after 00850 batchs: 1408.182861328125
INFO:root:Train (Epoch 27): Loss/seq after 00900 batchs: 1414.204833984375
INFO:root:Train (Epoch 27): Loss/seq after 00950 batchs: 1467.810546875
INFO:root:Train (Epoch 27): Loss/seq after 01000 batchs: 1466.9586181640625
INFO:root:Train (Epoch 27): Loss/seq after 01050 batchs: 1442.967529296875
INFO:root:Train (Epoch 27): Loss/seq after 01100 batchs: 1432.8192138671875
INFO:root:Train (Epoch 27): Loss/seq after 01150 batchs: 1413.087158203125
INFO:root:Train (Epoch 27): Loss/seq after 01200 batchs: 1399.7001953125
INFO:root:Train (Epoch 27): Loss/seq after 01250 batchs: 1389.264892578125
INFO:root:Train (Epoch 27): Loss/seq after 01300 batchs: 1392.3194580078125
INFO:root:Train (Epoch 27): Loss/seq after 01350 batchs: 1391.4010009765625
INFO:root:Train (Epoch 27): Loss/seq after 01400 batchs: 1422.8135986328125
INFO:root:Train (Epoch 27): Loss/seq after 01450 batchs: 1410.72119140625
INFO:root:Train (Epoch 27): Loss/seq after 01500 batchs: 1398.8636474609375
INFO:root:Train (Epoch 27): Loss/seq after 01550 batchs: 1398.365478515625
INFO:root:Train (Epoch 27): Loss/seq after 01600 batchs: 1379.4801025390625
INFO:root:Train (Epoch 27): Loss/seq after 01650 batchs: 1370.572021484375
INFO:root:Train (Epoch 27): Loss/seq after 01700 batchs: 1359.878173828125
INFO:root:Train (Epoch 27): Loss/seq after 01750 batchs: 1346.8486328125
INFO:root:Train (Epoch 27): Loss/seq after 01800 batchs: 1331.922607421875
INFO:root:Train (Epoch 27): Loss/seq after 01850 batchs: 1317.0479736328125
INFO:root:Train (Epoch 27): Loss/seq after 01900 batchs: 1314.735595703125
INFO:root:Train (Epoch 27): Loss/seq after 01950 batchs: 1308.806640625
INFO:root:Train (Epoch 27): Loss/seq after 02000 batchs: 1298.488037109375
INFO:root:Train (Epoch 27): Loss/seq after 02050 batchs: 1289.65234375
INFO:root:Train (Epoch 27): Loss/seq after 02100 batchs: 1277.58935546875
INFO:root:Train (Epoch 27): Loss/seq after 02150 batchs: 1266.365966796875
INFO:root:Train (Epoch 27): Loss/seq after 02200 batchs: 1254.36376953125
INFO:root:Train (Epoch 27): Loss/seq after 02250 batchs: 1254.25537109375
INFO:root:Train (Epoch 27): Loss/seq after 02300 batchs: 1258.8648681640625
INFO:root:Train (Epoch 27): Loss/seq after 02350 batchs: 1249.632080078125
INFO:root:Train (Epoch 27): Loss/seq after 02400 batchs: 1245.6025390625
INFO:root:Train (Epoch 27): Loss/seq after 02450 batchs: 1232.451416015625
INFO:root:Train (Epoch 27): Loss/seq after 02500 batchs: 1215.1259765625
INFO:root:Train (Epoch 27): Loss/seq after 02550 batchs: 1203.6658935546875
INFO:root:Train (Epoch 27): Loss/seq after 02600 batchs: 1200.8143310546875
INFO:root:Train (Epoch 27): Loss/seq after 02650 batchs: 1196.2779541015625
INFO:root:Train (Epoch 27): Loss/seq after 02700 batchs: 1191.861083984375
INFO:root:Train (Epoch 27): Loss/seq after 02750 batchs: 1221.8360595703125
INFO:root:Train (Epoch 27): Loss/seq after 02800 batchs: 1229.5225830078125
INFO:root:Train (Epoch 27): Loss/seq after 02850 batchs: 1225.729248046875
INFO:root:Train (Epoch 27): Loss/seq after 02900 batchs: 1222.918212890625
INFO:root:Train (Epoch 27): Loss/seq after 02950 batchs: 1214.9027099609375
INFO:root:Train (Epoch 27): Loss/seq after 03000 batchs: 1212.7445068359375
INFO:root:Train (Epoch 27): Loss/seq after 03050 batchs: 1215.16259765625
INFO:root:Train (Epoch 27): Loss/seq after 03100 batchs: 1227.8695068359375
INFO:root:Train (Epoch 27): Loss/seq after 03150 batchs: 1237.5279541015625
INFO:root:Train (Epoch 27): Loss/seq after 03200 batchs: 1244.959716796875
INFO:root:Train (Epoch 27): Loss/seq after 03250 batchs: 1250.325439453125
INFO:root:Train (Epoch 27): Loss/seq after 03300 batchs: 1247.7916259765625
INFO:root:Train (Epoch 27): Loss/seq after 03350 batchs: 1247.2166748046875
INFO:root:Train (Epoch 27): Loss/seq after 03400 batchs: 1238.3472900390625
INFO:root:Train (Epoch 27): Loss/seq after 03450 batchs: 1231.447998046875
INFO:root:Train (Epoch 27): Loss/seq after 03500 batchs: 1230.3173828125
INFO:root:Train (Epoch 27): Loss/seq after 03550 batchs: 1224.6558837890625
INFO:root:Train (Epoch 27): Loss/seq after 03600 batchs: 1230.252197265625
INFO:root:Train (Epoch 27): Loss/seq after 03650 batchs: 1225.6510009765625
INFO:root:Train (Epoch 27): Loss/seq after 03700 batchs: 1225.096435546875
INFO:root:Train (Epoch 27): Loss/seq after 03750 batchs: 1225.1693115234375
INFO:root:Train (Epoch 27): Loss/seq after 03800 batchs: 1218.2152099609375
INFO:root:Train (Epoch 27): Loss/seq after 03850 batchs: 1213.70947265625
INFO:root:Train (Epoch 27): Loss/seq after 03900 batchs: 1218.974853515625
INFO:root:Train (Epoch 27): Loss/seq after 03950 batchs: 1225.1378173828125
INFO:root:Train (Epoch 27): Loss/seq after 04000 batchs: 1216.2064208984375
INFO:root:Train (Epoch 27): Loss/seq after 04050 batchs: 1208.24169921875
INFO:root:Train (Epoch 27): Loss/seq after 04100 batchs: 1202.9771728515625
INFO:root:Train (Epoch 27): Loss/seq after 04150 batchs: 1197.29150390625
INFO:root:Train (Epoch 27): Loss/seq after 04200 batchs: 1191.8031005859375
INFO:root:Train (Epoch 27): Loss/seq after 04250 batchs: 1187.5150146484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 27): Loss/seq after 00000 batches: 880.5127563476562
INFO:root:# Valid (Epoch 27): Loss/seq after 00050 batches: 1099.29931640625
INFO:root:# Valid (Epoch 27): Loss/seq after 00100 batches: 1394.120849609375
INFO:root:# Valid (Epoch 27): Loss/seq after 00150 batches: 1121.614501953125
INFO:root:# Valid (Epoch 27): Loss/seq after 00200 batches: 1013.572998046875
INFO:root:Artifacts: Make stick videos for epoch 27
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_27_on_20220412_205654.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_27_index_980_on_20220412_205654.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 28): Loss/seq after 00000 batchs: 2139.92431640625
INFO:root:Train (Epoch 28): Loss/seq after 00050 batchs: 1532.2012939453125
INFO:root:Train (Epoch 28): Loss/seq after 00100 batchs: 1523.620361328125
INFO:root:Train (Epoch 28): Loss/seq after 00150 batchs: 1426.150390625
INFO:root:Train (Epoch 28): Loss/seq after 00200 batchs: 1530.0087890625
INFO:root:Train (Epoch 28): Loss/seq after 00250 batchs: 1657.486083984375
INFO:root:Train (Epoch 28): Loss/seq after 00300 batchs: 1566.76513671875
INFO:root:Train (Epoch 28): Loss/seq after 00350 batchs: 1469.498779296875
INFO:root:Train (Epoch 28): Loss/seq after 00400 batchs: 1510.0396728515625
INFO:root:Train (Epoch 28): Loss/seq after 00450 batchs: 1440.2860107421875
INFO:root:Train (Epoch 28): Loss/seq after 00500 batchs: 1460.5791015625
INFO:root:Train (Epoch 28): Loss/seq after 00550 batchs: 1398.822021484375
INFO:root:Train (Epoch 28): Loss/seq after 00600 batchs: 1362.466796875
INFO:root:Train (Epoch 28): Loss/seq after 00650 batchs: 1389.4852294921875
INFO:root:Train (Epoch 28): Loss/seq after 00700 batchs: 1420.404052734375
INFO:root:Train (Epoch 28): Loss/seq after 00750 batchs: 1451.9334716796875
INFO:root:Train (Epoch 28): Loss/seq after 00800 batchs: 1442.759521484375
INFO:root:Train (Epoch 28): Loss/seq after 00850 batchs: 1412.28564453125
INFO:root:Train (Epoch 28): Loss/seq after 00900 batchs: 1417.058837890625
INFO:root:Train (Epoch 28): Loss/seq after 00950 batchs: 1466.076416015625
INFO:root:Train (Epoch 28): Loss/seq after 01000 batchs: 1462.24267578125
INFO:root:Train (Epoch 28): Loss/seq after 01050 batchs: 1437.4893798828125
INFO:root:Train (Epoch 28): Loss/seq after 01100 batchs: 1426.23046875
INFO:root:Train (Epoch 28): Loss/seq after 01150 batchs: 1406.373291015625
INFO:root:Train (Epoch 28): Loss/seq after 01200 batchs: 1393.3743896484375
INFO:root:Train (Epoch 28): Loss/seq after 01250 batchs: 1380.37060546875
INFO:root:Train (Epoch 28): Loss/seq after 01300 batchs: 1383.829833984375
INFO:root:Train (Epoch 28): Loss/seq after 01350 batchs: 1383.7506103515625
INFO:root:Train (Epoch 28): Loss/seq after 01400 batchs: 1412.7679443359375
INFO:root:Train (Epoch 28): Loss/seq after 01450 batchs: 1400.51611328125
INFO:root:Train (Epoch 28): Loss/seq after 01500 batchs: 1389.1651611328125
INFO:root:Train (Epoch 28): Loss/seq after 01550 batchs: 1387.5106201171875
INFO:root:Train (Epoch 28): Loss/seq after 01600 batchs: 1368.927001953125
INFO:root:Train (Epoch 28): Loss/seq after 01650 batchs: 1359.0543212890625
INFO:root:Train (Epoch 28): Loss/seq after 01700 batchs: 1348.0789794921875
INFO:root:Train (Epoch 28): Loss/seq after 01750 batchs: 1335.2689208984375
INFO:root:Train (Epoch 28): Loss/seq after 01800 batchs: 1320.5247802734375
INFO:root:Train (Epoch 28): Loss/seq after 01850 batchs: 1305.7374267578125
INFO:root:Train (Epoch 28): Loss/seq after 01900 batchs: 1303.113525390625
INFO:root:Train (Epoch 28): Loss/seq after 01950 batchs: 1297.562744140625
INFO:root:Train (Epoch 28): Loss/seq after 02000 batchs: 1287.5821533203125
INFO:root:Train (Epoch 28): Loss/seq after 02050 batchs: 1278.8262939453125
INFO:root:Train (Epoch 28): Loss/seq after 02100 batchs: 1267.1092529296875
INFO:root:Train (Epoch 28): Loss/seq after 02150 batchs: 1256.56787109375
INFO:root:Train (Epoch 28): Loss/seq after 02200 batchs: 1244.83251953125
INFO:root:Train (Epoch 28): Loss/seq after 02250 batchs: 1245.766845703125
INFO:root:Train (Epoch 28): Loss/seq after 02300 batchs: 1249.7818603515625
INFO:root:Train (Epoch 28): Loss/seq after 02350 batchs: 1241.2049560546875
INFO:root:Train (Epoch 28): Loss/seq after 02400 batchs: 1237.4212646484375
INFO:root:Train (Epoch 28): Loss/seq after 02450 batchs: 1225.4007568359375
INFO:root:Train (Epoch 28): Loss/seq after 02500 batchs: 1208.326416015625
INFO:root:Train (Epoch 28): Loss/seq after 02550 batchs: 1197.5018310546875
INFO:root:Train (Epoch 28): Loss/seq after 02600 batchs: 1195.1380615234375
INFO:root:Train (Epoch 28): Loss/seq after 02650 batchs: 1190.4503173828125
INFO:root:Train (Epoch 28): Loss/seq after 02700 batchs: 1186.0869140625
INFO:root:Train (Epoch 28): Loss/seq after 02750 batchs: 1217.0081787109375
INFO:root:Train (Epoch 28): Loss/seq after 02800 batchs: 1223.780517578125
INFO:root:Train (Epoch 28): Loss/seq after 02850 batchs: 1220.322021484375
INFO:root:Train (Epoch 28): Loss/seq after 02900 batchs: 1217.3876953125
INFO:root:Train (Epoch 28): Loss/seq after 02950 batchs: 1209.6025390625
INFO:root:Train (Epoch 28): Loss/seq after 03000 batchs: 1207.566650390625
INFO:root:Train (Epoch 28): Loss/seq after 03050 batchs: 1210.3004150390625
INFO:root:Train (Epoch 28): Loss/seq after 03100 batchs: 1222.4459228515625
INFO:root:Train (Epoch 28): Loss/seq after 03150 batchs: 1234.413818359375
INFO:root:Train (Epoch 28): Loss/seq after 03200 batchs: 1242.528076171875
INFO:root:Train (Epoch 28): Loss/seq after 03250 batchs: 1247.951171875
INFO:root:Train (Epoch 28): Loss/seq after 03300 batchs: 1246.1439208984375
INFO:root:Train (Epoch 28): Loss/seq after 03350 batchs: 1244.1312255859375
INFO:root:Train (Epoch 28): Loss/seq after 03400 batchs: 1235.3653564453125
INFO:root:Train (Epoch 28): Loss/seq after 03450 batchs: 1228.890869140625
INFO:root:Train (Epoch 28): Loss/seq after 03500 batchs: 1227.4666748046875
INFO:root:Train (Epoch 28): Loss/seq after 03550 batchs: 1221.7523193359375
INFO:root:Train (Epoch 28): Loss/seq after 03600 batchs: 1227.2313232421875
INFO:root:Train (Epoch 28): Loss/seq after 03650 batchs: 1221.7061767578125
INFO:root:Train (Epoch 28): Loss/seq after 03700 batchs: 1220.9881591796875
INFO:root:Train (Epoch 28): Loss/seq after 03750 batchs: 1220.9547119140625
INFO:root:Train (Epoch 28): Loss/seq after 03800 batchs: 1214.01611328125
INFO:root:Train (Epoch 28): Loss/seq after 03850 batchs: 1209.5609130859375
INFO:root:Train (Epoch 28): Loss/seq after 03900 batchs: 1215.118408203125
INFO:root:Train (Epoch 28): Loss/seq after 03950 batchs: 1220.1376953125
INFO:root:Train (Epoch 28): Loss/seq after 04000 batchs: 1211.2943115234375
INFO:root:Train (Epoch 28): Loss/seq after 04050 batchs: 1203.3870849609375
INFO:root:Train (Epoch 28): Loss/seq after 04100 batchs: 1197.70654296875
INFO:root:Train (Epoch 28): Loss/seq after 04150 batchs: 1192.021728515625
INFO:root:Train (Epoch 28): Loss/seq after 04200 batchs: 1186.8619384765625
INFO:root:Train (Epoch 28): Loss/seq after 04250 batchs: 1182.857421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 28): Loss/seq after 00000 batches: 886.0388793945312
INFO:root:# Valid (Epoch 28): Loss/seq after 00050 batches: 1109.4169921875
INFO:root:# Valid (Epoch 28): Loss/seq after 00100 batches: 1481.1827392578125
INFO:root:# Valid (Epoch 28): Loss/seq after 00150 batches: 1181.677001953125
INFO:root:# Valid (Epoch 28): Loss/seq after 00200 batches: 1059.160888671875
INFO:root:Artifacts: Make stick videos for epoch 28
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_28_on_20220412_210217.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_28_index_646_on_20220412_210217.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 29): Loss/seq after 00000 batchs: 2303.63037109375
INFO:root:Train (Epoch 29): Loss/seq after 00050 batchs: 1518.4971923828125
INFO:root:Train (Epoch 29): Loss/seq after 00100 batchs: 1473.525146484375
INFO:root:Train (Epoch 29): Loss/seq after 00150 batchs: 1354.741455078125
INFO:root:Train (Epoch 29): Loss/seq after 00200 batchs: 1456.9613037109375
INFO:root:Train (Epoch 29): Loss/seq after 00250 batchs: 1581.8905029296875
INFO:root:Train (Epoch 29): Loss/seq after 00300 batchs: 1501.8961181640625
INFO:root:Train (Epoch 29): Loss/seq after 00350 batchs: 1404.848876953125
INFO:root:Train (Epoch 29): Loss/seq after 00400 batchs: 1446.28125
INFO:root:Train (Epoch 29): Loss/seq after 00450 batchs: 1382.8831787109375
INFO:root:Train (Epoch 29): Loss/seq after 00500 batchs: 1399.489501953125
INFO:root:Train (Epoch 29): Loss/seq after 00550 batchs: 1342.4786376953125
INFO:root:Train (Epoch 29): Loss/seq after 00600 batchs: 1308.9866943359375
INFO:root:Train (Epoch 29): Loss/seq after 00650 batchs: 1351.1795654296875
INFO:root:Train (Epoch 29): Loss/seq after 00700 batchs: 1396.2088623046875
INFO:root:Train (Epoch 29): Loss/seq after 00750 batchs: 1426.1962890625
INFO:root:Train (Epoch 29): Loss/seq after 00800 batchs: 1417.163330078125
INFO:root:Train (Epoch 29): Loss/seq after 00850 batchs: 1390.08154296875
INFO:root:Train (Epoch 29): Loss/seq after 00900 batchs: 1399.4632568359375
INFO:root:Train (Epoch 29): Loss/seq after 00950 batchs: 1457.5802001953125
INFO:root:Train (Epoch 29): Loss/seq after 01000 batchs: 1454.55712890625
INFO:root:Train (Epoch 29): Loss/seq after 01050 batchs: 1430.9208984375
INFO:root:Train (Epoch 29): Loss/seq after 01100 batchs: 1423.8187255859375
INFO:root:Train (Epoch 29): Loss/seq after 01150 batchs: 1403.522216796875
INFO:root:Train (Epoch 29): Loss/seq after 01200 batchs: 1389.7200927734375
INFO:root:Train (Epoch 29): Loss/seq after 01250 batchs: 1380.3177490234375
INFO:root:Train (Epoch 29): Loss/seq after 01300 batchs: 1383.969482421875
INFO:root:Train (Epoch 29): Loss/seq after 01350 batchs: 1384.469482421875
INFO:root:Train (Epoch 29): Loss/seq after 01400 batchs: 1415.7662353515625
INFO:root:Train (Epoch 29): Loss/seq after 01450 batchs: 1403.215576171875
INFO:root:Train (Epoch 29): Loss/seq after 01500 batchs: 1391.883544921875
INFO:root:Train (Epoch 29): Loss/seq after 01550 batchs: 1389.60693359375
INFO:root:Train (Epoch 29): Loss/seq after 01600 batchs: 1370.956787109375
INFO:root:Train (Epoch 29): Loss/seq after 01650 batchs: 1360.506591796875
INFO:root:Train (Epoch 29): Loss/seq after 01700 batchs: 1349.0118408203125
INFO:root:Train (Epoch 29): Loss/seq after 01750 batchs: 1335.9710693359375
INFO:root:Train (Epoch 29): Loss/seq after 01800 batchs: 1320.8314208984375
INFO:root:Train (Epoch 29): Loss/seq after 01850 batchs: 1305.882080078125
INFO:root:Train (Epoch 29): Loss/seq after 01900 batchs: 1302.8338623046875
INFO:root:Train (Epoch 29): Loss/seq after 01950 batchs: 1295.8861083984375
INFO:root:Train (Epoch 29): Loss/seq after 02000 batchs: 1285.577880859375
INFO:root:Train (Epoch 29): Loss/seq after 02050 batchs: 1276.546630859375
INFO:root:Train (Epoch 29): Loss/seq after 02100 batchs: 1264.462158203125
INFO:root:Train (Epoch 29): Loss/seq after 02150 batchs: 1253.378173828125
INFO:root:Train (Epoch 29): Loss/seq after 02200 batchs: 1241.6116943359375
INFO:root:Train (Epoch 29): Loss/seq after 02250 batchs: 1240.4874267578125
INFO:root:Train (Epoch 29): Loss/seq after 02300 batchs: 1244.541748046875
INFO:root:Train (Epoch 29): Loss/seq after 02350 batchs: 1235.4237060546875
INFO:root:Train (Epoch 29): Loss/seq after 02400 batchs: 1231.6370849609375
INFO:root:Train (Epoch 29): Loss/seq after 02450 batchs: 1219.252197265625
INFO:root:Train (Epoch 29): Loss/seq after 02500 batchs: 1202.1961669921875
INFO:root:Train (Epoch 29): Loss/seq after 02550 batchs: 1191.3956298828125
INFO:root:Train (Epoch 29): Loss/seq after 02600 batchs: 1190.8995361328125
INFO:root:Train (Epoch 29): Loss/seq after 02650 batchs: 1186.7738037109375
INFO:root:Train (Epoch 29): Loss/seq after 02700 batchs: 1183.15625
INFO:root:Train (Epoch 29): Loss/seq after 02750 batchs: 1213.1563720703125
INFO:root:Train (Epoch 29): Loss/seq after 02800 batchs: 1218.8414306640625
INFO:root:Train (Epoch 29): Loss/seq after 02850 batchs: 1215.1436767578125
INFO:root:Train (Epoch 29): Loss/seq after 02900 batchs: 1211.9730224609375
INFO:root:Train (Epoch 29): Loss/seq after 02950 batchs: 1204.07958984375
INFO:root:Train (Epoch 29): Loss/seq after 03000 batchs: 1202.1337890625
INFO:root:Train (Epoch 29): Loss/seq after 03050 batchs: 1204.672119140625
INFO:root:Train (Epoch 29): Loss/seq after 03100 batchs: 1215.12255859375
INFO:root:Train (Epoch 29): Loss/seq after 03150 batchs: 1225.092041015625
INFO:root:Train (Epoch 29): Loss/seq after 03200 batchs: 1233.8236083984375
INFO:root:Train (Epoch 29): Loss/seq after 03250 batchs: 1239.909423828125
INFO:root:Train (Epoch 29): Loss/seq after 03300 batchs: 1238.0216064453125
INFO:root:Train (Epoch 29): Loss/seq after 03350 batchs: 1238.4735107421875
INFO:root:Train (Epoch 29): Loss/seq after 03400 batchs: 1230.2784423828125
INFO:root:Train (Epoch 29): Loss/seq after 03450 batchs: 1224.1622314453125
INFO:root:Train (Epoch 29): Loss/seq after 03500 batchs: 1224.32763671875
INFO:root:Train (Epoch 29): Loss/seq after 03550 batchs: 1218.87158203125
INFO:root:Train (Epoch 29): Loss/seq after 03600 batchs: 1224.611328125
INFO:root:Train (Epoch 29): Loss/seq after 03650 batchs: 1219.4869384765625
INFO:root:Train (Epoch 29): Loss/seq after 03700 batchs: 1218.663818359375
INFO:root:Train (Epoch 29): Loss/seq after 03750 batchs: 1218.60791015625
INFO:root:Train (Epoch 29): Loss/seq after 03800 batchs: 1211.56103515625
INFO:root:Train (Epoch 29): Loss/seq after 03850 batchs: 1206.9969482421875
INFO:root:Train (Epoch 29): Loss/seq after 03900 batchs: 1211.0863037109375
INFO:root:Train (Epoch 29): Loss/seq after 03950 batchs: 1216.5137939453125
INFO:root:Train (Epoch 29): Loss/seq after 04000 batchs: 1207.6397705078125
INFO:root:Train (Epoch 29): Loss/seq after 04050 batchs: 1199.79150390625
INFO:root:Train (Epoch 29): Loss/seq after 04100 batchs: 1194.27783203125
INFO:root:Train (Epoch 29): Loss/seq after 04150 batchs: 1188.6177978515625
INFO:root:Train (Epoch 29): Loss/seq after 04200 batchs: 1183.412841796875
INFO:root:Train (Epoch 29): Loss/seq after 04250 batchs: 1179.12158203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 29): Loss/seq after 00000 batches: 874.6144409179688
INFO:root:# Valid (Epoch 29): Loss/seq after 00050 batches: 1097.9603271484375
INFO:root:# Valid (Epoch 29): Loss/seq after 00100 batches: 1392.1158447265625
INFO:root:# Valid (Epoch 29): Loss/seq after 00150 batches: 1111.45263671875
INFO:root:# Valid (Epoch 29): Loss/seq after 00200 batches: 1000.7910766601562
INFO:root:Artifacts: Make stick videos for epoch 29
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_29_on_20220412_210740.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_29_index_37_on_20220412_210740.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 30): Loss/seq after 00000 batchs: 1439.140869140625
INFO:root:Train (Epoch 30): Loss/seq after 00050 batchs: 1489.0035400390625
INFO:root:Train (Epoch 30): Loss/seq after 00100 batchs: 1448.8089599609375
INFO:root:Train (Epoch 30): Loss/seq after 00150 batchs: 1319.18701171875
INFO:root:Train (Epoch 30): Loss/seq after 00200 batchs: 1437.0439453125
INFO:root:Train (Epoch 30): Loss/seq after 00250 batchs: 1576.3897705078125
INFO:root:Train (Epoch 30): Loss/seq after 00300 batchs: 1497.2529296875
INFO:root:Train (Epoch 30): Loss/seq after 00350 batchs: 1402.905517578125
INFO:root:Train (Epoch 30): Loss/seq after 00400 batchs: 1443.8865966796875
INFO:root:Train (Epoch 30): Loss/seq after 00450 batchs: 1381.145751953125
INFO:root:Train (Epoch 30): Loss/seq after 00500 batchs: 1389.49267578125
INFO:root:Train (Epoch 30): Loss/seq after 00550 batchs: 1331.655517578125
INFO:root:Train (Epoch 30): Loss/seq after 00600 batchs: 1294.6644287109375
INFO:root:Train (Epoch 30): Loss/seq after 00650 batchs: 1322.9139404296875
INFO:root:Train (Epoch 30): Loss/seq after 00700 batchs: 1350.86181640625
INFO:root:Train (Epoch 30): Loss/seq after 00750 batchs: 1382.688232421875
INFO:root:Train (Epoch 30): Loss/seq after 00800 batchs: 1375.0439453125
INFO:root:Train (Epoch 30): Loss/seq after 00850 batchs: 1351.8349609375
INFO:root:Train (Epoch 30): Loss/seq after 00900 batchs: 1359.8143310546875
INFO:root:Train (Epoch 30): Loss/seq after 00950 batchs: 1404.4061279296875
INFO:root:Train (Epoch 30): Loss/seq after 01000 batchs: 1396.815185546875
INFO:root:Train (Epoch 30): Loss/seq after 01050 batchs: 1374.6790771484375
INFO:root:Train (Epoch 30): Loss/seq after 01100 batchs: 1365.41455078125
INFO:root:Train (Epoch 30): Loss/seq after 01150 batchs: 1349.2064208984375
INFO:root:Train (Epoch 30): Loss/seq after 01200 batchs: 1337.92578125
INFO:root:Train (Epoch 30): Loss/seq after 01250 batchs: 1327.4476318359375
INFO:root:Train (Epoch 30): Loss/seq after 01300 batchs: 1329.8701171875
INFO:root:Train (Epoch 30): Loss/seq after 01350 batchs: 1330.5423583984375
INFO:root:Train (Epoch 30): Loss/seq after 01400 batchs: 1360.4171142578125
INFO:root:Train (Epoch 30): Loss/seq after 01450 batchs: 1349.7645263671875
INFO:root:Train (Epoch 30): Loss/seq after 01500 batchs: 1339.74853515625
INFO:root:Train (Epoch 30): Loss/seq after 01550 batchs: 1337.666015625
INFO:root:Train (Epoch 30): Loss/seq after 01600 batchs: 1320.3292236328125
INFO:root:Train (Epoch 30): Loss/seq after 01650 batchs: 1311.971923828125
INFO:root:Train (Epoch 30): Loss/seq after 01700 batchs: 1302.74560546875
INFO:root:Train (Epoch 30): Loss/seq after 01750 batchs: 1291.1531982421875
INFO:root:Train (Epoch 30): Loss/seq after 01800 batchs: 1277.4296875
INFO:root:Train (Epoch 30): Loss/seq after 01850 batchs: 1263.749267578125
INFO:root:Train (Epoch 30): Loss/seq after 01900 batchs: 1262.1234130859375
INFO:root:Train (Epoch 30): Loss/seq after 01950 batchs: 1256.131103515625
INFO:root:Train (Epoch 30): Loss/seq after 02000 batchs: 1246.71630859375
INFO:root:Train (Epoch 30): Loss/seq after 02050 batchs: 1238.4405517578125
INFO:root:Train (Epoch 30): Loss/seq after 02100 batchs: 1227.1060791015625
INFO:root:Train (Epoch 30): Loss/seq after 02150 batchs: 1216.7352294921875
INFO:root:Train (Epoch 30): Loss/seq after 02200 batchs: 1205.7664794921875
INFO:root:Train (Epoch 30): Loss/seq after 02250 batchs: 1204.578369140625
INFO:root:Train (Epoch 30): Loss/seq after 02300 batchs: 1207.6883544921875
INFO:root:Train (Epoch 30): Loss/seq after 02350 batchs: 1198.840087890625
INFO:root:Train (Epoch 30): Loss/seq after 02400 batchs: 1195.315185546875
INFO:root:Train (Epoch 30): Loss/seq after 02450 batchs: 1182.9462890625
INFO:root:Train (Epoch 30): Loss/seq after 02500 batchs: 1166.571533203125
INFO:root:Train (Epoch 30): Loss/seq after 02550 batchs: 1155.837158203125
INFO:root:Train (Epoch 30): Loss/seq after 02600 batchs: 1153.62890625
INFO:root:Train (Epoch 30): Loss/seq after 02650 batchs: 1149.4534912109375
INFO:root:Train (Epoch 30): Loss/seq after 02700 batchs: 1145.0888671875
INFO:root:Train (Epoch 30): Loss/seq after 02750 batchs: 1174.6990966796875
INFO:root:Train (Epoch 30): Loss/seq after 02800 batchs: 1180.384521484375
INFO:root:Train (Epoch 30): Loss/seq after 02850 batchs: 1176.7747802734375
INFO:root:Train (Epoch 30): Loss/seq after 02900 batchs: 1174.4427490234375
INFO:root:Train (Epoch 30): Loss/seq after 02950 batchs: 1167.288818359375
INFO:root:Train (Epoch 30): Loss/seq after 03000 batchs: 1165.9046630859375
INFO:root:Train (Epoch 30): Loss/seq after 03050 batchs: 1169.0596923828125
INFO:root:Train (Epoch 30): Loss/seq after 03100 batchs: 1178.936279296875
INFO:root:Train (Epoch 30): Loss/seq after 03150 batchs: 1186.5185546875
INFO:root:Train (Epoch 30): Loss/seq after 03200 batchs: 1196.837158203125
INFO:root:Train (Epoch 30): Loss/seq after 03250 batchs: 1204.4205322265625
INFO:root:Train (Epoch 30): Loss/seq after 03300 batchs: 1203.444091796875
INFO:root:Train (Epoch 30): Loss/seq after 03350 batchs: 1202.8736572265625
INFO:root:Train (Epoch 30): Loss/seq after 03400 batchs: 1194.895751953125
INFO:root:Train (Epoch 30): Loss/seq after 03450 batchs: 1189.8668212890625
INFO:root:Train (Epoch 30): Loss/seq after 03500 batchs: 1190.184326171875
INFO:root:Train (Epoch 30): Loss/seq after 03550 batchs: 1184.9188232421875
INFO:root:Train (Epoch 30): Loss/seq after 03600 batchs: 1191.200927734375
INFO:root:Train (Epoch 30): Loss/seq after 03650 batchs: 1186.301513671875
INFO:root:Train (Epoch 30): Loss/seq after 03700 batchs: 1186.3858642578125
INFO:root:Train (Epoch 30): Loss/seq after 03750 batchs: 1186.7779541015625
INFO:root:Train (Epoch 30): Loss/seq after 03800 batchs: 1180.28564453125
INFO:root:Train (Epoch 30): Loss/seq after 03850 batchs: 1176.2093505859375
INFO:root:Train (Epoch 30): Loss/seq after 03900 batchs: 1180.837646484375
INFO:root:Train (Epoch 30): Loss/seq after 03950 batchs: 1187.271484375
INFO:root:Train (Epoch 30): Loss/seq after 04000 batchs: 1178.7618408203125
INFO:root:Train (Epoch 30): Loss/seq after 04050 batchs: 1171.2376708984375
INFO:root:Train (Epoch 30): Loss/seq after 04100 batchs: 1166.5947265625
INFO:root:Train (Epoch 30): Loss/seq after 04150 batchs: 1161.36572265625
INFO:root:Train (Epoch 30): Loss/seq after 04200 batchs: 1156.3489990234375
INFO:root:Train (Epoch 30): Loss/seq after 04250 batchs: 1152.2633056640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 30): Loss/seq after 00000 batches: 885.986572265625
INFO:root:# Valid (Epoch 30): Loss/seq after 00050 batches: 1099.7076416015625
INFO:root:# Valid (Epoch 30): Loss/seq after 00100 batches: 1391.7239990234375
INFO:root:# Valid (Epoch 30): Loss/seq after 00150 batches: 1110.95166015625
INFO:root:# Valid (Epoch 30): Loss/seq after 00200 batches: 1002.7105102539062
INFO:root:Artifacts: Make stick videos for epoch 30
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_30_on_20220412_211303.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_30_index_76_on_20220412_211303.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 31): Loss/seq after 00000 batchs: 2570.976806640625
INFO:root:Train (Epoch 31): Loss/seq after 00050 batchs: 1525.03466796875
INFO:root:Train (Epoch 31): Loss/seq after 00100 batchs: 1462.5526123046875
INFO:root:Train (Epoch 31): Loss/seq after 00150 batchs: 1322.1151123046875
INFO:root:Train (Epoch 31): Loss/seq after 00200 batchs: 1428.3048095703125
INFO:root:Train (Epoch 31): Loss/seq after 00250 batchs: 1550.295654296875
INFO:root:Train (Epoch 31): Loss/seq after 00300 batchs: 1474.9188232421875
INFO:root:Train (Epoch 31): Loss/seq after 00350 batchs: 1383.120361328125
INFO:root:Train (Epoch 31): Loss/seq after 00400 batchs: 1424.136474609375
INFO:root:Train (Epoch 31): Loss/seq after 00450 batchs: 1363.4415283203125
INFO:root:Train (Epoch 31): Loss/seq after 00500 batchs: 1367.0421142578125
INFO:root:Train (Epoch 31): Loss/seq after 00550 batchs: 1310.69873046875
INFO:root:Train (Epoch 31): Loss/seq after 00600 batchs: 1273.85205078125
INFO:root:Train (Epoch 31): Loss/seq after 00650 batchs: 1294.41015625
INFO:root:Train (Epoch 31): Loss/seq after 00700 batchs: 1327.36669921875
INFO:root:Train (Epoch 31): Loss/seq after 00750 batchs: 1362.9730224609375
INFO:root:Train (Epoch 31): Loss/seq after 00800 batchs: 1355.47705078125
INFO:root:Train (Epoch 31): Loss/seq after 00850 batchs: 1329.352294921875
INFO:root:Train (Epoch 31): Loss/seq after 00900 batchs: 1339.434814453125
INFO:root:Train (Epoch 31): Loss/seq after 00950 batchs: 1388.9404296875
INFO:root:Train (Epoch 31): Loss/seq after 01000 batchs: 1384.063720703125
INFO:root:Train (Epoch 31): Loss/seq after 01050 batchs: 1359.937255859375
INFO:root:Train (Epoch 31): Loss/seq after 01100 batchs: 1351.7569580078125
INFO:root:Train (Epoch 31): Loss/seq after 01150 batchs: 1335.111083984375
INFO:root:Train (Epoch 31): Loss/seq after 01200 batchs: 1325.1383056640625
INFO:root:Train (Epoch 31): Loss/seq after 01250 batchs: 1315.4154052734375
INFO:root:Train (Epoch 31): Loss/seq after 01300 batchs: 1317.7125244140625
INFO:root:Train (Epoch 31): Loss/seq after 01350 batchs: 1318.616943359375
INFO:root:Train (Epoch 31): Loss/seq after 01400 batchs: 1344.2178955078125
INFO:root:Train (Epoch 31): Loss/seq after 01450 batchs: 1333.763916015625
INFO:root:Train (Epoch 31): Loss/seq after 01500 batchs: 1324.378173828125
INFO:root:Train (Epoch 31): Loss/seq after 01550 batchs: 1322.084716796875
INFO:root:Train (Epoch 31): Loss/seq after 01600 batchs: 1305.050048828125
INFO:root:Train (Epoch 31): Loss/seq after 01650 batchs: 1295.3482666015625
INFO:root:Train (Epoch 31): Loss/seq after 01700 batchs: 1286.32373046875
INFO:root:Train (Epoch 31): Loss/seq after 01750 batchs: 1275.4595947265625
INFO:root:Train (Epoch 31): Loss/seq after 01800 batchs: 1262.2513427734375
INFO:root:Train (Epoch 31): Loss/seq after 01850 batchs: 1248.95947265625
INFO:root:Train (Epoch 31): Loss/seq after 01900 batchs: 1247.3594970703125
INFO:root:Train (Epoch 31): Loss/seq after 01950 batchs: 1240.7667236328125
INFO:root:Train (Epoch 31): Loss/seq after 02000 batchs: 1231.623046875
INFO:root:Train (Epoch 31): Loss/seq after 02050 batchs: 1223.8204345703125
INFO:root:Train (Epoch 31): Loss/seq after 02100 batchs: 1213.0189208984375
INFO:root:Train (Epoch 31): Loss/seq after 02150 batchs: 1202.8924560546875
INFO:root:Train (Epoch 31): Loss/seq after 02200 batchs: 1192.2554931640625
INFO:root:Train (Epoch 31): Loss/seq after 02250 batchs: 1191.3592529296875
INFO:root:Train (Epoch 31): Loss/seq after 02300 batchs: 1195.3875732421875
INFO:root:Train (Epoch 31): Loss/seq after 02350 batchs: 1186.470703125
INFO:root:Train (Epoch 31): Loss/seq after 02400 batchs: 1183.236328125
INFO:root:Train (Epoch 31): Loss/seq after 02450 batchs: 1171.329345703125
INFO:root:Train (Epoch 31): Loss/seq after 02500 batchs: 1155.1513671875
INFO:root:Train (Epoch 31): Loss/seq after 02550 batchs: 1144.980224609375
INFO:root:Train (Epoch 31): Loss/seq after 02600 batchs: 1144.3021240234375
INFO:root:Train (Epoch 31): Loss/seq after 02650 batchs: 1141.0206298828125
INFO:root:Train (Epoch 31): Loss/seq after 02700 batchs: 1137.6556396484375
INFO:root:Train (Epoch 31): Loss/seq after 02750 batchs: 1167.21484375
INFO:root:Train (Epoch 31): Loss/seq after 02800 batchs: 1172.345458984375
INFO:root:Train (Epoch 31): Loss/seq after 02850 batchs: 1168.6739501953125
INFO:root:Train (Epoch 31): Loss/seq after 02900 batchs: 1166.1033935546875
INFO:root:Train (Epoch 31): Loss/seq after 02950 batchs: 1158.8857421875
INFO:root:Train (Epoch 31): Loss/seq after 03000 batchs: 1157.6214599609375
INFO:root:Train (Epoch 31): Loss/seq after 03050 batchs: 1160.765625
INFO:root:Train (Epoch 31): Loss/seq after 03100 batchs: 1170.4703369140625
INFO:root:Train (Epoch 31): Loss/seq after 03150 batchs: 1176.6822509765625
INFO:root:Train (Epoch 31): Loss/seq after 03200 batchs: 1185.2752685546875
INFO:root:Train (Epoch 31): Loss/seq after 03250 batchs: 1192.989501953125
INFO:root:Train (Epoch 31): Loss/seq after 03300 batchs: 1191.43212890625
INFO:root:Train (Epoch 31): Loss/seq after 03350 batchs: 1190.009765625
INFO:root:Train (Epoch 31): Loss/seq after 03400 batchs: 1181.978515625
INFO:root:Train (Epoch 31): Loss/seq after 03450 batchs: 1175.333740234375
INFO:root:Train (Epoch 31): Loss/seq after 03500 batchs: 1174.4400634765625
INFO:root:Train (Epoch 31): Loss/seq after 03550 batchs: 1168.5836181640625
INFO:root:Train (Epoch 31): Loss/seq after 03600 batchs: 1174.45703125
INFO:root:Train (Epoch 31): Loss/seq after 03650 batchs: 1169.183837890625
INFO:root:Train (Epoch 31): Loss/seq after 03700 batchs: 1169.0987548828125
INFO:root:Train (Epoch 31): Loss/seq after 03750 batchs: 1169.775634765625
INFO:root:Train (Epoch 31): Loss/seq after 03800 batchs: 1163.4744873046875
INFO:root:Train (Epoch 31): Loss/seq after 03850 batchs: 1159.615478515625
INFO:root:Train (Epoch 31): Loss/seq after 03900 batchs: 1164.1773681640625
INFO:root:Train (Epoch 31): Loss/seq after 03950 batchs: 1168.814697265625
INFO:root:Train (Epoch 31): Loss/seq after 04000 batchs: 1160.564208984375
INFO:root:Train (Epoch 31): Loss/seq after 04050 batchs: 1153.2772216796875
INFO:root:Train (Epoch 31): Loss/seq after 04100 batchs: 1147.9908447265625
INFO:root:Train (Epoch 31): Loss/seq after 04150 batchs: 1142.832275390625
INFO:root:Train (Epoch 31): Loss/seq after 04200 batchs: 1138.1204833984375
INFO:root:Train (Epoch 31): Loss/seq after 04250 batchs: 1134.279296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 31): Loss/seq after 00000 batches: 904.060302734375
INFO:root:# Valid (Epoch 31): Loss/seq after 00050 batches: 1096.187255859375
INFO:root:# Valid (Epoch 31): Loss/seq after 00100 batches: 1389.3245849609375
INFO:root:# Valid (Epoch 31): Loss/seq after 00150 batches: 1108.8123779296875
INFO:root:# Valid (Epoch 31): Loss/seq after 00200 batches: 997.6755981445312
INFO:root:Artifacts: Make stick videos for epoch 31
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_31_on_20220412_211825.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_31_index_1663_on_20220412_211825.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 32): Loss/seq after 00000 batchs: 1716.1146240234375
INFO:root:Train (Epoch 32): Loss/seq after 00050 batchs: 1443.43603515625
INFO:root:Train (Epoch 32): Loss/seq after 00100 batchs: 1411.025390625
INFO:root:Train (Epoch 32): Loss/seq after 00150 batchs: 1274.0970458984375
INFO:root:Train (Epoch 32): Loss/seq after 00200 batchs: 1381.58740234375
INFO:root:Train (Epoch 32): Loss/seq after 00250 batchs: 1504.6029052734375
INFO:root:Train (Epoch 32): Loss/seq after 00300 batchs: 1436.848388671875
INFO:root:Train (Epoch 32): Loss/seq after 00350 batchs: 1345.146484375
INFO:root:Train (Epoch 32): Loss/seq after 00400 batchs: 1376.5753173828125
INFO:root:Train (Epoch 32): Loss/seq after 00450 batchs: 1321.22216796875
INFO:root:Train (Epoch 32): Loss/seq after 00500 batchs: 1330.545654296875
INFO:root:Train (Epoch 32): Loss/seq after 00550 batchs: 1277.3326416015625
INFO:root:Train (Epoch 32): Loss/seq after 00600 batchs: 1242.776123046875
INFO:root:Train (Epoch 32): Loss/seq after 00650 batchs: 1272.44921875
INFO:root:Train (Epoch 32): Loss/seq after 00700 batchs: 1286.7537841796875
INFO:root:Train (Epoch 32): Loss/seq after 00750 batchs: 1326.56005859375
INFO:root:Train (Epoch 32): Loss/seq after 00800 batchs: 1319.72900390625
INFO:root:Train (Epoch 32): Loss/seq after 00850 batchs: 1294.9320068359375
INFO:root:Train (Epoch 32): Loss/seq after 00900 batchs: 1304.555419921875
INFO:root:Train (Epoch 32): Loss/seq after 00950 batchs: 1343.1417236328125
INFO:root:Train (Epoch 32): Loss/seq after 01000 batchs: 1338.6829833984375
INFO:root:Train (Epoch 32): Loss/seq after 01050 batchs: 1316.127685546875
INFO:root:Train (Epoch 32): Loss/seq after 01100 batchs: 1312.292724609375
INFO:root:Train (Epoch 32): Loss/seq after 01150 batchs: 1296.6854248046875
INFO:root:Train (Epoch 32): Loss/seq after 01200 batchs: 1286.887939453125
INFO:root:Train (Epoch 32): Loss/seq after 01250 batchs: 1277.04736328125
INFO:root:Train (Epoch 32): Loss/seq after 01300 batchs: 1279.572998046875
INFO:root:Train (Epoch 32): Loss/seq after 01350 batchs: 1282.61962890625
INFO:root:Train (Epoch 32): Loss/seq after 01400 batchs: 1314.048828125
INFO:root:Train (Epoch 32): Loss/seq after 01450 batchs: 1304.3746337890625
INFO:root:Train (Epoch 32): Loss/seq after 01500 batchs: 1295.8521728515625
INFO:root:Train (Epoch 32): Loss/seq after 01550 batchs: 1294.2052001953125
INFO:root:Train (Epoch 32): Loss/seq after 01600 batchs: 1278.29443359375
INFO:root:Train (Epoch 32): Loss/seq after 01650 batchs: 1269.193359375
INFO:root:Train (Epoch 32): Loss/seq after 01700 batchs: 1260.16455078125
INFO:root:Train (Epoch 32): Loss/seq after 01750 batchs: 1249.8758544921875
INFO:root:Train (Epoch 32): Loss/seq after 01800 batchs: 1237.1802978515625
INFO:root:Train (Epoch 32): Loss/seq after 01850 batchs: 1224.532958984375
INFO:root:Train (Epoch 32): Loss/seq after 01900 batchs: 1223.8331298828125
INFO:root:Train (Epoch 32): Loss/seq after 01950 batchs: 1218.4561767578125
INFO:root:Train (Epoch 32): Loss/seq after 02000 batchs: 1209.8199462890625
INFO:root:Train (Epoch 32): Loss/seq after 02050 batchs: 1202.460693359375
INFO:root:Train (Epoch 32): Loss/seq after 02100 batchs: 1191.9703369140625
INFO:root:Train (Epoch 32): Loss/seq after 02150 batchs: 1182.286376953125
INFO:root:Train (Epoch 32): Loss/seq after 02200 batchs: 1172.123046875
INFO:root:Train (Epoch 32): Loss/seq after 02250 batchs: 1172.6441650390625
INFO:root:Train (Epoch 32): Loss/seq after 02300 batchs: 1177.185546875
INFO:root:Train (Epoch 32): Loss/seq after 02350 batchs: 1168.1947021484375
INFO:root:Train (Epoch 32): Loss/seq after 02400 batchs: 1164.863525390625
INFO:root:Train (Epoch 32): Loss/seq after 02450 batchs: 1153.0189208984375
INFO:root:Train (Epoch 32): Loss/seq after 02500 batchs: 1137.178955078125
INFO:root:Train (Epoch 32): Loss/seq after 02550 batchs: 1126.9317626953125
INFO:root:Train (Epoch 32): Loss/seq after 02600 batchs: 1125.34228515625
INFO:root:Train (Epoch 32): Loss/seq after 02650 batchs: 1121.520751953125
INFO:root:Train (Epoch 32): Loss/seq after 02700 batchs: 1117.8521728515625
INFO:root:Train (Epoch 32): Loss/seq after 02750 batchs: 1148.212646484375
INFO:root:Train (Epoch 32): Loss/seq after 02800 batchs: 1154.2288818359375
INFO:root:Train (Epoch 32): Loss/seq after 02850 batchs: 1151.3233642578125
INFO:root:Train (Epoch 32): Loss/seq after 02900 batchs: 1149.2000732421875
INFO:root:Train (Epoch 32): Loss/seq after 02950 batchs: 1142.70703125
INFO:root:Train (Epoch 32): Loss/seq after 03000 batchs: 1141.69189453125
INFO:root:Train (Epoch 32): Loss/seq after 03050 batchs: 1145.136962890625
INFO:root:Train (Epoch 32): Loss/seq after 03100 batchs: 1156.02490234375
INFO:root:Train (Epoch 32): Loss/seq after 03150 batchs: 1164.461669921875
INFO:root:Train (Epoch 32): Loss/seq after 03200 batchs: 1172.97021484375
INFO:root:Train (Epoch 32): Loss/seq after 03250 batchs: 1177.905029296875
INFO:root:Train (Epoch 32): Loss/seq after 03300 batchs: 1176.602294921875
INFO:root:Train (Epoch 32): Loss/seq after 03350 batchs: 1177.5216064453125
INFO:root:Train (Epoch 32): Loss/seq after 03400 batchs: 1169.7503662109375
INFO:root:Train (Epoch 32): Loss/seq after 03450 batchs: 1163.644287109375
INFO:root:Train (Epoch 32): Loss/seq after 03500 batchs: 1163.802734375
INFO:root:Train (Epoch 32): Loss/seq after 03550 batchs: 1158.533935546875
INFO:root:Train (Epoch 32): Loss/seq after 03600 batchs: 1164.8642578125
INFO:root:Train (Epoch 32): Loss/seq after 03650 batchs: 1159.9320068359375
INFO:root:Train (Epoch 32): Loss/seq after 03700 batchs: 1160.247802734375
INFO:root:Train (Epoch 32): Loss/seq after 03750 batchs: 1161.045166015625
INFO:root:Train (Epoch 32): Loss/seq after 03800 batchs: 1154.8009033203125
INFO:root:Train (Epoch 32): Loss/seq after 03850 batchs: 1151.0731201171875
INFO:root:Train (Epoch 32): Loss/seq after 03900 batchs: 1155.64208984375
INFO:root:Train (Epoch 32): Loss/seq after 03950 batchs: 1160.1978759765625
INFO:root:Train (Epoch 32): Loss/seq after 04000 batchs: 1152.0364990234375
INFO:root:Train (Epoch 32): Loss/seq after 04050 batchs: 1144.8504638671875
INFO:root:Train (Epoch 32): Loss/seq after 04100 batchs: 1139.81982421875
INFO:root:Train (Epoch 32): Loss/seq after 04150 batchs: 1134.8128662109375
INFO:root:Train (Epoch 32): Loss/seq after 04200 batchs: 1130.3463134765625
INFO:root:Train (Epoch 32): Loss/seq after 04250 batchs: 1126.5322265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 32): Loss/seq after 00000 batches: 874.154052734375
INFO:root:# Valid (Epoch 32): Loss/seq after 00050 batches: 1097.25830078125
INFO:root:# Valid (Epoch 32): Loss/seq after 00100 batches: 1399.8271484375
INFO:root:# Valid (Epoch 32): Loss/seq after 00150 batches: 1118.2530517578125
INFO:root:# Valid (Epoch 32): Loss/seq after 00200 batches: 1007.6265869140625
INFO:root:Artifacts: Make stick videos for epoch 32
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_32_on_20220412_212349.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_32_index_170_on_20220412_212349.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 33): Loss/seq after 00000 batchs: 1930.2899169921875
INFO:root:Train (Epoch 33): Loss/seq after 00050 batchs: 1453.59228515625
INFO:root:Train (Epoch 33): Loss/seq after 00100 batchs: 1408.1632080078125
INFO:root:Train (Epoch 33): Loss/seq after 00150 batchs: 1288.1915283203125
INFO:root:Train (Epoch 33): Loss/seq after 00200 batchs: 1394.4815673828125
INFO:root:Train (Epoch 33): Loss/seq after 00250 batchs: 1509.684814453125
INFO:root:Train (Epoch 33): Loss/seq after 00300 batchs: 1442.1396484375
INFO:root:Train (Epoch 33): Loss/seq after 00350 batchs: 1350.47412109375
INFO:root:Train (Epoch 33): Loss/seq after 00400 batchs: 1373.1822509765625
INFO:root:Train (Epoch 33): Loss/seq after 00450 batchs: 1318.15380859375
INFO:root:Train (Epoch 33): Loss/seq after 00500 batchs: 1327.16015625
INFO:root:Train (Epoch 33): Loss/seq after 00550 batchs: 1276.0162353515625
INFO:root:Train (Epoch 33): Loss/seq after 00600 batchs: 1244.550048828125
INFO:root:Train (Epoch 33): Loss/seq after 00650 batchs: 1266.9075927734375
INFO:root:Train (Epoch 33): Loss/seq after 00700 batchs: 1265.4669189453125
INFO:root:Train (Epoch 33): Loss/seq after 00750 batchs: 1303.26416015625
INFO:root:Train (Epoch 33): Loss/seq after 00800 batchs: 1296.992431640625
INFO:root:Train (Epoch 33): Loss/seq after 00850 batchs: 1275.0804443359375
INFO:root:Train (Epoch 33): Loss/seq after 00900 batchs: 1285.1767578125
INFO:root:Train (Epoch 33): Loss/seq after 00950 batchs: 1323.458251953125
INFO:root:Train (Epoch 33): Loss/seq after 01000 batchs: 1316.0933837890625
INFO:root:Train (Epoch 33): Loss/seq after 01050 batchs: 1293.0460205078125
INFO:root:Train (Epoch 33): Loss/seq after 01100 batchs: 1289.1959228515625
INFO:root:Train (Epoch 33): Loss/seq after 01150 batchs: 1275.404052734375
INFO:root:Train (Epoch 33): Loss/seq after 01200 batchs: 1267.135498046875
INFO:root:Train (Epoch 33): Loss/seq after 01250 batchs: 1259.8067626953125
INFO:root:Train (Epoch 33): Loss/seq after 01300 batchs: 1263.863525390625
INFO:root:Train (Epoch 33): Loss/seq after 01350 batchs: 1268.13427734375
INFO:root:Train (Epoch 33): Loss/seq after 01400 batchs: 1292.199462890625
INFO:root:Train (Epoch 33): Loss/seq after 01450 batchs: 1285.6043701171875
INFO:root:Train (Epoch 33): Loss/seq after 01500 batchs: 1278.2078857421875
INFO:root:Train (Epoch 33): Loss/seq after 01550 batchs: 1279.1705322265625
INFO:root:Train (Epoch 33): Loss/seq after 01600 batchs: 1263.9517822265625
INFO:root:Train (Epoch 33): Loss/seq after 01650 batchs: 1257.4285888671875
INFO:root:Train (Epoch 33): Loss/seq after 01700 batchs: 1248.8160400390625
INFO:root:Train (Epoch 33): Loss/seq after 01750 batchs: 1239.092041015625
INFO:root:Train (Epoch 33): Loss/seq after 01800 batchs: 1227.04443359375
INFO:root:Train (Epoch 33): Loss/seq after 01850 batchs: 1214.71630859375
INFO:root:Train (Epoch 33): Loss/seq after 01900 batchs: 1214.328857421875
INFO:root:Train (Epoch 33): Loss/seq after 01950 batchs: 1209.16552734375
INFO:root:Train (Epoch 33): Loss/seq after 02000 batchs: 1200.7889404296875
INFO:root:Train (Epoch 33): Loss/seq after 02050 batchs: 1193.981201171875
INFO:root:Train (Epoch 33): Loss/seq after 02100 batchs: 1183.6654052734375
INFO:root:Train (Epoch 33): Loss/seq after 02150 batchs: 1174.1146240234375
INFO:root:Train (Epoch 33): Loss/seq after 02200 batchs: 1164.118408203125
INFO:root:Train (Epoch 33): Loss/seq after 02250 batchs: 1164.672119140625
INFO:root:Train (Epoch 33): Loss/seq after 02300 batchs: 1170.6239013671875
INFO:root:Train (Epoch 33): Loss/seq after 02350 batchs: 1163.387939453125
INFO:root:Train (Epoch 33): Loss/seq after 02400 batchs: 1160.5640869140625
INFO:root:Train (Epoch 33): Loss/seq after 02450 batchs: 1149.4381103515625
INFO:root:Train (Epoch 33): Loss/seq after 02500 batchs: 1133.780029296875
INFO:root:Train (Epoch 33): Loss/seq after 02550 batchs: 1123.728759765625
INFO:root:Train (Epoch 33): Loss/seq after 02600 batchs: 1122.669189453125
INFO:root:Train (Epoch 33): Loss/seq after 02650 batchs: 1118.961669921875
INFO:root:Train (Epoch 33): Loss/seq after 02700 batchs: 1115.552978515625
INFO:root:Train (Epoch 33): Loss/seq after 02750 batchs: 1145.37109375
INFO:root:Train (Epoch 33): Loss/seq after 02800 batchs: 1150.7529296875
INFO:root:Train (Epoch 33): Loss/seq after 02850 batchs: 1147.467529296875
INFO:root:Train (Epoch 33): Loss/seq after 02900 batchs: 1144.916748046875
INFO:root:Train (Epoch 33): Loss/seq after 02950 batchs: 1138.0130615234375
INFO:root:Train (Epoch 33): Loss/seq after 03000 batchs: 1137.059326171875
INFO:root:Train (Epoch 33): Loss/seq after 03050 batchs: 1140.5782470703125
INFO:root:Train (Epoch 33): Loss/seq after 03100 batchs: 1148.6595458984375
INFO:root:Train (Epoch 33): Loss/seq after 03150 batchs: 1153.693359375
INFO:root:Train (Epoch 33): Loss/seq after 03200 batchs: 1162.143310546875
INFO:root:Train (Epoch 33): Loss/seq after 03250 batchs: 1166.8878173828125
INFO:root:Train (Epoch 33): Loss/seq after 03300 batchs: 1166.0263671875
INFO:root:Train (Epoch 33): Loss/seq after 03350 batchs: 1165.56787109375
INFO:root:Train (Epoch 33): Loss/seq after 03400 batchs: 1158.06884765625
INFO:root:Train (Epoch 33): Loss/seq after 03450 batchs: 1154.485595703125
INFO:root:Train (Epoch 33): Loss/seq after 03500 batchs: 1154.9544677734375
INFO:root:Train (Epoch 33): Loss/seq after 03550 batchs: 1150.42138671875
INFO:root:Train (Epoch 33): Loss/seq after 03600 batchs: 1156.972412109375
INFO:root:Train (Epoch 33): Loss/seq after 03650 batchs: 1152.734375
INFO:root:Train (Epoch 33): Loss/seq after 03700 batchs: 1152.60009765625
INFO:root:Train (Epoch 33): Loss/seq after 03750 batchs: 1153.3223876953125
INFO:root:Train (Epoch 33): Loss/seq after 03800 batchs: 1147.17626953125
INFO:root:Train (Epoch 33): Loss/seq after 03850 batchs: 1143.486328125
INFO:root:Train (Epoch 33): Loss/seq after 03900 batchs: 1147.8245849609375
INFO:root:Train (Epoch 33): Loss/seq after 03950 batchs: 1151.7569580078125
INFO:root:Train (Epoch 33): Loss/seq after 04000 batchs: 1143.717041015625
INFO:root:Train (Epoch 33): Loss/seq after 04050 batchs: 1136.625244140625
INFO:root:Train (Epoch 33): Loss/seq after 04100 batchs: 1131.6685791015625
INFO:root:Train (Epoch 33): Loss/seq after 04150 batchs: 1127.150634765625
INFO:root:Train (Epoch 33): Loss/seq after 04200 batchs: 1123.1917724609375
INFO:root:Train (Epoch 33): Loss/seq after 04250 batchs: 1119.7144775390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 33): Loss/seq after 00000 batches: 885.3975830078125
INFO:root:# Valid (Epoch 33): Loss/seq after 00050 batches: 1097.2587890625
INFO:root:# Valid (Epoch 33): Loss/seq after 00100 batches: 1394.142333984375
INFO:root:# Valid (Epoch 33): Loss/seq after 00150 batches: 1120.49853515625
INFO:root:# Valid (Epoch 33): Loss/seq after 00200 batches: 1011.4530029296875
INFO:root:Artifacts: Make stick videos for epoch 33
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_33_on_20220412_212911.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_33_index_635_on_20220412_212911.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 34): Loss/seq after 00000 batchs: 1666.261474609375
INFO:root:Train (Epoch 34): Loss/seq after 00050 batchs: 1479.8690185546875
INFO:root:Train (Epoch 34): Loss/seq after 00100 batchs: 1436.877197265625
INFO:root:Train (Epoch 34): Loss/seq after 00150 batchs: 1303.634521484375
INFO:root:Train (Epoch 34): Loss/seq after 00200 batchs: 1415.7716064453125
INFO:root:Train (Epoch 34): Loss/seq after 00250 batchs: 1525.4384765625
INFO:root:Train (Epoch 34): Loss/seq after 00300 batchs: 1454.524169921875
INFO:root:Train (Epoch 34): Loss/seq after 00350 batchs: 1361.62548828125
INFO:root:Train (Epoch 34): Loss/seq after 00400 batchs: 1390.5111083984375
INFO:root:Train (Epoch 34): Loss/seq after 00450 batchs: 1333.6248779296875
INFO:root:Train (Epoch 34): Loss/seq after 00500 batchs: 1341.7879638671875
INFO:root:Train (Epoch 34): Loss/seq after 00550 batchs: 1288.3533935546875
INFO:root:Train (Epoch 34): Loss/seq after 00600 batchs: 1250.4998779296875
INFO:root:Train (Epoch 34): Loss/seq after 00650 batchs: 1269.2774658203125
INFO:root:Train (Epoch 34): Loss/seq after 00700 batchs: 1259.0001220703125
INFO:root:Train (Epoch 34): Loss/seq after 00750 batchs: 1300.111083984375
INFO:root:Train (Epoch 34): Loss/seq after 00800 batchs: 1294.1871337890625
INFO:root:Train (Epoch 34): Loss/seq after 00850 batchs: 1270.178466796875
INFO:root:Train (Epoch 34): Loss/seq after 00900 batchs: 1275.3717041015625
INFO:root:Train (Epoch 34): Loss/seq after 00950 batchs: 1308.1572265625
INFO:root:Train (Epoch 34): Loss/seq after 01000 batchs: 1301.7122802734375
INFO:root:Train (Epoch 34): Loss/seq after 01050 batchs: 1280.7493896484375
INFO:root:Train (Epoch 34): Loss/seq after 01100 batchs: 1273.7972412109375
INFO:root:Train (Epoch 34): Loss/seq after 01150 batchs: 1259.5726318359375
INFO:root:Train (Epoch 34): Loss/seq after 01200 batchs: 1251.5843505859375
INFO:root:Train (Epoch 34): Loss/seq after 01250 batchs: 1245.9398193359375
INFO:root:Train (Epoch 34): Loss/seq after 01300 batchs: 1249.559814453125
INFO:root:Train (Epoch 34): Loss/seq after 01350 batchs: 1254.51123046875
INFO:root:Train (Epoch 34): Loss/seq after 01400 batchs: 1272.6575927734375
INFO:root:Train (Epoch 34): Loss/seq after 01450 batchs: 1265.0074462890625
INFO:root:Train (Epoch 34): Loss/seq after 01500 batchs: 1258.3656005859375
INFO:root:Train (Epoch 34): Loss/seq after 01550 batchs: 1259.20556640625
INFO:root:Train (Epoch 34): Loss/seq after 01600 batchs: 1245.375244140625
INFO:root:Train (Epoch 34): Loss/seq after 01650 batchs: 1238.8271484375
INFO:root:Train (Epoch 34): Loss/seq after 01700 batchs: 1230.61279296875
INFO:root:Train (Epoch 34): Loss/seq after 01750 batchs: 1221.0172119140625
INFO:root:Train (Epoch 34): Loss/seq after 01800 batchs: 1209.169189453125
INFO:root:Train (Epoch 34): Loss/seq after 01850 batchs: 1197.3206787109375
INFO:root:Train (Epoch 34): Loss/seq after 01900 batchs: 1197.180419921875
INFO:root:Train (Epoch 34): Loss/seq after 01950 batchs: 1192.7147216796875
INFO:root:Train (Epoch 34): Loss/seq after 02000 batchs: 1184.79150390625
INFO:root:Train (Epoch 34): Loss/seq after 02050 batchs: 1178.142333984375
INFO:root:Train (Epoch 34): Loss/seq after 02100 batchs: 1168.3487548828125
INFO:root:Train (Epoch 34): Loss/seq after 02150 batchs: 1159.288818359375
INFO:root:Train (Epoch 34): Loss/seq after 02200 batchs: 1149.5643310546875
INFO:root:Train (Epoch 34): Loss/seq after 02250 batchs: 1148.7296142578125
INFO:root:Train (Epoch 34): Loss/seq after 02300 batchs: 1153.1712646484375
INFO:root:Train (Epoch 34): Loss/seq after 02350 batchs: 1145.384765625
INFO:root:Train (Epoch 34): Loss/seq after 02400 batchs: 1142.112548828125
INFO:root:Train (Epoch 34): Loss/seq after 02450 batchs: 1130.6343994140625
INFO:root:Train (Epoch 34): Loss/seq after 02500 batchs: 1115.25927734375
INFO:root:Train (Epoch 34): Loss/seq after 02550 batchs: 1104.7579345703125
INFO:root:Train (Epoch 34): Loss/seq after 02600 batchs: 1103.243408203125
INFO:root:Train (Epoch 34): Loss/seq after 02650 batchs: 1099.59716796875
INFO:root:Train (Epoch 34): Loss/seq after 02700 batchs: 1096.094482421875
INFO:root:Train (Epoch 34): Loss/seq after 02750 batchs: 1125.9200439453125
INFO:root:Train (Epoch 34): Loss/seq after 02800 batchs: 1131.72705078125
INFO:root:Train (Epoch 34): Loss/seq after 02850 batchs: 1128.5858154296875
INFO:root:Train (Epoch 34): Loss/seq after 02900 batchs: 1126.4326171875
INFO:root:Train (Epoch 34): Loss/seq after 02950 batchs: 1119.624267578125
INFO:root:Train (Epoch 34): Loss/seq after 03000 batchs: 1118.9752197265625
INFO:root:Train (Epoch 34): Loss/seq after 03050 batchs: 1122.667724609375
INFO:root:Train (Epoch 34): Loss/seq after 03100 batchs: 1130.70849609375
INFO:root:Train (Epoch 34): Loss/seq after 03150 batchs: 1137.4605712890625
INFO:root:Train (Epoch 34): Loss/seq after 03200 batchs: 1145.487548828125
INFO:root:Train (Epoch 34): Loss/seq after 03250 batchs: 1149.5372314453125
INFO:root:Train (Epoch 34): Loss/seq after 03300 batchs: 1147.045166015625
INFO:root:Train (Epoch 34): Loss/seq after 03350 batchs: 1146.189697265625
INFO:root:Train (Epoch 34): Loss/seq after 03400 batchs: 1138.895263671875
INFO:root:Train (Epoch 34): Loss/seq after 03450 batchs: 1133.3182373046875
INFO:root:Train (Epoch 34): Loss/seq after 03500 batchs: 1131.9356689453125
INFO:root:Train (Epoch 34): Loss/seq after 03550 batchs: 1126.625244140625
INFO:root:Train (Epoch 34): Loss/seq after 03600 batchs: 1133.2027587890625
INFO:root:Train (Epoch 34): Loss/seq after 03650 batchs: 1128.0697021484375
INFO:root:Train (Epoch 34): Loss/seq after 03700 batchs: 1128.29736328125
INFO:root:Train (Epoch 34): Loss/seq after 03750 batchs: 1129.3143310546875
INFO:root:Train (Epoch 34): Loss/seq after 03800 batchs: 1123.3028564453125
INFO:root:Train (Epoch 34): Loss/seq after 03850 batchs: 1119.8377685546875
INFO:root:Train (Epoch 34): Loss/seq after 03900 batchs: 1123.1546630859375
INFO:root:Train (Epoch 34): Loss/seq after 03950 batchs: 1127.4586181640625
INFO:root:Train (Epoch 34): Loss/seq after 04000 batchs: 1119.6600341796875
INFO:root:Train (Epoch 34): Loss/seq after 04050 batchs: 1112.821533203125
INFO:root:Train (Epoch 34): Loss/seq after 04100 batchs: 1107.6756591796875
INFO:root:Train (Epoch 34): Loss/seq after 04150 batchs: 1103.05078125
INFO:root:Train (Epoch 34): Loss/seq after 04200 batchs: 1098.6910400390625
INFO:root:Train (Epoch 34): Loss/seq after 04250 batchs: 1095.1990966796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 34): Loss/seq after 00000 batches: 896.196044921875
INFO:root:# Valid (Epoch 34): Loss/seq after 00050 batches: 1096.2841796875
INFO:root:# Valid (Epoch 34): Loss/seq after 00100 batches: 1387.4033203125
INFO:root:# Valid (Epoch 34): Loss/seq after 00150 batches: 1124.28466796875
INFO:root:# Valid (Epoch 34): Loss/seq after 00200 batches: 1020.9855346679688
INFO:root:Artifacts: Make stick videos for epoch 34
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_34_on_20220412_213433.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_34_index_1774_on_20220412_213433.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 35): Loss/seq after 00000 batchs: 1647.56787109375
INFO:root:Train (Epoch 35): Loss/seq after 00050 batchs: 1392.184326171875
INFO:root:Train (Epoch 35): Loss/seq after 00100 batchs: 1405.4652099609375
INFO:root:Train (Epoch 35): Loss/seq after 00150 batchs: 1272.7430419921875
INFO:root:Train (Epoch 35): Loss/seq after 00200 batchs: 1366.764892578125
INFO:root:Train (Epoch 35): Loss/seq after 00250 batchs: 1486.300537109375
INFO:root:Train (Epoch 35): Loss/seq after 00300 batchs: 1422.41357421875
INFO:root:Train (Epoch 35): Loss/seq after 00350 batchs: 1332.332763671875
INFO:root:Train (Epoch 35): Loss/seq after 00400 batchs: 1355.19921875
INFO:root:Train (Epoch 35): Loss/seq after 00450 batchs: 1302.0721435546875
INFO:root:Train (Epoch 35): Loss/seq after 00500 batchs: 1315.0841064453125
INFO:root:Train (Epoch 35): Loss/seq after 00550 batchs: 1263.074462890625
INFO:root:Train (Epoch 35): Loss/seq after 00600 batchs: 1230.934326171875
INFO:root:Train (Epoch 35): Loss/seq after 00650 batchs: 1247.04833984375
INFO:root:Train (Epoch 35): Loss/seq after 00700 batchs: 1236.97216796875
INFO:root:Train (Epoch 35): Loss/seq after 00750 batchs: 1268.05419921875
INFO:root:Train (Epoch 35): Loss/seq after 00800 batchs: 1264.1044921875
INFO:root:Train (Epoch 35): Loss/seq after 00850 batchs: 1242.6976318359375
INFO:root:Train (Epoch 35): Loss/seq after 00900 batchs: 1249.875
INFO:root:Train (Epoch 35): Loss/seq after 00950 batchs: 1271.0777587890625
INFO:root:Train (Epoch 35): Loss/seq after 01000 batchs: 1263.5491943359375
INFO:root:Train (Epoch 35): Loss/seq after 01050 batchs: 1244.9232177734375
INFO:root:Train (Epoch 35): Loss/seq after 01100 batchs: 1237.0958251953125
INFO:root:Train (Epoch 35): Loss/seq after 01150 batchs: 1223.2537841796875
INFO:root:Train (Epoch 35): Loss/seq after 01200 batchs: 1215.93359375
INFO:root:Train (Epoch 35): Loss/seq after 01250 batchs: 1208.8182373046875
INFO:root:Train (Epoch 35): Loss/seq after 01300 batchs: 1213.0289306640625
INFO:root:Train (Epoch 35): Loss/seq after 01350 batchs: 1219.603515625
INFO:root:Train (Epoch 35): Loss/seq after 01400 batchs: 1238.8807373046875
INFO:root:Train (Epoch 35): Loss/seq after 01450 batchs: 1232.397216796875
INFO:root:Train (Epoch 35): Loss/seq after 01500 batchs: 1226.940185546875
INFO:root:Train (Epoch 35): Loss/seq after 01550 batchs: 1227.87744140625
INFO:root:Train (Epoch 35): Loss/seq after 01600 batchs: 1213.8221435546875
INFO:root:Train (Epoch 35): Loss/seq after 01650 batchs: 1207.008056640625
INFO:root:Train (Epoch 35): Loss/seq after 01700 batchs: 1199.474365234375
INFO:root:Train (Epoch 35): Loss/seq after 01750 batchs: 1190.4666748046875
INFO:root:Train (Epoch 35): Loss/seq after 01800 batchs: 1179.1522216796875
INFO:root:Train (Epoch 35): Loss/seq after 01850 batchs: 1167.7386474609375
INFO:root:Train (Epoch 35): Loss/seq after 01900 batchs: 1167.9722900390625
INFO:root:Train (Epoch 35): Loss/seq after 01950 batchs: 1163.55419921875
INFO:root:Train (Epoch 35): Loss/seq after 02000 batchs: 1156.15576171875
INFO:root:Train (Epoch 35): Loss/seq after 02050 batchs: 1149.8712158203125
INFO:root:Train (Epoch 35): Loss/seq after 02100 batchs: 1140.580322265625
INFO:root:Train (Epoch 35): Loss/seq after 02150 batchs: 1132.0323486328125
INFO:root:Train (Epoch 35): Loss/seq after 02200 batchs: 1122.7960205078125
INFO:root:Train (Epoch 35): Loss/seq after 02250 batchs: 1122.4171142578125
INFO:root:Train (Epoch 35): Loss/seq after 02300 batchs: 1127.53759765625
INFO:root:Train (Epoch 35): Loss/seq after 02350 batchs: 1119.1998291015625
INFO:root:Train (Epoch 35): Loss/seq after 02400 batchs: 1116.1363525390625
INFO:root:Train (Epoch 35): Loss/seq after 02450 batchs: 1105.1602783203125
INFO:root:Train (Epoch 35): Loss/seq after 02500 batchs: 1089.9793701171875
INFO:root:Train (Epoch 35): Loss/seq after 02550 batchs: 1079.5740966796875
INFO:root:Train (Epoch 35): Loss/seq after 02600 batchs: 1078.227783203125
INFO:root:Train (Epoch 35): Loss/seq after 02650 batchs: 1073.85009765625
INFO:root:Train (Epoch 35): Loss/seq after 02700 batchs: 1070.3897705078125
INFO:root:Train (Epoch 35): Loss/seq after 02750 batchs: 1098.3104248046875
INFO:root:Train (Epoch 35): Loss/seq after 02800 batchs: 1104.6099853515625
INFO:root:Train (Epoch 35): Loss/seq after 02850 batchs: 1101.14306640625
INFO:root:Train (Epoch 35): Loss/seq after 02900 batchs: 1100.5550537109375
INFO:root:Train (Epoch 35): Loss/seq after 02950 batchs: 1094.474609375
INFO:root:Train (Epoch 35): Loss/seq after 03000 batchs: 1094.2384033203125
INFO:root:Train (Epoch 35): Loss/seq after 03050 batchs: 1098.271728515625
INFO:root:Train (Epoch 35): Loss/seq after 03100 batchs: 1107.867919921875
INFO:root:Train (Epoch 35): Loss/seq after 03150 batchs: 1114.786865234375
INFO:root:Train (Epoch 35): Loss/seq after 03200 batchs: 1123.52880859375
INFO:root:Train (Epoch 35): Loss/seq after 03250 batchs: 1127.2271728515625
INFO:root:Train (Epoch 35): Loss/seq after 03300 batchs: 1125.095703125
INFO:root:Train (Epoch 35): Loss/seq after 03350 batchs: 1124.4609375
INFO:root:Train (Epoch 35): Loss/seq after 03400 batchs: 1117.09228515625
INFO:root:Train (Epoch 35): Loss/seq after 03450 batchs: 1112.5013427734375
INFO:root:Train (Epoch 35): Loss/seq after 03500 batchs: 1111.587646484375
INFO:root:Train (Epoch 35): Loss/seq after 03550 batchs: 1106.279541015625
INFO:root:Train (Epoch 35): Loss/seq after 03600 batchs: 1112.8013916015625
INFO:root:Train (Epoch 35): Loss/seq after 03650 batchs: 1107.66259765625
INFO:root:Train (Epoch 35): Loss/seq after 03700 batchs: 1107.58740234375
INFO:root:Train (Epoch 35): Loss/seq after 03750 batchs: 1108.7967529296875
INFO:root:Train (Epoch 35): Loss/seq after 03800 batchs: 1102.8206787109375
INFO:root:Train (Epoch 35): Loss/seq after 03850 batchs: 1099.462158203125
INFO:root:Train (Epoch 35): Loss/seq after 03900 batchs: 1103.891845703125
INFO:root:Train (Epoch 35): Loss/seq after 03950 batchs: 1107.8140869140625
INFO:root:Train (Epoch 35): Loss/seq after 04000 batchs: 1100.2034912109375
INFO:root:Train (Epoch 35): Loss/seq after 04050 batchs: 1093.3394775390625
INFO:root:Train (Epoch 35): Loss/seq after 04100 batchs: 1088.446533203125
INFO:root:Train (Epoch 35): Loss/seq after 04150 batchs: 1083.8048095703125
INFO:root:Train (Epoch 35): Loss/seq after 04200 batchs: 1079.4227294921875
INFO:root:Train (Epoch 35): Loss/seq after 04250 batchs: 1075.98876953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 35): Loss/seq after 00000 batches: 835.242919921875
INFO:root:# Valid (Epoch 35): Loss/seq after 00050 batches: 1077.2578125
INFO:root:# Valid (Epoch 35): Loss/seq after 00100 batches: 1376.24267578125
INFO:root:# Valid (Epoch 35): Loss/seq after 00150 batches: 1094.2672119140625
INFO:root:# Valid (Epoch 35): Loss/seq after 00200 batches: 986.9127807617188
INFO:root:Artifacts: Make stick videos for epoch 35
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_35_on_20220412_213956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_35_index_1908_on_20220412_213956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 36): Loss/seq after 00000 batchs: 1451.603515625
INFO:root:Train (Epoch 36): Loss/seq after 00050 batchs: 1339.0369873046875
INFO:root:Train (Epoch 36): Loss/seq after 00100 batchs: 1364.375
INFO:root:Train (Epoch 36): Loss/seq after 00150 batchs: 1236.3465576171875
INFO:root:Train (Epoch 36): Loss/seq after 00200 batchs: 1338.8551025390625
INFO:root:Train (Epoch 36): Loss/seq after 00250 batchs: 1464.36572265625
INFO:root:Train (Epoch 36): Loss/seq after 00300 batchs: 1402.9197998046875
INFO:root:Train (Epoch 36): Loss/seq after 00350 batchs: 1314.75927734375
INFO:root:Train (Epoch 36): Loss/seq after 00400 batchs: 1351.129150390625
INFO:root:Train (Epoch 36): Loss/seq after 00450 batchs: 1299.1129150390625
INFO:root:Train (Epoch 36): Loss/seq after 00500 batchs: 1307.9329833984375
INFO:root:Train (Epoch 36): Loss/seq after 00550 batchs: 1256.579345703125
INFO:root:Train (Epoch 36): Loss/seq after 00600 batchs: 1222.79345703125
INFO:root:Train (Epoch 36): Loss/seq after 00650 batchs: 1233.5155029296875
INFO:root:Train (Epoch 36): Loss/seq after 00700 batchs: 1217.8001708984375
INFO:root:Train (Epoch 36): Loss/seq after 00750 batchs: 1249.614990234375
INFO:root:Train (Epoch 36): Loss/seq after 00800 batchs: 1245.92626953125
INFO:root:Train (Epoch 36): Loss/seq after 00850 batchs: 1224.0216064453125
INFO:root:Train (Epoch 36): Loss/seq after 00900 batchs: 1232.121826171875
INFO:root:Train (Epoch 36): Loss/seq after 00950 batchs: 1261.65966796875
INFO:root:Train (Epoch 36): Loss/seq after 01000 batchs: 1255.0350341796875
INFO:root:Train (Epoch 36): Loss/seq after 01050 batchs: 1233.93408203125
INFO:root:Train (Epoch 36): Loss/seq after 01100 batchs: 1224.52490234375
INFO:root:Train (Epoch 36): Loss/seq after 01150 batchs: 1209.470703125
INFO:root:Train (Epoch 36): Loss/seq after 01200 batchs: 1203.0860595703125
INFO:root:Train (Epoch 36): Loss/seq after 01250 batchs: 1195.573974609375
INFO:root:Train (Epoch 36): Loss/seq after 01300 batchs: 1195.5574951171875
INFO:root:Train (Epoch 36): Loss/seq after 01350 batchs: 1197.4932861328125
INFO:root:Train (Epoch 36): Loss/seq after 01400 batchs: 1214.6524658203125
INFO:root:Train (Epoch 36): Loss/seq after 01450 batchs: 1208.521240234375
INFO:root:Train (Epoch 36): Loss/seq after 01500 batchs: 1202.968994140625
INFO:root:Train (Epoch 36): Loss/seq after 01550 batchs: 1203.1591796875
INFO:root:Train (Epoch 36): Loss/seq after 01600 batchs: 1189.255859375
INFO:root:Train (Epoch 36): Loss/seq after 01650 batchs: 1180.606201171875
INFO:root:Train (Epoch 36): Loss/seq after 01700 batchs: 1173.0054931640625
INFO:root:Train (Epoch 36): Loss/seq after 01750 batchs: 1164.03662109375
INFO:root:Train (Epoch 36): Loss/seq after 01800 batchs: 1152.939453125
INFO:root:Train (Epoch 36): Loss/seq after 01850 batchs: 1141.406005859375
INFO:root:Train (Epoch 36): Loss/seq after 01900 batchs: 1141.8699951171875
INFO:root:Train (Epoch 36): Loss/seq after 01950 batchs: 1136.774169921875
INFO:root:Train (Epoch 36): Loss/seq after 02000 batchs: 1129.583740234375
INFO:root:Train (Epoch 36): Loss/seq after 02050 batchs: 1123.482666015625
INFO:root:Train (Epoch 36): Loss/seq after 02100 batchs: 1114.2689208984375
INFO:root:Train (Epoch 36): Loss/seq after 02150 batchs: 1105.9349365234375
INFO:root:Train (Epoch 36): Loss/seq after 02200 batchs: 1097.095703125
INFO:root:Train (Epoch 36): Loss/seq after 02250 batchs: 1097.586181640625
INFO:root:Train (Epoch 36): Loss/seq after 02300 batchs: 1103.4249267578125
INFO:root:Train (Epoch 36): Loss/seq after 02350 batchs: 1095.056396484375
INFO:root:Train (Epoch 36): Loss/seq after 02400 batchs: 1091.762939453125
INFO:root:Train (Epoch 36): Loss/seq after 02450 batchs: 1081.0157470703125
INFO:root:Train (Epoch 36): Loss/seq after 02500 batchs: 1065.7786865234375
INFO:root:Train (Epoch 36): Loss/seq after 02550 batchs: 1055.9022216796875
INFO:root:Train (Epoch 36): Loss/seq after 02600 batchs: 1054.1524658203125
INFO:root:Train (Epoch 36): Loss/seq after 02650 batchs: 1049.610107421875
INFO:root:Train (Epoch 36): Loss/seq after 02700 batchs: 1046.2066650390625
INFO:root:Train (Epoch 36): Loss/seq after 02750 batchs: 1076.5242919921875
INFO:root:Train (Epoch 36): Loss/seq after 02800 batchs: 1082.1416015625
INFO:root:Train (Epoch 36): Loss/seq after 02850 batchs: 1079.253662109375
INFO:root:Train (Epoch 36): Loss/seq after 02900 batchs: 1078.184814453125
INFO:root:Train (Epoch 36): Loss/seq after 02950 batchs: 1072.5753173828125
INFO:root:Train (Epoch 36): Loss/seq after 03000 batchs: 1072.4210205078125
INFO:root:Train (Epoch 36): Loss/seq after 03050 batchs: 1076.74365234375
INFO:root:Train (Epoch 36): Loss/seq after 03100 batchs: 1085.19287109375
INFO:root:Train (Epoch 36): Loss/seq after 03150 batchs: 1090.8780517578125
INFO:root:Train (Epoch 36): Loss/seq after 03200 batchs: 1097.9422607421875
INFO:root:Train (Epoch 36): Loss/seq after 03250 batchs: 1102.1695556640625
INFO:root:Train (Epoch 36): Loss/seq after 03300 batchs: 1101.4510498046875
INFO:root:Train (Epoch 36): Loss/seq after 03350 batchs: 1100.93408203125
INFO:root:Train (Epoch 36): Loss/seq after 03400 batchs: 1093.4876708984375
INFO:root:Train (Epoch 36): Loss/seq after 03450 batchs: 1087.5992431640625
INFO:root:Train (Epoch 36): Loss/seq after 03500 batchs: 1086.5986328125
INFO:root:Train (Epoch 36): Loss/seq after 03550 batchs: 1081.765380859375
INFO:root:Train (Epoch 36): Loss/seq after 03600 batchs: 1088.225830078125
INFO:root:Train (Epoch 36): Loss/seq after 03650 batchs: 1083.460693359375
INFO:root:Train (Epoch 36): Loss/seq after 03700 batchs: 1083.495849609375
INFO:root:Train (Epoch 36): Loss/seq after 03750 batchs: 1084.927734375
INFO:root:Train (Epoch 36): Loss/seq after 03800 batchs: 1079.1873779296875
INFO:root:Train (Epoch 36): Loss/seq after 03850 batchs: 1076.129150390625
INFO:root:Train (Epoch 36): Loss/seq after 03900 batchs: 1079.9560546875
INFO:root:Train (Epoch 36): Loss/seq after 03950 batchs: 1084.314453125
INFO:root:Train (Epoch 36): Loss/seq after 04000 batchs: 1076.9620361328125
INFO:root:Train (Epoch 36): Loss/seq after 04050 batchs: 1070.25732421875
INFO:root:Train (Epoch 36): Loss/seq after 04100 batchs: 1065.29296875
INFO:root:Train (Epoch 36): Loss/seq after 04150 batchs: 1061.0010986328125
INFO:root:Train (Epoch 36): Loss/seq after 04200 batchs: 1056.842529296875
INFO:root:Train (Epoch 36): Loss/seq after 04250 batchs: 1053.481201171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 36): Loss/seq after 00000 batches: 885.5498657226562
INFO:root:# Valid (Epoch 36): Loss/seq after 00050 batches: 1049.014892578125
INFO:root:# Valid (Epoch 36): Loss/seq after 00100 batches: 1342.2674560546875
INFO:root:# Valid (Epoch 36): Loss/seq after 00150 batches: 1071.4566650390625
INFO:root:# Valid (Epoch 36): Loss/seq after 00200 batches: 969.8492431640625
INFO:root:Artifacts: Make stick videos for epoch 36
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_36_on_20220412_214518.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_36_index_1788_on_20220412_214518.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 37): Loss/seq after 00000 batchs: 1833.6407470703125
INFO:root:Train (Epoch 37): Loss/seq after 00050 batchs: 1313.66748046875
INFO:root:Train (Epoch 37): Loss/seq after 00100 batchs: 1333.7987060546875
INFO:root:Train (Epoch 37): Loss/seq after 00150 batchs: 1227.417236328125
INFO:root:Train (Epoch 37): Loss/seq after 00200 batchs: 1336.274169921875
INFO:root:Train (Epoch 37): Loss/seq after 00250 batchs: 1461.0091552734375
INFO:root:Train (Epoch 37): Loss/seq after 00300 batchs: 1398.5101318359375
INFO:root:Train (Epoch 37): Loss/seq after 00350 batchs: 1308.09130859375
INFO:root:Train (Epoch 37): Loss/seq after 00400 batchs: 1334.9439697265625
INFO:root:Train (Epoch 37): Loss/seq after 00450 batchs: 1282.683349609375
INFO:root:Train (Epoch 37): Loss/seq after 00500 batchs: 1292.3826904296875
INFO:root:Train (Epoch 37): Loss/seq after 00550 batchs: 1242.1671142578125
INFO:root:Train (Epoch 37): Loss/seq after 00600 batchs: 1207.7725830078125
INFO:root:Train (Epoch 37): Loss/seq after 00650 batchs: 1217.460205078125
INFO:root:Train (Epoch 37): Loss/seq after 00700 batchs: 1207.4249267578125
INFO:root:Train (Epoch 37): Loss/seq after 00750 batchs: 1243.6248779296875
INFO:root:Train (Epoch 37): Loss/seq after 00800 batchs: 1239.919189453125
INFO:root:Train (Epoch 37): Loss/seq after 00850 batchs: 1215.48291015625
INFO:root:Train (Epoch 37): Loss/seq after 00900 batchs: 1217.16845703125
INFO:root:Train (Epoch 37): Loss/seq after 00950 batchs: 1236.166015625
INFO:root:Train (Epoch 37): Loss/seq after 01000 batchs: 1231.7239990234375
INFO:root:Train (Epoch 37): Loss/seq after 01050 batchs: 1211.5179443359375
INFO:root:Train (Epoch 37): Loss/seq after 01100 batchs: 1203.2772216796875
INFO:root:Train (Epoch 37): Loss/seq after 01150 batchs: 1186.7877197265625
INFO:root:Train (Epoch 37): Loss/seq after 01200 batchs: 1179.7205810546875
INFO:root:Train (Epoch 37): Loss/seq after 01250 batchs: 1174.5474853515625
INFO:root:Train (Epoch 37): Loss/seq after 01300 batchs: 1177.5831298828125
INFO:root:Train (Epoch 37): Loss/seq after 01350 batchs: 1181.0208740234375
INFO:root:Train (Epoch 37): Loss/seq after 01400 batchs: 1197.580078125
INFO:root:Train (Epoch 37): Loss/seq after 01450 batchs: 1191.483642578125
INFO:root:Train (Epoch 37): Loss/seq after 01500 batchs: 1185.873046875
INFO:root:Train (Epoch 37): Loss/seq after 01550 batchs: 1187.0496826171875
INFO:root:Train (Epoch 37): Loss/seq after 01600 batchs: 1174.0836181640625
INFO:root:Train (Epoch 37): Loss/seq after 01650 batchs: 1166.567138671875
INFO:root:Train (Epoch 37): Loss/seq after 01700 batchs: 1159.441650390625
INFO:root:Train (Epoch 37): Loss/seq after 01750 batchs: 1150.1728515625
INFO:root:Train (Epoch 37): Loss/seq after 01800 batchs: 1139.49560546875
INFO:root:Train (Epoch 37): Loss/seq after 01850 batchs: 1128.085693359375
INFO:root:Train (Epoch 37): Loss/seq after 01900 batchs: 1128.670166015625
INFO:root:Train (Epoch 37): Loss/seq after 01950 batchs: 1124.8228759765625
INFO:root:Train (Epoch 37): Loss/seq after 02000 batchs: 1117.956787109375
INFO:root:Train (Epoch 37): Loss/seq after 02050 batchs: 1112.04052734375
INFO:root:Train (Epoch 37): Loss/seq after 02100 batchs: 1102.8880615234375
INFO:root:Train (Epoch 37): Loss/seq after 02150 batchs: 1094.919677734375
INFO:root:Train (Epoch 37): Loss/seq after 02200 batchs: 1085.9686279296875
INFO:root:Train (Epoch 37): Loss/seq after 02250 batchs: 1086.1966552734375
INFO:root:Train (Epoch 37): Loss/seq after 02300 batchs: 1092.1749267578125
INFO:root:Train (Epoch 37): Loss/seq after 02350 batchs: 1084.396240234375
INFO:root:Train (Epoch 37): Loss/seq after 02400 batchs: 1081.594970703125
INFO:root:Train (Epoch 37): Loss/seq after 02450 batchs: 1071.1871337890625
INFO:root:Train (Epoch 37): Loss/seq after 02500 batchs: 1056.059326171875
INFO:root:Train (Epoch 37): Loss/seq after 02550 batchs: 1045.6068115234375
INFO:root:Train (Epoch 37): Loss/seq after 02600 batchs: 1043.4146728515625
INFO:root:Train (Epoch 37): Loss/seq after 02650 batchs: 1038.720947265625
INFO:root:Train (Epoch 37): Loss/seq after 02700 batchs: 1035.23095703125
INFO:root:Train (Epoch 37): Loss/seq after 02750 batchs: 1064.2147216796875
INFO:root:Train (Epoch 37): Loss/seq after 02800 batchs: 1069.420654296875
INFO:root:Train (Epoch 37): Loss/seq after 02850 batchs: 1066.6298828125
INFO:root:Train (Epoch 37): Loss/seq after 02900 batchs: 1064.9608154296875
INFO:root:Train (Epoch 37): Loss/seq after 02950 batchs: 1058.726806640625
INFO:root:Train (Epoch 37): Loss/seq after 03000 batchs: 1058.693603515625
INFO:root:Train (Epoch 37): Loss/seq after 03050 batchs: 1062.9005126953125
INFO:root:Train (Epoch 37): Loss/seq after 03100 batchs: 1069.9239501953125
INFO:root:Train (Epoch 37): Loss/seq after 03150 batchs: 1074.2197265625
INFO:root:Train (Epoch 37): Loss/seq after 03200 batchs: 1082.2003173828125
INFO:root:Train (Epoch 37): Loss/seq after 03250 batchs: 1084.6717529296875
INFO:root:Train (Epoch 37): Loss/seq after 03300 batchs: 1082.4921875
INFO:root:Train (Epoch 37): Loss/seq after 03350 batchs: 1081.650390625
INFO:root:Train (Epoch 37): Loss/seq after 03400 batchs: 1074.0008544921875
INFO:root:Train (Epoch 37): Loss/seq after 03450 batchs: 1068.4447021484375
INFO:root:Train (Epoch 37): Loss/seq after 03500 batchs: 1067.288818359375
INFO:root:Train (Epoch 37): Loss/seq after 03550 batchs: 1062.103515625
INFO:root:Train (Epoch 37): Loss/seq after 03600 batchs: 1069.009765625
INFO:root:Train (Epoch 37): Loss/seq after 03650 batchs: 1064.5914306640625
INFO:root:Train (Epoch 37): Loss/seq after 03700 batchs: 1064.70703125
INFO:root:Train (Epoch 37): Loss/seq after 03750 batchs: 1066.3927001953125
INFO:root:Train (Epoch 37): Loss/seq after 03800 batchs: 1060.5157470703125
INFO:root:Train (Epoch 37): Loss/seq after 03850 batchs: 1057.484619140625
INFO:root:Train (Epoch 37): Loss/seq after 03900 batchs: 1060.994384765625
INFO:root:Train (Epoch 37): Loss/seq after 03950 batchs: 1065.0596923828125
INFO:root:Train (Epoch 37): Loss/seq after 04000 batchs: 1057.90234375
INFO:root:Train (Epoch 37): Loss/seq after 04050 batchs: 1051.3974609375
INFO:root:Train (Epoch 37): Loss/seq after 04100 batchs: 1046.833251953125
INFO:root:Train (Epoch 37): Loss/seq after 04150 batchs: 1042.603271484375
INFO:root:Train (Epoch 37): Loss/seq after 04200 batchs: 1038.538330078125
INFO:root:Train (Epoch 37): Loss/seq after 04250 batchs: 1035.1080322265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 37): Loss/seq after 00000 batches: 761.2949829101562
INFO:root:# Valid (Epoch 37): Loss/seq after 00050 batches: 1026.900146484375
INFO:root:# Valid (Epoch 37): Loss/seq after 00100 batches: 1326.646484375
INFO:root:# Valid (Epoch 37): Loss/seq after 00150 batches: 1053.2659912109375
INFO:root:# Valid (Epoch 37): Loss/seq after 00200 batches: 950.0579833984375
INFO:root:Artifacts: Make stick videos for epoch 37
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_37_on_20220412_215041.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_37_index_99_on_20220412_215041.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 38): Loss/seq after 00000 batchs: 1597.2296142578125
INFO:root:Train (Epoch 38): Loss/seq after 00050 batchs: 1294.4356689453125
INFO:root:Train (Epoch 38): Loss/seq after 00100 batchs: 1307.6026611328125
INFO:root:Train (Epoch 38): Loss/seq after 00150 batchs: 1191.3388671875
INFO:root:Train (Epoch 38): Loss/seq after 00200 batchs: 1287.958251953125
INFO:root:Train (Epoch 38): Loss/seq after 00250 batchs: 1441.6199951171875
INFO:root:Train (Epoch 38): Loss/seq after 00300 batchs: 1380.8292236328125
INFO:root:Train (Epoch 38): Loss/seq after 00350 batchs: 1291.0179443359375
INFO:root:Train (Epoch 38): Loss/seq after 00400 batchs: 1326.8369140625
INFO:root:Train (Epoch 38): Loss/seq after 00450 batchs: 1277.23974609375
INFO:root:Train (Epoch 38): Loss/seq after 00500 batchs: 1283.966796875
INFO:root:Train (Epoch 38): Loss/seq after 00550 batchs: 1233.907958984375
INFO:root:Train (Epoch 38): Loss/seq after 00600 batchs: 1197.8424072265625
INFO:root:Train (Epoch 38): Loss/seq after 00650 batchs: 1211.32080078125
INFO:root:Train (Epoch 38): Loss/seq after 00700 batchs: 1201.8914794921875
INFO:root:Train (Epoch 38): Loss/seq after 00750 batchs: 1233.605224609375
INFO:root:Train (Epoch 38): Loss/seq after 00800 batchs: 1228.0946044921875
INFO:root:Train (Epoch 38): Loss/seq after 00850 batchs: 1202.7003173828125
INFO:root:Train (Epoch 38): Loss/seq after 00900 batchs: 1205.029541015625
INFO:root:Train (Epoch 38): Loss/seq after 00950 batchs: 1224.1806640625
INFO:root:Train (Epoch 38): Loss/seq after 01000 batchs: 1217.8419189453125
INFO:root:Train (Epoch 38): Loss/seq after 01050 batchs: 1197.385009765625
INFO:root:Train (Epoch 38): Loss/seq after 01100 batchs: 1188.4892578125
INFO:root:Train (Epoch 38): Loss/seq after 01150 batchs: 1171.7574462890625
INFO:root:Train (Epoch 38): Loss/seq after 01200 batchs: 1164.9500732421875
INFO:root:Train (Epoch 38): Loss/seq after 01250 batchs: 1157.6470947265625
INFO:root:Train (Epoch 38): Loss/seq after 01300 batchs: 1157.58935546875
INFO:root:Train (Epoch 38): Loss/seq after 01350 batchs: 1159.9580078125
INFO:root:Train (Epoch 38): Loss/seq after 01400 batchs: 1177.91455078125
INFO:root:Train (Epoch 38): Loss/seq after 01450 batchs: 1170.811279296875
INFO:root:Train (Epoch 38): Loss/seq after 01500 batchs: 1166.0159912109375
INFO:root:Train (Epoch 38): Loss/seq after 01550 batchs: 1166.6126708984375
INFO:root:Train (Epoch 38): Loss/seq after 01600 batchs: 1154.177001953125
INFO:root:Train (Epoch 38): Loss/seq after 01650 batchs: 1147.0218505859375
INFO:root:Train (Epoch 38): Loss/seq after 01700 batchs: 1140.2689208984375
INFO:root:Train (Epoch 38): Loss/seq after 01750 batchs: 1131.5679931640625
INFO:root:Train (Epoch 38): Loss/seq after 01800 batchs: 1121.1654052734375
INFO:root:Train (Epoch 38): Loss/seq after 01850 batchs: 1110.3446044921875
INFO:root:Train (Epoch 38): Loss/seq after 01900 batchs: 1111.03173828125
INFO:root:Train (Epoch 38): Loss/seq after 01950 batchs: 1106.056884765625
INFO:root:Train (Epoch 38): Loss/seq after 02000 batchs: 1099.4205322265625
INFO:root:Train (Epoch 38): Loss/seq after 02050 batchs: 1093.693603515625
INFO:root:Train (Epoch 38): Loss/seq after 02100 batchs: 1084.84130859375
INFO:root:Train (Epoch 38): Loss/seq after 02150 batchs: 1077.0394287109375
INFO:root:Train (Epoch 38): Loss/seq after 02200 batchs: 1068.418212890625
INFO:root:Train (Epoch 38): Loss/seq after 02250 batchs: 1069.1959228515625
INFO:root:Train (Epoch 38): Loss/seq after 02300 batchs: 1075.610595703125
INFO:root:Train (Epoch 38): Loss/seq after 02350 batchs: 1067.630615234375
INFO:root:Train (Epoch 38): Loss/seq after 02400 batchs: 1064.086669921875
INFO:root:Train (Epoch 38): Loss/seq after 02450 batchs: 1053.6148681640625
INFO:root:Train (Epoch 38): Loss/seq after 02500 batchs: 1038.6483154296875
INFO:root:Train (Epoch 38): Loss/seq after 02550 batchs: 1028.26513671875
INFO:root:Train (Epoch 38): Loss/seq after 02600 batchs: 1026.1241455078125
INFO:root:Train (Epoch 38): Loss/seq after 02650 batchs: 1021.790283203125
INFO:root:Train (Epoch 38): Loss/seq after 02700 batchs: 1018.7432861328125
INFO:root:Train (Epoch 38): Loss/seq after 02750 batchs: 1047.732177734375
INFO:root:Train (Epoch 38): Loss/seq after 02800 batchs: 1053.0235595703125
INFO:root:Train (Epoch 38): Loss/seq after 02850 batchs: 1050.046875
INFO:root:Train (Epoch 38): Loss/seq after 02900 batchs: 1049.1700439453125
INFO:root:Train (Epoch 38): Loss/seq after 02950 batchs: 1043.2479248046875
INFO:root:Train (Epoch 38): Loss/seq after 03000 batchs: 1043.542724609375
INFO:root:Train (Epoch 38): Loss/seq after 03050 batchs: 1047.9090576171875
INFO:root:Train (Epoch 38): Loss/seq after 03100 batchs: 1056.537109375
INFO:root:Train (Epoch 38): Loss/seq after 03150 batchs: 1063.258544921875
INFO:root:Train (Epoch 38): Loss/seq after 03200 batchs: 1069.81640625
INFO:root:Train (Epoch 38): Loss/seq after 03250 batchs: 1073.132080078125
INFO:root:Train (Epoch 38): Loss/seq after 03300 batchs: 1073.072021484375
INFO:root:Train (Epoch 38): Loss/seq after 03350 batchs: 1074.7342529296875
INFO:root:Train (Epoch 38): Loss/seq after 03400 batchs: 1067.6998291015625
INFO:root:Train (Epoch 38): Loss/seq after 03450 batchs: 1063.8712158203125
INFO:root:Train (Epoch 38): Loss/seq after 03500 batchs: 1066.0526123046875
INFO:root:Train (Epoch 38): Loss/seq after 03550 batchs: 1062.8975830078125
INFO:root:Train (Epoch 38): Loss/seq after 03600 batchs: 1070.202880859375
INFO:root:Train (Epoch 38): Loss/seq after 03650 batchs: 1066.133544921875
INFO:root:Train (Epoch 38): Loss/seq after 03700 batchs: 1065.8470458984375
INFO:root:Train (Epoch 38): Loss/seq after 03750 batchs: 1067.404541015625
INFO:root:Train (Epoch 38): Loss/seq after 03800 batchs: 1061.4505615234375
INFO:root:Train (Epoch 38): Loss/seq after 03850 batchs: 1058.3302001953125
INFO:root:Train (Epoch 38): Loss/seq after 03900 batchs: 1061.400634765625
INFO:root:Train (Epoch 38): Loss/seq after 03950 batchs: 1066.144775390625
INFO:root:Train (Epoch 38): Loss/seq after 04000 batchs: 1058.9471435546875
INFO:root:Train (Epoch 38): Loss/seq after 04050 batchs: 1052.2119140625
INFO:root:Train (Epoch 38): Loss/seq after 04100 batchs: 1048.0509033203125
INFO:root:Train (Epoch 38): Loss/seq after 04150 batchs: 1043.8568115234375
INFO:root:Train (Epoch 38): Loss/seq after 04200 batchs: 1039.7437744140625
INFO:root:Train (Epoch 38): Loss/seq after 04250 batchs: 1036.2952880859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 38): Loss/seq after 00000 batches: 827.1770629882812
INFO:root:# Valid (Epoch 38): Loss/seq after 00050 batches: 1012.6122436523438
INFO:root:# Valid (Epoch 38): Loss/seq after 00100 batches: 1305.792724609375
INFO:root:# Valid (Epoch 38): Loss/seq after 00150 batches: 1030.20068359375
INFO:root:# Valid (Epoch 38): Loss/seq after 00200 batches: 932.620849609375
INFO:root:Artifacts: Make stick videos for epoch 38
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_38_on_20220412_215603.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_38_index_1133_on_20220412_215603.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 39): Loss/seq after 00000 batchs: 1576.101318359375
INFO:root:Train (Epoch 39): Loss/seq after 00050 batchs: 1328.5040283203125
INFO:root:Train (Epoch 39): Loss/seq after 00100 batchs: 1364.3717041015625
INFO:root:Train (Epoch 39): Loss/seq after 00150 batchs: 1230.647216796875
INFO:root:Train (Epoch 39): Loss/seq after 00200 batchs: 1330.47607421875
INFO:root:Train (Epoch 39): Loss/seq after 00250 batchs: 1451.0506591796875
INFO:root:Train (Epoch 39): Loss/seq after 00300 batchs: 1388.34375
INFO:root:Train (Epoch 39): Loss/seq after 00350 batchs: 1293.4210205078125
INFO:root:Train (Epoch 39): Loss/seq after 00400 batchs: 1317.885986328125
INFO:root:Train (Epoch 39): Loss/seq after 00450 batchs: 1267.52734375
INFO:root:Train (Epoch 39): Loss/seq after 00500 batchs: 1273.9317626953125
INFO:root:Train (Epoch 39): Loss/seq after 00550 batchs: 1225.4541015625
INFO:root:Train (Epoch 39): Loss/seq after 00600 batchs: 1190.238525390625
INFO:root:Train (Epoch 39): Loss/seq after 00650 batchs: 1198.6629638671875
INFO:root:Train (Epoch 39): Loss/seq after 00700 batchs: 1183.5048828125
INFO:root:Train (Epoch 39): Loss/seq after 00750 batchs: 1221.1241455078125
INFO:root:Train (Epoch 39): Loss/seq after 00800 batchs: 1216.623291015625
INFO:root:Train (Epoch 39): Loss/seq after 00850 batchs: 1191.181396484375
INFO:root:Train (Epoch 39): Loss/seq after 00900 batchs: 1191.8387451171875
INFO:root:Train (Epoch 39): Loss/seq after 00950 batchs: 1211.9061279296875
INFO:root:Train (Epoch 39): Loss/seq after 01000 batchs: 1206.6658935546875
INFO:root:Train (Epoch 39): Loss/seq after 01050 batchs: 1188.80419921875
INFO:root:Train (Epoch 39): Loss/seq after 01100 batchs: 1178.105224609375
INFO:root:Train (Epoch 39): Loss/seq after 01150 batchs: 1159.62109375
INFO:root:Train (Epoch 39): Loss/seq after 01200 batchs: 1153.687255859375
INFO:root:Train (Epoch 39): Loss/seq after 01250 batchs: 1147.7978515625
INFO:root:Train (Epoch 39): Loss/seq after 01300 batchs: 1151.4310302734375
INFO:root:Train (Epoch 39): Loss/seq after 01350 batchs: 1154.0167236328125
INFO:root:Train (Epoch 39): Loss/seq after 01400 batchs: 1171.28125
INFO:root:Train (Epoch 39): Loss/seq after 01450 batchs: 1164.761474609375
INFO:root:Train (Epoch 39): Loss/seq after 01500 batchs: 1159.9193115234375
INFO:root:Train (Epoch 39): Loss/seq after 01550 batchs: 1160.265380859375
INFO:root:Train (Epoch 39): Loss/seq after 01600 batchs: 1147.2801513671875
INFO:root:Train (Epoch 39): Loss/seq after 01650 batchs: 1138.67236328125
INFO:root:Train (Epoch 39): Loss/seq after 01700 batchs: 1131.9202880859375
INFO:root:Train (Epoch 39): Loss/seq after 01750 batchs: 1123.138427734375
INFO:root:Train (Epoch 39): Loss/seq after 01800 batchs: 1112.5379638671875
INFO:root:Train (Epoch 39): Loss/seq after 01850 batchs: 1101.4659423828125
INFO:root:Train (Epoch 39): Loss/seq after 01900 batchs: 1102.4053955078125
INFO:root:Train (Epoch 39): Loss/seq after 01950 batchs: 1097.2645263671875
INFO:root:Train (Epoch 39): Loss/seq after 02000 batchs: 1090.7728271484375
INFO:root:Train (Epoch 39): Loss/seq after 02050 batchs: 1085.095458984375
INFO:root:Train (Epoch 39): Loss/seq after 02100 batchs: 1076.00927734375
INFO:root:Train (Epoch 39): Loss/seq after 02150 batchs: 1068.2103271484375
INFO:root:Train (Epoch 39): Loss/seq after 02200 batchs: 1059.5400390625
INFO:root:Train (Epoch 39): Loss/seq after 02250 batchs: 1060.644775390625
INFO:root:Train (Epoch 39): Loss/seq after 02300 batchs: 1068.1314697265625
INFO:root:Train (Epoch 39): Loss/seq after 02350 batchs: 1060.0482177734375
INFO:root:Train (Epoch 39): Loss/seq after 02400 batchs: 1056.6624755859375
INFO:root:Train (Epoch 39): Loss/seq after 02450 batchs: 1046.219482421875
INFO:root:Train (Epoch 39): Loss/seq after 02500 batchs: 1031.29638671875
INFO:root:Train (Epoch 39): Loss/seq after 02550 batchs: 1020.5571899414062
INFO:root:Train (Epoch 39): Loss/seq after 02600 batchs: 1018.0418701171875
INFO:root:Train (Epoch 39): Loss/seq after 02650 batchs: 1013.7903442382812
INFO:root:Train (Epoch 39): Loss/seq after 02700 batchs: 1010.302490234375
INFO:root:Train (Epoch 39): Loss/seq after 02750 batchs: 1039.3699951171875
INFO:root:Train (Epoch 39): Loss/seq after 02800 batchs: 1044.9202880859375
INFO:root:Train (Epoch 39): Loss/seq after 02850 batchs: 1041.9556884765625
INFO:root:Train (Epoch 39): Loss/seq after 02900 batchs: 1040.405517578125
INFO:root:Train (Epoch 39): Loss/seq after 02950 batchs: 1034.224365234375
INFO:root:Train (Epoch 39): Loss/seq after 03000 batchs: 1034.4393310546875
INFO:root:Train (Epoch 39): Loss/seq after 03050 batchs: 1038.346435546875
INFO:root:Train (Epoch 39): Loss/seq after 03100 batchs: 1046.4539794921875
INFO:root:Train (Epoch 39): Loss/seq after 03150 batchs: 1050.711669921875
INFO:root:Train (Epoch 39): Loss/seq after 03200 batchs: 1057.2230224609375
INFO:root:Train (Epoch 39): Loss/seq after 03250 batchs: 1061.2860107421875
INFO:root:Train (Epoch 39): Loss/seq after 03300 batchs: 1059.795654296875
INFO:root:Train (Epoch 39): Loss/seq after 03350 batchs: 1058.9945068359375
INFO:root:Train (Epoch 39): Loss/seq after 03400 batchs: 1051.6671142578125
INFO:root:Train (Epoch 39): Loss/seq after 03450 batchs: 1046.087890625
INFO:root:Train (Epoch 39): Loss/seq after 03500 batchs: 1045.864990234375
INFO:root:Train (Epoch 39): Loss/seq after 03550 batchs: 1040.4827880859375
INFO:root:Train (Epoch 39): Loss/seq after 03600 batchs: 1047.3349609375
INFO:root:Train (Epoch 39): Loss/seq after 03650 batchs: 1042.4814453125
INFO:root:Train (Epoch 39): Loss/seq after 03700 batchs: 1042.3868408203125
INFO:root:Train (Epoch 39): Loss/seq after 03750 batchs: 1044.19580078125
INFO:root:Train (Epoch 39): Loss/seq after 03800 batchs: 1038.73876953125
INFO:root:Train (Epoch 39): Loss/seq after 03850 batchs: 1035.7357177734375
INFO:root:Train (Epoch 39): Loss/seq after 03900 batchs: 1039.5572509765625
INFO:root:Train (Epoch 39): Loss/seq after 03950 batchs: 1043.3524169921875
INFO:root:Train (Epoch 39): Loss/seq after 04000 batchs: 1036.423583984375
INFO:root:Train (Epoch 39): Loss/seq after 04050 batchs: 1029.937744140625
INFO:root:Train (Epoch 39): Loss/seq after 04100 batchs: 1025.18408203125
INFO:root:Train (Epoch 39): Loss/seq after 04150 batchs: 1021.0247192382812
INFO:root:Train (Epoch 39): Loss/seq after 04200 batchs: 1016.93798828125
INFO:root:Train (Epoch 39): Loss/seq after 04250 batchs: 1013.7015991210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 39): Loss/seq after 00000 batches: 898.1481323242188
INFO:root:# Valid (Epoch 39): Loss/seq after 00050 batches: 968.7680053710938
INFO:root:# Valid (Epoch 39): Loss/seq after 00100 batches: 1277.3646240234375
INFO:root:# Valid (Epoch 39): Loss/seq after 00150 batches: 1006.3305053710938
INFO:root:# Valid (Epoch 39): Loss/seq after 00200 batches: 917.5213012695312
INFO:root:Artifacts: Make stick videos for epoch 39
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_39_on_20220412_220123.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_39_index_548_on_20220412_220123.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 40): Loss/seq after 00000 batchs: 1802.89208984375
INFO:root:Train (Epoch 40): Loss/seq after 00050 batchs: 1265.39599609375
INFO:root:Train (Epoch 40): Loss/seq after 00100 batchs: 1294.0450439453125
INFO:root:Train (Epoch 40): Loss/seq after 00150 batchs: 1173.3043212890625
INFO:root:Train (Epoch 40): Loss/seq after 00200 batchs: 1281.8450927734375
INFO:root:Train (Epoch 40): Loss/seq after 00250 batchs: 1401.562744140625
INFO:root:Train (Epoch 40): Loss/seq after 00300 batchs: 1346.6029052734375
INFO:root:Train (Epoch 40): Loss/seq after 00350 batchs: 1259.989013671875
INFO:root:Train (Epoch 40): Loss/seq after 00400 batchs: 1295.842529296875
INFO:root:Train (Epoch 40): Loss/seq after 00450 batchs: 1247.9681396484375
INFO:root:Train (Epoch 40): Loss/seq after 00500 batchs: 1244.7088623046875
INFO:root:Train (Epoch 40): Loss/seq after 00550 batchs: 1196.9403076171875
INFO:root:Train (Epoch 40): Loss/seq after 00600 batchs: 1162.6822509765625
INFO:root:Train (Epoch 40): Loss/seq after 00650 batchs: 1171.2996826171875
INFO:root:Train (Epoch 40): Loss/seq after 00700 batchs: 1152.2225341796875
INFO:root:Train (Epoch 40): Loss/seq after 00750 batchs: 1182.577880859375
INFO:root:Train (Epoch 40): Loss/seq after 00800 batchs: 1179.156982421875
INFO:root:Train (Epoch 40): Loss/seq after 00850 batchs: 1154.1190185546875
INFO:root:Train (Epoch 40): Loss/seq after 00900 batchs: 1152.4830322265625
INFO:root:Train (Epoch 40): Loss/seq after 00950 batchs: 1170.42578125
INFO:root:Train (Epoch 40): Loss/seq after 01000 batchs: 1166.2125244140625
INFO:root:Train (Epoch 40): Loss/seq after 01050 batchs: 1146.25390625
INFO:root:Train (Epoch 40): Loss/seq after 01100 batchs: 1139.881591796875
INFO:root:Train (Epoch 40): Loss/seq after 01150 batchs: 1123.7266845703125
INFO:root:Train (Epoch 40): Loss/seq after 01200 batchs: 1119.047607421875
INFO:root:Train (Epoch 40): Loss/seq after 01250 batchs: 1112.5660400390625
INFO:root:Train (Epoch 40): Loss/seq after 01300 batchs: 1111.16796875
INFO:root:Train (Epoch 40): Loss/seq after 01350 batchs: 1113.121337890625
INFO:root:Train (Epoch 40): Loss/seq after 01400 batchs: 1127.3768310546875
INFO:root:Train (Epoch 40): Loss/seq after 01450 batchs: 1122.252685546875
INFO:root:Train (Epoch 40): Loss/seq after 01500 batchs: 1118.8526611328125
INFO:root:Train (Epoch 40): Loss/seq after 01550 batchs: 1119.600830078125
INFO:root:Train (Epoch 40): Loss/seq after 01600 batchs: 1107.9970703125
INFO:root:Train (Epoch 40): Loss/seq after 01650 batchs: 1100.7713623046875
INFO:root:Train (Epoch 40): Loss/seq after 01700 batchs: 1094.9263916015625
INFO:root:Train (Epoch 40): Loss/seq after 01750 batchs: 1087.12060546875
INFO:root:Train (Epoch 40): Loss/seq after 01800 batchs: 1077.1383056640625
INFO:root:Train (Epoch 40): Loss/seq after 01850 batchs: 1067.029052734375
INFO:root:Train (Epoch 40): Loss/seq after 01900 batchs: 1068.5435791015625
INFO:root:Train (Epoch 40): Loss/seq after 01950 batchs: 1064.635498046875
INFO:root:Train (Epoch 40): Loss/seq after 02000 batchs: 1058.897705078125
INFO:root:Train (Epoch 40): Loss/seq after 02050 batchs: 1053.9342041015625
INFO:root:Train (Epoch 40): Loss/seq after 02100 batchs: 1045.8514404296875
INFO:root:Train (Epoch 40): Loss/seq after 02150 batchs: 1038.7181396484375
INFO:root:Train (Epoch 40): Loss/seq after 02200 batchs: 1030.84326171875
INFO:root:Train (Epoch 40): Loss/seq after 02250 batchs: 1032.9322509765625
INFO:root:Train (Epoch 40): Loss/seq after 02300 batchs: 1041.099609375
INFO:root:Train (Epoch 40): Loss/seq after 02350 batchs: 1035.055908203125
INFO:root:Train (Epoch 40): Loss/seq after 02400 batchs: 1032.97802734375
INFO:root:Train (Epoch 40): Loss/seq after 02450 batchs: 1023.5953369140625
INFO:root:Train (Epoch 40): Loss/seq after 02500 batchs: 1008.9606323242188
INFO:root:Train (Epoch 40): Loss/seq after 02550 batchs: 998.8829956054688
INFO:root:Train (Epoch 40): Loss/seq after 02600 batchs: 997.1365966796875
INFO:root:Train (Epoch 40): Loss/seq after 02650 batchs: 992.7666625976562
INFO:root:Train (Epoch 40): Loss/seq after 02700 batchs: 990.1285400390625
INFO:root:Train (Epoch 40): Loss/seq after 02750 batchs: 1019.1105346679688
INFO:root:Train (Epoch 40): Loss/seq after 02800 batchs: 1025.294921875
INFO:root:Train (Epoch 40): Loss/seq after 02850 batchs: 1022.8239135742188
INFO:root:Train (Epoch 40): Loss/seq after 02900 batchs: 1021.8607788085938
INFO:root:Train (Epoch 40): Loss/seq after 02950 batchs: 1016.67578125
INFO:root:Train (Epoch 40): Loss/seq after 03000 batchs: 1017.3284912109375
INFO:root:Train (Epoch 40): Loss/seq after 03050 batchs: 1021.8004150390625
INFO:root:Train (Epoch 40): Loss/seq after 03100 batchs: 1030.06982421875
INFO:root:Train (Epoch 40): Loss/seq after 03150 batchs: 1032.7802734375
INFO:root:Train (Epoch 40): Loss/seq after 03200 batchs: 1040.0006103515625
INFO:root:Train (Epoch 40): Loss/seq after 03250 batchs: 1043.6773681640625
INFO:root:Train (Epoch 40): Loss/seq after 03300 batchs: 1041.9852294921875
INFO:root:Train (Epoch 40): Loss/seq after 03350 batchs: 1042.072021484375
INFO:root:Train (Epoch 40): Loss/seq after 03400 batchs: 1035.2188720703125
INFO:root:Train (Epoch 40): Loss/seq after 03450 batchs: 1030.7645263671875
INFO:root:Train (Epoch 40): Loss/seq after 03500 batchs: 1030.4287109375
INFO:root:Train (Epoch 40): Loss/seq after 03550 batchs: 1025.7288818359375
INFO:root:Train (Epoch 40): Loss/seq after 03600 batchs: 1032.9217529296875
INFO:root:Train (Epoch 40): Loss/seq after 03650 batchs: 1028.6082763671875
INFO:root:Train (Epoch 40): Loss/seq after 03700 batchs: 1028.67578125
INFO:root:Train (Epoch 40): Loss/seq after 03750 batchs: 1030.7828369140625
INFO:root:Train (Epoch 40): Loss/seq after 03800 batchs: 1025.348876953125
INFO:root:Train (Epoch 40): Loss/seq after 03850 batchs: 1022.63525390625
INFO:root:Train (Epoch 40): Loss/seq after 03900 batchs: 1026.259521484375
INFO:root:Train (Epoch 40): Loss/seq after 03950 batchs: 1030.4254150390625
INFO:root:Train (Epoch 40): Loss/seq after 04000 batchs: 1023.7060546875
INFO:root:Train (Epoch 40): Loss/seq after 04050 batchs: 1017.4774780273438
INFO:root:Train (Epoch 40): Loss/seq after 04100 batchs: 1012.8279418945312
INFO:root:Train (Epoch 40): Loss/seq after 04150 batchs: 1008.9990844726562
INFO:root:Train (Epoch 40): Loss/seq after 04200 batchs: 1005.1802978515625
INFO:root:Train (Epoch 40): Loss/seq after 04250 batchs: 1001.9281616210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 40): Loss/seq after 00000 batches: 743.3231201171875
INFO:root:# Valid (Epoch 40): Loss/seq after 00050 batches: 973.0278930664062
INFO:root:# Valid (Epoch 40): Loss/seq after 00100 batches: 1257.999267578125
INFO:root:# Valid (Epoch 40): Loss/seq after 00150 batches: 996.306396484375
INFO:root:# Valid (Epoch 40): Loss/seq after 00200 batches: 909.2562866210938
INFO:root:Artifacts: Make stick videos for epoch 40
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_40_on_20220412_220646.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_40_index_1743_on_20220412_220646.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 41): Loss/seq after 00000 batchs: 1699.626953125
INFO:root:Train (Epoch 41): Loss/seq after 00050 batchs: 1274.048583984375
INFO:root:Train (Epoch 41): Loss/seq after 00100 batchs: 1302.8409423828125
INFO:root:Train (Epoch 41): Loss/seq after 00150 batchs: 1177.637451171875
INFO:root:Train (Epoch 41): Loss/seq after 00200 batchs: 1279.8984375
INFO:root:Train (Epoch 41): Loss/seq after 00250 batchs: 1414.490966796875
INFO:root:Train (Epoch 41): Loss/seq after 00300 batchs: 1356.68896484375
INFO:root:Train (Epoch 41): Loss/seq after 00350 batchs: 1267.5758056640625
INFO:root:Train (Epoch 41): Loss/seq after 00400 batchs: 1296.5635986328125
INFO:root:Train (Epoch 41): Loss/seq after 00450 batchs: 1247.774658203125
INFO:root:Train (Epoch 41): Loss/seq after 00500 batchs: 1245.2054443359375
INFO:root:Train (Epoch 41): Loss/seq after 00550 batchs: 1197.6072998046875
INFO:root:Train (Epoch 41): Loss/seq after 00600 batchs: 1165.9658203125
INFO:root:Train (Epoch 41): Loss/seq after 00650 batchs: 1175.1600341796875
INFO:root:Train (Epoch 41): Loss/seq after 00700 batchs: 1159.2020263671875
INFO:root:Train (Epoch 41): Loss/seq after 00750 batchs: 1191.9105224609375
INFO:root:Train (Epoch 41): Loss/seq after 00800 batchs: 1186.943115234375
INFO:root:Train (Epoch 41): Loss/seq after 00850 batchs: 1159.343994140625
INFO:root:Train (Epoch 41): Loss/seq after 00900 batchs: 1157.065673828125
INFO:root:Train (Epoch 41): Loss/seq after 00950 batchs: 1174.524169921875
INFO:root:Train (Epoch 41): Loss/seq after 01000 batchs: 1166.9844970703125
INFO:root:Train (Epoch 41): Loss/seq after 01050 batchs: 1150.77880859375
INFO:root:Train (Epoch 41): Loss/seq after 01100 batchs: 1142.614990234375
INFO:root:Train (Epoch 41): Loss/seq after 01150 batchs: 1126.6058349609375
INFO:root:Train (Epoch 41): Loss/seq after 01200 batchs: 1122.6259765625
INFO:root:Train (Epoch 41): Loss/seq after 01250 batchs: 1117.1300048828125
INFO:root:Train (Epoch 41): Loss/seq after 01300 batchs: 1116.06201171875
INFO:root:Train (Epoch 41): Loss/seq after 01350 batchs: 1118.79296875
INFO:root:Train (Epoch 41): Loss/seq after 01400 batchs: 1135.5543212890625
INFO:root:Train (Epoch 41): Loss/seq after 01450 batchs: 1130.169921875
INFO:root:Train (Epoch 41): Loss/seq after 01500 batchs: 1126.474853515625
INFO:root:Train (Epoch 41): Loss/seq after 01550 batchs: 1128.660888671875
INFO:root:Train (Epoch 41): Loss/seq after 01600 batchs: 1116.5316162109375
INFO:root:Train (Epoch 41): Loss/seq after 01650 batchs: 1109.20068359375
INFO:root:Train (Epoch 41): Loss/seq after 01700 batchs: 1103.5889892578125
INFO:root:Train (Epoch 41): Loss/seq after 01750 batchs: 1096.0677490234375
INFO:root:Train (Epoch 41): Loss/seq after 01800 batchs: 1085.9755859375
INFO:root:Train (Epoch 41): Loss/seq after 01850 batchs: 1075.787109375
INFO:root:Train (Epoch 41): Loss/seq after 01900 batchs: 1077.2845458984375
INFO:root:Train (Epoch 41): Loss/seq after 01950 batchs: 1072.706787109375
INFO:root:Train (Epoch 41): Loss/seq after 02000 batchs: 1066.5753173828125
INFO:root:Train (Epoch 41): Loss/seq after 02050 batchs: 1061.369140625
INFO:root:Train (Epoch 41): Loss/seq after 02100 batchs: 1052.9244384765625
INFO:root:Train (Epoch 41): Loss/seq after 02150 batchs: 1045.5321044921875
INFO:root:Train (Epoch 41): Loss/seq after 02200 batchs: 1037.4451904296875
INFO:root:Train (Epoch 41): Loss/seq after 02250 batchs: 1038.2987060546875
INFO:root:Train (Epoch 41): Loss/seq after 02300 batchs: 1044.331298828125
INFO:root:Train (Epoch 41): Loss/seq after 02350 batchs: 1036.3065185546875
INFO:root:Train (Epoch 41): Loss/seq after 02400 batchs: 1033.624755859375
INFO:root:Train (Epoch 41): Loss/seq after 02450 batchs: 1023.5240478515625
INFO:root:Train (Epoch 41): Loss/seq after 02500 batchs: 1008.890625
INFO:root:Train (Epoch 41): Loss/seq after 02550 batchs: 998.6136474609375
INFO:root:Train (Epoch 41): Loss/seq after 02600 batchs: 996.474609375
INFO:root:Train (Epoch 41): Loss/seq after 02650 batchs: 992.4088134765625
INFO:root:Train (Epoch 41): Loss/seq after 02700 batchs: 989.6714477539062
INFO:root:Train (Epoch 41): Loss/seq after 02750 batchs: 1018.4465942382812
INFO:root:Train (Epoch 41): Loss/seq after 02800 batchs: 1023.306640625
INFO:root:Train (Epoch 41): Loss/seq after 02850 batchs: 1020.3561401367188
INFO:root:Train (Epoch 41): Loss/seq after 02900 batchs: 1019.5038452148438
INFO:root:Train (Epoch 41): Loss/seq after 02950 batchs: 1013.8768310546875
INFO:root:Train (Epoch 41): Loss/seq after 03000 batchs: 1014.4386596679688
INFO:root:Train (Epoch 41): Loss/seq after 03050 batchs: 1018.7211303710938
INFO:root:Train (Epoch 41): Loss/seq after 03100 batchs: 1026.9881591796875
INFO:root:Train (Epoch 41): Loss/seq after 03150 batchs: 1032.1795654296875
INFO:root:Train (Epoch 41): Loss/seq after 03200 batchs: 1038.7269287109375
INFO:root:Train (Epoch 41): Loss/seq after 03250 batchs: 1042.1531982421875
INFO:root:Train (Epoch 41): Loss/seq after 03300 batchs: 1041.0428466796875
INFO:root:Train (Epoch 41): Loss/seq after 03350 batchs: 1040.7376708984375
INFO:root:Train (Epoch 41): Loss/seq after 03400 batchs: 1033.3642578125
INFO:root:Train (Epoch 41): Loss/seq after 03450 batchs: 1028.2918701171875
INFO:root:Train (Epoch 41): Loss/seq after 03500 batchs: 1028.5023193359375
INFO:root:Train (Epoch 41): Loss/seq after 03550 batchs: 1023.777587890625
INFO:root:Train (Epoch 41): Loss/seq after 03600 batchs: 1030.6685791015625
INFO:root:Train (Epoch 41): Loss/seq after 03650 batchs: 1026.249755859375
INFO:root:Train (Epoch 41): Loss/seq after 03700 batchs: 1026.111572265625
INFO:root:Train (Epoch 41): Loss/seq after 03750 batchs: 1028.17822265625
INFO:root:Train (Epoch 41): Loss/seq after 03800 batchs: 1022.6011352539062
INFO:root:Train (Epoch 41): Loss/seq after 03850 batchs: 1019.7155151367188
INFO:root:Train (Epoch 41): Loss/seq after 03900 batchs: 1023.4783935546875
INFO:root:Train (Epoch 41): Loss/seq after 03950 batchs: 1027.93603515625
INFO:root:Train (Epoch 41): Loss/seq after 04000 batchs: 1021.349365234375
INFO:root:Train (Epoch 41): Loss/seq after 04050 batchs: 1015.1503295898438
INFO:root:Train (Epoch 41): Loss/seq after 04100 batchs: 1010.6043701171875
INFO:root:Train (Epoch 41): Loss/seq after 04150 batchs: 1006.6568603515625
INFO:root:Train (Epoch 41): Loss/seq after 04200 batchs: 1002.8402709960938
INFO:root:Train (Epoch 41): Loss/seq after 04250 batchs: 999.7173461914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 41): Loss/seq after 00000 batches: 902.5316772460938
INFO:root:# Valid (Epoch 41): Loss/seq after 00050 batches: 951.6182861328125
INFO:root:# Valid (Epoch 41): Loss/seq after 00100 batches: 1263.7425537109375
INFO:root:# Valid (Epoch 41): Loss/seq after 00150 batches: 994.88330078125
INFO:root:# Valid (Epoch 41): Loss/seq after 00200 batches: 906.3726196289062
INFO:root:Artifacts: Make stick videos for epoch 41
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_41_on_20220412_221209.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_41_index_366_on_20220412_221209.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 42): Loss/seq after 00000 batchs: 1537.7930908203125
INFO:root:Train (Epoch 42): Loss/seq after 00050 batchs: 1314.363525390625
INFO:root:Train (Epoch 42): Loss/seq after 00100 batchs: 1332.8486328125
INFO:root:Train (Epoch 42): Loss/seq after 00150 batchs: 1203.243896484375
INFO:root:Train (Epoch 42): Loss/seq after 00200 batchs: 1301.8292236328125
INFO:root:Train (Epoch 42): Loss/seq after 00250 batchs: 1422.7271728515625
INFO:root:Train (Epoch 42): Loss/seq after 00300 batchs: 1363.838134765625
INFO:root:Train (Epoch 42): Loss/seq after 00350 batchs: 1275.487060546875
INFO:root:Train (Epoch 42): Loss/seq after 00400 batchs: 1303.3028564453125
INFO:root:Train (Epoch 42): Loss/seq after 00450 batchs: 1254.8702392578125
INFO:root:Train (Epoch 42): Loss/seq after 00500 batchs: 1250.4661865234375
INFO:root:Train (Epoch 42): Loss/seq after 00550 batchs: 1201.7176513671875
INFO:root:Train (Epoch 42): Loss/seq after 00600 batchs: 1161.1744384765625
INFO:root:Train (Epoch 42): Loss/seq after 00650 batchs: 1168.2740478515625
INFO:root:Train (Epoch 42): Loss/seq after 00700 batchs: 1149.1483154296875
INFO:root:Train (Epoch 42): Loss/seq after 00750 batchs: 1178.2318115234375
INFO:root:Train (Epoch 42): Loss/seq after 00800 batchs: 1171.589599609375
INFO:root:Train (Epoch 42): Loss/seq after 00850 batchs: 1144.5819091796875
INFO:root:Train (Epoch 42): Loss/seq after 00900 batchs: 1139.479736328125
INFO:root:Train (Epoch 42): Loss/seq after 00950 batchs: 1157.8792724609375
INFO:root:Train (Epoch 42): Loss/seq after 01000 batchs: 1150.977294921875
INFO:root:Train (Epoch 42): Loss/seq after 01050 batchs: 1135.2210693359375
INFO:root:Train (Epoch 42): Loss/seq after 01100 batchs: 1127.2119140625
INFO:root:Train (Epoch 42): Loss/seq after 01150 batchs: 1110.6046142578125
INFO:root:Train (Epoch 42): Loss/seq after 01200 batchs: 1106.141845703125
INFO:root:Train (Epoch 42): Loss/seq after 01250 batchs: 1099.8348388671875
INFO:root:Train (Epoch 42): Loss/seq after 01300 batchs: 1098.546142578125
INFO:root:Train (Epoch 42): Loss/seq after 01350 batchs: 1100.7508544921875
INFO:root:Train (Epoch 42): Loss/seq after 01400 batchs: 1114.870849609375
INFO:root:Train (Epoch 42): Loss/seq after 01450 batchs: 1110.2607421875
INFO:root:Train (Epoch 42): Loss/seq after 01500 batchs: 1106.81005859375
INFO:root:Train (Epoch 42): Loss/seq after 01550 batchs: 1109.84423828125
INFO:root:Train (Epoch 42): Loss/seq after 01600 batchs: 1098.1605224609375
INFO:root:Train (Epoch 42): Loss/seq after 01650 batchs: 1091.8177490234375
INFO:root:Train (Epoch 42): Loss/seq after 01700 batchs: 1087.150634765625
INFO:root:Train (Epoch 42): Loss/seq after 01750 batchs: 1079.6201171875
INFO:root:Train (Epoch 42): Loss/seq after 01800 batchs: 1070.2276611328125
INFO:root:Train (Epoch 42): Loss/seq after 01850 batchs: 1060.2271728515625
INFO:root:Train (Epoch 42): Loss/seq after 01900 batchs: 1061.645263671875
INFO:root:Train (Epoch 42): Loss/seq after 01950 batchs: 1057.2088623046875
INFO:root:Train (Epoch 42): Loss/seq after 02000 batchs: 1051.55712890625
INFO:root:Train (Epoch 42): Loss/seq after 02050 batchs: 1046.653076171875
INFO:root:Train (Epoch 42): Loss/seq after 02100 batchs: 1038.66796875
INFO:root:Train (Epoch 42): Loss/seq after 02150 batchs: 1031.7725830078125
INFO:root:Train (Epoch 42): Loss/seq after 02200 batchs: 1024.129150390625
INFO:root:Train (Epoch 42): Loss/seq after 02250 batchs: 1027.41015625
INFO:root:Train (Epoch 42): Loss/seq after 02300 batchs: 1035.1346435546875
INFO:root:Train (Epoch 42): Loss/seq after 02350 batchs: 1028.9599609375
INFO:root:Train (Epoch 42): Loss/seq after 02400 batchs: 1026.7354736328125
INFO:root:Train (Epoch 42): Loss/seq after 02450 batchs: 1016.9345092773438
INFO:root:Train (Epoch 42): Loss/seq after 02500 batchs: 1002.3943481445312
INFO:root:Train (Epoch 42): Loss/seq after 02550 batchs: 992.2323608398438
INFO:root:Train (Epoch 42): Loss/seq after 02600 batchs: 990.4903564453125
INFO:root:Train (Epoch 42): Loss/seq after 02650 batchs: 986.11767578125
INFO:root:Train (Epoch 42): Loss/seq after 02700 batchs: 983.5721435546875
INFO:root:Train (Epoch 42): Loss/seq after 02750 batchs: 1013.202880859375
INFO:root:Train (Epoch 42): Loss/seq after 02800 batchs: 1019.7733154296875
INFO:root:Train (Epoch 42): Loss/seq after 02850 batchs: 1017.1056518554688
INFO:root:Train (Epoch 42): Loss/seq after 02900 batchs: 1016.0009155273438
INFO:root:Train (Epoch 42): Loss/seq after 02950 batchs: 1010.4225463867188
INFO:root:Train (Epoch 42): Loss/seq after 03000 batchs: 1010.998046875
INFO:root:Train (Epoch 42): Loss/seq after 03050 batchs: 1015.362060546875
INFO:root:Train (Epoch 42): Loss/seq after 03100 batchs: 1022.1669311523438
INFO:root:Train (Epoch 42): Loss/seq after 03150 batchs: 1027.6143798828125
INFO:root:Train (Epoch 42): Loss/seq after 03200 batchs: 1034.040283203125
INFO:root:Train (Epoch 42): Loss/seq after 03250 batchs: 1037.3643798828125
INFO:root:Train (Epoch 42): Loss/seq after 03300 batchs: 1035.50732421875
INFO:root:Train (Epoch 42): Loss/seq after 03350 batchs: 1034.837646484375
INFO:root:Train (Epoch 42): Loss/seq after 03400 batchs: 1027.3511962890625
INFO:root:Train (Epoch 42): Loss/seq after 03450 batchs: 1022.0620727539062
INFO:root:Train (Epoch 42): Loss/seq after 03500 batchs: 1022.1576538085938
INFO:root:Train (Epoch 42): Loss/seq after 03550 batchs: 1017.0865478515625
INFO:root:Train (Epoch 42): Loss/seq after 03600 batchs: 1024.2449951171875
INFO:root:Train (Epoch 42): Loss/seq after 03650 batchs: 1019.6820068359375
INFO:root:Train (Epoch 42): Loss/seq after 03700 batchs: 1019.662353515625
INFO:root:Train (Epoch 42): Loss/seq after 03750 batchs: 1021.7904052734375
INFO:root:Train (Epoch 42): Loss/seq after 03800 batchs: 1016.0385131835938
INFO:root:Train (Epoch 42): Loss/seq after 03850 batchs: 1013.2981567382812
INFO:root:Train (Epoch 42): Loss/seq after 03900 batchs: 1016.9071044921875
INFO:root:Train (Epoch 42): Loss/seq after 03950 batchs: 1021.0955200195312
INFO:root:Train (Epoch 42): Loss/seq after 04000 batchs: 1014.4284057617188
INFO:root:Train (Epoch 42): Loss/seq after 04050 batchs: 1008.011474609375
INFO:root:Train (Epoch 42): Loss/seq after 04100 batchs: 1003.45263671875
INFO:root:Train (Epoch 42): Loss/seq after 04150 batchs: 999.5418090820312
INFO:root:Train (Epoch 42): Loss/seq after 04200 batchs: 995.5576171875
INFO:root:Train (Epoch 42): Loss/seq after 04250 batchs: 992.512939453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 42): Loss/seq after 00000 batches: 650.58056640625
INFO:root:# Valid (Epoch 42): Loss/seq after 00050 batches: 925.6001586914062
INFO:root:# Valid (Epoch 42): Loss/seq after 00100 batches: 1227.836181640625
INFO:root:# Valid (Epoch 42): Loss/seq after 00150 batches: 963.8524169921875
INFO:root:# Valid (Epoch 42): Loss/seq after 00200 batches: 880.27783203125
INFO:root:Artifacts: Make stick videos for epoch 42
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_42_on_20220412_221731.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_42_index_1847_on_20220412_221731.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 43): Loss/seq after 00000 batchs: 1545.2991943359375
INFO:root:Train (Epoch 43): Loss/seq after 00050 batchs: 1270.97412109375
INFO:root:Train (Epoch 43): Loss/seq after 00100 batchs: 1274.1185302734375
INFO:root:Train (Epoch 43): Loss/seq after 00150 batchs: 1161.9833984375
INFO:root:Train (Epoch 43): Loss/seq after 00200 batchs: 1265.6622314453125
INFO:root:Train (Epoch 43): Loss/seq after 00250 batchs: 1394.6173095703125
INFO:root:Train (Epoch 43): Loss/seq after 00300 batchs: 1338.981201171875
INFO:root:Train (Epoch 43): Loss/seq after 00350 batchs: 1252.6842041015625
INFO:root:Train (Epoch 43): Loss/seq after 00400 batchs: 1276.129638671875
INFO:root:Train (Epoch 43): Loss/seq after 00450 batchs: 1230.609619140625
INFO:root:Train (Epoch 43): Loss/seq after 00500 batchs: 1228.9112548828125
INFO:root:Train (Epoch 43): Loss/seq after 00550 batchs: 1182.8804931640625
INFO:root:Train (Epoch 43): Loss/seq after 00600 batchs: 1143.4163818359375
INFO:root:Train (Epoch 43): Loss/seq after 00650 batchs: 1153.05419921875
INFO:root:Train (Epoch 43): Loss/seq after 00700 batchs: 1133.6475830078125
INFO:root:Train (Epoch 43): Loss/seq after 00750 batchs: 1165.5174560546875
INFO:root:Train (Epoch 43): Loss/seq after 00800 batchs: 1159.58203125
INFO:root:Train (Epoch 43): Loss/seq after 00850 batchs: 1131.7760009765625
INFO:root:Train (Epoch 43): Loss/seq after 00900 batchs: 1128.41845703125
INFO:root:Train (Epoch 43): Loss/seq after 00950 batchs: 1139.8812255859375
INFO:root:Train (Epoch 43): Loss/seq after 01000 batchs: 1131.806640625
INFO:root:Train (Epoch 43): Loss/seq after 01050 batchs: 1112.3392333984375
INFO:root:Train (Epoch 43): Loss/seq after 01100 batchs: 1101.2930908203125
INFO:root:Train (Epoch 43): Loss/seq after 01150 batchs: 1084.0693359375
INFO:root:Train (Epoch 43): Loss/seq after 01200 batchs: 1079.4200439453125
INFO:root:Train (Epoch 43): Loss/seq after 01250 batchs: 1075.042724609375
INFO:root:Train (Epoch 43): Loss/seq after 01300 batchs: 1075.470703125
INFO:root:Train (Epoch 43): Loss/seq after 01350 batchs: 1079.219482421875
INFO:root:Train (Epoch 43): Loss/seq after 01400 batchs: 1094.030517578125
INFO:root:Train (Epoch 43): Loss/seq after 01450 batchs: 1089.489013671875
INFO:root:Train (Epoch 43): Loss/seq after 01500 batchs: 1086.828369140625
INFO:root:Train (Epoch 43): Loss/seq after 01550 batchs: 1088.568359375
INFO:root:Train (Epoch 43): Loss/seq after 01600 batchs: 1077.8719482421875
INFO:root:Train (Epoch 43): Loss/seq after 01650 batchs: 1070.98291015625
INFO:root:Train (Epoch 43): Loss/seq after 01700 batchs: 1066.44677734375
INFO:root:Train (Epoch 43): Loss/seq after 01750 batchs: 1058.9835205078125
INFO:root:Train (Epoch 43): Loss/seq after 01800 batchs: 1049.703857421875
INFO:root:Train (Epoch 43): Loss/seq after 01850 batchs: 1039.9866943359375
INFO:root:Train (Epoch 43): Loss/seq after 01900 batchs: 1041.666748046875
INFO:root:Train (Epoch 43): Loss/seq after 01950 batchs: 1037.54833984375
INFO:root:Train (Epoch 43): Loss/seq after 02000 batchs: 1032.3590087890625
INFO:root:Train (Epoch 43): Loss/seq after 02050 batchs: 1027.5458984375
INFO:root:Train (Epoch 43): Loss/seq after 02100 batchs: 1019.4718017578125
INFO:root:Train (Epoch 43): Loss/seq after 02150 batchs: 1012.9271240234375
INFO:root:Train (Epoch 43): Loss/seq after 02200 batchs: 1005.4649047851562
INFO:root:Train (Epoch 43): Loss/seq after 02250 batchs: 1006.7013549804688
INFO:root:Train (Epoch 43): Loss/seq after 02300 batchs: 1014.23486328125
INFO:root:Train (Epoch 43): Loss/seq after 02350 batchs: 1007.6967163085938
INFO:root:Train (Epoch 43): Loss/seq after 02400 batchs: 1005.5433959960938
INFO:root:Train (Epoch 43): Loss/seq after 02450 batchs: 995.944091796875
INFO:root:Train (Epoch 43): Loss/seq after 02500 batchs: 981.9242553710938
INFO:root:Train (Epoch 43): Loss/seq after 02550 batchs: 972.0011596679688
INFO:root:Train (Epoch 43): Loss/seq after 02600 batchs: 970.22314453125
INFO:root:Train (Epoch 43): Loss/seq after 02650 batchs: 966.1983032226562
INFO:root:Train (Epoch 43): Loss/seq after 02700 batchs: 963.8170776367188
INFO:root:Train (Epoch 43): Loss/seq after 02750 batchs: 992.3854370117188
INFO:root:Train (Epoch 43): Loss/seq after 02800 batchs: 997.6932983398438
INFO:root:Train (Epoch 43): Loss/seq after 02850 batchs: 995.3385009765625
INFO:root:Train (Epoch 43): Loss/seq after 02900 batchs: 994.4505615234375
INFO:root:Train (Epoch 43): Loss/seq after 02950 batchs: 989.5284423828125
INFO:root:Train (Epoch 43): Loss/seq after 03000 batchs: 990.4074096679688
INFO:root:Train (Epoch 43): Loss/seq after 03050 batchs: 995.1517944335938
INFO:root:Train (Epoch 43): Loss/seq after 03100 batchs: 1002.7991333007812
INFO:root:Train (Epoch 43): Loss/seq after 03150 batchs: 1006.5231323242188
INFO:root:Train (Epoch 43): Loss/seq after 03200 batchs: 1012.7763061523438
INFO:root:Train (Epoch 43): Loss/seq after 03250 batchs: 1015.8206787109375
INFO:root:Train (Epoch 43): Loss/seq after 03300 batchs: 1014.6455078125
INFO:root:Train (Epoch 43): Loss/seq after 03350 batchs: 1013.8488159179688
INFO:root:Train (Epoch 43): Loss/seq after 03400 batchs: 1006.8558349609375
INFO:root:Train (Epoch 43): Loss/seq after 03450 batchs: 1001.6519775390625
INFO:root:Train (Epoch 43): Loss/seq after 03500 batchs: 1001.0632934570312
INFO:root:Train (Epoch 43): Loss/seq after 03550 batchs: 995.9629516601562
INFO:root:Train (Epoch 43): Loss/seq after 03600 batchs: 1003.2190551757812
INFO:root:Train (Epoch 43): Loss/seq after 03650 batchs: 998.7194213867188
INFO:root:Train (Epoch 43): Loss/seq after 03700 batchs: 998.9572143554688
INFO:root:Train (Epoch 43): Loss/seq after 03750 batchs: 1001.2828369140625
INFO:root:Train (Epoch 43): Loss/seq after 03800 batchs: 996.1903076171875
INFO:root:Train (Epoch 43): Loss/seq after 03850 batchs: 993.7932739257812
INFO:root:Train (Epoch 43): Loss/seq after 03900 batchs: 997.1035766601562
INFO:root:Train (Epoch 43): Loss/seq after 03950 batchs: 1001.1688842773438
INFO:root:Train (Epoch 43): Loss/seq after 04000 batchs: 994.6902465820312
INFO:root:Train (Epoch 43): Loss/seq after 04050 batchs: 988.5532836914062
INFO:root:Train (Epoch 43): Loss/seq after 04100 batchs: 984.0223388671875
INFO:root:Train (Epoch 43): Loss/seq after 04150 batchs: 980.3125
INFO:root:Train (Epoch 43): Loss/seq after 04200 batchs: 976.8302612304688
INFO:root:Train (Epoch 43): Loss/seq after 04250 batchs: 973.6650390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 43): Loss/seq after 00000 batches: 661.466796875
INFO:root:# Valid (Epoch 43): Loss/seq after 00050 batches: 878.7744750976562
INFO:root:# Valid (Epoch 43): Loss/seq after 00100 batches: 1194.1134033203125
INFO:root:# Valid (Epoch 43): Loss/seq after 00150 batches: 949.1937255859375
INFO:root:# Valid (Epoch 43): Loss/seq after 00200 batches: 871.5372314453125
INFO:root:Artifacts: Make stick videos for epoch 43
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_43_on_20220412_222255.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_43_index_1687_on_20220412_222255.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 44): Loss/seq after 00000 batchs: 2096.159423828125
INFO:root:Train (Epoch 44): Loss/seq after 00050 batchs: 1211.7745361328125
INFO:root:Train (Epoch 44): Loss/seq after 00100 batchs: 1219.7242431640625
INFO:root:Train (Epoch 44): Loss/seq after 00150 batchs: 1109.1470947265625
INFO:root:Train (Epoch 44): Loss/seq after 00200 batchs: 1224.278076171875
INFO:root:Train (Epoch 44): Loss/seq after 00250 batchs: 1355.3670654296875
INFO:root:Train (Epoch 44): Loss/seq after 00300 batchs: 1305.52197265625
INFO:root:Train (Epoch 44): Loss/seq after 00350 batchs: 1221.1368408203125
INFO:root:Train (Epoch 44): Loss/seq after 00400 batchs: 1247.5804443359375
INFO:root:Train (Epoch 44): Loss/seq after 00450 batchs: 1204.0098876953125
INFO:root:Train (Epoch 44): Loss/seq after 00500 batchs: 1207.6448974609375
INFO:root:Train (Epoch 44): Loss/seq after 00550 batchs: 1163.4915771484375
INFO:root:Train (Epoch 44): Loss/seq after 00600 batchs: 1129.5859375
INFO:root:Train (Epoch 44): Loss/seq after 00650 batchs: 1139.4534912109375
INFO:root:Train (Epoch 44): Loss/seq after 00700 batchs: 1120.8681640625
INFO:root:Train (Epoch 44): Loss/seq after 00750 batchs: 1155.0355224609375
INFO:root:Train (Epoch 44): Loss/seq after 00800 batchs: 1151.859130859375
INFO:root:Train (Epoch 44): Loss/seq after 00850 batchs: 1123.5406494140625
INFO:root:Train (Epoch 44): Loss/seq after 00900 batchs: 1121.7247314453125
INFO:root:Train (Epoch 44): Loss/seq after 00950 batchs: 1136.9764404296875
INFO:root:Train (Epoch 44): Loss/seq after 01000 batchs: 1131.5244140625
INFO:root:Train (Epoch 44): Loss/seq after 01050 batchs: 1110.4677734375
INFO:root:Train (Epoch 44): Loss/seq after 01100 batchs: 1104.46875
INFO:root:Train (Epoch 44): Loss/seq after 01150 batchs: 1087.174560546875
INFO:root:Train (Epoch 44): Loss/seq after 01200 batchs: 1083.0965576171875
INFO:root:Train (Epoch 44): Loss/seq after 01250 batchs: 1079.2320556640625
INFO:root:Train (Epoch 44): Loss/seq after 01300 batchs: 1078.69384765625
INFO:root:Train (Epoch 44): Loss/seq after 01350 batchs: 1079.773193359375
INFO:root:Train (Epoch 44): Loss/seq after 01400 batchs: 1094.2391357421875
INFO:root:Train (Epoch 44): Loss/seq after 01450 batchs: 1089.769775390625
INFO:root:Train (Epoch 44): Loss/seq after 01500 batchs: 1086.967041015625
INFO:root:Train (Epoch 44): Loss/seq after 01550 batchs: 1090.1544189453125
INFO:root:Train (Epoch 44): Loss/seq after 01600 batchs: 1079.7322998046875
INFO:root:Train (Epoch 44): Loss/seq after 01650 batchs: 1074.3841552734375
INFO:root:Train (Epoch 44): Loss/seq after 01700 batchs: 1069.597900390625
INFO:root:Train (Epoch 44): Loss/seq after 01750 batchs: 1062.184814453125
INFO:root:Train (Epoch 44): Loss/seq after 01800 batchs: 1053.095703125
INFO:root:Train (Epoch 44): Loss/seq after 01850 batchs: 1043.281982421875
INFO:root:Train (Epoch 44): Loss/seq after 01900 batchs: 1044.0916748046875
INFO:root:Train (Epoch 44): Loss/seq after 01950 batchs: 1040.1934814453125
INFO:root:Train (Epoch 44): Loss/seq after 02000 batchs: 1034.9285888671875
INFO:root:Train (Epoch 44): Loss/seq after 02050 batchs: 1029.8465576171875
INFO:root:Train (Epoch 44): Loss/seq after 02100 batchs: 1021.8347778320312
INFO:root:Train (Epoch 44): Loss/seq after 02150 batchs: 1014.76025390625
INFO:root:Train (Epoch 44): Loss/seq after 02200 batchs: 1007.1484375
INFO:root:Train (Epoch 44): Loss/seq after 02250 batchs: 1008.5247802734375
INFO:root:Train (Epoch 44): Loss/seq after 02300 batchs: 1015.3627319335938
INFO:root:Train (Epoch 44): Loss/seq after 02350 batchs: 1007.6895141601562
INFO:root:Train (Epoch 44): Loss/seq after 02400 batchs: 1005.2035522460938
INFO:root:Train (Epoch 44): Loss/seq after 02450 batchs: 995.5673217773438
INFO:root:Train (Epoch 44): Loss/seq after 02500 batchs: 981.437255859375
INFO:root:Train (Epoch 44): Loss/seq after 02550 batchs: 971.7284545898438
INFO:root:Train (Epoch 44): Loss/seq after 02600 batchs: 969.89697265625
INFO:root:Train (Epoch 44): Loss/seq after 02650 batchs: 966.15966796875
INFO:root:Train (Epoch 44): Loss/seq after 02700 batchs: 963.3939819335938
INFO:root:Train (Epoch 44): Loss/seq after 02750 batchs: 992.3903198242188
INFO:root:Train (Epoch 44): Loss/seq after 02800 batchs: 997.4360961914062
INFO:root:Train (Epoch 44): Loss/seq after 02850 batchs: 994.6726684570312
INFO:root:Train (Epoch 44): Loss/seq after 02900 batchs: 993.7686767578125
INFO:root:Train (Epoch 44): Loss/seq after 02950 batchs: 988.3368530273438
INFO:root:Train (Epoch 44): Loss/seq after 03000 batchs: 989.157470703125
INFO:root:Train (Epoch 44): Loss/seq after 03050 batchs: 993.5839233398438
INFO:root:Train (Epoch 44): Loss/seq after 03100 batchs: 1000.9906005859375
INFO:root:Train (Epoch 44): Loss/seq after 03150 batchs: 1005.62841796875
INFO:root:Train (Epoch 44): Loss/seq after 03200 batchs: 1012.1041870117188
INFO:root:Train (Epoch 44): Loss/seq after 03250 batchs: 1015.0633544921875
INFO:root:Train (Epoch 44): Loss/seq after 03300 batchs: 1015.3070068359375
INFO:root:Train (Epoch 44): Loss/seq after 03350 batchs: 1015.376953125
INFO:root:Train (Epoch 44): Loss/seq after 03400 batchs: 1008.0135498046875
INFO:root:Train (Epoch 44): Loss/seq after 03450 batchs: 1003.1400146484375
INFO:root:Train (Epoch 44): Loss/seq after 03500 batchs: 1004.1941528320312
INFO:root:Train (Epoch 44): Loss/seq after 03550 batchs: 1000.1624755859375
INFO:root:Train (Epoch 44): Loss/seq after 03600 batchs: 1007.4432373046875
INFO:root:Train (Epoch 44): Loss/seq after 03650 batchs: 1002.9743041992188
INFO:root:Train (Epoch 44): Loss/seq after 03700 batchs: 1002.8944702148438
INFO:root:Train (Epoch 44): Loss/seq after 03750 batchs: 1005.2763671875
INFO:root:Train (Epoch 44): Loss/seq after 03800 batchs: 999.9324340820312
INFO:root:Train (Epoch 44): Loss/seq after 03850 batchs: 997.3339233398438
INFO:root:Train (Epoch 44): Loss/seq after 03900 batchs: 1001.3237915039062
INFO:root:Train (Epoch 44): Loss/seq after 03950 batchs: 1005.0531616210938
INFO:root:Train (Epoch 44): Loss/seq after 04000 batchs: 998.5669555664062
INFO:root:Train (Epoch 44): Loss/seq after 04050 batchs: 992.1754760742188
INFO:root:Train (Epoch 44): Loss/seq after 04100 batchs: 987.7313232421875
INFO:root:Train (Epoch 44): Loss/seq after 04150 batchs: 984.1997680664062
INFO:root:Train (Epoch 44): Loss/seq after 04200 batchs: 980.3360595703125
INFO:root:Train (Epoch 44): Loss/seq after 04250 batchs: 977.3350219726562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 44): Loss/seq after 00000 batches: 728.1004028320312
INFO:root:# Valid (Epoch 44): Loss/seq after 00050 batches: 951.8175048828125
INFO:root:# Valid (Epoch 44): Loss/seq after 00100 batches: 1232.2244873046875
INFO:root:# Valid (Epoch 44): Loss/seq after 00150 batches: 970.5299072265625
INFO:root:# Valid (Epoch 44): Loss/seq after 00200 batches: 886.4636840820312
INFO:root:Artifacts: Make stick videos for epoch 44
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_44_on_20220412_222819.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_44_index_1240_on_20220412_222819.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 45): Loss/seq after 00000 batchs: 1553.677978515625
INFO:root:Train (Epoch 45): Loss/seq after 00050 batchs: 1185.1234130859375
INFO:root:Train (Epoch 45): Loss/seq after 00100 batchs: 1203.75537109375
INFO:root:Train (Epoch 45): Loss/seq after 00150 batchs: 1102.6383056640625
INFO:root:Train (Epoch 45): Loss/seq after 00200 batchs: 1220.1292724609375
INFO:root:Train (Epoch 45): Loss/seq after 00250 batchs: 1352.2725830078125
INFO:root:Train (Epoch 45): Loss/seq after 00300 batchs: 1301.917724609375
INFO:root:Train (Epoch 45): Loss/seq after 00350 batchs: 1216.6640625
INFO:root:Train (Epoch 45): Loss/seq after 00400 batchs: 1240.699951171875
INFO:root:Train (Epoch 45): Loss/seq after 00450 batchs: 1197.628173828125
INFO:root:Train (Epoch 45): Loss/seq after 00500 batchs: 1186.031005859375
INFO:root:Train (Epoch 45): Loss/seq after 00550 batchs: 1144.0892333984375
INFO:root:Train (Epoch 45): Loss/seq after 00600 batchs: 1110.2113037109375
INFO:root:Train (Epoch 45): Loss/seq after 00650 batchs: 1125.290283203125
INFO:root:Train (Epoch 45): Loss/seq after 00700 batchs: 1106.60107421875
INFO:root:Train (Epoch 45): Loss/seq after 00750 batchs: 1137.9207763671875
INFO:root:Train (Epoch 45): Loss/seq after 00800 batchs: 1134.604248046875
INFO:root:Train (Epoch 45): Loss/seq after 00850 batchs: 1107.847412109375
INFO:root:Train (Epoch 45): Loss/seq after 00900 batchs: 1104.6072998046875
INFO:root:Train (Epoch 45): Loss/seq after 00950 batchs: 1120.9111328125
INFO:root:Train (Epoch 45): Loss/seq after 01000 batchs: 1114.2000732421875
INFO:root:Train (Epoch 45): Loss/seq after 01050 batchs: 1096.44482421875
INFO:root:Train (Epoch 45): Loss/seq after 01100 batchs: 1088.6251220703125
INFO:root:Train (Epoch 45): Loss/seq after 01150 batchs: 1070.0567626953125
INFO:root:Train (Epoch 45): Loss/seq after 01200 batchs: 1065.980224609375
INFO:root:Train (Epoch 45): Loss/seq after 01250 batchs: 1060.917724609375
INFO:root:Train (Epoch 45): Loss/seq after 01300 batchs: 1061.0648193359375
INFO:root:Train (Epoch 45): Loss/seq after 01350 batchs: 1062.2178955078125
INFO:root:Train (Epoch 45): Loss/seq after 01400 batchs: 1079.2381591796875
INFO:root:Train (Epoch 45): Loss/seq after 01450 batchs: 1076.5758056640625
INFO:root:Train (Epoch 45): Loss/seq after 01500 batchs: 1073.989990234375
INFO:root:Train (Epoch 45): Loss/seq after 01550 batchs: 1076.3525390625
INFO:root:Train (Epoch 45): Loss/seq after 01600 batchs: 1065.319091796875
INFO:root:Train (Epoch 45): Loss/seq after 01650 batchs: 1058.2861328125
INFO:root:Train (Epoch 45): Loss/seq after 01700 batchs: 1053.5831298828125
INFO:root:Train (Epoch 45): Loss/seq after 01750 batchs: 1046.7529296875
INFO:root:Train (Epoch 45): Loss/seq after 01800 batchs: 1037.6649169921875
INFO:root:Train (Epoch 45): Loss/seq after 01850 batchs: 1028.4107666015625
INFO:root:Train (Epoch 45): Loss/seq after 01900 batchs: 1029.6583251953125
INFO:root:Train (Epoch 45): Loss/seq after 01950 batchs: 1025.9525146484375
INFO:root:Train (Epoch 45): Loss/seq after 02000 batchs: 1020.8982543945312
INFO:root:Train (Epoch 45): Loss/seq after 02050 batchs: 1016.3328857421875
INFO:root:Train (Epoch 45): Loss/seq after 02100 batchs: 1008.4614868164062
INFO:root:Train (Epoch 45): Loss/seq after 02150 batchs: 1001.7369995117188
INFO:root:Train (Epoch 45): Loss/seq after 02200 batchs: 994.1651611328125
INFO:root:Train (Epoch 45): Loss/seq after 02250 batchs: 994.7863159179688
INFO:root:Train (Epoch 45): Loss/seq after 02300 batchs: 1001.1778564453125
INFO:root:Train (Epoch 45): Loss/seq after 02350 batchs: 993.4105834960938
INFO:root:Train (Epoch 45): Loss/seq after 02400 batchs: 990.69970703125
INFO:root:Train (Epoch 45): Loss/seq after 02450 batchs: 981.1898193359375
INFO:root:Train (Epoch 45): Loss/seq after 02500 batchs: 967.4246215820312
INFO:root:Train (Epoch 45): Loss/seq after 02550 batchs: 957.6336669921875
INFO:root:Train (Epoch 45): Loss/seq after 02600 batchs: 956.0634155273438
INFO:root:Train (Epoch 45): Loss/seq after 02650 batchs: 952.8756103515625
INFO:root:Train (Epoch 45): Loss/seq after 02700 batchs: 949.9616088867188
INFO:root:Train (Epoch 45): Loss/seq after 02750 batchs: 977.4027099609375
INFO:root:Train (Epoch 45): Loss/seq after 02800 batchs: 982.0376586914062
INFO:root:Train (Epoch 45): Loss/seq after 02850 batchs: 979.3115844726562
INFO:root:Train (Epoch 45): Loss/seq after 02900 batchs: 979.2724609375
INFO:root:Train (Epoch 45): Loss/seq after 02950 batchs: 974.0825805664062
INFO:root:Train (Epoch 45): Loss/seq after 03000 batchs: 975.0166625976562
INFO:root:Train (Epoch 45): Loss/seq after 03050 batchs: 979.8929443359375
INFO:root:Train (Epoch 45): Loss/seq after 03100 batchs: 986.7086181640625
INFO:root:Train (Epoch 45): Loss/seq after 03150 batchs: 990.0592041015625
INFO:root:Train (Epoch 45): Loss/seq after 03200 batchs: 996.7775268554688
INFO:root:Train (Epoch 45): Loss/seq after 03250 batchs: 1000.0086669921875
INFO:root:Train (Epoch 45): Loss/seq after 03300 batchs: 998.4539794921875
INFO:root:Train (Epoch 45): Loss/seq after 03350 batchs: 998.8859252929688
INFO:root:Train (Epoch 45): Loss/seq after 03400 batchs: 992.1881713867188
INFO:root:Train (Epoch 45): Loss/seq after 03450 batchs: 987.1777954101562
INFO:root:Train (Epoch 45): Loss/seq after 03500 batchs: 987.0133056640625
INFO:root:Train (Epoch 45): Loss/seq after 03550 batchs: 982.1002197265625
INFO:root:Train (Epoch 45): Loss/seq after 03600 batchs: 989.8904418945312
INFO:root:Train (Epoch 45): Loss/seq after 03650 batchs: 985.3284301757812
INFO:root:Train (Epoch 45): Loss/seq after 03700 batchs: 985.2681884765625
INFO:root:Train (Epoch 45): Loss/seq after 03750 batchs: 987.8638916015625
INFO:root:Train (Epoch 45): Loss/seq after 03800 batchs: 982.6806640625
INFO:root:Train (Epoch 45): Loss/seq after 03850 batchs: 980.2218627929688
INFO:root:Train (Epoch 45): Loss/seq after 03900 batchs: 984.8840942382812
INFO:root:Train (Epoch 45): Loss/seq after 03950 batchs: 989.5059814453125
INFO:root:Train (Epoch 45): Loss/seq after 04000 batchs: 983.2142944335938
INFO:root:Train (Epoch 45): Loss/seq after 04050 batchs: 977.2333984375
INFO:root:Train (Epoch 45): Loss/seq after 04100 batchs: 972.9276123046875
INFO:root:Train (Epoch 45): Loss/seq after 04150 batchs: 969.4139404296875
INFO:root:Train (Epoch 45): Loss/seq after 04200 batchs: 965.7207641601562
INFO:root:Train (Epoch 45): Loss/seq after 04250 batchs: 962.7015991210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 45): Loss/seq after 00000 batches: 701.3595581054688
INFO:root:# Valid (Epoch 45): Loss/seq after 00050 batches: 938.4545288085938
INFO:root:# Valid (Epoch 45): Loss/seq after 00100 batches: 1222.3792724609375
INFO:root:# Valid (Epoch 45): Loss/seq after 00150 batches: 964.0518188476562
INFO:root:# Valid (Epoch 45): Loss/seq after 00200 batches: 879.2982788085938
INFO:root:Artifacts: Make stick videos for epoch 45
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_45_on_20220412_223340.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_45_index_617_on_20220412_223340.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 46): Loss/seq after 00000 batchs: 1597.75927734375
INFO:root:Train (Epoch 46): Loss/seq after 00050 batchs: 1220.973876953125
INFO:root:Train (Epoch 46): Loss/seq after 00100 batchs: 1262.59423828125
INFO:root:Train (Epoch 46): Loss/seq after 00150 batchs: 1142.531494140625
INFO:root:Train (Epoch 46): Loss/seq after 00200 batchs: 1272.72412109375
INFO:root:Train (Epoch 46): Loss/seq after 00250 batchs: 1381.765869140625
INFO:root:Train (Epoch 46): Loss/seq after 00300 batchs: 1328.6097412109375
INFO:root:Train (Epoch 46): Loss/seq after 00350 batchs: 1240.514404296875
INFO:root:Train (Epoch 46): Loss/seq after 00400 batchs: 1263.472412109375
INFO:root:Train (Epoch 46): Loss/seq after 00450 batchs: 1218.0001220703125
INFO:root:Train (Epoch 46): Loss/seq after 00500 batchs: 1212.605712890625
INFO:root:Train (Epoch 46): Loss/seq after 00550 batchs: 1167.0244140625
INFO:root:Train (Epoch 46): Loss/seq after 00600 batchs: 1133.52001953125
INFO:root:Train (Epoch 46): Loss/seq after 00650 batchs: 1147.8135986328125
INFO:root:Train (Epoch 46): Loss/seq after 00700 batchs: 1128.26220703125
INFO:root:Train (Epoch 46): Loss/seq after 00750 batchs: 1160.065673828125
INFO:root:Train (Epoch 46): Loss/seq after 00800 batchs: 1153.7816162109375
INFO:root:Train (Epoch 46): Loss/seq after 00850 batchs: 1124.4761962890625
INFO:root:Train (Epoch 46): Loss/seq after 00900 batchs: 1120.7142333984375
INFO:root:Train (Epoch 46): Loss/seq after 00950 batchs: 1134.9254150390625
INFO:root:Train (Epoch 46): Loss/seq after 01000 batchs: 1128.0872802734375
INFO:root:Train (Epoch 46): Loss/seq after 01050 batchs: 1107.894775390625
INFO:root:Train (Epoch 46): Loss/seq after 01100 batchs: 1098.2586669921875
INFO:root:Train (Epoch 46): Loss/seq after 01150 batchs: 1079.7733154296875
INFO:root:Train (Epoch 46): Loss/seq after 01200 batchs: 1075.3189697265625
INFO:root:Train (Epoch 46): Loss/seq after 01250 batchs: 1069.92724609375
INFO:root:Train (Epoch 46): Loss/seq after 01300 batchs: 1071.263427734375
INFO:root:Train (Epoch 46): Loss/seq after 01350 batchs: 1073.9757080078125
INFO:root:Train (Epoch 46): Loss/seq after 01400 batchs: 1089.15234375
INFO:root:Train (Epoch 46): Loss/seq after 01450 batchs: 1085.4227294921875
INFO:root:Train (Epoch 46): Loss/seq after 01500 batchs: 1082.7491455078125
INFO:root:Train (Epoch 46): Loss/seq after 01550 batchs: 1084.439208984375
INFO:root:Train (Epoch 46): Loss/seq after 01600 batchs: 1073.20263671875
INFO:root:Train (Epoch 46): Loss/seq after 01650 batchs: 1064.6717529296875
INFO:root:Train (Epoch 46): Loss/seq after 01700 batchs: 1059.3759765625
INFO:root:Train (Epoch 46): Loss/seq after 01750 batchs: 1051.611328125
INFO:root:Train (Epoch 46): Loss/seq after 01800 batchs: 1042.02880859375
INFO:root:Train (Epoch 46): Loss/seq after 01850 batchs: 1031.9132080078125
INFO:root:Train (Epoch 46): Loss/seq after 01900 batchs: 1033.0848388671875
INFO:root:Train (Epoch 46): Loss/seq after 01950 batchs: 1028.003173828125
INFO:root:Train (Epoch 46): Loss/seq after 02000 batchs: 1023.0653686523438
INFO:root:Train (Epoch 46): Loss/seq after 02050 batchs: 1018.2103881835938
INFO:root:Train (Epoch 46): Loss/seq after 02100 batchs: 1010.3895874023438
INFO:root:Train (Epoch 46): Loss/seq after 02150 batchs: 1003.6627197265625
INFO:root:Train (Epoch 46): Loss/seq after 02200 batchs: 996.2613525390625
INFO:root:Train (Epoch 46): Loss/seq after 02250 batchs: 996.3314208984375
INFO:root:Train (Epoch 46): Loss/seq after 02300 batchs: 1002.8973388671875
INFO:root:Train (Epoch 46): Loss/seq after 02350 batchs: 995.2037353515625
INFO:root:Train (Epoch 46): Loss/seq after 02400 batchs: 992.3877563476562
INFO:root:Train (Epoch 46): Loss/seq after 02450 batchs: 982.6881713867188
INFO:root:Train (Epoch 46): Loss/seq after 02500 batchs: 968.6867065429688
INFO:root:Train (Epoch 46): Loss/seq after 02550 batchs: 958.9977416992188
INFO:root:Train (Epoch 46): Loss/seq after 02600 batchs: 956.9169311523438
INFO:root:Train (Epoch 46): Loss/seq after 02650 batchs: 952.753173828125
INFO:root:Train (Epoch 46): Loss/seq after 02700 batchs: 950.0164184570312
INFO:root:Train (Epoch 46): Loss/seq after 02750 batchs: 977.9789428710938
INFO:root:Train (Epoch 46): Loss/seq after 02800 batchs: 983.1310424804688
INFO:root:Train (Epoch 46): Loss/seq after 02850 batchs: 980.4298706054688
INFO:root:Train (Epoch 46): Loss/seq after 02900 batchs: 979.71142578125
INFO:root:Train (Epoch 46): Loss/seq after 02950 batchs: 974.3267822265625
INFO:root:Train (Epoch 46): Loss/seq after 03000 batchs: 975.3777465820312
INFO:root:Train (Epoch 46): Loss/seq after 03050 batchs: 979.8312377929688
INFO:root:Train (Epoch 46): Loss/seq after 03100 batchs: 986.3759155273438
INFO:root:Train (Epoch 46): Loss/seq after 03150 batchs: 991.1226196289062
INFO:root:Train (Epoch 46): Loss/seq after 03200 batchs: 998.1155395507812
INFO:root:Train (Epoch 46): Loss/seq after 03250 batchs: 1000.8831176757812
INFO:root:Train (Epoch 46): Loss/seq after 03300 batchs: 999.350830078125
INFO:root:Train (Epoch 46): Loss/seq after 03350 batchs: 999.181884765625
INFO:root:Train (Epoch 46): Loss/seq after 03400 batchs: 992.41796875
INFO:root:Train (Epoch 46): Loss/seq after 03450 batchs: 987.2327880859375
INFO:root:Train (Epoch 46): Loss/seq after 03500 batchs: 986.3770141601562
INFO:root:Train (Epoch 46): Loss/seq after 03550 batchs: 981.4397583007812
INFO:root:Train (Epoch 46): Loss/seq after 03600 batchs: 988.4854736328125
INFO:root:Train (Epoch 46): Loss/seq after 03650 batchs: 984.227294921875
INFO:root:Train (Epoch 46): Loss/seq after 03700 batchs: 984.328857421875
INFO:root:Train (Epoch 46): Loss/seq after 03750 batchs: 986.8883056640625
INFO:root:Train (Epoch 46): Loss/seq after 03800 batchs: 981.7403564453125
INFO:root:Train (Epoch 46): Loss/seq after 03850 batchs: 979.11962890625
INFO:root:Train (Epoch 46): Loss/seq after 03900 batchs: 983.43017578125
INFO:root:Train (Epoch 46): Loss/seq after 03950 batchs: 987.7048950195312
INFO:root:Train (Epoch 46): Loss/seq after 04000 batchs: 981.4004516601562
INFO:root:Train (Epoch 46): Loss/seq after 04050 batchs: 975.4396362304688
INFO:root:Train (Epoch 46): Loss/seq after 04100 batchs: 971.308837890625
INFO:root:Train (Epoch 46): Loss/seq after 04150 batchs: 967.91015625
INFO:root:Train (Epoch 46): Loss/seq after 04200 batchs: 964.4393920898438
INFO:root:Train (Epoch 46): Loss/seq after 04250 batchs: 961.7394409179688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 46): Loss/seq after 00000 batches: 864.9700317382812
INFO:root:# Valid (Epoch 46): Loss/seq after 00050 batches: 935.2844848632812
INFO:root:# Valid (Epoch 46): Loss/seq after 00100 batches: 1229.859619140625
INFO:root:# Valid (Epoch 46): Loss/seq after 00150 batches: 972.7402954101562
INFO:root:# Valid (Epoch 46): Loss/seq after 00200 batches: 887.1548461914062
INFO:root:Artifacts: Make stick videos for epoch 46
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_46_on_20220412_223902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_46_index_201_on_20220412_223902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 47): Loss/seq after 00000 batchs: 1747.6512451171875
INFO:root:Train (Epoch 47): Loss/seq after 00050 batchs: 1218.673583984375
INFO:root:Train (Epoch 47): Loss/seq after 00100 batchs: 1298.9339599609375
INFO:root:Train (Epoch 47): Loss/seq after 00150 batchs: 1185.87060546875
INFO:root:Train (Epoch 47): Loss/seq after 00200 batchs: 1302.6524658203125
INFO:root:Train (Epoch 47): Loss/seq after 00250 batchs: 1420.8792724609375
INFO:root:Train (Epoch 47): Loss/seq after 00300 batchs: 1360.0726318359375
INFO:root:Train (Epoch 47): Loss/seq after 00350 batchs: 1268.3812255859375
INFO:root:Train (Epoch 47): Loss/seq after 00400 batchs: 1297.5780029296875
INFO:root:Train (Epoch 47): Loss/seq after 00450 batchs: 1248.3277587890625
INFO:root:Train (Epoch 47): Loss/seq after 00500 batchs: 1237.59912109375
INFO:root:Train (Epoch 47): Loss/seq after 00550 batchs: 1189.7403564453125
INFO:root:Train (Epoch 47): Loss/seq after 00600 batchs: 1151.5079345703125
INFO:root:Train (Epoch 47): Loss/seq after 00650 batchs: 1161.8271484375
INFO:root:Train (Epoch 47): Loss/seq after 00700 batchs: 1144.7108154296875
INFO:root:Train (Epoch 47): Loss/seq after 00750 batchs: 1181.37841796875
INFO:root:Train (Epoch 47): Loss/seq after 00800 batchs: 1175.190673828125
INFO:root:Train (Epoch 47): Loss/seq after 00850 batchs: 1146.5167236328125
INFO:root:Train (Epoch 47): Loss/seq after 00900 batchs: 1143.302978515625
INFO:root:Train (Epoch 47): Loss/seq after 00950 batchs: 1158.8851318359375
INFO:root:Train (Epoch 47): Loss/seq after 01000 batchs: 1152.523681640625
INFO:root:Train (Epoch 47): Loss/seq after 01050 batchs: 1132.44775390625
INFO:root:Train (Epoch 47): Loss/seq after 01100 batchs: 1118.48046875
INFO:root:Train (Epoch 47): Loss/seq after 01150 batchs: 1099.302001953125
INFO:root:Train (Epoch 47): Loss/seq after 01200 batchs: 1093.954345703125
INFO:root:Train (Epoch 47): Loss/seq after 01250 batchs: 1088.384521484375
INFO:root:Train (Epoch 47): Loss/seq after 01300 batchs: 1086.81201171875
INFO:root:Train (Epoch 47): Loss/seq after 01350 batchs: 1085.8251953125
INFO:root:Train (Epoch 47): Loss/seq after 01400 batchs: 1100.8909912109375
INFO:root:Train (Epoch 47): Loss/seq after 01450 batchs: 1095.85400390625
INFO:root:Train (Epoch 47): Loss/seq after 01500 batchs: 1092.7896728515625
INFO:root:Train (Epoch 47): Loss/seq after 01550 batchs: 1093.826171875
INFO:root:Train (Epoch 47): Loss/seq after 01600 batchs: 1082.331298828125
INFO:root:Train (Epoch 47): Loss/seq after 01650 batchs: 1074.8642578125
INFO:root:Train (Epoch 47): Loss/seq after 01700 batchs: 1069.746826171875
INFO:root:Train (Epoch 47): Loss/seq after 01750 batchs: 1062.39208984375
INFO:root:Train (Epoch 47): Loss/seq after 01800 batchs: 1052.7742919921875
INFO:root:Train (Epoch 47): Loss/seq after 01850 batchs: 1042.5633544921875
INFO:root:Train (Epoch 47): Loss/seq after 01900 batchs: 1042.9976806640625
INFO:root:Train (Epoch 47): Loss/seq after 01950 batchs: 1037.0155029296875
INFO:root:Train (Epoch 47): Loss/seq after 02000 batchs: 1031.6025390625
INFO:root:Train (Epoch 47): Loss/seq after 02050 batchs: 1026.3736572265625
INFO:root:Train (Epoch 47): Loss/seq after 02100 batchs: 1018.8543701171875
INFO:root:Train (Epoch 47): Loss/seq after 02150 batchs: 1011.9849853515625
INFO:root:Train (Epoch 47): Loss/seq after 02200 batchs: 1004.1442260742188
INFO:root:Train (Epoch 47): Loss/seq after 02250 batchs: 1005.2969970703125
INFO:root:Train (Epoch 47): Loss/seq after 02300 batchs: 1011.7217407226562
INFO:root:Train (Epoch 47): Loss/seq after 02350 batchs: 1004.3450317382812
INFO:root:Train (Epoch 47): Loss/seq after 02400 batchs: 1001.9368896484375
INFO:root:Train (Epoch 47): Loss/seq after 02450 batchs: 992.299072265625
INFO:root:Train (Epoch 47): Loss/seq after 02500 batchs: 977.8948364257812
INFO:root:Train (Epoch 47): Loss/seq after 02550 batchs: 967.6906127929688
INFO:root:Train (Epoch 47): Loss/seq after 02600 batchs: 965.7734375
INFO:root:Train (Epoch 47): Loss/seq after 02650 batchs: 961.7173461914062
INFO:root:Train (Epoch 47): Loss/seq after 02700 batchs: 958.3528442382812
INFO:root:Train (Epoch 47): Loss/seq after 02750 batchs: 986.6893310546875
INFO:root:Train (Epoch 47): Loss/seq after 02800 batchs: 990.851318359375
INFO:root:Train (Epoch 47): Loss/seq after 02850 batchs: 987.677734375
INFO:root:Train (Epoch 47): Loss/seq after 02900 batchs: 986.8433837890625
INFO:root:Train (Epoch 47): Loss/seq after 02950 batchs: 981.5366821289062
INFO:root:Train (Epoch 47): Loss/seq after 03000 batchs: 982.4172973632812
INFO:root:Train (Epoch 47): Loss/seq after 03050 batchs: 986.6323852539062
INFO:root:Train (Epoch 47): Loss/seq after 03100 batchs: 993.4102172851562
INFO:root:Train (Epoch 47): Loss/seq after 03150 batchs: 997.5172119140625
INFO:root:Train (Epoch 47): Loss/seq after 03200 batchs: 1003.6290893554688
INFO:root:Train (Epoch 47): Loss/seq after 03250 batchs: 1006.5874633789062
INFO:root:Train (Epoch 47): Loss/seq after 03300 batchs: 1004.3578491210938
INFO:root:Train (Epoch 47): Loss/seq after 03350 batchs: 1004.6695556640625
INFO:root:Train (Epoch 47): Loss/seq after 03400 batchs: 997.5133666992188
INFO:root:Train (Epoch 47): Loss/seq after 03450 batchs: 992.1207885742188
INFO:root:Train (Epoch 47): Loss/seq after 03500 batchs: 991.2238159179688
INFO:root:Train (Epoch 47): Loss/seq after 03550 batchs: 986.1967163085938
INFO:root:Train (Epoch 47): Loss/seq after 03600 batchs: 993.3473510742188
INFO:root:Train (Epoch 47): Loss/seq after 03650 batchs: 988.8582763671875
INFO:root:Train (Epoch 47): Loss/seq after 03700 batchs: 990.0762329101562
INFO:root:Train (Epoch 47): Loss/seq after 03750 batchs: 992.63427734375
INFO:root:Train (Epoch 47): Loss/seq after 03800 batchs: 987.4168701171875
INFO:root:Train (Epoch 47): Loss/seq after 03850 batchs: 984.9593505859375
INFO:root:Train (Epoch 47): Loss/seq after 03900 batchs: 988.6864013671875
INFO:root:Train (Epoch 47): Loss/seq after 03950 batchs: 992.495361328125
INFO:root:Train (Epoch 47): Loss/seq after 04000 batchs: 986.1463012695312
INFO:root:Train (Epoch 47): Loss/seq after 04050 batchs: 980.094970703125
INFO:root:Train (Epoch 47): Loss/seq after 04100 batchs: 975.6658935546875
INFO:root:Train (Epoch 47): Loss/seq after 04150 batchs: 972.21875
INFO:root:Train (Epoch 47): Loss/seq after 04200 batchs: 968.6433715820312
INFO:root:Train (Epoch 47): Loss/seq after 04250 batchs: 965.6497192382812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 47): Loss/seq after 00000 batches: 871.4096069335938
INFO:root:# Valid (Epoch 47): Loss/seq after 00050 batches: 941.5631713867188
INFO:root:# Valid (Epoch 47): Loss/seq after 00100 batches: 1244.844970703125
INFO:root:# Valid (Epoch 47): Loss/seq after 00150 batches: 1004.8831787109375
INFO:root:# Valid (Epoch 47): Loss/seq after 00200 batches: 931.532470703125
INFO:root:Artifacts: Make stick videos for epoch 47
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_47_on_20220412_224425.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_47_index_859_on_20220412_224425.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 48): Loss/seq after 00000 batchs: 1729.3177490234375
INFO:root:Train (Epoch 48): Loss/seq after 00050 batchs: 1196.766357421875
INFO:root:Train (Epoch 48): Loss/seq after 00100 batchs: 1236.4498291015625
INFO:root:Train (Epoch 48): Loss/seq after 00150 batchs: 1121.6055908203125
INFO:root:Train (Epoch 48): Loss/seq after 00200 batchs: 1235.0028076171875
INFO:root:Train (Epoch 48): Loss/seq after 00250 batchs: 1366.0924072265625
INFO:root:Train (Epoch 48): Loss/seq after 00300 batchs: 1315.0654296875
INFO:root:Train (Epoch 48): Loss/seq after 00350 batchs: 1228.630859375
INFO:root:Train (Epoch 48): Loss/seq after 00400 batchs: 1249.90625
INFO:root:Train (Epoch 48): Loss/seq after 00450 batchs: 1206.0479736328125
INFO:root:Train (Epoch 48): Loss/seq after 00500 batchs: 1202.8900146484375
INFO:root:Train (Epoch 48): Loss/seq after 00550 batchs: 1159.4332275390625
INFO:root:Train (Epoch 48): Loss/seq after 00600 batchs: 1124.912353515625
INFO:root:Train (Epoch 48): Loss/seq after 00650 batchs: 1134.9810791015625
INFO:root:Train (Epoch 48): Loss/seq after 00700 batchs: 1115.8309326171875
INFO:root:Train (Epoch 48): Loss/seq after 00750 batchs: 1146.7139892578125
INFO:root:Train (Epoch 48): Loss/seq after 00800 batchs: 1141.2039794921875
INFO:root:Train (Epoch 48): Loss/seq after 00850 batchs: 1113.9140625
INFO:root:Train (Epoch 48): Loss/seq after 00900 batchs: 1109.0872802734375
INFO:root:Train (Epoch 48): Loss/seq after 00950 batchs: 1121.5225830078125
INFO:root:Train (Epoch 48): Loss/seq after 01000 batchs: 1115.8392333984375
INFO:root:Train (Epoch 48): Loss/seq after 01050 batchs: 1102.225341796875
INFO:root:Train (Epoch 48): Loss/seq after 01100 batchs: 1092.5743408203125
INFO:root:Train (Epoch 48): Loss/seq after 01150 batchs: 1075.404296875
INFO:root:Train (Epoch 48): Loss/seq after 01200 batchs: 1071.66796875
INFO:root:Train (Epoch 48): Loss/seq after 01250 batchs: 1068.7808837890625
INFO:root:Train (Epoch 48): Loss/seq after 01300 batchs: 1067.76953125
INFO:root:Train (Epoch 48): Loss/seq after 01350 batchs: 1070.161865234375
INFO:root:Train (Epoch 48): Loss/seq after 01400 batchs: 1086.5096435546875
INFO:root:Train (Epoch 48): Loss/seq after 01450 batchs: 1082.7890625
INFO:root:Train (Epoch 48): Loss/seq after 01500 batchs: 1080.042724609375
INFO:root:Train (Epoch 48): Loss/seq after 01550 batchs: 1082.5787353515625
INFO:root:Train (Epoch 48): Loss/seq after 01600 batchs: 1070.8892822265625
INFO:root:Train (Epoch 48): Loss/seq after 01650 batchs: 1063.0186767578125
INFO:root:Train (Epoch 48): Loss/seq after 01700 batchs: 1057.844482421875
INFO:root:Train (Epoch 48): Loss/seq after 01750 batchs: 1050.4691162109375
INFO:root:Train (Epoch 48): Loss/seq after 01800 batchs: 1041.5382080078125
INFO:root:Train (Epoch 48): Loss/seq after 01850 batchs: 1031.484619140625
INFO:root:Train (Epoch 48): Loss/seq after 01900 batchs: 1031.8084716796875
INFO:root:Train (Epoch 48): Loss/seq after 01950 batchs: 1026.02685546875
INFO:root:Train (Epoch 48): Loss/seq after 02000 batchs: 1020.5597534179688
INFO:root:Train (Epoch 48): Loss/seq after 02050 batchs: 1015.8717041015625
INFO:root:Train (Epoch 48): Loss/seq after 02100 batchs: 1007.633056640625
INFO:root:Train (Epoch 48): Loss/seq after 02150 batchs: 1001.00244140625
INFO:root:Train (Epoch 48): Loss/seq after 02200 batchs: 993.61083984375
INFO:root:Train (Epoch 48): Loss/seq after 02250 batchs: 993.2361450195312
INFO:root:Train (Epoch 48): Loss/seq after 02300 batchs: 999.8040771484375
INFO:root:Train (Epoch 48): Loss/seq after 02350 batchs: 992.4279174804688
INFO:root:Train (Epoch 48): Loss/seq after 02400 batchs: 990.1305541992188
INFO:root:Train (Epoch 48): Loss/seq after 02450 batchs: 981.01416015625
INFO:root:Train (Epoch 48): Loss/seq after 02500 batchs: 967.2540283203125
INFO:root:Train (Epoch 48): Loss/seq after 02550 batchs: 957.2083129882812
INFO:root:Train (Epoch 48): Loss/seq after 02600 batchs: 955.5574951171875
INFO:root:Train (Epoch 48): Loss/seq after 02650 batchs: 951.8572998046875
INFO:root:Train (Epoch 48): Loss/seq after 02700 batchs: 948.3551635742188
INFO:root:Train (Epoch 48): Loss/seq after 02750 batchs: 975.7495727539062
INFO:root:Train (Epoch 48): Loss/seq after 02800 batchs: 981.0908813476562
INFO:root:Train (Epoch 48): Loss/seq after 02850 batchs: 978.8742065429688
INFO:root:Train (Epoch 48): Loss/seq after 02900 batchs: 978.918701171875
INFO:root:Train (Epoch 48): Loss/seq after 02950 batchs: 973.590576171875
INFO:root:Train (Epoch 48): Loss/seq after 03000 batchs: 974.577392578125
INFO:root:Train (Epoch 48): Loss/seq after 03050 batchs: 979.2046508789062
INFO:root:Train (Epoch 48): Loss/seq after 03100 batchs: 986.149658203125
INFO:root:Train (Epoch 48): Loss/seq after 03150 batchs: 989.469482421875
INFO:root:Train (Epoch 48): Loss/seq after 03200 batchs: 995.6648559570312
INFO:root:Train (Epoch 48): Loss/seq after 03250 batchs: 998.20068359375
INFO:root:Train (Epoch 48): Loss/seq after 03300 batchs: 996.149169921875
INFO:root:Train (Epoch 48): Loss/seq after 03350 batchs: 995.5498657226562
INFO:root:Train (Epoch 48): Loss/seq after 03400 batchs: 988.4844970703125
INFO:root:Train (Epoch 48): Loss/seq after 03450 batchs: 983.5153198242188
INFO:root:Train (Epoch 48): Loss/seq after 03500 batchs: 983.1094360351562
INFO:root:Train (Epoch 48): Loss/seq after 03550 batchs: 978.6270141601562
INFO:root:Train (Epoch 48): Loss/seq after 03600 batchs: 986.5614013671875
INFO:root:Train (Epoch 48): Loss/seq after 03650 batchs: 983.050048828125
INFO:root:Train (Epoch 48): Loss/seq after 03700 batchs: 983.8738403320312
INFO:root:Train (Epoch 48): Loss/seq after 03750 batchs: 986.29638671875
INFO:root:Train (Epoch 48): Loss/seq after 03800 batchs: 980.925048828125
INFO:root:Train (Epoch 48): Loss/seq after 03850 batchs: 978.3284301757812
INFO:root:Train (Epoch 48): Loss/seq after 03900 batchs: 981.8151245117188
INFO:root:Train (Epoch 48): Loss/seq after 03950 batchs: 986.1720581054688
INFO:root:Train (Epoch 48): Loss/seq after 04000 batchs: 979.9264526367188
INFO:root:Train (Epoch 48): Loss/seq after 04050 batchs: 974.0849609375
INFO:root:Train (Epoch 48): Loss/seq after 04100 batchs: 969.90966796875
INFO:root:Train (Epoch 48): Loss/seq after 04150 batchs: 966.60205078125
INFO:root:Train (Epoch 48): Loss/seq after 04200 batchs: 963.1787719726562
INFO:root:Train (Epoch 48): Loss/seq after 04250 batchs: 959.9088134765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 48): Loss/seq after 00000 batches: 846.3220825195312
INFO:root:# Valid (Epoch 48): Loss/seq after 00050 batches: 941.552734375
INFO:root:# Valid (Epoch 48): Loss/seq after 00100 batches: 1212.991455078125
INFO:root:# Valid (Epoch 48): Loss/seq after 00150 batches: 958.9025268554688
INFO:root:# Valid (Epoch 48): Loss/seq after 00200 batches: 878.059814453125
INFO:root:Artifacts: Make stick videos for epoch 48
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_48_on_20220412_224947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_48_index_907_on_20220412_224947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 49): Loss/seq after 00000 batchs: 1389.52392578125
INFO:root:Train (Epoch 49): Loss/seq after 00050 batchs: 1192.0460205078125
INFO:root:Train (Epoch 49): Loss/seq after 00100 batchs: 1243.9697265625
INFO:root:Train (Epoch 49): Loss/seq after 00150 batchs: 1137.5550537109375
INFO:root:Train (Epoch 49): Loss/seq after 00200 batchs: 1260.555908203125
INFO:root:Train (Epoch 49): Loss/seq after 00250 batchs: 1370.2879638671875
INFO:root:Train (Epoch 49): Loss/seq after 00300 batchs: 1317.7137451171875
INFO:root:Train (Epoch 49): Loss/seq after 00350 batchs: 1232.5648193359375
INFO:root:Train (Epoch 49): Loss/seq after 00400 batchs: 1250.961669921875
INFO:root:Train (Epoch 49): Loss/seq after 00450 batchs: 1206.967041015625
INFO:root:Train (Epoch 49): Loss/seq after 00500 batchs: 1203.3526611328125
INFO:root:Train (Epoch 49): Loss/seq after 00550 batchs: 1157.68310546875
INFO:root:Train (Epoch 49): Loss/seq after 00600 batchs: 1123.0860595703125
INFO:root:Train (Epoch 49): Loss/seq after 00650 batchs: 1130.285888671875
INFO:root:Train (Epoch 49): Loss/seq after 00700 batchs: 1112.6246337890625
INFO:root:Train (Epoch 49): Loss/seq after 00750 batchs: 1143.5732421875
INFO:root:Train (Epoch 49): Loss/seq after 00800 batchs: 1138.3870849609375
INFO:root:Train (Epoch 49): Loss/seq after 00850 batchs: 1112.6571044921875
INFO:root:Train (Epoch 49): Loss/seq after 00900 batchs: 1104.4249267578125
INFO:root:Train (Epoch 49): Loss/seq after 00950 batchs: 1114.5655517578125
INFO:root:Train (Epoch 49): Loss/seq after 01000 batchs: 1107.9718017578125
INFO:root:Train (Epoch 49): Loss/seq after 01050 batchs: 1090.149658203125
INFO:root:Train (Epoch 49): Loss/seq after 01100 batchs: 1084.968994140625
INFO:root:Train (Epoch 49): Loss/seq after 01150 batchs: 1068.7484130859375
INFO:root:Train (Epoch 49): Loss/seq after 01200 batchs: 1065.62646484375
INFO:root:Train (Epoch 49): Loss/seq after 01250 batchs: 1060.4884033203125
INFO:root:Train (Epoch 49): Loss/seq after 01300 batchs: 1059.4971923828125
INFO:root:Train (Epoch 49): Loss/seq after 01350 batchs: 1062.2757568359375
INFO:root:Train (Epoch 49): Loss/seq after 01400 batchs: 1077.56640625
INFO:root:Train (Epoch 49): Loss/seq after 01450 batchs: 1073.6136474609375
INFO:root:Train (Epoch 49): Loss/seq after 01500 batchs: 1071.396728515625
INFO:root:Train (Epoch 49): Loss/seq after 01550 batchs: 1073.5457763671875
INFO:root:Train (Epoch 49): Loss/seq after 01600 batchs: 1062.603515625
INFO:root:Train (Epoch 49): Loss/seq after 01650 batchs: 1055.1697998046875
INFO:root:Train (Epoch 49): Loss/seq after 01700 batchs: 1050.6290283203125
INFO:root:Train (Epoch 49): Loss/seq after 01750 batchs: 1043.48681640625
INFO:root:Train (Epoch 49): Loss/seq after 01800 batchs: 1034.2479248046875
INFO:root:Train (Epoch 49): Loss/seq after 01850 batchs: 1024.5045166015625
INFO:root:Train (Epoch 49): Loss/seq after 01900 batchs: 1024.9891357421875
INFO:root:Train (Epoch 49): Loss/seq after 01950 batchs: 1019.6661987304688
INFO:root:Train (Epoch 49): Loss/seq after 02000 batchs: 1014.5672607421875
INFO:root:Train (Epoch 49): Loss/seq after 02050 batchs: 1009.5960083007812
INFO:root:Train (Epoch 49): Loss/seq after 02100 batchs: 1002.0064697265625
INFO:root:Train (Epoch 49): Loss/seq after 02150 batchs: 995.5664672851562
INFO:root:Train (Epoch 49): Loss/seq after 02200 batchs: 988.207275390625
INFO:root:Train (Epoch 49): Loss/seq after 02250 batchs: 990.1931762695312
INFO:root:Train (Epoch 49): Loss/seq after 02300 batchs: 997.3855590820312
INFO:root:Train (Epoch 49): Loss/seq after 02350 batchs: 990.73828125
INFO:root:Train (Epoch 49): Loss/seq after 02400 batchs: 988.6588134765625
INFO:root:Train (Epoch 49): Loss/seq after 02450 batchs: 979.3323974609375
INFO:root:Train (Epoch 49): Loss/seq after 02500 batchs: 964.9788818359375
INFO:root:Train (Epoch 49): Loss/seq after 02550 batchs: 955.0760498046875
INFO:root:Train (Epoch 49): Loss/seq after 02600 batchs: 953.355712890625
INFO:root:Train (Epoch 49): Loss/seq after 02650 batchs: 949.8309326171875
INFO:root:Train (Epoch 49): Loss/seq after 02700 batchs: 947.569091796875
INFO:root:Train (Epoch 49): Loss/seq after 02750 batchs: 974.6748657226562
INFO:root:Train (Epoch 49): Loss/seq after 02800 batchs: 979.4642944335938
INFO:root:Train (Epoch 49): Loss/seq after 02850 batchs: 977.0441284179688
INFO:root:Train (Epoch 49): Loss/seq after 02900 batchs: 976.280029296875
INFO:root:Train (Epoch 49): Loss/seq after 02950 batchs: 970.8471069335938
INFO:root:Train (Epoch 49): Loss/seq after 03000 batchs: 972.0230102539062
INFO:root:Train (Epoch 49): Loss/seq after 03050 batchs: 976.9942016601562
INFO:root:Train (Epoch 49): Loss/seq after 03100 batchs: 984.375244140625
INFO:root:Train (Epoch 49): Loss/seq after 03150 batchs: 988.6256103515625
INFO:root:Train (Epoch 49): Loss/seq after 03200 batchs: 994.7452392578125
INFO:root:Train (Epoch 49): Loss/seq after 03250 batchs: 997.865966796875
INFO:root:Train (Epoch 49): Loss/seq after 03300 batchs: 995.8416748046875
INFO:root:Train (Epoch 49): Loss/seq after 03350 batchs: 994.7362670898438
INFO:root:Train (Epoch 49): Loss/seq after 03400 batchs: 988.0750732421875
INFO:root:Train (Epoch 49): Loss/seq after 03450 batchs: 983.0680541992188
INFO:root:Train (Epoch 49): Loss/seq after 03500 batchs: 982.140380859375
INFO:root:Train (Epoch 49): Loss/seq after 03550 batchs: 976.8903198242188
INFO:root:Train (Epoch 49): Loss/seq after 03600 batchs: 984.2247924804688
INFO:root:Train (Epoch 49): Loss/seq after 03650 batchs: 979.7006225585938
INFO:root:Train (Epoch 49): Loss/seq after 03700 batchs: 979.6758422851562
INFO:root:Train (Epoch 49): Loss/seq after 03750 batchs: 982.3323364257812
INFO:root:Train (Epoch 49): Loss/seq after 03800 batchs: 977.2426147460938
INFO:root:Train (Epoch 49): Loss/seq after 03850 batchs: 974.665771484375
INFO:root:Train (Epoch 49): Loss/seq after 03900 batchs: 978.5360717773438
INFO:root:Train (Epoch 49): Loss/seq after 03950 batchs: 982.463623046875
INFO:root:Train (Epoch 49): Loss/seq after 04000 batchs: 976.1580200195312
INFO:root:Train (Epoch 49): Loss/seq after 04050 batchs: 970.0891723632812
INFO:root:Train (Epoch 49): Loss/seq after 04100 batchs: 965.6286010742188
INFO:root:Train (Epoch 49): Loss/seq after 04150 batchs: 962.188232421875
INFO:root:Train (Epoch 49): Loss/seq after 04200 batchs: 958.3831176757812
INFO:root:Train (Epoch 49): Loss/seq after 04250 batchs: 955.2714233398438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 49): Loss/seq after 00000 batches: 628.2913208007812
INFO:root:# Valid (Epoch 49): Loss/seq after 00050 batches: 911.5947265625
INFO:root:# Valid (Epoch 49): Loss/seq after 00100 batches: 1200.0980224609375
INFO:root:# Valid (Epoch 49): Loss/seq after 00150 batches: 958.5913696289062
INFO:root:# Valid (Epoch 49): Loss/seq after 00200 batches: 880.8598022460938
INFO:root:Artifacts: Make stick videos for epoch 49
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_49_on_20220412_225509.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_49_index_576_on_20220412_225509.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 50): Loss/seq after 00000 batchs: 1717.610595703125
INFO:root:Train (Epoch 50): Loss/seq after 00050 batchs: 1218.015625
INFO:root:Train (Epoch 50): Loss/seq after 00100 batchs: 1210.12353515625
INFO:root:Train (Epoch 50): Loss/seq after 00150 batchs: 1101.407470703125
INFO:root:Train (Epoch 50): Loss/seq after 00200 batchs: 1223.7176513671875
INFO:root:Train (Epoch 50): Loss/seq after 00250 batchs: 1353.2984619140625
INFO:root:Train (Epoch 50): Loss/seq after 00300 batchs: 1302.77490234375
INFO:root:Train (Epoch 50): Loss/seq after 00350 batchs: 1216.9036865234375
INFO:root:Train (Epoch 50): Loss/seq after 00400 batchs: 1242.0498046875
INFO:root:Train (Epoch 50): Loss/seq after 00450 batchs: 1199.5966796875
INFO:root:Train (Epoch 50): Loss/seq after 00500 batchs: 1189.37158203125
INFO:root:Train (Epoch 50): Loss/seq after 00550 batchs: 1144.4356689453125
INFO:root:Train (Epoch 50): Loss/seq after 00600 batchs: 1110.8814697265625
INFO:root:Train (Epoch 50): Loss/seq after 00650 batchs: 1118.4671630859375
INFO:root:Train (Epoch 50): Loss/seq after 00700 batchs: 1100.1666259765625
INFO:root:Train (Epoch 50): Loss/seq after 00750 batchs: 1130.74462890625
INFO:root:Train (Epoch 50): Loss/seq after 00800 batchs: 1126.5767822265625
INFO:root:Train (Epoch 50): Loss/seq after 00850 batchs: 1099.57080078125
INFO:root:Train (Epoch 50): Loss/seq after 00900 batchs: 1095.6251220703125
INFO:root:Train (Epoch 50): Loss/seq after 00950 batchs: 1105.6138916015625
INFO:root:Train (Epoch 50): Loss/seq after 01000 batchs: 1098.8682861328125
INFO:root:Train (Epoch 50): Loss/seq after 01050 batchs: 1082.739013671875
INFO:root:Train (Epoch 50): Loss/seq after 01100 batchs: 1072.628173828125
INFO:root:Train (Epoch 50): Loss/seq after 01150 batchs: 1056.6336669921875
INFO:root:Train (Epoch 50): Loss/seq after 01200 batchs: 1053.212158203125
INFO:root:Train (Epoch 50): Loss/seq after 01250 batchs: 1048.456298828125
INFO:root:Train (Epoch 50): Loss/seq after 01300 batchs: 1044.7391357421875
INFO:root:Train (Epoch 50): Loss/seq after 01350 batchs: 1047.422607421875
INFO:root:Train (Epoch 50): Loss/seq after 01400 batchs: 1061.7027587890625
INFO:root:Train (Epoch 50): Loss/seq after 01450 batchs: 1057.427978515625
INFO:root:Train (Epoch 50): Loss/seq after 01500 batchs: 1055.4215087890625
INFO:root:Train (Epoch 50): Loss/seq after 01550 batchs: 1060.08056640625
INFO:root:Train (Epoch 50): Loss/seq after 01600 batchs: 1050.005615234375
INFO:root:Train (Epoch 50): Loss/seq after 01650 batchs: 1043.3048095703125
INFO:root:Train (Epoch 50): Loss/seq after 01700 batchs: 1038.8800048828125
INFO:root:Train (Epoch 50): Loss/seq after 01750 batchs: 1032.064697265625
INFO:root:Train (Epoch 50): Loss/seq after 01800 batchs: 1022.9248046875
INFO:root:Train (Epoch 50): Loss/seq after 01850 batchs: 1013.783935546875
INFO:root:Train (Epoch 50): Loss/seq after 01900 batchs: 1014.122314453125
INFO:root:Train (Epoch 50): Loss/seq after 01950 batchs: 1009.9082641601562
INFO:root:Train (Epoch 50): Loss/seq after 02000 batchs: 1005.109375
INFO:root:Train (Epoch 50): Loss/seq after 02050 batchs: 1000.43896484375
INFO:root:Train (Epoch 50): Loss/seq after 02100 batchs: 992.736572265625
INFO:root:Train (Epoch 50): Loss/seq after 02150 batchs: 986.27978515625
INFO:root:Train (Epoch 50): Loss/seq after 02200 batchs: 978.9642333984375
INFO:root:Train (Epoch 50): Loss/seq after 02250 batchs: 979.3104248046875
INFO:root:Train (Epoch 50): Loss/seq after 02300 batchs: 987.13330078125
INFO:root:Train (Epoch 50): Loss/seq after 02350 batchs: 980.0094604492188
INFO:root:Train (Epoch 50): Loss/seq after 02400 batchs: 977.994384765625
INFO:root:Train (Epoch 50): Loss/seq after 02450 batchs: 968.73583984375
INFO:root:Train (Epoch 50): Loss/seq after 02500 batchs: 954.8311767578125
INFO:root:Train (Epoch 50): Loss/seq after 02550 batchs: 945.3302612304688
INFO:root:Train (Epoch 50): Loss/seq after 02600 batchs: 943.0697631835938
INFO:root:Train (Epoch 50): Loss/seq after 02650 batchs: 939.6033325195312
INFO:root:Train (Epoch 50): Loss/seq after 02700 batchs: 936.7445678710938
INFO:root:Train (Epoch 50): Loss/seq after 02750 batchs: 964.1883544921875
INFO:root:Train (Epoch 50): Loss/seq after 02800 batchs: 968.7389526367188
INFO:root:Train (Epoch 50): Loss/seq after 02850 batchs: 966.2132568359375
INFO:root:Train (Epoch 50): Loss/seq after 02900 batchs: 965.083740234375
INFO:root:Train (Epoch 50): Loss/seq after 02950 batchs: 960.0253295898438
INFO:root:Train (Epoch 50): Loss/seq after 03000 batchs: 961.1536254882812
INFO:root:Train (Epoch 50): Loss/seq after 03050 batchs: 965.850341796875
INFO:root:Train (Epoch 50): Loss/seq after 03100 batchs: 972.34814453125
INFO:root:Train (Epoch 50): Loss/seq after 03150 batchs: 976.1519775390625
INFO:root:Train (Epoch 50): Loss/seq after 03200 batchs: 982.0339965820312
INFO:root:Train (Epoch 50): Loss/seq after 03250 batchs: 984.7356567382812
INFO:root:Train (Epoch 50): Loss/seq after 03300 batchs: 983.17431640625
INFO:root:Train (Epoch 50): Loss/seq after 03350 batchs: 982.260498046875
INFO:root:Train (Epoch 50): Loss/seq after 03400 batchs: 975.4518432617188
INFO:root:Train (Epoch 50): Loss/seq after 03450 batchs: 970.4732666015625
INFO:root:Train (Epoch 50): Loss/seq after 03500 batchs: 969.5990600585938
INFO:root:Train (Epoch 50): Loss/seq after 03550 batchs: 964.896240234375
INFO:root:Train (Epoch 50): Loss/seq after 03600 batchs: 972.1455078125
INFO:root:Train (Epoch 50): Loss/seq after 03650 batchs: 967.9509887695312
INFO:root:Train (Epoch 50): Loss/seq after 03700 batchs: 969.12158203125
INFO:root:Train (Epoch 50): Loss/seq after 03750 batchs: 971.86767578125
INFO:root:Train (Epoch 50): Loss/seq after 03800 batchs: 966.9003295898438
INFO:root:Train (Epoch 50): Loss/seq after 03850 batchs: 964.5242919921875
INFO:root:Train (Epoch 50): Loss/seq after 03900 batchs: 968.3905029296875
INFO:root:Train (Epoch 50): Loss/seq after 03950 batchs: 972.0817260742188
INFO:root:Train (Epoch 50): Loss/seq after 04000 batchs: 965.91357421875
INFO:root:Train (Epoch 50): Loss/seq after 04050 batchs: 959.9267578125
INFO:root:Train (Epoch 50): Loss/seq after 04100 batchs: 955.5646362304688
INFO:root:Train (Epoch 50): Loss/seq after 04150 batchs: 952.1922607421875
INFO:root:Train (Epoch 50): Loss/seq after 04200 batchs: 948.631591796875
INFO:root:Train (Epoch 50): Loss/seq after 04250 batchs: 945.6063232421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 50): Loss/seq after 00000 batches: 710.170166015625
INFO:root:# Valid (Epoch 50): Loss/seq after 00050 batches: 949.7581787109375
INFO:root:# Valid (Epoch 50): Loss/seq after 00100 batches: 1215.427001953125
INFO:root:# Valid (Epoch 50): Loss/seq after 00150 batches: 973.7359008789062
INFO:root:# Valid (Epoch 50): Loss/seq after 00200 batches: 894.9336547851562
INFO:root:Artifacts: Make stick videos for epoch 50
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_50_on_20220412_230031.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_50_index_1242_on_20220412_230031.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 51): Loss/seq after 00000 batchs: 1710.5474853515625
INFO:root:Train (Epoch 51): Loss/seq after 00050 batchs: 1204.5897216796875
INFO:root:Train (Epoch 51): Loss/seq after 00100 batchs: 1221.382080078125
INFO:root:Train (Epoch 51): Loss/seq after 00150 batchs: 1106.415771484375
INFO:root:Train (Epoch 51): Loss/seq after 00200 batchs: 1209.736572265625
INFO:root:Train (Epoch 51): Loss/seq after 00250 batchs: 1324.1072998046875
INFO:root:Train (Epoch 51): Loss/seq after 00300 batchs: 1279.97509765625
INFO:root:Train (Epoch 51): Loss/seq after 00350 batchs: 1196.2314453125
INFO:root:Train (Epoch 51): Loss/seq after 00400 batchs: 1220.533203125
INFO:root:Train (Epoch 51): Loss/seq after 00450 batchs: 1179.411376953125
INFO:root:Train (Epoch 51): Loss/seq after 00500 batchs: 1169.875732421875
INFO:root:Train (Epoch 51): Loss/seq after 00550 batchs: 1127.9847412109375
INFO:root:Train (Epoch 51): Loss/seq after 00600 batchs: 1093.6806640625
INFO:root:Train (Epoch 51): Loss/seq after 00650 batchs: 1102.7861328125
INFO:root:Train (Epoch 51): Loss/seq after 00700 batchs: 1085.9119873046875
INFO:root:Train (Epoch 51): Loss/seq after 00750 batchs: 1115.9801025390625
INFO:root:Train (Epoch 51): Loss/seq after 00800 batchs: 1110.3116455078125
INFO:root:Train (Epoch 51): Loss/seq after 00850 batchs: 1085.8612060546875
INFO:root:Train (Epoch 51): Loss/seq after 00900 batchs: 1082.8370361328125
INFO:root:Train (Epoch 51): Loss/seq after 00950 batchs: 1096.7119140625
INFO:root:Train (Epoch 51): Loss/seq after 01000 batchs: 1092.207275390625
INFO:root:Train (Epoch 51): Loss/seq after 01050 batchs: 1075.9434814453125
INFO:root:Train (Epoch 51): Loss/seq after 01100 batchs: 1066.943359375
INFO:root:Train (Epoch 51): Loss/seq after 01150 batchs: 1051.3763427734375
INFO:root:Train (Epoch 51): Loss/seq after 01200 batchs: 1046.93017578125
INFO:root:Train (Epoch 51): Loss/seq after 01250 batchs: 1041.63623046875
INFO:root:Train (Epoch 51): Loss/seq after 01300 batchs: 1039.1414794921875
INFO:root:Train (Epoch 51): Loss/seq after 01350 batchs: 1040.089111328125
INFO:root:Train (Epoch 51): Loss/seq after 01400 batchs: 1055.59521484375
INFO:root:Train (Epoch 51): Loss/seq after 01450 batchs: 1051.800048828125
INFO:root:Train (Epoch 51): Loss/seq after 01500 batchs: 1050.2144775390625
INFO:root:Train (Epoch 51): Loss/seq after 01550 batchs: 1052.4913330078125
INFO:root:Train (Epoch 51): Loss/seq after 01600 batchs: 1042.0123291015625
INFO:root:Train (Epoch 51): Loss/seq after 01650 batchs: 1034.9598388671875
INFO:root:Train (Epoch 51): Loss/seq after 01700 batchs: 1030.45068359375
INFO:root:Train (Epoch 51): Loss/seq after 01750 batchs: 1024.183837890625
INFO:root:Train (Epoch 51): Loss/seq after 01800 batchs: 1015.5313110351562
INFO:root:Train (Epoch 51): Loss/seq after 01850 batchs: 1006.4619140625
INFO:root:Train (Epoch 51): Loss/seq after 01900 batchs: 1007.0277099609375
INFO:root:Train (Epoch 51): Loss/seq after 01950 batchs: 1002.132568359375
INFO:root:Train (Epoch 51): Loss/seq after 02000 batchs: 997.5142211914062
INFO:root:Train (Epoch 51): Loss/seq after 02050 batchs: 993.3674926757812
INFO:root:Train (Epoch 51): Loss/seq after 02100 batchs: 985.7757568359375
INFO:root:Train (Epoch 51): Loss/seq after 02150 batchs: 979.235107421875
INFO:root:Train (Epoch 51): Loss/seq after 02200 batchs: 972.0350952148438
INFO:root:Train (Epoch 51): Loss/seq after 02250 batchs: 972.96435546875
INFO:root:Train (Epoch 51): Loss/seq after 02300 batchs: 980.3153686523438
INFO:root:Train (Epoch 51): Loss/seq after 02350 batchs: 974.7261962890625
INFO:root:Train (Epoch 51): Loss/seq after 02400 batchs: 972.7058715820312
INFO:root:Train (Epoch 51): Loss/seq after 02450 batchs: 963.2756958007812
INFO:root:Train (Epoch 51): Loss/seq after 02500 batchs: 949.662841796875
INFO:root:Train (Epoch 51): Loss/seq after 02550 batchs: 939.6058349609375
INFO:root:Train (Epoch 51): Loss/seq after 02600 batchs: 938.3250732421875
INFO:root:Train (Epoch 51): Loss/seq after 02650 batchs: 934.9097290039062
INFO:root:Train (Epoch 51): Loss/seq after 02700 batchs: 931.5050048828125
INFO:root:Train (Epoch 51): Loss/seq after 02750 batchs: 958.7952270507812
INFO:root:Train (Epoch 51): Loss/seq after 02800 batchs: 963.6312255859375
INFO:root:Train (Epoch 51): Loss/seq after 02850 batchs: 961.22265625
INFO:root:Train (Epoch 51): Loss/seq after 02900 batchs: 960.7471313476562
INFO:root:Train (Epoch 51): Loss/seq after 02950 batchs: 955.7063598632812
INFO:root:Train (Epoch 51): Loss/seq after 03000 batchs: 956.927734375
INFO:root:Train (Epoch 51): Loss/seq after 03050 batchs: 961.6553955078125
INFO:root:Train (Epoch 51): Loss/seq after 03100 batchs: 968.1556396484375
INFO:root:Train (Epoch 51): Loss/seq after 03150 batchs: 971.3037109375
INFO:root:Train (Epoch 51): Loss/seq after 03200 batchs: 978.2118530273438
INFO:root:Train (Epoch 51): Loss/seq after 03250 batchs: 981.7637329101562
INFO:root:Train (Epoch 51): Loss/seq after 03300 batchs: 980.2744140625
INFO:root:Train (Epoch 51): Loss/seq after 03350 batchs: 979.478271484375
INFO:root:Train (Epoch 51): Loss/seq after 03400 batchs: 972.62646484375
INFO:root:Train (Epoch 51): Loss/seq after 03450 batchs: 967.5081787109375
INFO:root:Train (Epoch 51): Loss/seq after 03500 batchs: 967.1011352539062
INFO:root:Train (Epoch 51): Loss/seq after 03550 batchs: 961.9805297851562
INFO:root:Train (Epoch 51): Loss/seq after 03600 batchs: 969.2333984375
INFO:root:Train (Epoch 51): Loss/seq after 03650 batchs: 964.8271484375
INFO:root:Train (Epoch 51): Loss/seq after 03700 batchs: 965.8833618164062
INFO:root:Train (Epoch 51): Loss/seq after 03750 batchs: 968.5433959960938
INFO:root:Train (Epoch 51): Loss/seq after 03800 batchs: 963.7763061523438
INFO:root:Train (Epoch 51): Loss/seq after 03850 batchs: 961.4151000976562
INFO:root:Train (Epoch 51): Loss/seq after 03900 batchs: 965.311767578125
INFO:root:Train (Epoch 51): Loss/seq after 03950 batchs: 969.4379272460938
INFO:root:Train (Epoch 51): Loss/seq after 04000 batchs: 963.2689208984375
INFO:root:Train (Epoch 51): Loss/seq after 04050 batchs: 957.2764282226562
INFO:root:Train (Epoch 51): Loss/seq after 04100 batchs: 953.1471557617188
INFO:root:Train (Epoch 51): Loss/seq after 04150 batchs: 949.85107421875
INFO:root:Train (Epoch 51): Loss/seq after 04200 batchs: 946.462890625
INFO:root:Train (Epoch 51): Loss/seq after 04250 batchs: 943.1023559570312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 51): Loss/seq after 00000 batches: 651.6551513671875
INFO:root:# Valid (Epoch 51): Loss/seq after 00050 batches: 923.2355346679688
INFO:root:# Valid (Epoch 51): Loss/seq after 00100 batches: 1206.82080078125
INFO:root:# Valid (Epoch 51): Loss/seq after 00150 batches: 961.429931640625
INFO:root:# Valid (Epoch 51): Loss/seq after 00200 batches: 884.4475708007812
INFO:root:Artifacts: Make stick videos for epoch 51
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_51_on_20220412_230554.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_51_index_135_on_20220412_230554.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 52): Loss/seq after 00000 batchs: 1664.8304443359375
INFO:root:Train (Epoch 52): Loss/seq after 00050 batchs: 1204.4798583984375
INFO:root:Train (Epoch 52): Loss/seq after 00100 batchs: 1200.4263916015625
INFO:root:Train (Epoch 52): Loss/seq after 00150 batchs: 1090.513427734375
INFO:root:Train (Epoch 52): Loss/seq after 00200 batchs: 1209.814208984375
INFO:root:Train (Epoch 52): Loss/seq after 00250 batchs: 1325.9710693359375
INFO:root:Train (Epoch 52): Loss/seq after 00300 batchs: 1281.218017578125
INFO:root:Train (Epoch 52): Loss/seq after 00350 batchs: 1197.1177978515625
INFO:root:Train (Epoch 52): Loss/seq after 00400 batchs: 1220.7891845703125
INFO:root:Train (Epoch 52): Loss/seq after 00450 batchs: 1179.255615234375
INFO:root:Train (Epoch 52): Loss/seq after 00500 batchs: 1168.0220947265625
INFO:root:Train (Epoch 52): Loss/seq after 00550 batchs: 1125.300537109375
INFO:root:Train (Epoch 52): Loss/seq after 00600 batchs: 1090.6943359375
INFO:root:Train (Epoch 52): Loss/seq after 00650 batchs: 1096.045654296875
INFO:root:Train (Epoch 52): Loss/seq after 00700 batchs: 1076.3106689453125
INFO:root:Train (Epoch 52): Loss/seq after 00750 batchs: 1106.71240234375
INFO:root:Train (Epoch 52): Loss/seq after 00800 batchs: 1101.64208984375
INFO:root:Train (Epoch 52): Loss/seq after 00850 batchs: 1075.79833984375
INFO:root:Train (Epoch 52): Loss/seq after 00900 batchs: 1075.56201171875
INFO:root:Train (Epoch 52): Loss/seq after 00950 batchs: 1085.677001953125
INFO:root:Train (Epoch 52): Loss/seq after 01000 batchs: 1079.38525390625
INFO:root:Train (Epoch 52): Loss/seq after 01050 batchs: 1062.8292236328125
INFO:root:Train (Epoch 52): Loss/seq after 01100 batchs: 1053.3607177734375
INFO:root:Train (Epoch 52): Loss/seq after 01150 batchs: 1036.430419921875
INFO:root:Train (Epoch 52): Loss/seq after 01200 batchs: 1033.369384765625
INFO:root:Train (Epoch 52): Loss/seq after 01250 batchs: 1028.8612060546875
INFO:root:Train (Epoch 52): Loss/seq after 01300 batchs: 1027.2303466796875
INFO:root:Train (Epoch 52): Loss/seq after 01350 batchs: 1025.9420166015625
INFO:root:Train (Epoch 52): Loss/seq after 01400 batchs: 1042.5726318359375
INFO:root:Train (Epoch 52): Loss/seq after 01450 batchs: 1038.6529541015625
INFO:root:Train (Epoch 52): Loss/seq after 01500 batchs: 1037.4154052734375
INFO:root:Train (Epoch 52): Loss/seq after 01550 batchs: 1040.71728515625
INFO:root:Train (Epoch 52): Loss/seq after 01600 batchs: 1030.7689208984375
INFO:root:Train (Epoch 52): Loss/seq after 01650 batchs: 1024.0
INFO:root:Train (Epoch 52): Loss/seq after 01700 batchs: 1019.4766845703125
INFO:root:Train (Epoch 52): Loss/seq after 01750 batchs: 1013.1238403320312
INFO:root:Train (Epoch 52): Loss/seq after 01800 batchs: 1004.664794921875
INFO:root:Train (Epoch 52): Loss/seq after 01850 batchs: 995.6001586914062
INFO:root:Train (Epoch 52): Loss/seq after 01900 batchs: 995.7449340820312
INFO:root:Train (Epoch 52): Loss/seq after 01950 batchs: 990.6026611328125
INFO:root:Train (Epoch 52): Loss/seq after 02000 batchs: 986.0899047851562
INFO:root:Train (Epoch 52): Loss/seq after 02050 batchs: 981.731201171875
INFO:root:Train (Epoch 52): Loss/seq after 02100 batchs: 974.2423706054688
INFO:root:Train (Epoch 52): Loss/seq after 02150 batchs: 967.99951171875
INFO:root:Train (Epoch 52): Loss/seq after 02200 batchs: 960.8623657226562
INFO:root:Train (Epoch 52): Loss/seq after 02250 batchs: 961.93115234375
INFO:root:Train (Epoch 52): Loss/seq after 02300 batchs: 969.6519775390625
INFO:root:Train (Epoch 52): Loss/seq after 02350 batchs: 963.6472778320312
INFO:root:Train (Epoch 52): Loss/seq after 02400 batchs: 962.0480346679688
INFO:root:Train (Epoch 52): Loss/seq after 02450 batchs: 953.06884765625
INFO:root:Train (Epoch 52): Loss/seq after 02500 batchs: 939.2640991210938
INFO:root:Train (Epoch 52): Loss/seq after 02550 batchs: 929.5275268554688
INFO:root:Train (Epoch 52): Loss/seq after 02600 batchs: 928.6309814453125
INFO:root:Train (Epoch 52): Loss/seq after 02650 batchs: 925.6880493164062
INFO:root:Train (Epoch 52): Loss/seq after 02700 batchs: 922.7686157226562
INFO:root:Train (Epoch 52): Loss/seq after 02750 batchs: 950.5525512695312
INFO:root:Train (Epoch 52): Loss/seq after 02800 batchs: 954.2869262695312
INFO:root:Train (Epoch 52): Loss/seq after 02850 batchs: 951.8713989257812
INFO:root:Train (Epoch 52): Loss/seq after 02900 batchs: 951.0427856445312
INFO:root:Train (Epoch 52): Loss/seq after 02950 batchs: 946.0162353515625
INFO:root:Train (Epoch 52): Loss/seq after 03000 batchs: 947.3980102539062
INFO:root:Train (Epoch 52): Loss/seq after 03050 batchs: 952.139404296875
INFO:root:Train (Epoch 52): Loss/seq after 03100 batchs: 958.2312622070312
INFO:root:Train (Epoch 52): Loss/seq after 03150 batchs: 962.4317016601562
INFO:root:Train (Epoch 52): Loss/seq after 03200 batchs: 968.9198608398438
INFO:root:Train (Epoch 52): Loss/seq after 03250 batchs: 972.117431640625
INFO:root:Train (Epoch 52): Loss/seq after 03300 batchs: 970.4246215820312
INFO:root:Train (Epoch 52): Loss/seq after 03350 batchs: 970.0477905273438
INFO:root:Train (Epoch 52): Loss/seq after 03400 batchs: 962.8541870117188
INFO:root:Train (Epoch 52): Loss/seq after 03450 batchs: 957.8661499023438
INFO:root:Train (Epoch 52): Loss/seq after 03500 batchs: 957.0654296875
INFO:root:Train (Epoch 52): Loss/seq after 03550 batchs: 951.9459838867188
INFO:root:Train (Epoch 52): Loss/seq after 03600 batchs: 959.0557861328125
INFO:root:Train (Epoch 52): Loss/seq after 03650 batchs: 954.6559448242188
INFO:root:Train (Epoch 52): Loss/seq after 03700 batchs: 954.7769775390625
INFO:root:Train (Epoch 52): Loss/seq after 03750 batchs: 957.6231689453125
INFO:root:Train (Epoch 52): Loss/seq after 03800 batchs: 952.76806640625
INFO:root:Train (Epoch 52): Loss/seq after 03850 batchs: 950.1729125976562
INFO:root:Train (Epoch 52): Loss/seq after 03900 batchs: 954.1871337890625
INFO:root:Train (Epoch 52): Loss/seq after 03950 batchs: 957.8652954101562
INFO:root:Train (Epoch 52): Loss/seq after 04000 batchs: 951.66357421875
INFO:root:Train (Epoch 52): Loss/seq after 04050 batchs: 945.6165771484375
INFO:root:Train (Epoch 52): Loss/seq after 04100 batchs: 941.3058471679688
INFO:root:Train (Epoch 52): Loss/seq after 04150 batchs: 938.0899658203125
INFO:root:Train (Epoch 52): Loss/seq after 04200 batchs: 934.7546997070312
INFO:root:Train (Epoch 52): Loss/seq after 04250 batchs: 932.0325927734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 52): Loss/seq after 00000 batches: 680.094970703125
INFO:root:# Valid (Epoch 52): Loss/seq after 00050 batches: 911.6419067382812
INFO:root:# Valid (Epoch 52): Loss/seq after 00100 batches: 1174.9971923828125
INFO:root:# Valid (Epoch 52): Loss/seq after 00150 batches: 948.3931884765625
INFO:root:# Valid (Epoch 52): Loss/seq after 00200 batches: 876.0524291992188
INFO:root:Artifacts: Make stick videos for epoch 52
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_52_on_20220412_231117.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_52_index_161_on_20220412_231117.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 53): Loss/seq after 00000 batchs: 1483.833984375
INFO:root:Train (Epoch 53): Loss/seq after 00050 batchs: 1149.26416015625
INFO:root:Train (Epoch 53): Loss/seq after 00100 batchs: 1188.697998046875
INFO:root:Train (Epoch 53): Loss/seq after 00150 batchs: 1080.3848876953125
INFO:root:Train (Epoch 53): Loss/seq after 00200 batchs: 1208.065185546875
INFO:root:Train (Epoch 53): Loss/seq after 00250 batchs: 1329.65185546875
INFO:root:Train (Epoch 53): Loss/seq after 00300 batchs: 1282.0133056640625
INFO:root:Train (Epoch 53): Loss/seq after 00350 batchs: 1195.758056640625
INFO:root:Train (Epoch 53): Loss/seq after 00400 batchs: 1219.8519287109375
INFO:root:Train (Epoch 53): Loss/seq after 00450 batchs: 1177.2027587890625
INFO:root:Train (Epoch 53): Loss/seq after 00500 batchs: 1168.94091796875
INFO:root:Train (Epoch 53): Loss/seq after 00550 batchs: 1125.993408203125
INFO:root:Train (Epoch 53): Loss/seq after 00600 batchs: 1093.8321533203125
INFO:root:Train (Epoch 53): Loss/seq after 00650 batchs: 1100.82275390625
INFO:root:Train (Epoch 53): Loss/seq after 00700 batchs: 1080.22509765625
INFO:root:Train (Epoch 53): Loss/seq after 00750 batchs: 1113.496337890625
INFO:root:Train (Epoch 53): Loss/seq after 00800 batchs: 1110.439453125
INFO:root:Train (Epoch 53): Loss/seq after 00850 batchs: 1083.8060302734375
INFO:root:Train (Epoch 53): Loss/seq after 00900 batchs: 1082.3917236328125
INFO:root:Train (Epoch 53): Loss/seq after 00950 batchs: 1093.4942626953125
INFO:root:Train (Epoch 53): Loss/seq after 01000 batchs: 1086.2359619140625
INFO:root:Train (Epoch 53): Loss/seq after 01050 batchs: 1068.521240234375
INFO:root:Train (Epoch 53): Loss/seq after 01100 batchs: 1057.723388671875
INFO:root:Train (Epoch 53): Loss/seq after 01150 batchs: 1040.0821533203125
INFO:root:Train (Epoch 53): Loss/seq after 01200 batchs: 1037.3687744140625
INFO:root:Train (Epoch 53): Loss/seq after 01250 batchs: 1031.822509765625
INFO:root:Train (Epoch 53): Loss/seq after 01300 batchs: 1027.37158203125
INFO:root:Train (Epoch 53): Loss/seq after 01350 batchs: 1027.3138427734375
INFO:root:Train (Epoch 53): Loss/seq after 01400 batchs: 1040.2686767578125
INFO:root:Train (Epoch 53): Loss/seq after 01450 batchs: 1036.1617431640625
INFO:root:Train (Epoch 53): Loss/seq after 01500 batchs: 1034.4449462890625
INFO:root:Train (Epoch 53): Loss/seq after 01550 batchs: 1036.520263671875
INFO:root:Train (Epoch 53): Loss/seq after 01600 batchs: 1026.0498046875
INFO:root:Train (Epoch 53): Loss/seq after 01650 batchs: 1018.6414184570312
INFO:root:Train (Epoch 53): Loss/seq after 01700 batchs: 1014.1024780273438
INFO:root:Train (Epoch 53): Loss/seq after 01750 batchs: 1007.527587890625
INFO:root:Train (Epoch 53): Loss/seq after 01800 batchs: 998.8807983398438
INFO:root:Train (Epoch 53): Loss/seq after 01850 batchs: 990.017822265625
INFO:root:Train (Epoch 53): Loss/seq after 01900 batchs: 990.1527709960938
INFO:root:Train (Epoch 53): Loss/seq after 01950 batchs: 984.7459106445312
INFO:root:Train (Epoch 53): Loss/seq after 02000 batchs: 980.0369262695312
INFO:root:Train (Epoch 53): Loss/seq after 02050 batchs: 975.7085571289062
INFO:root:Train (Epoch 53): Loss/seq after 02100 batchs: 968.4529418945312
INFO:root:Train (Epoch 53): Loss/seq after 02150 batchs: 962.1031494140625
INFO:root:Train (Epoch 53): Loss/seq after 02200 batchs: 954.8196411132812
INFO:root:Train (Epoch 53): Loss/seq after 02250 batchs: 955.6962890625
INFO:root:Train (Epoch 53): Loss/seq after 02300 batchs: 962.6270141601562
INFO:root:Train (Epoch 53): Loss/seq after 02350 batchs: 957.093017578125
INFO:root:Train (Epoch 53): Loss/seq after 02400 batchs: 955.1758422851562
INFO:root:Train (Epoch 53): Loss/seq after 02450 batchs: 946.0189819335938
INFO:root:Train (Epoch 53): Loss/seq after 02500 batchs: 932.450927734375
INFO:root:Train (Epoch 53): Loss/seq after 02550 batchs: 923.274658203125
INFO:root:Train (Epoch 53): Loss/seq after 02600 batchs: 922.173095703125
INFO:root:Train (Epoch 53): Loss/seq after 02650 batchs: 918.7318725585938
INFO:root:Train (Epoch 53): Loss/seq after 02700 batchs: 915.4866333007812
INFO:root:Train (Epoch 53): Loss/seq after 02750 batchs: 942.9077758789062
INFO:root:Train (Epoch 53): Loss/seq after 02800 batchs: 946.57080078125
INFO:root:Train (Epoch 53): Loss/seq after 02850 batchs: 944.463623046875
INFO:root:Train (Epoch 53): Loss/seq after 02900 batchs: 943.823974609375
INFO:root:Train (Epoch 53): Loss/seq after 02950 batchs: 938.9950561523438
INFO:root:Train (Epoch 53): Loss/seq after 03000 batchs: 940.1994018554688
INFO:root:Train (Epoch 53): Loss/seq after 03050 batchs: 945.4345703125
INFO:root:Train (Epoch 53): Loss/seq after 03100 batchs: 951.701904296875
INFO:root:Train (Epoch 53): Loss/seq after 03150 batchs: 955.28369140625
INFO:root:Train (Epoch 53): Loss/seq after 03200 batchs: 961.87451171875
INFO:root:Train (Epoch 53): Loss/seq after 03250 batchs: 964.65625
INFO:root:Train (Epoch 53): Loss/seq after 03300 batchs: 962.8046875
INFO:root:Train (Epoch 53): Loss/seq after 03350 batchs: 962.007080078125
INFO:root:Train (Epoch 53): Loss/seq after 03400 batchs: 955.2715454101562
INFO:root:Train (Epoch 53): Loss/seq after 03450 batchs: 950.481201171875
INFO:root:Train (Epoch 53): Loss/seq after 03500 batchs: 949.7276000976562
INFO:root:Train (Epoch 53): Loss/seq after 03550 batchs: 944.6927490234375
INFO:root:Train (Epoch 53): Loss/seq after 03600 batchs: 952.3505249023438
INFO:root:Train (Epoch 53): Loss/seq after 03650 batchs: 947.701416015625
INFO:root:Train (Epoch 53): Loss/seq after 03700 batchs: 948.5143432617188
INFO:root:Train (Epoch 53): Loss/seq after 03750 batchs: 951.0935668945312
INFO:root:Train (Epoch 53): Loss/seq after 03800 batchs: 946.0789184570312
INFO:root:Train (Epoch 53): Loss/seq after 03850 batchs: 943.8113403320312
INFO:root:Train (Epoch 53): Loss/seq after 03900 batchs: 947.834228515625
INFO:root:Train (Epoch 53): Loss/seq after 03950 batchs: 951.8048095703125
INFO:root:Train (Epoch 53): Loss/seq after 04000 batchs: 945.66455078125
INFO:root:Train (Epoch 53): Loss/seq after 04050 batchs: 939.5971069335938
INFO:root:Train (Epoch 53): Loss/seq after 04100 batchs: 935.54150390625
INFO:root:Train (Epoch 53): Loss/seq after 04150 batchs: 932.4696044921875
INFO:root:Train (Epoch 53): Loss/seq after 04200 batchs: 929.1701049804688
INFO:root:Train (Epoch 53): Loss/seq after 04250 batchs: 926.11865234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 53): Loss/seq after 00000 batches: 848.7418212890625
INFO:root:# Valid (Epoch 53): Loss/seq after 00050 batches: 916.1140747070312
INFO:root:# Valid (Epoch 53): Loss/seq after 00100 batches: 1184.0789794921875
INFO:root:# Valid (Epoch 53): Loss/seq after 00150 batches: 934.9251098632812
INFO:root:# Valid (Epoch 53): Loss/seq after 00200 batches: 852.1843872070312
INFO:root:Artifacts: Make stick videos for epoch 53
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_53_on_20220412_231640.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_53_index_60_on_20220412_231640.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 54): Loss/seq after 00000 batchs: 1443.567138671875
INFO:root:Train (Epoch 54): Loss/seq after 00050 batchs: 1151.0638427734375
INFO:root:Train (Epoch 54): Loss/seq after 00100 batchs: 1245.2977294921875
INFO:root:Train (Epoch 54): Loss/seq after 00150 batchs: 1151.0418701171875
INFO:root:Train (Epoch 54): Loss/seq after 00200 batchs: 1254.8443603515625
INFO:root:Train (Epoch 54): Loss/seq after 00250 batchs: 1367.3353271484375
INFO:root:Train (Epoch 54): Loss/seq after 00300 batchs: 1314.97265625
INFO:root:Train (Epoch 54): Loss/seq after 00350 batchs: 1229.7802734375
INFO:root:Train (Epoch 54): Loss/seq after 00400 batchs: 1252.05908203125
INFO:root:Train (Epoch 54): Loss/seq after 00450 batchs: 1204.879150390625
INFO:root:Train (Epoch 54): Loss/seq after 00500 batchs: 1187.8546142578125
INFO:root:Train (Epoch 54): Loss/seq after 00550 batchs: 1143.579345703125
INFO:root:Train (Epoch 54): Loss/seq after 00600 batchs: 1103.291259765625
INFO:root:Train (Epoch 54): Loss/seq after 00650 batchs: 1110.4935302734375
INFO:root:Train (Epoch 54): Loss/seq after 00700 batchs: 1086.4512939453125
INFO:root:Train (Epoch 54): Loss/seq after 00750 batchs: 1117.6199951171875
INFO:root:Train (Epoch 54): Loss/seq after 00800 batchs: 1112.617431640625
INFO:root:Train (Epoch 54): Loss/seq after 00850 batchs: 1085.138671875
INFO:root:Train (Epoch 54): Loss/seq after 00900 batchs: 1077.4451904296875
INFO:root:Train (Epoch 54): Loss/seq after 00950 batchs: 1086.97265625
INFO:root:Train (Epoch 54): Loss/seq after 01000 batchs: 1081.071044921875
INFO:root:Train (Epoch 54): Loss/seq after 01050 batchs: 1064.6640625
INFO:root:Train (Epoch 54): Loss/seq after 01100 batchs: 1052.8892822265625
INFO:root:Train (Epoch 54): Loss/seq after 01150 batchs: 1036.99560546875
INFO:root:Train (Epoch 54): Loss/seq after 01200 batchs: 1032.807373046875
INFO:root:Train (Epoch 54): Loss/seq after 01250 batchs: 1027.0960693359375
INFO:root:Train (Epoch 54): Loss/seq after 01300 batchs: 1025.0028076171875
INFO:root:Train (Epoch 54): Loss/seq after 01350 batchs: 1025.1201171875
INFO:root:Train (Epoch 54): Loss/seq after 01400 batchs: 1040.02001953125
INFO:root:Train (Epoch 54): Loss/seq after 01450 batchs: 1036.66259765625
INFO:root:Train (Epoch 54): Loss/seq after 01500 batchs: 1035.01123046875
INFO:root:Train (Epoch 54): Loss/seq after 01550 batchs: 1036.266845703125
INFO:root:Train (Epoch 54): Loss/seq after 01600 batchs: 1025.8797607421875
INFO:root:Train (Epoch 54): Loss/seq after 01650 batchs: 1018.7914428710938
INFO:root:Train (Epoch 54): Loss/seq after 01700 batchs: 1014.3609619140625
INFO:root:Train (Epoch 54): Loss/seq after 01750 batchs: 1007.88818359375
INFO:root:Train (Epoch 54): Loss/seq after 01800 batchs: 999.2460327148438
INFO:root:Train (Epoch 54): Loss/seq after 01850 batchs: 990.1616821289062
INFO:root:Train (Epoch 54): Loss/seq after 01900 batchs: 990.2745361328125
INFO:root:Train (Epoch 54): Loss/seq after 01950 batchs: 985.8204345703125
INFO:root:Train (Epoch 54): Loss/seq after 02000 batchs: 981.0031127929688
INFO:root:Train (Epoch 54): Loss/seq after 02050 batchs: 976.0889282226562
INFO:root:Train (Epoch 54): Loss/seq after 02100 batchs: 968.9393920898438
INFO:root:Train (Epoch 54): Loss/seq after 02150 batchs: 962.4741821289062
INFO:root:Train (Epoch 54): Loss/seq after 02200 batchs: 955.5675659179688
INFO:root:Train (Epoch 54): Loss/seq after 02250 batchs: 956.0958862304688
INFO:root:Train (Epoch 54): Loss/seq after 02300 batchs: 963.9178466796875
INFO:root:Train (Epoch 54): Loss/seq after 02350 batchs: 957.4766235351562
INFO:root:Train (Epoch 54): Loss/seq after 02400 batchs: 955.1290283203125
INFO:root:Train (Epoch 54): Loss/seq after 02450 batchs: 945.6859130859375
INFO:root:Train (Epoch 54): Loss/seq after 02500 batchs: 932.0985717773438
INFO:root:Train (Epoch 54): Loss/seq after 02550 batchs: 922.5323486328125
INFO:root:Train (Epoch 54): Loss/seq after 02600 batchs: 920.6508178710938
INFO:root:Train (Epoch 54): Loss/seq after 02650 batchs: 916.8806762695312
INFO:root:Train (Epoch 54): Loss/seq after 02700 batchs: 913.1198120117188
INFO:root:Train (Epoch 54): Loss/seq after 02750 batchs: 938.7595825195312
INFO:root:Train (Epoch 54): Loss/seq after 02800 batchs: 942.9345092773438
INFO:root:Train (Epoch 54): Loss/seq after 02850 batchs: 940.6658325195312
INFO:root:Train (Epoch 54): Loss/seq after 02900 batchs: 939.7672729492188
INFO:root:Train (Epoch 54): Loss/seq after 02950 batchs: 934.6447143554688
INFO:root:Train (Epoch 54): Loss/seq after 03000 batchs: 935.9781494140625
INFO:root:Train (Epoch 54): Loss/seq after 03050 batchs: 940.5494384765625
INFO:root:Train (Epoch 54): Loss/seq after 03100 batchs: 946.6902465820312
INFO:root:Train (Epoch 54): Loss/seq after 03150 batchs: 951.1165161132812
INFO:root:Train (Epoch 54): Loss/seq after 03200 batchs: 957.3270263671875
INFO:root:Train (Epoch 54): Loss/seq after 03250 batchs: 960.557373046875
INFO:root:Train (Epoch 54): Loss/seq after 03300 batchs: 958.977783203125
INFO:root:Train (Epoch 54): Loss/seq after 03350 batchs: 957.9541015625
INFO:root:Train (Epoch 54): Loss/seq after 03400 batchs: 951.13623046875
INFO:root:Train (Epoch 54): Loss/seq after 03450 batchs: 946.2119140625
INFO:root:Train (Epoch 54): Loss/seq after 03500 batchs: 945.3310546875
INFO:root:Train (Epoch 54): Loss/seq after 03550 batchs: 939.8200073242188
INFO:root:Train (Epoch 54): Loss/seq after 03600 batchs: 947.1224365234375
INFO:root:Train (Epoch 54): Loss/seq after 03650 batchs: 942.5045166015625
INFO:root:Train (Epoch 54): Loss/seq after 03700 batchs: 943.61669921875
INFO:root:Train (Epoch 54): Loss/seq after 03750 batchs: 946.3941040039062
INFO:root:Train (Epoch 54): Loss/seq after 03800 batchs: 941.199951171875
INFO:root:Train (Epoch 54): Loss/seq after 03850 batchs: 938.7846069335938
INFO:root:Train (Epoch 54): Loss/seq after 03900 batchs: 942.3936157226562
INFO:root:Train (Epoch 54): Loss/seq after 03950 batchs: 946.2432861328125
INFO:root:Train (Epoch 54): Loss/seq after 04000 batchs: 940.088134765625
INFO:root:Train (Epoch 54): Loss/seq after 04050 batchs: 934.2155151367188
INFO:root:Train (Epoch 54): Loss/seq after 04100 batchs: 930.0526123046875
INFO:root:Train (Epoch 54): Loss/seq after 04150 batchs: 926.9788818359375
INFO:root:Train (Epoch 54): Loss/seq after 04200 batchs: 923.4097290039062
INFO:root:Train (Epoch 54): Loss/seq after 04250 batchs: 920.5615844726562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 54): Loss/seq after 00000 batches: 593.336181640625
INFO:root:# Valid (Epoch 54): Loss/seq after 00050 batches: 892.3004760742188
INFO:root:# Valid (Epoch 54): Loss/seq after 00100 batches: 1181.1666259765625
INFO:root:# Valid (Epoch 54): Loss/seq after 00150 batches: 922.238525390625
INFO:root:# Valid (Epoch 54): Loss/seq after 00200 batches: 844.4901123046875
INFO:root:Artifacts: Make stick videos for epoch 54
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_54_on_20220412_232203.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_54_index_498_on_20220412_232203.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 55): Loss/seq after 00000 batchs: 1620.3271484375
INFO:root:Train (Epoch 55): Loss/seq after 00050 batchs: 1150.06982421875
INFO:root:Train (Epoch 55): Loss/seq after 00100 batchs: 1160.13623046875
INFO:root:Train (Epoch 55): Loss/seq after 00150 batchs: 1059.1884765625
INFO:root:Train (Epoch 55): Loss/seq after 00200 batchs: 1187.2249755859375
INFO:root:Train (Epoch 55): Loss/seq after 00250 batchs: 1303.1171875
INFO:root:Train (Epoch 55): Loss/seq after 00300 batchs: 1258.555908203125
INFO:root:Train (Epoch 55): Loss/seq after 00350 batchs: 1176.4630126953125
INFO:root:Train (Epoch 55): Loss/seq after 00400 batchs: 1202.4010009765625
INFO:root:Train (Epoch 55): Loss/seq after 00450 batchs: 1159.2900390625
INFO:root:Train (Epoch 55): Loss/seq after 00500 batchs: 1152.623779296875
INFO:root:Train (Epoch 55): Loss/seq after 00550 batchs: 1114.7161865234375
INFO:root:Train (Epoch 55): Loss/seq after 00600 batchs: 1078.8116455078125
INFO:root:Train (Epoch 55): Loss/seq after 00650 batchs: 1087.66796875
INFO:root:Train (Epoch 55): Loss/seq after 00700 batchs: 1066.5186767578125
INFO:root:Train (Epoch 55): Loss/seq after 00750 batchs: 1100.025390625
INFO:root:Train (Epoch 55): Loss/seq after 00800 batchs: 1097.529296875
INFO:root:Train (Epoch 55): Loss/seq after 00850 batchs: 1071.5328369140625
INFO:root:Train (Epoch 55): Loss/seq after 00900 batchs: 1069.0177001953125
INFO:root:Train (Epoch 55): Loss/seq after 00950 batchs: 1079.5224609375
INFO:root:Train (Epoch 55): Loss/seq after 01000 batchs: 1074.9473876953125
INFO:root:Train (Epoch 55): Loss/seq after 01050 batchs: 1055.298583984375
INFO:root:Train (Epoch 55): Loss/seq after 01100 batchs: 1043.9573974609375
INFO:root:Train (Epoch 55): Loss/seq after 01150 batchs: 1027.1927490234375
INFO:root:Train (Epoch 55): Loss/seq after 01200 batchs: 1023.6809692382812
INFO:root:Train (Epoch 55): Loss/seq after 01250 batchs: 1018.7308959960938
INFO:root:Train (Epoch 55): Loss/seq after 01300 batchs: 1016.1668090820312
INFO:root:Train (Epoch 55): Loss/seq after 01350 batchs: 1014.4740600585938
INFO:root:Train (Epoch 55): Loss/seq after 01400 batchs: 1029.1776123046875
INFO:root:Train (Epoch 55): Loss/seq after 01450 batchs: 1025.0521240234375
INFO:root:Train (Epoch 55): Loss/seq after 01500 batchs: 1023.57861328125
INFO:root:Train (Epoch 55): Loss/seq after 01550 batchs: 1024.4970703125
INFO:root:Train (Epoch 55): Loss/seq after 01600 batchs: 1013.6927490234375
INFO:root:Train (Epoch 55): Loss/seq after 01650 batchs: 1005.9854736328125
INFO:root:Train (Epoch 55): Loss/seq after 01700 batchs: 1001.4105834960938
INFO:root:Train (Epoch 55): Loss/seq after 01750 batchs: 994.7734375
INFO:root:Train (Epoch 55): Loss/seq after 01800 batchs: 986.7258911132812
INFO:root:Train (Epoch 55): Loss/seq after 01850 batchs: 977.7357788085938
INFO:root:Train (Epoch 55): Loss/seq after 01900 batchs: 977.2717895507812
INFO:root:Train (Epoch 55): Loss/seq after 01950 batchs: 972.576416015625
INFO:root:Train (Epoch 55): Loss/seq after 02000 batchs: 967.0
INFO:root:Train (Epoch 55): Loss/seq after 02050 batchs: 962.7388305664062
INFO:root:Train (Epoch 55): Loss/seq after 02100 batchs: 955.5492553710938
INFO:root:Train (Epoch 55): Loss/seq after 02150 batchs: 949.2401123046875
INFO:root:Train (Epoch 55): Loss/seq after 02200 batchs: 942.3773193359375
INFO:root:Train (Epoch 55): Loss/seq after 02250 batchs: 942.648193359375
INFO:root:Train (Epoch 55): Loss/seq after 02300 batchs: 949.2612915039062
INFO:root:Train (Epoch 55): Loss/seq after 02350 batchs: 941.3428344726562
INFO:root:Train (Epoch 55): Loss/seq after 02400 batchs: 939.1317138671875
INFO:root:Train (Epoch 55): Loss/seq after 02450 batchs: 930.1958618164062
INFO:root:Train (Epoch 55): Loss/seq after 02500 batchs: 916.6494140625
INFO:root:Train (Epoch 55): Loss/seq after 02550 batchs: 907.4647827148438
INFO:root:Train (Epoch 55): Loss/seq after 02600 batchs: 905.7904663085938
INFO:root:Train (Epoch 55): Loss/seq after 02650 batchs: 902.8263549804688
INFO:root:Train (Epoch 55): Loss/seq after 02700 batchs: 899.2171630859375
INFO:root:Train (Epoch 55): Loss/seq after 02750 batchs: 924.9326171875
INFO:root:Train (Epoch 55): Loss/seq after 02800 batchs: 927.7691650390625
INFO:root:Train (Epoch 55): Loss/seq after 02850 batchs: 925.45703125
INFO:root:Train (Epoch 55): Loss/seq after 02900 batchs: 924.688720703125
INFO:root:Train (Epoch 55): Loss/seq after 02950 batchs: 919.6066284179688
INFO:root:Train (Epoch 55): Loss/seq after 03000 batchs: 921.1405639648438
INFO:root:Train (Epoch 55): Loss/seq after 03050 batchs: 926.4149169921875
INFO:root:Train (Epoch 55): Loss/seq after 03100 batchs: 932.9862670898438
INFO:root:Train (Epoch 55): Loss/seq after 03150 batchs: 937.1497192382812
INFO:root:Train (Epoch 55): Loss/seq after 03200 batchs: 943.5424194335938
INFO:root:Train (Epoch 55): Loss/seq after 03250 batchs: 947.188720703125
INFO:root:Train (Epoch 55): Loss/seq after 03300 batchs: 945.6710205078125
INFO:root:Train (Epoch 55): Loss/seq after 03350 batchs: 944.70947265625
INFO:root:Train (Epoch 55): Loss/seq after 03400 batchs: 938.056396484375
INFO:root:Train (Epoch 55): Loss/seq after 03450 batchs: 933.5783081054688
INFO:root:Train (Epoch 55): Loss/seq after 03500 batchs: 933.3516845703125
INFO:root:Train (Epoch 55): Loss/seq after 03550 batchs: 927.99365234375
INFO:root:Train (Epoch 55): Loss/seq after 03600 batchs: 934.9419555664062
INFO:root:Train (Epoch 55): Loss/seq after 03650 batchs: 930.8187255859375
INFO:root:Train (Epoch 55): Loss/seq after 03700 batchs: 931.2954711914062
INFO:root:Train (Epoch 55): Loss/seq after 03750 batchs: 934.1177368164062
INFO:root:Train (Epoch 55): Loss/seq after 03800 batchs: 929.4146728515625
INFO:root:Train (Epoch 55): Loss/seq after 03850 batchs: 927.1914672851562
INFO:root:Train (Epoch 55): Loss/seq after 03900 batchs: 931.0513916015625
INFO:root:Train (Epoch 55): Loss/seq after 03950 batchs: 935.442138671875
INFO:root:Train (Epoch 55): Loss/seq after 04000 batchs: 929.5892944335938
INFO:root:Train (Epoch 55): Loss/seq after 04050 batchs: 923.7232666015625
INFO:root:Train (Epoch 55): Loss/seq after 04100 batchs: 919.6456298828125
INFO:root:Train (Epoch 55): Loss/seq after 04150 batchs: 916.71044921875
INFO:root:Train (Epoch 55): Loss/seq after 04200 batchs: 913.4498901367188
INFO:root:Train (Epoch 55): Loss/seq after 04250 batchs: 910.7797241210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 55): Loss/seq after 00000 batches: 885.1968994140625
INFO:root:# Valid (Epoch 55): Loss/seq after 00050 batches: 885.5101928710938
INFO:root:# Valid (Epoch 55): Loss/seq after 00100 batches: 1171.626953125
INFO:root:# Valid (Epoch 55): Loss/seq after 00150 batches: 920.3104248046875
INFO:root:# Valid (Epoch 55): Loss/seq after 00200 batches: 844.8792724609375
INFO:root:Artifacts: Make stick videos for epoch 55
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_55_on_20220412_232725.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_55_index_1638_on_20220412_232725.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 56): Loss/seq after 00000 batchs: 1651.621826171875
INFO:root:Train (Epoch 56): Loss/seq after 00050 batchs: 1172.9732666015625
INFO:root:Train (Epoch 56): Loss/seq after 00100 batchs: 1178.28369140625
INFO:root:Train (Epoch 56): Loss/seq after 00150 batchs: 1067.258544921875
INFO:root:Train (Epoch 56): Loss/seq after 00200 batchs: 1184.9915771484375
INFO:root:Train (Epoch 56): Loss/seq after 00250 batchs: 1310.002685546875
INFO:root:Train (Epoch 56): Loss/seq after 00300 batchs: 1262.831787109375
INFO:root:Train (Epoch 56): Loss/seq after 00350 batchs: 1182.978515625
INFO:root:Train (Epoch 56): Loss/seq after 00400 batchs: 1205.11572265625
INFO:root:Train (Epoch 56): Loss/seq after 00450 batchs: 1162.338134765625
INFO:root:Train (Epoch 56): Loss/seq after 00500 batchs: 1147.384765625
INFO:root:Train (Epoch 56): Loss/seq after 00550 batchs: 1105.085205078125
INFO:root:Train (Epoch 56): Loss/seq after 00600 batchs: 1070.22314453125
INFO:root:Train (Epoch 56): Loss/seq after 00650 batchs: 1078.6773681640625
INFO:root:Train (Epoch 56): Loss/seq after 00700 batchs: 1059.4932861328125
INFO:root:Train (Epoch 56): Loss/seq after 00750 batchs: 1090.6712646484375
INFO:root:Train (Epoch 56): Loss/seq after 00800 batchs: 1085.3624267578125
INFO:root:Train (Epoch 56): Loss/seq after 00850 batchs: 1059.594482421875
INFO:root:Train (Epoch 56): Loss/seq after 00900 batchs: 1054.705810546875
INFO:root:Train (Epoch 56): Loss/seq after 00950 batchs: 1067.4139404296875
INFO:root:Train (Epoch 56): Loss/seq after 01000 batchs: 1061.528076171875
INFO:root:Train (Epoch 56): Loss/seq after 01050 batchs: 1043.215087890625
INFO:root:Train (Epoch 56): Loss/seq after 01100 batchs: 1028.6419677734375
INFO:root:Train (Epoch 56): Loss/seq after 01150 batchs: 1011.9887084960938
INFO:root:Train (Epoch 56): Loss/seq after 01200 batchs: 1009.431396484375
INFO:root:Train (Epoch 56): Loss/seq after 01250 batchs: 1002.6973266601562
INFO:root:Train (Epoch 56): Loss/seq after 01300 batchs: 997.4165649414062
INFO:root:Train (Epoch 56): Loss/seq after 01350 batchs: 994.7401733398438
INFO:root:Train (Epoch 56): Loss/seq after 01400 batchs: 1010.499267578125
INFO:root:Train (Epoch 56): Loss/seq after 01450 batchs: 1006.9891357421875
INFO:root:Train (Epoch 56): Loss/seq after 01500 batchs: 1005.8379516601562
INFO:root:Train (Epoch 56): Loss/seq after 01550 batchs: 1007.5845947265625
INFO:root:Train (Epoch 56): Loss/seq after 01600 batchs: 997.106689453125
INFO:root:Train (Epoch 56): Loss/seq after 01650 batchs: 990.3989868164062
INFO:root:Train (Epoch 56): Loss/seq after 01700 batchs: 986.2818603515625
INFO:root:Train (Epoch 56): Loss/seq after 01750 batchs: 980.473388671875
INFO:root:Train (Epoch 56): Loss/seq after 01800 batchs: 972.16552734375
INFO:root:Train (Epoch 56): Loss/seq after 01850 batchs: 963.3766479492188
INFO:root:Train (Epoch 56): Loss/seq after 01900 batchs: 963.1991577148438
INFO:root:Train (Epoch 56): Loss/seq after 01950 batchs: 958.350341796875
INFO:root:Train (Epoch 56): Loss/seq after 02000 batchs: 953.5944213867188
INFO:root:Train (Epoch 56): Loss/seq after 02050 batchs: 949.1187133789062
INFO:root:Train (Epoch 56): Loss/seq after 02100 batchs: 942.1592407226562
INFO:root:Train (Epoch 56): Loss/seq after 02150 batchs: 936.2147216796875
INFO:root:Train (Epoch 56): Loss/seq after 02200 batchs: 929.1560668945312
INFO:root:Train (Epoch 56): Loss/seq after 02250 batchs: 929.0455932617188
INFO:root:Train (Epoch 56): Loss/seq after 02300 batchs: 935.7534790039062
INFO:root:Train (Epoch 56): Loss/seq after 02350 batchs: 927.8783569335938
INFO:root:Train (Epoch 56): Loss/seq after 02400 batchs: 925.7889404296875
INFO:root:Train (Epoch 56): Loss/seq after 02450 batchs: 916.89208984375
INFO:root:Train (Epoch 56): Loss/seq after 02500 batchs: 903.891357421875
INFO:root:Train (Epoch 56): Loss/seq after 02550 batchs: 894.2953491210938
INFO:root:Train (Epoch 56): Loss/seq after 02600 batchs: 892.3745727539062
INFO:root:Train (Epoch 56): Loss/seq after 02650 batchs: 888.8701171875
INFO:root:Train (Epoch 56): Loss/seq after 02700 batchs: 885.7886962890625
INFO:root:Train (Epoch 56): Loss/seq after 02750 batchs: 911.0489501953125
INFO:root:Train (Epoch 56): Loss/seq after 02800 batchs: 914.4404907226562
INFO:root:Train (Epoch 56): Loss/seq after 02850 batchs: 912.4801025390625
INFO:root:Train (Epoch 56): Loss/seq after 02900 batchs: 912.1285400390625
INFO:root:Train (Epoch 56): Loss/seq after 02950 batchs: 907.7310791015625
INFO:root:Train (Epoch 56): Loss/seq after 03000 batchs: 909.3822631835938
INFO:root:Train (Epoch 56): Loss/seq after 03050 batchs: 914.3097534179688
INFO:root:Train (Epoch 56): Loss/seq after 03100 batchs: 920.3828125
INFO:root:Train (Epoch 56): Loss/seq after 03150 batchs: 924.8296508789062
INFO:root:Train (Epoch 56): Loss/seq after 03200 batchs: 931.1505126953125
INFO:root:Train (Epoch 56): Loss/seq after 03250 batchs: 935.4358520507812
INFO:root:Train (Epoch 56): Loss/seq after 03300 batchs: 933.6461181640625
INFO:root:Train (Epoch 56): Loss/seq after 03350 batchs: 932.54541015625
INFO:root:Train (Epoch 56): Loss/seq after 03400 batchs: 925.9510498046875
INFO:root:Train (Epoch 56): Loss/seq after 03450 batchs: 921.371337890625
INFO:root:Train (Epoch 56): Loss/seq after 03500 batchs: 920.4072875976562
INFO:root:Train (Epoch 56): Loss/seq after 03550 batchs: 915.5062255859375
INFO:root:Train (Epoch 56): Loss/seq after 03600 batchs: 922.554443359375
INFO:root:Train (Epoch 56): Loss/seq after 03650 batchs: 918.2434692382812
INFO:root:Train (Epoch 56): Loss/seq after 03700 batchs: 919.5567626953125
INFO:root:Train (Epoch 56): Loss/seq after 03750 batchs: 922.5656127929688
INFO:root:Train (Epoch 56): Loss/seq after 03800 batchs: 917.9255981445312
INFO:root:Train (Epoch 56): Loss/seq after 03850 batchs: 915.5956420898438
INFO:root:Train (Epoch 56): Loss/seq after 03900 batchs: 919.6573486328125
INFO:root:Train (Epoch 56): Loss/seq after 03950 batchs: 924.0413208007812
INFO:root:Train (Epoch 56): Loss/seq after 04000 batchs: 918.2521362304688
INFO:root:Train (Epoch 56): Loss/seq after 04050 batchs: 912.3632202148438
INFO:root:Train (Epoch 56): Loss/seq after 04100 batchs: 908.248291015625
INFO:root:Train (Epoch 56): Loss/seq after 04150 batchs: 905.2281494140625
INFO:root:Train (Epoch 56): Loss/seq after 04200 batchs: 901.9764404296875
INFO:root:Train (Epoch 56): Loss/seq after 04250 batchs: 899.1048583984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 56): Loss/seq after 00000 batches: 919.1336059570312
INFO:root:# Valid (Epoch 56): Loss/seq after 00050 batches: 933.1160888671875
INFO:root:# Valid (Epoch 56): Loss/seq after 00100 batches: 1186.9912109375
INFO:root:# Valid (Epoch 56): Loss/seq after 00150 batches: 951.6964111328125
INFO:root:# Valid (Epoch 56): Loss/seq after 00200 batches: 878.8226928710938
INFO:root:Artifacts: Make stick videos for epoch 56
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_56_on_20220412_233246.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_56_index_1161_on_20220412_233246.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 57): Loss/seq after 00000 batchs: 1609.387451171875
INFO:root:Train (Epoch 57): Loss/seq after 00050 batchs: 1128.3875732421875
INFO:root:Train (Epoch 57): Loss/seq after 00100 batchs: 1145.395751953125
INFO:root:Train (Epoch 57): Loss/seq after 00150 batchs: 1039.0491943359375
INFO:root:Train (Epoch 57): Loss/seq after 00200 batchs: 1160.7696533203125
INFO:root:Train (Epoch 57): Loss/seq after 00250 batchs: 1278.5389404296875
INFO:root:Train (Epoch 57): Loss/seq after 00300 batchs: 1236.0445556640625
INFO:root:Train (Epoch 57): Loss/seq after 00350 batchs: 1155.59423828125
INFO:root:Train (Epoch 57): Loss/seq after 00400 batchs: 1178.9224853515625
INFO:root:Train (Epoch 57): Loss/seq after 00450 batchs: 1140.6903076171875
INFO:root:Train (Epoch 57): Loss/seq after 00500 batchs: 1128.947509765625
INFO:root:Train (Epoch 57): Loss/seq after 00550 batchs: 1088.2252197265625
INFO:root:Train (Epoch 57): Loss/seq after 00600 batchs: 1052.9312744140625
INFO:root:Train (Epoch 57): Loss/seq after 00650 batchs: 1060.389404296875
INFO:root:Train (Epoch 57): Loss/seq after 00700 batchs: 1046.29541015625
INFO:root:Train (Epoch 57): Loss/seq after 00750 batchs: 1078.69482421875
INFO:root:Train (Epoch 57): Loss/seq after 00800 batchs: 1074.80908203125
INFO:root:Train (Epoch 57): Loss/seq after 00850 batchs: 1046.78173828125
INFO:root:Train (Epoch 57): Loss/seq after 00900 batchs: 1038.9654541015625
INFO:root:Train (Epoch 57): Loss/seq after 00950 batchs: 1056.02392578125
INFO:root:Train (Epoch 57): Loss/seq after 01000 batchs: 1050.6160888671875
INFO:root:Train (Epoch 57): Loss/seq after 01050 batchs: 1033.018310546875
INFO:root:Train (Epoch 57): Loss/seq after 01100 batchs: 1018.5072021484375
INFO:root:Train (Epoch 57): Loss/seq after 01150 batchs: 1000.4356079101562
INFO:root:Train (Epoch 57): Loss/seq after 01200 batchs: 998.0367431640625
INFO:root:Train (Epoch 57): Loss/seq after 01250 batchs: 993.5083618164062
INFO:root:Train (Epoch 57): Loss/seq after 01300 batchs: 990.1085815429688
INFO:root:Train (Epoch 57): Loss/seq after 01350 batchs: 989.5501098632812
INFO:root:Train (Epoch 57): Loss/seq after 01400 batchs: 1005.8690795898438
INFO:root:Train (Epoch 57): Loss/seq after 01450 batchs: 1002.6685791015625
INFO:root:Train (Epoch 57): Loss/seq after 01500 batchs: 1001.7723999023438
INFO:root:Train (Epoch 57): Loss/seq after 01550 batchs: 1002.7762451171875
INFO:root:Train (Epoch 57): Loss/seq after 01600 batchs: 992.6861572265625
INFO:root:Train (Epoch 57): Loss/seq after 01650 batchs: 985.367919921875
INFO:root:Train (Epoch 57): Loss/seq after 01700 batchs: 981.1359252929688
INFO:root:Train (Epoch 57): Loss/seq after 01750 batchs: 975.2325439453125
INFO:root:Train (Epoch 57): Loss/seq after 01800 batchs: 967.158447265625
INFO:root:Train (Epoch 57): Loss/seq after 01850 batchs: 958.5059204101562
INFO:root:Train (Epoch 57): Loss/seq after 01900 batchs: 958.10498046875
INFO:root:Train (Epoch 57): Loss/seq after 01950 batchs: 952.8733520507812
INFO:root:Train (Epoch 57): Loss/seq after 02000 batchs: 947.68505859375
INFO:root:Train (Epoch 57): Loss/seq after 02050 batchs: 943.630615234375
INFO:root:Train (Epoch 57): Loss/seq after 02100 batchs: 936.561767578125
INFO:root:Train (Epoch 57): Loss/seq after 02150 batchs: 931.1689453125
INFO:root:Train (Epoch 57): Loss/seq after 02200 batchs: 924.3067626953125
INFO:root:Train (Epoch 57): Loss/seq after 02250 batchs: 924.9639892578125
INFO:root:Train (Epoch 57): Loss/seq after 02300 batchs: 932.2579345703125
INFO:root:Train (Epoch 57): Loss/seq after 02350 batchs: 925.7607421875
INFO:root:Train (Epoch 57): Loss/seq after 02400 batchs: 924.0579833984375
INFO:root:Train (Epoch 57): Loss/seq after 02450 batchs: 915.5069580078125
INFO:root:Train (Epoch 57): Loss/seq after 02500 batchs: 902.3865356445312
INFO:root:Train (Epoch 57): Loss/seq after 02550 batchs: 892.9202270507812
INFO:root:Train (Epoch 57): Loss/seq after 02600 batchs: 890.50634765625
INFO:root:Train (Epoch 57): Loss/seq after 02650 batchs: 886.5980834960938
INFO:root:Train (Epoch 57): Loss/seq after 02700 batchs: 883.4893188476562
INFO:root:Train (Epoch 57): Loss/seq after 02750 batchs: 909.1231689453125
INFO:root:Train (Epoch 57): Loss/seq after 02800 batchs: 912.7963256835938
INFO:root:Train (Epoch 57): Loss/seq after 02850 batchs: 910.7171020507812
INFO:root:Train (Epoch 57): Loss/seq after 02900 batchs: 910.226806640625
INFO:root:Train (Epoch 57): Loss/seq after 02950 batchs: 905.435546875
INFO:root:Train (Epoch 57): Loss/seq after 03000 batchs: 907.1595458984375
INFO:root:Train (Epoch 57): Loss/seq after 03050 batchs: 912.0839233398438
INFO:root:Train (Epoch 57): Loss/seq after 03100 batchs: 918.7960205078125
INFO:root:Train (Epoch 57): Loss/seq after 03150 batchs: 925.5427856445312
INFO:root:Train (Epoch 57): Loss/seq after 03200 batchs: 934.8025512695312
INFO:root:Train (Epoch 57): Loss/seq after 03250 batchs: 940.0947875976562
INFO:root:Train (Epoch 57): Loss/seq after 03300 batchs: 938.2100830078125
INFO:root:Train (Epoch 57): Loss/seq after 03350 batchs: 936.3915405273438
INFO:root:Train (Epoch 57): Loss/seq after 03400 batchs: 929.324462890625
INFO:root:Train (Epoch 57): Loss/seq after 03450 batchs: 924.5100708007812
INFO:root:Train (Epoch 57): Loss/seq after 03500 batchs: 923.3382568359375
INFO:root:Train (Epoch 57): Loss/seq after 03550 batchs: 918.2257080078125
INFO:root:Train (Epoch 57): Loss/seq after 03600 batchs: 925.5195922851562
INFO:root:Train (Epoch 57): Loss/seq after 03650 batchs: 920.6502075195312
INFO:root:Train (Epoch 57): Loss/seq after 03700 batchs: 920.626953125
INFO:root:Train (Epoch 57): Loss/seq after 03750 batchs: 923.5634765625
INFO:root:Train (Epoch 57): Loss/seq after 03800 batchs: 918.3552856445312
INFO:root:Train (Epoch 57): Loss/seq after 03850 batchs: 915.9967041015625
INFO:root:Train (Epoch 57): Loss/seq after 03900 batchs: 920.2706909179688
INFO:root:Train (Epoch 57): Loss/seq after 03950 batchs: 924.7455444335938
INFO:root:Train (Epoch 57): Loss/seq after 04000 batchs: 918.9296875
INFO:root:Train (Epoch 57): Loss/seq after 04050 batchs: 912.84619140625
INFO:root:Train (Epoch 57): Loss/seq after 04100 batchs: 908.6322021484375
INFO:root:Train (Epoch 57): Loss/seq after 04150 batchs: 905.6211547851562
INFO:root:Train (Epoch 57): Loss/seq after 04200 batchs: 902.3726196289062
INFO:root:Train (Epoch 57): Loss/seq after 04250 batchs: 899.2761840820312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 57): Loss/seq after 00000 batches: 782.9744873046875
INFO:root:# Valid (Epoch 57): Loss/seq after 00050 batches: 859.067138671875
INFO:root:# Valid (Epoch 57): Loss/seq after 00100 batches: 1143.9942626953125
INFO:root:# Valid (Epoch 57): Loss/seq after 00150 batches: 880.1041259765625
INFO:root:# Valid (Epoch 57): Loss/seq after 00200 batches: 802.496337890625
INFO:root:Artifacts: Make stick videos for epoch 57
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_57_on_20220412_233808.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_57_index_1466_on_20220412_233808.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 58): Loss/seq after 00000 batchs: 1712.3038330078125
INFO:root:Train (Epoch 58): Loss/seq after 00050 batchs: 1143.495361328125
INFO:root:Train (Epoch 58): Loss/seq after 00100 batchs: 1180.3724365234375
INFO:root:Train (Epoch 58): Loss/seq after 00150 batchs: 1064.8262939453125
INFO:root:Train (Epoch 58): Loss/seq after 00200 batchs: 1168.0653076171875
INFO:root:Train (Epoch 58): Loss/seq after 00250 batchs: 1273.8160400390625
INFO:root:Train (Epoch 58): Loss/seq after 00300 batchs: 1231.8131103515625
INFO:root:Train (Epoch 58): Loss/seq after 00350 batchs: 1147.475830078125
INFO:root:Train (Epoch 58): Loss/seq after 00400 batchs: 1165.211669921875
INFO:root:Train (Epoch 58): Loss/seq after 00450 batchs: 1127.4248046875
INFO:root:Train (Epoch 58): Loss/seq after 00500 batchs: 1114.85302734375
INFO:root:Train (Epoch 58): Loss/seq after 00550 batchs: 1078.48388671875
INFO:root:Train (Epoch 58): Loss/seq after 00600 batchs: 1043.5072021484375
INFO:root:Train (Epoch 58): Loss/seq after 00650 batchs: 1057.918701171875
INFO:root:Train (Epoch 58): Loss/seq after 00700 batchs: 1047.59228515625
INFO:root:Train (Epoch 58): Loss/seq after 00750 batchs: 1080.22509765625
INFO:root:Train (Epoch 58): Loss/seq after 00800 batchs: 1075.3084716796875
INFO:root:Train (Epoch 58): Loss/seq after 00850 batchs: 1045.95263671875
INFO:root:Train (Epoch 58): Loss/seq after 00900 batchs: 1032.0850830078125
INFO:root:Train (Epoch 58): Loss/seq after 00950 batchs: 1054.8428955078125
INFO:root:Train (Epoch 58): Loss/seq after 01000 batchs: 1048.767578125
INFO:root:Train (Epoch 58): Loss/seq after 01050 batchs: 1031.7982177734375
INFO:root:Train (Epoch 58): Loss/seq after 01100 batchs: 1016.22607421875
INFO:root:Train (Epoch 58): Loss/seq after 01150 batchs: 993.4197998046875
INFO:root:Train (Epoch 58): Loss/seq after 01200 batchs: 991.365966796875
INFO:root:Train (Epoch 58): Loss/seq after 01250 batchs: 987.3312377929688
INFO:root:Train (Epoch 58): Loss/seq after 01300 batchs: 981.4341430664062
INFO:root:Train (Epoch 58): Loss/seq after 01350 batchs: 977.8262329101562
INFO:root:Train (Epoch 58): Loss/seq after 01400 batchs: 999.17041015625
INFO:root:Train (Epoch 58): Loss/seq after 01450 batchs: 997.6402587890625
INFO:root:Train (Epoch 58): Loss/seq after 01500 batchs: 996.8931884765625
INFO:root:Train (Epoch 58): Loss/seq after 01550 batchs: 998.8321533203125
INFO:root:Train (Epoch 58): Loss/seq after 01600 batchs: 988.3598022460938
INFO:root:Train (Epoch 58): Loss/seq after 01650 batchs: 980.92431640625
INFO:root:Train (Epoch 58): Loss/seq after 01700 batchs: 976.6372680664062
INFO:root:Train (Epoch 58): Loss/seq after 01750 batchs: 969.9276123046875
INFO:root:Train (Epoch 58): Loss/seq after 01800 batchs: 961.8204345703125
INFO:root:Train (Epoch 58): Loss/seq after 01850 batchs: 952.4954223632812
INFO:root:Train (Epoch 58): Loss/seq after 01900 batchs: 952.6194458007812
INFO:root:Train (Epoch 58): Loss/seq after 01950 batchs: 946.9547729492188
INFO:root:Train (Epoch 58): Loss/seq after 02000 batchs: 942.7481689453125
INFO:root:Train (Epoch 58): Loss/seq after 02050 batchs: 938.1116333007812
INFO:root:Train (Epoch 58): Loss/seq after 02100 batchs: 930.5761108398438
INFO:root:Train (Epoch 58): Loss/seq after 02150 batchs: 924.7013549804688
INFO:root:Train (Epoch 58): Loss/seq after 02200 batchs: 917.6719970703125
INFO:root:Train (Epoch 58): Loss/seq after 02250 batchs: 918.3220825195312
INFO:root:Train (Epoch 58): Loss/seq after 02300 batchs: 925.23779296875
INFO:root:Train (Epoch 58): Loss/seq after 02350 batchs: 917.371826171875
INFO:root:Train (Epoch 58): Loss/seq after 02400 batchs: 914.4303588867188
INFO:root:Train (Epoch 58): Loss/seq after 02450 batchs: 905.45263671875
INFO:root:Train (Epoch 58): Loss/seq after 02500 batchs: 891.8048706054688
INFO:root:Train (Epoch 58): Loss/seq after 02550 batchs: 882.0548706054688
INFO:root:Train (Epoch 58): Loss/seq after 02600 batchs: 879.5558471679688
INFO:root:Train (Epoch 58): Loss/seq after 02650 batchs: 875.0419921875
INFO:root:Train (Epoch 58): Loss/seq after 02700 batchs: 871.7757568359375
INFO:root:Train (Epoch 58): Loss/seq after 02750 batchs: 897.7528686523438
INFO:root:Train (Epoch 58): Loss/seq after 02800 batchs: 901.454833984375
INFO:root:Train (Epoch 58): Loss/seq after 02850 batchs: 899.1154174804688
INFO:root:Train (Epoch 58): Loss/seq after 02900 batchs: 898.3906860351562
INFO:root:Train (Epoch 58): Loss/seq after 02950 batchs: 893.8501586914062
INFO:root:Train (Epoch 58): Loss/seq after 03000 batchs: 895.3924560546875
INFO:root:Train (Epoch 58): Loss/seq after 03050 batchs: 900.2008666992188
INFO:root:Train (Epoch 58): Loss/seq after 03100 batchs: 906.6399536132812
INFO:root:Train (Epoch 58): Loss/seq after 03150 batchs: 913.2874145507812
INFO:root:Train (Epoch 58): Loss/seq after 03200 batchs: 920.5320434570312
INFO:root:Train (Epoch 58): Loss/seq after 03250 batchs: 925.443603515625
INFO:root:Train (Epoch 58): Loss/seq after 03300 batchs: 924.8738403320312
INFO:root:Train (Epoch 58): Loss/seq after 03350 batchs: 923.1668701171875
INFO:root:Train (Epoch 58): Loss/seq after 03400 batchs: 915.5784301757812
INFO:root:Train (Epoch 58): Loss/seq after 03450 batchs: 910.7619018554688
INFO:root:Train (Epoch 58): Loss/seq after 03500 batchs: 909.6180419921875
INFO:root:Train (Epoch 58): Loss/seq after 03550 batchs: 904.5629272460938
INFO:root:Train (Epoch 58): Loss/seq after 03600 batchs: 911.5223388671875
INFO:root:Train (Epoch 58): Loss/seq after 03650 batchs: 906.7496337890625
INFO:root:Train (Epoch 58): Loss/seq after 03700 batchs: 906.8966064453125
INFO:root:Train (Epoch 58): Loss/seq after 03750 batchs: 909.6876831054688
INFO:root:Train (Epoch 58): Loss/seq after 03800 batchs: 904.4437866210938
INFO:root:Train (Epoch 58): Loss/seq after 03850 batchs: 902.0057373046875
INFO:root:Train (Epoch 58): Loss/seq after 03900 batchs: 905.7711181640625
INFO:root:Train (Epoch 58): Loss/seq after 03950 batchs: 909.7882080078125
INFO:root:Train (Epoch 58): Loss/seq after 04000 batchs: 903.9281616210938
INFO:root:Train (Epoch 58): Loss/seq after 04050 batchs: 897.7246704101562
INFO:root:Train (Epoch 58): Loss/seq after 04100 batchs: 893.5574340820312
INFO:root:Train (Epoch 58): Loss/seq after 04150 batchs: 890.6229248046875
INFO:root:Train (Epoch 58): Loss/seq after 04200 batchs: 887.349365234375
INFO:root:Train (Epoch 58): Loss/seq after 04250 batchs: 884.2327270507812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 58): Loss/seq after 00000 batches: 619.1583251953125
INFO:root:# Valid (Epoch 58): Loss/seq after 00050 batches: 805.182373046875
INFO:root:# Valid (Epoch 58): Loss/seq after 00100 batches: 1093.5625
INFO:root:# Valid (Epoch 58): Loss/seq after 00150 batches: 836.4830322265625
INFO:root:# Valid (Epoch 58): Loss/seq after 00200 batches: 773.8180541992188
INFO:root:Artifacts: Make stick videos for epoch 58
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_58_on_20220412_234328.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_58_index_630_on_20220412_234328.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 59): Loss/seq after 00000 batchs: 1521.6259765625
INFO:root:Train (Epoch 59): Loss/seq after 00050 batchs: 1120.91748046875
INFO:root:Train (Epoch 59): Loss/seq after 00100 batchs: 1149.98876953125
INFO:root:Train (Epoch 59): Loss/seq after 00150 batchs: 1034.4591064453125
INFO:root:Train (Epoch 59): Loss/seq after 00200 batchs: 1144.789794921875
INFO:root:Train (Epoch 59): Loss/seq after 00250 batchs: 1260.5296630859375
INFO:root:Train (Epoch 59): Loss/seq after 00300 batchs: 1217.05517578125
INFO:root:Train (Epoch 59): Loss/seq after 00350 batchs: 1130.9698486328125
INFO:root:Train (Epoch 59): Loss/seq after 00400 batchs: 1151.626953125
INFO:root:Train (Epoch 59): Loss/seq after 00450 batchs: 1114.0892333984375
INFO:root:Train (Epoch 59): Loss/seq after 00500 batchs: 1104.9527587890625
INFO:root:Train (Epoch 59): Loss/seq after 00550 batchs: 1067.5916748046875
INFO:root:Train (Epoch 59): Loss/seq after 00600 batchs: 1035.90576171875
INFO:root:Train (Epoch 59): Loss/seq after 00650 batchs: 1051.9371337890625
INFO:root:Train (Epoch 59): Loss/seq after 00700 batchs: 1038.767333984375
INFO:root:Train (Epoch 59): Loss/seq after 00750 batchs: 1071.9443359375
INFO:root:Train (Epoch 59): Loss/seq after 00800 batchs: 1067.34521484375
INFO:root:Train (Epoch 59): Loss/seq after 00850 batchs: 1035.270263671875
INFO:root:Train (Epoch 59): Loss/seq after 00900 batchs: 1017.29052734375
INFO:root:Train (Epoch 59): Loss/seq after 00950 batchs: 1035.2391357421875
INFO:root:Train (Epoch 59): Loss/seq after 01000 batchs: 1029.8671875
INFO:root:Train (Epoch 59): Loss/seq after 01050 batchs: 1011.3059692382812
INFO:root:Train (Epoch 59): Loss/seq after 01100 batchs: 995.0729370117188
INFO:root:Train (Epoch 59): Loss/seq after 01150 batchs: 971.7586059570312
INFO:root:Train (Epoch 59): Loss/seq after 01200 batchs: 969.2263793945312
INFO:root:Train (Epoch 59): Loss/seq after 01250 batchs: 962.4567260742188
INFO:root:Train (Epoch 59): Loss/seq after 01300 batchs: 958.1193237304688
INFO:root:Train (Epoch 59): Loss/seq after 01350 batchs: 954.773681640625
INFO:root:Train (Epoch 59): Loss/seq after 01400 batchs: 973.4072875976562
INFO:root:Train (Epoch 59): Loss/seq after 01450 batchs: 970.630859375
INFO:root:Train (Epoch 59): Loss/seq after 01500 batchs: 970.0970458984375
INFO:root:Train (Epoch 59): Loss/seq after 01550 batchs: 971.3982543945312
INFO:root:Train (Epoch 59): Loss/seq after 01600 batchs: 961.8027954101562
INFO:root:Train (Epoch 59): Loss/seq after 01650 batchs: 954.8467407226562
INFO:root:Train (Epoch 59): Loss/seq after 01700 batchs: 951.0623779296875
INFO:root:Train (Epoch 59): Loss/seq after 01750 batchs: 944.1600952148438
INFO:root:Train (Epoch 59): Loss/seq after 01800 batchs: 935.9556884765625
INFO:root:Train (Epoch 59): Loss/seq after 01850 batchs: 926.8304443359375
INFO:root:Train (Epoch 59): Loss/seq after 01900 batchs: 926.2070922851562
INFO:root:Train (Epoch 59): Loss/seq after 01950 batchs: 920.1503295898438
INFO:root:Train (Epoch 59): Loss/seq after 02000 batchs: 915.4505004882812
INFO:root:Train (Epoch 59): Loss/seq after 02050 batchs: 911.2796020507812
INFO:root:Train (Epoch 59): Loss/seq after 02100 batchs: 904.1389770507812
INFO:root:Train (Epoch 59): Loss/seq after 02150 batchs: 898.5197143554688
INFO:root:Train (Epoch 59): Loss/seq after 02200 batchs: 891.6381225585938
INFO:root:Train (Epoch 59): Loss/seq after 02250 batchs: 892.3015747070312
INFO:root:Train (Epoch 59): Loss/seq after 02300 batchs: 899.2529296875
INFO:root:Train (Epoch 59): Loss/seq after 02350 batchs: 891.8141479492188
INFO:root:Train (Epoch 59): Loss/seq after 02400 batchs: 890.2213745117188
INFO:root:Train (Epoch 59): Loss/seq after 02450 batchs: 882.2050170898438
INFO:root:Train (Epoch 59): Loss/seq after 02500 batchs: 868.55078125
INFO:root:Train (Epoch 59): Loss/seq after 02550 batchs: 858.7691040039062
INFO:root:Train (Epoch 59): Loss/seq after 02600 batchs: 856.6600341796875
INFO:root:Train (Epoch 59): Loss/seq after 02650 batchs: 852.297119140625
INFO:root:Train (Epoch 59): Loss/seq after 02700 batchs: 849.00634765625
INFO:root:Train (Epoch 59): Loss/seq after 02750 batchs: 873.9114990234375
INFO:root:Train (Epoch 59): Loss/seq after 02800 batchs: 877.2476806640625
INFO:root:Train (Epoch 59): Loss/seq after 02850 batchs: 875.13916015625
INFO:root:Train (Epoch 59): Loss/seq after 02900 batchs: 874.5357055664062
INFO:root:Train (Epoch 59): Loss/seq after 02950 batchs: 870.0532836914062
INFO:root:Train (Epoch 59): Loss/seq after 03000 batchs: 871.8226928710938
INFO:root:Train (Epoch 59): Loss/seq after 03050 batchs: 876.7716674804688
INFO:root:Train (Epoch 59): Loss/seq after 03100 batchs: 882.947998046875
INFO:root:Train (Epoch 59): Loss/seq after 03150 batchs: 887.8047485351562
INFO:root:Train (Epoch 59): Loss/seq after 03200 batchs: 894.4108276367188
INFO:root:Train (Epoch 59): Loss/seq after 03250 batchs: 899.2855224609375
INFO:root:Train (Epoch 59): Loss/seq after 03300 batchs: 897.81787109375
INFO:root:Train (Epoch 59): Loss/seq after 03350 batchs: 896.2579956054688
INFO:root:Train (Epoch 59): Loss/seq after 03400 batchs: 888.6475830078125
INFO:root:Train (Epoch 59): Loss/seq after 03450 batchs: 883.9591674804688
INFO:root:Train (Epoch 59): Loss/seq after 03500 batchs: 883.0060424804688
INFO:root:Train (Epoch 59): Loss/seq after 03550 batchs: 877.8566284179688
INFO:root:Train (Epoch 59): Loss/seq after 03600 batchs: 885.18896484375
INFO:root:Train (Epoch 59): Loss/seq after 03650 batchs: 880.6039428710938
INFO:root:Train (Epoch 59): Loss/seq after 03700 batchs: 881.2073974609375
INFO:root:Train (Epoch 59): Loss/seq after 03750 batchs: 884.6072998046875
INFO:root:Train (Epoch 59): Loss/seq after 03800 batchs: 879.5382690429688
INFO:root:Train (Epoch 59): Loss/seq after 03850 batchs: 877.2966918945312
INFO:root:Train (Epoch 59): Loss/seq after 03900 batchs: 881.3876342773438
INFO:root:Train (Epoch 59): Loss/seq after 03950 batchs: 885.6704711914062
INFO:root:Train (Epoch 59): Loss/seq after 04000 batchs: 880.0664672851562
INFO:root:Train (Epoch 59): Loss/seq after 04050 batchs: 873.9830932617188
INFO:root:Train (Epoch 59): Loss/seq after 04100 batchs: 870.0442504882812
INFO:root:Train (Epoch 59): Loss/seq after 04150 batchs: 867.2418823242188
INFO:root:Train (Epoch 59): Loss/seq after 04200 batchs: 864.2831420898438
INFO:root:Train (Epoch 59): Loss/seq after 04250 batchs: 861.160400390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 59): Loss/seq after 00000 batches: 566.3981323242188
INFO:root:# Valid (Epoch 59): Loss/seq after 00050 batches: 748.60498046875
INFO:root:# Valid (Epoch 59): Loss/seq after 00100 batches: 1057.912841796875
INFO:root:# Valid (Epoch 59): Loss/seq after 00150 batches: 813.1239624023438
INFO:root:# Valid (Epoch 59): Loss/seq after 00200 batches: 756.2227172851562
INFO:root:Artifacts: Make stick videos for epoch 59
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_59_on_20220412_234849.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_59_index_605_on_20220412_234849.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 60): Loss/seq after 00000 batchs: 1492.70947265625
INFO:root:Train (Epoch 60): Loss/seq after 00050 batchs: 1092.07080078125
INFO:root:Train (Epoch 60): Loss/seq after 00100 batchs: 1154.1904296875
INFO:root:Train (Epoch 60): Loss/seq after 00150 batchs: 1038.2213134765625
INFO:root:Train (Epoch 60): Loss/seq after 00200 batchs: 1144.98095703125
INFO:root:Train (Epoch 60): Loss/seq after 00250 batchs: 1255.96142578125
INFO:root:Train (Epoch 60): Loss/seq after 00300 batchs: 1214.4078369140625
INFO:root:Train (Epoch 60): Loss/seq after 00350 batchs: 1130.1392822265625
INFO:root:Train (Epoch 60): Loss/seq after 00400 batchs: 1153.897216796875
INFO:root:Train (Epoch 60): Loss/seq after 00450 batchs: 1115.9154052734375
INFO:root:Train (Epoch 60): Loss/seq after 00500 batchs: 1102.3211669921875
INFO:root:Train (Epoch 60): Loss/seq after 00550 batchs: 1062.1014404296875
INFO:root:Train (Epoch 60): Loss/seq after 00600 batchs: 1024.664794921875
INFO:root:Train (Epoch 60): Loss/seq after 00650 batchs: 1038.8050537109375
INFO:root:Train (Epoch 60): Loss/seq after 00700 batchs: 1030.18115234375
INFO:root:Train (Epoch 60): Loss/seq after 00750 batchs: 1061.2108154296875
INFO:root:Train (Epoch 60): Loss/seq after 00800 batchs: 1055.180419921875
INFO:root:Train (Epoch 60): Loss/seq after 00850 batchs: 1023.2617797851562
INFO:root:Train (Epoch 60): Loss/seq after 00900 batchs: 1004.8946533203125
INFO:root:Train (Epoch 60): Loss/seq after 00950 batchs: 1020.4698486328125
INFO:root:Train (Epoch 60): Loss/seq after 01000 batchs: 1012.6754760742188
INFO:root:Train (Epoch 60): Loss/seq after 01050 batchs: 994.9652709960938
INFO:root:Train (Epoch 60): Loss/seq after 01100 batchs: 978.0152587890625
INFO:root:Train (Epoch 60): Loss/seq after 01150 batchs: 954.4710083007812
INFO:root:Train (Epoch 60): Loss/seq after 01200 batchs: 951.7900390625
INFO:root:Train (Epoch 60): Loss/seq after 01250 batchs: 946.0438842773438
INFO:root:Train (Epoch 60): Loss/seq after 01300 batchs: 940.0826416015625
INFO:root:Train (Epoch 60): Loss/seq after 01350 batchs: 934.6040649414062
INFO:root:Train (Epoch 60): Loss/seq after 01400 batchs: 955.5173950195312
INFO:root:Train (Epoch 60): Loss/seq after 01450 batchs: 952.4517211914062
INFO:root:Train (Epoch 60): Loss/seq after 01500 batchs: 952.2257080078125
INFO:root:Train (Epoch 60): Loss/seq after 01550 batchs: 954.2111206054688
INFO:root:Train (Epoch 60): Loss/seq after 01600 batchs: 944.6717529296875
INFO:root:Train (Epoch 60): Loss/seq after 01650 batchs: 937.3568725585938
INFO:root:Train (Epoch 60): Loss/seq after 01700 batchs: 933.74951171875
INFO:root:Train (Epoch 60): Loss/seq after 01750 batchs: 927.0014038085938
INFO:root:Train (Epoch 60): Loss/seq after 01800 batchs: 919.3519287109375
INFO:root:Train (Epoch 60): Loss/seq after 01850 batchs: 910.750244140625
INFO:root:Train (Epoch 60): Loss/seq after 01900 batchs: 910.4733276367188
INFO:root:Train (Epoch 60): Loss/seq after 01950 batchs: 904.7920532226562
INFO:root:Train (Epoch 60): Loss/seq after 02000 batchs: 900.5239868164062
INFO:root:Train (Epoch 60): Loss/seq after 02050 batchs: 896.3757934570312
INFO:root:Train (Epoch 60): Loss/seq after 02100 batchs: 889.2957153320312
INFO:root:Train (Epoch 60): Loss/seq after 02150 batchs: 883.7020874023438
INFO:root:Train (Epoch 60): Loss/seq after 02200 batchs: 877.1087646484375
INFO:root:Train (Epoch 60): Loss/seq after 02250 batchs: 877.85205078125
INFO:root:Train (Epoch 60): Loss/seq after 02300 batchs: 884.95263671875
INFO:root:Train (Epoch 60): Loss/seq after 02350 batchs: 877.130126953125
INFO:root:Train (Epoch 60): Loss/seq after 02400 batchs: 874.5306396484375
INFO:root:Train (Epoch 60): Loss/seq after 02450 batchs: 865.957275390625
INFO:root:Train (Epoch 60): Loss/seq after 02500 batchs: 852.4564208984375
INFO:root:Train (Epoch 60): Loss/seq after 02550 batchs: 842.605712890625
INFO:root:Train (Epoch 60): Loss/seq after 02600 batchs: 840.1388549804688
INFO:root:Train (Epoch 60): Loss/seq after 02650 batchs: 835.8174438476562
INFO:root:Train (Epoch 60): Loss/seq after 02700 batchs: 832.635009765625
INFO:root:Train (Epoch 60): Loss/seq after 02750 batchs: 858.0379028320312
INFO:root:Train (Epoch 60): Loss/seq after 02800 batchs: 861.7405395507812
INFO:root:Train (Epoch 60): Loss/seq after 02850 batchs: 859.4974975585938
INFO:root:Train (Epoch 60): Loss/seq after 02900 batchs: 858.9775390625
INFO:root:Train (Epoch 60): Loss/seq after 02950 batchs: 854.9407958984375
INFO:root:Train (Epoch 60): Loss/seq after 03000 batchs: 856.8698120117188
INFO:root:Train (Epoch 60): Loss/seq after 03050 batchs: 861.652099609375
INFO:root:Train (Epoch 60): Loss/seq after 03100 batchs: 868.6287231445312
INFO:root:Train (Epoch 60): Loss/seq after 03150 batchs: 874.3760986328125
INFO:root:Train (Epoch 60): Loss/seq after 03200 batchs: 881.9853515625
INFO:root:Train (Epoch 60): Loss/seq after 03250 batchs: 886.1240234375
INFO:root:Train (Epoch 60): Loss/seq after 03300 batchs: 884.3330078125
INFO:root:Train (Epoch 60): Loss/seq after 03350 batchs: 882.4970703125
INFO:root:Train (Epoch 60): Loss/seq after 03400 batchs: 874.7804565429688
INFO:root:Train (Epoch 60): Loss/seq after 03450 batchs: 870.2582397460938
INFO:root:Train (Epoch 60): Loss/seq after 03500 batchs: 869.3763427734375
INFO:root:Train (Epoch 60): Loss/seq after 03550 batchs: 864.5840454101562
INFO:root:Train (Epoch 60): Loss/seq after 03600 batchs: 871.8690185546875
INFO:root:Train (Epoch 60): Loss/seq after 03650 batchs: 867.6339721679688
INFO:root:Train (Epoch 60): Loss/seq after 03700 batchs: 868.3632202148438
INFO:root:Train (Epoch 60): Loss/seq after 03750 batchs: 871.8666381835938
INFO:root:Train (Epoch 60): Loss/seq after 03800 batchs: 866.93017578125
INFO:root:Train (Epoch 60): Loss/seq after 03850 batchs: 864.7349243164062
INFO:root:Train (Epoch 60): Loss/seq after 03900 batchs: 868.6239013671875
INFO:root:Train (Epoch 60): Loss/seq after 03950 batchs: 872.62255859375
INFO:root:Train (Epoch 60): Loss/seq after 04000 batchs: 867.1151733398438
INFO:root:Train (Epoch 60): Loss/seq after 04050 batchs: 861.1727905273438
INFO:root:Train (Epoch 60): Loss/seq after 04100 batchs: 857.2208862304688
INFO:root:Train (Epoch 60): Loss/seq after 04150 batchs: 854.541015625
INFO:root:Train (Epoch 60): Loss/seq after 04200 batchs: 851.4578247070312
INFO:root:Train (Epoch 60): Loss/seq after 04250 batchs: 848.2120971679688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 60): Loss/seq after 00000 batches: 538.1236572265625
INFO:root:# Valid (Epoch 60): Loss/seq after 00050 batches: 742.5574951171875
INFO:root:# Valid (Epoch 60): Loss/seq after 00100 batches: 1030.267822265625
INFO:root:# Valid (Epoch 60): Loss/seq after 00150 batches: 790.0659790039062
INFO:root:# Valid (Epoch 60): Loss/seq after 00200 batches: 739.4298706054688
INFO:root:Artifacts: Make stick videos for epoch 60
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_60_on_20220412_235411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_60_index_1751_on_20220412_235411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 61): Loss/seq after 00000 batchs: 1423.76953125
INFO:root:Train (Epoch 61): Loss/seq after 00050 batchs: 1057.476318359375
INFO:root:Train (Epoch 61): Loss/seq after 00100 batchs: 1090.39306640625
INFO:root:Train (Epoch 61): Loss/seq after 00150 batchs: 989.5787353515625
INFO:root:Train (Epoch 61): Loss/seq after 00200 batchs: 1108.40234375
INFO:root:Train (Epoch 61): Loss/seq after 00250 batchs: 1224.37109375
INFO:root:Train (Epoch 61): Loss/seq after 00300 batchs: 1185.33984375
INFO:root:Train (Epoch 61): Loss/seq after 00350 batchs: 1101.2889404296875
INFO:root:Train (Epoch 61): Loss/seq after 00400 batchs: 1123.296142578125
INFO:root:Train (Epoch 61): Loss/seq after 00450 batchs: 1087.6492919921875
INFO:root:Train (Epoch 61): Loss/seq after 00500 batchs: 1071.748779296875
INFO:root:Train (Epoch 61): Loss/seq after 00550 batchs: 1035.8087158203125
INFO:root:Train (Epoch 61): Loss/seq after 00600 batchs: 998.8984985351562
INFO:root:Train (Epoch 61): Loss/seq after 00650 batchs: 1015.0462036132812
INFO:root:Train (Epoch 61): Loss/seq after 00700 batchs: 998.7650146484375
INFO:root:Train (Epoch 61): Loss/seq after 00750 batchs: 1031.830322265625
INFO:root:Train (Epoch 61): Loss/seq after 00800 batchs: 1024.30078125
INFO:root:Train (Epoch 61): Loss/seq after 00850 batchs: 992.6275024414062
INFO:root:Train (Epoch 61): Loss/seq after 00900 batchs: 975.257080078125
INFO:root:Train (Epoch 61): Loss/seq after 00950 batchs: 990.1043701171875
INFO:root:Train (Epoch 61): Loss/seq after 01000 batchs: 984.0738525390625
INFO:root:Train (Epoch 61): Loss/seq after 01050 batchs: 964.78369140625
INFO:root:Train (Epoch 61): Loss/seq after 01100 batchs: 948.7354736328125
INFO:root:Train (Epoch 61): Loss/seq after 01150 batchs: 925.8405151367188
INFO:root:Train (Epoch 61): Loss/seq after 01200 batchs: 924.0668334960938
INFO:root:Train (Epoch 61): Loss/seq after 01250 batchs: 918.9296264648438
INFO:root:Train (Epoch 61): Loss/seq after 01300 batchs: 912.185302734375
INFO:root:Train (Epoch 61): Loss/seq after 01350 batchs: 906.3112182617188
INFO:root:Train (Epoch 61): Loss/seq after 01400 batchs: 926.2427368164062
INFO:root:Train (Epoch 61): Loss/seq after 01450 batchs: 925.4346313476562
INFO:root:Train (Epoch 61): Loss/seq after 01500 batchs: 926.0031127929688
INFO:root:Train (Epoch 61): Loss/seq after 01550 batchs: 928.674560546875
INFO:root:Train (Epoch 61): Loss/seq after 01600 batchs: 920.179443359375
INFO:root:Train (Epoch 61): Loss/seq after 01650 batchs: 914.531005859375
INFO:root:Train (Epoch 61): Loss/seq after 01700 batchs: 911.1190795898438
INFO:root:Train (Epoch 61): Loss/seq after 01750 batchs: 904.72705078125
INFO:root:Train (Epoch 61): Loss/seq after 01800 batchs: 897.37939453125
INFO:root:Train (Epoch 61): Loss/seq after 01850 batchs: 889.1729736328125
INFO:root:Train (Epoch 61): Loss/seq after 01900 batchs: 888.7542114257812
INFO:root:Train (Epoch 61): Loss/seq after 01950 batchs: 883.3646240234375
INFO:root:Train (Epoch 61): Loss/seq after 02000 batchs: 878.9290161132812
INFO:root:Train (Epoch 61): Loss/seq after 02050 batchs: 875.1071166992188
INFO:root:Train (Epoch 61): Loss/seq after 02100 batchs: 868.525390625
INFO:root:Train (Epoch 61): Loss/seq after 02150 batchs: 863.4847412109375
INFO:root:Train (Epoch 61): Loss/seq after 02200 batchs: 857.3278198242188
INFO:root:Train (Epoch 61): Loss/seq after 02250 batchs: 857.8286743164062
INFO:root:Train (Epoch 61): Loss/seq after 02300 batchs: 865.1701049804688
INFO:root:Train (Epoch 61): Loss/seq after 02350 batchs: 857.6476440429688
INFO:root:Train (Epoch 61): Loss/seq after 02400 batchs: 855.6145629882812
INFO:root:Train (Epoch 61): Loss/seq after 02450 batchs: 847.3513793945312
INFO:root:Train (Epoch 61): Loss/seq after 02500 batchs: 834.10888671875
INFO:root:Train (Epoch 61): Loss/seq after 02550 batchs: 824.521240234375
INFO:root:Train (Epoch 61): Loss/seq after 02600 batchs: 822.5220947265625
INFO:root:Train (Epoch 61): Loss/seq after 02650 batchs: 818.5896606445312
INFO:root:Train (Epoch 61): Loss/seq after 02700 batchs: 815.5467529296875
INFO:root:Train (Epoch 61): Loss/seq after 02750 batchs: 841.2237548828125
INFO:root:Train (Epoch 61): Loss/seq after 02800 batchs: 845.0199584960938
INFO:root:Train (Epoch 61): Loss/seq after 02850 batchs: 843.156982421875
INFO:root:Train (Epoch 61): Loss/seq after 02900 batchs: 843.4611206054688
INFO:root:Train (Epoch 61): Loss/seq after 02950 batchs: 839.4534301757812
INFO:root:Train (Epoch 61): Loss/seq after 03000 batchs: 841.505126953125
INFO:root:Train (Epoch 61): Loss/seq after 03050 batchs: 846.5265502929688
INFO:root:Train (Epoch 61): Loss/seq after 03100 batchs: 854.533447265625
INFO:root:Train (Epoch 61): Loss/seq after 03150 batchs: 861.1329345703125
INFO:root:Train (Epoch 61): Loss/seq after 03200 batchs: 868.2077026367188
INFO:root:Train (Epoch 61): Loss/seq after 03250 batchs: 874.1249389648438
INFO:root:Train (Epoch 61): Loss/seq after 03300 batchs: 875.1849975585938
INFO:root:Train (Epoch 61): Loss/seq after 03350 batchs: 876.5501708984375
INFO:root:Train (Epoch 61): Loss/seq after 03400 batchs: 869.2774658203125
INFO:root:Train (Epoch 61): Loss/seq after 03450 batchs: 865.5769653320312
INFO:root:Train (Epoch 61): Loss/seq after 03500 batchs: 866.2614135742188
INFO:root:Train (Epoch 61): Loss/seq after 03550 batchs: 861.9949951171875
INFO:root:Train (Epoch 61): Loss/seq after 03600 batchs: 869.5520629882812
INFO:root:Train (Epoch 61): Loss/seq after 03650 batchs: 865.027587890625
INFO:root:Train (Epoch 61): Loss/seq after 03700 batchs: 865.2683715820312
INFO:root:Train (Epoch 61): Loss/seq after 03750 batchs: 868.5240478515625
INFO:root:Train (Epoch 61): Loss/seq after 03800 batchs: 863.4874877929688
INFO:root:Train (Epoch 61): Loss/seq after 03850 batchs: 861.2628784179688
INFO:root:Train (Epoch 61): Loss/seq after 03900 batchs: 865.6717529296875
INFO:root:Train (Epoch 61): Loss/seq after 03950 batchs: 869.6544799804688
INFO:root:Train (Epoch 61): Loss/seq after 04000 batchs: 864.2357788085938
INFO:root:Train (Epoch 61): Loss/seq after 04050 batchs: 858.1842041015625
INFO:root:Train (Epoch 61): Loss/seq after 04100 batchs: 854.1846923828125
INFO:root:Train (Epoch 61): Loss/seq after 04150 batchs: 851.4529418945312
INFO:root:Train (Epoch 61): Loss/seq after 04200 batchs: 848.6280517578125
INFO:root:Train (Epoch 61): Loss/seq after 04250 batchs: 845.7545776367188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 61): Loss/seq after 00000 batches: 573.9165649414062
INFO:root:# Valid (Epoch 61): Loss/seq after 00050 batches: 735.6561279296875
INFO:root:# Valid (Epoch 61): Loss/seq after 00100 batches: 1017.1177368164062
INFO:root:# Valid (Epoch 61): Loss/seq after 00150 batches: 774.6044311523438
INFO:root:# Valid (Epoch 61): Loss/seq after 00200 batches: 718.3344116210938
INFO:root:Artifacts: Make stick videos for epoch 61
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_61_on_20220412_235933.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_61_index_123_on_20220412_235933.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 62): Loss/seq after 00000 batchs: 1472.78076171875
INFO:root:Train (Epoch 62): Loss/seq after 00050 batchs: 1068.904052734375
INFO:root:Train (Epoch 62): Loss/seq after 00100 batchs: 1099.7647705078125
INFO:root:Train (Epoch 62): Loss/seq after 00150 batchs: 1004.6843872070312
INFO:root:Train (Epoch 62): Loss/seq after 00200 batchs: 1127.5875244140625
INFO:root:Train (Epoch 62): Loss/seq after 00250 batchs: 1244.45166015625
INFO:root:Train (Epoch 62): Loss/seq after 00300 batchs: 1202.4140625
INFO:root:Train (Epoch 62): Loss/seq after 00350 batchs: 1116.4254150390625
INFO:root:Train (Epoch 62): Loss/seq after 00400 batchs: 1135.16259765625
INFO:root:Train (Epoch 62): Loss/seq after 00450 batchs: 1098.162841796875
INFO:root:Train (Epoch 62): Loss/seq after 00500 batchs: 1085.4189453125
INFO:root:Train (Epoch 62): Loss/seq after 00550 batchs: 1046.4437255859375
INFO:root:Train (Epoch 62): Loss/seq after 00600 batchs: 1007.3925170898438
INFO:root:Train (Epoch 62): Loss/seq after 00650 batchs: 1017.5975341796875
INFO:root:Train (Epoch 62): Loss/seq after 00700 batchs: 999.625
INFO:root:Train (Epoch 62): Loss/seq after 00750 batchs: 1037.8941650390625
INFO:root:Train (Epoch 62): Loss/seq after 00800 batchs: 1030.6114501953125
INFO:root:Train (Epoch 62): Loss/seq after 00850 batchs: 999.1508178710938
INFO:root:Train (Epoch 62): Loss/seq after 00900 batchs: 982.0138549804688
INFO:root:Train (Epoch 62): Loss/seq after 00950 batchs: 995.387939453125
INFO:root:Train (Epoch 62): Loss/seq after 01000 batchs: 988.4247436523438
INFO:root:Train (Epoch 62): Loss/seq after 01050 batchs: 970.5054931640625
INFO:root:Train (Epoch 62): Loss/seq after 01100 batchs: 952.8427734375
INFO:root:Train (Epoch 62): Loss/seq after 01150 batchs: 929.5780029296875
INFO:root:Train (Epoch 62): Loss/seq after 01200 batchs: 927.3648681640625
INFO:root:Train (Epoch 62): Loss/seq after 01250 batchs: 920.2534790039062
INFO:root:Train (Epoch 62): Loss/seq after 01300 batchs: 913.9203491210938
INFO:root:Train (Epoch 62): Loss/seq after 01350 batchs: 907.2282104492188
INFO:root:Train (Epoch 62): Loss/seq after 01400 batchs: 924.625244140625
INFO:root:Train (Epoch 62): Loss/seq after 01450 batchs: 922.918212890625
INFO:root:Train (Epoch 62): Loss/seq after 01500 batchs: 923.1434936523438
INFO:root:Train (Epoch 62): Loss/seq after 01550 batchs: 925.3201904296875
INFO:root:Train (Epoch 62): Loss/seq after 01600 batchs: 916.2048950195312
INFO:root:Train (Epoch 62): Loss/seq after 01650 batchs: 909.43505859375
INFO:root:Train (Epoch 62): Loss/seq after 01700 batchs: 905.8466796875
INFO:root:Train (Epoch 62): Loss/seq after 01750 batchs: 899.3583374023438
INFO:root:Train (Epoch 62): Loss/seq after 01800 batchs: 891.7685546875
INFO:root:Train (Epoch 62): Loss/seq after 01850 batchs: 883.435546875
INFO:root:Train (Epoch 62): Loss/seq after 01900 batchs: 883.455810546875
INFO:root:Train (Epoch 62): Loss/seq after 01950 batchs: 878.48828125
INFO:root:Train (Epoch 62): Loss/seq after 02000 batchs: 873.9039306640625
INFO:root:Train (Epoch 62): Loss/seq after 02050 batchs: 870.1932983398438
INFO:root:Train (Epoch 62): Loss/seq after 02100 batchs: 863.6949462890625
INFO:root:Train (Epoch 62): Loss/seq after 02150 batchs: 858.9813842773438
INFO:root:Train (Epoch 62): Loss/seq after 02200 batchs: 852.9228515625
INFO:root:Train (Epoch 62): Loss/seq after 02250 batchs: 854.0846557617188
INFO:root:Train (Epoch 62): Loss/seq after 02300 batchs: 861.511962890625
INFO:root:Train (Epoch 62): Loss/seq after 02350 batchs: 853.5244140625
INFO:root:Train (Epoch 62): Loss/seq after 02400 batchs: 851.2904052734375
INFO:root:Train (Epoch 62): Loss/seq after 02450 batchs: 843.066650390625
INFO:root:Train (Epoch 62): Loss/seq after 02500 batchs: 829.8707275390625
INFO:root:Train (Epoch 62): Loss/seq after 02550 batchs: 820.2906494140625
INFO:root:Train (Epoch 62): Loss/seq after 02600 batchs: 818.0385131835938
INFO:root:Train (Epoch 62): Loss/seq after 02650 batchs: 813.9892578125
INFO:root:Train (Epoch 62): Loss/seq after 02700 batchs: 810.5750122070312
INFO:root:Train (Epoch 62): Loss/seq after 02750 batchs: 834.7329711914062
INFO:root:Train (Epoch 62): Loss/seq after 02800 batchs: 838.5440063476562
INFO:root:Train (Epoch 62): Loss/seq after 02850 batchs: 836.8318481445312
INFO:root:Train (Epoch 62): Loss/seq after 02900 batchs: 836.3740844726562
INFO:root:Train (Epoch 62): Loss/seq after 02950 batchs: 832.191650390625
INFO:root:Train (Epoch 62): Loss/seq after 03000 batchs: 834.2984008789062
INFO:root:Train (Epoch 62): Loss/seq after 03050 batchs: 839.1860961914062
INFO:root:Train (Epoch 62): Loss/seq after 03100 batchs: 845.4344482421875
INFO:root:Train (Epoch 62): Loss/seq after 03150 batchs: 851.1148071289062
INFO:root:Train (Epoch 62): Loss/seq after 03200 batchs: 858.0139770507812
INFO:root:Train (Epoch 62): Loss/seq after 03250 batchs: 862.5625
INFO:root:Train (Epoch 62): Loss/seq after 03300 batchs: 860.8555908203125
INFO:root:Train (Epoch 62): Loss/seq after 03350 batchs: 860.9314575195312
INFO:root:Train (Epoch 62): Loss/seq after 03400 batchs: 853.6448364257812
INFO:root:Train (Epoch 62): Loss/seq after 03450 batchs: 849.5481567382812
INFO:root:Train (Epoch 62): Loss/seq after 03500 batchs: 849.5480346679688
INFO:root:Train (Epoch 62): Loss/seq after 03550 batchs: 844.7425537109375
INFO:root:Train (Epoch 62): Loss/seq after 03600 batchs: 852.0308227539062
INFO:root:Train (Epoch 62): Loss/seq after 03650 batchs: 848.1990966796875
INFO:root:Train (Epoch 62): Loss/seq after 03700 batchs: 848.7134399414062
INFO:root:Train (Epoch 62): Loss/seq after 03750 batchs: 852.0383911132812
INFO:root:Train (Epoch 62): Loss/seq after 03800 batchs: 847.1322021484375
INFO:root:Train (Epoch 62): Loss/seq after 03850 batchs: 845.1683349609375
INFO:root:Train (Epoch 62): Loss/seq after 03900 batchs: 849.6011352539062
INFO:root:Train (Epoch 62): Loss/seq after 03950 batchs: 854.3988037109375
INFO:root:Train (Epoch 62): Loss/seq after 04000 batchs: 849.1416015625
INFO:root:Train (Epoch 62): Loss/seq after 04050 batchs: 843.3431396484375
INFO:root:Train (Epoch 62): Loss/seq after 04100 batchs: 839.683837890625
INFO:root:Train (Epoch 62): Loss/seq after 04150 batchs: 837.2674560546875
INFO:root:Train (Epoch 62): Loss/seq after 04200 batchs: 834.2986450195312
INFO:root:Train (Epoch 62): Loss/seq after 04250 batchs: 831.3262939453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 62): Loss/seq after 00000 batches: 558.89306640625
INFO:root:# Valid (Epoch 62): Loss/seq after 00050 batches: 731.920654296875
INFO:root:# Valid (Epoch 62): Loss/seq after 00100 batches: 1016.7032470703125
INFO:root:# Valid (Epoch 62): Loss/seq after 00150 batches: 772.8876953125
INFO:root:# Valid (Epoch 62): Loss/seq after 00200 batches: 712.1666259765625
INFO:root:Artifacts: Make stick videos for epoch 62
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_62_on_20220413_000455.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_62_index_1417_on_20220413_000455.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 63): Loss/seq after 00000 batchs: 1443.122802734375
INFO:root:Train (Epoch 63): Loss/seq after 00050 batchs: 1073.3702392578125
INFO:root:Train (Epoch 63): Loss/seq after 00100 batchs: 1104.00537109375
INFO:root:Train (Epoch 63): Loss/seq after 00150 batchs: 987.8557739257812
INFO:root:Train (Epoch 63): Loss/seq after 00200 batchs: 1100.83984375
INFO:root:Train (Epoch 63): Loss/seq after 00250 batchs: 1214.2191162109375
INFO:root:Train (Epoch 63): Loss/seq after 00300 batchs: 1175.26806640625
INFO:root:Train (Epoch 63): Loss/seq after 00350 batchs: 1091.5311279296875
INFO:root:Train (Epoch 63): Loss/seq after 00400 batchs: 1108.2314453125
INFO:root:Train (Epoch 63): Loss/seq after 00450 batchs: 1073.975830078125
INFO:root:Train (Epoch 63): Loss/seq after 00500 batchs: 1058.2960205078125
INFO:root:Train (Epoch 63): Loss/seq after 00550 batchs: 1021.1563110351562
INFO:root:Train (Epoch 63): Loss/seq after 00600 batchs: 985.1686401367188
INFO:root:Train (Epoch 63): Loss/seq after 00650 batchs: 999.1140747070312
INFO:root:Train (Epoch 63): Loss/seq after 00700 batchs: 981.6047973632812
INFO:root:Train (Epoch 63): Loss/seq after 00750 batchs: 1013.2003784179688
INFO:root:Train (Epoch 63): Loss/seq after 00800 batchs: 1008.155517578125
INFO:root:Train (Epoch 63): Loss/seq after 00850 batchs: 977.2303466796875
INFO:root:Train (Epoch 63): Loss/seq after 00900 batchs: 960.1243286132812
INFO:root:Train (Epoch 63): Loss/seq after 00950 batchs: 977.3106689453125
INFO:root:Train (Epoch 63): Loss/seq after 01000 batchs: 971.2999267578125
INFO:root:Train (Epoch 63): Loss/seq after 01050 batchs: 955.9124145507812
INFO:root:Train (Epoch 63): Loss/seq after 01100 batchs: 942.1591186523438
INFO:root:Train (Epoch 63): Loss/seq after 01150 batchs: 920.069091796875
INFO:root:Train (Epoch 63): Loss/seq after 01200 batchs: 919.619140625
INFO:root:Train (Epoch 63): Loss/seq after 01250 batchs: 916.29736328125
INFO:root:Train (Epoch 63): Loss/seq after 01300 batchs: 909.1729125976562
INFO:root:Train (Epoch 63): Loss/seq after 01350 batchs: 903.1527099609375
INFO:root:Train (Epoch 63): Loss/seq after 01400 batchs: 922.006591796875
INFO:root:Train (Epoch 63): Loss/seq after 01450 batchs: 920.3540649414062
INFO:root:Train (Epoch 63): Loss/seq after 01500 batchs: 921.2454223632812
INFO:root:Train (Epoch 63): Loss/seq after 01550 batchs: 922.8648681640625
INFO:root:Train (Epoch 63): Loss/seq after 01600 batchs: 913.5870361328125
INFO:root:Train (Epoch 63): Loss/seq after 01650 batchs: 906.5805053710938
INFO:root:Train (Epoch 63): Loss/seq after 01700 batchs: 903.3501586914062
INFO:root:Train (Epoch 63): Loss/seq after 01750 batchs: 897.2035522460938
INFO:root:Train (Epoch 63): Loss/seq after 01800 batchs: 889.8651123046875
INFO:root:Train (Epoch 63): Loss/seq after 01850 batchs: 881.6553955078125
INFO:root:Train (Epoch 63): Loss/seq after 01900 batchs: 882.125
INFO:root:Train (Epoch 63): Loss/seq after 01950 batchs: 877.2821655273438
INFO:root:Train (Epoch 63): Loss/seq after 02000 batchs: 872.9104614257812
INFO:root:Train (Epoch 63): Loss/seq after 02050 batchs: 868.9340209960938
INFO:root:Train (Epoch 63): Loss/seq after 02100 batchs: 862.1978149414062
INFO:root:Train (Epoch 63): Loss/seq after 02150 batchs: 857.2301635742188
INFO:root:Train (Epoch 63): Loss/seq after 02200 batchs: 851.1480712890625
INFO:root:Train (Epoch 63): Loss/seq after 02250 batchs: 851.936279296875
INFO:root:Train (Epoch 63): Loss/seq after 02300 batchs: 859.1675415039062
INFO:root:Train (Epoch 63): Loss/seq after 02350 batchs: 851.6002197265625
INFO:root:Train (Epoch 63): Loss/seq after 02400 batchs: 849.5321655273438
INFO:root:Train (Epoch 63): Loss/seq after 02450 batchs: 841.0689697265625
INFO:root:Train (Epoch 63): Loss/seq after 02500 batchs: 827.8690795898438
INFO:root:Train (Epoch 63): Loss/seq after 02550 batchs: 818.2220458984375
INFO:root:Train (Epoch 63): Loss/seq after 02600 batchs: 816.0090942382812
INFO:root:Train (Epoch 63): Loss/seq after 02650 batchs: 811.9598388671875
INFO:root:Train (Epoch 63): Loss/seq after 02700 batchs: 808.6998901367188
INFO:root:Train (Epoch 63): Loss/seq after 02750 batchs: 833.1383666992188
INFO:root:Train (Epoch 63): Loss/seq after 02800 batchs: 836.63720703125
INFO:root:Train (Epoch 63): Loss/seq after 02850 batchs: 834.8161010742188
INFO:root:Train (Epoch 63): Loss/seq after 02900 batchs: 834.78515625
INFO:root:Train (Epoch 63): Loss/seq after 02950 batchs: 831.0860595703125
INFO:root:Train (Epoch 63): Loss/seq after 03000 batchs: 833.3392333984375
INFO:root:Train (Epoch 63): Loss/seq after 03050 batchs: 838.38916015625
INFO:root:Train (Epoch 63): Loss/seq after 03100 batchs: 844.3096313476562
INFO:root:Train (Epoch 63): Loss/seq after 03150 batchs: 849.8184204101562
INFO:root:Train (Epoch 63): Loss/seq after 03200 batchs: 856.8865966796875
INFO:root:Train (Epoch 63): Loss/seq after 03250 batchs: 861.8511352539062
INFO:root:Train (Epoch 63): Loss/seq after 03300 batchs: 860.5297241210938
INFO:root:Train (Epoch 63): Loss/seq after 03350 batchs: 859.1511840820312
INFO:root:Train (Epoch 63): Loss/seq after 03400 batchs: 851.7720336914062
INFO:root:Train (Epoch 63): Loss/seq after 03450 batchs: 847.5330200195312
INFO:root:Train (Epoch 63): Loss/seq after 03500 batchs: 846.4810180664062
INFO:root:Train (Epoch 63): Loss/seq after 03550 batchs: 841.5146484375
INFO:root:Train (Epoch 63): Loss/seq after 03600 batchs: 848.6068725585938
INFO:root:Train (Epoch 63): Loss/seq after 03650 batchs: 844.3331909179688
INFO:root:Train (Epoch 63): Loss/seq after 03700 batchs: 844.7255249023438
INFO:root:Train (Epoch 63): Loss/seq after 03750 batchs: 848.1648559570312
INFO:root:Train (Epoch 63): Loss/seq after 03800 batchs: 843.2980346679688
INFO:root:Train (Epoch 63): Loss/seq after 03850 batchs: 841.28076171875
INFO:root:Train (Epoch 63): Loss/seq after 03900 batchs: 845.7318115234375
INFO:root:Train (Epoch 63): Loss/seq after 03950 batchs: 849.79345703125
INFO:root:Train (Epoch 63): Loss/seq after 04000 batchs: 844.5502319335938
INFO:root:Train (Epoch 63): Loss/seq after 04050 batchs: 838.5857543945312
INFO:root:Train (Epoch 63): Loss/seq after 04100 batchs: 834.9793090820312
INFO:root:Train (Epoch 63): Loss/seq after 04150 batchs: 832.52734375
INFO:root:Train (Epoch 63): Loss/seq after 04200 batchs: 829.3523559570312
INFO:root:Train (Epoch 63): Loss/seq after 04250 batchs: 826.2561645507812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 63): Loss/seq after 00000 batches: 564.63427734375
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:# Valid (Epoch 63): Loss/seq after 00050 batches: 729.1744384765625
INFO:root:# Valid (Epoch 63): Loss/seq after 00100 batches: 1010.2363891601562
INFO:root:# Valid (Epoch 63): Loss/seq after 00150 batches: 762.9827880859375
INFO:root:# Valid (Epoch 63): Loss/seq after 00200 batches: 706.1804809570312
INFO:root:Artifacts: Make stick videos for epoch 63
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_63_on_20220413_001018.gif.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_63_index_1373_on_20220413_001018.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 64): Loss/seq after 00000 batchs: 1603.478515625
INFO:root:Train (Epoch 64): Loss/seq after 00050 batchs: 1069.54443359375
INFO:root:Train (Epoch 64): Loss/seq after 00100 batchs: 1103.9290771484375
INFO:root:Train (Epoch 64): Loss/seq after 00150 batchs: 987.170654296875
INFO:root:Train (Epoch 64): Loss/seq after 00200 batchs: 1108.5062255859375
INFO:root:Train (Epoch 64): Loss/seq after 00250 batchs: 1220.0264892578125
INFO:root:Train (Epoch 64): Loss/seq after 00300 batchs: 1181.38134765625
INFO:root:Train (Epoch 64): Loss/seq after 00350 batchs: 1096.428955078125
INFO:root:Train (Epoch 64): Loss/seq after 00400 batchs: 1110.0606689453125
INFO:root:Train (Epoch 64): Loss/seq after 00450 batchs: 1074.1024169921875
INFO:root:Train (Epoch 64): Loss/seq after 00500 batchs: 1054.80029296875
INFO:root:Train (Epoch 64): Loss/seq after 00550 batchs: 1017.171875
INFO:root:Train (Epoch 64): Loss/seq after 00600 batchs: 978.7288818359375
INFO:root:Train (Epoch 64): Loss/seq after 00650 batchs: 991.3875732421875
INFO:root:Train (Epoch 64): Loss/seq after 00700 batchs: 973.5810546875
INFO:root:Train (Epoch 64): Loss/seq after 00750 batchs: 1007.0509033203125
INFO:root:Train (Epoch 64): Loss/seq after 00800 batchs: 1000.5067749023438
INFO:root:Train (Epoch 64): Loss/seq after 00850 batchs: 969.15185546875
INFO:root:Train (Epoch 64): Loss/seq after 00900 batchs: 950.4036254882812
INFO:root:Train (Epoch 64): Loss/seq after 00950 batchs: 964.4895629882812
INFO:root:Train (Epoch 64): Loss/seq after 01000 batchs: 960.1400146484375
INFO:root:Train (Epoch 64): Loss/seq after 01050 batchs: 941.52685546875
INFO:root:Train (Epoch 64): Loss/seq after 01100 batchs: 926.5531005859375
INFO:root:Train (Epoch 64): Loss/seq after 01150 batchs: 903.5377807617188
INFO:root:Train (Epoch 64): Loss/seq after 01200 batchs: 902.8310546875
INFO:root:Train (Epoch 64): Loss/seq after 01250 batchs: 896.778076171875
INFO:root:Train (Epoch 64): Loss/seq after 01300 batchs: 891.3468627929688
INFO:root:Train (Epoch 64): Loss/seq after 01350 batchs: 884.5703735351562
INFO:root:Train (Epoch 64): Loss/seq after 01400 batchs: 904.4854736328125
INFO:root:Train (Epoch 64): Loss/seq after 01450 batchs: 902.2977294921875
INFO:root:Train (Epoch 64): Loss/seq after 01500 batchs: 903.7476196289062
INFO:root:Train (Epoch 64): Loss/seq after 01550 batchs: 905.1724243164062
INFO:root:Train (Epoch 64): Loss/seq after 01600 batchs: 896.3781127929688
INFO:root:Train (Epoch 64): Loss/seq after 01650 batchs: 889.611572265625
INFO:root:Train (Epoch 64): Loss/seq after 01700 batchs: 886.3213500976562
INFO:root:Train (Epoch 64): Loss/seq after 01750 batchs: 880.5697021484375
INFO:root:Train (Epoch 64): Loss/seq after 01800 batchs: 873.8048706054688
INFO:root:Train (Epoch 64): Loss/seq after 01850 batchs: 866.0930786132812
INFO:root:Train (Epoch 64): Loss/seq after 01900 batchs: 866.614501953125
INFO:root:Train (Epoch 64): Loss/seq after 01950 batchs: 862.6266479492188
INFO:root:Train (Epoch 64): Loss/seq after 02000 batchs: 858.5319213867188
INFO:root:Train (Epoch 64): Loss/seq after 02050 batchs: 854.9758911132812
INFO:root:Train (Epoch 64): Loss/seq after 02100 batchs: 848.4916381835938
INFO:root:Train (Epoch 64): Loss/seq after 02150 batchs: 843.7055053710938
INFO:root:Train (Epoch 64): Loss/seq after 02200 batchs: 837.679931640625
INFO:root:Train (Epoch 64): Loss/seq after 02250 batchs: 837.7952880859375
INFO:root:Train (Epoch 64): Loss/seq after 02300 batchs: 844.590576171875
INFO:root:Train (Epoch 64): Loss/seq after 02350 batchs: 836.816162109375
INFO:root:Train (Epoch 64): Loss/seq after 02400 batchs: 834.8204956054688
INFO:root:Train (Epoch 64): Loss/seq after 02450 batchs: 827.0106201171875
INFO:root:Train (Epoch 64): Loss/seq after 02500 batchs: 814.0979614257812
INFO:root:Train (Epoch 64): Loss/seq after 02550 batchs: 804.64501953125
INFO:root:Train (Epoch 64): Loss/seq after 02600 batchs: 802.5521240234375
INFO:root:Train (Epoch 64): Loss/seq after 02650 batchs: 798.65966796875
INFO:root:Train (Epoch 64): Loss/seq after 02700 batchs: 795.3732299804688
INFO:root:Train (Epoch 64): Loss/seq after 02750 batchs: 820.1410522460938
INFO:root:Train (Epoch 64): Loss/seq after 02800 batchs: 823.4320678710938
INFO:root:Train (Epoch 64): Loss/seq after 02850 batchs: 821.7525634765625
INFO:root:Train (Epoch 64): Loss/seq after 02900 batchs: 821.463623046875
INFO:root:Train (Epoch 64): Loss/seq after 02950 batchs: 817.4345703125
INFO:root:Train (Epoch 64): Loss/seq after 03000 batchs: 819.8298950195312
INFO:root:Train (Epoch 64): Loss/seq after 03050 batchs: 824.7901000976562
INFO:root:Train (Epoch 64): Loss/seq after 03100 batchs: 831.0074462890625
INFO:root:Train (Epoch 64): Loss/seq after 03150 batchs: 836.7965698242188
INFO:root:Train (Epoch 64): Loss/seq after 03200 batchs: 844.0341186523438
INFO:root:Train (Epoch 64): Loss/seq after 03250 batchs: 848.6642456054688
INFO:root:Train (Epoch 64): Loss/seq after 03300 batchs: 847.3196411132812
INFO:root:Train (Epoch 64): Loss/seq after 03350 batchs: 845.6953735351562
INFO:root:Train (Epoch 64): Loss/seq after 03400 batchs: 838.4121704101562
INFO:root:Train (Epoch 64): Loss/seq after 03450 batchs: 834.3764038085938
INFO:root:Train (Epoch 64): Loss/seq after 03500 batchs: 833.7084350585938
INFO:root:Train (Epoch 64): Loss/seq after 03550 batchs: 828.8412475585938
INFO:root:Train (Epoch 64): Loss/seq after 03600 batchs: 835.9736328125
INFO:root:Train (Epoch 64): Loss/seq after 03650 batchs: 831.5396728515625
INFO:root:Train (Epoch 64): Loss/seq after 03700 batchs: 832.1181640625
INFO:root:Train (Epoch 64): Loss/seq after 03750 batchs: 835.7477416992188
INFO:root:Train (Epoch 64): Loss/seq after 03800 batchs: 831.068603515625
INFO:root:Train (Epoch 64): Loss/seq after 03850 batchs: 829.1920166015625
INFO:root:Train (Epoch 64): Loss/seq after 03900 batchs: 833.71728515625
INFO:root:Train (Epoch 64): Loss/seq after 03950 batchs: 837.8201904296875
INFO:root:Train (Epoch 64): Loss/seq after 04000 batchs: 832.7294311523438
INFO:root:Train (Epoch 64): Loss/seq after 04050 batchs: 827.0164184570312
INFO:root:Train (Epoch 64): Loss/seq after 04100 batchs: 823.4442138671875
INFO:root:Train (Epoch 64): Loss/seq after 04150 batchs: 821.0741577148438
INFO:root:Train (Epoch 64): Loss/seq after 04200 batchs: 818.1739501953125
INFO:root:Train (Epoch 64): Loss/seq after 04250 batchs: 815.1802978515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 64): Loss/seq after 00000 batches: 549.1057739257812
INFO:root:# Valid (Epoch 64): Loss/seq after 00050 batches: 725.8013305664062
INFO:root:# Valid (Epoch 64): Loss/seq after 00100 batches: 1018.3887329101562
INFO:root:# Valid (Epoch 64): Loss/seq after 00150 batches: 785.6873168945312
INFO:root:# Valid (Epoch 64): Loss/seq after 00200 batches: 738.9015502929688
INFO:root:Artifacts: Make stick videos for epoch 64
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_64_on_20220413_001614.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_64_index_764_on_20220413_001614.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 65): Loss/seq after 00000 batchs: 1599.9246826171875
INFO:root:Train (Epoch 65): Loss/seq after 00050 batchs: 1071.2916259765625
INFO:root:Train (Epoch 65): Loss/seq after 00100 batchs: 1088.69482421875
INFO:root:Train (Epoch 65): Loss/seq after 00150 batchs: 990.47265625
INFO:root:Train (Epoch 65): Loss/seq after 00200 batchs: 1105.686279296875
INFO:root:Train (Epoch 65): Loss/seq after 00250 batchs: 1219.815185546875
INFO:root:Train (Epoch 65): Loss/seq after 00300 batchs: 1180.503662109375
INFO:root:Train (Epoch 65): Loss/seq after 00350 batchs: 1096.6307373046875
INFO:root:Train (Epoch 65): Loss/seq after 00400 batchs: 1116.12548828125
INFO:root:Train (Epoch 65): Loss/seq after 00450 batchs: 1079.66015625
INFO:root:Train (Epoch 65): Loss/seq after 00500 batchs: 1065.033203125
INFO:root:Train (Epoch 65): Loss/seq after 00550 batchs: 1029.2591552734375
INFO:root:Train (Epoch 65): Loss/seq after 00600 batchs: 991.6192626953125
INFO:root:Train (Epoch 65): Loss/seq after 00650 batchs: 1001.1184692382812
INFO:root:Train (Epoch 65): Loss/seq after 00700 batchs: 983.4877319335938
INFO:root:Train (Epoch 65): Loss/seq after 00750 batchs: 1014.51708984375
INFO:root:Train (Epoch 65): Loss/seq after 00800 batchs: 1009.3938598632812
INFO:root:Train (Epoch 65): Loss/seq after 00850 batchs: 978.0925903320312
INFO:root:Train (Epoch 65): Loss/seq after 00900 batchs: 960.8792724609375
INFO:root:Train (Epoch 65): Loss/seq after 00950 batchs: 974.9811401367188
INFO:root:Train (Epoch 65): Loss/seq after 01000 batchs: 969.8195190429688
INFO:root:Train (Epoch 65): Loss/seq after 01050 batchs: 954.7347412109375
INFO:root:Train (Epoch 65): Loss/seq after 01100 batchs: 939.7461547851562
INFO:root:Train (Epoch 65): Loss/seq after 01150 batchs: 917.6263427734375
INFO:root:Train (Epoch 65): Loss/seq after 01200 batchs: 915.8512573242188
INFO:root:Train (Epoch 65): Loss/seq after 01250 batchs: 910.1961669921875
INFO:root:Train (Epoch 65): Loss/seq after 01300 batchs: 903.5813598632812
INFO:root:Train (Epoch 65): Loss/seq after 01350 batchs: 896.87060546875
INFO:root:Train (Epoch 65): Loss/seq after 01400 batchs: 915.617431640625
INFO:root:Train (Epoch 65): Loss/seq after 01450 batchs: 913.3132934570312
INFO:root:Train (Epoch 65): Loss/seq after 01500 batchs: 914.0119018554688
INFO:root:Train (Epoch 65): Loss/seq after 01550 batchs: 915.395263671875
INFO:root:Train (Epoch 65): Loss/seq after 01600 batchs: 905.343017578125
INFO:root:Train (Epoch 65): Loss/seq after 01650 batchs: 898.615966796875
INFO:root:Train (Epoch 65): Loss/seq after 01700 batchs: 895.2832641601562
INFO:root:Train (Epoch 65): Loss/seq after 01750 batchs: 889.3214721679688
INFO:root:Train (Epoch 65): Loss/seq after 01800 batchs: 881.954833984375
INFO:root:Train (Epoch 65): Loss/seq after 01850 batchs: 873.8158569335938
INFO:root:Train (Epoch 65): Loss/seq after 01900 batchs: 873.8689575195312
INFO:root:Train (Epoch 65): Loss/seq after 01950 batchs: 868.812255859375
INFO:root:Train (Epoch 65): Loss/seq after 02000 batchs: 864.2364501953125
INFO:root:Train (Epoch 65): Loss/seq after 02050 batchs: 860.7359008789062
INFO:root:Train (Epoch 65): Loss/seq after 02100 batchs: 854.219970703125
INFO:root:Train (Epoch 65): Loss/seq after 02150 batchs: 849.251953125
INFO:root:Train (Epoch 65): Loss/seq after 02200 batchs: 842.9978637695312
INFO:root:Train (Epoch 65): Loss/seq after 02250 batchs: 843.048828125
INFO:root:Train (Epoch 65): Loss/seq after 02300 batchs: 849.5629272460938
INFO:root:Train (Epoch 65): Loss/seq after 02350 batchs: 842.413818359375
INFO:root:Train (Epoch 65): Loss/seq after 02400 batchs: 840.4796752929688
INFO:root:Train (Epoch 65): Loss/seq after 02450 batchs: 832.5611572265625
INFO:root:Train (Epoch 65): Loss/seq after 02500 batchs: 819.5343627929688
INFO:root:Train (Epoch 65): Loss/seq after 02550 batchs: 810.014404296875
INFO:root:Train (Epoch 65): Loss/seq after 02600 batchs: 807.83935546875
INFO:root:Train (Epoch 65): Loss/seq after 02650 batchs: 803.77001953125
INFO:root:Train (Epoch 65): Loss/seq after 02700 batchs: 800.611083984375
INFO:root:Train (Epoch 65): Loss/seq after 02750 batchs: 825.1585083007812
INFO:root:Train (Epoch 65): Loss/seq after 02800 batchs: 828.560791015625
INFO:root:Train (Epoch 65): Loss/seq after 02850 batchs: 826.9320678710938
INFO:root:Train (Epoch 65): Loss/seq after 02900 batchs: 826.7571411132812
INFO:root:Train (Epoch 65): Loss/seq after 02950 batchs: 822.9338989257812
INFO:root:Train (Epoch 65): Loss/seq after 03000 batchs: 825.1641235351562
INFO:root:Train (Epoch 65): Loss/seq after 03050 batchs: 830.045654296875
INFO:root:Train (Epoch 65): Loss/seq after 03100 batchs: 835.402099609375
INFO:root:Train (Epoch 65): Loss/seq after 03150 batchs: 840.8086547851562
INFO:root:Train (Epoch 65): Loss/seq after 03200 batchs: 847.4156494140625
INFO:root:Train (Epoch 65): Loss/seq after 03250 batchs: 852.23974609375
INFO:root:Train (Epoch 65): Loss/seq after 03300 batchs: 850.1843872070312
INFO:root:Train (Epoch 65): Loss/seq after 03350 batchs: 848.9343872070312
INFO:root:Train (Epoch 65): Loss/seq after 03400 batchs: 841.5533447265625
INFO:root:Train (Epoch 65): Loss/seq after 03450 batchs: 837.5797119140625
INFO:root:Train (Epoch 65): Loss/seq after 03500 batchs: 837.2811889648438
INFO:root:Train (Epoch 65): Loss/seq after 03550 batchs: 832.6064453125
INFO:root:Train (Epoch 65): Loss/seq after 03600 batchs: 840.0123901367188
INFO:root:Train (Epoch 65): Loss/seq after 03650 batchs: 835.5719604492188
INFO:root:Train (Epoch 65): Loss/seq after 03700 batchs: 835.8330688476562
INFO:root:Train (Epoch 65): Loss/seq after 03750 batchs: 839.3170776367188
INFO:root:Train (Epoch 65): Loss/seq after 03800 batchs: 834.5383911132812
INFO:root:Train (Epoch 65): Loss/seq after 03850 batchs: 832.4263305664062
INFO:root:Train (Epoch 65): Loss/seq after 03900 batchs: 836.7396240234375
INFO:root:Train (Epoch 65): Loss/seq after 03950 batchs: 840.5968017578125
INFO:root:Train (Epoch 65): Loss/seq after 04000 batchs: 835.3324584960938
INFO:root:Train (Epoch 65): Loss/seq after 04050 batchs: 829.4942016601562
INFO:root:Train (Epoch 65): Loss/seq after 04100 batchs: 825.7911376953125
INFO:root:Train (Epoch 65): Loss/seq after 04150 batchs: 823.3839111328125
INFO:root:Train (Epoch 65): Loss/seq after 04200 batchs: 820.5402221679688
INFO:root:Train (Epoch 65): Loss/seq after 04250 batchs: 817.7275390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 65): Loss/seq after 00000 batches: 541.1835327148438
INFO:root:# Valid (Epoch 65): Loss/seq after 00050 batches: 731.9706420898438
INFO:root:# Valid (Epoch 65): Loss/seq after 00100 batches: 1009.2291870117188
INFO:root:# Valid (Epoch 65): Loss/seq after 00150 batches: 771.1837768554688
INFO:root:# Valid (Epoch 65): Loss/seq after 00200 batches: 716.3670654296875
INFO:root:Artifacts: Make stick videos for epoch 65
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_65_on_20220413_002135.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_65_index_1559_on_20220413_002135.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 66): Loss/seq after 00000 batchs: 1533.2803955078125
INFO:root:Train (Epoch 66): Loss/seq after 00050 batchs: 1057.6668701171875
INFO:root:Train (Epoch 66): Loss/seq after 00100 batchs: 1086.614501953125
INFO:root:Train (Epoch 66): Loss/seq after 00150 batchs: 978.4677124023438
INFO:root:Train (Epoch 66): Loss/seq after 00200 batchs: 1094.70458984375
INFO:root:Train (Epoch 66): Loss/seq after 00250 batchs: 1206.630615234375
INFO:root:Train (Epoch 66): Loss/seq after 00300 batchs: 1168.927001953125
INFO:root:Train (Epoch 66): Loss/seq after 00350 batchs: 1084.5826416015625
INFO:root:Train (Epoch 66): Loss/seq after 00400 batchs: 1099.2860107421875
INFO:root:Train (Epoch 66): Loss/seq after 00450 batchs: 1062.2816162109375
INFO:root:Train (Epoch 66): Loss/seq after 00500 batchs: 1044.0069580078125
INFO:root:Train (Epoch 66): Loss/seq after 00550 batchs: 1006.3636474609375
INFO:root:Train (Epoch 66): Loss/seq after 00600 batchs: 968.9608764648438
INFO:root:Train (Epoch 66): Loss/seq after 00650 batchs: 979.4130249023438
INFO:root:Train (Epoch 66): Loss/seq after 00700 batchs: 961.5943603515625
INFO:root:Train (Epoch 66): Loss/seq after 00750 batchs: 998.3368530273438
INFO:root:Train (Epoch 66): Loss/seq after 00800 batchs: 993.368408203125
INFO:root:Train (Epoch 66): Loss/seq after 00850 batchs: 961.660888671875
INFO:root:Train (Epoch 66): Loss/seq after 00900 batchs: 941.745361328125
INFO:root:Train (Epoch 66): Loss/seq after 00950 batchs: 956.68359375
INFO:root:Train (Epoch 66): Loss/seq after 01000 batchs: 949.8416748046875
INFO:root:Train (Epoch 66): Loss/seq after 01050 batchs: 931.7657470703125
INFO:root:Train (Epoch 66): Loss/seq after 01100 batchs: 916.0250244140625
INFO:root:Train (Epoch 66): Loss/seq after 01150 batchs: 892.9896240234375
INFO:root:Train (Epoch 66): Loss/seq after 01200 batchs: 892.013916015625
INFO:root:Train (Epoch 66): Loss/seq after 01250 batchs: 886.1854248046875
INFO:root:Train (Epoch 66): Loss/seq after 01300 batchs: 879.6717529296875
INFO:root:Train (Epoch 66): Loss/seq after 01350 batchs: 873.1991577148438
INFO:root:Train (Epoch 66): Loss/seq after 01400 batchs: 891.617919921875
INFO:root:Train (Epoch 66): Loss/seq after 01450 batchs: 889.3847045898438
INFO:root:Train (Epoch 66): Loss/seq after 01500 batchs: 890.57861328125
INFO:root:Train (Epoch 66): Loss/seq after 01550 batchs: 891.1217651367188
INFO:root:Train (Epoch 66): Loss/seq after 01600 batchs: 881.6151733398438
INFO:root:Train (Epoch 66): Loss/seq after 01650 batchs: 875.0597534179688
INFO:root:Train (Epoch 66): Loss/seq after 01700 batchs: 871.9657592773438
INFO:root:Train (Epoch 66): Loss/seq after 01750 batchs: 866.0897827148438
INFO:root:Train (Epoch 66): Loss/seq after 01800 batchs: 859.2278442382812
INFO:root:Train (Epoch 66): Loss/seq after 01850 batchs: 851.8074951171875
INFO:root:Train (Epoch 66): Loss/seq after 01900 batchs: 851.7984008789062
INFO:root:Train (Epoch 66): Loss/seq after 01950 batchs: 846.9584350585938
INFO:root:Train (Epoch 66): Loss/seq after 02000 batchs: 842.5548706054688
INFO:root:Train (Epoch 66): Loss/seq after 02050 batchs: 838.7357177734375
INFO:root:Train (Epoch 66): Loss/seq after 02100 batchs: 832.4664916992188
INFO:root:Train (Epoch 66): Loss/seq after 02150 batchs: 827.7586669921875
INFO:root:Train (Epoch 66): Loss/seq after 02200 batchs: 821.7542114257812
INFO:root:Train (Epoch 66): Loss/seq after 02250 batchs: 821.4586791992188
INFO:root:Train (Epoch 66): Loss/seq after 02300 batchs: 828.4314575195312
INFO:root:Train (Epoch 66): Loss/seq after 02350 batchs: 820.8305053710938
INFO:root:Train (Epoch 66): Loss/seq after 02400 batchs: 818.8844604492188
INFO:root:Train (Epoch 66): Loss/seq after 02450 batchs: 810.840087890625
INFO:root:Train (Epoch 66): Loss/seq after 02500 batchs: 798.2152099609375
INFO:root:Train (Epoch 66): Loss/seq after 02550 batchs: 788.9647827148438
INFO:root:Train (Epoch 66): Loss/seq after 02600 batchs: 786.8678588867188
INFO:root:Train (Epoch 66): Loss/seq after 02650 batchs: 783.0991821289062
INFO:root:Train (Epoch 66): Loss/seq after 02700 batchs: 779.7284545898438
INFO:root:Train (Epoch 66): Loss/seq after 02750 batchs: 804.6824340820312
INFO:root:Train (Epoch 66): Loss/seq after 02800 batchs: 808.2803344726562
INFO:root:Train (Epoch 66): Loss/seq after 02850 batchs: 806.8078002929688
INFO:root:Train (Epoch 66): Loss/seq after 02900 batchs: 806.8827514648438
INFO:root:Train (Epoch 66): Loss/seq after 02950 batchs: 803.2141723632812
INFO:root:Train (Epoch 66): Loss/seq after 03000 batchs: 805.6326293945312
INFO:root:Train (Epoch 66): Loss/seq after 03050 batchs: 810.6910400390625
INFO:root:Train (Epoch 66): Loss/seq after 03100 batchs: 816.6466064453125
INFO:root:Train (Epoch 66): Loss/seq after 03150 batchs: 822.625244140625
INFO:root:Train (Epoch 66): Loss/seq after 03200 batchs: 829.2965087890625
INFO:root:Train (Epoch 66): Loss/seq after 03250 batchs: 834.6556396484375
INFO:root:Train (Epoch 66): Loss/seq after 03300 batchs: 832.642333984375
INFO:root:Train (Epoch 66): Loss/seq after 03350 batchs: 831.6533203125
INFO:root:Train (Epoch 66): Loss/seq after 03400 batchs: 824.3126220703125
INFO:root:Train (Epoch 66): Loss/seq after 03450 batchs: 820.392822265625
INFO:root:Train (Epoch 66): Loss/seq after 03500 batchs: 819.6516723632812
INFO:root:Train (Epoch 66): Loss/seq after 03550 batchs: 815.0049438476562
INFO:root:Train (Epoch 66): Loss/seq after 03600 batchs: 822.170166015625
INFO:root:Train (Epoch 66): Loss/seq after 03650 batchs: 817.954833984375
INFO:root:Train (Epoch 66): Loss/seq after 03700 batchs: 818.4562377929688
INFO:root:Train (Epoch 66): Loss/seq after 03750 batchs: 821.9898681640625
INFO:root:Train (Epoch 66): Loss/seq after 03800 batchs: 817.232421875
INFO:root:Train (Epoch 66): Loss/seq after 03850 batchs: 815.1475830078125
INFO:root:Train (Epoch 66): Loss/seq after 03900 batchs: 819.467529296875
INFO:root:Train (Epoch 66): Loss/seq after 03950 batchs: 823.600830078125
INFO:root:Train (Epoch 66): Loss/seq after 04000 batchs: 818.47802734375
INFO:root:Train (Epoch 66): Loss/seq after 04050 batchs: 812.66015625
INFO:root:Train (Epoch 66): Loss/seq after 04100 batchs: 809.1635131835938
INFO:root:Train (Epoch 66): Loss/seq after 04150 batchs: 806.8464965820312
INFO:root:Train (Epoch 66): Loss/seq after 04200 batchs: 803.979736328125
INFO:root:Train (Epoch 66): Loss/seq after 04250 batchs: 801.1937866210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 66): Loss/seq after 00000 batches: 517.2546997070312
INFO:root:# Valid (Epoch 66): Loss/seq after 00050 batches: 708.34130859375
INFO:root:# Valid (Epoch 66): Loss/seq after 00100 batches: 983.3990478515625
INFO:root:# Valid (Epoch 66): Loss/seq after 00150 batches: 749.3292846679688
INFO:root:# Valid (Epoch 66): Loss/seq after 00200 batches: 694.4453125
INFO:root:Artifacts: Make stick videos for epoch 66
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_66_on_20220413_002658.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_66_index_1022_on_20220413_002658.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 67): Loss/seq after 00000 batchs: 1388.5556640625
INFO:root:Train (Epoch 67): Loss/seq after 00050 batchs: 1026.1300048828125
INFO:root:Train (Epoch 67): Loss/seq after 00100 batchs: 1096.4906005859375
INFO:root:Train (Epoch 67): Loss/seq after 00150 batchs: 987.297607421875
INFO:root:Train (Epoch 67): Loss/seq after 00200 batchs: 1097.8040771484375
INFO:root:Train (Epoch 67): Loss/seq after 00250 batchs: 1211.34716796875
INFO:root:Train (Epoch 67): Loss/seq after 00300 batchs: 1171.5543212890625
INFO:root:Train (Epoch 67): Loss/seq after 00350 batchs: 1085.127685546875
INFO:root:Train (Epoch 67): Loss/seq after 00400 batchs: 1100.5654296875
INFO:root:Train (Epoch 67): Loss/seq after 00450 batchs: 1063.0494384765625
INFO:root:Train (Epoch 67): Loss/seq after 00500 batchs: 1044.3662109375
INFO:root:Train (Epoch 67): Loss/seq after 00550 batchs: 1006.6356811523438
INFO:root:Train (Epoch 67): Loss/seq after 00600 batchs: 969.9669799804688
INFO:root:Train (Epoch 67): Loss/seq after 00650 batchs: 981.0928344726562
INFO:root:Train (Epoch 67): Loss/seq after 00700 batchs: 963.1805419921875
INFO:root:Train (Epoch 67): Loss/seq after 00750 batchs: 993.8673706054688
INFO:root:Train (Epoch 67): Loss/seq after 00800 batchs: 987.941162109375
INFO:root:Train (Epoch 67): Loss/seq after 00850 batchs: 957.280517578125
INFO:root:Train (Epoch 67): Loss/seq after 00900 batchs: 938.3900146484375
INFO:root:Train (Epoch 67): Loss/seq after 00950 batchs: 954.7132568359375
INFO:root:Train (Epoch 67): Loss/seq after 01000 batchs: 947.4747924804688
INFO:root:Train (Epoch 67): Loss/seq after 01050 batchs: 927.5531616210938
INFO:root:Train (Epoch 67): Loss/seq after 01100 batchs: 912.6614990234375
INFO:root:Train (Epoch 67): Loss/seq after 01150 batchs: 889.6165161132812
INFO:root:Train (Epoch 67): Loss/seq after 01200 batchs: 888.046630859375
INFO:root:Train (Epoch 67): Loss/seq after 01250 batchs: 881.110595703125
INFO:root:Train (Epoch 67): Loss/seq after 01300 batchs: 873.9638671875
INFO:root:Train (Epoch 67): Loss/seq after 01350 batchs: 865.6564331054688
INFO:root:Train (Epoch 67): Loss/seq after 01400 batchs: 884.5280151367188
INFO:root:Train (Epoch 67): Loss/seq after 01450 batchs: 881.9374389648438
INFO:root:Train (Epoch 67): Loss/seq after 01500 batchs: 882.7230224609375
INFO:root:Train (Epoch 67): Loss/seq after 01550 batchs: 884.1260375976562
INFO:root:Train (Epoch 67): Loss/seq after 01600 batchs: 874.7003784179688
INFO:root:Train (Epoch 67): Loss/seq after 01650 batchs: 868.109375
INFO:root:Train (Epoch 67): Loss/seq after 01700 batchs: 865.0299682617188
INFO:root:Train (Epoch 67): Loss/seq after 01750 batchs: 858.8439331054688
INFO:root:Train (Epoch 67): Loss/seq after 01800 batchs: 851.7066040039062
INFO:root:Train (Epoch 67): Loss/seq after 01850 batchs: 844.1989135742188
INFO:root:Train (Epoch 67): Loss/seq after 01900 batchs: 843.9016723632812
INFO:root:Train (Epoch 67): Loss/seq after 01950 batchs: 839.8279418945312
INFO:root:Train (Epoch 67): Loss/seq after 02000 batchs: 835.4161376953125
INFO:root:Train (Epoch 67): Loss/seq after 02050 batchs: 831.6251220703125
INFO:root:Train (Epoch 67): Loss/seq after 02100 batchs: 825.3251953125
INFO:root:Train (Epoch 67): Loss/seq after 02150 batchs: 820.4929809570312
INFO:root:Train (Epoch 67): Loss/seq after 02200 batchs: 814.475830078125
INFO:root:Train (Epoch 67): Loss/seq after 02250 batchs: 814.4557495117188
INFO:root:Train (Epoch 67): Loss/seq after 02300 batchs: 819.97265625
INFO:root:Train (Epoch 67): Loss/seq after 02350 batchs: 812.3223876953125
INFO:root:Train (Epoch 67): Loss/seq after 02400 batchs: 810.244140625
INFO:root:Train (Epoch 67): Loss/seq after 02450 batchs: 802.10498046875
INFO:root:Train (Epoch 67): Loss/seq after 02500 batchs: 789.5922241210938
INFO:root:Train (Epoch 67): Loss/seq after 02550 batchs: 780.4177856445312
INFO:root:Train (Epoch 67): Loss/seq after 02600 batchs: 778.3465576171875
INFO:root:Train (Epoch 67): Loss/seq after 02650 batchs: 774.6130981445312
INFO:root:Train (Epoch 67): Loss/seq after 02700 batchs: 771.282470703125
INFO:root:Train (Epoch 67): Loss/seq after 02750 batchs: 795.9298706054688
INFO:root:Train (Epoch 67): Loss/seq after 02800 batchs: 799.6600952148438
INFO:root:Train (Epoch 67): Loss/seq after 02850 batchs: 798.287353515625
INFO:root:Train (Epoch 67): Loss/seq after 02900 batchs: 798.0030517578125
INFO:root:Train (Epoch 67): Loss/seq after 02950 batchs: 794.4498291015625
INFO:root:Train (Epoch 67): Loss/seq after 03000 batchs: 796.8280029296875
INFO:root:Train (Epoch 67): Loss/seq after 03050 batchs: 801.6436767578125
INFO:root:Train (Epoch 67): Loss/seq after 03100 batchs: 807.4678955078125
INFO:root:Train (Epoch 67): Loss/seq after 03150 batchs: 813.1358642578125
INFO:root:Train (Epoch 67): Loss/seq after 03200 batchs: 819.7861938476562
INFO:root:Train (Epoch 67): Loss/seq after 03250 batchs: 824.7471923828125
INFO:root:Train (Epoch 67): Loss/seq after 03300 batchs: 823.2824096679688
INFO:root:Train (Epoch 67): Loss/seq after 03350 batchs: 822.045166015625
INFO:root:Train (Epoch 67): Loss/seq after 03400 batchs: 814.8126220703125
INFO:root:Train (Epoch 67): Loss/seq after 03450 batchs: 810.9334106445312
INFO:root:Train (Epoch 67): Loss/seq after 03500 batchs: 810.0252685546875
INFO:root:Train (Epoch 67): Loss/seq after 03550 batchs: 805.2453002929688
INFO:root:Train (Epoch 67): Loss/seq after 03600 batchs: 812.3554077148438
INFO:root:Train (Epoch 67): Loss/seq after 03650 batchs: 808.5234985351562
INFO:root:Train (Epoch 67): Loss/seq after 03700 batchs: 809.3519897460938
INFO:root:Train (Epoch 67): Loss/seq after 03750 batchs: 812.765625
INFO:root:Train (Epoch 67): Loss/seq after 03800 batchs: 807.9807739257812
INFO:root:Train (Epoch 67): Loss/seq after 03850 batchs: 805.9471435546875
INFO:root:Train (Epoch 67): Loss/seq after 03900 batchs: 810.4228515625
INFO:root:Train (Epoch 67): Loss/seq after 03950 batchs: 814.5811767578125
INFO:root:Train (Epoch 67): Loss/seq after 04000 batchs: 809.3781127929688
INFO:root:Train (Epoch 67): Loss/seq after 04050 batchs: 803.6137084960938
INFO:root:Train (Epoch 67): Loss/seq after 04100 batchs: 800.1000366210938
INFO:root:Train (Epoch 67): Loss/seq after 04150 batchs: 797.88720703125
INFO:root:Train (Epoch 67): Loss/seq after 04200 batchs: 794.9779052734375
INFO:root:Train (Epoch 67): Loss/seq after 04250 batchs: 792.064453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 67): Loss/seq after 00000 batches: 541.596435546875
INFO:root:# Valid (Epoch 67): Loss/seq after 00050 batches: 703.9668579101562
INFO:root:# Valid (Epoch 67): Loss/seq after 00100 batches: 975.7066650390625
INFO:root:# Valid (Epoch 67): Loss/seq after 00150 batches: 741.0087280273438
INFO:root:# Valid (Epoch 67): Loss/seq after 00200 batches: 685.9088134765625
INFO:root:Artifacts: Make stick videos for epoch 67
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_67_on_20220413_003220.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_67_index_597_on_20220413_003220.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 68): Loss/seq after 00000 batchs: 1365.0341796875
INFO:root:Train (Epoch 68): Loss/seq after 00050 batchs: 1026.7947998046875
INFO:root:Train (Epoch 68): Loss/seq after 00100 batchs: 1068.6787109375
INFO:root:Train (Epoch 68): Loss/seq after 00150 batchs: 966.7258911132812
INFO:root:Train (Epoch 68): Loss/seq after 00200 batchs: 1080.0570068359375
INFO:root:Train (Epoch 68): Loss/seq after 00250 batchs: 1191.620361328125
INFO:root:Train (Epoch 68): Loss/seq after 00300 batchs: 1153.4854736328125
INFO:root:Train (Epoch 68): Loss/seq after 00350 batchs: 1068.33837890625
INFO:root:Train (Epoch 68): Loss/seq after 00400 batchs: 1086.4510498046875
INFO:root:Train (Epoch 68): Loss/seq after 00450 batchs: 1049.19482421875
INFO:root:Train (Epoch 68): Loss/seq after 00500 batchs: 1030.53466796875
INFO:root:Train (Epoch 68): Loss/seq after 00550 batchs: 994.2122192382812
INFO:root:Train (Epoch 68): Loss/seq after 00600 batchs: 958.8997192382812
INFO:root:Train (Epoch 68): Loss/seq after 00650 batchs: 972.1395874023438
INFO:root:Train (Epoch 68): Loss/seq after 00700 batchs: 954.0217895507812
INFO:root:Train (Epoch 68): Loss/seq after 00750 batchs: 986.1832275390625
INFO:root:Train (Epoch 68): Loss/seq after 00800 batchs: 980.4635620117188
INFO:root:Train (Epoch 68): Loss/seq after 00850 batchs: 949.5823974609375
INFO:root:Train (Epoch 68): Loss/seq after 00900 batchs: 929.5090942382812
INFO:root:Train (Epoch 68): Loss/seq after 00950 batchs: 944.92041015625
INFO:root:Train (Epoch 68): Loss/seq after 01000 batchs: 938.2941284179688
INFO:root:Train (Epoch 68): Loss/seq after 01050 batchs: 919.1856079101562
INFO:root:Train (Epoch 68): Loss/seq after 01100 batchs: 903.337646484375
INFO:root:Train (Epoch 68): Loss/seq after 01150 batchs: 880.58984375
INFO:root:Train (Epoch 68): Loss/seq after 01200 batchs: 880.2079467773438
INFO:root:Train (Epoch 68): Loss/seq after 01250 batchs: 874.196533203125
INFO:root:Train (Epoch 68): Loss/seq after 01300 batchs: 865.580810546875
INFO:root:Train (Epoch 68): Loss/seq after 01350 batchs: 857.684814453125
INFO:root:Train (Epoch 68): Loss/seq after 01400 batchs: 876.1395263671875
INFO:root:Train (Epoch 68): Loss/seq after 01450 batchs: 874.0230102539062
INFO:root:Train (Epoch 68): Loss/seq after 01500 batchs: 874.99609375
INFO:root:Train (Epoch 68): Loss/seq after 01550 batchs: 875.6407470703125
INFO:root:Train (Epoch 68): Loss/seq after 01600 batchs: 866.0950317382812
INFO:root:Train (Epoch 68): Loss/seq after 01650 batchs: 860.4072875976562
INFO:root:Train (Epoch 68): Loss/seq after 01700 batchs: 857.3262329101562
INFO:root:Train (Epoch 68): Loss/seq after 01750 batchs: 851.2743530273438
INFO:root:Train (Epoch 68): Loss/seq after 01800 batchs: 844.7047119140625
INFO:root:Train (Epoch 68): Loss/seq after 01850 batchs: 837.298828125
INFO:root:Train (Epoch 68): Loss/seq after 01900 batchs: 836.3299560546875
INFO:root:Train (Epoch 68): Loss/seq after 01950 batchs: 831.4232177734375
INFO:root:Train (Epoch 68): Loss/seq after 02000 batchs: 826.636474609375
INFO:root:Train (Epoch 68): Loss/seq after 02050 batchs: 822.6005249023438
INFO:root:Train (Epoch 68): Loss/seq after 02100 batchs: 816.490234375
INFO:root:Train (Epoch 68): Loss/seq after 02150 batchs: 811.8443603515625
INFO:root:Train (Epoch 68): Loss/seq after 02200 batchs: 805.8914184570312
INFO:root:Train (Epoch 68): Loss/seq after 02250 batchs: 806.4833984375
INFO:root:Train (Epoch 68): Loss/seq after 02300 batchs: 813.3890380859375
INFO:root:Train (Epoch 68): Loss/seq after 02350 batchs: 805.9822998046875
INFO:root:Train (Epoch 68): Loss/seq after 02400 batchs: 804.1080322265625
INFO:root:Train (Epoch 68): Loss/seq after 02450 batchs: 796.0144653320312
INFO:root:Train (Epoch 68): Loss/seq after 02500 batchs: 783.5897827148438
INFO:root:Train (Epoch 68): Loss/seq after 02550 batchs: 774.5344848632812
INFO:root:Train (Epoch 68): Loss/seq after 02600 batchs: 772.4609985351562
INFO:root:Train (Epoch 68): Loss/seq after 02650 batchs: 768.8519897460938
INFO:root:Train (Epoch 68): Loss/seq after 02700 batchs: 765.6802368164062
INFO:root:Train (Epoch 68): Loss/seq after 02750 batchs: 790.6804809570312
INFO:root:Train (Epoch 68): Loss/seq after 02800 batchs: 794.192626953125
INFO:root:Train (Epoch 68): Loss/seq after 02850 batchs: 792.758056640625
INFO:root:Train (Epoch 68): Loss/seq after 02900 batchs: 792.3204345703125
INFO:root:Train (Epoch 68): Loss/seq after 02950 batchs: 788.9317016601562
INFO:root:Train (Epoch 68): Loss/seq after 03000 batchs: 791.4432373046875
INFO:root:Train (Epoch 68): Loss/seq after 03050 batchs: 796.22216796875
INFO:root:Train (Epoch 68): Loss/seq after 03100 batchs: 801.4536743164062
INFO:root:Train (Epoch 68): Loss/seq after 03150 batchs: 806.9802856445312
INFO:root:Train (Epoch 68): Loss/seq after 03200 batchs: 814.4061279296875
INFO:root:Train (Epoch 68): Loss/seq after 03250 batchs: 819.278076171875
INFO:root:Train (Epoch 68): Loss/seq after 03300 batchs: 817.65283203125
INFO:root:Train (Epoch 68): Loss/seq after 03350 batchs: 816.3540649414062
INFO:root:Train (Epoch 68): Loss/seq after 03400 batchs: 809.1139526367188
INFO:root:Train (Epoch 68): Loss/seq after 03450 batchs: 805.3140258789062
INFO:root:Train (Epoch 68): Loss/seq after 03500 batchs: 804.8333129882812
INFO:root:Train (Epoch 68): Loss/seq after 03550 batchs: 800.2141723632812
INFO:root:Train (Epoch 68): Loss/seq after 03600 batchs: 807.4205322265625
INFO:root:Train (Epoch 68): Loss/seq after 03650 batchs: 803.3054809570312
INFO:root:Train (Epoch 68): Loss/seq after 03700 batchs: 804.0769653320312
INFO:root:Train (Epoch 68): Loss/seq after 03750 batchs: 807.5194702148438
INFO:root:Train (Epoch 68): Loss/seq after 03800 batchs: 802.7918090820312
INFO:root:Train (Epoch 68): Loss/seq after 03850 batchs: 800.751220703125
INFO:root:Train (Epoch 68): Loss/seq after 03900 batchs: 805.1720581054688
INFO:root:Train (Epoch 68): Loss/seq after 03950 batchs: 808.9799194335938
INFO:root:Train (Epoch 68): Loss/seq after 04000 batchs: 803.8209228515625
INFO:root:Train (Epoch 68): Loss/seq after 04050 batchs: 798.0908813476562
INFO:root:Train (Epoch 68): Loss/seq after 04100 batchs: 794.6051635742188
INFO:root:Train (Epoch 68): Loss/seq after 04150 batchs: 792.42529296875
INFO:root:Train (Epoch 68): Loss/seq after 04200 batchs: 789.4310302734375
INFO:root:Train (Epoch 68): Loss/seq after 04250 batchs: 786.60107421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 68): Loss/seq after 00000 batches: 517.8175659179688
INFO:root:# Valid (Epoch 68): Loss/seq after 00050 batches: 712.4863891601562
INFO:root:# Valid (Epoch 68): Loss/seq after 00100 batches: 981.565673828125
INFO:root:# Valid (Epoch 68): Loss/seq after 00150 batches: 740.4929809570312
INFO:root:# Valid (Epoch 68): Loss/seq after 00200 batches: 683.4848022460938
INFO:root:Artifacts: Make stick videos for epoch 68
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_68_on_20220413_003743.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_68_index_293_on_20220413_003743.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 69): Loss/seq after 00000 batchs: 1530.1644287109375
INFO:root:Train (Epoch 69): Loss/seq after 00050 batchs: 1017.9343872070312
INFO:root:Train (Epoch 69): Loss/seq after 00100 batchs: 1045.936767578125
INFO:root:Train (Epoch 69): Loss/seq after 00150 batchs: 953.1605834960938
INFO:root:Train (Epoch 69): Loss/seq after 00200 batchs: 1060.908447265625
INFO:root:Train (Epoch 69): Loss/seq after 00250 batchs: 1179.3553466796875
INFO:root:Train (Epoch 69): Loss/seq after 00300 batchs: 1143.62451171875
INFO:root:Train (Epoch 69): Loss/seq after 00350 batchs: 1059.5709228515625
INFO:root:Train (Epoch 69): Loss/seq after 00400 batchs: 1074.5150146484375
INFO:root:Train (Epoch 69): Loss/seq after 00450 batchs: 1037.6898193359375
INFO:root:Train (Epoch 69): Loss/seq after 00500 batchs: 1018.3444213867188
INFO:root:Train (Epoch 69): Loss/seq after 00550 batchs: 982.2654418945312
INFO:root:Train (Epoch 69): Loss/seq after 00600 batchs: 944.45703125
INFO:root:Train (Epoch 69): Loss/seq after 00650 batchs: 955.032958984375
INFO:root:Train (Epoch 69): Loss/seq after 00700 batchs: 936.1881713867188
INFO:root:Train (Epoch 69): Loss/seq after 00750 batchs: 973.244873046875
INFO:root:Train (Epoch 69): Loss/seq after 00800 batchs: 968.113037109375
INFO:root:Train (Epoch 69): Loss/seq after 00850 batchs: 937.6824951171875
INFO:root:Train (Epoch 69): Loss/seq after 00900 batchs: 918.6414184570312
INFO:root:Train (Epoch 69): Loss/seq after 00950 batchs: 932.3761596679688
INFO:root:Train (Epoch 69): Loss/seq after 01000 batchs: 925.6665649414062
INFO:root:Train (Epoch 69): Loss/seq after 01050 batchs: 908.7893676757812
INFO:root:Train (Epoch 69): Loss/seq after 01100 batchs: 893.5645751953125
INFO:root:Train (Epoch 69): Loss/seq after 01150 batchs: 871.0526733398438
INFO:root:Train (Epoch 69): Loss/seq after 01200 batchs: 869.6526489257812
INFO:root:Train (Epoch 69): Loss/seq after 01250 batchs: 863.0590209960938
INFO:root:Train (Epoch 69): Loss/seq after 01300 batchs: 854.9251708984375
INFO:root:Train (Epoch 69): Loss/seq after 01350 batchs: 847.4501953125
INFO:root:Train (Epoch 69): Loss/seq after 01400 batchs: 863.7863159179688
INFO:root:Train (Epoch 69): Loss/seq after 01450 batchs: 860.835693359375
INFO:root:Train (Epoch 69): Loss/seq after 01500 batchs: 861.9141845703125
INFO:root:Train (Epoch 69): Loss/seq after 01550 batchs: 863.6607055664062
INFO:root:Train (Epoch 69): Loss/seq after 01600 batchs: 854.462646484375
INFO:root:Train (Epoch 69): Loss/seq after 01650 batchs: 850.2412719726562
INFO:root:Train (Epoch 69): Loss/seq after 01700 batchs: 848.0123291015625
INFO:root:Train (Epoch 69): Loss/seq after 01750 batchs: 842.3361206054688
INFO:root:Train (Epoch 69): Loss/seq after 01800 batchs: 835.8117065429688
INFO:root:Train (Epoch 69): Loss/seq after 01850 batchs: 828.4889526367188
INFO:root:Train (Epoch 69): Loss/seq after 01900 batchs: 828.460205078125
INFO:root:Train (Epoch 69): Loss/seq after 01950 batchs: 823.9564819335938
INFO:root:Train (Epoch 69): Loss/seq after 02000 batchs: 819.2033081054688
INFO:root:Train (Epoch 69): Loss/seq after 02050 batchs: 815.2814331054688
INFO:root:Train (Epoch 69): Loss/seq after 02100 batchs: 809.1337280273438
INFO:root:Train (Epoch 69): Loss/seq after 02150 batchs: 804.5098266601562
INFO:root:Train (Epoch 69): Loss/seq after 02200 batchs: 798.7722778320312
INFO:root:Train (Epoch 69): Loss/seq after 02250 batchs: 799.2637329101562
INFO:root:Train (Epoch 69): Loss/seq after 02300 batchs: 807.09912109375
INFO:root:Train (Epoch 69): Loss/seq after 02350 batchs: 799.927001953125
INFO:root:Train (Epoch 69): Loss/seq after 02400 batchs: 798.0193481445312
INFO:root:Train (Epoch 69): Loss/seq after 02450 batchs: 789.9965209960938
INFO:root:Train (Epoch 69): Loss/seq after 02500 batchs: 777.6770629882812
INFO:root:Train (Epoch 69): Loss/seq after 02550 batchs: 768.563720703125
INFO:root:Train (Epoch 69): Loss/seq after 02600 batchs: 766.5755615234375
INFO:root:Train (Epoch 69): Loss/seq after 02650 batchs: 762.8953857421875
INFO:root:Train (Epoch 69): Loss/seq after 02700 batchs: 759.5986328125
INFO:root:Train (Epoch 69): Loss/seq after 02750 batchs: 783.9838256835938
INFO:root:Train (Epoch 69): Loss/seq after 02800 batchs: 787.3529663085938
INFO:root:Train (Epoch 69): Loss/seq after 02850 batchs: 786.0446166992188
INFO:root:Train (Epoch 69): Loss/seq after 02900 batchs: 785.856201171875
INFO:root:Train (Epoch 69): Loss/seq after 02950 batchs: 782.446044921875
INFO:root:Train (Epoch 69): Loss/seq after 03000 batchs: 785.044189453125
INFO:root:Train (Epoch 69): Loss/seq after 03050 batchs: 790.090087890625
INFO:root:Train (Epoch 69): Loss/seq after 03100 batchs: 795.2780151367188
INFO:root:Train (Epoch 69): Loss/seq after 03150 batchs: 801.2955322265625
INFO:root:Train (Epoch 69): Loss/seq after 03200 batchs: 807.8233642578125
INFO:root:Train (Epoch 69): Loss/seq after 03250 batchs: 812.6959228515625
INFO:root:Train (Epoch 69): Loss/seq after 03300 batchs: 811.2567138671875
INFO:root:Train (Epoch 69): Loss/seq after 03350 batchs: 810.1404418945312
INFO:root:Train (Epoch 69): Loss/seq after 03400 batchs: 802.9957885742188
INFO:root:Train (Epoch 69): Loss/seq after 03450 batchs: 799.270751953125
INFO:root:Train (Epoch 69): Loss/seq after 03500 batchs: 798.5669555664062
INFO:root:Train (Epoch 69): Loss/seq after 03550 batchs: 793.7774047851562
INFO:root:Train (Epoch 69): Loss/seq after 03600 batchs: 800.9476928710938
INFO:root:Train (Epoch 69): Loss/seq after 03650 batchs: 796.4964599609375
INFO:root:Train (Epoch 69): Loss/seq after 03700 batchs: 797.0867919921875
INFO:root:Train (Epoch 69): Loss/seq after 03750 batchs: 800.5010986328125
INFO:root:Train (Epoch 69): Loss/seq after 03800 batchs: 795.8688354492188
INFO:root:Train (Epoch 69): Loss/seq after 03850 batchs: 793.91796875
INFO:root:Train (Epoch 69): Loss/seq after 03900 batchs: 798.0735473632812
INFO:root:Train (Epoch 69): Loss/seq after 03950 batchs: 801.85693359375
INFO:root:Train (Epoch 69): Loss/seq after 04000 batchs: 796.8705444335938
INFO:root:Train (Epoch 69): Loss/seq after 04050 batchs: 791.1749877929688
INFO:root:Train (Epoch 69): Loss/seq after 04100 batchs: 787.7736206054688
INFO:root:Train (Epoch 69): Loss/seq after 04150 batchs: 785.6460571289062
INFO:root:Train (Epoch 69): Loss/seq after 04200 batchs: 782.815185546875
INFO:root:Train (Epoch 69): Loss/seq after 04250 batchs: 779.9230346679688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 69): Loss/seq after 00000 batches: 589.5048828125
INFO:root:# Valid (Epoch 69): Loss/seq after 00050 batches: 714.9447021484375
INFO:root:# Valid (Epoch 69): Loss/seq after 00100 batches: 980.466796875
INFO:root:# Valid (Epoch 69): Loss/seq after 00150 batches: 738.1934204101562
INFO:root:# Valid (Epoch 69): Loss/seq after 00200 batches: 682.0647583007812
INFO:root:Artifacts: Make stick videos for epoch 69
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_69_on_20220413_004306.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_69_index_214_on_20220413_004306.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 70): Loss/seq after 00000 batchs: 1343.13720703125
INFO:root:Train (Epoch 70): Loss/seq after 00050 batchs: 1008.7473754882812
INFO:root:Train (Epoch 70): Loss/seq after 00100 batchs: 1054.3770751953125
INFO:root:Train (Epoch 70): Loss/seq after 00150 batchs: 951.6448364257812
INFO:root:Train (Epoch 70): Loss/seq after 00200 batchs: 1067.630859375
INFO:root:Train (Epoch 70): Loss/seq after 00250 batchs: 1181.1571044921875
INFO:root:Train (Epoch 70): Loss/seq after 00300 batchs: 1144.3681640625
INFO:root:Train (Epoch 70): Loss/seq after 00350 batchs: 1059.832275390625
INFO:root:Train (Epoch 70): Loss/seq after 00400 batchs: 1074.349365234375
INFO:root:Train (Epoch 70): Loss/seq after 00450 batchs: 1037.447509765625
INFO:root:Train (Epoch 70): Loss/seq after 00500 batchs: 1018.314453125
INFO:root:Train (Epoch 70): Loss/seq after 00550 batchs: 982.4490966796875
INFO:root:Train (Epoch 70): Loss/seq after 00600 batchs: 944.4340209960938
INFO:root:Train (Epoch 70): Loss/seq after 00650 batchs: 954.8445434570312
INFO:root:Train (Epoch 70): Loss/seq after 00700 batchs: 937.88330078125
INFO:root:Train (Epoch 70): Loss/seq after 00750 batchs: 966.1148681640625
INFO:root:Train (Epoch 70): Loss/seq after 00800 batchs: 960.429443359375
INFO:root:Train (Epoch 70): Loss/seq after 00850 batchs: 930.0391845703125
INFO:root:Train (Epoch 70): Loss/seq after 00900 batchs: 912.3115844726562
INFO:root:Train (Epoch 70): Loss/seq after 00950 batchs: 927.7620849609375
INFO:root:Train (Epoch 70): Loss/seq after 01000 batchs: 921.7183837890625
INFO:root:Train (Epoch 70): Loss/seq after 01050 batchs: 903.5301513671875
INFO:root:Train (Epoch 70): Loss/seq after 01100 batchs: 887.8665161132812
INFO:root:Train (Epoch 70): Loss/seq after 01150 batchs: 865.3529663085938
INFO:root:Train (Epoch 70): Loss/seq after 01200 batchs: 863.9690551757812
INFO:root:Train (Epoch 70): Loss/seq after 01250 batchs: 858.12939453125
INFO:root:Train (Epoch 70): Loss/seq after 01300 batchs: 849.6083374023438
INFO:root:Train (Epoch 70): Loss/seq after 01350 batchs: 841.8079833984375
INFO:root:Train (Epoch 70): Loss/seq after 01400 batchs: 859.1278686523438
INFO:root:Train (Epoch 70): Loss/seq after 01450 batchs: 857.1735229492188
INFO:root:Train (Epoch 70): Loss/seq after 01500 batchs: 858.503662109375
INFO:root:Train (Epoch 70): Loss/seq after 01550 batchs: 858.9752197265625
INFO:root:Train (Epoch 70): Loss/seq after 01600 batchs: 849.8474731445312
INFO:root:Train (Epoch 70): Loss/seq after 01650 batchs: 844.3021240234375
INFO:root:Train (Epoch 70): Loss/seq after 01700 batchs: 841.69873046875
INFO:root:Train (Epoch 70): Loss/seq after 01750 batchs: 835.7108764648438
INFO:root:Train (Epoch 70): Loss/seq after 01800 batchs: 829.20947265625
INFO:root:Train (Epoch 70): Loss/seq after 01850 batchs: 822.2799072265625
INFO:root:Train (Epoch 70): Loss/seq after 01900 batchs: 822.064208984375
INFO:root:Train (Epoch 70): Loss/seq after 01950 batchs: 818.067626953125
INFO:root:Train (Epoch 70): Loss/seq after 02000 batchs: 813.2301635742188
INFO:root:Train (Epoch 70): Loss/seq after 02050 batchs: 809.1192626953125
INFO:root:Train (Epoch 70): Loss/seq after 02100 batchs: 803.0569458007812
INFO:root:Train (Epoch 70): Loss/seq after 02150 batchs: 798.3524780273438
INFO:root:Train (Epoch 70): Loss/seq after 02200 batchs: 792.6500854492188
INFO:root:Train (Epoch 70): Loss/seq after 02250 batchs: 792.1893920898438
INFO:root:Train (Epoch 70): Loss/seq after 02300 batchs: 799.2050170898438
INFO:root:Train (Epoch 70): Loss/seq after 02350 batchs: 791.988037109375
INFO:root:Train (Epoch 70): Loss/seq after 02400 batchs: 790.2794189453125
INFO:root:Train (Epoch 70): Loss/seq after 02450 batchs: 782.273193359375
INFO:root:Train (Epoch 70): Loss/seq after 02500 batchs: 770.1149291992188
INFO:root:Train (Epoch 70): Loss/seq after 02550 batchs: 761.1630249023438
INFO:root:Train (Epoch 70): Loss/seq after 02600 batchs: 759.2929077148438
INFO:root:Train (Epoch 70): Loss/seq after 02650 batchs: 755.6559448242188
INFO:root:Train (Epoch 70): Loss/seq after 02700 batchs: 752.4817504882812
INFO:root:Train (Epoch 70): Loss/seq after 02750 batchs: 777.4620361328125
INFO:root:Train (Epoch 70): Loss/seq after 02800 batchs: 781.0115966796875
INFO:root:Train (Epoch 70): Loss/seq after 02850 batchs: 779.789306640625
INFO:root:Train (Epoch 70): Loss/seq after 02900 batchs: 779.4148559570312
INFO:root:Train (Epoch 70): Loss/seq after 02950 batchs: 775.9021606445312
INFO:root:Train (Epoch 70): Loss/seq after 03000 batchs: 778.5133666992188
INFO:root:Train (Epoch 70): Loss/seq after 03050 batchs: 783.36669921875
INFO:root:Train (Epoch 70): Loss/seq after 03100 batchs: 788.7088012695312
INFO:root:Train (Epoch 70): Loss/seq after 03150 batchs: 794.225830078125
INFO:root:Train (Epoch 70): Loss/seq after 03200 batchs: 801.7338256835938
INFO:root:Train (Epoch 70): Loss/seq after 03250 batchs: 806.813720703125
INFO:root:Train (Epoch 70): Loss/seq after 03300 batchs: 805.5875854492188
INFO:root:Train (Epoch 70): Loss/seq after 03350 batchs: 804.5300903320312
INFO:root:Train (Epoch 70): Loss/seq after 03400 batchs: 797.4185791015625
INFO:root:Train (Epoch 70): Loss/seq after 03450 batchs: 793.7363891601562
INFO:root:Train (Epoch 70): Loss/seq after 03500 batchs: 793.6428833007812
INFO:root:Train (Epoch 70): Loss/seq after 03550 batchs: 789.2335205078125
INFO:root:Train (Epoch 70): Loss/seq after 03600 batchs: 796.7081298828125
INFO:root:Train (Epoch 70): Loss/seq after 03650 batchs: 792.5996704101562
INFO:root:Train (Epoch 70): Loss/seq after 03700 batchs: 793.5004272460938
INFO:root:Train (Epoch 70): Loss/seq after 03750 batchs: 796.9932250976562
INFO:root:Train (Epoch 70): Loss/seq after 03800 batchs: 792.4220581054688
INFO:root:Train (Epoch 70): Loss/seq after 03850 batchs: 790.3289794921875
INFO:root:Train (Epoch 70): Loss/seq after 03900 batchs: 794.713623046875
INFO:root:Train (Epoch 70): Loss/seq after 03950 batchs: 798.693115234375
INFO:root:Train (Epoch 70): Loss/seq after 04000 batchs: 793.6090087890625
INFO:root:Train (Epoch 70): Loss/seq after 04050 batchs: 787.9495239257812
INFO:root:Train (Epoch 70): Loss/seq after 04100 batchs: 784.617919921875
INFO:root:Train (Epoch 70): Loss/seq after 04150 batchs: 782.5574340820312
INFO:root:Train (Epoch 70): Loss/seq after 04200 batchs: 779.757568359375
INFO:root:Train (Epoch 70): Loss/seq after 04250 batchs: 777.0264892578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 70): Loss/seq after 00000 batches: 578.3475341796875
INFO:root:# Valid (Epoch 70): Loss/seq after 00050 batches: 699.4110717773438
INFO:root:# Valid (Epoch 70): Loss/seq after 00100 batches: 970.4962158203125
INFO:root:# Valid (Epoch 70): Loss/seq after 00150 batches: 737.3528442382812
INFO:root:# Valid (Epoch 70): Loss/seq after 00200 batches: 686.7973022460938
INFO:root:Artifacts: Make stick videos for epoch 70
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_70_on_20220413_004828.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_70_index_1189_on_20220413_004828.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 71): Loss/seq after 00000 batchs: 1455.14404296875
INFO:root:Train (Epoch 71): Loss/seq after 00050 batchs: 1025.0748291015625
INFO:root:Train (Epoch 71): Loss/seq after 00100 batchs: 1073.45263671875
INFO:root:Train (Epoch 71): Loss/seq after 00150 batchs: 962.398681640625
INFO:root:Train (Epoch 71): Loss/seq after 00200 batchs: 1069.4664306640625
INFO:root:Train (Epoch 71): Loss/seq after 00250 batchs: 1175.927734375
INFO:root:Train (Epoch 71): Loss/seq after 00300 batchs: 1139.6790771484375
INFO:root:Train (Epoch 71): Loss/seq after 00350 batchs: 1055.0596923828125
INFO:root:Train (Epoch 71): Loss/seq after 00400 batchs: 1069.7376708984375
INFO:root:Train (Epoch 71): Loss/seq after 00450 batchs: 1033.7745361328125
INFO:root:Train (Epoch 71): Loss/seq after 00500 batchs: 1014.5787963867188
INFO:root:Train (Epoch 71): Loss/seq after 00550 batchs: 977.8165893554688
INFO:root:Train (Epoch 71): Loss/seq after 00600 batchs: 940.2962646484375
INFO:root:Train (Epoch 71): Loss/seq after 00650 batchs: 948.5222778320312
INFO:root:Train (Epoch 71): Loss/seq after 00700 batchs: 930.3723754882812
INFO:root:Train (Epoch 71): Loss/seq after 00750 batchs: 958.6617431640625
INFO:root:Train (Epoch 71): Loss/seq after 00800 batchs: 953.2850952148438
INFO:root:Train (Epoch 71): Loss/seq after 00850 batchs: 923.4387817382812
INFO:root:Train (Epoch 71): Loss/seq after 00900 batchs: 904.9632568359375
INFO:root:Train (Epoch 71): Loss/seq after 00950 batchs: 919.0025634765625
INFO:root:Train (Epoch 71): Loss/seq after 01000 batchs: 913.5293579101562
INFO:root:Train (Epoch 71): Loss/seq after 01050 batchs: 896.7689208984375
INFO:root:Train (Epoch 71): Loss/seq after 01100 batchs: 883.0324096679688
INFO:root:Train (Epoch 71): Loss/seq after 01150 batchs: 860.9022827148438
INFO:root:Train (Epoch 71): Loss/seq after 01200 batchs: 859.6771240234375
INFO:root:Train (Epoch 71): Loss/seq after 01250 batchs: 853.4436645507812
INFO:root:Train (Epoch 71): Loss/seq after 01300 batchs: 844.4854125976562
INFO:root:Train (Epoch 71): Loss/seq after 01350 batchs: 837.2059936523438
INFO:root:Train (Epoch 71): Loss/seq after 01400 batchs: 854.344482421875
INFO:root:Train (Epoch 71): Loss/seq after 01450 batchs: 852.4151611328125
INFO:root:Train (Epoch 71): Loss/seq after 01500 batchs: 853.634765625
INFO:root:Train (Epoch 71): Loss/seq after 01550 batchs: 854.2030639648438
INFO:root:Train (Epoch 71): Loss/seq after 01600 batchs: 844.907958984375
INFO:root:Train (Epoch 71): Loss/seq after 01650 batchs: 839.6286010742188
INFO:root:Train (Epoch 71): Loss/seq after 01700 batchs: 837.6239013671875
INFO:root:Train (Epoch 71): Loss/seq after 01750 batchs: 832.1381225585938
INFO:root:Train (Epoch 71): Loss/seq after 01800 batchs: 825.7595825195312
INFO:root:Train (Epoch 71): Loss/seq after 01850 batchs: 818.6351318359375
INFO:root:Train (Epoch 71): Loss/seq after 01900 batchs: 817.9965209960938
INFO:root:Train (Epoch 71): Loss/seq after 01950 batchs: 813.3226318359375
INFO:root:Train (Epoch 71): Loss/seq after 02000 batchs: 808.5401000976562
INFO:root:Train (Epoch 71): Loss/seq after 02050 batchs: 804.7201538085938
INFO:root:Train (Epoch 71): Loss/seq after 02100 batchs: 798.6483764648438
INFO:root:Train (Epoch 71): Loss/seq after 02150 batchs: 794.01220703125
INFO:root:Train (Epoch 71): Loss/seq after 02200 batchs: 788.3326416015625
INFO:root:Train (Epoch 71): Loss/seq after 02250 batchs: 787.9776611328125
INFO:root:Train (Epoch 71): Loss/seq after 02300 batchs: 793.4744873046875
INFO:root:Train (Epoch 71): Loss/seq after 02350 batchs: 786.1561279296875
INFO:root:Train (Epoch 71): Loss/seq after 02400 batchs: 784.3832397460938
INFO:root:Train (Epoch 71): Loss/seq after 02450 batchs: 776.4801635742188
INFO:root:Train (Epoch 71): Loss/seq after 02500 batchs: 764.4194946289062
INFO:root:Train (Epoch 71): Loss/seq after 02550 batchs: 755.592041015625
INFO:root:Train (Epoch 71): Loss/seq after 02600 batchs: 753.5572509765625
INFO:root:Train (Epoch 71): Loss/seq after 02650 batchs: 750.0051879882812
INFO:root:Train (Epoch 71): Loss/seq after 02700 batchs: 746.6239624023438
INFO:root:Train (Epoch 71): Loss/seq after 02750 batchs: 770.2474975585938
INFO:root:Train (Epoch 71): Loss/seq after 02800 batchs: 773.7260131835938
INFO:root:Train (Epoch 71): Loss/seq after 02850 batchs: 772.4080200195312
INFO:root:Train (Epoch 71): Loss/seq after 02900 batchs: 772.4498291015625
INFO:root:Train (Epoch 71): Loss/seq after 02950 batchs: 769.2243041992188
INFO:root:Train (Epoch 71): Loss/seq after 03000 batchs: 771.9275512695312
INFO:root:Train (Epoch 71): Loss/seq after 03050 batchs: 776.9111328125
INFO:root:Train (Epoch 71): Loss/seq after 03100 batchs: 781.7716674804688
INFO:root:Train (Epoch 71): Loss/seq after 03150 batchs: 788.251953125
INFO:root:Train (Epoch 71): Loss/seq after 03200 batchs: 795.0348510742188
INFO:root:Train (Epoch 71): Loss/seq after 03250 batchs: 800.3030395507812
INFO:root:Train (Epoch 71): Loss/seq after 03300 batchs: 799.5668334960938
INFO:root:Train (Epoch 71): Loss/seq after 03350 batchs: 798.8898315429688
INFO:root:Train (Epoch 71): Loss/seq after 03400 batchs: 791.84033203125
INFO:root:Train (Epoch 71): Loss/seq after 03450 batchs: 788.3007202148438
INFO:root:Train (Epoch 71): Loss/seq after 03500 batchs: 787.864990234375
INFO:root:Train (Epoch 71): Loss/seq after 03550 batchs: 783.2904052734375
INFO:root:Train (Epoch 71): Loss/seq after 03600 batchs: 790.5028076171875
INFO:root:Train (Epoch 71): Loss/seq after 03650 batchs: 786.2620239257812
INFO:root:Train (Epoch 71): Loss/seq after 03700 batchs: 787.2672119140625
INFO:root:Train (Epoch 71): Loss/seq after 03750 batchs: 790.8037719726562
INFO:root:Train (Epoch 71): Loss/seq after 03800 batchs: 786.1895141601562
INFO:root:Train (Epoch 71): Loss/seq after 03850 batchs: 784.2174072265625
INFO:root:Train (Epoch 71): Loss/seq after 03900 batchs: 788.5275268554688
INFO:root:Train (Epoch 71): Loss/seq after 03950 batchs: 792.4266357421875
INFO:root:Train (Epoch 71): Loss/seq after 04000 batchs: 787.3640747070312
INFO:root:Train (Epoch 71): Loss/seq after 04050 batchs: 781.7101440429688
INFO:root:Train (Epoch 71): Loss/seq after 04100 batchs: 778.2863159179688
INFO:root:Train (Epoch 71): Loss/seq after 04150 batchs: 776.2483520507812
INFO:root:Train (Epoch 71): Loss/seq after 04200 batchs: 773.5773315429688
INFO:root:Train (Epoch 71): Loss/seq after 04250 batchs: 770.8988037109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 71): Loss/seq after 00000 batches: 523.5752563476562
INFO:root:# Valid (Epoch 71): Loss/seq after 00050 batches: 691.3268432617188
INFO:root:# Valid (Epoch 71): Loss/seq after 00100 batches: 956.0678100585938
INFO:root:# Valid (Epoch 71): Loss/seq after 00150 batches: 724.932861328125
INFO:root:# Valid (Epoch 71): Loss/seq after 00200 batches: 670.9157104492188
INFO:root:Artifacts: Make stick videos for epoch 71
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_71_on_20220413_005350.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_71_index_83_on_20220413_005350.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 72): Loss/seq after 00000 batchs: 1513.067626953125
INFO:root:Train (Epoch 72): Loss/seq after 00050 batchs: 1040.31005859375
INFO:root:Train (Epoch 72): Loss/seq after 00100 batchs: 1074.6063232421875
INFO:root:Train (Epoch 72): Loss/seq after 00150 batchs: 964.1873779296875
INFO:root:Train (Epoch 72): Loss/seq after 00200 batchs: 1066.7130126953125
INFO:root:Train (Epoch 72): Loss/seq after 00250 batchs: 1177.77685546875
INFO:root:Train (Epoch 72): Loss/seq after 00300 batchs: 1141.0531005859375
INFO:root:Train (Epoch 72): Loss/seq after 00350 batchs: 1056.7586669921875
INFO:root:Train (Epoch 72): Loss/seq after 00400 batchs: 1075.79931640625
INFO:root:Train (Epoch 72): Loss/seq after 00450 batchs: 1037.97021484375
INFO:root:Train (Epoch 72): Loss/seq after 00500 batchs: 1012.974365234375
INFO:root:Train (Epoch 72): Loss/seq after 00550 batchs: 976.88427734375
INFO:root:Train (Epoch 72): Loss/seq after 00600 batchs: 938.7719116210938
INFO:root:Train (Epoch 72): Loss/seq after 00650 batchs: 942.40234375
INFO:root:Train (Epoch 72): Loss/seq after 00700 batchs: 923.615478515625
INFO:root:Train (Epoch 72): Loss/seq after 00750 batchs: 956.403076171875
INFO:root:Train (Epoch 72): Loss/seq after 00800 batchs: 951.2234497070312
INFO:root:Train (Epoch 72): Loss/seq after 00850 batchs: 920.4277954101562
INFO:root:Train (Epoch 72): Loss/seq after 00900 batchs: 900.8104248046875
INFO:root:Train (Epoch 72): Loss/seq after 00950 batchs: 913.7216796875
INFO:root:Train (Epoch 72): Loss/seq after 01000 batchs: 906.7764892578125
INFO:root:Train (Epoch 72): Loss/seq after 01050 batchs: 889.4671630859375
INFO:root:Train (Epoch 72): Loss/seq after 01100 batchs: 874.8124389648438
INFO:root:Train (Epoch 72): Loss/seq after 01150 batchs: 852.3771362304688
INFO:root:Train (Epoch 72): Loss/seq after 01200 batchs: 851.0110473632812
INFO:root:Train (Epoch 72): Loss/seq after 01250 batchs: 844.2359008789062
INFO:root:Train (Epoch 72): Loss/seq after 01300 batchs: 835.71337890625
INFO:root:Train (Epoch 72): Loss/seq after 01350 batchs: 828.24951171875
INFO:root:Train (Epoch 72): Loss/seq after 01400 batchs: 845.43505859375
INFO:root:Train (Epoch 72): Loss/seq after 01450 batchs: 842.9688720703125
INFO:root:Train (Epoch 72): Loss/seq after 01500 batchs: 844.2825927734375
INFO:root:Train (Epoch 72): Loss/seq after 01550 batchs: 844.6840209960938
INFO:root:Train (Epoch 72): Loss/seq after 01600 batchs: 835.2953491210938
INFO:root:Train (Epoch 72): Loss/seq after 01650 batchs: 829.8577880859375
INFO:root:Train (Epoch 72): Loss/seq after 01700 batchs: 827.1273803710938
INFO:root:Train (Epoch 72): Loss/seq after 01750 batchs: 821.029296875
INFO:root:Train (Epoch 72): Loss/seq after 01800 batchs: 814.688720703125
INFO:root:Train (Epoch 72): Loss/seq after 01850 batchs: 807.6386108398438
INFO:root:Train (Epoch 72): Loss/seq after 01900 batchs: 806.765380859375
INFO:root:Train (Epoch 72): Loss/seq after 01950 batchs: 802.3169555664062
INFO:root:Train (Epoch 72): Loss/seq after 02000 batchs: 797.9772338867188
INFO:root:Train (Epoch 72): Loss/seq after 02050 batchs: 794.1951293945312
INFO:root:Train (Epoch 72): Loss/seq after 02100 batchs: 788.3091430664062
INFO:root:Train (Epoch 72): Loss/seq after 02150 batchs: 783.9395141601562
INFO:root:Train (Epoch 72): Loss/seq after 02200 batchs: 778.4971313476562
INFO:root:Train (Epoch 72): Loss/seq after 02250 batchs: 778.359375
INFO:root:Train (Epoch 72): Loss/seq after 02300 batchs: 783.4171142578125
INFO:root:Train (Epoch 72): Loss/seq after 02350 batchs: 776.302978515625
INFO:root:Train (Epoch 72): Loss/seq after 02400 batchs: 774.5684814453125
INFO:root:Train (Epoch 72): Loss/seq after 02450 batchs: 766.889892578125
INFO:root:Train (Epoch 72): Loss/seq after 02500 batchs: 755.0083618164062
INFO:root:Train (Epoch 72): Loss/seq after 02550 batchs: 746.2443237304688
INFO:root:Train (Epoch 72): Loss/seq after 02600 batchs: 744.4019775390625
INFO:root:Train (Epoch 72): Loss/seq after 02650 batchs: 740.9547119140625
INFO:root:Train (Epoch 72): Loss/seq after 02700 batchs: 737.8255004882812
INFO:root:Train (Epoch 72): Loss/seq after 02750 batchs: 761.9255981445312
INFO:root:Train (Epoch 72): Loss/seq after 02800 batchs: 765.537841796875
INFO:root:Train (Epoch 72): Loss/seq after 02850 batchs: 764.16357421875
INFO:root:Train (Epoch 72): Loss/seq after 02900 batchs: 763.6799926757812
INFO:root:Train (Epoch 72): Loss/seq after 02950 batchs: 760.3506469726562
INFO:root:Train (Epoch 72): Loss/seq after 03000 batchs: 763.1463012695312
INFO:root:Train (Epoch 72): Loss/seq after 03050 batchs: 768.15185546875
INFO:root:Train (Epoch 72): Loss/seq after 03100 batchs: 772.9384765625
INFO:root:Train (Epoch 72): Loss/seq after 03150 batchs: 779.2171020507812
INFO:root:Train (Epoch 72): Loss/seq after 03200 batchs: 786.9110717773438
INFO:root:Train (Epoch 72): Loss/seq after 03250 batchs: 792.1165161132812
INFO:root:Train (Epoch 72): Loss/seq after 03300 batchs: 791.1856689453125
INFO:root:Train (Epoch 72): Loss/seq after 03350 batchs: 790.368896484375
INFO:root:Train (Epoch 72): Loss/seq after 03400 batchs: 783.3843994140625
INFO:root:Train (Epoch 72): Loss/seq after 03450 batchs: 779.9806518554688
INFO:root:Train (Epoch 72): Loss/seq after 03500 batchs: 779.7176513671875
INFO:root:Train (Epoch 72): Loss/seq after 03550 batchs: 775.1279907226562
INFO:root:Train (Epoch 72): Loss/seq after 03600 batchs: 782.4586181640625
INFO:root:Train (Epoch 72): Loss/seq after 03650 batchs: 778.0579833984375
INFO:root:Train (Epoch 72): Loss/seq after 03700 batchs: 778.7547607421875
INFO:root:Train (Epoch 72): Loss/seq after 03750 batchs: 782.1619873046875
INFO:root:Train (Epoch 72): Loss/seq after 03800 batchs: 777.63818359375
INFO:root:Train (Epoch 72): Loss/seq after 03850 batchs: 775.7760009765625
INFO:root:Train (Epoch 72): Loss/seq after 03900 batchs: 780.2700805664062
INFO:root:Train (Epoch 72): Loss/seq after 03950 batchs: 784.4737548828125
INFO:root:Train (Epoch 72): Loss/seq after 04000 batchs: 779.43798828125
INFO:root:Train (Epoch 72): Loss/seq after 04050 batchs: 773.9050903320312
INFO:root:Train (Epoch 72): Loss/seq after 04100 batchs: 770.588134765625
INFO:root:Train (Epoch 72): Loss/seq after 04150 batchs: 768.5864868164062
INFO:root:Train (Epoch 72): Loss/seq after 04200 batchs: 766.0692749023438
INFO:root:Train (Epoch 72): Loss/seq after 04250 batchs: 763.4705810546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 72): Loss/seq after 00000 batches: 539.1529541015625
INFO:root:# Valid (Epoch 72): Loss/seq after 00050 batches: 696.207275390625
INFO:root:# Valid (Epoch 72): Loss/seq after 00100 batches: 961.5046997070312
INFO:root:# Valid (Epoch 72): Loss/seq after 00150 batches: 734.9873657226562
INFO:root:# Valid (Epoch 72): Loss/seq after 00200 batches: 685.4855346679688
INFO:root:Artifacts: Make stick videos for epoch 72
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_72_on_20220413_005912.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_72_index_162_on_20220413_005912.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 73): Loss/seq after 00000 batchs: 1451.9697265625
INFO:root:Train (Epoch 73): Loss/seq after 00050 batchs: 996.5175170898438
INFO:root:Train (Epoch 73): Loss/seq after 00100 batchs: 1044.35791015625
INFO:root:Train (Epoch 73): Loss/seq after 00150 batchs: 939.3536987304688
INFO:root:Train (Epoch 73): Loss/seq after 00200 batchs: 1040.2138671875
INFO:root:Train (Epoch 73): Loss/seq after 00250 batchs: 1155.4776611328125
INFO:root:Train (Epoch 73): Loss/seq after 00300 batchs: 1121.4560546875
INFO:root:Train (Epoch 73): Loss/seq after 00350 batchs: 1038.6678466796875
INFO:root:Train (Epoch 73): Loss/seq after 00400 batchs: 1051.4859619140625
INFO:root:Train (Epoch 73): Loss/seq after 00450 batchs: 1016.8109741210938
INFO:root:Train (Epoch 73): Loss/seq after 00500 batchs: 996.8071899414062
INFO:root:Train (Epoch 73): Loss/seq after 00550 batchs: 961.0314331054688
INFO:root:Train (Epoch 73): Loss/seq after 00600 batchs: 923.5543823242188
INFO:root:Train (Epoch 73): Loss/seq after 00650 batchs: 930.634765625
INFO:root:Train (Epoch 73): Loss/seq after 00700 batchs: 910.583984375
INFO:root:Train (Epoch 73): Loss/seq after 00750 batchs: 938.3764038085938
INFO:root:Train (Epoch 73): Loss/seq after 00800 batchs: 933.4600219726562
INFO:root:Train (Epoch 73): Loss/seq after 00850 batchs: 903.7340698242188
INFO:root:Train (Epoch 73): Loss/seq after 00900 batchs: 884.5911254882812
INFO:root:Train (Epoch 73): Loss/seq after 00950 batchs: 892.1884155273438
INFO:root:Train (Epoch 73): Loss/seq after 01000 batchs: 886.677734375
INFO:root:Train (Epoch 73): Loss/seq after 01050 batchs: 869.2630004882812
INFO:root:Train (Epoch 73): Loss/seq after 01100 batchs: 854.1329345703125
INFO:root:Train (Epoch 73): Loss/seq after 01150 batchs: 832.6333618164062
INFO:root:Train (Epoch 73): Loss/seq after 01200 batchs: 831.8828735351562
INFO:root:Train (Epoch 73): Loss/seq after 01250 batchs: 825.3259887695312
INFO:root:Train (Epoch 73): Loss/seq after 01300 batchs: 817.3382568359375
INFO:root:Train (Epoch 73): Loss/seq after 01350 batchs: 809.7235107421875
INFO:root:Train (Epoch 73): Loss/seq after 01400 batchs: 829.4996337890625
INFO:root:Train (Epoch 73): Loss/seq after 01450 batchs: 827.6300659179688
INFO:root:Train (Epoch 73): Loss/seq after 01500 batchs: 829.33740234375
INFO:root:Train (Epoch 73): Loss/seq after 01550 batchs: 830.1637573242188
INFO:root:Train (Epoch 73): Loss/seq after 01600 batchs: 821.0049438476562
INFO:root:Train (Epoch 73): Loss/seq after 01650 batchs: 815.3700561523438
INFO:root:Train (Epoch 73): Loss/seq after 01700 batchs: 812.9865112304688
INFO:root:Train (Epoch 73): Loss/seq after 01750 batchs: 807.3305053710938
INFO:root:Train (Epoch 73): Loss/seq after 01800 batchs: 801.1914672851562
INFO:root:Train (Epoch 73): Loss/seq after 01850 batchs: 794.322265625
INFO:root:Train (Epoch 73): Loss/seq after 01900 batchs: 793.7578735351562
INFO:root:Train (Epoch 73): Loss/seq after 01950 batchs: 789.2700805664062
INFO:root:Train (Epoch 73): Loss/seq after 02000 batchs: 785.0166015625
INFO:root:Train (Epoch 73): Loss/seq after 02050 batchs: 781.4603271484375
INFO:root:Train (Epoch 73): Loss/seq after 02100 batchs: 775.7957153320312
INFO:root:Train (Epoch 73): Loss/seq after 02150 batchs: 771.5858764648438
INFO:root:Train (Epoch 73): Loss/seq after 02200 batchs: 766.1358642578125
INFO:root:Train (Epoch 73): Loss/seq after 02250 batchs: 765.6110229492188
INFO:root:Train (Epoch 73): Loss/seq after 02300 batchs: 770.1713256835938
INFO:root:Train (Epoch 73): Loss/seq after 02350 batchs: 763.505859375
INFO:root:Train (Epoch 73): Loss/seq after 02400 batchs: 762.1539306640625
INFO:root:Train (Epoch 73): Loss/seq after 02450 batchs: 754.6217651367188
INFO:root:Train (Epoch 73): Loss/seq after 02500 batchs: 743.0067138671875
INFO:root:Train (Epoch 73): Loss/seq after 02550 batchs: 734.4790649414062
INFO:root:Train (Epoch 73): Loss/seq after 02600 batchs: 732.647216796875
INFO:root:Train (Epoch 73): Loss/seq after 02650 batchs: 729.503173828125
INFO:root:Train (Epoch 73): Loss/seq after 02700 batchs: 726.4447631835938
INFO:root:Train (Epoch 73): Loss/seq after 02750 batchs: 750.273193359375
INFO:root:Train (Epoch 73): Loss/seq after 02800 batchs: 754.216552734375
INFO:root:Train (Epoch 73): Loss/seq after 02850 batchs: 753.1702270507812
INFO:root:Train (Epoch 73): Loss/seq after 02900 batchs: 753.6902465820312
INFO:root:Train (Epoch 73): Loss/seq after 02950 batchs: 750.6488647460938
INFO:root:Train (Epoch 73): Loss/seq after 03000 batchs: 753.4688110351562
INFO:root:Train (Epoch 73): Loss/seq after 03050 batchs: 758.564697265625
INFO:root:Train (Epoch 73): Loss/seq after 03100 batchs: 763.1885986328125
INFO:root:Train (Epoch 73): Loss/seq after 03150 batchs: 769.9258422851562
INFO:root:Train (Epoch 73): Loss/seq after 03200 batchs: 776.6148681640625
INFO:root:Train (Epoch 73): Loss/seq after 03250 batchs: 781.71044921875
INFO:root:Train (Epoch 73): Loss/seq after 03300 batchs: 780.4155883789062
INFO:root:Train (Epoch 73): Loss/seq after 03350 batchs: 779.4882202148438
INFO:root:Train (Epoch 73): Loss/seq after 03400 batchs: 772.6712646484375
INFO:root:Train (Epoch 73): Loss/seq after 03450 batchs: 769.2645263671875
INFO:root:Train (Epoch 73): Loss/seq after 03500 batchs: 768.5921630859375
INFO:root:Train (Epoch 73): Loss/seq after 03550 batchs: 764.0559692382812
INFO:root:Train (Epoch 73): Loss/seq after 03600 batchs: 771.3478393554688
INFO:root:Train (Epoch 73): Loss/seq after 03650 batchs: 767.03125
INFO:root:Train (Epoch 73): Loss/seq after 03700 batchs: 767.8883056640625
INFO:root:Train (Epoch 73): Loss/seq after 03750 batchs: 771.4489135742188
INFO:root:Train (Epoch 73): Loss/seq after 03800 batchs: 766.9915161132812
INFO:root:Train (Epoch 73): Loss/seq after 03850 batchs: 765.1262817382812
INFO:root:Train (Epoch 73): Loss/seq after 03900 batchs: 769.5883178710938
INFO:root:Train (Epoch 73): Loss/seq after 03950 batchs: 773.3866577148438
INFO:root:Train (Epoch 73): Loss/seq after 04000 batchs: 768.3673095703125
INFO:root:Train (Epoch 73): Loss/seq after 04050 batchs: 762.958984375
INFO:root:Train (Epoch 73): Loss/seq after 04100 batchs: 759.7425537109375
INFO:root:Train (Epoch 73): Loss/seq after 04150 batchs: 757.8750610351562
INFO:root:Train (Epoch 73): Loss/seq after 04200 batchs: 755.191162109375
INFO:root:Train (Epoch 73): Loss/seq after 04250 batchs: 752.5615844726562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 73): Loss/seq after 00000 batches: 539.4979858398438
INFO:root:# Valid (Epoch 73): Loss/seq after 00050 batches: 698.3804931640625
INFO:root:# Valid (Epoch 73): Loss/seq after 00100 batches: 957.0946044921875
INFO:root:# Valid (Epoch 73): Loss/seq after 00150 batches: 725.4708862304688
INFO:root:# Valid (Epoch 73): Loss/seq after 00200 batches: 670.3214111328125
INFO:root:Artifacts: Make stick videos for epoch 73
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_73_on_20220413_010435.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_73_index_164_on_20220413_010435.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 74): Loss/seq after 00000 batchs: 1445.1646728515625
INFO:root:Train (Epoch 74): Loss/seq after 00050 batchs: 1020.8842163085938
INFO:root:Train (Epoch 74): Loss/seq after 00100 batchs: 1056.30615234375
INFO:root:Train (Epoch 74): Loss/seq after 00150 batchs: 949.8109741210938
INFO:root:Train (Epoch 74): Loss/seq after 00200 batchs: 1045.2730712890625
INFO:root:Train (Epoch 74): Loss/seq after 00250 batchs: 1162.4495849609375
INFO:root:Train (Epoch 74): Loss/seq after 00300 batchs: 1128.0003662109375
INFO:root:Train (Epoch 74): Loss/seq after 00350 batchs: 1044.87353515625
INFO:root:Train (Epoch 74): Loss/seq after 00400 batchs: 1058.6097412109375
INFO:root:Train (Epoch 74): Loss/seq after 00450 batchs: 1022.3150634765625
INFO:root:Train (Epoch 74): Loss/seq after 00500 batchs: 997.5216674804688
INFO:root:Train (Epoch 74): Loss/seq after 00550 batchs: 961.2444458007812
INFO:root:Train (Epoch 74): Loss/seq after 00600 batchs: 925.521728515625
INFO:root:Train (Epoch 74): Loss/seq after 00650 batchs: 930.6401977539062
INFO:root:Train (Epoch 74): Loss/seq after 00700 batchs: 912.3853759765625
INFO:root:Train (Epoch 74): Loss/seq after 00750 batchs: 943.4877319335938
INFO:root:Train (Epoch 74): Loss/seq after 00800 batchs: 938.56640625
INFO:root:Train (Epoch 74): Loss/seq after 00850 batchs: 908.6290283203125
INFO:root:Train (Epoch 74): Loss/seq after 00900 batchs: 890.01611328125
INFO:root:Train (Epoch 74): Loss/seq after 00950 batchs: 900.0047607421875
INFO:root:Train (Epoch 74): Loss/seq after 01000 batchs: 893.5115966796875
INFO:root:Train (Epoch 74): Loss/seq after 01050 batchs: 876.2614135742188
INFO:root:Train (Epoch 74): Loss/seq after 01100 batchs: 860.6177368164062
INFO:root:Train (Epoch 74): Loss/seq after 01150 batchs: 838.4092407226562
INFO:root:Train (Epoch 74): Loss/seq after 01200 batchs: 837.0032958984375
INFO:root:Train (Epoch 74): Loss/seq after 01250 batchs: 830.042236328125
INFO:root:Train (Epoch 74): Loss/seq after 01300 batchs: 821.158447265625
INFO:root:Train (Epoch 74): Loss/seq after 01350 batchs: 812.8250732421875
INFO:root:Train (Epoch 74): Loss/seq after 01400 batchs: 827.658203125
INFO:root:Train (Epoch 74): Loss/seq after 01450 batchs: 825.0840454101562
INFO:root:Train (Epoch 74): Loss/seq after 01500 batchs: 826.7632446289062
INFO:root:Train (Epoch 74): Loss/seq after 01550 batchs: 827.4528198242188
INFO:root:Train (Epoch 74): Loss/seq after 01600 batchs: 818.0946655273438
INFO:root:Train (Epoch 74): Loss/seq after 01650 batchs: 812.7400512695312
INFO:root:Train (Epoch 74): Loss/seq after 01700 batchs: 810.468994140625
INFO:root:Train (Epoch 74): Loss/seq after 01750 batchs: 804.8408203125
INFO:root:Train (Epoch 74): Loss/seq after 01800 batchs: 799.0160522460938
INFO:root:Train (Epoch 74): Loss/seq after 01850 batchs: 792.2770385742188
INFO:root:Train (Epoch 74): Loss/seq after 01900 batchs: 791.7583618164062
INFO:root:Train (Epoch 74): Loss/seq after 01950 batchs: 787.1561279296875
INFO:root:Train (Epoch 74): Loss/seq after 02000 batchs: 782.7636108398438
INFO:root:Train (Epoch 74): Loss/seq after 02050 batchs: 779.2399291992188
INFO:root:Train (Epoch 74): Loss/seq after 02100 batchs: 773.59326171875
INFO:root:Train (Epoch 74): Loss/seq after 02150 batchs: 769.5049438476562
INFO:root:Train (Epoch 74): Loss/seq after 02200 batchs: 764.0709838867188
INFO:root:Train (Epoch 74): Loss/seq after 02250 batchs: 763.6434326171875
INFO:root:Train (Epoch 74): Loss/seq after 02300 batchs: 769.0786743164062
INFO:root:Train (Epoch 74): Loss/seq after 02350 batchs: 762.4690551757812
INFO:root:Train (Epoch 74): Loss/seq after 02400 batchs: 761.1951293945312
INFO:root:Train (Epoch 74): Loss/seq after 02450 batchs: 753.7047729492188
INFO:root:Train (Epoch 74): Loss/seq after 02500 batchs: 742.0545043945312
INFO:root:Train (Epoch 74): Loss/seq after 02550 batchs: 733.4935913085938
INFO:root:Train (Epoch 74): Loss/seq after 02600 batchs: 731.7245483398438
INFO:root:Train (Epoch 74): Loss/seq after 02650 batchs: 728.4138793945312
INFO:root:Train (Epoch 74): Loss/seq after 02700 batchs: 725.2957153320312
INFO:root:Train (Epoch 74): Loss/seq after 02750 batchs: 749.3247680664062
INFO:root:Train (Epoch 74): Loss/seq after 02800 batchs: 752.6702880859375
INFO:root:Train (Epoch 74): Loss/seq after 02850 batchs: 751.691162109375
INFO:root:Train (Epoch 74): Loss/seq after 02900 batchs: 751.3901977539062
INFO:root:Train (Epoch 74): Loss/seq after 02950 batchs: 748.1696166992188
INFO:root:Train (Epoch 74): Loss/seq after 03000 batchs: 751.024658203125
INFO:root:Train (Epoch 74): Loss/seq after 03050 batchs: 755.8594360351562
INFO:root:Train (Epoch 74): Loss/seq after 03100 batchs: 760.68896484375
INFO:root:Train (Epoch 74): Loss/seq after 03150 batchs: 766.6781616210938
INFO:root:Train (Epoch 74): Loss/seq after 03200 batchs: 774.0296630859375
INFO:root:Train (Epoch 74): Loss/seq after 03250 batchs: 779.0501098632812
INFO:root:Train (Epoch 74): Loss/seq after 03300 batchs: 777.6463623046875
INFO:root:Train (Epoch 74): Loss/seq after 03350 batchs: 776.8750610351562
INFO:root:Train (Epoch 74): Loss/seq after 03400 batchs: 770.17236328125
INFO:root:Train (Epoch 74): Loss/seq after 03450 batchs: 767.0335693359375
INFO:root:Train (Epoch 74): Loss/seq after 03500 batchs: 766.8385009765625
INFO:root:Train (Epoch 74): Loss/seq after 03550 batchs: 762.2797241210938
INFO:root:Train (Epoch 74): Loss/seq after 03600 batchs: 769.4800415039062
INFO:root:Train (Epoch 74): Loss/seq after 03650 batchs: 765.1599731445312
INFO:root:Train (Epoch 74): Loss/seq after 03700 batchs: 765.9799194335938
INFO:root:Train (Epoch 74): Loss/seq after 03750 batchs: 769.5030517578125
INFO:root:Train (Epoch 74): Loss/seq after 03800 batchs: 765.0872802734375
INFO:root:Train (Epoch 74): Loss/seq after 03850 batchs: 763.2473754882812
INFO:root:Train (Epoch 74): Loss/seq after 03900 batchs: 767.5948486328125
INFO:root:Train (Epoch 74): Loss/seq after 03950 batchs: 771.433349609375
INFO:root:Train (Epoch 74): Loss/seq after 04000 batchs: 766.2933959960938
INFO:root:Train (Epoch 74): Loss/seq after 04050 batchs: 760.8533935546875
INFO:root:Train (Epoch 74): Loss/seq after 04100 batchs: 757.5912475585938
INFO:root:Train (Epoch 74): Loss/seq after 04150 batchs: 755.7314453125
INFO:root:Train (Epoch 74): Loss/seq after 04200 batchs: 753.308837890625
INFO:root:Train (Epoch 74): Loss/seq after 04250 batchs: 750.6973266601562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 74): Loss/seq after 00000 batches: 536.25537109375
INFO:root:# Valid (Epoch 74): Loss/seq after 00050 batches: 684.0211791992188
INFO:root:# Valid (Epoch 74): Loss/seq after 00100 batches: 939.8931884765625
INFO:root:# Valid (Epoch 74): Loss/seq after 00150 batches: 709.7264404296875
INFO:root:# Valid (Epoch 74): Loss/seq after 00200 batches: 653.8863525390625
INFO:root:Artifacts: Make stick videos for epoch 74
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_74_on_20220413_010956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_74_index_810_on_20220413_010956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 75): Loss/seq after 00000 batchs: 1336.9293212890625
INFO:root:Train (Epoch 75): Loss/seq after 00050 batchs: 979.6183471679688
INFO:root:Train (Epoch 75): Loss/seq after 00100 batchs: 1008.9326782226562
INFO:root:Train (Epoch 75): Loss/seq after 00150 batchs: 914.4221801757812
INFO:root:Train (Epoch 75): Loss/seq after 00200 batchs: 1018.7674560546875
INFO:root:Train (Epoch 75): Loss/seq after 00250 batchs: 1134.8536376953125
INFO:root:Train (Epoch 75): Loss/seq after 00300 batchs: 1104.556884765625
INFO:root:Train (Epoch 75): Loss/seq after 00350 batchs: 1024.0029296875
INFO:root:Train (Epoch 75): Loss/seq after 00400 batchs: 1040.3292236328125
INFO:root:Train (Epoch 75): Loss/seq after 00450 batchs: 1006.2918701171875
INFO:root:Train (Epoch 75): Loss/seq after 00500 batchs: 982.9391479492188
INFO:root:Train (Epoch 75): Loss/seq after 00550 batchs: 947.8203735351562
INFO:root:Train (Epoch 75): Loss/seq after 00600 batchs: 912.3058471679688
INFO:root:Train (Epoch 75): Loss/seq after 00650 batchs: 915.2620849609375
INFO:root:Train (Epoch 75): Loss/seq after 00700 batchs: 897.2255249023438
INFO:root:Train (Epoch 75): Loss/seq after 00750 batchs: 924.1383056640625
INFO:root:Train (Epoch 75): Loss/seq after 00800 batchs: 921.9880981445312
INFO:root:Train (Epoch 75): Loss/seq after 00850 batchs: 892.674072265625
INFO:root:Train (Epoch 75): Loss/seq after 00900 batchs: 874.8609008789062
INFO:root:Train (Epoch 75): Loss/seq after 00950 batchs: 890.4567260742188
INFO:root:Train (Epoch 75): Loss/seq after 01000 batchs: 885.466064453125
INFO:root:Train (Epoch 75): Loss/seq after 01050 batchs: 870.3240966796875
INFO:root:Train (Epoch 75): Loss/seq after 01100 batchs: 857.003662109375
INFO:root:Train (Epoch 75): Loss/seq after 01150 batchs: 836.6112060546875
INFO:root:Train (Epoch 75): Loss/seq after 01200 batchs: 835.9476928710938
INFO:root:Train (Epoch 75): Loss/seq after 01250 batchs: 829.5341186523438
INFO:root:Train (Epoch 75): Loss/seq after 01300 batchs: 820.3945922851562
INFO:root:Train (Epoch 75): Loss/seq after 01350 batchs: 812.063232421875
INFO:root:Train (Epoch 75): Loss/seq after 01400 batchs: 827.6669921875
INFO:root:Train (Epoch 75): Loss/seq after 01450 batchs: 825.3488159179688
INFO:root:Train (Epoch 75): Loss/seq after 01500 batchs: 827.0804443359375
INFO:root:Train (Epoch 75): Loss/seq after 01550 batchs: 827.7674560546875
INFO:root:Train (Epoch 75): Loss/seq after 01600 batchs: 818.5345458984375
INFO:root:Train (Epoch 75): Loss/seq after 01650 batchs: 813.0610961914062
INFO:root:Train (Epoch 75): Loss/seq after 01700 batchs: 810.5376586914062
INFO:root:Train (Epoch 75): Loss/seq after 01750 batchs: 804.5066528320312
INFO:root:Train (Epoch 75): Loss/seq after 01800 batchs: 798.1849975585938
INFO:root:Train (Epoch 75): Loss/seq after 01850 batchs: 791.3660278320312
INFO:root:Train (Epoch 75): Loss/seq after 01900 batchs: 790.431396484375
INFO:root:Train (Epoch 75): Loss/seq after 01950 batchs: 785.8530883789062
INFO:root:Train (Epoch 75): Loss/seq after 02000 batchs: 781.322509765625
INFO:root:Train (Epoch 75): Loss/seq after 02050 batchs: 777.634765625
INFO:root:Train (Epoch 75): Loss/seq after 02100 batchs: 771.9111938476562
INFO:root:Train (Epoch 75): Loss/seq after 02150 batchs: 767.4198608398438
INFO:root:Train (Epoch 75): Loss/seq after 02200 batchs: 761.9406127929688
INFO:root:Train (Epoch 75): Loss/seq after 02250 batchs: 761.3271484375
INFO:root:Train (Epoch 75): Loss/seq after 02300 batchs: 765.8214111328125
INFO:root:Train (Epoch 75): Loss/seq after 02350 batchs: 759.0828247070312
INFO:root:Train (Epoch 75): Loss/seq after 02400 batchs: 757.6532592773438
INFO:root:Train (Epoch 75): Loss/seq after 02450 batchs: 750.1157836914062
INFO:root:Train (Epoch 75): Loss/seq after 02500 batchs: 738.5803833007812
INFO:root:Train (Epoch 75): Loss/seq after 02550 batchs: 730.1697998046875
INFO:root:Train (Epoch 75): Loss/seq after 02600 batchs: 728.3350830078125
INFO:root:Train (Epoch 75): Loss/seq after 02650 batchs: 725.0161743164062
INFO:root:Train (Epoch 75): Loss/seq after 02700 batchs: 722.0137939453125
INFO:root:Train (Epoch 75): Loss/seq after 02750 batchs: 745.0491333007812
INFO:root:Train (Epoch 75): Loss/seq after 02800 batchs: 748.7352905273438
INFO:root:Train (Epoch 75): Loss/seq after 02850 batchs: 747.747314453125
INFO:root:Train (Epoch 75): Loss/seq after 02900 batchs: 748.0128173828125
INFO:root:Train (Epoch 75): Loss/seq after 02950 batchs: 745.1522216796875
INFO:root:Train (Epoch 75): Loss/seq after 03000 batchs: 747.9654541015625
INFO:root:Train (Epoch 75): Loss/seq after 03050 batchs: 752.8616943359375
INFO:root:Train (Epoch 75): Loss/seq after 03100 batchs: 758.0433349609375
INFO:root:Train (Epoch 75): Loss/seq after 03150 batchs: 765.175048828125
INFO:root:Train (Epoch 75): Loss/seq after 03200 batchs: 772.0326538085938
INFO:root:Train (Epoch 75): Loss/seq after 03250 batchs: 777.129150390625
INFO:root:Train (Epoch 75): Loss/seq after 03300 batchs: 776.6764526367188
INFO:root:Train (Epoch 75): Loss/seq after 03350 batchs: 776.211181640625
INFO:root:Train (Epoch 75): Loss/seq after 03400 batchs: 769.4586791992188
INFO:root:Train (Epoch 75): Loss/seq after 03450 batchs: 766.186279296875
INFO:root:Train (Epoch 75): Loss/seq after 03500 batchs: 765.9840087890625
INFO:root:Train (Epoch 75): Loss/seq after 03550 batchs: 761.4234619140625
INFO:root:Train (Epoch 75): Loss/seq after 03600 batchs: 768.64404296875
INFO:root:Train (Epoch 75): Loss/seq after 03650 batchs: 764.51904296875
INFO:root:Train (Epoch 75): Loss/seq after 03700 batchs: 765.4651489257812
INFO:root:Train (Epoch 75): Loss/seq after 03750 batchs: 768.9827880859375
INFO:root:Train (Epoch 75): Loss/seq after 03800 batchs: 764.559326171875
INFO:root:Train (Epoch 75): Loss/seq after 03850 batchs: 762.80810546875
INFO:root:Train (Epoch 75): Loss/seq after 03900 batchs: 766.9756469726562
INFO:root:Train (Epoch 75): Loss/seq after 03950 batchs: 770.3363037109375
INFO:root:Train (Epoch 75): Loss/seq after 04000 batchs: 765.212158203125
INFO:root:Train (Epoch 75): Loss/seq after 04050 batchs: 759.721435546875
INFO:root:Train (Epoch 75): Loss/seq after 04100 batchs: 756.482177734375
INFO:root:Train (Epoch 75): Loss/seq after 04150 batchs: 754.610595703125
INFO:root:Train (Epoch 75): Loss/seq after 04200 batchs: 751.9324951171875
INFO:root:Train (Epoch 75): Loss/seq after 04250 batchs: 749.2264404296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 75): Loss/seq after 00000 batches: 538.291259765625
INFO:root:# Valid (Epoch 75): Loss/seq after 00050 batches: 681.8740844726562
INFO:root:# Valid (Epoch 75): Loss/seq after 00100 batches: 924.5692138671875
INFO:root:# Valid (Epoch 75): Loss/seq after 00150 batches: 697.48046875
INFO:root:# Valid (Epoch 75): Loss/seq after 00200 batches: 643.1906127929688
INFO:root:Artifacts: Make stick videos for epoch 75
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_75_on_20220413_011518.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_75_index_1029_on_20220413_011518.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 76): Loss/seq after 00000 batchs: 1282.900146484375
INFO:root:Train (Epoch 76): Loss/seq after 00050 batchs: 961.0623779296875
INFO:root:Train (Epoch 76): Loss/seq after 00100 batchs: 992.1581420898438
INFO:root:Train (Epoch 76): Loss/seq after 00150 batchs: 896.4133911132812
INFO:root:Train (Epoch 76): Loss/seq after 00200 batchs: 997.072021484375
INFO:root:Train (Epoch 76): Loss/seq after 00250 batchs: 1116.1217041015625
INFO:root:Train (Epoch 76): Loss/seq after 00300 batchs: 1086.4244384765625
INFO:root:Train (Epoch 76): Loss/seq after 00350 batchs: 1008.2315673828125
INFO:root:Train (Epoch 76): Loss/seq after 00400 batchs: 1024.7279052734375
INFO:root:Train (Epoch 76): Loss/seq after 00450 batchs: 991.1788940429688
INFO:root:Train (Epoch 76): Loss/seq after 00500 batchs: 967.2041015625
INFO:root:Train (Epoch 76): Loss/seq after 00550 batchs: 932.936279296875
INFO:root:Train (Epoch 76): Loss/seq after 00600 batchs: 898.4255981445312
INFO:root:Train (Epoch 76): Loss/seq after 00650 batchs: 902.7407836914062
INFO:root:Train (Epoch 76): Loss/seq after 00700 batchs: 886.3911743164062
INFO:root:Train (Epoch 76): Loss/seq after 00750 batchs: 916.8204345703125
INFO:root:Train (Epoch 76): Loss/seq after 00800 batchs: 914.7643432617188
INFO:root:Train (Epoch 76): Loss/seq after 00850 batchs: 886.0092163085938
INFO:root:Train (Epoch 76): Loss/seq after 00900 batchs: 866.8972778320312
INFO:root:Train (Epoch 76): Loss/seq after 00950 batchs: 875.7654418945312
INFO:root:Train (Epoch 76): Loss/seq after 01000 batchs: 867.7808227539062
INFO:root:Train (Epoch 76): Loss/seq after 01050 batchs: 853.5169677734375
INFO:root:Train (Epoch 76): Loss/seq after 01100 batchs: 839.7003173828125
INFO:root:Train (Epoch 76): Loss/seq after 01150 batchs: 818.6896362304688
INFO:root:Train (Epoch 76): Loss/seq after 01200 batchs: 818.7921752929688
INFO:root:Train (Epoch 76): Loss/seq after 01250 batchs: 812.779296875
INFO:root:Train (Epoch 76): Loss/seq after 01300 batchs: 803.8030395507812
INFO:root:Train (Epoch 76): Loss/seq after 01350 batchs: 796.078125
INFO:root:Train (Epoch 76): Loss/seq after 01400 batchs: 811.3743896484375
INFO:root:Train (Epoch 76): Loss/seq after 01450 batchs: 809.4984130859375
INFO:root:Train (Epoch 76): Loss/seq after 01500 batchs: 811.6928100585938
INFO:root:Train (Epoch 76): Loss/seq after 01550 batchs: 812.454833984375
INFO:root:Train (Epoch 76): Loss/seq after 01600 batchs: 803.5258178710938
INFO:root:Train (Epoch 76): Loss/seq after 01650 batchs: 798.759033203125
INFO:root:Train (Epoch 76): Loss/seq after 01700 batchs: 796.9464721679688
INFO:root:Train (Epoch 76): Loss/seq after 01750 batchs: 791.3562622070312
INFO:root:Train (Epoch 76): Loss/seq after 01800 batchs: 785.5654907226562
INFO:root:Train (Epoch 76): Loss/seq after 01850 batchs: 779.0095825195312
INFO:root:Train (Epoch 76): Loss/seq after 01900 batchs: 778.19287109375
INFO:root:Train (Epoch 76): Loss/seq after 01950 batchs: 773.9277954101562
INFO:root:Train (Epoch 76): Loss/seq after 02000 batchs: 769.6680908203125
INFO:root:Train (Epoch 76): Loss/seq after 02050 batchs: 766.0231323242188
INFO:root:Train (Epoch 76): Loss/seq after 02100 batchs: 760.4972534179688
INFO:root:Train (Epoch 76): Loss/seq after 02150 batchs: 756.2549438476562
INFO:root:Train (Epoch 76): Loss/seq after 02200 batchs: 751.0379638671875
INFO:root:Train (Epoch 76): Loss/seq after 02250 batchs: 750.4865112304688
INFO:root:Train (Epoch 76): Loss/seq after 02300 batchs: 753.1513671875
INFO:root:Train (Epoch 76): Loss/seq after 02350 batchs: 747.0426635742188
INFO:root:Train (Epoch 76): Loss/seq after 02400 batchs: 746.0047607421875
INFO:root:Train (Epoch 76): Loss/seq after 02450 batchs: 738.6887817382812
INFO:root:Train (Epoch 76): Loss/seq after 02500 batchs: 727.3155517578125
INFO:root:Train (Epoch 76): Loss/seq after 02550 batchs: 718.9288940429688
INFO:root:Train (Epoch 76): Loss/seq after 02600 batchs: 717.24462890625
INFO:root:Train (Epoch 76): Loss/seq after 02650 batchs: 714.0045776367188
INFO:root:Train (Epoch 76): Loss/seq after 02700 batchs: 710.9523315429688
INFO:root:Train (Epoch 76): Loss/seq after 02750 batchs: 733.6979370117188
INFO:root:Train (Epoch 76): Loss/seq after 02800 batchs: 737.4266967773438
INFO:root:Train (Epoch 76): Loss/seq after 02850 batchs: 736.808837890625
INFO:root:Train (Epoch 76): Loss/seq after 02900 batchs: 737.2308959960938
INFO:root:Train (Epoch 76): Loss/seq after 02950 batchs: 734.5614013671875
INFO:root:Train (Epoch 76): Loss/seq after 03000 batchs: 737.5074462890625
INFO:root:Train (Epoch 76): Loss/seq after 03050 batchs: 742.5128173828125
INFO:root:Train (Epoch 76): Loss/seq after 03100 batchs: 747.8104248046875
INFO:root:Train (Epoch 76): Loss/seq after 03150 batchs: 754.0609741210938
INFO:root:Train (Epoch 76): Loss/seq after 03200 batchs: 760.1123046875
INFO:root:Train (Epoch 76): Loss/seq after 03250 batchs: 765.16748046875
INFO:root:Train (Epoch 76): Loss/seq after 03300 batchs: 763.7321166992188
INFO:root:Train (Epoch 76): Loss/seq after 03350 batchs: 763.1205444335938
INFO:root:Train (Epoch 76): Loss/seq after 03400 batchs: 756.4952392578125
INFO:root:Train (Epoch 76): Loss/seq after 03450 batchs: 753.0908813476562
INFO:root:Train (Epoch 76): Loss/seq after 03500 batchs: 752.6251220703125
INFO:root:Train (Epoch 76): Loss/seq after 03550 batchs: 748.3560791015625
INFO:root:Train (Epoch 76): Loss/seq after 03600 batchs: 755.9552001953125
INFO:root:Train (Epoch 76): Loss/seq after 03650 batchs: 751.968505859375
INFO:root:Train (Epoch 76): Loss/seq after 03700 batchs: 753.636474609375
INFO:root:Train (Epoch 76): Loss/seq after 03750 batchs: 757.3158569335938
INFO:root:Train (Epoch 76): Loss/seq after 03800 batchs: 753.0369873046875
INFO:root:Train (Epoch 76): Loss/seq after 03850 batchs: 751.302490234375
INFO:root:Train (Epoch 76): Loss/seq after 03900 batchs: 755.5254516601562
INFO:root:Train (Epoch 76): Loss/seq after 03950 batchs: 759.1940307617188
INFO:root:Train (Epoch 76): Loss/seq after 04000 batchs: 754.2152709960938
INFO:root:Train (Epoch 76): Loss/seq after 04050 batchs: 748.9161376953125
INFO:root:Train (Epoch 76): Loss/seq after 04100 batchs: 745.7789306640625
INFO:root:Train (Epoch 76): Loss/seq after 04150 batchs: 744.0919189453125
INFO:root:Train (Epoch 76): Loss/seq after 04200 batchs: 741.4182739257812
INFO:root:Train (Epoch 76): Loss/seq after 04250 batchs: 738.8275756835938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 76): Loss/seq after 00000 batches: 527.9622802734375
INFO:root:# Valid (Epoch 76): Loss/seq after 00050 batches: 677.2883911132812
INFO:root:# Valid (Epoch 76): Loss/seq after 00100 batches: 918.5724487304688
INFO:root:# Valid (Epoch 76): Loss/seq after 00150 batches: 692.2899169921875
INFO:root:# Valid (Epoch 76): Loss/seq after 00200 batches: 639.45361328125
INFO:root:Artifacts: Make stick videos for epoch 76
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_76_on_20220413_012040.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_76_index_423_on_20220413_012040.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 77): Loss/seq after 00000 batchs: 1317.7064208984375
INFO:root:Train (Epoch 77): Loss/seq after 00050 batchs: 982.4287109375
INFO:root:Train (Epoch 77): Loss/seq after 00100 batchs: 1005.0720825195312
INFO:root:Train (Epoch 77): Loss/seq after 00150 batchs: 911.5330200195312
INFO:root:Train (Epoch 77): Loss/seq after 00200 batchs: 1004.6026000976562
INFO:root:Train (Epoch 77): Loss/seq after 00250 batchs: 1122.4066162109375
INFO:root:Train (Epoch 77): Loss/seq after 00300 batchs: 1092.2587890625
INFO:root:Train (Epoch 77): Loss/seq after 00350 batchs: 1012.2094116210938
INFO:root:Train (Epoch 77): Loss/seq after 00400 batchs: 1027.3448486328125
INFO:root:Train (Epoch 77): Loss/seq after 00450 batchs: 992.6332397460938
INFO:root:Train (Epoch 77): Loss/seq after 00500 batchs: 969.1302490234375
INFO:root:Train (Epoch 77): Loss/seq after 00550 batchs: 935.2899780273438
INFO:root:Train (Epoch 77): Loss/seq after 00600 batchs: 899.9166870117188
INFO:root:Train (Epoch 77): Loss/seq after 00650 batchs: 903.4945068359375
INFO:root:Train (Epoch 77): Loss/seq after 00700 batchs: 886.080810546875
INFO:root:Train (Epoch 77): Loss/seq after 00750 batchs: 912.0005493164062
INFO:root:Train (Epoch 77): Loss/seq after 00800 batchs: 907.7220458984375
INFO:root:Train (Epoch 77): Loss/seq after 00850 batchs: 879.338623046875
INFO:root:Train (Epoch 77): Loss/seq after 00900 batchs: 862.0750732421875
INFO:root:Train (Epoch 77): Loss/seq after 00950 batchs: 872.978515625
INFO:root:Train (Epoch 77): Loss/seq after 01000 batchs: 866.2510375976562
INFO:root:Train (Epoch 77): Loss/seq after 01050 batchs: 849.3916625976562
INFO:root:Train (Epoch 77): Loss/seq after 01100 batchs: 835.4913940429688
INFO:root:Train (Epoch 77): Loss/seq after 01150 batchs: 814.8723754882812
INFO:root:Train (Epoch 77): Loss/seq after 01200 batchs: 814.2155151367188
INFO:root:Train (Epoch 77): Loss/seq after 01250 batchs: 808.1997680664062
INFO:root:Train (Epoch 77): Loss/seq after 01300 batchs: 799.1591796875
INFO:root:Train (Epoch 77): Loss/seq after 01350 batchs: 791.219970703125
INFO:root:Train (Epoch 77): Loss/seq after 01400 batchs: 807.287353515625
INFO:root:Train (Epoch 77): Loss/seq after 01450 batchs: 805.395263671875
INFO:root:Train (Epoch 77): Loss/seq after 01500 batchs: 807.5422973632812
INFO:root:Train (Epoch 77): Loss/seq after 01550 batchs: 807.9378662109375
INFO:root:Train (Epoch 77): Loss/seq after 01600 batchs: 799.06591796875
INFO:root:Train (Epoch 77): Loss/seq after 01650 batchs: 793.8866577148438
INFO:root:Train (Epoch 77): Loss/seq after 01700 batchs: 792.1097412109375
INFO:root:Train (Epoch 77): Loss/seq after 01750 batchs: 786.5032348632812
INFO:root:Train (Epoch 77): Loss/seq after 01800 batchs: 780.586669921875
INFO:root:Train (Epoch 77): Loss/seq after 01850 batchs: 774.11083984375
INFO:root:Train (Epoch 77): Loss/seq after 01900 batchs: 773.301025390625
INFO:root:Train (Epoch 77): Loss/seq after 01950 batchs: 768.8739013671875
INFO:root:Train (Epoch 77): Loss/seq after 02000 batchs: 764.6181030273438
INFO:root:Train (Epoch 77): Loss/seq after 02050 batchs: 761.1163330078125
INFO:root:Train (Epoch 77): Loss/seq after 02100 batchs: 755.7750244140625
INFO:root:Train (Epoch 77): Loss/seq after 02150 batchs: 751.6135864257812
INFO:root:Train (Epoch 77): Loss/seq after 02200 batchs: 746.2183227539062
INFO:root:Train (Epoch 77): Loss/seq after 02250 batchs: 745.12451171875
INFO:root:Train (Epoch 77): Loss/seq after 02300 batchs: 748.471923828125
INFO:root:Train (Epoch 77): Loss/seq after 02350 batchs: 742.2214965820312
INFO:root:Train (Epoch 77): Loss/seq after 02400 batchs: 741.0656127929688
INFO:root:Train (Epoch 77): Loss/seq after 02450 batchs: 733.6546020507812
INFO:root:Train (Epoch 77): Loss/seq after 02500 batchs: 722.3721313476562
INFO:root:Train (Epoch 77): Loss/seq after 02550 batchs: 713.9821166992188
INFO:root:Train (Epoch 77): Loss/seq after 02600 batchs: 712.2601318359375
INFO:root:Train (Epoch 77): Loss/seq after 02650 batchs: 709.117431640625
INFO:root:Train (Epoch 77): Loss/seq after 02700 batchs: 706.1937866210938
INFO:root:Train (Epoch 77): Loss/seq after 02750 batchs: 728.194091796875
INFO:root:Train (Epoch 77): Loss/seq after 02800 batchs: 731.6417236328125
INFO:root:Train (Epoch 77): Loss/seq after 02850 batchs: 730.6627807617188
INFO:root:Train (Epoch 77): Loss/seq after 02900 batchs: 730.9580078125
INFO:root:Train (Epoch 77): Loss/seq after 02950 batchs: 727.9998168945312
INFO:root:Train (Epoch 77): Loss/seq after 03000 batchs: 730.9579467773438
INFO:root:Train (Epoch 77): Loss/seq after 03050 batchs: 735.8464965820312
INFO:root:Train (Epoch 77): Loss/seq after 03100 batchs: 741.287841796875
INFO:root:Train (Epoch 77): Loss/seq after 03150 batchs: 748.1388549804688
INFO:root:Train (Epoch 77): Loss/seq after 03200 batchs: 754.4307861328125
INFO:root:Train (Epoch 77): Loss/seq after 03250 batchs: 759.86572265625
INFO:root:Train (Epoch 77): Loss/seq after 03300 batchs: 758.6068725585938
INFO:root:Train (Epoch 77): Loss/seq after 03350 batchs: 757.721923828125
INFO:root:Train (Epoch 77): Loss/seq after 03400 batchs: 751.1878051757812
INFO:root:Train (Epoch 77): Loss/seq after 03450 batchs: 747.8304443359375
INFO:root:Train (Epoch 77): Loss/seq after 03500 batchs: 747.2230834960938
INFO:root:Train (Epoch 77): Loss/seq after 03550 batchs: 742.7911376953125
INFO:root:Train (Epoch 77): Loss/seq after 03600 batchs: 750.1998291015625
INFO:root:Train (Epoch 77): Loss/seq after 03650 batchs: 746.2586669921875
INFO:root:Train (Epoch 77): Loss/seq after 03700 batchs: 747.5205688476562
INFO:root:Train (Epoch 77): Loss/seq after 03750 batchs: 751.1865234375
INFO:root:Train (Epoch 77): Loss/seq after 03800 batchs: 746.96826171875
INFO:root:Train (Epoch 77): Loss/seq after 03850 batchs: 745.23388671875
INFO:root:Train (Epoch 77): Loss/seq after 03900 batchs: 749.54443359375
INFO:root:Train (Epoch 77): Loss/seq after 03950 batchs: 753.1842041015625
INFO:root:Train (Epoch 77): Loss/seq after 04000 batchs: 748.2208862304688
INFO:root:Train (Epoch 77): Loss/seq after 04050 batchs: 742.991455078125
INFO:root:Train (Epoch 77): Loss/seq after 04100 batchs: 739.8932495117188
INFO:root:Train (Epoch 77): Loss/seq after 04150 batchs: 738.1575927734375
INFO:root:Train (Epoch 77): Loss/seq after 04200 batchs: 735.7177124023438
INFO:root:Train (Epoch 77): Loss/seq after 04250 batchs: 733.2745971679688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 77): Loss/seq after 00000 batches: 551.8743896484375
INFO:root:# Valid (Epoch 77): Loss/seq after 00050 batches: 682.9947509765625
INFO:root:# Valid (Epoch 77): Loss/seq after 00100 batches: 930.4853515625
INFO:root:# Valid (Epoch 77): Loss/seq after 00150 batches: 703.6978759765625
INFO:root:# Valid (Epoch 77): Loss/seq after 00200 batches: 650.0155639648438
INFO:root:Artifacts: Make stick videos for epoch 77
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_77_on_20220413_012603.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_77_index_829_on_20220413_012603.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 78): Loss/seq after 00000 batchs: 1471.251708984375
INFO:root:Train (Epoch 78): Loss/seq after 00050 batchs: 966.3125610351562
INFO:root:Train (Epoch 78): Loss/seq after 00100 batchs: 996.99951171875
INFO:root:Train (Epoch 78): Loss/seq after 00150 batchs: 900.5916748046875
INFO:root:Train (Epoch 78): Loss/seq after 00200 batchs: 998.224609375
INFO:root:Train (Epoch 78): Loss/seq after 00250 batchs: 1116.0400390625
INFO:root:Train (Epoch 78): Loss/seq after 00300 batchs: 1086.4061279296875
INFO:root:Train (Epoch 78): Loss/seq after 00350 batchs: 1007.4666748046875
INFO:root:Train (Epoch 78): Loss/seq after 00400 batchs: 1019.7996826171875
INFO:root:Train (Epoch 78): Loss/seq after 00450 batchs: 985.9505004882812
INFO:root:Train (Epoch 78): Loss/seq after 00500 batchs: 961.1884765625
INFO:root:Train (Epoch 78): Loss/seq after 00550 batchs: 926.9591064453125
INFO:root:Train (Epoch 78): Loss/seq after 00600 batchs: 891.6077270507812
INFO:root:Train (Epoch 78): Loss/seq after 00650 batchs: 891.3595581054688
INFO:root:Train (Epoch 78): Loss/seq after 00700 batchs: 873.0159912109375
INFO:root:Train (Epoch 78): Loss/seq after 00750 batchs: 897.287353515625
INFO:root:Train (Epoch 78): Loss/seq after 00800 batchs: 893.4798583984375
INFO:root:Train (Epoch 78): Loss/seq after 00850 batchs: 864.966552734375
INFO:root:Train (Epoch 78): Loss/seq after 00900 batchs: 846.3265991210938
INFO:root:Train (Epoch 78): Loss/seq after 00950 batchs: 854.1904296875
INFO:root:Train (Epoch 78): Loss/seq after 01000 batchs: 847.99853515625
INFO:root:Train (Epoch 78): Loss/seq after 01050 batchs: 832.45703125
INFO:root:Train (Epoch 78): Loss/seq after 01100 batchs: 818.495361328125
INFO:root:Train (Epoch 78): Loss/seq after 01150 batchs: 798.1519165039062
INFO:root:Train (Epoch 78): Loss/seq after 01200 batchs: 798.4212646484375
INFO:root:Train (Epoch 78): Loss/seq after 01250 batchs: 792.6012573242188
INFO:root:Train (Epoch 78): Loss/seq after 01300 batchs: 783.6851196289062
INFO:root:Train (Epoch 78): Loss/seq after 01350 batchs: 776.63623046875
INFO:root:Train (Epoch 78): Loss/seq after 01400 batchs: 793.0282592773438
INFO:root:Train (Epoch 78): Loss/seq after 01450 batchs: 791.532470703125
INFO:root:Train (Epoch 78): Loss/seq after 01500 batchs: 793.7488403320312
INFO:root:Train (Epoch 78): Loss/seq after 01550 batchs: 795.0216674804688
INFO:root:Train (Epoch 78): Loss/seq after 01600 batchs: 786.220458984375
INFO:root:Train (Epoch 78): Loss/seq after 01650 batchs: 781.8244018554688
INFO:root:Train (Epoch 78): Loss/seq after 01700 batchs: 780.6185913085938
INFO:root:Train (Epoch 78): Loss/seq after 01750 batchs: 775.445068359375
INFO:root:Train (Epoch 78): Loss/seq after 01800 batchs: 769.8690185546875
INFO:root:Train (Epoch 78): Loss/seq after 01850 batchs: 763.451171875
INFO:root:Train (Epoch 78): Loss/seq after 01900 batchs: 762.6154174804688
INFO:root:Train (Epoch 78): Loss/seq after 01950 batchs: 758.677978515625
INFO:root:Train (Epoch 78): Loss/seq after 02000 batchs: 754.8982543945312
INFO:root:Train (Epoch 78): Loss/seq after 02050 batchs: 751.5042114257812
INFO:root:Train (Epoch 78): Loss/seq after 02100 batchs: 746.2380981445312
INFO:root:Train (Epoch 78): Loss/seq after 02150 batchs: 742.3342895507812
INFO:root:Train (Epoch 78): Loss/seq after 02200 batchs: 737.1002807617188
INFO:root:Train (Epoch 78): Loss/seq after 02250 batchs: 736.4848022460938
INFO:root:Train (Epoch 78): Loss/seq after 02300 batchs: 739.5045166015625
INFO:root:Train (Epoch 78): Loss/seq after 02350 batchs: 733.3546142578125
INFO:root:Train (Epoch 78): Loss/seq after 02400 batchs: 732.5093994140625
INFO:root:Train (Epoch 78): Loss/seq after 02450 batchs: 725.3873901367188
INFO:root:Train (Epoch 78): Loss/seq after 02500 batchs: 714.2777099609375
INFO:root:Train (Epoch 78): Loss/seq after 02550 batchs: 706.1087646484375
INFO:root:Train (Epoch 78): Loss/seq after 02600 batchs: 704.4970092773438
INFO:root:Train (Epoch 78): Loss/seq after 02650 batchs: 701.4837036132812
INFO:root:Train (Epoch 78): Loss/seq after 02700 batchs: 698.6399536132812
INFO:root:Train (Epoch 78): Loss/seq after 02750 batchs: 719.6958618164062
INFO:root:Train (Epoch 78): Loss/seq after 02800 batchs: 723.6766967773438
INFO:root:Train (Epoch 78): Loss/seq after 02850 batchs: 723.1353759765625
INFO:root:Train (Epoch 78): Loss/seq after 02900 batchs: 723.3594970703125
INFO:root:Train (Epoch 78): Loss/seq after 02950 batchs: 720.8536987304688
INFO:root:Train (Epoch 78): Loss/seq after 03000 batchs: 723.900390625
INFO:root:Train (Epoch 78): Loss/seq after 03050 batchs: 728.5017700195312
INFO:root:Train (Epoch 78): Loss/seq after 03100 batchs: 733.48193359375
INFO:root:Train (Epoch 78): Loss/seq after 03150 batchs: 739.9552612304688
INFO:root:Train (Epoch 78): Loss/seq after 03200 batchs: 746.913330078125
INFO:root:Train (Epoch 78): Loss/seq after 03250 batchs: 752.0997924804688
INFO:root:Train (Epoch 78): Loss/seq after 03300 batchs: 751.0113525390625
INFO:root:Train (Epoch 78): Loss/seq after 03350 batchs: 750.3858642578125
INFO:root:Train (Epoch 78): Loss/seq after 03400 batchs: 743.9456176757812
INFO:root:Train (Epoch 78): Loss/seq after 03450 batchs: 740.8150024414062
INFO:root:Train (Epoch 78): Loss/seq after 03500 batchs: 740.6176147460938
INFO:root:Train (Epoch 78): Loss/seq after 03550 batchs: 736.2210083007812
INFO:root:Train (Epoch 78): Loss/seq after 03600 batchs: 743.5994873046875
INFO:root:Train (Epoch 78): Loss/seq after 03650 batchs: 739.5189819335938
INFO:root:Train (Epoch 78): Loss/seq after 03700 batchs: 740.5786743164062
INFO:root:Train (Epoch 78): Loss/seq after 03750 batchs: 744.3101196289062
INFO:root:Train (Epoch 78): Loss/seq after 03800 batchs: 740.1301879882812
INFO:root:Train (Epoch 78): Loss/seq after 03850 batchs: 738.4453125
INFO:root:Train (Epoch 78): Loss/seq after 03900 batchs: 743.114990234375
INFO:root:Train (Epoch 78): Loss/seq after 03950 batchs: 746.717529296875
INFO:root:Train (Epoch 78): Loss/seq after 04000 batchs: 741.7957153320312
INFO:root:Train (Epoch 78): Loss/seq after 04050 batchs: 736.5808715820312
INFO:root:Train (Epoch 78): Loss/seq after 04100 batchs: 733.4345703125
INFO:root:Train (Epoch 78): Loss/seq after 04150 batchs: 731.7964477539062
INFO:root:Train (Epoch 78): Loss/seq after 04200 batchs: 729.5064086914062
INFO:root:Train (Epoch 78): Loss/seq after 04250 batchs: 727.0943603515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 78): Loss/seq after 00000 batches: 544.553466796875
INFO:root:# Valid (Epoch 78): Loss/seq after 00050 batches: 687.8892211914062
INFO:root:# Valid (Epoch 78): Loss/seq after 00100 batches: 936.6535034179688
INFO:root:# Valid (Epoch 78): Loss/seq after 00150 batches: 707.4248046875
INFO:root:# Valid (Epoch 78): Loss/seq after 00200 batches: 653.0955200195312
INFO:root:Artifacts: Make stick videos for epoch 78
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_78_on_20220413_013125.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_78_index_231_on_20220413_013125.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 79): Loss/seq after 00000 batchs: 1522.747314453125
INFO:root:Train (Epoch 79): Loss/seq after 00050 batchs: 976.9664306640625
INFO:root:Train (Epoch 79): Loss/seq after 00100 batchs: 1023.171875
INFO:root:Train (Epoch 79): Loss/seq after 00150 batchs: 917.38330078125
INFO:root:Train (Epoch 79): Loss/seq after 00200 batchs: 1010.3645629882812
INFO:root:Train (Epoch 79): Loss/seq after 00250 batchs: 1123.44189453125
INFO:root:Train (Epoch 79): Loss/seq after 00300 batchs: 1093.205078125
INFO:root:Train (Epoch 79): Loss/seq after 00350 batchs: 1013.0005493164062
INFO:root:Train (Epoch 79): Loss/seq after 00400 batchs: 1025.7294921875
INFO:root:Train (Epoch 79): Loss/seq after 00450 batchs: 990.7705688476562
INFO:root:Train (Epoch 79): Loss/seq after 00500 batchs: 970.0233154296875
INFO:root:Train (Epoch 79): Loss/seq after 00550 batchs: 934.8299560546875
INFO:root:Train (Epoch 79): Loss/seq after 00600 batchs: 898.9097290039062
INFO:root:Train (Epoch 79): Loss/seq after 00650 batchs: 897.7759399414062
INFO:root:Train (Epoch 79): Loss/seq after 00700 batchs: 880.3984985351562
INFO:root:Train (Epoch 79): Loss/seq after 00750 batchs: 905.4998779296875
INFO:root:Train (Epoch 79): Loss/seq after 00800 batchs: 901.4771118164062
INFO:root:Train (Epoch 79): Loss/seq after 00850 batchs: 872.713134765625
INFO:root:Train (Epoch 79): Loss/seq after 00900 batchs: 854.2070922851562
INFO:root:Train (Epoch 79): Loss/seq after 00950 batchs: 863.6857299804688
INFO:root:Train (Epoch 79): Loss/seq after 01000 batchs: 855.6893310546875
INFO:root:Train (Epoch 79): Loss/seq after 01050 batchs: 839.0498657226562
INFO:root:Train (Epoch 79): Loss/seq after 01100 batchs: 825.4293212890625
INFO:root:Train (Epoch 79): Loss/seq after 01150 batchs: 805.6766357421875
INFO:root:Train (Epoch 79): Loss/seq after 01200 batchs: 805.1171875
INFO:root:Train (Epoch 79): Loss/seq after 01250 batchs: 798.8236694335938
INFO:root:Train (Epoch 79): Loss/seq after 01300 batchs: 789.6441650390625
INFO:root:Train (Epoch 79): Loss/seq after 01350 batchs: 781.812255859375
INFO:root:Train (Epoch 79): Loss/seq after 01400 batchs: 796.0243530273438
INFO:root:Train (Epoch 79): Loss/seq after 01450 batchs: 793.8751831054688
INFO:root:Train (Epoch 79): Loss/seq after 01500 batchs: 796.1183471679688
INFO:root:Train (Epoch 79): Loss/seq after 01550 batchs: 796.5327758789062
INFO:root:Train (Epoch 79): Loss/seq after 01600 batchs: 787.5113525390625
INFO:root:Train (Epoch 79): Loss/seq after 01650 batchs: 782.2935180664062
INFO:root:Train (Epoch 79): Loss/seq after 01700 batchs: 780.4542236328125
INFO:root:Train (Epoch 79): Loss/seq after 01750 batchs: 774.9721069335938
INFO:root:Train (Epoch 79): Loss/seq after 01800 batchs: 769.1257934570312
INFO:root:Train (Epoch 79): Loss/seq after 01850 batchs: 762.6756591796875
INFO:root:Train (Epoch 79): Loss/seq after 01900 batchs: 762.232177734375
INFO:root:Train (Epoch 79): Loss/seq after 01950 batchs: 758.0059204101562
INFO:root:Train (Epoch 79): Loss/seq after 02000 batchs: 754.1449584960938
INFO:root:Train (Epoch 79): Loss/seq after 02050 batchs: 750.9324340820312
INFO:root:Train (Epoch 79): Loss/seq after 02100 batchs: 745.7166137695312
INFO:root:Train (Epoch 79): Loss/seq after 02150 batchs: 741.5001220703125
INFO:root:Train (Epoch 79): Loss/seq after 02200 batchs: 736.267578125
INFO:root:Train (Epoch 79): Loss/seq after 02250 batchs: 735.0322875976562
INFO:root:Train (Epoch 79): Loss/seq after 02300 batchs: 737.9058227539062
INFO:root:Train (Epoch 79): Loss/seq after 02350 batchs: 731.6676025390625
INFO:root:Train (Epoch 79): Loss/seq after 02400 batchs: 730.7361450195312
INFO:root:Train (Epoch 79): Loss/seq after 02450 batchs: 723.6260375976562
INFO:root:Train (Epoch 79): Loss/seq after 02500 batchs: 712.5418090820312
INFO:root:Train (Epoch 79): Loss/seq after 02550 batchs: 704.3905029296875
INFO:root:Train (Epoch 79): Loss/seq after 02600 batchs: 702.79296875
INFO:root:Train (Epoch 79): Loss/seq after 02650 batchs: 699.683349609375
INFO:root:Train (Epoch 79): Loss/seq after 02700 batchs: 696.6106567382812
INFO:root:Train (Epoch 79): Loss/seq after 02750 batchs: 716.7968139648438
INFO:root:Train (Epoch 79): Loss/seq after 02800 batchs: 720.3785400390625
INFO:root:Train (Epoch 79): Loss/seq after 02850 batchs: 719.8280029296875
INFO:root:Train (Epoch 79): Loss/seq after 02900 batchs: 720.2098999023438
INFO:root:Train (Epoch 79): Loss/seq after 02950 batchs: 717.7589111328125
INFO:root:Train (Epoch 79): Loss/seq after 03000 batchs: 720.8037719726562
INFO:root:Train (Epoch 79): Loss/seq after 03050 batchs: 725.4557495117188
INFO:root:Train (Epoch 79): Loss/seq after 03100 batchs: 730.1882934570312
INFO:root:Train (Epoch 79): Loss/seq after 03150 batchs: 736.9844970703125
INFO:root:Train (Epoch 79): Loss/seq after 03200 batchs: 743.885986328125
INFO:root:Train (Epoch 79): Loss/seq after 03250 batchs: 749.0426025390625
INFO:root:Train (Epoch 79): Loss/seq after 03300 batchs: 748.3489379882812
INFO:root:Train (Epoch 79): Loss/seq after 03350 batchs: 748.5753173828125
INFO:root:Train (Epoch 79): Loss/seq after 03400 batchs: 742.28857421875
INFO:root:Train (Epoch 79): Loss/seq after 03450 batchs: 738.86181640625
INFO:root:Train (Epoch 79): Loss/seq after 03500 batchs: 738.3836059570312
INFO:root:Train (Epoch 79): Loss/seq after 03550 batchs: 734.14599609375
INFO:root:Train (Epoch 79): Loss/seq after 03600 batchs: 741.6492919921875
INFO:root:Train (Epoch 79): Loss/seq after 03650 batchs: 737.6043701171875
INFO:root:Train (Epoch 79): Loss/seq after 03700 batchs: 738.654541015625
INFO:root:Train (Epoch 79): Loss/seq after 03750 batchs: 742.2590942382812
INFO:root:Train (Epoch 79): Loss/seq after 03800 batchs: 738.0490112304688
INFO:root:Train (Epoch 79): Loss/seq after 03850 batchs: 736.3163452148438
INFO:root:Train (Epoch 79): Loss/seq after 03900 batchs: 740.5975341796875
INFO:root:Train (Epoch 79): Loss/seq after 03950 batchs: 744.39013671875
INFO:root:Train (Epoch 79): Loss/seq after 04000 batchs: 739.3446655273438
INFO:root:Train (Epoch 79): Loss/seq after 04050 batchs: 734.1233520507812
INFO:root:Train (Epoch 79): Loss/seq after 04100 batchs: 731.0225219726562
INFO:root:Train (Epoch 79): Loss/seq after 04150 batchs: 729.4170532226562
INFO:root:Train (Epoch 79): Loss/seq after 04200 batchs: 726.9382934570312
INFO:root:Train (Epoch 79): Loss/seq after 04250 batchs: 724.348388671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 79): Loss/seq after 00000 batches: 528.3292236328125
INFO:root:# Valid (Epoch 79): Loss/seq after 00050 batches: 682.7073364257812
INFO:root:# Valid (Epoch 79): Loss/seq after 00100 batches: 903.0188598632812
INFO:root:# Valid (Epoch 79): Loss/seq after 00150 batches: 683.2858276367188
INFO:root:# Valid (Epoch 79): Loss/seq after 00200 batches: 630.5352172851562
INFO:root:Artifacts: Make stick videos for epoch 79
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_79_on_20220413_013646.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_79_index_1418_on_20220413_013646.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 80): Loss/seq after 00000 batchs: 1343.1129150390625
INFO:root:Train (Epoch 80): Loss/seq after 00050 batchs: 941.1780395507812
INFO:root:Train (Epoch 80): Loss/seq after 00100 batchs: 977.0992431640625
INFO:root:Train (Epoch 80): Loss/seq after 00150 batchs: 882.4395751953125
INFO:root:Train (Epoch 80): Loss/seq after 00200 batchs: 983.5403442382812
INFO:root:Train (Epoch 80): Loss/seq after 00250 batchs: 1102.989501953125
INFO:root:Train (Epoch 80): Loss/seq after 00300 batchs: 1074.44189453125
INFO:root:Train (Epoch 80): Loss/seq after 00350 batchs: 996.1624145507812
INFO:root:Train (Epoch 80): Loss/seq after 00400 batchs: 1014.3272705078125
INFO:root:Train (Epoch 80): Loss/seq after 00450 batchs: 981.0314331054688
INFO:root:Train (Epoch 80): Loss/seq after 00500 batchs: 961.8326416015625
INFO:root:Train (Epoch 80): Loss/seq after 00550 batchs: 926.17724609375
INFO:root:Train (Epoch 80): Loss/seq after 00600 batchs: 890.7909545898438
INFO:root:Train (Epoch 80): Loss/seq after 00650 batchs: 890.63134765625
INFO:root:Train (Epoch 80): Loss/seq after 00700 batchs: 872.1417236328125
INFO:root:Train (Epoch 80): Loss/seq after 00750 batchs: 891.5868530273438
INFO:root:Train (Epoch 80): Loss/seq after 00800 batchs: 888.0098266601562
INFO:root:Train (Epoch 80): Loss/seq after 00850 batchs: 859.4328002929688
INFO:root:Train (Epoch 80): Loss/seq after 00900 batchs: 841.7421875
INFO:root:Train (Epoch 80): Loss/seq after 00950 batchs: 849.634521484375
INFO:root:Train (Epoch 80): Loss/seq after 01000 batchs: 841.2351684570312
INFO:root:Train (Epoch 80): Loss/seq after 01050 batchs: 826.6018676757812
INFO:root:Train (Epoch 80): Loss/seq after 01100 batchs: 812.3920288085938
INFO:root:Train (Epoch 80): Loss/seq after 01150 batchs: 791.8275756835938
INFO:root:Train (Epoch 80): Loss/seq after 01200 batchs: 791.5667724609375
INFO:root:Train (Epoch 80): Loss/seq after 01250 batchs: 786.2503662109375
INFO:root:Train (Epoch 80): Loss/seq after 01300 batchs: 776.6318359375
INFO:root:Train (Epoch 80): Loss/seq after 01350 batchs: 768.1448364257812
INFO:root:Train (Epoch 80): Loss/seq after 01400 batchs: 783.2461547851562
INFO:root:Train (Epoch 80): Loss/seq after 01450 batchs: 781.7100219726562
INFO:root:Train (Epoch 80): Loss/seq after 01500 batchs: 784.2864990234375
INFO:root:Train (Epoch 80): Loss/seq after 01550 batchs: 785.599365234375
INFO:root:Train (Epoch 80): Loss/seq after 01600 batchs: 777.05810546875
INFO:root:Train (Epoch 80): Loss/seq after 01650 batchs: 772.9647827148438
INFO:root:Train (Epoch 80): Loss/seq after 01700 batchs: 771.6682739257812
INFO:root:Train (Epoch 80): Loss/seq after 01750 batchs: 766.323486328125
INFO:root:Train (Epoch 80): Loss/seq after 01800 batchs: 760.5982666015625
INFO:root:Train (Epoch 80): Loss/seq after 01850 batchs: 754.2352905273438
INFO:root:Train (Epoch 80): Loss/seq after 01900 batchs: 753.4806518554688
INFO:root:Train (Epoch 80): Loss/seq after 01950 batchs: 749.6031494140625
INFO:root:Train (Epoch 80): Loss/seq after 02000 batchs: 745.4443969726562
INFO:root:Train (Epoch 80): Loss/seq after 02050 batchs: 742.3466186523438
INFO:root:Train (Epoch 80): Loss/seq after 02100 batchs: 737.1654052734375
INFO:root:Train (Epoch 80): Loss/seq after 02150 batchs: 733.097900390625
INFO:root:Train (Epoch 80): Loss/seq after 02200 batchs: 727.9472045898438
INFO:root:Train (Epoch 80): Loss/seq after 02250 batchs: 726.8359985351562
INFO:root:Train (Epoch 80): Loss/seq after 02300 batchs: 729.9078979492188
INFO:root:Train (Epoch 80): Loss/seq after 02350 batchs: 723.8925170898438
INFO:root:Train (Epoch 80): Loss/seq after 02400 batchs: 723.024658203125
INFO:root:Train (Epoch 80): Loss/seq after 02450 batchs: 715.8851318359375
INFO:root:Train (Epoch 80): Loss/seq after 02500 batchs: 704.9375
INFO:root:Train (Epoch 80): Loss/seq after 02550 batchs: 696.830322265625
INFO:root:Train (Epoch 80): Loss/seq after 02600 batchs: 695.159912109375
INFO:root:Train (Epoch 80): Loss/seq after 02650 batchs: 692.2569580078125
INFO:root:Train (Epoch 80): Loss/seq after 02700 batchs: 689.3344116210938
INFO:root:Train (Epoch 80): Loss/seq after 02750 batchs: 708.5992431640625
INFO:root:Train (Epoch 80): Loss/seq after 02800 batchs: 711.7978515625
INFO:root:Train (Epoch 80): Loss/seq after 02850 batchs: 711.5023193359375
INFO:root:Train (Epoch 80): Loss/seq after 02900 batchs: 712.0720825195312
INFO:root:Train (Epoch 80): Loss/seq after 02950 batchs: 709.2037963867188
INFO:root:Train (Epoch 80): Loss/seq after 03000 batchs: 712.3802490234375
INFO:root:Train (Epoch 80): Loss/seq after 03050 batchs: 717.2180786132812
INFO:root:Train (Epoch 80): Loss/seq after 03100 batchs: 721.9109497070312
INFO:root:Train (Epoch 80): Loss/seq after 03150 batchs: 729.1940307617188
INFO:root:Train (Epoch 80): Loss/seq after 03200 batchs: 735.2332153320312
INFO:root:Train (Epoch 80): Loss/seq after 03250 batchs: 739.9204711914062
INFO:root:Train (Epoch 80): Loss/seq after 03300 batchs: 738.8512573242188
INFO:root:Train (Epoch 80): Loss/seq after 03350 batchs: 738.365234375
INFO:root:Train (Epoch 80): Loss/seq after 03400 batchs: 732.0535888671875
INFO:root:Train (Epoch 80): Loss/seq after 03450 batchs: 728.8233642578125
INFO:root:Train (Epoch 80): Loss/seq after 03500 batchs: 728.4895629882812
INFO:root:Train (Epoch 80): Loss/seq after 03550 batchs: 724.19091796875
INFO:root:Train (Epoch 80): Loss/seq after 03600 batchs: 731.7979736328125
INFO:root:Train (Epoch 80): Loss/seq after 03650 batchs: 727.7793579101562
INFO:root:Train (Epoch 80): Loss/seq after 03700 batchs: 728.8067626953125
INFO:root:Train (Epoch 80): Loss/seq after 03750 batchs: 732.4830322265625
INFO:root:Train (Epoch 80): Loss/seq after 03800 batchs: 728.4415283203125
INFO:root:Train (Epoch 80): Loss/seq after 03850 batchs: 726.83935546875
INFO:root:Train (Epoch 80): Loss/seq after 03900 batchs: 730.9571533203125
INFO:root:Train (Epoch 80): Loss/seq after 03950 batchs: 734.4967651367188
INFO:root:Train (Epoch 80): Loss/seq after 04000 batchs: 729.4382934570312
INFO:root:Train (Epoch 80): Loss/seq after 04050 batchs: 724.3181762695312
INFO:root:Train (Epoch 80): Loss/seq after 04100 batchs: 721.3079223632812
INFO:root:Train (Epoch 80): Loss/seq after 04150 batchs: 719.7437133789062
INFO:root:Train (Epoch 80): Loss/seq after 04200 batchs: 717.3861694335938
INFO:root:Train (Epoch 80): Loss/seq after 04250 batchs: 715.0541381835938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 80): Loss/seq after 00000 batches: 559.8964233398438
INFO:root:# Valid (Epoch 80): Loss/seq after 00050 batches: 698.0911865234375
INFO:root:# Valid (Epoch 80): Loss/seq after 00100 batches: 911.4584350585938
INFO:root:# Valid (Epoch 80): Loss/seq after 00150 batches: 691.4473266601562
INFO:root:# Valid (Epoch 80): Loss/seq after 00200 batches: 635.7667236328125
INFO:root:Artifacts: Make stick videos for epoch 80
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_80_on_20220413_014208.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_80_index_1212_on_20220413_014208.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 81): Loss/seq after 00000 batchs: 1318.236083984375
INFO:root:Train (Epoch 81): Loss/seq after 00050 batchs: 954.08740234375
INFO:root:Train (Epoch 81): Loss/seq after 00100 batchs: 994.337158203125
INFO:root:Train (Epoch 81): Loss/seq after 00150 batchs: 904.19140625
INFO:root:Train (Epoch 81): Loss/seq after 00200 batchs: 1008.9310302734375
INFO:root:Train (Epoch 81): Loss/seq after 00250 batchs: 1132.83154296875
INFO:root:Train (Epoch 81): Loss/seq after 00300 batchs: 1100.2962646484375
INFO:root:Train (Epoch 81): Loss/seq after 00350 batchs: 1019.6925659179688
INFO:root:Train (Epoch 81): Loss/seq after 00400 batchs: 1030.0987548828125
INFO:root:Train (Epoch 81): Loss/seq after 00450 batchs: 994.36083984375
INFO:root:Train (Epoch 81): Loss/seq after 00500 batchs: 970.9299926757812
INFO:root:Train (Epoch 81): Loss/seq after 00550 batchs: 936.1077270507812
INFO:root:Train (Epoch 81): Loss/seq after 00600 batchs: 900.3743286132812
INFO:root:Train (Epoch 81): Loss/seq after 00650 batchs: 900.928955078125
INFO:root:Train (Epoch 81): Loss/seq after 00700 batchs: 882.4999389648438
INFO:root:Train (Epoch 81): Loss/seq after 00750 batchs: 902.2753295898438
INFO:root:Train (Epoch 81): Loss/seq after 00800 batchs: 898.7863159179688
INFO:root:Train (Epoch 81): Loss/seq after 00850 batchs: 870.0713500976562
INFO:root:Train (Epoch 81): Loss/seq after 00900 batchs: 851.35009765625
INFO:root:Train (Epoch 81): Loss/seq after 00950 batchs: 858.1395874023438
INFO:root:Train (Epoch 81): Loss/seq after 01000 batchs: 848.9907836914062
INFO:root:Train (Epoch 81): Loss/seq after 01050 batchs: 832.6195068359375
INFO:root:Train (Epoch 81): Loss/seq after 01100 batchs: 819.2562255859375
INFO:root:Train (Epoch 81): Loss/seq after 01150 batchs: 798.854736328125
INFO:root:Train (Epoch 81): Loss/seq after 01200 batchs: 798.32568359375
INFO:root:Train (Epoch 81): Loss/seq after 01250 batchs: 792.5692138671875
INFO:root:Train (Epoch 81): Loss/seq after 01300 batchs: 782.4404296875
INFO:root:Train (Epoch 81): Loss/seq after 01350 batchs: 772.8507690429688
INFO:root:Train (Epoch 81): Loss/seq after 01400 batchs: 787.2071533203125
INFO:root:Train (Epoch 81): Loss/seq after 01450 batchs: 785.2803955078125
INFO:root:Train (Epoch 81): Loss/seq after 01500 batchs: 787.1903076171875
INFO:root:Train (Epoch 81): Loss/seq after 01550 batchs: 788.1925048828125
INFO:root:Train (Epoch 81): Loss/seq after 01600 batchs: 779.3809814453125
INFO:root:Train (Epoch 81): Loss/seq after 01650 batchs: 774.5895385742188
INFO:root:Train (Epoch 81): Loss/seq after 01700 batchs: 773.065673828125
INFO:root:Train (Epoch 81): Loss/seq after 01750 batchs: 767.37060546875
INFO:root:Train (Epoch 81): Loss/seq after 01800 batchs: 761.6483154296875
INFO:root:Train (Epoch 81): Loss/seq after 01850 batchs: 755.0477905273438
INFO:root:Train (Epoch 81): Loss/seq after 01900 batchs: 753.9885864257812
INFO:root:Train (Epoch 81): Loss/seq after 01950 batchs: 749.8619384765625
INFO:root:Train (Epoch 81): Loss/seq after 02000 batchs: 745.6121215820312
INFO:root:Train (Epoch 81): Loss/seq after 02050 batchs: 741.753173828125
INFO:root:Train (Epoch 81): Loss/seq after 02100 batchs: 736.4359130859375
INFO:root:Train (Epoch 81): Loss/seq after 02150 batchs: 732.2142944335938
INFO:root:Train (Epoch 81): Loss/seq after 02200 batchs: 726.9660034179688
INFO:root:Train (Epoch 81): Loss/seq after 02250 batchs: 725.7420043945312
INFO:root:Train (Epoch 81): Loss/seq after 02300 batchs: 727.1241455078125
INFO:root:Train (Epoch 81): Loss/seq after 02350 batchs: 721.3605346679688
INFO:root:Train (Epoch 81): Loss/seq after 02400 batchs: 720.4782104492188
INFO:root:Train (Epoch 81): Loss/seq after 02450 batchs: 713.2437133789062
INFO:root:Train (Epoch 81): Loss/seq after 02500 batchs: 702.3582763671875
INFO:root:Train (Epoch 81): Loss/seq after 02550 batchs: 694.290283203125
INFO:root:Train (Epoch 81): Loss/seq after 02600 batchs: 692.6143188476562
INFO:root:Train (Epoch 81): Loss/seq after 02650 batchs: 689.6876831054688
INFO:root:Train (Epoch 81): Loss/seq after 02700 batchs: 686.5643310546875
INFO:root:Train (Epoch 81): Loss/seq after 02750 batchs: 703.3292236328125
INFO:root:Train (Epoch 81): Loss/seq after 02800 batchs: 706.6336669921875
INFO:root:Train (Epoch 81): Loss/seq after 02850 batchs: 706.3200073242188
INFO:root:Train (Epoch 81): Loss/seq after 02900 batchs: 707.0848999023438
INFO:root:Train (Epoch 81): Loss/seq after 02950 batchs: 704.5419921875
INFO:root:Train (Epoch 81): Loss/seq after 03000 batchs: 707.73779296875
INFO:root:Train (Epoch 81): Loss/seq after 03050 batchs: 711.9027099609375
INFO:root:Train (Epoch 81): Loss/seq after 03100 batchs: 716.6799926757812
INFO:root:Train (Epoch 81): Loss/seq after 03150 batchs: 723.2623291015625
INFO:root:Train (Epoch 81): Loss/seq after 03200 batchs: 729.19189453125
INFO:root:Train (Epoch 81): Loss/seq after 03250 batchs: 734.096435546875
INFO:root:Train (Epoch 81): Loss/seq after 03300 batchs: 733.3032836914062
INFO:root:Train (Epoch 81): Loss/seq after 03350 batchs: 732.8761596679688
INFO:root:Train (Epoch 81): Loss/seq after 03400 batchs: 726.7794189453125
INFO:root:Train (Epoch 81): Loss/seq after 03450 batchs: 723.9069213867188
INFO:root:Train (Epoch 81): Loss/seq after 03500 batchs: 724.1298217773438
INFO:root:Train (Epoch 81): Loss/seq after 03550 batchs: 719.902587890625
INFO:root:Train (Epoch 81): Loss/seq after 03600 batchs: 727.5835571289062
INFO:root:Train (Epoch 81): Loss/seq after 03650 batchs: 723.4853515625
INFO:root:Train (Epoch 81): Loss/seq after 03700 batchs: 724.5533447265625
INFO:root:Train (Epoch 81): Loss/seq after 03750 batchs: 728.3489379882812
INFO:root:Train (Epoch 81): Loss/seq after 03800 batchs: 724.2540283203125
INFO:root:Train (Epoch 81): Loss/seq after 03850 batchs: 722.5518798828125
INFO:root:Train (Epoch 81): Loss/seq after 03900 batchs: 726.7271728515625
INFO:root:Train (Epoch 81): Loss/seq after 03950 batchs: 730.4013061523438
INFO:root:Train (Epoch 81): Loss/seq after 04000 batchs: 725.3416137695312
INFO:root:Train (Epoch 81): Loss/seq after 04050 batchs: 720.266357421875
INFO:root:Train (Epoch 81): Loss/seq after 04100 batchs: 717.2154541015625
INFO:root:Train (Epoch 81): Loss/seq after 04150 batchs: 715.65869140625
INFO:root:Train (Epoch 81): Loss/seq after 04200 batchs: 713.4508056640625
INFO:root:Train (Epoch 81): Loss/seq after 04250 batchs: 711.2067260742188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 81): Loss/seq after 00000 batches: 556.5484008789062
INFO:root:# Valid (Epoch 81): Loss/seq after 00050 batches: 692.0130615234375
INFO:root:# Valid (Epoch 81): Loss/seq after 00100 batches: 929.7127075195312
INFO:root:# Valid (Epoch 81): Loss/seq after 00150 batches: 703.0314331054688
INFO:root:# Valid (Epoch 81): Loss/seq after 00200 batches: 646.9514770507812
INFO:root:Artifacts: Make stick videos for epoch 81
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_81_on_20220413_014730.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_81_index_961_on_20220413_014730.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 82): Loss/seq after 00000 batchs: 1448.69189453125
INFO:root:Train (Epoch 82): Loss/seq after 00050 batchs: 947.3324584960938
INFO:root:Train (Epoch 82): Loss/seq after 00100 batchs: 983.3900756835938
INFO:root:Train (Epoch 82): Loss/seq after 00150 batchs: 888.5153198242188
INFO:root:Train (Epoch 82): Loss/seq after 00200 batchs: 974.2568359375
INFO:root:Train (Epoch 82): Loss/seq after 00250 batchs: 1092.918212890625
INFO:root:Train (Epoch 82): Loss/seq after 00300 batchs: 1065.3765869140625
INFO:root:Train (Epoch 82): Loss/seq after 00350 batchs: 988.8489379882812
INFO:root:Train (Epoch 82): Loss/seq after 00400 batchs: 1001.1619873046875
INFO:root:Train (Epoch 82): Loss/seq after 00450 batchs: 968.3425903320312
INFO:root:Train (Epoch 82): Loss/seq after 00500 batchs: 945.6875610351562
INFO:root:Train (Epoch 82): Loss/seq after 00550 batchs: 911.5758056640625
INFO:root:Train (Epoch 82): Loss/seq after 00600 batchs: 877.3834838867188
INFO:root:Train (Epoch 82): Loss/seq after 00650 batchs: 875.2584228515625
INFO:root:Train (Epoch 82): Loss/seq after 00700 batchs: 855.2536010742188
INFO:root:Train (Epoch 82): Loss/seq after 00750 batchs: 876.3087158203125
INFO:root:Train (Epoch 82): Loss/seq after 00800 batchs: 873.5459594726562
INFO:root:Train (Epoch 82): Loss/seq after 00850 batchs: 845.3909301757812
INFO:root:Train (Epoch 82): Loss/seq after 00900 batchs: 829.0333251953125
INFO:root:Train (Epoch 82): Loss/seq after 00950 batchs: 838.0878295898438
INFO:root:Train (Epoch 82): Loss/seq after 01000 batchs: 830.936767578125
INFO:root:Train (Epoch 82): Loss/seq after 01050 batchs: 814.9580688476562
INFO:root:Train (Epoch 82): Loss/seq after 01100 batchs: 801.4647827148438
INFO:root:Train (Epoch 82): Loss/seq after 01150 batchs: 781.4680786132812
INFO:root:Train (Epoch 82): Loss/seq after 01200 batchs: 781.153564453125
INFO:root:Train (Epoch 82): Loss/seq after 01250 batchs: 775.2774047851562
INFO:root:Train (Epoch 82): Loss/seq after 01300 batchs: 766.7405395507812
INFO:root:Train (Epoch 82): Loss/seq after 01350 batchs: 758.455078125
INFO:root:Train (Epoch 82): Loss/seq after 01400 batchs: 770.4178466796875
INFO:root:Train (Epoch 82): Loss/seq after 01450 batchs: 768.5833129882812
INFO:root:Train (Epoch 82): Loss/seq after 01500 batchs: 771.0806884765625
INFO:root:Train (Epoch 82): Loss/seq after 01550 batchs: 771.8987426757812
INFO:root:Train (Epoch 82): Loss/seq after 01600 batchs: 763.2709350585938
INFO:root:Train (Epoch 82): Loss/seq after 01650 batchs: 758.609619140625
INFO:root:Train (Epoch 82): Loss/seq after 01700 batchs: 757.2039184570312
INFO:root:Train (Epoch 82): Loss/seq after 01750 batchs: 751.9736938476562
INFO:root:Train (Epoch 82): Loss/seq after 01800 batchs: 746.5656127929688
INFO:root:Train (Epoch 82): Loss/seq after 01850 batchs: 740.1917114257812
INFO:root:Train (Epoch 82): Loss/seq after 01900 batchs: 739.3121948242188
INFO:root:Train (Epoch 82): Loss/seq after 01950 batchs: 735.3952026367188
INFO:root:Train (Epoch 82): Loss/seq after 02000 batchs: 731.6788940429688
INFO:root:Train (Epoch 82): Loss/seq after 02050 batchs: 728.4044189453125
INFO:root:Train (Epoch 82): Loss/seq after 02100 batchs: 723.5735473632812
INFO:root:Train (Epoch 82): Loss/seq after 02150 batchs: 719.8938598632812
INFO:root:Train (Epoch 82): Loss/seq after 02200 batchs: 714.8494873046875
INFO:root:Train (Epoch 82): Loss/seq after 02250 batchs: 714.0634765625
INFO:root:Train (Epoch 82): Loss/seq after 02300 batchs: 715.81201171875
INFO:root:Train (Epoch 82): Loss/seq after 02350 batchs: 709.9281616210938
INFO:root:Train (Epoch 82): Loss/seq after 02400 batchs: 709.2708129882812
INFO:root:Train (Epoch 82): Loss/seq after 02450 batchs: 702.2784423828125
INFO:root:Train (Epoch 82): Loss/seq after 02500 batchs: 691.602783203125
INFO:root:Train (Epoch 82): Loss/seq after 02550 batchs: 683.581298828125
INFO:root:Train (Epoch 82): Loss/seq after 02600 batchs: 682.0281982421875
INFO:root:Train (Epoch 82): Loss/seq after 02650 batchs: 679.0562744140625
INFO:root:Train (Epoch 82): Loss/seq after 02700 batchs: 676.1983642578125
INFO:root:Train (Epoch 82): Loss/seq after 02750 batchs: 691.7351684570312
INFO:root:Train (Epoch 82): Loss/seq after 02800 batchs: 695.1180419921875
INFO:root:Train (Epoch 82): Loss/seq after 02850 batchs: 694.6764526367188
INFO:root:Train (Epoch 82): Loss/seq after 02900 batchs: 695.5992431640625
INFO:root:Train (Epoch 82): Loss/seq after 02950 batchs: 693.1829833984375
INFO:root:Train (Epoch 82): Loss/seq after 03000 batchs: 696.4904174804688
INFO:root:Train (Epoch 82): Loss/seq after 03050 batchs: 700.9613647460938
INFO:root:Train (Epoch 82): Loss/seq after 03100 batchs: 705.4390869140625
INFO:root:Train (Epoch 82): Loss/seq after 03150 batchs: 711.89990234375
INFO:root:Train (Epoch 82): Loss/seq after 03200 batchs: 717.5702514648438
INFO:root:Train (Epoch 82): Loss/seq after 03250 batchs: 722.1779174804688
INFO:root:Train (Epoch 82): Loss/seq after 03300 batchs: 721.261962890625
INFO:root:Train (Epoch 82): Loss/seq after 03350 batchs: 721.3759155273438
INFO:root:Train (Epoch 82): Loss/seq after 03400 batchs: 715.463623046875
INFO:root:Train (Epoch 82): Loss/seq after 03450 batchs: 712.2506103515625
INFO:root:Train (Epoch 82): Loss/seq after 03500 batchs: 712.334716796875
INFO:root:Train (Epoch 82): Loss/seq after 03550 batchs: 708.4124145507812
INFO:root:Train (Epoch 82): Loss/seq after 03600 batchs: 716.2066650390625
INFO:root:Train (Epoch 82): Loss/seq after 03650 batchs: 712.4868774414062
INFO:root:Train (Epoch 82): Loss/seq after 03700 batchs: 713.7418823242188
INFO:root:Train (Epoch 82): Loss/seq after 03750 batchs: 717.4684448242188
INFO:root:Train (Epoch 82): Loss/seq after 03800 batchs: 713.5775756835938
INFO:root:Train (Epoch 82): Loss/seq after 03850 batchs: 712.0577392578125
INFO:root:Train (Epoch 82): Loss/seq after 03900 batchs: 716.4451904296875
INFO:root:Train (Epoch 82): Loss/seq after 03950 batchs: 720.2689819335938
INFO:root:Train (Epoch 82): Loss/seq after 04000 batchs: 715.2750244140625
INFO:root:Train (Epoch 82): Loss/seq after 04050 batchs: 710.2672119140625
INFO:root:Train (Epoch 82): Loss/seq after 04100 batchs: 707.3773193359375
INFO:root:Train (Epoch 82): Loss/seq after 04150 batchs: 706.00244140625
INFO:root:Train (Epoch 82): Loss/seq after 04200 batchs: 703.556396484375
INFO:root:Train (Epoch 82): Loss/seq after 04250 batchs: 701.0887451171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 82): Loss/seq after 00000 batches: 590.4567260742188
INFO:root:# Valid (Epoch 82): Loss/seq after 00050 batches: 690.7544555664062
INFO:root:# Valid (Epoch 82): Loss/seq after 00100 batches: 892.7390747070312
INFO:root:# Valid (Epoch 82): Loss/seq after 00150 batches: 671.18115234375
INFO:root:# Valid (Epoch 82): Loss/seq after 00200 batches: 614.68505859375
INFO:root:Artifacts: Make stick videos for epoch 82
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_82_on_20220413_015251.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_82_index_1847_on_20220413_015251.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 83): Loss/seq after 00000 batchs: 1195.1341552734375
INFO:root:Train (Epoch 83): Loss/seq after 00050 batchs: 916.3628540039062
INFO:root:Train (Epoch 83): Loss/seq after 00100 batchs: 940.1854248046875
INFO:root:Train (Epoch 83): Loss/seq after 00150 batchs: 849.0892333984375
INFO:root:Train (Epoch 83): Loss/seq after 00200 batchs: 939.4644775390625
INFO:root:Train (Epoch 83): Loss/seq after 00250 batchs: 1061.023681640625
INFO:root:Train (Epoch 83): Loss/seq after 00300 batchs: 1037.9473876953125
INFO:root:Train (Epoch 83): Loss/seq after 00350 batchs: 963.736083984375
INFO:root:Train (Epoch 83): Loss/seq after 00400 batchs: 978.0017700195312
INFO:root:Train (Epoch 83): Loss/seq after 00450 batchs: 947.6845703125
INFO:root:Train (Epoch 83): Loss/seq after 00500 batchs: 923.121337890625
INFO:root:Train (Epoch 83): Loss/seq after 00550 batchs: 890.3416137695312
INFO:root:Train (Epoch 83): Loss/seq after 00600 batchs: 856.563232421875
INFO:root:Train (Epoch 83): Loss/seq after 00650 batchs: 852.8955688476562
INFO:root:Train (Epoch 83): Loss/seq after 00700 batchs: 836.5516357421875
INFO:root:Train (Epoch 83): Loss/seq after 00750 batchs: 853.0556640625
INFO:root:Train (Epoch 83): Loss/seq after 00800 batchs: 850.3931884765625
INFO:root:Train (Epoch 83): Loss/seq after 00850 batchs: 823.2013549804688
INFO:root:Train (Epoch 83): Loss/seq after 00900 batchs: 806.5075073242188
INFO:root:Train (Epoch 83): Loss/seq after 00950 batchs: 815.0758666992188
INFO:root:Train (Epoch 83): Loss/seq after 01000 batchs: 808.5499267578125
INFO:root:Train (Epoch 83): Loss/seq after 01050 batchs: 794.0060424804688
INFO:root:Train (Epoch 83): Loss/seq after 01100 batchs: 780.8356323242188
INFO:root:Train (Epoch 83): Loss/seq after 01150 batchs: 762.0016479492188
INFO:root:Train (Epoch 83): Loss/seq after 01200 batchs: 762.5870971679688
INFO:root:Train (Epoch 83): Loss/seq after 01250 batchs: 757.5302124023438
INFO:root:Train (Epoch 83): Loss/seq after 01300 batchs: 748.1605224609375
INFO:root:Train (Epoch 83): Loss/seq after 01350 batchs: 740.2869262695312
INFO:root:Train (Epoch 83): Loss/seq after 01400 batchs: 754.2833862304688
INFO:root:Train (Epoch 83): Loss/seq after 01450 batchs: 753.2577514648438
INFO:root:Train (Epoch 83): Loss/seq after 01500 batchs: 756.1587524414062
INFO:root:Train (Epoch 83): Loss/seq after 01550 batchs: 757.07275390625
INFO:root:Train (Epoch 83): Loss/seq after 01600 batchs: 748.885986328125
INFO:root:Train (Epoch 83): Loss/seq after 01650 batchs: 744.026611328125
INFO:root:Train (Epoch 83): Loss/seq after 01700 batchs: 743.439208984375
INFO:root:Train (Epoch 83): Loss/seq after 01750 batchs: 738.5570068359375
INFO:root:Train (Epoch 83): Loss/seq after 01800 batchs: 733.24267578125
INFO:root:Train (Epoch 83): Loss/seq after 01850 batchs: 727.1182861328125
INFO:root:Train (Epoch 83): Loss/seq after 01900 batchs: 726.3639526367188
INFO:root:Train (Epoch 83): Loss/seq after 01950 batchs: 722.8311157226562
INFO:root:Train (Epoch 83): Loss/seq after 02000 batchs: 719.2744140625
INFO:root:Train (Epoch 83): Loss/seq after 02050 batchs: 716.1034545898438
INFO:root:Train (Epoch 83): Loss/seq after 02100 batchs: 711.2354125976562
INFO:root:Train (Epoch 83): Loss/seq after 02150 batchs: 707.4751586914062
INFO:root:Train (Epoch 83): Loss/seq after 02200 batchs: 702.5261840820312
INFO:root:Train (Epoch 83): Loss/seq after 02250 batchs: 701.4556884765625
INFO:root:Train (Epoch 83): Loss/seq after 02300 batchs: 703.17626953125
INFO:root:Train (Epoch 83): Loss/seq after 02350 batchs: 697.3585205078125
INFO:root:Train (Epoch 83): Loss/seq after 02400 batchs: 696.9493408203125
INFO:root:Train (Epoch 83): Loss/seq after 02450 batchs: 690.3093872070312
INFO:root:Train (Epoch 83): Loss/seq after 02500 batchs: 679.8461303710938
INFO:root:Train (Epoch 83): Loss/seq after 02550 batchs: 672.1190185546875
INFO:root:Train (Epoch 83): Loss/seq after 02600 batchs: 670.6990356445312
INFO:root:Train (Epoch 83): Loss/seq after 02650 batchs: 667.8568725585938
INFO:root:Train (Epoch 83): Loss/seq after 02700 batchs: 665.2412719726562
INFO:root:Train (Epoch 83): Loss/seq after 02750 batchs: 679.4400634765625
INFO:root:Train (Epoch 83): Loss/seq after 02800 batchs: 682.8257446289062
INFO:root:Train (Epoch 83): Loss/seq after 02850 batchs: 682.4932250976562
INFO:root:Train (Epoch 83): Loss/seq after 02900 batchs: 683.2341918945312
INFO:root:Train (Epoch 83): Loss/seq after 02950 batchs: 680.859130859375
INFO:root:Train (Epoch 83): Loss/seq after 03000 batchs: 684.32177734375
INFO:root:Train (Epoch 83): Loss/seq after 03050 batchs: 688.6868286132812
INFO:root:Train (Epoch 83): Loss/seq after 03100 batchs: 693.7756958007812
INFO:root:Train (Epoch 83): Loss/seq after 03150 batchs: 700.2625732421875
INFO:root:Train (Epoch 83): Loss/seq after 03200 batchs: 704.8388061523438
INFO:root:Train (Epoch 83): Loss/seq after 03250 batchs: 709.9816284179688
INFO:root:Train (Epoch 83): Loss/seq after 03300 batchs: 708.6565551757812
INFO:root:Train (Epoch 83): Loss/seq after 03350 batchs: 708.3167724609375
INFO:root:Train (Epoch 83): Loss/seq after 03400 batchs: 702.3978271484375
INFO:root:Train (Epoch 83): Loss/seq after 03450 batchs: 699.47216796875
INFO:root:Train (Epoch 83): Loss/seq after 03500 batchs: 699.383056640625
INFO:root:Train (Epoch 83): Loss/seq after 03550 batchs: 695.47509765625
INFO:root:Train (Epoch 83): Loss/seq after 03600 batchs: 703.2442016601562
INFO:root:Train (Epoch 83): Loss/seq after 03650 batchs: 699.7025756835938
INFO:root:Train (Epoch 83): Loss/seq after 03700 batchs: 701.3992309570312
INFO:root:Train (Epoch 83): Loss/seq after 03750 batchs: 705.3885498046875
INFO:root:Train (Epoch 83): Loss/seq after 03800 batchs: 701.5653686523438
INFO:root:Train (Epoch 83): Loss/seq after 03850 batchs: 700.0930786132812
INFO:root:Train (Epoch 83): Loss/seq after 03900 batchs: 704.8829956054688
INFO:root:Train (Epoch 83): Loss/seq after 03950 batchs: 708.8491821289062
INFO:root:Train (Epoch 83): Loss/seq after 04000 batchs: 703.9346313476562
INFO:root:Train (Epoch 83): Loss/seq after 04050 batchs: 699.0394897460938
INFO:root:Train (Epoch 83): Loss/seq after 04100 batchs: 696.1597290039062
INFO:root:Train (Epoch 83): Loss/seq after 04150 batchs: 694.801025390625
INFO:root:Train (Epoch 83): Loss/seq after 04200 batchs: 692.41015625
INFO:root:Train (Epoch 83): Loss/seq after 04250 batchs: 689.9979248046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 83): Loss/seq after 00000 batches: 518.126708984375
INFO:root:# Valid (Epoch 83): Loss/seq after 00050 batches: 691.0301513671875
INFO:root:# Valid (Epoch 83): Loss/seq after 00100 batches: 844.236083984375
INFO:root:# Valid (Epoch 83): Loss/seq after 00150 batches: 642.0260620117188
INFO:root:# Valid (Epoch 83): Loss/seq after 00200 batches: 594.4252319335938
INFO:root:Artifacts: Make stick videos for epoch 83
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_83_on_20220413_015813.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_83_index_1360_on_20220413_015813.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 84): Loss/seq after 00000 batchs: 1165.8162841796875
INFO:root:Train (Epoch 84): Loss/seq after 00050 batchs: 927.24560546875
INFO:root:Train (Epoch 84): Loss/seq after 00100 batchs: 940.7352294921875
INFO:root:Train (Epoch 84): Loss/seq after 00150 batchs: 850.1030883789062
INFO:root:Train (Epoch 84): Loss/seq after 00200 batchs: 949.5708618164062
INFO:root:Train (Epoch 84): Loss/seq after 00250 batchs: 1069.2115478515625
INFO:root:Train (Epoch 84): Loss/seq after 00300 batchs: 1044.8765869140625
INFO:root:Train (Epoch 84): Loss/seq after 00350 batchs: 971.0811157226562
INFO:root:Train (Epoch 84): Loss/seq after 00400 batchs: 988.2839965820312
INFO:root:Train (Epoch 84): Loss/seq after 00450 batchs: 957.4384765625
INFO:root:Train (Epoch 84): Loss/seq after 00500 batchs: 931.632568359375
INFO:root:Train (Epoch 84): Loss/seq after 00550 batchs: 898.2264404296875
INFO:root:Train (Epoch 84): Loss/seq after 00600 batchs: 864.8386840820312
INFO:root:Train (Epoch 84): Loss/seq after 00650 batchs: 861.6456298828125
INFO:root:Train (Epoch 84): Loss/seq after 00700 batchs: 842.5324096679688
INFO:root:Train (Epoch 84): Loss/seq after 00750 batchs: 860.2915649414062
INFO:root:Train (Epoch 84): Loss/seq after 00800 batchs: 859.1670532226562
INFO:root:Train (Epoch 84): Loss/seq after 00850 batchs: 832.2676391601562
INFO:root:Train (Epoch 84): Loss/seq after 00900 batchs: 817.2041015625
INFO:root:Train (Epoch 84): Loss/seq after 00950 batchs: 824.8116455078125
INFO:root:Train (Epoch 84): Loss/seq after 01000 batchs: 820.0416870117188
INFO:root:Train (Epoch 84): Loss/seq after 01050 batchs: 805.0813598632812
INFO:root:Train (Epoch 84): Loss/seq after 01100 batchs: 791.8490600585938
INFO:root:Train (Epoch 84): Loss/seq after 01150 batchs: 772.2195434570312
INFO:root:Train (Epoch 84): Loss/seq after 01200 batchs: 772.029052734375
INFO:root:Train (Epoch 84): Loss/seq after 01250 batchs: 766.8074951171875
INFO:root:Train (Epoch 84): Loss/seq after 01300 batchs: 757.1646728515625
INFO:root:Train (Epoch 84): Loss/seq after 01350 batchs: 748.8026123046875
INFO:root:Train (Epoch 84): Loss/seq after 01400 batchs: 760.6880493164062
INFO:root:Train (Epoch 84): Loss/seq after 01450 batchs: 759.3145751953125
INFO:root:Train (Epoch 84): Loss/seq after 01500 batchs: 761.9069213867188
INFO:root:Train (Epoch 84): Loss/seq after 01550 batchs: 762.436279296875
INFO:root:Train (Epoch 84): Loss/seq after 01600 batchs: 753.7763671875
INFO:root:Train (Epoch 84): Loss/seq after 01650 batchs: 749.077880859375
INFO:root:Train (Epoch 84): Loss/seq after 01700 batchs: 747.9107666015625
INFO:root:Train (Epoch 84): Loss/seq after 01750 batchs: 742.7223510742188
INFO:root:Train (Epoch 84): Loss/seq after 01800 batchs: 737.18408203125
INFO:root:Train (Epoch 84): Loss/seq after 01850 batchs: 731.12548828125
INFO:root:Train (Epoch 84): Loss/seq after 01900 batchs: 730.3716430664062
INFO:root:Train (Epoch 84): Loss/seq after 01950 batchs: 726.8509521484375
INFO:root:Train (Epoch 84): Loss/seq after 02000 batchs: 723.0206909179688
INFO:root:Train (Epoch 84): Loss/seq after 02050 batchs: 719.4838256835938
INFO:root:Train (Epoch 84): Loss/seq after 02100 batchs: 714.5673828125
INFO:root:Train (Epoch 84): Loss/seq after 02150 batchs: 710.6839599609375
INFO:root:Train (Epoch 84): Loss/seq after 02200 batchs: 705.59814453125
INFO:root:Train (Epoch 84): Loss/seq after 02250 batchs: 704.435302734375
INFO:root:Train (Epoch 84): Loss/seq after 02300 batchs: 705.3366088867188
INFO:root:Train (Epoch 84): Loss/seq after 02350 batchs: 699.1385498046875
INFO:root:Train (Epoch 84): Loss/seq after 02400 batchs: 698.62158203125
INFO:root:Train (Epoch 84): Loss/seq after 02450 batchs: 691.8334350585938
INFO:root:Train (Epoch 84): Loss/seq after 02500 batchs: 681.3401489257812
INFO:root:Train (Epoch 84): Loss/seq after 02550 batchs: 673.645751953125
INFO:root:Train (Epoch 84): Loss/seq after 02600 batchs: 672.2496337890625
INFO:root:Train (Epoch 84): Loss/seq after 02650 batchs: 669.5770263671875
INFO:root:Train (Epoch 84): Loss/seq after 02700 batchs: 666.7466430664062
INFO:root:Train (Epoch 84): Loss/seq after 02750 batchs: 677.8154296875
INFO:root:Train (Epoch 84): Loss/seq after 02800 batchs: 680.8822021484375
INFO:root:Train (Epoch 84): Loss/seq after 02850 batchs: 680.3892822265625
INFO:root:Train (Epoch 84): Loss/seq after 02900 batchs: 681.1369018554688
INFO:root:Train (Epoch 84): Loss/seq after 02950 batchs: 678.8027954101562
INFO:root:Train (Epoch 84): Loss/seq after 03000 batchs: 682.2760009765625
INFO:root:Train (Epoch 84): Loss/seq after 03050 batchs: 686.469482421875
INFO:root:Train (Epoch 84): Loss/seq after 03100 batchs: 691.3847045898438
INFO:root:Train (Epoch 84): Loss/seq after 03150 batchs: 698.4351196289062
INFO:root:Train (Epoch 84): Loss/seq after 03200 batchs: 704.0145874023438
INFO:root:Train (Epoch 84): Loss/seq after 03250 batchs: 709.1322021484375
INFO:root:Train (Epoch 84): Loss/seq after 03300 batchs: 708.1365966796875
INFO:root:Train (Epoch 84): Loss/seq after 03350 batchs: 707.7392578125
INFO:root:Train (Epoch 84): Loss/seq after 03400 batchs: 701.9032592773438
INFO:root:Train (Epoch 84): Loss/seq after 03450 batchs: 698.9652099609375
INFO:root:Train (Epoch 84): Loss/seq after 03500 batchs: 698.841552734375
INFO:root:Train (Epoch 84): Loss/seq after 03550 batchs: 694.7715454101562
INFO:root:Train (Epoch 84): Loss/seq after 03600 batchs: 702.4087524414062
INFO:root:Train (Epoch 84): Loss/seq after 03650 batchs: 698.5740966796875
INFO:root:Train (Epoch 84): Loss/seq after 03700 batchs: 699.8453369140625
INFO:root:Train (Epoch 84): Loss/seq after 03750 batchs: 703.66015625
INFO:root:Train (Epoch 84): Loss/seq after 03800 batchs: 699.8421630859375
INFO:root:Train (Epoch 84): Loss/seq after 03850 batchs: 698.3851318359375
INFO:root:Train (Epoch 84): Loss/seq after 03900 batchs: 702.7525634765625
INFO:root:Train (Epoch 84): Loss/seq after 03950 batchs: 706.4190673828125
INFO:root:Train (Epoch 84): Loss/seq after 04000 batchs: 701.5333862304688
INFO:root:Train (Epoch 84): Loss/seq after 04050 batchs: 696.670166015625
INFO:root:Train (Epoch 84): Loss/seq after 04100 batchs: 693.8013305664062
INFO:root:Train (Epoch 84): Loss/seq after 04150 batchs: 692.4924926757812
INFO:root:Train (Epoch 84): Loss/seq after 04200 batchs: 690.0828857421875
INFO:root:Train (Epoch 84): Loss/seq after 04250 batchs: 687.7413330078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 84): Loss/seq after 00000 batches: 545.7978515625
INFO:root:# Valid (Epoch 84): Loss/seq after 00050 batches: 684.6471557617188
INFO:root:# Valid (Epoch 84): Loss/seq after 00100 batches: 845.115234375
INFO:root:# Valid (Epoch 84): Loss/seq after 00150 batches: 641.691650390625
INFO:root:# Valid (Epoch 84): Loss/seq after 00200 batches: 592.4649658203125
INFO:root:Artifacts: Make stick videos for epoch 84
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_84_on_20220413_020335.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_84_index_1322_on_20220413_020335.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 85): Loss/seq after 00000 batchs: 1169.258056640625
INFO:root:Train (Epoch 85): Loss/seq after 00050 batchs: 916.6914672851562
INFO:root:Train (Epoch 85): Loss/seq after 00100 batchs: 946.9714965820312
INFO:root:Train (Epoch 85): Loss/seq after 00150 batchs: 855.5640258789062
INFO:root:Train (Epoch 85): Loss/seq after 00200 batchs: 939.6998901367188
INFO:root:Train (Epoch 85): Loss/seq after 00250 batchs: 1057.5902099609375
INFO:root:Train (Epoch 85): Loss/seq after 00300 batchs: 1034.516845703125
INFO:root:Train (Epoch 85): Loss/seq after 00350 batchs: 959.8558349609375
INFO:root:Train (Epoch 85): Loss/seq after 00400 batchs: 970.2645263671875
INFO:root:Train (Epoch 85): Loss/seq after 00450 batchs: 939.6029052734375
INFO:root:Train (Epoch 85): Loss/seq after 00500 batchs: 915.4999389648438
INFO:root:Train (Epoch 85): Loss/seq after 00550 batchs: 882.7431030273438
INFO:root:Train (Epoch 85): Loss/seq after 00600 batchs: 850.5948486328125
INFO:root:Train (Epoch 85): Loss/seq after 00650 batchs: 847.543701171875
INFO:root:Train (Epoch 85): Loss/seq after 00700 batchs: 829.0682983398438
INFO:root:Train (Epoch 85): Loss/seq after 00750 batchs: 847.570068359375
INFO:root:Train (Epoch 85): Loss/seq after 00800 batchs: 846.0581665039062
INFO:root:Train (Epoch 85): Loss/seq after 00850 batchs: 819.260498046875
INFO:root:Train (Epoch 85): Loss/seq after 00900 batchs: 803.16357421875
INFO:root:Train (Epoch 85): Loss/seq after 00950 batchs: 809.8841552734375
INFO:root:Train (Epoch 85): Loss/seq after 01000 batchs: 803.2509155273438
INFO:root:Train (Epoch 85): Loss/seq after 01050 batchs: 789.5176391601562
INFO:root:Train (Epoch 85): Loss/seq after 01100 batchs: 777.4878540039062
INFO:root:Train (Epoch 85): Loss/seq after 01150 batchs: 758.3504638671875
INFO:root:Train (Epoch 85): Loss/seq after 01200 batchs: 758.779296875
INFO:root:Train (Epoch 85): Loss/seq after 01250 batchs: 753.6898803710938
INFO:root:Train (Epoch 85): Loss/seq after 01300 batchs: 744.140625
INFO:root:Train (Epoch 85): Loss/seq after 01350 batchs: 735.0194702148438
INFO:root:Train (Epoch 85): Loss/seq after 01400 batchs: 747.2235717773438
INFO:root:Train (Epoch 85): Loss/seq after 01450 batchs: 746.3216552734375
INFO:root:Train (Epoch 85): Loss/seq after 01500 batchs: 749.3817749023438
INFO:root:Train (Epoch 85): Loss/seq after 01550 batchs: 750.6749267578125
INFO:root:Train (Epoch 85): Loss/seq after 01600 batchs: 742.5198364257812
INFO:root:Train (Epoch 85): Loss/seq after 01650 batchs: 738.1898803710938
INFO:root:Train (Epoch 85): Loss/seq after 01700 batchs: 737.2157592773438
INFO:root:Train (Epoch 85): Loss/seq after 01750 batchs: 732.296875
INFO:root:Train (Epoch 85): Loss/seq after 01800 batchs: 727.227294921875
INFO:root:Train (Epoch 85): Loss/seq after 01850 batchs: 721.252197265625
INFO:root:Train (Epoch 85): Loss/seq after 01900 batchs: 720.54931640625
INFO:root:Train (Epoch 85): Loss/seq after 01950 batchs: 717.0516967773438
INFO:root:Train (Epoch 85): Loss/seq after 02000 batchs: 713.29736328125
INFO:root:Train (Epoch 85): Loss/seq after 02050 batchs: 710.0276489257812
INFO:root:Train (Epoch 85): Loss/seq after 02100 batchs: 705.2390747070312
INFO:root:Train (Epoch 85): Loss/seq after 02150 batchs: 701.3828735351562
INFO:root:Train (Epoch 85): Loss/seq after 02200 batchs: 696.5183715820312
INFO:root:Train (Epoch 85): Loss/seq after 02250 batchs: 695.2757568359375
INFO:root:Train (Epoch 85): Loss/seq after 02300 batchs: 696.50341796875
INFO:root:Train (Epoch 85): Loss/seq after 02350 batchs: 691.0441284179688
INFO:root:Train (Epoch 85): Loss/seq after 02400 batchs: 690.8281860351562
INFO:root:Train (Epoch 85): Loss/seq after 02450 batchs: 684.2014770507812
INFO:root:Train (Epoch 85): Loss/seq after 02500 batchs: 673.8925170898438
INFO:root:Train (Epoch 85): Loss/seq after 02550 batchs: 666.2637939453125
INFO:root:Train (Epoch 85): Loss/seq after 02600 batchs: 664.8134155273438
INFO:root:Train (Epoch 85): Loss/seq after 02650 batchs: 662.0228271484375
INFO:root:Train (Epoch 85): Loss/seq after 02700 batchs: 659.2883911132812
INFO:root:Train (Epoch 85): Loss/seq after 02750 batchs: 669.8526000976562
INFO:root:Train (Epoch 85): Loss/seq after 02800 batchs: 673.5513916015625
INFO:root:Train (Epoch 85): Loss/seq after 02850 batchs: 673.221923828125
INFO:root:Train (Epoch 85): Loss/seq after 02900 batchs: 673.8984985351562
INFO:root:Train (Epoch 85): Loss/seq after 02950 batchs: 671.515625
INFO:root:Train (Epoch 85): Loss/seq after 03000 batchs: 675.0587768554688
INFO:root:Train (Epoch 85): Loss/seq after 03050 batchs: 678.754638671875
INFO:root:Train (Epoch 85): Loss/seq after 03100 batchs: 683.4910278320312
INFO:root:Train (Epoch 85): Loss/seq after 03150 batchs: 689.4674682617188
INFO:root:Train (Epoch 85): Loss/seq after 03200 batchs: 694.9885864257812
INFO:root:Train (Epoch 85): Loss/seq after 03250 batchs: 699.6148681640625
INFO:root:Train (Epoch 85): Loss/seq after 03300 batchs: 698.4288330078125
INFO:root:Train (Epoch 85): Loss/seq after 03350 batchs: 698.2207641601562
INFO:root:Train (Epoch 85): Loss/seq after 03400 batchs: 692.4329833984375
INFO:root:Train (Epoch 85): Loss/seq after 03450 batchs: 689.583251953125
INFO:root:Train (Epoch 85): Loss/seq after 03500 batchs: 689.3588256835938
INFO:root:Train (Epoch 85): Loss/seq after 03550 batchs: 685.4725952148438
INFO:root:Train (Epoch 85): Loss/seq after 03600 batchs: 693.438720703125
INFO:root:Train (Epoch 85): Loss/seq after 03650 batchs: 689.8759765625
INFO:root:Train (Epoch 85): Loss/seq after 03700 batchs: 691.3463134765625
INFO:root:Train (Epoch 85): Loss/seq after 03750 batchs: 695.2750854492188
INFO:root:Train (Epoch 85): Loss/seq after 03800 batchs: 691.5690307617188
INFO:root:Train (Epoch 85): Loss/seq after 03850 batchs: 690.2213134765625
INFO:root:Train (Epoch 85): Loss/seq after 03900 batchs: 694.94873046875
INFO:root:Train (Epoch 85): Loss/seq after 03950 batchs: 698.9779663085938
INFO:root:Train (Epoch 85): Loss/seq after 04000 batchs: 694.1765747070312
INFO:root:Train (Epoch 85): Loss/seq after 04050 batchs: 689.3594970703125
INFO:root:Train (Epoch 85): Loss/seq after 04100 batchs: 686.5411987304688
INFO:root:Train (Epoch 85): Loss/seq after 04150 batchs: 685.258544921875
INFO:root:Train (Epoch 85): Loss/seq after 04200 batchs: 682.881591796875
INFO:root:Train (Epoch 85): Loss/seq after 04250 batchs: 680.539794921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 85): Loss/seq after 00000 batches: 535.994140625
INFO:root:# Valid (Epoch 85): Loss/seq after 00050 batches: 674.8878173828125
INFO:root:# Valid (Epoch 85): Loss/seq after 00100 batches: 836.4288940429688
INFO:root:# Valid (Epoch 85): Loss/seq after 00150 batches: 641.4009399414062
INFO:root:# Valid (Epoch 85): Loss/seq after 00200 batches: 594.363037109375
INFO:root:Artifacts: Make stick videos for epoch 85
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_85_on_20220413_020857.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_85_index_552_on_20220413_020857.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 86): Loss/seq after 00000 batchs: 1165.79345703125
INFO:root:Train (Epoch 86): Loss/seq after 00050 batchs: 934.3937377929688
INFO:root:Train (Epoch 86): Loss/seq after 00100 batchs: 962.0439453125
INFO:root:Train (Epoch 86): Loss/seq after 00150 batchs: 869.1516723632812
INFO:root:Train (Epoch 86): Loss/seq after 00200 batchs: 948.574462890625
INFO:root:Train (Epoch 86): Loss/seq after 00250 batchs: 1072.652587890625
INFO:root:Train (Epoch 86): Loss/seq after 00300 batchs: 1047.184326171875
INFO:root:Train (Epoch 86): Loss/seq after 00350 batchs: 971.66015625
INFO:root:Train (Epoch 86): Loss/seq after 00400 batchs: 983.0946655273438
INFO:root:Train (Epoch 86): Loss/seq after 00450 batchs: 951.7235717773438
INFO:root:Train (Epoch 86): Loss/seq after 00500 batchs: 925.3076171875
INFO:root:Train (Epoch 86): Loss/seq after 00550 batchs: 891.7255249023438
INFO:root:Train (Epoch 86): Loss/seq after 00600 batchs: 858.3289794921875
INFO:root:Train (Epoch 86): Loss/seq after 00650 batchs: 852.447021484375
INFO:root:Train (Epoch 86): Loss/seq after 00700 batchs: 831.4468994140625
INFO:root:Train (Epoch 86): Loss/seq after 00750 batchs: 844.465576171875
INFO:root:Train (Epoch 86): Loss/seq after 00800 batchs: 842.1503295898438
INFO:root:Train (Epoch 86): Loss/seq after 00850 batchs: 815.896728515625
INFO:root:Train (Epoch 86): Loss/seq after 00900 batchs: 800.1988525390625
INFO:root:Train (Epoch 86): Loss/seq after 00950 batchs: 807.5513305664062
INFO:root:Train (Epoch 86): Loss/seq after 01000 batchs: 800.5311889648438
INFO:root:Train (Epoch 86): Loss/seq after 01050 batchs: 786.3128051757812
INFO:root:Train (Epoch 86): Loss/seq after 01100 batchs: 773.6747436523438
INFO:root:Train (Epoch 86): Loss/seq after 01150 batchs: 755.010986328125
INFO:root:Train (Epoch 86): Loss/seq after 01200 batchs: 755.3840942382812
INFO:root:Train (Epoch 86): Loss/seq after 01250 batchs: 750.2592163085938
INFO:root:Train (Epoch 86): Loss/seq after 01300 batchs: 740.5083618164062
INFO:root:Train (Epoch 86): Loss/seq after 01350 batchs: 731.298583984375
INFO:root:Train (Epoch 86): Loss/seq after 01400 batchs: 744.636474609375
INFO:root:Train (Epoch 86): Loss/seq after 01450 batchs: 743.6758422851562
INFO:root:Train (Epoch 86): Loss/seq after 01500 batchs: 746.54443359375
INFO:root:Train (Epoch 86): Loss/seq after 01550 batchs: 747.2601928710938
INFO:root:Train (Epoch 86): Loss/seq after 01600 batchs: 739.0770874023438
INFO:root:Train (Epoch 86): Loss/seq after 01650 batchs: 734.4692993164062
INFO:root:Train (Epoch 86): Loss/seq after 01700 batchs: 734.2098388671875
INFO:root:Train (Epoch 86): Loss/seq after 01750 batchs: 729.207763671875
INFO:root:Train (Epoch 86): Loss/seq after 01800 batchs: 724.01416015625
INFO:root:Train (Epoch 86): Loss/seq after 01850 batchs: 717.8748779296875
INFO:root:Train (Epoch 86): Loss/seq after 01900 batchs: 717.1852416992188
INFO:root:Train (Epoch 86): Loss/seq after 01950 batchs: 713.5175170898438
INFO:root:Train (Epoch 86): Loss/seq after 02000 batchs: 709.83740234375
INFO:root:Train (Epoch 86): Loss/seq after 02050 batchs: 706.5711059570312
INFO:root:Train (Epoch 86): Loss/seq after 02100 batchs: 701.865234375
INFO:root:Train (Epoch 86): Loss/seq after 02150 batchs: 698.2132568359375
INFO:root:Train (Epoch 86): Loss/seq after 02200 batchs: 693.3432006835938
INFO:root:Train (Epoch 86): Loss/seq after 02250 batchs: 692.0422973632812
INFO:root:Train (Epoch 86): Loss/seq after 02300 batchs: 692.4278564453125
INFO:root:Train (Epoch 86): Loss/seq after 02350 batchs: 686.7167358398438
INFO:root:Train (Epoch 86): Loss/seq after 02400 batchs: 686.5581665039062
INFO:root:Train (Epoch 86): Loss/seq after 02450 batchs: 679.9539794921875
INFO:root:Train (Epoch 86): Loss/seq after 02500 batchs: 669.6970825195312
INFO:root:Train (Epoch 86): Loss/seq after 02550 batchs: 662.1524047851562
INFO:root:Train (Epoch 86): Loss/seq after 02600 batchs: 660.799560546875
INFO:root:Train (Epoch 86): Loss/seq after 02650 batchs: 658.1394653320312
INFO:root:Train (Epoch 86): Loss/seq after 02700 batchs: 655.9632568359375
INFO:root:Train (Epoch 86): Loss/seq after 02750 batchs: 666.1420288085938
INFO:root:Train (Epoch 86): Loss/seq after 02800 batchs: 670.1982421875
INFO:root:Train (Epoch 86): Loss/seq after 02850 batchs: 670.4194946289062
INFO:root:Train (Epoch 86): Loss/seq after 02900 batchs: 672.127685546875
INFO:root:Train (Epoch 86): Loss/seq after 02950 batchs: 670.0342407226562
INFO:root:Train (Epoch 86): Loss/seq after 03000 batchs: 673.602783203125
INFO:root:Train (Epoch 86): Loss/seq after 03050 batchs: 677.621337890625
INFO:root:Train (Epoch 86): Loss/seq after 03100 batchs: 682.7188110351562
INFO:root:Train (Epoch 86): Loss/seq after 03150 batchs: 688.6305541992188
INFO:root:Train (Epoch 86): Loss/seq after 03200 batchs: 693.7924194335938
INFO:root:Train (Epoch 86): Loss/seq after 03250 batchs: 698.3272094726562
INFO:root:Train (Epoch 86): Loss/seq after 03300 batchs: 696.9335327148438
INFO:root:Train (Epoch 86): Loss/seq after 03350 batchs: 696.7984619140625
INFO:root:Train (Epoch 86): Loss/seq after 03400 batchs: 691.1488037109375
INFO:root:Train (Epoch 86): Loss/seq after 03450 batchs: 688.3250732421875
INFO:root:Train (Epoch 86): Loss/seq after 03500 batchs: 687.9215087890625
INFO:root:Train (Epoch 86): Loss/seq after 03550 batchs: 683.8172607421875
INFO:root:Train (Epoch 86): Loss/seq after 03600 batchs: 691.5733642578125
INFO:root:Train (Epoch 86): Loss/seq after 03650 batchs: 687.8411254882812
INFO:root:Train (Epoch 86): Loss/seq after 03700 batchs: 689.5352783203125
INFO:root:Train (Epoch 86): Loss/seq after 03750 batchs: 693.5053100585938
INFO:root:Train (Epoch 86): Loss/seq after 03800 batchs: 689.78857421875
INFO:root:Train (Epoch 86): Loss/seq after 03850 batchs: 688.3157958984375
INFO:root:Train (Epoch 86): Loss/seq after 03900 batchs: 693.091552734375
INFO:root:Train (Epoch 86): Loss/seq after 03950 batchs: 697.1936645507812
INFO:root:Train (Epoch 86): Loss/seq after 04000 batchs: 692.3308715820312
INFO:root:Train (Epoch 86): Loss/seq after 04050 batchs: 687.5635986328125
INFO:root:Train (Epoch 86): Loss/seq after 04100 batchs: 684.786376953125
INFO:root:Train (Epoch 86): Loss/seq after 04150 batchs: 683.57080078125
INFO:root:Train (Epoch 86): Loss/seq after 04200 batchs: 681.2792358398438
INFO:root:Train (Epoch 86): Loss/seq after 04250 batchs: 678.9207763671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 86): Loss/seq after 00000 batches: 525.3696899414062
INFO:root:# Valid (Epoch 86): Loss/seq after 00050 batches: 662.89599609375
INFO:root:# Valid (Epoch 86): Loss/seq after 00100 batches: 818.9826049804688
INFO:root:# Valid (Epoch 86): Loss/seq after 00150 batches: 618.3690795898438
INFO:root:# Valid (Epoch 86): Loss/seq after 00200 batches: 573.2002563476562
INFO:root:Artifacts: Make stick videos for epoch 86
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_86_on_20220413_021419.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_86_index_477_on_20220413_021419.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 87): Loss/seq after 00000 batchs: 1208.3375244140625
INFO:root:Train (Epoch 87): Loss/seq after 00050 batchs: 922.6089477539062
INFO:root:Train (Epoch 87): Loss/seq after 00100 batchs: 948.5275268554688
INFO:root:Train (Epoch 87): Loss/seq after 00150 batchs: 855.9789428710938
INFO:root:Train (Epoch 87): Loss/seq after 00200 batchs: 941.4608154296875
INFO:root:Train (Epoch 87): Loss/seq after 00250 batchs: 1059.5418701171875
INFO:root:Train (Epoch 87): Loss/seq after 00300 batchs: 1035.3873291015625
INFO:root:Train (Epoch 87): Loss/seq after 00350 batchs: 961.8709716796875
INFO:root:Train (Epoch 87): Loss/seq after 00400 batchs: 976.9107055664062
INFO:root:Train (Epoch 87): Loss/seq after 00450 batchs: 946.6942749023438
INFO:root:Train (Epoch 87): Loss/seq after 00500 batchs: 921.6701049804688
INFO:root:Train (Epoch 87): Loss/seq after 00550 batchs: 888.4671020507812
INFO:root:Train (Epoch 87): Loss/seq after 00600 batchs: 854.9515380859375
INFO:root:Train (Epoch 87): Loss/seq after 00650 batchs: 846.61865234375
INFO:root:Train (Epoch 87): Loss/seq after 00700 batchs: 827.3055419921875
INFO:root:Train (Epoch 87): Loss/seq after 00750 batchs: 842.5007934570312
INFO:root:Train (Epoch 87): Loss/seq after 00800 batchs: 840.5662231445312
INFO:root:Train (Epoch 87): Loss/seq after 00850 batchs: 813.9886474609375
INFO:root:Train (Epoch 87): Loss/seq after 00900 batchs: 797.6821899414062
INFO:root:Train (Epoch 87): Loss/seq after 00950 batchs: 802.2471313476562
INFO:root:Train (Epoch 87): Loss/seq after 01000 batchs: 794.0031127929688
INFO:root:Train (Epoch 87): Loss/seq after 01050 batchs: 779.5816650390625
INFO:root:Train (Epoch 87): Loss/seq after 01100 batchs: 766.774658203125
INFO:root:Train (Epoch 87): Loss/seq after 01150 batchs: 747.977294921875
INFO:root:Train (Epoch 87): Loss/seq after 01200 batchs: 748.5291137695312
INFO:root:Train (Epoch 87): Loss/seq after 01250 batchs: 743.1505126953125
INFO:root:Train (Epoch 87): Loss/seq after 01300 batchs: 733.377197265625
INFO:root:Train (Epoch 87): Loss/seq after 01350 batchs: 724.5482788085938
INFO:root:Train (Epoch 87): Loss/seq after 01400 batchs: 733.7869873046875
INFO:root:Train (Epoch 87): Loss/seq after 01450 batchs: 732.4996337890625
INFO:root:Train (Epoch 87): Loss/seq after 01500 batchs: 735.5751342773438
INFO:root:Train (Epoch 87): Loss/seq after 01550 batchs: 736.7598876953125
INFO:root:Train (Epoch 87): Loss/seq after 01600 batchs: 728.8001708984375
INFO:root:Train (Epoch 87): Loss/seq after 01650 batchs: 724.7202758789062
INFO:root:Train (Epoch 87): Loss/seq after 01700 batchs: 724.2764892578125
INFO:root:Train (Epoch 87): Loss/seq after 01750 batchs: 719.6083984375
INFO:root:Train (Epoch 87): Loss/seq after 01800 batchs: 714.7100219726562
INFO:root:Train (Epoch 87): Loss/seq after 01850 batchs: 708.8759765625
INFO:root:Train (Epoch 87): Loss/seq after 01900 batchs: 708.2531127929688
INFO:root:Train (Epoch 87): Loss/seq after 01950 batchs: 704.9700317382812
INFO:root:Train (Epoch 87): Loss/seq after 02000 batchs: 701.6049194335938
INFO:root:Train (Epoch 87): Loss/seq after 02050 batchs: 698.6253051757812
INFO:root:Train (Epoch 87): Loss/seq after 02100 batchs: 694.1581420898438
INFO:root:Train (Epoch 87): Loss/seq after 02150 batchs: 690.7409057617188
INFO:root:Train (Epoch 87): Loss/seq after 02200 batchs: 686.07080078125
INFO:root:Train (Epoch 87): Loss/seq after 02250 batchs: 684.7367553710938
INFO:root:Train (Epoch 87): Loss/seq after 02300 batchs: 685.4946899414062
INFO:root:Train (Epoch 87): Loss/seq after 02350 batchs: 679.778076171875
INFO:root:Train (Epoch 87): Loss/seq after 02400 batchs: 679.5126342773438
INFO:root:Train (Epoch 87): Loss/seq after 02450 batchs: 673.0078125
INFO:root:Train (Epoch 87): Loss/seq after 02500 batchs: 662.898681640625
INFO:root:Train (Epoch 87): Loss/seq after 02550 batchs: 655.4330444335938
INFO:root:Train (Epoch 87): Loss/seq after 02600 batchs: 654.149169921875
INFO:root:Train (Epoch 87): Loss/seq after 02650 batchs: 651.4631958007812
INFO:root:Train (Epoch 87): Loss/seq after 02700 batchs: 648.9286499023438
INFO:root:Train (Epoch 87): Loss/seq after 02750 batchs: 658.1133422851562
INFO:root:Train (Epoch 87): Loss/seq after 02800 batchs: 661.18701171875
INFO:root:Train (Epoch 87): Loss/seq after 02850 batchs: 660.7106323242188
INFO:root:Train (Epoch 87): Loss/seq after 02900 batchs: 661.7571411132812
INFO:root:Train (Epoch 87): Loss/seq after 02950 batchs: 659.4923095703125
INFO:root:Train (Epoch 87): Loss/seq after 03000 batchs: 663.1459350585938
INFO:root:Train (Epoch 87): Loss/seq after 03050 batchs: 666.7916870117188
INFO:root:Train (Epoch 87): Loss/seq after 03100 batchs: 671.906982421875
INFO:root:Train (Epoch 87): Loss/seq after 03150 batchs: 678.2871704101562
INFO:root:Train (Epoch 87): Loss/seq after 03200 batchs: 683.0838012695312
INFO:root:Train (Epoch 87): Loss/seq after 03250 batchs: 688.0
INFO:root:Train (Epoch 87): Loss/seq after 03300 batchs: 687.1282958984375
INFO:root:Train (Epoch 87): Loss/seq after 03350 batchs: 687.2781372070312
INFO:root:Train (Epoch 87): Loss/seq after 03400 batchs: 681.6975708007812
INFO:root:Train (Epoch 87): Loss/seq after 03450 batchs: 678.9616088867188
INFO:root:Train (Epoch 87): Loss/seq after 03500 batchs: 678.828857421875
INFO:root:Train (Epoch 87): Loss/seq after 03550 batchs: 675.2508544921875
INFO:root:Train (Epoch 87): Loss/seq after 03600 batchs: 683.321044921875
INFO:root:Train (Epoch 87): Loss/seq after 03650 batchs: 679.7280883789062
INFO:root:Train (Epoch 87): Loss/seq after 03700 batchs: 681.2661743164062
INFO:root:Train (Epoch 87): Loss/seq after 03750 batchs: 685.2362060546875
INFO:root:Train (Epoch 87): Loss/seq after 03800 batchs: 681.645263671875
INFO:root:Train (Epoch 87): Loss/seq after 03850 batchs: 680.233642578125
INFO:root:Train (Epoch 87): Loss/seq after 03900 batchs: 685.082275390625
INFO:root:Train (Epoch 87): Loss/seq after 03950 batchs: 688.9129638671875
INFO:root:Train (Epoch 87): Loss/seq after 04000 batchs: 684.1705932617188
INFO:root:Train (Epoch 87): Loss/seq after 04050 batchs: 679.5012817382812
INFO:root:Train (Epoch 87): Loss/seq after 04100 batchs: 676.7738037109375
INFO:root:Train (Epoch 87): Loss/seq after 04150 batchs: 675.6495971679688
INFO:root:Train (Epoch 87): Loss/seq after 04200 batchs: 673.3561401367188
INFO:root:Train (Epoch 87): Loss/seq after 04250 batchs: 671.0819091796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 87): Loss/seq after 00000 batches: 524.0399780273438
INFO:root:# Valid (Epoch 87): Loss/seq after 00050 batches: 692.0963745117188
INFO:root:# Valid (Epoch 87): Loss/seq after 00100 batches: 847.91796875
INFO:root:# Valid (Epoch 87): Loss/seq after 00150 batches: 643.4865112304688
INFO:root:# Valid (Epoch 87): Loss/seq after 00200 batches: 596.0148315429688
INFO:root:Artifacts: Make stick videos for epoch 87
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_87_on_20220413_021941.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_87_index_96_on_20220413_021941.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 88): Loss/seq after 00000 batchs: 1143.3837890625
INFO:root:Train (Epoch 88): Loss/seq after 00050 batchs: 886.3330078125
INFO:root:Train (Epoch 88): Loss/seq after 00100 batchs: 919.4335327148438
INFO:root:Train (Epoch 88): Loss/seq after 00150 batchs: 834.3798217773438
INFO:root:Train (Epoch 88): Loss/seq after 00200 batchs: 913.156982421875
INFO:root:Train (Epoch 88): Loss/seq after 00250 batchs: 1029.920166015625
INFO:root:Train (Epoch 88): Loss/seq after 00300 batchs: 1010.2189331054688
INFO:root:Train (Epoch 88): Loss/seq after 00350 batchs: 938.99365234375
INFO:root:Train (Epoch 88): Loss/seq after 00400 batchs: 948.2277221679688
INFO:root:Train (Epoch 88): Loss/seq after 00450 batchs: 920.0818481445312
INFO:root:Train (Epoch 88): Loss/seq after 00500 batchs: 893.4569091796875
INFO:root:Train (Epoch 88): Loss/seq after 00550 batchs: 862.131591796875
INFO:root:Train (Epoch 88): Loss/seq after 00600 batchs: 831.2314453125
INFO:root:Train (Epoch 88): Loss/seq after 00650 batchs: 826.2979736328125
INFO:root:Train (Epoch 88): Loss/seq after 00700 batchs: 810.3515625
INFO:root:Train (Epoch 88): Loss/seq after 00750 batchs: 823.2805786132812
INFO:root:Train (Epoch 88): Loss/seq after 00800 batchs: 822.77783203125
INFO:root:Train (Epoch 88): Loss/seq after 00850 batchs: 796.8165893554688
INFO:root:Train (Epoch 88): Loss/seq after 00900 batchs: 781.5657348632812
INFO:root:Train (Epoch 88): Loss/seq after 00950 batchs: 786.132568359375
INFO:root:Train (Epoch 88): Loss/seq after 01000 batchs: 777.6038818359375
INFO:root:Train (Epoch 88): Loss/seq after 01050 batchs: 764.1100463867188
INFO:root:Train (Epoch 88): Loss/seq after 01100 batchs: 752.0001831054688
INFO:root:Train (Epoch 88): Loss/seq after 01150 batchs: 733.9552001953125
INFO:root:Train (Epoch 88): Loss/seq after 01200 batchs: 735.0262451171875
INFO:root:Train (Epoch 88): Loss/seq after 01250 batchs: 730.8509521484375
INFO:root:Train (Epoch 88): Loss/seq after 01300 batchs: 720.952880859375
INFO:root:Train (Epoch 88): Loss/seq after 01350 batchs: 712.1985473632812
INFO:root:Train (Epoch 88): Loss/seq after 01400 batchs: 722.7728881835938
INFO:root:Train (Epoch 88): Loss/seq after 01450 batchs: 721.927978515625
INFO:root:Train (Epoch 88): Loss/seq after 01500 batchs: 725.3580932617188
INFO:root:Train (Epoch 88): Loss/seq after 01550 batchs: 727.2638549804688
INFO:root:Train (Epoch 88): Loss/seq after 01600 batchs: 719.8027954101562
INFO:root:Train (Epoch 88): Loss/seq after 01650 batchs: 716.2394409179688
INFO:root:Train (Epoch 88): Loss/seq after 01700 batchs: 715.9393310546875
INFO:root:Train (Epoch 88): Loss/seq after 01750 batchs: 711.3327026367188
INFO:root:Train (Epoch 88): Loss/seq after 01800 batchs: 706.478759765625
INFO:root:Train (Epoch 88): Loss/seq after 01850 batchs: 700.8729858398438
INFO:root:Train (Epoch 88): Loss/seq after 01900 batchs: 700.5524291992188
INFO:root:Train (Epoch 88): Loss/seq after 01950 batchs: 697.0498046875
INFO:root:Train (Epoch 88): Loss/seq after 02000 batchs: 693.7498779296875
INFO:root:Train (Epoch 88): Loss/seq after 02050 batchs: 690.8761596679688
INFO:root:Train (Epoch 88): Loss/seq after 02100 batchs: 686.4014282226562
INFO:root:Train (Epoch 88): Loss/seq after 02150 batchs: 683.0841674804688
INFO:root:Train (Epoch 88): Loss/seq after 02200 batchs: 678.4542846679688
INFO:root:Train (Epoch 88): Loss/seq after 02250 batchs: 677.378173828125
INFO:root:Train (Epoch 88): Loss/seq after 02300 batchs: 678.020751953125
INFO:root:Train (Epoch 88): Loss/seq after 02350 batchs: 672.9913330078125
INFO:root:Train (Epoch 88): Loss/seq after 02400 batchs: 672.9977416992188
INFO:root:Train (Epoch 88): Loss/seq after 02450 batchs: 666.741455078125
INFO:root:Train (Epoch 88): Loss/seq after 02500 batchs: 656.7264404296875
INFO:root:Train (Epoch 88): Loss/seq after 02550 batchs: 649.3841552734375
INFO:root:Train (Epoch 88): Loss/seq after 02600 batchs: 648.0398559570312
INFO:root:Train (Epoch 88): Loss/seq after 02650 batchs: 645.355712890625
INFO:root:Train (Epoch 88): Loss/seq after 02700 batchs: 642.7986450195312
INFO:root:Train (Epoch 88): Loss/seq after 02750 batchs: 651.560546875
INFO:root:Train (Epoch 88): Loss/seq after 02800 batchs: 654.728515625
INFO:root:Train (Epoch 88): Loss/seq after 02850 batchs: 654.4312133789062
INFO:root:Train (Epoch 88): Loss/seq after 02900 batchs: 655.4661254882812
INFO:root:Train (Epoch 88): Loss/seq after 02950 batchs: 653.2595825195312
INFO:root:Train (Epoch 88): Loss/seq after 03000 batchs: 657.0763549804688
INFO:root:Train (Epoch 88): Loss/seq after 03050 batchs: 660.3175659179688
INFO:root:Train (Epoch 88): Loss/seq after 03100 batchs: 665.157470703125
INFO:root:Train (Epoch 88): Loss/seq after 03150 batchs: 672.4573364257812
INFO:root:Train (Epoch 88): Loss/seq after 03200 batchs: 677.1315307617188
INFO:root:Train (Epoch 88): Loss/seq after 03250 batchs: 681.9669799804688
INFO:root:Train (Epoch 88): Loss/seq after 03300 batchs: 682.0567626953125
INFO:root:Train (Epoch 88): Loss/seq after 03350 batchs: 682.4302978515625
INFO:root:Train (Epoch 88): Loss/seq after 03400 batchs: 676.9252319335938
INFO:root:Train (Epoch 88): Loss/seq after 03450 batchs: 674.3097534179688
INFO:root:Train (Epoch 88): Loss/seq after 03500 batchs: 674.6748657226562
INFO:root:Train (Epoch 88): Loss/seq after 03550 batchs: 670.9293823242188
INFO:root:Train (Epoch 88): Loss/seq after 03600 batchs: 679.0584106445312
INFO:root:Train (Epoch 88): Loss/seq after 03650 batchs: 675.5614013671875
INFO:root:Train (Epoch 88): Loss/seq after 03700 batchs: 677.4300537109375
INFO:root:Train (Epoch 88): Loss/seq after 03750 batchs: 681.4024047851562
INFO:root:Train (Epoch 88): Loss/seq after 03800 batchs: 677.82470703125
INFO:root:Train (Epoch 88): Loss/seq after 03850 batchs: 676.48828125
INFO:root:Train (Epoch 88): Loss/seq after 03900 batchs: 681.4514770507812
INFO:root:Train (Epoch 88): Loss/seq after 03950 batchs: 685.5215454101562
INFO:root:Train (Epoch 88): Loss/seq after 04000 batchs: 680.80322265625
INFO:root:Train (Epoch 88): Loss/seq after 04050 batchs: 676.1319580078125
INFO:root:Train (Epoch 88): Loss/seq after 04100 batchs: 673.5621948242188
INFO:root:Train (Epoch 88): Loss/seq after 04150 batchs: 672.4526977539062
INFO:root:Train (Epoch 88): Loss/seq after 04200 batchs: 670.189208984375
INFO:root:Train (Epoch 88): Loss/seq after 04250 batchs: 667.9456176757812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 88): Loss/seq after 00000 batches: 542.355224609375
INFO:root:# Valid (Epoch 88): Loss/seq after 00050 batches: 673.6735229492188
INFO:root:# Valid (Epoch 88): Loss/seq after 00100 batches: 813.0214233398438
INFO:root:# Valid (Epoch 88): Loss/seq after 00150 batches: 614.0068969726562
INFO:root:# Valid (Epoch 88): Loss/seq after 00200 batches: 569.5645751953125
INFO:root:Artifacts: Make stick videos for epoch 88
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_88_on_20220413_022504.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_88_index_356_on_20220413_022504.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 89): Loss/seq after 00000 batchs: 1326.5869140625
INFO:root:Train (Epoch 89): Loss/seq after 00050 batchs: 895.9676513671875
INFO:root:Train (Epoch 89): Loss/seq after 00100 batchs: 929.0078735351562
INFO:root:Train (Epoch 89): Loss/seq after 00150 batchs: 833.7195434570312
INFO:root:Train (Epoch 89): Loss/seq after 00200 batchs: 912.8475952148438
INFO:root:Train (Epoch 89): Loss/seq after 00250 batchs: 1034.9915771484375
INFO:root:Train (Epoch 89): Loss/seq after 00300 batchs: 1014.5576782226562
INFO:root:Train (Epoch 89): Loss/seq after 00350 batchs: 942.2437744140625
INFO:root:Train (Epoch 89): Loss/seq after 00400 batchs: 954.7828369140625
INFO:root:Train (Epoch 89): Loss/seq after 00450 batchs: 925.6598510742188
INFO:root:Train (Epoch 89): Loss/seq after 00500 batchs: 898.9463500976562
INFO:root:Train (Epoch 89): Loss/seq after 00550 batchs: 867.737548828125
INFO:root:Train (Epoch 89): Loss/seq after 00600 batchs: 835.6072387695312
INFO:root:Train (Epoch 89): Loss/seq after 00650 batchs: 828.9189453125
INFO:root:Train (Epoch 89): Loss/seq after 00700 batchs: 810.4602661132812
INFO:root:Train (Epoch 89): Loss/seq after 00750 batchs: 823.600830078125
INFO:root:Train (Epoch 89): Loss/seq after 00800 batchs: 822.1348266601562
INFO:root:Train (Epoch 89): Loss/seq after 00850 batchs: 795.6004028320312
INFO:root:Train (Epoch 89): Loss/seq after 00900 batchs: 780.7349853515625
INFO:root:Train (Epoch 89): Loss/seq after 00950 batchs: 785.6090087890625
INFO:root:Train (Epoch 89): Loss/seq after 01000 batchs: 776.5706176757812
INFO:root:Train (Epoch 89): Loss/seq after 01050 batchs: 763.4450073242188
INFO:root:Train (Epoch 89): Loss/seq after 01100 batchs: 751.9453735351562
INFO:root:Train (Epoch 89): Loss/seq after 01150 batchs: 734.125244140625
INFO:root:Train (Epoch 89): Loss/seq after 01200 batchs: 735.432861328125
INFO:root:Train (Epoch 89): Loss/seq after 01250 batchs: 730.6441040039062
INFO:root:Train (Epoch 89): Loss/seq after 01300 batchs: 720.0484619140625
INFO:root:Train (Epoch 89): Loss/seq after 01350 batchs: 711.024169921875
INFO:root:Train (Epoch 89): Loss/seq after 01400 batchs: 722.1865844726562
INFO:root:Train (Epoch 89): Loss/seq after 01450 batchs: 721.3888549804688
INFO:root:Train (Epoch 89): Loss/seq after 01500 batchs: 725.0155029296875
INFO:root:Train (Epoch 89): Loss/seq after 01550 batchs: 726.4203491210938
INFO:root:Train (Epoch 89): Loss/seq after 01600 batchs: 718.8082275390625
INFO:root:Train (Epoch 89): Loss/seq after 01650 batchs: 714.9480590820312
INFO:root:Train (Epoch 89): Loss/seq after 01700 batchs: 714.6649780273438
INFO:root:Train (Epoch 89): Loss/seq after 01750 batchs: 710.1295776367188
INFO:root:Train (Epoch 89): Loss/seq after 01800 batchs: 705.3992309570312
INFO:root:Train (Epoch 89): Loss/seq after 01850 batchs: 699.5943603515625
INFO:root:Train (Epoch 89): Loss/seq after 01900 batchs: 699.1224975585938
INFO:root:Train (Epoch 89): Loss/seq after 01950 batchs: 695.7721557617188
INFO:root:Train (Epoch 89): Loss/seq after 02000 batchs: 692.443603515625
INFO:root:Train (Epoch 89): Loss/seq after 02050 batchs: 689.3628540039062
INFO:root:Train (Epoch 89): Loss/seq after 02100 batchs: 684.859375
INFO:root:Train (Epoch 89): Loss/seq after 02150 batchs: 681.4786987304688
INFO:root:Train (Epoch 89): Loss/seq after 02200 batchs: 676.902099609375
INFO:root:Train (Epoch 89): Loss/seq after 02250 batchs: 675.9668579101562
INFO:root:Train (Epoch 89): Loss/seq after 02300 batchs: 675.5181274414062
INFO:root:Train (Epoch 89): Loss/seq after 02350 batchs: 669.8681640625
INFO:root:Train (Epoch 89): Loss/seq after 02400 batchs: 669.8553466796875
INFO:root:Train (Epoch 89): Loss/seq after 02450 batchs: 663.6021118164062
INFO:root:Train (Epoch 89): Loss/seq after 02500 batchs: 653.636474609375
INFO:root:Train (Epoch 89): Loss/seq after 02550 batchs: 646.5120239257812
INFO:root:Train (Epoch 89): Loss/seq after 02600 batchs: 645.45458984375
INFO:root:Train (Epoch 89): Loss/seq after 02650 batchs: 642.9387817382812
INFO:root:Train (Epoch 89): Loss/seq after 02700 batchs: 640.39453125
INFO:root:Train (Epoch 89): Loss/seq after 02750 batchs: 647.4677734375
INFO:root:Train (Epoch 89): Loss/seq after 02800 batchs: 650.4124755859375
INFO:root:Train (Epoch 89): Loss/seq after 02850 batchs: 650.2378540039062
INFO:root:Train (Epoch 89): Loss/seq after 02900 batchs: 651.2564086914062
INFO:root:Train (Epoch 89): Loss/seq after 02950 batchs: 649.1812744140625
INFO:root:Train (Epoch 89): Loss/seq after 03000 batchs: 653.0536499023438
INFO:root:Train (Epoch 89): Loss/seq after 03050 batchs: 656.5281982421875
INFO:root:Train (Epoch 89): Loss/seq after 03100 batchs: 660.9064331054688
INFO:root:Train (Epoch 89): Loss/seq after 03150 batchs: 667.2452392578125
INFO:root:Train (Epoch 89): Loss/seq after 03200 batchs: 672.0381469726562
INFO:root:Train (Epoch 89): Loss/seq after 03250 batchs: 676.652099609375
INFO:root:Train (Epoch 89): Loss/seq after 03300 batchs: 675.2861328125
INFO:root:Train (Epoch 89): Loss/seq after 03350 batchs: 675.0247192382812
INFO:root:Train (Epoch 89): Loss/seq after 03400 batchs: 669.5167846679688
INFO:root:Train (Epoch 89): Loss/seq after 03450 batchs: 666.8585815429688
INFO:root:Train (Epoch 89): Loss/seq after 03500 batchs: 666.7774658203125
INFO:root:Train (Epoch 89): Loss/seq after 03550 batchs: 662.9750366210938
INFO:root:Train (Epoch 89): Loss/seq after 03600 batchs: 670.961181640625
INFO:root:Train (Epoch 89): Loss/seq after 03650 batchs: 667.4210205078125
INFO:root:Train (Epoch 89): Loss/seq after 03700 batchs: 669.2838745117188
INFO:root:Train (Epoch 89): Loss/seq after 03750 batchs: 673.4215698242188
INFO:root:Train (Epoch 89): Loss/seq after 03800 batchs: 669.9181518554688
INFO:root:Train (Epoch 89): Loss/seq after 03850 batchs: 668.4903564453125
INFO:root:Train (Epoch 89): Loss/seq after 03900 batchs: 673.6597290039062
INFO:root:Train (Epoch 89): Loss/seq after 03950 batchs: 677.604736328125
INFO:root:Train (Epoch 89): Loss/seq after 04000 batchs: 672.9236450195312
INFO:root:Train (Epoch 89): Loss/seq after 04050 batchs: 668.3511352539062
INFO:root:Train (Epoch 89): Loss/seq after 04100 batchs: 665.7001953125
INFO:root:Train (Epoch 89): Loss/seq after 04150 batchs: 664.65771484375
INFO:root:Train (Epoch 89): Loss/seq after 04200 batchs: 662.4009399414062
INFO:root:Train (Epoch 89): Loss/seq after 04250 batchs: 660.203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 89): Loss/seq after 00000 batches: 545.07080078125
INFO:root:# Valid (Epoch 89): Loss/seq after 00050 batches: 701.146240234375
INFO:root:# Valid (Epoch 89): Loss/seq after 00100 batches: 794.9609985351562
INFO:root:# Valid (Epoch 89): Loss/seq after 00150 batches: 602.0545654296875
INFO:root:# Valid (Epoch 89): Loss/seq after 00200 batches: 559.2064819335938
INFO:root:Artifacts: Make stick videos for epoch 89
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_89_on_20220413_023025.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_89_index_200_on_20220413_023025.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 90): Loss/seq after 00000 batchs: 1152.4775390625
INFO:root:Train (Epoch 90): Loss/seq after 00050 batchs: 888.8165893554688
INFO:root:Train (Epoch 90): Loss/seq after 00100 batchs: 908.1422119140625
INFO:root:Train (Epoch 90): Loss/seq after 00150 batchs: 819.6849365234375
INFO:root:Train (Epoch 90): Loss/seq after 00200 batchs: 893.9107666015625
INFO:root:Train (Epoch 90): Loss/seq after 00250 batchs: 1013.0479125976562
INFO:root:Train (Epoch 90): Loss/seq after 00300 batchs: 995.9033203125
INFO:root:Train (Epoch 90): Loss/seq after 00350 batchs: 926.6920166015625
INFO:root:Train (Epoch 90): Loss/seq after 00400 batchs: 938.5254516601562
INFO:root:Train (Epoch 90): Loss/seq after 00450 batchs: 911.1820068359375
INFO:root:Train (Epoch 90): Loss/seq after 00500 batchs: 883.3955688476562
INFO:root:Train (Epoch 90): Loss/seq after 00550 batchs: 852.680908203125
INFO:root:Train (Epoch 90): Loss/seq after 00600 batchs: 821.5831909179688
INFO:root:Train (Epoch 90): Loss/seq after 00650 batchs: 813.6521606445312
INFO:root:Train (Epoch 90): Loss/seq after 00700 batchs: 793.0005493164062
INFO:root:Train (Epoch 90): Loss/seq after 00750 batchs: 806.109130859375
INFO:root:Train (Epoch 90): Loss/seq after 00800 batchs: 805.1550903320312
INFO:root:Train (Epoch 90): Loss/seq after 00850 batchs: 780.2440795898438
INFO:root:Train (Epoch 90): Loss/seq after 00900 batchs: 765.6488037109375
INFO:root:Train (Epoch 90): Loss/seq after 00950 batchs: 771.5111694335938
INFO:root:Train (Epoch 90): Loss/seq after 01000 batchs: 765.05419921875
INFO:root:Train (Epoch 90): Loss/seq after 01050 batchs: 753.9935913085938
INFO:root:Train (Epoch 90): Loss/seq after 01100 batchs: 743.3720092773438
INFO:root:Train (Epoch 90): Loss/seq after 01150 batchs: 725.9927978515625
INFO:root:Train (Epoch 90): Loss/seq after 01200 batchs: 727.7727661132812
INFO:root:Train (Epoch 90): Loss/seq after 01250 batchs: 723.36279296875
INFO:root:Train (Epoch 90): Loss/seq after 01300 batchs: 712.3695678710938
INFO:root:Train (Epoch 90): Loss/seq after 01350 batchs: 702.8914184570312
INFO:root:Train (Epoch 90): Loss/seq after 01400 batchs: 713.071533203125
INFO:root:Train (Epoch 90): Loss/seq after 01450 batchs: 712.9720458984375
INFO:root:Train (Epoch 90): Loss/seq after 01500 batchs: 716.8174438476562
INFO:root:Train (Epoch 90): Loss/seq after 01550 batchs: 718.3916625976562
INFO:root:Train (Epoch 90): Loss/seq after 01600 batchs: 710.87890625
INFO:root:Train (Epoch 90): Loss/seq after 01650 batchs: 707.1360473632812
INFO:root:Train (Epoch 90): Loss/seq after 01700 batchs: 706.9866943359375
INFO:root:Train (Epoch 90): Loss/seq after 01750 batchs: 702.60302734375
INFO:root:Train (Epoch 90): Loss/seq after 01800 batchs: 697.9744873046875
INFO:root:Train (Epoch 90): Loss/seq after 01850 batchs: 692.2348022460938
INFO:root:Train (Epoch 90): Loss/seq after 01900 batchs: 691.66455078125
INFO:root:Train (Epoch 90): Loss/seq after 01950 batchs: 688.3284912109375
INFO:root:Train (Epoch 90): Loss/seq after 02000 batchs: 685.1437377929688
INFO:root:Train (Epoch 90): Loss/seq after 02050 batchs: 682.2028198242188
INFO:root:Train (Epoch 90): Loss/seq after 02100 batchs: 677.8814697265625
INFO:root:Train (Epoch 90): Loss/seq after 02150 batchs: 674.625732421875
INFO:root:Train (Epoch 90): Loss/seq after 02200 batchs: 670.22119140625
INFO:root:Train (Epoch 90): Loss/seq after 02250 batchs: 668.650634765625
INFO:root:Train (Epoch 90): Loss/seq after 02300 batchs: 667.6136474609375
INFO:root:Train (Epoch 90): Loss/seq after 02350 batchs: 662.0861206054688
INFO:root:Train (Epoch 90): Loss/seq after 02400 batchs: 662.2670288085938
INFO:root:Train (Epoch 90): Loss/seq after 02450 batchs: 656.1027221679688
INFO:root:Train (Epoch 90): Loss/seq after 02500 batchs: 646.253173828125
INFO:root:Train (Epoch 90): Loss/seq after 02550 batchs: 639.062744140625
INFO:root:Train (Epoch 90): Loss/seq after 02600 batchs: 637.9666748046875
INFO:root:Train (Epoch 90): Loss/seq after 02650 batchs: 635.4117431640625
INFO:root:Train (Epoch 90): Loss/seq after 02700 batchs: 632.7942504882812
INFO:root:Train (Epoch 90): Loss/seq after 02750 batchs: 638.4923706054688
INFO:root:Train (Epoch 90): Loss/seq after 02800 batchs: 641.4003295898438
INFO:root:Train (Epoch 90): Loss/seq after 02850 batchs: 641.1732177734375
INFO:root:Train (Epoch 90): Loss/seq after 02900 batchs: 642.5693359375
INFO:root:Train (Epoch 90): Loss/seq after 02950 batchs: 640.6207275390625
INFO:root:Train (Epoch 90): Loss/seq after 03000 batchs: 644.6019287109375
INFO:root:Train (Epoch 90): Loss/seq after 03050 batchs: 647.7333374023438
INFO:root:Train (Epoch 90): Loss/seq after 03100 batchs: 652.3908081054688
INFO:root:Train (Epoch 90): Loss/seq after 03150 batchs: 658.6543579101562
INFO:root:Train (Epoch 90): Loss/seq after 03200 batchs: 663.55029296875
INFO:root:Train (Epoch 90): Loss/seq after 03250 batchs: 668.1869506835938
INFO:root:Train (Epoch 90): Loss/seq after 03300 batchs: 667.0633544921875
INFO:root:Train (Epoch 90): Loss/seq after 03350 batchs: 667.1513061523438
INFO:root:Train (Epoch 90): Loss/seq after 03400 batchs: 661.7227783203125
INFO:root:Train (Epoch 90): Loss/seq after 03450 batchs: 659.160400390625
INFO:root:Train (Epoch 90): Loss/seq after 03500 batchs: 659.2843627929688
INFO:root:Train (Epoch 90): Loss/seq after 03550 batchs: 655.6913452148438
INFO:root:Train (Epoch 90): Loss/seq after 03600 batchs: 663.886474609375
INFO:root:Train (Epoch 90): Loss/seq after 03650 batchs: 660.457275390625
INFO:root:Train (Epoch 90): Loss/seq after 03700 batchs: 662.2355346679688
INFO:root:Train (Epoch 90): Loss/seq after 03750 batchs: 666.4702758789062
INFO:root:Train (Epoch 90): Loss/seq after 03800 batchs: 663.0753173828125
INFO:root:Train (Epoch 90): Loss/seq after 03850 batchs: 661.86474609375
INFO:root:Train (Epoch 90): Loss/seq after 03900 batchs: 666.8646850585938
INFO:root:Train (Epoch 90): Loss/seq after 03950 batchs: 670.5562133789062
INFO:root:Train (Epoch 90): Loss/seq after 04000 batchs: 666.00732421875
INFO:root:Train (Epoch 90): Loss/seq after 04050 batchs: 661.5662841796875
INFO:root:Train (Epoch 90): Loss/seq after 04100 batchs: 659.0947265625
INFO:root:Train (Epoch 90): Loss/seq after 04150 batchs: 658.1669311523438
INFO:root:Train (Epoch 90): Loss/seq after 04200 batchs: 656.04931640625
INFO:root:Train (Epoch 90): Loss/seq after 04250 batchs: 653.8165893554688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 90): Loss/seq after 00000 batches: 608.1428833007812
INFO:root:# Valid (Epoch 90): Loss/seq after 00050 batches: 709.1810913085938
INFO:root:# Valid (Epoch 90): Loss/seq after 00100 batches: 823.0752563476562
INFO:root:# Valid (Epoch 90): Loss/seq after 00150 batches: 622.3380126953125
INFO:root:# Valid (Epoch 90): Loss/seq after 00200 batches: 575.1207885742188
INFO:root:Artifacts: Make stick videos for epoch 90
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_90_on_20220413_023544.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_90_index_692_on_20220413_023544.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 91): Loss/seq after 00000 batchs: 1305.8702392578125
INFO:root:Train (Epoch 91): Loss/seq after 00050 batchs: 900.147216796875
INFO:root:Train (Epoch 91): Loss/seq after 00100 batchs: 911.6588134765625
INFO:root:Train (Epoch 91): Loss/seq after 00150 batchs: 826.8507690429688
INFO:root:Train (Epoch 91): Loss/seq after 00200 batchs: 902.0869140625
INFO:root:Train (Epoch 91): Loss/seq after 00250 batchs: 1017.19482421875
INFO:root:Train (Epoch 91): Loss/seq after 00300 batchs: 999.8572998046875
INFO:root:Train (Epoch 91): Loss/seq after 00350 batchs: 930.5032958984375
INFO:root:Train (Epoch 91): Loss/seq after 00400 batchs: 939.3101806640625
INFO:root:Train (Epoch 91): Loss/seq after 00450 batchs: 912.2577514648438
INFO:root:Train (Epoch 91): Loss/seq after 00500 batchs: 886.5949096679688
INFO:root:Train (Epoch 91): Loss/seq after 00550 batchs: 855.3452758789062
INFO:root:Train (Epoch 91): Loss/seq after 00600 batchs: 823.9962768554688
INFO:root:Train (Epoch 91): Loss/seq after 00650 batchs: 812.4857788085938
INFO:root:Train (Epoch 91): Loss/seq after 00700 batchs: 794.9611206054688
INFO:root:Train (Epoch 91): Loss/seq after 00750 batchs: 806.3159790039062
INFO:root:Train (Epoch 91): Loss/seq after 00800 batchs: 805.0924682617188
INFO:root:Train (Epoch 91): Loss/seq after 00850 batchs: 779.5814819335938
INFO:root:Train (Epoch 91): Loss/seq after 00900 batchs: 764.8613891601562
INFO:root:Train (Epoch 91): Loss/seq after 00950 batchs: 768.087646484375
INFO:root:Train (Epoch 91): Loss/seq after 01000 batchs: 760.0140991210938
INFO:root:Train (Epoch 91): Loss/seq after 01050 batchs: 747.2349243164062
INFO:root:Train (Epoch 91): Loss/seq after 01100 batchs: 736.0863037109375
INFO:root:Train (Epoch 91): Loss/seq after 01150 batchs: 718.4874267578125
INFO:root:Train (Epoch 91): Loss/seq after 01200 batchs: 720.2706298828125
INFO:root:Train (Epoch 91): Loss/seq after 01250 batchs: 716.2114868164062
INFO:root:Train (Epoch 91): Loss/seq after 01300 batchs: 705.5408325195312
INFO:root:Train (Epoch 91): Loss/seq after 01350 batchs: 696.3432006835938
INFO:root:Train (Epoch 91): Loss/seq after 01400 batchs: 705.80078125
INFO:root:Train (Epoch 91): Loss/seq after 01450 batchs: 705.2140502929688
INFO:root:Train (Epoch 91): Loss/seq after 01500 batchs: 709.2523193359375
INFO:root:Train (Epoch 91): Loss/seq after 01550 batchs: 710.7421875
INFO:root:Train (Epoch 91): Loss/seq after 01600 batchs: 703.3366088867188
INFO:root:Train (Epoch 91): Loss/seq after 01650 batchs: 699.8820190429688
INFO:root:Train (Epoch 91): Loss/seq after 01700 batchs: 700.16650390625
INFO:root:Train (Epoch 91): Loss/seq after 01750 batchs: 695.82275390625
INFO:root:Train (Epoch 91): Loss/seq after 01800 batchs: 691.336669921875
INFO:root:Train (Epoch 91): Loss/seq after 01850 batchs: 685.97314453125
INFO:root:Train (Epoch 91): Loss/seq after 01900 batchs: 685.7782592773438
INFO:root:Train (Epoch 91): Loss/seq after 01950 batchs: 682.8200073242188
INFO:root:Train (Epoch 91): Loss/seq after 02000 batchs: 679.8019409179688
INFO:root:Train (Epoch 91): Loss/seq after 02050 batchs: 676.9368286132812
INFO:root:Train (Epoch 91): Loss/seq after 02100 batchs: 672.6686401367188
INFO:root:Train (Epoch 91): Loss/seq after 02150 batchs: 669.4218139648438
INFO:root:Train (Epoch 91): Loss/seq after 02200 batchs: 665.0042724609375
INFO:root:Train (Epoch 91): Loss/seq after 02250 batchs: 663.8413696289062
INFO:root:Train (Epoch 91): Loss/seq after 02300 batchs: 663.36181640625
INFO:root:Train (Epoch 91): Loss/seq after 02350 batchs: 657.7682495117188
INFO:root:Train (Epoch 91): Loss/seq after 02400 batchs: 657.9674072265625
INFO:root:Train (Epoch 91): Loss/seq after 02450 batchs: 651.9185791015625
INFO:root:Train (Epoch 91): Loss/seq after 02500 batchs: 642.150146484375
INFO:root:Train (Epoch 91): Loss/seq after 02550 batchs: 635.2201538085938
INFO:root:Train (Epoch 91): Loss/seq after 02600 batchs: 634.2363891601562
INFO:root:Train (Epoch 91): Loss/seq after 02650 batchs: 631.9854125976562
INFO:root:Train (Epoch 91): Loss/seq after 02700 batchs: 629.4981079101562
INFO:root:Train (Epoch 91): Loss/seq after 02750 batchs: 634.4938354492188
INFO:root:Train (Epoch 91): Loss/seq after 02800 batchs: 637.8142700195312
INFO:root:Train (Epoch 91): Loss/seq after 02850 batchs: 637.8114624023438
INFO:root:Train (Epoch 91): Loss/seq after 02900 batchs: 639.0831298828125
INFO:root:Train (Epoch 91): Loss/seq after 02950 batchs: 637.4085083007812
INFO:root:Train (Epoch 91): Loss/seq after 03000 batchs: 641.4785766601562
INFO:root:Train (Epoch 91): Loss/seq after 03050 batchs: 644.564208984375
INFO:root:Train (Epoch 91): Loss/seq after 03100 batchs: 649.3460083007812
INFO:root:Train (Epoch 91): Loss/seq after 03150 batchs: 655.5443725585938
INFO:root:Train (Epoch 91): Loss/seq after 03200 batchs: 660.1248168945312
INFO:root:Train (Epoch 91): Loss/seq after 03250 batchs: 664.7222290039062
INFO:root:Train (Epoch 91): Loss/seq after 03300 batchs: 663.5042114257812
INFO:root:Train (Epoch 91): Loss/seq after 03350 batchs: 663.5438232421875
INFO:root:Train (Epoch 91): Loss/seq after 03400 batchs: 658.2017211914062
INFO:root:Train (Epoch 91): Loss/seq after 03450 batchs: 655.6764526367188
INFO:root:Train (Epoch 91): Loss/seq after 03500 batchs: 655.6266479492188
INFO:root:Train (Epoch 91): Loss/seq after 03550 batchs: 652.28466796875
INFO:root:Train (Epoch 91): Loss/seq after 03600 batchs: 660.4830322265625
INFO:root:Train (Epoch 91): Loss/seq after 03650 batchs: 657.103271484375
INFO:root:Train (Epoch 91): Loss/seq after 03700 batchs: 658.6964111328125
INFO:root:Train (Epoch 91): Loss/seq after 03750 batchs: 662.949462890625
INFO:root:Train (Epoch 91): Loss/seq after 03800 batchs: 659.6429443359375
INFO:root:Train (Epoch 91): Loss/seq after 03850 batchs: 658.4332885742188
INFO:root:Train (Epoch 91): Loss/seq after 03900 batchs: 663.30615234375
INFO:root:Train (Epoch 91): Loss/seq after 03950 batchs: 667.3977661132812
INFO:root:Train (Epoch 91): Loss/seq after 04000 batchs: 662.8847045898438
INFO:root:Train (Epoch 91): Loss/seq after 04050 batchs: 658.40869140625
INFO:root:Train (Epoch 91): Loss/seq after 04100 batchs: 655.79931640625
INFO:root:Train (Epoch 91): Loss/seq after 04150 batchs: 654.8251342773438
INFO:root:Train (Epoch 91): Loss/seq after 04200 batchs: 652.5786743164062
INFO:root:Train (Epoch 91): Loss/seq after 04250 batchs: 650.4676513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 91): Loss/seq after 00000 batches: 539.8079833984375
INFO:root:# Valid (Epoch 91): Loss/seq after 00050 batches: 716.4574584960938
INFO:root:# Valid (Epoch 91): Loss/seq after 00100 batches: 829.7115478515625
INFO:root:# Valid (Epoch 91): Loss/seq after 00150 batches: 627.2661743164062
INFO:root:# Valid (Epoch 91): Loss/seq after 00200 batches: 579.7930297851562
INFO:root:Artifacts: Make stick videos for epoch 91
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_91_on_20220413_024106.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_91_index_1458_on_20220413_024106.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 92): Loss/seq after 00000 batchs: 1154.571044921875
INFO:root:Train (Epoch 92): Loss/seq after 00050 batchs: 881.0532836914062
INFO:root:Train (Epoch 92): Loss/seq after 00100 batchs: 908.57958984375
INFO:root:Train (Epoch 92): Loss/seq after 00150 batchs: 822.9848022460938
INFO:root:Train (Epoch 92): Loss/seq after 00200 batchs: 896.6876220703125
INFO:root:Train (Epoch 92): Loss/seq after 00250 batchs: 1011.7633056640625
INFO:root:Train (Epoch 92): Loss/seq after 00300 batchs: 995.091552734375
INFO:root:Train (Epoch 92): Loss/seq after 00350 batchs: 925.1259155273438
INFO:root:Train (Epoch 92): Loss/seq after 00400 batchs: 929.80615234375
INFO:root:Train (Epoch 92): Loss/seq after 00450 batchs: 903.1795043945312
INFO:root:Train (Epoch 92): Loss/seq after 00500 batchs: 876.5869750976562
INFO:root:Train (Epoch 92): Loss/seq after 00550 batchs: 846.2146606445312
INFO:root:Train (Epoch 92): Loss/seq after 00600 batchs: 815.3128662109375
INFO:root:Train (Epoch 92): Loss/seq after 00650 batchs: 801.5118408203125
INFO:root:Train (Epoch 92): Loss/seq after 00700 batchs: 782.6185913085938
INFO:root:Train (Epoch 92): Loss/seq after 00750 batchs: 793.5905151367188
INFO:root:Train (Epoch 92): Loss/seq after 00800 batchs: 793.518798828125
INFO:root:Train (Epoch 92): Loss/seq after 00850 batchs: 768.4190673828125
INFO:root:Train (Epoch 92): Loss/seq after 00900 batchs: 753.5892944335938
INFO:root:Train (Epoch 92): Loss/seq after 00950 batchs: 755.7119750976562
INFO:root:Train (Epoch 92): Loss/seq after 01000 batchs: 747.1085205078125
INFO:root:Train (Epoch 92): Loss/seq after 01050 batchs: 734.0437622070312
INFO:root:Train (Epoch 92): Loss/seq after 01100 batchs: 722.5300903320312
INFO:root:Train (Epoch 92): Loss/seq after 01150 batchs: 705.4125366210938
INFO:root:Train (Epoch 92): Loss/seq after 01200 batchs: 707.635009765625
INFO:root:Train (Epoch 92): Loss/seq after 01250 batchs: 703.5433349609375
INFO:root:Train (Epoch 92): Loss/seq after 01300 batchs: 692.6939697265625
INFO:root:Train (Epoch 92): Loss/seq after 01350 batchs: 683.1884155273438
INFO:root:Train (Epoch 92): Loss/seq after 01400 batchs: 692.6787109375
INFO:root:Train (Epoch 92): Loss/seq after 01450 batchs: 692.6295776367188
INFO:root:Train (Epoch 92): Loss/seq after 01500 batchs: 697.0136108398438
INFO:root:Train (Epoch 92): Loss/seq after 01550 batchs: 698.5372924804688
INFO:root:Train (Epoch 92): Loss/seq after 01600 batchs: 691.7055053710938
INFO:root:Train (Epoch 92): Loss/seq after 01650 batchs: 688.3695068359375
INFO:root:Train (Epoch 92): Loss/seq after 01700 batchs: 688.8553466796875
INFO:root:Train (Epoch 92): Loss/seq after 01750 batchs: 684.8671875
INFO:root:Train (Epoch 92): Loss/seq after 01800 batchs: 680.5841064453125
INFO:root:Train (Epoch 92): Loss/seq after 01850 batchs: 675.406494140625
INFO:root:Train (Epoch 92): Loss/seq after 01900 batchs: 675.2662963867188
INFO:root:Train (Epoch 92): Loss/seq after 01950 batchs: 672.3211669921875
INFO:root:Train (Epoch 92): Loss/seq after 02000 batchs: 669.2914428710938
INFO:root:Train (Epoch 92): Loss/seq after 02050 batchs: 666.6494750976562
INFO:root:Train (Epoch 92): Loss/seq after 02100 batchs: 662.687744140625
INFO:root:Train (Epoch 92): Loss/seq after 02150 batchs: 659.6783447265625
INFO:root:Train (Epoch 92): Loss/seq after 02200 batchs: 655.6021118164062
INFO:root:Train (Epoch 92): Loss/seq after 02250 batchs: 654.2083740234375
INFO:root:Train (Epoch 92): Loss/seq after 02300 batchs: 653.009765625
INFO:root:Train (Epoch 92): Loss/seq after 02350 batchs: 647.5269775390625
INFO:root:Train (Epoch 92): Loss/seq after 02400 batchs: 647.984619140625
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 92): Loss/seq after 02450 batchs: 642.1690063476562
INFO:root:Train (Epoch 92): Loss/seq after 02500 batchs: 632.6591796875
INFO:root:Train (Epoch 92): Loss/seq after 02550 batchs: 625.7435913085938
INFO:root:Train (Epoch 92): Loss/seq after 02600 batchs: 624.6741333007812
INFO:root:Train (Epoch 92): Loss/seq after 02650 batchs: 622.40576171875
INFO:root:Train (Epoch 92): Loss/seq after 02700 batchs: 619.934814453125
INFO:root:Train (Epoch 92): Loss/seq after 02750 batchs: 624.6693725585938
INFO:root:Train (Epoch 92): Loss/seq after 02800 batchs: 627.3816528320312
INFO:root:Train (Epoch 92): Loss/seq after 02850 batchs: 627.29833984375
INFO:root:Train (Epoch 92): Loss/seq after 02900 batchs: 628.993408203125
INFO:root:Train (Epoch 92): Loss/seq after 02950 batchs: 627.1307373046875
INFO:root:Train (Epoch 92): Loss/seq after 03000 batchs: 631.3084716796875
INFO:root:Train (Epoch 92): Loss/seq after 03050 batchs: 634.3651733398438
INFO:root:Train (Epoch 92): Loss/seq after 03100 batchs: 639.1600341796875
INFO:root:Train (Epoch 92): Loss/seq after 03150 batchs: 646.3182373046875
INFO:root:Train (Epoch 92): Loss/seq after 03200 batchs: 649.7584228515625
INFO:root:Train (Epoch 92): Loss/seq after 03250 batchs: 654.3240966796875
INFO:root:Train (Epoch 92): Loss/seq after 03300 batchs: 654.0389404296875
INFO:root:Train (Epoch 92): Loss/seq after 03350 batchs: 654.9429321289062
INFO:root:Train (Epoch 92): Loss/seq after 03400 batchs: 649.707763671875
INFO:root:Train (Epoch 92): Loss/seq after 03450 batchs: 647.3758544921875
INFO:root:Train (Epoch 92): Loss/seq after 03500 batchs: 647.8831787109375
INFO:root:Train (Epoch 92): Loss/seq after 03550 batchs: 644.2872924804688
INFO:root:Train (Epoch 92): Loss/seq after 03600 batchs: 652.5208740234375
INFO:root:Train (Epoch 92): Loss/seq after 03650 batchs: 649.1495971679688
INFO:root:Train (Epoch 92): Loss/seq after 03700 batchs: 650.8668212890625
INFO:root:Train (Epoch 92): Loss/seq after 03750 batchs: 655.1246948242188
INFO:root:Train (Epoch 92): Loss/seq after 03800 batchs: 651.8319091796875
INFO:root:Train (Epoch 92): Loss/seq after 03850 batchs: 650.5660400390625
INFO:root:Train (Epoch 92): Loss/seq after 03900 batchs: 655.4600219726562
INFO:root:Train (Epoch 92): Loss/seq after 03950 batchs: 659.4378662109375
INFO:root:Train (Epoch 92): Loss/seq after 04000 batchs: 655.0055541992188
INFO:root:Train (Epoch 92): Loss/seq after 04050 batchs: 650.623046875
INFO:root:Train (Epoch 92): Loss/seq after 04100 batchs: 648.1848754882812
INFO:root:Train (Epoch 92): Loss/seq after 04150 batchs: 647.340576171875
INFO:root:Train (Epoch 92): Loss/seq after 04200 batchs: 645.3229370117188
INFO:root:Train (Epoch 92): Loss/seq after 04250 batchs: 643.2916259765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 92): Loss/seq after 00000 batches: 550.5587768554688
INFO:root:# Valid (Epoch 92): Loss/seq after 00050 batches: 674.0213012695312
INFO:root:# Valid (Epoch 92): Loss/seq after 00100 batches: 786.26171875
INFO:root:# Valid (Epoch 92): Loss/seq after 00150 batches: 598.9158935546875
INFO:root:# Valid (Epoch 92): Loss/seq after 00200 batches: 561.5225219726562
INFO:root:Artifacts: Make stick videos for epoch 92
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_92_on_20220413_024627.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_92_index_1749_on_20220413_024627.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 93): Loss/seq after 00000 batchs: 1121.767822265625
INFO:root:Train (Epoch 93): Loss/seq after 00050 batchs: 879.4989013671875
INFO:root:Train (Epoch 93): Loss/seq after 00100 batchs: 908.8609619140625
INFO:root:Train (Epoch 93): Loss/seq after 00150 batchs: 820.3938598632812
INFO:root:Train (Epoch 93): Loss/seq after 00200 batchs: 885.9964599609375
INFO:root:Train (Epoch 93): Loss/seq after 00250 batchs: 1000.1030883789062
INFO:root:Train (Epoch 93): Loss/seq after 00300 batchs: 985.26318359375
INFO:root:Train (Epoch 93): Loss/seq after 00350 batchs: 916.5558471679688
INFO:root:Train (Epoch 93): Loss/seq after 00400 batchs: 920.84228515625
INFO:root:Train (Epoch 93): Loss/seq after 00450 batchs: 894.6443481445312
INFO:root:Train (Epoch 93): Loss/seq after 00500 batchs: 868.18359375
INFO:root:Train (Epoch 93): Loss/seq after 00550 batchs: 838.6648559570312
INFO:root:Train (Epoch 93): Loss/seq after 00600 batchs: 808.0200805664062
INFO:root:Train (Epoch 93): Loss/seq after 00650 batchs: 796.0814819335938
INFO:root:Train (Epoch 93): Loss/seq after 00700 batchs: 778.3212890625
INFO:root:Train (Epoch 93): Loss/seq after 00750 batchs: 789.72509765625
INFO:root:Train (Epoch 93): Loss/seq after 00800 batchs: 790.9970092773438
INFO:root:Train (Epoch 93): Loss/seq after 00850 batchs: 766.677001953125
INFO:root:Train (Epoch 93): Loss/seq after 00900 batchs: 751.6480102539062
INFO:root:Train (Epoch 93): Loss/seq after 00950 batchs: 754.6737060546875
INFO:root:Train (Epoch 93): Loss/seq after 01000 batchs: 746.440185546875
INFO:root:Train (Epoch 93): Loss/seq after 01050 batchs: 734.787841796875
INFO:root:Train (Epoch 93): Loss/seq after 01100 batchs: 725.0023803710938
INFO:root:Train (Epoch 93): Loss/seq after 01150 batchs: 707.8406982421875
INFO:root:Train (Epoch 93): Loss/seq after 01200 batchs: 710.1242065429688
INFO:root:Train (Epoch 93): Loss/seq after 01250 batchs: 706.2742919921875
INFO:root:Train (Epoch 93): Loss/seq after 01300 batchs: 694.45947265625
INFO:root:Train (Epoch 93): Loss/seq after 01350 batchs: 684.947998046875
INFO:root:Train (Epoch 93): Loss/seq after 01400 batchs: 696.6043090820312
INFO:root:Train (Epoch 93): Loss/seq after 01450 batchs: 696.2542114257812
INFO:root:Train (Epoch 93): Loss/seq after 01500 batchs: 700.4291381835938
INFO:root:Train (Epoch 93): Loss/seq after 01550 batchs: 701.9542846679688
INFO:root:Train (Epoch 93): Loss/seq after 01600 batchs: 694.6754150390625
INFO:root:Train (Epoch 93): Loss/seq after 01650 batchs: 691.1902465820312
INFO:root:Train (Epoch 93): Loss/seq after 01700 batchs: 691.3329467773438
INFO:root:Train (Epoch 93): Loss/seq after 01750 batchs: 687.3057250976562
INFO:root:Train (Epoch 93): Loss/seq after 01800 batchs: 682.9765625
INFO:root:Train (Epoch 93): Loss/seq after 01850 batchs: 677.65478515625
INFO:root:Train (Epoch 93): Loss/seq after 01900 batchs: 677.5357666015625
INFO:root:Train (Epoch 93): Loss/seq after 01950 batchs: 674.9916381835938
INFO:root:Train (Epoch 93): Loss/seq after 02000 batchs: 671.8372802734375
INFO:root:Train (Epoch 93): Loss/seq after 02050 batchs: 668.979736328125
INFO:root:Train (Epoch 93): Loss/seq after 02100 batchs: 664.8666381835938
INFO:root:Train (Epoch 93): Loss/seq after 02150 batchs: 661.8270874023438
INFO:root:Train (Epoch 93): Loss/seq after 02200 batchs: 657.6581420898438
INFO:root:Train (Epoch 93): Loss/seq after 02250 batchs: 655.8922729492188
INFO:root:Train (Epoch 93): Loss/seq after 02300 batchs: 655.127685546875
INFO:root:Train (Epoch 93): Loss/seq after 02350 batchs: 649.4185180664062
INFO:root:Train (Epoch 93): Loss/seq after 02400 batchs: 649.7466430664062
INFO:root:Train (Epoch 93): Loss/seq after 02450 batchs: 643.825439453125
INFO:root:Train (Epoch 93): Loss/seq after 02500 batchs: 634.25
INFO:root:Train (Epoch 93): Loss/seq after 02550 batchs: 627.3572998046875
INFO:root:Train (Epoch 93): Loss/seq after 02600 batchs: 626.2406005859375
INFO:root:Train (Epoch 93): Loss/seq after 02650 batchs: 623.8626708984375
INFO:root:Train (Epoch 93): Loss/seq after 02700 batchs: 621.4354858398438
INFO:root:Train (Epoch 93): Loss/seq after 02750 batchs: 625.6688232421875
INFO:root:Train (Epoch 93): Loss/seq after 02800 batchs: 628.2643432617188
INFO:root:Train (Epoch 93): Loss/seq after 02850 batchs: 628.7010498046875
INFO:root:Train (Epoch 93): Loss/seq after 02900 batchs: 629.9384765625
INFO:root:Train (Epoch 93): Loss/seq after 02950 batchs: 628.1962890625
INFO:root:Train (Epoch 93): Loss/seq after 03000 batchs: 632.3609619140625
INFO:root:Train (Epoch 93): Loss/seq after 03050 batchs: 635.342529296875
INFO:root:Train (Epoch 93): Loss/seq after 03100 batchs: 640.0953369140625
INFO:root:Train (Epoch 93): Loss/seq after 03150 batchs: 646.1858520507812
INFO:root:Train (Epoch 93): Loss/seq after 03200 batchs: 649.4534301757812
INFO:root:Train (Epoch 93): Loss/seq after 03250 batchs: 653.1986083984375
INFO:root:Train (Epoch 93): Loss/seq after 03300 batchs: 652.3089599609375
INFO:root:Train (Epoch 93): Loss/seq after 03350 batchs: 652.5620727539062
INFO:root:Train (Epoch 93): Loss/seq after 03400 batchs: 647.3556518554688
INFO:root:Train (Epoch 93): Loss/seq after 03450 batchs: 644.9990844726562
INFO:root:Train (Epoch 93): Loss/seq after 03500 batchs: 645.2639770507812
INFO:root:Train (Epoch 93): Loss/seq after 03550 batchs: 641.9365844726562
INFO:root:Train (Epoch 93): Loss/seq after 03600 batchs: 650.2557373046875
INFO:root:Train (Epoch 93): Loss/seq after 03650 batchs: 647.0047607421875
INFO:root:Train (Epoch 93): Loss/seq after 03700 batchs: 649.1752319335938
INFO:root:Train (Epoch 93): Loss/seq after 03750 batchs: 653.5202026367188
INFO:root:Train (Epoch 93): Loss/seq after 03800 batchs: 650.255126953125
INFO:root:Train (Epoch 93): Loss/seq after 03850 batchs: 649.1527099609375
INFO:root:Train (Epoch 93): Loss/seq after 03900 batchs: 653.8548583984375
INFO:root:Train (Epoch 93): Loss/seq after 03950 batchs: 658.0089721679688
INFO:root:Train (Epoch 93): Loss/seq after 04000 batchs: 653.5947265625
INFO:root:Train (Epoch 93): Loss/seq after 04050 batchs: 649.2342529296875
INFO:root:Train (Epoch 93): Loss/seq after 04100 batchs: 646.8070678710938
INFO:root:Train (Epoch 93): Loss/seq after 04150 batchs: 645.9695434570312
INFO:root:Train (Epoch 93): Loss/seq after 04200 batchs: 643.9016723632812
INFO:root:Train (Epoch 93): Loss/seq after 04250 batchs: 641.7823486328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 93): Loss/seq after 00000 batches: 540.1961059570312
INFO:root:# Valid (Epoch 93): Loss/seq after 00050 batches: 697.8449096679688
INFO:root:# Valid (Epoch 93): Loss/seq after 00100 batches: 805.4299926757812
INFO:root:# Valid (Epoch 93): Loss/seq after 00150 batches: 610.898193359375
INFO:root:# Valid (Epoch 93): Loss/seq after 00200 batches: 567.4630126953125
INFO:root:Artifacts: Make stick videos for epoch 93
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_93_on_20220413_025150.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_93_index_818_on_20220413_025150.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 94): Loss/seq after 00000 batchs: 1185.731689453125
INFO:root:Train (Epoch 94): Loss/seq after 00050 batchs: 873.0206909179688
INFO:root:Train (Epoch 94): Loss/seq after 00100 batchs: 901.5934448242188
INFO:root:Train (Epoch 94): Loss/seq after 00150 batchs: 812.1630249023438
INFO:root:Train (Epoch 94): Loss/seq after 00200 batchs: 886.3339233398438
INFO:root:Train (Epoch 94): Loss/seq after 00250 batchs: 1003.5736083984375
INFO:root:Train (Epoch 94): Loss/seq after 00300 batchs: 987.5616455078125
INFO:root:Train (Epoch 94): Loss/seq after 00350 batchs: 919.39794921875
INFO:root:Train (Epoch 94): Loss/seq after 00400 batchs: 926.2927856445312
INFO:root:Train (Epoch 94): Loss/seq after 00450 batchs: 900.0631713867188
INFO:root:Train (Epoch 94): Loss/seq after 00500 batchs: 872.974609375
INFO:root:Train (Epoch 94): Loss/seq after 00550 batchs: 843.8995971679688
INFO:root:Train (Epoch 94): Loss/seq after 00600 batchs: 814.3722534179688
INFO:root:Train (Epoch 94): Loss/seq after 00650 batchs: 802.3237915039062
INFO:root:Train (Epoch 94): Loss/seq after 00700 batchs: 781.4459228515625
INFO:root:Train (Epoch 94): Loss/seq after 00750 batchs: 791.9920043945312
INFO:root:Train (Epoch 94): Loss/seq after 00800 batchs: 793.2157592773438
INFO:root:Train (Epoch 94): Loss/seq after 00850 batchs: 768.4553833007812
INFO:root:Train (Epoch 94): Loss/seq after 00900 batchs: 753.5106811523438
INFO:root:Train (Epoch 94): Loss/seq after 00950 batchs: 755.790771484375
INFO:root:Train (Epoch 94): Loss/seq after 01000 batchs: 746.6005859375
INFO:root:Train (Epoch 94): Loss/seq after 01050 batchs: 733.8555908203125
INFO:root:Train (Epoch 94): Loss/seq after 01100 batchs: 722.5079345703125
INFO:root:Train (Epoch 94): Loss/seq after 01150 batchs: 705.6278076171875
INFO:root:Train (Epoch 94): Loss/seq after 01200 batchs: 707.6707763671875
INFO:root:Train (Epoch 94): Loss/seq after 01250 batchs: 703.8145141601562
INFO:root:Train (Epoch 94): Loss/seq after 01300 batchs: 692.2849731445312
INFO:root:Train (Epoch 94): Loss/seq after 01350 batchs: 682.64892578125
INFO:root:Train (Epoch 94): Loss/seq after 01400 batchs: 692.318115234375
INFO:root:Train (Epoch 94): Loss/seq after 01450 batchs: 692.08935546875
INFO:root:Train (Epoch 94): Loss/seq after 01500 batchs: 696.3670043945312
INFO:root:Train (Epoch 94): Loss/seq after 01550 batchs: 698.0863647460938
INFO:root:Train (Epoch 94): Loss/seq after 01600 batchs: 691.1371459960938
INFO:root:Train (Epoch 94): Loss/seq after 01650 batchs: 687.7066040039062
INFO:root:Train (Epoch 94): Loss/seq after 01700 batchs: 688.368896484375
INFO:root:Train (Epoch 94): Loss/seq after 01750 batchs: 684.22705078125
INFO:root:Train (Epoch 94): Loss/seq after 01800 batchs: 679.9160766601562
INFO:root:Train (Epoch 94): Loss/seq after 01850 batchs: 674.6728515625
INFO:root:Train (Epoch 94): Loss/seq after 01900 batchs: 674.70654296875
INFO:root:Train (Epoch 94): Loss/seq after 01950 batchs: 671.7159423828125
INFO:root:Train (Epoch 94): Loss/seq after 02000 batchs: 668.7088012695312
INFO:root:Train (Epoch 94): Loss/seq after 02050 batchs: 666.0806884765625
INFO:root:Train (Epoch 94): Loss/seq after 02100 batchs: 662.06640625
INFO:root:Train (Epoch 94): Loss/seq after 02150 batchs: 659.006103515625
INFO:root:Train (Epoch 94): Loss/seq after 02200 batchs: 654.8231201171875
INFO:root:Train (Epoch 94): Loss/seq after 02250 batchs: 653.324951171875
INFO:root:Train (Epoch 94): Loss/seq after 02300 batchs: 651.8272705078125
INFO:root:Train (Epoch 94): Loss/seq after 02350 batchs: 646.4368896484375
INFO:root:Train (Epoch 94): Loss/seq after 02400 batchs: 646.7862548828125
INFO:root:Train (Epoch 94): Loss/seq after 02450 batchs: 640.8818969726562
INFO:root:Train (Epoch 94): Loss/seq after 02500 batchs: 631.3350219726562
INFO:root:Train (Epoch 94): Loss/seq after 02550 batchs: 624.453369140625
INFO:root:Train (Epoch 94): Loss/seq after 02600 batchs: 623.27880859375
INFO:root:Train (Epoch 94): Loss/seq after 02650 batchs: 620.830322265625
INFO:root:Train (Epoch 94): Loss/seq after 02700 batchs: 618.4865112304688
INFO:root:Train (Epoch 94): Loss/seq after 02750 batchs: 622.3536376953125
INFO:root:Train (Epoch 94): Loss/seq after 02800 batchs: 625.7711791992188
INFO:root:Train (Epoch 94): Loss/seq after 02850 batchs: 625.821533203125
INFO:root:Train (Epoch 94): Loss/seq after 02900 batchs: 627.0238647460938
INFO:root:Train (Epoch 94): Loss/seq after 02950 batchs: 625.1455078125
INFO:root:Train (Epoch 94): Loss/seq after 03000 batchs: 629.3451538085938
INFO:root:Train (Epoch 94): Loss/seq after 03050 batchs: 632.2714233398438
INFO:root:Train (Epoch 94): Loss/seq after 03100 batchs: 636.720947265625
INFO:root:Train (Epoch 94): Loss/seq after 03150 batchs: 642.63134765625
INFO:root:Train (Epoch 94): Loss/seq after 03200 batchs: 645.9091186523438
INFO:root:Train (Epoch 94): Loss/seq after 03250 batchs: 649.7547607421875
INFO:root:Train (Epoch 94): Loss/seq after 03300 batchs: 648.843017578125
INFO:root:Train (Epoch 94): Loss/seq after 03350 batchs: 648.9755859375
INFO:root:Train (Epoch 94): Loss/seq after 03400 batchs: 643.8370361328125
INFO:root:Train (Epoch 94): Loss/seq after 03450 batchs: 641.3788452148438
INFO:root:Train (Epoch 94): Loss/seq after 03500 batchs: 641.8579711914062
INFO:root:Train (Epoch 94): Loss/seq after 03550 batchs: 638.5156860351562
INFO:root:Train (Epoch 94): Loss/seq after 03600 batchs: 647.0001220703125
INFO:root:Train (Epoch 94): Loss/seq after 03650 batchs: 643.7664794921875
INFO:root:Train (Epoch 94): Loss/seq after 03700 batchs: 645.8838500976562
INFO:root:Train (Epoch 94): Loss/seq after 03750 batchs: 650.2412109375
INFO:root:Train (Epoch 94): Loss/seq after 03800 batchs: 647.0062866210938
INFO:root:Train (Epoch 94): Loss/seq after 03850 batchs: 645.7775268554688
INFO:root:Train (Epoch 94): Loss/seq after 03900 batchs: 650.3114624023438
INFO:root:Train (Epoch 94): Loss/seq after 03950 batchs: 654.5316772460938
INFO:root:Train (Epoch 94): Loss/seq after 04000 batchs: 650.121337890625
INFO:root:Train (Epoch 94): Loss/seq after 04050 batchs: 645.7597045898438
INFO:root:Train (Epoch 94): Loss/seq after 04100 batchs: 643.3154907226562
INFO:root:Train (Epoch 94): Loss/seq after 04150 batchs: 642.5100708007812
INFO:root:Train (Epoch 94): Loss/seq after 04200 batchs: 640.5511474609375
INFO:root:Train (Epoch 94): Loss/seq after 04250 batchs: 638.5226440429688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 94): Loss/seq after 00000 batches: 533.1202392578125
INFO:root:# Valid (Epoch 94): Loss/seq after 00050 batches: 681.9360961914062
INFO:root:# Valid (Epoch 94): Loss/seq after 00100 batches: 790.968994140625
INFO:root:# Valid (Epoch 94): Loss/seq after 00150 batches: 599.1730346679688
INFO:root:# Valid (Epoch 94): Loss/seq after 00200 batches: 560.1491088867188
INFO:root:Artifacts: Make stick videos for epoch 94
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_94_on_20220413_025712.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_94_index_645_on_20220413_025712.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 95): Loss/seq after 00000 batchs: 1205.9002685546875
INFO:root:Train (Epoch 95): Loss/seq after 00050 batchs: 877.25830078125
INFO:root:Train (Epoch 95): Loss/seq after 00100 batchs: 899.7518310546875
INFO:root:Train (Epoch 95): Loss/seq after 00150 batchs: 816.6282348632812
INFO:root:Train (Epoch 95): Loss/seq after 00200 batchs: 885.1149291992188
INFO:root:Train (Epoch 95): Loss/seq after 00250 batchs: 1001.93017578125
INFO:root:Train (Epoch 95): Loss/seq after 00300 batchs: 986.5228271484375
INFO:root:Train (Epoch 95): Loss/seq after 00350 batchs: 919.0995483398438
INFO:root:Train (Epoch 95): Loss/seq after 00400 batchs: 925.6898193359375
INFO:root:Train (Epoch 95): Loss/seq after 00450 batchs: 899.7210693359375
INFO:root:Train (Epoch 95): Loss/seq after 00500 batchs: 873.1203002929688
INFO:root:Train (Epoch 95): Loss/seq after 00550 batchs: 843.55322265625
INFO:root:Train (Epoch 95): Loss/seq after 00600 batchs: 813.05322265625
INFO:root:Train (Epoch 95): Loss/seq after 00650 batchs: 797.5936279296875
INFO:root:Train (Epoch 95): Loss/seq after 00700 batchs: 774.273193359375
INFO:root:Train (Epoch 95): Loss/seq after 00750 batchs: 785.214111328125
INFO:root:Train (Epoch 95): Loss/seq after 00800 batchs: 785.8194580078125
INFO:root:Train (Epoch 95): Loss/seq after 00850 batchs: 760.9743041992188
INFO:root:Train (Epoch 95): Loss/seq after 00900 batchs: 744.9828491210938
INFO:root:Train (Epoch 95): Loss/seq after 00950 batchs: 746.0670776367188
INFO:root:Train (Epoch 95): Loss/seq after 01000 batchs: 737.4957885742188
INFO:root:Train (Epoch 95): Loss/seq after 01050 batchs: 725.4204711914062
INFO:root:Train (Epoch 95): Loss/seq after 01100 batchs: 714.6937255859375
INFO:root:Train (Epoch 95): Loss/seq after 01150 batchs: 697.9081420898438
INFO:root:Train (Epoch 95): Loss/seq after 01200 batchs: 700.401123046875
INFO:root:Train (Epoch 95): Loss/seq after 01250 batchs: 696.67138671875
INFO:root:Train (Epoch 95): Loss/seq after 01300 batchs: 685.9007568359375
INFO:root:Train (Epoch 95): Loss/seq after 01350 batchs: 675.921142578125
INFO:root:Train (Epoch 95): Loss/seq after 01400 batchs: 685.1489868164062
INFO:root:Train (Epoch 95): Loss/seq after 01450 batchs: 685.1022338867188
INFO:root:Train (Epoch 95): Loss/seq after 01500 batchs: 689.735595703125
INFO:root:Train (Epoch 95): Loss/seq after 01550 batchs: 690.8612670898438
INFO:root:Train (Epoch 95): Loss/seq after 01600 batchs: 683.7384033203125
INFO:root:Train (Epoch 95): Loss/seq after 01650 batchs: 680.5067138671875
INFO:root:Train (Epoch 95): Loss/seq after 01700 batchs: 681.3744506835938
INFO:root:Train (Epoch 95): Loss/seq after 01750 batchs: 677.548583984375
INFO:root:Train (Epoch 95): Loss/seq after 01800 batchs: 673.4468383789062
INFO:root:Train (Epoch 95): Loss/seq after 01850 batchs: 668.607666015625
INFO:root:Train (Epoch 95): Loss/seq after 01900 batchs: 668.9249267578125
INFO:root:Train (Epoch 95): Loss/seq after 01950 batchs: 666.34228515625
INFO:root:Train (Epoch 95): Loss/seq after 02000 batchs: 663.590576171875
INFO:root:Train (Epoch 95): Loss/seq after 02050 batchs: 660.985107421875
INFO:root:Train (Epoch 95): Loss/seq after 02100 batchs: 656.9757690429688
INFO:root:Train (Epoch 95): Loss/seq after 02150 batchs: 654.0479125976562
INFO:root:Train (Epoch 95): Loss/seq after 02200 batchs: 649.9207153320312
INFO:root:Train (Epoch 95): Loss/seq after 02250 batchs: 648.1622924804688
INFO:root:Train (Epoch 95): Loss/seq after 02300 batchs: 646.3273315429688
INFO:root:Train (Epoch 95): Loss/seq after 02350 batchs: 641.0687255859375
INFO:root:Train (Epoch 95): Loss/seq after 02400 batchs: 641.5759887695312
INFO:root:Train (Epoch 95): Loss/seq after 02450 batchs: 635.7916870117188
INFO:root:Train (Epoch 95): Loss/seq after 02500 batchs: 626.3502807617188
INFO:root:Train (Epoch 95): Loss/seq after 02550 batchs: 619.5281982421875
INFO:root:Train (Epoch 95): Loss/seq after 02600 batchs: 618.6846923828125
INFO:root:Train (Epoch 95): Loss/seq after 02650 batchs: 616.3236083984375
INFO:root:Train (Epoch 95): Loss/seq after 02700 batchs: 613.912353515625
INFO:root:Train (Epoch 95): Loss/seq after 02750 batchs: 616.106689453125
INFO:root:Train (Epoch 95): Loss/seq after 02800 batchs: 618.4712524414062
INFO:root:Train (Epoch 95): Loss/seq after 02850 batchs: 618.1611328125
INFO:root:Train (Epoch 95): Loss/seq after 02900 batchs: 619.611083984375
INFO:root:Train (Epoch 95): Loss/seq after 02950 batchs: 617.81201171875
INFO:root:Train (Epoch 95): Loss/seq after 03000 batchs: 622.0736083984375
INFO:root:Train (Epoch 95): Loss/seq after 03050 batchs: 624.6431274414062
INFO:root:Train (Epoch 95): Loss/seq after 03100 batchs: 629.3422241210938
INFO:root:Train (Epoch 95): Loss/seq after 03150 batchs: 635.5493774414062
INFO:root:Train (Epoch 95): Loss/seq after 03200 batchs: 638.9080200195312
INFO:root:Train (Epoch 95): Loss/seq after 03250 batchs: 642.6616821289062
INFO:root:Train (Epoch 95): Loss/seq after 03300 batchs: 641.5042724609375
INFO:root:Train (Epoch 95): Loss/seq after 03350 batchs: 641.594970703125
INFO:root:Train (Epoch 95): Loss/seq after 03400 batchs: 636.5103759765625
INFO:root:Train (Epoch 95): Loss/seq after 03450 batchs: 634.1567993164062
INFO:root:Train (Epoch 95): Loss/seq after 03500 batchs: 634.4136352539062
INFO:root:Train (Epoch 95): Loss/seq after 03550 batchs: 630.9734497070312
INFO:root:Train (Epoch 95): Loss/seq after 03600 batchs: 639.24365234375
INFO:root:Train (Epoch 95): Loss/seq after 03650 batchs: 635.8564453125
INFO:root:Train (Epoch 95): Loss/seq after 03700 batchs: 637.7789916992188
INFO:root:Train (Epoch 95): Loss/seq after 03750 batchs: 642.142578125
INFO:root:Train (Epoch 95): Loss/seq after 03800 batchs: 639.037109375
INFO:root:Train (Epoch 95): Loss/seq after 03850 batchs: 637.9080200195312
INFO:root:Train (Epoch 95): Loss/seq after 03900 batchs: 642.8263549804688
INFO:root:Train (Epoch 95): Loss/seq after 03950 batchs: 646.9624633789062
INFO:root:Train (Epoch 95): Loss/seq after 04000 batchs: 642.6840209960938
INFO:root:Train (Epoch 95): Loss/seq after 04050 batchs: 638.402099609375
INFO:root:Train (Epoch 95): Loss/seq after 04100 batchs: 636.0023193359375
INFO:root:Train (Epoch 95): Loss/seq after 04150 batchs: 635.2840576171875
INFO:root:Train (Epoch 95): Loss/seq after 04200 batchs: 633.3934936523438
INFO:root:Train (Epoch 95): Loss/seq after 04250 batchs: 631.5184936523438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 95): Loss/seq after 00000 batches: 578.9805908203125
INFO:root:# Valid (Epoch 95): Loss/seq after 00050 batches: 727.2318115234375
INFO:root:# Valid (Epoch 95): Loss/seq after 00100 batches: 812.4267578125
INFO:root:# Valid (Epoch 95): Loss/seq after 00150 batches: 616.7966918945312
INFO:root:# Valid (Epoch 95): Loss/seq after 00200 batches: 574.7129516601562
INFO:root:Artifacts: Make stick videos for epoch 95
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_95_on_20220413_030235.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_95_index_932_on_20220413_030235.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 96): Loss/seq after 00000 batchs: 1144.1944580078125
INFO:root:Train (Epoch 96): Loss/seq after 00050 batchs: 875.9320068359375
INFO:root:Train (Epoch 96): Loss/seq after 00100 batchs: 899.4909057617188
INFO:root:Train (Epoch 96): Loss/seq after 00150 batchs: 814.8792114257812
INFO:root:Train (Epoch 96): Loss/seq after 00200 batchs: 885.9852294921875
INFO:root:Train (Epoch 96): Loss/seq after 00250 batchs: 1003.00244140625
INFO:root:Train (Epoch 96): Loss/seq after 00300 batchs: 986.5582275390625
INFO:root:Train (Epoch 96): Loss/seq after 00350 batchs: 918.9522094726562
INFO:root:Train (Epoch 96): Loss/seq after 00400 batchs: 923.9964599609375
INFO:root:Train (Epoch 96): Loss/seq after 00450 batchs: 897.7525634765625
INFO:root:Train (Epoch 96): Loss/seq after 00500 batchs: 869.8161010742188
INFO:root:Train (Epoch 96): Loss/seq after 00550 batchs: 840.2277221679688
INFO:root:Train (Epoch 96): Loss/seq after 00600 batchs: 809.1763305664062
INFO:root:Train (Epoch 96): Loss/seq after 00650 batchs: 792.2296142578125
INFO:root:Train (Epoch 96): Loss/seq after 00700 batchs: 769.0562744140625
INFO:root:Train (Epoch 96): Loss/seq after 00750 batchs: 777.0987548828125
INFO:root:Train (Epoch 96): Loss/seq after 00800 batchs: 777.4159545898438
INFO:root:Train (Epoch 96): Loss/seq after 00850 batchs: 752.9091186523438
INFO:root:Train (Epoch 96): Loss/seq after 00900 batchs: 738.545654296875
INFO:root:Train (Epoch 96): Loss/seq after 00950 batchs: 739.6104125976562
INFO:root:Train (Epoch 96): Loss/seq after 01000 batchs: 730.4624633789062
INFO:root:Train (Epoch 96): Loss/seq after 01050 batchs: 717.2745361328125
INFO:root:Train (Epoch 96): Loss/seq after 01100 batchs: 706.306640625
INFO:root:Train (Epoch 96): Loss/seq after 01150 batchs: 689.6861572265625
INFO:root:Train (Epoch 96): Loss/seq after 01200 batchs: 692.05517578125
INFO:root:Train (Epoch 96): Loss/seq after 01250 batchs: 688.4423828125
INFO:root:Train (Epoch 96): Loss/seq after 01300 batchs: 676.5730590820312
INFO:root:Train (Epoch 96): Loss/seq after 01350 batchs: 666.5733032226562
INFO:root:Train (Epoch 96): Loss/seq after 01400 batchs: 674.50732421875
INFO:root:Train (Epoch 96): Loss/seq after 01450 batchs: 674.3053588867188
INFO:root:Train (Epoch 96): Loss/seq after 01500 batchs: 679.131103515625
INFO:root:Train (Epoch 96): Loss/seq after 01550 batchs: 680.6340942382812
INFO:root:Train (Epoch 96): Loss/seq after 01600 batchs: 673.7622680664062
INFO:root:Train (Epoch 96): Loss/seq after 01650 batchs: 670.669189453125
INFO:root:Train (Epoch 96): Loss/seq after 01700 batchs: 671.703857421875
INFO:root:Train (Epoch 96): Loss/seq after 01750 batchs: 668.016357421875
INFO:root:Train (Epoch 96): Loss/seq after 01800 batchs: 664.151611328125
INFO:root:Train (Epoch 96): Loss/seq after 01850 batchs: 659.3408203125
INFO:root:Train (Epoch 96): Loss/seq after 01900 batchs: 659.495361328125
INFO:root:Train (Epoch 96): Loss/seq after 01950 batchs: 657.1187744140625
INFO:root:Train (Epoch 96): Loss/seq after 02000 batchs: 654.5217895507812
INFO:root:Train (Epoch 96): Loss/seq after 02050 batchs: 652.1007690429688
INFO:root:Train (Epoch 96): Loss/seq after 02100 batchs: 648.420654296875
INFO:root:Train (Epoch 96): Loss/seq after 02150 batchs: 645.6527099609375
INFO:root:Train (Epoch 96): Loss/seq after 02200 batchs: 641.7239990234375
INFO:root:Train (Epoch 96): Loss/seq after 02250 batchs: 640.2959594726562
INFO:root:Train (Epoch 96): Loss/seq after 02300 batchs: 638.6863403320312
INFO:root:Train (Epoch 96): Loss/seq after 02350 batchs: 633.3607177734375
INFO:root:Train (Epoch 96): Loss/seq after 02400 batchs: 634.03271484375
INFO:root:Train (Epoch 96): Loss/seq after 02450 batchs: 628.4363403320312
INFO:root:Train (Epoch 96): Loss/seq after 02500 batchs: 619.160400390625
INFO:root:Train (Epoch 96): Loss/seq after 02550 batchs: 612.4520263671875
INFO:root:Train (Epoch 96): Loss/seq after 02600 batchs: 611.5718383789062
INFO:root:Train (Epoch 96): Loss/seq after 02650 batchs: 609.3234252929688
INFO:root:Train (Epoch 96): Loss/seq after 02700 batchs: 607.0281372070312
INFO:root:Train (Epoch 96): Loss/seq after 02750 batchs: 609.0114135742188
INFO:root:Train (Epoch 96): Loss/seq after 02800 batchs: 611.1317749023438
INFO:root:Train (Epoch 96): Loss/seq after 02850 batchs: 611.196044921875
INFO:root:Train (Epoch 96): Loss/seq after 02900 batchs: 612.7042846679688
INFO:root:Train (Epoch 96): Loss/seq after 02950 batchs: 611.0775756835938
INFO:root:Train (Epoch 96): Loss/seq after 03000 batchs: 615.4548950195312
INFO:root:Train (Epoch 96): Loss/seq after 03050 batchs: 618.1875
INFO:root:Train (Epoch 96): Loss/seq after 03100 batchs: 622.5455322265625
INFO:root:Train (Epoch 96): Loss/seq after 03150 batchs: 628.5133056640625
INFO:root:Train (Epoch 96): Loss/seq after 03200 batchs: 631.4544677734375
INFO:root:Train (Epoch 96): Loss/seq after 03250 batchs: 634.72412109375
INFO:root:Train (Epoch 96): Loss/seq after 03300 batchs: 633.7974853515625
INFO:root:Train (Epoch 96): Loss/seq after 03350 batchs: 634.049072265625
INFO:root:Train (Epoch 96): Loss/seq after 03400 batchs: 629.0234375
INFO:root:Train (Epoch 96): Loss/seq after 03450 batchs: 626.7243041992188
INFO:root:Train (Epoch 96): Loss/seq after 03500 batchs: 626.9690551757812
INFO:root:Train (Epoch 96): Loss/seq after 03550 batchs: 623.6483154296875
INFO:root:Train (Epoch 96): Loss/seq after 03600 batchs: 632.362548828125
INFO:root:Train (Epoch 96): Loss/seq after 03650 batchs: 629.2925415039062
INFO:root:Train (Epoch 96): Loss/seq after 03700 batchs: 631.578125
INFO:root:Train (Epoch 96): Loss/seq after 03750 batchs: 636.0441284179688
INFO:root:Train (Epoch 96): Loss/seq after 03800 batchs: 632.9464721679688
INFO:root:Train (Epoch 96): Loss/seq after 03850 batchs: 631.8280029296875
INFO:root:Train (Epoch 96): Loss/seq after 03900 batchs: 636.3262329101562
INFO:root:Train (Epoch 96): Loss/seq after 03950 batchs: 640.2783203125
INFO:root:Train (Epoch 96): Loss/seq after 04000 batchs: 636.06494140625
INFO:root:Train (Epoch 96): Loss/seq after 04050 batchs: 631.86181640625
INFO:root:Train (Epoch 96): Loss/seq after 04100 batchs: 629.5681762695312
INFO:root:Train (Epoch 96): Loss/seq after 04150 batchs: 628.9183349609375
INFO:root:Train (Epoch 96): Loss/seq after 04200 batchs: 626.921875
INFO:root:Train (Epoch 96): Loss/seq after 04250 batchs: 625.130859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 96): Loss/seq after 00000 batches: 556.1528930664062
INFO:root:# Valid (Epoch 96): Loss/seq after 00050 batches: 716.687744140625
INFO:root:# Valid (Epoch 96): Loss/seq after 00100 batches: 841.459716796875
INFO:root:# Valid (Epoch 96): Loss/seq after 00150 batches: 639.7276000976562
INFO:root:# Valid (Epoch 96): Loss/seq after 00200 batches: 592.5216674804688
INFO:root:Artifacts: Make stick videos for epoch 96
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_96_on_20220413_030756.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_96_index_1653_on_20220413_030756.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 97): Loss/seq after 00000 batchs: 1034.98876953125
INFO:root:Train (Epoch 97): Loss/seq after 00050 batchs: 867.4013671875
INFO:root:Train (Epoch 97): Loss/seq after 00100 batchs: 880.7407836914062
INFO:root:Train (Epoch 97): Loss/seq after 00150 batchs: 799.3782958984375
INFO:root:Train (Epoch 97): Loss/seq after 00200 batchs: 865.4742431640625
INFO:root:Train (Epoch 97): Loss/seq after 00250 batchs: 974.3602905273438
INFO:root:Train (Epoch 97): Loss/seq after 00300 batchs: 962.972900390625
INFO:root:Train (Epoch 97): Loss/seq after 00350 batchs: 897.4635620117188
INFO:root:Train (Epoch 97): Loss/seq after 00400 batchs: 899.0938110351562
INFO:root:Train (Epoch 97): Loss/seq after 00450 batchs: 875.1758422851562
INFO:root:Train (Epoch 97): Loss/seq after 00500 batchs: 847.385498046875
INFO:root:Train (Epoch 97): Loss/seq after 00550 batchs: 819.46142578125
INFO:root:Train (Epoch 97): Loss/seq after 00600 batchs: 790.2318115234375
INFO:root:Train (Epoch 97): Loss/seq after 00650 batchs: 772.1649780273438
INFO:root:Train (Epoch 97): Loss/seq after 00700 batchs: 750.8052368164062
INFO:root:Train (Epoch 97): Loss/seq after 00750 batchs: 759.4409790039062
INFO:root:Train (Epoch 97): Loss/seq after 00800 batchs: 760.364501953125
INFO:root:Train (Epoch 97): Loss/seq after 00850 batchs: 736.4832153320312
INFO:root:Train (Epoch 97): Loss/seq after 00900 batchs: 722.5527954101562
INFO:root:Train (Epoch 97): Loss/seq after 00950 batchs: 723.3569946289062
INFO:root:Train (Epoch 97): Loss/seq after 01000 batchs: 714.1865234375
INFO:root:Train (Epoch 97): Loss/seq after 01050 batchs: 702.5243530273438
INFO:root:Train (Epoch 97): Loss/seq after 01100 batchs: 692.2142944335938
INFO:root:Train (Epoch 97): Loss/seq after 01150 batchs: 676.1044921875
INFO:root:Train (Epoch 97): Loss/seq after 01200 batchs: 679.0796508789062
INFO:root:Train (Epoch 97): Loss/seq after 01250 batchs: 676.4247436523438
INFO:root:Train (Epoch 97): Loss/seq after 01300 batchs: 664.5904541015625
INFO:root:Train (Epoch 97): Loss/seq after 01350 batchs: 655.2212524414062
INFO:root:Train (Epoch 97): Loss/seq after 01400 batchs: 664.5965576171875
INFO:root:Train (Epoch 97): Loss/seq after 01450 batchs: 665.08154296875
INFO:root:Train (Epoch 97): Loss/seq after 01500 batchs: 670.1691284179688
INFO:root:Train (Epoch 97): Loss/seq after 01550 batchs: 671.974365234375
INFO:root:Train (Epoch 97): Loss/seq after 01600 batchs: 665.8367919921875
INFO:root:Train (Epoch 97): Loss/seq after 01650 batchs: 663.0164184570312
INFO:root:Train (Epoch 97): Loss/seq after 01700 batchs: 664.2380981445312
INFO:root:Train (Epoch 97): Loss/seq after 01750 batchs: 660.7353515625
INFO:root:Train (Epoch 97): Loss/seq after 01800 batchs: 657.058349609375
INFO:root:Train (Epoch 97): Loss/seq after 01850 batchs: 652.3034057617188
INFO:root:Train (Epoch 97): Loss/seq after 01900 batchs: 652.2868041992188
INFO:root:Train (Epoch 97): Loss/seq after 01950 batchs: 649.9700927734375
INFO:root:Train (Epoch 97): Loss/seq after 02000 batchs: 647.5635986328125
INFO:root:Train (Epoch 97): Loss/seq after 02050 batchs: 645.2650146484375
INFO:root:Train (Epoch 97): Loss/seq after 02100 batchs: 641.5792846679688
INFO:root:Train (Epoch 97): Loss/seq after 02150 batchs: 638.9901123046875
INFO:root:Train (Epoch 97): Loss/seq after 02200 batchs: 635.2239379882812
INFO:root:Train (Epoch 97): Loss/seq after 02250 batchs: 633.7819213867188
INFO:root:Train (Epoch 97): Loss/seq after 02300 batchs: 631.8976440429688
INFO:root:Train (Epoch 97): Loss/seq after 02350 batchs: 626.7131958007812
INFO:root:Train (Epoch 97): Loss/seq after 02400 batchs: 627.56494140625
INFO:root:Train (Epoch 97): Loss/seq after 02450 batchs: 622.035400390625
INFO:root:Train (Epoch 97): Loss/seq after 02500 batchs: 612.8457641601562
INFO:root:Train (Epoch 97): Loss/seq after 02550 batchs: 606.3488159179688
INFO:root:Train (Epoch 97): Loss/seq after 02600 batchs: 605.6058959960938
INFO:root:Train (Epoch 97): Loss/seq after 02650 batchs: 603.5116577148438
INFO:root:Train (Epoch 97): Loss/seq after 02700 batchs: 601.4705200195312
INFO:root:Train (Epoch 97): Loss/seq after 02750 batchs: 604.2276000976562
INFO:root:Train (Epoch 97): Loss/seq after 02800 batchs: 606.2646484375
INFO:root:Train (Epoch 97): Loss/seq after 02850 batchs: 606.20068359375
INFO:root:Train (Epoch 97): Loss/seq after 02900 batchs: 607.693115234375
INFO:root:Train (Epoch 97): Loss/seq after 02950 batchs: 606.2824096679688
INFO:root:Train (Epoch 97): Loss/seq after 03000 batchs: 610.7723388671875
INFO:root:Train (Epoch 97): Loss/seq after 03050 batchs: 612.9578857421875
INFO:root:Train (Epoch 97): Loss/seq after 03100 batchs: 617.5848999023438
INFO:root:Train (Epoch 97): Loss/seq after 03150 batchs: 623.5098266601562
INFO:root:Train (Epoch 97): Loss/seq after 03200 batchs: 626.19873046875
INFO:root:Train (Epoch 97): Loss/seq after 03250 batchs: 629.4689331054688
INFO:root:Train (Epoch 97): Loss/seq after 03300 batchs: 628.08544921875
INFO:root:Train (Epoch 97): Loss/seq after 03350 batchs: 628.298583984375
INFO:root:Train (Epoch 97): Loss/seq after 03400 batchs: 623.4240112304688
INFO:root:Train (Epoch 97): Loss/seq after 03450 batchs: 621.1966552734375
INFO:root:Train (Epoch 97): Loss/seq after 03500 batchs: 621.445068359375
INFO:root:Train (Epoch 97): Loss/seq after 03550 batchs: 618.1838989257812
INFO:root:Train (Epoch 97): Loss/seq after 03600 batchs: 626.5219116210938
INFO:root:Train (Epoch 97): Loss/seq after 03650 batchs: 623.5767822265625
INFO:root:Train (Epoch 97): Loss/seq after 03700 batchs: 625.7784423828125
INFO:root:Train (Epoch 97): Loss/seq after 03750 batchs: 630.34912109375
INFO:root:Train (Epoch 97): Loss/seq after 03800 batchs: 627.400634765625
INFO:root:Train (Epoch 97): Loss/seq after 03850 batchs: 626.3165283203125
INFO:root:Train (Epoch 97): Loss/seq after 03900 batchs: 630.9984741210938
INFO:root:Train (Epoch 97): Loss/seq after 03950 batchs: 634.8715209960938
INFO:root:Train (Epoch 97): Loss/seq after 04000 batchs: 630.7158203125
INFO:root:Train (Epoch 97): Loss/seq after 04050 batchs: 626.617919921875
INFO:root:Train (Epoch 97): Loss/seq after 04100 batchs: 624.3363647460938
INFO:root:Train (Epoch 97): Loss/seq after 04150 batchs: 623.711669921875
INFO:root:Train (Epoch 97): Loss/seq after 04200 batchs: 621.8328857421875
INFO:root:Train (Epoch 97): Loss/seq after 04250 batchs: 619.9437255859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 97): Loss/seq after 00000 batches: 508.9850769042969
INFO:root:# Valid (Epoch 97): Loss/seq after 00050 batches: 696.7321166992188
INFO:root:# Valid (Epoch 97): Loss/seq after 00100 batches: 794.5220947265625
INFO:root:# Valid (Epoch 97): Loss/seq after 00150 batches: 601.38427734375
INFO:root:# Valid (Epoch 97): Loss/seq after 00200 batches: 559.8279418945312
INFO:root:Artifacts: Make stick videos for epoch 97
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_97_on_20220413_031316.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_97_index_149_on_20220413_031316.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 98): Loss/seq after 00000 batchs: 1215.62255859375
INFO:root:Train (Epoch 98): Loss/seq after 00050 batchs: 849.8348999023438
INFO:root:Train (Epoch 98): Loss/seq after 00100 batchs: 865.1412353515625
INFO:root:Train (Epoch 98): Loss/seq after 00150 batchs: 790.3125
INFO:root:Train (Epoch 98): Loss/seq after 00200 batchs: 856.3665771484375
INFO:root:Train (Epoch 98): Loss/seq after 00250 batchs: 975.30810546875
INFO:root:Train (Epoch 98): Loss/seq after 00300 batchs: 963.829833984375
INFO:root:Train (Epoch 98): Loss/seq after 00350 batchs: 898.6112060546875
INFO:root:Train (Epoch 98): Loss/seq after 00400 batchs: 901.0695190429688
INFO:root:Train (Epoch 98): Loss/seq after 00450 batchs: 877.0814819335938
INFO:root:Train (Epoch 98): Loss/seq after 00500 batchs: 849.9161376953125
INFO:root:Train (Epoch 98): Loss/seq after 00550 batchs: 822.1575927734375
INFO:root:Train (Epoch 98): Loss/seq after 00600 batchs: 792.58251953125
INFO:root:Train (Epoch 98): Loss/seq after 00650 batchs: 773.367919921875
INFO:root:Train (Epoch 98): Loss/seq after 00700 batchs: 751.2432250976562
INFO:root:Train (Epoch 98): Loss/seq after 00750 batchs: 759.9830932617188
INFO:root:Train (Epoch 98): Loss/seq after 00800 batchs: 760.8220825195312
INFO:root:Train (Epoch 98): Loss/seq after 00850 batchs: 737.7266235351562
INFO:root:Train (Epoch 98): Loss/seq after 00900 batchs: 724.2960815429688
INFO:root:Train (Epoch 98): Loss/seq after 00950 batchs: 725.3546752929688
INFO:root:Train (Epoch 98): Loss/seq after 01000 batchs: 715.623046875
INFO:root:Train (Epoch 98): Loss/seq after 01050 batchs: 703.8071899414062
INFO:root:Train (Epoch 98): Loss/seq after 01100 batchs: 693.6458740234375
INFO:root:Train (Epoch 98): Loss/seq after 01150 batchs: 677.5391845703125
INFO:root:Train (Epoch 98): Loss/seq after 01200 batchs: 680.6013793945312
INFO:root:Train (Epoch 98): Loss/seq after 01250 batchs: 677.8873291015625
INFO:root:Train (Epoch 98): Loss/seq after 01300 batchs: 666.2066650390625
INFO:root:Train (Epoch 98): Loss/seq after 01350 batchs: 656.4193725585938
INFO:root:Train (Epoch 98): Loss/seq after 01400 batchs: 663.603271484375
INFO:root:Train (Epoch 98): Loss/seq after 01450 batchs: 664.0042724609375
INFO:root:Train (Epoch 98): Loss/seq after 01500 batchs: 669.146484375
INFO:root:Train (Epoch 98): Loss/seq after 01550 batchs: 670.9300537109375
INFO:root:Train (Epoch 98): Loss/seq after 01600 batchs: 664.47998046875
INFO:root:Train (Epoch 98): Loss/seq after 01650 batchs: 661.57373046875
INFO:root:Train (Epoch 98): Loss/seq after 01700 batchs: 662.6409301757812
INFO:root:Train (Epoch 98): Loss/seq after 01750 batchs: 659.067138671875
INFO:root:Train (Epoch 98): Loss/seq after 01800 batchs: 655.2637939453125
INFO:root:Train (Epoch 98): Loss/seq after 01850 batchs: 650.5731201171875
INFO:root:Train (Epoch 98): Loss/seq after 01900 batchs: 650.66650390625
INFO:root:Train (Epoch 98): Loss/seq after 01950 batchs: 648.5501708984375
INFO:root:Train (Epoch 98): Loss/seq after 02000 batchs: 646.2081909179688
INFO:root:Train (Epoch 98): Loss/seq after 02050 batchs: 643.9512329101562
INFO:root:Train (Epoch 98): Loss/seq after 02100 batchs: 640.4180908203125
INFO:root:Train (Epoch 98): Loss/seq after 02150 batchs: 637.9381103515625
INFO:root:Train (Epoch 98): Loss/seq after 02200 batchs: 634.1369018554688
INFO:root:Train (Epoch 98): Loss/seq after 02250 batchs: 632.4405517578125
INFO:root:Train (Epoch 98): Loss/seq after 02300 batchs: 630.227783203125
INFO:root:Train (Epoch 98): Loss/seq after 02350 batchs: 624.9033813476562
INFO:root:Train (Epoch 98): Loss/seq after 02400 batchs: 625.682373046875
INFO:root:Train (Epoch 98): Loss/seq after 02450 batchs: 620.2481689453125
INFO:root:Train (Epoch 98): Loss/seq after 02500 batchs: 611.0997314453125
INFO:root:Train (Epoch 98): Loss/seq after 02550 batchs: 604.5585327148438
INFO:root:Train (Epoch 98): Loss/seq after 02600 batchs: 603.6162719726562
INFO:root:Train (Epoch 98): Loss/seq after 02650 batchs: 601.3888549804688
INFO:root:Train (Epoch 98): Loss/seq after 02700 batchs: 599.0335693359375
INFO:root:Train (Epoch 98): Loss/seq after 02750 batchs: 601.5311279296875
INFO:root:Train (Epoch 98): Loss/seq after 02800 batchs: 603.636962890625
INFO:root:Train (Epoch 98): Loss/seq after 02850 batchs: 603.5594482421875
INFO:root:Train (Epoch 98): Loss/seq after 02900 batchs: 604.8980102539062
INFO:root:Train (Epoch 98): Loss/seq after 02950 batchs: 603.2845458984375
INFO:root:Train (Epoch 98): Loss/seq after 03000 batchs: 607.7731323242188
INFO:root:Train (Epoch 98): Loss/seq after 03050 batchs: 610.2221069335938
INFO:root:Train (Epoch 98): Loss/seq after 03100 batchs: 614.1959228515625
INFO:root:Train (Epoch 98): Loss/seq after 03150 batchs: 619.8094482421875
INFO:root:Train (Epoch 98): Loss/seq after 03200 batchs: 622.5008544921875
INFO:root:Train (Epoch 98): Loss/seq after 03250 batchs: 625.773193359375
INFO:root:Train (Epoch 98): Loss/seq after 03300 batchs: 624.61767578125
INFO:root:Train (Epoch 98): Loss/seq after 03350 batchs: 625.0568237304688
INFO:root:Train (Epoch 98): Loss/seq after 03400 batchs: 620.2169799804688
INFO:root:Train (Epoch 98): Loss/seq after 03450 batchs: 618.0032958984375
INFO:root:Train (Epoch 98): Loss/seq after 03500 batchs: 618.335693359375
INFO:root:Train (Epoch 98): Loss/seq after 03550 batchs: 615.027099609375
INFO:root:Train (Epoch 98): Loss/seq after 03600 batchs: 623.2789306640625
INFO:root:Train (Epoch 98): Loss/seq after 03650 batchs: 620.2648315429688
INFO:root:Train (Epoch 98): Loss/seq after 03700 batchs: 622.4219970703125
INFO:root:Train (Epoch 98): Loss/seq after 03750 batchs: 626.9364013671875
INFO:root:Train (Epoch 98): Loss/seq after 03800 batchs: 624.0034790039062
INFO:root:Train (Epoch 98): Loss/seq after 03850 batchs: 622.9038696289062
INFO:root:Train (Epoch 98): Loss/seq after 03900 batchs: 627.5870361328125
INFO:root:Train (Epoch 98): Loss/seq after 03950 batchs: 631.8621215820312
INFO:root:Train (Epoch 98): Loss/seq after 04000 batchs: 627.7322998046875
INFO:root:Train (Epoch 98): Loss/seq after 04050 batchs: 623.6221923828125
INFO:root:Train (Epoch 98): Loss/seq after 04100 batchs: 621.4085083007812
INFO:root:Train (Epoch 98): Loss/seq after 04150 batchs: 620.8407592773438
INFO:root:Train (Epoch 98): Loss/seq after 04200 batchs: 619.0902099609375
INFO:root:Train (Epoch 98): Loss/seq after 04250 batchs: 617.2531127929688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 98): Loss/seq after 00000 batches: 559.7125854492188
INFO:root:# Valid (Epoch 98): Loss/seq after 00050 batches: 725.0237426757812
INFO:root:# Valid (Epoch 98): Loss/seq after 00100 batches: 799.9574584960938
INFO:root:# Valid (Epoch 98): Loss/seq after 00150 batches: 606.6360473632812
INFO:root:# Valid (Epoch 98): Loss/seq after 00200 batches: 564.01806640625
INFO:root:Artifacts: Make stick videos for epoch 98
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_98_on_20220413_031838.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_98_index_546_on_20220413_031838.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 99): Loss/seq after 00000 batchs: 1158.8228759765625
INFO:root:Train (Epoch 99): Loss/seq after 00050 batchs: 847.0761108398438
INFO:root:Train (Epoch 99): Loss/seq after 00100 batchs: 864.046142578125
INFO:root:Train (Epoch 99): Loss/seq after 00150 batchs: 789.4554443359375
INFO:root:Train (Epoch 99): Loss/seq after 00200 batchs: 849.736328125
INFO:root:Train (Epoch 99): Loss/seq after 00250 batchs: 961.0720825195312
INFO:root:Train (Epoch 99): Loss/seq after 00300 batchs: 951.5230102539062
INFO:root:Train (Epoch 99): Loss/seq after 00350 batchs: 887.1966552734375
INFO:root:Train (Epoch 99): Loss/seq after 00400 batchs: 887.64794921875
INFO:root:Train (Epoch 99): Loss/seq after 00450 batchs: 865.215087890625
INFO:root:Train (Epoch 99): Loss/seq after 00500 batchs: 838.40673828125
INFO:root:Train (Epoch 99): Loss/seq after 00550 batchs: 811.7069702148438
INFO:root:Train (Epoch 99): Loss/seq after 00600 batchs: 783.3953247070312
INFO:root:Train (Epoch 99): Loss/seq after 00650 batchs: 765.2227172851562
INFO:root:Train (Epoch 99): Loss/seq after 00700 batchs: 741.669189453125
INFO:root:Train (Epoch 99): Loss/seq after 00750 batchs: 751.533935546875
INFO:root:Train (Epoch 99): Loss/seq after 00800 batchs: 753.8194580078125
INFO:root:Train (Epoch 99): Loss/seq after 00850 batchs: 731.1078491210938
INFO:root:Train (Epoch 99): Loss/seq after 00900 batchs: 717.5205078125
INFO:root:Train (Epoch 99): Loss/seq after 00950 batchs: 718.12744140625
INFO:root:Train (Epoch 99): Loss/seq after 01000 batchs: 709.4508056640625
INFO:root:Train (Epoch 99): Loss/seq after 01050 batchs: 697.66455078125
INFO:root:Train (Epoch 99): Loss/seq after 01100 batchs: 688.5072021484375
INFO:root:Train (Epoch 99): Loss/seq after 01150 batchs: 672.5288696289062
INFO:root:Train (Epoch 99): Loss/seq after 01200 batchs: 675.7974243164062
INFO:root:Train (Epoch 99): Loss/seq after 01250 batchs: 673.0675048828125
INFO:root:Train (Epoch 99): Loss/seq after 01300 batchs: 660.9517211914062
INFO:root:Train (Epoch 99): Loss/seq after 01350 batchs: 650.670654296875
INFO:root:Train (Epoch 99): Loss/seq after 01400 batchs: 657.48583984375
INFO:root:Train (Epoch 99): Loss/seq after 01450 batchs: 657.962646484375
INFO:root:Train (Epoch 99): Loss/seq after 01500 batchs: 663.219970703125
INFO:root:Train (Epoch 99): Loss/seq after 01550 batchs: 664.9256591796875
INFO:root:Train (Epoch 99): Loss/seq after 01600 batchs: 658.6702270507812
INFO:root:Train (Epoch 99): Loss/seq after 01650 batchs: 656.0857543945312
INFO:root:Train (Epoch 99): Loss/seq after 01700 batchs: 657.7324829101562
INFO:root:Train (Epoch 99): Loss/seq after 01750 batchs: 654.3600463867188
INFO:root:Train (Epoch 99): Loss/seq after 01800 batchs: 650.6636962890625
INFO:root:Train (Epoch 99): Loss/seq after 01850 batchs: 646.0143432617188
INFO:root:Train (Epoch 99): Loss/seq after 01900 batchs: 646.331787109375
INFO:root:Train (Epoch 99): Loss/seq after 01950 batchs: 644.1326904296875
INFO:root:Train (Epoch 99): Loss/seq after 02000 batchs: 641.7697143554688
INFO:root:Train (Epoch 99): Loss/seq after 02050 batchs: 639.5936279296875
INFO:root:Train (Epoch 99): Loss/seq after 02100 batchs: 636.059814453125
INFO:root:Train (Epoch 99): Loss/seq after 02150 batchs: 633.5252075195312
INFO:root:Train (Epoch 99): Loss/seq after 02200 batchs: 629.80419921875
INFO:root:Train (Epoch 99): Loss/seq after 02250 batchs: 628.7613525390625
INFO:root:Train (Epoch 99): Loss/seq after 02300 batchs: 627.8504638671875
INFO:root:Train (Epoch 99): Loss/seq after 02350 batchs: 622.8428955078125
INFO:root:Train (Epoch 99): Loss/seq after 02400 batchs: 623.742431640625
INFO:root:Train (Epoch 99): Loss/seq after 02450 batchs: 618.2730712890625
INFO:root:Train (Epoch 99): Loss/seq after 02500 batchs: 609.1102294921875
INFO:root:Train (Epoch 99): Loss/seq after 02550 batchs: 602.6036376953125
INFO:root:Train (Epoch 99): Loss/seq after 02600 batchs: 601.7288818359375
INFO:root:Train (Epoch 99): Loss/seq after 02650 batchs: 599.4580078125
INFO:root:Train (Epoch 99): Loss/seq after 02700 batchs: 597.1820678710938
INFO:root:Train (Epoch 99): Loss/seq after 02750 batchs: 599.3135986328125
INFO:root:Train (Epoch 99): Loss/seq after 02800 batchs: 601.8034057617188
INFO:root:Train (Epoch 99): Loss/seq after 02850 batchs: 601.8381958007812
INFO:root:Train (Epoch 99): Loss/seq after 02900 batchs: 603.1057739257812
INFO:root:Train (Epoch 99): Loss/seq after 02950 batchs: 601.50146484375
INFO:root:Train (Epoch 99): Loss/seq after 03000 batchs: 605.9501953125
INFO:root:Train (Epoch 99): Loss/seq after 03050 batchs: 608.2359008789062
INFO:root:Train (Epoch 99): Loss/seq after 03100 batchs: 612.8030395507812
INFO:root:Train (Epoch 99): Loss/seq after 03150 batchs: 618.6424560546875
INFO:root:Train (Epoch 99): Loss/seq after 03200 batchs: 621.206787109375
INFO:root:Train (Epoch 99): Loss/seq after 03250 batchs: 624.5619506835938
INFO:root:Train (Epoch 99): Loss/seq after 03300 batchs: 623.47607421875
INFO:root:Train (Epoch 99): Loss/seq after 03350 batchs: 623.7875366210938
INFO:root:Train (Epoch 99): Loss/seq after 03400 batchs: 618.955322265625
INFO:root:Train (Epoch 99): Loss/seq after 03450 batchs: 616.7664794921875
INFO:root:Train (Epoch 99): Loss/seq after 03500 batchs: 616.9252319335938
INFO:root:Train (Epoch 99): Loss/seq after 03550 batchs: 613.6404418945312
INFO:root:Train (Epoch 99): Loss/seq after 03600 batchs: 621.7622680664062
INFO:root:Train (Epoch 99): Loss/seq after 03650 batchs: 618.6425170898438
INFO:root:Train (Epoch 99): Loss/seq after 03700 batchs: 620.679443359375
INFO:root:Train (Epoch 99): Loss/seq after 03750 batchs: 625.2000122070312
INFO:root:Train (Epoch 99): Loss/seq after 03800 batchs: 622.2376098632812
INFO:root:Train (Epoch 99): Loss/seq after 03850 batchs: 621.0455932617188
INFO:root:Train (Epoch 99): Loss/seq after 03900 batchs: 625.5346069335938
INFO:root:Train (Epoch 99): Loss/seq after 03950 batchs: 629.3699951171875
INFO:root:Train (Epoch 99): Loss/seq after 04000 batchs: 625.2289428710938
INFO:root:Train (Epoch 99): Loss/seq after 04050 batchs: 621.1360473632812
INFO:root:Train (Epoch 99): Loss/seq after 04100 batchs: 618.9329833984375
INFO:root:Train (Epoch 99): Loss/seq after 04150 batchs: 618.3826293945312
INFO:root:Train (Epoch 99): Loss/seq after 04200 batchs: 616.5794677734375
INFO:root:Train (Epoch 99): Loss/seq after 04250 batchs: 614.7520141601562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 99): Loss/seq after 00000 batches: 576.7721557617188
INFO:root:# Valid (Epoch 99): Loss/seq after 00050 batches: 759.6915283203125
INFO:root:# Valid (Epoch 99): Loss/seq after 00100 batches: 810.2160034179688
INFO:root:# Valid (Epoch 99): Loss/seq after 00150 batches: 613.970947265625
INFO:root:# Valid (Epoch 99): Loss/seq after 00200 batches: 568.390625
INFO:root:Artifacts: Make stick videos for epoch 99
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_99_on_20220413_032401.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_99_index_1743_on_20220413_032401.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 100): Loss/seq after 00000 batchs: 1080.63037109375
INFO:root:Train (Epoch 100): Loss/seq after 00050 batchs: 853.8775634765625
INFO:root:Train (Epoch 100): Loss/seq after 00100 batchs: 868.3973388671875
INFO:root:Train (Epoch 100): Loss/seq after 00150 batchs: 787.7162475585938
INFO:root:Train (Epoch 100): Loss/seq after 00200 batchs: 852.651123046875
INFO:root:Train (Epoch 100): Loss/seq after 00250 batchs: 964.4801635742188
INFO:root:Train (Epoch 100): Loss/seq after 00300 batchs: 953.8673706054688
INFO:root:Train (Epoch 100): Loss/seq after 00350 batchs: 889.2952880859375
INFO:root:Train (Epoch 100): Loss/seq after 00400 batchs: 889.7523803710938
INFO:root:Train (Epoch 100): Loss/seq after 00450 batchs: 866.97705078125
INFO:root:Train (Epoch 100): Loss/seq after 00500 batchs: 839.7018432617188
INFO:root:Train (Epoch 100): Loss/seq after 00550 batchs: 811.7188110351562
INFO:root:Train (Epoch 100): Loss/seq after 00600 batchs: 783.2507934570312
INFO:root:Train (Epoch 100): Loss/seq after 00650 batchs: 765.5680541992188
INFO:root:Train (Epoch 100): Loss/seq after 00700 batchs: 743.1094360351562
INFO:root:Train (Epoch 100): Loss/seq after 00750 batchs: 751.8320922851562
INFO:root:Train (Epoch 100): Loss/seq after 00800 batchs: 753.4025268554688
INFO:root:Train (Epoch 100): Loss/seq after 00850 batchs: 730.0413208007812
INFO:root:Train (Epoch 100): Loss/seq after 00900 batchs: 716.3377075195312
INFO:root:Train (Epoch 100): Loss/seq after 00950 batchs: 716.2083129882812
INFO:root:Train (Epoch 100): Loss/seq after 01000 batchs: 706.5798950195312
INFO:root:Train (Epoch 100): Loss/seq after 01050 batchs: 695.0194702148438
INFO:root:Train (Epoch 100): Loss/seq after 01100 batchs: 686.1868896484375
INFO:root:Train (Epoch 100): Loss/seq after 01150 batchs: 670.2560424804688
INFO:root:Train (Epoch 100): Loss/seq after 01200 batchs: 673.5243530273438
INFO:root:Train (Epoch 100): Loss/seq after 01250 batchs: 670.6058959960938
INFO:root:Train (Epoch 100): Loss/seq after 01300 batchs: 658.2562255859375
INFO:root:Train (Epoch 100): Loss/seq after 01350 batchs: 648.5875244140625
INFO:root:Train (Epoch 100): Loss/seq after 01400 batchs: 656.0409545898438
INFO:root:Train (Epoch 100): Loss/seq after 01450 batchs: 656.5150146484375
INFO:root:Train (Epoch 100): Loss/seq after 01500 batchs: 661.8372802734375
INFO:root:Train (Epoch 100): Loss/seq after 01550 batchs: 663.7609252929688
INFO:root:Train (Epoch 100): Loss/seq after 01600 batchs: 657.671875
INFO:root:Train (Epoch 100): Loss/seq after 01650 batchs: 654.9995727539062
INFO:root:Train (Epoch 100): Loss/seq after 01700 batchs: 656.58154296875
INFO:root:Train (Epoch 100): Loss/seq after 01750 batchs: 653.1116333007812
INFO:root:Train (Epoch 100): Loss/seq after 01800 batchs: 649.519287109375
INFO:root:Train (Epoch 100): Loss/seq after 01850 batchs: 644.9169921875
INFO:root:Train (Epoch 100): Loss/seq after 01900 batchs: 645.1954345703125
INFO:root:Train (Epoch 100): Loss/seq after 01950 batchs: 643.029541015625
INFO:root:Train (Epoch 100): Loss/seq after 02000 batchs: 640.726806640625
INFO:root:Train (Epoch 100): Loss/seq after 02050 batchs: 638.4909057617188
INFO:root:Train (Epoch 100): Loss/seq after 02100 batchs: 634.988037109375
INFO:root:Train (Epoch 100): Loss/seq after 02150 batchs: 632.469970703125
INFO:root:Train (Epoch 100): Loss/seq after 02200 batchs: 628.6647338867188
INFO:root:Train (Epoch 100): Loss/seq after 02250 batchs: 627.0982055664062
INFO:root:Train (Epoch 100): Loss/seq after 02300 batchs: 625.1550903320312
INFO:root:Train (Epoch 100): Loss/seq after 02350 batchs: 620.2525024414062
INFO:root:Train (Epoch 100): Loss/seq after 02400 batchs: 621.15380859375
INFO:root:Train (Epoch 100): Loss/seq after 02450 batchs: 615.7241821289062
INFO:root:Train (Epoch 100): Loss/seq after 02500 batchs: 606.6445922851562
INFO:root:Train (Epoch 100): Loss/seq after 02550 batchs: 600.1607666015625
INFO:root:Train (Epoch 100): Loss/seq after 02600 batchs: 599.2493896484375
INFO:root:Train (Epoch 100): Loss/seq after 02650 batchs: 597.0081787109375
INFO:root:Train (Epoch 100): Loss/seq after 02700 batchs: 594.6663208007812
INFO:root:Train (Epoch 100): Loss/seq after 02750 batchs: 596.5020751953125
INFO:root:Train (Epoch 100): Loss/seq after 02800 batchs: 598.4671630859375
INFO:root:Train (Epoch 100): Loss/seq after 02850 batchs: 598.4661254882812
INFO:root:Train (Epoch 100): Loss/seq after 02900 batchs: 599.9423828125
INFO:root:Train (Epoch 100): Loss/seq after 02950 batchs: 598.5667114257812
INFO:root:Train (Epoch 100): Loss/seq after 03000 batchs: 603.1278686523438
INFO:root:Train (Epoch 100): Loss/seq after 03050 batchs: 605.2396240234375
INFO:root:Train (Epoch 100): Loss/seq after 03100 batchs: 609.129150390625
INFO:root:Train (Epoch 100): Loss/seq after 03150 batchs: 614.5391845703125
INFO:root:Train (Epoch 100): Loss/seq after 03200 batchs: 616.8336181640625
INFO:root:Train (Epoch 100): Loss/seq after 03250 batchs: 619.8975219726562
INFO:root:Train (Epoch 100): Loss/seq after 03300 batchs: 618.537841796875
INFO:root:Train (Epoch 100): Loss/seq after 03350 batchs: 618.7556762695312
INFO:root:Train (Epoch 100): Loss/seq after 03400 batchs: 613.9076538085938
INFO:root:Train (Epoch 100): Loss/seq after 03450 batchs: 611.7569580078125
INFO:root:Train (Epoch 100): Loss/seq after 03500 batchs: 612.0057373046875
INFO:root:Train (Epoch 100): Loss/seq after 03550 batchs: 608.7032470703125
INFO:root:Train (Epoch 100): Loss/seq after 03600 batchs: 616.6290893554688
INFO:root:Train (Epoch 100): Loss/seq after 03650 batchs: 613.5950317382812
INFO:root:Train (Epoch 100): Loss/seq after 03700 batchs: 615.7499389648438
INFO:root:Train (Epoch 100): Loss/seq after 03750 batchs: 620.3339233398438
INFO:root:Train (Epoch 100): Loss/seq after 03800 batchs: 617.450439453125
INFO:root:Train (Epoch 100): Loss/seq after 03850 batchs: 616.2890014648438
INFO:root:Train (Epoch 100): Loss/seq after 03900 batchs: 620.718994140625
INFO:root:Train (Epoch 100): Loss/seq after 03950 batchs: 624.7088012695312
INFO:root:Train (Epoch 100): Loss/seq after 04000 batchs: 620.6218872070312
INFO:root:Train (Epoch 100): Loss/seq after 04050 batchs: 616.59130859375
INFO:root:Train (Epoch 100): Loss/seq after 04100 batchs: 614.3910522460938
INFO:root:Train (Epoch 100): Loss/seq after 04150 batchs: 613.8468627929688
INFO:root:Train (Epoch 100): Loss/seq after 04200 batchs: 612.0526733398438
INFO:root:Train (Epoch 100): Loss/seq after 04250 batchs: 610.2156982421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 100): Loss/seq after 00000 batches: 522.9656372070312
INFO:root:# Valid (Epoch 100): Loss/seq after 00050 batches: 740.7017211914062
INFO:root:# Valid (Epoch 100): Loss/seq after 00100 batches: 824.3338623046875
INFO:root:# Valid (Epoch 100): Loss/seq after 00150 batches: 626.1486206054688
INFO:root:# Valid (Epoch 100): Loss/seq after 00200 batches: 583.2049560546875
INFO:root:Artifacts: Make stick videos for epoch 100
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_100_on_20220413_032925.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_100_index_336_on_20220413_032925.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 101): Loss/seq after 00000 batchs: 1099.4515380859375
INFO:root:Train (Epoch 101): Loss/seq after 00050 batchs: 846.0142211914062
INFO:root:Train (Epoch 101): Loss/seq after 00100 batchs: 856.07275390625
INFO:root:Train (Epoch 101): Loss/seq after 00150 batchs: 775.3751220703125
INFO:root:Train (Epoch 101): Loss/seq after 00200 batchs: 841.786376953125
INFO:root:Train (Epoch 101): Loss/seq after 00250 batchs: 951.7816772460938
INFO:root:Train (Epoch 101): Loss/seq after 00300 batchs: 942.5979614257812
INFO:root:Train (Epoch 101): Loss/seq after 00350 batchs: 879.2271118164062
INFO:root:Train (Epoch 101): Loss/seq after 00400 batchs: 882.5535888671875
INFO:root:Train (Epoch 101): Loss/seq after 00450 batchs: 860.266357421875
INFO:root:Train (Epoch 101): Loss/seq after 00500 batchs: 833.453857421875
INFO:root:Train (Epoch 101): Loss/seq after 00550 batchs: 807.5775146484375
INFO:root:Train (Epoch 101): Loss/seq after 00600 batchs: 779.1029052734375
INFO:root:Train (Epoch 101): Loss/seq after 00650 batchs: 760.1802368164062
INFO:root:Train (Epoch 101): Loss/seq after 00700 batchs: 736.1793823242188
INFO:root:Train (Epoch 101): Loss/seq after 00750 batchs: 744.2779541015625
INFO:root:Train (Epoch 101): Loss/seq after 00800 batchs: 746.42822265625
INFO:root:Train (Epoch 101): Loss/seq after 00850 batchs: 723.4790649414062
INFO:root:Train (Epoch 101): Loss/seq after 00900 batchs: 710.3032836914062
INFO:root:Train (Epoch 101): Loss/seq after 00950 batchs: 711.627197265625
INFO:root:Train (Epoch 101): Loss/seq after 01000 batchs: 702.155029296875
INFO:root:Train (Epoch 101): Loss/seq after 01050 batchs: 691.2278442382812
INFO:root:Train (Epoch 101): Loss/seq after 01100 batchs: 681.7158203125
INFO:root:Train (Epoch 101): Loss/seq after 01150 batchs: 665.9703979492188
INFO:root:Train (Epoch 101): Loss/seq after 01200 batchs: 669.2928466796875
INFO:root:Train (Epoch 101): Loss/seq after 01250 batchs: 666.677490234375
INFO:root:Train (Epoch 101): Loss/seq after 01300 batchs: 654.0357055664062
INFO:root:Train (Epoch 101): Loss/seq after 01350 batchs: 643.9271850585938
INFO:root:Train (Epoch 101): Loss/seq after 01400 batchs: 650.6399536132812
INFO:root:Train (Epoch 101): Loss/seq after 01450 batchs: 651.2481689453125
INFO:root:Train (Epoch 101): Loss/seq after 01500 batchs: 656.8111572265625
INFO:root:Train (Epoch 101): Loss/seq after 01550 batchs: 658.6641235351562
INFO:root:Train (Epoch 101): Loss/seq after 01600 batchs: 652.5576782226562
INFO:root:Train (Epoch 101): Loss/seq after 01650 batchs: 649.9884643554688
INFO:root:Train (Epoch 101): Loss/seq after 01700 batchs: 652.0580444335938
INFO:root:Train (Epoch 101): Loss/seq after 01750 batchs: 648.6747436523438
INFO:root:Train (Epoch 101): Loss/seq after 01800 batchs: 645.1407470703125
INFO:root:Train (Epoch 101): Loss/seq after 01850 batchs: 640.5755004882812
INFO:root:Train (Epoch 101): Loss/seq after 01900 batchs: 640.8671875
INFO:root:Train (Epoch 101): Loss/seq after 01950 batchs: 638.9225463867188
INFO:root:Train (Epoch 101): Loss/seq after 02000 batchs: 636.6559448242188
INFO:root:Train (Epoch 101): Loss/seq after 02050 batchs: 634.4465942382812
INFO:root:Train (Epoch 101): Loss/seq after 02100 batchs: 631.0571899414062
INFO:root:Train (Epoch 101): Loss/seq after 02150 batchs: 628.5888061523438
INFO:root:Train (Epoch 101): Loss/seq after 02200 batchs: 624.9659423828125
INFO:root:Train (Epoch 101): Loss/seq after 02250 batchs: 623.4896240234375
INFO:root:Train (Epoch 101): Loss/seq after 02300 batchs: 621.4235229492188
INFO:root:Train (Epoch 101): Loss/seq after 02350 batchs: 616.486572265625
INFO:root:Train (Epoch 101): Loss/seq after 02400 batchs: 617.4871826171875
INFO:root:Train (Epoch 101): Loss/seq after 02450 batchs: 612.1227416992188
INFO:root:Train (Epoch 101): Loss/seq after 02500 batchs: 603.080078125
INFO:root:Train (Epoch 101): Loss/seq after 02550 batchs: 596.6832275390625
INFO:root:Train (Epoch 101): Loss/seq after 02600 batchs: 595.7889404296875
INFO:root:Train (Epoch 101): Loss/seq after 02650 batchs: 593.6610107421875
INFO:root:Train (Epoch 101): Loss/seq after 02700 batchs: 591.4149780273438
INFO:root:Train (Epoch 101): Loss/seq after 02750 batchs: 592.1106567382812
INFO:root:Train (Epoch 101): Loss/seq after 02800 batchs: 594.0060424804688
INFO:root:Train (Epoch 101): Loss/seq after 02850 batchs: 593.8343505859375
INFO:root:Train (Epoch 101): Loss/seq after 02900 batchs: 595.317138671875
INFO:root:Train (Epoch 101): Loss/seq after 02950 batchs: 593.8836059570312
INFO:root:Train (Epoch 101): Loss/seq after 03000 batchs: 598.5187377929688
INFO:root:Train (Epoch 101): Loss/seq after 03050 batchs: 601.1446533203125
INFO:root:Train (Epoch 101): Loss/seq after 03100 batchs: 605.1387329101562
INFO:root:Train (Epoch 101): Loss/seq after 03150 batchs: 610.8610229492188
INFO:root:Train (Epoch 101): Loss/seq after 03200 batchs: 613.1698608398438
INFO:root:Train (Epoch 101): Loss/seq after 03250 batchs: 616.244140625
INFO:root:Train (Epoch 101): Loss/seq after 03300 batchs: 614.8890380859375
INFO:root:Train (Epoch 101): Loss/seq after 03350 batchs: 615.366943359375
INFO:root:Train (Epoch 101): Loss/seq after 03400 batchs: 610.6146240234375
INFO:root:Train (Epoch 101): Loss/seq after 03450 batchs: 608.65966796875
INFO:root:Train (Epoch 101): Loss/seq after 03500 batchs: 609.1627807617188
INFO:root:Train (Epoch 101): Loss/seq after 03550 batchs: 605.8916625976562
INFO:root:Train (Epoch 101): Loss/seq after 03600 batchs: 613.7756958007812
INFO:root:Train (Epoch 101): Loss/seq after 03650 batchs: 610.7501220703125
INFO:root:Train (Epoch 101): Loss/seq after 03700 batchs: 612.9220581054688
INFO:root:Train (Epoch 101): Loss/seq after 03750 batchs: 617.498779296875
INFO:root:Train (Epoch 101): Loss/seq after 03800 batchs: 614.7111206054688
INFO:root:Train (Epoch 101): Loss/seq after 03850 batchs: 613.6392211914062
INFO:root:Train (Epoch 101): Loss/seq after 03900 batchs: 617.9742431640625
INFO:root:Train (Epoch 101): Loss/seq after 03950 batchs: 621.8344116210938
INFO:root:Train (Epoch 101): Loss/seq after 04000 batchs: 617.6951293945312
INFO:root:Train (Epoch 101): Loss/seq after 04050 batchs: 613.6807861328125
INFO:root:Train (Epoch 101): Loss/seq after 04100 batchs: 611.5350341796875
INFO:root:Train (Epoch 101): Loss/seq after 04150 batchs: 611.0541381835938
INFO:root:Train (Epoch 101): Loss/seq after 04200 batchs: 609.3137817382812
INFO:root:Train (Epoch 101): Loss/seq after 04250 batchs: 607.4801025390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 101): Loss/seq after 00000 batches: 539.0656127929688
INFO:root:# Valid (Epoch 101): Loss/seq after 00050 batches: 744.4827270507812
INFO:root:# Valid (Epoch 101): Loss/seq after 00100 batches: 812.6493530273438
INFO:root:# Valid (Epoch 101): Loss/seq after 00150 batches: 615.7882080078125
INFO:root:# Valid (Epoch 101): Loss/seq after 00200 batches: 571.4609375
INFO:root:Artifacts: Make stick videos for epoch 101
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_101_on_20220413_033450.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_101_index_235_on_20220413_033450.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 102): Loss/seq after 00000 batchs: 984.3629760742188
INFO:root:Train (Epoch 102): Loss/seq after 00050 batchs: 845.8574829101562
INFO:root:Train (Epoch 102): Loss/seq after 00100 batchs: 855.1739501953125
INFO:root:Train (Epoch 102): Loss/seq after 00150 batchs: 780.62939453125
INFO:root:Train (Epoch 102): Loss/seq after 00200 batchs: 844.9727783203125
INFO:root:Train (Epoch 102): Loss/seq after 00250 batchs: 953.0228271484375
INFO:root:Train (Epoch 102): Loss/seq after 00300 batchs: 945.16455078125
INFO:root:Train (Epoch 102): Loss/seq after 00350 batchs: 881.8438110351562
INFO:root:Train (Epoch 102): Loss/seq after 00400 batchs: 883.5164184570312
INFO:root:Train (Epoch 102): Loss/seq after 00450 batchs: 861.4491577148438
INFO:root:Train (Epoch 102): Loss/seq after 00500 batchs: 833.7869262695312
INFO:root:Train (Epoch 102): Loss/seq after 00550 batchs: 806.3436889648438
INFO:root:Train (Epoch 102): Loss/seq after 00600 batchs: 777.2559204101562
INFO:root:Train (Epoch 102): Loss/seq after 00650 batchs: 757.2129516601562
INFO:root:Train (Epoch 102): Loss/seq after 00700 batchs: 734.9379272460938
INFO:root:Train (Epoch 102): Loss/seq after 00750 batchs: 742.3893432617188
INFO:root:Train (Epoch 102): Loss/seq after 00800 batchs: 742.8849487304688
INFO:root:Train (Epoch 102): Loss/seq after 00850 batchs: 719.9421997070312
INFO:root:Train (Epoch 102): Loss/seq after 00900 batchs: 705.8545532226562
INFO:root:Train (Epoch 102): Loss/seq after 00950 batchs: 706.566162109375
INFO:root:Train (Epoch 102): Loss/seq after 01000 batchs: 696.5415649414062
INFO:root:Train (Epoch 102): Loss/seq after 01050 batchs: 685.3650512695312
INFO:root:Train (Epoch 102): Loss/seq after 01100 batchs: 675.5971069335938
INFO:root:Train (Epoch 102): Loss/seq after 01150 batchs: 659.8064575195312
INFO:root:Train (Epoch 102): Loss/seq after 01200 batchs: 663.4427490234375
INFO:root:Train (Epoch 102): Loss/seq after 01250 batchs: 660.5645141601562
INFO:root:Train (Epoch 102): Loss/seq after 01300 batchs: 648.4153442382812
INFO:root:Train (Epoch 102): Loss/seq after 01350 batchs: 638.0205078125
INFO:root:Train (Epoch 102): Loss/seq after 01400 batchs: 645.015869140625
INFO:root:Train (Epoch 102): Loss/seq after 01450 batchs: 645.6455688476562
INFO:root:Train (Epoch 102): Loss/seq after 01500 batchs: 651.3165893554688
INFO:root:Train (Epoch 102): Loss/seq after 01550 batchs: 653.2718505859375
INFO:root:Train (Epoch 102): Loss/seq after 01600 batchs: 647.0584106445312
INFO:root:Train (Epoch 102): Loss/seq after 01650 batchs: 644.5161743164062
INFO:root:Train (Epoch 102): Loss/seq after 01700 batchs: 645.849853515625
INFO:root:Train (Epoch 102): Loss/seq after 01750 batchs: 642.6918334960938
INFO:root:Train (Epoch 102): Loss/seq after 01800 batchs: 639.2088623046875
INFO:root:Train (Epoch 102): Loss/seq after 01850 batchs: 634.7107543945312
INFO:root:Train (Epoch 102): Loss/seq after 01900 batchs: 634.8803100585938
INFO:root:Train (Epoch 102): Loss/seq after 01950 batchs: 632.9427490234375
INFO:root:Train (Epoch 102): Loss/seq after 02000 batchs: 630.7451782226562
INFO:root:Train (Epoch 102): Loss/seq after 02050 batchs: 628.8778076171875
INFO:root:Train (Epoch 102): Loss/seq after 02100 batchs: 625.6005859375
INFO:root:Train (Epoch 102): Loss/seq after 02150 batchs: 623.384765625
INFO:root:Train (Epoch 102): Loss/seq after 02200 batchs: 619.7916259765625
INFO:root:Train (Epoch 102): Loss/seq after 02250 batchs: 618.581298828125
INFO:root:Train (Epoch 102): Loss/seq after 02300 batchs: 615.8984375
INFO:root:Train (Epoch 102): Loss/seq after 02350 batchs: 610.9286499023438
INFO:root:Train (Epoch 102): Loss/seq after 02400 batchs: 611.9379272460938
INFO:root:Train (Epoch 102): Loss/seq after 02450 batchs: 606.5633544921875
INFO:root:Train (Epoch 102): Loss/seq after 02500 batchs: 597.6148071289062
INFO:root:Train (Epoch 102): Loss/seq after 02550 batchs: 591.3272094726562
INFO:root:Train (Epoch 102): Loss/seq after 02600 batchs: 590.4741821289062
INFO:root:Train (Epoch 102): Loss/seq after 02650 batchs: 588.355224609375
INFO:root:Train (Epoch 102): Loss/seq after 02700 batchs: 586.2218017578125
INFO:root:Train (Epoch 102): Loss/seq after 02750 batchs: 587.1815185546875
INFO:root:Train (Epoch 102): Loss/seq after 02800 batchs: 588.693115234375
INFO:root:Train (Epoch 102): Loss/seq after 02850 batchs: 588.7308959960938
INFO:root:Train (Epoch 102): Loss/seq after 02900 batchs: 590.096435546875
INFO:root:Train (Epoch 102): Loss/seq after 02950 batchs: 588.7376098632812
INFO:root:Train (Epoch 102): Loss/seq after 03000 batchs: 593.4490966796875
INFO:root:Train (Epoch 102): Loss/seq after 03050 batchs: 595.3685913085938
INFO:root:Train (Epoch 102): Loss/seq after 03100 batchs: 599.3619384765625
INFO:root:Train (Epoch 102): Loss/seq after 03150 batchs: 604.7631225585938
INFO:root:Train (Epoch 102): Loss/seq after 03200 batchs: 607.1376342773438
INFO:root:Train (Epoch 102): Loss/seq after 03250 batchs: 610.4437866210938
INFO:root:Train (Epoch 102): Loss/seq after 03300 batchs: 609.390380859375
INFO:root:Train (Epoch 102): Loss/seq after 03350 batchs: 609.6248168945312
INFO:root:Train (Epoch 102): Loss/seq after 03400 batchs: 604.8872680664062
INFO:root:Train (Epoch 102): Loss/seq after 03450 batchs: 602.865234375
INFO:root:Train (Epoch 102): Loss/seq after 03500 batchs: 603.2047119140625
INFO:root:Train (Epoch 102): Loss/seq after 03550 batchs: 600.072998046875
INFO:root:Train (Epoch 102): Loss/seq after 03600 batchs: 608.2908935546875
INFO:root:Train (Epoch 102): Loss/seq after 03650 batchs: 605.3841552734375
INFO:root:Train (Epoch 102): Loss/seq after 03700 batchs: 607.5777587890625
INFO:root:Train (Epoch 102): Loss/seq after 03750 batchs: 612.25244140625
INFO:root:Train (Epoch 102): Loss/seq after 03800 batchs: 609.45166015625
INFO:root:Train (Epoch 102): Loss/seq after 03850 batchs: 608.3947143554688
INFO:root:Train (Epoch 102): Loss/seq after 03900 batchs: 612.6373291015625
INFO:root:Train (Epoch 102): Loss/seq after 03950 batchs: 616.404052734375
INFO:root:Train (Epoch 102): Loss/seq after 04000 batchs: 612.2716064453125
INFO:root:Train (Epoch 102): Loss/seq after 04050 batchs: 608.3084106445312
INFO:root:Train (Epoch 102): Loss/seq after 04100 batchs: 606.1900024414062
INFO:root:Train (Epoch 102): Loss/seq after 04150 batchs: 605.7057495117188
INFO:root:Train (Epoch 102): Loss/seq after 04200 batchs: 603.9024047851562
INFO:root:Train (Epoch 102): Loss/seq after 04250 batchs: 602.3585815429688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 102): Loss/seq after 00000 batches: 533.8619995117188
INFO:root:# Valid (Epoch 102): Loss/seq after 00050 batches: 715.968017578125
INFO:root:# Valid (Epoch 102): Loss/seq after 00100 batches: 808.4898681640625
INFO:root:# Valid (Epoch 102): Loss/seq after 00150 batches: 610.7572631835938
INFO:root:# Valid (Epoch 102): Loss/seq after 00200 batches: 567.1929931640625
INFO:root:Artifacts: Make stick videos for epoch 102
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_102_on_20220413_034018.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_102_index_1892_on_20220413_034018.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 103): Loss/seq after 00000 batchs: 1101.7744140625
INFO:root:Train (Epoch 103): Loss/seq after 00050 batchs: 840.3433227539062
INFO:root:Train (Epoch 103): Loss/seq after 00100 batchs: 841.02978515625
INFO:root:Train (Epoch 103): Loss/seq after 00150 batchs: 767.1455688476562
INFO:root:Train (Epoch 103): Loss/seq after 00200 batchs: 831.1588134765625
INFO:root:Train (Epoch 103): Loss/seq after 00250 batchs: 943.4432373046875
INFO:root:Train (Epoch 103): Loss/seq after 00300 batchs: 936.0315551757812
INFO:root:Train (Epoch 103): Loss/seq after 00350 batchs: 873.1925659179688
INFO:root:Train (Epoch 103): Loss/seq after 00400 batchs: 873.19384765625
INFO:root:Train (Epoch 103): Loss/seq after 00450 batchs: 851.84326171875
INFO:root:Train (Epoch 103): Loss/seq after 00500 batchs: 825.0698852539062
INFO:root:Train (Epoch 103): Loss/seq after 00550 batchs: 798.2745971679688
INFO:root:Train (Epoch 103): Loss/seq after 00600 batchs: 770.5354614257812
INFO:root:Train (Epoch 103): Loss/seq after 00650 batchs: 748.9662475585938
INFO:root:Train (Epoch 103): Loss/seq after 00700 batchs: 724.9265747070312
INFO:root:Train (Epoch 103): Loss/seq after 00750 batchs: 732.416748046875
INFO:root:Train (Epoch 103): Loss/seq after 00800 batchs: 734.01318359375
INFO:root:Train (Epoch 103): Loss/seq after 00850 batchs: 711.2100219726562
INFO:root:Train (Epoch 103): Loss/seq after 00900 batchs: 697.563232421875
INFO:root:Train (Epoch 103): Loss/seq after 00950 batchs: 698.3656005859375
INFO:root:Train (Epoch 103): Loss/seq after 01000 batchs: 689.409423828125
INFO:root:Train (Epoch 103): Loss/seq after 01050 batchs: 680.445068359375
INFO:root:Train (Epoch 103): Loss/seq after 01100 batchs: 671.9268798828125
INFO:root:Train (Epoch 103): Loss/seq after 01150 batchs: 656.5296020507812
INFO:root:Train (Epoch 103): Loss/seq after 01200 batchs: 660.6708984375
INFO:root:Train (Epoch 103): Loss/seq after 01250 batchs: 657.9223022460938
INFO:root:Train (Epoch 103): Loss/seq after 01300 batchs: 645.1129760742188
INFO:root:Train (Epoch 103): Loss/seq after 01350 batchs: 635.1075439453125
INFO:root:Train (Epoch 103): Loss/seq after 01400 batchs: 641.7459716796875
INFO:root:Train (Epoch 103): Loss/seq after 01450 batchs: 642.4922485351562
INFO:root:Train (Epoch 103): Loss/seq after 01500 batchs: 648.109130859375
INFO:root:Train (Epoch 103): Loss/seq after 01550 batchs: 650.1907958984375
INFO:root:Train (Epoch 103): Loss/seq after 01600 batchs: 644.0750732421875
INFO:root:Train (Epoch 103): Loss/seq after 01650 batchs: 641.4522094726562
INFO:root:Train (Epoch 103): Loss/seq after 01700 batchs: 642.7708740234375
INFO:root:Train (Epoch 103): Loss/seq after 01750 batchs: 639.5540161132812
INFO:root:Train (Epoch 103): Loss/seq after 01800 batchs: 636.1956176757812
INFO:root:Train (Epoch 103): Loss/seq after 01850 batchs: 631.7029418945312
INFO:root:Train (Epoch 103): Loss/seq after 01900 batchs: 631.8446044921875
INFO:root:Train (Epoch 103): Loss/seq after 01950 batchs: 629.8983154296875
INFO:root:Train (Epoch 103): Loss/seq after 02000 batchs: 627.7387084960938
INFO:root:Train (Epoch 103): Loss/seq after 02050 batchs: 625.7802734375
INFO:root:Train (Epoch 103): Loss/seq after 02100 batchs: 622.5335083007812
INFO:root:Train (Epoch 103): Loss/seq after 02150 batchs: 620.3876953125
INFO:root:Train (Epoch 103): Loss/seq after 02200 batchs: 616.9173583984375
INFO:root:Train (Epoch 103): Loss/seq after 02250 batchs: 615.367431640625
INFO:root:Train (Epoch 103): Loss/seq after 02300 batchs: 613.1187133789062
INFO:root:Train (Epoch 103): Loss/seq after 02350 batchs: 608.0770263671875
INFO:root:Train (Epoch 103): Loss/seq after 02400 batchs: 609.1402587890625
INFO:root:Train (Epoch 103): Loss/seq after 02450 batchs: 603.7720336914062
INFO:root:Train (Epoch 103): Loss/seq after 02500 batchs: 594.8906860351562
INFO:root:Train (Epoch 103): Loss/seq after 02550 batchs: 588.593994140625
INFO:root:Train (Epoch 103): Loss/seq after 02600 batchs: 587.7504272460938
INFO:root:Train (Epoch 103): Loss/seq after 02650 batchs: 585.7100219726562
INFO:root:Train (Epoch 103): Loss/seq after 02700 batchs: 583.52978515625
INFO:root:Train (Epoch 103): Loss/seq after 02750 batchs: 583.9149780273438
INFO:root:Train (Epoch 103): Loss/seq after 02800 batchs: 585.1234130859375
INFO:root:Train (Epoch 103): Loss/seq after 02850 batchs: 585.2540893554688
INFO:root:Train (Epoch 103): Loss/seq after 02900 batchs: 586.490478515625
INFO:root:Train (Epoch 103): Loss/seq after 02950 batchs: 585.0785522460938
INFO:root:Train (Epoch 103): Loss/seq after 03000 batchs: 589.814453125
INFO:root:Train (Epoch 103): Loss/seq after 03050 batchs: 592.06298828125
INFO:root:Train (Epoch 103): Loss/seq after 03100 batchs: 596.3119506835938
INFO:root:Train (Epoch 103): Loss/seq after 03150 batchs: 601.75634765625
INFO:root:Train (Epoch 103): Loss/seq after 03200 batchs: 603.7377319335938
INFO:root:Train (Epoch 103): Loss/seq after 03250 batchs: 606.4838256835938
INFO:root:Train (Epoch 103): Loss/seq after 03300 batchs: 605.3001708984375
INFO:root:Train (Epoch 103): Loss/seq after 03350 batchs: 605.3709716796875
INFO:root:Train (Epoch 103): Loss/seq after 03400 batchs: 600.7699584960938
INFO:root:Train (Epoch 103): Loss/seq after 03450 batchs: 598.763671875
INFO:root:Train (Epoch 103): Loss/seq after 03500 batchs: 599.0927734375
INFO:root:Train (Epoch 103): Loss/seq after 03550 batchs: 596.0604248046875
INFO:root:Train (Epoch 103): Loss/seq after 03600 batchs: 604.1531372070312
INFO:root:Train (Epoch 103): Loss/seq after 03650 batchs: 601.2833251953125
INFO:root:Train (Epoch 103): Loss/seq after 03700 batchs: 603.6288452148438
INFO:root:Train (Epoch 103): Loss/seq after 03750 batchs: 608.3006591796875
INFO:root:Train (Epoch 103): Loss/seq after 03800 batchs: 605.5479736328125
INFO:root:Train (Epoch 103): Loss/seq after 03850 batchs: 604.4337158203125
INFO:root:Train (Epoch 103): Loss/seq after 03900 batchs: 608.6077880859375
INFO:root:Train (Epoch 103): Loss/seq after 03950 batchs: 612.3035888671875
INFO:root:Train (Epoch 103): Loss/seq after 04000 batchs: 608.1911010742188
INFO:root:Train (Epoch 103): Loss/seq after 04050 batchs: 604.2991943359375
INFO:root:Train (Epoch 103): Loss/seq after 04100 batchs: 602.1383056640625
INFO:root:Train (Epoch 103): Loss/seq after 04150 batchs: 601.685546875
INFO:root:Train (Epoch 103): Loss/seq after 04200 batchs: 599.952880859375
INFO:root:Train (Epoch 103): Loss/seq after 04250 batchs: 598.1236572265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 103): Loss/seq after 00000 batches: 498.51263427734375
INFO:root:# Valid (Epoch 103): Loss/seq after 00050 batches: 699.83544921875
INFO:root:# Valid (Epoch 103): Loss/seq after 00100 batches: 777.9586791992188
INFO:root:# Valid (Epoch 103): Loss/seq after 00150 batches: 586.8676147460938
INFO:root:# Valid (Epoch 103): Loss/seq after 00200 batches: 547.2717895507812
INFO:root:Artifacts: Make stick videos for epoch 103
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_103_on_20220413_034543.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_103_index_1100_on_20220413_034543.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 104): Loss/seq after 00000 batchs: 992.3125610351562
INFO:root:Train (Epoch 104): Loss/seq after 00050 batchs: 830.08544921875
INFO:root:Train (Epoch 104): Loss/seq after 00100 batchs: 828.9269409179688
INFO:root:Train (Epoch 104): Loss/seq after 00150 batchs: 757.6358642578125
INFO:root:Train (Epoch 104): Loss/seq after 00200 batchs: 820.04345703125
INFO:root:Train (Epoch 104): Loss/seq after 00250 batchs: 934.8301391601562
INFO:root:Train (Epoch 104): Loss/seq after 00300 batchs: 927.8515014648438
INFO:root:Train (Epoch 104): Loss/seq after 00350 batchs: 865.8970947265625
INFO:root:Train (Epoch 104): Loss/seq after 00400 batchs: 866.2924194335938
INFO:root:Train (Epoch 104): Loss/seq after 00450 batchs: 845.4691772460938
INFO:root:Train (Epoch 104): Loss/seq after 00500 batchs: 818.9608764648438
INFO:root:Train (Epoch 104): Loss/seq after 00550 batchs: 792.8512573242188
INFO:root:Train (Epoch 104): Loss/seq after 00600 batchs: 765.8919677734375
INFO:root:Train (Epoch 104): Loss/seq after 00650 batchs: 744.701171875
INFO:root:Train (Epoch 104): Loss/seq after 00700 batchs: 719.945556640625
INFO:root:Train (Epoch 104): Loss/seq after 00750 batchs: 726.989990234375
INFO:root:Train (Epoch 104): Loss/seq after 00800 batchs: 729.3495483398438
INFO:root:Train (Epoch 104): Loss/seq after 00850 batchs: 707.2854614257812
INFO:root:Train (Epoch 104): Loss/seq after 00900 batchs: 693.8821411132812
INFO:root:Train (Epoch 104): Loss/seq after 00950 batchs: 694.806640625
INFO:root:Train (Epoch 104): Loss/seq after 01000 batchs: 685.8123779296875
INFO:root:Train (Epoch 104): Loss/seq after 01050 batchs: 676.1376342773438
INFO:root:Train (Epoch 104): Loss/seq after 01100 batchs: 668.5331420898438
INFO:root:Train (Epoch 104): Loss/seq after 01150 batchs: 653.3090209960938
INFO:root:Train (Epoch 104): Loss/seq after 01200 batchs: 657.5596313476562
INFO:root:Train (Epoch 104): Loss/seq after 01250 batchs: 655.3676147460938
INFO:root:Train (Epoch 104): Loss/seq after 01300 batchs: 643.3701782226562
INFO:root:Train (Epoch 104): Loss/seq after 01350 batchs: 633.2133178710938
INFO:root:Train (Epoch 104): Loss/seq after 01400 batchs: 639.669677734375
INFO:root:Train (Epoch 104): Loss/seq after 01450 batchs: 640.8566284179688
INFO:root:Train (Epoch 104): Loss/seq after 01500 batchs: 646.6397705078125
INFO:root:Train (Epoch 104): Loss/seq after 01550 batchs: 649.1194458007812
INFO:root:Train (Epoch 104): Loss/seq after 01600 batchs: 643.1742553710938
INFO:root:Train (Epoch 104): Loss/seq after 01650 batchs: 640.7020263671875
INFO:root:Train (Epoch 104): Loss/seq after 01700 batchs: 641.9943237304688
INFO:root:Train (Epoch 104): Loss/seq after 01750 batchs: 638.8243408203125
INFO:root:Train (Epoch 104): Loss/seq after 01800 batchs: 635.2823486328125
INFO:root:Train (Epoch 104): Loss/seq after 01850 batchs: 630.728515625
INFO:root:Train (Epoch 104): Loss/seq after 01900 batchs: 630.9182739257812
INFO:root:Train (Epoch 104): Loss/seq after 01950 batchs: 628.77685546875
INFO:root:Train (Epoch 104): Loss/seq after 02000 batchs: 626.4524536132812
INFO:root:Train (Epoch 104): Loss/seq after 02050 batchs: 624.5427856445312
INFO:root:Train (Epoch 104): Loss/seq after 02100 batchs: 621.1972045898438
INFO:root:Train (Epoch 104): Loss/seq after 02150 batchs: 618.7993774414062
INFO:root:Train (Epoch 104): Loss/seq after 02200 batchs: 615.3570556640625
INFO:root:Train (Epoch 104): Loss/seq after 02250 batchs: 613.7061157226562
INFO:root:Train (Epoch 104): Loss/seq after 02300 batchs: 611.0516357421875
INFO:root:Train (Epoch 104): Loss/seq after 02350 batchs: 606.1507568359375
INFO:root:Train (Epoch 104): Loss/seq after 02400 batchs: 607.135498046875
INFO:root:Train (Epoch 104): Loss/seq after 02450 batchs: 601.8262939453125
INFO:root:Train (Epoch 104): Loss/seq after 02500 batchs: 592.9730224609375
INFO:root:Train (Epoch 104): Loss/seq after 02550 batchs: 586.704833984375
INFO:root:Train (Epoch 104): Loss/seq after 02600 batchs: 585.8804931640625
INFO:root:Train (Epoch 104): Loss/seq after 02650 batchs: 583.8421630859375
INFO:root:Train (Epoch 104): Loss/seq after 02700 batchs: 581.6495361328125
INFO:root:Train (Epoch 104): Loss/seq after 02750 batchs: 582.2428588867188
INFO:root:Train (Epoch 104): Loss/seq after 02800 batchs: 583.45556640625
INFO:root:Train (Epoch 104): Loss/seq after 02850 batchs: 583.3267211914062
INFO:root:Train (Epoch 104): Loss/seq after 02900 batchs: 584.6874389648438
INFO:root:Train (Epoch 104): Loss/seq after 02950 batchs: 583.3532104492188
INFO:root:Train (Epoch 104): Loss/seq after 03000 batchs: 588.0775146484375
INFO:root:Train (Epoch 104): Loss/seq after 03050 batchs: 590.0861206054688
INFO:root:Train (Epoch 104): Loss/seq after 03100 batchs: 594.3504638671875
INFO:root:Train (Epoch 104): Loss/seq after 03150 batchs: 599.3759765625
INFO:root:Train (Epoch 104): Loss/seq after 03200 batchs: 601.2257080078125
INFO:root:Train (Epoch 104): Loss/seq after 03250 batchs: 604.04052734375
INFO:root:Train (Epoch 104): Loss/seq after 03300 batchs: 602.8065795898438
INFO:root:Train (Epoch 104): Loss/seq after 03350 batchs: 603.0241088867188
INFO:root:Train (Epoch 104): Loss/seq after 03400 batchs: 598.3492431640625
INFO:root:Train (Epoch 104): Loss/seq after 03450 batchs: 596.4627685546875
INFO:root:Train (Epoch 104): Loss/seq after 03500 batchs: 596.8067016601562
INFO:root:Train (Epoch 104): Loss/seq after 03550 batchs: 593.904052734375
INFO:root:Train (Epoch 104): Loss/seq after 03600 batchs: 601.9682006835938
INFO:root:Train (Epoch 104): Loss/seq after 03650 batchs: 599.084228515625
INFO:root:Train (Epoch 104): Loss/seq after 03700 batchs: 601.5362548828125
INFO:root:Train (Epoch 104): Loss/seq after 03750 batchs: 606.2138061523438
INFO:root:Train (Epoch 104): Loss/seq after 03800 batchs: 603.5379028320312
INFO:root:Train (Epoch 104): Loss/seq after 03850 batchs: 602.3189697265625
INFO:root:Train (Epoch 104): Loss/seq after 03900 batchs: 606.585205078125
INFO:root:Train (Epoch 104): Loss/seq after 03950 batchs: 610.4827270507812
INFO:root:Train (Epoch 104): Loss/seq after 04000 batchs: 606.3975219726562
INFO:root:Train (Epoch 104): Loss/seq after 04050 batchs: 602.4960327148438
INFO:root:Train (Epoch 104): Loss/seq after 04100 batchs: 600.4396362304688
INFO:root:Train (Epoch 104): Loss/seq after 04150 batchs: 600.0322875976562
INFO:root:Train (Epoch 104): Loss/seq after 04200 batchs: 598.2896118164062
INFO:root:Train (Epoch 104): Loss/seq after 04250 batchs: 596.4537353515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 104): Loss/seq after 00000 batches: 526.0565185546875
INFO:root:# Valid (Epoch 104): Loss/seq after 00050 batches: 715.0862426757812
INFO:root:# Valid (Epoch 104): Loss/seq after 00100 batches: 782.1183471679688
INFO:root:# Valid (Epoch 104): Loss/seq after 00150 batches: 588.5912475585938
INFO:root:# Valid (Epoch 104): Loss/seq after 00200 batches: 545.7337646484375
INFO:root:Artifacts: Make stick videos for epoch 104
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_104_on_20220413_035105.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_104_index_1337_on_20220413_035105.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 105): Loss/seq after 00000 batchs: 1021.7373657226562
INFO:root:Train (Epoch 105): Loss/seq after 00050 batchs: 826.945556640625
INFO:root:Train (Epoch 105): Loss/seq after 00100 batchs: 834.3212280273438
INFO:root:Train (Epoch 105): Loss/seq after 00150 batchs: 759.19482421875
INFO:root:Train (Epoch 105): Loss/seq after 00200 batchs: 823.3793334960938
INFO:root:Train (Epoch 105): Loss/seq after 00250 batchs: 930.1036987304688
INFO:root:Train (Epoch 105): Loss/seq after 00300 batchs: 923.3809814453125
INFO:root:Train (Epoch 105): Loss/seq after 00350 batchs: 862.0668334960938
INFO:root:Train (Epoch 105): Loss/seq after 00400 batchs: 861.4168090820312
INFO:root:Train (Epoch 105): Loss/seq after 00450 batchs: 841.4766845703125
INFO:root:Train (Epoch 105): Loss/seq after 00500 batchs: 813.5416870117188
INFO:root:Train (Epoch 105): Loss/seq after 00550 batchs: 787.156494140625
INFO:root:Train (Epoch 105): Loss/seq after 00600 batchs: 758.9408569335938
INFO:root:Train (Epoch 105): Loss/seq after 00650 batchs: 738.9943237304688
INFO:root:Train (Epoch 105): Loss/seq after 00700 batchs: 715.0728149414062
INFO:root:Train (Epoch 105): Loss/seq after 00750 batchs: 723.6760864257812
INFO:root:Train (Epoch 105): Loss/seq after 00800 batchs: 725.3060913085938
INFO:root:Train (Epoch 105): Loss/seq after 00850 batchs: 702.9248046875
INFO:root:Train (Epoch 105): Loss/seq after 00900 batchs: 690.3571166992188
INFO:root:Train (Epoch 105): Loss/seq after 00950 batchs: 689.3417358398438
INFO:root:Train (Epoch 105): Loss/seq after 01000 batchs: 679.863525390625
INFO:root:Train (Epoch 105): Loss/seq after 01050 batchs: 669.693359375
INFO:root:Train (Epoch 105): Loss/seq after 01100 batchs: 660.78369140625
INFO:root:Train (Epoch 105): Loss/seq after 01150 batchs: 645.5357055664062
INFO:root:Train (Epoch 105): Loss/seq after 01200 batchs: 649.5167236328125
INFO:root:Train (Epoch 105): Loss/seq after 01250 batchs: 647.3975830078125
INFO:root:Train (Epoch 105): Loss/seq after 01300 batchs: 635.01806640625
INFO:root:Train (Epoch 105): Loss/seq after 01350 batchs: 625.1043701171875
INFO:root:Train (Epoch 105): Loss/seq after 01400 batchs: 631.3743896484375
INFO:root:Train (Epoch 105): Loss/seq after 01450 batchs: 632.61572265625
INFO:root:Train (Epoch 105): Loss/seq after 01500 batchs: 638.4912109375
INFO:root:Train (Epoch 105): Loss/seq after 01550 batchs: 640.4974365234375
INFO:root:Train (Epoch 105): Loss/seq after 01600 batchs: 634.6245727539062
INFO:root:Train (Epoch 105): Loss/seq after 01650 batchs: 632.3070068359375
INFO:root:Train (Epoch 105): Loss/seq after 01700 batchs: 634.0001220703125
INFO:root:Train (Epoch 105): Loss/seq after 01750 batchs: 630.9755859375
INFO:root:Train (Epoch 105): Loss/seq after 01800 batchs: 627.5989379882812
INFO:root:Train (Epoch 105): Loss/seq after 01850 batchs: 623.3428955078125
INFO:root:Train (Epoch 105): Loss/seq after 01900 batchs: 623.7880249023438
INFO:root:Train (Epoch 105): Loss/seq after 01950 batchs: 621.769287109375
INFO:root:Train (Epoch 105): Loss/seq after 02000 batchs: 619.6824340820312
INFO:root:Train (Epoch 105): Loss/seq after 02050 batchs: 617.7691040039062
INFO:root:Train (Epoch 105): Loss/seq after 02100 batchs: 614.6002197265625
INFO:root:Train (Epoch 105): Loss/seq after 02150 batchs: 612.2448120117188
INFO:root:Train (Epoch 105): Loss/seq after 02200 batchs: 608.8360595703125
INFO:root:Train (Epoch 105): Loss/seq after 02250 batchs: 607.2381591796875
INFO:root:Train (Epoch 105): Loss/seq after 02300 batchs: 604.443603515625
INFO:root:Train (Epoch 105): Loss/seq after 02350 batchs: 599.6123046875
INFO:root:Train (Epoch 105): Loss/seq after 02400 batchs: 600.7296752929688
INFO:root:Train (Epoch 105): Loss/seq after 02450 batchs: 595.5833129882812
INFO:root:Train (Epoch 105): Loss/seq after 02500 batchs: 586.8365478515625
INFO:root:Train (Epoch 105): Loss/seq after 02550 batchs: 580.684326171875
INFO:root:Train (Epoch 105): Loss/seq after 02600 batchs: 579.950927734375
INFO:root:Train (Epoch 105): Loss/seq after 02650 batchs: 577.9180297851562
INFO:root:Train (Epoch 105): Loss/seq after 02700 batchs: 575.79345703125
INFO:root:Train (Epoch 105): Loss/seq after 02750 batchs: 576.4581909179688
INFO:root:Train (Epoch 105): Loss/seq after 02800 batchs: 577.6408081054688
INFO:root:Train (Epoch 105): Loss/seq after 02850 batchs: 577.545166015625
INFO:root:Train (Epoch 105): Loss/seq after 02900 batchs: 578.9193725585938
INFO:root:Train (Epoch 105): Loss/seq after 02950 batchs: 577.648681640625
INFO:root:Train (Epoch 105): Loss/seq after 03000 batchs: 582.4606323242188
INFO:root:Train (Epoch 105): Loss/seq after 03050 batchs: 584.564453125
INFO:root:Train (Epoch 105): Loss/seq after 03100 batchs: 588.4071655273438
INFO:root:Train (Epoch 105): Loss/seq after 03150 batchs: 593.1060791015625
INFO:root:Train (Epoch 105): Loss/seq after 03200 batchs: 595.0525512695312
INFO:root:Train (Epoch 105): Loss/seq after 03250 batchs: 597.870361328125
INFO:root:Train (Epoch 105): Loss/seq after 03300 batchs: 596.5406494140625
INFO:root:Train (Epoch 105): Loss/seq after 03350 batchs: 596.71240234375
INFO:root:Train (Epoch 105): Loss/seq after 03400 batchs: 592.141357421875
INFO:root:Train (Epoch 105): Loss/seq after 03450 batchs: 590.2671508789062
INFO:root:Train (Epoch 105): Loss/seq after 03500 batchs: 590.6629028320312
INFO:root:Train (Epoch 105): Loss/seq after 03550 batchs: 587.60986328125
INFO:root:Train (Epoch 105): Loss/seq after 03600 batchs: 595.535400390625
INFO:root:Train (Epoch 105): Loss/seq after 03650 batchs: 592.8794555664062
INFO:root:Train (Epoch 105): Loss/seq after 03700 batchs: 595.3384399414062
INFO:root:Train (Epoch 105): Loss/seq after 03750 batchs: 600.1076049804688
INFO:root:Train (Epoch 105): Loss/seq after 03800 batchs: 597.4318237304688
INFO:root:Train (Epoch 105): Loss/seq after 03850 batchs: 596.298828125
INFO:root:Train (Epoch 105): Loss/seq after 03900 batchs: 600.4614868164062
INFO:root:Train (Epoch 105): Loss/seq after 03950 batchs: 604.1889038085938
INFO:root:Train (Epoch 105): Loss/seq after 04000 batchs: 600.0882568359375
INFO:root:Train (Epoch 105): Loss/seq after 04050 batchs: 596.2612915039062
INFO:root:Train (Epoch 105): Loss/seq after 04100 batchs: 594.2244262695312
INFO:root:Train (Epoch 105): Loss/seq after 04150 batchs: 593.8167724609375
INFO:root:Train (Epoch 105): Loss/seq after 04200 batchs: 592.0695190429688
INFO:root:Train (Epoch 105): Loss/seq after 04250 batchs: 590.2999267578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 105): Loss/seq after 00000 batches: 520.2024536132812
INFO:root:# Valid (Epoch 105): Loss/seq after 00050 batches: 738.607666015625
INFO:root:# Valid (Epoch 105): Loss/seq after 00100 batches: 778.7593994140625
INFO:root:# Valid (Epoch 105): Loss/seq after 00150 batches: 589.8191528320312
INFO:root:# Valid (Epoch 105): Loss/seq after 00200 batches: 547.0744018554688
INFO:root:Artifacts: Make stick videos for epoch 105
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_105_on_20220413_035626.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_105_index_1330_on_20220413_035626.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 106): Loss/seq after 00000 batchs: 1139.0240478515625
INFO:root:Train (Epoch 106): Loss/seq after 00050 batchs: 821.0179443359375
INFO:root:Train (Epoch 106): Loss/seq after 00100 batchs: 827.9415893554688
INFO:root:Train (Epoch 106): Loss/seq after 00150 batchs: 752.6458740234375
INFO:root:Train (Epoch 106): Loss/seq after 00200 batchs: 812.6065673828125
INFO:root:Train (Epoch 106): Loss/seq after 00250 batchs: 924.3070678710938
INFO:root:Train (Epoch 106): Loss/seq after 00300 batchs: 917.8598022460938
INFO:root:Train (Epoch 106): Loss/seq after 00350 batchs: 857.6280517578125
INFO:root:Train (Epoch 106): Loss/seq after 00400 batchs: 858.5116577148438
INFO:root:Train (Epoch 106): Loss/seq after 00450 batchs: 838.2310791015625
INFO:root:Train (Epoch 106): Loss/seq after 00500 batchs: 810.6234741210938
INFO:root:Train (Epoch 106): Loss/seq after 00550 batchs: 784.3502197265625
INFO:root:Train (Epoch 106): Loss/seq after 00600 batchs: 757.0494384765625
INFO:root:Train (Epoch 106): Loss/seq after 00650 batchs: 736.6653442382812
INFO:root:Train (Epoch 106): Loss/seq after 00700 batchs: 712.5418701171875
INFO:root:Train (Epoch 106): Loss/seq after 00750 batchs: 720.630126953125
INFO:root:Train (Epoch 106): Loss/seq after 00800 batchs: 723.007080078125
INFO:root:Train (Epoch 106): Loss/seq after 00850 batchs: 701.0523681640625
INFO:root:Train (Epoch 106): Loss/seq after 00900 batchs: 687.55126953125
INFO:root:Train (Epoch 106): Loss/seq after 00950 batchs: 687.4984741210938
INFO:root:Train (Epoch 106): Loss/seq after 01000 batchs: 678.2150268554688
INFO:root:Train (Epoch 106): Loss/seq after 01050 batchs: 668.5550537109375
INFO:root:Train (Epoch 106): Loss/seq after 01100 batchs: 660.0234375
INFO:root:Train (Epoch 106): Loss/seq after 01150 batchs: 644.869873046875
INFO:root:Train (Epoch 106): Loss/seq after 01200 batchs: 649.2647705078125
INFO:root:Train (Epoch 106): Loss/seq after 01250 batchs: 647.1329345703125
INFO:root:Train (Epoch 106): Loss/seq after 01300 batchs: 634.7871704101562
INFO:root:Train (Epoch 106): Loss/seq after 01350 batchs: 624.5227661132812
INFO:root:Train (Epoch 106): Loss/seq after 01400 batchs: 630.9661865234375
INFO:root:Train (Epoch 106): Loss/seq after 01450 batchs: 632.1998901367188
INFO:root:Train (Epoch 106): Loss/seq after 01500 batchs: 638.0565795898438
INFO:root:Train (Epoch 106): Loss/seq after 01550 batchs: 640.0177612304688
INFO:root:Train (Epoch 106): Loss/seq after 01600 batchs: 634.234375
INFO:root:Train (Epoch 106): Loss/seq after 01650 batchs: 631.92529296875
INFO:root:Train (Epoch 106): Loss/seq after 01700 batchs: 633.4711303710938
INFO:root:Train (Epoch 106): Loss/seq after 01750 batchs: 630.3123779296875
INFO:root:Train (Epoch 106): Loss/seq after 01800 batchs: 626.8582153320312
INFO:root:Train (Epoch 106): Loss/seq after 01850 batchs: 622.3798828125
INFO:root:Train (Epoch 106): Loss/seq after 01900 batchs: 622.7634887695312
INFO:root:Train (Epoch 106): Loss/seq after 01950 batchs: 620.9713745117188
INFO:root:Train (Epoch 106): Loss/seq after 02000 batchs: 618.9597778320312
INFO:root:Train (Epoch 106): Loss/seq after 02050 batchs: 617.0596923828125
INFO:root:Train (Epoch 106): Loss/seq after 02100 batchs: 613.8277587890625
INFO:root:Train (Epoch 106): Loss/seq after 02150 batchs: 611.47216796875
INFO:root:Train (Epoch 106): Loss/seq after 02200 batchs: 608.0458984375
INFO:root:Train (Epoch 106): Loss/seq after 02250 batchs: 606.3798828125
INFO:root:Train (Epoch 106): Loss/seq after 02300 batchs: 603.5994262695312
INFO:root:Train (Epoch 106): Loss/seq after 02350 batchs: 598.7933349609375
INFO:root:Train (Epoch 106): Loss/seq after 02400 batchs: 599.9560546875
INFO:root:Train (Epoch 106): Loss/seq after 02450 batchs: 594.7959594726562
INFO:root:Train (Epoch 106): Loss/seq after 02500 batchs: 586.0776977539062
INFO:root:Train (Epoch 106): Loss/seq after 02550 batchs: 579.8184204101562
INFO:root:Train (Epoch 106): Loss/seq after 02600 batchs: 579.1137084960938
INFO:root:Train (Epoch 106): Loss/seq after 02650 batchs: 577.136474609375
INFO:root:Train (Epoch 106): Loss/seq after 02700 batchs: 575.0025024414062
INFO:root:Train (Epoch 106): Loss/seq after 02750 batchs: 574.9781494140625
INFO:root:Train (Epoch 106): Loss/seq after 02800 batchs: 576.2229614257812
INFO:root:Train (Epoch 106): Loss/seq after 02850 batchs: 576.2518920898438
INFO:root:Train (Epoch 106): Loss/seq after 02900 batchs: 577.5244750976562
INFO:root:Train (Epoch 106): Loss/seq after 02950 batchs: 576.1837158203125
INFO:root:Train (Epoch 106): Loss/seq after 03000 batchs: 580.9446411132812
INFO:root:Train (Epoch 106): Loss/seq after 03050 batchs: 582.9723510742188
INFO:root:Train (Epoch 106): Loss/seq after 03100 batchs: 586.5830078125
INFO:root:Train (Epoch 106): Loss/seq after 03150 batchs: 590.8757934570312
INFO:root:Train (Epoch 106): Loss/seq after 03200 batchs: 592.5384521484375
INFO:root:Train (Epoch 106): Loss/seq after 03250 batchs: 595.3964233398438
INFO:root:Train (Epoch 106): Loss/seq after 03300 batchs: 594.1475219726562
INFO:root:Train (Epoch 106): Loss/seq after 03350 batchs: 594.3025512695312
INFO:root:Train (Epoch 106): Loss/seq after 03400 batchs: 589.7400512695312
INFO:root:Train (Epoch 106): Loss/seq after 03450 batchs: 587.8671264648438
INFO:root:Train (Epoch 106): Loss/seq after 03500 batchs: 588.230224609375
INFO:root:Train (Epoch 106): Loss/seq after 03550 batchs: 585.2051391601562
INFO:root:Train (Epoch 106): Loss/seq after 03600 batchs: 593.1176147460938
INFO:root:Train (Epoch 106): Loss/seq after 03650 batchs: 590.23193359375
INFO:root:Train (Epoch 106): Loss/seq after 03700 batchs: 592.5950927734375
INFO:root:Train (Epoch 106): Loss/seq after 03750 batchs: 597.288818359375
INFO:root:Train (Epoch 106): Loss/seq after 03800 batchs: 594.668212890625
INFO:root:Train (Epoch 106): Loss/seq after 03850 batchs: 593.4888916015625
INFO:root:Train (Epoch 106): Loss/seq after 03900 batchs: 597.283203125
INFO:root:Train (Epoch 106): Loss/seq after 03950 batchs: 601.053955078125
INFO:root:Train (Epoch 106): Loss/seq after 04000 batchs: 596.9437866210938
INFO:root:Train (Epoch 106): Loss/seq after 04050 batchs: 593.1268920898438
INFO:root:Train (Epoch 106): Loss/seq after 04100 batchs: 591.1024780273438
INFO:root:Train (Epoch 106): Loss/seq after 04150 batchs: 590.7076416015625
INFO:root:Train (Epoch 106): Loss/seq after 04200 batchs: 589.03662109375
INFO:root:Train (Epoch 106): Loss/seq after 04250 batchs: 587.4432373046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 106): Loss/seq after 00000 batches: 530.3338012695312
INFO:root:# Valid (Epoch 106): Loss/seq after 00050 batches: 785.612060546875
INFO:root:# Valid (Epoch 106): Loss/seq after 00100 batches: 842.524169921875
INFO:root:# Valid (Epoch 106): Loss/seq after 00150 batches: 631.6402587890625
INFO:root:# Valid (Epoch 106): Loss/seq after 00200 batches: 579.6956787109375
INFO:root:Artifacts: Make stick videos for epoch 106
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_106_on_20220413_040147.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_106_index_1405_on_20220413_040147.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 107): Loss/seq after 00000 batchs: 1005.4962158203125
INFO:root:Train (Epoch 107): Loss/seq after 00050 batchs: 815.4879760742188
INFO:root:Train (Epoch 107): Loss/seq after 00100 batchs: 814.4661254882812
INFO:root:Train (Epoch 107): Loss/seq after 00150 batchs: 743.258056640625
INFO:root:Train (Epoch 107): Loss/seq after 00200 batchs: 810.268798828125
INFO:root:Train (Epoch 107): Loss/seq after 00250 batchs: 920.4546508789062
INFO:root:Train (Epoch 107): Loss/seq after 00300 batchs: 914.4161987304688
INFO:root:Train (Epoch 107): Loss/seq after 00350 batchs: 853.9030151367188
INFO:root:Train (Epoch 107): Loss/seq after 00400 batchs: 853.9739379882812
INFO:root:Train (Epoch 107): Loss/seq after 00450 batchs: 834.3729858398438
INFO:root:Train (Epoch 107): Loss/seq after 00500 batchs: 808.70361328125
INFO:root:Train (Epoch 107): Loss/seq after 00550 batchs: 783.532470703125
INFO:root:Train (Epoch 107): Loss/seq after 00600 batchs: 756.4555053710938
INFO:root:Train (Epoch 107): Loss/seq after 00650 batchs: 736.118408203125
INFO:root:Train (Epoch 107): Loss/seq after 00700 batchs: 711.6734619140625
INFO:root:Train (Epoch 107): Loss/seq after 00750 batchs: 718.1380615234375
INFO:root:Train (Epoch 107): Loss/seq after 00800 batchs: 719.5387573242188
INFO:root:Train (Epoch 107): Loss/seq after 00850 batchs: 697.6531372070312
INFO:root:Train (Epoch 107): Loss/seq after 00900 batchs: 683.5910034179688
INFO:root:Train (Epoch 107): Loss/seq after 00950 batchs: 682.8273315429688
INFO:root:Train (Epoch 107): Loss/seq after 01000 batchs: 673.5996704101562
INFO:root:Train (Epoch 107): Loss/seq after 01050 batchs: 662.8846435546875
INFO:root:Train (Epoch 107): Loss/seq after 01100 batchs: 654.5169067382812
INFO:root:Train (Epoch 107): Loss/seq after 01150 batchs: 639.3427124023438
INFO:root:Train (Epoch 107): Loss/seq after 01200 batchs: 643.2446899414062
INFO:root:Train (Epoch 107): Loss/seq after 01250 batchs: 640.987060546875
INFO:root:Train (Epoch 107): Loss/seq after 01300 batchs: 628.6019287109375
INFO:root:Train (Epoch 107): Loss/seq after 01350 batchs: 618.6671142578125
INFO:root:Train (Epoch 107): Loss/seq after 01400 batchs: 624.7022094726562
INFO:root:Train (Epoch 107): Loss/seq after 01450 batchs: 626.0035400390625
INFO:root:Train (Epoch 107): Loss/seq after 01500 batchs: 632.0218505859375
INFO:root:Train (Epoch 107): Loss/seq after 01550 batchs: 633.8974609375
INFO:root:Train (Epoch 107): Loss/seq after 01600 batchs: 627.7708129882812
INFO:root:Train (Epoch 107): Loss/seq after 01650 batchs: 625.4173583984375
INFO:root:Train (Epoch 107): Loss/seq after 01700 batchs: 627.0418701171875
INFO:root:Train (Epoch 107): Loss/seq after 01750 batchs: 624.0391235351562
INFO:root:Train (Epoch 107): Loss/seq after 01800 batchs: 620.6393432617188
INFO:root:Train (Epoch 107): Loss/seq after 01850 batchs: 616.3389282226562
INFO:root:Train (Epoch 107): Loss/seq after 01900 batchs: 616.7437744140625
INFO:root:Train (Epoch 107): Loss/seq after 01950 batchs: 614.8275146484375
INFO:root:Train (Epoch 107): Loss/seq after 02000 batchs: 612.9044189453125
INFO:root:Train (Epoch 107): Loss/seq after 02050 batchs: 610.8721923828125
INFO:root:Train (Epoch 107): Loss/seq after 02100 batchs: 607.7919921875
INFO:root:Train (Epoch 107): Loss/seq after 02150 batchs: 605.52734375
INFO:root:Train (Epoch 107): Loss/seq after 02200 batchs: 602.0091552734375
INFO:root:Train (Epoch 107): Loss/seq after 02250 batchs: 600.3748779296875
INFO:root:Train (Epoch 107): Loss/seq after 02300 batchs: 597.4553833007812
INFO:root:Train (Epoch 107): Loss/seq after 02350 batchs: 592.8067626953125
INFO:root:Train (Epoch 107): Loss/seq after 02400 batchs: 593.90771484375
INFO:root:Train (Epoch 107): Loss/seq after 02450 batchs: 588.7891845703125
INFO:root:Train (Epoch 107): Loss/seq after 02500 batchs: 580.1751098632812
INFO:root:Train (Epoch 107): Loss/seq after 02550 batchs: 574.0296630859375
INFO:root:Train (Epoch 107): Loss/seq after 02600 batchs: 573.1493530273438
INFO:root:Train (Epoch 107): Loss/seq after 02650 batchs: 571.21630859375
INFO:root:Train (Epoch 107): Loss/seq after 02700 batchs: 569.1588745117188
INFO:root:Train (Epoch 107): Loss/seq after 02750 batchs: 569.3182373046875
INFO:root:Train (Epoch 107): Loss/seq after 02800 batchs: 570.270751953125
INFO:root:Train (Epoch 107): Loss/seq after 02850 batchs: 570.5416259765625
INFO:root:Train (Epoch 107): Loss/seq after 02900 batchs: 572.2528076171875
INFO:root:Train (Epoch 107): Loss/seq after 02950 batchs: 571.018310546875
INFO:root:Train (Epoch 107): Loss/seq after 03000 batchs: 575.8903198242188
INFO:root:Train (Epoch 107): Loss/seq after 03050 batchs: 577.9368286132812
INFO:root:Train (Epoch 107): Loss/seq after 03100 batchs: 581.6277465820312
INFO:root:Train (Epoch 107): Loss/seq after 03150 batchs: 586.0150756835938
INFO:root:Train (Epoch 107): Loss/seq after 03200 batchs: 587.8790893554688
INFO:root:Train (Epoch 107): Loss/seq after 03250 batchs: 590.9295654296875
INFO:root:Train (Epoch 107): Loss/seq after 03300 batchs: 589.8442993164062
INFO:root:Train (Epoch 107): Loss/seq after 03350 batchs: 590.4500122070312
INFO:root:Train (Epoch 107): Loss/seq after 03400 batchs: 585.936767578125
INFO:root:Train (Epoch 107): Loss/seq after 03450 batchs: 584.068359375
INFO:root:Train (Epoch 107): Loss/seq after 03500 batchs: 584.4404296875
INFO:root:Train (Epoch 107): Loss/seq after 03550 batchs: 581.4578857421875
INFO:root:Train (Epoch 107): Loss/seq after 03600 batchs: 589.5282592773438
INFO:root:Train (Epoch 107): Loss/seq after 03650 batchs: 586.7138671875
INFO:root:Train (Epoch 107): Loss/seq after 03700 batchs: 589.06982421875
INFO:root:Train (Epoch 107): Loss/seq after 03750 batchs: 593.6231689453125
INFO:root:Train (Epoch 107): Loss/seq after 03800 batchs: 591.015380859375
INFO:root:Train (Epoch 107): Loss/seq after 03850 batchs: 589.6563720703125
INFO:root:Train (Epoch 107): Loss/seq after 03900 batchs: 593.7294311523438
INFO:root:Train (Epoch 107): Loss/seq after 03950 batchs: 597.2890625
INFO:root:Train (Epoch 107): Loss/seq after 04000 batchs: 593.1304931640625
INFO:root:Train (Epoch 107): Loss/seq after 04050 batchs: 589.30615234375
INFO:root:Train (Epoch 107): Loss/seq after 04100 batchs: 587.3302612304688
INFO:root:Train (Epoch 107): Loss/seq after 04150 batchs: 586.9078369140625
INFO:root:Train (Epoch 107): Loss/seq after 04200 batchs: 585.2369995117188
INFO:root:Train (Epoch 107): Loss/seq after 04250 batchs: 583.406982421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 107): Loss/seq after 00000 batches: 513.8994140625
INFO:root:# Valid (Epoch 107): Loss/seq after 00050 batches: 727.6233520507812
INFO:root:# Valid (Epoch 107): Loss/seq after 00100 batches: 783.023193359375
INFO:root:# Valid (Epoch 107): Loss/seq after 00150 batches: 588.7955322265625
INFO:root:# Valid (Epoch 107): Loss/seq after 00200 batches: 542.6610717773438
INFO:root:Artifacts: Make stick videos for epoch 107
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_107_on_20220413_040710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_107_index_1009_on_20220413_040710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 108): Loss/seq after 00000 batchs: 984.5891723632812
INFO:root:Train (Epoch 108): Loss/seq after 00050 batchs: 805.5377197265625
INFO:root:Train (Epoch 108): Loss/seq after 00100 batchs: 814.6392822265625
INFO:root:Train (Epoch 108): Loss/seq after 00150 batchs: 745.2533569335938
INFO:root:Train (Epoch 108): Loss/seq after 00200 batchs: 807.3886108398438
INFO:root:Train (Epoch 108): Loss/seq after 00250 batchs: 911.8404541015625
INFO:root:Train (Epoch 108): Loss/seq after 00300 batchs: 906.0745239257812
INFO:root:Train (Epoch 108): Loss/seq after 00350 batchs: 848.0048828125
INFO:root:Train (Epoch 108): Loss/seq after 00400 batchs: 850.4500732421875
INFO:root:Train (Epoch 108): Loss/seq after 00450 batchs: 831.1585083007812
INFO:root:Train (Epoch 108): Loss/seq after 00500 batchs: 804.3915405273438
INFO:root:Train (Epoch 108): Loss/seq after 00550 batchs: 778.86181640625
INFO:root:Train (Epoch 108): Loss/seq after 00600 batchs: 751.4927368164062
INFO:root:Train (Epoch 108): Loss/seq after 00650 batchs: 729.967041015625
INFO:root:Train (Epoch 108): Loss/seq after 00700 batchs: 705.1456298828125
INFO:root:Train (Epoch 108): Loss/seq after 00750 batchs: 712.9566040039062
INFO:root:Train (Epoch 108): Loss/seq after 00800 batchs: 716.6478271484375
INFO:root:Train (Epoch 108): Loss/seq after 00850 batchs: 694.9959716796875
INFO:root:Train (Epoch 108): Loss/seq after 00900 batchs: 681.7667236328125
INFO:root:Train (Epoch 108): Loss/seq after 00950 batchs: 680.821533203125
INFO:root:Train (Epoch 108): Loss/seq after 01000 batchs: 671.2859497070312
INFO:root:Train (Epoch 108): Loss/seq after 01050 batchs: 663.47802734375
INFO:root:Train (Epoch 108): Loss/seq after 01100 batchs: 655.7374877929688
INFO:root:Train (Epoch 108): Loss/seq after 01150 batchs: 640.9393920898438
INFO:root:Train (Epoch 108): Loss/seq after 01200 batchs: 645.351806640625
INFO:root:Train (Epoch 108): Loss/seq after 01250 batchs: 643.0692749023438
INFO:root:Train (Epoch 108): Loss/seq after 01300 batchs: 630.5562744140625
INFO:root:Train (Epoch 108): Loss/seq after 01350 batchs: 620.4638061523438
INFO:root:Train (Epoch 108): Loss/seq after 01400 batchs: 625.6815185546875
INFO:root:Train (Epoch 108): Loss/seq after 01450 batchs: 626.6616821289062
INFO:root:Train (Epoch 108): Loss/seq after 01500 batchs: 632.6527709960938
INFO:root:Train (Epoch 108): Loss/seq after 01550 batchs: 634.8916625976562
INFO:root:Train (Epoch 108): Loss/seq after 01600 batchs: 629.0390625
INFO:root:Train (Epoch 108): Loss/seq after 01650 batchs: 626.698974609375
INFO:root:Train (Epoch 108): Loss/seq after 01700 batchs: 628.1664428710938
INFO:root:Train (Epoch 108): Loss/seq after 01750 batchs: 625.1043090820312
INFO:root:Train (Epoch 108): Loss/seq after 01800 batchs: 621.5675659179688
INFO:root:Train (Epoch 108): Loss/seq after 01850 batchs: 617.2410888671875
INFO:root:Train (Epoch 108): Loss/seq after 01900 batchs: 617.5198364257812
INFO:root:Train (Epoch 108): Loss/seq after 01950 batchs: 615.6996459960938
INFO:root:Train (Epoch 108): Loss/seq after 02000 batchs: 613.7568969726562
INFO:root:Train (Epoch 108): Loss/seq after 02050 batchs: 611.8370971679688
INFO:root:Train (Epoch 108): Loss/seq after 02100 batchs: 608.6016235351562
INFO:root:Train (Epoch 108): Loss/seq after 02150 batchs: 606.2570190429688
INFO:root:Train (Epoch 108): Loss/seq after 02200 batchs: 602.8992919921875
INFO:root:Train (Epoch 108): Loss/seq after 02250 batchs: 601.1429443359375
INFO:root:Train (Epoch 108): Loss/seq after 02300 batchs: 598.2302856445312
INFO:root:Train (Epoch 108): Loss/seq after 02350 batchs: 593.4356079101562
INFO:root:Train (Epoch 108): Loss/seq after 02400 batchs: 594.499755859375
INFO:root:Train (Epoch 108): Loss/seq after 02450 batchs: 589.33203125
INFO:root:Train (Epoch 108): Loss/seq after 02500 batchs: 580.6862182617188
INFO:root:Train (Epoch 108): Loss/seq after 02550 batchs: 574.619873046875
INFO:root:Train (Epoch 108): Loss/seq after 02600 batchs: 573.8704223632812
INFO:root:Train (Epoch 108): Loss/seq after 02650 batchs: 571.91357421875
INFO:root:Train (Epoch 108): Loss/seq after 02700 batchs: 569.6990966796875
INFO:root:Train (Epoch 108): Loss/seq after 02750 batchs: 569.3291015625
INFO:root:Train (Epoch 108): Loss/seq after 02800 batchs: 570.6707153320312
INFO:root:Train (Epoch 108): Loss/seq after 02850 batchs: 570.8160400390625
INFO:root:Train (Epoch 108): Loss/seq after 02900 batchs: 572.2279052734375
INFO:root:Train (Epoch 108): Loss/seq after 02950 batchs: 571.0053100585938
INFO:root:Train (Epoch 108): Loss/seq after 03000 batchs: 575.7794799804688
INFO:root:Train (Epoch 108): Loss/seq after 03050 batchs: 577.7694702148438
INFO:root:Train (Epoch 108): Loss/seq after 03100 batchs: 581.801513671875
INFO:root:Train (Epoch 108): Loss/seq after 03150 batchs: 585.859375
INFO:root:Train (Epoch 108): Loss/seq after 03200 batchs: 587.5328979492188
INFO:root:Train (Epoch 108): Loss/seq after 03250 batchs: 590.601318359375
INFO:root:Train (Epoch 108): Loss/seq after 03300 batchs: 589.7750244140625
INFO:root:Train (Epoch 108): Loss/seq after 03350 batchs: 589.9318237304688
INFO:root:Train (Epoch 108): Loss/seq after 03400 batchs: 585.449462890625
INFO:root:Train (Epoch 108): Loss/seq after 03450 batchs: 583.5861206054688
INFO:root:Train (Epoch 108): Loss/seq after 03500 batchs: 583.9740600585938
INFO:root:Train (Epoch 108): Loss/seq after 03550 batchs: 581.0390625
INFO:root:Train (Epoch 108): Loss/seq after 03600 batchs: 588.93310546875
INFO:root:Train (Epoch 108): Loss/seq after 03650 batchs: 586.248046875
INFO:root:Train (Epoch 108): Loss/seq after 03700 batchs: 588.6140747070312
INFO:root:Train (Epoch 108): Loss/seq after 03750 batchs: 593.2009887695312
INFO:root:Train (Epoch 108): Loss/seq after 03800 batchs: 590.6513061523438
INFO:root:Train (Epoch 108): Loss/seq after 03850 batchs: 589.3826904296875
INFO:root:Train (Epoch 108): Loss/seq after 03900 batchs: 593.3413696289062
INFO:root:Train (Epoch 108): Loss/seq after 03950 batchs: 596.9212646484375
INFO:root:Train (Epoch 108): Loss/seq after 04000 batchs: 592.7444458007812
INFO:root:Train (Epoch 108): Loss/seq after 04050 batchs: 588.94970703125
INFO:root:Train (Epoch 108): Loss/seq after 04100 batchs: 586.9661865234375
INFO:root:Train (Epoch 108): Loss/seq after 04150 batchs: 586.4794921875
INFO:root:Train (Epoch 108): Loss/seq after 04200 batchs: 584.8682861328125
INFO:root:Train (Epoch 108): Loss/seq after 04250 batchs: 583.2723999023438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 108): Loss/seq after 00000 batches: 526.4622802734375
INFO:root:# Valid (Epoch 108): Loss/seq after 00050 batches: 735.4995727539062
INFO:root:# Valid (Epoch 108): Loss/seq after 00100 batches: 802.5197143554688
INFO:root:# Valid (Epoch 108): Loss/seq after 00150 batches: 604.1795043945312
INFO:root:# Valid (Epoch 108): Loss/seq after 00200 batches: 555.4756469726562
INFO:root:Artifacts: Make stick videos for epoch 108
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_108_on_20220413_041231.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_108_index_627_on_20220413_041231.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 109): Loss/seq after 00000 batchs: 1140.81982421875
INFO:root:Train (Epoch 109): Loss/seq after 00050 batchs: 821.5827026367188
INFO:root:Train (Epoch 109): Loss/seq after 00100 batchs: 817.2025146484375
INFO:root:Train (Epoch 109): Loss/seq after 00150 batchs: 742.3972778320312
INFO:root:Train (Epoch 109): Loss/seq after 00200 batchs: 799.5182495117188
INFO:root:Train (Epoch 109): Loss/seq after 00250 batchs: 903.705078125
INFO:root:Train (Epoch 109): Loss/seq after 00300 batchs: 899.454833984375
INFO:root:Train (Epoch 109): Loss/seq after 00350 batchs: 841.0986328125
INFO:root:Train (Epoch 109): Loss/seq after 00400 batchs: 840.2364501953125
INFO:root:Train (Epoch 109): Loss/seq after 00450 batchs: 821.5381469726562
INFO:root:Train (Epoch 109): Loss/seq after 00500 batchs: 794.6681518554688
INFO:root:Train (Epoch 109): Loss/seq after 00550 batchs: 769.369140625
INFO:root:Train (Epoch 109): Loss/seq after 00600 batchs: 742.067626953125
INFO:root:Train (Epoch 109): Loss/seq after 00650 batchs: 720.3833618164062
INFO:root:Train (Epoch 109): Loss/seq after 00700 batchs: 696.52197265625
INFO:root:Train (Epoch 109): Loss/seq after 00750 batchs: 704.0326538085938
INFO:root:Train (Epoch 109): Loss/seq after 00800 batchs: 705.6942138671875
INFO:root:Train (Epoch 109): Loss/seq after 00850 batchs: 684.1177978515625
INFO:root:Train (Epoch 109): Loss/seq after 00900 batchs: 670.98876953125
INFO:root:Train (Epoch 109): Loss/seq after 00950 batchs: 670.0645141601562
INFO:root:Train (Epoch 109): Loss/seq after 01000 batchs: 660.4373168945312
INFO:root:Train (Epoch 109): Loss/seq after 01050 batchs: 649.626953125
INFO:root:Train (Epoch 109): Loss/seq after 01100 batchs: 640.9150390625
INFO:root:Train (Epoch 109): Loss/seq after 01150 batchs: 626.0048828125
INFO:root:Train (Epoch 109): Loss/seq after 01200 batchs: 630.3419189453125
INFO:root:Train (Epoch 109): Loss/seq after 01250 batchs: 628.2434692382812
INFO:root:Train (Epoch 109): Loss/seq after 01300 batchs: 616.4567260742188
INFO:root:Train (Epoch 109): Loss/seq after 01350 batchs: 606.6343383789062
INFO:root:Train (Epoch 109): Loss/seq after 01400 batchs: 612.50244140625
INFO:root:Train (Epoch 109): Loss/seq after 01450 batchs: 613.7338256835938
INFO:root:Train (Epoch 109): Loss/seq after 01500 batchs: 619.9190673828125
INFO:root:Train (Epoch 109): Loss/seq after 01550 batchs: 622.2171630859375
INFO:root:Train (Epoch 109): Loss/seq after 01600 batchs: 616.9555053710938
INFO:root:Train (Epoch 109): Loss/seq after 01650 batchs: 615.0067749023438
INFO:root:Train (Epoch 109): Loss/seq after 01700 batchs: 616.9603881835938
INFO:root:Train (Epoch 109): Loss/seq after 01750 batchs: 614.0123291015625
INFO:root:Train (Epoch 109): Loss/seq after 01800 batchs: 610.7976684570312
INFO:root:Train (Epoch 109): Loss/seq after 01850 batchs: 606.6971435546875
INFO:root:Train (Epoch 109): Loss/seq after 01900 batchs: 606.9444580078125
INFO:root:Train (Epoch 109): Loss/seq after 01950 batchs: 605.2808837890625
INFO:root:Train (Epoch 109): Loss/seq after 02000 batchs: 603.468017578125
INFO:root:Train (Epoch 109): Loss/seq after 02050 batchs: 601.8150634765625
INFO:root:Train (Epoch 109): Loss/seq after 02100 batchs: 598.9497680664062
INFO:root:Train (Epoch 109): Loss/seq after 02150 batchs: 596.8494262695312
INFO:root:Train (Epoch 109): Loss/seq after 02200 batchs: 593.5015258789062
INFO:root:Train (Epoch 109): Loss/seq after 02250 batchs: 591.9815673828125
INFO:root:Train (Epoch 109): Loss/seq after 02300 batchs: 589.2286987304688
INFO:root:Train (Epoch 109): Loss/seq after 02350 batchs: 584.5780639648438
INFO:root:Train (Epoch 109): Loss/seq after 02400 batchs: 585.847900390625
INFO:root:Train (Epoch 109): Loss/seq after 02450 batchs: 580.7401733398438
INFO:root:Train (Epoch 109): Loss/seq after 02500 batchs: 572.2633666992188
INFO:root:Train (Epoch 109): Loss/seq after 02550 batchs: 566.1980590820312
INFO:root:Train (Epoch 109): Loss/seq after 02600 batchs: 565.4022827148438
INFO:root:Train (Epoch 109): Loss/seq after 02650 batchs: 563.5029907226562
INFO:root:Train (Epoch 109): Loss/seq after 02700 batchs: 561.45751953125
INFO:root:Train (Epoch 109): Loss/seq after 02750 batchs: 561.169189453125
INFO:root:Train (Epoch 109): Loss/seq after 02800 batchs: 561.9720458984375
INFO:root:Train (Epoch 109): Loss/seq after 02850 batchs: 562.1420288085938
INFO:root:Train (Epoch 109): Loss/seq after 02900 batchs: 563.646484375
INFO:root:Train (Epoch 109): Loss/seq after 02950 batchs: 562.5098876953125
INFO:root:Train (Epoch 109): Loss/seq after 03000 batchs: 567.4566040039062
INFO:root:Train (Epoch 109): Loss/seq after 03050 batchs: 569.351806640625
INFO:root:Train (Epoch 109): Loss/seq after 03100 batchs: 573.053466796875
INFO:root:Train (Epoch 109): Loss/seq after 03150 batchs: 577.3272705078125
INFO:root:Train (Epoch 109): Loss/seq after 03200 batchs: 579.1617431640625
INFO:root:Train (Epoch 109): Loss/seq after 03250 batchs: 582.2247924804688
INFO:root:Train (Epoch 109): Loss/seq after 03300 batchs: 581.0924682617188
INFO:root:Train (Epoch 109): Loss/seq after 03350 batchs: 581.1009521484375
INFO:root:Train (Epoch 109): Loss/seq after 03400 batchs: 576.7468872070312
INFO:root:Train (Epoch 109): Loss/seq after 03450 batchs: 575.0604248046875
INFO:root:Train (Epoch 109): Loss/seq after 03500 batchs: 575.4046630859375
INFO:root:Train (Epoch 109): Loss/seq after 03550 batchs: 572.5009155273438
INFO:root:Train (Epoch 109): Loss/seq after 03600 batchs: 580.2610473632812
INFO:root:Train (Epoch 109): Loss/seq after 03650 batchs: 577.5459594726562
INFO:root:Train (Epoch 109): Loss/seq after 03700 batchs: 579.9569091796875
INFO:root:Train (Epoch 109): Loss/seq after 03750 batchs: 584.557861328125
INFO:root:Train (Epoch 109): Loss/seq after 03800 batchs: 582.1184692382812
INFO:root:Train (Epoch 109): Loss/seq after 03850 batchs: 580.95703125
INFO:root:Train (Epoch 109): Loss/seq after 03900 batchs: 584.9556884765625
INFO:root:Train (Epoch 109): Loss/seq after 03950 batchs: 588.669189453125
INFO:root:Train (Epoch 109): Loss/seq after 04000 batchs: 584.556640625
INFO:root:Train (Epoch 109): Loss/seq after 04050 batchs: 580.8506469726562
INFO:root:Train (Epoch 109): Loss/seq after 04100 batchs: 578.9005126953125
INFO:root:Train (Epoch 109): Loss/seq after 04150 batchs: 578.4718627929688
INFO:root:Train (Epoch 109): Loss/seq after 04200 batchs: 576.8473510742188
INFO:root:Train (Epoch 109): Loss/seq after 04250 batchs: 575.0819091796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 109): Loss/seq after 00000 batches: 543.3851318359375
INFO:root:# Valid (Epoch 109): Loss/seq after 00050 batches: 771.0762329101562
INFO:root:# Valid (Epoch 109): Loss/seq after 00100 batches: 806.9846801757812
INFO:root:# Valid (Epoch 109): Loss/seq after 00150 batches: 607.4683227539062
INFO:root:# Valid (Epoch 109): Loss/seq after 00200 batches: 557.7925415039062
INFO:root:Artifacts: Make stick videos for epoch 109
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_109_on_20220413_041755.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_109_index_567_on_20220413_041755.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 110): Loss/seq after 00000 batchs: 1031.67041015625
INFO:root:Train (Epoch 110): Loss/seq after 00050 batchs: 805.4407958984375
INFO:root:Train (Epoch 110): Loss/seq after 00100 batchs: 814.044921875
INFO:root:Train (Epoch 110): Loss/seq after 00150 batchs: 742.0411987304688
INFO:root:Train (Epoch 110): Loss/seq after 00200 batchs: 799.5906982421875
INFO:root:Train (Epoch 110): Loss/seq after 00250 batchs: 910.4763793945312
INFO:root:Train (Epoch 110): Loss/seq after 00300 batchs: 905.6128540039062
INFO:root:Train (Epoch 110): Loss/seq after 00350 batchs: 847.5316162109375
INFO:root:Train (Epoch 110): Loss/seq after 00400 batchs: 847.3621826171875
INFO:root:Train (Epoch 110): Loss/seq after 00450 batchs: 828.3964233398438
INFO:root:Train (Epoch 110): Loss/seq after 00500 batchs: 803.9121704101562
INFO:root:Train (Epoch 110): Loss/seq after 00550 batchs: 778.9712524414062
INFO:root:Train (Epoch 110): Loss/seq after 00600 batchs: 751.4766235351562
INFO:root:Train (Epoch 110): Loss/seq after 00650 batchs: 729.0391845703125
INFO:root:Train (Epoch 110): Loss/seq after 00700 batchs: 704.0828247070312
INFO:root:Train (Epoch 110): Loss/seq after 00750 batchs: 712.0301513671875
INFO:root:Train (Epoch 110): Loss/seq after 00800 batchs: 714.254150390625
INFO:root:Train (Epoch 110): Loss/seq after 00850 batchs: 692.2626953125
INFO:root:Train (Epoch 110): Loss/seq after 00900 batchs: 679.3215942382812
INFO:root:Train (Epoch 110): Loss/seq after 00950 batchs: 678.1957397460938
INFO:root:Train (Epoch 110): Loss/seq after 01000 batchs: 669.0224609375
INFO:root:Train (Epoch 110): Loss/seq after 01050 batchs: 658.0872802734375
INFO:root:Train (Epoch 110): Loss/seq after 01100 batchs: 649.349609375
INFO:root:Train (Epoch 110): Loss/seq after 01150 batchs: 634.1333618164062
INFO:root:Train (Epoch 110): Loss/seq after 01200 batchs: 637.8796997070312
INFO:root:Train (Epoch 110): Loss/seq after 01250 batchs: 635.3655395507812
INFO:root:Train (Epoch 110): Loss/seq after 01300 batchs: 623.5264282226562
INFO:root:Train (Epoch 110): Loss/seq after 01350 batchs: 613.2322998046875
INFO:root:Train (Epoch 110): Loss/seq after 01400 batchs: 618.2987670898438
INFO:root:Train (Epoch 110): Loss/seq after 01450 batchs: 619.6419677734375
INFO:root:Train (Epoch 110): Loss/seq after 01500 batchs: 625.5558471679688
INFO:root:Train (Epoch 110): Loss/seq after 01550 batchs: 627.317138671875
INFO:root:Train (Epoch 110): Loss/seq after 01600 batchs: 621.4266967773438
INFO:root:Train (Epoch 110): Loss/seq after 01650 batchs: 618.9195556640625
INFO:root:Train (Epoch 110): Loss/seq after 01700 batchs: 620.3948974609375
INFO:root:Train (Epoch 110): Loss/seq after 01750 batchs: 617.3359375
INFO:root:Train (Epoch 110): Loss/seq after 01800 batchs: 613.9110717773438
INFO:root:Train (Epoch 110): Loss/seq after 01850 batchs: 609.7778930664062
INFO:root:Train (Epoch 110): Loss/seq after 01900 batchs: 610.0955810546875
INFO:root:Train (Epoch 110): Loss/seq after 01950 batchs: 608.350830078125
INFO:root:Train (Epoch 110): Loss/seq after 02000 batchs: 606.4521484375
INFO:root:Train (Epoch 110): Loss/seq after 02050 batchs: 604.5150756835938
INFO:root:Train (Epoch 110): Loss/seq after 02100 batchs: 601.3271484375
INFO:root:Train (Epoch 110): Loss/seq after 02150 batchs: 598.9845581054688
INFO:root:Train (Epoch 110): Loss/seq after 02200 batchs: 595.702392578125
INFO:root:Train (Epoch 110): Loss/seq after 02250 batchs: 593.8760375976562
INFO:root:Train (Epoch 110): Loss/seq after 02300 batchs: 590.9312133789062
INFO:root:Train (Epoch 110): Loss/seq after 02350 batchs: 586.2521362304688
INFO:root:Train (Epoch 110): Loss/seq after 02400 batchs: 587.4508666992188
INFO:root:Train (Epoch 110): Loss/seq after 02450 batchs: 582.2893676757812
INFO:root:Train (Epoch 110): Loss/seq after 02500 batchs: 573.7574462890625
INFO:root:Train (Epoch 110): Loss/seq after 02550 batchs: 567.6480102539062
INFO:root:Train (Epoch 110): Loss/seq after 02600 batchs: 566.9049072265625
INFO:root:Train (Epoch 110): Loss/seq after 02650 batchs: 564.8563232421875
INFO:root:Train (Epoch 110): Loss/seq after 02700 batchs: 562.74462890625
INFO:root:Train (Epoch 110): Loss/seq after 02750 batchs: 562.4686889648438
INFO:root:Train (Epoch 110): Loss/seq after 02800 batchs: 563.1461791992188
INFO:root:Train (Epoch 110): Loss/seq after 02850 batchs: 563.3316650390625
INFO:root:Train (Epoch 110): Loss/seq after 02900 batchs: 564.8218994140625
INFO:root:Train (Epoch 110): Loss/seq after 02950 batchs: 563.555419921875
INFO:root:Train (Epoch 110): Loss/seq after 03000 batchs: 568.4304809570312
INFO:root:Train (Epoch 110): Loss/seq after 03050 batchs: 570.3525390625
INFO:root:Train (Epoch 110): Loss/seq after 03100 batchs: 573.943115234375
INFO:root:Train (Epoch 110): Loss/seq after 03150 batchs: 577.8641967773438
INFO:root:Train (Epoch 110): Loss/seq after 03200 batchs: 579.42431640625
INFO:root:Train (Epoch 110): Loss/seq after 03250 batchs: 582.0211181640625
INFO:root:Train (Epoch 110): Loss/seq after 03300 batchs: 581.0181274414062
INFO:root:Train (Epoch 110): Loss/seq after 03350 batchs: 581.4357299804688
INFO:root:Train (Epoch 110): Loss/seq after 03400 batchs: 577.0397338867188
INFO:root:Train (Epoch 110): Loss/seq after 03450 batchs: 575.2876586914062
INFO:root:Train (Epoch 110): Loss/seq after 03500 batchs: 575.7830810546875
INFO:root:Train (Epoch 110): Loss/seq after 03550 batchs: 573.072021484375
INFO:root:Train (Epoch 110): Loss/seq after 03600 batchs: 581.641357421875
INFO:root:Train (Epoch 110): Loss/seq after 03650 batchs: 578.8421020507812
INFO:root:Train (Epoch 110): Loss/seq after 03700 batchs: 581.4598388671875
INFO:root:Train (Epoch 110): Loss/seq after 03750 batchs: 586.04296875
INFO:root:Train (Epoch 110): Loss/seq after 03800 batchs: 583.4815673828125
INFO:root:Train (Epoch 110): Loss/seq after 03850 batchs: 582.0943603515625
INFO:root:Train (Epoch 110): Loss/seq after 03900 batchs: 585.80517578125
INFO:root:Train (Epoch 110): Loss/seq after 03950 batchs: 589.4049072265625
INFO:root:Train (Epoch 110): Loss/seq after 04000 batchs: 585.2727661132812
INFO:root:Train (Epoch 110): Loss/seq after 04050 batchs: 581.6043701171875
INFO:root:Train (Epoch 110): Loss/seq after 04100 batchs: 579.713134765625
INFO:root:Train (Epoch 110): Loss/seq after 04150 batchs: 579.3184204101562
INFO:root:Train (Epoch 110): Loss/seq after 04200 batchs: 577.6791381835938
INFO:root:Train (Epoch 110): Loss/seq after 04250 batchs: 575.9871826171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 110): Loss/seq after 00000 batches: 546.4087524414062
INFO:root:# Valid (Epoch 110): Loss/seq after 00050 batches: 746.674072265625
INFO:root:# Valid (Epoch 110): Loss/seq after 00100 batches: 810.0818481445312
INFO:root:# Valid (Epoch 110): Loss/seq after 00150 batches: 607.5213623046875
INFO:root:# Valid (Epoch 110): Loss/seq after 00200 batches: 557.3484497070312
INFO:root:Artifacts: Make stick videos for epoch 110
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_110_on_20220413_042317.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_110_index_853_on_20220413_042317.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 111): Loss/seq after 00000 batchs: 1160.6510009765625
INFO:root:Train (Epoch 111): Loss/seq after 00050 batchs: 825.5134887695312
INFO:root:Train (Epoch 111): Loss/seq after 00100 batchs: 813.7786865234375
INFO:root:Train (Epoch 111): Loss/seq after 00150 batchs: 736.5661010742188
INFO:root:Train (Epoch 111): Loss/seq after 00200 batchs: 794.6642456054688
INFO:root:Train (Epoch 111): Loss/seq after 00250 batchs: 896.7647094726562
INFO:root:Train (Epoch 111): Loss/seq after 00300 batchs: 891.7969360351562
INFO:root:Train (Epoch 111): Loss/seq after 00350 batchs: 833.95849609375
INFO:root:Train (Epoch 111): Loss/seq after 00400 batchs: 832.0052490234375
INFO:root:Train (Epoch 111): Loss/seq after 00450 batchs: 814.17578125
INFO:root:Train (Epoch 111): Loss/seq after 00500 batchs: 787.0501708984375
INFO:root:Train (Epoch 111): Loss/seq after 00550 batchs: 761.7269287109375
INFO:root:Train (Epoch 111): Loss/seq after 00600 batchs: 734.7260131835938
INFO:root:Train (Epoch 111): Loss/seq after 00650 batchs: 712.7323608398438
INFO:root:Train (Epoch 111): Loss/seq after 00700 batchs: 688.3167724609375
INFO:root:Train (Epoch 111): Loss/seq after 00750 batchs: 695.4141845703125
INFO:root:Train (Epoch 111): Loss/seq after 00800 batchs: 698.3806762695312
INFO:root:Train (Epoch 111): Loss/seq after 00850 batchs: 676.5516967773438
INFO:root:Train (Epoch 111): Loss/seq after 00900 batchs: 663.3045654296875
INFO:root:Train (Epoch 111): Loss/seq after 00950 batchs: 662.7449340820312
INFO:root:Train (Epoch 111): Loss/seq after 01000 batchs: 653.308837890625
INFO:root:Train (Epoch 111): Loss/seq after 01050 batchs: 643.1044921875
INFO:root:Train (Epoch 111): Loss/seq after 01100 batchs: 634.7263793945312
INFO:root:Train (Epoch 111): Loss/seq after 01150 batchs: 620.4347534179688
INFO:root:Train (Epoch 111): Loss/seq after 01200 batchs: 624.5873413085938
INFO:root:Train (Epoch 111): Loss/seq after 01250 batchs: 622.9758911132812
INFO:root:Train (Epoch 111): Loss/seq after 01300 batchs: 610.9054565429688
INFO:root:Train (Epoch 111): Loss/seq after 01350 batchs: 601.3809204101562
INFO:root:Train (Epoch 111): Loss/seq after 01400 batchs: 606.8594360351562
INFO:root:Train (Epoch 111): Loss/seq after 01450 batchs: 608.5221557617188
INFO:root:Train (Epoch 111): Loss/seq after 01500 batchs: 614.9267578125
INFO:root:Train (Epoch 111): Loss/seq after 01550 batchs: 617.0594482421875
INFO:root:Train (Epoch 111): Loss/seq after 01600 batchs: 611.6873168945312
INFO:root:Train (Epoch 111): Loss/seq after 01650 batchs: 609.7820434570312
INFO:root:Train (Epoch 111): Loss/seq after 01700 batchs: 611.6875
INFO:root:Train (Epoch 111): Loss/seq after 01750 batchs: 608.9114379882812
INFO:root:Train (Epoch 111): Loss/seq after 01800 batchs: 605.7328491210938
INFO:root:Train (Epoch 111): Loss/seq after 01850 batchs: 601.7546997070312
INFO:root:Train (Epoch 111): Loss/seq after 01900 batchs: 602.09765625
INFO:root:Train (Epoch 111): Loss/seq after 01950 batchs: 600.3975219726562
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 111): Loss/seq after 02000 batchs: 598.6112670898438
INFO:root:Train (Epoch 111): Loss/seq after 02050 batchs: 596.9767456054688
INFO:root:Train (Epoch 111): Loss/seq after 02100 batchs: 593.8386840820312
INFO:root:Train (Epoch 111): Loss/seq after 02150 batchs: 591.4553833007812
INFO:root:Train (Epoch 111): Loss/seq after 02200 batchs: 588.18994140625
INFO:root:Train (Epoch 111): Loss/seq after 02250 batchs: 586.2547607421875
INFO:root:Train (Epoch 111): Loss/seq after 02300 batchs: 583.4158325195312
INFO:root:Train (Epoch 111): Loss/seq after 02350 batchs: 579.18212890625
INFO:root:Train (Epoch 111): Loss/seq after 02400 batchs: 580.547119140625
INFO:root:Train (Epoch 111): Loss/seq after 02450 batchs: 575.5308227539062
INFO:root:Train (Epoch 111): Loss/seq after 02500 batchs: 567.1288452148438
INFO:root:Train (Epoch 111): Loss/seq after 02550 batchs: 561.24951171875
INFO:root:Train (Epoch 111): Loss/seq after 02600 batchs: 560.6124267578125
INFO:root:Train (Epoch 111): Loss/seq after 02650 batchs: 558.5960693359375
INFO:root:Train (Epoch 111): Loss/seq after 02700 batchs: 556.4624633789062
INFO:root:Train (Epoch 111): Loss/seq after 02750 batchs: 555.6192626953125
INFO:root:Train (Epoch 111): Loss/seq after 02800 batchs: 556.1835327148438
INFO:root:Train (Epoch 111): Loss/seq after 02850 batchs: 556.4359130859375
INFO:root:Train (Epoch 111): Loss/seq after 02900 batchs: 558.0681762695312
INFO:root:Train (Epoch 111): Loss/seq after 02950 batchs: 556.9417724609375
INFO:root:Train (Epoch 111): Loss/seq after 03000 batchs: 561.936767578125
INFO:root:Train (Epoch 111): Loss/seq after 03050 batchs: 564.0319213867188
INFO:root:Train (Epoch 111): Loss/seq after 03100 batchs: 568.0565185546875
INFO:root:Train (Epoch 111): Loss/seq after 03150 batchs: 572.6325073242188
INFO:root:Train (Epoch 111): Loss/seq after 03200 batchs: 574.1849975585938
INFO:root:Train (Epoch 111): Loss/seq after 03250 batchs: 576.6428833007812
INFO:root:Train (Epoch 111): Loss/seq after 03300 batchs: 575.4614868164062
INFO:root:Train (Epoch 111): Loss/seq after 03350 batchs: 575.6783447265625
INFO:root:Train (Epoch 111): Loss/seq after 03400 batchs: 571.3089599609375
INFO:root:Train (Epoch 111): Loss/seq after 03450 batchs: 569.72216796875
INFO:root:Train (Epoch 111): Loss/seq after 03500 batchs: 570.3270263671875
INFO:root:Train (Epoch 111): Loss/seq after 03550 batchs: 567.4351196289062
INFO:root:Train (Epoch 111): Loss/seq after 03600 batchs: 575.4544677734375
INFO:root:Train (Epoch 111): Loss/seq after 03650 batchs: 572.7689819335938
INFO:root:Train (Epoch 111): Loss/seq after 03700 batchs: 575.169921875
INFO:root:Train (Epoch 111): Loss/seq after 03750 batchs: 579.83935546875
INFO:root:Train (Epoch 111): Loss/seq after 03800 batchs: 577.3639526367188
INFO:root:Train (Epoch 111): Loss/seq after 03850 batchs: 576.0399780273438
INFO:root:Train (Epoch 111): Loss/seq after 03900 batchs: 580.1322631835938
INFO:root:Train (Epoch 111): Loss/seq after 03950 batchs: 583.5562133789062
INFO:root:Train (Epoch 111): Loss/seq after 04000 batchs: 579.442626953125
INFO:root:Train (Epoch 111): Loss/seq after 04050 batchs: 575.7548217773438
INFO:root:Train (Epoch 111): Loss/seq after 04100 batchs: 573.8346557617188
INFO:root:Train (Epoch 111): Loss/seq after 04150 batchs: 573.4790649414062
INFO:root:Train (Epoch 111): Loss/seq after 04200 batchs: 571.94677734375
INFO:root:Train (Epoch 111): Loss/seq after 04250 batchs: 570.1720581054688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 111): Loss/seq after 00000 batches: 533.6962890625
INFO:root:# Valid (Epoch 111): Loss/seq after 00050 batches: 747.1156005859375
INFO:root:# Valid (Epoch 111): Loss/seq after 00100 batches: 774.0449829101562
INFO:root:# Valid (Epoch 111): Loss/seq after 00150 batches: 585.192626953125
INFO:root:# Valid (Epoch 111): Loss/seq after 00200 batches: 540.3594970703125
INFO:root:Artifacts: Make stick videos for epoch 111
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_111_on_20220413_042839.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_111_index_1712_on_20220413_042839.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 112): Loss/seq after 00000 batchs: 1059.7213134765625
INFO:root:Train (Epoch 112): Loss/seq after 00050 batchs: 797.7261962890625
INFO:root:Train (Epoch 112): Loss/seq after 00100 batchs: 795.0430908203125
INFO:root:Train (Epoch 112): Loss/seq after 00150 batchs: 727.5931396484375
INFO:root:Train (Epoch 112): Loss/seq after 00200 batchs: 791.7097778320312
INFO:root:Train (Epoch 112): Loss/seq after 00250 batchs: 894.25439453125
INFO:root:Train (Epoch 112): Loss/seq after 00300 batchs: 889.385986328125
INFO:root:Train (Epoch 112): Loss/seq after 00350 batchs: 832.5760498046875
INFO:root:Train (Epoch 112): Loss/seq after 00400 batchs: 831.8516235351562
INFO:root:Train (Epoch 112): Loss/seq after 00450 batchs: 813.7974853515625
INFO:root:Train (Epoch 112): Loss/seq after 00500 batchs: 786.64453125
INFO:root:Train (Epoch 112): Loss/seq after 00550 batchs: 761.6823120117188
INFO:root:Train (Epoch 112): Loss/seq after 00600 batchs: 734.481689453125
INFO:root:Train (Epoch 112): Loss/seq after 00650 batchs: 711.2322387695312
INFO:root:Train (Epoch 112): Loss/seq after 00700 batchs: 686.2188110351562
INFO:root:Train (Epoch 112): Loss/seq after 00750 batchs: 692.9608154296875
INFO:root:Train (Epoch 112): Loss/seq after 00800 batchs: 695.9320068359375
INFO:root:Train (Epoch 112): Loss/seq after 00850 batchs: 674.3859252929688
INFO:root:Train (Epoch 112): Loss/seq after 00900 batchs: 660.9302978515625
INFO:root:Train (Epoch 112): Loss/seq after 00950 batchs: 659.2142333984375
INFO:root:Train (Epoch 112): Loss/seq after 01000 batchs: 649.85986328125
INFO:root:Train (Epoch 112): Loss/seq after 01050 batchs: 640.328369140625
INFO:root:Train (Epoch 112): Loss/seq after 01100 batchs: 633.720947265625
INFO:root:Train (Epoch 112): Loss/seq after 01150 batchs: 618.8408813476562
INFO:root:Train (Epoch 112): Loss/seq after 01200 batchs: 623.0776977539062
INFO:root:Train (Epoch 112): Loss/seq after 01250 batchs: 621.3622436523438
INFO:root:Train (Epoch 112): Loss/seq after 01300 batchs: 609.1456298828125
INFO:root:Train (Epoch 112): Loss/seq after 01350 batchs: 599.4861450195312
INFO:root:Train (Epoch 112): Loss/seq after 01400 batchs: 605.0357055664062
INFO:root:Train (Epoch 112): Loss/seq after 01450 batchs: 606.465087890625
INFO:root:Train (Epoch 112): Loss/seq after 01500 batchs: 612.888427734375
INFO:root:Train (Epoch 112): Loss/seq after 01550 batchs: 614.8956298828125
INFO:root:Train (Epoch 112): Loss/seq after 01600 batchs: 609.5575561523438
INFO:root:Train (Epoch 112): Loss/seq after 01650 batchs: 607.5404663085938
INFO:root:Train (Epoch 112): Loss/seq after 01700 batchs: 609.794677734375
INFO:root:Train (Epoch 112): Loss/seq after 01750 batchs: 606.879638671875
INFO:root:Train (Epoch 112): Loss/seq after 01800 batchs: 603.6650390625
INFO:root:Train (Epoch 112): Loss/seq after 01850 batchs: 599.7084350585938
INFO:root:Train (Epoch 112): Loss/seq after 01900 batchs: 600.1362915039062
INFO:root:Train (Epoch 112): Loss/seq after 01950 batchs: 598.6720581054688
INFO:root:Train (Epoch 112): Loss/seq after 02000 batchs: 596.8953857421875
INFO:root:Train (Epoch 112): Loss/seq after 02050 batchs: 595.0348510742188
INFO:root:Train (Epoch 112): Loss/seq after 02100 batchs: 592.114013671875
INFO:root:Train (Epoch 112): Loss/seq after 02150 batchs: 589.8076171875
INFO:root:Train (Epoch 112): Loss/seq after 02200 batchs: 586.54931640625
INFO:root:Train (Epoch 112): Loss/seq after 02250 batchs: 584.8883666992188
INFO:root:Train (Epoch 112): Loss/seq after 02300 batchs: 581.7119140625
INFO:root:Train (Epoch 112): Loss/seq after 02350 batchs: 577.0248413085938
INFO:root:Train (Epoch 112): Loss/seq after 02400 batchs: 578.2759399414062
INFO:root:Train (Epoch 112): Loss/seq after 02450 batchs: 573.3089599609375
INFO:root:Train (Epoch 112): Loss/seq after 02500 batchs: 564.9456787109375
INFO:root:Train (Epoch 112): Loss/seq after 02550 batchs: 559.0231323242188
INFO:root:Train (Epoch 112): Loss/seq after 02600 batchs: 558.1527709960938
INFO:root:Train (Epoch 112): Loss/seq after 02650 batchs: 556.0957641601562
INFO:root:Train (Epoch 112): Loss/seq after 02700 batchs: 553.9786376953125
INFO:root:Train (Epoch 112): Loss/seq after 02750 batchs: 553.4609375
INFO:root:Train (Epoch 112): Loss/seq after 02800 batchs: 554.04150390625
INFO:root:Train (Epoch 112): Loss/seq after 02850 batchs: 554.000732421875
INFO:root:Train (Epoch 112): Loss/seq after 02900 batchs: 555.3793334960938
INFO:root:Train (Epoch 112): Loss/seq after 02950 batchs: 554.21337890625
INFO:root:Train (Epoch 112): Loss/seq after 03000 batchs: 559.1727294921875
INFO:root:Train (Epoch 112): Loss/seq after 03050 batchs: 561.121826171875
INFO:root:Train (Epoch 112): Loss/seq after 03100 batchs: 564.755615234375
INFO:root:Train (Epoch 112): Loss/seq after 03150 batchs: 569.4087524414062
INFO:root:Train (Epoch 112): Loss/seq after 03200 batchs: 571.0067749023438
INFO:root:Train (Epoch 112): Loss/seq after 03250 batchs: 573.6178588867188
INFO:root:Train (Epoch 112): Loss/seq after 03300 batchs: 572.5196533203125
INFO:root:Train (Epoch 112): Loss/seq after 03350 batchs: 572.575439453125
INFO:root:Train (Epoch 112): Loss/seq after 03400 batchs: 568.2099609375
INFO:root:Train (Epoch 112): Loss/seq after 03450 batchs: 566.56396484375
INFO:root:Train (Epoch 112): Loss/seq after 03500 batchs: 567.1416015625
INFO:root:Train (Epoch 112): Loss/seq after 03550 batchs: 564.2748413085938
INFO:root:Train (Epoch 112): Loss/seq after 03600 batchs: 572.1478271484375
INFO:root:Train (Epoch 112): Loss/seq after 03650 batchs: 569.5895385742188
INFO:root:Train (Epoch 112): Loss/seq after 03700 batchs: 572.0975952148438
INFO:root:Train (Epoch 112): Loss/seq after 03750 batchs: 576.6732177734375
INFO:root:Train (Epoch 112): Loss/seq after 03800 batchs: 574.2904663085938
INFO:root:Train (Epoch 112): Loss/seq after 03850 batchs: 573.0070190429688
INFO:root:Train (Epoch 112): Loss/seq after 03900 batchs: 576.8009033203125
INFO:root:Train (Epoch 112): Loss/seq after 03950 batchs: 580.3667602539062
INFO:root:Train (Epoch 112): Loss/seq after 04000 batchs: 576.2847900390625
INFO:root:Train (Epoch 112): Loss/seq after 04050 batchs: 572.6019897460938
INFO:root:Train (Epoch 112): Loss/seq after 04100 batchs: 570.7269897460938
INFO:root:Train (Epoch 112): Loss/seq after 04150 batchs: 570.3297729492188
INFO:root:Train (Epoch 112): Loss/seq after 04200 batchs: 568.8320922851562
INFO:root:Train (Epoch 112): Loss/seq after 04250 batchs: 567.1157836914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 112): Loss/seq after 00000 batches: 559.5101318359375
INFO:root:# Valid (Epoch 112): Loss/seq after 00050 batches: 721.2166137695312
INFO:root:# Valid (Epoch 112): Loss/seq after 00100 batches: 750.9100952148438
INFO:root:# Valid (Epoch 112): Loss/seq after 00150 batches: 569.216064453125
INFO:root:# Valid (Epoch 112): Loss/seq after 00200 batches: 528.2304077148438
INFO:root:Artifacts: Make stick videos for epoch 112
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_112_on_20220413_043359.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_112_index_1894_on_20220413_043359.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 113): Loss/seq after 00000 batchs: 957.4862670898438
INFO:root:Train (Epoch 113): Loss/seq after 00050 batchs: 804.5112915039062
INFO:root:Train (Epoch 113): Loss/seq after 00100 batchs: 801.1024780273438
INFO:root:Train (Epoch 113): Loss/seq after 00150 batchs: 730.6149291992188
INFO:root:Train (Epoch 113): Loss/seq after 00200 batchs: 789.98388671875
INFO:root:Train (Epoch 113): Loss/seq after 00250 batchs: 886.9967041015625
INFO:root:Train (Epoch 113): Loss/seq after 00300 batchs: 884.1549682617188
INFO:root:Train (Epoch 113): Loss/seq after 00350 batchs: 827.702880859375
INFO:root:Train (Epoch 113): Loss/seq after 00400 batchs: 826.7926635742188
INFO:root:Train (Epoch 113): Loss/seq after 00450 batchs: 809.3822631835938
INFO:root:Train (Epoch 113): Loss/seq after 00500 batchs: 782.7848510742188
INFO:root:Train (Epoch 113): Loss/seq after 00550 batchs: 758.56298828125
INFO:root:Train (Epoch 113): Loss/seq after 00600 batchs: 731.5391845703125
INFO:root:Train (Epoch 113): Loss/seq after 00650 batchs: 709.2955932617188
INFO:root:Train (Epoch 113): Loss/seq after 00700 batchs: 684.3349609375
INFO:root:Train (Epoch 113): Loss/seq after 00750 batchs: 691.4335327148438
INFO:root:Train (Epoch 113): Loss/seq after 00800 batchs: 693.6348876953125
INFO:root:Train (Epoch 113): Loss/seq after 00850 batchs: 672.124267578125
INFO:root:Train (Epoch 113): Loss/seq after 00900 batchs: 658.7677612304688
INFO:root:Train (Epoch 113): Loss/seq after 00950 batchs: 658.9010009765625
INFO:root:Train (Epoch 113): Loss/seq after 01000 batchs: 649.6723022460938
INFO:root:Train (Epoch 113): Loss/seq after 01050 batchs: 639.873291015625
INFO:root:Train (Epoch 113): Loss/seq after 01100 batchs: 631.509765625
INFO:root:Train (Epoch 113): Loss/seq after 01150 batchs: 616.5619506835938
INFO:root:Train (Epoch 113): Loss/seq after 01200 batchs: 621.2130737304688
INFO:root:Train (Epoch 113): Loss/seq after 01250 batchs: 619.4700927734375
INFO:root:Train (Epoch 113): Loss/seq after 01300 batchs: 607.4616088867188
INFO:root:Train (Epoch 113): Loss/seq after 01350 batchs: 597.5855102539062
INFO:root:Train (Epoch 113): Loss/seq after 01400 batchs: 602.4407348632812
INFO:root:Train (Epoch 113): Loss/seq after 01450 batchs: 604.0845947265625
INFO:root:Train (Epoch 113): Loss/seq after 01500 batchs: 610.4052734375
INFO:root:Train (Epoch 113): Loss/seq after 01550 batchs: 612.5963745117188
INFO:root:Train (Epoch 113): Loss/seq after 01600 batchs: 607.18505859375
INFO:root:Train (Epoch 113): Loss/seq after 01650 batchs: 605.0733642578125
INFO:root:Train (Epoch 113): Loss/seq after 01700 batchs: 606.8367919921875
INFO:root:Train (Epoch 113): Loss/seq after 01750 batchs: 603.9165649414062
INFO:root:Train (Epoch 113): Loss/seq after 01800 batchs: 600.5103149414062
INFO:root:Train (Epoch 113): Loss/seq after 01850 batchs: 596.406494140625
INFO:root:Train (Epoch 113): Loss/seq after 01900 batchs: 596.8950805664062
INFO:root:Train (Epoch 113): Loss/seq after 01950 batchs: 595.3535766601562
INFO:root:Train (Epoch 113): Loss/seq after 02000 batchs: 593.7230834960938
INFO:root:Train (Epoch 113): Loss/seq after 02050 batchs: 592.18505859375
INFO:root:Train (Epoch 113): Loss/seq after 02100 batchs: 589.2481689453125
INFO:root:Train (Epoch 113): Loss/seq after 02150 batchs: 586.9262084960938
INFO:root:Train (Epoch 113): Loss/seq after 02200 batchs: 583.7548828125
INFO:root:Train (Epoch 113): Loss/seq after 02250 batchs: 582.2518920898438
INFO:root:Train (Epoch 113): Loss/seq after 02300 batchs: 579.352294921875
INFO:root:Train (Epoch 113): Loss/seq after 02350 batchs: 574.92822265625
INFO:root:Train (Epoch 113): Loss/seq after 02400 batchs: 576.1051025390625
INFO:root:Train (Epoch 113): Loss/seq after 02450 batchs: 571.1082763671875
INFO:root:Train (Epoch 113): Loss/seq after 02500 batchs: 562.7747802734375
INFO:root:Train (Epoch 113): Loss/seq after 02550 batchs: 556.8010864257812
INFO:root:Train (Epoch 113): Loss/seq after 02600 batchs: 556.0078125
INFO:root:Train (Epoch 113): Loss/seq after 02650 batchs: 553.9393310546875
INFO:root:Train (Epoch 113): Loss/seq after 02700 batchs: 551.8407592773438
INFO:root:Train (Epoch 113): Loss/seq after 02750 batchs: 551.0594482421875
INFO:root:Train (Epoch 113): Loss/seq after 02800 batchs: 551.54736328125
INFO:root:Train (Epoch 113): Loss/seq after 02850 batchs: 551.6336669921875
INFO:root:Train (Epoch 113): Loss/seq after 02900 batchs: 553.102294921875
INFO:root:Train (Epoch 113): Loss/seq after 02950 batchs: 551.9780883789062
INFO:root:Train (Epoch 113): Loss/seq after 03000 batchs: 556.9490966796875
INFO:root:Train (Epoch 113): Loss/seq after 03050 batchs: 558.86376953125
INFO:root:Train (Epoch 113): Loss/seq after 03100 batchs: 562.477783203125
INFO:root:Train (Epoch 113): Loss/seq after 03150 batchs: 566.0458984375
INFO:root:Train (Epoch 113): Loss/seq after 03200 batchs: 567.5048828125
INFO:root:Train (Epoch 113): Loss/seq after 03250 batchs: 570.1558837890625
INFO:root:Train (Epoch 113): Loss/seq after 03300 batchs: 568.8621215820312
INFO:root:Train (Epoch 113): Loss/seq after 03350 batchs: 568.933837890625
INFO:root:Train (Epoch 113): Loss/seq after 03400 batchs: 564.603271484375
INFO:root:Train (Epoch 113): Loss/seq after 03450 batchs: 563.040771484375
INFO:root:Train (Epoch 113): Loss/seq after 03500 batchs: 563.55029296875
INFO:root:Train (Epoch 113): Loss/seq after 03550 batchs: 560.6454467773438
INFO:root:Train (Epoch 113): Loss/seq after 03600 batchs: 568.2338256835938
INFO:root:Train (Epoch 113): Loss/seq after 03650 batchs: 565.850830078125
INFO:root:Train (Epoch 113): Loss/seq after 03700 batchs: 568.4569091796875
INFO:root:Train (Epoch 113): Loss/seq after 03750 batchs: 573.0765380859375
INFO:root:Train (Epoch 113): Loss/seq after 03800 batchs: 570.7255249023438
INFO:root:Train (Epoch 113): Loss/seq after 03850 batchs: 569.4806518554688
INFO:root:Train (Epoch 113): Loss/seq after 03900 batchs: 573.2335815429688
INFO:root:Train (Epoch 113): Loss/seq after 03950 batchs: 576.7437133789062
INFO:root:Train (Epoch 113): Loss/seq after 04000 batchs: 572.6992797851562
INFO:root:Train (Epoch 113): Loss/seq after 04050 batchs: 569.0485229492188
INFO:root:Train (Epoch 113): Loss/seq after 04100 batchs: 567.1625366210938
INFO:root:Train (Epoch 113): Loss/seq after 04150 batchs: 566.8057861328125
INFO:root:Train (Epoch 113): Loss/seq after 04200 batchs: 565.3267822265625
INFO:root:Train (Epoch 113): Loss/seq after 04250 batchs: 563.592041015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 113): Loss/seq after 00000 batches: 527.1577758789062
INFO:root:# Valid (Epoch 113): Loss/seq after 00050 batches: 763.1688232421875
INFO:root:# Valid (Epoch 113): Loss/seq after 00100 batches: 785.5182495117188
INFO:root:# Valid (Epoch 113): Loss/seq after 00150 batches: 593.89306640625
INFO:root:# Valid (Epoch 113): Loss/seq after 00200 batches: 546.6698608398438
INFO:root:Artifacts: Make stick videos for epoch 113
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_113_on_20220413_043921.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_113_index_1586_on_20220413_043921.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 114): Loss/seq after 00000 batchs: 998.638916015625
INFO:root:Train (Epoch 114): Loss/seq after 00050 batchs: 808.8844604492188
INFO:root:Train (Epoch 114): Loss/seq after 00100 batchs: 808.1840209960938
INFO:root:Train (Epoch 114): Loss/seq after 00150 batchs: 736.6544189453125
INFO:root:Train (Epoch 114): Loss/seq after 00200 batchs: 789.3958740234375
INFO:root:Train (Epoch 114): Loss/seq after 00250 batchs: 889.1834106445312
INFO:root:Train (Epoch 114): Loss/seq after 00300 batchs: 885.0161743164062
INFO:root:Train (Epoch 114): Loss/seq after 00350 batchs: 827.8582763671875
INFO:root:Train (Epoch 114): Loss/seq after 00400 batchs: 825.5911254882812
INFO:root:Train (Epoch 114): Loss/seq after 00450 batchs: 807.9732666015625
INFO:root:Train (Epoch 114): Loss/seq after 00500 batchs: 780.6632690429688
INFO:root:Train (Epoch 114): Loss/seq after 00550 batchs: 756.67578125
INFO:root:Train (Epoch 114): Loss/seq after 00600 batchs: 730.170166015625
INFO:root:Train (Epoch 114): Loss/seq after 00650 batchs: 706.2953491210938
INFO:root:Train (Epoch 114): Loss/seq after 00700 batchs: 679.9492797851562
INFO:root:Train (Epoch 114): Loss/seq after 00750 batchs: 685.1564331054688
INFO:root:Train (Epoch 114): Loss/seq after 00800 batchs: 688.7002563476562
INFO:root:Train (Epoch 114): Loss/seq after 00850 batchs: 667.4573974609375
INFO:root:Train (Epoch 114): Loss/seq after 00900 batchs: 654.2568969726562
INFO:root:Train (Epoch 114): Loss/seq after 00950 batchs: 652.832763671875
INFO:root:Train (Epoch 114): Loss/seq after 01000 batchs: 643.6966552734375
INFO:root:Train (Epoch 114): Loss/seq after 01050 batchs: 633.00244140625
INFO:root:Train (Epoch 114): Loss/seq after 01100 batchs: 624.685302734375
INFO:root:Train (Epoch 114): Loss/seq after 01150 batchs: 609.9463500976562
INFO:root:Train (Epoch 114): Loss/seq after 01200 batchs: 614.3715209960938
INFO:root:Train (Epoch 114): Loss/seq after 01250 batchs: 612.2601928710938
INFO:root:Train (Epoch 114): Loss/seq after 01300 batchs: 600.4082641601562
INFO:root:Train (Epoch 114): Loss/seq after 01350 batchs: 590.7816772460938
INFO:root:Train (Epoch 114): Loss/seq after 01400 batchs: 596.0592041015625
INFO:root:Train (Epoch 114): Loss/seq after 01450 batchs: 597.8292236328125
INFO:root:Train (Epoch 114): Loss/seq after 01500 batchs: 604.3085327148438
INFO:root:Train (Epoch 114): Loss/seq after 01550 batchs: 606.2896118164062
INFO:root:Train (Epoch 114): Loss/seq after 01600 batchs: 600.846923828125
INFO:root:Train (Epoch 114): Loss/seq after 01650 batchs: 598.7374267578125
INFO:root:Train (Epoch 114): Loss/seq after 01700 batchs: 600.8506469726562
INFO:root:Train (Epoch 114): Loss/seq after 01750 batchs: 598.097412109375
INFO:root:Train (Epoch 114): Loss/seq after 01800 batchs: 594.817626953125
INFO:root:Train (Epoch 114): Loss/seq after 01850 batchs: 590.9113159179688
INFO:root:Train (Epoch 114): Loss/seq after 01900 batchs: 591.2717895507812
INFO:root:Train (Epoch 114): Loss/seq after 01950 batchs: 589.6237182617188
INFO:root:Train (Epoch 114): Loss/seq after 02000 batchs: 588.2555541992188
INFO:root:Train (Epoch 114): Loss/seq after 02050 batchs: 586.8954467773438
INFO:root:Train (Epoch 114): Loss/seq after 02100 batchs: 584.0575561523438
INFO:root:Train (Epoch 114): Loss/seq after 02150 batchs: 581.9100952148438
INFO:root:Train (Epoch 114): Loss/seq after 02200 batchs: 578.7330322265625
INFO:root:Train (Epoch 114): Loss/seq after 02250 batchs: 576.9170532226562
INFO:root:Train (Epoch 114): Loss/seq after 02300 batchs: 573.9276733398438
INFO:root:Train (Epoch 114): Loss/seq after 02350 batchs: 569.4969482421875
INFO:root:Train (Epoch 114): Loss/seq after 02400 batchs: 570.7461547851562
INFO:root:Train (Epoch 114): Loss/seq after 02450 batchs: 565.90087890625
INFO:root:Train (Epoch 114): Loss/seq after 02500 batchs: 557.6414184570312
INFO:root:Train (Epoch 114): Loss/seq after 02550 batchs: 551.8470458984375
INFO:root:Train (Epoch 114): Loss/seq after 02600 batchs: 551.1806640625
INFO:root:Train (Epoch 114): Loss/seq after 02650 batchs: 549.2090454101562
INFO:root:Train (Epoch 114): Loss/seq after 02700 batchs: 547.1951904296875
INFO:root:Train (Epoch 114): Loss/seq after 02750 batchs: 546.04443359375
INFO:root:Train (Epoch 114): Loss/seq after 02800 batchs: 546.3184814453125
INFO:root:Train (Epoch 114): Loss/seq after 02850 batchs: 546.4694213867188
INFO:root:Train (Epoch 114): Loss/seq after 02900 batchs: 547.9124755859375
INFO:root:Train (Epoch 114): Loss/seq after 02950 batchs: 546.8391723632812
INFO:root:Train (Epoch 114): Loss/seq after 03000 batchs: 551.9198608398438
INFO:root:Train (Epoch 114): Loss/seq after 03050 batchs: 553.8853149414062
INFO:root:Train (Epoch 114): Loss/seq after 03100 batchs: 557.547119140625
INFO:root:Train (Epoch 114): Loss/seq after 03150 batchs: 561.423095703125
INFO:root:Train (Epoch 114): Loss/seq after 03200 batchs: 563.1380004882812
INFO:root:Train (Epoch 114): Loss/seq after 03250 batchs: 566.1107177734375
INFO:root:Train (Epoch 114): Loss/seq after 03300 batchs: 564.9827270507812
INFO:root:Train (Epoch 114): Loss/seq after 03350 batchs: 565.0712280273438
INFO:root:Train (Epoch 114): Loss/seq after 03400 batchs: 560.7867431640625
INFO:root:Train (Epoch 114): Loss/seq after 03450 batchs: 559.1851806640625
INFO:root:Train (Epoch 114): Loss/seq after 03500 batchs: 559.6074829101562
INFO:root:Train (Epoch 114): Loss/seq after 03550 batchs: 556.801513671875
INFO:root:Train (Epoch 114): Loss/seq after 03600 batchs: 564.6062622070312
INFO:root:Train (Epoch 114): Loss/seq after 03650 batchs: 561.9761352539062
INFO:root:Train (Epoch 114): Loss/seq after 03700 batchs: 564.478759765625
INFO:root:Train (Epoch 114): Loss/seq after 03750 batchs: 569.1036376953125
INFO:root:Train (Epoch 114): Loss/seq after 03800 batchs: 566.8084716796875
INFO:root:Train (Epoch 114): Loss/seq after 03850 batchs: 565.6709594726562
INFO:root:Train (Epoch 114): Loss/seq after 03900 batchs: 569.4813232421875
INFO:root:Train (Epoch 114): Loss/seq after 03950 batchs: 573.0219116210938
INFO:root:Train (Epoch 114): Loss/seq after 04000 batchs: 568.9990234375
INFO:root:Train (Epoch 114): Loss/seq after 04050 batchs: 565.3902587890625
INFO:root:Train (Epoch 114): Loss/seq after 04100 batchs: 563.5588989257812
INFO:root:Train (Epoch 114): Loss/seq after 04150 batchs: 563.2120361328125
INFO:root:Train (Epoch 114): Loss/seq after 04200 batchs: 561.5912475585938
INFO:root:Train (Epoch 114): Loss/seq after 04250 batchs: 559.7424926757812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 114): Loss/seq after 00000 batches: 520.464111328125
INFO:root:# Valid (Epoch 114): Loss/seq after 00050 batches: 710.7192993164062
INFO:root:# Valid (Epoch 114): Loss/seq after 00100 batches: 746.7710571289062
INFO:root:# Valid (Epoch 114): Loss/seq after 00150 batches: 563.9498291015625
INFO:root:# Valid (Epoch 114): Loss/seq after 00200 batches: 520.5992431640625
INFO:root:Artifacts: Make stick videos for epoch 114
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_114_on_20220413_044442.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_114_index_662_on_20220413_044442.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 115): Loss/seq after 00000 batchs: 999.7984619140625
INFO:root:Train (Epoch 115): Loss/seq after 00050 batchs: 792.889404296875
INFO:root:Train (Epoch 115): Loss/seq after 00100 batchs: 783.87060546875
INFO:root:Train (Epoch 115): Loss/seq after 00150 batchs: 713.3673706054688
INFO:root:Train (Epoch 115): Loss/seq after 00200 batchs: 773.3410034179688
INFO:root:Train (Epoch 115): Loss/seq after 00250 batchs: 874.942138671875
INFO:root:Train (Epoch 115): Loss/seq after 00300 batchs: 872.7205810546875
INFO:root:Train (Epoch 115): Loss/seq after 00350 batchs: 817.6756591796875
INFO:root:Train (Epoch 115): Loss/seq after 00400 batchs: 816.2211303710938
INFO:root:Train (Epoch 115): Loss/seq after 00450 batchs: 799.964599609375
INFO:root:Train (Epoch 115): Loss/seq after 00500 batchs: 773.1015014648438
INFO:root:Train (Epoch 115): Loss/seq after 00550 batchs: 749.56005859375
INFO:root:Train (Epoch 115): Loss/seq after 00600 batchs: 722.8758544921875
INFO:root:Train (Epoch 115): Loss/seq after 00650 batchs: 699.6603393554688
INFO:root:Train (Epoch 115): Loss/seq after 00700 batchs: 674.0743408203125
INFO:root:Train (Epoch 115): Loss/seq after 00750 batchs: 681.4409790039062
INFO:root:Train (Epoch 115): Loss/seq after 00800 batchs: 683.9268798828125
INFO:root:Train (Epoch 115): Loss/seq after 00850 batchs: 662.8541259765625
INFO:root:Train (Epoch 115): Loss/seq after 00900 batchs: 650.001708984375
INFO:root:Train (Epoch 115): Loss/seq after 00950 batchs: 649.9761962890625
INFO:root:Train (Epoch 115): Loss/seq after 01000 batchs: 640.8158569335938
INFO:root:Train (Epoch 115): Loss/seq after 01050 batchs: 631.6343994140625
INFO:root:Train (Epoch 115): Loss/seq after 01100 batchs: 624.3182373046875
INFO:root:Train (Epoch 115): Loss/seq after 01150 batchs: 610.0230712890625
INFO:root:Train (Epoch 115): Loss/seq after 01200 batchs: 614.2327880859375
INFO:root:Train (Epoch 115): Loss/seq after 01250 batchs: 612.3319702148438
INFO:root:Train (Epoch 115): Loss/seq after 01300 batchs: 600.3895263671875
INFO:root:Train (Epoch 115): Loss/seq after 01350 batchs: 590.6917114257812
INFO:root:Train (Epoch 115): Loss/seq after 01400 batchs: 595.6098022460938
INFO:root:Train (Epoch 115): Loss/seq after 01450 batchs: 596.9910278320312
INFO:root:Train (Epoch 115): Loss/seq after 01500 batchs: 603.257568359375
INFO:root:Train (Epoch 115): Loss/seq after 01550 batchs: 605.3248291015625
INFO:root:Train (Epoch 115): Loss/seq after 01600 batchs: 599.9779663085938
INFO:root:Train (Epoch 115): Loss/seq after 01650 batchs: 597.92578125
INFO:root:Train (Epoch 115): Loss/seq after 01700 batchs: 599.8652954101562
INFO:root:Train (Epoch 115): Loss/seq after 01750 batchs: 596.9196166992188
INFO:root:Train (Epoch 115): Loss/seq after 01800 batchs: 593.6470947265625
INFO:root:Train (Epoch 115): Loss/seq after 01850 batchs: 589.5339965820312
INFO:root:Train (Epoch 115): Loss/seq after 01900 batchs: 589.8245239257812
INFO:root:Train (Epoch 115): Loss/seq after 01950 batchs: 588.2239990234375
INFO:root:Train (Epoch 115): Loss/seq after 02000 batchs: 586.7777709960938
INFO:root:Train (Epoch 115): Loss/seq after 02050 batchs: 585.125732421875
INFO:root:Train (Epoch 115): Loss/seq after 02100 batchs: 582.2222900390625
INFO:root:Train (Epoch 115): Loss/seq after 02150 batchs: 580.1921997070312
INFO:root:Train (Epoch 115): Loss/seq after 02200 batchs: 576.9585571289062
INFO:root:Train (Epoch 115): Loss/seq after 02250 batchs: 575.4171752929688
INFO:root:Train (Epoch 115): Loss/seq after 02300 batchs: 572.4153442382812
INFO:root:Train (Epoch 115): Loss/seq after 02350 batchs: 568.0079956054688
INFO:root:Train (Epoch 115): Loss/seq after 02400 batchs: 569.2633056640625
INFO:root:Train (Epoch 115): Loss/seq after 02450 batchs: 564.4652099609375
INFO:root:Train (Epoch 115): Loss/seq after 02500 batchs: 556.193603515625
INFO:root:Train (Epoch 115): Loss/seq after 02550 batchs: 550.347900390625
INFO:root:Train (Epoch 115): Loss/seq after 02600 batchs: 549.3544921875
INFO:root:Train (Epoch 115): Loss/seq after 02650 batchs: 547.1712036132812
INFO:root:Train (Epoch 115): Loss/seq after 02700 batchs: 545.15478515625
INFO:root:Train (Epoch 115): Loss/seq after 02750 batchs: 543.7723999023438
INFO:root:Train (Epoch 115): Loss/seq after 02800 batchs: 544.2011108398438
INFO:root:Train (Epoch 115): Loss/seq after 02850 batchs: 544.05810546875
INFO:root:Train (Epoch 115): Loss/seq after 02900 batchs: 545.76953125
INFO:root:Train (Epoch 115): Loss/seq after 02950 batchs: 544.6875610351562
INFO:root:Train (Epoch 115): Loss/seq after 03000 batchs: 549.701171875
INFO:root:Train (Epoch 115): Loss/seq after 03050 batchs: 551.81005859375
INFO:root:Train (Epoch 115): Loss/seq after 03100 batchs: 555.2664794921875
INFO:root:Train (Epoch 115): Loss/seq after 03150 batchs: 558.6392211914062
INFO:root:Train (Epoch 115): Loss/seq after 03200 batchs: 559.9010009765625
INFO:root:Train (Epoch 115): Loss/seq after 03250 batchs: 562.7246704101562
INFO:root:Train (Epoch 115): Loss/seq after 03300 batchs: 561.8991088867188
INFO:root:Train (Epoch 115): Loss/seq after 03350 batchs: 562.3753051757812
INFO:root:Train (Epoch 115): Loss/seq after 03400 batchs: 558.1610107421875
INFO:root:Train (Epoch 115): Loss/seq after 03450 batchs: 556.6629638671875
INFO:root:Train (Epoch 115): Loss/seq after 03500 batchs: 557.1669311523438
INFO:root:Train (Epoch 115): Loss/seq after 03550 batchs: 554.3789672851562
INFO:root:Train (Epoch 115): Loss/seq after 03600 batchs: 562.3676147460938
INFO:root:Train (Epoch 115): Loss/seq after 03650 batchs: 559.7528686523438
INFO:root:Train (Epoch 115): Loss/seq after 03700 batchs: 562.2700805664062
INFO:root:Train (Epoch 115): Loss/seq after 03750 batchs: 566.888427734375
INFO:root:Train (Epoch 115): Loss/seq after 03800 batchs: 564.4776000976562
INFO:root:Train (Epoch 115): Loss/seq after 03850 batchs: 563.1914672851562
INFO:root:Train (Epoch 115): Loss/seq after 03900 batchs: 566.6326904296875
INFO:root:Train (Epoch 115): Loss/seq after 03950 batchs: 570.1455078125
INFO:root:Train (Epoch 115): Loss/seq after 04000 batchs: 566.1636962890625
INFO:root:Train (Epoch 115): Loss/seq after 04050 batchs: 562.5978393554688
INFO:root:Train (Epoch 115): Loss/seq after 04100 batchs: 560.7859497070312
INFO:root:Train (Epoch 115): Loss/seq after 04150 batchs: 560.4381103515625
INFO:root:Train (Epoch 115): Loss/seq after 04200 batchs: 558.86572265625
INFO:root:Train (Epoch 115): Loss/seq after 04250 batchs: 557.0570678710938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 115): Loss/seq after 00000 batches: 564.9229736328125
INFO:root:# Valid (Epoch 115): Loss/seq after 00050 batches: 697.1624145507812
INFO:root:# Valid (Epoch 115): Loss/seq after 00100 batches: 720.0675659179688
INFO:root:# Valid (Epoch 115): Loss/seq after 00150 batches: 546.6851806640625
INFO:root:# Valid (Epoch 115): Loss/seq after 00200 batches: 508.42840576171875
INFO:root:Artifacts: Make stick videos for epoch 115
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_115_on_20220413_045005.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_115_index_733_on_20220413_045005.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 116): Loss/seq after 00000 batchs: 926.4334106445312
INFO:root:Train (Epoch 116): Loss/seq after 00050 batchs: 770.9852294921875
INFO:root:Train (Epoch 116): Loss/seq after 00100 batchs: 772.8131103515625
INFO:root:Train (Epoch 116): Loss/seq after 00150 batchs: 701.38720703125
INFO:root:Train (Epoch 116): Loss/seq after 00200 batchs: 758.0379028320312
INFO:root:Train (Epoch 116): Loss/seq after 00250 batchs: 855.85986328125
INFO:root:Train (Epoch 116): Loss/seq after 00300 batchs: 854.5347900390625
INFO:root:Train (Epoch 116): Loss/seq after 00350 batchs: 801.1918334960938
INFO:root:Train (Epoch 116): Loss/seq after 00400 batchs: 800.1778564453125
INFO:root:Train (Epoch 116): Loss/seq after 00450 batchs: 784.7634887695312
INFO:root:Train (Epoch 116): Loss/seq after 00500 batchs: 758.3431396484375
INFO:root:Train (Epoch 116): Loss/seq after 00550 batchs: 735.3787231445312
INFO:root:Train (Epoch 116): Loss/seq after 00600 batchs: 710.0872192382812
INFO:root:Train (Epoch 116): Loss/seq after 00650 batchs: 688.1315307617188
INFO:root:Train (Epoch 116): Loss/seq after 00700 batchs: 663.7236938476562
INFO:root:Train (Epoch 116): Loss/seq after 00750 batchs: 670.676513671875
INFO:root:Train (Epoch 116): Loss/seq after 00800 batchs: 674.2026977539062
INFO:root:Train (Epoch 116): Loss/seq after 00850 batchs: 653.5115966796875
INFO:root:Train (Epoch 116): Loss/seq after 00900 batchs: 640.5363159179688
INFO:root:Train (Epoch 116): Loss/seq after 00950 batchs: 639.306640625
INFO:root:Train (Epoch 116): Loss/seq after 01000 batchs: 630.7854614257812
INFO:root:Train (Epoch 116): Loss/seq after 01050 batchs: 620.651123046875
INFO:root:Train (Epoch 116): Loss/seq after 01100 batchs: 612.963623046875
INFO:root:Train (Epoch 116): Loss/seq after 01150 batchs: 598.3212890625
INFO:root:Train (Epoch 116): Loss/seq after 01200 batchs: 602.65869140625
INFO:root:Train (Epoch 116): Loss/seq after 01250 batchs: 600.9078979492188
INFO:root:Train (Epoch 116): Loss/seq after 01300 batchs: 589.2200317382812
INFO:root:Train (Epoch 116): Loss/seq after 01350 batchs: 580.3785400390625
INFO:root:Train (Epoch 116): Loss/seq after 01400 batchs: 585.568359375
INFO:root:Train (Epoch 116): Loss/seq after 01450 batchs: 587.3178100585938
INFO:root:Train (Epoch 116): Loss/seq after 01500 batchs: 593.9898071289062
INFO:root:Train (Epoch 116): Loss/seq after 01550 batchs: 596.0692749023438
INFO:root:Train (Epoch 116): Loss/seq after 01600 batchs: 590.7446899414062
INFO:root:Train (Epoch 116): Loss/seq after 01650 batchs: 588.9165649414062
INFO:root:Train (Epoch 116): Loss/seq after 01700 batchs: 591.3280639648438
INFO:root:Train (Epoch 116): Loss/seq after 01750 batchs: 588.78564453125
INFO:root:Train (Epoch 116): Loss/seq after 01800 batchs: 585.5831298828125
INFO:root:Train (Epoch 116): Loss/seq after 01850 batchs: 581.7461547851562
INFO:root:Train (Epoch 116): Loss/seq after 01900 batchs: 581.6797485351562
INFO:root:Train (Epoch 116): Loss/seq after 01950 batchs: 580.3812255859375
INFO:root:Train (Epoch 116): Loss/seq after 02000 batchs: 579.0463256835938
INFO:root:Train (Epoch 116): Loss/seq after 02050 batchs: 577.4735717773438
INFO:root:Train (Epoch 116): Loss/seq after 02100 batchs: 574.6577758789062
INFO:root:Train (Epoch 116): Loss/seq after 02150 batchs: 572.54638671875
INFO:root:Train (Epoch 116): Loss/seq after 02200 batchs: 569.5073852539062
INFO:root:Train (Epoch 116): Loss/seq after 02250 batchs: 567.9387817382812
INFO:root:Train (Epoch 116): Loss/seq after 02300 batchs: 565.1937255859375
INFO:root:Train (Epoch 116): Loss/seq after 02350 batchs: 560.8392944335938
INFO:root:Train (Epoch 116): Loss/seq after 02400 batchs: 562.1598510742188
INFO:root:Train (Epoch 116): Loss/seq after 02450 batchs: 557.47509765625
INFO:root:Train (Epoch 116): Loss/seq after 02500 batchs: 549.3599853515625
INFO:root:Train (Epoch 116): Loss/seq after 02550 batchs: 543.5266723632812
INFO:root:Train (Epoch 116): Loss/seq after 02600 batchs: 542.90478515625
INFO:root:Train (Epoch 116): Loss/seq after 02650 batchs: 540.822265625
INFO:root:Train (Epoch 116): Loss/seq after 02700 batchs: 538.771484375
INFO:root:Train (Epoch 116): Loss/seq after 02750 batchs: 537.59423828125
INFO:root:Train (Epoch 116): Loss/seq after 02800 batchs: 537.3770751953125
INFO:root:Train (Epoch 116): Loss/seq after 02850 batchs: 537.3884887695312
INFO:root:Train (Epoch 116): Loss/seq after 02900 batchs: 539.0602416992188
INFO:root:Train (Epoch 116): Loss/seq after 02950 batchs: 538.12255859375
INFO:root:Train (Epoch 116): Loss/seq after 03000 batchs: 543.22607421875
INFO:root:Train (Epoch 116): Loss/seq after 03050 batchs: 545.1756591796875
INFO:root:Train (Epoch 116): Loss/seq after 03100 batchs: 548.6861572265625
INFO:root:Train (Epoch 116): Loss/seq after 03150 batchs: 552.0349731445312
INFO:root:Train (Epoch 116): Loss/seq after 03200 batchs: 553.2957153320312
INFO:root:Train (Epoch 116): Loss/seq after 03250 batchs: 555.9483032226562
INFO:root:Train (Epoch 116): Loss/seq after 03300 batchs: 554.8792724609375
INFO:root:Train (Epoch 116): Loss/seq after 03350 batchs: 555.188232421875
INFO:root:Train (Epoch 116): Loss/seq after 03400 batchs: 551.003662109375
INFO:root:Train (Epoch 116): Loss/seq after 03450 batchs: 549.5492553710938
INFO:root:Train (Epoch 116): Loss/seq after 03500 batchs: 550.1339721679688
INFO:root:Train (Epoch 116): Loss/seq after 03550 batchs: 547.3897705078125
INFO:root:Train (Epoch 116): Loss/seq after 03600 batchs: 555.1004638671875
INFO:root:Train (Epoch 116): Loss/seq after 03650 batchs: 552.6856079101562
INFO:root:Train (Epoch 116): Loss/seq after 03700 batchs: 555.3045043945312
INFO:root:Train (Epoch 116): Loss/seq after 03750 batchs: 559.9398193359375
INFO:root:Train (Epoch 116): Loss/seq after 03800 batchs: 557.7105712890625
INFO:root:Train (Epoch 116): Loss/seq after 03850 batchs: 556.5184936523438
INFO:root:Train (Epoch 116): Loss/seq after 03900 batchs: 560.1526489257812
INFO:root:Train (Epoch 116): Loss/seq after 03950 batchs: 563.6970825195312
INFO:root:Train (Epoch 116): Loss/seq after 04000 batchs: 559.7798461914062
INFO:root:Train (Epoch 116): Loss/seq after 04050 batchs: 556.2763671875
INFO:root:Train (Epoch 116): Loss/seq after 04100 batchs: 554.5568237304688
INFO:root:Train (Epoch 116): Loss/seq after 04150 batchs: 554.2791748046875
INFO:root:Train (Epoch 116): Loss/seq after 04200 batchs: 552.7825927734375
INFO:root:Train (Epoch 116): Loss/seq after 04250 batchs: 550.9945678710938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 116): Loss/seq after 00000 batches: 511.4385681152344
INFO:root:# Valid (Epoch 116): Loss/seq after 00050 batches: 688.906494140625
INFO:root:# Valid (Epoch 116): Loss/seq after 00100 batches: 726.642333984375
INFO:root:# Valid (Epoch 116): Loss/seq after 00150 batches: 551.1559448242188
INFO:root:# Valid (Epoch 116): Loss/seq after 00200 batches: 510.16845703125
INFO:root:Artifacts: Make stick videos for epoch 116
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_116_on_20220413_045527.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_116_index_470_on_20220413_045527.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 117): Loss/seq after 00000 batchs: 1159.9764404296875
INFO:root:Train (Epoch 117): Loss/seq after 00050 batchs: 789.9293212890625
INFO:root:Train (Epoch 117): Loss/seq after 00100 batchs: 789.9606323242188
INFO:root:Train (Epoch 117): Loss/seq after 00150 batchs: 720.6673583984375
INFO:root:Train (Epoch 117): Loss/seq after 00200 batchs: 778.6170043945312
INFO:root:Train (Epoch 117): Loss/seq after 00250 batchs: 874.5513916015625
INFO:root:Train (Epoch 117): Loss/seq after 00300 batchs: 872.5173950195312
INFO:root:Train (Epoch 117): Loss/seq after 00350 batchs: 817.0775146484375
INFO:root:Train (Epoch 117): Loss/seq after 00400 batchs: 814.2945556640625
INFO:root:Train (Epoch 117): Loss/seq after 00450 batchs: 797.5289306640625
INFO:root:Train (Epoch 117): Loss/seq after 00500 batchs: 772.8270874023438
INFO:root:Train (Epoch 117): Loss/seq after 00550 batchs: 747.9047241210938
INFO:root:Train (Epoch 117): Loss/seq after 00600 batchs: 721.2030639648438
INFO:root:Train (Epoch 117): Loss/seq after 00650 batchs: 698.2455444335938
INFO:root:Train (Epoch 117): Loss/seq after 00700 batchs: 672.154296875
INFO:root:Train (Epoch 117): Loss/seq after 00750 batchs: 678.1837158203125
INFO:root:Train (Epoch 117): Loss/seq after 00800 batchs: 680.9664306640625
INFO:root:Train (Epoch 117): Loss/seq after 00850 batchs: 659.4490356445312
INFO:root:Train (Epoch 117): Loss/seq after 00900 batchs: 645.6282348632812
INFO:root:Train (Epoch 117): Loss/seq after 00950 batchs: 644.58251953125
INFO:root:Train (Epoch 117): Loss/seq after 01000 batchs: 635.532470703125
INFO:root:Train (Epoch 117): Loss/seq after 01050 batchs: 624.9191284179688
INFO:root:Train (Epoch 117): Loss/seq after 01100 batchs: 617.1201782226562
INFO:root:Train (Epoch 117): Loss/seq after 01150 batchs: 602.701171875
INFO:root:Train (Epoch 117): Loss/seq after 01200 batchs: 606.97119140625
INFO:root:Train (Epoch 117): Loss/seq after 01250 batchs: 604.9384765625
INFO:root:Train (Epoch 117): Loss/seq after 01300 batchs: 593.431396484375
INFO:root:Train (Epoch 117): Loss/seq after 01350 batchs: 584.1947631835938
INFO:root:Train (Epoch 117): Loss/seq after 01400 batchs: 589.7172241210938
INFO:root:Train (Epoch 117): Loss/seq after 01450 batchs: 591.5028076171875
INFO:root:Train (Epoch 117): Loss/seq after 01500 batchs: 597.9463500976562
INFO:root:Train (Epoch 117): Loss/seq after 01550 batchs: 599.673095703125
INFO:root:Train (Epoch 117): Loss/seq after 01600 batchs: 594.1788330078125
INFO:root:Train (Epoch 117): Loss/seq after 01650 batchs: 591.892333984375
INFO:root:Train (Epoch 117): Loss/seq after 01700 batchs: 594.0756225585938
INFO:root:Train (Epoch 117): Loss/seq after 01750 batchs: 591.191162109375
INFO:root:Train (Epoch 117): Loss/seq after 01800 batchs: 587.9083251953125
INFO:root:Train (Epoch 117): Loss/seq after 01850 batchs: 583.9332885742188
INFO:root:Train (Epoch 117): Loss/seq after 01900 batchs: 583.7306518554688
INFO:root:Train (Epoch 117): Loss/seq after 01950 batchs: 581.8692626953125
INFO:root:Train (Epoch 117): Loss/seq after 02000 batchs: 580.4577026367188
INFO:root:Train (Epoch 117): Loss/seq after 02050 batchs: 578.9239501953125
INFO:root:Train (Epoch 117): Loss/seq after 02100 batchs: 576.0514526367188
INFO:root:Train (Epoch 117): Loss/seq after 02150 batchs: 574.0194091796875
INFO:root:Train (Epoch 117): Loss/seq after 02200 batchs: 570.8308715820312
INFO:root:Train (Epoch 117): Loss/seq after 02250 batchs: 569.181884765625
INFO:root:Train (Epoch 117): Loss/seq after 02300 batchs: 566.3262939453125
INFO:root:Train (Epoch 117): Loss/seq after 02350 batchs: 562.0184936523438
INFO:root:Train (Epoch 117): Loss/seq after 02400 batchs: 563.3365478515625
INFO:root:Train (Epoch 117): Loss/seq after 02450 batchs: 558.5463256835938
INFO:root:Train (Epoch 117): Loss/seq after 02500 batchs: 550.39453125
INFO:root:Train (Epoch 117): Loss/seq after 02550 batchs: 544.6725463867188
INFO:root:Train (Epoch 117): Loss/seq after 02600 batchs: 543.7982177734375
INFO:root:Train (Epoch 117): Loss/seq after 02650 batchs: 541.6001586914062
INFO:root:Train (Epoch 117): Loss/seq after 02700 batchs: 539.3634643554688
INFO:root:Train (Epoch 117): Loss/seq after 02750 batchs: 537.9723510742188
INFO:root:Train (Epoch 117): Loss/seq after 02800 batchs: 538.1705932617188
INFO:root:Train (Epoch 117): Loss/seq after 02850 batchs: 538.014892578125
INFO:root:Train (Epoch 117): Loss/seq after 02900 batchs: 539.7263793945312
INFO:root:Train (Epoch 117): Loss/seq after 02950 batchs: 538.6735229492188
INFO:root:Train (Epoch 117): Loss/seq after 03000 batchs: 543.6250610351562
INFO:root:Train (Epoch 117): Loss/seq after 03050 batchs: 545.577392578125
INFO:root:Train (Epoch 117): Loss/seq after 03100 batchs: 548.9677124023438
INFO:root:Train (Epoch 117): Loss/seq after 03150 batchs: 552.3033447265625
INFO:root:Train (Epoch 117): Loss/seq after 03200 batchs: 553.070556640625
INFO:root:Train (Epoch 117): Loss/seq after 03250 batchs: 555.6079711914062
INFO:root:Train (Epoch 117): Loss/seq after 03300 batchs: 554.4577026367188
INFO:root:Train (Epoch 117): Loss/seq after 03350 batchs: 554.3228759765625
INFO:root:Train (Epoch 117): Loss/seq after 03400 batchs: 550.12060546875
INFO:root:Train (Epoch 117): Loss/seq after 03450 batchs: 548.615478515625
INFO:root:Train (Epoch 117): Loss/seq after 03500 batchs: 549.185791015625
INFO:root:Train (Epoch 117): Loss/seq after 03550 batchs: 546.4298095703125
INFO:root:Train (Epoch 117): Loss/seq after 03600 batchs: 554.2185668945312
INFO:root:Train (Epoch 117): Loss/seq after 03650 batchs: 551.6450805664062
INFO:root:Train (Epoch 117): Loss/seq after 03700 batchs: 554.23486328125
INFO:root:Train (Epoch 117): Loss/seq after 03750 batchs: 558.8679809570312
INFO:root:Train (Epoch 117): Loss/seq after 03800 batchs: 556.6344604492188
INFO:root:Train (Epoch 117): Loss/seq after 03850 batchs: 555.4057006835938
INFO:root:Train (Epoch 117): Loss/seq after 03900 batchs: 559.090087890625
INFO:root:Train (Epoch 117): Loss/seq after 03950 batchs: 562.522216796875
INFO:root:Train (Epoch 117): Loss/seq after 04000 batchs: 558.5668334960938
INFO:root:Train (Epoch 117): Loss/seq after 04050 batchs: 555.0248413085938
INFO:root:Train (Epoch 117): Loss/seq after 04100 batchs: 553.28564453125
INFO:root:Train (Epoch 117): Loss/seq after 04150 batchs: 553.0558471679688
INFO:root:Train (Epoch 117): Loss/seq after 04200 batchs: 551.6422119140625
INFO:root:Train (Epoch 117): Loss/seq after 04250 batchs: 549.8236083984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 117): Loss/seq after 00000 batches: 512.5776977539062
INFO:root:# Valid (Epoch 117): Loss/seq after 00050 batches: 686.7137451171875
INFO:root:# Valid (Epoch 117): Loss/seq after 00100 batches: 720.9886474609375
INFO:root:# Valid (Epoch 117): Loss/seq after 00150 batches: 548.6614990234375
INFO:root:# Valid (Epoch 117): Loss/seq after 00200 batches: 508.8608093261719
INFO:root:Artifacts: Make stick videos for epoch 117
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_117_on_20220413_050048.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_117_index_528_on_20220413_050048.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 118): Loss/seq after 00000 batchs: 1028.6070556640625
INFO:root:Train (Epoch 118): Loss/seq after 00050 batchs: 778.865478515625
INFO:root:Train (Epoch 118): Loss/seq after 00100 batchs: 772.7202758789062
INFO:root:Train (Epoch 118): Loss/seq after 00150 batchs: 702.0918579101562
INFO:root:Train (Epoch 118): Loss/seq after 00200 batchs: 761.7867431640625
INFO:root:Train (Epoch 118): Loss/seq after 00250 batchs: 854.0438232421875
INFO:root:Train (Epoch 118): Loss/seq after 00300 batchs: 854.2523803710938
INFO:root:Train (Epoch 118): Loss/seq after 00350 batchs: 801.0111083984375
INFO:root:Train (Epoch 118): Loss/seq after 00400 batchs: 799.9581298828125
INFO:root:Train (Epoch 118): Loss/seq after 00450 batchs: 784.6492919921875
INFO:root:Train (Epoch 118): Loss/seq after 00500 batchs: 760.1144409179688
INFO:root:Train (Epoch 118): Loss/seq after 00550 batchs: 737.1847534179688
INFO:root:Train (Epoch 118): Loss/seq after 00600 batchs: 711.4873657226562
INFO:root:Train (Epoch 118): Loss/seq after 00650 batchs: 688.5223999023438
INFO:root:Train (Epoch 118): Loss/seq after 00700 batchs: 664.0909423828125
INFO:root:Train (Epoch 118): Loss/seq after 00750 batchs: 670.3536376953125
INFO:root:Train (Epoch 118): Loss/seq after 00800 batchs: 673.1300659179688
INFO:root:Train (Epoch 118): Loss/seq after 00850 batchs: 652.0596313476562
INFO:root:Train (Epoch 118): Loss/seq after 00900 batchs: 638.50439453125
INFO:root:Train (Epoch 118): Loss/seq after 00950 batchs: 636.03564453125
INFO:root:Train (Epoch 118): Loss/seq after 01000 batchs: 627.0089721679688
INFO:root:Train (Epoch 118): Loss/seq after 01050 batchs: 616.7354736328125
INFO:root:Train (Epoch 118): Loss/seq after 01100 batchs: 608.8828735351562
INFO:root:Train (Epoch 118): Loss/seq after 01150 batchs: 594.1205444335938
INFO:root:Train (Epoch 118): Loss/seq after 01200 batchs: 598.7782592773438
INFO:root:Train (Epoch 118): Loss/seq after 01250 batchs: 596.8839111328125
INFO:root:Train (Epoch 118): Loss/seq after 01300 batchs: 585.298095703125
INFO:root:Train (Epoch 118): Loss/seq after 01350 batchs: 576.3058471679688
INFO:root:Train (Epoch 118): Loss/seq after 01400 batchs: 580.911376953125
INFO:root:Train (Epoch 118): Loss/seq after 01450 batchs: 582.4820556640625
INFO:root:Train (Epoch 118): Loss/seq after 01500 batchs: 589.1141967773438
INFO:root:Train (Epoch 118): Loss/seq after 01550 batchs: 590.7269287109375
INFO:root:Train (Epoch 118): Loss/seq after 01600 batchs: 585.5008544921875
INFO:root:Train (Epoch 118): Loss/seq after 01650 batchs: 583.644775390625
INFO:root:Train (Epoch 118): Loss/seq after 01700 batchs: 586.2693481445312
INFO:root:Train (Epoch 118): Loss/seq after 01750 batchs: 583.4668579101562
INFO:root:Train (Epoch 118): Loss/seq after 01800 batchs: 580.4219360351562
INFO:root:Train (Epoch 118): Loss/seq after 01850 batchs: 576.6902465820312
INFO:root:Train (Epoch 118): Loss/seq after 01900 batchs: 576.5592651367188
INFO:root:Train (Epoch 118): Loss/seq after 01950 batchs: 574.8933715820312
INFO:root:Train (Epoch 118): Loss/seq after 02000 batchs: 573.6104125976562
INFO:root:Train (Epoch 118): Loss/seq after 02050 batchs: 572.0953369140625
INFO:root:Train (Epoch 118): Loss/seq after 02100 batchs: 569.4013671875
INFO:root:Train (Epoch 118): Loss/seq after 02150 batchs: 567.4760131835938
INFO:root:Train (Epoch 118): Loss/seq after 02200 batchs: 564.3916015625
INFO:root:Train (Epoch 118): Loss/seq after 02250 batchs: 562.6931762695312
INFO:root:Train (Epoch 118): Loss/seq after 02300 batchs: 559.6195068359375
INFO:root:Train (Epoch 118): Loss/seq after 02350 batchs: 555.3587036132812
INFO:root:Train (Epoch 118): Loss/seq after 02400 batchs: 556.6637573242188
INFO:root:Train (Epoch 118): Loss/seq after 02450 batchs: 551.998291015625
INFO:root:Train (Epoch 118): Loss/seq after 02500 batchs: 543.979736328125
INFO:root:Train (Epoch 118): Loss/seq after 02550 batchs: 538.2382202148438
INFO:root:Train (Epoch 118): Loss/seq after 02600 batchs: 537.2810668945312
INFO:root:Train (Epoch 118): Loss/seq after 02650 batchs: 535.2102661132812
INFO:root:Train (Epoch 118): Loss/seq after 02700 batchs: 533.1407470703125
INFO:root:Train (Epoch 118): Loss/seq after 02750 batchs: 531.7416381835938
INFO:root:Train (Epoch 118): Loss/seq after 02800 batchs: 532.1358032226562
INFO:root:Train (Epoch 118): Loss/seq after 02850 batchs: 532.172119140625
INFO:root:Train (Epoch 118): Loss/seq after 02900 batchs: 533.7855834960938
INFO:root:Train (Epoch 118): Loss/seq after 02950 batchs: 532.8516235351562
INFO:root:Train (Epoch 118): Loss/seq after 03000 batchs: 537.9857177734375
INFO:root:Train (Epoch 118): Loss/seq after 03050 batchs: 540.0247802734375
INFO:root:Train (Epoch 118): Loss/seq after 03100 batchs: 543.5352783203125
INFO:root:Train (Epoch 118): Loss/seq after 03150 batchs: 546.5466918945312
INFO:root:Train (Epoch 118): Loss/seq after 03200 batchs: 547.6265869140625
INFO:root:Train (Epoch 118): Loss/seq after 03250 batchs: 550.174072265625
INFO:root:Train (Epoch 118): Loss/seq after 03300 batchs: 549.2337036132812
INFO:root:Train (Epoch 118): Loss/seq after 03350 batchs: 549.1617431640625
INFO:root:Train (Epoch 118): Loss/seq after 03400 batchs: 544.9434204101562
INFO:root:Train (Epoch 118): Loss/seq after 03450 batchs: 543.4925537109375
INFO:root:Train (Epoch 118): Loss/seq after 03500 batchs: 544.4063720703125
INFO:root:Train (Epoch 118): Loss/seq after 03550 batchs: 541.912841796875
INFO:root:Train (Epoch 118): Loss/seq after 03600 batchs: 549.6504516601562
INFO:root:Train (Epoch 118): Loss/seq after 03650 batchs: 547.2572631835938
INFO:root:Train (Epoch 118): Loss/seq after 03700 batchs: 549.8621215820312
INFO:root:Train (Epoch 118): Loss/seq after 03750 batchs: 554.424560546875
INFO:root:Train (Epoch 118): Loss/seq after 03800 batchs: 552.2052001953125
INFO:root:Train (Epoch 118): Loss/seq after 03850 batchs: 551.0196533203125
INFO:root:Train (Epoch 118): Loss/seq after 03900 batchs: 554.3336791992188
INFO:root:Train (Epoch 118): Loss/seq after 03950 batchs: 557.8175659179688
INFO:root:Train (Epoch 118): Loss/seq after 04000 batchs: 553.9521484375
INFO:root:Train (Epoch 118): Loss/seq after 04050 batchs: 550.4774169921875
INFO:root:Train (Epoch 118): Loss/seq after 04100 batchs: 548.7376098632812
INFO:root:Train (Epoch 118): Loss/seq after 04150 batchs: 548.5047607421875
INFO:root:Train (Epoch 118): Loss/seq after 04200 batchs: 547.0903930664062
INFO:root:Train (Epoch 118): Loss/seq after 04250 batchs: 545.322509765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 118): Loss/seq after 00000 batches: 501.415283203125
INFO:root:# Valid (Epoch 118): Loss/seq after 00050 batches: 681.117919921875
INFO:root:# Valid (Epoch 118): Loss/seq after 00100 batches: 715.5302124023438
INFO:root:# Valid (Epoch 118): Loss/seq after 00150 batches: 542.7385864257812
INFO:root:# Valid (Epoch 118): Loss/seq after 00200 batches: 503.8626403808594
INFO:root:Artifacts: Make stick videos for epoch 118
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_118_on_20220413_050609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_118_index_1130_on_20220413_050609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 119): Loss/seq after 00000 batchs: 992.8432006835938
INFO:root:Train (Epoch 119): Loss/seq after 00050 batchs: 786.268310546875
INFO:root:Train (Epoch 119): Loss/seq after 00100 batchs: 770.1617431640625
INFO:root:Train (Epoch 119): Loss/seq after 00150 batchs: 699.2548217773438
INFO:root:Train (Epoch 119): Loss/seq after 00200 batchs: 758.5454711914062
INFO:root:Train (Epoch 119): Loss/seq after 00250 batchs: 848.2799682617188
INFO:root:Train (Epoch 119): Loss/seq after 00300 batchs: 847.6716918945312
INFO:root:Train (Epoch 119): Loss/seq after 00350 batchs: 794.6777954101562
INFO:root:Train (Epoch 119): Loss/seq after 00400 batchs: 789.0965576171875
INFO:root:Train (Epoch 119): Loss/seq after 00450 batchs: 775.0242309570312
INFO:root:Train (Epoch 119): Loss/seq after 00500 batchs: 749.9566650390625
INFO:root:Train (Epoch 119): Loss/seq after 00550 batchs: 727.1182250976562
INFO:root:Train (Epoch 119): Loss/seq after 00600 batchs: 701.3761596679688
INFO:root:Train (Epoch 119): Loss/seq after 00650 batchs: 677.9041748046875
INFO:root:Train (Epoch 119): Loss/seq after 00700 batchs: 651.8857421875
INFO:root:Train (Epoch 119): Loss/seq after 00750 batchs: 658.7256469726562
INFO:root:Train (Epoch 119): Loss/seq after 00800 batchs: 663.1485595703125
INFO:root:Train (Epoch 119): Loss/seq after 00850 batchs: 642.2904663085938
INFO:root:Train (Epoch 119): Loss/seq after 00900 batchs: 629.512939453125
INFO:root:Train (Epoch 119): Loss/seq after 00950 batchs: 629.2583618164062
INFO:root:Train (Epoch 119): Loss/seq after 01000 batchs: 621.2081298828125
INFO:root:Train (Epoch 119): Loss/seq after 01050 batchs: 612.4598388671875
INFO:root:Train (Epoch 119): Loss/seq after 01100 batchs: 606.0396118164062
INFO:root:Train (Epoch 119): Loss/seq after 01150 batchs: 591.3093872070312
INFO:root:Train (Epoch 119): Loss/seq after 01200 batchs: 595.9130249023438
INFO:root:Train (Epoch 119): Loss/seq after 01250 batchs: 594.9652709960938
INFO:root:Train (Epoch 119): Loss/seq after 01300 batchs: 583.9841918945312
INFO:root:Train (Epoch 119): Loss/seq after 01350 batchs: 574.5870971679688
INFO:root:Train (Epoch 119): Loss/seq after 01400 batchs: 579.0294799804688
INFO:root:Train (Epoch 119): Loss/seq after 01450 batchs: 580.9722900390625
INFO:root:Train (Epoch 119): Loss/seq after 01500 batchs: 587.4928588867188
INFO:root:Train (Epoch 119): Loss/seq after 01550 batchs: 589.4720458984375
INFO:root:Train (Epoch 119): Loss/seq after 01600 batchs: 584.265625
INFO:root:Train (Epoch 119): Loss/seq after 01650 batchs: 582.5091552734375
INFO:root:Train (Epoch 119): Loss/seq after 01700 batchs: 585.0210571289062
INFO:root:Train (Epoch 119): Loss/seq after 01750 batchs: 582.4468994140625
INFO:root:Train (Epoch 119): Loss/seq after 01800 batchs: 579.3231811523438
INFO:root:Train (Epoch 119): Loss/seq after 01850 batchs: 575.4161987304688
INFO:root:Train (Epoch 119): Loss/seq after 01900 batchs: 575.0986328125
INFO:root:Train (Epoch 119): Loss/seq after 01950 batchs: 573.4147338867188
INFO:root:Train (Epoch 119): Loss/seq after 02000 batchs: 572.127197265625
INFO:root:Train (Epoch 119): Loss/seq after 02050 batchs: 570.6585693359375
INFO:root:Train (Epoch 119): Loss/seq after 02100 batchs: 567.8461303710938
INFO:root:Train (Epoch 119): Loss/seq after 02150 batchs: 565.6048583984375
INFO:root:Train (Epoch 119): Loss/seq after 02200 batchs: 562.5366821289062
INFO:root:Train (Epoch 119): Loss/seq after 02250 batchs: 561.0015869140625
INFO:root:Train (Epoch 119): Loss/seq after 02300 batchs: 558.1048583984375
INFO:root:Train (Epoch 119): Loss/seq after 02350 batchs: 553.902587890625
INFO:root:Train (Epoch 119): Loss/seq after 02400 batchs: 555.1712036132812
INFO:root:Train (Epoch 119): Loss/seq after 02450 batchs: 550.4658813476562
INFO:root:Train (Epoch 119): Loss/seq after 02500 batchs: 542.4653930664062
INFO:root:Train (Epoch 119): Loss/seq after 02550 batchs: 536.7745971679688
INFO:root:Train (Epoch 119): Loss/seq after 02600 batchs: 536.1895141601562
INFO:root:Train (Epoch 119): Loss/seq after 02650 batchs: 533.9688110351562
INFO:root:Train (Epoch 119): Loss/seq after 02700 batchs: 531.939453125
INFO:root:Train (Epoch 119): Loss/seq after 02750 batchs: 530.4083251953125
INFO:root:Train (Epoch 119): Loss/seq after 02800 batchs: 530.47900390625
INFO:root:Train (Epoch 119): Loss/seq after 02850 batchs: 530.3550415039062
INFO:root:Train (Epoch 119): Loss/seq after 02900 batchs: 531.95263671875
INFO:root:Train (Epoch 119): Loss/seq after 02950 batchs: 531.0299682617188
INFO:root:Train (Epoch 119): Loss/seq after 03000 batchs: 536.0973510742188
INFO:root:Train (Epoch 119): Loss/seq after 03050 batchs: 538.0444946289062
INFO:root:Train (Epoch 119): Loss/seq after 03100 batchs: 541.418212890625
INFO:root:Train (Epoch 119): Loss/seq after 03150 batchs: 544.643798828125
INFO:root:Train (Epoch 119): Loss/seq after 03200 batchs: 545.7747802734375
INFO:root:Train (Epoch 119): Loss/seq after 03250 batchs: 548.396240234375
INFO:root:Train (Epoch 119): Loss/seq after 03300 batchs: 547.3446044921875
INFO:root:Train (Epoch 119): Loss/seq after 03350 batchs: 547.494384765625
INFO:root:Train (Epoch 119): Loss/seq after 03400 batchs: 543.2265014648438
INFO:root:Train (Epoch 119): Loss/seq after 03450 batchs: 541.895751953125
INFO:root:Train (Epoch 119): Loss/seq after 03500 batchs: 542.6227416992188
INFO:root:Train (Epoch 119): Loss/seq after 03550 batchs: 539.8515014648438
INFO:root:Train (Epoch 119): Loss/seq after 03600 batchs: 547.3759765625
INFO:root:Train (Epoch 119): Loss/seq after 03650 batchs: 544.8363647460938
INFO:root:Train (Epoch 119): Loss/seq after 03700 batchs: 547.275390625
INFO:root:Train (Epoch 119): Loss/seq after 03750 batchs: 551.8532104492188
INFO:root:Train (Epoch 119): Loss/seq after 03800 batchs: 549.6351318359375
INFO:root:Train (Epoch 119): Loss/seq after 03850 batchs: 548.4954833984375
INFO:root:Train (Epoch 119): Loss/seq after 03900 batchs: 551.9972534179688
INFO:root:Train (Epoch 119): Loss/seq after 03950 batchs: 555.3549194335938
INFO:root:Train (Epoch 119): Loss/seq after 04000 batchs: 551.4756469726562
INFO:root:Train (Epoch 119): Loss/seq after 04050 batchs: 547.991943359375
INFO:root:Train (Epoch 119): Loss/seq after 04100 batchs: 546.2962646484375
INFO:root:Train (Epoch 119): Loss/seq after 04150 batchs: 546.0996704101562
INFO:root:Train (Epoch 119): Loss/seq after 04200 batchs: 544.7017211914062
INFO:root:Train (Epoch 119): Loss/seq after 04250 batchs: 542.9744262695312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 119): Loss/seq after 00000 batches: 517.7312622070312
INFO:root:# Valid (Epoch 119): Loss/seq after 00050 batches: 655.8267822265625
INFO:root:# Valid (Epoch 119): Loss/seq after 00100 batches: 691.7640380859375
INFO:root:# Valid (Epoch 119): Loss/seq after 00150 batches: 528.5203247070312
INFO:root:# Valid (Epoch 119): Loss/seq after 00200 batches: 492.0107421875
INFO:root:Artifacts: Make stick videos for epoch 119
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_119_on_20220413_051131.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_119_index_916_on_20220413_051131.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 120): Loss/seq after 00000 batchs: 915.35400390625
INFO:root:Train (Epoch 120): Loss/seq after 00050 batchs: 767.8172607421875
INFO:root:Train (Epoch 120): Loss/seq after 00100 batchs: 760.0310668945312
INFO:root:Train (Epoch 120): Loss/seq after 00150 batchs: 693.9190673828125
INFO:root:Train (Epoch 120): Loss/seq after 00200 batchs: 749.281005859375
INFO:root:Train (Epoch 120): Loss/seq after 00250 batchs: 839.0075073242188
INFO:root:Train (Epoch 120): Loss/seq after 00300 batchs: 839.744140625
INFO:root:Train (Epoch 120): Loss/seq after 00350 batchs: 788.0126342773438
INFO:root:Train (Epoch 120): Loss/seq after 00400 batchs: 786.6665649414062
INFO:root:Train (Epoch 120): Loss/seq after 00450 batchs: 772.789306640625
INFO:root:Train (Epoch 120): Loss/seq after 00500 batchs: 747.6851196289062
INFO:root:Train (Epoch 120): Loss/seq after 00550 batchs: 725.8977661132812
INFO:root:Train (Epoch 120): Loss/seq after 00600 batchs: 700.1954345703125
INFO:root:Train (Epoch 120): Loss/seq after 00650 batchs: 676.8374633789062
INFO:root:Train (Epoch 120): Loss/seq after 00700 batchs: 651.7499389648438
INFO:root:Train (Epoch 120): Loss/seq after 00750 batchs: 658.6234741210938
INFO:root:Train (Epoch 120): Loss/seq after 00800 batchs: 661.73291015625
INFO:root:Train (Epoch 120): Loss/seq after 00850 batchs: 640.9473266601562
INFO:root:Train (Epoch 120): Loss/seq after 00900 batchs: 627.600830078125
INFO:root:Train (Epoch 120): Loss/seq after 00950 batchs: 625.6880493164062
INFO:root:Train (Epoch 120): Loss/seq after 01000 batchs: 616.2391357421875
INFO:root:Train (Epoch 120): Loss/seq after 01050 batchs: 605.651123046875
INFO:root:Train (Epoch 120): Loss/seq after 01100 batchs: 597.9279174804688
INFO:root:Train (Epoch 120): Loss/seq after 01150 batchs: 583.5588989257812
INFO:root:Train (Epoch 120): Loss/seq after 01200 batchs: 588.4348754882812
INFO:root:Train (Epoch 120): Loss/seq after 01250 batchs: 586.6987915039062
INFO:root:Train (Epoch 120): Loss/seq after 01300 batchs: 575.46240234375
INFO:root:Train (Epoch 120): Loss/seq after 01350 batchs: 566.5267944335938
INFO:root:Train (Epoch 120): Loss/seq after 01400 batchs: 571.8893432617188
INFO:root:Train (Epoch 120): Loss/seq after 01450 batchs: 574.05419921875
INFO:root:Train (Epoch 120): Loss/seq after 01500 batchs: 580.9532470703125
INFO:root:Train (Epoch 120): Loss/seq after 01550 batchs: 582.8370971679688
INFO:root:Train (Epoch 120): Loss/seq after 01600 batchs: 577.61083984375
INFO:root:Train (Epoch 120): Loss/seq after 01650 batchs: 576.016845703125
INFO:root:Train (Epoch 120): Loss/seq after 01700 batchs: 578.4342651367188
INFO:root:Train (Epoch 120): Loss/seq after 01750 batchs: 575.7806396484375
INFO:root:Train (Epoch 120): Loss/seq after 01800 batchs: 572.742919921875
INFO:root:Train (Epoch 120): Loss/seq after 01850 batchs: 569.0731201171875
INFO:root:Train (Epoch 120): Loss/seq after 01900 batchs: 568.973388671875
INFO:root:Train (Epoch 120): Loss/seq after 01950 batchs: 567.4734497070312
INFO:root:Train (Epoch 120): Loss/seq after 02000 batchs: 566.2991943359375
INFO:root:Train (Epoch 120): Loss/seq after 02050 batchs: 564.9698486328125
INFO:root:Train (Epoch 120): Loss/seq after 02100 batchs: 562.3185424804688
INFO:root:Train (Epoch 120): Loss/seq after 02150 batchs: 560.2242431640625
INFO:root:Train (Epoch 120): Loss/seq after 02200 batchs: 557.322509765625
INFO:root:Train (Epoch 120): Loss/seq after 02250 batchs: 555.6937866210938
INFO:root:Train (Epoch 120): Loss/seq after 02300 batchs: 552.595703125
INFO:root:Train (Epoch 120): Loss/seq after 02350 batchs: 548.4544067382812
INFO:root:Train (Epoch 120): Loss/seq after 02400 batchs: 549.5888061523438
INFO:root:Train (Epoch 120): Loss/seq after 02450 batchs: 545.0239868164062
INFO:root:Train (Epoch 120): Loss/seq after 02500 batchs: 537.0823974609375
INFO:root:Train (Epoch 120): Loss/seq after 02550 batchs: 531.4275512695312
INFO:root:Train (Epoch 120): Loss/seq after 02600 batchs: 530.7625122070312
INFO:root:Train (Epoch 120): Loss/seq after 02650 batchs: 528.3949584960938
INFO:root:Train (Epoch 120): Loss/seq after 02700 batchs: 526.3380737304688
INFO:root:Train (Epoch 120): Loss/seq after 02750 batchs: 524.7158203125
INFO:root:Train (Epoch 120): Loss/seq after 02800 batchs: 524.8743896484375
INFO:root:Train (Epoch 120): Loss/seq after 02850 batchs: 524.8424072265625
INFO:root:Train (Epoch 120): Loss/seq after 02900 batchs: 526.47802734375
INFO:root:Train (Epoch 120): Loss/seq after 02950 batchs: 525.7391357421875
INFO:root:Train (Epoch 120): Loss/seq after 03000 batchs: 530.9083251953125
INFO:root:Train (Epoch 120): Loss/seq after 03050 batchs: 532.9918212890625
INFO:root:Train (Epoch 120): Loss/seq after 03100 batchs: 536.4302368164062
INFO:root:Train (Epoch 120): Loss/seq after 03150 batchs: 539.3479614257812
INFO:root:Train (Epoch 120): Loss/seq after 03200 batchs: 540.2584838867188
INFO:root:Train (Epoch 120): Loss/seq after 03250 batchs: 542.7318115234375
INFO:root:Train (Epoch 120): Loss/seq after 03300 batchs: 541.8836669921875
INFO:root:Train (Epoch 120): Loss/seq after 03350 batchs: 541.8794555664062
INFO:root:Train (Epoch 120): Loss/seq after 03400 batchs: 537.7758178710938
INFO:root:Train (Epoch 120): Loss/seq after 03450 batchs: 536.5408935546875
INFO:root:Train (Epoch 120): Loss/seq after 03500 batchs: 537.1910400390625
INFO:root:Train (Epoch 120): Loss/seq after 03550 batchs: 534.7446899414062
INFO:root:Train (Epoch 120): Loss/seq after 03600 batchs: 542.481201171875
INFO:root:Train (Epoch 120): Loss/seq after 03650 batchs: 540.2272338867188
INFO:root:Train (Epoch 120): Loss/seq after 03700 batchs: 542.9375610351562
INFO:root:Train (Epoch 120): Loss/seq after 03750 batchs: 547.5614624023438
INFO:root:Train (Epoch 120): Loss/seq after 03800 batchs: 545.39111328125
INFO:root:Train (Epoch 120): Loss/seq after 03850 batchs: 544.1665649414062
INFO:root:Train (Epoch 120): Loss/seq after 03900 batchs: 547.6422119140625
INFO:root:Train (Epoch 120): Loss/seq after 03950 batchs: 551.1438598632812
INFO:root:Train (Epoch 120): Loss/seq after 04000 batchs: 547.3158569335938
INFO:root:Train (Epoch 120): Loss/seq after 04050 batchs: 543.8723754882812
INFO:root:Train (Epoch 120): Loss/seq after 04100 batchs: 542.2315673828125
INFO:root:Train (Epoch 120): Loss/seq after 04150 batchs: 542.0570678710938
INFO:root:Train (Epoch 120): Loss/seq after 04200 batchs: 540.634033203125
INFO:root:Train (Epoch 120): Loss/seq after 04250 batchs: 538.8169555664062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 120): Loss/seq after 00000 batches: 527.1964111328125
INFO:root:# Valid (Epoch 120): Loss/seq after 00050 batches: 662.529541015625
INFO:root:# Valid (Epoch 120): Loss/seq after 00100 batches: 697.6820068359375
INFO:root:# Valid (Epoch 120): Loss/seq after 00150 batches: 531.812744140625
INFO:root:# Valid (Epoch 120): Loss/seq after 00200 batches: 495.3864440917969
INFO:root:Artifacts: Make stick videos for epoch 120
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_120_on_20220413_051653.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_120_index_827_on_20220413_051653.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 121): Loss/seq after 00000 batchs: 992.173828125
INFO:root:Train (Epoch 121): Loss/seq after 00050 batchs: 768.282958984375
INFO:root:Train (Epoch 121): Loss/seq after 00100 batchs: 758.41064453125
INFO:root:Train (Epoch 121): Loss/seq after 00150 batchs: 687.8687744140625
INFO:root:Train (Epoch 121): Loss/seq after 00200 batchs: 745.2705078125
INFO:root:Train (Epoch 121): Loss/seq after 00250 batchs: 835.6782836914062
INFO:root:Train (Epoch 121): Loss/seq after 00300 batchs: 837.0004272460938
INFO:root:Train (Epoch 121): Loss/seq after 00350 batchs: 785.585205078125
INFO:root:Train (Epoch 121): Loss/seq after 00400 batchs: 781.8594970703125
INFO:root:Train (Epoch 121): Loss/seq after 00450 batchs: 768.21728515625
INFO:root:Train (Epoch 121): Loss/seq after 00500 batchs: 743.5562744140625
INFO:root:Train (Epoch 121): Loss/seq after 00550 batchs: 721.8316650390625
INFO:root:Train (Epoch 121): Loss/seq after 00600 batchs: 696.585693359375
INFO:root:Train (Epoch 121): Loss/seq after 00650 batchs: 673.5511474609375
INFO:root:Train (Epoch 121): Loss/seq after 00700 batchs: 648.1770629882812
INFO:root:Train (Epoch 121): Loss/seq after 00750 batchs: 653.9016723632812
INFO:root:Train (Epoch 121): Loss/seq after 00800 batchs: 657.1514282226562
INFO:root:Train (Epoch 121): Loss/seq after 00850 batchs: 636.5166015625
INFO:root:Train (Epoch 121): Loss/seq after 00900 batchs: 623.5166625976562
INFO:root:Train (Epoch 121): Loss/seq after 00950 batchs: 621.4757080078125
INFO:root:Train (Epoch 121): Loss/seq after 01000 batchs: 612.721435546875
INFO:root:Train (Epoch 121): Loss/seq after 01050 batchs: 602.6522827148438
INFO:root:Train (Epoch 121): Loss/seq after 01100 batchs: 594.8217163085938
INFO:root:Train (Epoch 121): Loss/seq after 01150 batchs: 580.3321533203125
INFO:root:Train (Epoch 121): Loss/seq after 01200 batchs: 585.1851196289062
INFO:root:Train (Epoch 121): Loss/seq after 01250 batchs: 583.8109741210938
INFO:root:Train (Epoch 121): Loss/seq after 01300 batchs: 572.8715209960938
INFO:root:Train (Epoch 121): Loss/seq after 01350 batchs: 563.7098999023438
INFO:root:Train (Epoch 121): Loss/seq after 01400 batchs: 567.9690551757812
INFO:root:Train (Epoch 121): Loss/seq after 01450 batchs: 569.7803955078125
INFO:root:Train (Epoch 121): Loss/seq after 01500 batchs: 576.5015869140625
INFO:root:Train (Epoch 121): Loss/seq after 01550 batchs: 578.3208618164062
INFO:root:Train (Epoch 121): Loss/seq after 01600 batchs: 573.1829833984375
INFO:root:Train (Epoch 121): Loss/seq after 01650 batchs: 571.4785766601562
INFO:root:Train (Epoch 121): Loss/seq after 01700 batchs: 573.8845825195312
INFO:root:Train (Epoch 121): Loss/seq after 01750 batchs: 571.3399658203125
INFO:root:Train (Epoch 121): Loss/seq after 01800 batchs: 568.2222290039062
INFO:root:Train (Epoch 121): Loss/seq after 01850 batchs: 564.5820922851562
INFO:root:Train (Epoch 121): Loss/seq after 01900 batchs: 564.4707641601562
INFO:root:Train (Epoch 121): Loss/seq after 01950 batchs: 563.074462890625
INFO:root:Train (Epoch 121): Loss/seq after 02000 batchs: 561.9656982421875
INFO:root:Train (Epoch 121): Loss/seq after 02050 batchs: 560.686767578125
INFO:root:Train (Epoch 121): Loss/seq after 02100 batchs: 558.0730590820312
INFO:root:Train (Epoch 121): Loss/seq after 02150 batchs: 556.0868530273438
INFO:root:Train (Epoch 121): Loss/seq after 02200 batchs: 553.15185546875
INFO:root:Train (Epoch 121): Loss/seq after 02250 batchs: 551.7423095703125
INFO:root:Train (Epoch 121): Loss/seq after 02300 batchs: 548.7908935546875
INFO:root:Train (Epoch 121): Loss/seq after 02350 batchs: 544.6041259765625
INFO:root:Train (Epoch 121): Loss/seq after 02400 batchs: 545.7855224609375
INFO:root:Train (Epoch 121): Loss/seq after 02450 batchs: 541.2527465820312
INFO:root:Train (Epoch 121): Loss/seq after 02500 batchs: 533.3667602539062
INFO:root:Train (Epoch 121): Loss/seq after 02550 batchs: 527.786376953125
INFO:root:Train (Epoch 121): Loss/seq after 02600 batchs: 526.9263305664062
INFO:root:Train (Epoch 121): Loss/seq after 02650 batchs: 524.5453491210938
INFO:root:Train (Epoch 121): Loss/seq after 02700 batchs: 522.4979248046875
INFO:root:Train (Epoch 121): Loss/seq after 02750 batchs: 520.7335205078125
INFO:root:Train (Epoch 121): Loss/seq after 02800 batchs: 520.5723876953125
INFO:root:Train (Epoch 121): Loss/seq after 02850 batchs: 520.4859619140625
INFO:root:Train (Epoch 121): Loss/seq after 02900 batchs: 522.0099487304688
INFO:root:Train (Epoch 121): Loss/seq after 02950 batchs: 521.176513671875
INFO:root:Train (Epoch 121): Loss/seq after 03000 batchs: 526.423095703125
INFO:root:Train (Epoch 121): Loss/seq after 03050 batchs: 528.3031005859375
INFO:root:Train (Epoch 121): Loss/seq after 03100 batchs: 531.6468505859375
INFO:root:Train (Epoch 121): Loss/seq after 03150 batchs: 534.52685546875
INFO:root:Train (Epoch 121): Loss/seq after 03200 batchs: 535.2543334960938
INFO:root:Train (Epoch 121): Loss/seq after 03250 batchs: 537.7947998046875
INFO:root:Train (Epoch 121): Loss/seq after 03300 batchs: 536.7775268554688
INFO:root:Train (Epoch 121): Loss/seq after 03350 batchs: 536.687744140625
INFO:root:Train (Epoch 121): Loss/seq after 03400 batchs: 532.3535766601562
INFO:root:Train (Epoch 121): Loss/seq after 03450 batchs: 531.0293579101562
INFO:root:Train (Epoch 121): Loss/seq after 03500 batchs: 531.7188720703125
INFO:root:Train (Epoch 121): Loss/seq after 03550 batchs: 529.0108032226562
INFO:root:Train (Epoch 121): Loss/seq after 03600 batchs: 536.338134765625
INFO:root:Train (Epoch 121): Loss/seq after 03650 batchs: 533.97998046875
INFO:root:Train (Epoch 121): Loss/seq after 03700 batchs: 536.5651245117188
INFO:root:Train (Epoch 121): Loss/seq after 03750 batchs: 541.1043090820312
INFO:root:Train (Epoch 121): Loss/seq after 03800 batchs: 539.0613403320312
INFO:root:Train (Epoch 121): Loss/seq after 03850 batchs: 537.893310546875
INFO:root:Train (Epoch 121): Loss/seq after 03900 batchs: 541.1074829101562
INFO:root:Train (Epoch 121): Loss/seq after 03950 batchs: 544.4786987304688
INFO:root:Train (Epoch 121): Loss/seq after 04000 batchs: 540.686767578125
INFO:root:Train (Epoch 121): Loss/seq after 04050 batchs: 537.2925415039062
INFO:root:Train (Epoch 121): Loss/seq after 04100 batchs: 535.7064208984375
INFO:root:Train (Epoch 121): Loss/seq after 04150 batchs: 535.6258544921875
INFO:root:Train (Epoch 121): Loss/seq after 04200 batchs: 534.1812744140625
INFO:root:Train (Epoch 121): Loss/seq after 04250 batchs: 532.4406127929688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 121): Loss/seq after 00000 batches: 496.84814453125
INFO:root:# Valid (Epoch 121): Loss/seq after 00050 batches: 645.8580322265625
INFO:root:# Valid (Epoch 121): Loss/seq after 00100 batches: 686.1442260742188
INFO:root:# Valid (Epoch 121): Loss/seq after 00150 batches: 523.2430419921875
INFO:root:# Valid (Epoch 121): Loss/seq after 00200 batches: 486.6811828613281
INFO:root:Artifacts: Make stick videos for epoch 121
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_121_on_20220413_052215.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_121_index_1312_on_20220413_052215.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 122): Loss/seq after 00000 batchs: 906.2771606445312
INFO:root:Train (Epoch 122): Loss/seq after 00050 batchs: 762.7691040039062
INFO:root:Train (Epoch 122): Loss/seq after 00100 batchs: 748.360107421875
INFO:root:Train (Epoch 122): Loss/seq after 00150 batchs: 680.604248046875
INFO:root:Train (Epoch 122): Loss/seq after 00200 batchs: 742.6083374023438
INFO:root:Train (Epoch 122): Loss/seq after 00250 batchs: 836.5303955078125
INFO:root:Train (Epoch 122): Loss/seq after 00300 batchs: 838.1509399414062
INFO:root:Train (Epoch 122): Loss/seq after 00350 batchs: 785.5238647460938
INFO:root:Train (Epoch 122): Loss/seq after 00400 batchs: 782.498779296875
INFO:root:Train (Epoch 122): Loss/seq after 00450 batchs: 768.8528442382812
INFO:root:Train (Epoch 122): Loss/seq after 00500 batchs: 744.025390625
INFO:root:Train (Epoch 122): Loss/seq after 00550 batchs: 722.1934814453125
INFO:root:Train (Epoch 122): Loss/seq after 00600 batchs: 696.2769165039062
INFO:root:Train (Epoch 122): Loss/seq after 00650 batchs: 672.4566040039062
INFO:root:Train (Epoch 122): Loss/seq after 00700 batchs: 647.0209350585938
INFO:root:Train (Epoch 122): Loss/seq after 00750 batchs: 651.8991088867188
INFO:root:Train (Epoch 122): Loss/seq after 00800 batchs: 656.4446411132812
INFO:root:Train (Epoch 122): Loss/seq after 00850 batchs: 636.2409057617188
INFO:root:Train (Epoch 122): Loss/seq after 00900 batchs: 623.8982543945312
INFO:root:Train (Epoch 122): Loss/seq after 00950 batchs: 622.2094116210938
INFO:root:Train (Epoch 122): Loss/seq after 01000 batchs: 613.1047973632812
INFO:root:Train (Epoch 122): Loss/seq after 01050 batchs: 602.7473754882812
INFO:root:Train (Epoch 122): Loss/seq after 01100 batchs: 594.8478393554688
INFO:root:Train (Epoch 122): Loss/seq after 01150 batchs: 580.1532592773438
INFO:root:Train (Epoch 122): Loss/seq after 01200 batchs: 584.7401733398438
INFO:root:Train (Epoch 122): Loss/seq after 01250 batchs: 583.2146606445312
INFO:root:Train (Epoch 122): Loss/seq after 01300 batchs: 571.8074340820312
INFO:root:Train (Epoch 122): Loss/seq after 01350 batchs: 562.6220092773438
INFO:root:Train (Epoch 122): Loss/seq after 01400 batchs: 566.8056030273438
INFO:root:Train (Epoch 122): Loss/seq after 01450 batchs: 568.9671630859375
INFO:root:Train (Epoch 122): Loss/seq after 01500 batchs: 575.8880615234375
INFO:root:Train (Epoch 122): Loss/seq after 01550 batchs: 577.5036010742188
INFO:root:Train (Epoch 122): Loss/seq after 01600 batchs: 572.1795043945312
INFO:root:Train (Epoch 122): Loss/seq after 01650 batchs: 570.3594360351562
INFO:root:Train (Epoch 122): Loss/seq after 01700 batchs: 573.2305297851562
INFO:root:Train (Epoch 122): Loss/seq after 01750 batchs: 570.5245361328125
INFO:root:Train (Epoch 122): Loss/seq after 01800 batchs: 567.4371337890625
INFO:root:Train (Epoch 122): Loss/seq after 01850 batchs: 563.7034912109375
INFO:root:Train (Epoch 122): Loss/seq after 01900 batchs: 563.7857666015625
INFO:root:Train (Epoch 122): Loss/seq after 01950 batchs: 562.0247192382812
INFO:root:Train (Epoch 122): Loss/seq after 02000 batchs: 560.8218383789062
INFO:root:Train (Epoch 122): Loss/seq after 02050 batchs: 559.4693603515625
INFO:root:Train (Epoch 122): Loss/seq after 02100 batchs: 556.8701171875
INFO:root:Train (Epoch 122): Loss/seq after 02150 batchs: 554.859130859375
INFO:root:Train (Epoch 122): Loss/seq after 02200 batchs: 552.0160522460938
INFO:root:Train (Epoch 122): Loss/seq after 02250 batchs: 550.3974609375
INFO:root:Train (Epoch 122): Loss/seq after 02300 batchs: 547.2758178710938
INFO:root:Train (Epoch 122): Loss/seq after 02350 batchs: 543.2002563476562
INFO:root:Train (Epoch 122): Loss/seq after 02400 batchs: 544.2705688476562
INFO:root:Train (Epoch 122): Loss/seq after 02450 batchs: 539.7703857421875
INFO:root:Train (Epoch 122): Loss/seq after 02500 batchs: 531.8894653320312
INFO:root:Train (Epoch 122): Loss/seq after 02550 batchs: 526.341796875
INFO:root:Train (Epoch 122): Loss/seq after 02600 batchs: 525.5723266601562
INFO:root:Train (Epoch 122): Loss/seq after 02650 batchs: 523.0780029296875
INFO:root:Train (Epoch 122): Loss/seq after 02700 batchs: 521.0634765625
INFO:root:Train (Epoch 122): Loss/seq after 02750 batchs: 519.3569946289062
INFO:root:Train (Epoch 122): Loss/seq after 02800 batchs: 519.2872924804688
INFO:root:Train (Epoch 122): Loss/seq after 02850 batchs: 519.1572875976562
INFO:root:Train (Epoch 122): Loss/seq after 02900 batchs: 520.7818603515625
INFO:root:Train (Epoch 122): Loss/seq after 02950 batchs: 519.889892578125
INFO:root:Train (Epoch 122): Loss/seq after 03000 batchs: 525.0435180664062
INFO:root:Train (Epoch 122): Loss/seq after 03050 batchs: 526.9573974609375
INFO:root:Train (Epoch 122): Loss/seq after 03100 batchs: 530.1445922851562
INFO:root:Train (Epoch 122): Loss/seq after 03150 batchs: 532.7007446289062
INFO:root:Train (Epoch 122): Loss/seq after 03200 batchs: 533.7872314453125
INFO:root:Train (Epoch 122): Loss/seq after 03250 batchs: 536.545654296875
INFO:root:Train (Epoch 122): Loss/seq after 03300 batchs: 535.5870971679688
INFO:root:Train (Epoch 122): Loss/seq after 03350 batchs: 535.4212036132812
INFO:root:Train (Epoch 122): Loss/seq after 03400 batchs: 531.151123046875
INFO:root:Train (Epoch 122): Loss/seq after 03450 batchs: 529.8947143554688
INFO:root:Train (Epoch 122): Loss/seq after 03500 batchs: 530.7244262695312
INFO:root:Train (Epoch 122): Loss/seq after 03550 batchs: 528.2169799804688
INFO:root:Train (Epoch 122): Loss/seq after 03600 batchs: 535.80322265625
INFO:root:Train (Epoch 122): Loss/seq after 03650 batchs: 533.5006103515625
INFO:root:Train (Epoch 122): Loss/seq after 03700 batchs: 535.8628540039062
INFO:root:Train (Epoch 122): Loss/seq after 03750 batchs: 540.3016967773438
INFO:root:Train (Epoch 122): Loss/seq after 03800 batchs: 538.1639404296875
INFO:root:Train (Epoch 122): Loss/seq after 03850 batchs: 536.93505859375
INFO:root:Train (Epoch 122): Loss/seq after 03900 batchs: 540.277099609375
INFO:root:Train (Epoch 122): Loss/seq after 03950 batchs: 543.6605834960938
INFO:root:Train (Epoch 122): Loss/seq after 04000 batchs: 539.8764038085938
INFO:root:Train (Epoch 122): Loss/seq after 04050 batchs: 536.4629516601562
INFO:root:Train (Epoch 122): Loss/seq after 04100 batchs: 534.9103393554688
INFO:root:Train (Epoch 122): Loss/seq after 04150 batchs: 534.7758178710938
INFO:root:Train (Epoch 122): Loss/seq after 04200 batchs: 533.403564453125
INFO:root:Train (Epoch 122): Loss/seq after 04250 batchs: 531.5789794921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 122): Loss/seq after 00000 batches: 503.4864501953125
INFO:root:# Valid (Epoch 122): Loss/seq after 00050 batches: 639.8284912109375
INFO:root:# Valid (Epoch 122): Loss/seq after 00100 batches: 687.4675903320312
INFO:root:# Valid (Epoch 122): Loss/seq after 00150 batches: 522.4917602539062
INFO:root:# Valid (Epoch 122): Loss/seq after 00200 batches: 488.34222412109375
INFO:root:Artifacts: Make stick videos for epoch 122
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_122_on_20220413_052738.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_122_index_1747_on_20220413_052738.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 123): Loss/seq after 00000 batchs: 890.0928955078125
INFO:root:Train (Epoch 123): Loss/seq after 00050 batchs: 766.2907104492188
INFO:root:Train (Epoch 123): Loss/seq after 00100 batchs: 752.6921997070312
INFO:root:Train (Epoch 123): Loss/seq after 00150 batchs: 680.4957275390625
INFO:root:Train (Epoch 123): Loss/seq after 00200 batchs: 739.8391723632812
INFO:root:Train (Epoch 123): Loss/seq after 00250 batchs: 820.9434814453125
INFO:root:Train (Epoch 123): Loss/seq after 00300 batchs: 823.7162475585938
INFO:root:Train (Epoch 123): Loss/seq after 00350 batchs: 772.7822875976562
INFO:root:Train (Epoch 123): Loss/seq after 00400 batchs: 769.2081298828125
INFO:root:Train (Epoch 123): Loss/seq after 00450 batchs: 756.7546997070312
INFO:root:Train (Epoch 123): Loss/seq after 00500 batchs: 735.2271118164062
INFO:root:Train (Epoch 123): Loss/seq after 00550 batchs: 713.8428955078125
INFO:root:Train (Epoch 123): Loss/seq after 00600 batchs: 688.709228515625
INFO:root:Train (Epoch 123): Loss/seq after 00650 batchs: 666.908203125
INFO:root:Train (Epoch 123): Loss/seq after 00700 batchs: 641.8086547851562
INFO:root:Train (Epoch 123): Loss/seq after 00750 batchs: 647.9107055664062
INFO:root:Train (Epoch 123): Loss/seq after 00800 batchs: 651.8150024414062
INFO:root:Train (Epoch 123): Loss/seq after 00850 batchs: 630.8497314453125
INFO:root:Train (Epoch 123): Loss/seq after 00900 batchs: 617.67919921875
INFO:root:Train (Epoch 123): Loss/seq after 00950 batchs: 615.9085693359375
INFO:root:Train (Epoch 123): Loss/seq after 01000 batchs: 606.75244140625
INFO:root:Train (Epoch 123): Loss/seq after 01050 batchs: 596.9716186523438
INFO:root:Train (Epoch 123): Loss/seq after 01100 batchs: 589.9520263671875
INFO:root:Train (Epoch 123): Loss/seq after 01150 batchs: 575.6683959960938
INFO:root:Train (Epoch 123): Loss/seq after 01200 batchs: 580.1166381835938
INFO:root:Train (Epoch 123): Loss/seq after 01250 batchs: 579.065673828125
INFO:root:Train (Epoch 123): Loss/seq after 01300 batchs: 567.5903930664062
INFO:root:Train (Epoch 123): Loss/seq after 01350 batchs: 558.9092407226562
INFO:root:Train (Epoch 123): Loss/seq after 01400 batchs: 562.7007446289062
INFO:root:Train (Epoch 123): Loss/seq after 01450 batchs: 564.3247680664062
INFO:root:Train (Epoch 123): Loss/seq after 01500 batchs: 571.375
INFO:root:Train (Epoch 123): Loss/seq after 01550 batchs: 573.3692016601562
INFO:root:Train (Epoch 123): Loss/seq after 01600 batchs: 568.407958984375
INFO:root:Train (Epoch 123): Loss/seq after 01650 batchs: 566.8262939453125
INFO:root:Train (Epoch 123): Loss/seq after 01700 batchs: 569.676513671875
INFO:root:Train (Epoch 123): Loss/seq after 01750 batchs: 567.0062255859375
INFO:root:Train (Epoch 123): Loss/seq after 01800 batchs: 563.881591796875
INFO:root:Train (Epoch 123): Loss/seq after 01850 batchs: 560.1854248046875
INFO:root:Train (Epoch 123): Loss/seq after 01900 batchs: 559.977783203125
INFO:root:Train (Epoch 123): Loss/seq after 01950 batchs: 558.2827758789062
INFO:root:Train (Epoch 123): Loss/seq after 02000 batchs: 557.2279663085938
INFO:root:Train (Epoch 123): Loss/seq after 02050 batchs: 556.0748901367188
INFO:root:Train (Epoch 123): Loss/seq after 02100 batchs: 553.433349609375
INFO:root:Train (Epoch 123): Loss/seq after 02150 batchs: 551.365478515625
INFO:root:Train (Epoch 123): Loss/seq after 02200 batchs: 548.4610595703125
INFO:root:Train (Epoch 123): Loss/seq after 02250 batchs: 546.7862548828125
INFO:root:Train (Epoch 123): Loss/seq after 02300 batchs: 543.9224853515625
INFO:root:Train (Epoch 123): Loss/seq after 02350 batchs: 539.8026123046875
INFO:root:Train (Epoch 123): Loss/seq after 02400 batchs: 540.7490844726562
INFO:root:Train (Epoch 123): Loss/seq after 02450 batchs: 536.2733764648438
INFO:root:Train (Epoch 123): Loss/seq after 02500 batchs: 528.4530029296875
INFO:root:Train (Epoch 123): Loss/seq after 02550 batchs: 522.7955932617188
INFO:root:Train (Epoch 123): Loss/seq after 02600 batchs: 522.0150146484375
INFO:root:Train (Epoch 123): Loss/seq after 02650 batchs: 519.4566040039062
INFO:root:Train (Epoch 123): Loss/seq after 02700 batchs: 517.3233642578125
INFO:root:Train (Epoch 123): Loss/seq after 02750 batchs: 515.3580932617188
INFO:root:Train (Epoch 123): Loss/seq after 02800 batchs: 515.2902221679688
INFO:root:Train (Epoch 123): Loss/seq after 02850 batchs: 515.2777099609375
INFO:root:Train (Epoch 123): Loss/seq after 02900 batchs: 517.0336303710938
INFO:root:Train (Epoch 123): Loss/seq after 02950 batchs: 516.2333984375
INFO:root:Train (Epoch 123): Loss/seq after 03000 batchs: 521.3865966796875
INFO:root:Train (Epoch 123): Loss/seq after 03050 batchs: 523.3893432617188
INFO:root:Train (Epoch 123): Loss/seq after 03100 batchs: 526.54931640625
INFO:root:Train (Epoch 123): Loss/seq after 03150 batchs: 528.9559936523438
INFO:root:Train (Epoch 123): Loss/seq after 03200 batchs: 529.9256591796875
INFO:root:Train (Epoch 123): Loss/seq after 03250 batchs: 532.4814453125
INFO:root:Train (Epoch 123): Loss/seq after 03300 batchs: 531.36328125
INFO:root:Train (Epoch 123): Loss/seq after 03350 batchs: 530.9547729492188
INFO:root:Train (Epoch 123): Loss/seq after 03400 batchs: 526.7868041992188
INFO:root:Train (Epoch 123): Loss/seq after 03450 batchs: 525.46142578125
INFO:root:Train (Epoch 123): Loss/seq after 03500 batchs: 526.09375
INFO:root:Train (Epoch 123): Loss/seq after 03550 batchs: 523.4447021484375
INFO:root:Train (Epoch 123): Loss/seq after 03600 batchs: 531.0713500976562
INFO:root:Train (Epoch 123): Loss/seq after 03650 batchs: 528.7062377929688
INFO:root:Train (Epoch 123): Loss/seq after 03700 batchs: 531.2680053710938
INFO:root:Train (Epoch 123): Loss/seq after 03750 batchs: 535.8392333984375
INFO:root:Train (Epoch 123): Loss/seq after 03800 batchs: 533.7935791015625
INFO:root:Train (Epoch 123): Loss/seq after 03850 batchs: 532.640380859375
INFO:root:Train (Epoch 123): Loss/seq after 03900 batchs: 535.8687133789062
INFO:root:Train (Epoch 123): Loss/seq after 03950 batchs: 539.1337280273438
INFO:root:Train (Epoch 123): Loss/seq after 04000 batchs: 535.3779296875
INFO:root:Train (Epoch 123): Loss/seq after 04050 batchs: 531.96142578125
INFO:root:Train (Epoch 123): Loss/seq after 04100 batchs: 530.4243774414062
INFO:root:Train (Epoch 123): Loss/seq after 04150 batchs: 530.3206787109375
INFO:root:Train (Epoch 123): Loss/seq after 04200 batchs: 529.0006713867188
INFO:root:Train (Epoch 123): Loss/seq after 04250 batchs: 527.2755126953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 123): Loss/seq after 00000 batches: 520.84130859375
INFO:root:# Valid (Epoch 123): Loss/seq after 00050 batches: 629.74951171875
INFO:root:# Valid (Epoch 123): Loss/seq after 00100 batches: 673.1232299804688
INFO:root:# Valid (Epoch 123): Loss/seq after 00150 batches: 516.0197143554688
INFO:root:# Valid (Epoch 123): Loss/seq after 00200 batches: 485.3652038574219
INFO:root:Artifacts: Make stick videos for epoch 123
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_123_on_20220413_053302.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_123_index_1177_on_20220413_053302.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 124): Loss/seq after 00000 batchs: 995.1102294921875
INFO:root:Train (Epoch 124): Loss/seq after 00050 batchs: 753.9085083007812
INFO:root:Train (Epoch 124): Loss/seq after 00100 batchs: 744.3495483398438
INFO:root:Train (Epoch 124): Loss/seq after 00150 batchs: 676.1616821289062
INFO:root:Train (Epoch 124): Loss/seq after 00200 batchs: 729.7564086914062
INFO:root:Train (Epoch 124): Loss/seq after 00250 batchs: 816.5510864257812
INFO:root:Train (Epoch 124): Loss/seq after 00300 batchs: 820.279296875
INFO:root:Train (Epoch 124): Loss/seq after 00350 batchs: 769.87890625
INFO:root:Train (Epoch 124): Loss/seq after 00400 batchs: 768.19384765625
INFO:root:Train (Epoch 124): Loss/seq after 00450 batchs: 756.2146606445312
INFO:root:Train (Epoch 124): Loss/seq after 00500 batchs: 734.502685546875
INFO:root:Train (Epoch 124): Loss/seq after 00550 batchs: 714.4696044921875
INFO:root:Train (Epoch 124): Loss/seq after 00600 batchs: 689.2296752929688
INFO:root:Train (Epoch 124): Loss/seq after 00650 batchs: 666.4360961914062
INFO:root:Train (Epoch 124): Loss/seq after 00700 batchs: 642.0914306640625
INFO:root:Train (Epoch 124): Loss/seq after 00750 batchs: 648.9930419921875
INFO:root:Train (Epoch 124): Loss/seq after 00800 batchs: 652.9452514648438
INFO:root:Train (Epoch 124): Loss/seq after 00850 batchs: 631.9970703125
INFO:root:Train (Epoch 124): Loss/seq after 00900 batchs: 619.3148193359375
INFO:root:Train (Epoch 124): Loss/seq after 00950 batchs: 616.8079833984375
INFO:root:Train (Epoch 124): Loss/seq after 01000 batchs: 609.0418701171875
INFO:root:Train (Epoch 124): Loss/seq after 01050 batchs: 598.331298828125
INFO:root:Train (Epoch 124): Loss/seq after 01100 batchs: 591.3347778320312
INFO:root:Train (Epoch 124): Loss/seq after 01150 batchs: 577.1431274414062
INFO:root:Train (Epoch 124): Loss/seq after 01200 batchs: 581.5750122070312
INFO:root:Train (Epoch 124): Loss/seq after 01250 batchs: 580.1668701171875
INFO:root:Train (Epoch 124): Loss/seq after 01300 batchs: 568.7910766601562
INFO:root:Train (Epoch 124): Loss/seq after 01350 batchs: 559.7804565429688
INFO:root:Train (Epoch 124): Loss/seq after 01400 batchs: 564.198486328125
INFO:root:Train (Epoch 124): Loss/seq after 01450 batchs: 566.0886840820312
INFO:root:Train (Epoch 124): Loss/seq after 01500 batchs: 572.781494140625
INFO:root:Train (Epoch 124): Loss/seq after 01550 batchs: 574.109619140625
INFO:root:Train (Epoch 124): Loss/seq after 01600 batchs: 568.7627563476562
INFO:root:Train (Epoch 124): Loss/seq after 01650 batchs: 567.1056518554688
INFO:root:Train (Epoch 124): Loss/seq after 01700 batchs: 569.9843139648438
INFO:root:Train (Epoch 124): Loss/seq after 01750 batchs: 567.3549194335938
INFO:root:Train (Epoch 124): Loss/seq after 01800 batchs: 564.122802734375
INFO:root:Train (Epoch 124): Loss/seq after 01850 batchs: 560.3402709960938
INFO:root:Train (Epoch 124): Loss/seq after 01900 batchs: 560.2487182617188
INFO:root:Train (Epoch 124): Loss/seq after 01950 batchs: 558.4547119140625
INFO:root:Train (Epoch 124): Loss/seq after 02000 batchs: 557.186279296875
INFO:root:Train (Epoch 124): Loss/seq after 02050 batchs: 555.9852905273438
INFO:root:Train (Epoch 124): Loss/seq after 02100 batchs: 553.5064086914062
INFO:root:Train (Epoch 124): Loss/seq after 02150 batchs: 551.3265991210938
INFO:root:Train (Epoch 124): Loss/seq after 02200 batchs: 548.4161376953125
INFO:root:Train (Epoch 124): Loss/seq after 02250 batchs: 546.7077026367188
INFO:root:Train (Epoch 124): Loss/seq after 02300 batchs: 543.7540283203125
INFO:root:Train (Epoch 124): Loss/seq after 02350 batchs: 539.7354125976562
INFO:root:Train (Epoch 124): Loss/seq after 02400 batchs: 540.7598266601562
INFO:root:Train (Epoch 124): Loss/seq after 02450 batchs: 536.2669677734375
INFO:root:Train (Epoch 124): Loss/seq after 02500 batchs: 528.4476318359375
INFO:root:Train (Epoch 124): Loss/seq after 02550 batchs: 522.7094116210938
INFO:root:Train (Epoch 124): Loss/seq after 02600 batchs: 521.667236328125
INFO:root:Train (Epoch 124): Loss/seq after 02650 batchs: 518.9393310546875
INFO:root:Train (Epoch 124): Loss/seq after 02700 batchs: 516.7435913085938
INFO:root:Train (Epoch 124): Loss/seq after 02750 batchs: 514.8051147460938
INFO:root:Train (Epoch 124): Loss/seq after 02800 batchs: 515.0140380859375
INFO:root:Train (Epoch 124): Loss/seq after 02850 batchs: 514.884765625
INFO:root:Train (Epoch 124): Loss/seq after 02900 batchs: 516.3468017578125
INFO:root:Train (Epoch 124): Loss/seq after 02950 batchs: 515.5226440429688
INFO:root:Train (Epoch 124): Loss/seq after 03000 batchs: 520.7855834960938
INFO:root:Train (Epoch 124): Loss/seq after 03050 batchs: 522.6481323242188
INFO:root:Train (Epoch 124): Loss/seq after 03100 batchs: 525.7459106445312
INFO:root:Train (Epoch 124): Loss/seq after 03150 batchs: 528.9183959960938
INFO:root:Train (Epoch 124): Loss/seq after 03200 batchs: 529.67529296875
INFO:root:Train (Epoch 124): Loss/seq after 03250 batchs: 532.161376953125
INFO:root:Train (Epoch 124): Loss/seq after 03300 batchs: 531.3732299804688
INFO:root:Train (Epoch 124): Loss/seq after 03350 batchs: 531.4655151367188
INFO:root:Train (Epoch 124): Loss/seq after 03400 batchs: 527.27099609375
INFO:root:Train (Epoch 124): Loss/seq after 03450 batchs: 526.0989379882812
INFO:root:Train (Epoch 124): Loss/seq after 03500 batchs: 527.1536254882812
INFO:root:Train (Epoch 124): Loss/seq after 03550 batchs: 524.472900390625
INFO:root:Train (Epoch 124): Loss/seq after 03600 batchs: 531.9273071289062
INFO:root:Train (Epoch 124): Loss/seq after 03650 batchs: 529.5961303710938
INFO:root:Train (Epoch 124): Loss/seq after 03700 batchs: 532.0210571289062
INFO:root:Train (Epoch 124): Loss/seq after 03750 batchs: 536.4993286132812
INFO:root:Train (Epoch 124): Loss/seq after 03800 batchs: 534.362060546875
INFO:root:Train (Epoch 124): Loss/seq after 03850 batchs: 533.0568237304688
INFO:root:Train (Epoch 124): Loss/seq after 03900 batchs: 536.4448852539062
INFO:root:Train (Epoch 124): Loss/seq after 03950 batchs: 539.9874877929688
INFO:root:Train (Epoch 124): Loss/seq after 04000 batchs: 536.2486572265625
INFO:root:Train (Epoch 124): Loss/seq after 04050 batchs: 532.8533325195312
INFO:root:Train (Epoch 124): Loss/seq after 04100 batchs: 531.2691650390625
INFO:root:Train (Epoch 124): Loss/seq after 04150 batchs: 531.0933227539062
INFO:root:Train (Epoch 124): Loss/seq after 04200 batchs: 529.6361694335938
INFO:root:Train (Epoch 124): Loss/seq after 04250 batchs: 527.8778686523438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 124): Loss/seq after 00000 batches: 523.03125
INFO:root:# Valid (Epoch 124): Loss/seq after 00050 batches: 639.3746948242188
INFO:root:# Valid (Epoch 124): Loss/seq after 00100 batches: 677.3543090820312
INFO:root:# Valid (Epoch 124): Loss/seq after 00150 batches: 513.7323608398438
INFO:root:# Valid (Epoch 124): Loss/seq after 00200 batches: 477.96087646484375
INFO:root:Artifacts: Make stick videos for epoch 124
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_124_on_20220413_053825.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_124_index_1164_on_20220413_053825.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 125): Loss/seq after 00000 batchs: 1027.89892578125
INFO:root:Train (Epoch 125): Loss/seq after 00050 batchs: 753.466552734375
INFO:root:Train (Epoch 125): Loss/seq after 00100 batchs: 737.4088745117188
INFO:root:Train (Epoch 125): Loss/seq after 00150 batchs: 672.2516479492188
INFO:root:Train (Epoch 125): Loss/seq after 00200 batchs: 726.841552734375
INFO:root:Train (Epoch 125): Loss/seq after 00250 batchs: 810.4461669921875
INFO:root:Train (Epoch 125): Loss/seq after 00300 batchs: 814.6346435546875
INFO:root:Train (Epoch 125): Loss/seq after 00350 batchs: 765.1417236328125
INFO:root:Train (Epoch 125): Loss/seq after 00400 batchs: 763.6351318359375
INFO:root:Train (Epoch 125): Loss/seq after 00450 batchs: 751.361083984375
INFO:root:Train (Epoch 125): Loss/seq after 00500 batchs: 727.3036499023438
INFO:root:Train (Epoch 125): Loss/seq after 00550 batchs: 705.94677734375
INFO:root:Train (Epoch 125): Loss/seq after 00600 batchs: 681.04833984375
INFO:root:Train (Epoch 125): Loss/seq after 00650 batchs: 657.9463500976562
INFO:root:Train (Epoch 125): Loss/seq after 00700 batchs: 632.4622802734375
INFO:root:Train (Epoch 125): Loss/seq after 00750 batchs: 637.7001953125
INFO:root:Train (Epoch 125): Loss/seq after 00800 batchs: 641.4152221679688
INFO:root:Train (Epoch 125): Loss/seq after 00850 batchs: 620.7584838867188
INFO:root:Train (Epoch 125): Loss/seq after 00900 batchs: 607.9937744140625
INFO:root:Train (Epoch 125): Loss/seq after 00950 batchs: 606.8110961914062
INFO:root:Train (Epoch 125): Loss/seq after 01000 batchs: 598.20703125
INFO:root:Train (Epoch 125): Loss/seq after 01050 batchs: 588.2280883789062
INFO:root:Train (Epoch 125): Loss/seq after 01100 batchs: 580.226806640625
INFO:root:Train (Epoch 125): Loss/seq after 01150 batchs: 565.9668579101562
INFO:root:Train (Epoch 125): Loss/seq after 01200 batchs: 570.9886474609375
INFO:root:Train (Epoch 125): Loss/seq after 01250 batchs: 569.834228515625
INFO:root:Train (Epoch 125): Loss/seq after 01300 batchs: 558.68994140625
INFO:root:Train (Epoch 125): Loss/seq after 01350 batchs: 550.194091796875
INFO:root:Train (Epoch 125): Loss/seq after 01400 batchs: 554.1315307617188
INFO:root:Train (Epoch 125): Loss/seq after 01450 batchs: 555.8567504882812
INFO:root:Train (Epoch 125): Loss/seq after 01500 batchs: 562.7057495117188
INFO:root:Train (Epoch 125): Loss/seq after 01550 batchs: 564.438720703125
INFO:root:Train (Epoch 125): Loss/seq after 01600 batchs: 559.9470825195312
INFO:root:Train (Epoch 125): Loss/seq after 01650 batchs: 558.7870483398438
INFO:root:Train (Epoch 125): Loss/seq after 01700 batchs: 562.01220703125
INFO:root:Train (Epoch 125): Loss/seq after 01750 batchs: 559.3603515625
INFO:root:Train (Epoch 125): Loss/seq after 01800 batchs: 556.2474975585938
INFO:root:Train (Epoch 125): Loss/seq after 01850 batchs: 552.5989990234375
INFO:root:Train (Epoch 125): Loss/seq after 01900 batchs: 552.1716918945312
INFO:root:Train (Epoch 125): Loss/seq after 01950 batchs: 550.8084716796875
INFO:root:Train (Epoch 125): Loss/seq after 02000 batchs: 549.9212036132812
INFO:root:Train (Epoch 125): Loss/seq after 02050 batchs: 548.7454223632812
INFO:root:Train (Epoch 125): Loss/seq after 02100 batchs: 546.328857421875
INFO:root:Train (Epoch 125): Loss/seq after 02150 batchs: 544.433837890625
INFO:root:Train (Epoch 125): Loss/seq after 02200 batchs: 541.6558837890625
INFO:root:Train (Epoch 125): Loss/seq after 02250 batchs: 539.800048828125
INFO:root:Train (Epoch 125): Loss/seq after 02300 batchs: 536.501708984375
INFO:root:Train (Epoch 125): Loss/seq after 02350 batchs: 532.57470703125
INFO:root:Train (Epoch 125): Loss/seq after 02400 batchs: 533.3680419921875
INFO:root:Train (Epoch 125): Loss/seq after 02450 batchs: 529.0762329101562
INFO:root:Train (Epoch 125): Loss/seq after 02500 batchs: 521.432861328125
INFO:root:Train (Epoch 125): Loss/seq after 02550 batchs: 515.7928466796875
INFO:root:Train (Epoch 125): Loss/seq after 02600 batchs: 514.9299926757812
INFO:root:Train (Epoch 125): Loss/seq after 02650 batchs: 512.4306640625
INFO:root:Train (Epoch 125): Loss/seq after 02700 batchs: 510.4695129394531
INFO:root:Train (Epoch 125): Loss/seq after 02750 batchs: 508.20489501953125
INFO:root:Train (Epoch 125): Loss/seq after 02800 batchs: 507.90924072265625
INFO:root:Train (Epoch 125): Loss/seq after 02850 batchs: 507.9205627441406
INFO:root:Train (Epoch 125): Loss/seq after 02900 batchs: 509.536376953125
INFO:root:Train (Epoch 125): Loss/seq after 02950 batchs: 508.805908203125
INFO:root:Train (Epoch 125): Loss/seq after 03000 batchs: 514.0756225585938
INFO:root:Train (Epoch 125): Loss/seq after 03050 batchs: 516.0123291015625
INFO:root:Train (Epoch 125): Loss/seq after 03100 batchs: 518.83154296875
INFO:root:Train (Epoch 125): Loss/seq after 03150 batchs: 521.305908203125
INFO:root:Train (Epoch 125): Loss/seq after 03200 batchs: 522.1583251953125
INFO:root:Train (Epoch 125): Loss/seq after 03250 batchs: 524.1473388671875
INFO:root:Train (Epoch 125): Loss/seq after 03300 batchs: 523.2819213867188
INFO:root:Train (Epoch 125): Loss/seq after 03350 batchs: 523.1824951171875
INFO:root:Train (Epoch 125): Loss/seq after 03400 batchs: 518.9373168945312
INFO:root:Train (Epoch 125): Loss/seq after 03450 batchs: 517.7395629882812
INFO:root:Train (Epoch 125): Loss/seq after 03500 batchs: 518.5399780273438
INFO:root:Train (Epoch 125): Loss/seq after 03550 batchs: 515.8885498046875
INFO:root:Train (Epoch 125): Loss/seq after 03600 batchs: 523.5028686523438
INFO:root:Train (Epoch 125): Loss/seq after 03650 batchs: 521.2052001953125
INFO:root:Train (Epoch 125): Loss/seq after 03700 batchs: 523.7379760742188
INFO:root:Train (Epoch 125): Loss/seq after 03750 batchs: 528.1419677734375
INFO:root:Train (Epoch 125): Loss/seq after 03800 batchs: 526.1481323242188
INFO:root:Train (Epoch 125): Loss/seq after 03850 batchs: 524.9742431640625
INFO:root:Train (Epoch 125): Loss/seq after 03900 batchs: 528.2845458984375
INFO:root:Train (Epoch 125): Loss/seq after 03950 batchs: 531.5078125
INFO:root:Train (Epoch 125): Loss/seq after 04000 batchs: 527.8177490234375
INFO:root:Train (Epoch 125): Loss/seq after 04050 batchs: 524.4717407226562
INFO:root:Train (Epoch 125): Loss/seq after 04100 batchs: 522.9851684570312
INFO:root:Train (Epoch 125): Loss/seq after 04150 batchs: 522.876953125
INFO:root:Train (Epoch 125): Loss/seq after 04200 batchs: 521.4766235351562
INFO:root:Train (Epoch 125): Loss/seq after 04250 batchs: 519.7132568359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 125): Loss/seq after 00000 batches: 443.77130126953125
INFO:root:# Valid (Epoch 125): Loss/seq after 00050 batches: 597.9756469726562
INFO:root:# Valid (Epoch 125): Loss/seq after 00100 batches: 642.2521362304688
INFO:root:# Valid (Epoch 125): Loss/seq after 00150 batches: 489.86273193359375
INFO:root:# Valid (Epoch 125): Loss/seq after 00200 batches: 459.3748779296875
INFO:root:Artifacts: Make stick videos for epoch 125
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_125_on_20220413_054346.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_125_index_600_on_20220413_054346.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 126): Loss/seq after 00000 batchs: 890.435302734375
INFO:root:Train (Epoch 126): Loss/seq after 00050 batchs: 766.0668334960938
INFO:root:Train (Epoch 126): Loss/seq after 00100 batchs: 741.2490844726562
INFO:root:Train (Epoch 126): Loss/seq after 00150 batchs: 674.5059814453125
INFO:root:Train (Epoch 126): Loss/seq after 00200 batchs: 728.9727783203125
INFO:root:Train (Epoch 126): Loss/seq after 00250 batchs: 811.6866455078125
INFO:root:Train (Epoch 126): Loss/seq after 00300 batchs: 816.1976928710938
INFO:root:Train (Epoch 126): Loss/seq after 00350 batchs: 766.02734375
INFO:root:Train (Epoch 126): Loss/seq after 00400 batchs: 760.8785400390625
INFO:root:Train (Epoch 126): Loss/seq after 00450 batchs: 749.2106323242188
INFO:root:Train (Epoch 126): Loss/seq after 00500 batchs: 725.7674560546875
INFO:root:Train (Epoch 126): Loss/seq after 00550 batchs: 705.0028076171875
INFO:root:Train (Epoch 126): Loss/seq after 00600 batchs: 680.3806762695312
INFO:root:Train (Epoch 126): Loss/seq after 00650 batchs: 657.8832397460938
INFO:root:Train (Epoch 126): Loss/seq after 00700 batchs: 633.2213745117188
INFO:root:Train (Epoch 126): Loss/seq after 00750 batchs: 638.276123046875
INFO:root:Train (Epoch 126): Loss/seq after 00800 batchs: 642.1021728515625
INFO:root:Train (Epoch 126): Loss/seq after 00850 batchs: 621.1384887695312
INFO:root:Train (Epoch 126): Loss/seq after 00900 batchs: 608.255859375
INFO:root:Train (Epoch 126): Loss/seq after 00950 batchs: 606.8240966796875
INFO:root:Train (Epoch 126): Loss/seq after 01000 batchs: 597.4650268554688
INFO:root:Train (Epoch 126): Loss/seq after 01050 batchs: 588.0421142578125
INFO:root:Train (Epoch 126): Loss/seq after 01100 batchs: 581.2335205078125
INFO:root:Train (Epoch 126): Loss/seq after 01150 batchs: 566.880859375
INFO:root:Train (Epoch 126): Loss/seq after 01200 batchs: 572.2967529296875
INFO:root:Train (Epoch 126): Loss/seq after 01250 batchs: 570.9253540039062
INFO:root:Train (Epoch 126): Loss/seq after 01300 batchs: 559.951416015625
INFO:root:Train (Epoch 126): Loss/seq after 01350 batchs: 550.9948120117188
INFO:root:Train (Epoch 126): Loss/seq after 01400 batchs: 555.1950073242188
INFO:root:Train (Epoch 126): Loss/seq after 01450 batchs: 556.7086181640625
INFO:root:Train (Epoch 126): Loss/seq after 01500 batchs: 563.7422485351562
INFO:root:Train (Epoch 126): Loss/seq after 01550 batchs: 564.8504638671875
INFO:root:Train (Epoch 126): Loss/seq after 01600 batchs: 559.640380859375
INFO:root:Train (Epoch 126): Loss/seq after 01650 batchs: 557.9678344726562
INFO:root:Train (Epoch 126): Loss/seq after 01700 batchs: 560.9541015625
INFO:root:Train (Epoch 126): Loss/seq after 01750 batchs: 558.4295043945312
INFO:root:Train (Epoch 126): Loss/seq after 01800 batchs: 555.35205078125
INFO:root:Train (Epoch 126): Loss/seq after 01850 batchs: 551.6953735351562
INFO:root:Train (Epoch 126): Loss/seq after 01900 batchs: 551.61279296875
INFO:root:Train (Epoch 126): Loss/seq after 01950 batchs: 549.8125
INFO:root:Train (Epoch 126): Loss/seq after 02000 batchs: 548.79052734375
INFO:root:Train (Epoch 126): Loss/seq after 02050 batchs: 547.6015014648438
INFO:root:Train (Epoch 126): Loss/seq after 02100 batchs: 545.02001953125
INFO:root:Train (Epoch 126): Loss/seq after 02150 batchs: 543.038330078125
INFO:root:Train (Epoch 126): Loss/seq after 02200 batchs: 540.239990234375
INFO:root:Train (Epoch 126): Loss/seq after 02250 batchs: 538.6885375976562
INFO:root:Train (Epoch 126): Loss/seq after 02300 batchs: 535.50732421875
INFO:root:Train (Epoch 126): Loss/seq after 02350 batchs: 531.5445556640625
INFO:root:Train (Epoch 126): Loss/seq after 02400 batchs: 532.3130493164062
INFO:root:Train (Epoch 126): Loss/seq after 02450 batchs: 527.9306030273438
INFO:root:Train (Epoch 126): Loss/seq after 02500 batchs: 520.2135620117188
INFO:root:Train (Epoch 126): Loss/seq after 02550 batchs: 514.6116943359375
INFO:root:Train (Epoch 126): Loss/seq after 02600 batchs: 513.566162109375
INFO:root:Train (Epoch 126): Loss/seq after 02650 batchs: 510.94732666015625
INFO:root:Train (Epoch 126): Loss/seq after 02700 batchs: 508.7807922363281
INFO:root:Train (Epoch 126): Loss/seq after 02750 batchs: 506.43609619140625
INFO:root:Train (Epoch 126): Loss/seq after 02800 batchs: 505.97015380859375
INFO:root:Train (Epoch 126): Loss/seq after 02850 batchs: 505.7984924316406
INFO:root:Train (Epoch 126): Loss/seq after 02900 batchs: 507.3536071777344
INFO:root:Train (Epoch 126): Loss/seq after 02950 batchs: 506.5701599121094
INFO:root:Train (Epoch 126): Loss/seq after 03000 batchs: 511.7718505859375
INFO:root:Train (Epoch 126): Loss/seq after 03050 batchs: 513.7689819335938
INFO:root:Train (Epoch 126): Loss/seq after 03100 batchs: 516.7499389648438
INFO:root:Train (Epoch 126): Loss/seq after 03150 batchs: 519.3077392578125
INFO:root:Train (Epoch 126): Loss/seq after 03200 batchs: 520.1238403320312
INFO:root:Train (Epoch 126): Loss/seq after 03250 batchs: 522.5068969726562
INFO:root:Train (Epoch 126): Loss/seq after 03300 batchs: 521.3899536132812
INFO:root:Train (Epoch 126): Loss/seq after 03350 batchs: 521.1201171875
INFO:root:Train (Epoch 126): Loss/seq after 03400 batchs: 516.8992919921875
INFO:root:Train (Epoch 126): Loss/seq after 03450 batchs: 515.653076171875
INFO:root:Train (Epoch 126): Loss/seq after 03500 batchs: 516.248046875
INFO:root:Train (Epoch 126): Loss/seq after 03550 batchs: 513.5709838867188
INFO:root:Train (Epoch 126): Loss/seq after 03600 batchs: 521.0243530273438
INFO:root:Train (Epoch 126): Loss/seq after 03650 batchs: 518.7929077148438
INFO:root:Train (Epoch 126): Loss/seq after 03700 batchs: 521.2662963867188
INFO:root:Train (Epoch 126): Loss/seq after 03750 batchs: 525.6454467773438
INFO:root:Train (Epoch 126): Loss/seq after 03800 batchs: 523.6657104492188
INFO:root:Train (Epoch 126): Loss/seq after 03850 batchs: 522.5736694335938
INFO:root:Train (Epoch 126): Loss/seq after 03900 batchs: 525.9533081054688
INFO:root:Train (Epoch 126): Loss/seq after 03950 batchs: 529.4952392578125
INFO:root:Train (Epoch 126): Loss/seq after 04000 batchs: 525.8506469726562
INFO:root:Train (Epoch 126): Loss/seq after 04050 batchs: 522.532958984375
INFO:root:Train (Epoch 126): Loss/seq after 04100 batchs: 520.9962768554688
INFO:root:Train (Epoch 126): Loss/seq after 04150 batchs: 520.9140625
INFO:root:Train (Epoch 126): Loss/seq after 04200 batchs: 519.6319580078125
INFO:root:Train (Epoch 126): Loss/seq after 04250 batchs: 517.957275390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 126): Loss/seq after 00000 batches: 486.9114685058594
INFO:root:# Valid (Epoch 126): Loss/seq after 00050 batches: 614.6441650390625
INFO:root:# Valid (Epoch 126): Loss/seq after 00100 batches: 655.4103393554688
INFO:root:# Valid (Epoch 126): Loss/seq after 00150 batches: 498.53472900390625
INFO:root:# Valid (Epoch 126): Loss/seq after 00200 batches: 465.4679260253906
INFO:root:Artifacts: Make stick videos for epoch 126
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_126_on_20220413_054910.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_126_index_1772_on_20220413_054910.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 127): Loss/seq after 00000 batchs: 990.7598876953125
INFO:root:Train (Epoch 127): Loss/seq after 00050 batchs: 748.7448120117188
INFO:root:Train (Epoch 127): Loss/seq after 00100 batchs: 731.8643798828125
INFO:root:Train (Epoch 127): Loss/seq after 00150 batchs: 663.4998168945312
INFO:root:Train (Epoch 127): Loss/seq after 00200 batchs: 717.7688598632812
INFO:root:Train (Epoch 127): Loss/seq after 00250 batchs: 810.1038818359375
INFO:root:Train (Epoch 127): Loss/seq after 00300 batchs: 812.7574462890625
INFO:root:Train (Epoch 127): Loss/seq after 00350 batchs: 763.07861328125
INFO:root:Train (Epoch 127): Loss/seq after 00400 batchs: 760.4107055664062
INFO:root:Train (Epoch 127): Loss/seq after 00450 batchs: 748.7726440429688
INFO:root:Train (Epoch 127): Loss/seq after 00500 batchs: 725.9130859375
INFO:root:Train (Epoch 127): Loss/seq after 00550 batchs: 705.3140869140625
INFO:root:Train (Epoch 127): Loss/seq after 00600 batchs: 680.0025024414062
INFO:root:Train (Epoch 127): Loss/seq after 00650 batchs: 656.5863647460938
INFO:root:Train (Epoch 127): Loss/seq after 00700 batchs: 631.4754028320312
INFO:root:Train (Epoch 127): Loss/seq after 00750 batchs: 636.9688720703125
INFO:root:Train (Epoch 127): Loss/seq after 00800 batchs: 640.9230346679688
INFO:root:Train (Epoch 127): Loss/seq after 00850 batchs: 619.890869140625
INFO:root:Train (Epoch 127): Loss/seq after 00900 batchs: 607.452880859375
INFO:root:Train (Epoch 127): Loss/seq after 00950 batchs: 605.3338012695312
INFO:root:Train (Epoch 127): Loss/seq after 01000 batchs: 596.1201171875
INFO:root:Train (Epoch 127): Loss/seq after 01050 batchs: 585.616455078125
INFO:root:Train (Epoch 127): Loss/seq after 01100 batchs: 578.3005981445312
INFO:root:Train (Epoch 127): Loss/seq after 01150 batchs: 564.1634521484375
INFO:root:Train (Epoch 127): Loss/seq after 01200 batchs: 569.0507202148438
INFO:root:Train (Epoch 127): Loss/seq after 01250 batchs: 567.5068359375
INFO:root:Train (Epoch 127): Loss/seq after 01300 batchs: 556.515869140625
INFO:root:Train (Epoch 127): Loss/seq after 01350 batchs: 547.7554321289062
INFO:root:Train (Epoch 127): Loss/seq after 01400 batchs: 552.4515991210938
INFO:root:Train (Epoch 127): Loss/seq after 01450 batchs: 554.2684936523438
INFO:root:Train (Epoch 127): Loss/seq after 01500 batchs: 561.2344360351562
INFO:root:Train (Epoch 127): Loss/seq after 01550 batchs: 562.0360717773438
INFO:root:Train (Epoch 127): Loss/seq after 01600 batchs: 556.9332885742188
INFO:root:Train (Epoch 127): Loss/seq after 01650 batchs: 555.3617553710938
INFO:root:Train (Epoch 127): Loss/seq after 01700 batchs: 558.2714233398438
INFO:root:Train (Epoch 127): Loss/seq after 01750 batchs: 555.6143798828125
INFO:root:Train (Epoch 127): Loss/seq after 01800 batchs: 552.5382690429688
INFO:root:Train (Epoch 127): Loss/seq after 01850 batchs: 548.939453125
INFO:root:Train (Epoch 127): Loss/seq after 01900 batchs: 548.6673583984375
INFO:root:Train (Epoch 127): Loss/seq after 01950 batchs: 547.0301513671875
INFO:root:Train (Epoch 127): Loss/seq after 02000 batchs: 546.0435791015625
INFO:root:Train (Epoch 127): Loss/seq after 02050 batchs: 544.9532470703125
INFO:root:Train (Epoch 127): Loss/seq after 02100 batchs: 542.4263305664062
INFO:root:Train (Epoch 127): Loss/seq after 02150 batchs: 540.498046875
INFO:root:Train (Epoch 127): Loss/seq after 02200 batchs: 537.7105102539062
INFO:root:Train (Epoch 127): Loss/seq after 02250 batchs: 536.0335693359375
INFO:root:Train (Epoch 127): Loss/seq after 02300 batchs: 533.0845947265625
INFO:root:Train (Epoch 127): Loss/seq after 02350 batchs: 529.0645141601562
INFO:root:Train (Epoch 127): Loss/seq after 02400 batchs: 529.7678833007812
INFO:root:Train (Epoch 127): Loss/seq after 02450 batchs: 525.440673828125
INFO:root:Train (Epoch 127): Loss/seq after 02500 batchs: 517.8079223632812
INFO:root:Train (Epoch 127): Loss/seq after 02550 batchs: 512.0739135742188
INFO:root:Train (Epoch 127): Loss/seq after 02600 batchs: 511.2599792480469
INFO:root:Train (Epoch 127): Loss/seq after 02650 batchs: 508.7361755371094
INFO:root:Train (Epoch 127): Loss/seq after 02700 batchs: 506.50177001953125
INFO:root:Train (Epoch 127): Loss/seq after 02750 batchs: 504.5182800292969
INFO:root:Train (Epoch 127): Loss/seq after 02800 batchs: 504.4378356933594
INFO:root:Train (Epoch 127): Loss/seq after 02850 batchs: 504.2575378417969
INFO:root:Train (Epoch 127): Loss/seq after 02900 batchs: 505.8204345703125
INFO:root:Train (Epoch 127): Loss/seq after 02950 batchs: 505.03900146484375
INFO:root:Train (Epoch 127): Loss/seq after 03000 batchs: 510.202392578125
INFO:root:Train (Epoch 127): Loss/seq after 03050 batchs: 512.5178833007812
INFO:root:Train (Epoch 127): Loss/seq after 03100 batchs: 515.5778198242188
INFO:root:Train (Epoch 127): Loss/seq after 03150 batchs: 517.901123046875
INFO:root:Train (Epoch 127): Loss/seq after 03200 batchs: 518.693115234375
INFO:root:Train (Epoch 127): Loss/seq after 03250 batchs: 521.20849609375
INFO:root:Train (Epoch 127): Loss/seq after 03300 batchs: 520.2492065429688
INFO:root:Train (Epoch 127): Loss/seq after 03350 batchs: 520.0455932617188
INFO:root:Train (Epoch 127): Loss/seq after 03400 batchs: 515.9760131835938
INFO:root:Train (Epoch 127): Loss/seq after 03450 batchs: 514.7850952148438
INFO:root:Train (Epoch 127): Loss/seq after 03500 batchs: 515.88232421875
INFO:root:Train (Epoch 127): Loss/seq after 03550 batchs: 513.6433715820312
INFO:root:Train (Epoch 127): Loss/seq after 03600 batchs: 521.3438110351562
INFO:root:Train (Epoch 127): Loss/seq after 03650 batchs: 519.0380859375
INFO:root:Train (Epoch 127): Loss/seq after 03700 batchs: 521.7569580078125
INFO:root:Train (Epoch 127): Loss/seq after 03750 batchs: 526.1357421875
INFO:root:Train (Epoch 127): Loss/seq after 03800 batchs: 524.1719970703125
INFO:root:Train (Epoch 127): Loss/seq after 03850 batchs: 522.9811401367188
INFO:root:Train (Epoch 127): Loss/seq after 03900 batchs: 526.024169921875
INFO:root:Train (Epoch 127): Loss/seq after 03950 batchs: 529.4909057617188
INFO:root:Train (Epoch 127): Loss/seq after 04000 batchs: 525.811279296875
INFO:root:Train (Epoch 127): Loss/seq after 04050 batchs: 522.4537353515625
INFO:root:Train (Epoch 127): Loss/seq after 04100 batchs: 520.9887084960938
INFO:root:Train (Epoch 127): Loss/seq after 04150 batchs: 520.8921508789062
INFO:root:Train (Epoch 127): Loss/seq after 04200 batchs: 519.5073852539062
INFO:root:Train (Epoch 127): Loss/seq after 04250 batchs: 517.8532104492188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 127): Loss/seq after 00000 batches: 493.9927062988281
INFO:root:# Valid (Epoch 127): Loss/seq after 00050 batches: 591.8717651367188
INFO:root:# Valid (Epoch 127): Loss/seq after 00100 batches: 649.2378540039062
INFO:root:# Valid (Epoch 127): Loss/seq after 00150 batches: 496.97442626953125
INFO:root:# Valid (Epoch 127): Loss/seq after 00200 batches: 467.169189453125
INFO:root:Artifacts: Make stick videos for epoch 127
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_127_on_20220413_055434.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_127_index_1908_on_20220413_055434.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 128): Loss/seq after 00000 batchs: 869.6087036132812
INFO:root:Train (Epoch 128): Loss/seq after 00050 batchs: 744.999267578125
INFO:root:Train (Epoch 128): Loss/seq after 00100 batchs: 726.2660522460938
INFO:root:Train (Epoch 128): Loss/seq after 00150 batchs: 663.6033935546875
INFO:root:Train (Epoch 128): Loss/seq after 00200 batchs: 721.3687133789062
INFO:root:Train (Epoch 128): Loss/seq after 00250 batchs: 799.1384887695312
INFO:root:Train (Epoch 128): Loss/seq after 00300 batchs: 802.7517700195312
INFO:root:Train (Epoch 128): Loss/seq after 00350 batchs: 753.8026733398438
INFO:root:Train (Epoch 128): Loss/seq after 00400 batchs: 749.9444580078125
INFO:root:Train (Epoch 128): Loss/seq after 00450 batchs: 739.1987915039062
INFO:root:Train (Epoch 128): Loss/seq after 00500 batchs: 715.9525146484375
INFO:root:Train (Epoch 128): Loss/seq after 00550 batchs: 695.269287109375
INFO:root:Train (Epoch 128): Loss/seq after 00600 batchs: 670.4346923828125
INFO:root:Train (Epoch 128): Loss/seq after 00650 batchs: 646.7750854492188
INFO:root:Train (Epoch 128): Loss/seq after 00700 batchs: 623.2711791992188
INFO:root:Train (Epoch 128): Loss/seq after 00750 batchs: 628.4173583984375
INFO:root:Train (Epoch 128): Loss/seq after 00800 batchs: 633.513671875
INFO:root:Train (Epoch 128): Loss/seq after 00850 batchs: 612.7123413085938
INFO:root:Train (Epoch 128): Loss/seq after 00900 batchs: 599.7449340820312
INFO:root:Train (Epoch 128): Loss/seq after 00950 batchs: 597.23291015625
INFO:root:Train (Epoch 128): Loss/seq after 01000 batchs: 588.2188110351562
INFO:root:Train (Epoch 128): Loss/seq after 01050 batchs: 578.4824829101562
INFO:root:Train (Epoch 128): Loss/seq after 01100 batchs: 571.2559204101562
INFO:root:Train (Epoch 128): Loss/seq after 01150 batchs: 557.1057739257812
INFO:root:Train (Epoch 128): Loss/seq after 01200 batchs: 561.6856079101562
INFO:root:Train (Epoch 128): Loss/seq after 01250 batchs: 560.559814453125
INFO:root:Train (Epoch 128): Loss/seq after 01300 batchs: 549.4929809570312
INFO:root:Train (Epoch 128): Loss/seq after 01350 batchs: 540.8096313476562
INFO:root:Train (Epoch 128): Loss/seq after 01400 batchs: 545.0877685546875
INFO:root:Train (Epoch 128): Loss/seq after 01450 batchs: 547.0123291015625
INFO:root:Train (Epoch 128): Loss/seq after 01500 batchs: 554.1302490234375
INFO:root:Train (Epoch 128): Loss/seq after 01550 batchs: 555.4081420898438
INFO:root:Train (Epoch 128): Loss/seq after 01600 batchs: 550.5838012695312
INFO:root:Train (Epoch 128): Loss/seq after 01650 batchs: 549.0795288085938
INFO:root:Train (Epoch 128): Loss/seq after 01700 batchs: 552.06787109375
INFO:root:Train (Epoch 128): Loss/seq after 01750 batchs: 549.5133666992188
INFO:root:Train (Epoch 128): Loss/seq after 01800 batchs: 546.4736328125
INFO:root:Train (Epoch 128): Loss/seq after 01850 batchs: 543.0195922851562
INFO:root:Train (Epoch 128): Loss/seq after 01900 batchs: 542.793701171875
INFO:root:Train (Epoch 128): Loss/seq after 01950 batchs: 541.2225341796875
INFO:root:Train (Epoch 128): Loss/seq after 02000 batchs: 540.3076171875
INFO:root:Train (Epoch 128): Loss/seq after 02050 batchs: 539.3604736328125
INFO:root:Train (Epoch 128): Loss/seq after 02100 batchs: 536.9862060546875
INFO:root:Train (Epoch 128): Loss/seq after 02150 batchs: 535.0403442382812
INFO:root:Train (Epoch 128): Loss/seq after 02200 batchs: 532.3268432617188
INFO:root:Train (Epoch 128): Loss/seq after 02250 batchs: 530.7958374023438
INFO:root:Train (Epoch 128): Loss/seq after 02300 batchs: 527.6753540039062
INFO:root:Train (Epoch 128): Loss/seq after 02350 batchs: 523.9989013671875
INFO:root:Train (Epoch 128): Loss/seq after 02400 batchs: 524.8892822265625
INFO:root:Train (Epoch 128): Loss/seq after 02450 batchs: 520.6219482421875
INFO:root:Train (Epoch 128): Loss/seq after 02500 batchs: 513.088134765625
INFO:root:Train (Epoch 128): Loss/seq after 02550 batchs: 507.42767333984375
INFO:root:Train (Epoch 128): Loss/seq after 02600 batchs: 506.3453063964844
INFO:root:Train (Epoch 128): Loss/seq after 02650 batchs: 503.56689453125
INFO:root:Train (Epoch 128): Loss/seq after 02700 batchs: 501.48040771484375
INFO:root:Train (Epoch 128): Loss/seq after 02750 batchs: 499.2997741699219
INFO:root:Train (Epoch 128): Loss/seq after 02800 batchs: 499.07733154296875
INFO:root:Train (Epoch 128): Loss/seq after 02850 batchs: 499.02886962890625
INFO:root:Train (Epoch 128): Loss/seq after 02900 batchs: 500.7539978027344
INFO:root:Train (Epoch 128): Loss/seq after 02950 batchs: 500.0887451171875
INFO:root:Train (Epoch 128): Loss/seq after 03000 batchs: 505.4092102050781
INFO:root:Train (Epoch 128): Loss/seq after 03050 batchs: 507.5193176269531
INFO:root:Train (Epoch 128): Loss/seq after 03100 batchs: 510.8481140136719
INFO:root:Train (Epoch 128): Loss/seq after 03150 batchs: 513.9141845703125
INFO:root:Train (Epoch 128): Loss/seq after 03200 batchs: 514.6492919921875
INFO:root:Train (Epoch 128): Loss/seq after 03250 batchs: 517.1622924804688
INFO:root:Train (Epoch 128): Loss/seq after 03300 batchs: 516.3009643554688
INFO:root:Train (Epoch 128): Loss/seq after 03350 batchs: 516.1589965820312
INFO:root:Train (Epoch 128): Loss/seq after 03400 batchs: 512.0070190429688
INFO:root:Train (Epoch 128): Loss/seq after 03450 batchs: 510.84625244140625
INFO:root:Train (Epoch 128): Loss/seq after 03500 batchs: 511.5140686035156
INFO:root:Train (Epoch 128): Loss/seq after 03550 batchs: 508.9906921386719
INFO:root:Train (Epoch 128): Loss/seq after 03600 batchs: 516.5032348632812
INFO:root:Train (Epoch 128): Loss/seq after 03650 batchs: 514.2586059570312
INFO:root:Train (Epoch 128): Loss/seq after 03700 batchs: 516.759521484375
INFO:root:Train (Epoch 128): Loss/seq after 03750 batchs: 521.1898803710938
INFO:root:Train (Epoch 128): Loss/seq after 03800 batchs: 519.2159423828125
INFO:root:Train (Epoch 128): Loss/seq after 03850 batchs: 518.1365966796875
INFO:root:Train (Epoch 128): Loss/seq after 03900 batchs: 521.315185546875
INFO:root:Train (Epoch 128): Loss/seq after 03950 batchs: 524.7031860351562
INFO:root:Train (Epoch 128): Loss/seq after 04000 batchs: 521.0879516601562
INFO:root:Train (Epoch 128): Loss/seq after 04050 batchs: 517.7534790039062
INFO:root:Train (Epoch 128): Loss/seq after 04100 batchs: 516.29736328125
INFO:root:Train (Epoch 128): Loss/seq after 04150 batchs: 516.239013671875
INFO:root:Train (Epoch 128): Loss/seq after 04200 batchs: 514.9591674804688
INFO:root:Train (Epoch 128): Loss/seq after 04250 batchs: 513.2733764648438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 128): Loss/seq after 00000 batches: 481.3594970703125
INFO:root:# Valid (Epoch 128): Loss/seq after 00050 batches: 605.8048095703125
INFO:root:# Valid (Epoch 128): Loss/seq after 00100 batches: 666.2115478515625
INFO:root:# Valid (Epoch 128): Loss/seq after 00150 batches: 507.648681640625
INFO:root:# Valid (Epoch 128): Loss/seq after 00200 batches: 475.2896423339844
INFO:root:Artifacts: Make stick videos for epoch 128
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_128_on_20220413_055957.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_128_index_497_on_20220413_055957.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 129): Loss/seq after 00000 batchs: 962.267333984375
INFO:root:Train (Epoch 129): Loss/seq after 00050 batchs: 743.7824096679688
INFO:root:Train (Epoch 129): Loss/seq after 00100 batchs: 724.3970947265625
INFO:root:Train (Epoch 129): Loss/seq after 00150 batchs: 658.4159545898438
INFO:root:Train (Epoch 129): Loss/seq after 00200 batchs: 714.0989379882812
INFO:root:Train (Epoch 129): Loss/seq after 00250 batchs: 790.7966918945312
INFO:root:Train (Epoch 129): Loss/seq after 00300 batchs: 796.0458984375
INFO:root:Train (Epoch 129): Loss/seq after 00350 batchs: 746.801025390625
INFO:root:Train (Epoch 129): Loss/seq after 00400 batchs: 740.3604736328125
INFO:root:Train (Epoch 129): Loss/seq after 00450 batchs: 730.6132202148438
INFO:root:Train (Epoch 129): Loss/seq after 00500 batchs: 707.780517578125
INFO:root:Train (Epoch 129): Loss/seq after 00550 batchs: 687.6517944335938
INFO:root:Train (Epoch 129): Loss/seq after 00600 batchs: 663.689697265625
INFO:root:Train (Epoch 129): Loss/seq after 00650 batchs: 640.306884765625
INFO:root:Train (Epoch 129): Loss/seq after 00700 batchs: 615.8556518554688
INFO:root:Train (Epoch 129): Loss/seq after 00750 batchs: 621.242431640625
INFO:root:Train (Epoch 129): Loss/seq after 00800 batchs: 625.2890014648438
INFO:root:Train (Epoch 129): Loss/seq after 00850 batchs: 605.1260986328125
INFO:root:Train (Epoch 129): Loss/seq after 00900 batchs: 592.9134521484375
INFO:root:Train (Epoch 129): Loss/seq after 00950 batchs: 591.5762329101562
INFO:root:Train (Epoch 129): Loss/seq after 01000 batchs: 582.4835815429688
INFO:root:Train (Epoch 129): Loss/seq after 01050 batchs: 572.4522705078125
INFO:root:Train (Epoch 129): Loss/seq after 01100 batchs: 564.9110107421875
INFO:root:Train (Epoch 129): Loss/seq after 01150 batchs: 550.7601928710938
INFO:root:Train (Epoch 129): Loss/seq after 01200 batchs: 555.5090942382812
INFO:root:Train (Epoch 129): Loss/seq after 01250 batchs: 554.1890258789062
INFO:root:Train (Epoch 129): Loss/seq after 01300 batchs: 543.28564453125
INFO:root:Train (Epoch 129): Loss/seq after 01350 batchs: 534.6718139648438
INFO:root:Train (Epoch 129): Loss/seq after 01400 batchs: 538.486328125
INFO:root:Train (Epoch 129): Loss/seq after 01450 batchs: 540.4710693359375
INFO:root:Train (Epoch 129): Loss/seq after 01500 batchs: 547.6375732421875
INFO:root:Train (Epoch 129): Loss/seq after 01550 batchs: 548.9520874023438
INFO:root:Train (Epoch 129): Loss/seq after 01600 batchs: 544.2301635742188
INFO:root:Train (Epoch 129): Loss/seq after 01650 batchs: 543.06787109375
INFO:root:Train (Epoch 129): Loss/seq after 01700 batchs: 546.2992553710938
INFO:root:Train (Epoch 129): Loss/seq after 01750 batchs: 543.7208862304688
INFO:root:Train (Epoch 129): Loss/seq after 01800 batchs: 540.8565673828125
INFO:root:Train (Epoch 129): Loss/seq after 01850 batchs: 537.6651611328125
INFO:root:Train (Epoch 129): Loss/seq after 01900 batchs: 537.233154296875
INFO:root:Train (Epoch 129): Loss/seq after 01950 batchs: 535.5152587890625
INFO:root:Train (Epoch 129): Loss/seq after 02000 batchs: 534.6992797851562
INFO:root:Train (Epoch 129): Loss/seq after 02050 batchs: 533.7985229492188
INFO:root:Train (Epoch 129): Loss/seq after 02100 batchs: 531.5311279296875
INFO:root:Train (Epoch 129): Loss/seq after 02150 batchs: 529.69140625
INFO:root:Train (Epoch 129): Loss/seq after 02200 batchs: 527.0968627929688
INFO:root:Train (Epoch 129): Loss/seq after 02250 batchs: 525.7119140625
INFO:root:Train (Epoch 129): Loss/seq after 02300 batchs: 522.69140625
INFO:root:Train (Epoch 129): Loss/seq after 02350 batchs: 518.9404296875
INFO:root:Train (Epoch 129): Loss/seq after 02400 batchs: 519.6981811523438
INFO:root:Train (Epoch 129): Loss/seq after 02450 batchs: 515.5301513671875
INFO:root:Train (Epoch 129): Loss/seq after 02500 batchs: 508.0639343261719
INFO:root:Train (Epoch 129): Loss/seq after 02550 batchs: 502.4656982421875
INFO:root:Train (Epoch 129): Loss/seq after 02600 batchs: 501.4858093261719
INFO:root:Train (Epoch 129): Loss/seq after 02650 batchs: 498.8315124511719
INFO:root:Train (Epoch 129): Loss/seq after 02700 batchs: 496.9098205566406
INFO:root:Train (Epoch 129): Loss/seq after 02750 batchs: 494.75897216796875
INFO:root:Train (Epoch 129): Loss/seq after 02800 batchs: 494.5704040527344
INFO:root:Train (Epoch 129): Loss/seq after 02850 batchs: 494.502685546875
INFO:root:Train (Epoch 129): Loss/seq after 02900 batchs: 496.1363525390625
INFO:root:Train (Epoch 129): Loss/seq after 02950 batchs: 495.5125427246094
INFO:root:Train (Epoch 129): Loss/seq after 03000 batchs: 500.7936706542969
INFO:root:Train (Epoch 129): Loss/seq after 03050 batchs: 502.8973388671875
INFO:root:Train (Epoch 129): Loss/seq after 03100 batchs: 506.1322937011719
INFO:root:Train (Epoch 129): Loss/seq after 03150 batchs: 508.3207702636719
INFO:root:Train (Epoch 129): Loss/seq after 03200 batchs: 509.1179504394531
INFO:root:Train (Epoch 129): Loss/seq after 03250 batchs: 511.24267578125
INFO:root:Train (Epoch 129): Loss/seq after 03300 batchs: 510.7059020996094
INFO:root:Train (Epoch 129): Loss/seq after 03350 batchs: 510.4704284667969
INFO:root:Train (Epoch 129): Loss/seq after 03400 batchs: 506.30023193359375
INFO:root:Train (Epoch 129): Loss/seq after 03450 batchs: 505.0757141113281
INFO:root:Train (Epoch 129): Loss/seq after 03500 batchs: 505.9469909667969
INFO:root:Train (Epoch 129): Loss/seq after 03550 batchs: 503.3955078125
INFO:root:Train (Epoch 129): Loss/seq after 03600 batchs: 510.8991394042969
INFO:root:Train (Epoch 129): Loss/seq after 03650 batchs: 508.6963195800781
INFO:root:Train (Epoch 129): Loss/seq after 03700 batchs: 511.3434143066406
INFO:root:Train (Epoch 129): Loss/seq after 03750 batchs: 515.781005859375
INFO:root:Train (Epoch 129): Loss/seq after 03800 batchs: 513.8973999023438
INFO:root:Train (Epoch 129): Loss/seq after 03850 batchs: 512.8193359375
INFO:root:Train (Epoch 129): Loss/seq after 03900 batchs: 516.1766357421875
INFO:root:Train (Epoch 129): Loss/seq after 03950 batchs: 519.5364990234375
INFO:root:Train (Epoch 129): Loss/seq after 04000 batchs: 515.9537963867188
INFO:root:Train (Epoch 129): Loss/seq after 04050 batchs: 512.67578125
INFO:root:Train (Epoch 129): Loss/seq after 04100 batchs: 511.2160949707031
INFO:root:Train (Epoch 129): Loss/seq after 04150 batchs: 511.1559753417969
INFO:root:Train (Epoch 129): Loss/seq after 04200 batchs: 509.86590576171875
INFO:root:Train (Epoch 129): Loss/seq after 04250 batchs: 508.25775146484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 129): Loss/seq after 00000 batches: 503.6225280761719
INFO:root:# Valid (Epoch 129): Loss/seq after 00050 batches: 604.8157348632812
INFO:root:# Valid (Epoch 129): Loss/seq after 00100 batches: 649.5051879882812
INFO:root:# Valid (Epoch 129): Loss/seq after 00150 batches: 497.2796936035156
INFO:root:# Valid (Epoch 129): Loss/seq after 00200 batches: 466.6949462890625
INFO:root:Artifacts: Make stick videos for epoch 129
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_129_on_20220413_060521.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_129_index_1443_on_20220413_060521.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 130): Loss/seq after 00000 batchs: 859.05615234375
INFO:root:Train (Epoch 130): Loss/seq after 00050 batchs: 732.31640625
INFO:root:Train (Epoch 130): Loss/seq after 00100 batchs: 718.9896850585938
INFO:root:Train (Epoch 130): Loss/seq after 00150 batchs: 652.8737182617188
INFO:root:Train (Epoch 130): Loss/seq after 00200 batchs: 707.0928955078125
INFO:root:Train (Epoch 130): Loss/seq after 00250 batchs: 785.571044921875
INFO:root:Train (Epoch 130): Loss/seq after 00300 batchs: 791.4257202148438
INFO:root:Train (Epoch 130): Loss/seq after 00350 batchs: 743.33642578125
INFO:root:Train (Epoch 130): Loss/seq after 00400 batchs: 736.99853515625
INFO:root:Train (Epoch 130): Loss/seq after 00450 batchs: 728.0578002929688
INFO:root:Train (Epoch 130): Loss/seq after 00500 batchs: 704.9707641601562
INFO:root:Train (Epoch 130): Loss/seq after 00550 batchs: 685.3563842773438
INFO:root:Train (Epoch 130): Loss/seq after 00600 batchs: 660.9524536132812
INFO:root:Train (Epoch 130): Loss/seq after 00650 batchs: 638.2274780273438
INFO:root:Train (Epoch 130): Loss/seq after 00700 batchs: 613.263427734375
INFO:root:Train (Epoch 130): Loss/seq after 00750 batchs: 617.70947265625
INFO:root:Train (Epoch 130): Loss/seq after 00800 batchs: 622.8749389648438
INFO:root:Train (Epoch 130): Loss/seq after 00850 batchs: 602.1891479492188
INFO:root:Train (Epoch 130): Loss/seq after 00900 batchs: 589.9088745117188
INFO:root:Train (Epoch 130): Loss/seq after 00950 batchs: 587.2216796875
INFO:root:Train (Epoch 130): Loss/seq after 01000 batchs: 578.4190063476562
INFO:root:Train (Epoch 130): Loss/seq after 01050 batchs: 568.3331298828125
INFO:root:Train (Epoch 130): Loss/seq after 01100 batchs: 561.0460815429688
INFO:root:Train (Epoch 130): Loss/seq after 01150 batchs: 547.2219848632812
INFO:root:Train (Epoch 130): Loss/seq after 01200 batchs: 552.1828002929688
INFO:root:Train (Epoch 130): Loss/seq after 01250 batchs: 551.430419921875
INFO:root:Train (Epoch 130): Loss/seq after 01300 batchs: 540.5341796875
INFO:root:Train (Epoch 130): Loss/seq after 01350 batchs: 532.1417846679688
INFO:root:Train (Epoch 130): Loss/seq after 01400 batchs: 536.4298706054688
INFO:root:Train (Epoch 130): Loss/seq after 01450 batchs: 538.410888671875
INFO:root:Train (Epoch 130): Loss/seq after 01500 batchs: 545.6119384765625
INFO:root:Train (Epoch 130): Loss/seq after 01550 batchs: 547.2102661132812
INFO:root:Train (Epoch 130): Loss/seq after 01600 batchs: 542.6177368164062
INFO:root:Train (Epoch 130): Loss/seq after 01650 batchs: 541.2930297851562
INFO:root:Train (Epoch 130): Loss/seq after 01700 batchs: 544.6713256835938
INFO:root:Train (Epoch 130): Loss/seq after 01750 batchs: 542.1970825195312
INFO:root:Train (Epoch 130): Loss/seq after 01800 batchs: 539.4056396484375
INFO:root:Train (Epoch 130): Loss/seq after 01850 batchs: 536.1104125976562
INFO:root:Train (Epoch 130): Loss/seq after 01900 batchs: 535.8577270507812
INFO:root:Train (Epoch 130): Loss/seq after 01950 batchs: 534.000244140625
INFO:root:Train (Epoch 130): Loss/seq after 02000 batchs: 533.1314697265625
INFO:root:Train (Epoch 130): Loss/seq after 02050 batchs: 532.2265625
INFO:root:Train (Epoch 130): Loss/seq after 02100 batchs: 530.0829467773438
INFO:root:Train (Epoch 130): Loss/seq after 02150 batchs: 528.1288452148438
INFO:root:Train (Epoch 130): Loss/seq after 02200 batchs: 525.5499877929688
INFO:root:Train (Epoch 130): Loss/seq after 02250 batchs: 524.1422119140625
INFO:root:Train (Epoch 130): Loss/seq after 02300 batchs: 521.172119140625
INFO:root:Train (Epoch 130): Loss/seq after 02350 batchs: 517.3500366210938
INFO:root:Train (Epoch 130): Loss/seq after 02400 batchs: 518.0078735351562
INFO:root:Train (Epoch 130): Loss/seq after 02450 batchs: 513.873291015625
INFO:root:Train (Epoch 130): Loss/seq after 02500 batchs: 506.47271728515625
INFO:root:Train (Epoch 130): Loss/seq after 02550 batchs: 500.8526916503906
INFO:root:Train (Epoch 130): Loss/seq after 02600 batchs: 499.72283935546875
INFO:root:Train (Epoch 130): Loss/seq after 02650 batchs: 496.98193359375
INFO:root:Train (Epoch 130): Loss/seq after 02700 batchs: 494.9658508300781
INFO:root:Train (Epoch 130): Loss/seq after 02750 batchs: 492.32745361328125
INFO:root:Train (Epoch 130): Loss/seq after 02800 batchs: 491.74505615234375
INFO:root:Train (Epoch 130): Loss/seq after 02850 batchs: 491.5204772949219
INFO:root:Train (Epoch 130): Loss/seq after 02900 batchs: 493.0419921875
INFO:root:Train (Epoch 130): Loss/seq after 02950 batchs: 492.4473876953125
INFO:root:Train (Epoch 130): Loss/seq after 03000 batchs: 497.6850280761719
INFO:root:Train (Epoch 130): Loss/seq after 03050 batchs: 499.8543395996094
INFO:root:Train (Epoch 130): Loss/seq after 03100 batchs: 502.736083984375
INFO:root:Train (Epoch 130): Loss/seq after 03150 batchs: 504.83563232421875
INFO:root:Train (Epoch 130): Loss/seq after 03200 batchs: 505.529296875
INFO:root:Train (Epoch 130): Loss/seq after 03250 batchs: 507.74322509765625
INFO:root:Train (Epoch 130): Loss/seq after 03300 batchs: 506.64898681640625
INFO:root:Train (Epoch 130): Loss/seq after 03350 batchs: 506.1194763183594
INFO:root:Train (Epoch 130): Loss/seq after 03400 batchs: 501.9713439941406
INFO:root:Train (Epoch 130): Loss/seq after 03450 batchs: 500.6837158203125
INFO:root:Train (Epoch 130): Loss/seq after 03500 batchs: 501.6368408203125
INFO:root:Train (Epoch 130): Loss/seq after 03550 batchs: 499.15435791015625
INFO:root:Train (Epoch 130): Loss/seq after 03600 batchs: 506.4005432128906
INFO:root:Train (Epoch 130): Loss/seq after 03650 batchs: 504.1753845214844
INFO:root:Train (Epoch 130): Loss/seq after 03700 batchs: 506.79656982421875
INFO:root:Train (Epoch 130): Loss/seq after 03750 batchs: 511.18572998046875
INFO:root:Train (Epoch 130): Loss/seq after 03800 batchs: 509.3692321777344
INFO:root:Train (Epoch 130): Loss/seq after 03850 batchs: 508.27655029296875
INFO:root:Train (Epoch 130): Loss/seq after 03900 batchs: 511.44464111328125
INFO:root:Train (Epoch 130): Loss/seq after 03950 batchs: 514.7338256835938
INFO:root:Train (Epoch 130): Loss/seq after 04000 batchs: 511.2095031738281
INFO:root:Train (Epoch 130): Loss/seq after 04050 batchs: 507.9794921875
INFO:root:Train (Epoch 130): Loss/seq after 04100 batchs: 506.65704345703125
INFO:root:Train (Epoch 130): Loss/seq after 04150 batchs: 506.65399169921875
INFO:root:Train (Epoch 130): Loss/seq after 04200 batchs: 505.4410095214844
INFO:root:Train (Epoch 130): Loss/seq after 04250 batchs: 503.8042297363281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 130): Loss/seq after 00000 batches: 444.6103210449219
INFO:root:# Valid (Epoch 130): Loss/seq after 00050 batches: 600.7911376953125
INFO:root:# Valid (Epoch 130): Loss/seq after 00100 batches: 668.5004272460938
INFO:root:# Valid (Epoch 130): Loss/seq after 00150 batches: 508.5368347167969
INFO:root:# Valid (Epoch 130): Loss/seq after 00200 batches: 476.64715576171875
INFO:root:Artifacts: Make stick videos for epoch 130
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_130_on_20220413_061042.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_130_index_1312_on_20220413_061042.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 131): Loss/seq after 00000 batchs: 969.1082763671875
INFO:root:Train (Epoch 131): Loss/seq after 00050 batchs: 738.8154296875
INFO:root:Train (Epoch 131): Loss/seq after 00100 batchs: 713.4526977539062
INFO:root:Train (Epoch 131): Loss/seq after 00150 batchs: 652.5919799804688
INFO:root:Train (Epoch 131): Loss/seq after 00200 batchs: 707.4259643554688
INFO:root:Train (Epoch 131): Loss/seq after 00250 batchs: 786.3963623046875
INFO:root:Train (Epoch 131): Loss/seq after 00300 batchs: 792.5731201171875
INFO:root:Train (Epoch 131): Loss/seq after 00350 batchs: 743.3966674804688
INFO:root:Train (Epoch 131): Loss/seq after 00400 batchs: 738.4522705078125
INFO:root:Train (Epoch 131): Loss/seq after 00450 batchs: 728.895751953125
INFO:root:Train (Epoch 131): Loss/seq after 00500 batchs: 707.8072509765625
INFO:root:Train (Epoch 131): Loss/seq after 00550 batchs: 688.1016235351562
INFO:root:Train (Epoch 131): Loss/seq after 00600 batchs: 664.3419799804688
INFO:root:Train (Epoch 131): Loss/seq after 00650 batchs: 641.9441528320312
INFO:root:Train (Epoch 131): Loss/seq after 00700 batchs: 615.9970703125
INFO:root:Train (Epoch 131): Loss/seq after 00750 batchs: 620.3653564453125
INFO:root:Train (Epoch 131): Loss/seq after 00800 batchs: 624.7798461914062
INFO:root:Train (Epoch 131): Loss/seq after 00850 batchs: 604.564697265625
INFO:root:Train (Epoch 131): Loss/seq after 00900 batchs: 592.182861328125
INFO:root:Train (Epoch 131): Loss/seq after 00950 batchs: 589.79248046875
INFO:root:Train (Epoch 131): Loss/seq after 01000 batchs: 581.1062622070312
INFO:root:Train (Epoch 131): Loss/seq after 01050 batchs: 571.0227661132812
INFO:root:Train (Epoch 131): Loss/seq after 01100 batchs: 563.9760131835938
INFO:root:Train (Epoch 131): Loss/seq after 01150 batchs: 550.0541381835938
INFO:root:Train (Epoch 131): Loss/seq after 01200 batchs: 554.77587890625
INFO:root:Train (Epoch 131): Loss/seq after 01250 batchs: 553.9401245117188
INFO:root:Train (Epoch 131): Loss/seq after 01300 batchs: 543.0905151367188
INFO:root:Train (Epoch 131): Loss/seq after 01350 batchs: 534.3668212890625
INFO:root:Train (Epoch 131): Loss/seq after 01400 batchs: 537.4749755859375
INFO:root:Train (Epoch 131): Loss/seq after 01450 batchs: 539.1882934570312
INFO:root:Train (Epoch 131): Loss/seq after 01500 batchs: 546.1906127929688
INFO:root:Train (Epoch 131): Loss/seq after 01550 batchs: 547.7841796875
INFO:root:Train (Epoch 131): Loss/seq after 01600 batchs: 543.3621215820312
INFO:root:Train (Epoch 131): Loss/seq after 01650 batchs: 542.1787719726562
INFO:root:Train (Epoch 131): Loss/seq after 01700 batchs: 545.8428955078125
INFO:root:Train (Epoch 131): Loss/seq after 01750 batchs: 543.30322265625
INFO:root:Train (Epoch 131): Loss/seq after 01800 batchs: 540.3436889648438
INFO:root:Train (Epoch 131): Loss/seq after 01850 batchs: 536.8309936523438
INFO:root:Train (Epoch 131): Loss/seq after 01900 batchs: 536.8348388671875
INFO:root:Train (Epoch 131): Loss/seq after 01950 batchs: 535.5607299804688
INFO:root:Train (Epoch 131): Loss/seq after 02000 batchs: 534.7238159179688
INFO:root:Train (Epoch 131): Loss/seq after 02050 batchs: 533.8660278320312
INFO:root:Train (Epoch 131): Loss/seq after 02100 batchs: 531.484130859375
INFO:root:Train (Epoch 131): Loss/seq after 02150 batchs: 529.479736328125
INFO:root:Train (Epoch 131): Loss/seq after 02200 batchs: 526.81298828125
INFO:root:Train (Epoch 131): Loss/seq after 02250 batchs: 525.164794921875
INFO:root:Train (Epoch 131): Loss/seq after 02300 batchs: 521.9457397460938
INFO:root:Train (Epoch 131): Loss/seq after 02350 batchs: 518.0261840820312
INFO:root:Train (Epoch 131): Loss/seq after 02400 batchs: 518.6700439453125
INFO:root:Train (Epoch 131): Loss/seq after 02450 batchs: 514.448974609375
INFO:root:Train (Epoch 131): Loss/seq after 02500 batchs: 506.9814453125
INFO:root:Train (Epoch 131): Loss/seq after 02550 batchs: 501.2467041015625
INFO:root:Train (Epoch 131): Loss/seq after 02600 batchs: 500.0466003417969
INFO:root:Train (Epoch 131): Loss/seq after 02650 batchs: 497.10784912109375
INFO:root:Train (Epoch 131): Loss/seq after 02700 batchs: 494.9698791503906
INFO:root:Train (Epoch 131): Loss/seq after 02750 batchs: 492.6059265136719
INFO:root:Train (Epoch 131): Loss/seq after 02800 batchs: 492.1024169921875
INFO:root:Train (Epoch 131): Loss/seq after 02850 batchs: 491.9867248535156
INFO:root:Train (Epoch 131): Loss/seq after 02900 batchs: 493.6535949707031
INFO:root:Train (Epoch 131): Loss/seq after 02950 batchs: 492.9399719238281
INFO:root:Train (Epoch 131): Loss/seq after 03000 batchs: 498.2264099121094
INFO:root:Train (Epoch 131): Loss/seq after 03050 batchs: 500.3485107421875
INFO:root:Train (Epoch 131): Loss/seq after 03100 batchs: 503.31829833984375
INFO:root:Train (Epoch 131): Loss/seq after 03150 batchs: 505.29510498046875
INFO:root:Train (Epoch 131): Loss/seq after 03200 batchs: 505.83349609375
INFO:root:Train (Epoch 131): Loss/seq after 03250 batchs: 508.15240478515625
INFO:root:Train (Epoch 131): Loss/seq after 03300 batchs: 507.135986328125
INFO:root:Train (Epoch 131): Loss/seq after 03350 batchs: 506.6001892089844
INFO:root:Train (Epoch 131): Loss/seq after 03400 batchs: 502.55120849609375
INFO:root:Train (Epoch 131): Loss/seq after 03450 batchs: 501.4842529296875
INFO:root:Train (Epoch 131): Loss/seq after 03500 batchs: 502.2007751464844
INFO:root:Train (Epoch 131): Loss/seq after 03550 batchs: 499.67724609375
INFO:root:Train (Epoch 131): Loss/seq after 03600 batchs: 506.9260559082031
INFO:root:Train (Epoch 131): Loss/seq after 03650 batchs: 504.7267150878906
INFO:root:Train (Epoch 131): Loss/seq after 03700 batchs: 507.1942443847656
INFO:root:Train (Epoch 131): Loss/seq after 03750 batchs: 511.54278564453125
INFO:root:Train (Epoch 131): Loss/seq after 03800 batchs: 509.71533203125
INFO:root:Train (Epoch 131): Loss/seq after 03850 batchs: 508.6440734863281
INFO:root:Train (Epoch 131): Loss/seq after 03900 batchs: 511.6455383300781
INFO:root:Train (Epoch 131): Loss/seq after 03950 batchs: 514.8648681640625
INFO:root:Train (Epoch 131): Loss/seq after 04000 batchs: 511.299560546875
INFO:root:Train (Epoch 131): Loss/seq after 04050 batchs: 508.0457763671875
INFO:root:Train (Epoch 131): Loss/seq after 04100 batchs: 506.66949462890625
INFO:root:Train (Epoch 131): Loss/seq after 04150 batchs: 506.7198791503906
INFO:root:Train (Epoch 131): Loss/seq after 04200 batchs: 505.4393005371094
INFO:root:Train (Epoch 131): Loss/seq after 04250 batchs: 503.8219909667969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 131): Loss/seq after 00000 batches: 434.648681640625
INFO:root:# Valid (Epoch 131): Loss/seq after 00050 batches: 576.832275390625
INFO:root:# Valid (Epoch 131): Loss/seq after 00100 batches: 635.4721069335938
INFO:root:# Valid (Epoch 131): Loss/seq after 00150 batches: 484.810546875
INFO:root:# Valid (Epoch 131): Loss/seq after 00200 batches: 455.1230773925781
INFO:root:Artifacts: Make stick videos for epoch 131
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_131_on_20220413_061605.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_131_index_1115_on_20220413_061605.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 132): Loss/seq after 00000 batchs: 878.7415161132812
INFO:root:Train (Epoch 132): Loss/seq after 00050 batchs: 723.3247680664062
INFO:root:Train (Epoch 132): Loss/seq after 00100 batchs: 715.0162963867188
INFO:root:Train (Epoch 132): Loss/seq after 00150 batchs: 651.9306030273438
INFO:root:Train (Epoch 132): Loss/seq after 00200 batchs: 709.2960815429688
INFO:root:Train (Epoch 132): Loss/seq after 00250 batchs: 783.1932373046875
INFO:root:Train (Epoch 132): Loss/seq after 00300 batchs: 787.5264892578125
INFO:root:Train (Epoch 132): Loss/seq after 00350 batchs: 739.2882080078125
INFO:root:Train (Epoch 132): Loss/seq after 00400 batchs: 731.7916259765625
INFO:root:Train (Epoch 132): Loss/seq after 00450 batchs: 722.5352172851562
INFO:root:Train (Epoch 132): Loss/seq after 00500 batchs: 699.9894409179688
INFO:root:Train (Epoch 132): Loss/seq after 00550 batchs: 680.094970703125
INFO:root:Train (Epoch 132): Loss/seq after 00600 batchs: 656.7852783203125
INFO:root:Train (Epoch 132): Loss/seq after 00650 batchs: 632.7748413085938
INFO:root:Train (Epoch 132): Loss/seq after 00700 batchs: 608.1256103515625
INFO:root:Train (Epoch 132): Loss/seq after 00750 batchs: 612.3936767578125
INFO:root:Train (Epoch 132): Loss/seq after 00800 batchs: 617.4625244140625
INFO:root:Train (Epoch 132): Loss/seq after 00850 batchs: 597.7078247070312
INFO:root:Train (Epoch 132): Loss/seq after 00900 batchs: 584.96630859375
INFO:root:Train (Epoch 132): Loss/seq after 00950 batchs: 582.6932373046875
INFO:root:Train (Epoch 132): Loss/seq after 01000 batchs: 573.853759765625
INFO:root:Train (Epoch 132): Loss/seq after 01050 batchs: 564.6640014648438
INFO:root:Train (Epoch 132): Loss/seq after 01100 batchs: 557.4224853515625
INFO:root:Train (Epoch 132): Loss/seq after 01150 batchs: 543.5369873046875
INFO:root:Train (Epoch 132): Loss/seq after 01200 batchs: 549.072509765625
INFO:root:Train (Epoch 132): Loss/seq after 01250 batchs: 548.158203125
INFO:root:Train (Epoch 132): Loss/seq after 01300 batchs: 537.53515625
INFO:root:Train (Epoch 132): Loss/seq after 01350 batchs: 529.0189208984375
INFO:root:Train (Epoch 132): Loss/seq after 01400 batchs: 533.0681762695312
INFO:root:Train (Epoch 132): Loss/seq after 01450 batchs: 535.188720703125
INFO:root:Train (Epoch 132): Loss/seq after 01500 batchs: 542.5413818359375
INFO:root:Train (Epoch 132): Loss/seq after 01550 batchs: 543.6265869140625
INFO:root:Train (Epoch 132): Loss/seq after 01600 batchs: 538.7049560546875
INFO:root:Train (Epoch 132): Loss/seq after 01650 batchs: 537.1889038085938
INFO:root:Train (Epoch 132): Loss/seq after 01700 batchs: 540.1569213867188
INFO:root:Train (Epoch 132): Loss/seq after 01750 batchs: 537.6040649414062
INFO:root:Train (Epoch 132): Loss/seq after 01800 batchs: 534.739013671875
INFO:root:Train (Epoch 132): Loss/seq after 01850 batchs: 531.426025390625
INFO:root:Train (Epoch 132): Loss/seq after 01900 batchs: 531.0732421875
INFO:root:Train (Epoch 132): Loss/seq after 01950 batchs: 529.4651489257812
INFO:root:Train (Epoch 132): Loss/seq after 02000 batchs: 528.8148803710938
INFO:root:Train (Epoch 132): Loss/seq after 02050 batchs: 527.9317016601562
INFO:root:Train (Epoch 132): Loss/seq after 02100 batchs: 525.700927734375
INFO:root:Train (Epoch 132): Loss/seq after 02150 batchs: 523.7713012695312
INFO:root:Train (Epoch 132): Loss/seq after 02200 batchs: 521.2429809570312
INFO:root:Train (Epoch 132): Loss/seq after 02250 batchs: 519.904052734375
INFO:root:Train (Epoch 132): Loss/seq after 02300 batchs: 516.464599609375
INFO:root:Train (Epoch 132): Loss/seq after 02350 batchs: 512.701904296875
INFO:root:Train (Epoch 132): Loss/seq after 02400 batchs: 513.3606567382812
INFO:root:Train (Epoch 132): Loss/seq after 02450 batchs: 509.26422119140625
INFO:root:Train (Epoch 132): Loss/seq after 02500 batchs: 501.87493896484375
INFO:root:Train (Epoch 132): Loss/seq after 02550 batchs: 496.2453918457031
INFO:root:Train (Epoch 132): Loss/seq after 02600 batchs: 495.2715759277344
INFO:root:Train (Epoch 132): Loss/seq after 02650 batchs: 492.2608337402344
INFO:root:Train (Epoch 132): Loss/seq after 02700 batchs: 490.0412902832031
INFO:root:Train (Epoch 132): Loss/seq after 02750 batchs: 487.6545104980469
INFO:root:Train (Epoch 132): Loss/seq after 02800 batchs: 487.0805358886719
INFO:root:Train (Epoch 132): Loss/seq after 02850 batchs: 487.1151428222656
INFO:root:Train (Epoch 132): Loss/seq after 02900 batchs: 488.8177490234375
INFO:root:Train (Epoch 132): Loss/seq after 02950 batchs: 488.1794738769531
INFO:root:Train (Epoch 132): Loss/seq after 03000 batchs: 493.5360107421875
INFO:root:Train (Epoch 132): Loss/seq after 03050 batchs: 495.5774841308594
INFO:root:Train (Epoch 132): Loss/seq after 03100 batchs: 498.4653625488281
INFO:root:Train (Epoch 132): Loss/seq after 03150 batchs: 500.5465393066406
INFO:root:Train (Epoch 132): Loss/seq after 03200 batchs: 501.2418212890625
INFO:root:Train (Epoch 132): Loss/seq after 03250 batchs: 503.3922424316406
INFO:root:Train (Epoch 132): Loss/seq after 03300 batchs: 502.3025817871094
INFO:root:Train (Epoch 132): Loss/seq after 03350 batchs: 501.83074951171875
INFO:root:Train (Epoch 132): Loss/seq after 03400 batchs: 497.94610595703125
INFO:root:Train (Epoch 132): Loss/seq after 03450 batchs: 496.77642822265625
INFO:root:Train (Epoch 132): Loss/seq after 03500 batchs: 497.5679931640625
INFO:root:Train (Epoch 132): Loss/seq after 03550 batchs: 495.01416015625
INFO:root:Train (Epoch 132): Loss/seq after 03600 batchs: 502.3634033203125
INFO:root:Train (Epoch 132): Loss/seq after 03650 batchs: 500.15887451171875
INFO:root:Train (Epoch 132): Loss/seq after 03700 batchs: 502.59161376953125
INFO:root:Train (Epoch 132): Loss/seq after 03750 batchs: 507.0558776855469
INFO:root:Train (Epoch 132): Loss/seq after 03800 batchs: 505.2537536621094
INFO:root:Train (Epoch 132): Loss/seq after 03850 batchs: 504.0764465332031
INFO:root:Train (Epoch 132): Loss/seq after 03900 batchs: 507.1387939453125
INFO:root:Train (Epoch 132): Loss/seq after 03950 batchs: 510.41217041015625
INFO:root:Train (Epoch 132): Loss/seq after 04000 batchs: 506.9284362792969
INFO:root:Train (Epoch 132): Loss/seq after 04050 batchs: 503.71429443359375
INFO:root:Train (Epoch 132): Loss/seq after 04100 batchs: 502.3316650390625
INFO:root:Train (Epoch 132): Loss/seq after 04150 batchs: 502.295654296875
INFO:root:Train (Epoch 132): Loss/seq after 04200 batchs: 501.0211181640625
INFO:root:Train (Epoch 132): Loss/seq after 04250 batchs: 499.3658447265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 132): Loss/seq after 00000 batches: 497.6382141113281
INFO:root:# Valid (Epoch 132): Loss/seq after 00050 batches: 577.1005859375
INFO:root:# Valid (Epoch 132): Loss/seq after 00100 batches: 631.14404296875
INFO:root:# Valid (Epoch 132): Loss/seq after 00150 batches: 482.9915771484375
INFO:root:# Valid (Epoch 132): Loss/seq after 00200 batches: 453.5335388183594
INFO:root:Artifacts: Make stick videos for epoch 132
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_132_on_20220413_062127.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_132_index_910_on_20220413_062127.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 133): Loss/seq after 00000 batchs: 1071.4246826171875
INFO:root:Train (Epoch 133): Loss/seq after 00050 batchs: 732.5530395507812
INFO:root:Train (Epoch 133): Loss/seq after 00100 batchs: 702.430419921875
INFO:root:Train (Epoch 133): Loss/seq after 00150 batchs: 641.048828125
INFO:root:Train (Epoch 133): Loss/seq after 00200 batchs: 701.400390625
INFO:root:Train (Epoch 133): Loss/seq after 00250 batchs: 774.6016235351562
INFO:root:Train (Epoch 133): Loss/seq after 00300 batchs: 780.7989501953125
INFO:root:Train (Epoch 133): Loss/seq after 00350 batchs: 734.096435546875
INFO:root:Train (Epoch 133): Loss/seq after 00400 batchs: 728.3506469726562
INFO:root:Train (Epoch 133): Loss/seq after 00450 batchs: 719.9736938476562
INFO:root:Train (Epoch 133): Loss/seq after 00500 batchs: 697.7826538085938
INFO:root:Train (Epoch 133): Loss/seq after 00550 batchs: 678.18408203125
INFO:root:Train (Epoch 133): Loss/seq after 00600 batchs: 654.281982421875
INFO:root:Train (Epoch 133): Loss/seq after 00650 batchs: 631.3162841796875
INFO:root:Train (Epoch 133): Loss/seq after 00700 batchs: 606.5439453125
INFO:root:Train (Epoch 133): Loss/seq after 00750 batchs: 610.1741943359375
INFO:root:Train (Epoch 133): Loss/seq after 00800 batchs: 614.6228637695312
INFO:root:Train (Epoch 133): Loss/seq after 00850 batchs: 594.8258666992188
INFO:root:Train (Epoch 133): Loss/seq after 00900 batchs: 583.13720703125
INFO:root:Train (Epoch 133): Loss/seq after 00950 batchs: 580.5896606445312
INFO:root:Train (Epoch 133): Loss/seq after 01000 batchs: 571.6908569335938
INFO:root:Train (Epoch 133): Loss/seq after 01050 batchs: 561.591796875
INFO:root:Train (Epoch 133): Loss/seq after 01100 batchs: 553.4891357421875
INFO:root:Train (Epoch 133): Loss/seq after 01150 batchs: 539.423828125
INFO:root:Train (Epoch 133): Loss/seq after 01200 batchs: 544.8163452148438
INFO:root:Train (Epoch 133): Loss/seq after 01250 batchs: 543.9315185546875
INFO:root:Train (Epoch 133): Loss/seq after 01300 batchs: 533.3303833007812
INFO:root:Train (Epoch 133): Loss/seq after 01350 batchs: 524.9215698242188
INFO:root:Train (Epoch 133): Loss/seq after 01400 batchs: 527.8925170898438
INFO:root:Train (Epoch 133): Loss/seq after 01450 batchs: 529.7449951171875
INFO:root:Train (Epoch 133): Loss/seq after 01500 batchs: 537.177001953125
INFO:root:Train (Epoch 133): Loss/seq after 01550 batchs: 538.1854858398438
INFO:root:Train (Epoch 133): Loss/seq after 01600 batchs: 533.329833984375
INFO:root:Train (Epoch 133): Loss/seq after 01650 batchs: 531.9305419921875
INFO:root:Train (Epoch 133): Loss/seq after 01700 batchs: 535.2786254882812
INFO:root:Train (Epoch 133): Loss/seq after 01750 batchs: 532.8557739257812
INFO:root:Train (Epoch 133): Loss/seq after 01800 batchs: 529.9440307617188
INFO:root:Train (Epoch 133): Loss/seq after 01850 batchs: 526.74951171875
INFO:root:Train (Epoch 133): Loss/seq after 01900 batchs: 526.4649047851562
INFO:root:Train (Epoch 133): Loss/seq after 01950 batchs: 524.6422729492188
INFO:root:Train (Epoch 133): Loss/seq after 02000 batchs: 524.0953369140625
INFO:root:Train (Epoch 133): Loss/seq after 02050 batchs: 523.3220825195312
INFO:root:Train (Epoch 133): Loss/seq after 02100 batchs: 521.2823486328125
INFO:root:Train (Epoch 133): Loss/seq after 02150 batchs: 519.4468994140625
INFO:root:Train (Epoch 133): Loss/seq after 02200 batchs: 516.934814453125
INFO:root:Train (Epoch 133): Loss/seq after 02250 batchs: 515.3064575195312
INFO:root:Train (Epoch 133): Loss/seq after 02300 batchs: 512.1332397460938
INFO:root:Train (Epoch 133): Loss/seq after 02350 batchs: 508.419189453125
INFO:root:Train (Epoch 133): Loss/seq after 02400 batchs: 509.0790710449219
INFO:root:Train (Epoch 133): Loss/seq after 02450 batchs: 505.07470703125
INFO:root:Train (Epoch 133): Loss/seq after 02500 batchs: 497.78173828125
INFO:root:Train (Epoch 133): Loss/seq after 02550 batchs: 492.1617431640625
INFO:root:Train (Epoch 133): Loss/seq after 02600 batchs: 491.0767822265625
INFO:root:Train (Epoch 133): Loss/seq after 02650 batchs: 488.23553466796875
INFO:root:Train (Epoch 133): Loss/seq after 02700 batchs: 486.3131103515625
INFO:root:Train (Epoch 133): Loss/seq after 02750 batchs: 483.85003662109375
INFO:root:Train (Epoch 133): Loss/seq after 02800 batchs: 483.19671630859375
INFO:root:Train (Epoch 133): Loss/seq after 02850 batchs: 483.10198974609375
INFO:root:Train (Epoch 133): Loss/seq after 02900 batchs: 484.9412536621094
INFO:root:Train (Epoch 133): Loss/seq after 02950 batchs: 484.431884765625
INFO:root:Train (Epoch 133): Loss/seq after 03000 batchs: 489.7743835449219
INFO:root:Train (Epoch 133): Loss/seq after 03050 batchs: 491.8662414550781
INFO:root:Train (Epoch 133): Loss/seq after 03100 batchs: 494.752685546875
INFO:root:Train (Epoch 133): Loss/seq after 03150 batchs: 496.5848388671875
INFO:root:Train (Epoch 133): Loss/seq after 03200 batchs: 497.2319030761719
INFO:root:Train (Epoch 133): Loss/seq after 03250 batchs: 499.43719482421875
INFO:root:Train (Epoch 133): Loss/seq after 03300 batchs: 498.5704345703125
INFO:root:Train (Epoch 133): Loss/seq after 03350 batchs: 498.0318298339844
INFO:root:Train (Epoch 133): Loss/seq after 03400 batchs: 494.20751953125
INFO:root:Train (Epoch 133): Loss/seq after 03450 batchs: 493.1575927734375
INFO:root:Train (Epoch 133): Loss/seq after 03500 batchs: 494.2626647949219
INFO:root:Train (Epoch 133): Loss/seq after 03550 batchs: 491.8547058105469
INFO:root:Train (Epoch 133): Loss/seq after 03600 batchs: 499.1275939941406
INFO:root:Train (Epoch 133): Loss/seq after 03650 batchs: 497.00396728515625
INFO:root:Train (Epoch 133): Loss/seq after 03700 batchs: 499.5655212402344
INFO:root:Train (Epoch 133): Loss/seq after 03750 batchs: 503.9447326660156
INFO:root:Train (Epoch 133): Loss/seq after 03800 batchs: 502.1509704589844
INFO:root:Train (Epoch 133): Loss/seq after 03850 batchs: 501.0730285644531
INFO:root:Train (Epoch 133): Loss/seq after 03900 batchs: 504.0534973144531
INFO:root:Train (Epoch 133): Loss/seq after 03950 batchs: 507.20233154296875
INFO:root:Train (Epoch 133): Loss/seq after 04000 batchs: 503.7388610839844
INFO:root:Train (Epoch 133): Loss/seq after 04050 batchs: 500.5497131347656
INFO:root:Train (Epoch 133): Loss/seq after 04100 batchs: 499.22320556640625
INFO:root:Train (Epoch 133): Loss/seq after 04150 batchs: 499.26495361328125
INFO:root:Train (Epoch 133): Loss/seq after 04200 batchs: 498.1161804199219
INFO:root:Train (Epoch 133): Loss/seq after 04250 batchs: 496.5752868652344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 133): Loss/seq after 00000 batches: 458.63165283203125
INFO:root:# Valid (Epoch 133): Loss/seq after 00050 batches: 590.9260864257812
INFO:root:# Valid (Epoch 133): Loss/seq after 00100 batches: 627.0841674804688
INFO:root:# Valid (Epoch 133): Loss/seq after 00150 batches: 478.91845703125
INFO:root:# Valid (Epoch 133): Loss/seq after 00200 batches: 451.0113525390625
INFO:root:Artifacts: Make stick videos for epoch 133
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_133_on_20220413_062650.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_133_index_1426_on_20220413_062650.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 134): Loss/seq after 00000 batchs: 991.3023681640625
INFO:root:Train (Epoch 134): Loss/seq after 00050 batchs: 720.7696533203125
INFO:root:Train (Epoch 134): Loss/seq after 00100 batchs: 694.9046630859375
INFO:root:Train (Epoch 134): Loss/seq after 00150 batchs: 636.8558349609375
INFO:root:Train (Epoch 134): Loss/seq after 00200 batchs: 690.614013671875
INFO:root:Train (Epoch 134): Loss/seq after 00250 batchs: 764.1109619140625
INFO:root:Train (Epoch 134): Loss/seq after 00300 batchs: 770.3845825195312
INFO:root:Train (Epoch 134): Loss/seq after 00350 batchs: 723.9735717773438
INFO:root:Train (Epoch 134): Loss/seq after 00400 batchs: 715.6102905273438
INFO:root:Train (Epoch 134): Loss/seq after 00450 batchs: 708.1959228515625
INFO:root:Train (Epoch 134): Loss/seq after 00500 batchs: 687.016357421875
INFO:root:Train (Epoch 134): Loss/seq after 00550 batchs: 668.0518188476562
INFO:root:Train (Epoch 134): Loss/seq after 00600 batchs: 645.1693115234375
INFO:root:Train (Epoch 134): Loss/seq after 00650 batchs: 623.5433959960938
INFO:root:Train (Epoch 134): Loss/seq after 00700 batchs: 598.7359619140625
INFO:root:Train (Epoch 134): Loss/seq after 00750 batchs: 603.7102661132812
INFO:root:Train (Epoch 134): Loss/seq after 00800 batchs: 608.3750610351562
INFO:root:Train (Epoch 134): Loss/seq after 00850 batchs: 588.9911499023438
INFO:root:Train (Epoch 134): Loss/seq after 00900 batchs: 577.6602172851562
INFO:root:Train (Epoch 134): Loss/seq after 00950 batchs: 575.4857788085938
INFO:root:Train (Epoch 134): Loss/seq after 01000 batchs: 567.716552734375
INFO:root:Train (Epoch 134): Loss/seq after 01050 batchs: 557.9492797851562
INFO:root:Train (Epoch 134): Loss/seq after 01100 batchs: 550.492431640625
INFO:root:Train (Epoch 134): Loss/seq after 01150 batchs: 536.8675537109375
INFO:root:Train (Epoch 134): Loss/seq after 01200 batchs: 541.787353515625
INFO:root:Train (Epoch 134): Loss/seq after 01250 batchs: 540.95703125
INFO:root:Train (Epoch 134): Loss/seq after 01300 batchs: 530.6488037109375
INFO:root:Train (Epoch 134): Loss/seq after 01350 batchs: 522.2211303710938
INFO:root:Train (Epoch 134): Loss/seq after 01400 batchs: 526.2974243164062
INFO:root:Train (Epoch 134): Loss/seq after 01450 batchs: 528.3414306640625
INFO:root:Train (Epoch 134): Loss/seq after 01500 batchs: 535.6275024414062
INFO:root:Train (Epoch 134): Loss/seq after 01550 batchs: 536.5762939453125
INFO:root:Train (Epoch 134): Loss/seq after 01600 batchs: 531.9292602539062
INFO:root:Train (Epoch 134): Loss/seq after 01650 batchs: 530.4786376953125
INFO:root:Train (Epoch 134): Loss/seq after 01700 batchs: 533.6798095703125
INFO:root:Train (Epoch 134): Loss/seq after 01750 batchs: 531.1303100585938
INFO:root:Train (Epoch 134): Loss/seq after 01800 batchs: 528.1533203125
INFO:root:Train (Epoch 134): Loss/seq after 01850 batchs: 524.8746948242188
INFO:root:Train (Epoch 134): Loss/seq after 01900 batchs: 524.5643310546875
INFO:root:Train (Epoch 134): Loss/seq after 01950 batchs: 522.7547607421875
INFO:root:Train (Epoch 134): Loss/seq after 02000 batchs: 522.0390625
INFO:root:Train (Epoch 134): Loss/seq after 02050 batchs: 521.1900024414062
INFO:root:Train (Epoch 134): Loss/seq after 02100 batchs: 518.9539794921875
INFO:root:Train (Epoch 134): Loss/seq after 02150 batchs: 517.1979370117188
INFO:root:Train (Epoch 134): Loss/seq after 02200 batchs: 514.6409301757812
INFO:root:Train (Epoch 134): Loss/seq after 02250 batchs: 513.0941772460938
INFO:root:Train (Epoch 134): Loss/seq after 02300 batchs: 509.9477233886719
INFO:root:Train (Epoch 134): Loss/seq after 02350 batchs: 506.20947265625
INFO:root:Train (Epoch 134): Loss/seq after 02400 batchs: 506.75927734375
INFO:root:Train (Epoch 134): Loss/seq after 02450 batchs: 502.6929931640625
INFO:root:Train (Epoch 134): Loss/seq after 02500 batchs: 495.4222717285156
INFO:root:Train (Epoch 134): Loss/seq after 02550 batchs: 489.70074462890625
INFO:root:Train (Epoch 134): Loss/seq after 02600 batchs: 488.7749328613281
INFO:root:Train (Epoch 134): Loss/seq after 02650 batchs: 485.8100280761719
INFO:root:Train (Epoch 134): Loss/seq after 02700 batchs: 483.7744140625
INFO:root:Train (Epoch 134): Loss/seq after 02750 batchs: 481.01043701171875
INFO:root:Train (Epoch 134): Loss/seq after 02800 batchs: 480.399169921875
INFO:root:Train (Epoch 134): Loss/seq after 02850 batchs: 480.4294128417969
INFO:root:Train (Epoch 134): Loss/seq after 02900 batchs: 481.8924865722656
INFO:root:Train (Epoch 134): Loss/seq after 02950 batchs: 481.3811340332031
INFO:root:Train (Epoch 134): Loss/seq after 03000 batchs: 486.7466125488281
INFO:root:Train (Epoch 134): Loss/seq after 03050 batchs: 489.0493469238281
INFO:root:Train (Epoch 134): Loss/seq after 03100 batchs: 491.7582092285156
INFO:root:Train (Epoch 134): Loss/seq after 03150 batchs: 494.0052185058594
INFO:root:Train (Epoch 134): Loss/seq after 03200 batchs: 494.632080078125
INFO:root:Train (Epoch 134): Loss/seq after 03250 batchs: 496.73065185546875
INFO:root:Train (Epoch 134): Loss/seq after 03300 batchs: 495.8365478515625
INFO:root:Train (Epoch 134): Loss/seq after 03350 batchs: 495.402587890625
INFO:root:Train (Epoch 134): Loss/seq after 03400 batchs: 491.55364990234375
INFO:root:Train (Epoch 134): Loss/seq after 03450 batchs: 490.39166259765625
INFO:root:Train (Epoch 134): Loss/seq after 03500 batchs: 491.5721130371094
INFO:root:Train (Epoch 134): Loss/seq after 03550 batchs: 489.0527038574219
INFO:root:Train (Epoch 134): Loss/seq after 03600 batchs: 496.3175048828125
INFO:root:Train (Epoch 134): Loss/seq after 03650 batchs: 494.15972900390625
INFO:root:Train (Epoch 134): Loss/seq after 03700 batchs: 496.7004699707031
INFO:root:Train (Epoch 134): Loss/seq after 03750 batchs: 501.04437255859375
INFO:root:Train (Epoch 134): Loss/seq after 03800 batchs: 499.24285888671875
INFO:root:Train (Epoch 134): Loss/seq after 03850 batchs: 498.1447448730469
INFO:root:Train (Epoch 134): Loss/seq after 03900 batchs: 501.24139404296875
INFO:root:Train (Epoch 134): Loss/seq after 03950 batchs: 504.5015563964844
INFO:root:Train (Epoch 134): Loss/seq after 04000 batchs: 501.0739440917969
INFO:root:Train (Epoch 134): Loss/seq after 04050 batchs: 497.9243469238281
INFO:root:Train (Epoch 134): Loss/seq after 04100 batchs: 496.5742492675781
INFO:root:Train (Epoch 134): Loss/seq after 04150 batchs: 496.54827880859375
INFO:root:Train (Epoch 134): Loss/seq after 04200 batchs: 495.2547302246094
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 134): Loss/seq after 04250 batchs: 493.6004333496094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 134): Loss/seq after 00000 batches: 444.9117126464844
INFO:root:# Valid (Epoch 134): Loss/seq after 00050 batches: 584.7035522460938
INFO:root:# Valid (Epoch 134): Loss/seq after 00100 batches: 607.2857055664062
INFO:root:# Valid (Epoch 134): Loss/seq after 00150 batches: 464.9170227050781
wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)
INFO:root:# Valid (Epoch 134): Loss/seq after 00200 batches: 438.41021728515625
INFO:root:Artifacts: Make stick videos for epoch 134
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_134_on_20220413_063214.gif.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_134_index_474_on_20220413_063214.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 135): Loss/seq after 00000 batchs: 937.5689697265625
INFO:root:Train (Epoch 135): Loss/seq after 00050 batchs: 716.4747314453125
INFO:root:Train (Epoch 135): Loss/seq after 00100 batchs: 704.912841796875
INFO:root:Train (Epoch 135): Loss/seq after 00150 batchs: 641.717529296875
INFO:root:Train (Epoch 135): Loss/seq after 00200 batchs: 693.9246826171875
INFO:root:Train (Epoch 135): Loss/seq after 00250 batchs: 765.1434936523438
INFO:root:Train (Epoch 135): Loss/seq after 00300 batchs: 770.8577880859375
INFO:root:Train (Epoch 135): Loss/seq after 00350 batchs: 724.4890747070312
INFO:root:Train (Epoch 135): Loss/seq after 00400 batchs: 719.8592529296875
INFO:root:Train (Epoch 135): Loss/seq after 00450 batchs: 711.919921875
INFO:root:Train (Epoch 135): Loss/seq after 00500 batchs: 689.9871826171875
INFO:root:Train (Epoch 135): Loss/seq after 00550 batchs: 671.0963134765625
INFO:root:Train (Epoch 135): Loss/seq after 00600 batchs: 647.5601196289062
INFO:root:Train (Epoch 135): Loss/seq after 00650 batchs: 624.1412963867188
INFO:root:Train (Epoch 135): Loss/seq after 00700 batchs: 599.6871337890625
INFO:root:Train (Epoch 135): Loss/seq after 00750 batchs: 602.964111328125
INFO:root:Train (Epoch 135): Loss/seq after 00800 batchs: 607.3598022460938
INFO:root:Train (Epoch 135): Loss/seq after 00850 batchs: 587.3655395507812
INFO:root:Train (Epoch 135): Loss/seq after 00900 batchs: 575.4771118164062
INFO:root:Train (Epoch 135): Loss/seq after 00950 batchs: 573.1107177734375
INFO:root:Train (Epoch 135): Loss/seq after 01000 batchs: 564.0164184570312
INFO:root:Train (Epoch 135): Loss/seq after 01050 batchs: 554.4625854492188
INFO:root:Train (Epoch 135): Loss/seq after 01100 batchs: 546.8818359375
INFO:root:Train (Epoch 135): Loss/seq after 01150 batchs: 533.1100463867188
INFO:root:Train (Epoch 135): Loss/seq after 01200 batchs: 538.1142578125
INFO:root:Train (Epoch 135): Loss/seq after 01250 batchs: 537.09619140625
INFO:root:Train (Epoch 135): Loss/seq after 01300 batchs: 526.4593505859375
INFO:root:Train (Epoch 135): Loss/seq after 01350 batchs: 518.2511596679688
INFO:root:Train (Epoch 135): Loss/seq after 01400 batchs: 521.732666015625
INFO:root:Train (Epoch 135): Loss/seq after 01450 batchs: 523.8136596679688
INFO:root:Train (Epoch 135): Loss/seq after 01500 batchs: 531.1864624023438
INFO:root:Train (Epoch 135): Loss/seq after 01550 batchs: 532.190185546875
INFO:root:Train (Epoch 135): Loss/seq after 01600 batchs: 527.3226928710938
INFO:root:Train (Epoch 135): Loss/seq after 01650 batchs: 525.9965209960938
INFO:root:Train (Epoch 135): Loss/seq after 01700 batchs: 529.4529418945312
INFO:root:Train (Epoch 135): Loss/seq after 01750 batchs: 527.0505981445312
INFO:root:Train (Epoch 135): Loss/seq after 01800 batchs: 524.2919311523438
INFO:root:Train (Epoch 135): Loss/seq after 01850 batchs: 521.1157836914062
INFO:root:Train (Epoch 135): Loss/seq after 01900 batchs: 520.5056762695312
INFO:root:Train (Epoch 135): Loss/seq after 01950 batchs: 518.7181396484375
INFO:root:Train (Epoch 135): Loss/seq after 02000 batchs: 518.1734008789062
INFO:root:Train (Epoch 135): Loss/seq after 02050 batchs: 517.5001831054688
INFO:root:Train (Epoch 135): Loss/seq after 02100 batchs: 515.35888671875
INFO:root:Train (Epoch 135): Loss/seq after 02150 batchs: 513.529296875
INFO:root:Train (Epoch 135): Loss/seq after 02200 batchs: 511.17169189453125
INFO:root:Train (Epoch 135): Loss/seq after 02250 batchs: 509.69464111328125
INFO:root:Train (Epoch 135): Loss/seq after 02300 batchs: 506.3993835449219
INFO:root:Train (Epoch 135): Loss/seq after 02350 batchs: 502.8529357910156
INFO:root:Train (Epoch 135): Loss/seq after 02400 batchs: 503.3992614746094
INFO:root:Train (Epoch 135): Loss/seq after 02450 batchs: 499.3880920410156
INFO:root:Train (Epoch 135): Loss/seq after 02500 batchs: 492.17059326171875
INFO:root:Train (Epoch 135): Loss/seq after 02550 batchs: 486.5082702636719
INFO:root:Train (Epoch 135): Loss/seq after 02600 batchs: 485.4415588378906
INFO:root:Train (Epoch 135): Loss/seq after 02650 batchs: 482.4284362792969
INFO:root:Train (Epoch 135): Loss/seq after 02700 batchs: 480.40899658203125
INFO:root:Train (Epoch 135): Loss/seq after 02750 batchs: 478.0876159667969
INFO:root:Train (Epoch 135): Loss/seq after 02800 batchs: 477.44158935546875
INFO:root:Train (Epoch 135): Loss/seq after 02850 batchs: 477.32440185546875
INFO:root:Train (Epoch 135): Loss/seq after 02900 batchs: 478.7879943847656
INFO:root:Train (Epoch 135): Loss/seq after 02950 batchs: 478.2955627441406
INFO:root:Train (Epoch 135): Loss/seq after 03000 batchs: 483.6428527832031
INFO:root:Train (Epoch 135): Loss/seq after 03050 batchs: 485.77362060546875
INFO:root:Train (Epoch 135): Loss/seq after 03100 batchs: 488.5712890625
INFO:root:Train (Epoch 135): Loss/seq after 03150 batchs: 490.6055603027344
INFO:root:Train (Epoch 135): Loss/seq after 03200 batchs: 490.8320007324219
INFO:root:Train (Epoch 135): Loss/seq after 03250 batchs: 493.10284423828125
INFO:root:Train (Epoch 135): Loss/seq after 03300 batchs: 492.3367004394531
INFO:root:Train (Epoch 135): Loss/seq after 03350 batchs: 492.4249267578125
INFO:root:Train (Epoch 135): Loss/seq after 03400 batchs: 488.6744689941406
INFO:root:Train (Epoch 135): Loss/seq after 03450 batchs: 487.610595703125
INFO:root:Train (Epoch 135): Loss/seq after 03500 batchs: 488.8904113769531
INFO:root:Train (Epoch 135): Loss/seq after 03550 batchs: 486.58489990234375
INFO:root:Train (Epoch 135): Loss/seq after 03600 batchs: 493.86871337890625
INFO:root:Train (Epoch 135): Loss/seq after 03650 batchs: 491.89990234375
INFO:root:Train (Epoch 135): Loss/seq after 03700 batchs: 494.38104248046875
INFO:root:Train (Epoch 135): Loss/seq after 03750 batchs: 498.83465576171875
INFO:root:Train (Epoch 135): Loss/seq after 03800 batchs: 497.08978271484375
INFO:root:Train (Epoch 135): Loss/seq after 03850 batchs: 496.02001953125
INFO:root:Train (Epoch 135): Loss/seq after 03900 batchs: 499.2005920410156
INFO:root:Train (Epoch 135): Loss/seq after 03950 batchs: 502.54193115234375
INFO:root:Train (Epoch 135): Loss/seq after 04000 batchs: 499.1302795410156
INFO:root:Train (Epoch 135): Loss/seq after 04050 batchs: 495.9869384765625
INFO:root:Train (Epoch 135): Loss/seq after 04100 batchs: 494.6669921875
INFO:root:Train (Epoch 135): Loss/seq after 04150 batchs: 494.64508056640625
INFO:root:Train (Epoch 135): Loss/seq after 04200 batchs: 493.3749694824219
INFO:root:Train (Epoch 135): Loss/seq after 04250 batchs: 491.72320556640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 135): Loss/seq after 00000 batches: 396.8619079589844
INFO:root:# Valid (Epoch 135): Loss/seq after 00050 batches: 553.249267578125
INFO:root:# Valid (Epoch 135): Loss/seq after 00100 batches: 594.2164916992188
INFO:root:# Valid (Epoch 135): Loss/seq after 00150 batches: 458.0347595214844
INFO:root:# Valid (Epoch 135): Loss/seq after 00200 batches: 432.43927001953125
INFO:root:Artifacts: Make stick videos for epoch 135
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_135_on_20220413_063754.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_135_index_1733_on_20220413_063754.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 136): Loss/seq after 00000 batchs: 841.62744140625
INFO:root:Train (Epoch 136): Loss/seq after 00050 batchs: 688.4696044921875
INFO:root:Train (Epoch 136): Loss/seq after 00100 batchs: 682.5330200195312
INFO:root:Train (Epoch 136): Loss/seq after 00150 batchs: 625.8541870117188
INFO:root:Train (Epoch 136): Loss/seq after 00200 batchs: 688.8335571289062
INFO:root:Train (Epoch 136): Loss/seq after 00250 batchs: 765.4505004882812
INFO:root:Train (Epoch 136): Loss/seq after 00300 batchs: 771.832763671875
INFO:root:Train (Epoch 136): Loss/seq after 00350 batchs: 724.9120483398438
INFO:root:Train (Epoch 136): Loss/seq after 00400 batchs: 718.6773681640625
INFO:root:Train (Epoch 136): Loss/seq after 00450 batchs: 710.9882202148438
INFO:root:Train (Epoch 136): Loss/seq after 00500 batchs: 689.0059814453125
INFO:root:Train (Epoch 136): Loss/seq after 00550 batchs: 670.4338989257812
INFO:root:Train (Epoch 136): Loss/seq after 00600 batchs: 647.588623046875
INFO:root:Train (Epoch 136): Loss/seq after 00650 batchs: 624.4131469726562
INFO:root:Train (Epoch 136): Loss/seq after 00700 batchs: 600.2777709960938
INFO:root:Train (Epoch 136): Loss/seq after 00750 batchs: 603.56005859375
INFO:root:Train (Epoch 136): Loss/seq after 00800 batchs: 608.3355712890625
INFO:root:Train (Epoch 136): Loss/seq after 00850 batchs: 588.3349609375
INFO:root:Train (Epoch 136): Loss/seq after 00900 batchs: 576.4481811523438
INFO:root:Train (Epoch 136): Loss/seq after 00950 batchs: 573.8634033203125
INFO:root:Train (Epoch 136): Loss/seq after 01000 batchs: 565.0886840820312
INFO:root:Train (Epoch 136): Loss/seq after 01050 batchs: 557.2783203125
INFO:root:Train (Epoch 136): Loss/seq after 01100 batchs: 550.0635986328125
INFO:root:Train (Epoch 136): Loss/seq after 01150 batchs: 536.0560302734375
INFO:root:Train (Epoch 136): Loss/seq after 01200 batchs: 541.4782104492188
INFO:root:Train (Epoch 136): Loss/seq after 01250 batchs: 540.3682250976562
INFO:root:Train (Epoch 136): Loss/seq after 01300 batchs: 529.5708618164062
INFO:root:Train (Epoch 136): Loss/seq after 01350 batchs: 520.9967651367188
INFO:root:Train (Epoch 136): Loss/seq after 01400 batchs: 524.142578125
INFO:root:Train (Epoch 136): Loss/seq after 01450 batchs: 526.1412353515625
INFO:root:Train (Epoch 136): Loss/seq after 01500 batchs: 533.0601196289062
INFO:root:Train (Epoch 136): Loss/seq after 01550 batchs: 534.1925048828125
INFO:root:Train (Epoch 136): Loss/seq after 01600 batchs: 529.6557006835938
INFO:root:Train (Epoch 136): Loss/seq after 01650 batchs: 527.8196411132812
INFO:root:Train (Epoch 136): Loss/seq after 01700 batchs: 530.9262084960938
INFO:root:Train (Epoch 136): Loss/seq after 01750 batchs: 528.2598266601562
INFO:root:Train (Epoch 136): Loss/seq after 01800 batchs: 525.300048828125
INFO:root:Train (Epoch 136): Loss/seq after 01850 batchs: 521.9922485351562
INFO:root:Train (Epoch 136): Loss/seq after 01900 batchs: 521.3960571289062
INFO:root:Train (Epoch 136): Loss/seq after 01950 batchs: 519.62744140625
INFO:root:Train (Epoch 136): Loss/seq after 02000 batchs: 519.0428466796875
INFO:root:Train (Epoch 136): Loss/seq after 02050 batchs: 518.2183837890625
INFO:root:Train (Epoch 136): Loss/seq after 02100 batchs: 516.0094604492188
INFO:root:Train (Epoch 136): Loss/seq after 02150 batchs: 514.1285400390625
INFO:root:Train (Epoch 136): Loss/seq after 02200 batchs: 511.6720275878906
INFO:root:Train (Epoch 136): Loss/seq after 02250 batchs: 510.2350158691406
INFO:root:Train (Epoch 136): Loss/seq after 02300 batchs: 507.02752685546875
INFO:root:Train (Epoch 136): Loss/seq after 02350 batchs: 503.4754333496094
INFO:root:Train (Epoch 136): Loss/seq after 02400 batchs: 504.15045166015625
INFO:root:Train (Epoch 136): Loss/seq after 02450 batchs: 500.1686096191406
INFO:root:Train (Epoch 136): Loss/seq after 02500 batchs: 492.9507751464844
INFO:root:Train (Epoch 136): Loss/seq after 02550 batchs: 487.23089599609375
INFO:root:Train (Epoch 136): Loss/seq after 02600 batchs: 486.2325439453125
INFO:root:Train (Epoch 136): Loss/seq after 02650 batchs: 483.12371826171875
INFO:root:Train (Epoch 136): Loss/seq after 02700 batchs: 481.04022216796875
INFO:root:Train (Epoch 136): Loss/seq after 02750 batchs: 478.0445556640625
INFO:root:Train (Epoch 136): Loss/seq after 02800 batchs: 477.1445007324219
INFO:root:Train (Epoch 136): Loss/seq after 02850 batchs: 477.02508544921875
INFO:root:Train (Epoch 136): Loss/seq after 02900 batchs: 478.50067138671875
INFO:root:Train (Epoch 136): Loss/seq after 02950 batchs: 478.0234375
INFO:root:Train (Epoch 136): Loss/seq after 03000 batchs: 483.345703125
INFO:root:Train (Epoch 136): Loss/seq after 03050 batchs: 485.3921813964844
INFO:root:Train (Epoch 136): Loss/seq after 03100 batchs: 488.0625915527344
INFO:root:Train (Epoch 136): Loss/seq after 03150 batchs: 490.1963806152344
INFO:root:Train (Epoch 136): Loss/seq after 03200 batchs: 490.6756896972656
INFO:root:Train (Epoch 136): Loss/seq after 03250 batchs: 492.50537109375
INFO:root:Train (Epoch 136): Loss/seq after 03300 batchs: 491.5632629394531
INFO:root:Train (Epoch 136): Loss/seq after 03350 batchs: 490.8736267089844
INFO:root:Train (Epoch 136): Loss/seq after 03400 batchs: 487.0081481933594
INFO:root:Train (Epoch 136): Loss/seq after 03450 batchs: 485.8482666015625
INFO:root:Train (Epoch 136): Loss/seq after 03500 batchs: 486.64837646484375
INFO:root:Train (Epoch 136): Loss/seq after 03550 batchs: 484.10009765625
INFO:root:Train (Epoch 136): Loss/seq after 03600 batchs: 491.1624450683594
INFO:root:Train (Epoch 136): Loss/seq after 03650 batchs: 489.07470703125
INFO:root:Train (Epoch 136): Loss/seq after 03700 batchs: 491.6181945800781
INFO:root:Train (Epoch 136): Loss/seq after 03750 batchs: 495.9683532714844
INFO:root:Train (Epoch 136): Loss/seq after 03800 batchs: 494.1767272949219
INFO:root:Train (Epoch 136): Loss/seq after 03850 batchs: 493.0986022949219
INFO:root:Train (Epoch 136): Loss/seq after 03900 batchs: 496.2423400878906
INFO:root:Train (Epoch 136): Loss/seq after 03950 batchs: 499.42755126953125
INFO:root:Train (Epoch 136): Loss/seq after 04000 batchs: 496.0579528808594
INFO:root:Train (Epoch 136): Loss/seq after 04050 batchs: 492.9343566894531
INFO:root:Train (Epoch 136): Loss/seq after 04100 batchs: 491.6742858886719
INFO:root:Train (Epoch 136): Loss/seq after 04150 batchs: 491.7206726074219
INFO:root:Train (Epoch 136): Loss/seq after 04200 batchs: 490.469482421875
INFO:root:Train (Epoch 136): Loss/seq after 04250 batchs: 488.9071044921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 136): Loss/seq after 00000 batches: 425.10986328125
INFO:root:# Valid (Epoch 136): Loss/seq after 00050 batches: 552.3569946289062
INFO:root:# Valid (Epoch 136): Loss/seq after 00100 batches: 609.6768798828125
INFO:root:# Valid (Epoch 136): Loss/seq after 00150 batches: 464.65863037109375
INFO:root:# Valid (Epoch 136): Loss/seq after 00200 batches: 435.70672607421875
INFO:root:Artifacts: Make stick videos for epoch 136
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_136_on_20220413_064318.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_136_index_996_on_20220413_064318.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 137): Loss/seq after 00000 batchs: 876.7866821289062
INFO:root:Train (Epoch 137): Loss/seq after 00050 batchs: 703.8862915039062
INFO:root:Train (Epoch 137): Loss/seq after 00100 batchs: 677.9765014648438
INFO:root:Train (Epoch 137): Loss/seq after 00150 batchs: 622.69775390625
INFO:root:Train (Epoch 137): Loss/seq after 00200 batchs: 679.5302124023438
INFO:root:Train (Epoch 137): Loss/seq after 00250 batchs: 755.3687133789062
INFO:root:Train (Epoch 137): Loss/seq after 00300 batchs: 762.5519409179688
INFO:root:Train (Epoch 137): Loss/seq after 00350 batchs: 716.6575927734375
INFO:root:Train (Epoch 137): Loss/seq after 00400 batchs: 708.798828125
INFO:root:Train (Epoch 137): Loss/seq after 00450 batchs: 701.8079833984375
INFO:root:Train (Epoch 137): Loss/seq after 00500 batchs: 680.2178955078125
INFO:root:Train (Epoch 137): Loss/seq after 00550 batchs: 662.3367309570312
INFO:root:Train (Epoch 137): Loss/seq after 00600 batchs: 639.2466430664062
INFO:root:Train (Epoch 137): Loss/seq after 00650 batchs: 616.9241333007812
INFO:root:Train (Epoch 137): Loss/seq after 00700 batchs: 592.4718627929688
INFO:root:Train (Epoch 137): Loss/seq after 00750 batchs: 594.876220703125
INFO:root:Train (Epoch 137): Loss/seq after 00800 batchs: 599.4721069335938
INFO:root:Train (Epoch 137): Loss/seq after 00850 batchs: 579.8729858398438
INFO:root:Train (Epoch 137): Loss/seq after 00900 batchs: 568.2095947265625
INFO:root:Train (Epoch 137): Loss/seq after 00950 batchs: 566.2093505859375
INFO:root:Train (Epoch 137): Loss/seq after 01000 batchs: 556.8356323242188
INFO:root:Train (Epoch 137): Loss/seq after 01050 batchs: 547.35888671875
INFO:root:Train (Epoch 137): Loss/seq after 01100 batchs: 539.8922119140625
INFO:root:Train (Epoch 137): Loss/seq after 01150 batchs: 526.0344848632812
INFO:root:Train (Epoch 137): Loss/seq after 01200 batchs: 530.9133911132812
INFO:root:Train (Epoch 137): Loss/seq after 01250 batchs: 530.2081298828125
INFO:root:Train (Epoch 137): Loss/seq after 01300 batchs: 519.7218627929688
INFO:root:Train (Epoch 137): Loss/seq after 01350 batchs: 511.4172668457031
INFO:root:Train (Epoch 137): Loss/seq after 01400 batchs: 514.636474609375
INFO:root:Train (Epoch 137): Loss/seq after 01450 batchs: 516.7210693359375
INFO:root:Train (Epoch 137): Loss/seq after 01500 batchs: 524.04736328125
INFO:root:Train (Epoch 137): Loss/seq after 01550 batchs: 524.86328125
INFO:root:Train (Epoch 137): Loss/seq after 01600 batchs: 520.0515747070312
INFO:root:Train (Epoch 137): Loss/seq after 01650 batchs: 518.4841918945312
INFO:root:Train (Epoch 137): Loss/seq after 01700 batchs: 521.6870727539062
INFO:root:Train (Epoch 137): Loss/seq after 01750 batchs: 519.331298828125
INFO:root:Train (Epoch 137): Loss/seq after 01800 batchs: 516.6019897460938
INFO:root:Train (Epoch 137): Loss/seq after 01850 batchs: 513.44384765625
INFO:root:Train (Epoch 137): Loss/seq after 01900 batchs: 513.03759765625
INFO:root:Train (Epoch 137): Loss/seq after 01950 batchs: 511.4062194824219
INFO:root:Train (Epoch 137): Loss/seq after 02000 batchs: 511.08551025390625
INFO:root:Train (Epoch 137): Loss/seq after 02050 batchs: 510.3488464355469
INFO:root:Train (Epoch 137): Loss/seq after 02100 batchs: 508.3010559082031
INFO:root:Train (Epoch 137): Loss/seq after 02150 batchs: 506.6048889160156
INFO:root:Train (Epoch 137): Loss/seq after 02200 batchs: 504.28662109375
INFO:root:Train (Epoch 137): Loss/seq after 02250 batchs: 502.80303955078125
INFO:root:Train (Epoch 137): Loss/seq after 02300 batchs: 499.5230712890625
INFO:root:Train (Epoch 137): Loss/seq after 02350 batchs: 496.04296875
INFO:root:Train (Epoch 137): Loss/seq after 02400 batchs: 496.72064208984375
INFO:root:Train (Epoch 137): Loss/seq after 02450 batchs: 492.84991455078125
INFO:root:Train (Epoch 137): Loss/seq after 02500 batchs: 485.77593994140625
INFO:root:Train (Epoch 137): Loss/seq after 02550 batchs: 480.1951599121094
INFO:root:Train (Epoch 137): Loss/seq after 02600 batchs: 479.0995178222656
INFO:root:Train (Epoch 137): Loss/seq after 02650 batchs: 475.97137451171875
INFO:root:Train (Epoch 137): Loss/seq after 02700 batchs: 473.8194885253906
INFO:root:Train (Epoch 137): Loss/seq after 02750 batchs: 470.8575134277344
INFO:root:Train (Epoch 137): Loss/seq after 02800 batchs: 470.19720458984375
INFO:root:Train (Epoch 137): Loss/seq after 02850 batchs: 470.1629333496094
INFO:root:Train (Epoch 137): Loss/seq after 02900 batchs: 471.6099548339844
INFO:root:Train (Epoch 137): Loss/seq after 02950 batchs: 471.2080993652344
INFO:root:Train (Epoch 137): Loss/seq after 03000 batchs: 476.43212890625
INFO:root:Train (Epoch 137): Loss/seq after 03050 batchs: 478.5638122558594
INFO:root:Train (Epoch 137): Loss/seq after 03100 batchs: 481.480712890625
INFO:root:Train (Epoch 137): Loss/seq after 03150 batchs: 483.2210998535156
INFO:root:Train (Epoch 137): Loss/seq after 03200 batchs: 483.6974792480469
INFO:root:Train (Epoch 137): Loss/seq after 03250 batchs: 485.92950439453125
INFO:root:Train (Epoch 137): Loss/seq after 03300 batchs: 485.0489807128906
INFO:root:Train (Epoch 137): Loss/seq after 03350 batchs: 484.3426513671875
INFO:root:Train (Epoch 137): Loss/seq after 03400 batchs: 480.5692138671875
INFO:root:Train (Epoch 137): Loss/seq after 03450 batchs: 479.54827880859375
INFO:root:Train (Epoch 137): Loss/seq after 03500 batchs: 480.5544128417969
INFO:root:Train (Epoch 137): Loss/seq after 03550 batchs: 478.1227111816406
INFO:root:Train (Epoch 137): Loss/seq after 03600 batchs: 485.3577575683594
INFO:root:Train (Epoch 137): Loss/seq after 03650 batchs: 483.3397216796875
INFO:root:Train (Epoch 137): Loss/seq after 03700 batchs: 485.8971862792969
INFO:root:Train (Epoch 137): Loss/seq after 03750 batchs: 490.27294921875
INFO:root:Train (Epoch 137): Loss/seq after 03800 batchs: 488.5882263183594
INFO:root:Train (Epoch 137): Loss/seq after 03850 batchs: 487.4526062011719
INFO:root:Train (Epoch 137): Loss/seq after 03900 batchs: 490.6915283203125
INFO:root:Train (Epoch 137): Loss/seq after 03950 batchs: 494.1371765136719
INFO:root:Train (Epoch 137): Loss/seq after 04000 batchs: 490.7727355957031
INFO:root:Train (Epoch 137): Loss/seq after 04050 batchs: 487.6745910644531
INFO:root:Train (Epoch 137): Loss/seq after 04100 batchs: 486.39947509765625
INFO:root:Train (Epoch 137): Loss/seq after 04150 batchs: 486.4921875
INFO:root:Train (Epoch 137): Loss/seq after 04200 batchs: 485.3302307128906
INFO:root:Train (Epoch 137): Loss/seq after 04250 batchs: 483.70257568359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 137): Loss/seq after 00000 batches: 440.23187255859375
INFO:root:# Valid (Epoch 137): Loss/seq after 00050 batches: 551.7730712890625
INFO:root:# Valid (Epoch 137): Loss/seq after 00100 batches: 599.488525390625
INFO:root:# Valid (Epoch 137): Loss/seq after 00150 batches: 460.788818359375
INFO:root:# Valid (Epoch 137): Loss/seq after 00200 batches: 436.3246154785156
INFO:root:Artifacts: Make stick videos for epoch 137
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_137_on_20220413_064843.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_137_index_100_on_20220413_064843.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 138): Loss/seq after 00000 batchs: 889.3980102539062
INFO:root:Train (Epoch 138): Loss/seq after 00050 batchs: 701.2789306640625
INFO:root:Train (Epoch 138): Loss/seq after 00100 batchs: 671.1842651367188
INFO:root:Train (Epoch 138): Loss/seq after 00150 batchs: 617.1676635742188
INFO:root:Train (Epoch 138): Loss/seq after 00200 batchs: 676.4818725585938
INFO:root:Train (Epoch 138): Loss/seq after 00250 batchs: 749.1506958007812
INFO:root:Train (Epoch 138): Loss/seq after 00300 batchs: 756.679443359375
INFO:root:Train (Epoch 138): Loss/seq after 00350 batchs: 710.5863037109375
INFO:root:Train (Epoch 138): Loss/seq after 00400 batchs: 701.7238159179688
INFO:root:Train (Epoch 138): Loss/seq after 00450 batchs: 695.3884887695312
INFO:root:Train (Epoch 138): Loss/seq after 00500 batchs: 675.1497192382812
INFO:root:Train (Epoch 138): Loss/seq after 00550 batchs: 656.1065673828125
INFO:root:Train (Epoch 138): Loss/seq after 00600 batchs: 633.8040771484375
INFO:root:Train (Epoch 138): Loss/seq after 00650 batchs: 610.8071899414062
INFO:root:Train (Epoch 138): Loss/seq after 00700 batchs: 587.042236328125
INFO:root:Train (Epoch 138): Loss/seq after 00750 batchs: 590.0693969726562
INFO:root:Train (Epoch 138): Loss/seq after 00800 batchs: 595.7400512695312
INFO:root:Train (Epoch 138): Loss/seq after 00850 batchs: 576.2079467773438
INFO:root:Train (Epoch 138): Loss/seq after 00900 batchs: 564.9346313476562
INFO:root:Train (Epoch 138): Loss/seq after 00950 batchs: 563.1493530273438
INFO:root:Train (Epoch 138): Loss/seq after 01000 batchs: 554.3724365234375
INFO:root:Train (Epoch 138): Loss/seq after 01050 batchs: 544.6668701171875
INFO:root:Train (Epoch 138): Loss/seq after 01100 batchs: 537.3191528320312
INFO:root:Train (Epoch 138): Loss/seq after 01150 batchs: 523.5541381835938
INFO:root:Train (Epoch 138): Loss/seq after 01200 batchs: 528.98974609375
INFO:root:Train (Epoch 138): Loss/seq after 01250 batchs: 528.1324462890625
INFO:root:Train (Epoch 138): Loss/seq after 01300 batchs: 517.7236938476562
INFO:root:Train (Epoch 138): Loss/seq after 01350 batchs: 509.3445739746094
INFO:root:Train (Epoch 138): Loss/seq after 01400 batchs: 512.7127685546875
INFO:root:Train (Epoch 138): Loss/seq after 01450 batchs: 514.7791137695312
INFO:root:Train (Epoch 138): Loss/seq after 01500 batchs: 522.1126098632812
INFO:root:Train (Epoch 138): Loss/seq after 01550 batchs: 522.8640747070312
INFO:root:Train (Epoch 138): Loss/seq after 01600 batchs: 518.2152099609375
INFO:root:Train (Epoch 138): Loss/seq after 01650 batchs: 516.7776489257812
INFO:root:Train (Epoch 138): Loss/seq after 01700 batchs: 520.1889038085938
INFO:root:Train (Epoch 138): Loss/seq after 01750 batchs: 517.7734985351562
INFO:root:Train (Epoch 138): Loss/seq after 01800 batchs: 515.0053100585938
INFO:root:Train (Epoch 138): Loss/seq after 01850 batchs: 511.90911865234375
INFO:root:Train (Epoch 138): Loss/seq after 01900 batchs: 511.40643310546875
INFO:root:Train (Epoch 138): Loss/seq after 01950 batchs: 509.7134094238281
INFO:root:Train (Epoch 138): Loss/seq after 02000 batchs: 509.2552185058594
INFO:root:Train (Epoch 138): Loss/seq after 02050 batchs: 508.5959777832031
INFO:root:Train (Epoch 138): Loss/seq after 02100 batchs: 506.6962890625
INFO:root:Train (Epoch 138): Loss/seq after 02150 batchs: 504.9170837402344
INFO:root:Train (Epoch 138): Loss/seq after 02200 batchs: 502.4556579589844
INFO:root:Train (Epoch 138): Loss/seq after 02250 batchs: 500.8099670410156
INFO:root:Train (Epoch 138): Loss/seq after 02300 batchs: 497.51763916015625
INFO:root:Train (Epoch 138): Loss/seq after 02350 batchs: 493.8873291015625
INFO:root:Train (Epoch 138): Loss/seq after 02400 batchs: 494.375
INFO:root:Train (Epoch 138): Loss/seq after 02450 batchs: 490.5234680175781
INFO:root:Train (Epoch 138): Loss/seq after 02500 batchs: 483.4949645996094
INFO:root:Train (Epoch 138): Loss/seq after 02550 batchs: 477.8624572753906
INFO:root:Train (Epoch 138): Loss/seq after 02600 batchs: 476.7259521484375
INFO:root:Train (Epoch 138): Loss/seq after 02650 batchs: 473.6598815917969
INFO:root:Train (Epoch 138): Loss/seq after 02700 batchs: 471.5986328125
INFO:root:Train (Epoch 138): Loss/seq after 02750 batchs: 468.79095458984375
INFO:root:Train (Epoch 138): Loss/seq after 02800 batchs: 468.0355529785156
INFO:root:Train (Epoch 138): Loss/seq after 02850 batchs: 468.0045166015625
INFO:root:Train (Epoch 138): Loss/seq after 02900 batchs: 469.6395568847656
INFO:root:Train (Epoch 138): Loss/seq after 02950 batchs: 469.2313537597656
INFO:root:Train (Epoch 138): Loss/seq after 03000 batchs: 474.5826416015625
INFO:root:Train (Epoch 138): Loss/seq after 03050 batchs: 476.69384765625
INFO:root:Train (Epoch 138): Loss/seq after 03100 batchs: 479.4970397949219
INFO:root:Train (Epoch 138): Loss/seq after 03150 batchs: 481.49639892578125
INFO:root:Train (Epoch 138): Loss/seq after 03200 batchs: 482.1016845703125
INFO:root:Train (Epoch 138): Loss/seq after 03250 batchs: 484.5711975097656
INFO:root:Train (Epoch 138): Loss/seq after 03300 batchs: 484.0177307128906
INFO:root:Train (Epoch 138): Loss/seq after 03350 batchs: 483.5373229980469
INFO:root:Train (Epoch 138): Loss/seq after 03400 batchs: 479.9277648925781
INFO:root:Train (Epoch 138): Loss/seq after 03450 batchs: 478.85943603515625
INFO:root:Train (Epoch 138): Loss/seq after 03500 batchs: 479.8741760253906
INFO:root:Train (Epoch 138): Loss/seq after 03550 batchs: 477.65521240234375
INFO:root:Train (Epoch 138): Loss/seq after 03600 batchs: 485.15777587890625
INFO:root:Train (Epoch 138): Loss/seq after 03650 batchs: 483.08612060546875
INFO:root:Train (Epoch 138): Loss/seq after 03700 batchs: 485.5655517578125
INFO:root:Train (Epoch 138): Loss/seq after 03750 batchs: 489.7908020019531
INFO:root:Train (Epoch 138): Loss/seq after 03800 batchs: 488.1134338378906
INFO:root:Train (Epoch 138): Loss/seq after 03850 batchs: 487.1123046875
INFO:root:Train (Epoch 138): Loss/seq after 03900 batchs: 490.03399658203125
INFO:root:Train (Epoch 138): Loss/seq after 03950 batchs: 493.26849365234375
INFO:root:Train (Epoch 138): Loss/seq after 04000 batchs: 489.9453430175781
INFO:root:Train (Epoch 138): Loss/seq after 04050 batchs: 486.8204650878906
INFO:root:Train (Epoch 138): Loss/seq after 04100 batchs: 485.5804748535156
INFO:root:Train (Epoch 138): Loss/seq after 04150 batchs: 485.6362609863281
INFO:root:Train (Epoch 138): Loss/seq after 04200 batchs: 484.466064453125
INFO:root:Train (Epoch 138): Loss/seq after 04250 batchs: 482.88427734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 138): Loss/seq after 00000 batches: 431.1954650878906
INFO:root:# Valid (Epoch 138): Loss/seq after 00050 batches: 551.1450805664062
INFO:root:# Valid (Epoch 138): Loss/seq after 00100 batches: 592.7312622070312
INFO:root:# Valid (Epoch 138): Loss/seq after 00150 batches: 452.3509826660156
INFO:root:# Valid (Epoch 138): Loss/seq after 00200 batches: 424.8558349609375
INFO:root:Artifacts: Make stick videos for epoch 138
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_138_on_20220413_065406.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_138_index_1267_on_20220413_065406.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 139): Loss/seq after 00000 batchs: 823.3771362304688
INFO:root:Train (Epoch 139): Loss/seq after 00050 batchs: 691.4730834960938
INFO:root:Train (Epoch 139): Loss/seq after 00100 batchs: 669.7398071289062
INFO:root:Train (Epoch 139): Loss/seq after 00150 batchs: 614.7817993164062
INFO:root:Train (Epoch 139): Loss/seq after 00200 batchs: 670.8981323242188
INFO:root:Train (Epoch 139): Loss/seq after 00250 batchs: 742.6536254882812
INFO:root:Train (Epoch 139): Loss/seq after 00300 batchs: 748.2042236328125
INFO:root:Train (Epoch 139): Loss/seq after 00350 batchs: 702.9373779296875
INFO:root:Train (Epoch 139): Loss/seq after 00400 batchs: 694.165283203125
INFO:root:Train (Epoch 139): Loss/seq after 00450 batchs: 689.0368041992188
INFO:root:Train (Epoch 139): Loss/seq after 00500 batchs: 668.5654296875
INFO:root:Train (Epoch 139): Loss/seq after 00550 batchs: 650.4031982421875
INFO:root:Train (Epoch 139): Loss/seq after 00600 batchs: 628.5035400390625
INFO:root:Train (Epoch 139): Loss/seq after 00650 batchs: 605.4710693359375
INFO:root:Train (Epoch 139): Loss/seq after 00700 batchs: 580.9418334960938
INFO:root:Train (Epoch 139): Loss/seq after 00750 batchs: 583.8374633789062
INFO:root:Train (Epoch 139): Loss/seq after 00800 batchs: 589.1998901367188
INFO:root:Train (Epoch 139): Loss/seq after 00850 batchs: 570.12060546875
INFO:root:Train (Epoch 139): Loss/seq after 00900 batchs: 559.1885986328125
INFO:root:Train (Epoch 139): Loss/seq after 00950 batchs: 557.2969970703125
INFO:root:Train (Epoch 139): Loss/seq after 01000 batchs: 548.3161010742188
INFO:root:Train (Epoch 139): Loss/seq after 01050 batchs: 538.5408325195312
INFO:root:Train (Epoch 139): Loss/seq after 01100 batchs: 531.2291870117188
INFO:root:Train (Epoch 139): Loss/seq after 01150 batchs: 517.5946655273438
INFO:root:Train (Epoch 139): Loss/seq after 01200 batchs: 522.871826171875
INFO:root:Train (Epoch 139): Loss/seq after 01250 batchs: 522.1631469726562
INFO:root:Train (Epoch 139): Loss/seq after 01300 batchs: 512.0264892578125
INFO:root:Train (Epoch 139): Loss/seq after 01350 batchs: 504.02386474609375
INFO:root:Train (Epoch 139): Loss/seq after 01400 batchs: 507.3587646484375
INFO:root:Train (Epoch 139): Loss/seq after 01450 batchs: 509.57244873046875
INFO:root:Train (Epoch 139): Loss/seq after 01500 batchs: 517.0432739257812
INFO:root:Train (Epoch 139): Loss/seq after 01550 batchs: 517.621826171875
INFO:root:Train (Epoch 139): Loss/seq after 01600 batchs: 512.9494018554688
INFO:root:Train (Epoch 139): Loss/seq after 01650 batchs: 511.655517578125
INFO:root:Train (Epoch 139): Loss/seq after 01700 batchs: 515.3995361328125
INFO:root:Train (Epoch 139): Loss/seq after 01750 batchs: 513.0934448242188
INFO:root:Train (Epoch 139): Loss/seq after 01800 batchs: 510.33062744140625
INFO:root:Train (Epoch 139): Loss/seq after 01850 batchs: 507.2803039550781
INFO:root:Train (Epoch 139): Loss/seq after 01900 batchs: 506.4330749511719
INFO:root:Train (Epoch 139): Loss/seq after 01950 batchs: 505.07147216796875
INFO:root:Train (Epoch 139): Loss/seq after 02000 batchs: 504.721923828125
INFO:root:Train (Epoch 139): Loss/seq after 02050 batchs: 504.29986572265625
INFO:root:Train (Epoch 139): Loss/seq after 02100 batchs: 502.29052734375
INFO:root:Train (Epoch 139): Loss/seq after 02150 batchs: 500.4256286621094
INFO:root:Train (Epoch 139): Loss/seq after 02200 batchs: 498.0970153808594
INFO:root:Train (Epoch 139): Loss/seq after 02250 batchs: 496.682861328125
INFO:root:Train (Epoch 139): Loss/seq after 02300 batchs: 493.2401428222656
INFO:root:Train (Epoch 139): Loss/seq after 02350 batchs: 489.6910705566406
INFO:root:Train (Epoch 139): Loss/seq after 02400 batchs: 490.34625244140625
INFO:root:Train (Epoch 139): Loss/seq after 02450 batchs: 486.5206604003906
INFO:root:Train (Epoch 139): Loss/seq after 02500 batchs: 479.53997802734375
INFO:root:Train (Epoch 139): Loss/seq after 02550 batchs: 473.85986328125
INFO:root:Train (Epoch 139): Loss/seq after 02600 batchs: 472.7616271972656
INFO:root:Train (Epoch 139): Loss/seq after 02650 batchs: 469.5841979980469
INFO:root:Train (Epoch 139): Loss/seq after 02700 batchs: 467.4624938964844
INFO:root:Train (Epoch 139): Loss/seq after 02750 batchs: 464.60992431640625
INFO:root:Train (Epoch 139): Loss/seq after 02800 batchs: 463.87548828125
INFO:root:Train (Epoch 139): Loss/seq after 02850 batchs: 463.7835388183594
INFO:root:Train (Epoch 139): Loss/seq after 02900 batchs: 465.23663330078125
INFO:root:Train (Epoch 139): Loss/seq after 02950 batchs: 464.9277648925781
INFO:root:Train (Epoch 139): Loss/seq after 03000 batchs: 470.4292907714844
INFO:root:Train (Epoch 139): Loss/seq after 03050 batchs: 472.51123046875
INFO:root:Train (Epoch 139): Loss/seq after 03100 batchs: 475.3404846191406
INFO:root:Train (Epoch 139): Loss/seq after 03150 batchs: 477.0721435546875
INFO:root:Train (Epoch 139): Loss/seq after 03200 batchs: 477.48583984375
INFO:root:Train (Epoch 139): Loss/seq after 03250 batchs: 479.3793640136719
INFO:root:Train (Epoch 139): Loss/seq after 03300 batchs: 478.6470642089844
INFO:root:Train (Epoch 139): Loss/seq after 03350 batchs: 477.8757019042969
INFO:root:Train (Epoch 139): Loss/seq after 03400 batchs: 474.25042724609375
INFO:root:Train (Epoch 139): Loss/seq after 03450 batchs: 473.1827087402344
INFO:root:Train (Epoch 139): Loss/seq after 03500 batchs: 474.5264587402344
INFO:root:Train (Epoch 139): Loss/seq after 03550 batchs: 472.1137390136719
INFO:root:Train (Epoch 139): Loss/seq after 03600 batchs: 479.32147216796875
INFO:root:Train (Epoch 139): Loss/seq after 03650 batchs: 477.3282165527344
INFO:root:Train (Epoch 139): Loss/seq after 03700 batchs: 479.8029479980469
INFO:root:Train (Epoch 139): Loss/seq after 03750 batchs: 484.113525390625
INFO:root:Train (Epoch 139): Loss/seq after 03800 batchs: 482.5360412597656
INFO:root:Train (Epoch 139): Loss/seq after 03850 batchs: 481.5557556152344
INFO:root:Train (Epoch 139): Loss/seq after 03900 batchs: 484.39410400390625
INFO:root:Train (Epoch 139): Loss/seq after 03950 batchs: 487.6585998535156
INFO:root:Train (Epoch 139): Loss/seq after 04000 batchs: 484.37939453125
INFO:root:Train (Epoch 139): Loss/seq after 04050 batchs: 481.3205871582031
INFO:root:Train (Epoch 139): Loss/seq after 04100 batchs: 480.0852966308594
INFO:root:Train (Epoch 139): Loss/seq after 04150 batchs: 480.2056884765625
INFO:root:Train (Epoch 139): Loss/seq after 04200 batchs: 479.0274658203125
INFO:root:Train (Epoch 139): Loss/seq after 04250 batchs: 477.4730529785156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 139): Loss/seq after 00000 batches: 434.19598388671875
INFO:root:# Valid (Epoch 139): Loss/seq after 00050 batches: 568.4237060546875
INFO:root:# Valid (Epoch 139): Loss/seq after 00100 batches: 613.4973754882812
INFO:root:# Valid (Epoch 139): Loss/seq after 00150 batches: 469.1058654785156
INFO:root:# Valid (Epoch 139): Loss/seq after 00200 batches: 440.3395690917969
INFO:root:Artifacts: Make stick videos for epoch 139
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_139_on_20220413_065928.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_139_index_269_on_20220413_065928.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 140): Loss/seq after 00000 batchs: 1020.4146728515625
INFO:root:Train (Epoch 140): Loss/seq after 00050 batchs: 687.3375854492188
INFO:root:Train (Epoch 140): Loss/seq after 00100 batchs: 672.2334594726562
INFO:root:Train (Epoch 140): Loss/seq after 00150 batchs: 611.5813598632812
INFO:root:Train (Epoch 140): Loss/seq after 00200 batchs: 669.9611206054688
INFO:root:Train (Epoch 140): Loss/seq after 00250 batchs: 739.6612548828125
INFO:root:Train (Epoch 140): Loss/seq after 00300 batchs: 746.38232421875
INFO:root:Train (Epoch 140): Loss/seq after 00350 batchs: 700.6927490234375
INFO:root:Train (Epoch 140): Loss/seq after 00400 batchs: 690.3563232421875
INFO:root:Train (Epoch 140): Loss/seq after 00450 batchs: 684.8116455078125
INFO:root:Train (Epoch 140): Loss/seq after 00500 batchs: 663.9520263671875
INFO:root:Train (Epoch 140): Loss/seq after 00550 batchs: 646.2188110351562
INFO:root:Train (Epoch 140): Loss/seq after 00600 batchs: 623.7947387695312
INFO:root:Train (Epoch 140): Loss/seq after 00650 batchs: 600.8753662109375
INFO:root:Train (Epoch 140): Loss/seq after 00700 batchs: 576.7587890625
INFO:root:Train (Epoch 140): Loss/seq after 00750 batchs: 578.9860229492188
INFO:root:Train (Epoch 140): Loss/seq after 00800 batchs: 583.1319580078125
INFO:root:Train (Epoch 140): Loss/seq after 00850 batchs: 564.132080078125
INFO:root:Train (Epoch 140): Loss/seq after 00900 batchs: 552.749755859375
INFO:root:Train (Epoch 140): Loss/seq after 00950 batchs: 550.8366088867188
INFO:root:Train (Epoch 140): Loss/seq after 01000 batchs: 541.7200927734375
INFO:root:Train (Epoch 140): Loss/seq after 01050 batchs: 532.3519897460938
INFO:root:Train (Epoch 140): Loss/seq after 01100 batchs: 524.5270385742188
INFO:root:Train (Epoch 140): Loss/seq after 01150 batchs: 511.06915283203125
INFO:root:Train (Epoch 140): Loss/seq after 01200 batchs: 516.3712768554688
INFO:root:Train (Epoch 140): Loss/seq after 01250 batchs: 516.0092163085938
INFO:root:Train (Epoch 140): Loss/seq after 01300 batchs: 505.9449462890625
INFO:root:Train (Epoch 140): Loss/seq after 01350 batchs: 497.58807373046875
INFO:root:Train (Epoch 140): Loss/seq after 01400 batchs: 500.4847412109375
INFO:root:Train (Epoch 140): Loss/seq after 01450 batchs: 502.688232421875
INFO:root:Train (Epoch 140): Loss/seq after 01500 batchs: 510.2457580566406
INFO:root:Train (Epoch 140): Loss/seq after 01550 batchs: 510.4951171875
INFO:root:Train (Epoch 140): Loss/seq after 01600 batchs: 506.0065002441406
INFO:root:Train (Epoch 140): Loss/seq after 01650 batchs: 504.5647888183594
INFO:root:Train (Epoch 140): Loss/seq after 01700 batchs: 508.0867004394531
INFO:root:Train (Epoch 140): Loss/seq after 01750 batchs: 505.82501220703125
INFO:root:Train (Epoch 140): Loss/seq after 01800 batchs: 503.1989440917969
INFO:root:Train (Epoch 140): Loss/seq after 01850 batchs: 500.3417053222656
INFO:root:Train (Epoch 140): Loss/seq after 01900 batchs: 500.0581359863281
INFO:root:Train (Epoch 140): Loss/seq after 01950 batchs: 498.54510498046875
INFO:root:Train (Epoch 140): Loss/seq after 02000 batchs: 498.34088134765625
INFO:root:Train (Epoch 140): Loss/seq after 02050 batchs: 497.8963623046875
INFO:root:Train (Epoch 140): Loss/seq after 02100 batchs: 496.00628662109375
INFO:root:Train (Epoch 140): Loss/seq after 02150 batchs: 494.22930908203125
INFO:root:Train (Epoch 140): Loss/seq after 02200 batchs: 492.0044860839844
INFO:root:Train (Epoch 140): Loss/seq after 02250 batchs: 490.58026123046875
INFO:root:Train (Epoch 140): Loss/seq after 02300 batchs: 487.5011291503906
INFO:root:Train (Epoch 140): Loss/seq after 02350 batchs: 484.08697509765625
INFO:root:Train (Epoch 140): Loss/seq after 02400 batchs: 484.56201171875
INFO:root:Train (Epoch 140): Loss/seq after 02450 batchs: 480.7934875488281
INFO:root:Train (Epoch 140): Loss/seq after 02500 batchs: 473.94842529296875
INFO:root:Train (Epoch 140): Loss/seq after 02550 batchs: 468.3239440917969
INFO:root:Train (Epoch 140): Loss/seq after 02600 batchs: 467.2964172363281
INFO:root:Train (Epoch 140): Loss/seq after 02650 batchs: 464.2220458984375
INFO:root:Train (Epoch 140): Loss/seq after 02700 batchs: 462.179443359375
INFO:root:Train (Epoch 140): Loss/seq after 02750 batchs: 459.2406921386719
INFO:root:Train (Epoch 140): Loss/seq after 02800 batchs: 458.12982177734375
INFO:root:Train (Epoch 140): Loss/seq after 02850 batchs: 458.26165771484375
INFO:root:Train (Epoch 140): Loss/seq after 02900 batchs: 459.7806091308594
INFO:root:Train (Epoch 140): Loss/seq after 02950 batchs: 459.42620849609375
INFO:root:Train (Epoch 140): Loss/seq after 03000 batchs: 464.9432067871094
INFO:root:Train (Epoch 140): Loss/seq after 03050 batchs: 467.1475830078125
INFO:root:Train (Epoch 140): Loss/seq after 03100 batchs: 469.7338562011719
INFO:root:Train (Epoch 140): Loss/seq after 03150 batchs: 471.72943115234375
INFO:root:Train (Epoch 140): Loss/seq after 03200 batchs: 472.7608642578125
INFO:root:Train (Epoch 140): Loss/seq after 03250 batchs: 474.8904113769531
INFO:root:Train (Epoch 140): Loss/seq after 03300 batchs: 474.0567321777344
INFO:root:Train (Epoch 140): Loss/seq after 03350 batchs: 473.3414001464844
INFO:root:Train (Epoch 140): Loss/seq after 03400 batchs: 469.7210693359375
INFO:root:Train (Epoch 140): Loss/seq after 03450 batchs: 468.7281188964844
INFO:root:Train (Epoch 140): Loss/seq after 03500 batchs: 469.6519470214844
INFO:root:Train (Epoch 140): Loss/seq after 03550 batchs: 467.3589172363281
INFO:root:Train (Epoch 140): Loss/seq after 03600 batchs: 474.60321044921875
INFO:root:Train (Epoch 140): Loss/seq after 03650 batchs: 472.64031982421875
INFO:root:Train (Epoch 140): Loss/seq after 03700 batchs: 475.2989196777344
INFO:root:Train (Epoch 140): Loss/seq after 03750 batchs: 479.64385986328125
INFO:root:Train (Epoch 140): Loss/seq after 03800 batchs: 478.044677734375
INFO:root:Train (Epoch 140): Loss/seq after 03850 batchs: 477.02996826171875
INFO:root:Train (Epoch 140): Loss/seq after 03900 batchs: 480.0062255859375
INFO:root:Train (Epoch 140): Loss/seq after 03950 batchs: 482.9836120605469
INFO:root:Train (Epoch 140): Loss/seq after 04000 batchs: 479.73736572265625
INFO:root:Train (Epoch 140): Loss/seq after 04050 batchs: 476.6943054199219
INFO:root:Train (Epoch 140): Loss/seq after 04100 batchs: 475.5268249511719
INFO:root:Train (Epoch 140): Loss/seq after 04150 batchs: 475.6729431152344
INFO:root:Train (Epoch 140): Loss/seq after 04200 batchs: 474.52606201171875
INFO:root:Train (Epoch 140): Loss/seq after 04250 batchs: 472.943603515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 140): Loss/seq after 00000 batches: 418.5604248046875
INFO:root:# Valid (Epoch 140): Loss/seq after 00050 batches: 559.4188232421875
INFO:root:# Valid (Epoch 140): Loss/seq after 00100 batches: 579.1506958007812
INFO:root:# Valid (Epoch 140): Loss/seq after 00150 batches: 445.6036376953125
INFO:root:# Valid (Epoch 140): Loss/seq after 00200 batches: 421.0020446777344
INFO:root:Artifacts: Make stick videos for epoch 140
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_140_on_20220413_070450.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_140_index_558_on_20220413_070450.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 141): Loss/seq after 00000 batchs: 934.3883666992188
INFO:root:Train (Epoch 141): Loss/seq after 00050 batchs: 678.6643676757812
INFO:root:Train (Epoch 141): Loss/seq after 00100 batchs: 668.9719848632812
INFO:root:Train (Epoch 141): Loss/seq after 00150 batchs: 612.1715698242188
INFO:root:Train (Epoch 141): Loss/seq after 00200 batchs: 664.8989868164062
INFO:root:Train (Epoch 141): Loss/seq after 00250 batchs: 731.2760620117188
INFO:root:Train (Epoch 141): Loss/seq after 00300 batchs: 738.5028686523438
INFO:root:Train (Epoch 141): Loss/seq after 00350 batchs: 694.4511108398438
INFO:root:Train (Epoch 141): Loss/seq after 00400 batchs: 687.0951538085938
INFO:root:Train (Epoch 141): Loss/seq after 00450 batchs: 681.897705078125
INFO:root:Train (Epoch 141): Loss/seq after 00500 batchs: 660.2265625
INFO:root:Train (Epoch 141): Loss/seq after 00550 batchs: 641.6869506835938
INFO:root:Train (Epoch 141): Loss/seq after 00600 batchs: 619.207763671875
INFO:root:Train (Epoch 141): Loss/seq after 00650 batchs: 596.5751953125
INFO:root:Train (Epoch 141): Loss/seq after 00700 batchs: 572.7656860351562
INFO:root:Train (Epoch 141): Loss/seq after 00750 batchs: 574.654541015625
INFO:root:Train (Epoch 141): Loss/seq after 00800 batchs: 579.6932373046875
INFO:root:Train (Epoch 141): Loss/seq after 00850 batchs: 560.99658203125
INFO:root:Train (Epoch 141): Loss/seq after 00900 batchs: 550.3458251953125
INFO:root:Train (Epoch 141): Loss/seq after 00950 batchs: 548.4473876953125
INFO:root:Train (Epoch 141): Loss/seq after 01000 batchs: 539.2426147460938
INFO:root:Train (Epoch 141): Loss/seq after 01050 batchs: 529.8455810546875
INFO:root:Train (Epoch 141): Loss/seq after 01100 batchs: 521.88330078125
INFO:root:Train (Epoch 141): Loss/seq after 01150 batchs: 508.29986572265625
INFO:root:Train (Epoch 141): Loss/seq after 01200 batchs: 513.4291381835938
INFO:root:Train (Epoch 141): Loss/seq after 01250 batchs: 512.8548583984375
INFO:root:Train (Epoch 141): Loss/seq after 01300 batchs: 502.58978271484375
INFO:root:Train (Epoch 141): Loss/seq after 01350 batchs: 494.3497619628906
INFO:root:Train (Epoch 141): Loss/seq after 01400 batchs: 497.72100830078125
INFO:root:Train (Epoch 141): Loss/seq after 01450 batchs: 499.94451904296875
INFO:root:Train (Epoch 141): Loss/seq after 01500 batchs: 507.6039733886719
INFO:root:Train (Epoch 141): Loss/seq after 01550 batchs: 508.173095703125
INFO:root:Train (Epoch 141): Loss/seq after 01600 batchs: 503.6109924316406
INFO:root:Train (Epoch 141): Loss/seq after 01650 batchs: 502.04638671875
INFO:root:Train (Epoch 141): Loss/seq after 01700 batchs: 505.5540771484375
INFO:root:Train (Epoch 141): Loss/seq after 01750 batchs: 503.33648681640625
INFO:root:Train (Epoch 141): Loss/seq after 01800 batchs: 500.774658203125
INFO:root:Train (Epoch 141): Loss/seq after 01850 batchs: 497.8883361816406
INFO:root:Train (Epoch 141): Loss/seq after 01900 batchs: 497.3287353515625
INFO:root:Train (Epoch 141): Loss/seq after 01950 batchs: 495.8914794921875
INFO:root:Train (Epoch 141): Loss/seq after 02000 batchs: 495.7174072265625
INFO:root:Train (Epoch 141): Loss/seq after 02050 batchs: 495.2799987792969
INFO:root:Train (Epoch 141): Loss/seq after 02100 batchs: 493.4453125
INFO:root:Train (Epoch 141): Loss/seq after 02150 batchs: 491.72601318359375
INFO:root:Train (Epoch 141): Loss/seq after 02200 batchs: 489.4549560546875
INFO:root:Train (Epoch 141): Loss/seq after 02250 batchs: 487.9516906738281
INFO:root:Train (Epoch 141): Loss/seq after 02300 batchs: 484.6566467285156
INFO:root:Train (Epoch 141): Loss/seq after 02350 batchs: 481.18438720703125
INFO:root:Train (Epoch 141): Loss/seq after 02400 batchs: 481.7738952636719
INFO:root:Train (Epoch 141): Loss/seq after 02450 batchs: 478.026611328125
INFO:root:Train (Epoch 141): Loss/seq after 02500 batchs: 471.24591064453125
INFO:root:Train (Epoch 141): Loss/seq after 02550 batchs: 465.6511535644531
INFO:root:Train (Epoch 141): Loss/seq after 02600 batchs: 464.587890625
INFO:root:Train (Epoch 141): Loss/seq after 02650 batchs: 461.479248046875
INFO:root:Train (Epoch 141): Loss/seq after 02700 batchs: 459.2412109375
INFO:root:Train (Epoch 141): Loss/seq after 02750 batchs: 456.3168029785156
INFO:root:Train (Epoch 141): Loss/seq after 02800 batchs: 455.37103271484375
INFO:root:Train (Epoch 141): Loss/seq after 02850 batchs: 455.32391357421875
INFO:root:Train (Epoch 141): Loss/seq after 02900 batchs: 456.7380065917969
INFO:root:Train (Epoch 141): Loss/seq after 02950 batchs: 456.3587341308594
INFO:root:Train (Epoch 141): Loss/seq after 03000 batchs: 461.9526672363281
INFO:root:Train (Epoch 141): Loss/seq after 03050 batchs: 464.18487548828125
INFO:root:Train (Epoch 141): Loss/seq after 03100 batchs: 466.8195495605469
INFO:root:Train (Epoch 141): Loss/seq after 03150 batchs: 468.2727355957031
INFO:root:Train (Epoch 141): Loss/seq after 03200 batchs: 468.64959716796875
INFO:root:Train (Epoch 141): Loss/seq after 03250 batchs: 470.7686462402344
INFO:root:Train (Epoch 141): Loss/seq after 03300 batchs: 470.1474609375
INFO:root:Train (Epoch 141): Loss/seq after 03350 batchs: 469.87506103515625
INFO:root:Train (Epoch 141): Loss/seq after 03400 batchs: 466.27996826171875
INFO:root:Train (Epoch 141): Loss/seq after 03450 batchs: 465.28521728515625
INFO:root:Train (Epoch 141): Loss/seq after 03500 batchs: 466.32965087890625
INFO:root:Train (Epoch 141): Loss/seq after 03550 batchs: 463.9632263183594
INFO:root:Train (Epoch 141): Loss/seq after 03600 batchs: 471.00445556640625
INFO:root:Train (Epoch 141): Loss/seq after 03650 batchs: 469.2007751464844
INFO:root:Train (Epoch 141): Loss/seq after 03700 batchs: 471.6224060058594
INFO:root:Train (Epoch 141): Loss/seq after 03750 batchs: 475.9530029296875
INFO:root:Train (Epoch 141): Loss/seq after 03800 batchs: 474.3896179199219
INFO:root:Train (Epoch 141): Loss/seq after 03850 batchs: 473.2762451171875
INFO:root:Train (Epoch 141): Loss/seq after 03900 batchs: 476.20111083984375
INFO:root:Train (Epoch 141): Loss/seq after 03950 batchs: 479.3067626953125
INFO:root:Train (Epoch 141): Loss/seq after 04000 batchs: 476.06524658203125
INFO:root:Train (Epoch 141): Loss/seq after 04050 batchs: 473.0486755371094
INFO:root:Train (Epoch 141): Loss/seq after 04100 batchs: 471.833740234375
INFO:root:Train (Epoch 141): Loss/seq after 04150 batchs: 471.9457092285156
INFO:root:Train (Epoch 141): Loss/seq after 04200 batchs: 470.75665283203125
INFO:root:Train (Epoch 141): Loss/seq after 04250 batchs: 469.21270751953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 141): Loss/seq after 00000 batches: 422.6839904785156
INFO:root:# Valid (Epoch 141): Loss/seq after 00050 batches: 542.5197143554688
INFO:root:# Valid (Epoch 141): Loss/seq after 00100 batches: 578.597412109375
INFO:root:# Valid (Epoch 141): Loss/seq after 00150 batches: 445.85455322265625
INFO:root:# Valid (Epoch 141): Loss/seq after 00200 batches: 421.2492370605469
INFO:root:Artifacts: Make stick videos for epoch 141
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_141_on_20220413_071012.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_141_index_209_on_20220413_071012.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 142): Loss/seq after 00000 batchs: 847.1537475585938
INFO:root:Train (Epoch 142): Loss/seq after 00050 batchs: 687.19873046875
INFO:root:Train (Epoch 142): Loss/seq after 00100 batchs: 661.3220825195312
INFO:root:Train (Epoch 142): Loss/seq after 00150 batchs: 605.577880859375
INFO:root:Train (Epoch 142): Loss/seq after 00200 batchs: 662.9249877929688
INFO:root:Train (Epoch 142): Loss/seq after 00250 batchs: 728.0003051757812
INFO:root:Train (Epoch 142): Loss/seq after 00300 batchs: 734.8653564453125
INFO:root:Train (Epoch 142): Loss/seq after 00350 batchs: 690.66259765625
INFO:root:Train (Epoch 142): Loss/seq after 00400 batchs: 681.53662109375
INFO:root:Train (Epoch 142): Loss/seq after 00450 batchs: 676.4141235351562
INFO:root:Train (Epoch 142): Loss/seq after 00500 batchs: 655.1227416992188
INFO:root:Train (Epoch 142): Loss/seq after 00550 batchs: 638.0194091796875
INFO:root:Train (Epoch 142): Loss/seq after 00600 batchs: 616.1654052734375
INFO:root:Train (Epoch 142): Loss/seq after 00650 batchs: 593.617431640625
INFO:root:Train (Epoch 142): Loss/seq after 00700 batchs: 569.76123046875
INFO:root:Train (Epoch 142): Loss/seq after 00750 batchs: 572.1431884765625
INFO:root:Train (Epoch 142): Loss/seq after 00800 batchs: 576.2965698242188
INFO:root:Train (Epoch 142): Loss/seq after 00850 batchs: 557.8202514648438
INFO:root:Train (Epoch 142): Loss/seq after 00900 batchs: 547.2884521484375
INFO:root:Train (Epoch 142): Loss/seq after 00950 batchs: 545.1275634765625
INFO:root:Train (Epoch 142): Loss/seq after 01000 batchs: 536.4918212890625
INFO:root:Train (Epoch 142): Loss/seq after 01050 batchs: 527.3350830078125
INFO:root:Train (Epoch 142): Loss/seq after 01100 batchs: 519.7561645507812
INFO:root:Train (Epoch 142): Loss/seq after 01150 batchs: 506.3847351074219
INFO:root:Train (Epoch 142): Loss/seq after 01200 batchs: 511.5912780761719
INFO:root:Train (Epoch 142): Loss/seq after 01250 batchs: 511.3172302246094
INFO:root:Train (Epoch 142): Loss/seq after 01300 batchs: 501.0061340332031
INFO:root:Train (Epoch 142): Loss/seq after 01350 batchs: 492.79888916015625
INFO:root:Train (Epoch 142): Loss/seq after 01400 batchs: 495.8497009277344
INFO:root:Train (Epoch 142): Loss/seq after 01450 batchs: 497.9915466308594
INFO:root:Train (Epoch 142): Loss/seq after 01500 batchs: 505.4355163574219
INFO:root:Train (Epoch 142): Loss/seq after 01550 batchs: 506.2801513671875
INFO:root:Train (Epoch 142): Loss/seq after 01600 batchs: 502.0299377441406
INFO:root:Train (Epoch 142): Loss/seq after 01650 batchs: 500.5955505371094
INFO:root:Train (Epoch 142): Loss/seq after 01700 batchs: 504.2830505371094
INFO:root:Train (Epoch 142): Loss/seq after 01750 batchs: 502.0530700683594
INFO:root:Train (Epoch 142): Loss/seq after 01800 batchs: 499.61163330078125
INFO:root:Train (Epoch 142): Loss/seq after 01850 batchs: 496.67071533203125
INFO:root:Train (Epoch 142): Loss/seq after 01900 batchs: 496.4606018066406
INFO:root:Train (Epoch 142): Loss/seq after 01950 batchs: 494.8348388671875
INFO:root:Train (Epoch 142): Loss/seq after 02000 batchs: 494.6755676269531
INFO:root:Train (Epoch 142): Loss/seq after 02050 batchs: 494.3570861816406
INFO:root:Train (Epoch 142): Loss/seq after 02100 batchs: 492.4647216796875
INFO:root:Train (Epoch 142): Loss/seq after 02150 batchs: 490.6981506347656
INFO:root:Train (Epoch 142): Loss/seq after 02200 batchs: 488.3964538574219
INFO:root:Train (Epoch 142): Loss/seq after 02250 batchs: 486.8927307128906
INFO:root:Train (Epoch 142): Loss/seq after 02300 batchs: 483.5877685546875
INFO:root:Train (Epoch 142): Loss/seq after 02350 batchs: 480.208251953125
INFO:root:Train (Epoch 142): Loss/seq after 02400 batchs: 480.70330810546875
INFO:root:Train (Epoch 142): Loss/seq after 02450 batchs: 476.9768981933594
INFO:root:Train (Epoch 142): Loss/seq after 02500 batchs: 470.1431579589844
INFO:root:Train (Epoch 142): Loss/seq after 02550 batchs: 464.4986267089844
INFO:root:Train (Epoch 142): Loss/seq after 02600 batchs: 463.4137878417969
INFO:root:Train (Epoch 142): Loss/seq after 02650 batchs: 460.2838439941406
INFO:root:Train (Epoch 142): Loss/seq after 02700 batchs: 458.1006774902344
INFO:root:Train (Epoch 142): Loss/seq after 02750 batchs: 455.3565673828125
INFO:root:Train (Epoch 142): Loss/seq after 02800 batchs: 454.3893127441406
INFO:root:Train (Epoch 142): Loss/seq after 02850 batchs: 454.3151550292969
INFO:root:Train (Epoch 142): Loss/seq after 02900 batchs: 455.7536315917969
INFO:root:Train (Epoch 142): Loss/seq after 02950 batchs: 455.4464111328125
INFO:root:Train (Epoch 142): Loss/seq after 03000 batchs: 460.90142822265625
INFO:root:Train (Epoch 142): Loss/seq after 03050 batchs: 463.186767578125
INFO:root:Train (Epoch 142): Loss/seq after 03100 batchs: 465.74627685546875
INFO:root:Train (Epoch 142): Loss/seq after 03150 batchs: 467.34283447265625
INFO:root:Train (Epoch 142): Loss/seq after 03200 batchs: 467.5775146484375
INFO:root:Train (Epoch 142): Loss/seq after 03250 batchs: 469.62530517578125
INFO:root:Train (Epoch 142): Loss/seq after 03300 batchs: 469.0696105957031
INFO:root:Train (Epoch 142): Loss/seq after 03350 batchs: 468.6081848144531
INFO:root:Train (Epoch 142): Loss/seq after 03400 batchs: 465.01031494140625
INFO:root:Train (Epoch 142): Loss/seq after 03450 batchs: 463.9927062988281
INFO:root:Train (Epoch 142): Loss/seq after 03500 batchs: 464.9539489746094
INFO:root:Train (Epoch 142): Loss/seq after 03550 batchs: 462.6141357421875
INFO:root:Train (Epoch 142): Loss/seq after 03600 batchs: 469.6593017578125
INFO:root:Train (Epoch 142): Loss/seq after 03650 batchs: 467.7959899902344
INFO:root:Train (Epoch 142): Loss/seq after 03700 batchs: 470.3751220703125
INFO:root:Train (Epoch 142): Loss/seq after 03750 batchs: 474.6473083496094
INFO:root:Train (Epoch 142): Loss/seq after 03800 batchs: 473.1441345214844
INFO:root:Train (Epoch 142): Loss/seq after 03850 batchs: 472.0792236328125
INFO:root:Train (Epoch 142): Loss/seq after 03900 batchs: 474.904296875
INFO:root:Train (Epoch 142): Loss/seq after 03950 batchs: 478.0760192871094
INFO:root:Train (Epoch 142): Loss/seq after 04000 batchs: 474.8755187988281
INFO:root:Train (Epoch 142): Loss/seq after 04050 batchs: 471.890625
INFO:root:Train (Epoch 142): Loss/seq after 04100 batchs: 470.7608947753906
INFO:root:Train (Epoch 142): Loss/seq after 04150 batchs: 470.8703918457031
INFO:root:Train (Epoch 142): Loss/seq after 04200 batchs: 469.73785400390625
INFO:root:Train (Epoch 142): Loss/seq after 04250 batchs: 468.22113037109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 142): Loss/seq after 00000 batches: 380.319580078125
INFO:root:# Valid (Epoch 142): Loss/seq after 00050 batches: 535.4580688476562
INFO:root:# Valid (Epoch 142): Loss/seq after 00100 batches: 588.8560180664062
INFO:root:# Valid (Epoch 142): Loss/seq after 00150 batches: 449.82366943359375
INFO:root:# Valid (Epoch 142): Loss/seq after 00200 batches: 422.3504943847656
INFO:root:Artifacts: Make stick videos for epoch 142
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_142_on_20220413_071533.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_142_index_1864_on_20220413_071533.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 143): Loss/seq after 00000 batchs: 783.30517578125
INFO:root:Train (Epoch 143): Loss/seq after 00050 batchs: 670.815673828125
INFO:root:Train (Epoch 143): Loss/seq after 00100 batchs: 646.5999755859375
INFO:root:Train (Epoch 143): Loss/seq after 00150 batchs: 592.698486328125
INFO:root:Train (Epoch 143): Loss/seq after 00200 batchs: 653.2794189453125
INFO:root:Train (Epoch 143): Loss/seq after 00250 batchs: 719.6043090820312
INFO:root:Train (Epoch 143): Loss/seq after 00300 batchs: 727.1484375
INFO:root:Train (Epoch 143): Loss/seq after 00350 batchs: 684.3804931640625
INFO:root:Train (Epoch 143): Loss/seq after 00400 batchs: 673.6704711914062
INFO:root:Train (Epoch 143): Loss/seq after 00450 batchs: 669.859375
INFO:root:Train (Epoch 143): Loss/seq after 00500 batchs: 650.352783203125
INFO:root:Train (Epoch 143): Loss/seq after 00550 batchs: 633.7784423828125
INFO:root:Train (Epoch 143): Loss/seq after 00600 batchs: 612.305419921875
INFO:root:Train (Epoch 143): Loss/seq after 00650 batchs: 590.220947265625
INFO:root:Train (Epoch 143): Loss/seq after 00700 batchs: 566.0216064453125
INFO:root:Train (Epoch 143): Loss/seq after 00750 batchs: 567.4028930664062
INFO:root:Train (Epoch 143): Loss/seq after 00800 batchs: 572.6932373046875
INFO:root:Train (Epoch 143): Loss/seq after 00850 batchs: 554.3627319335938
INFO:root:Train (Epoch 143): Loss/seq after 00900 batchs: 543.6748657226562
INFO:root:Train (Epoch 143): Loss/seq after 00950 batchs: 540.8292846679688
INFO:root:Train (Epoch 143): Loss/seq after 01000 batchs: 531.941162109375
INFO:root:Train (Epoch 143): Loss/seq after 01050 batchs: 522.6044921875
INFO:root:Train (Epoch 143): Loss/seq after 01100 batchs: 514.5948486328125
INFO:root:Train (Epoch 143): Loss/seq after 01150 batchs: 501.2090148925781
INFO:root:Train (Epoch 143): Loss/seq after 01200 batchs: 506.55816650390625
INFO:root:Train (Epoch 143): Loss/seq after 01250 batchs: 506.3547668457031
INFO:root:Train (Epoch 143): Loss/seq after 01300 batchs: 496.1468505859375
INFO:root:Train (Epoch 143): Loss/seq after 01350 batchs: 488.24896240234375
INFO:root:Train (Epoch 143): Loss/seq after 01400 batchs: 491.78582763671875
INFO:root:Train (Epoch 143): Loss/seq after 01450 batchs: 494.2064514160156
INFO:root:Train (Epoch 143): Loss/seq after 01500 batchs: 501.64886474609375
INFO:root:Train (Epoch 143): Loss/seq after 01550 batchs: 502.5229797363281
INFO:root:Train (Epoch 143): Loss/seq after 01600 batchs: 498.0361022949219
INFO:root:Train (Epoch 143): Loss/seq after 01650 batchs: 496.4154968261719
INFO:root:Train (Epoch 143): Loss/seq after 01700 batchs: 499.8627014160156
INFO:root:Train (Epoch 143): Loss/seq after 01750 batchs: 497.5950622558594
INFO:root:Train (Epoch 143): Loss/seq after 01800 batchs: 495.15008544921875
INFO:root:Train (Epoch 143): Loss/seq after 01850 batchs: 492.3526306152344
INFO:root:Train (Epoch 143): Loss/seq after 01900 batchs: 491.87030029296875
INFO:root:Train (Epoch 143): Loss/seq after 01950 batchs: 490.2992858886719
INFO:root:Train (Epoch 143): Loss/seq after 02000 batchs: 490.2113952636719
INFO:root:Train (Epoch 143): Loss/seq after 02050 batchs: 489.81988525390625
INFO:root:Train (Epoch 143): Loss/seq after 02100 batchs: 488.0126953125
INFO:root:Train (Epoch 143): Loss/seq after 02150 batchs: 486.4175720214844
INFO:root:Train (Epoch 143): Loss/seq after 02200 batchs: 484.16986083984375
INFO:root:Train (Epoch 143): Loss/seq after 02250 batchs: 482.66497802734375
INFO:root:Train (Epoch 143): Loss/seq after 02300 batchs: 479.2793273925781
INFO:root:Train (Epoch 143): Loss/seq after 02350 batchs: 475.8885498046875
INFO:root:Train (Epoch 143): Loss/seq after 02400 batchs: 476.41827392578125
INFO:root:Train (Epoch 143): Loss/seq after 02450 batchs: 472.671875
INFO:root:Train (Epoch 143): Loss/seq after 02500 batchs: 465.9188232421875
INFO:root:Train (Epoch 143): Loss/seq after 02550 batchs: 460.3147277832031
INFO:root:Train (Epoch 143): Loss/seq after 02600 batchs: 459.40386962890625
INFO:root:Train (Epoch 143): Loss/seq after 02650 batchs: 456.1891784667969
INFO:root:Train (Epoch 143): Loss/seq after 02700 batchs: 454.1224670410156
INFO:root:Train (Epoch 143): Loss/seq after 02750 batchs: 451.1563720703125
INFO:root:Train (Epoch 143): Loss/seq after 02800 batchs: 450.0483703613281
INFO:root:Train (Epoch 143): Loss/seq after 02850 batchs: 450.0873107910156
INFO:root:Train (Epoch 143): Loss/seq after 02900 batchs: 451.7655029296875
INFO:root:Train (Epoch 143): Loss/seq after 02950 batchs: 451.4687805175781
INFO:root:Train (Epoch 143): Loss/seq after 03000 batchs: 456.8841857910156
INFO:root:Train (Epoch 143): Loss/seq after 03050 batchs: 459.0666198730469
INFO:root:Train (Epoch 143): Loss/seq after 03100 batchs: 461.4300842285156
INFO:root:Train (Epoch 143): Loss/seq after 03150 batchs: 462.4432678222656
INFO:root:Train (Epoch 143): Loss/seq after 03200 batchs: 462.517578125
INFO:root:Train (Epoch 143): Loss/seq after 03250 batchs: 464.3748474121094
INFO:root:Train (Epoch 143): Loss/seq after 03300 batchs: 463.57177734375
INFO:root:Train (Epoch 143): Loss/seq after 03350 batchs: 462.7232666015625
INFO:root:Train (Epoch 143): Loss/seq after 03400 batchs: 459.2550964355469
INFO:root:Train (Epoch 143): Loss/seq after 03450 batchs: 458.16015625
INFO:root:Train (Epoch 143): Loss/seq after 03500 batchs: 459.20379638671875
INFO:root:Train (Epoch 143): Loss/seq after 03550 batchs: 456.7960205078125
INFO:root:Train (Epoch 143): Loss/seq after 03600 batchs: 463.85760498046875
INFO:root:Train (Epoch 143): Loss/seq after 03650 batchs: 461.98974609375
INFO:root:Train (Epoch 143): Loss/seq after 03700 batchs: 464.5387878417969
INFO:root:Train (Epoch 143): Loss/seq after 03750 batchs: 468.80865478515625
INFO:root:Train (Epoch 143): Loss/seq after 03800 batchs: 467.3175964355469
INFO:root:Train (Epoch 143): Loss/seq after 03850 batchs: 466.3655090332031
INFO:root:Train (Epoch 143): Loss/seq after 03900 batchs: 469.0793151855469
INFO:root:Train (Epoch 143): Loss/seq after 03950 batchs: 472.09246826171875
INFO:root:Train (Epoch 143): Loss/seq after 04000 batchs: 468.9282531738281
INFO:root:Train (Epoch 143): Loss/seq after 04050 batchs: 465.9808654785156
INFO:root:Train (Epoch 143): Loss/seq after 04100 batchs: 464.8806457519531
INFO:root:Train (Epoch 143): Loss/seq after 04150 batchs: 465.0724792480469
INFO:root:Train (Epoch 143): Loss/seq after 04200 batchs: 464.0029602050781
INFO:root:Train (Epoch 143): Loss/seq after 04250 batchs: 462.48199462890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 143): Loss/seq after 00000 batches: 423.9361877441406
INFO:root:# Valid (Epoch 143): Loss/seq after 00050 batches: 535.3616333007812
INFO:root:# Valid (Epoch 143): Loss/seq after 00100 batches: 569.6815185546875
INFO:root:# Valid (Epoch 143): Loss/seq after 00150 batches: 437.1659240722656
INFO:root:# Valid (Epoch 143): Loss/seq after 00200 batches: 412.2240295410156
INFO:root:Artifacts: Make stick videos for epoch 143
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_143_on_20220413_072056.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_143_index_551_on_20220413_072056.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 144): Loss/seq after 00000 batchs: 897.11083984375
INFO:root:Train (Epoch 144): Loss/seq after 00050 batchs: 677.3563232421875
INFO:root:Train (Epoch 144): Loss/seq after 00100 batchs: 646.0293579101562
INFO:root:Train (Epoch 144): Loss/seq after 00150 batchs: 590.0917358398438
INFO:root:Train (Epoch 144): Loss/seq after 00200 batchs: 643.9950561523438
INFO:root:Train (Epoch 144): Loss/seq after 00250 batchs: 713.9110717773438
INFO:root:Train (Epoch 144): Loss/seq after 00300 batchs: 722.125244140625
INFO:root:Train (Epoch 144): Loss/seq after 00350 batchs: 678.751220703125
INFO:root:Train (Epoch 144): Loss/seq after 00400 batchs: 670.5237426757812
INFO:root:Train (Epoch 144): Loss/seq after 00450 batchs: 666.639404296875
INFO:root:Train (Epoch 144): Loss/seq after 00500 batchs: 646.2435913085938
INFO:root:Train (Epoch 144): Loss/seq after 00550 batchs: 629.28515625
INFO:root:Train (Epoch 144): Loss/seq after 00600 batchs: 608.0517578125
INFO:root:Train (Epoch 144): Loss/seq after 00650 batchs: 585.6486206054688
INFO:root:Train (Epoch 144): Loss/seq after 00700 batchs: 562.7466430664062
INFO:root:Train (Epoch 144): Loss/seq after 00750 batchs: 564.60546875
INFO:root:Train (Epoch 144): Loss/seq after 00800 batchs: 569.3984985351562
INFO:root:Train (Epoch 144): Loss/seq after 00850 batchs: 550.7869873046875
INFO:root:Train (Epoch 144): Loss/seq after 00900 batchs: 540.054931640625
INFO:root:Train (Epoch 144): Loss/seq after 00950 batchs: 537.4764404296875
INFO:root:Train (Epoch 144): Loss/seq after 01000 batchs: 528.89892578125
INFO:root:Train (Epoch 144): Loss/seq after 01050 batchs: 519.6830444335938
INFO:root:Train (Epoch 144): Loss/seq after 01100 batchs: 511.47998046875
INFO:root:Train (Epoch 144): Loss/seq after 01150 batchs: 498.18023681640625
INFO:root:Train (Epoch 144): Loss/seq after 01200 batchs: 503.7571105957031
INFO:root:Train (Epoch 144): Loss/seq after 01250 batchs: 503.482666015625
INFO:root:Train (Epoch 144): Loss/seq after 01300 batchs: 493.42645263671875
INFO:root:Train (Epoch 144): Loss/seq after 01350 batchs: 485.8538513183594
INFO:root:Train (Epoch 144): Loss/seq after 01400 batchs: 488.7293701171875
INFO:root:Train (Epoch 144): Loss/seq after 01450 batchs: 490.987060546875
INFO:root:Train (Epoch 144): Loss/seq after 01500 batchs: 498.57586669921875
INFO:root:Train (Epoch 144): Loss/seq after 01550 batchs: 498.8645935058594
INFO:root:Train (Epoch 144): Loss/seq after 01600 batchs: 494.3651123046875
INFO:root:Train (Epoch 144): Loss/seq after 01650 batchs: 492.9600524902344
INFO:root:Train (Epoch 144): Loss/seq after 01700 batchs: 496.6086730957031
INFO:root:Train (Epoch 144): Loss/seq after 01750 batchs: 494.3424072265625
INFO:root:Train (Epoch 144): Loss/seq after 01800 batchs: 491.8349304199219
INFO:root:Train (Epoch 144): Loss/seq after 01850 batchs: 489.1026916503906
INFO:root:Train (Epoch 144): Loss/seq after 01900 batchs: 488.70703125
INFO:root:Train (Epoch 144): Loss/seq after 01950 batchs: 487.2248229980469
INFO:root:Train (Epoch 144): Loss/seq after 02000 batchs: 487.248291015625
INFO:root:Train (Epoch 144): Loss/seq after 02050 batchs: 487.0792236328125
INFO:root:Train (Epoch 144): Loss/seq after 02100 batchs: 485.36322021484375
INFO:root:Train (Epoch 144): Loss/seq after 02150 batchs: 483.66632080078125
INFO:root:Train (Epoch 144): Loss/seq after 02200 batchs: 481.482666015625
INFO:root:Train (Epoch 144): Loss/seq after 02250 batchs: 480.0705871582031
INFO:root:Train (Epoch 144): Loss/seq after 02300 batchs: 476.7506408691406
INFO:root:Train (Epoch 144): Loss/seq after 02350 batchs: 473.3330993652344
INFO:root:Train (Epoch 144): Loss/seq after 02400 batchs: 473.8343811035156
INFO:root:Train (Epoch 144): Loss/seq after 02450 batchs: 470.1092224121094
INFO:root:Train (Epoch 144): Loss/seq after 02500 batchs: 463.42169189453125
INFO:root:Train (Epoch 144): Loss/seq after 02550 batchs: 457.7984619140625
INFO:root:Train (Epoch 144): Loss/seq after 02600 batchs: 456.682861328125
INFO:root:Train (Epoch 144): Loss/seq after 02650 batchs: 453.3342590332031
INFO:root:Train (Epoch 144): Loss/seq after 02700 batchs: 451.1601867675781
INFO:root:Train (Epoch 144): Loss/seq after 02750 batchs: 448.1735534667969
INFO:root:Train (Epoch 144): Loss/seq after 02800 batchs: 446.9190368652344
INFO:root:Train (Epoch 144): Loss/seq after 02850 batchs: 446.97149658203125
INFO:root:Train (Epoch 144): Loss/seq after 02900 batchs: 448.3948974609375
INFO:root:Train (Epoch 144): Loss/seq after 02950 batchs: 448.154296875
INFO:root:Train (Epoch 144): Loss/seq after 03000 batchs: 453.7008361816406
INFO:root:Train (Epoch 144): Loss/seq after 03050 batchs: 455.9222106933594
INFO:root:Train (Epoch 144): Loss/seq after 03100 batchs: 458.31134033203125
INFO:root:Train (Epoch 144): Loss/seq after 03150 batchs: 459.1427917480469
INFO:root:Train (Epoch 144): Loss/seq after 03200 batchs: 459.6578063964844
INFO:root:Train (Epoch 144): Loss/seq after 03250 batchs: 461.6188659667969
INFO:root:Train (Epoch 144): Loss/seq after 03300 batchs: 461.0208740234375
INFO:root:Train (Epoch 144): Loss/seq after 03350 batchs: 460.4294128417969
INFO:root:Train (Epoch 144): Loss/seq after 03400 batchs: 457.0736083984375
INFO:root:Train (Epoch 144): Loss/seq after 03450 batchs: 456.0858154296875
INFO:root:Train (Epoch 144): Loss/seq after 03500 batchs: 457.2103271484375
INFO:root:Train (Epoch 144): Loss/seq after 03550 batchs: 454.9425964355469
INFO:root:Train (Epoch 144): Loss/seq after 03600 batchs: 461.97747802734375
INFO:root:Train (Epoch 144): Loss/seq after 03650 batchs: 460.1858215332031
INFO:root:Train (Epoch 144): Loss/seq after 03700 batchs: 462.76568603515625
INFO:root:Train (Epoch 144): Loss/seq after 03750 batchs: 466.9715270996094
INFO:root:Train (Epoch 144): Loss/seq after 03800 batchs: 465.538818359375
INFO:root:Train (Epoch 144): Loss/seq after 03850 batchs: 464.5196533203125
INFO:root:Train (Epoch 144): Loss/seq after 03900 batchs: 467.2611389160156
INFO:root:Train (Epoch 144): Loss/seq after 03950 batchs: 470.1833801269531
INFO:root:Train (Epoch 144): Loss/seq after 04000 batchs: 467.03851318359375
INFO:root:Train (Epoch 144): Loss/seq after 04050 batchs: 464.0840148925781
INFO:root:Train (Epoch 144): Loss/seq after 04100 batchs: 462.9714050292969
INFO:root:Train (Epoch 144): Loss/seq after 04150 batchs: 463.05706787109375
INFO:root:Train (Epoch 144): Loss/seq after 04200 batchs: 461.99334716796875
INFO:root:Train (Epoch 144): Loss/seq after 04250 batchs: 460.5031433105469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 144): Loss/seq after 00000 batches: 391.59881591796875
INFO:root:# Valid (Epoch 144): Loss/seq after 00050 batches: 543.2612915039062
INFO:root:# Valid (Epoch 144): Loss/seq after 00100 batches: 574.0118408203125
INFO:root:# Valid (Epoch 144): Loss/seq after 00150 batches: 439.5300598144531
INFO:root:# Valid (Epoch 144): Loss/seq after 00200 batches: 416.5260314941406
INFO:root:Artifacts: Make stick videos for epoch 144
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_144_on_20220413_072616.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_144_index_241_on_20220413_072616.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 145): Loss/seq after 00000 batchs: 817.8723754882812
INFO:root:Train (Epoch 145): Loss/seq after 00050 batchs: 677.7898559570312
INFO:root:Train (Epoch 145): Loss/seq after 00100 batchs: 643.9002685546875
INFO:root:Train (Epoch 145): Loss/seq after 00150 batchs: 590.7576904296875
INFO:root:Train (Epoch 145): Loss/seq after 00200 batchs: 641.0914306640625
INFO:root:Train (Epoch 145): Loss/seq after 00250 batchs: 711.7423095703125
INFO:root:Train (Epoch 145): Loss/seq after 00300 batchs: 720.7362670898438
INFO:root:Train (Epoch 145): Loss/seq after 00350 batchs: 678.7587280273438
INFO:root:Train (Epoch 145): Loss/seq after 00400 batchs: 668.5302734375
INFO:root:Train (Epoch 145): Loss/seq after 00450 batchs: 665.2030639648438
INFO:root:Train (Epoch 145): Loss/seq after 00500 batchs: 646.235107421875
INFO:root:Train (Epoch 145): Loss/seq after 00550 batchs: 629.1207275390625
INFO:root:Train (Epoch 145): Loss/seq after 00600 batchs: 607.2421875
INFO:root:Train (Epoch 145): Loss/seq after 00650 batchs: 585.8776245117188
INFO:root:Train (Epoch 145): Loss/seq after 00700 batchs: 562.9193115234375
INFO:root:Train (Epoch 145): Loss/seq after 00750 batchs: 563.5820922851562
INFO:root:Train (Epoch 145): Loss/seq after 00800 batchs: 568.2879028320312
INFO:root:Train (Epoch 145): Loss/seq after 00850 batchs: 550.09619140625
INFO:root:Train (Epoch 145): Loss/seq after 00900 batchs: 539.3645629882812
INFO:root:Train (Epoch 145): Loss/seq after 00950 batchs: 537.5816650390625
INFO:root:Train (Epoch 145): Loss/seq after 01000 batchs: 528.585693359375
INFO:root:Train (Epoch 145): Loss/seq after 01050 batchs: 519.1876831054688
INFO:root:Train (Epoch 145): Loss/seq after 01100 batchs: 511.08563232421875
INFO:root:Train (Epoch 145): Loss/seq after 01150 batchs: 497.6140441894531
INFO:root:Train (Epoch 145): Loss/seq after 01200 batchs: 502.7294006347656
INFO:root:Train (Epoch 145): Loss/seq after 01250 batchs: 502.3007507324219
INFO:root:Train (Epoch 145): Loss/seq after 01300 batchs: 492.1455993652344
INFO:root:Train (Epoch 145): Loss/seq after 01350 batchs: 484.16827392578125
INFO:root:Train (Epoch 145): Loss/seq after 01400 batchs: 487.4599304199219
INFO:root:Train (Epoch 145): Loss/seq after 01450 batchs: 489.678955078125
INFO:root:Train (Epoch 145): Loss/seq after 01500 batchs: 497.18243408203125
INFO:root:Train (Epoch 145): Loss/seq after 01550 batchs: 497.5771484375
INFO:root:Train (Epoch 145): Loss/seq after 01600 batchs: 492.9945983886719
INFO:root:Train (Epoch 145): Loss/seq after 01650 batchs: 491.2071228027344
INFO:root:Train (Epoch 145): Loss/seq after 01700 batchs: 494.9325256347656
INFO:root:Train (Epoch 145): Loss/seq after 01750 batchs: 492.8912353515625
INFO:root:Train (Epoch 145): Loss/seq after 01800 batchs: 490.46826171875
INFO:root:Train (Epoch 145): Loss/seq after 01850 batchs: 487.8092041015625
INFO:root:Train (Epoch 145): Loss/seq after 01900 batchs: 487.17962646484375
INFO:root:Train (Epoch 145): Loss/seq after 01950 batchs: 485.7560119628906
INFO:root:Train (Epoch 145): Loss/seq after 02000 batchs: 485.76641845703125
INFO:root:Train (Epoch 145): Loss/seq after 02050 batchs: 485.44976806640625
INFO:root:Train (Epoch 145): Loss/seq after 02100 batchs: 483.66754150390625
INFO:root:Train (Epoch 145): Loss/seq after 02150 batchs: 481.9978942871094
INFO:root:Train (Epoch 145): Loss/seq after 02200 batchs: 479.80718994140625
INFO:root:Train (Epoch 145): Loss/seq after 02250 batchs: 478.5840148925781
INFO:root:Train (Epoch 145): Loss/seq after 02300 batchs: 475.54290771484375
INFO:root:Train (Epoch 145): Loss/seq after 02350 batchs: 472.1934814453125
INFO:root:Train (Epoch 145): Loss/seq after 02400 batchs: 472.6741638183594
INFO:root:Train (Epoch 145): Loss/seq after 02450 batchs: 468.99224853515625
INFO:root:Train (Epoch 145): Loss/seq after 02500 batchs: 462.33056640625
INFO:root:Train (Epoch 145): Loss/seq after 02550 batchs: 456.6910095214844
INFO:root:Train (Epoch 145): Loss/seq after 02600 batchs: 455.4862365722656
INFO:root:Train (Epoch 145): Loss/seq after 02650 batchs: 452.15313720703125
INFO:root:Train (Epoch 145): Loss/seq after 02700 batchs: 449.8690490722656
INFO:root:Train (Epoch 145): Loss/seq after 02750 batchs: 447.0282287597656
INFO:root:Train (Epoch 145): Loss/seq after 02800 batchs: 445.8576354980469
INFO:root:Train (Epoch 145): Loss/seq after 02850 batchs: 445.869140625
INFO:root:Train (Epoch 145): Loss/seq after 02900 batchs: 447.41314697265625
INFO:root:Train (Epoch 145): Loss/seq after 02950 batchs: 447.1364440917969
INFO:root:Train (Epoch 145): Loss/seq after 03000 batchs: 452.6913757324219
INFO:root:Train (Epoch 145): Loss/seq after 03050 batchs: 454.8185729980469
INFO:root:Train (Epoch 145): Loss/seq after 03100 batchs: 457.16729736328125
INFO:root:Train (Epoch 145): Loss/seq after 03150 batchs: 458.9883728027344
INFO:root:Train (Epoch 145): Loss/seq after 03200 batchs: 459.037109375
INFO:root:Train (Epoch 145): Loss/seq after 03250 batchs: 461.0405578613281
INFO:root:Train (Epoch 145): Loss/seq after 03300 batchs: 460.35919189453125
INFO:root:Train (Epoch 145): Loss/seq after 03350 batchs: 459.7666320800781
INFO:root:Train (Epoch 145): Loss/seq after 03400 batchs: 456.2179870605469
INFO:root:Train (Epoch 145): Loss/seq after 03450 batchs: 455.1747131347656
INFO:root:Train (Epoch 145): Loss/seq after 03500 batchs: 456.1895751953125
INFO:root:Train (Epoch 145): Loss/seq after 03550 batchs: 453.83319091796875
INFO:root:Train (Epoch 145): Loss/seq after 03600 batchs: 460.7705383300781
INFO:root:Train (Epoch 145): Loss/seq after 03650 batchs: 458.9920349121094
INFO:root:Train (Epoch 145): Loss/seq after 03700 batchs: 461.5909729003906
INFO:root:Train (Epoch 145): Loss/seq after 03750 batchs: 465.88153076171875
INFO:root:Train (Epoch 145): Loss/seq after 03800 batchs: 464.3978576660156
INFO:root:Train (Epoch 145): Loss/seq after 03850 batchs: 463.4484558105469
INFO:root:Train (Epoch 145): Loss/seq after 03900 batchs: 466.10943603515625
INFO:root:Train (Epoch 145): Loss/seq after 03950 batchs: 469.0977478027344
INFO:root:Train (Epoch 145): Loss/seq after 04000 batchs: 465.9888610839844
INFO:root:Train (Epoch 145): Loss/seq after 04050 batchs: 463.052734375
INFO:root:Train (Epoch 145): Loss/seq after 04100 batchs: 461.8899841308594
INFO:root:Train (Epoch 145): Loss/seq after 04150 batchs: 461.9956359863281
INFO:root:Train (Epoch 145): Loss/seq after 04200 batchs: 460.9170227050781
INFO:root:Train (Epoch 145): Loss/seq after 04250 batchs: 459.4318542480469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 145): Loss/seq after 00000 batches: 374.1029052734375
INFO:root:# Valid (Epoch 145): Loss/seq after 00050 batches: 539.7349243164062
INFO:root:# Valid (Epoch 145): Loss/seq after 00100 batches: 570.7196044921875
INFO:root:# Valid (Epoch 145): Loss/seq after 00150 batches: 438.6524353027344
INFO:root:# Valid (Epoch 145): Loss/seq after 00200 batches: 415.26605224609375
INFO:root:Artifacts: Make stick videos for epoch 145
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_145_on_20220413_073136.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_145_index_757_on_20220413_073136.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 146): Loss/seq after 00000 batchs: 875.47705078125
INFO:root:Train (Epoch 146): Loss/seq after 00050 batchs: 673.8679809570312
INFO:root:Train (Epoch 146): Loss/seq after 00100 batchs: 641.5260009765625
INFO:root:Train (Epoch 146): Loss/seq after 00150 batchs: 587.54833984375
INFO:root:Train (Epoch 146): Loss/seq after 00200 batchs: 636.0860595703125
INFO:root:Train (Epoch 146): Loss/seq after 00250 batchs: 702.642822265625
INFO:root:Train (Epoch 146): Loss/seq after 00300 batchs: 710.8057250976562
INFO:root:Train (Epoch 146): Loss/seq after 00350 batchs: 668.4655151367188
INFO:root:Train (Epoch 146): Loss/seq after 00400 batchs: 656.0089721679688
INFO:root:Train (Epoch 146): Loss/seq after 00450 batchs: 653.1787719726562
INFO:root:Train (Epoch 146): Loss/seq after 00500 batchs: 632.6896362304688
INFO:root:Train (Epoch 146): Loss/seq after 00550 batchs: 616.687255859375
INFO:root:Train (Epoch 146): Loss/seq after 00600 batchs: 596.1381225585938
INFO:root:Train (Epoch 146): Loss/seq after 00650 batchs: 573.960205078125
INFO:root:Train (Epoch 146): Loss/seq after 00700 batchs: 551.7036743164062
INFO:root:Train (Epoch 146): Loss/seq after 00750 batchs: 553.439453125
INFO:root:Train (Epoch 146): Loss/seq after 00800 batchs: 560.1534423828125
INFO:root:Train (Epoch 146): Loss/seq after 00850 batchs: 542.159423828125
INFO:root:Train (Epoch 146): Loss/seq after 00900 batchs: 531.8510131835938
INFO:root:Train (Epoch 146): Loss/seq after 00950 batchs: 529.22998046875
INFO:root:Train (Epoch 146): Loss/seq after 01000 batchs: 520.9105224609375
INFO:root:Train (Epoch 146): Loss/seq after 01050 batchs: 511.9355163574219
INFO:root:Train (Epoch 146): Loss/seq after 01100 batchs: 503.8941955566406
INFO:root:Train (Epoch 146): Loss/seq after 01150 batchs: 490.9695129394531
INFO:root:Train (Epoch 146): Loss/seq after 01200 batchs: 495.8567810058594
INFO:root:Train (Epoch 146): Loss/seq after 01250 batchs: 495.1631164550781
INFO:root:Train (Epoch 146): Loss/seq after 01300 batchs: 485.6600646972656
INFO:root:Train (Epoch 146): Loss/seq after 01350 batchs: 478.2641296386719
INFO:root:Train (Epoch 146): Loss/seq after 01400 batchs: 481.2982177734375
INFO:root:Train (Epoch 146): Loss/seq after 01450 batchs: 483.6763916015625
INFO:root:Train (Epoch 146): Loss/seq after 01500 batchs: 491.3706359863281
INFO:root:Train (Epoch 146): Loss/seq after 01550 batchs: 491.8837585449219
INFO:root:Train (Epoch 146): Loss/seq after 01600 batchs: 487.5294189453125
INFO:root:Train (Epoch 146): Loss/seq after 01650 batchs: 486.2294921875
INFO:root:Train (Epoch 146): Loss/seq after 01700 batchs: 490.1684265136719
INFO:root:Train (Epoch 146): Loss/seq after 01750 batchs: 488.03546142578125
INFO:root:Train (Epoch 146): Loss/seq after 01800 batchs: 485.5697326660156
INFO:root:Train (Epoch 146): Loss/seq after 01850 batchs: 482.9007873535156
INFO:root:Train (Epoch 146): Loss/seq after 01900 batchs: 482.52752685546875
INFO:root:Train (Epoch 146): Loss/seq after 01950 batchs: 481.3106384277344
INFO:root:Train (Epoch 146): Loss/seq after 02000 batchs: 481.3441162109375
INFO:root:Train (Epoch 146): Loss/seq after 02050 batchs: 481.2424011230469
INFO:root:Train (Epoch 146): Loss/seq after 02100 batchs: 479.59844970703125
INFO:root:Train (Epoch 146): Loss/seq after 02150 batchs: 477.8743896484375
INFO:root:Train (Epoch 146): Loss/seq after 02200 batchs: 475.7115783691406
INFO:root:Train (Epoch 146): Loss/seq after 02250 batchs: 474.2540588378906
INFO:root:Train (Epoch 146): Loss/seq after 02300 batchs: 471.1085205078125
INFO:root:Train (Epoch 146): Loss/seq after 02350 batchs: 467.77398681640625
INFO:root:Train (Epoch 146): Loss/seq after 02400 batchs: 468.37860107421875
INFO:root:Train (Epoch 146): Loss/seq after 02450 batchs: 464.8952331542969
INFO:root:Train (Epoch 146): Loss/seq after 02500 batchs: 458.2749328613281
INFO:root:Train (Epoch 146): Loss/seq after 02550 batchs: 452.65106201171875
INFO:root:Train (Epoch 146): Loss/seq after 02600 batchs: 451.5333557128906
INFO:root:Train (Epoch 146): Loss/seq after 02650 batchs: 448.1761169433594
INFO:root:Train (Epoch 146): Loss/seq after 02700 batchs: 445.9393005371094
INFO:root:Train (Epoch 146): Loss/seq after 02750 batchs: 443.18212890625
INFO:root:Train (Epoch 146): Loss/seq after 02800 batchs: 442.1766357421875
INFO:root:Train (Epoch 146): Loss/seq after 02850 batchs: 442.2521667480469
INFO:root:Train (Epoch 146): Loss/seq after 02900 batchs: 443.6068420410156
INFO:root:Train (Epoch 146): Loss/seq after 02950 batchs: 443.4090576171875
INFO:root:Train (Epoch 146): Loss/seq after 03000 batchs: 448.9295349121094
INFO:root:Train (Epoch 146): Loss/seq after 03050 batchs: 451.2355041503906
INFO:root:Train (Epoch 146): Loss/seq after 03100 batchs: 453.7198486328125
INFO:root:Train (Epoch 146): Loss/seq after 03150 batchs: 455.01202392578125
INFO:root:Train (Epoch 146): Loss/seq after 03200 batchs: 455.3498840332031
INFO:root:Train (Epoch 146): Loss/seq after 03250 batchs: 457.0909729003906
INFO:root:Train (Epoch 146): Loss/seq after 03300 batchs: 456.3904113769531
INFO:root:Train (Epoch 146): Loss/seq after 03350 batchs: 455.9083251953125
INFO:root:Train (Epoch 146): Loss/seq after 03400 batchs: 452.47003173828125
INFO:root:Train (Epoch 146): Loss/seq after 03450 batchs: 451.48724365234375
INFO:root:Train (Epoch 146): Loss/seq after 03500 batchs: 452.34918212890625
INFO:root:Train (Epoch 146): Loss/seq after 03550 batchs: 450.1988830566406
INFO:root:Train (Epoch 146): Loss/seq after 03600 batchs: 457.1412048339844
INFO:root:Train (Epoch 146): Loss/seq after 03650 batchs: 455.3405456542969
INFO:root:Train (Epoch 146): Loss/seq after 03700 batchs: 457.7832336425781
INFO:root:Train (Epoch 146): Loss/seq after 03750 batchs: 462.0424499511719
INFO:root:Train (Epoch 146): Loss/seq after 03800 batchs: 460.6234130859375
INFO:root:Train (Epoch 146): Loss/seq after 03850 batchs: 459.5772705078125
INFO:root:Train (Epoch 146): Loss/seq after 03900 batchs: 462.35186767578125
INFO:root:Train (Epoch 146): Loss/seq after 03950 batchs: 465.380615234375
INFO:root:Train (Epoch 146): Loss/seq after 04000 batchs: 462.29193115234375
INFO:root:Train (Epoch 146): Loss/seq after 04050 batchs: 459.3712158203125
INFO:root:Train (Epoch 146): Loss/seq after 04100 batchs: 458.2008361816406
INFO:root:Train (Epoch 146): Loss/seq after 04150 batchs: 458.33648681640625
INFO:root:Train (Epoch 146): Loss/seq after 04200 batchs: 457.2030029296875
INFO:root:Train (Epoch 146): Loss/seq after 04250 batchs: 455.7018127441406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 146): Loss/seq after 00000 batches: 374.5528869628906
INFO:root:# Valid (Epoch 146): Loss/seq after 00050 batches: 533.117919921875
INFO:root:# Valid (Epoch 146): Loss/seq after 00100 batches: 564.54345703125
INFO:root:# Valid (Epoch 146): Loss/seq after 00150 batches: 431.2518310546875
INFO:root:# Valid (Epoch 146): Loss/seq after 00200 batches: 406.0646667480469
INFO:root:Artifacts: Make stick videos for epoch 146
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_146_on_20220413_073658.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_146_index_416_on_20220413_073658.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 147): Loss/seq after 00000 batchs: 819.837646484375
INFO:root:Train (Epoch 147): Loss/seq after 00050 batchs: 655.6766967773438
INFO:root:Train (Epoch 147): Loss/seq after 00100 batchs: 636.1054077148438
INFO:root:Train (Epoch 147): Loss/seq after 00150 batchs: 580.99609375
INFO:root:Train (Epoch 147): Loss/seq after 00200 batchs: 640.3917236328125
INFO:root:Train (Epoch 147): Loss/seq after 00250 batchs: 712.87744140625
INFO:root:Train (Epoch 147): Loss/seq after 00300 batchs: 719.6597290039062
INFO:root:Train (Epoch 147): Loss/seq after 00350 batchs: 676.7965698242188
INFO:root:Train (Epoch 147): Loss/seq after 00400 batchs: 664.734619140625
INFO:root:Train (Epoch 147): Loss/seq after 00450 batchs: 660.970947265625
INFO:root:Train (Epoch 147): Loss/seq after 00500 batchs: 639.8099975585938
INFO:root:Train (Epoch 147): Loss/seq after 00550 batchs: 622.7258911132812
INFO:root:Train (Epoch 147): Loss/seq after 00600 batchs: 601.8958740234375
INFO:root:Train (Epoch 147): Loss/seq after 00650 batchs: 578.8475952148438
INFO:root:Train (Epoch 147): Loss/seq after 00700 batchs: 555.742919921875
INFO:root:Train (Epoch 147): Loss/seq after 00750 batchs: 555.5244750976562
INFO:root:Train (Epoch 147): Loss/seq after 00800 batchs: 560.6627807617188
INFO:root:Train (Epoch 147): Loss/seq after 00850 batchs: 542.932861328125
INFO:root:Train (Epoch 147): Loss/seq after 00900 batchs: 533.1353149414062
INFO:root:Train (Epoch 147): Loss/seq after 00950 batchs: 530.6873168945312
INFO:root:Train (Epoch 147): Loss/seq after 01000 batchs: 522.1173706054688
INFO:root:Train (Epoch 147): Loss/seq after 01050 batchs: 513.2793579101562
INFO:root:Train (Epoch 147): Loss/seq after 01100 batchs: 505.4438781738281
INFO:root:Train (Epoch 147): Loss/seq after 01150 batchs: 492.3199157714844
INFO:root:Train (Epoch 147): Loss/seq after 01200 batchs: 497.4716491699219
INFO:root:Train (Epoch 147): Loss/seq after 01250 batchs: 497.38623046875
INFO:root:Train (Epoch 147): Loss/seq after 01300 batchs: 487.2284240722656
INFO:root:Train (Epoch 147): Loss/seq after 01350 batchs: 479.7852783203125
INFO:root:Train (Epoch 147): Loss/seq after 01400 batchs: 482.4627990722656
INFO:root:Train (Epoch 147): Loss/seq after 01450 batchs: 485.0366516113281
INFO:root:Train (Epoch 147): Loss/seq after 01500 batchs: 492.5631103515625
INFO:root:Train (Epoch 147): Loss/seq after 01550 batchs: 493.5494384765625
INFO:root:Train (Epoch 147): Loss/seq after 01600 batchs: 489.0666198730469
INFO:root:Train (Epoch 147): Loss/seq after 01650 batchs: 487.2459411621094
INFO:root:Train (Epoch 147): Loss/seq after 01700 batchs: 491.0955505371094
INFO:root:Train (Epoch 147): Loss/seq after 01750 batchs: 488.8277587890625
INFO:root:Train (Epoch 147): Loss/seq after 01800 batchs: 486.5289306640625
INFO:root:Train (Epoch 147): Loss/seq after 01850 batchs: 483.82989501953125
INFO:root:Train (Epoch 147): Loss/seq after 01900 batchs: 483.1322326660156
INFO:root:Train (Epoch 147): Loss/seq after 01950 batchs: 481.5160827636719
INFO:root:Train (Epoch 147): Loss/seq after 02000 batchs: 481.50286865234375
INFO:root:Train (Epoch 147): Loss/seq after 02050 batchs: 481.20465087890625
INFO:root:Train (Epoch 147): Loss/seq after 02100 batchs: 479.3270263671875
INFO:root:Train (Epoch 147): Loss/seq after 02150 batchs: 477.68365478515625
INFO:root:Train (Epoch 147): Loss/seq after 02200 batchs: 475.6180114746094
INFO:root:Train (Epoch 147): Loss/seq after 02250 batchs: 474.0668640136719
INFO:root:Train (Epoch 147): Loss/seq after 02300 batchs: 470.8061218261719
INFO:root:Train (Epoch 147): Loss/seq after 02350 batchs: 467.4519348144531
INFO:root:Train (Epoch 147): Loss/seq after 02400 batchs: 467.9513244628906
INFO:root:Train (Epoch 147): Loss/seq after 02450 batchs: 464.27227783203125
INFO:root:Train (Epoch 147): Loss/seq after 02500 batchs: 457.6529846191406
INFO:root:Train (Epoch 147): Loss/seq after 02550 batchs: 451.9846496582031
INFO:root:Train (Epoch 147): Loss/seq after 02600 batchs: 450.8203125
INFO:root:Train (Epoch 147): Loss/seq after 02650 batchs: 447.44610595703125
INFO:root:Train (Epoch 147): Loss/seq after 02700 batchs: 445.0522155761719
INFO:root:Train (Epoch 147): Loss/seq after 02750 batchs: 442.0873107910156
INFO:root:Train (Epoch 147): Loss/seq after 02800 batchs: 440.880615234375
INFO:root:Train (Epoch 147): Loss/seq after 02850 batchs: 440.842041015625
INFO:root:Train (Epoch 147): Loss/seq after 02900 batchs: 442.05816650390625
INFO:root:Train (Epoch 147): Loss/seq after 02950 batchs: 441.8598327636719
INFO:root:Train (Epoch 147): Loss/seq after 03000 batchs: 447.42340087890625
INFO:root:Train (Epoch 147): Loss/seq after 03050 batchs: 449.6001892089844
INFO:root:Train (Epoch 147): Loss/seq after 03100 batchs: 452.2073669433594
INFO:root:Train (Epoch 147): Loss/seq after 03150 batchs: 453.3614807128906
INFO:root:Train (Epoch 147): Loss/seq after 03200 batchs: 453.7213439941406
INFO:root:Train (Epoch 147): Loss/seq after 03250 batchs: 455.5831604003906
INFO:root:Train (Epoch 147): Loss/seq after 03300 batchs: 455.1615905761719
INFO:root:Train (Epoch 147): Loss/seq after 03350 batchs: 454.4190673828125
INFO:root:Train (Epoch 147): Loss/seq after 03400 batchs: 450.9392395019531
INFO:root:Train (Epoch 147): Loss/seq after 03450 batchs: 450.01629638671875
INFO:root:Train (Epoch 147): Loss/seq after 03500 batchs: 451.2469787597656
INFO:root:Train (Epoch 147): Loss/seq after 03550 batchs: 448.86279296875
INFO:root:Train (Epoch 147): Loss/seq after 03600 batchs: 455.7619323730469
INFO:root:Train (Epoch 147): Loss/seq after 03650 batchs: 453.9140930175781
INFO:root:Train (Epoch 147): Loss/seq after 03700 batchs: 456.39544677734375
INFO:root:Train (Epoch 147): Loss/seq after 03750 batchs: 460.6341247558594
INFO:root:Train (Epoch 147): Loss/seq after 03800 batchs: 459.1839294433594
INFO:root:Train (Epoch 147): Loss/seq after 03850 batchs: 458.0908508300781
INFO:root:Train (Epoch 147): Loss/seq after 03900 batchs: 460.7633972167969
INFO:root:Train (Epoch 147): Loss/seq after 03950 batchs: 463.76953125
INFO:root:Train (Epoch 147): Loss/seq after 04000 batchs: 460.7120361328125
INFO:root:Train (Epoch 147): Loss/seq after 04050 batchs: 457.8013610839844
INFO:root:Train (Epoch 147): Loss/seq after 04100 batchs: 456.7105407714844
INFO:root:Train (Epoch 147): Loss/seq after 04150 batchs: 456.88800048828125
INFO:root:Train (Epoch 147): Loss/seq after 04200 batchs: 455.81549072265625
INFO:root:Train (Epoch 147): Loss/seq after 04250 batchs: 454.33172607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 147): Loss/seq after 00000 batches: 363.4672546386719
INFO:root:# Valid (Epoch 147): Loss/seq after 00050 batches: 549.9008178710938
INFO:root:# Valid (Epoch 147): Loss/seq after 00100 batches: 582.228271484375
INFO:root:# Valid (Epoch 147): Loss/seq after 00150 batches: 446.47357177734375
INFO:root:# Valid (Epoch 147): Loss/seq after 00200 batches: 419.55413818359375
INFO:root:Artifacts: Make stick videos for epoch 147
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_147_on_20220413_074221.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_147_index_1456_on_20220413_074221.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 148): Loss/seq after 00000 batchs: 844.391357421875
INFO:root:Train (Epoch 148): Loss/seq after 00050 batchs: 647.6478271484375
INFO:root:Train (Epoch 148): Loss/seq after 00100 batchs: 625.3020629882812
INFO:root:Train (Epoch 148): Loss/seq after 00150 batchs: 572.2721557617188
INFO:root:Train (Epoch 148): Loss/seq after 00200 batchs: 629.1942749023438
INFO:root:Train (Epoch 148): Loss/seq after 00250 batchs: 696.507080078125
INFO:root:Train (Epoch 148): Loss/seq after 00300 batchs: 703.888671875
INFO:root:Train (Epoch 148): Loss/seq after 00350 batchs: 662.33544921875
INFO:root:Train (Epoch 148): Loss/seq after 00400 batchs: 651.3739013671875
INFO:root:Train (Epoch 148): Loss/seq after 00450 batchs: 648.5796508789062
INFO:root:Train (Epoch 148): Loss/seq after 00500 batchs: 629.131591796875
INFO:root:Train (Epoch 148): Loss/seq after 00550 batchs: 613.2459106445312
INFO:root:Train (Epoch 148): Loss/seq after 00600 batchs: 593.2852172851562
INFO:root:Train (Epoch 148): Loss/seq after 00650 batchs: 571.5030517578125
INFO:root:Train (Epoch 148): Loss/seq after 00700 batchs: 549.9467163085938
INFO:root:Train (Epoch 148): Loss/seq after 00750 batchs: 550.4844970703125
INFO:root:Train (Epoch 148): Loss/seq after 00800 batchs: 556.1461791992188
INFO:root:Train (Epoch 148): Loss/seq after 00850 batchs: 538.6138916015625
INFO:root:Train (Epoch 148): Loss/seq after 00900 batchs: 528.2154541015625
INFO:root:Train (Epoch 148): Loss/seq after 00950 batchs: 525.9761962890625
INFO:root:Train (Epoch 148): Loss/seq after 01000 batchs: 517.5519409179688
INFO:root:Train (Epoch 148): Loss/seq after 01050 batchs: 508.9917907714844
INFO:root:Train (Epoch 148): Loss/seq after 01100 batchs: 501.30389404296875
INFO:root:Train (Epoch 148): Loss/seq after 01150 batchs: 488.3614501953125
INFO:root:Train (Epoch 148): Loss/seq after 01200 batchs: 493.4408874511719
INFO:root:Train (Epoch 148): Loss/seq after 01250 batchs: 493.03997802734375
INFO:root:Train (Epoch 148): Loss/seq after 01300 batchs: 482.9393615722656
INFO:root:Train (Epoch 148): Loss/seq after 01350 batchs: 475.37945556640625
INFO:root:Train (Epoch 148): Loss/seq after 01400 batchs: 478.4282531738281
INFO:root:Train (Epoch 148): Loss/seq after 01450 batchs: 480.9493103027344
INFO:root:Train (Epoch 148): Loss/seq after 01500 batchs: 488.5335388183594
INFO:root:Train (Epoch 148): Loss/seq after 01550 batchs: 489.20477294921875
INFO:root:Train (Epoch 148): Loss/seq after 01600 batchs: 484.9981384277344
INFO:root:Train (Epoch 148): Loss/seq after 01650 batchs: 483.2851257324219
INFO:root:Train (Epoch 148): Loss/seq after 01700 batchs: 487.0784606933594
INFO:root:Train (Epoch 148): Loss/seq after 01750 batchs: 485.0770568847656
INFO:root:Train (Epoch 148): Loss/seq after 01800 batchs: 482.6617736816406
INFO:root:Train (Epoch 148): Loss/seq after 01850 batchs: 480.0053405761719
INFO:root:Train (Epoch 148): Loss/seq after 01900 batchs: 479.4225158691406
INFO:root:Train (Epoch 148): Loss/seq after 01950 batchs: 478.06427001953125
INFO:root:Train (Epoch 148): Loss/seq after 02000 batchs: 478.1004333496094
INFO:root:Train (Epoch 148): Loss/seq after 02050 batchs: 477.8229064941406
INFO:root:Train (Epoch 148): Loss/seq after 02100 batchs: 476.14892578125
INFO:root:Train (Epoch 148): Loss/seq after 02150 batchs: 474.5831298828125
INFO:root:Train (Epoch 148): Loss/seq after 02200 batchs: 472.4757080078125
INFO:root:Train (Epoch 148): Loss/seq after 02250 batchs: 470.8974914550781
INFO:root:Train (Epoch 148): Loss/seq after 02300 batchs: 467.6956787109375
INFO:root:Train (Epoch 148): Loss/seq after 02350 batchs: 464.44549560546875
INFO:root:Train (Epoch 148): Loss/seq after 02400 batchs: 464.8770751953125
INFO:root:Train (Epoch 148): Loss/seq after 02450 batchs: 461.2767333984375
INFO:root:Train (Epoch 148): Loss/seq after 02500 batchs: 454.6888732910156
INFO:root:Train (Epoch 148): Loss/seq after 02550 batchs: 448.975830078125
INFO:root:Train (Epoch 148): Loss/seq after 02600 batchs: 447.7578430175781
INFO:root:Train (Epoch 148): Loss/seq after 02650 batchs: 444.2524108886719
INFO:root:Train (Epoch 148): Loss/seq after 02700 batchs: 441.806396484375
INFO:root:Train (Epoch 148): Loss/seq after 02750 batchs: 438.6556091308594
INFO:root:Train (Epoch 148): Loss/seq after 02800 batchs: 437.3880310058594
INFO:root:Train (Epoch 148): Loss/seq after 02850 batchs: 437.39825439453125
INFO:root:Train (Epoch 148): Loss/seq after 02900 batchs: 438.7091064453125
INFO:root:Train (Epoch 148): Loss/seq after 02950 batchs: 438.5546569824219
INFO:root:Train (Epoch 148): Loss/seq after 03000 batchs: 444.08441162109375
INFO:root:Train (Epoch 148): Loss/seq after 03050 batchs: 446.19732666015625
INFO:root:Train (Epoch 148): Loss/seq after 03100 batchs: 448.3824768066406
INFO:root:Train (Epoch 148): Loss/seq after 03150 batchs: 449.55859375
INFO:root:Train (Epoch 148): Loss/seq after 03200 batchs: 450.03143310546875
INFO:root:Train (Epoch 148): Loss/seq after 03250 batchs: 451.97381591796875
INFO:root:Train (Epoch 148): Loss/seq after 03300 batchs: 451.12799072265625
INFO:root:Train (Epoch 148): Loss/seq after 03350 batchs: 450.5438537597656
INFO:root:Train (Epoch 148): Loss/seq after 03400 batchs: 447.23553466796875
INFO:root:Train (Epoch 148): Loss/seq after 03450 batchs: 446.1947021484375
INFO:root:Train (Epoch 148): Loss/seq after 03500 batchs: 447.17926025390625
INFO:root:Train (Epoch 148): Loss/seq after 03550 batchs: 445.1217346191406
INFO:root:Train (Epoch 148): Loss/seq after 03600 batchs: 451.9930419921875
INFO:root:Train (Epoch 148): Loss/seq after 03650 batchs: 450.35736083984375
INFO:root:Train (Epoch 148): Loss/seq after 03700 batchs: 452.9455261230469
INFO:root:Train (Epoch 148): Loss/seq after 03750 batchs: 457.17633056640625
INFO:root:Train (Epoch 148): Loss/seq after 03800 batchs: 455.7869873046875
INFO:root:Train (Epoch 148): Loss/seq after 03850 batchs: 454.8042907714844
INFO:root:Train (Epoch 148): Loss/seq after 03900 batchs: 457.6210021972656
INFO:root:Train (Epoch 148): Loss/seq after 03950 batchs: 460.66455078125
INFO:root:Train (Epoch 148): Loss/seq after 04000 batchs: 457.62432861328125
INFO:root:Train (Epoch 148): Loss/seq after 04050 batchs: 454.7197570800781
INFO:root:Train (Epoch 148): Loss/seq after 04100 batchs: 453.6000671386719
INFO:root:Train (Epoch 148): Loss/seq after 04150 batchs: 453.7176513671875
INFO:root:Train (Epoch 148): Loss/seq after 04200 batchs: 452.5245056152344
INFO:root:Train (Epoch 148): Loss/seq after 04250 batchs: 450.9593505859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 148): Loss/seq after 00000 batches: 357.16973876953125
INFO:root:# Valid (Epoch 148): Loss/seq after 00050 batches: 524.6930541992188
INFO:root:# Valid (Epoch 148): Loss/seq after 00100 batches: 563.1778564453125
INFO:root:# Valid (Epoch 148): Loss/seq after 00150 batches: 432.8174743652344
INFO:root:# Valid (Epoch 148): Loss/seq after 00200 batches: 409.0925598144531
INFO:root:Artifacts: Make stick videos for epoch 148
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_148_on_20220413_074744.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_148_index_312_on_20220413_074744.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 149): Loss/seq after 00000 batchs: 882.186767578125
INFO:root:Train (Epoch 149): Loss/seq after 00050 batchs: 664.8265991210938
INFO:root:Train (Epoch 149): Loss/seq after 00100 batchs: 622.9212646484375
INFO:root:Train (Epoch 149): Loss/seq after 00150 batchs: 570.3430786132812
INFO:root:Train (Epoch 149): Loss/seq after 00200 batchs: 620.0554809570312
INFO:root:Train (Epoch 149): Loss/seq after 00250 batchs: 686.2174072265625
INFO:root:Train (Epoch 149): Loss/seq after 00300 batchs: 695.6129150390625
INFO:root:Train (Epoch 149): Loss/seq after 00350 batchs: 654.2392578125
INFO:root:Train (Epoch 149): Loss/seq after 00400 batchs: 642.9964599609375
INFO:root:Train (Epoch 149): Loss/seq after 00450 batchs: 641.9463500976562
INFO:root:Train (Epoch 149): Loss/seq after 00500 batchs: 622.1947631835938
INFO:root:Train (Epoch 149): Loss/seq after 00550 batchs: 606.9659423828125
INFO:root:Train (Epoch 149): Loss/seq after 00600 batchs: 586.739990234375
INFO:root:Train (Epoch 149): Loss/seq after 00650 batchs: 564.7208251953125
INFO:root:Train (Epoch 149): Loss/seq after 00700 batchs: 542.28857421875
INFO:root:Train (Epoch 149): Loss/seq after 00750 batchs: 542.5193481445312
INFO:root:Train (Epoch 149): Loss/seq after 00800 batchs: 547.3140258789062
INFO:root:Train (Epoch 149): Loss/seq after 00850 batchs: 529.920654296875
INFO:root:Train (Epoch 149): Loss/seq after 00900 batchs: 520.1341552734375
INFO:root:Train (Epoch 149): Loss/seq after 00950 batchs: 517.8614501953125
INFO:root:Train (Epoch 149): Loss/seq after 01000 batchs: 509.34613037109375
INFO:root:Train (Epoch 149): Loss/seq after 01050 batchs: 501.3754577636719
INFO:root:Train (Epoch 149): Loss/seq after 01100 batchs: 494.1369323730469
INFO:root:Train (Epoch 149): Loss/seq after 01150 batchs: 481.42138671875
INFO:root:Train (Epoch 149): Loss/seq after 01200 batchs: 487.2331237792969
INFO:root:Train (Epoch 149): Loss/seq after 01250 batchs: 487.21881103515625
INFO:root:Train (Epoch 149): Loss/seq after 01300 batchs: 477.5212707519531
INFO:root:Train (Epoch 149): Loss/seq after 01350 batchs: 470.179931640625
INFO:root:Train (Epoch 149): Loss/seq after 01400 batchs: 473.2710876464844
INFO:root:Train (Epoch 149): Loss/seq after 01450 batchs: 475.8948974609375
INFO:root:Train (Epoch 149): Loss/seq after 01500 batchs: 483.5777587890625
INFO:root:Train (Epoch 149): Loss/seq after 01550 batchs: 483.7771301269531
INFO:root:Train (Epoch 149): Loss/seq after 01600 batchs: 479.42218017578125
INFO:root:Train (Epoch 149): Loss/seq after 01650 batchs: 477.95440673828125
INFO:root:Train (Epoch 149): Loss/seq after 01700 batchs: 481.65838623046875
INFO:root:Train (Epoch 149): Loss/seq after 01750 batchs: 479.5658264160156
INFO:root:Train (Epoch 149): Loss/seq after 01800 batchs: 477.22052001953125
INFO:root:Train (Epoch 149): Loss/seq after 01850 batchs: 474.6438903808594
INFO:root:Train (Epoch 149): Loss/seq after 01900 batchs: 474.29925537109375
INFO:root:Train (Epoch 149): Loss/seq after 01950 batchs: 472.8449401855469
INFO:root:Train (Epoch 149): Loss/seq after 02000 batchs: 472.9568786621094
INFO:root:Train (Epoch 149): Loss/seq after 02050 batchs: 472.8305969238281
INFO:root:Train (Epoch 149): Loss/seq after 02100 batchs: 471.20709228515625
INFO:root:Train (Epoch 149): Loss/seq after 02150 batchs: 469.6412048339844
INFO:root:Train (Epoch 149): Loss/seq after 02200 batchs: 467.7175598144531
INFO:root:Train (Epoch 149): Loss/seq after 02250 batchs: 466.3216552734375
INFO:root:Train (Epoch 149): Loss/seq after 02300 batchs: 463.0861511230469
INFO:root:Train (Epoch 149): Loss/seq after 02350 batchs: 459.8429870605469
INFO:root:Train (Epoch 149): Loss/seq after 02400 batchs: 460.40789794921875
INFO:root:Train (Epoch 149): Loss/seq after 02450 batchs: 456.9139099121094
INFO:root:Train (Epoch 149): Loss/seq after 02500 batchs: 450.4245300292969
INFO:root:Train (Epoch 149): Loss/seq after 02550 batchs: 444.84539794921875
INFO:root:Train (Epoch 149): Loss/seq after 02600 batchs: 443.6168212890625
INFO:root:Train (Epoch 149): Loss/seq after 02650 batchs: 440.0152282714844
INFO:root:Train (Epoch 149): Loss/seq after 02700 batchs: 437.66436767578125
INFO:root:Train (Epoch 149): Loss/seq after 02750 batchs: 434.7868347167969
INFO:root:Train (Epoch 149): Loss/seq after 02800 batchs: 433.5848693847656
INFO:root:Train (Epoch 149): Loss/seq after 02850 batchs: 433.605712890625
INFO:root:Train (Epoch 149): Loss/seq after 02900 batchs: 434.9571533203125
INFO:root:Train (Epoch 149): Loss/seq after 02950 batchs: 434.7836608886719
INFO:root:Train (Epoch 149): Loss/seq after 03000 batchs: 440.3399963378906
INFO:root:Train (Epoch 149): Loss/seq after 03050 batchs: 442.47467041015625
INFO:root:Train (Epoch 149): Loss/seq after 03100 batchs: 444.8940124511719
INFO:root:Train (Epoch 149): Loss/seq after 03150 batchs: 445.96966552734375
INFO:root:Train (Epoch 149): Loss/seq after 03200 batchs: 446.093505859375
INFO:root:Train (Epoch 149): Loss/seq after 03250 batchs: 447.7901611328125
INFO:root:Train (Epoch 149): Loss/seq after 03300 batchs: 447.0733337402344
INFO:root:Train (Epoch 149): Loss/seq after 03350 batchs: 446.31976318359375
INFO:root:Train (Epoch 149): Loss/seq after 03400 batchs: 443.0054626464844
INFO:root:Train (Epoch 149): Loss/seq after 03450 batchs: 441.9886779785156
INFO:root:Train (Epoch 149): Loss/seq after 03500 batchs: 442.9673156738281
INFO:root:Train (Epoch 149): Loss/seq after 03550 batchs: 440.7758483886719
INFO:root:Train (Epoch 149): Loss/seq after 03600 batchs: 447.634765625
INFO:root:Train (Epoch 149): Loss/seq after 03650 batchs: 445.9758605957031
INFO:root:Train (Epoch 149): Loss/seq after 03700 batchs: 448.642333984375
INFO:root:Train (Epoch 149): Loss/seq after 03750 batchs: 452.71258544921875
INFO:root:Train (Epoch 149): Loss/seq after 03800 batchs: 451.3326110839844
INFO:root:Train (Epoch 149): Loss/seq after 03850 batchs: 450.3936767578125
INFO:root:Train (Epoch 149): Loss/seq after 03900 batchs: 452.9637451171875
INFO:root:Train (Epoch 149): Loss/seq after 03950 batchs: 456.02362060546875
INFO:root:Train (Epoch 149): Loss/seq after 04000 batchs: 453.000244140625
INFO:root:Train (Epoch 149): Loss/seq after 04050 batchs: 450.16522216796875
INFO:root:Train (Epoch 149): Loss/seq after 04100 batchs: 449.01226806640625
INFO:root:Train (Epoch 149): Loss/seq after 04150 batchs: 449.18597412109375
INFO:root:Train (Epoch 149): Loss/seq after 04200 batchs: 448.1025695800781
INFO:root:Train (Epoch 149): Loss/seq after 04250 batchs: 446.6849060058594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 149): Loss/seq after 00000 batches: 349.5600280761719
INFO:root:# Valid (Epoch 149): Loss/seq after 00050 batches: 531.5115356445312
INFO:root:# Valid (Epoch 149): Loss/seq after 00100 batches: 568.5931396484375
INFO:root:# Valid (Epoch 149): Loss/seq after 00150 batches: 435.91839599609375
INFO:root:# Valid (Epoch 149): Loss/seq after 00200 batches: 411.6534118652344
INFO:root:Artifacts: Make stick videos for epoch 149
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_149_on_20220413_075308.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_149_index_492_on_20220413_075308.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 150): Loss/seq after 00000 batchs: 856.3627319335938
INFO:root:Train (Epoch 150): Loss/seq after 00050 batchs: 644.7759399414062
INFO:root:Train (Epoch 150): Loss/seq after 00100 batchs: 613.822021484375
INFO:root:Train (Epoch 150): Loss/seq after 00150 batchs: 562.8261108398438
INFO:root:Train (Epoch 150): Loss/seq after 00200 batchs: 618.336181640625
INFO:root:Train (Epoch 150): Loss/seq after 00250 batchs: 688.1334838867188
INFO:root:Train (Epoch 150): Loss/seq after 00300 batchs: 696.8954467773438
INFO:root:Train (Epoch 150): Loss/seq after 00350 batchs: 655.2579345703125
INFO:root:Train (Epoch 150): Loss/seq after 00400 batchs: 646.2907104492188
INFO:root:Train (Epoch 150): Loss/seq after 00450 batchs: 644.387451171875
INFO:root:Train (Epoch 150): Loss/seq after 00500 batchs: 624.1753540039062
INFO:root:Train (Epoch 150): Loss/seq after 00550 batchs: 608.4202880859375
INFO:root:Train (Epoch 150): Loss/seq after 00600 batchs: 587.8380126953125
INFO:root:Train (Epoch 150): Loss/seq after 00650 batchs: 566.546142578125
INFO:root:Train (Epoch 150): Loss/seq after 00700 batchs: 544.192138671875
INFO:root:Train (Epoch 150): Loss/seq after 00750 batchs: 544.990478515625
INFO:root:Train (Epoch 150): Loss/seq after 00800 batchs: 549.4861450195312
INFO:root:Train (Epoch 150): Loss/seq after 00850 batchs: 531.9625244140625
INFO:root:Train (Epoch 150): Loss/seq after 00900 batchs: 521.5862426757812
INFO:root:Train (Epoch 150): Loss/seq after 00950 batchs: 519.4102172851562
INFO:root:Train (Epoch 150): Loss/seq after 01000 batchs: 511.3197021484375
INFO:root:Train (Epoch 150): Loss/seq after 01050 batchs: 502.6282043457031
INFO:root:Train (Epoch 150): Loss/seq after 01100 batchs: 494.76055908203125
INFO:root:Train (Epoch 150): Loss/seq after 01150 batchs: 481.9794921875
INFO:root:Train (Epoch 150): Loss/seq after 01200 batchs: 487.31243896484375
INFO:root:Train (Epoch 150): Loss/seq after 01250 batchs: 487.10821533203125
INFO:root:Train (Epoch 150): Loss/seq after 01300 batchs: 477.29266357421875
INFO:root:Train (Epoch 150): Loss/seq after 01350 batchs: 469.5785217285156
INFO:root:Train (Epoch 150): Loss/seq after 01400 batchs: 472.0628662109375
INFO:root:Train (Epoch 150): Loss/seq after 01450 batchs: 474.69293212890625
INFO:root:Train (Epoch 150): Loss/seq after 01500 batchs: 482.28839111328125
INFO:root:Train (Epoch 150): Loss/seq after 01550 batchs: 482.3657531738281
INFO:root:Train (Epoch 150): Loss/seq after 01600 batchs: 477.903564453125
INFO:root:Train (Epoch 150): Loss/seq after 01650 batchs: 476.1561279296875
INFO:root:Train (Epoch 150): Loss/seq after 01700 batchs: 479.93115234375
INFO:root:Train (Epoch 150): Loss/seq after 01750 batchs: 477.85009765625
INFO:root:Train (Epoch 150): Loss/seq after 01800 batchs: 475.3666687011719
INFO:root:Train (Epoch 150): Loss/seq after 01850 batchs: 472.8207702636719
INFO:root:Train (Epoch 150): Loss/seq after 01900 batchs: 472.3035583496094
INFO:root:Train (Epoch 150): Loss/seq after 01950 batchs: 471.0828857421875
INFO:root:Train (Epoch 150): Loss/seq after 02000 batchs: 471.2952575683594
INFO:root:Train (Epoch 150): Loss/seq after 02050 batchs: 470.990966796875
INFO:root:Train (Epoch 150): Loss/seq after 02100 batchs: 469.4101867675781
INFO:root:Train (Epoch 150): Loss/seq after 02150 batchs: 467.79150390625
INFO:root:Train (Epoch 150): Loss/seq after 02200 batchs: 465.7823791503906
INFO:root:Train (Epoch 150): Loss/seq after 02250 batchs: 464.5086669921875
INFO:root:Train (Epoch 150): Loss/seq after 02300 batchs: 461.2096252441406
INFO:root:Train (Epoch 150): Loss/seq after 02350 batchs: 458.1028747558594
INFO:root:Train (Epoch 150): Loss/seq after 02400 batchs: 458.5806579589844
INFO:root:Train (Epoch 150): Loss/seq after 02450 batchs: 455.0151062011719
INFO:root:Train (Epoch 150): Loss/seq after 02500 batchs: 448.5834045410156
INFO:root:Train (Epoch 150): Loss/seq after 02550 batchs: 443.0584411621094
INFO:root:Train (Epoch 150): Loss/seq after 02600 batchs: 441.9381408691406
INFO:root:Train (Epoch 150): Loss/seq after 02650 batchs: 438.402587890625
INFO:root:Train (Epoch 150): Loss/seq after 02700 batchs: 436.0872497558594
INFO:root:Train (Epoch 150): Loss/seq after 02750 batchs: 433.1401062011719
INFO:root:Train (Epoch 150): Loss/seq after 02800 batchs: 432.07086181640625
INFO:root:Train (Epoch 150): Loss/seq after 02850 batchs: 432.0362243652344
INFO:root:Train (Epoch 150): Loss/seq after 02900 batchs: 433.33642578125
INFO:root:Train (Epoch 150): Loss/seq after 02950 batchs: 433.3173828125
INFO:root:Train (Epoch 150): Loss/seq after 03000 batchs: 438.95245361328125
INFO:root:Train (Epoch 150): Loss/seq after 03050 batchs: 441.158935546875
INFO:root:Train (Epoch 150): Loss/seq after 03100 batchs: 443.497802734375
INFO:root:Train (Epoch 150): Loss/seq after 03150 batchs: 444.4918518066406
INFO:root:Train (Epoch 150): Loss/seq after 03200 batchs: 444.7201843261719
INFO:root:Train (Epoch 150): Loss/seq after 03250 batchs: 447.0165710449219
INFO:root:Train (Epoch 150): Loss/seq after 03300 batchs: 446.5195007324219
INFO:root:Train (Epoch 150): Loss/seq after 03350 batchs: 446.36273193359375
INFO:root:Train (Epoch 150): Loss/seq after 03400 batchs: 443.10052490234375
INFO:root:Train (Epoch 150): Loss/seq after 03450 batchs: 442.11688232421875
INFO:root:Train (Epoch 150): Loss/seq after 03500 batchs: 443.0527648925781
INFO:root:Train (Epoch 150): Loss/seq after 03550 batchs: 440.7854309082031
INFO:root:Train (Epoch 150): Loss/seq after 03600 batchs: 447.56622314453125
INFO:root:Train (Epoch 150): Loss/seq after 03650 batchs: 445.85272216796875
INFO:root:Train (Epoch 150): Loss/seq after 03700 batchs: 448.57415771484375
INFO:root:Train (Epoch 150): Loss/seq after 03750 batchs: 452.8189392089844
INFO:root:Train (Epoch 150): Loss/seq after 03800 batchs: 451.4916687011719
INFO:root:Train (Epoch 150): Loss/seq after 03850 batchs: 450.4563903808594
INFO:root:Train (Epoch 150): Loss/seq after 03900 batchs: 453.1153564453125
INFO:root:Train (Epoch 150): Loss/seq after 03950 batchs: 456.0554504394531
INFO:root:Train (Epoch 150): Loss/seq after 04000 batchs: 453.02252197265625
INFO:root:Train (Epoch 150): Loss/seq after 04050 batchs: 450.1747131347656
INFO:root:Train (Epoch 150): Loss/seq after 04100 batchs: 449.101318359375
INFO:root:Train (Epoch 150): Loss/seq after 04150 batchs: 449.2364501953125
INFO:root:Train (Epoch 150): Loss/seq after 04200 batchs: 448.2262268066406
INFO:root:Train (Epoch 150): Loss/seq after 04250 batchs: 446.79443359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 150): Loss/seq after 00000 batches: 372.5683288574219
INFO:root:# Valid (Epoch 150): Loss/seq after 00050 batches: 538.362060546875
INFO:root:# Valid (Epoch 150): Loss/seq after 00100 batches: 575.7800903320312
INFO:root:# Valid (Epoch 150): Loss/seq after 00150 batches: 442.3738708496094
INFO:root:# Valid (Epoch 150): Loss/seq after 00200 batches: 420.05767822265625
INFO:root:Artifacts: Make stick videos for epoch 150
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_150_on_20220413_075831.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_150_index_118_on_20220413_075831.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 151): Loss/seq after 00000 batchs: 820.8591918945312
INFO:root:Train (Epoch 151): Loss/seq after 00050 batchs: 641.5955200195312
INFO:root:Train (Epoch 151): Loss/seq after 00100 batchs: 608.296630859375
INFO:root:Train (Epoch 151): Loss/seq after 00150 batchs: 560.0520629882812
INFO:root:Train (Epoch 151): Loss/seq after 00200 batchs: 614.4988403320312
INFO:root:Train (Epoch 151): Loss/seq after 00250 batchs: 680.9923706054688
INFO:root:Train (Epoch 151): Loss/seq after 00300 batchs: 688.6892700195312
INFO:root:Train (Epoch 151): Loss/seq after 00350 batchs: 647.4498901367188
INFO:root:Train (Epoch 151): Loss/seq after 00400 batchs: 635.96240234375
INFO:root:Train (Epoch 151): Loss/seq after 00450 batchs: 634.9883422851562
INFO:root:Train (Epoch 151): Loss/seq after 00500 batchs: 615.0994873046875
INFO:root:Train (Epoch 151): Loss/seq after 00550 batchs: 599.6266479492188
INFO:root:Train (Epoch 151): Loss/seq after 00600 batchs: 580.2152709960938
INFO:root:Train (Epoch 151): Loss/seq after 00650 batchs: 558.748291015625
INFO:root:Train (Epoch 151): Loss/seq after 00700 batchs: 536.753173828125
INFO:root:Train (Epoch 151): Loss/seq after 00750 batchs: 536.1919555664062
INFO:root:Train (Epoch 151): Loss/seq after 00800 batchs: 540.9947509765625
INFO:root:Train (Epoch 151): Loss/seq after 00850 batchs: 523.9517211914062
INFO:root:Train (Epoch 151): Loss/seq after 00900 batchs: 513.9807739257812
INFO:root:Train (Epoch 151): Loss/seq after 00950 batchs: 511.68560791015625
INFO:root:Train (Epoch 151): Loss/seq after 01000 batchs: 503.48541259765625
INFO:root:Train (Epoch 151): Loss/seq after 01050 batchs: 495.4096374511719
INFO:root:Train (Epoch 151): Loss/seq after 01100 batchs: 487.8838806152344
INFO:root:Train (Epoch 151): Loss/seq after 01150 batchs: 475.18768310546875
INFO:root:Train (Epoch 151): Loss/seq after 01200 batchs: 480.4817199707031
INFO:root:Train (Epoch 151): Loss/seq after 01250 batchs: 480.78131103515625
INFO:root:Train (Epoch 151): Loss/seq after 01300 batchs: 470.95440673828125
INFO:root:Train (Epoch 151): Loss/seq after 01350 batchs: 463.4082336425781
INFO:root:Train (Epoch 151): Loss/seq after 01400 batchs: 466.069091796875
INFO:root:Train (Epoch 151): Loss/seq after 01450 batchs: 468.705078125
INFO:root:Train (Epoch 151): Loss/seq after 01500 batchs: 476.5796813964844
INFO:root:Train (Epoch 151): Loss/seq after 01550 batchs: 477.3489074707031
INFO:root:Train (Epoch 151): Loss/seq after 01600 batchs: 473.3963317871094
INFO:root:Train (Epoch 151): Loss/seq after 01650 batchs: 471.728515625
INFO:root:Train (Epoch 151): Loss/seq after 01700 batchs: 475.84857177734375
INFO:root:Train (Epoch 151): Loss/seq after 01750 batchs: 473.85186767578125
INFO:root:Train (Epoch 151): Loss/seq after 01800 batchs: 471.740966796875
INFO:root:Train (Epoch 151): Loss/seq after 01850 batchs: 469.26861572265625
INFO:root:Train (Epoch 151): Loss/seq after 01900 batchs: 468.67352294921875
INFO:root:Train (Epoch 151): Loss/seq after 01950 batchs: 467.3863220214844
INFO:root:Train (Epoch 151): Loss/seq after 02000 batchs: 467.639404296875
INFO:root:Train (Epoch 151): Loss/seq after 02050 batchs: 467.57916259765625
INFO:root:Train (Epoch 151): Loss/seq after 02100 batchs: 465.8567810058594
INFO:root:Train (Epoch 151): Loss/seq after 02150 batchs: 464.3209228515625
INFO:root:Train (Epoch 151): Loss/seq after 02200 batchs: 462.2483825683594
INFO:root:Train (Epoch 151): Loss/seq after 02250 batchs: 461.03631591796875
INFO:root:Train (Epoch 151): Loss/seq after 02300 batchs: 457.7312927246094
INFO:root:Train (Epoch 151): Loss/seq after 02350 batchs: 454.6669921875
INFO:root:Train (Epoch 151): Loss/seq after 02400 batchs: 455.1535339355469
INFO:root:Train (Epoch 151): Loss/seq after 02450 batchs: 451.70819091796875
INFO:root:Train (Epoch 151): Loss/seq after 02500 batchs: 445.3039245605469
INFO:root:Train (Epoch 151): Loss/seq after 02550 batchs: 439.7505187988281
INFO:root:Train (Epoch 151): Loss/seq after 02600 batchs: 438.6541748046875
INFO:root:Train (Epoch 151): Loss/seq after 02650 batchs: 435.23736572265625
INFO:root:Train (Epoch 151): Loss/seq after 02700 batchs: 433.0791931152344
INFO:root:Train (Epoch 151): Loss/seq after 02750 batchs: 430.055419921875
INFO:root:Train (Epoch 151): Loss/seq after 02800 batchs: 428.8630676269531
INFO:root:Train (Epoch 151): Loss/seq after 02850 batchs: 428.8075866699219
INFO:root:Train (Epoch 151): Loss/seq after 02900 batchs: 430.24127197265625
INFO:root:Train (Epoch 151): Loss/seq after 02950 batchs: 430.2165222167969
INFO:root:Train (Epoch 151): Loss/seq after 03000 batchs: 435.771728515625
INFO:root:Train (Epoch 151): Loss/seq after 03050 batchs: 438.0538635253906
INFO:root:Train (Epoch 151): Loss/seq after 03100 batchs: 440.3502502441406
INFO:root:Train (Epoch 151): Loss/seq after 03150 batchs: 441.34039306640625
INFO:root:Train (Epoch 151): Loss/seq after 03200 batchs: 441.6194763183594
INFO:root:Train (Epoch 151): Loss/seq after 03250 batchs: 443.3812561035156
INFO:root:Train (Epoch 151): Loss/seq after 03300 batchs: 442.7033996582031
INFO:root:Train (Epoch 151): Loss/seq after 03350 batchs: 441.9206848144531
INFO:root:Train (Epoch 151): Loss/seq after 03400 batchs: 438.65252685546875
INFO:root:Train (Epoch 151): Loss/seq after 03450 batchs: 437.79229736328125
INFO:root:Train (Epoch 151): Loss/seq after 03500 batchs: 438.7395324707031
INFO:root:Train (Epoch 151): Loss/seq after 03550 batchs: 436.5432434082031
INFO:root:Train (Epoch 151): Loss/seq after 03600 batchs: 443.3591613769531
INFO:root:Train (Epoch 151): Loss/seq after 03650 batchs: 441.64990234375
INFO:root:Train (Epoch 151): Loss/seq after 03700 batchs: 444.1227111816406
INFO:root:Train (Epoch 151): Loss/seq after 03750 batchs: 448.2823181152344
INFO:root:Train (Epoch 151): Loss/seq after 03800 batchs: 446.9709167480469
INFO:root:Train (Epoch 151): Loss/seq after 03850 batchs: 445.93035888671875
INFO:root:Train (Epoch 151): Loss/seq after 03900 batchs: 448.63543701171875
INFO:root:Train (Epoch 151): Loss/seq after 03950 batchs: 451.45928955078125
INFO:root:Train (Epoch 151): Loss/seq after 04000 batchs: 448.4837646484375
INFO:root:Train (Epoch 151): Loss/seq after 04050 batchs: 445.6850280761719
INFO:root:Train (Epoch 151): Loss/seq after 04100 batchs: 444.57672119140625
INFO:root:Train (Epoch 151): Loss/seq after 04150 batchs: 444.73443603515625
INFO:root:Train (Epoch 151): Loss/seq after 04200 batchs: 443.6988830566406
INFO:root:Train (Epoch 151): Loss/seq after 04250 batchs: 442.2063903808594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 151): Loss/seq after 00000 batches: 352.1575927734375
INFO:root:# Valid (Epoch 151): Loss/seq after 00050 batches: 525.2080688476562
INFO:root:# Valid (Epoch 151): Loss/seq after 00100 batches: 557.3988647460938
INFO:root:# Valid (Epoch 151): Loss/seq after 00150 batches: 427.98968505859375
INFO:root:# Valid (Epoch 151): Loss/seq after 00200 batches: 405.42266845703125
INFO:root:Artifacts: Make stick videos for epoch 151
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_151_on_20220413_080357.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_151_index_132_on_20220413_080357.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 152): Loss/seq after 00000 batchs: 864.4371948242188
INFO:root:Train (Epoch 152): Loss/seq after 00050 batchs: 630.1934814453125
INFO:root:Train (Epoch 152): Loss/seq after 00100 batchs: 602.3213500976562
INFO:root:Train (Epoch 152): Loss/seq after 00150 batchs: 555.7708129882812
INFO:root:Train (Epoch 152): Loss/seq after 00200 batchs: 608.1798706054688
INFO:root:Train (Epoch 152): Loss/seq after 00250 batchs: 681.0520629882812
INFO:root:Train (Epoch 152): Loss/seq after 00300 batchs: 689.48779296875
INFO:root:Train (Epoch 152): Loss/seq after 00350 batchs: 649.1218872070312
INFO:root:Train (Epoch 152): Loss/seq after 00400 batchs: 639.43994140625
INFO:root:Train (Epoch 152): Loss/seq after 00450 batchs: 637.765625
INFO:root:Train (Epoch 152): Loss/seq after 00500 batchs: 619.471435546875
INFO:root:Train (Epoch 152): Loss/seq after 00550 batchs: 603.6367797851562
INFO:root:Train (Epoch 152): Loss/seq after 00600 batchs: 583.9348754882812
INFO:root:Train (Epoch 152): Loss/seq after 00650 batchs: 562.8071899414062
INFO:root:Train (Epoch 152): Loss/seq after 00700 batchs: 540.6655883789062
INFO:root:Train (Epoch 152): Loss/seq after 00750 batchs: 541.2522583007812
INFO:root:Train (Epoch 152): Loss/seq after 00800 batchs: 547.7275390625
INFO:root:Train (Epoch 152): Loss/seq after 00850 batchs: 530.1637573242188
INFO:root:Train (Epoch 152): Loss/seq after 00900 batchs: 520.3063354492188
INFO:root:Train (Epoch 152): Loss/seq after 00950 batchs: 518.2459716796875
INFO:root:Train (Epoch 152): Loss/seq after 01000 batchs: 509.8450012207031
INFO:root:Train (Epoch 152): Loss/seq after 01050 batchs: 501.3246765136719
INFO:root:Train (Epoch 152): Loss/seq after 01100 batchs: 493.5904541015625
INFO:root:Train (Epoch 152): Loss/seq after 01150 batchs: 480.79248046875
INFO:root:Train (Epoch 152): Loss/seq after 01200 batchs: 485.73931884765625
INFO:root:Train (Epoch 152): Loss/seq after 01250 batchs: 485.5138244628906
INFO:root:Train (Epoch 152): Loss/seq after 01300 batchs: 475.7664794921875
INFO:root:Train (Epoch 152): Loss/seq after 01350 batchs: 468.30364990234375
INFO:root:Train (Epoch 152): Loss/seq after 01400 batchs: 470.99273681640625
INFO:root:Train (Epoch 152): Loss/seq after 01450 batchs: 473.4101867675781
INFO:root:Train (Epoch 152): Loss/seq after 01500 batchs: 480.8788146972656
INFO:root:Train (Epoch 152): Loss/seq after 01550 batchs: 481.09771728515625
INFO:root:Train (Epoch 152): Loss/seq after 01600 batchs: 476.8512878417969
INFO:root:Train (Epoch 152): Loss/seq after 01650 batchs: 475.217041015625
INFO:root:Train (Epoch 152): Loss/seq after 01700 batchs: 479.3981628417969
INFO:root:Train (Epoch 152): Loss/seq after 01750 batchs: 477.2120361328125
INFO:root:Train (Epoch 152): Loss/seq after 01800 batchs: 474.69085693359375
INFO:root:Train (Epoch 152): Loss/seq after 01850 batchs: 472.1637878417969
INFO:root:Train (Epoch 152): Loss/seq after 01900 batchs: 471.3034362792969
INFO:root:Train (Epoch 152): Loss/seq after 01950 batchs: 469.77947998046875
INFO:root:Train (Epoch 152): Loss/seq after 02000 batchs: 469.9560241699219
INFO:root:Train (Epoch 152): Loss/seq after 02050 batchs: 469.63848876953125
INFO:root:Train (Epoch 152): Loss/seq after 02100 batchs: 467.9921569824219
INFO:root:Train (Epoch 152): Loss/seq after 02150 batchs: 466.3103332519531
INFO:root:Train (Epoch 152): Loss/seq after 02200 batchs: 464.3249206542969
INFO:root:Train (Epoch 152): Loss/seq after 02250 batchs: 462.7470703125
INFO:root:Train (Epoch 152): Loss/seq after 02300 batchs: 459.3958435058594
INFO:root:Train (Epoch 152): Loss/seq after 02350 batchs: 456.2704772949219
INFO:root:Train (Epoch 152): Loss/seq after 02400 batchs: 456.6978759765625
INFO:root:Train (Epoch 152): Loss/seq after 02450 batchs: 453.1986999511719
INFO:root:Train (Epoch 152): Loss/seq after 02500 batchs: 446.73150634765625
INFO:root:Train (Epoch 152): Loss/seq after 02550 batchs: 441.1022033691406
INFO:root:Train (Epoch 152): Loss/seq after 02600 batchs: 439.8748474121094
INFO:root:Train (Epoch 152): Loss/seq after 02650 batchs: 436.4284362792969
INFO:root:Train (Epoch 152): Loss/seq after 02700 batchs: 434.0889587402344
INFO:root:Train (Epoch 152): Loss/seq after 02750 batchs: 431.0586853027344
INFO:root:Train (Epoch 152): Loss/seq after 02800 batchs: 429.6119079589844
INFO:root:Train (Epoch 152): Loss/seq after 02850 batchs: 429.5654296875
INFO:root:Train (Epoch 152): Loss/seq after 02900 batchs: 431.0023193359375
INFO:root:Train (Epoch 152): Loss/seq after 02950 batchs: 430.80548095703125
INFO:root:Train (Epoch 152): Loss/seq after 03000 batchs: 436.1983337402344
INFO:root:Train (Epoch 152): Loss/seq after 03050 batchs: 438.3692321777344
INFO:root:Train (Epoch 152): Loss/seq after 03100 batchs: 440.41363525390625
INFO:root:Train (Epoch 152): Loss/seq after 03150 batchs: 440.9681091308594
INFO:root:Train (Epoch 152): Loss/seq after 03200 batchs: 441.2552490234375
INFO:root:Train (Epoch 152): Loss/seq after 03250 batchs: 443.0351257324219
INFO:root:Train (Epoch 152): Loss/seq after 03300 batchs: 442.4801940917969
INFO:root:Train (Epoch 152): Loss/seq after 03350 batchs: 441.8017578125
INFO:root:Train (Epoch 152): Loss/seq after 03400 batchs: 438.5436706542969
INFO:root:Train (Epoch 152): Loss/seq after 03450 batchs: 437.56256103515625
INFO:root:Train (Epoch 152): Loss/seq after 03500 batchs: 438.5489196777344
INFO:root:Train (Epoch 152): Loss/seq after 03550 batchs: 436.3671875
INFO:root:Train (Epoch 152): Loss/seq after 03600 batchs: 443.255126953125
INFO:root:Train (Epoch 152): Loss/seq after 03650 batchs: 441.5341491699219
INFO:root:Train (Epoch 152): Loss/seq after 03700 batchs: 444.1325988769531
INFO:root:Train (Epoch 152): Loss/seq after 03750 batchs: 448.3230895996094
INFO:root:Train (Epoch 152): Loss/seq after 03800 batchs: 447.0345458984375
INFO:root:Train (Epoch 152): Loss/seq after 03850 batchs: 446.01348876953125
INFO:root:Train (Epoch 152): Loss/seq after 03900 batchs: 448.564453125
INFO:root:Train (Epoch 152): Loss/seq after 03950 batchs: 451.30596923828125
INFO:root:Train (Epoch 152): Loss/seq after 04000 batchs: 448.3279724121094
INFO:root:Train (Epoch 152): Loss/seq after 04050 batchs: 445.51116943359375
INFO:root:Train (Epoch 152): Loss/seq after 04100 batchs: 444.4796447753906
INFO:root:Train (Epoch 152): Loss/seq after 04150 batchs: 444.5700988769531
INFO:root:Train (Epoch 152): Loss/seq after 04200 batchs: 443.5100402832031
INFO:root:Train (Epoch 152): Loss/seq after 04250 batchs: 442.0016784667969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 152): Loss/seq after 00000 batches: 370.2014465332031
INFO:root:# Valid (Epoch 152): Loss/seq after 00050 batches: 525.6270141601562
INFO:root:# Valid (Epoch 152): Loss/seq after 00100 batches: 550.1011962890625
INFO:root:# Valid (Epoch 152): Loss/seq after 00150 batches: 422.294921875
INFO:root:# Valid (Epoch 152): Loss/seq after 00200 batches: 397.6051940917969
INFO:root:Artifacts: Make stick videos for epoch 152
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_152_on_20220413_080920.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_152_index_427_on_20220413_080920.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 153): Loss/seq after 00000 batchs: 811.0992431640625
INFO:root:Train (Epoch 153): Loss/seq after 00050 batchs: 630.2040405273438
INFO:root:Train (Epoch 153): Loss/seq after 00100 batchs: 602.8431396484375
INFO:root:Train (Epoch 153): Loss/seq after 00150 batchs: 557.9651489257812
INFO:root:Train (Epoch 153): Loss/seq after 00200 batchs: 605.37451171875
INFO:root:Train (Epoch 153): Loss/seq after 00250 batchs: 673.59765625
INFO:root:Train (Epoch 153): Loss/seq after 00300 batchs: 682.0656127929688
INFO:root:Train (Epoch 153): Loss/seq after 00350 batchs: 641.5658569335938
INFO:root:Train (Epoch 153): Loss/seq after 00400 batchs: 629.540283203125
INFO:root:Train (Epoch 153): Loss/seq after 00450 batchs: 629.4660034179688
INFO:root:Train (Epoch 153): Loss/seq after 00500 batchs: 610.68310546875
INFO:root:Train (Epoch 153): Loss/seq after 00550 batchs: 595.4738159179688
INFO:root:Train (Epoch 153): Loss/seq after 00600 batchs: 575.9830932617188
INFO:root:Train (Epoch 153): Loss/seq after 00650 batchs: 554.3106079101562
INFO:root:Train (Epoch 153): Loss/seq after 00700 batchs: 532.5736694335938
INFO:root:Train (Epoch 153): Loss/seq after 00750 batchs: 533.533447265625
INFO:root:Train (Epoch 153): Loss/seq after 00800 batchs: 538.6026611328125
INFO:root:Train (Epoch 153): Loss/seq after 00850 batchs: 521.572265625
INFO:root:Train (Epoch 153): Loss/seq after 00900 batchs: 511.5023498535156
INFO:root:Train (Epoch 153): Loss/seq after 00950 batchs: 509.2068176269531
INFO:root:Train (Epoch 153): Loss/seq after 01000 batchs: 501.2400207519531
INFO:root:Train (Epoch 153): Loss/seq after 01050 batchs: 493.78466796875
INFO:root:Train (Epoch 153): Loss/seq after 01100 batchs: 486.5389099121094
INFO:root:Train (Epoch 153): Loss/seq after 01150 batchs: 473.7916564941406
INFO:root:Train (Epoch 153): Loss/seq after 01200 batchs: 478.6523132324219
INFO:root:Train (Epoch 153): Loss/seq after 01250 batchs: 478.6339416503906
INFO:root:Train (Epoch 153): Loss/seq after 01300 batchs: 469.1548767089844
INFO:root:Train (Epoch 153): Loss/seq after 01350 batchs: 461.706787109375
INFO:root:Train (Epoch 153): Loss/seq after 01400 batchs: 464.37164306640625
INFO:root:Train (Epoch 153): Loss/seq after 01450 batchs: 466.8343811035156
INFO:root:Train (Epoch 153): Loss/seq after 01500 batchs: 474.6091613769531
INFO:root:Train (Epoch 153): Loss/seq after 01550 batchs: 474.9148254394531
INFO:root:Train (Epoch 153): Loss/seq after 01600 batchs: 470.7555236816406
INFO:root:Train (Epoch 153): Loss/seq after 01650 batchs: 469.080078125
INFO:root:Train (Epoch 153): Loss/seq after 01700 batchs: 472.7457580566406
INFO:root:Train (Epoch 153): Loss/seq after 01750 batchs: 470.78179931640625
INFO:root:Train (Epoch 153): Loss/seq after 01800 batchs: 468.51153564453125
INFO:root:Train (Epoch 153): Loss/seq after 01850 batchs: 466.00030517578125
INFO:root:Train (Epoch 153): Loss/seq after 01900 batchs: 465.5262756347656
INFO:root:Train (Epoch 153): Loss/seq after 01950 batchs: 464.2145690917969
INFO:root:Train (Epoch 153): Loss/seq after 02000 batchs: 464.36871337890625
INFO:root:Train (Epoch 153): Loss/seq after 02050 batchs: 464.0234069824219
INFO:root:Train (Epoch 153): Loss/seq after 02100 batchs: 462.4256896972656
INFO:root:Train (Epoch 153): Loss/seq after 02150 batchs: 460.91754150390625
INFO:root:Train (Epoch 153): Loss/seq after 02200 batchs: 458.9970397949219
INFO:root:Train (Epoch 153): Loss/seq after 02250 batchs: 457.7655944824219
INFO:root:Train (Epoch 153): Loss/seq after 02300 batchs: 454.6707458496094
INFO:root:Train (Epoch 153): Loss/seq after 02350 batchs: 451.5575256347656
INFO:root:Train (Epoch 153): Loss/seq after 02400 batchs: 452.1324462890625
INFO:root:Train (Epoch 153): Loss/seq after 02450 batchs: 448.7012023925781
INFO:root:Train (Epoch 153): Loss/seq after 02500 batchs: 442.3465576171875
INFO:root:Train (Epoch 153): Loss/seq after 02550 batchs: 436.7786560058594
INFO:root:Train (Epoch 153): Loss/seq after 02600 batchs: 435.50970458984375
INFO:root:Train (Epoch 153): Loss/seq after 02650 batchs: 432.10089111328125
INFO:root:Train (Epoch 153): Loss/seq after 02700 batchs: 429.9060363769531
INFO:root:Train (Epoch 153): Loss/seq after 02750 batchs: 426.84246826171875
INFO:root:Train (Epoch 153): Loss/seq after 02800 batchs: 426.16314697265625
INFO:root:Train (Epoch 153): Loss/seq after 02850 batchs: 426.21343994140625
INFO:root:Train (Epoch 153): Loss/seq after 02900 batchs: 427.6310729980469
INFO:root:Train (Epoch 153): Loss/seq after 02950 batchs: 427.6022033691406
INFO:root:Train (Epoch 153): Loss/seq after 03000 batchs: 433.08984375
INFO:root:Train (Epoch 153): Loss/seq after 03050 batchs: 435.2737731933594
INFO:root:Train (Epoch 153): Loss/seq after 03100 batchs: 437.56634521484375
INFO:root:Train (Epoch 153): Loss/seq after 03150 batchs: 438.4839782714844
INFO:root:Train (Epoch 153): Loss/seq after 03200 batchs: 438.95794677734375
INFO:root:Train (Epoch 153): Loss/seq after 03250 batchs: 440.8658142089844
INFO:root:Train (Epoch 153): Loss/seq after 03300 batchs: 440.3212890625
INFO:root:Train (Epoch 153): Loss/seq after 03350 batchs: 439.5715026855469
INFO:root:Train (Epoch 153): Loss/seq after 03400 batchs: 436.2841491699219
INFO:root:Train (Epoch 153): Loss/seq after 03450 batchs: 435.406494140625
INFO:root:Train (Epoch 153): Loss/seq after 03500 batchs: 436.4905090332031
INFO:root:Train (Epoch 153): Loss/seq after 03550 batchs: 434.3077697753906
INFO:root:Train (Epoch 153): Loss/seq after 03600 batchs: 440.9574279785156
INFO:root:Train (Epoch 153): Loss/seq after 03650 batchs: 439.2950439453125
INFO:root:Train (Epoch 153): Loss/seq after 03700 batchs: 441.63116455078125
INFO:root:Train (Epoch 153): Loss/seq after 03750 batchs: 445.84429931640625
INFO:root:Train (Epoch 153): Loss/seq after 03800 batchs: 444.50665283203125
INFO:root:Train (Epoch 153): Loss/seq after 03850 batchs: 443.45550537109375
INFO:root:Train (Epoch 153): Loss/seq after 03900 batchs: 446.1269836425781
INFO:root:Train (Epoch 153): Loss/seq after 03950 batchs: 449.0755920410156
INFO:root:Train (Epoch 153): Loss/seq after 04000 batchs: 446.1141357421875
INFO:root:Train (Epoch 153): Loss/seq after 04050 batchs: 443.3056640625
INFO:root:Train (Epoch 153): Loss/seq after 04100 batchs: 442.2438049316406
INFO:root:Train (Epoch 153): Loss/seq after 04150 batchs: 442.35321044921875
INFO:root:Train (Epoch 153): Loss/seq after 04200 batchs: 441.2641906738281
INFO:root:Train (Epoch 153): Loss/seq after 04250 batchs: 439.74713134765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 153): Loss/seq after 00000 batches: 383.24468994140625
INFO:root:# Valid (Epoch 153): Loss/seq after 00050 batches: 536.7293090820312
INFO:root:# Valid (Epoch 153): Loss/seq after 00100 batches: 554.74169921875
INFO:root:# Valid (Epoch 153): Loss/seq after 00150 batches: 424.99688720703125
INFO:root:# Valid (Epoch 153): Loss/seq after 00200 batches: 399.48663330078125
INFO:root:Artifacts: Make stick videos for epoch 153
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_153_on_20220413_081442.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_153_index_1798_on_20220413_081442.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 154): Loss/seq after 00000 batchs: 834.0714721679688
INFO:root:Train (Epoch 154): Loss/seq after 00050 batchs: 637.588623046875
INFO:root:Train (Epoch 154): Loss/seq after 00100 batchs: 602.7238159179688
INFO:root:Train (Epoch 154): Loss/seq after 00150 batchs: 555.6442260742188
INFO:root:Train (Epoch 154): Loss/seq after 00200 batchs: 605.8157348632812
INFO:root:Train (Epoch 154): Loss/seq after 00250 batchs: 673.5542602539062
INFO:root:Train (Epoch 154): Loss/seq after 00300 batchs: 681.7086791992188
INFO:root:Train (Epoch 154): Loss/seq after 00350 batchs: 641.619140625
INFO:root:Train (Epoch 154): Loss/seq after 00400 batchs: 630.6358032226562
INFO:root:Train (Epoch 154): Loss/seq after 00450 batchs: 630.1936645507812
INFO:root:Train (Epoch 154): Loss/seq after 00500 batchs: 610.8662109375
INFO:root:Train (Epoch 154): Loss/seq after 00550 batchs: 594.9867553710938
INFO:root:Train (Epoch 154): Loss/seq after 00600 batchs: 574.8895874023438
INFO:root:Train (Epoch 154): Loss/seq after 00650 batchs: 554.1201171875
INFO:root:Train (Epoch 154): Loss/seq after 00700 batchs: 532.4823608398438
INFO:root:Train (Epoch 154): Loss/seq after 00750 batchs: 532.7583618164062
INFO:root:Train (Epoch 154): Loss/seq after 00800 batchs: 537.23486328125
INFO:root:Train (Epoch 154): Loss/seq after 00850 batchs: 519.967041015625
INFO:root:Train (Epoch 154): Loss/seq after 00900 batchs: 509.57244873046875
INFO:root:Train (Epoch 154): Loss/seq after 00950 batchs: 507.509521484375
INFO:root:Train (Epoch 154): Loss/seq after 01000 batchs: 498.901123046875
INFO:root:Train (Epoch 154): Loss/seq after 01050 batchs: 490.5684509277344
INFO:root:Train (Epoch 154): Loss/seq after 01100 batchs: 482.56353759765625
INFO:root:Train (Epoch 154): Loss/seq after 01150 batchs: 469.98626708984375
INFO:root:Train (Epoch 154): Loss/seq after 01200 batchs: 475.37109375
INFO:root:Train (Epoch 154): Loss/seq after 01250 batchs: 475.3324279785156
INFO:root:Train (Epoch 154): Loss/seq after 01300 batchs: 465.67431640625
INFO:root:Train (Epoch 154): Loss/seq after 01350 batchs: 458.2016906738281
INFO:root:Train (Epoch 154): Loss/seq after 01400 batchs: 460.8672180175781
INFO:root:Train (Epoch 154): Loss/seq after 01450 batchs: 463.3193359375
INFO:root:Train (Epoch 154): Loss/seq after 01500 batchs: 471.1295166015625
INFO:root:Train (Epoch 154): Loss/seq after 01550 batchs: 471.33380126953125
INFO:root:Train (Epoch 154): Loss/seq after 01600 batchs: 467.1759338378906
INFO:root:Train (Epoch 154): Loss/seq after 01650 batchs: 465.55987548828125
INFO:root:Train (Epoch 154): Loss/seq after 01700 batchs: 469.75714111328125
INFO:root:Train (Epoch 154): Loss/seq after 01750 batchs: 467.8212890625
INFO:root:Train (Epoch 154): Loss/seq after 01800 batchs: 465.66058349609375
INFO:root:Train (Epoch 154): Loss/seq after 01850 batchs: 463.16021728515625
INFO:root:Train (Epoch 154): Loss/seq after 01900 batchs: 462.819091796875
INFO:root:Train (Epoch 154): Loss/seq after 01950 batchs: 461.42724609375
INFO:root:Train (Epoch 154): Loss/seq after 02000 batchs: 461.572021484375
INFO:root:Train (Epoch 154): Loss/seq after 02050 batchs: 461.4901123046875
INFO:root:Train (Epoch 154): Loss/seq after 02100 batchs: 459.9181213378906
INFO:root:Train (Epoch 154): Loss/seq after 02150 batchs: 458.3232116699219
INFO:root:Train (Epoch 154): Loss/seq after 02200 batchs: 456.46185302734375
INFO:root:Train (Epoch 154): Loss/seq after 02250 batchs: 455.0234375
INFO:root:Train (Epoch 154): Loss/seq after 02300 batchs: 451.734619140625
INFO:root:Train (Epoch 154): Loss/seq after 02350 batchs: 448.5596618652344
INFO:root:Train (Epoch 154): Loss/seq after 02400 batchs: 449.010009765625
INFO:root:Train (Epoch 154): Loss/seq after 02450 batchs: 445.5474853515625
INFO:root:Train (Epoch 154): Loss/seq after 02500 batchs: 439.19403076171875
INFO:root:Train (Epoch 154): Loss/seq after 02550 batchs: 433.6059265136719
INFO:root:Train (Epoch 154): Loss/seq after 02600 batchs: 432.4001770019531
INFO:root:Train (Epoch 154): Loss/seq after 02650 batchs: 428.88519287109375
INFO:root:Train (Epoch 154): Loss/seq after 02700 batchs: 426.56207275390625
INFO:root:Train (Epoch 154): Loss/seq after 02750 batchs: 423.4391784667969
INFO:root:Train (Epoch 154): Loss/seq after 02800 batchs: 422.0343017578125
INFO:root:Train (Epoch 154): Loss/seq after 02850 batchs: 422.06451416015625
INFO:root:Train (Epoch 154): Loss/seq after 02900 batchs: 423.4095764160156
INFO:root:Train (Epoch 154): Loss/seq after 02950 batchs: 423.358642578125
INFO:root:Train (Epoch 154): Loss/seq after 03000 batchs: 428.8711853027344
INFO:root:Train (Epoch 154): Loss/seq after 03050 batchs: 431.0636901855469
INFO:root:Train (Epoch 154): Loss/seq after 03100 batchs: 433.2377014160156
INFO:root:Train (Epoch 154): Loss/seq after 03150 batchs: 434.43927001953125
INFO:root:Train (Epoch 154): Loss/seq after 03200 batchs: 434.6956787109375
INFO:root:Train (Epoch 154): Loss/seq after 03250 batchs: 436.33892822265625
INFO:root:Train (Epoch 154): Loss/seq after 03300 batchs: 435.70037841796875
INFO:root:Train (Epoch 154): Loss/seq after 03350 batchs: 435.15069580078125
INFO:root:Train (Epoch 154): Loss/seq after 03400 batchs: 432.0260925292969
INFO:root:Train (Epoch 154): Loss/seq after 03450 batchs: 431.0192565917969
INFO:root:Train (Epoch 154): Loss/seq after 03500 batchs: 432.06317138671875
INFO:root:Train (Epoch 154): Loss/seq after 03550 batchs: 429.8539123535156
INFO:root:Train (Epoch 154): Loss/seq after 03600 batchs: 436.5610046386719
INFO:root:Train (Epoch 154): Loss/seq after 03650 batchs: 434.97900390625
INFO:root:Train (Epoch 154): Loss/seq after 03700 batchs: 437.2718811035156
INFO:root:Train (Epoch 154): Loss/seq after 03750 batchs: 441.4200744628906
INFO:root:Train (Epoch 154): Loss/seq after 03800 batchs: 440.144287109375
INFO:root:Train (Epoch 154): Loss/seq after 03850 batchs: 439.158203125
INFO:root:Train (Epoch 154): Loss/seq after 03900 batchs: 441.9324035644531
INFO:root:Train (Epoch 154): Loss/seq after 03950 batchs: 444.8638916015625
INFO:root:Train (Epoch 154): Loss/seq after 04000 batchs: 441.9365539550781
INFO:root:Train (Epoch 154): Loss/seq after 04050 batchs: 439.1795959472656
INFO:root:Train (Epoch 154): Loss/seq after 04100 batchs: 438.17431640625
INFO:root:Train (Epoch 154): Loss/seq after 04150 batchs: 438.3043518066406
INFO:root:Train (Epoch 154): Loss/seq after 04200 batchs: 437.25421142578125
INFO:root:Train (Epoch 154): Loss/seq after 04250 batchs: 435.7777099609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 154): Loss/seq after 00000 batches: 362.1250915527344
INFO:root:# Valid (Epoch 154): Loss/seq after 00050 batches: 525.5564575195312
INFO:root:# Valid (Epoch 154): Loss/seq after 00100 batches: 548.5490112304688
INFO:root:# Valid (Epoch 154): Loss/seq after 00150 batches: 422.017822265625
INFO:root:# Valid (Epoch 154): Loss/seq after 00200 batches: 398.1318054199219
INFO:root:Artifacts: Make stick videos for epoch 154
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_154_on_20220413_082005.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_154_index_11_on_20220413_082005.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 155): Loss/seq after 00000 batchs: 819.0180053710938
INFO:root:Train (Epoch 155): Loss/seq after 00050 batchs: 615.7515258789062
INFO:root:Train (Epoch 155): Loss/seq after 00100 batchs: 589.697998046875
INFO:root:Train (Epoch 155): Loss/seq after 00150 batchs: 544.0676879882812
INFO:root:Train (Epoch 155): Loss/seq after 00200 batchs: 597.5200805664062
INFO:root:Train (Epoch 155): Loss/seq after 00250 batchs: 663.9725952148438
INFO:root:Train (Epoch 155): Loss/seq after 00300 batchs: 675.1754150390625
INFO:root:Train (Epoch 155): Loss/seq after 00350 batchs: 635.9652709960938
INFO:root:Train (Epoch 155): Loss/seq after 00400 batchs: 623.8113403320312
INFO:root:Train (Epoch 155): Loss/seq after 00450 batchs: 624.3710327148438
INFO:root:Train (Epoch 155): Loss/seq after 00500 batchs: 604.287353515625
INFO:root:Train (Epoch 155): Loss/seq after 00550 batchs: 589.53564453125
INFO:root:Train (Epoch 155): Loss/seq after 00600 batchs: 569.6326904296875
INFO:root:Train (Epoch 155): Loss/seq after 00650 batchs: 548.4963989257812
INFO:root:Train (Epoch 155): Loss/seq after 00700 batchs: 526.3991088867188
INFO:root:Train (Epoch 155): Loss/seq after 00750 batchs: 526.3558959960938
INFO:root:Train (Epoch 155): Loss/seq after 00800 batchs: 531.6093139648438
INFO:root:Train (Epoch 155): Loss/seq after 00850 batchs: 515.0853271484375
INFO:root:Train (Epoch 155): Loss/seq after 00900 batchs: 504.8458557128906
INFO:root:Train (Epoch 155): Loss/seq after 00950 batchs: 502.7940673828125
INFO:root:Train (Epoch 155): Loss/seq after 01000 batchs: 494.9082946777344
INFO:root:Train (Epoch 155): Loss/seq after 01050 batchs: 486.3801574707031
INFO:root:Train (Epoch 155): Loss/seq after 01100 batchs: 478.02203369140625
INFO:root:Train (Epoch 155): Loss/seq after 01150 batchs: 465.7401428222656
INFO:root:Train (Epoch 155): Loss/seq after 01200 batchs: 470.49713134765625
INFO:root:Train (Epoch 155): Loss/seq after 01250 batchs: 470.7806396484375
INFO:root:Train (Epoch 155): Loss/seq after 01300 batchs: 461.3560791015625
INFO:root:Train (Epoch 155): Loss/seq after 01350 batchs: 454.2292175292969
INFO:root:Train (Epoch 155): Loss/seq after 01400 batchs: 456.4220886230469
INFO:root:Train (Epoch 155): Loss/seq after 01450 batchs: 459.2842102050781
INFO:root:Train (Epoch 155): Loss/seq after 01500 batchs: 467.2723693847656
INFO:root:Train (Epoch 155): Loss/seq after 01550 batchs: 467.4372863769531
INFO:root:Train (Epoch 155): Loss/seq after 01600 batchs: 463.419921875
INFO:root:Train (Epoch 155): Loss/seq after 01650 batchs: 461.8426513671875
INFO:root:Train (Epoch 155): Loss/seq after 01700 batchs: 465.9528503417969
INFO:root:Train (Epoch 155): Loss/seq after 01750 batchs: 464.0447692871094
INFO:root:Train (Epoch 155): Loss/seq after 01800 batchs: 461.8268127441406
INFO:root:Train (Epoch 155): Loss/seq after 01850 batchs: 459.39495849609375
INFO:root:Train (Epoch 155): Loss/seq after 01900 batchs: 458.6016540527344
INFO:root:Train (Epoch 155): Loss/seq after 01950 batchs: 457.5257263183594
INFO:root:Train (Epoch 155): Loss/seq after 02000 batchs: 457.8342590332031
INFO:root:Train (Epoch 155): Loss/seq after 02050 batchs: 457.7158508300781
INFO:root:Train (Epoch 155): Loss/seq after 02100 batchs: 456.3125915527344
INFO:root:Train (Epoch 155): Loss/seq after 02150 batchs: 454.9358825683594
INFO:root:Train (Epoch 155): Loss/seq after 02200 batchs: 453.0926208496094
INFO:root:Train (Epoch 155): Loss/seq after 02250 batchs: 451.7807312011719
INFO:root:Train (Epoch 155): Loss/seq after 02300 batchs: 448.4880065917969
INFO:root:Train (Epoch 155): Loss/seq after 02350 batchs: 445.5613098144531
INFO:root:Train (Epoch 155): Loss/seq after 02400 batchs: 446.13275146484375
INFO:root:Train (Epoch 155): Loss/seq after 02450 batchs: 442.6993408203125
INFO:root:Train (Epoch 155): Loss/seq after 02500 batchs: 436.4170837402344
INFO:root:Train (Epoch 155): Loss/seq after 02550 batchs: 430.8362731933594
INFO:root:Train (Epoch 155): Loss/seq after 02600 batchs: 429.6278381347656
INFO:root:Train (Epoch 155): Loss/seq after 02650 batchs: 426.19354248046875
INFO:root:Train (Epoch 155): Loss/seq after 02700 batchs: 424.0425109863281
INFO:root:Train (Epoch 155): Loss/seq after 02750 batchs: 421.06732177734375
INFO:root:Train (Epoch 155): Loss/seq after 02800 batchs: 419.7138977050781
INFO:root:Train (Epoch 155): Loss/seq after 02850 batchs: 419.77349853515625
INFO:root:Train (Epoch 155): Loss/seq after 02900 batchs: 421.1547546386719
INFO:root:Train (Epoch 155): Loss/seq after 02950 batchs: 421.1534729003906
INFO:root:Train (Epoch 155): Loss/seq after 03000 batchs: 426.7427978515625
INFO:root:Train (Epoch 155): Loss/seq after 03050 batchs: 429.10400390625
INFO:root:Train (Epoch 155): Loss/seq after 03100 batchs: 431.405517578125
INFO:root:Train (Epoch 155): Loss/seq after 03150 batchs: 432.3064880371094
INFO:root:Train (Epoch 155): Loss/seq after 03200 batchs: 432.6719970703125
INFO:root:Train (Epoch 155): Loss/seq after 03250 batchs: 434.5585021972656
INFO:root:Train (Epoch 155): Loss/seq after 03300 batchs: 433.9090881347656
INFO:root:Train (Epoch 155): Loss/seq after 03350 batchs: 433.01422119140625
INFO:root:Train (Epoch 155): Loss/seq after 03400 batchs: 429.84783935546875
INFO:root:Train (Epoch 155): Loss/seq after 03450 batchs: 428.8472900390625
INFO:root:Train (Epoch 155): Loss/seq after 03500 batchs: 429.8115539550781
INFO:root:Train (Epoch 155): Loss/seq after 03550 batchs: 427.60064697265625
INFO:root:Train (Epoch 155): Loss/seq after 03600 batchs: 434.3094787597656
INFO:root:Train (Epoch 155): Loss/seq after 03650 batchs: 432.6703796386719
INFO:root:Train (Epoch 155): Loss/seq after 03700 batchs: 434.99798583984375
INFO:root:Train (Epoch 155): Loss/seq after 03750 batchs: 439.2242126464844
INFO:root:Train (Epoch 155): Loss/seq after 03800 batchs: 437.97314453125
INFO:root:Train (Epoch 155): Loss/seq after 03850 batchs: 437.0030822753906
INFO:root:Train (Epoch 155): Loss/seq after 03900 batchs: 439.7460021972656
INFO:root:Train (Epoch 155): Loss/seq after 03950 batchs: 442.7151184082031
INFO:root:Train (Epoch 155): Loss/seq after 04000 batchs: 439.7913513183594
INFO:root:Train (Epoch 155): Loss/seq after 04050 batchs: 437.0332946777344
INFO:root:Train (Epoch 155): Loss/seq after 04100 batchs: 436.0318603515625
INFO:root:Train (Epoch 155): Loss/seq after 04150 batchs: 436.17083740234375
INFO:root:Train (Epoch 155): Loss/seq after 04200 batchs: 435.11279296875
INFO:root:Train (Epoch 155): Loss/seq after 04250 batchs: 433.70513916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 155): Loss/seq after 00000 batches: 365.17059326171875
INFO:root:# Valid (Epoch 155): Loss/seq after 00050 batches: 523.9396362304688
INFO:root:# Valid (Epoch 155): Loss/seq after 00100 batches: 555.1701049804688
INFO:root:# Valid (Epoch 155): Loss/seq after 00150 batches: 426.3897399902344
INFO:root:# Valid (Epoch 155): Loss/seq after 00200 batches: 402.85540771484375
INFO:root:Artifacts: Make stick videos for epoch 155
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_155_on_20220413_082528.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_155_index_1199_on_20220413_082528.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 156): Loss/seq after 00000 batchs: 818.2189331054688
INFO:root:Train (Epoch 156): Loss/seq after 00050 batchs: 605.7223510742188
INFO:root:Train (Epoch 156): Loss/seq after 00100 batchs: 588.7575073242188
INFO:root:Train (Epoch 156): Loss/seq after 00150 batchs: 543.965087890625
INFO:root:Train (Epoch 156): Loss/seq after 00200 batchs: 595.9854125976562
INFO:root:Train (Epoch 156): Loss/seq after 00250 batchs: 659.469482421875
INFO:root:Train (Epoch 156): Loss/seq after 00300 batchs: 667.1844482421875
INFO:root:Train (Epoch 156): Loss/seq after 00350 batchs: 627.985107421875
INFO:root:Train (Epoch 156): Loss/seq after 00400 batchs: 616.6231689453125
INFO:root:Train (Epoch 156): Loss/seq after 00450 batchs: 617.8253173828125
INFO:root:Train (Epoch 156): Loss/seq after 00500 batchs: 600.2745361328125
INFO:root:Train (Epoch 156): Loss/seq after 00550 batchs: 586.681884765625
INFO:root:Train (Epoch 156): Loss/seq after 00600 batchs: 568.3613891601562
INFO:root:Train (Epoch 156): Loss/seq after 00650 batchs: 547.2305297851562
INFO:root:Train (Epoch 156): Loss/seq after 00700 batchs: 525.5684204101562
INFO:root:Train (Epoch 156): Loss/seq after 00750 batchs: 524.7908935546875
INFO:root:Train (Epoch 156): Loss/seq after 00800 batchs: 530.5840454101562
INFO:root:Train (Epoch 156): Loss/seq after 00850 batchs: 514.0640869140625
INFO:root:Train (Epoch 156): Loss/seq after 00900 batchs: 504.2666320800781
INFO:root:Train (Epoch 156): Loss/seq after 00950 batchs: 502.3012390136719
INFO:root:Train (Epoch 156): Loss/seq after 01000 batchs: 494.271240234375
INFO:root:Train (Epoch 156): Loss/seq after 01050 batchs: 486.09576416015625
INFO:root:Train (Epoch 156): Loss/seq after 01100 batchs: 478.2951354980469
INFO:root:Train (Epoch 156): Loss/seq after 01150 batchs: 465.8724670410156
INFO:root:Train (Epoch 156): Loss/seq after 01200 batchs: 470.70404052734375
INFO:root:Train (Epoch 156): Loss/seq after 01250 batchs: 470.9783630371094
INFO:root:Train (Epoch 156): Loss/seq after 01300 batchs: 461.4233703613281
INFO:root:Train (Epoch 156): Loss/seq after 01350 batchs: 453.9168395996094
INFO:root:Train (Epoch 156): Loss/seq after 01400 batchs: 456.6197814941406
INFO:root:Train (Epoch 156): Loss/seq after 01450 batchs: 459.2786865234375
INFO:root:Train (Epoch 156): Loss/seq after 01500 batchs: 466.8121337890625
INFO:root:Train (Epoch 156): Loss/seq after 01550 batchs: 467.1026916503906
INFO:root:Train (Epoch 156): Loss/seq after 01600 batchs: 462.9753723144531
INFO:root:Train (Epoch 156): Loss/seq after 01650 batchs: 461.4551696777344
INFO:root:Train (Epoch 156): Loss/seq after 01700 batchs: 465.53515625
INFO:root:Train (Epoch 156): Loss/seq after 01750 batchs: 463.4564514160156
INFO:root:Train (Epoch 156): Loss/seq after 01800 batchs: 461.30377197265625
INFO:root:Train (Epoch 156): Loss/seq after 01850 batchs: 458.7400207519531
INFO:root:Train (Epoch 156): Loss/seq after 01900 batchs: 458.1940002441406
INFO:root:Train (Epoch 156): Loss/seq after 01950 batchs: 457.0610656738281
INFO:root:Train (Epoch 156): Loss/seq after 02000 batchs: 457.40325927734375
INFO:root:Train (Epoch 156): Loss/seq after 02050 batchs: 457.21893310546875
INFO:root:Train (Epoch 156): Loss/seq after 02100 batchs: 455.6543884277344
INFO:root:Train (Epoch 156): Loss/seq after 02150 batchs: 454.2310791015625
INFO:root:Train (Epoch 156): Loss/seq after 02200 batchs: 452.4546203613281
INFO:root:Train (Epoch 156): Loss/seq after 02250 batchs: 451.073974609375
INFO:root:Train (Epoch 156): Loss/seq after 02300 batchs: 447.86688232421875
INFO:root:Train (Epoch 156): Loss/seq after 02350 batchs: 444.78741455078125
INFO:root:Train (Epoch 156): Loss/seq after 02400 batchs: 445.34954833984375
INFO:root:Train (Epoch 156): Loss/seq after 02450 batchs: 441.97796630859375
INFO:root:Train (Epoch 156): Loss/seq after 02500 batchs: 435.69952392578125
INFO:root:Train (Epoch 156): Loss/seq after 02550 batchs: 430.109375
INFO:root:Train (Epoch 156): Loss/seq after 02600 batchs: 428.68707275390625
INFO:root:Train (Epoch 156): Loss/seq after 02650 batchs: 425.1358947753906
INFO:root:Train (Epoch 156): Loss/seq after 02700 batchs: 422.9176025390625
INFO:root:Train (Epoch 156): Loss/seq after 02750 batchs: 419.6805725097656
INFO:root:Train (Epoch 156): Loss/seq after 02800 batchs: 418.1374816894531
INFO:root:Train (Epoch 156): Loss/seq after 02850 batchs: 417.96826171875
INFO:root:Train (Epoch 156): Loss/seq after 02900 batchs: 419.3179016113281
INFO:root:Train (Epoch 156): Loss/seq after 02950 batchs: 419.2596435546875
INFO:root:Train (Epoch 156): Loss/seq after 03000 batchs: 424.7392272949219
INFO:root:Train (Epoch 156): Loss/seq after 03050 batchs: 426.8370361328125
INFO:root:Train (Epoch 156): Loss/seq after 03100 batchs: 428.7080993652344
INFO:root:Train (Epoch 156): Loss/seq after 03150 batchs: 429.47869873046875
INFO:root:Train (Epoch 156): Loss/seq after 03200 batchs: 429.4692077636719
INFO:root:Train (Epoch 156): Loss/seq after 03250 batchs: 431.6116638183594
INFO:root:Train (Epoch 156): Loss/seq after 03300 batchs: 431.0855407714844
INFO:root:Train (Epoch 156): Loss/seq after 03350 batchs: 430.1891784667969
INFO:root:Train (Epoch 156): Loss/seq after 03400 batchs: 427.06793212890625
INFO:root:Train (Epoch 156): Loss/seq after 03450 batchs: 426.1390380859375
INFO:root:Train (Epoch 156): Loss/seq after 03500 batchs: 427.13836669921875
INFO:root:Train (Epoch 156): Loss/seq after 03550 batchs: 425.06597900390625
INFO:root:Train (Epoch 156): Loss/seq after 03600 batchs: 431.683837890625
INFO:root:Train (Epoch 156): Loss/seq after 03650 batchs: 430.08489990234375
INFO:root:Train (Epoch 156): Loss/seq after 03700 batchs: 432.31378173828125
INFO:root:Train (Epoch 156): Loss/seq after 03750 batchs: 436.5746765136719
INFO:root:Train (Epoch 156): Loss/seq after 03800 batchs: 435.33642578125
INFO:root:Train (Epoch 156): Loss/seq after 03850 batchs: 434.42218017578125
INFO:root:Train (Epoch 156): Loss/seq after 03900 batchs: 436.9374694824219
INFO:root:Train (Epoch 156): Loss/seq after 03950 batchs: 439.8067626953125
INFO:root:Train (Epoch 156): Loss/seq after 04000 batchs: 436.933349609375
INFO:root:Train (Epoch 156): Loss/seq after 04050 batchs: 434.201171875
INFO:root:Train (Epoch 156): Loss/seq after 04100 batchs: 433.2608642578125
INFO:root:Train (Epoch 156): Loss/seq after 04150 batchs: 433.37518310546875
INFO:root:Train (Epoch 156): Loss/seq after 04200 batchs: 432.4421691894531
INFO:root:Train (Epoch 156): Loss/seq after 04250 batchs: 431.05621337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 156): Loss/seq after 00000 batches: 383.0657958984375
INFO:root:# Valid (Epoch 156): Loss/seq after 00050 batches: 539.4743041992188
INFO:root:# Valid (Epoch 156): Loss/seq after 00100 batches: 559.170654296875
INFO:root:# Valid (Epoch 156): Loss/seq after 00150 batches: 431.68707275390625
INFO:root:# Valid (Epoch 156): Loss/seq after 00200 batches: 410.01739501953125
INFO:root:Artifacts: Make stick videos for epoch 156
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_156_on_20220413_083051.gif.
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_156_index_1852_on_20220413_083051.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 157): Loss/seq after 00000 batchs: 710.9571533203125
INFO:root:Train (Epoch 157): Loss/seq after 00050 batchs: 631.3800659179688
INFO:root:Train (Epoch 157): Loss/seq after 00100 batchs: 598.3447265625
INFO:root:Train (Epoch 157): Loss/seq after 00150 batchs: 552.0323486328125
INFO:root:Train (Epoch 157): Loss/seq after 00200 batchs: 599.0838623046875
INFO:root:Train (Epoch 157): Loss/seq after 00250 batchs: 665.1929931640625
INFO:root:Train (Epoch 157): Loss/seq after 00300 batchs: 673.6323852539062
INFO:root:Train (Epoch 157): Loss/seq after 00350 batchs: 633.3863525390625
INFO:root:Train (Epoch 157): Loss/seq after 00400 batchs: 620.6490478515625
INFO:root:Train (Epoch 157): Loss/seq after 00450 batchs: 621.4149780273438
INFO:root:Train (Epoch 157): Loss/seq after 00500 batchs: 602.0228881835938
INFO:root:Train (Epoch 157): Loss/seq after 00550 batchs: 588.2193603515625
INFO:root:Train (Epoch 157): Loss/seq after 00600 batchs: 568.809326171875
INFO:root:Train (Epoch 157): Loss/seq after 00650 batchs: 548.5087890625
INFO:root:Train (Epoch 157): Loss/seq after 00700 batchs: 525.90625
INFO:root:Train (Epoch 157): Loss/seq after 00750 batchs: 525.4154052734375
INFO:root:Train (Epoch 157): Loss/seq after 00800 batchs: 531.0774536132812
INFO:root:Train (Epoch 157): Loss/seq after 00850 batchs: 514.2841186523438
INFO:root:Train (Epoch 157): Loss/seq after 00900 batchs: 503.9689025878906
INFO:root:Train (Epoch 157): Loss/seq after 00950 batchs: 501.5320739746094
INFO:root:Train (Epoch 157): Loss/seq after 01000 batchs: 493.3301696777344
INFO:root:Train (Epoch 157): Loss/seq after 01050 batchs: 484.4349060058594
INFO:root:Train (Epoch 157): Loss/seq after 01100 batchs: 476.3188171386719
INFO:root:Train (Epoch 157): Loss/seq after 01150 batchs: 463.768798828125
INFO:root:Train (Epoch 157): Loss/seq after 01200 batchs: 468.4568176269531
INFO:root:Train (Epoch 157): Loss/seq after 01250 batchs: 469.0354309082031
INFO:root:Train (Epoch 157): Loss/seq after 01300 batchs: 459.6715393066406
INFO:root:Train (Epoch 157): Loss/seq after 01350 batchs: 452.2834167480469
INFO:root:Train (Epoch 157): Loss/seq after 01400 batchs: 454.3122863769531
INFO:root:Train (Epoch 157): Loss/seq after 01450 batchs: 457.00982666015625
INFO:root:Train (Epoch 157): Loss/seq after 01500 batchs: 464.6932678222656
INFO:root:Train (Epoch 157): Loss/seq after 01550 batchs: 465.2509460449219
INFO:root:Train (Epoch 157): Loss/seq after 01600 batchs: 461.275634765625
INFO:root:Train (Epoch 157): Loss/seq after 01650 batchs: 459.5492248535156
INFO:root:Train (Epoch 157): Loss/seq after 01700 batchs: 463.43109130859375
INFO:root:Train (Epoch 157): Loss/seq after 01750 batchs: 461.4801330566406
INFO:root:Train (Epoch 157): Loss/seq after 01800 batchs: 459.2248840332031
INFO:root:Train (Epoch 157): Loss/seq after 01850 batchs: 456.7746276855469
INFO:root:Train (Epoch 157): Loss/seq after 01900 batchs: 456.2945861816406
INFO:root:Train (Epoch 157): Loss/seq after 01950 batchs: 455.0139465332031
INFO:root:Train (Epoch 157): Loss/seq after 02000 batchs: 455.313232421875
INFO:root:Train (Epoch 157): Loss/seq after 02050 batchs: 455.1166687011719
INFO:root:Train (Epoch 157): Loss/seq after 02100 batchs: 453.5919494628906
INFO:root:Train (Epoch 157): Loss/seq after 02150 batchs: 452.1073303222656
INFO:root:Train (Epoch 157): Loss/seq after 02200 batchs: 450.13995361328125
INFO:root:Train (Epoch 157): Loss/seq after 02250 batchs: 448.8829650878906
INFO:root:Train (Epoch 157): Loss/seq after 02300 batchs: 445.6568603515625
INFO:root:Train (Epoch 157): Loss/seq after 02350 batchs: 442.7795104980469
INFO:root:Train (Epoch 157): Loss/seq after 02400 batchs: 443.3285217285156
INFO:root:Train (Epoch 157): Loss/seq after 02450 batchs: 440.0282897949219
INFO:root:Train (Epoch 157): Loss/seq after 02500 batchs: 433.7773742675781
INFO:root:Train (Epoch 157): Loss/seq after 02550 batchs: 428.1703186035156
INFO:root:Train (Epoch 157): Loss/seq after 02600 batchs: 426.8184814453125
INFO:root:Train (Epoch 157): Loss/seq after 02650 batchs: 423.2839050292969
INFO:root:Train (Epoch 157): Loss/seq after 02700 batchs: 420.87982177734375
INFO:root:Train (Epoch 157): Loss/seq after 02750 batchs: 418.0317687988281
INFO:root:Train (Epoch 157): Loss/seq after 02800 batchs: 416.2342834472656
INFO:root:Train (Epoch 157): Loss/seq after 02850 batchs: 416.20269775390625
INFO:root:Train (Epoch 157): Loss/seq after 02900 batchs: 417.4330139160156
INFO:root:Train (Epoch 157): Loss/seq after 02950 batchs: 417.38909912109375
INFO:root:Train (Epoch 157): Loss/seq after 03000 batchs: 422.968994140625
INFO:root:Train (Epoch 157): Loss/seq after 03050 batchs: 425.1370544433594
INFO:root:Train (Epoch 157): Loss/seq after 03100 batchs: 427.1709289550781
INFO:root:Train (Epoch 157): Loss/seq after 03150 batchs: 428.4289245605469
INFO:root:Train (Epoch 157): Loss/seq after 03200 batchs: 428.83880615234375
INFO:root:Train (Epoch 157): Loss/seq after 03250 batchs: 430.3539123535156
INFO:root:Train (Epoch 157): Loss/seq after 03300 batchs: 429.7950439453125
INFO:root:Train (Epoch 157): Loss/seq after 03350 batchs: 428.8437194824219
INFO:root:Train (Epoch 157): Loss/seq after 03400 batchs: 425.6232604980469
INFO:root:Train (Epoch 157): Loss/seq after 03450 batchs: 424.5698547363281
INFO:root:Train (Epoch 157): Loss/seq after 03500 batchs: 425.5962219238281
INFO:root:Train (Epoch 157): Loss/seq after 03550 batchs: 423.4886779785156
INFO:root:Train (Epoch 157): Loss/seq after 03600 batchs: 430.1029052734375
INFO:root:Train (Epoch 157): Loss/seq after 03650 batchs: 428.5267639160156
INFO:root:Train (Epoch 157): Loss/seq after 03700 batchs: 430.8309326171875
INFO:root:Train (Epoch 157): Loss/seq after 03750 batchs: 434.9786376953125
INFO:root:Train (Epoch 157): Loss/seq after 03800 batchs: 433.78948974609375
INFO:root:Train (Epoch 157): Loss/seq after 03850 batchs: 432.79144287109375
INFO:root:Train (Epoch 157): Loss/seq after 03900 batchs: 435.0878601074219
INFO:root:Train (Epoch 157): Loss/seq after 03950 batchs: 437.9661865234375
INFO:root:Train (Epoch 157): Loss/seq after 04000 batchs: 435.1214294433594
INFO:root:Train (Epoch 157): Loss/seq after 04050 batchs: 432.41314697265625
INFO:root:Train (Epoch 157): Loss/seq after 04100 batchs: 431.4539794921875
INFO:root:Train (Epoch 157): Loss/seq after 04150 batchs: 431.64276123046875
INFO:root:Train (Epoch 157): Loss/seq after 04200 batchs: 430.73126220703125
INFO:root:Train (Epoch 157): Loss/seq after 04250 batchs: 429.31005859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 157): Loss/seq after 00000 batches: 354.0929870605469
INFO:root:# Valid (Epoch 157): Loss/seq after 00050 batches: 521.5096435546875
INFO:root:# Valid (Epoch 157): Loss/seq after 00100 batches: 549.4984130859375
INFO:root:# Valid (Epoch 157): Loss/seq after 00150 batches: 421.2492370605469
INFO:root:# Valid (Epoch 157): Loss/seq after 00200 batches: 395.69586181640625
INFO:root:Artifacts: Make stick videos for epoch 157
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_157_on_20220413_083648.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_157_index_1373_on_20220413_083648.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 158): Loss/seq after 00000 batchs: 778.146240234375
INFO:root:Train (Epoch 158): Loss/seq after 00050 batchs: 620.7418212890625
INFO:root:Train (Epoch 158): Loss/seq after 00100 batchs: 582.2754516601562
INFO:root:Train (Epoch 158): Loss/seq after 00150 batchs: 537.630859375
INFO:root:Train (Epoch 158): Loss/seq after 00200 batchs: 588.2504272460938
INFO:root:Train (Epoch 158): Loss/seq after 00250 batchs: 654.0125732421875
INFO:root:Train (Epoch 158): Loss/seq after 00300 batchs: 663.0618896484375
INFO:root:Train (Epoch 158): Loss/seq after 00350 batchs: 624.6685180664062
INFO:root:Train (Epoch 158): Loss/seq after 00400 batchs: 611.6810302734375
INFO:root:Train (Epoch 158): Loss/seq after 00450 batchs: 612.6597290039062
INFO:root:Train (Epoch 158): Loss/seq after 00500 batchs: 593.9066772460938
INFO:root:Train (Epoch 158): Loss/seq after 00550 batchs: 580.2362670898438
INFO:root:Train (Epoch 158): Loss/seq after 00600 batchs: 561.5370483398438
INFO:root:Train (Epoch 158): Loss/seq after 00650 batchs: 541.9681396484375
INFO:root:Train (Epoch 158): Loss/seq after 00700 batchs: 520.0780639648438
INFO:root:Train (Epoch 158): Loss/seq after 00750 batchs: 519.7745971679688
INFO:root:Train (Epoch 158): Loss/seq after 00800 batchs: 525.4337158203125
INFO:root:Train (Epoch 158): Loss/seq after 00850 batchs: 509.1146240234375
INFO:root:Train (Epoch 158): Loss/seq after 00900 batchs: 499.355224609375
INFO:root:Train (Epoch 158): Loss/seq after 00950 batchs: 496.8807373046875
INFO:root:Train (Epoch 158): Loss/seq after 01000 batchs: 488.555419921875
INFO:root:Train (Epoch 158): Loss/seq after 01050 batchs: 480.33502197265625
INFO:root:Train (Epoch 158): Loss/seq after 01100 batchs: 472.2596740722656
INFO:root:Train (Epoch 158): Loss/seq after 01150 batchs: 459.9053039550781
INFO:root:Train (Epoch 158): Loss/seq after 01200 batchs: 464.9782409667969
INFO:root:Train (Epoch 158): Loss/seq after 01250 batchs: 465.271484375
INFO:root:Train (Epoch 158): Loss/seq after 01300 batchs: 455.92138671875
INFO:root:Train (Epoch 158): Loss/seq after 01350 batchs: 448.9450378417969
INFO:root:Train (Epoch 158): Loss/seq after 01400 batchs: 451.9523620605469
INFO:root:Train (Epoch 158): Loss/seq after 01450 batchs: 454.8892517089844
INFO:root:Train (Epoch 158): Loss/seq after 01500 batchs: 462.6029357910156
INFO:root:Train (Epoch 158): Loss/seq after 01550 batchs: 462.79718017578125
INFO:root:Train (Epoch 158): Loss/seq after 01600 batchs: 458.8674011230469
INFO:root:Train (Epoch 158): Loss/seq after 01650 batchs: 457.0070495605469
INFO:root:Train (Epoch 158): Loss/seq after 01700 batchs: 461.0537414550781
INFO:root:Train (Epoch 158): Loss/seq after 01750 batchs: 459.0643310546875
INFO:root:Train (Epoch 158): Loss/seq after 01800 batchs: 457.0140075683594
INFO:root:Train (Epoch 158): Loss/seq after 01850 batchs: 454.644287109375
INFO:root:Train (Epoch 158): Loss/seq after 01900 batchs: 454.16021728515625
INFO:root:Train (Epoch 158): Loss/seq after 01950 batchs: 453.19940185546875
INFO:root:Train (Epoch 158): Loss/seq after 02000 batchs: 453.5822448730469
INFO:root:Train (Epoch 158): Loss/seq after 02050 batchs: 453.6587829589844
INFO:root:Train (Epoch 158): Loss/seq after 02100 batchs: 452.2354736328125
INFO:root:Train (Epoch 158): Loss/seq after 02150 batchs: 450.6155700683594
INFO:root:Train (Epoch 158): Loss/seq after 02200 batchs: 448.7872314453125
INFO:root:Train (Epoch 158): Loss/seq after 02250 batchs: 447.46771240234375
INFO:root:Train (Epoch 158): Loss/seq after 02300 batchs: 444.4563293457031
INFO:root:Train (Epoch 158): Loss/seq after 02350 batchs: 441.5039978027344
INFO:root:Train (Epoch 158): Loss/seq after 02400 batchs: 442.1505126953125
INFO:root:Train (Epoch 158): Loss/seq after 02450 batchs: 438.839599609375
INFO:root:Train (Epoch 158): Loss/seq after 02500 batchs: 432.6058044433594
INFO:root:Train (Epoch 158): Loss/seq after 02550 batchs: 427.0669250488281
INFO:root:Train (Epoch 158): Loss/seq after 02600 batchs: 425.74432373046875
INFO:root:Train (Epoch 158): Loss/seq after 02650 batchs: 422.1190490722656
INFO:root:Train (Epoch 158): Loss/seq after 02700 batchs: 419.7413024902344
INFO:root:Train (Epoch 158): Loss/seq after 02750 batchs: 416.5098876953125
INFO:root:Train (Epoch 158): Loss/seq after 02800 batchs: 414.7507019042969
INFO:root:Train (Epoch 158): Loss/seq after 02850 batchs: 414.686767578125
INFO:root:Train (Epoch 158): Loss/seq after 02900 batchs: 416.025390625
INFO:root:Train (Epoch 158): Loss/seq after 02950 batchs: 415.9853515625
INFO:root:Train (Epoch 158): Loss/seq after 03000 batchs: 421.6972351074219
INFO:root:Train (Epoch 158): Loss/seq after 03050 batchs: 423.951904296875
INFO:root:Train (Epoch 158): Loss/seq after 03100 batchs: 425.9018859863281
INFO:root:Train (Epoch 158): Loss/seq after 03150 batchs: 426.9825134277344
INFO:root:Train (Epoch 158): Loss/seq after 03200 batchs: 427.43670654296875
INFO:root:Train (Epoch 158): Loss/seq after 03250 batchs: 428.78271484375
INFO:root:Train (Epoch 158): Loss/seq after 03300 batchs: 428.0477600097656
INFO:root:Train (Epoch 158): Loss/seq after 03350 batchs: 427.00030517578125
INFO:root:Train (Epoch 158): Loss/seq after 03400 batchs: 423.84808349609375
INFO:root:Train (Epoch 158): Loss/seq after 03450 batchs: 422.75390625
INFO:root:Train (Epoch 158): Loss/seq after 03500 batchs: 423.61767578125
INFO:root:Train (Epoch 158): Loss/seq after 03550 batchs: 421.5995178222656
INFO:root:Train (Epoch 158): Loss/seq after 03600 batchs: 428.2322082519531
INFO:root:Train (Epoch 158): Loss/seq after 03650 batchs: 426.5854187011719
INFO:root:Train (Epoch 158): Loss/seq after 03700 batchs: 428.9352722167969
INFO:root:Train (Epoch 158): Loss/seq after 03750 batchs: 433.1304016113281
INFO:root:Train (Epoch 158): Loss/seq after 03800 batchs: 431.9530029296875
INFO:root:Train (Epoch 158): Loss/seq after 03850 batchs: 431.0140380859375
INFO:root:Train (Epoch 158): Loss/seq after 03900 batchs: 433.4378662109375
INFO:root:Train (Epoch 158): Loss/seq after 03950 batchs: 436.2686767578125
INFO:root:Train (Epoch 158): Loss/seq after 04000 batchs: 433.4007568359375
INFO:root:Train (Epoch 158): Loss/seq after 04050 batchs: 430.72674560546875
INFO:root:Train (Epoch 158): Loss/seq after 04100 batchs: 429.78887939453125
INFO:root:Train (Epoch 158): Loss/seq after 04150 batchs: 429.90869140625
INFO:root:Train (Epoch 158): Loss/seq after 04200 batchs: 428.8847351074219
INFO:root:Train (Epoch 158): Loss/seq after 04250 batchs: 427.4731140136719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 158): Loss/seq after 00000 batches: 343.6112365722656
INFO:root:# Valid (Epoch 158): Loss/seq after 00050 batches: 521.8721923828125
INFO:root:# Valid (Epoch 158): Loss/seq after 00100 batches: 551.3941650390625
INFO:root:# Valid (Epoch 158): Loss/seq after 00150 batches: 422.02423095703125
INFO:root:# Valid (Epoch 158): Loss/seq after 00200 batches: 398.4459228515625
INFO:root:Artifacts: Make stick videos for epoch 158
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_158_on_20220413_084210.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_158_index_639_on_20220413_084210.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 159): Loss/seq after 00000 batchs: 754.3858642578125
INFO:root:Train (Epoch 159): Loss/seq after 00050 batchs: 611.6675415039062
INFO:root:Train (Epoch 159): Loss/seq after 00100 batchs: 579.0720825195312
INFO:root:Train (Epoch 159): Loss/seq after 00150 batchs: 534.0738525390625
INFO:root:Train (Epoch 159): Loss/seq after 00200 batchs: 584.4554443359375
INFO:root:Train (Epoch 159): Loss/seq after 00250 batchs: 648.5377197265625
INFO:root:Train (Epoch 159): Loss/seq after 00300 batchs: 657.6272583007812
INFO:root:Train (Epoch 159): Loss/seq after 00350 batchs: 619.208984375
INFO:root:Train (Epoch 159): Loss/seq after 00400 batchs: 606.6392822265625
INFO:root:Train (Epoch 159): Loss/seq after 00450 batchs: 608.3729248046875
INFO:root:Train (Epoch 159): Loss/seq after 00500 batchs: 589.57763671875
INFO:root:Train (Epoch 159): Loss/seq after 00550 batchs: 576.5946655273438
INFO:root:Train (Epoch 159): Loss/seq after 00600 batchs: 557.9469604492188
INFO:root:Train (Epoch 159): Loss/seq after 00650 batchs: 537.5620727539062
INFO:root:Train (Epoch 159): Loss/seq after 00700 batchs: 516.0964965820312
INFO:root:Train (Epoch 159): Loss/seq after 00750 batchs: 515.329345703125
INFO:root:Train (Epoch 159): Loss/seq after 00800 batchs: 520.8082885742188
INFO:root:Train (Epoch 159): Loss/seq after 00850 batchs: 504.81475830078125
INFO:root:Train (Epoch 159): Loss/seq after 00900 batchs: 495.4676513671875
INFO:root:Train (Epoch 159): Loss/seq after 00950 batchs: 493.3733215332031
INFO:root:Train (Epoch 159): Loss/seq after 01000 batchs: 485.5987548828125
INFO:root:Train (Epoch 159): Loss/seq after 01050 batchs: 477.7923583984375
INFO:root:Train (Epoch 159): Loss/seq after 01100 batchs: 469.9900207519531
INFO:root:Train (Epoch 159): Loss/seq after 01150 batchs: 457.7952575683594
INFO:root:Train (Epoch 159): Loss/seq after 01200 batchs: 462.2332763671875
INFO:root:Train (Epoch 159): Loss/seq after 01250 batchs: 462.5616149902344
INFO:root:Train (Epoch 159): Loss/seq after 01300 batchs: 453.05145263671875
INFO:root:Train (Epoch 159): Loss/seq after 01350 batchs: 446.0388488769531
INFO:root:Train (Epoch 159): Loss/seq after 01400 batchs: 448.5456848144531
INFO:root:Train (Epoch 159): Loss/seq after 01450 batchs: 451.1934509277344
INFO:root:Train (Epoch 159): Loss/seq after 01500 batchs: 459.09747314453125
INFO:root:Train (Epoch 159): Loss/seq after 01550 batchs: 459.6573486328125
INFO:root:Train (Epoch 159): Loss/seq after 01600 batchs: 455.4638977050781
INFO:root:Train (Epoch 159): Loss/seq after 01650 batchs: 453.5538024902344
INFO:root:Train (Epoch 159): Loss/seq after 01700 batchs: 457.4530334472656
INFO:root:Train (Epoch 159): Loss/seq after 01750 batchs: 455.654296875
INFO:root:Train (Epoch 159): Loss/seq after 01800 batchs: 453.66998291015625
INFO:root:Train (Epoch 159): Loss/seq after 01850 batchs: 451.2955322265625
INFO:root:Train (Epoch 159): Loss/seq after 01900 batchs: 450.84503173828125
INFO:root:Train (Epoch 159): Loss/seq after 01950 batchs: 449.6147155761719
INFO:root:Train (Epoch 159): Loss/seq after 02000 batchs: 450.131103515625
INFO:root:Train (Epoch 159): Loss/seq after 02050 batchs: 450.0857849121094
INFO:root:Train (Epoch 159): Loss/seq after 02100 batchs: 448.6200866699219
INFO:root:Train (Epoch 159): Loss/seq after 02150 batchs: 446.9783020019531
INFO:root:Train (Epoch 159): Loss/seq after 02200 batchs: 445.2602844238281
INFO:root:Train (Epoch 159): Loss/seq after 02250 batchs: 444.2413024902344
INFO:root:Train (Epoch 159): Loss/seq after 02300 batchs: 441.0003967285156
INFO:root:Train (Epoch 159): Loss/seq after 02350 batchs: 438.1686096191406
INFO:root:Train (Epoch 159): Loss/seq after 02400 batchs: 438.7420959472656
INFO:root:Train (Epoch 159): Loss/seq after 02450 batchs: 435.4022216796875
INFO:root:Train (Epoch 159): Loss/seq after 02500 batchs: 429.19012451171875
INFO:root:Train (Epoch 159): Loss/seq after 02550 batchs: 423.61126708984375
INFO:root:Train (Epoch 159): Loss/seq after 02600 batchs: 422.3064270019531
INFO:root:Train (Epoch 159): Loss/seq after 02650 batchs: 418.7304382324219
INFO:root:Train (Epoch 159): Loss/seq after 02700 batchs: 416.3183288574219
INFO:root:Train (Epoch 159): Loss/seq after 02750 batchs: 413.2810363769531
INFO:root:Train (Epoch 159): Loss/seq after 02800 batchs: 411.89263916015625
INFO:root:Train (Epoch 159): Loss/seq after 02850 batchs: 412.0472717285156
INFO:root:Train (Epoch 159): Loss/seq after 02900 batchs: 413.45843505859375
INFO:root:Train (Epoch 159): Loss/seq after 02950 batchs: 413.6023254394531
INFO:root:Train (Epoch 159): Loss/seq after 03000 batchs: 419.12908935546875
INFO:root:Train (Epoch 159): Loss/seq after 03050 batchs: 421.3534240722656
INFO:root:Train (Epoch 159): Loss/seq after 03100 batchs: 423.4565734863281
INFO:root:Train (Epoch 159): Loss/seq after 03150 batchs: 423.8746643066406
INFO:root:Train (Epoch 159): Loss/seq after 03200 batchs: 424.13336181640625
INFO:root:Train (Epoch 159): Loss/seq after 03250 batchs: 425.72393798828125
INFO:root:Train (Epoch 159): Loss/seq after 03300 batchs: 425.2236328125
INFO:root:Train (Epoch 159): Loss/seq after 03350 batchs: 424.24114990234375
INFO:root:Train (Epoch 159): Loss/seq after 03400 batchs: 421.1246032714844
INFO:root:Train (Epoch 159): Loss/seq after 03450 batchs: 420.1755065917969
INFO:root:Train (Epoch 159): Loss/seq after 03500 batchs: 421.4241027832031
INFO:root:Train (Epoch 159): Loss/seq after 03550 batchs: 419.5387268066406
INFO:root:Train (Epoch 159): Loss/seq after 03600 batchs: 426.29595947265625
INFO:root:Train (Epoch 159): Loss/seq after 03650 batchs: 424.8322448730469
INFO:root:Train (Epoch 159): Loss/seq after 03700 batchs: 427.1737976074219
INFO:root:Train (Epoch 159): Loss/seq after 03750 batchs: 431.314697265625
INFO:root:Train (Epoch 159): Loss/seq after 03800 batchs: 430.1473693847656
INFO:root:Train (Epoch 159): Loss/seq after 03850 batchs: 429.1350402832031
INFO:root:Train (Epoch 159): Loss/seq after 03900 batchs: 431.7378234863281
INFO:root:Train (Epoch 159): Loss/seq after 03950 batchs: 434.3608703613281
INFO:root:Train (Epoch 159): Loss/seq after 04000 batchs: 431.53570556640625
INFO:root:Train (Epoch 159): Loss/seq after 04050 batchs: 428.863037109375
INFO:root:Train (Epoch 159): Loss/seq after 04100 batchs: 427.9211730957031
INFO:root:Train (Epoch 159): Loss/seq after 04150 batchs: 428.0467529296875
INFO:root:Train (Epoch 159): Loss/seq after 04200 batchs: 426.9562683105469
INFO:root:Train (Epoch 159): Loss/seq after 04250 batchs: 425.5692443847656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 159): Loss/seq after 00000 batches: 360.2618103027344
INFO:root:# Valid (Epoch 159): Loss/seq after 00050 batches: 531.5322265625
INFO:root:# Valid (Epoch 159): Loss/seq after 00100 batches: 554.4892578125
INFO:root:# Valid (Epoch 159): Loss/seq after 00150 batches: 422.49273681640625
INFO:root:# Valid (Epoch 159): Loss/seq after 00200 batches: 398.1933288574219
INFO:root:Artifacts: Make stick videos for epoch 159
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_159_on_20220413_084734.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_159_index_1603_on_20220413_084734.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 160): Loss/seq after 00000 batchs: 810.9686279296875
INFO:root:Train (Epoch 160): Loss/seq after 00050 batchs: 618.7915649414062
INFO:root:Train (Epoch 160): Loss/seq after 00100 batchs: 596.1687622070312
INFO:root:Train (Epoch 160): Loss/seq after 00150 batchs: 547.1748657226562
INFO:root:Train (Epoch 160): Loss/seq after 00200 batchs: 595.3158569335938
INFO:root:Train (Epoch 160): Loss/seq after 00250 batchs: 655.804443359375
INFO:root:Train (Epoch 160): Loss/seq after 00300 batchs: 663.9254150390625
INFO:root:Train (Epoch 160): Loss/seq after 00350 batchs: 624.5040283203125
INFO:root:Train (Epoch 160): Loss/seq after 00400 batchs: 610.27392578125
INFO:root:Train (Epoch 160): Loss/seq after 00450 batchs: 611.4921875
INFO:root:Train (Epoch 160): Loss/seq after 00500 batchs: 593.3941650390625
INFO:root:Train (Epoch 160): Loss/seq after 00550 batchs: 579.8626708984375
INFO:root:Train (Epoch 160): Loss/seq after 00600 batchs: 560.88232421875
INFO:root:Train (Epoch 160): Loss/seq after 00650 batchs: 539.4132080078125
INFO:root:Train (Epoch 160): Loss/seq after 00700 batchs: 517.5232543945312
INFO:root:Train (Epoch 160): Loss/seq after 00750 batchs: 517.0863037109375
INFO:root:Train (Epoch 160): Loss/seq after 00800 batchs: 521.9783935546875
INFO:root:Train (Epoch 160): Loss/seq after 00850 batchs: 505.48284912109375
INFO:root:Train (Epoch 160): Loss/seq after 00900 batchs: 495.3028869628906
INFO:root:Train (Epoch 160): Loss/seq after 00950 batchs: 492.76519775390625
INFO:root:Train (Epoch 160): Loss/seq after 01000 batchs: 484.7982482910156
INFO:root:Train (Epoch 160): Loss/seq after 01050 batchs: 475.9595031738281
INFO:root:Train (Epoch 160): Loss/seq after 01100 batchs: 467.8255920410156
INFO:root:Train (Epoch 160): Loss/seq after 01150 batchs: 455.8428649902344
INFO:root:Train (Epoch 160): Loss/seq after 01200 batchs: 461.1339416503906
INFO:root:Train (Epoch 160): Loss/seq after 01250 batchs: 461.1842041015625
INFO:root:Train (Epoch 160): Loss/seq after 01300 batchs: 451.8475646972656
INFO:root:Train (Epoch 160): Loss/seq after 01350 batchs: 444.75372314453125
INFO:root:Train (Epoch 160): Loss/seq after 01400 batchs: 446.4616394042969
INFO:root:Train (Epoch 160): Loss/seq after 01450 batchs: 449.20977783203125
INFO:root:Train (Epoch 160): Loss/seq after 01500 batchs: 456.6905822753906
INFO:root:Train (Epoch 160): Loss/seq after 01550 batchs: 457.03173828125
INFO:root:Train (Epoch 160): Loss/seq after 01600 batchs: 453.0467529296875
INFO:root:Train (Epoch 160): Loss/seq after 01650 batchs: 451.485107421875
INFO:root:Train (Epoch 160): Loss/seq after 01700 batchs: 455.51373291015625
INFO:root:Train (Epoch 160): Loss/seq after 01750 batchs: 453.6691589355469
INFO:root:Train (Epoch 160): Loss/seq after 01800 batchs: 451.7196960449219
INFO:root:Train (Epoch 160): Loss/seq after 01850 batchs: 449.43572998046875
INFO:root:Train (Epoch 160): Loss/seq after 01900 batchs: 448.93450927734375
INFO:root:Train (Epoch 160): Loss/seq after 01950 batchs: 447.8507385253906
INFO:root:Train (Epoch 160): Loss/seq after 02000 batchs: 448.2669677734375
INFO:root:Train (Epoch 160): Loss/seq after 02050 batchs: 448.24212646484375
INFO:root:Train (Epoch 160): Loss/seq after 02100 batchs: 446.7323913574219
INFO:root:Train (Epoch 160): Loss/seq after 02150 batchs: 445.3258361816406
INFO:root:Train (Epoch 160): Loss/seq after 02200 batchs: 443.55902099609375
INFO:root:Train (Epoch 160): Loss/seq after 02250 batchs: 442.50421142578125
INFO:root:Train (Epoch 160): Loss/seq after 02300 batchs: 439.4523010253906
INFO:root:Train (Epoch 160): Loss/seq after 02350 batchs: 436.5614013671875
INFO:root:Train (Epoch 160): Loss/seq after 02400 batchs: 437.0806884765625
INFO:root:Train (Epoch 160): Loss/seq after 02450 batchs: 433.7194519042969
INFO:root:Train (Epoch 160): Loss/seq after 02500 batchs: 427.5437316894531
INFO:root:Train (Epoch 160): Loss/seq after 02550 batchs: 421.984619140625
INFO:root:Train (Epoch 160): Loss/seq after 02600 batchs: 420.582763671875
INFO:root:Train (Epoch 160): Loss/seq after 02650 batchs: 417.0478515625
INFO:root:Train (Epoch 160): Loss/seq after 02700 batchs: 414.80706787109375
INFO:root:Train (Epoch 160): Loss/seq after 02750 batchs: 411.62774658203125
INFO:root:Train (Epoch 160): Loss/seq after 02800 batchs: 409.90966796875
INFO:root:Train (Epoch 160): Loss/seq after 02850 batchs: 409.8632507324219
INFO:root:Train (Epoch 160): Loss/seq after 02900 batchs: 411.30743408203125
INFO:root:Train (Epoch 160): Loss/seq after 02950 batchs: 411.3606262207031
INFO:root:Train (Epoch 160): Loss/seq after 03000 batchs: 417.0810546875
INFO:root:Train (Epoch 160): Loss/seq after 03050 batchs: 419.3246765136719
INFO:root:Train (Epoch 160): Loss/seq after 03100 batchs: 421.1306457519531
INFO:root:Train (Epoch 160): Loss/seq after 03150 batchs: 421.5442810058594
INFO:root:Train (Epoch 160): Loss/seq after 03200 batchs: 421.6109924316406
INFO:root:Train (Epoch 160): Loss/seq after 03250 batchs: 423.2370300292969
INFO:root:Train (Epoch 160): Loss/seq after 03300 batchs: 422.5246887207031
INFO:root:Train (Epoch 160): Loss/seq after 03350 batchs: 421.6447448730469
INFO:root:Train (Epoch 160): Loss/seq after 03400 batchs: 418.5692138671875
INFO:root:Train (Epoch 160): Loss/seq after 03450 batchs: 417.5074462890625
INFO:root:Train (Epoch 160): Loss/seq after 03500 batchs: 418.29083251953125
INFO:root:Train (Epoch 160): Loss/seq after 03550 batchs: 416.244384765625
INFO:root:Train (Epoch 160): Loss/seq after 03600 batchs: 422.8802490234375
INFO:root:Train (Epoch 160): Loss/seq after 03650 batchs: 421.3399353027344
INFO:root:Train (Epoch 160): Loss/seq after 03700 batchs: 423.7913513183594
INFO:root:Train (Epoch 160): Loss/seq after 03750 batchs: 428.02069091796875
INFO:root:Train (Epoch 160): Loss/seq after 03800 batchs: 426.91741943359375
INFO:root:Train (Epoch 160): Loss/seq after 03850 batchs: 426.0031433105469
INFO:root:Train (Epoch 160): Loss/seq after 03900 batchs: 428.5419006347656
INFO:root:Train (Epoch 160): Loss/seq after 03950 batchs: 431.2870788574219
INFO:root:Train (Epoch 160): Loss/seq after 04000 batchs: 428.48345947265625
INFO:root:Train (Epoch 160): Loss/seq after 04050 batchs: 425.8340148925781
INFO:root:Train (Epoch 160): Loss/seq after 04100 batchs: 424.8999938964844
INFO:root:Train (Epoch 160): Loss/seq after 04150 batchs: 425.0099792480469
INFO:root:Train (Epoch 160): Loss/seq after 04200 batchs: 423.9694519042969
INFO:root:Train (Epoch 160): Loss/seq after 04250 batchs: 422.53985595703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 160): Loss/seq after 00000 batches: 347.75390625
INFO:root:# Valid (Epoch 160): Loss/seq after 00050 batches: 535.508544921875
INFO:root:# Valid (Epoch 160): Loss/seq after 00100 batches: 549.5772094726562
INFO:root:# Valid (Epoch 160): Loss/seq after 00150 batches: 423.0474853515625
INFO:root:# Valid (Epoch 160): Loss/seq after 00200 batches: 403.2479553222656
INFO:root:Artifacts: Make stick videos for epoch 160
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_160_on_20220413_085257.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_160_index_1746_on_20220413_085257.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 161): Loss/seq after 00000 batchs: 722.1864624023438
INFO:root:Train (Epoch 161): Loss/seq after 00050 batchs: 606.388671875
INFO:root:Train (Epoch 161): Loss/seq after 00100 batchs: 580.1729736328125
INFO:root:Train (Epoch 161): Loss/seq after 00150 batchs: 534.6747436523438
INFO:root:Train (Epoch 161): Loss/seq after 00200 batchs: 584.252197265625
INFO:root:Train (Epoch 161): Loss/seq after 00250 batchs: 652.7412719726562
INFO:root:Train (Epoch 161): Loss/seq after 00300 batchs: 662.5484619140625
INFO:root:Train (Epoch 161): Loss/seq after 00350 batchs: 623.0222778320312
INFO:root:Train (Epoch 161): Loss/seq after 00400 batchs: 609.7083129882812
INFO:root:Train (Epoch 161): Loss/seq after 00450 batchs: 611.1808471679688
INFO:root:Train (Epoch 161): Loss/seq after 00500 batchs: 593.1879272460938
INFO:root:Train (Epoch 161): Loss/seq after 00550 batchs: 578.65673828125
INFO:root:Train (Epoch 161): Loss/seq after 00600 batchs: 560.0258178710938
INFO:root:Train (Epoch 161): Loss/seq after 00650 batchs: 539.9441528320312
INFO:root:Train (Epoch 161): Loss/seq after 00700 batchs: 518.2871704101562
INFO:root:Train (Epoch 161): Loss/seq after 00750 batchs: 517.4912109375
INFO:root:Train (Epoch 161): Loss/seq after 00800 batchs: 523.2289428710938
INFO:root:Train (Epoch 161): Loss/seq after 00850 batchs: 507.5685119628906
INFO:root:Train (Epoch 161): Loss/seq after 00900 batchs: 498.37786865234375
INFO:root:Train (Epoch 161): Loss/seq after 00950 batchs: 495.5229797363281
INFO:root:Train (Epoch 161): Loss/seq after 01000 batchs: 487.2895202636719
INFO:root:Train (Epoch 161): Loss/seq after 01050 batchs: 479.3657531738281
INFO:root:Train (Epoch 161): Loss/seq after 01100 batchs: 471.41021728515625
INFO:root:Train (Epoch 161): Loss/seq after 01150 batchs: 458.960205078125
INFO:root:Train (Epoch 161): Loss/seq after 01200 batchs: 463.33123779296875
INFO:root:Train (Epoch 161): Loss/seq after 01250 batchs: 463.63250732421875
INFO:root:Train (Epoch 161): Loss/seq after 01300 batchs: 454.0679626464844
INFO:root:Train (Epoch 161): Loss/seq after 01350 batchs: 446.73382568359375
INFO:root:Train (Epoch 161): Loss/seq after 01400 batchs: 448.93316650390625
INFO:root:Train (Epoch 161): Loss/seq after 01450 batchs: 451.72491455078125
INFO:root:Train (Epoch 161): Loss/seq after 01500 batchs: 459.577880859375
INFO:root:Train (Epoch 161): Loss/seq after 01550 batchs: 459.70159912109375
INFO:root:Train (Epoch 161): Loss/seq after 01600 batchs: 455.5962829589844
INFO:root:Train (Epoch 161): Loss/seq after 01650 batchs: 453.801025390625
INFO:root:Train (Epoch 161): Loss/seq after 01700 batchs: 457.6781921386719
INFO:root:Train (Epoch 161): Loss/seq after 01750 batchs: 455.6793518066406
INFO:root:Train (Epoch 161): Loss/seq after 01800 batchs: 453.4437255859375
INFO:root:Train (Epoch 161): Loss/seq after 01850 batchs: 451.0589599609375
INFO:root:Train (Epoch 161): Loss/seq after 01900 batchs: 450.637451171875
INFO:root:Train (Epoch 161): Loss/seq after 01950 batchs: 449.6907043457031
INFO:root:Train (Epoch 161): Loss/seq after 02000 batchs: 450.1177062988281
INFO:root:Train (Epoch 161): Loss/seq after 02050 batchs: 449.8648681640625
INFO:root:Train (Epoch 161): Loss/seq after 02100 batchs: 448.336181640625
INFO:root:Train (Epoch 161): Loss/seq after 02150 batchs: 446.7213439941406
INFO:root:Train (Epoch 161): Loss/seq after 02200 batchs: 444.8547058105469
INFO:root:Train (Epoch 161): Loss/seq after 02250 batchs: 443.7021789550781
INFO:root:Train (Epoch 161): Loss/seq after 02300 batchs: 440.6240539550781
INFO:root:Train (Epoch 161): Loss/seq after 02350 batchs: 437.6669616699219
INFO:root:Train (Epoch 161): Loss/seq after 02400 batchs: 438.10296630859375
INFO:root:Train (Epoch 161): Loss/seq after 02450 batchs: 434.7129211425781
INFO:root:Train (Epoch 161): Loss/seq after 02500 batchs: 428.4569091796875
INFO:root:Train (Epoch 161): Loss/seq after 02550 batchs: 422.807861328125
INFO:root:Train (Epoch 161): Loss/seq after 02600 batchs: 421.3730773925781
INFO:root:Train (Epoch 161): Loss/seq after 02650 batchs: 417.71697998046875
INFO:root:Train (Epoch 161): Loss/seq after 02700 batchs: 415.2037048339844
INFO:root:Train (Epoch 161): Loss/seq after 02750 batchs: 411.87420654296875
INFO:root:Train (Epoch 161): Loss/seq after 02800 batchs: 410.1893615722656
INFO:root:Train (Epoch 161): Loss/seq after 02850 batchs: 410.0606384277344
INFO:root:Train (Epoch 161): Loss/seq after 02900 batchs: 411.3206787109375
INFO:root:Train (Epoch 161): Loss/seq after 02950 batchs: 411.29168701171875
INFO:root:Train (Epoch 161): Loss/seq after 03000 batchs: 416.8485107421875
INFO:root:Train (Epoch 161): Loss/seq after 03050 batchs: 418.96710205078125
INFO:root:Train (Epoch 161): Loss/seq after 03100 batchs: 420.6796569824219
INFO:root:Train (Epoch 161): Loss/seq after 03150 batchs: 421.0819396972656
INFO:root:Train (Epoch 161): Loss/seq after 03200 batchs: 421.049560546875
INFO:root:Train (Epoch 161): Loss/seq after 03250 batchs: 422.48248291015625
INFO:root:Train (Epoch 161): Loss/seq after 03300 batchs: 421.73699951171875
INFO:root:Train (Epoch 161): Loss/seq after 03350 batchs: 420.72705078125
INFO:root:Train (Epoch 161): Loss/seq after 03400 batchs: 417.7135009765625
INFO:root:Train (Epoch 161): Loss/seq after 03450 batchs: 416.7663269042969
INFO:root:Train (Epoch 161): Loss/seq after 03500 batchs: 417.5724182128906
INFO:root:Train (Epoch 161): Loss/seq after 03550 batchs: 415.5260925292969
INFO:root:Train (Epoch 161): Loss/seq after 03600 batchs: 422.22613525390625
INFO:root:Train (Epoch 161): Loss/seq after 03650 batchs: 420.7687683105469
INFO:root:Train (Epoch 161): Loss/seq after 03700 batchs: 423.34197998046875
INFO:root:Train (Epoch 161): Loss/seq after 03750 batchs: 427.617431640625
INFO:root:Train (Epoch 161): Loss/seq after 03800 batchs: 426.4869384765625
INFO:root:Train (Epoch 161): Loss/seq after 03850 batchs: 425.5907287597656
INFO:root:Train (Epoch 161): Loss/seq after 03900 batchs: 428.043701171875
INFO:root:Train (Epoch 161): Loss/seq after 03950 batchs: 430.65216064453125
INFO:root:Train (Epoch 161): Loss/seq after 04000 batchs: 427.8586120605469
INFO:root:Train (Epoch 161): Loss/seq after 04050 batchs: 425.2072448730469
INFO:root:Train (Epoch 161): Loss/seq after 04100 batchs: 424.27056884765625
INFO:root:Train (Epoch 161): Loss/seq after 04150 batchs: 424.38739013671875
INFO:root:Train (Epoch 161): Loss/seq after 04200 batchs: 423.4363098144531
INFO:root:Train (Epoch 161): Loss/seq after 04250 batchs: 422.0946044921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 161): Loss/seq after 00000 batches: 360.0367431640625
INFO:root:# Valid (Epoch 161): Loss/seq after 00050 batches: 543.08251953125
INFO:root:# Valid (Epoch 161): Loss/seq after 00100 batches: 581.3767700195312
INFO:root:# Valid (Epoch 161): Loss/seq after 00150 batches: 445.9845275878906
INFO:root:# Valid (Epoch 161): Loss/seq after 00200 batches: 424.30694580078125
INFO:root:Artifacts: Make stick videos for epoch 161
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_161_on_20220413_085820.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_161_index_109_on_20220413_085820.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 162): Loss/seq after 00000 batchs: 805.6942138671875
INFO:root:Train (Epoch 162): Loss/seq after 00050 batchs: 610.9164428710938
INFO:root:Train (Epoch 162): Loss/seq after 00100 batchs: 575.8821411132812
INFO:root:Train (Epoch 162): Loss/seq after 00150 batchs: 532.5899658203125
INFO:root:Train (Epoch 162): Loss/seq after 00200 batchs: 581.7343139648438
INFO:root:Train (Epoch 162): Loss/seq after 00250 batchs: 641.7257690429688
INFO:root:Train (Epoch 162): Loss/seq after 00300 batchs: 650.6574096679688
INFO:root:Train (Epoch 162): Loss/seq after 00350 batchs: 612.174072265625
INFO:root:Train (Epoch 162): Loss/seq after 00400 batchs: 599.024169921875
INFO:root:Train (Epoch 162): Loss/seq after 00450 batchs: 601.4745483398438
INFO:root:Train (Epoch 162): Loss/seq after 00500 batchs: 583.5068969726562
INFO:root:Train (Epoch 162): Loss/seq after 00550 batchs: 570.1438598632812
INFO:root:Train (Epoch 162): Loss/seq after 00600 batchs: 552.1913452148438
INFO:root:Train (Epoch 162): Loss/seq after 00650 batchs: 531.1536254882812
INFO:root:Train (Epoch 162): Loss/seq after 00700 batchs: 509.8802795410156
INFO:root:Train (Epoch 162): Loss/seq after 00750 batchs: 508.1709289550781
INFO:root:Train (Epoch 162): Loss/seq after 00800 batchs: 512.712158203125
INFO:root:Train (Epoch 162): Loss/seq after 00850 batchs: 496.9151306152344
INFO:root:Train (Epoch 162): Loss/seq after 00900 batchs: 486.8453369140625
INFO:root:Train (Epoch 162): Loss/seq after 00950 batchs: 484.1781005859375
INFO:root:Train (Epoch 162): Loss/seq after 01000 batchs: 475.95599365234375
INFO:root:Train (Epoch 162): Loss/seq after 01050 batchs: 468.12677001953125
INFO:root:Train (Epoch 162): Loss/seq after 01100 batchs: 460.4837951660156
INFO:root:Train (Epoch 162): Loss/seq after 01150 batchs: 448.75970458984375
INFO:root:Train (Epoch 162): Loss/seq after 01200 batchs: 453.6064758300781
INFO:root:Train (Epoch 162): Loss/seq after 01250 batchs: 454.21893310546875
INFO:root:Train (Epoch 162): Loss/seq after 01300 batchs: 444.8545227050781
INFO:root:Train (Epoch 162): Loss/seq after 01350 batchs: 438.27569580078125
INFO:root:Train (Epoch 162): Loss/seq after 01400 batchs: 440.391357421875
INFO:root:Train (Epoch 162): Loss/seq after 01450 batchs: 443.31317138671875
INFO:root:Train (Epoch 162): Loss/seq after 01500 batchs: 451.24090576171875
INFO:root:Train (Epoch 162): Loss/seq after 01550 batchs: 451.6566162109375
INFO:root:Train (Epoch 162): Loss/seq after 01600 batchs: 447.74041748046875
INFO:root:Train (Epoch 162): Loss/seq after 01650 batchs: 446.1120300292969
INFO:root:Train (Epoch 162): Loss/seq after 01700 batchs: 450.250732421875
INFO:root:Train (Epoch 162): Loss/seq after 01750 batchs: 448.3516845703125
INFO:root:Train (Epoch 162): Loss/seq after 01800 batchs: 446.4767761230469
INFO:root:Train (Epoch 162): Loss/seq after 01850 batchs: 444.2340087890625
INFO:root:Train (Epoch 162): Loss/seq after 01900 batchs: 443.5400085449219
INFO:root:Train (Epoch 162): Loss/seq after 01950 batchs: 442.5882263183594
INFO:root:Train (Epoch 162): Loss/seq after 02000 batchs: 443.1547546386719
INFO:root:Train (Epoch 162): Loss/seq after 02050 batchs: 443.27166748046875
INFO:root:Train (Epoch 162): Loss/seq after 02100 batchs: 441.8921813964844
INFO:root:Train (Epoch 162): Loss/seq after 02150 batchs: 440.48236083984375
INFO:root:Train (Epoch 162): Loss/seq after 02200 batchs: 438.7206726074219
INFO:root:Train (Epoch 162): Loss/seq after 02250 batchs: 437.4453430175781
INFO:root:Train (Epoch 162): Loss/seq after 02300 batchs: 434.3476867675781
INFO:root:Train (Epoch 162): Loss/seq after 02350 batchs: 431.49737548828125
INFO:root:Train (Epoch 162): Loss/seq after 02400 batchs: 432.0318298339844
INFO:root:Train (Epoch 162): Loss/seq after 02450 batchs: 428.7607727050781
INFO:root:Train (Epoch 162): Loss/seq after 02500 batchs: 422.6002197265625
INFO:root:Train (Epoch 162): Loss/seq after 02550 batchs: 417.1668395996094
INFO:root:Train (Epoch 162): Loss/seq after 02600 batchs: 415.80462646484375
INFO:root:Train (Epoch 162): Loss/seq after 02650 batchs: 412.1659851074219
INFO:root:Train (Epoch 162): Loss/seq after 02700 batchs: 409.76763916015625
INFO:root:Train (Epoch 162): Loss/seq after 02750 batchs: 406.756103515625
INFO:root:Train (Epoch 162): Loss/seq after 02800 batchs: 404.9498291015625
INFO:root:Train (Epoch 162): Loss/seq after 02850 batchs: 404.8501892089844
INFO:root:Train (Epoch 162): Loss/seq after 02900 batchs: 406.05487060546875
INFO:root:Train (Epoch 162): Loss/seq after 02950 batchs: 406.1197814941406
INFO:root:Train (Epoch 162): Loss/seq after 03000 batchs: 411.5409240722656
INFO:root:Train (Epoch 162): Loss/seq after 03050 batchs: 413.6311950683594
INFO:root:Train (Epoch 162): Loss/seq after 03100 batchs: 415.5365905761719
INFO:root:Train (Epoch 162): Loss/seq after 03150 batchs: 415.9888916015625
INFO:root:Train (Epoch 162): Loss/seq after 03200 batchs: 416.26348876953125
INFO:root:Train (Epoch 162): Loss/seq after 03250 batchs: 417.6531677246094
INFO:root:Train (Epoch 162): Loss/seq after 03300 batchs: 417.1619567871094
INFO:root:Train (Epoch 162): Loss/seq after 03350 batchs: 415.9610595703125
INFO:root:Train (Epoch 162): Loss/seq after 03400 batchs: 412.9380187988281
INFO:root:Train (Epoch 162): Loss/seq after 03450 batchs: 411.9488525390625
INFO:root:Train (Epoch 162): Loss/seq after 03500 batchs: 412.72723388671875
INFO:root:Train (Epoch 162): Loss/seq after 03550 batchs: 410.7939758300781
INFO:root:Train (Epoch 162): Loss/seq after 03600 batchs: 417.49822998046875
INFO:root:Train (Epoch 162): Loss/seq after 03650 batchs: 415.9755859375
INFO:root:Train (Epoch 162): Loss/seq after 03700 batchs: 418.2895202636719
INFO:root:Train (Epoch 162): Loss/seq after 03750 batchs: 422.48876953125
INFO:root:Train (Epoch 162): Loss/seq after 03800 batchs: 421.4040222167969
INFO:root:Train (Epoch 162): Loss/seq after 03850 batchs: 420.5248718261719
INFO:root:Train (Epoch 162): Loss/seq after 03900 batchs: 422.75115966796875
INFO:root:Train (Epoch 162): Loss/seq after 03950 batchs: 425.31787109375
INFO:root:Train (Epoch 162): Loss/seq after 04000 batchs: 422.59112548828125
INFO:root:Train (Epoch 162): Loss/seq after 04050 batchs: 420.01220703125
INFO:root:Train (Epoch 162): Loss/seq after 04100 batchs: 419.1310119628906
INFO:root:Train (Epoch 162): Loss/seq after 04150 batchs: 419.2299499511719
INFO:root:Train (Epoch 162): Loss/seq after 04200 batchs: 418.294677734375
INFO:root:Train (Epoch 162): Loss/seq after 04250 batchs: 416.8943176269531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 162): Loss/seq after 00000 batches: 350.4969787597656
INFO:root:# Valid (Epoch 162): Loss/seq after 00050 batches: 513.6892700195312
INFO:root:# Valid (Epoch 162): Loss/seq after 00100 batches: 547.3739624023438
INFO:root:# Valid (Epoch 162): Loss/seq after 00150 batches: 420.72979736328125
INFO:root:# Valid (Epoch 162): Loss/seq after 00200 batches: 399.799072265625
INFO:root:Artifacts: Make stick videos for epoch 162
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_162_on_20220413_090342.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_162_index_1071_on_20220413_090342.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 163): Loss/seq after 00000 batchs: 777.8291015625
INFO:root:Train (Epoch 163): Loss/seq after 00050 batchs: 601.1145629882812
INFO:root:Train (Epoch 163): Loss/seq after 00100 batchs: 563.185546875
INFO:root:Train (Epoch 163): Loss/seq after 00150 batchs: 522.2634887695312
INFO:root:Train (Epoch 163): Loss/seq after 00200 batchs: 571.01123046875
INFO:root:Train (Epoch 163): Loss/seq after 00250 batchs: 639.3325805664062
INFO:root:Train (Epoch 163): Loss/seq after 00300 batchs: 649.216796875
INFO:root:Train (Epoch 163): Loss/seq after 00350 batchs: 611.99462890625
INFO:root:Train (Epoch 163): Loss/seq after 00400 batchs: 598.5641479492188
INFO:root:Train (Epoch 163): Loss/seq after 00450 batchs: 601.193359375
INFO:root:Train (Epoch 163): Loss/seq after 00500 batchs: 581.5645141601562
INFO:root:Train (Epoch 163): Loss/seq after 00550 batchs: 568.193115234375
INFO:root:Train (Epoch 163): Loss/seq after 00600 batchs: 549.9949340820312
INFO:root:Train (Epoch 163): Loss/seq after 00650 batchs: 529.3194580078125
INFO:root:Train (Epoch 163): Loss/seq after 00700 batchs: 507.7288818359375
INFO:root:Train (Epoch 163): Loss/seq after 00750 batchs: 506.9595031738281
INFO:root:Train (Epoch 163): Loss/seq after 00800 batchs: 512.0267333984375
INFO:root:Train (Epoch 163): Loss/seq after 00850 batchs: 496.0648193359375
INFO:root:Train (Epoch 163): Loss/seq after 00900 batchs: 485.6708984375
INFO:root:Train (Epoch 163): Loss/seq after 00950 batchs: 483.737548828125
INFO:root:Train (Epoch 163): Loss/seq after 01000 batchs: 475.53619384765625
INFO:root:Train (Epoch 163): Loss/seq after 01050 batchs: 467.2843017578125
INFO:root:Train (Epoch 163): Loss/seq after 01100 batchs: 459.1943359375
INFO:root:Train (Epoch 163): Loss/seq after 01150 batchs: 447.2122802734375
INFO:root:Train (Epoch 163): Loss/seq after 01200 batchs: 451.90960693359375
INFO:root:Train (Epoch 163): Loss/seq after 01250 batchs: 452.72003173828125
INFO:root:Train (Epoch 163): Loss/seq after 01300 batchs: 443.7428283691406
INFO:root:Train (Epoch 163): Loss/seq after 01350 batchs: 436.7688903808594
INFO:root:Train (Epoch 163): Loss/seq after 01400 batchs: 438.7653503417969
INFO:root:Train (Epoch 163): Loss/seq after 01450 batchs: 441.6210021972656
INFO:root:Train (Epoch 163): Loss/seq after 01500 batchs: 449.2000732421875
INFO:root:Train (Epoch 163): Loss/seq after 01550 batchs: 449.2193908691406
INFO:root:Train (Epoch 163): Loss/seq after 01600 batchs: 445.4891662597656
INFO:root:Train (Epoch 163): Loss/seq after 01650 batchs: 443.9078674316406
INFO:root:Train (Epoch 163): Loss/seq after 01700 batchs: 448.0679931640625
INFO:root:Train (Epoch 163): Loss/seq after 01750 batchs: 446.2091369628906
INFO:root:Train (Epoch 163): Loss/seq after 01800 batchs: 444.0989685058594
INFO:root:Train (Epoch 163): Loss/seq after 01850 batchs: 441.964599609375
INFO:root:Train (Epoch 163): Loss/seq after 01900 batchs: 441.4163513183594
INFO:root:Train (Epoch 163): Loss/seq after 01950 batchs: 440.26495361328125
INFO:root:Train (Epoch 163): Loss/seq after 02000 batchs: 440.7498779296875
INFO:root:Train (Epoch 163): Loss/seq after 02050 batchs: 440.6038818359375
INFO:root:Train (Epoch 163): Loss/seq after 02100 batchs: 439.1509704589844
INFO:root:Train (Epoch 163): Loss/seq after 02150 batchs: 437.72119140625
INFO:root:Train (Epoch 163): Loss/seq after 02200 batchs: 436.0069885253906
INFO:root:Train (Epoch 163): Loss/seq after 02250 batchs: 434.6895751953125
INFO:root:Train (Epoch 163): Loss/seq after 02300 batchs: 431.51287841796875
INFO:root:Train (Epoch 163): Loss/seq after 02350 batchs: 428.73077392578125
INFO:root:Train (Epoch 163): Loss/seq after 02400 batchs: 429.1988220214844
INFO:root:Train (Epoch 163): Loss/seq after 02450 batchs: 425.93988037109375
INFO:root:Train (Epoch 163): Loss/seq after 02500 batchs: 419.8684997558594
INFO:root:Train (Epoch 163): Loss/seq after 02550 batchs: 414.3200988769531
INFO:root:Train (Epoch 163): Loss/seq after 02600 batchs: 412.8058776855469
INFO:root:Train (Epoch 163): Loss/seq after 02650 batchs: 409.23046875
INFO:root:Train (Epoch 163): Loss/seq after 02700 batchs: 406.8028564453125
INFO:root:Train (Epoch 163): Loss/seq after 02750 batchs: 403.5594177246094
INFO:root:Train (Epoch 163): Loss/seq after 02800 batchs: 401.77093505859375
INFO:root:Train (Epoch 163): Loss/seq after 02850 batchs: 401.6753234863281
INFO:root:Train (Epoch 163): Loss/seq after 02900 batchs: 403.0045471191406
INFO:root:Train (Epoch 163): Loss/seq after 02950 batchs: 403.16015625
INFO:root:Train (Epoch 163): Loss/seq after 03000 batchs: 408.7687683105469
INFO:root:Train (Epoch 163): Loss/seq after 03050 batchs: 410.954345703125
INFO:root:Train (Epoch 163): Loss/seq after 03100 batchs: 412.784423828125
INFO:root:Train (Epoch 163): Loss/seq after 03150 batchs: 413.53436279296875
INFO:root:Train (Epoch 163): Loss/seq after 03200 batchs: 413.8642272949219
INFO:root:Train (Epoch 163): Loss/seq after 03250 batchs: 415.3495788574219
INFO:root:Train (Epoch 163): Loss/seq after 03300 batchs: 414.8377380371094
INFO:root:Train (Epoch 163): Loss/seq after 03350 batchs: 413.71295166015625
INFO:root:Train (Epoch 163): Loss/seq after 03400 batchs: 410.6737060546875
INFO:root:Train (Epoch 163): Loss/seq after 03450 batchs: 409.6436767578125
INFO:root:Train (Epoch 163): Loss/seq after 03500 batchs: 410.51092529296875
INFO:root:Train (Epoch 163): Loss/seq after 03550 batchs: 408.3636474609375
INFO:root:Train (Epoch 163): Loss/seq after 03600 batchs: 415.0356750488281
INFO:root:Train (Epoch 163): Loss/seq after 03650 batchs: 413.517578125
INFO:root:Train (Epoch 163): Loss/seq after 03700 batchs: 415.6541442871094
INFO:root:Train (Epoch 163): Loss/seq after 03750 batchs: 419.9421691894531
INFO:root:Train (Epoch 163): Loss/seq after 03800 batchs: 418.8646545410156
INFO:root:Train (Epoch 163): Loss/seq after 03850 batchs: 417.9416809082031
INFO:root:Train (Epoch 163): Loss/seq after 03900 batchs: 420.279296875
INFO:root:Train (Epoch 163): Loss/seq after 03950 batchs: 422.87017822265625
INFO:root:Train (Epoch 163): Loss/seq after 04000 batchs: 420.1720275878906
INFO:root:Train (Epoch 163): Loss/seq after 04050 batchs: 417.6155090332031
INFO:root:Train (Epoch 163): Loss/seq after 04100 batchs: 416.7544860839844
INFO:root:Train (Epoch 163): Loss/seq after 04150 batchs: 416.9337463378906
INFO:root:Train (Epoch 163): Loss/seq after 04200 batchs: 415.9667663574219
INFO:root:Train (Epoch 163): Loss/seq after 04250 batchs: 414.6073303222656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 163): Loss/seq after 00000 batches: 358.7235107421875
INFO:root:# Valid (Epoch 163): Loss/seq after 00050 batches: 525.2931518554688
INFO:root:# Valid (Epoch 163): Loss/seq after 00100 batches: 541.5392456054688
INFO:root:# Valid (Epoch 163): Loss/seq after 00150 batches: 416.8760070800781
INFO:root:# Valid (Epoch 163): Loss/seq after 00200 batches: 393.19537353515625
INFO:root:Artifacts: Make stick videos for epoch 163
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_163_on_20220413_090905.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_163_index_264_on_20220413_090905.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 164): Loss/seq after 00000 batchs: 791.7604370117188
INFO:root:Train (Epoch 164): Loss/seq after 00050 batchs: 577.8465576171875
INFO:root:Train (Epoch 164): Loss/seq after 00100 batchs: 549.9342651367188
INFO:root:Train (Epoch 164): Loss/seq after 00150 batchs: 510.41510009765625
INFO:root:Train (Epoch 164): Loss/seq after 00200 batchs: 558.7887573242188
INFO:root:Train (Epoch 164): Loss/seq after 00250 batchs: 624.7478637695312
INFO:root:Train (Epoch 164): Loss/seq after 00300 batchs: 637.3887939453125
INFO:root:Train (Epoch 164): Loss/seq after 00350 batchs: 600.3245849609375
INFO:root:Train (Epoch 164): Loss/seq after 00400 batchs: 586.1448364257812
INFO:root:Train (Epoch 164): Loss/seq after 00450 batchs: 589.6721801757812
INFO:root:Train (Epoch 164): Loss/seq after 00500 batchs: 571.0530395507812
INFO:root:Train (Epoch 164): Loss/seq after 00550 batchs: 557.8363647460938
INFO:root:Train (Epoch 164): Loss/seq after 00600 batchs: 539.965576171875
INFO:root:Train (Epoch 164): Loss/seq after 00650 batchs: 520.0603637695312
INFO:root:Train (Epoch 164): Loss/seq after 00700 batchs: 499.3260192871094
INFO:root:Train (Epoch 164): Loss/seq after 00750 batchs: 496.60711669921875
INFO:root:Train (Epoch 164): Loss/seq after 00800 batchs: 502.4697570800781
INFO:root:Train (Epoch 164): Loss/seq after 00850 batchs: 487.29754638671875
INFO:root:Train (Epoch 164): Loss/seq after 00900 batchs: 478.01361083984375
INFO:root:Train (Epoch 164): Loss/seq after 00950 batchs: 475.9119567871094
INFO:root:Train (Epoch 164): Loss/seq after 01000 batchs: 468.5924987792969
INFO:root:Train (Epoch 164): Loss/seq after 01050 batchs: 462.05712890625
INFO:root:Train (Epoch 164): Loss/seq after 01100 batchs: 455.2713623046875
INFO:root:Train (Epoch 164): Loss/seq after 01150 batchs: 443.5625305175781
INFO:root:Train (Epoch 164): Loss/seq after 01200 batchs: 448.531005859375
INFO:root:Train (Epoch 164): Loss/seq after 01250 batchs: 449.5159912109375
INFO:root:Train (Epoch 164): Loss/seq after 01300 batchs: 440.4764099121094
INFO:root:Train (Epoch 164): Loss/seq after 01350 batchs: 433.5612487792969
INFO:root:Train (Epoch 164): Loss/seq after 01400 batchs: 435.6183166503906
INFO:root:Train (Epoch 164): Loss/seq after 01450 batchs: 438.56048583984375
INFO:root:Train (Epoch 164): Loss/seq after 01500 batchs: 446.1707763671875
INFO:root:Train (Epoch 164): Loss/seq after 01550 batchs: 447.0035705566406
INFO:root:Train (Epoch 164): Loss/seq after 01600 batchs: 443.2462463378906
INFO:root:Train (Epoch 164): Loss/seq after 01650 batchs: 441.58709716796875
INFO:root:Train (Epoch 164): Loss/seq after 01700 batchs: 445.7568664550781
INFO:root:Train (Epoch 164): Loss/seq after 01750 batchs: 444.0760498046875
INFO:root:Train (Epoch 164): Loss/seq after 01800 batchs: 442.3130798339844
INFO:root:Train (Epoch 164): Loss/seq after 01850 batchs: 440.1946716308594
INFO:root:Train (Epoch 164): Loss/seq after 01900 batchs: 439.85107421875
INFO:root:Train (Epoch 164): Loss/seq after 01950 batchs: 439.26043701171875
INFO:root:Train (Epoch 164): Loss/seq after 02000 batchs: 439.85833740234375
INFO:root:Train (Epoch 164): Loss/seq after 02050 batchs: 439.9180603027344
INFO:root:Train (Epoch 164): Loss/seq after 02100 batchs: 438.4111022949219
INFO:root:Train (Epoch 164): Loss/seq after 02150 batchs: 437.0198669433594
INFO:root:Train (Epoch 164): Loss/seq after 02200 batchs: 435.3158264160156
INFO:root:Train (Epoch 164): Loss/seq after 02250 batchs: 434.0368347167969
INFO:root:Train (Epoch 164): Loss/seq after 02300 batchs: 430.87823486328125
INFO:root:Train (Epoch 164): Loss/seq after 02350 batchs: 428.1443176269531
INFO:root:Train (Epoch 164): Loss/seq after 02400 batchs: 428.75201416015625
INFO:root:Train (Epoch 164): Loss/seq after 02450 batchs: 425.4726867675781
INFO:root:Train (Epoch 164): Loss/seq after 02500 batchs: 419.36834716796875
INFO:root:Train (Epoch 164): Loss/seq after 02550 batchs: 413.88494873046875
INFO:root:Train (Epoch 164): Loss/seq after 02600 batchs: 412.3829345703125
INFO:root:Train (Epoch 164): Loss/seq after 02650 batchs: 408.6767272949219
INFO:root:Train (Epoch 164): Loss/seq after 02700 batchs: 406.3497009277344
INFO:root:Train (Epoch 164): Loss/seq after 02750 batchs: 403.3231201171875
INFO:root:Train (Epoch 164): Loss/seq after 02800 batchs: 401.79266357421875
INFO:root:Train (Epoch 164): Loss/seq after 02850 batchs: 401.5857238769531
INFO:root:Train (Epoch 164): Loss/seq after 02900 batchs: 402.84808349609375
INFO:root:Train (Epoch 164): Loss/seq after 02950 batchs: 402.8826599121094
INFO:root:Train (Epoch 164): Loss/seq after 03000 batchs: 408.4232177734375
INFO:root:Train (Epoch 164): Loss/seq after 03050 batchs: 410.4298400878906
INFO:root:Train (Epoch 164): Loss/seq after 03100 batchs: 412.17864990234375
INFO:root:Train (Epoch 164): Loss/seq after 03150 batchs: 412.8662414550781
INFO:root:Train (Epoch 164): Loss/seq after 03200 batchs: 412.85321044921875
INFO:root:Train (Epoch 164): Loss/seq after 03250 batchs: 414.3039855957031
INFO:root:Train (Epoch 164): Loss/seq after 03300 batchs: 413.7015075683594
INFO:root:Train (Epoch 164): Loss/seq after 03350 batchs: 412.48583984375
INFO:root:Train (Epoch 164): Loss/seq after 03400 batchs: 409.5059814453125
INFO:root:Train (Epoch 164): Loss/seq after 03450 batchs: 408.59490966796875
INFO:root:Train (Epoch 164): Loss/seq after 03500 batchs: 409.4375305175781
INFO:root:Train (Epoch 164): Loss/seq after 03550 batchs: 407.31494140625
INFO:root:Train (Epoch 164): Loss/seq after 03600 batchs: 413.86114501953125
INFO:root:Train (Epoch 164): Loss/seq after 03650 batchs: 412.2964782714844
INFO:root:Train (Epoch 164): Loss/seq after 03700 batchs: 414.6638488769531
INFO:root:Train (Epoch 164): Loss/seq after 03750 batchs: 418.8466796875
INFO:root:Train (Epoch 164): Loss/seq after 03800 batchs: 417.795166015625
INFO:root:Train (Epoch 164): Loss/seq after 03850 batchs: 416.85748291015625
INFO:root:Train (Epoch 164): Loss/seq after 03900 batchs: 419.1480712890625
INFO:root:Train (Epoch 164): Loss/seq after 03950 batchs: 421.8178405761719
INFO:root:Train (Epoch 164): Loss/seq after 04000 batchs: 419.11627197265625
INFO:root:Train (Epoch 164): Loss/seq after 04050 batchs: 416.5710754394531
INFO:root:Train (Epoch 164): Loss/seq after 04100 batchs: 415.69573974609375
INFO:root:Train (Epoch 164): Loss/seq after 04150 batchs: 415.8163757324219
INFO:root:Train (Epoch 164): Loss/seq after 04200 batchs: 414.8348388671875
INFO:root:Train (Epoch 164): Loss/seq after 04250 batchs: 413.47161865234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 164): Loss/seq after 00000 batches: 352.82037353515625
INFO:root:# Valid (Epoch 164): Loss/seq after 00050 batches: 521.3876953125
INFO:root:# Valid (Epoch 164): Loss/seq after 00100 batches: 547.8176879882812
INFO:root:# Valid (Epoch 164): Loss/seq after 00150 batches: 418.6954040527344
INFO:root:# Valid (Epoch 164): Loss/seq after 00200 batches: 393.62408447265625
INFO:root:Artifacts: Make stick videos for epoch 164
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_164_on_20220413_091433.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_164_index_307_on_20220413_091433.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 165): Loss/seq after 00000 batchs: 733.7252197265625
INFO:root:Train (Epoch 165): Loss/seq after 00050 batchs: 574.1539306640625
INFO:root:Train (Epoch 165): Loss/seq after 00100 batchs: 545.0425415039062
INFO:root:Train (Epoch 165): Loss/seq after 00150 batchs: 507.8948059082031
INFO:root:Train (Epoch 165): Loss/seq after 00200 batchs: 557.8446044921875
INFO:root:Train (Epoch 165): Loss/seq after 00250 batchs: 623.689208984375
INFO:root:Train (Epoch 165): Loss/seq after 00300 batchs: 636.24658203125
INFO:root:Train (Epoch 165): Loss/seq after 00350 batchs: 599.63330078125
INFO:root:Train (Epoch 165): Loss/seq after 00400 batchs: 584.8631591796875
INFO:root:Train (Epoch 165): Loss/seq after 00450 batchs: 588.6911010742188
INFO:root:Train (Epoch 165): Loss/seq after 00500 batchs: 569.4465942382812
INFO:root:Train (Epoch 165): Loss/seq after 00550 batchs: 557.349609375
INFO:root:Train (Epoch 165): Loss/seq after 00600 batchs: 539.9310302734375
INFO:root:Train (Epoch 165): Loss/seq after 00650 batchs: 520.1331787109375
INFO:root:Train (Epoch 165): Loss/seq after 00700 batchs: 499.20770263671875
INFO:root:Train (Epoch 165): Loss/seq after 00750 batchs: 496.7178649902344
INFO:root:Train (Epoch 165): Loss/seq after 00800 batchs: 502.1835021972656
INFO:root:Train (Epoch 165): Loss/seq after 00850 batchs: 486.78857421875
INFO:root:Train (Epoch 165): Loss/seq after 00900 batchs: 476.6311340332031
INFO:root:Train (Epoch 165): Loss/seq after 00950 batchs: 474.115966796875
INFO:root:Train (Epoch 165): Loss/seq after 01000 batchs: 466.2156677246094
INFO:root:Train (Epoch 165): Loss/seq after 01050 batchs: 458.1760559082031
INFO:root:Train (Epoch 165): Loss/seq after 01100 batchs: 449.9996032714844
INFO:root:Train (Epoch 165): Loss/seq after 01150 batchs: 438.27716064453125
INFO:root:Train (Epoch 165): Loss/seq after 01200 batchs: 443.3332214355469
INFO:root:Train (Epoch 165): Loss/seq after 01250 batchs: 444.07763671875
INFO:root:Train (Epoch 165): Loss/seq after 01300 batchs: 435.35833740234375
INFO:root:Train (Epoch 165): Loss/seq after 01350 batchs: 428.3907165527344
INFO:root:Train (Epoch 165): Loss/seq after 01400 batchs: 430.48236083984375
INFO:root:Train (Epoch 165): Loss/seq after 01450 batchs: 433.34326171875
INFO:root:Train (Epoch 165): Loss/seq after 01500 batchs: 440.8285827636719
INFO:root:Train (Epoch 165): Loss/seq after 01550 batchs: 441.43768310546875
INFO:root:Train (Epoch 165): Loss/seq after 01600 batchs: 437.7811279296875
INFO:root:Train (Epoch 165): Loss/seq after 01650 batchs: 436.0763854980469
INFO:root:Train (Epoch 165): Loss/seq after 01700 batchs: 440.54388427734375
INFO:root:Train (Epoch 165): Loss/seq after 01750 batchs: 438.762939453125
INFO:root:Train (Epoch 165): Loss/seq after 01800 batchs: 437.06866455078125
INFO:root:Train (Epoch 165): Loss/seq after 01850 batchs: 435.1226806640625
INFO:root:Train (Epoch 165): Loss/seq after 01900 batchs: 434.91937255859375
INFO:root:Train (Epoch 165): Loss/seq after 01950 batchs: 434.3044738769531
INFO:root:Train (Epoch 165): Loss/seq after 02000 batchs: 434.9712829589844
INFO:root:Train (Epoch 165): Loss/seq after 02050 batchs: 435.03289794921875
INFO:root:Train (Epoch 165): Loss/seq after 02100 batchs: 433.7079772949219
INFO:root:Train (Epoch 165): Loss/seq after 02150 batchs: 432.36212158203125
INFO:root:Train (Epoch 165): Loss/seq after 02200 batchs: 430.680419921875
INFO:root:Train (Epoch 165): Loss/seq after 02250 batchs: 429.4061584472656
INFO:root:Train (Epoch 165): Loss/seq after 02300 batchs: 426.3463439941406
INFO:root:Train (Epoch 165): Loss/seq after 02350 batchs: 423.6014709472656
INFO:root:Train (Epoch 165): Loss/seq after 02400 batchs: 424.29803466796875
INFO:root:Train (Epoch 165): Loss/seq after 02450 batchs: 421.1339111328125
INFO:root:Train (Epoch 165): Loss/seq after 02500 batchs: 415.09893798828125
INFO:root:Train (Epoch 165): Loss/seq after 02550 batchs: 409.6817626953125
INFO:root:Train (Epoch 165): Loss/seq after 02600 batchs: 408.28863525390625
INFO:root:Train (Epoch 165): Loss/seq after 02650 batchs: 404.712890625
INFO:root:Train (Epoch 165): Loss/seq after 02700 batchs: 402.2681884765625
INFO:root:Train (Epoch 165): Loss/seq after 02750 batchs: 398.96270751953125
INFO:root:Train (Epoch 165): Loss/seq after 02800 batchs: 397.1853332519531
INFO:root:Train (Epoch 165): Loss/seq after 02850 batchs: 397.1377258300781
INFO:root:Train (Epoch 165): Loss/seq after 02900 batchs: 398.4589538574219
INFO:root:Train (Epoch 165): Loss/seq after 02950 batchs: 398.6110534667969
INFO:root:Train (Epoch 165): Loss/seq after 03000 batchs: 404.25689697265625
INFO:root:Train (Epoch 165): Loss/seq after 03050 batchs: 406.8740234375
INFO:root:Train (Epoch 165): Loss/seq after 03100 batchs: 408.8691101074219
INFO:root:Train (Epoch 165): Loss/seq after 03150 batchs: 409.2043151855469
INFO:root:Train (Epoch 165): Loss/seq after 03200 batchs: 409.2249755859375
INFO:root:Train (Epoch 165): Loss/seq after 03250 batchs: 410.541015625
INFO:root:Train (Epoch 165): Loss/seq after 03300 batchs: 409.9165954589844
INFO:root:Train (Epoch 165): Loss/seq after 03350 batchs: 408.66070556640625
INFO:root:Train (Epoch 165): Loss/seq after 03400 batchs: 405.7078552246094
INFO:root:Train (Epoch 165): Loss/seq after 03450 batchs: 404.71484375
INFO:root:Train (Epoch 165): Loss/seq after 03500 batchs: 405.5665283203125
INFO:root:Train (Epoch 165): Loss/seq after 03550 batchs: 403.5313415527344
INFO:root:Train (Epoch 165): Loss/seq after 03600 batchs: 410.1927795410156
INFO:root:Train (Epoch 165): Loss/seq after 03650 batchs: 408.642578125
INFO:root:Train (Epoch 165): Loss/seq after 03700 batchs: 411.0311279296875
INFO:root:Train (Epoch 165): Loss/seq after 03750 batchs: 415.2256164550781
INFO:root:Train (Epoch 165): Loss/seq after 03800 batchs: 414.22698974609375
INFO:root:Train (Epoch 165): Loss/seq after 03850 batchs: 413.3297424316406
INFO:root:Train (Epoch 165): Loss/seq after 03900 batchs: 415.5624694824219
INFO:root:Train (Epoch 165): Loss/seq after 03950 batchs: 418.29083251953125
INFO:root:Train (Epoch 165): Loss/seq after 04000 batchs: 415.6105041503906
INFO:root:Train (Epoch 165): Loss/seq after 04050 batchs: 413.078857421875
INFO:root:Train (Epoch 165): Loss/seq after 04100 batchs: 412.212646484375
INFO:root:Train (Epoch 165): Loss/seq after 04150 batchs: 412.3197021484375
INFO:root:Train (Epoch 165): Loss/seq after 04200 batchs: 411.3717041015625
INFO:root:Train (Epoch 165): Loss/seq after 04250 batchs: 410.0491027832031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 165): Loss/seq after 00000 batches: 344.8385009765625
INFO:root:# Valid (Epoch 165): Loss/seq after 00050 batches: 521.5380249023438
INFO:root:# Valid (Epoch 165): Loss/seq after 00100 batches: 531.4917602539062
INFO:root:# Valid (Epoch 165): Loss/seq after 00150 batches: 408.76287841796875
INFO:root:# Valid (Epoch 165): Loss/seq after 00200 batches: 385.7496337890625
INFO:root:Artifacts: Make stick videos for epoch 165
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_165_on_20220413_091956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_165_index_1397_on_20220413_091956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 166): Loss/seq after 00000 batchs: 772.3857421875
INFO:root:Train (Epoch 166): Loss/seq after 00050 batchs: 578.5938720703125
INFO:root:Train (Epoch 166): Loss/seq after 00100 batchs: 551.110107421875
INFO:root:Train (Epoch 166): Loss/seq after 00150 batchs: 508.3390808105469
INFO:root:Train (Epoch 166): Loss/seq after 00200 batchs: 555.720703125
INFO:root:Train (Epoch 166): Loss/seq after 00250 batchs: 619.9853515625
INFO:root:Train (Epoch 166): Loss/seq after 00300 batchs: 632.0463256835938
INFO:root:Train (Epoch 166): Loss/seq after 00350 batchs: 596.0983276367188
INFO:root:Train (Epoch 166): Loss/seq after 00400 batchs: 580.8984985351562
INFO:root:Train (Epoch 166): Loss/seq after 00450 batchs: 584.8446044921875
INFO:root:Train (Epoch 166): Loss/seq after 00500 batchs: 567.143310546875
INFO:root:Train (Epoch 166): Loss/seq after 00550 batchs: 554.5210571289062
INFO:root:Train (Epoch 166): Loss/seq after 00600 batchs: 536.7779541015625
INFO:root:Train (Epoch 166): Loss/seq after 00650 batchs: 516.98583984375
INFO:root:Train (Epoch 166): Loss/seq after 00700 batchs: 496.10125732421875
INFO:root:Train (Epoch 166): Loss/seq after 00750 batchs: 494.2711181640625
INFO:root:Train (Epoch 166): Loss/seq after 00800 batchs: 500.17791748046875
INFO:root:Train (Epoch 166): Loss/seq after 00850 batchs: 484.8167419433594
INFO:root:Train (Epoch 166): Loss/seq after 00900 batchs: 475.1103515625
INFO:root:Train (Epoch 166): Loss/seq after 00950 batchs: 473.48785400390625
INFO:root:Train (Epoch 166): Loss/seq after 01000 batchs: 465.5400085449219
INFO:root:Train (Epoch 166): Loss/seq after 01050 batchs: 457.814697265625
INFO:root:Train (Epoch 166): Loss/seq after 01100 batchs: 449.8016662597656
INFO:root:Train (Epoch 166): Loss/seq after 01150 batchs: 438.2883605957031
INFO:root:Train (Epoch 166): Loss/seq after 01200 batchs: 442.8905029296875
INFO:root:Train (Epoch 166): Loss/seq after 01250 batchs: 443.65533447265625
INFO:root:Train (Epoch 166): Loss/seq after 01300 batchs: 434.8213195800781
INFO:root:Train (Epoch 166): Loss/seq after 01350 batchs: 427.7502746582031
INFO:root:Train (Epoch 166): Loss/seq after 01400 batchs: 429.7370910644531
INFO:root:Train (Epoch 166): Loss/seq after 01450 batchs: 432.6330871582031
INFO:root:Train (Epoch 166): Loss/seq after 01500 batchs: 440.6484680175781
INFO:root:Train (Epoch 166): Loss/seq after 01550 batchs: 440.77459716796875
INFO:root:Train (Epoch 166): Loss/seq after 01600 batchs: 436.93096923828125
INFO:root:Train (Epoch 166): Loss/seq after 01650 batchs: 435.270263671875
INFO:root:Train (Epoch 166): Loss/seq after 01700 batchs: 439.6730041503906
INFO:root:Train (Epoch 166): Loss/seq after 01750 batchs: 438.01025390625
INFO:root:Train (Epoch 166): Loss/seq after 01800 batchs: 436.158935546875
INFO:root:Train (Epoch 166): Loss/seq after 01850 batchs: 433.9608154296875
INFO:root:Train (Epoch 166): Loss/seq after 01900 batchs: 433.5918884277344
INFO:root:Train (Epoch 166): Loss/seq after 01950 batchs: 432.6450500488281
INFO:root:Train (Epoch 166): Loss/seq after 02000 batchs: 433.23858642578125
INFO:root:Train (Epoch 166): Loss/seq after 02050 batchs: 433.2320861816406
INFO:root:Train (Epoch 166): Loss/seq after 02100 batchs: 431.83013916015625
INFO:root:Train (Epoch 166): Loss/seq after 02150 batchs: 430.5176086425781
INFO:root:Train (Epoch 166): Loss/seq after 02200 batchs: 428.954833984375
INFO:root:Train (Epoch 166): Loss/seq after 02250 batchs: 427.792724609375
INFO:root:Train (Epoch 166): Loss/seq after 02300 batchs: 424.80902099609375
INFO:root:Train (Epoch 166): Loss/seq after 02350 batchs: 422.14105224609375
INFO:root:Train (Epoch 166): Loss/seq after 02400 batchs: 422.78424072265625
INFO:root:Train (Epoch 166): Loss/seq after 02450 batchs: 419.5957336425781
INFO:root:Train (Epoch 166): Loss/seq after 02500 batchs: 413.59429931640625
INFO:root:Train (Epoch 166): Loss/seq after 02550 batchs: 408.179443359375
INFO:root:Train (Epoch 166): Loss/seq after 02600 batchs: 406.70562744140625
INFO:root:Train (Epoch 166): Loss/seq after 02650 batchs: 403.08416748046875
INFO:root:Train (Epoch 166): Loss/seq after 02700 batchs: 400.73583984375
INFO:root:Train (Epoch 166): Loss/seq after 02750 batchs: 397.4640808105469
INFO:root:Train (Epoch 166): Loss/seq after 02800 batchs: 395.9655456542969
INFO:root:Train (Epoch 166): Loss/seq after 02850 batchs: 395.8568115234375
INFO:root:Train (Epoch 166): Loss/seq after 02900 batchs: 397.0455627441406
INFO:root:Train (Epoch 166): Loss/seq after 02950 batchs: 397.19488525390625
INFO:root:Train (Epoch 166): Loss/seq after 03000 batchs: 402.7584533691406
INFO:root:Train (Epoch 166): Loss/seq after 03050 batchs: 404.93310546875
INFO:root:Train (Epoch 166): Loss/seq after 03100 batchs: 406.85906982421875
INFO:root:Train (Epoch 166): Loss/seq after 03150 batchs: 407.1665954589844
INFO:root:Train (Epoch 166): Loss/seq after 03200 batchs: 407.2283630371094
INFO:root:Train (Epoch 166): Loss/seq after 03250 batchs: 408.2244567871094
INFO:root:Train (Epoch 166): Loss/seq after 03300 batchs: 407.8085632324219
INFO:root:Train (Epoch 166): Loss/seq after 03350 batchs: 406.54937744140625
INFO:root:Train (Epoch 166): Loss/seq after 03400 batchs: 403.6070251464844
INFO:root:Train (Epoch 166): Loss/seq after 03450 batchs: 402.6618957519531
INFO:root:Train (Epoch 166): Loss/seq after 03500 batchs: 403.65313720703125
INFO:root:Train (Epoch 166): Loss/seq after 03550 batchs: 401.53961181640625
INFO:root:Train (Epoch 166): Loss/seq after 03600 batchs: 408.11932373046875
INFO:root:Train (Epoch 166): Loss/seq after 03650 batchs: 406.6604919433594
INFO:root:Train (Epoch 166): Loss/seq after 03700 batchs: 409.1263427734375
INFO:root:Train (Epoch 166): Loss/seq after 03750 batchs: 413.38177490234375
INFO:root:Train (Epoch 166): Loss/seq after 03800 batchs: 412.3769226074219
INFO:root:Train (Epoch 166): Loss/seq after 03850 batchs: 411.48419189453125
INFO:root:Train (Epoch 166): Loss/seq after 03900 batchs: 413.59332275390625
INFO:root:Train (Epoch 166): Loss/seq after 03950 batchs: 416.1864929199219
INFO:root:Train (Epoch 166): Loss/seq after 04000 batchs: 413.5364990234375
INFO:root:Train (Epoch 166): Loss/seq after 04050 batchs: 411.014404296875
INFO:root:Train (Epoch 166): Loss/seq after 04100 batchs: 410.16943359375
INFO:root:Train (Epoch 166): Loss/seq after 04150 batchs: 410.3300476074219
INFO:root:Train (Epoch 166): Loss/seq after 04200 batchs: 409.3951416015625
INFO:root:Train (Epoch 166): Loss/seq after 04250 batchs: 408.0871276855469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 166): Loss/seq after 00000 batches: 349.5875549316406
INFO:root:# Valid (Epoch 166): Loss/seq after 00050 batches: 507.09918212890625
INFO:root:# Valid (Epoch 166): Loss/seq after 00100 batches: 517.2819213867188
INFO:root:# Valid (Epoch 166): Loss/seq after 00150 batches: 398.8203125
INFO:root:# Valid (Epoch 166): Loss/seq after 00200 batches: 376.91021728515625
INFO:root:Artifacts: Make stick videos for epoch 166
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_166_on_20220413_092520.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_166_index_1076_on_20220413_092520.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 167): Loss/seq after 00000 batchs: 738.3143310546875
INFO:root:Train (Epoch 167): Loss/seq after 00050 batchs: 575.141845703125
INFO:root:Train (Epoch 167): Loss/seq after 00100 batchs: 548.5560302734375
INFO:root:Train (Epoch 167): Loss/seq after 00150 batchs: 507.6180114746094
INFO:root:Train (Epoch 167): Loss/seq after 00200 batchs: 559.859619140625
INFO:root:Train (Epoch 167): Loss/seq after 00250 batchs: 626.8735961914062
INFO:root:Train (Epoch 167): Loss/seq after 00300 batchs: 637.03271484375
INFO:root:Train (Epoch 167): Loss/seq after 00350 batchs: 599.6011352539062
INFO:root:Train (Epoch 167): Loss/seq after 00400 batchs: 583.804443359375
INFO:root:Train (Epoch 167): Loss/seq after 00450 batchs: 587.6504516601562
INFO:root:Train (Epoch 167): Loss/seq after 00500 batchs: 570.8665771484375
INFO:root:Train (Epoch 167): Loss/seq after 00550 batchs: 558.9359741210938
INFO:root:Train (Epoch 167): Loss/seq after 00600 batchs: 541.0888061523438
INFO:root:Train (Epoch 167): Loss/seq after 00650 batchs: 520.990478515625
INFO:root:Train (Epoch 167): Loss/seq after 00700 batchs: 500.2006530761719
INFO:root:Train (Epoch 167): Loss/seq after 00750 batchs: 496.5720520019531
INFO:root:Train (Epoch 167): Loss/seq after 00800 batchs: 501.5663146972656
INFO:root:Train (Epoch 167): Loss/seq after 00850 batchs: 486.0380859375
INFO:root:Train (Epoch 167): Loss/seq after 00900 batchs: 475.87152099609375
INFO:root:Train (Epoch 167): Loss/seq after 00950 batchs: 473.3985595703125
INFO:root:Train (Epoch 167): Loss/seq after 01000 batchs: 465.4968566894531
INFO:root:Train (Epoch 167): Loss/seq after 01050 batchs: 457.6861877441406
INFO:root:Train (Epoch 167): Loss/seq after 01100 batchs: 449.68060302734375
INFO:root:Train (Epoch 167): Loss/seq after 01150 batchs: 438.0492858886719
INFO:root:Train (Epoch 167): Loss/seq after 01200 batchs: 442.4073791503906
INFO:root:Train (Epoch 167): Loss/seq after 01250 batchs: 442.9670104980469
INFO:root:Train (Epoch 167): Loss/seq after 01300 batchs: 434.0713806152344
INFO:root:Train (Epoch 167): Loss/seq after 01350 batchs: 427.0915222167969
INFO:root:Train (Epoch 167): Loss/seq after 01400 batchs: 428.9924011230469
INFO:root:Train (Epoch 167): Loss/seq after 01450 batchs: 431.8967590332031
INFO:root:Train (Epoch 167): Loss/seq after 01500 batchs: 439.6607666015625
INFO:root:Train (Epoch 167): Loss/seq after 01550 batchs: 440.047607421875
INFO:root:Train (Epoch 167): Loss/seq after 01600 batchs: 436.2995300292969
INFO:root:Train (Epoch 167): Loss/seq after 01650 batchs: 434.80255126953125
INFO:root:Train (Epoch 167): Loss/seq after 01700 batchs: 438.95068359375
INFO:root:Train (Epoch 167): Loss/seq after 01750 batchs: 437.31536865234375
INFO:root:Train (Epoch 167): Loss/seq after 01800 batchs: 435.42828369140625
INFO:root:Train (Epoch 167): Loss/seq after 01850 batchs: 433.3646240234375
INFO:root:Train (Epoch 167): Loss/seq after 01900 batchs: 432.83612060546875
INFO:root:Train (Epoch 167): Loss/seq after 01950 batchs: 431.9775390625
INFO:root:Train (Epoch 167): Loss/seq after 02000 batchs: 432.56976318359375
INFO:root:Train (Epoch 167): Loss/seq after 02050 batchs: 432.5630798339844
INFO:root:Train (Epoch 167): Loss/seq after 02100 batchs: 431.22509765625
INFO:root:Train (Epoch 167): Loss/seq after 02150 batchs: 429.8857116699219
INFO:root:Train (Epoch 167): Loss/seq after 02200 batchs: 428.21630859375
INFO:root:Train (Epoch 167): Loss/seq after 02250 batchs: 426.9521484375
INFO:root:Train (Epoch 167): Loss/seq after 02300 batchs: 423.75518798828125
INFO:root:Train (Epoch 167): Loss/seq after 02350 batchs: 420.9778747558594
INFO:root:Train (Epoch 167): Loss/seq after 02400 batchs: 421.4774475097656
INFO:root:Train (Epoch 167): Loss/seq after 02450 batchs: 418.2597351074219
INFO:root:Train (Epoch 167): Loss/seq after 02500 batchs: 412.2358703613281
INFO:root:Train (Epoch 167): Loss/seq after 02550 batchs: 406.7702941894531
INFO:root:Train (Epoch 167): Loss/seq after 02600 batchs: 405.2149963378906
INFO:root:Train (Epoch 167): Loss/seq after 02650 batchs: 401.5792236328125
INFO:root:Train (Epoch 167): Loss/seq after 02700 batchs: 399.3009338378906
INFO:root:Train (Epoch 167): Loss/seq after 02750 batchs: 396.14501953125
INFO:root:Train (Epoch 167): Loss/seq after 02800 batchs: 394.6943054199219
INFO:root:Train (Epoch 167): Loss/seq after 02850 batchs: 394.4850158691406
INFO:root:Train (Epoch 167): Loss/seq after 02900 batchs: 395.7287902832031
INFO:root:Train (Epoch 167): Loss/seq after 02950 batchs: 395.97088623046875
INFO:root:Train (Epoch 167): Loss/seq after 03000 batchs: 401.5330810546875
INFO:root:Train (Epoch 167): Loss/seq after 03050 batchs: 403.60400390625
INFO:root:Train (Epoch 167): Loss/seq after 03100 batchs: 405.3690490722656
INFO:root:Train (Epoch 167): Loss/seq after 03150 batchs: 405.2210998535156
INFO:root:Train (Epoch 167): Loss/seq after 03200 batchs: 405.2626953125
INFO:root:Train (Epoch 167): Loss/seq after 03250 batchs: 406.5020446777344
INFO:root:Train (Epoch 167): Loss/seq after 03300 batchs: 405.73236083984375
INFO:root:Train (Epoch 167): Loss/seq after 03350 batchs: 404.5132141113281
INFO:root:Train (Epoch 167): Loss/seq after 03400 batchs: 401.57720947265625
INFO:root:Train (Epoch 167): Loss/seq after 03450 batchs: 400.6495666503906
INFO:root:Train (Epoch 167): Loss/seq after 03500 batchs: 401.504150390625
INFO:root:Train (Epoch 167): Loss/seq after 03550 batchs: 399.6758117675781
INFO:root:Train (Epoch 167): Loss/seq after 03600 batchs: 406.29510498046875
INFO:root:Train (Epoch 167): Loss/seq after 03650 batchs: 404.9073486328125
INFO:root:Train (Epoch 167): Loss/seq after 03700 batchs: 407.318115234375
INFO:root:Train (Epoch 167): Loss/seq after 03750 batchs: 411.4710998535156
INFO:root:Train (Epoch 167): Loss/seq after 03800 batchs: 410.4844970703125
INFO:root:Train (Epoch 167): Loss/seq after 03850 batchs: 409.577392578125
INFO:root:Train (Epoch 167): Loss/seq after 03900 batchs: 411.7100830078125
INFO:root:Train (Epoch 167): Loss/seq after 03950 batchs: 414.1867980957031
INFO:root:Train (Epoch 167): Loss/seq after 04000 batchs: 411.55029296875
INFO:root:Train (Epoch 167): Loss/seq after 04050 batchs: 409.0567626953125
INFO:root:Train (Epoch 167): Loss/seq after 04100 batchs: 408.2212219238281
INFO:root:Train (Epoch 167): Loss/seq after 04150 batchs: 408.3336486816406
INFO:root:Train (Epoch 167): Loss/seq after 04200 batchs: 407.337890625
INFO:root:Train (Epoch 167): Loss/seq after 04250 batchs: 406.0625915527344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 167): Loss/seq after 00000 batches: 340.4709777832031
INFO:root:# Valid (Epoch 167): Loss/seq after 00050 batches: 521.5320434570312
INFO:root:# Valid (Epoch 167): Loss/seq after 00100 batches: 537.0423583984375
INFO:root:# Valid (Epoch 167): Loss/seq after 00150 batches: 413.433349609375
INFO:root:# Valid (Epoch 167): Loss/seq after 00200 batches: 389.96954345703125
INFO:root:Artifacts: Make stick videos for epoch 167
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_167_on_20220413_093043.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_167_index_1256_on_20220413_093043.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 168): Loss/seq after 00000 batchs: 751.5457153320312
INFO:root:Train (Epoch 168): Loss/seq after 00050 batchs: 571.3818969726562
INFO:root:Train (Epoch 168): Loss/seq after 00100 batchs: 543.6234741210938
INFO:root:Train (Epoch 168): Loss/seq after 00150 batchs: 504.8742370605469
INFO:root:Train (Epoch 168): Loss/seq after 00200 batchs: 561.8724365234375
INFO:root:Train (Epoch 168): Loss/seq after 00250 batchs: 630.4783325195312
INFO:root:Train (Epoch 168): Loss/seq after 00300 batchs: 639.8978881835938
INFO:root:Train (Epoch 168): Loss/seq after 00350 batchs: 601.5874633789062
INFO:root:Train (Epoch 168): Loss/seq after 00400 batchs: 585.8275756835938
INFO:root:Train (Epoch 168): Loss/seq after 00450 batchs: 589.0301513671875
INFO:root:Train (Epoch 168): Loss/seq after 00500 batchs: 570.4583129882812
INFO:root:Train (Epoch 168): Loss/seq after 00550 batchs: 557.339599609375
INFO:root:Train (Epoch 168): Loss/seq after 00600 batchs: 539.8348388671875
INFO:root:Train (Epoch 168): Loss/seq after 00650 batchs: 519.9149169921875
INFO:root:Train (Epoch 168): Loss/seq after 00700 batchs: 498.47344970703125
INFO:root:Train (Epoch 168): Loss/seq after 00750 batchs: 496.28802490234375
INFO:root:Train (Epoch 168): Loss/seq after 00800 batchs: 501.4619445800781
INFO:root:Train (Epoch 168): Loss/seq after 00850 batchs: 485.96234130859375
INFO:root:Train (Epoch 168): Loss/seq after 00900 batchs: 476.0665588378906
INFO:root:Train (Epoch 168): Loss/seq after 00950 batchs: 473.75555419921875
INFO:root:Train (Epoch 168): Loss/seq after 01000 batchs: 465.9205627441406
INFO:root:Train (Epoch 168): Loss/seq after 01050 batchs: 457.8212890625
INFO:root:Train (Epoch 168): Loss/seq after 01100 batchs: 449.9918518066406
INFO:root:Train (Epoch 168): Loss/seq after 01150 batchs: 438.48602294921875
INFO:root:Train (Epoch 168): Loss/seq after 01200 batchs: 442.1989440917969
INFO:root:Train (Epoch 168): Loss/seq after 01250 batchs: 442.85687255859375
INFO:root:Train (Epoch 168): Loss/seq after 01300 batchs: 433.95330810546875
INFO:root:Train (Epoch 168): Loss/seq after 01350 batchs: 426.9190368652344
INFO:root:Train (Epoch 168): Loss/seq after 01400 batchs: 428.99981689453125
INFO:root:Train (Epoch 168): Loss/seq after 01450 batchs: 432.0465087890625
INFO:root:Train (Epoch 168): Loss/seq after 01500 batchs: 439.6745910644531
INFO:root:Train (Epoch 168): Loss/seq after 01550 batchs: 439.7358703613281
INFO:root:Train (Epoch 168): Loss/seq after 01600 batchs: 436.1510314941406
INFO:root:Train (Epoch 168): Loss/seq after 01650 batchs: 434.46868896484375
INFO:root:Train (Epoch 168): Loss/seq after 01700 batchs: 438.7047119140625
INFO:root:Train (Epoch 168): Loss/seq after 01750 batchs: 437.0954895019531
INFO:root:Train (Epoch 168): Loss/seq after 01800 batchs: 435.2997741699219
INFO:root:Train (Epoch 168): Loss/seq after 01850 batchs: 433.0934143066406
INFO:root:Train (Epoch 168): Loss/seq after 01900 batchs: 432.495361328125
INFO:root:Train (Epoch 168): Loss/seq after 01950 batchs: 431.37847900390625
INFO:root:Train (Epoch 168): Loss/seq after 02000 batchs: 431.9984130859375
INFO:root:Train (Epoch 168): Loss/seq after 02050 batchs: 432.1608581542969
INFO:root:Train (Epoch 168): Loss/seq after 02100 batchs: 430.7082214355469
INFO:root:Train (Epoch 168): Loss/seq after 02150 batchs: 429.3774719238281
INFO:root:Train (Epoch 168): Loss/seq after 02200 batchs: 427.7707824707031
INFO:root:Train (Epoch 168): Loss/seq after 02250 batchs: 426.529296875
INFO:root:Train (Epoch 168): Loss/seq after 02300 batchs: 423.51043701171875
INFO:root:Train (Epoch 168): Loss/seq after 02350 batchs: 420.84588623046875
INFO:root:Train (Epoch 168): Loss/seq after 02400 batchs: 421.4608154296875
INFO:root:Train (Epoch 168): Loss/seq after 02450 batchs: 418.26007080078125
INFO:root:Train (Epoch 168): Loss/seq after 02500 batchs: 412.25048828125
INFO:root:Train (Epoch 168): Loss/seq after 02550 batchs: 406.72747802734375
INFO:root:Train (Epoch 168): Loss/seq after 02600 batchs: 405.1554260253906
INFO:root:Train (Epoch 168): Loss/seq after 02650 batchs: 401.5223388671875
INFO:root:Train (Epoch 168): Loss/seq after 02700 batchs: 399.1446228027344
INFO:root:Train (Epoch 168): Loss/seq after 02750 batchs: 396.0081481933594
INFO:root:Train (Epoch 168): Loss/seq after 02800 batchs: 394.4635314941406
INFO:root:Train (Epoch 168): Loss/seq after 02850 batchs: 394.2589416503906
INFO:root:Train (Epoch 168): Loss/seq after 02900 batchs: 395.5625
INFO:root:Train (Epoch 168): Loss/seq after 02950 batchs: 395.697998046875
INFO:root:Train (Epoch 168): Loss/seq after 03000 batchs: 401.1705017089844
INFO:root:Train (Epoch 168): Loss/seq after 03050 batchs: 403.3116760253906
INFO:root:Train (Epoch 168): Loss/seq after 03100 batchs: 405.2278137207031
INFO:root:Train (Epoch 168): Loss/seq after 03150 batchs: 405.0100402832031
INFO:root:Train (Epoch 168): Loss/seq after 03200 batchs: 404.9084777832031
INFO:root:Train (Epoch 168): Loss/seq after 03250 batchs: 406.01922607421875
INFO:root:Train (Epoch 168): Loss/seq after 03300 batchs: 405.27178955078125
INFO:root:Train (Epoch 168): Loss/seq after 03350 batchs: 403.9324645996094
INFO:root:Train (Epoch 168): Loss/seq after 03400 batchs: 400.9361877441406
INFO:root:Train (Epoch 168): Loss/seq after 03450 batchs: 400.02117919921875
INFO:root:Train (Epoch 168): Loss/seq after 03500 batchs: 400.89349365234375
INFO:root:Train (Epoch 168): Loss/seq after 03550 batchs: 398.9529113769531
INFO:root:Train (Epoch 168): Loss/seq after 03600 batchs: 405.5262451171875
INFO:root:Train (Epoch 168): Loss/seq after 03650 batchs: 404.122802734375
INFO:root:Train (Epoch 168): Loss/seq after 03700 batchs: 406.3684387207031
INFO:root:Train (Epoch 168): Loss/seq after 03750 batchs: 410.513916015625
INFO:root:Train (Epoch 168): Loss/seq after 03800 batchs: 409.522216796875
INFO:root:Train (Epoch 168): Loss/seq after 03850 batchs: 408.6675720214844
INFO:root:Train (Epoch 168): Loss/seq after 03900 batchs: 410.6471252441406
INFO:root:Train (Epoch 168): Loss/seq after 03950 batchs: 413.2080078125
INFO:root:Train (Epoch 168): Loss/seq after 04000 batchs: 410.58673095703125
INFO:root:Train (Epoch 168): Loss/seq after 04050 batchs: 408.077392578125
INFO:root:Train (Epoch 168): Loss/seq after 04100 batchs: 407.2346496582031
INFO:root:Train (Epoch 168): Loss/seq after 04150 batchs: 407.3275146484375
INFO:root:Train (Epoch 168): Loss/seq after 04200 batchs: 406.3345642089844
INFO:root:Train (Epoch 168): Loss/seq after 04250 batchs: 404.9676513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 168): Loss/seq after 00000 batches: 347.9779357910156
INFO:root:# Valid (Epoch 168): Loss/seq after 00050 batches: 530.733642578125
INFO:root:# Valid (Epoch 168): Loss/seq after 00100 batches: 532.8118896484375
INFO:root:# Valid (Epoch 168): Loss/seq after 00150 batches: 413.3825378417969
INFO:root:# Valid (Epoch 168): Loss/seq after 00200 batches: 395.104736328125
INFO:root:Artifacts: Make stick videos for epoch 168
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_168_on_20220413_093606.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_168_index_1323_on_20220413_093606.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 169): Loss/seq after 00000 batchs: 710.6630859375
INFO:root:Train (Epoch 169): Loss/seq after 00050 batchs: 572.7831420898438
INFO:root:Train (Epoch 169): Loss/seq after 00100 batchs: 545.5941162109375
INFO:root:Train (Epoch 169): Loss/seq after 00150 batchs: 505.4522399902344
INFO:root:Train (Epoch 169): Loss/seq after 00200 batchs: 556.5634155273438
INFO:root:Train (Epoch 169): Loss/seq after 00250 batchs: 618.5478515625
INFO:root:Train (Epoch 169): Loss/seq after 00300 batchs: 627.9739990234375
INFO:root:Train (Epoch 169): Loss/seq after 00350 batchs: 591.8082885742188
INFO:root:Train (Epoch 169): Loss/seq after 00400 batchs: 576.41845703125
INFO:root:Train (Epoch 169): Loss/seq after 00450 batchs: 580.8164672851562
INFO:root:Train (Epoch 169): Loss/seq after 00500 batchs: 561.33447265625
INFO:root:Train (Epoch 169): Loss/seq after 00550 batchs: 548.6015625
INFO:root:Train (Epoch 169): Loss/seq after 00600 batchs: 531.5017700195312
INFO:root:Train (Epoch 169): Loss/seq after 00650 batchs: 511.0082702636719
INFO:root:Train (Epoch 169): Loss/seq after 00700 batchs: 490.51348876953125
INFO:root:Train (Epoch 169): Loss/seq after 00750 batchs: 488.2937927246094
INFO:root:Train (Epoch 169): Loss/seq after 00800 batchs: 494.720458984375
INFO:root:Train (Epoch 169): Loss/seq after 00850 batchs: 479.9256286621094
INFO:root:Train (Epoch 169): Loss/seq after 00900 batchs: 469.8759765625
INFO:root:Train (Epoch 169): Loss/seq after 00950 batchs: 467.1072692871094
INFO:root:Train (Epoch 169): Loss/seq after 01000 batchs: 459.1751708984375
INFO:root:Train (Epoch 169): Loss/seq after 01050 batchs: 451.4886474609375
INFO:root:Train (Epoch 169): Loss/seq after 01100 batchs: 443.7944030761719
INFO:root:Train (Epoch 169): Loss/seq after 01150 batchs: 432.4327697753906
INFO:root:Train (Epoch 169): Loss/seq after 01200 batchs: 436.3522644042969
INFO:root:Train (Epoch 169): Loss/seq after 01250 batchs: 437.0892639160156
INFO:root:Train (Epoch 169): Loss/seq after 01300 batchs: 428.3139953613281
INFO:root:Train (Epoch 169): Loss/seq after 01350 batchs: 421.7106018066406
INFO:root:Train (Epoch 169): Loss/seq after 01400 batchs: 423.44232177734375
INFO:root:Train (Epoch 169): Loss/seq after 01450 batchs: 426.6204833984375
INFO:root:Train (Epoch 169): Loss/seq after 01500 batchs: 434.0865783691406
INFO:root:Train (Epoch 169): Loss/seq after 01550 batchs: 434.3705139160156
INFO:root:Train (Epoch 169): Loss/seq after 01600 batchs: 430.7737121582031
INFO:root:Train (Epoch 169): Loss/seq after 01650 batchs: 429.24493408203125
INFO:root:Train (Epoch 169): Loss/seq after 01700 batchs: 433.5239562988281
INFO:root:Train (Epoch 169): Loss/seq after 01750 batchs: 431.86334228515625
INFO:root:Train (Epoch 169): Loss/seq after 01800 batchs: 430.0800476074219
INFO:root:Train (Epoch 169): Loss/seq after 01850 batchs: 428.0042724609375
INFO:root:Train (Epoch 169): Loss/seq after 01900 batchs: 427.37872314453125
INFO:root:Train (Epoch 169): Loss/seq after 01950 batchs: 426.4261779785156
INFO:root:Train (Epoch 169): Loss/seq after 02000 batchs: 427.1657409667969
INFO:root:Train (Epoch 169): Loss/seq after 02050 batchs: 427.3488464355469
INFO:root:Train (Epoch 169): Loss/seq after 02100 batchs: 426.0160827636719
INFO:root:Train (Epoch 169): Loss/seq after 02150 batchs: 424.7294616699219
INFO:root:Train (Epoch 169): Loss/seq after 02200 batchs: 423.1699523925781
INFO:root:Train (Epoch 169): Loss/seq after 02250 batchs: 421.8514404296875
INFO:root:Train (Epoch 169): Loss/seq after 02300 batchs: 418.83538818359375
INFO:root:Train (Epoch 169): Loss/seq after 02350 batchs: 416.1648864746094
INFO:root:Train (Epoch 169): Loss/seq after 02400 batchs: 416.771484375
INFO:root:Train (Epoch 169): Loss/seq after 02450 batchs: 413.6040954589844
INFO:root:Train (Epoch 169): Loss/seq after 02500 batchs: 407.6789245605469
INFO:root:Train (Epoch 169): Loss/seq after 02550 batchs: 402.2489318847656
INFO:root:Train (Epoch 169): Loss/seq after 02600 batchs: 400.78424072265625
INFO:root:Train (Epoch 169): Loss/seq after 02650 batchs: 397.0626220703125
INFO:root:Train (Epoch 169): Loss/seq after 02700 batchs: 394.71661376953125
INFO:root:Train (Epoch 169): Loss/seq after 02750 batchs: 391.489013671875
INFO:root:Train (Epoch 169): Loss/seq after 02800 batchs: 389.9831848144531
INFO:root:Train (Epoch 169): Loss/seq after 02850 batchs: 389.8231506347656
INFO:root:Train (Epoch 169): Loss/seq after 02900 batchs: 391.3036804199219
INFO:root:Train (Epoch 169): Loss/seq after 02950 batchs: 391.56072998046875
INFO:root:Train (Epoch 169): Loss/seq after 03000 batchs: 397.0798645019531
INFO:root:Train (Epoch 169): Loss/seq after 03050 batchs: 399.3454284667969
INFO:root:Train (Epoch 169): Loss/seq after 03100 batchs: 400.9870910644531
INFO:root:Train (Epoch 169): Loss/seq after 03150 batchs: 401.0629577636719
INFO:root:Train (Epoch 169): Loss/seq after 03200 batchs: 401.10882568359375
INFO:root:Train (Epoch 169): Loss/seq after 03250 batchs: 402.74267578125
INFO:root:Train (Epoch 169): Loss/seq after 03300 batchs: 402.5315856933594
INFO:root:Train (Epoch 169): Loss/seq after 03350 batchs: 401.48834228515625
INFO:root:Train (Epoch 169): Loss/seq after 03400 batchs: 398.61676025390625
INFO:root:Train (Epoch 169): Loss/seq after 03450 batchs: 397.73614501953125
INFO:root:Train (Epoch 169): Loss/seq after 03500 batchs: 398.8276672363281
INFO:root:Train (Epoch 169): Loss/seq after 03550 batchs: 396.8928527832031
INFO:root:Train (Epoch 169): Loss/seq after 03600 batchs: 403.463134765625
INFO:root:Train (Epoch 169): Loss/seq after 03650 batchs: 401.9906921386719
INFO:root:Train (Epoch 169): Loss/seq after 03700 batchs: 404.2650451660156
INFO:root:Train (Epoch 169): Loss/seq after 03750 batchs: 408.43707275390625
INFO:root:Train (Epoch 169): Loss/seq after 03800 batchs: 407.4547424316406
INFO:root:Train (Epoch 169): Loss/seq after 03850 batchs: 406.584228515625
INFO:root:Train (Epoch 169): Loss/seq after 03900 batchs: 408.8843994140625
INFO:root:Train (Epoch 169): Loss/seq after 03950 batchs: 411.5451354980469
INFO:root:Train (Epoch 169): Loss/seq after 04000 batchs: 408.9489440917969
INFO:root:Train (Epoch 169): Loss/seq after 04050 batchs: 406.4717712402344
INFO:root:Train (Epoch 169): Loss/seq after 04100 batchs: 405.6607971191406
INFO:root:Train (Epoch 169): Loss/seq after 04150 batchs: 405.7944641113281
INFO:root:Train (Epoch 169): Loss/seq after 04200 batchs: 404.83929443359375
INFO:root:Train (Epoch 169): Loss/seq after 04250 batchs: 403.49395751953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 169): Loss/seq after 00000 batches: 337.07757568359375
INFO:root:# Valid (Epoch 169): Loss/seq after 00050 batches: 528.5774536132812
INFO:root:# Valid (Epoch 169): Loss/seq after 00100 batches: 534.7235717773438
INFO:root:# Valid (Epoch 169): Loss/seq after 00150 batches: 410.46270751953125
INFO:root:# Valid (Epoch 169): Loss/seq after 00200 batches: 392.4226379394531
INFO:root:Artifacts: Make stick videos for epoch 169
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_169_on_20220413_094128.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_169_index_245_on_20220413_094128.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 170): Loss/seq after 00000 batchs: 679.7402954101562
INFO:root:Train (Epoch 170): Loss/seq after 00050 batchs: 571.4969482421875
INFO:root:Train (Epoch 170): Loss/seq after 00100 batchs: 543.7374877929688
INFO:root:Train (Epoch 170): Loss/seq after 00150 batchs: 507.8480529785156
INFO:root:Train (Epoch 170): Loss/seq after 00200 batchs: 554.3577880859375
INFO:root:Train (Epoch 170): Loss/seq after 00250 batchs: 612.7703247070312
INFO:root:Train (Epoch 170): Loss/seq after 00300 batchs: 624.5025024414062
INFO:root:Train (Epoch 170): Loss/seq after 00350 batchs: 588.5961303710938
INFO:root:Train (Epoch 170): Loss/seq after 00400 batchs: 573.9549560546875
INFO:root:Train (Epoch 170): Loss/seq after 00450 batchs: 578.4658203125
INFO:root:Train (Epoch 170): Loss/seq after 00500 batchs: 560.1715087890625
INFO:root:Train (Epoch 170): Loss/seq after 00550 batchs: 547.7944946289062
INFO:root:Train (Epoch 170): Loss/seq after 00600 batchs: 530.55419921875
INFO:root:Train (Epoch 170): Loss/seq after 00650 batchs: 510.5959167480469
INFO:root:Train (Epoch 170): Loss/seq after 00700 batchs: 489.33453369140625
INFO:root:Train (Epoch 170): Loss/seq after 00750 batchs: 487.098388671875
INFO:root:Train (Epoch 170): Loss/seq after 00800 batchs: 492.0819091796875
INFO:root:Train (Epoch 170): Loss/seq after 00850 batchs: 477.14508056640625
INFO:root:Train (Epoch 170): Loss/seq after 00900 batchs: 467.6890563964844
INFO:root:Train (Epoch 170): Loss/seq after 00950 batchs: 465.3165588378906
INFO:root:Train (Epoch 170): Loss/seq after 01000 batchs: 457.6518249511719
INFO:root:Train (Epoch 170): Loss/seq after 01050 batchs: 449.7218017578125
INFO:root:Train (Epoch 170): Loss/seq after 01100 batchs: 441.7378845214844
INFO:root:Train (Epoch 170): Loss/seq after 01150 batchs: 430.3507385253906
INFO:root:Train (Epoch 170): Loss/seq after 01200 batchs: 433.9217834472656
INFO:root:Train (Epoch 170): Loss/seq after 01250 batchs: 434.5687561035156
INFO:root:Train (Epoch 170): Loss/seq after 01300 batchs: 425.71405029296875
INFO:root:Train (Epoch 170): Loss/seq after 01350 batchs: 419.09033203125
INFO:root:Train (Epoch 170): Loss/seq after 01400 batchs: 421.25738525390625
INFO:root:Train (Epoch 170): Loss/seq after 01450 batchs: 424.08282470703125
INFO:root:Train (Epoch 170): Loss/seq after 01500 batchs: 431.6592102050781
INFO:root:Train (Epoch 170): Loss/seq after 01550 batchs: 432.32916259765625
INFO:root:Train (Epoch 170): Loss/seq after 01600 batchs: 428.7059020996094
INFO:root:Train (Epoch 170): Loss/seq after 01650 batchs: 427.2767333984375
INFO:root:Train (Epoch 170): Loss/seq after 01700 batchs: 431.7005615234375
INFO:root:Train (Epoch 170): Loss/seq after 01750 batchs: 430.1542053222656
INFO:root:Train (Epoch 170): Loss/seq after 01800 batchs: 428.2869567871094
INFO:root:Train (Epoch 170): Loss/seq after 01850 batchs: 426.2166442871094
INFO:root:Train (Epoch 170): Loss/seq after 01900 batchs: 425.6884765625
INFO:root:Train (Epoch 170): Loss/seq after 01950 batchs: 424.6885070800781
INFO:root:Train (Epoch 170): Loss/seq after 02000 batchs: 425.40594482421875
INFO:root:Train (Epoch 170): Loss/seq after 02050 batchs: 425.50286865234375
INFO:root:Train (Epoch 170): Loss/seq after 02100 batchs: 424.2195129394531
INFO:root:Train (Epoch 170): Loss/seq after 02150 batchs: 422.94329833984375
INFO:root:Train (Epoch 170): Loss/seq after 02200 batchs: 421.4142150878906
INFO:root:Train (Epoch 170): Loss/seq after 02250 batchs: 420.38092041015625
INFO:root:Train (Epoch 170): Loss/seq after 02300 batchs: 417.2787170410156
INFO:root:Train (Epoch 170): Loss/seq after 02350 batchs: 414.62255859375
INFO:root:Train (Epoch 170): Loss/seq after 02400 batchs: 415.2974853515625
INFO:root:Train (Epoch 170): Loss/seq after 02450 batchs: 412.1495666503906
INFO:root:Train (Epoch 170): Loss/seq after 02500 batchs: 406.2056884765625
INFO:root:Train (Epoch 170): Loss/seq after 02550 batchs: 400.7941589355469
INFO:root:Train (Epoch 170): Loss/seq after 02600 batchs: 399.1634521484375
INFO:root:Train (Epoch 170): Loss/seq after 02650 batchs: 395.50445556640625
INFO:root:Train (Epoch 170): Loss/seq after 02700 batchs: 393.1778564453125
INFO:root:Train (Epoch 170): Loss/seq after 02750 batchs: 389.8082275390625
INFO:root:Train (Epoch 170): Loss/seq after 02800 batchs: 388.01806640625
INFO:root:Train (Epoch 170): Loss/seq after 02850 batchs: 387.8551025390625
INFO:root:Train (Epoch 170): Loss/seq after 02900 batchs: 389.2133483886719
INFO:root:Train (Epoch 170): Loss/seq after 02950 batchs: 389.460693359375
INFO:root:Train (Epoch 170): Loss/seq after 03000 batchs: 394.9792175292969
INFO:root:Train (Epoch 170): Loss/seq after 03050 batchs: 397.2713623046875
INFO:root:Train (Epoch 170): Loss/seq after 03100 batchs: 399.0338439941406
INFO:root:Train (Epoch 170): Loss/seq after 03150 batchs: 399.3507385253906
INFO:root:Train (Epoch 170): Loss/seq after 03200 batchs: 399.3116760253906
INFO:root:Train (Epoch 170): Loss/seq after 03250 batchs: 400.2873229980469
INFO:root:Train (Epoch 170): Loss/seq after 03300 batchs: 400.05596923828125
INFO:root:Train (Epoch 170): Loss/seq after 03350 batchs: 398.9372863769531
INFO:root:Train (Epoch 170): Loss/seq after 03400 batchs: 396.0412902832031
INFO:root:Train (Epoch 170): Loss/seq after 03450 batchs: 395.1566467285156
INFO:root:Train (Epoch 170): Loss/seq after 03500 batchs: 396.1745910644531
INFO:root:Train (Epoch 170): Loss/seq after 03550 batchs: 394.11602783203125
INFO:root:Train (Epoch 170): Loss/seq after 03600 batchs: 400.6609802246094
INFO:root:Train (Epoch 170): Loss/seq after 03650 batchs: 399.265869140625
INFO:root:Train (Epoch 170): Loss/seq after 03700 batchs: 401.5360412597656
INFO:root:Train (Epoch 170): Loss/seq after 03750 batchs: 405.6993408203125
INFO:root:Train (Epoch 170): Loss/seq after 03800 batchs: 404.7566223144531
INFO:root:Train (Epoch 170): Loss/seq after 03850 batchs: 403.89752197265625
INFO:root:Train (Epoch 170): Loss/seq after 03900 batchs: 406.0200500488281
INFO:root:Train (Epoch 170): Loss/seq after 03950 batchs: 408.47198486328125
INFO:root:Train (Epoch 170): Loss/seq after 04000 batchs: 405.9007873535156
INFO:root:Train (Epoch 170): Loss/seq after 04050 batchs: 403.4747619628906
INFO:root:Train (Epoch 170): Loss/seq after 04100 batchs: 402.7102966308594
INFO:root:Train (Epoch 170): Loss/seq after 04150 batchs: 402.8485107421875
INFO:root:Train (Epoch 170): Loss/seq after 04200 batchs: 401.9129333496094
INFO:root:Train (Epoch 170): Loss/seq after 04250 batchs: 400.61029052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 170): Loss/seq after 00000 batches: 362.8666076660156
INFO:root:# Valid (Epoch 170): Loss/seq after 00050 batches: 517.5608520507812
INFO:root:# Valid (Epoch 170): Loss/seq after 00100 batches: 519.416015625
INFO:root:# Valid (Epoch 170): Loss/seq after 00150 batches: 397.9119873046875
INFO:root:# Valid (Epoch 170): Loss/seq after 00200 batches: 376.10614013671875
INFO:root:Artifacts: Make stick videos for epoch 170
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_170_on_20220413_094650.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_170_index_1356_on_20220413_094650.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 171): Loss/seq after 00000 batchs: 726.7879028320312
INFO:root:Train (Epoch 171): Loss/seq after 00050 batchs: 551.16357421875
INFO:root:Train (Epoch 171): Loss/seq after 00100 batchs: 525.8079833984375
INFO:root:Train (Epoch 171): Loss/seq after 00150 batchs: 492.7021484375
INFO:root:Train (Epoch 171): Loss/seq after 00200 batchs: 547.2914428710938
INFO:root:Train (Epoch 171): Loss/seq after 00250 batchs: 609.9178466796875
INFO:root:Train (Epoch 171): Loss/seq after 00300 batchs: 620.7572021484375
INFO:root:Train (Epoch 171): Loss/seq after 00350 batchs: 585.392333984375
INFO:root:Train (Epoch 171): Loss/seq after 00400 batchs: 570.7929077148438
INFO:root:Train (Epoch 171): Loss/seq after 00450 batchs: 575.3662109375
INFO:root:Train (Epoch 171): Loss/seq after 00500 batchs: 556.966796875
INFO:root:Train (Epoch 171): Loss/seq after 00550 batchs: 544.779296875
INFO:root:Train (Epoch 171): Loss/seq after 00600 batchs: 527.8246459960938
INFO:root:Train (Epoch 171): Loss/seq after 00650 batchs: 507.3018493652344
INFO:root:Train (Epoch 171): Loss/seq after 00700 batchs: 486.5870666503906
INFO:root:Train (Epoch 171): Loss/seq after 00750 batchs: 484.2062072753906
INFO:root:Train (Epoch 171): Loss/seq after 00800 batchs: 490.01513671875
INFO:root:Train (Epoch 171): Loss/seq after 00850 batchs: 475.2448425292969
INFO:root:Train (Epoch 171): Loss/seq after 00900 batchs: 465.0511474609375
INFO:root:Train (Epoch 171): Loss/seq after 00950 batchs: 462.1346740722656
INFO:root:Train (Epoch 171): Loss/seq after 01000 batchs: 454.254150390625
INFO:root:Train (Epoch 171): Loss/seq after 01050 batchs: 446.7060546875
INFO:root:Train (Epoch 171): Loss/seq after 01100 batchs: 438.55780029296875
INFO:root:Train (Epoch 171): Loss/seq after 01150 batchs: 427.2884216308594
INFO:root:Train (Epoch 171): Loss/seq after 01200 batchs: 431.1811218261719
INFO:root:Train (Epoch 171): Loss/seq after 01250 batchs: 431.9455871582031
INFO:root:Train (Epoch 171): Loss/seq after 01300 batchs: 422.97149658203125
INFO:root:Train (Epoch 171): Loss/seq after 01350 batchs: 416.1524963378906
INFO:root:Train (Epoch 171): Loss/seq after 01400 batchs: 418.2752380371094
INFO:root:Train (Epoch 171): Loss/seq after 01450 batchs: 421.3128356933594
INFO:root:Train (Epoch 171): Loss/seq after 01500 batchs: 429.17144775390625
INFO:root:Train (Epoch 171): Loss/seq after 01550 batchs: 429.4598388671875
INFO:root:Train (Epoch 171): Loss/seq after 01600 batchs: 425.80462646484375
INFO:root:Train (Epoch 171): Loss/seq after 01650 batchs: 424.1020812988281
INFO:root:Train (Epoch 171): Loss/seq after 01700 batchs: 428.4631652832031
INFO:root:Train (Epoch 171): Loss/seq after 01750 batchs: 426.88623046875
INFO:root:Train (Epoch 171): Loss/seq after 01800 batchs: 425.3732604980469
INFO:root:Train (Epoch 171): Loss/seq after 01850 batchs: 423.3533630371094
INFO:root:Train (Epoch 171): Loss/seq after 01900 batchs: 422.910400390625
INFO:root:Train (Epoch 171): Loss/seq after 01950 batchs: 422.2461853027344
INFO:root:Train (Epoch 171): Loss/seq after 02000 batchs: 423.0575256347656
INFO:root:Train (Epoch 171): Loss/seq after 02050 batchs: 423.121337890625
INFO:root:Train (Epoch 171): Loss/seq after 02100 batchs: 421.885498046875
INFO:root:Train (Epoch 171): Loss/seq after 02150 batchs: 420.6919250488281
INFO:root:Train (Epoch 171): Loss/seq after 02200 batchs: 419.16387939453125
INFO:root:Train (Epoch 171): Loss/seq after 02250 batchs: 418.0094909667969
INFO:root:Train (Epoch 171): Loss/seq after 02300 batchs: 414.8291931152344
INFO:root:Train (Epoch 171): Loss/seq after 02350 batchs: 412.2386169433594
INFO:root:Train (Epoch 171): Loss/seq after 02400 batchs: 412.8603210449219
INFO:root:Train (Epoch 171): Loss/seq after 02450 batchs: 409.7795104980469
INFO:root:Train (Epoch 171): Loss/seq after 02500 batchs: 403.84759521484375
INFO:root:Train (Epoch 171): Loss/seq after 02550 batchs: 398.43212890625
INFO:root:Train (Epoch 171): Loss/seq after 02600 batchs: 396.8569030761719
INFO:root:Train (Epoch 171): Loss/seq after 02650 batchs: 393.22784423828125
INFO:root:Train (Epoch 171): Loss/seq after 02700 batchs: 391.04547119140625
INFO:root:Train (Epoch 171): Loss/seq after 02750 batchs: 387.7228088378906
INFO:root:Train (Epoch 171): Loss/seq after 02800 batchs: 386.1219177246094
INFO:root:Train (Epoch 171): Loss/seq after 02850 batchs: 386.0245666503906
INFO:root:Train (Epoch 171): Loss/seq after 02900 batchs: 387.36376953125
INFO:root:Train (Epoch 171): Loss/seq after 02950 batchs: 387.657958984375
INFO:root:Train (Epoch 171): Loss/seq after 03000 batchs: 393.1282958984375
INFO:root:Train (Epoch 171): Loss/seq after 03050 batchs: 395.3397521972656
INFO:root:Train (Epoch 171): Loss/seq after 03100 batchs: 397.41412353515625
INFO:root:Train (Epoch 171): Loss/seq after 03150 batchs: 397.51336669921875
INFO:root:Train (Epoch 171): Loss/seq after 03200 batchs: 397.6391296386719
INFO:root:Train (Epoch 171): Loss/seq after 03250 batchs: 398.766845703125
INFO:root:Train (Epoch 171): Loss/seq after 03300 batchs: 398.4598693847656
INFO:root:Train (Epoch 171): Loss/seq after 03350 batchs: 397.3885498046875
INFO:root:Train (Epoch 171): Loss/seq after 03400 batchs: 394.5825500488281
INFO:root:Train (Epoch 171): Loss/seq after 03450 batchs: 393.736572265625
INFO:root:Train (Epoch 171): Loss/seq after 03500 batchs: 394.7876892089844
INFO:root:Train (Epoch 171): Loss/seq after 03550 batchs: 392.7712707519531
INFO:root:Train (Epoch 171): Loss/seq after 03600 batchs: 399.4951171875
INFO:root:Train (Epoch 171): Loss/seq after 03650 batchs: 398.1262512207031
INFO:root:Train (Epoch 171): Loss/seq after 03700 batchs: 400.4468078613281
INFO:root:Train (Epoch 171): Loss/seq after 03750 batchs: 404.6667785644531
INFO:root:Train (Epoch 171): Loss/seq after 03800 batchs: 403.7498474121094
INFO:root:Train (Epoch 171): Loss/seq after 03850 batchs: 402.8767395019531
INFO:root:Train (Epoch 171): Loss/seq after 03900 batchs: 404.911376953125
INFO:root:Train (Epoch 171): Loss/seq after 03950 batchs: 407.4626159667969
INFO:root:Train (Epoch 171): Loss/seq after 04000 batchs: 404.89984130859375
INFO:root:Train (Epoch 171): Loss/seq after 04050 batchs: 402.4417419433594
INFO:root:Train (Epoch 171): Loss/seq after 04100 batchs: 401.6378173828125
INFO:root:Train (Epoch 171): Loss/seq after 04150 batchs: 401.7031555175781
INFO:root:Train (Epoch 171): Loss/seq after 04200 batchs: 400.7277526855469
INFO:root:Train (Epoch 171): Loss/seq after 04250 batchs: 399.42547607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 171): Loss/seq after 00000 batches: 349.3772277832031
INFO:root:# Valid (Epoch 171): Loss/seq after 00050 batches: 500.62554931640625
INFO:root:# Valid (Epoch 171): Loss/seq after 00100 batches: 496.6583557128906
INFO:root:# Valid (Epoch 171): Loss/seq after 00150 batches: 381.68829345703125
INFO:root:# Valid (Epoch 171): Loss/seq after 00200 batches: 362.32080078125
INFO:root:Artifacts: Make stick videos for epoch 171
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_171_on_20220413_095212.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_171_index_323_on_20220413_095212.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 172): Loss/seq after 00000 batchs: 700.2391357421875
INFO:root:Train (Epoch 172): Loss/seq after 00050 batchs: 559.5516967773438
INFO:root:Train (Epoch 172): Loss/seq after 00100 batchs: 526.6052856445312
INFO:root:Train (Epoch 172): Loss/seq after 00150 batchs: 489.3863220214844
INFO:root:Train (Epoch 172): Loss/seq after 00200 batchs: 541.5199584960938
INFO:root:Train (Epoch 172): Loss/seq after 00250 batchs: 603.0615844726562
INFO:root:Train (Epoch 172): Loss/seq after 00300 batchs: 615.727294921875
INFO:root:Train (Epoch 172): Loss/seq after 00350 batchs: 580.3925170898438
INFO:root:Train (Epoch 172): Loss/seq after 00400 batchs: 564.0816650390625
INFO:root:Train (Epoch 172): Loss/seq after 00450 batchs: 569.6026611328125
INFO:root:Train (Epoch 172): Loss/seq after 00500 batchs: 550.6951904296875
INFO:root:Train (Epoch 172): Loss/seq after 00550 batchs: 538.5233154296875
INFO:root:Train (Epoch 172): Loss/seq after 00600 batchs: 521.4193725585938
INFO:root:Train (Epoch 172): Loss/seq after 00650 batchs: 502.7334289550781
INFO:root:Train (Epoch 172): Loss/seq after 00700 batchs: 482.93609619140625
INFO:root:Train (Epoch 172): Loss/seq after 00750 batchs: 482.0043640136719
INFO:root:Train (Epoch 172): Loss/seq after 00800 batchs: 486.7442932128906
INFO:root:Train (Epoch 172): Loss/seq after 00850 batchs: 472.0302429199219
INFO:root:Train (Epoch 172): Loss/seq after 00900 batchs: 461.7318420410156
INFO:root:Train (Epoch 172): Loss/seq after 00950 batchs: 459.96197509765625
INFO:root:Train (Epoch 172): Loss/seq after 01000 batchs: 452.5475769042969
INFO:root:Train (Epoch 172): Loss/seq after 01050 batchs: 445.0392761230469
INFO:root:Train (Epoch 172): Loss/seq after 01100 batchs: 436.7086181640625
INFO:root:Train (Epoch 172): Loss/seq after 01150 batchs: 425.2044372558594
INFO:root:Train (Epoch 172): Loss/seq after 01200 batchs: 429.4697265625
INFO:root:Train (Epoch 172): Loss/seq after 01250 batchs: 430.1887512207031
INFO:root:Train (Epoch 172): Loss/seq after 01300 batchs: 421.6249084472656
INFO:root:Train (Epoch 172): Loss/seq after 01350 batchs: 414.91522216796875
INFO:root:Train (Epoch 172): Loss/seq after 01400 batchs: 416.81060791015625
INFO:root:Train (Epoch 172): Loss/seq after 01450 batchs: 420.0012512207031
INFO:root:Train (Epoch 172): Loss/seq after 01500 batchs: 427.4958801269531
INFO:root:Train (Epoch 172): Loss/seq after 01550 batchs: 427.7026062011719
INFO:root:Train (Epoch 172): Loss/seq after 01600 batchs: 424.38763427734375
INFO:root:Train (Epoch 172): Loss/seq after 01650 batchs: 422.98260498046875
INFO:root:Train (Epoch 172): Loss/seq after 01700 batchs: 427.3477478027344
INFO:root:Train (Epoch 172): Loss/seq after 01750 batchs: 425.8040466308594
INFO:root:Train (Epoch 172): Loss/seq after 01800 batchs: 424.0089416503906
INFO:root:Train (Epoch 172): Loss/seq after 01850 batchs: 421.9306335449219
INFO:root:Train (Epoch 172): Loss/seq after 01900 batchs: 421.5579528808594
INFO:root:Train (Epoch 172): Loss/seq after 01950 batchs: 420.81634521484375
INFO:root:Train (Epoch 172): Loss/seq after 02000 batchs: 421.5682678222656
INFO:root:Train (Epoch 172): Loss/seq after 02050 batchs: 421.609130859375
INFO:root:Train (Epoch 172): Loss/seq after 02100 batchs: 420.3712158203125
INFO:root:Train (Epoch 172): Loss/seq after 02150 batchs: 419.1609191894531
INFO:root:Train (Epoch 172): Loss/seq after 02200 batchs: 417.65625
INFO:root:Train (Epoch 172): Loss/seq after 02250 batchs: 416.42095947265625
INFO:root:Train (Epoch 172): Loss/seq after 02300 batchs: 413.4461975097656
INFO:root:Train (Epoch 172): Loss/seq after 02350 batchs: 410.87506103515625
INFO:root:Train (Epoch 172): Loss/seq after 02400 batchs: 411.5176086425781
INFO:root:Train (Epoch 172): Loss/seq after 02450 batchs: 408.46246337890625
INFO:root:Train (Epoch 172): Loss/seq after 02500 batchs: 402.600341796875
INFO:root:Train (Epoch 172): Loss/seq after 02550 batchs: 397.20916748046875
INFO:root:Train (Epoch 172): Loss/seq after 02600 batchs: 395.6065368652344
INFO:root:Train (Epoch 172): Loss/seq after 02650 batchs: 391.9564514160156
INFO:root:Train (Epoch 172): Loss/seq after 02700 batchs: 389.5305480957031
INFO:root:Train (Epoch 172): Loss/seq after 02750 batchs: 386.3828430175781
INFO:root:Train (Epoch 172): Loss/seq after 02800 batchs: 384.4264831542969
INFO:root:Train (Epoch 172): Loss/seq after 02850 batchs: 384.2347106933594
INFO:root:Train (Epoch 172): Loss/seq after 02900 batchs: 385.6461486816406
INFO:root:Train (Epoch 172): Loss/seq after 02950 batchs: 385.9137878417969
INFO:root:Train (Epoch 172): Loss/seq after 03000 batchs: 391.5392150878906
INFO:root:Train (Epoch 172): Loss/seq after 03050 batchs: 393.7928771972656
INFO:root:Train (Epoch 172): Loss/seq after 03100 batchs: 395.66986083984375
INFO:root:Train (Epoch 172): Loss/seq after 03150 batchs: 395.75238037109375
INFO:root:Train (Epoch 172): Loss/seq after 03200 batchs: 395.56646728515625
INFO:root:Train (Epoch 172): Loss/seq after 03250 batchs: 397.13018798828125
INFO:root:Train (Epoch 172): Loss/seq after 03300 batchs: 396.8260498046875
INFO:root:Train (Epoch 172): Loss/seq after 03350 batchs: 395.6108703613281
INFO:root:Train (Epoch 172): Loss/seq after 03400 batchs: 392.7400817871094
INFO:root:Train (Epoch 172): Loss/seq after 03450 batchs: 391.86248779296875
INFO:root:Train (Epoch 172): Loss/seq after 03500 batchs: 392.8638610839844
INFO:root:Train (Epoch 172): Loss/seq after 03550 batchs: 390.9659729003906
INFO:root:Train (Epoch 172): Loss/seq after 03600 batchs: 397.6775207519531
INFO:root:Train (Epoch 172): Loss/seq after 03650 batchs: 396.2509460449219
INFO:root:Train (Epoch 172): Loss/seq after 03700 batchs: 398.740234375
INFO:root:Train (Epoch 172): Loss/seq after 03750 batchs: 403.0003967285156
INFO:root:Train (Epoch 172): Loss/seq after 03800 batchs: 402.1076965332031
INFO:root:Train (Epoch 172): Loss/seq after 03850 batchs: 401.3223571777344
INFO:root:Train (Epoch 172): Loss/seq after 03900 batchs: 403.5106506347656
INFO:root:Train (Epoch 172): Loss/seq after 03950 batchs: 406.1614990234375
INFO:root:Train (Epoch 172): Loss/seq after 04000 batchs: 403.5896301269531
INFO:root:Train (Epoch 172): Loss/seq after 04050 batchs: 401.15728759765625
INFO:root:Train (Epoch 172): Loss/seq after 04100 batchs: 400.354248046875
INFO:root:Train (Epoch 172): Loss/seq after 04150 batchs: 400.4743957519531
INFO:root:Train (Epoch 172): Loss/seq after 04200 batchs: 399.551513671875
INFO:root:Train (Epoch 172): Loss/seq after 04250 batchs: 398.2046203613281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 172): Loss/seq after 00000 batches: 350.0117492675781
INFO:root:# Valid (Epoch 172): Loss/seq after 00050 batches: 509.6863708496094
INFO:root:# Valid (Epoch 172): Loss/seq after 00100 batches: 516.2985229492188
INFO:root:# Valid (Epoch 172): Loss/seq after 00150 batches: 397.7821350097656
INFO:root:# Valid (Epoch 172): Loss/seq after 00200 batches: 378.1926574707031
INFO:root:Artifacts: Make stick videos for epoch 172
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_172_on_20220413_095738.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_172_index_1469_on_20220413_095738.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 173): Loss/seq after 00000 batchs: 692.4044799804688
INFO:root:Train (Epoch 173): Loss/seq after 00050 batchs: 549.2970581054688
INFO:root:Train (Epoch 173): Loss/seq after 00100 batchs: 528.9279174804688
INFO:root:Train (Epoch 173): Loss/seq after 00150 batchs: 493.6611633300781
INFO:root:Train (Epoch 173): Loss/seq after 00200 batchs: 539.6622924804688
INFO:root:Train (Epoch 173): Loss/seq after 00250 batchs: 615.6846313476562
INFO:root:Train (Epoch 173): Loss/seq after 00300 batchs: 627.4252319335938
INFO:root:Train (Epoch 173): Loss/seq after 00350 batchs: 590.7230834960938
INFO:root:Train (Epoch 173): Loss/seq after 00400 batchs: 574.4414672851562
INFO:root:Train (Epoch 173): Loss/seq after 00450 batchs: 578.6141357421875
INFO:root:Train (Epoch 173): Loss/seq after 00500 batchs: 561.3286743164062
INFO:root:Train (Epoch 173): Loss/seq after 00550 batchs: 548.6600341796875
INFO:root:Train (Epoch 173): Loss/seq after 00600 batchs: 530.4256591796875
INFO:root:Train (Epoch 173): Loss/seq after 00650 batchs: 511.07177734375
INFO:root:Train (Epoch 173): Loss/seq after 00700 batchs: 491.0384826660156
INFO:root:Train (Epoch 173): Loss/seq after 00750 batchs: 487.2290954589844
INFO:root:Train (Epoch 173): Loss/seq after 00800 batchs: 492.0574645996094
INFO:root:Train (Epoch 173): Loss/seq after 00850 batchs: 476.85589599609375
INFO:root:Train (Epoch 173): Loss/seq after 00900 batchs: 466.9588317871094
INFO:root:Train (Epoch 173): Loss/seq after 00950 batchs: 464.6869201660156
INFO:root:Train (Epoch 173): Loss/seq after 01000 batchs: 456.8532409667969
INFO:root:Train (Epoch 173): Loss/seq after 01050 batchs: 449.1522521972656
INFO:root:Train (Epoch 173): Loss/seq after 01100 batchs: 441.4588623046875
INFO:root:Train (Epoch 173): Loss/seq after 01150 batchs: 429.99169921875
INFO:root:Train (Epoch 173): Loss/seq after 01200 batchs: 433.376953125
INFO:root:Train (Epoch 173): Loss/seq after 01250 batchs: 433.9736328125
INFO:root:Train (Epoch 173): Loss/seq after 01300 batchs: 425.0793151855469
INFO:root:Train (Epoch 173): Loss/seq after 01350 batchs: 418.1761474609375
INFO:root:Train (Epoch 173): Loss/seq after 01400 batchs: 419.8488464355469
INFO:root:Train (Epoch 173): Loss/seq after 01450 batchs: 422.9924621582031
INFO:root:Train (Epoch 173): Loss/seq after 01500 batchs: 430.6014099121094
INFO:root:Train (Epoch 173): Loss/seq after 01550 batchs: 431.1553955078125
INFO:root:Train (Epoch 173): Loss/seq after 01600 batchs: 427.42041015625
INFO:root:Train (Epoch 173): Loss/seq after 01650 batchs: 425.77606201171875
INFO:root:Train (Epoch 173): Loss/seq after 01700 batchs: 430.15509033203125
INFO:root:Train (Epoch 173): Loss/seq after 01750 batchs: 428.5362548828125
INFO:root:Train (Epoch 173): Loss/seq after 01800 batchs: 426.6220397949219
INFO:root:Train (Epoch 173): Loss/seq after 01850 batchs: 424.5345764160156
INFO:root:Train (Epoch 173): Loss/seq after 01900 batchs: 423.9792175292969
INFO:root:Train (Epoch 173): Loss/seq after 01950 batchs: 423.17767333984375
INFO:root:Train (Epoch 173): Loss/seq after 02000 batchs: 423.9356384277344
INFO:root:Train (Epoch 173): Loss/seq after 02050 batchs: 424.04241943359375
INFO:root:Train (Epoch 173): Loss/seq after 02100 batchs: 422.59527587890625
INFO:root:Train (Epoch 173): Loss/seq after 02150 batchs: 421.3236389160156
INFO:root:Train (Epoch 173): Loss/seq after 02200 batchs: 419.6672668457031
INFO:root:Train (Epoch 173): Loss/seq after 02250 batchs: 418.20159912109375
INFO:root:Train (Epoch 173): Loss/seq after 02300 batchs: 415.03912353515625
INFO:root:Train (Epoch 173): Loss/seq after 02350 batchs: 412.3524169921875
INFO:root:Train (Epoch 173): Loss/seq after 02400 batchs: 412.96026611328125
INFO:root:Train (Epoch 173): Loss/seq after 02450 batchs: 409.8559875488281
INFO:root:Train (Epoch 173): Loss/seq after 02500 batchs: 403.89764404296875
INFO:root:Train (Epoch 173): Loss/seq after 02550 batchs: 398.4333190917969
INFO:root:Train (Epoch 173): Loss/seq after 02600 batchs: 396.6617736816406
INFO:root:Train (Epoch 173): Loss/seq after 02650 batchs: 392.916015625
INFO:root:Train (Epoch 173): Loss/seq after 02700 batchs: 390.49163818359375
INFO:root:Train (Epoch 173): Loss/seq after 02750 batchs: 387.14178466796875
INFO:root:Train (Epoch 173): Loss/seq after 02800 batchs: 385.3077087402344
INFO:root:Train (Epoch 173): Loss/seq after 02850 batchs: 385.02862548828125
INFO:root:Train (Epoch 173): Loss/seq after 02900 batchs: 386.2359313964844
INFO:root:Train (Epoch 173): Loss/seq after 02950 batchs: 386.4551696777344
INFO:root:Train (Epoch 173): Loss/seq after 03000 batchs: 391.98236083984375
INFO:root:Train (Epoch 173): Loss/seq after 03050 batchs: 394.15533447265625
INFO:root:Train (Epoch 173): Loss/seq after 03100 batchs: 395.7532958984375
INFO:root:Train (Epoch 173): Loss/seq after 03150 batchs: 395.55340576171875
INFO:root:Train (Epoch 173): Loss/seq after 03200 batchs: 395.5537109375
INFO:root:Train (Epoch 173): Loss/seq after 03250 batchs: 396.6481018066406
INFO:root:Train (Epoch 173): Loss/seq after 03300 batchs: 395.9535827636719
INFO:root:Train (Epoch 173): Loss/seq after 03350 batchs: 394.9810791015625
INFO:root:Train (Epoch 173): Loss/seq after 03400 batchs: 392.1263122558594
INFO:root:Train (Epoch 173): Loss/seq after 03450 batchs: 391.1626892089844
INFO:root:Train (Epoch 173): Loss/seq after 03500 batchs: 391.99603271484375
INFO:root:Train (Epoch 173): Loss/seq after 03550 batchs: 389.90423583984375
INFO:root:Train (Epoch 173): Loss/seq after 03600 batchs: 396.4249267578125
INFO:root:Train (Epoch 173): Loss/seq after 03650 batchs: 395.0273742675781
INFO:root:Train (Epoch 173): Loss/seq after 03700 batchs: 397.2682189941406
INFO:root:Train (Epoch 173): Loss/seq after 03750 batchs: 401.40240478515625
INFO:root:Train (Epoch 173): Loss/seq after 03800 batchs: 400.5008239746094
INFO:root:Train (Epoch 173): Loss/seq after 03850 batchs: 399.60345458984375
INFO:root:Train (Epoch 173): Loss/seq after 03900 batchs: 401.7503662109375
INFO:root:Train (Epoch 173): Loss/seq after 03950 batchs: 404.37890625
INFO:root:Train (Epoch 173): Loss/seq after 04000 batchs: 401.8643798828125
INFO:root:Train (Epoch 173): Loss/seq after 04050 batchs: 399.4535827636719
INFO:root:Train (Epoch 173): Loss/seq after 04100 batchs: 398.65985107421875
INFO:root:Train (Epoch 173): Loss/seq after 04150 batchs: 398.760009765625
INFO:root:Train (Epoch 173): Loss/seq after 04200 batchs: 397.7732238769531
INFO:root:Train (Epoch 173): Loss/seq after 04250 batchs: 396.44482421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 173): Loss/seq after 00000 batches: 357.2662048339844
INFO:root:# Valid (Epoch 173): Loss/seq after 00050 batches: 516.6941528320312
INFO:root:# Valid (Epoch 173): Loss/seq after 00100 batches: 513.485107421875
INFO:root:# Valid (Epoch 173): Loss/seq after 00150 batches: 395.2010192871094
INFO:root:# Valid (Epoch 173): Loss/seq after 00200 batches: 376.67236328125
INFO:root:Artifacts: Make stick videos for epoch 173
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_173_on_20220413_100300.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_173_index_87_on_20220413_100300.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 174): Loss/seq after 00000 batchs: 725.6958618164062
INFO:root:Train (Epoch 174): Loss/seq after 00050 batchs: 549.9404907226562
INFO:root:Train (Epoch 174): Loss/seq after 00100 batchs: 525.362060546875
INFO:root:Train (Epoch 174): Loss/seq after 00150 batchs: 489.5338439941406
INFO:root:Train (Epoch 174): Loss/seq after 00200 batchs: 536.4912719726562
INFO:root:Train (Epoch 174): Loss/seq after 00250 batchs: 594.2064819335938
INFO:root:Train (Epoch 174): Loss/seq after 00300 batchs: 607.7759399414062
INFO:root:Train (Epoch 174): Loss/seq after 00350 batchs: 573.5441284179688
INFO:root:Train (Epoch 174): Loss/seq after 00400 batchs: 558.7584838867188
INFO:root:Train (Epoch 174): Loss/seq after 00450 batchs: 564.3697509765625
INFO:root:Train (Epoch 174): Loss/seq after 00500 batchs: 545.7427978515625
INFO:root:Train (Epoch 174): Loss/seq after 00550 batchs: 534.7626342773438
INFO:root:Train (Epoch 174): Loss/seq after 00600 batchs: 517.9695434570312
INFO:root:Train (Epoch 174): Loss/seq after 00650 batchs: 497.63934326171875
INFO:root:Train (Epoch 174): Loss/seq after 00700 batchs: 477.2929382324219
INFO:root:Train (Epoch 174): Loss/seq after 00750 batchs: 474.79248046875
INFO:root:Train (Epoch 174): Loss/seq after 00800 batchs: 479.4648742675781
INFO:root:Train (Epoch 174): Loss/seq after 00850 batchs: 465.0638122558594
INFO:root:Train (Epoch 174): Loss/seq after 00900 batchs: 455.51947021484375
INFO:root:Train (Epoch 174): Loss/seq after 00950 batchs: 452.90838623046875
INFO:root:Train (Epoch 174): Loss/seq after 01000 batchs: 445.5359191894531
INFO:root:Train (Epoch 174): Loss/seq after 01050 batchs: 438.04302978515625
INFO:root:Train (Epoch 174): Loss/seq after 01100 batchs: 430.07952880859375
INFO:root:Train (Epoch 174): Loss/seq after 01150 batchs: 418.93157958984375
INFO:root:Train (Epoch 174): Loss/seq after 01200 batchs: 422.6671447753906
INFO:root:Train (Epoch 174): Loss/seq after 01250 batchs: 423.7518615722656
INFO:root:Train (Epoch 174): Loss/seq after 01300 batchs: 415.21343994140625
INFO:root:Train (Epoch 174): Loss/seq after 01350 batchs: 408.5128479003906
INFO:root:Train (Epoch 174): Loss/seq after 01400 batchs: 410.1985168457031
INFO:root:Train (Epoch 174): Loss/seq after 01450 batchs: 413.1020812988281
INFO:root:Train (Epoch 174): Loss/seq after 01500 batchs: 420.72381591796875
INFO:root:Train (Epoch 174): Loss/seq after 01550 batchs: 420.98663330078125
INFO:root:Train (Epoch 174): Loss/seq after 01600 batchs: 417.6370544433594
INFO:root:Train (Epoch 174): Loss/seq after 01650 batchs: 416.1296691894531
INFO:root:Train (Epoch 174): Loss/seq after 01700 batchs: 420.5789794921875
INFO:root:Train (Epoch 174): Loss/seq after 01750 batchs: 419.26385498046875
INFO:root:Train (Epoch 174): Loss/seq after 01800 batchs: 417.71319580078125
INFO:root:Train (Epoch 174): Loss/seq after 01850 batchs: 415.814697265625
INFO:root:Train (Epoch 174): Loss/seq after 01900 batchs: 415.578857421875
INFO:root:Train (Epoch 174): Loss/seq after 01950 batchs: 415.06097412109375
INFO:root:Train (Epoch 174): Loss/seq after 02000 batchs: 416.0310363769531
INFO:root:Train (Epoch 174): Loss/seq after 02050 batchs: 416.3309326171875
INFO:root:Train (Epoch 174): Loss/seq after 02100 batchs: 415.11956787109375
INFO:root:Train (Epoch 174): Loss/seq after 02150 batchs: 413.9986267089844
INFO:root:Train (Epoch 174): Loss/seq after 02200 batchs: 412.63873291015625
INFO:root:Train (Epoch 174): Loss/seq after 02250 batchs: 411.485595703125
INFO:root:Train (Epoch 174): Loss/seq after 02300 batchs: 408.5154113769531
INFO:root:Train (Epoch 174): Loss/seq after 02350 batchs: 405.9590148925781
INFO:root:Train (Epoch 174): Loss/seq after 02400 batchs: 406.61181640625
INFO:root:Train (Epoch 174): Loss/seq after 02450 batchs: 403.5569763183594
INFO:root:Train (Epoch 174): Loss/seq after 02500 batchs: 397.6630554199219
INFO:root:Train (Epoch 174): Loss/seq after 02550 batchs: 392.28680419921875
INFO:root:Train (Epoch 174): Loss/seq after 02600 batchs: 390.6904602050781
INFO:root:Train (Epoch 174): Loss/seq after 02650 batchs: 387.0589904785156
INFO:root:Train (Epoch 174): Loss/seq after 02700 batchs: 384.68511962890625
INFO:root:Train (Epoch 174): Loss/seq after 02750 batchs: 381.42401123046875
INFO:root:Train (Epoch 174): Loss/seq after 02800 batchs: 379.5893859863281
INFO:root:Train (Epoch 174): Loss/seq after 02850 batchs: 379.3992004394531
INFO:root:Train (Epoch 174): Loss/seq after 02900 batchs: 380.7427062988281
INFO:root:Train (Epoch 174): Loss/seq after 02950 batchs: 381.1043395996094
INFO:root:Train (Epoch 174): Loss/seq after 03000 batchs: 386.69482421875
INFO:root:Train (Epoch 174): Loss/seq after 03050 batchs: 389.01251220703125
INFO:root:Train (Epoch 174): Loss/seq after 03100 batchs: 390.5545959472656
INFO:root:Train (Epoch 174): Loss/seq after 03150 batchs: 390.3318176269531
INFO:root:Train (Epoch 174): Loss/seq after 03200 batchs: 390.1783142089844
INFO:root:Train (Epoch 174): Loss/seq after 03250 batchs: 390.921875
INFO:root:Train (Epoch 174): Loss/seq after 03300 batchs: 390.5022888183594
INFO:root:Train (Epoch 174): Loss/seq after 03350 batchs: 389.42779541015625
INFO:root:Train (Epoch 174): Loss/seq after 03400 batchs: 386.625
INFO:root:Train (Epoch 174): Loss/seq after 03450 batchs: 385.7832946777344
INFO:root:Train (Epoch 174): Loss/seq after 03500 batchs: 386.7482604980469
INFO:root:Train (Epoch 174): Loss/seq after 03550 batchs: 384.8935546875
INFO:root:Train (Epoch 174): Loss/seq after 03600 batchs: 391.47113037109375
INFO:root:Train (Epoch 174): Loss/seq after 03650 batchs: 390.1183776855469
INFO:root:Train (Epoch 174): Loss/seq after 03700 batchs: 392.3363037109375
INFO:root:Train (Epoch 174): Loss/seq after 03750 batchs: 396.5997009277344
INFO:root:Train (Epoch 174): Loss/seq after 03800 batchs: 395.7155456542969
INFO:root:Train (Epoch 174): Loss/seq after 03850 batchs: 394.906982421875
INFO:root:Train (Epoch 174): Loss/seq after 03900 batchs: 396.93646240234375
INFO:root:Train (Epoch 174): Loss/seq after 03950 batchs: 399.29986572265625
INFO:root:Train (Epoch 174): Loss/seq after 04000 batchs: 396.8303527832031
INFO:root:Train (Epoch 174): Loss/seq after 04050 batchs: 394.4352111816406
INFO:root:Train (Epoch 174): Loss/seq after 04100 batchs: 393.7501525878906
INFO:root:Train (Epoch 174): Loss/seq after 04150 batchs: 393.87615966796875
INFO:root:Train (Epoch 174): Loss/seq after 04200 batchs: 393.0087890625
INFO:root:Train (Epoch 174): Loss/seq after 04250 batchs: 391.7281188964844
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 174): Loss/seq after 00000 batches: 349.8717346191406
INFO:root:# Valid (Epoch 174): Loss/seq after 00050 batches: 517.283203125
INFO:root:# Valid (Epoch 174): Loss/seq after 00100 batches: 527.2654418945312
INFO:root:# Valid (Epoch 174): Loss/seq after 00150 batches: 404.091064453125
INFO:root:# Valid (Epoch 174): Loss/seq after 00200 batches: 383.506591796875
INFO:root:Artifacts: Make stick videos for epoch 174
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_174_on_20220413_100821.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_174_index_192_on_20220413_100821.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 175): Loss/seq after 00000 batchs: 653.9646606445312
INFO:root:Train (Epoch 175): Loss/seq after 00050 batchs: 541.2581787109375
INFO:root:Train (Epoch 175): Loss/seq after 00100 batchs: 522.3434448242188
INFO:root:Train (Epoch 175): Loss/seq after 00150 batchs: 485.45269775390625
INFO:root:Train (Epoch 175): Loss/seq after 00200 batchs: 535.3499145507812
INFO:root:Train (Epoch 175): Loss/seq after 00250 batchs: 592.917236328125
INFO:root:Train (Epoch 175): Loss/seq after 00300 batchs: 606.5990600585938
INFO:root:Train (Epoch 175): Loss/seq after 00350 batchs: 572.3363037109375
INFO:root:Train (Epoch 175): Loss/seq after 00400 batchs: 556.6143188476562
INFO:root:Train (Epoch 175): Loss/seq after 00450 batchs: 562.8362426757812
INFO:root:Train (Epoch 175): Loss/seq after 00500 batchs: 544.6802978515625
INFO:root:Train (Epoch 175): Loss/seq after 00550 batchs: 533.2305908203125
INFO:root:Train (Epoch 175): Loss/seq after 00600 batchs: 516.1492919921875
INFO:root:Train (Epoch 175): Loss/seq after 00650 batchs: 496.7328186035156
INFO:root:Train (Epoch 175): Loss/seq after 00700 batchs: 476.0634460449219
INFO:root:Train (Epoch 175): Loss/seq after 00750 batchs: 472.2422790527344
INFO:root:Train (Epoch 175): Loss/seq after 00800 batchs: 477.5855712890625
INFO:root:Train (Epoch 175): Loss/seq after 00850 batchs: 463.3506774902344
INFO:root:Train (Epoch 175): Loss/seq after 00900 batchs: 453.13134765625
INFO:root:Train (Epoch 175): Loss/seq after 00950 batchs: 450.6433410644531
INFO:root:Train (Epoch 175): Loss/seq after 01000 batchs: 443.35687255859375
INFO:root:Train (Epoch 175): Loss/seq after 01050 batchs: 436.1619567871094
INFO:root:Train (Epoch 175): Loss/seq after 01100 batchs: 428.57513427734375
INFO:root:Train (Epoch 175): Loss/seq after 01150 batchs: 417.5279235839844
INFO:root:Train (Epoch 175): Loss/seq after 01200 batchs: 421.158203125
INFO:root:Train (Epoch 175): Loss/seq after 01250 batchs: 422.45037841796875
INFO:root:Train (Epoch 175): Loss/seq after 01300 batchs: 413.82470703125
INFO:root:Train (Epoch 175): Loss/seq after 01350 batchs: 407.204833984375
INFO:root:Train (Epoch 175): Loss/seq after 01400 batchs: 408.9188537597656
INFO:root:Train (Epoch 175): Loss/seq after 01450 batchs: 412.2466735839844
INFO:root:Train (Epoch 175): Loss/seq after 01500 batchs: 420.05322265625
INFO:root:Train (Epoch 175): Loss/seq after 01550 batchs: 420.1444396972656
INFO:root:Train (Epoch 175): Loss/seq after 01600 batchs: 416.7611083984375
INFO:root:Train (Epoch 175): Loss/seq after 01650 batchs: 415.2687683105469
INFO:root:Train (Epoch 175): Loss/seq after 01700 batchs: 419.6729431152344
INFO:root:Train (Epoch 175): Loss/seq after 01750 batchs: 418.2496337890625
INFO:root:Train (Epoch 175): Loss/seq after 01800 batchs: 416.5824279785156
INFO:root:Train (Epoch 175): Loss/seq after 01850 batchs: 414.6131286621094
INFO:root:Train (Epoch 175): Loss/seq after 01900 batchs: 414.07232666015625
INFO:root:Train (Epoch 175): Loss/seq after 01950 batchs: 413.2581787109375
INFO:root:Train (Epoch 175): Loss/seq after 02000 batchs: 414.19696044921875
INFO:root:Train (Epoch 175): Loss/seq after 02050 batchs: 414.3494873046875
INFO:root:Train (Epoch 175): Loss/seq after 02100 batchs: 412.9921569824219
INFO:root:Train (Epoch 175): Loss/seq after 02150 batchs: 411.93682861328125
INFO:root:Train (Epoch 175): Loss/seq after 02200 batchs: 410.50897216796875
INFO:root:Train (Epoch 175): Loss/seq after 02250 batchs: 409.30926513671875
INFO:root:Train (Epoch 175): Loss/seq after 02300 batchs: 406.2851257324219
INFO:root:Train (Epoch 175): Loss/seq after 02350 batchs: 403.7762756347656
INFO:root:Train (Epoch 175): Loss/seq after 02400 batchs: 404.4712829589844
INFO:root:Train (Epoch 175): Loss/seq after 02450 batchs: 401.45599365234375
INFO:root:Train (Epoch 175): Loss/seq after 02500 batchs: 395.6672668457031
INFO:root:Train (Epoch 175): Loss/seq after 02550 batchs: 390.2693176269531
INFO:root:Train (Epoch 175): Loss/seq after 02600 batchs: 388.6756591796875
INFO:root:Train (Epoch 175): Loss/seq after 02650 batchs: 385.0771789550781
INFO:root:Train (Epoch 175): Loss/seq after 02700 batchs: 382.6674499511719
INFO:root:Train (Epoch 175): Loss/seq after 02750 batchs: 379.2792663574219
INFO:root:Train (Epoch 175): Loss/seq after 02800 batchs: 377.2718200683594
INFO:root:Train (Epoch 175): Loss/seq after 02850 batchs: 377.2206726074219
INFO:root:Train (Epoch 175): Loss/seq after 02900 batchs: 378.6139831542969
INFO:root:Train (Epoch 175): Loss/seq after 02950 batchs: 379.0056457519531
INFO:root:Train (Epoch 175): Loss/seq after 03000 batchs: 384.5871887207031
INFO:root:Train (Epoch 175): Loss/seq after 03050 batchs: 386.7836608886719
INFO:root:Train (Epoch 175): Loss/seq after 03100 batchs: 388.6297912597656
INFO:root:Train (Epoch 175): Loss/seq after 03150 batchs: 388.7370910644531
INFO:root:Train (Epoch 175): Loss/seq after 03200 batchs: 388.50238037109375
INFO:root:Train (Epoch 175): Loss/seq after 03250 batchs: 389.4029846191406
INFO:root:Train (Epoch 175): Loss/seq after 03300 batchs: 388.98419189453125
INFO:root:Train (Epoch 175): Loss/seq after 03350 batchs: 387.6952209472656
INFO:root:Train (Epoch 175): Loss/seq after 03400 batchs: 384.92279052734375
INFO:root:Train (Epoch 175): Loss/seq after 03450 batchs: 383.99725341796875
INFO:root:Train (Epoch 175): Loss/seq after 03500 batchs: 385.0658874511719
INFO:root:Train (Epoch 175): Loss/seq after 03550 batchs: 383.1703186035156
INFO:root:Train (Epoch 175): Loss/seq after 03600 batchs: 389.6055908203125
INFO:root:Train (Epoch 175): Loss/seq after 03650 batchs: 388.30059814453125
INFO:root:Train (Epoch 175): Loss/seq after 03700 batchs: 390.51263427734375
INFO:root:Train (Epoch 175): Loss/seq after 03750 batchs: 394.7757873535156
INFO:root:Train (Epoch 175): Loss/seq after 03800 batchs: 393.9071960449219
INFO:root:Train (Epoch 175): Loss/seq after 03850 batchs: 393.14300537109375
INFO:root:Train (Epoch 175): Loss/seq after 03900 batchs: 395.07818603515625
INFO:root:Train (Epoch 175): Loss/seq after 03950 batchs: 397.4072265625
INFO:root:Train (Epoch 175): Loss/seq after 04000 batchs: 394.958984375
INFO:root:Train (Epoch 175): Loss/seq after 04050 batchs: 392.5946044921875
INFO:root:Train (Epoch 175): Loss/seq after 04100 batchs: 391.88983154296875
INFO:root:Train (Epoch 175): Loss/seq after 04150 batchs: 392.03656005859375
INFO:root:Train (Epoch 175): Loss/seq after 04200 batchs: 391.1205749511719
INFO:root:Train (Epoch 175): Loss/seq after 04250 batchs: 389.8666076660156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 175): Loss/seq after 00000 batches: 335.8738098144531
INFO:root:# Valid (Epoch 175): Loss/seq after 00050 batches: 506.10333251953125
INFO:root:# Valid (Epoch 175): Loss/seq after 00100 batches: 519.395751953125
INFO:root:# Valid (Epoch 175): Loss/seq after 00150 batches: 397.1939392089844
INFO:root:# Valid (Epoch 175): Loss/seq after 00200 batches: 377.0061340332031
INFO:root:Artifacts: Make stick videos for epoch 175
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_175_on_20220413_101344.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_175_index_1794_on_20220413_101344.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 176): Loss/seq after 00000 batchs: 698.6284790039062
INFO:root:Train (Epoch 176): Loss/seq after 00050 batchs: 527.407958984375
INFO:root:Train (Epoch 176): Loss/seq after 00100 batchs: 506.6501159667969
INFO:root:Train (Epoch 176): Loss/seq after 00150 batchs: 480.36724853515625
INFO:root:Train (Epoch 176): Loss/seq after 00200 batchs: 528.6885986328125
INFO:root:Train (Epoch 176): Loss/seq after 00250 batchs: 586.4635009765625
INFO:root:Train (Epoch 176): Loss/seq after 00300 batchs: 600.0431518554688
INFO:root:Train (Epoch 176): Loss/seq after 00350 batchs: 566.2277221679688
INFO:root:Train (Epoch 176): Loss/seq after 00400 batchs: 550.7267456054688
INFO:root:Train (Epoch 176): Loss/seq after 00450 batchs: 557.0860595703125
INFO:root:Train (Epoch 176): Loss/seq after 00500 batchs: 539.6255493164062
INFO:root:Train (Epoch 176): Loss/seq after 00550 batchs: 528.6824340820312
INFO:root:Train (Epoch 176): Loss/seq after 00600 batchs: 512.0189819335938
INFO:root:Train (Epoch 176): Loss/seq after 00650 batchs: 492.27557373046875
INFO:root:Train (Epoch 176): Loss/seq after 00700 batchs: 472.156494140625
INFO:root:Train (Epoch 176): Loss/seq after 00750 batchs: 468.621826171875
INFO:root:Train (Epoch 176): Loss/seq after 00800 batchs: 474.2748107910156
INFO:root:Train (Epoch 176): Loss/seq after 00850 batchs: 460.34979248046875
INFO:root:Train (Epoch 176): Loss/seq after 00900 batchs: 450.0830383300781
INFO:root:Train (Epoch 176): Loss/seq after 00950 batchs: 447.9920654296875
INFO:root:Train (Epoch 176): Loss/seq after 01000 batchs: 440.8788146972656
INFO:root:Train (Epoch 176): Loss/seq after 01050 batchs: 433.3269348144531
INFO:root:Train (Epoch 176): Loss/seq after 01100 batchs: 425.7544250488281
INFO:root:Train (Epoch 176): Loss/seq after 01150 batchs: 414.6041259765625
INFO:root:Train (Epoch 176): Loss/seq after 01200 batchs: 418.51898193359375
INFO:root:Train (Epoch 176): Loss/seq after 01250 batchs: 419.5497131347656
INFO:root:Train (Epoch 176): Loss/seq after 01300 batchs: 410.8503112792969
INFO:root:Train (Epoch 176): Loss/seq after 01350 batchs: 404.15899658203125
INFO:root:Train (Epoch 176): Loss/seq after 01400 batchs: 405.9884338378906
INFO:root:Train (Epoch 176): Loss/seq after 01450 batchs: 409.1346740722656
INFO:root:Train (Epoch 176): Loss/seq after 01500 batchs: 417.1979064941406
INFO:root:Train (Epoch 176): Loss/seq after 01550 batchs: 417.34271240234375
INFO:root:Train (Epoch 176): Loss/seq after 01600 batchs: 413.94647216796875
INFO:root:Train (Epoch 176): Loss/seq after 01650 batchs: 412.4889221191406
INFO:root:Train (Epoch 176): Loss/seq after 01700 batchs: 416.942138671875
INFO:root:Train (Epoch 176): Loss/seq after 01750 batchs: 415.5401306152344
INFO:root:Train (Epoch 176): Loss/seq after 01800 batchs: 413.97149658203125
INFO:root:Train (Epoch 176): Loss/seq after 01850 batchs: 412.07415771484375
INFO:root:Train (Epoch 176): Loss/seq after 01900 batchs: 411.55426025390625
INFO:root:Train (Epoch 176): Loss/seq after 01950 batchs: 410.8845520019531
INFO:root:Train (Epoch 176): Loss/seq after 02000 batchs: 411.8417053222656
INFO:root:Train (Epoch 176): Loss/seq after 02050 batchs: 411.9698181152344
INFO:root:Train (Epoch 176): Loss/seq after 02100 batchs: 410.8626708984375
INFO:root:Train (Epoch 176): Loss/seq after 02150 batchs: 409.7224426269531
INFO:root:Train (Epoch 176): Loss/seq after 02200 batchs: 408.2184753417969
INFO:root:Train (Epoch 176): Loss/seq after 02250 batchs: 406.94140625
INFO:root:Train (Epoch 176): Loss/seq after 02300 batchs: 403.76275634765625
INFO:root:Train (Epoch 176): Loss/seq after 02350 batchs: 401.27545166015625
INFO:root:Train (Epoch 176): Loss/seq after 02400 batchs: 402.0162353515625
INFO:root:Train (Epoch 176): Loss/seq after 02450 batchs: 398.9851379394531
INFO:root:Train (Epoch 176): Loss/seq after 02500 batchs: 393.2275695800781
INFO:root:Train (Epoch 176): Loss/seq after 02550 batchs: 387.8521423339844
INFO:root:Train (Epoch 176): Loss/seq after 02600 batchs: 386.12774658203125
INFO:root:Train (Epoch 176): Loss/seq after 02650 batchs: 382.52935791015625
INFO:root:Train (Epoch 176): Loss/seq after 02700 batchs: 380.2784423828125
INFO:root:Train (Epoch 176): Loss/seq after 02750 batchs: 377.0220642089844
INFO:root:Train (Epoch 176): Loss/seq after 02800 batchs: 375.2274475097656
INFO:root:Train (Epoch 176): Loss/seq after 02850 batchs: 374.9759216308594
INFO:root:Train (Epoch 176): Loss/seq after 02900 batchs: 376.2958679199219
INFO:root:Train (Epoch 176): Loss/seq after 02950 batchs: 376.6731262207031
INFO:root:Train (Epoch 176): Loss/seq after 03000 batchs: 382.249267578125
INFO:root:Train (Epoch 176): Loss/seq after 03050 batchs: 384.5371398925781
INFO:root:Train (Epoch 176): Loss/seq after 03100 batchs: 386.06280517578125
INFO:root:Train (Epoch 176): Loss/seq after 03150 batchs: 385.5499572753906
INFO:root:Train (Epoch 176): Loss/seq after 03200 batchs: 385.4040222167969
INFO:root:Train (Epoch 176): Loss/seq after 03250 batchs: 386.3797912597656
INFO:root:Train (Epoch 176): Loss/seq after 03300 batchs: 385.8343811035156
INFO:root:Train (Epoch 176): Loss/seq after 03350 batchs: 384.680908203125
INFO:root:Train (Epoch 176): Loss/seq after 03400 batchs: 382.0260925292969
INFO:root:Train (Epoch 176): Loss/seq after 03450 batchs: 381.1683654785156
INFO:root:Train (Epoch 176): Loss/seq after 03500 batchs: 382.0478515625
INFO:root:Train (Epoch 176): Loss/seq after 03550 batchs: 380.1255187988281
INFO:root:Train (Epoch 176): Loss/seq after 03600 batchs: 386.7225341796875
INFO:root:Train (Epoch 176): Loss/seq after 03650 batchs: 385.2858581542969
INFO:root:Train (Epoch 176): Loss/seq after 03700 batchs: 387.40960693359375
INFO:root:Train (Epoch 176): Loss/seq after 03750 batchs: 391.6507568359375
INFO:root:Train (Epoch 176): Loss/seq after 03800 batchs: 390.8454284667969
INFO:root:Train (Epoch 176): Loss/seq after 03850 batchs: 390.06683349609375
INFO:root:Train (Epoch 176): Loss/seq after 03900 batchs: 391.831787109375
INFO:root:Train (Epoch 176): Loss/seq after 03950 batchs: 394.2574157714844
INFO:root:Train (Epoch 176): Loss/seq after 04000 batchs: 391.84796142578125
INFO:root:Train (Epoch 176): Loss/seq after 04050 batchs: 389.5264892578125
INFO:root:Train (Epoch 176): Loss/seq after 04100 batchs: 388.89813232421875
INFO:root:Train (Epoch 176): Loss/seq after 04150 batchs: 389.0112609863281
INFO:root:Train (Epoch 176): Loss/seq after 04200 batchs: 388.2928161621094
INFO:root:Train (Epoch 176): Loss/seq after 04250 batchs: 387.0660705566406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 176): Loss/seq after 00000 batches: 338.3376770019531
INFO:root:# Valid (Epoch 176): Loss/seq after 00050 batches: 502.4947204589844
INFO:root:# Valid (Epoch 176): Loss/seq after 00100 batches: 506.66168212890625
INFO:root:# Valid (Epoch 176): Loss/seq after 00150 batches: 388.71685791015625
INFO:root:# Valid (Epoch 176): Loss/seq after 00200 batches: 366.8675537109375
INFO:root:Artifacts: Make stick videos for epoch 176
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_176_on_20220413_101906.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_176_index_577_on_20220413_101906.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 177): Loss/seq after 00000 batchs: 716.3517456054688
INFO:root:Train (Epoch 177): Loss/seq after 00050 batchs: 525.7255249023438
INFO:root:Train (Epoch 177): Loss/seq after 00100 batchs: 508.2489929199219
INFO:root:Train (Epoch 177): Loss/seq after 00150 batchs: 477.1924743652344
INFO:root:Train (Epoch 177): Loss/seq after 00200 batchs: 526.7206420898438
INFO:root:Train (Epoch 177): Loss/seq after 00250 batchs: 585.891357421875
INFO:root:Train (Epoch 177): Loss/seq after 00300 batchs: 598.177734375
INFO:root:Train (Epoch 177): Loss/seq after 00350 batchs: 565.1158447265625
INFO:root:Train (Epoch 177): Loss/seq after 00400 batchs: 550.2201538085938
INFO:root:Train (Epoch 177): Loss/seq after 00450 batchs: 556.7752075195312
INFO:root:Train (Epoch 177): Loss/seq after 00500 batchs: 538.304931640625
INFO:root:Train (Epoch 177): Loss/seq after 00550 batchs: 527.0829467773438
INFO:root:Train (Epoch 177): Loss/seq after 00600 batchs: 510.5734558105469
INFO:root:Train (Epoch 177): Loss/seq after 00650 batchs: 490.6807861328125
INFO:root:Train (Epoch 177): Loss/seq after 00700 batchs: 471.2266845703125
INFO:root:Train (Epoch 177): Loss/seq after 00750 batchs: 468.0389404296875
INFO:root:Train (Epoch 177): Loss/seq after 00800 batchs: 473.0644836425781
INFO:root:Train (Epoch 177): Loss/seq after 00850 batchs: 458.74139404296875
INFO:root:Train (Epoch 177): Loss/seq after 00900 batchs: 448.59002685546875
INFO:root:Train (Epoch 177): Loss/seq after 00950 batchs: 445.482421875
INFO:root:Train (Epoch 177): Loss/seq after 01000 batchs: 438.0902099609375
INFO:root:Train (Epoch 177): Loss/seq after 01050 batchs: 430.9244689941406
INFO:root:Train (Epoch 177): Loss/seq after 01100 batchs: 423.43572998046875
INFO:root:Train (Epoch 177): Loss/seq after 01150 batchs: 412.48284912109375
INFO:root:Train (Epoch 177): Loss/seq after 01200 batchs: 416.2311706542969
INFO:root:Train (Epoch 177): Loss/seq after 01250 batchs: 417.3004455566406
INFO:root:Train (Epoch 177): Loss/seq after 01300 batchs: 408.8545837402344
INFO:root:Train (Epoch 177): Loss/seq after 01350 batchs: 402.2665100097656
INFO:root:Train (Epoch 177): Loss/seq after 01400 batchs: 404.2033386230469
INFO:root:Train (Epoch 177): Loss/seq after 01450 batchs: 407.5816345214844
INFO:root:Train (Epoch 177): Loss/seq after 01500 batchs: 415.2293701171875
INFO:root:Train (Epoch 177): Loss/seq after 01550 batchs: 415.4900207519531
INFO:root:Train (Epoch 177): Loss/seq after 01600 batchs: 412.17230224609375
INFO:root:Train (Epoch 177): Loss/seq after 01650 batchs: 410.5939025878906
INFO:root:Train (Epoch 177): Loss/seq after 01700 batchs: 415.2649841308594
INFO:root:Train (Epoch 177): Loss/seq after 01750 batchs: 413.9097595214844
INFO:root:Train (Epoch 177): Loss/seq after 01800 batchs: 412.4512023925781
INFO:root:Train (Epoch 177): Loss/seq after 01850 batchs: 410.5337829589844
INFO:root:Train (Epoch 177): Loss/seq after 01900 batchs: 410.0443420410156
INFO:root:Train (Epoch 177): Loss/seq after 01950 batchs: 409.3503723144531
INFO:root:Train (Epoch 177): Loss/seq after 02000 batchs: 410.22039794921875
INFO:root:Train (Epoch 177): Loss/seq after 02050 batchs: 410.26971435546875
INFO:root:Train (Epoch 177): Loss/seq after 02100 batchs: 409.1432189941406
INFO:root:Train (Epoch 177): Loss/seq after 02150 batchs: 408.0555114746094
INFO:root:Train (Epoch 177): Loss/seq after 02200 batchs: 406.6138610839844
INFO:root:Train (Epoch 177): Loss/seq after 02250 batchs: 405.3629455566406
INFO:root:Train (Epoch 177): Loss/seq after 02300 batchs: 402.2884216308594
INFO:root:Train (Epoch 177): Loss/seq after 02350 batchs: 399.8269958496094
INFO:root:Train (Epoch 177): Loss/seq after 02400 batchs: 400.48095703125
INFO:root:Train (Epoch 177): Loss/seq after 02450 batchs: 397.406005859375
INFO:root:Train (Epoch 177): Loss/seq after 02500 batchs: 391.57525634765625
INFO:root:Train (Epoch 177): Loss/seq after 02550 batchs: 386.221435546875
INFO:root:Train (Epoch 177): Loss/seq after 02600 batchs: 384.5338134765625
INFO:root:Train (Epoch 177): Loss/seq after 02650 batchs: 380.97320556640625
INFO:root:Train (Epoch 177): Loss/seq after 02700 batchs: 378.64056396484375
INFO:root:Train (Epoch 177): Loss/seq after 02750 batchs: 375.4570007324219
INFO:root:Train (Epoch 177): Loss/seq after 02800 batchs: 373.7283630371094
INFO:root:Train (Epoch 177): Loss/seq after 02850 batchs: 373.6599426269531
INFO:root:Train (Epoch 177): Loss/seq after 02900 batchs: 375.0366516113281
INFO:root:Train (Epoch 177): Loss/seq after 02950 batchs: 375.4040222167969
INFO:root:Train (Epoch 177): Loss/seq after 03000 batchs: 380.91827392578125
INFO:root:Train (Epoch 177): Loss/seq after 03050 batchs: 383.1495666503906
INFO:root:Train (Epoch 177): Loss/seq after 03100 batchs: 384.7646179199219
INFO:root:Train (Epoch 177): Loss/seq after 03150 batchs: 384.6412353515625
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 177): Loss/seq after 03200 batchs: 384.6313781738281
INFO:root:Train (Epoch 177): Loss/seq after 03250 batchs: 385.3491516113281
INFO:root:Train (Epoch 177): Loss/seq after 03300 batchs: 384.76019287109375
INFO:root:Train (Epoch 177): Loss/seq after 03350 batchs: 383.6257019042969
INFO:root:Train (Epoch 177): Loss/seq after 03400 batchs: 380.8835754394531
INFO:root:Train (Epoch 177): Loss/seq after 03450 batchs: 379.9136657714844
INFO:root:Train (Epoch 177): Loss/seq after 03500 batchs: 380.5668029785156
INFO:root:Train (Epoch 177): Loss/seq after 03550 batchs: 378.49957275390625
INFO:root:Train (Epoch 177): Loss/seq after 03600 batchs: 385.0684814453125
INFO:root:Train (Epoch 177): Loss/seq after 03650 batchs: 383.693115234375
INFO:root:Train (Epoch 177): Loss/seq after 03700 batchs: 385.8687744140625
INFO:root:Train (Epoch 177): Loss/seq after 03750 batchs: 390.0882263183594
INFO:root:Train (Epoch 177): Loss/seq after 03800 batchs: 389.31976318359375
INFO:root:Train (Epoch 177): Loss/seq after 03850 batchs: 388.51416015625
INFO:root:Train (Epoch 177): Loss/seq after 03900 batchs: 390.4297790527344
INFO:root:Train (Epoch 177): Loss/seq after 03950 batchs: 392.8449401855469
INFO:root:Train (Epoch 177): Loss/seq after 04000 batchs: 390.4498291015625
INFO:root:Train (Epoch 177): Loss/seq after 04050 batchs: 388.1443786621094
INFO:root:Train (Epoch 177): Loss/seq after 04100 batchs: 387.48870849609375
INFO:root:Train (Epoch 177): Loss/seq after 04150 batchs: 387.6526794433594
INFO:root:Train (Epoch 177): Loss/seq after 04200 batchs: 386.71673583984375
INFO:root:Train (Epoch 177): Loss/seq after 04250 batchs: 385.4992370605469
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 177): Loss/seq after 00000 batches: 343.53436279296875
INFO:root:# Valid (Epoch 177): Loss/seq after 00050 batches: 502.89215087890625
INFO:root:# Valid (Epoch 177): Loss/seq after 00100 batches: 521.3623657226562
INFO:root:# Valid (Epoch 177): Loss/seq after 00150 batches: 399.2220153808594
INFO:root:# Valid (Epoch 177): Loss/seq after 00200 batches: 374.90240478515625
INFO:root:Artifacts: Make stick videos for epoch 177
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_177_on_20220413_102428.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_177_index_1261_on_20220413_102428.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 178): Loss/seq after 00000 batchs: 696.6038208007812
INFO:root:Train (Epoch 178): Loss/seq after 00050 batchs: 543.11962890625
INFO:root:Train (Epoch 178): Loss/seq after 00100 batchs: 516.9998168945312
INFO:root:Train (Epoch 178): Loss/seq after 00150 batchs: 479.19671630859375
INFO:root:Train (Epoch 178): Loss/seq after 00200 batchs: 527.7606811523438
INFO:root:Train (Epoch 178): Loss/seq after 00250 batchs: 586.6517333984375
INFO:root:Train (Epoch 178): Loss/seq after 00300 batchs: 598.837646484375
INFO:root:Train (Epoch 178): Loss/seq after 00350 batchs: 565.377197265625
INFO:root:Train (Epoch 178): Loss/seq after 00400 batchs: 549.7577514648438
INFO:root:Train (Epoch 178): Loss/seq after 00450 batchs: 556.0687255859375
INFO:root:Train (Epoch 178): Loss/seq after 00500 batchs: 537.279541015625
INFO:root:Train (Epoch 178): Loss/seq after 00550 batchs: 525.9556884765625
INFO:root:Train (Epoch 178): Loss/seq after 00600 batchs: 509.8395080566406
INFO:root:Train (Epoch 178): Loss/seq after 00650 batchs: 490.4085998535156
INFO:root:Train (Epoch 178): Loss/seq after 00700 batchs: 470.82427978515625
INFO:root:Train (Epoch 178): Loss/seq after 00750 batchs: 467.97467041015625
INFO:root:Train (Epoch 178): Loss/seq after 00800 batchs: 472.4773864746094
INFO:root:Train (Epoch 178): Loss/seq after 00850 batchs: 458.4967346191406
INFO:root:Train (Epoch 178): Loss/seq after 00900 batchs: 448.4443054199219
INFO:root:Train (Epoch 178): Loss/seq after 00950 batchs: 445.68487548828125
INFO:root:Train (Epoch 178): Loss/seq after 01000 batchs: 437.7829895019531
INFO:root:Train (Epoch 178): Loss/seq after 01050 batchs: 430.4474792480469
INFO:root:Train (Epoch 178): Loss/seq after 01100 batchs: 422.5392761230469
INFO:root:Train (Epoch 178): Loss/seq after 01150 batchs: 411.6272277832031
INFO:root:Train (Epoch 178): Loss/seq after 01200 batchs: 414.15631103515625
INFO:root:Train (Epoch 178): Loss/seq after 01250 batchs: 415.1925048828125
INFO:root:Train (Epoch 178): Loss/seq after 01300 batchs: 406.54412841796875
INFO:root:Train (Epoch 178): Loss/seq after 01350 batchs: 399.9913330078125
INFO:root:Train (Epoch 178): Loss/seq after 01400 batchs: 402.13623046875
INFO:root:Train (Epoch 178): Loss/seq after 01450 batchs: 405.4743957519531
INFO:root:Train (Epoch 178): Loss/seq after 01500 batchs: 413.0898132324219
INFO:root:Train (Epoch 178): Loss/seq after 01550 batchs: 413.2065124511719
INFO:root:Train (Epoch 178): Loss/seq after 01600 batchs: 409.7181701660156
INFO:root:Train (Epoch 178): Loss/seq after 01650 batchs: 408.2518615722656
INFO:root:Train (Epoch 178): Loss/seq after 01700 batchs: 412.7998046875
INFO:root:Train (Epoch 178): Loss/seq after 01750 batchs: 411.556640625
INFO:root:Train (Epoch 178): Loss/seq after 01800 batchs: 409.7870788574219
INFO:root:Train (Epoch 178): Loss/seq after 01850 batchs: 407.9264221191406
INFO:root:Train (Epoch 178): Loss/seq after 01900 batchs: 407.2578125
INFO:root:Train (Epoch 178): Loss/seq after 01950 batchs: 406.54168701171875
INFO:root:Train (Epoch 178): Loss/seq after 02000 batchs: 407.51629638671875
INFO:root:Train (Epoch 178): Loss/seq after 02050 batchs: 407.55078125
INFO:root:Train (Epoch 178): Loss/seq after 02100 batchs: 406.3868103027344
INFO:root:Train (Epoch 178): Loss/seq after 02150 batchs: 405.3156433105469
INFO:root:Train (Epoch 178): Loss/seq after 02200 batchs: 403.8648681640625
INFO:root:Train (Epoch 178): Loss/seq after 02250 batchs: 402.6477355957031
INFO:root:Train (Epoch 178): Loss/seq after 02300 batchs: 399.7816162109375
INFO:root:Train (Epoch 178): Loss/seq after 02350 batchs: 397.3102111816406
INFO:root:Train (Epoch 178): Loss/seq after 02400 batchs: 398.0309753417969
INFO:root:Train (Epoch 178): Loss/seq after 02450 batchs: 395.0459289550781
INFO:root:Train (Epoch 178): Loss/seq after 02500 batchs: 389.3594665527344
INFO:root:Train (Epoch 178): Loss/seq after 02550 batchs: 384.0654602050781
INFO:root:Train (Epoch 178): Loss/seq after 02600 batchs: 382.3700866699219
INFO:root:Train (Epoch 178): Loss/seq after 02650 batchs: 378.7213439941406
INFO:root:Train (Epoch 178): Loss/seq after 02700 batchs: 376.4192810058594
INFO:root:Train (Epoch 178): Loss/seq after 02750 batchs: 373.3488464355469
INFO:root:Train (Epoch 178): Loss/seq after 02800 batchs: 371.4789123535156
INFO:root:Train (Epoch 178): Loss/seq after 02850 batchs: 371.3215026855469
INFO:root:Train (Epoch 178): Loss/seq after 02900 batchs: 372.791748046875
INFO:root:Train (Epoch 178): Loss/seq after 02950 batchs: 373.1515197753906
INFO:root:Train (Epoch 178): Loss/seq after 03000 batchs: 378.73687744140625
INFO:root:Train (Epoch 178): Loss/seq after 03050 batchs: 380.8980407714844
INFO:root:Train (Epoch 178): Loss/seq after 03100 batchs: 382.7160949707031
INFO:root:Train (Epoch 178): Loss/seq after 03150 batchs: 382.51898193359375
INFO:root:Train (Epoch 178): Loss/seq after 03200 batchs: 382.6759948730469
INFO:root:Train (Epoch 178): Loss/seq after 03250 batchs: 383.3419494628906
INFO:root:Train (Epoch 178): Loss/seq after 03300 batchs: 382.7889404296875
INFO:root:Train (Epoch 178): Loss/seq after 03350 batchs: 381.6061096191406
INFO:root:Train (Epoch 178): Loss/seq after 03400 batchs: 378.8660583496094
INFO:root:Train (Epoch 178): Loss/seq after 03450 batchs: 377.98016357421875
INFO:root:Train (Epoch 178): Loss/seq after 03500 batchs: 378.9211730957031
INFO:root:Train (Epoch 178): Loss/seq after 03550 batchs: 376.95068359375
INFO:root:Train (Epoch 178): Loss/seq after 03600 batchs: 383.3652038574219
INFO:root:Train (Epoch 178): Loss/seq after 03650 batchs: 382.04229736328125
INFO:root:Train (Epoch 178): Loss/seq after 03700 batchs: 384.5120544433594
INFO:root:Train (Epoch 178): Loss/seq after 03750 batchs: 388.79437255859375
INFO:root:Train (Epoch 178): Loss/seq after 03800 batchs: 388.02880859375
INFO:root:Train (Epoch 178): Loss/seq after 03850 batchs: 387.25390625
INFO:root:Train (Epoch 178): Loss/seq after 03900 batchs: 389.22161865234375
INFO:root:Train (Epoch 178): Loss/seq after 03950 batchs: 391.59765625
INFO:root:Train (Epoch 178): Loss/seq after 04000 batchs: 389.208740234375
INFO:root:Train (Epoch 178): Loss/seq after 04050 batchs: 386.9178771972656
INFO:root:Train (Epoch 178): Loss/seq after 04100 batchs: 386.28607177734375
INFO:root:Train (Epoch 178): Loss/seq after 04150 batchs: 386.45849609375
INFO:root:Train (Epoch 178): Loss/seq after 04200 batchs: 385.65679931640625
INFO:root:Train (Epoch 178): Loss/seq after 04250 batchs: 384.4245910644531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 178): Loss/seq after 00000 batches: 317.09112548828125
INFO:root:# Valid (Epoch 178): Loss/seq after 00050 batches: 498.9114074707031
INFO:root:# Valid (Epoch 178): Loss/seq after 00100 batches: 512.6572875976562
INFO:root:# Valid (Epoch 178): Loss/seq after 00150 batches: 395.79351806640625
INFO:root:# Valid (Epoch 178): Loss/seq after 00200 batches: 374.8591613769531
INFO:root:Artifacts: Make stick videos for epoch 178
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_178_on_20220413_102956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_178_index_1225_on_20220413_102956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 179): Loss/seq after 00000 batchs: 613.5130004882812
INFO:root:Train (Epoch 179): Loss/seq after 00050 batchs: 526.3973999023438
INFO:root:Train (Epoch 179): Loss/seq after 00100 batchs: 501.6218566894531
INFO:root:Train (Epoch 179): Loss/seq after 00150 batchs: 467.5463562011719
INFO:root:Train (Epoch 179): Loss/seq after 00200 batchs: 514.247314453125
INFO:root:Train (Epoch 179): Loss/seq after 00250 batchs: 573.857666015625
INFO:root:Train (Epoch 179): Loss/seq after 00300 batchs: 587.9052734375
INFO:root:Train (Epoch 179): Loss/seq after 00350 batchs: 555.1071166992188
INFO:root:Train (Epoch 179): Loss/seq after 00400 batchs: 538.8348388671875
INFO:root:Train (Epoch 179): Loss/seq after 00450 batchs: 546.1375122070312
INFO:root:Train (Epoch 179): Loss/seq after 00500 batchs: 527.14453125
INFO:root:Train (Epoch 179): Loss/seq after 00550 batchs: 516.3569946289062
INFO:root:Train (Epoch 179): Loss/seq after 00600 batchs: 500.6906433105469
INFO:root:Train (Epoch 179): Loss/seq after 00650 batchs: 481.7349853515625
INFO:root:Train (Epoch 179): Loss/seq after 00700 batchs: 461.38299560546875
INFO:root:Train (Epoch 179): Loss/seq after 00750 batchs: 457.7295837402344
INFO:root:Train (Epoch 179): Loss/seq after 00800 batchs: 462.944091796875
INFO:root:Train (Epoch 179): Loss/seq after 00850 batchs: 449.24566650390625
INFO:root:Train (Epoch 179): Loss/seq after 00900 batchs: 439.62286376953125
INFO:root:Train (Epoch 179): Loss/seq after 00950 batchs: 437.2735900878906
INFO:root:Train (Epoch 179): Loss/seq after 01000 batchs: 430.0341796875
INFO:root:Train (Epoch 179): Loss/seq after 01050 batchs: 423.1278991699219
INFO:root:Train (Epoch 179): Loss/seq after 01100 batchs: 415.9938049316406
INFO:root:Train (Epoch 179): Loss/seq after 01150 batchs: 405.06201171875
INFO:root:Train (Epoch 179): Loss/seq after 01200 batchs: 408.20904541015625
INFO:root:Train (Epoch 179): Loss/seq after 01250 batchs: 409.37164306640625
INFO:root:Train (Epoch 179): Loss/seq after 01300 batchs: 401.15533447265625
INFO:root:Train (Epoch 179): Loss/seq after 01350 batchs: 394.831787109375
INFO:root:Train (Epoch 179): Loss/seq after 01400 batchs: 396.44976806640625
INFO:root:Train (Epoch 179): Loss/seq after 01450 batchs: 399.9289245605469
INFO:root:Train (Epoch 179): Loss/seq after 01500 batchs: 407.74713134765625
INFO:root:Train (Epoch 179): Loss/seq after 01550 batchs: 408.1759948730469
INFO:root:Train (Epoch 179): Loss/seq after 01600 batchs: 404.9582214355469
INFO:root:Train (Epoch 179): Loss/seq after 01650 batchs: 403.85064697265625
INFO:root:Train (Epoch 179): Loss/seq after 01700 batchs: 408.63250732421875
INFO:root:Train (Epoch 179): Loss/seq after 01750 batchs: 407.3660583496094
INFO:root:Train (Epoch 179): Loss/seq after 01800 batchs: 405.72442626953125
INFO:root:Train (Epoch 179): Loss/seq after 01850 batchs: 404.0174560546875
INFO:root:Train (Epoch 179): Loss/seq after 01900 batchs: 403.5111083984375
INFO:root:Train (Epoch 179): Loss/seq after 01950 batchs: 403.0729064941406
INFO:root:Train (Epoch 179): Loss/seq after 02000 batchs: 404.0737609863281
INFO:root:Train (Epoch 179): Loss/seq after 02050 batchs: 404.28662109375
INFO:root:Train (Epoch 179): Loss/seq after 02100 batchs: 403.2138366699219
INFO:root:Train (Epoch 179): Loss/seq after 02150 batchs: 402.20770263671875
INFO:root:Train (Epoch 179): Loss/seq after 02200 batchs: 400.9519348144531
INFO:root:Train (Epoch 179): Loss/seq after 02250 batchs: 399.7928466796875
INFO:root:Train (Epoch 179): Loss/seq after 02300 batchs: 396.85089111328125
INFO:root:Train (Epoch 179): Loss/seq after 02350 batchs: 394.4910888671875
INFO:root:Train (Epoch 179): Loss/seq after 02400 batchs: 395.3038330078125
INFO:root:Train (Epoch 179): Loss/seq after 02450 batchs: 392.3337707519531
INFO:root:Train (Epoch 179): Loss/seq after 02500 batchs: 386.6531982421875
INFO:root:Train (Epoch 179): Loss/seq after 02550 batchs: 381.4304504394531
INFO:root:Train (Epoch 179): Loss/seq after 02600 batchs: 379.7581787109375
INFO:root:Train (Epoch 179): Loss/seq after 02650 batchs: 376.1729736328125
INFO:root:Train (Epoch 179): Loss/seq after 02700 batchs: 373.8794250488281
INFO:root:Train (Epoch 179): Loss/seq after 02750 batchs: 370.6924133300781
INFO:root:Train (Epoch 179): Loss/seq after 02800 batchs: 368.7785949707031
INFO:root:Train (Epoch 179): Loss/seq after 02850 batchs: 368.66552734375
INFO:root:Train (Epoch 179): Loss/seq after 02900 batchs: 369.9692687988281
INFO:root:Train (Epoch 179): Loss/seq after 02950 batchs: 370.3959655761719
INFO:root:Train (Epoch 179): Loss/seq after 03000 batchs: 376.0366516113281
INFO:root:Train (Epoch 179): Loss/seq after 03050 batchs: 378.2230529785156
INFO:root:Train (Epoch 179): Loss/seq after 03100 batchs: 379.81512451171875
INFO:root:Train (Epoch 179): Loss/seq after 03150 batchs: 379.71124267578125
INFO:root:Train (Epoch 179): Loss/seq after 03200 batchs: 379.72247314453125
INFO:root:Train (Epoch 179): Loss/seq after 03250 batchs: 380.6939392089844
INFO:root:Train (Epoch 179): Loss/seq after 03300 batchs: 380.1813049316406
INFO:root:Train (Epoch 179): Loss/seq after 03350 batchs: 378.8016357421875
INFO:root:Train (Epoch 179): Loss/seq after 03400 batchs: 376.1264343261719
INFO:root:Train (Epoch 179): Loss/seq after 03450 batchs: 375.349365234375
INFO:root:Train (Epoch 179): Loss/seq after 03500 batchs: 376.1527099609375
INFO:root:Train (Epoch 179): Loss/seq after 03550 batchs: 374.2366027832031
INFO:root:Train (Epoch 179): Loss/seq after 03600 batchs: 380.8287048339844
INFO:root:Train (Epoch 179): Loss/seq after 03650 batchs: 379.37799072265625
INFO:root:Train (Epoch 179): Loss/seq after 03700 batchs: 381.6586608886719
INFO:root:Train (Epoch 179): Loss/seq after 03750 batchs: 386.0445861816406
INFO:root:Train (Epoch 179): Loss/seq after 03800 batchs: 385.2210693359375
INFO:root:Train (Epoch 179): Loss/seq after 03850 batchs: 384.47979736328125
INFO:root:Train (Epoch 179): Loss/seq after 03900 batchs: 386.3813781738281
INFO:root:Train (Epoch 179): Loss/seq after 03950 batchs: 388.7405700683594
INFO:root:Train (Epoch 179): Loss/seq after 04000 batchs: 386.3675842285156
INFO:root:Train (Epoch 179): Loss/seq after 04050 batchs: 384.08990478515625
INFO:root:Train (Epoch 179): Loss/seq after 04100 batchs: 383.46063232421875
INFO:root:Train (Epoch 179): Loss/seq after 04150 batchs: 383.5928649902344
INFO:root:Train (Epoch 179): Loss/seq after 04200 batchs: 382.682861328125
INFO:root:Train (Epoch 179): Loss/seq after 04250 batchs: 381.4549560546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 179): Loss/seq after 00000 batches: 348.9479064941406
INFO:root:# Valid (Epoch 179): Loss/seq after 00050 batches: 493.88409423828125
INFO:root:# Valid (Epoch 179): Loss/seq after 00100 batches: 512.9022827148438
INFO:root:# Valid (Epoch 179): Loss/seq after 00150 batches: 395.0868835449219
INFO:root:# Valid (Epoch 179): Loss/seq after 00200 batches: 374.05157470703125
INFO:root:Artifacts: Make stick videos for epoch 179
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_179_on_20220413_103521.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_179_index_273_on_20220413_103521.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 180): Loss/seq after 00000 batchs: 796.1638793945312
INFO:root:Train (Epoch 180): Loss/seq after 00050 batchs: 519.0993041992188
INFO:root:Train (Epoch 180): Loss/seq after 00100 batchs: 496.4850158691406
INFO:root:Train (Epoch 180): Loss/seq after 00150 batchs: 465.8913879394531
INFO:root:Train (Epoch 180): Loss/seq after 00200 batchs: 516.133056640625
INFO:root:Train (Epoch 180): Loss/seq after 00250 batchs: 576.3763427734375
INFO:root:Train (Epoch 180): Loss/seq after 00300 batchs: 589.7252807617188
INFO:root:Train (Epoch 180): Loss/seq after 00350 batchs: 556.7153930664062
INFO:root:Train (Epoch 180): Loss/seq after 00400 batchs: 540.4658203125
INFO:root:Train (Epoch 180): Loss/seq after 00450 batchs: 547.1638793945312
INFO:root:Train (Epoch 180): Loss/seq after 00500 batchs: 528.8614501953125
INFO:root:Train (Epoch 180): Loss/seq after 00550 batchs: 518.69921875
INFO:root:Train (Epoch 180): Loss/seq after 00600 batchs: 502.19659423828125
INFO:root:Train (Epoch 180): Loss/seq after 00650 batchs: 482.41259765625
INFO:root:Train (Epoch 180): Loss/seq after 00700 batchs: 462.3461608886719
INFO:root:Train (Epoch 180): Loss/seq after 00750 batchs: 459.3262023925781
INFO:root:Train (Epoch 180): Loss/seq after 00800 batchs: 464.5013427734375
INFO:root:Train (Epoch 180): Loss/seq after 00850 batchs: 450.5878601074219
INFO:root:Train (Epoch 180): Loss/seq after 00900 batchs: 440.4234619140625
INFO:root:Train (Epoch 180): Loss/seq after 00950 batchs: 437.1403503417969
INFO:root:Train (Epoch 180): Loss/seq after 01000 batchs: 429.9849548339844
INFO:root:Train (Epoch 180): Loss/seq after 01050 batchs: 422.59210205078125
INFO:root:Train (Epoch 180): Loss/seq after 01100 batchs: 414.9599304199219
INFO:root:Train (Epoch 180): Loss/seq after 01150 batchs: 404.2377014160156
INFO:root:Train (Epoch 180): Loss/seq after 01200 batchs: 407.6546325683594
INFO:root:Train (Epoch 180): Loss/seq after 01250 batchs: 408.7871398925781
INFO:root:Train (Epoch 180): Loss/seq after 01300 batchs: 400.4904479980469
INFO:root:Train (Epoch 180): Loss/seq after 01350 batchs: 393.9127502441406
INFO:root:Train (Epoch 180): Loss/seq after 01400 batchs: 395.59979248046875
INFO:root:Train (Epoch 180): Loss/seq after 01450 batchs: 398.981201171875
INFO:root:Train (Epoch 180): Loss/seq after 01500 batchs: 407.03387451171875
INFO:root:Train (Epoch 180): Loss/seq after 01550 batchs: 407.24249267578125
INFO:root:Train (Epoch 180): Loss/seq after 01600 batchs: 404.0340881347656
INFO:root:Train (Epoch 180): Loss/seq after 01650 batchs: 402.5160217285156
INFO:root:Train (Epoch 180): Loss/seq after 01700 batchs: 407.11962890625
INFO:root:Train (Epoch 180): Loss/seq after 01750 batchs: 405.6764831542969
INFO:root:Train (Epoch 180): Loss/seq after 01800 batchs: 404.1668701171875
INFO:root:Train (Epoch 180): Loss/seq after 01850 batchs: 402.4415283203125
INFO:root:Train (Epoch 180): Loss/seq after 01900 batchs: 401.93121337890625
INFO:root:Train (Epoch 180): Loss/seq after 01950 batchs: 401.60601806640625
INFO:root:Train (Epoch 180): Loss/seq after 02000 batchs: 402.7393493652344
INFO:root:Train (Epoch 180): Loss/seq after 02050 batchs: 403.1173095703125
INFO:root:Train (Epoch 180): Loss/seq after 02100 batchs: 401.9992980957031
INFO:root:Train (Epoch 180): Loss/seq after 02150 batchs: 401.00872802734375
INFO:root:Train (Epoch 180): Loss/seq after 02200 batchs: 399.6614990234375
INFO:root:Train (Epoch 180): Loss/seq after 02250 batchs: 398.6418762207031
INFO:root:Train (Epoch 180): Loss/seq after 02300 batchs: 395.7879333496094
INFO:root:Train (Epoch 180): Loss/seq after 02350 batchs: 393.3740539550781
INFO:root:Train (Epoch 180): Loss/seq after 02400 batchs: 394.0826416015625
INFO:root:Train (Epoch 180): Loss/seq after 02450 batchs: 391.0606994628906
INFO:root:Train (Epoch 180): Loss/seq after 02500 batchs: 385.36383056640625
INFO:root:Train (Epoch 180): Loss/seq after 02550 batchs: 380.130859375
INFO:root:Train (Epoch 180): Loss/seq after 02600 batchs: 378.4555969238281
INFO:root:Train (Epoch 180): Loss/seq after 02650 batchs: 374.8295593261719
INFO:root:Train (Epoch 180): Loss/seq after 02700 batchs: 372.5150146484375
INFO:root:Train (Epoch 180): Loss/seq after 02750 batchs: 369.3323974609375
INFO:root:Train (Epoch 180): Loss/seq after 02800 batchs: 367.3017578125
INFO:root:Train (Epoch 180): Loss/seq after 02850 batchs: 367.0474548339844
INFO:root:Train (Epoch 180): Loss/seq after 02900 batchs: 368.5614318847656
INFO:root:Train (Epoch 180): Loss/seq after 02950 batchs: 369.01324462890625
INFO:root:Train (Epoch 180): Loss/seq after 03000 batchs: 374.5499572753906
INFO:root:Train (Epoch 180): Loss/seq after 03050 batchs: 376.8554382324219
INFO:root:Train (Epoch 180): Loss/seq after 03100 batchs: 378.3484802246094
INFO:root:Train (Epoch 180): Loss/seq after 03150 batchs: 378.4408264160156
INFO:root:Train (Epoch 180): Loss/seq after 03200 batchs: 378.3870849609375
INFO:root:Train (Epoch 180): Loss/seq after 03250 batchs: 379.3133239746094
INFO:root:Train (Epoch 180): Loss/seq after 03300 batchs: 378.99462890625
INFO:root:Train (Epoch 180): Loss/seq after 03350 batchs: 377.880126953125
INFO:root:Train (Epoch 180): Loss/seq after 03400 batchs: 375.20892333984375
INFO:root:Train (Epoch 180): Loss/seq after 03450 batchs: 374.39520263671875
INFO:root:Train (Epoch 180): Loss/seq after 03500 batchs: 375.2481689453125
INFO:root:Train (Epoch 180): Loss/seq after 03550 batchs: 373.30462646484375
INFO:root:Train (Epoch 180): Loss/seq after 03600 batchs: 379.8731384277344
INFO:root:Train (Epoch 180): Loss/seq after 03650 batchs: 378.5557861328125
INFO:root:Train (Epoch 180): Loss/seq after 03700 batchs: 380.7243347167969
INFO:root:Train (Epoch 180): Loss/seq after 03750 batchs: 384.98565673828125
INFO:root:Train (Epoch 180): Loss/seq after 03800 batchs: 384.22125244140625
INFO:root:Train (Epoch 180): Loss/seq after 03850 batchs: 383.54791259765625
INFO:root:Train (Epoch 180): Loss/seq after 03900 batchs: 385.4947509765625
INFO:root:Train (Epoch 180): Loss/seq after 03950 batchs: 387.997802734375
INFO:root:Train (Epoch 180): Loss/seq after 04000 batchs: 385.6628112792969
INFO:root:Train (Epoch 180): Loss/seq after 04050 batchs: 383.3710021972656
INFO:root:Train (Epoch 180): Loss/seq after 04100 batchs: 382.7882080078125
INFO:root:Train (Epoch 180): Loss/seq after 04150 batchs: 382.97247314453125
INFO:root:Train (Epoch 180): Loss/seq after 04200 batchs: 382.20367431640625
INFO:root:Train (Epoch 180): Loss/seq after 04250 batchs: 380.9889831542969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 180): Loss/seq after 00000 batches: 360.1075134277344
INFO:root:# Valid (Epoch 180): Loss/seq after 00050 batches: 480.92498779296875
INFO:root:# Valid (Epoch 180): Loss/seq after 00100 batches: 490.41998291015625
INFO:root:# Valid (Epoch 180): Loss/seq after 00150 batches: 380.8121032714844
INFO:root:# Valid (Epoch 180): Loss/seq after 00200 batches: 362.83856201171875
INFO:root:Artifacts: Make stick videos for epoch 180
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_180_on_20220413_104046.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_180_index_735_on_20220413_104046.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 181): Loss/seq after 00000 batchs: 693.4105224609375
INFO:root:Train (Epoch 181): Loss/seq after 00050 batchs: 514.8201904296875
INFO:root:Train (Epoch 181): Loss/seq after 00100 batchs: 491.4142761230469
INFO:root:Train (Epoch 181): Loss/seq after 00150 batchs: 461.20172119140625
INFO:root:Train (Epoch 181): Loss/seq after 00200 batchs: 512.1637573242188
INFO:root:Train (Epoch 181): Loss/seq after 00250 batchs: 569.3368530273438
INFO:root:Train (Epoch 181): Loss/seq after 00300 batchs: 584.1417236328125
INFO:root:Train (Epoch 181): Loss/seq after 00350 batchs: 552.117919921875
INFO:root:Train (Epoch 181): Loss/seq after 00400 batchs: 536.2600708007812
INFO:root:Train (Epoch 181): Loss/seq after 00450 batchs: 543.6934204101562
INFO:root:Train (Epoch 181): Loss/seq after 00500 batchs: 527.3268432617188
INFO:root:Train (Epoch 181): Loss/seq after 00550 batchs: 516.8789672851562
INFO:root:Train (Epoch 181): Loss/seq after 00600 batchs: 500.66595458984375
INFO:root:Train (Epoch 181): Loss/seq after 00650 batchs: 481.5790100097656
INFO:root:Train (Epoch 181): Loss/seq after 00700 batchs: 461.24078369140625
INFO:root:Train (Epoch 181): Loss/seq after 00750 batchs: 457.6405029296875
INFO:root:Train (Epoch 181): Loss/seq after 00800 batchs: 463.9097595214844
INFO:root:Train (Epoch 181): Loss/seq after 00850 batchs: 450.5108947753906
INFO:root:Train (Epoch 181): Loss/seq after 00900 batchs: 440.75579833984375
INFO:root:Train (Epoch 181): Loss/seq after 00950 batchs: 438.3005065917969
INFO:root:Train (Epoch 181): Loss/seq after 01000 batchs: 431.39288330078125
INFO:root:Train (Epoch 181): Loss/seq after 01050 batchs: 423.78460693359375
INFO:root:Train (Epoch 181): Loss/seq after 01100 batchs: 415.6664733886719
INFO:root:Train (Epoch 181): Loss/seq after 01150 batchs: 404.8428649902344
INFO:root:Train (Epoch 181): Loss/seq after 01200 batchs: 408.3753662109375
INFO:root:Train (Epoch 181): Loss/seq after 01250 batchs: 409.7721252441406
INFO:root:Train (Epoch 181): Loss/seq after 01300 batchs: 401.52545166015625
INFO:root:Train (Epoch 181): Loss/seq after 01350 batchs: 395.1534423828125
INFO:root:Train (Epoch 181): Loss/seq after 01400 batchs: 397.27471923828125
INFO:root:Train (Epoch 181): Loss/seq after 01450 batchs: 400.8298645019531
INFO:root:Train (Epoch 181): Loss/seq after 01500 batchs: 408.6352233886719
INFO:root:Train (Epoch 181): Loss/seq after 01550 batchs: 409.17498779296875
INFO:root:Train (Epoch 181): Loss/seq after 01600 batchs: 405.83343505859375
INFO:root:Train (Epoch 181): Loss/seq after 01650 batchs: 404.4051513671875
INFO:root:Train (Epoch 181): Loss/seq after 01700 batchs: 408.9709167480469
INFO:root:Train (Epoch 181): Loss/seq after 01750 batchs: 407.6075744628906
INFO:root:Train (Epoch 181): Loss/seq after 01800 batchs: 406.0431213378906
INFO:root:Train (Epoch 181): Loss/seq after 01850 batchs: 404.2067565917969
INFO:root:Train (Epoch 181): Loss/seq after 01900 batchs: 403.6255187988281
INFO:root:Train (Epoch 181): Loss/seq after 01950 batchs: 403.3605651855469
INFO:root:Train (Epoch 181): Loss/seq after 02000 batchs: 404.2133483886719
INFO:root:Train (Epoch 181): Loss/seq after 02050 batchs: 404.26434326171875
INFO:root:Train (Epoch 181): Loss/seq after 02100 batchs: 403.2061462402344
INFO:root:Train (Epoch 181): Loss/seq after 02150 batchs: 402.1761169433594
INFO:root:Train (Epoch 181): Loss/seq after 02200 batchs: 400.7947692871094
INFO:root:Train (Epoch 181): Loss/seq after 02250 batchs: 399.63812255859375
INFO:root:Train (Epoch 181): Loss/seq after 02300 batchs: 396.6565246582031
INFO:root:Train (Epoch 181): Loss/seq after 02350 batchs: 394.20599365234375
INFO:root:Train (Epoch 181): Loss/seq after 02400 batchs: 394.9970397949219
INFO:root:Train (Epoch 181): Loss/seq after 02450 batchs: 392.03826904296875
INFO:root:Train (Epoch 181): Loss/seq after 02500 batchs: 386.3213195800781
INFO:root:Train (Epoch 181): Loss/seq after 02550 batchs: 381.0350646972656
INFO:root:Train (Epoch 181): Loss/seq after 02600 batchs: 379.3349609375
INFO:root:Train (Epoch 181): Loss/seq after 02650 batchs: 375.63116455078125
INFO:root:Train (Epoch 181): Loss/seq after 02700 batchs: 373.3410949707031
INFO:root:Train (Epoch 181): Loss/seq after 02750 batchs: 370.0157165527344
INFO:root:Train (Epoch 181): Loss/seq after 02800 batchs: 368.0095520019531
INFO:root:Train (Epoch 181): Loss/seq after 02850 batchs: 367.765625
INFO:root:Train (Epoch 181): Loss/seq after 02900 batchs: 369.14239501953125
INFO:root:Train (Epoch 181): Loss/seq after 02950 batchs: 369.5347900390625
INFO:root:Train (Epoch 181): Loss/seq after 03000 batchs: 375.10418701171875
INFO:root:Train (Epoch 181): Loss/seq after 03050 batchs: 377.32342529296875
INFO:root:Train (Epoch 181): Loss/seq after 03100 batchs: 378.8289489746094
INFO:root:Train (Epoch 181): Loss/seq after 03150 batchs: 378.5390319824219
INFO:root:Train (Epoch 181): Loss/seq after 03200 batchs: 378.4766845703125
INFO:root:Train (Epoch 181): Loss/seq after 03250 batchs: 379.2066650390625
INFO:root:Train (Epoch 181): Loss/seq after 03300 batchs: 378.82342529296875
INFO:root:Train (Epoch 181): Loss/seq after 03350 batchs: 377.3493957519531
INFO:root:Train (Epoch 181): Loss/seq after 03400 batchs: 374.67047119140625
INFO:root:Train (Epoch 181): Loss/seq after 03450 batchs: 373.832275390625
INFO:root:Train (Epoch 181): Loss/seq after 03500 batchs: 374.6304931640625
INFO:root:Train (Epoch 181): Loss/seq after 03550 batchs: 372.6548767089844
INFO:root:Train (Epoch 181): Loss/seq after 03600 batchs: 379.1166076660156
INFO:root:Train (Epoch 181): Loss/seq after 03650 batchs: 377.72918701171875
INFO:root:Train (Epoch 181): Loss/seq after 03700 batchs: 379.91497802734375
INFO:root:Train (Epoch 181): Loss/seq after 03750 batchs: 384.1627502441406
INFO:root:Train (Epoch 181): Loss/seq after 03800 batchs: 383.4053039550781
INFO:root:Train (Epoch 181): Loss/seq after 03850 batchs: 382.6367492675781
INFO:root:Train (Epoch 181): Loss/seq after 03900 batchs: 384.3458557128906
INFO:root:Train (Epoch 181): Loss/seq after 03950 batchs: 386.67657470703125
INFO:root:Train (Epoch 181): Loss/seq after 04000 batchs: 384.34588623046875
INFO:root:Train (Epoch 181): Loss/seq after 04050 batchs: 382.0457458496094
INFO:root:Train (Epoch 181): Loss/seq after 04100 batchs: 381.4192810058594
INFO:root:Train (Epoch 181): Loss/seq after 04150 batchs: 381.58709716796875
INFO:root:Train (Epoch 181): Loss/seq after 04200 batchs: 380.8657531738281
INFO:root:Train (Epoch 181): Loss/seq after 04250 batchs: 379.5958557128906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 181): Loss/seq after 00000 batches: 352.1563415527344
INFO:root:# Valid (Epoch 181): Loss/seq after 00050 batches: 492.1966247558594
INFO:root:# Valid (Epoch 181): Loss/seq after 00100 batches: 499.3418884277344
INFO:root:# Valid (Epoch 181): Loss/seq after 00150 batches: 383.97564697265625
INFO:root:# Valid (Epoch 181): Loss/seq after 00200 batches: 363.29864501953125
INFO:root:Artifacts: Make stick videos for epoch 181
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_181_on_20220413_104609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_181_index_1808_on_20220413_104609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 182): Loss/seq after 00000 batchs: 630.0640869140625
INFO:root:Train (Epoch 182): Loss/seq after 00050 batchs: 512.1157836914062
INFO:root:Train (Epoch 182): Loss/seq after 00100 batchs: 488.9178771972656
INFO:root:Train (Epoch 182): Loss/seq after 00150 batchs: 459.8805847167969
INFO:root:Train (Epoch 182): Loss/seq after 00200 batchs: 511.15142822265625
INFO:root:Train (Epoch 182): Loss/seq after 00250 batchs: 572.7906494140625
INFO:root:Train (Epoch 182): Loss/seq after 00300 batchs: 587.2838745117188
INFO:root:Train (Epoch 182): Loss/seq after 00350 batchs: 554.3093872070312
INFO:root:Train (Epoch 182): Loss/seq after 00400 batchs: 538.9966430664062
INFO:root:Train (Epoch 182): Loss/seq after 00450 batchs: 545.9717407226562
INFO:root:Train (Epoch 182): Loss/seq after 00500 batchs: 526.9312744140625
INFO:root:Train (Epoch 182): Loss/seq after 00550 batchs: 516.3385620117188
INFO:root:Train (Epoch 182): Loss/seq after 00600 batchs: 500.7156066894531
INFO:root:Train (Epoch 182): Loss/seq after 00650 batchs: 481.0140075683594
INFO:root:Train (Epoch 182): Loss/seq after 00700 batchs: 461.681396484375
INFO:root:Train (Epoch 182): Loss/seq after 00750 batchs: 457.6697692871094
INFO:root:Train (Epoch 182): Loss/seq after 00800 batchs: 462.9333801269531
INFO:root:Train (Epoch 182): Loss/seq after 00850 batchs: 449.4185485839844
INFO:root:Train (Epoch 182): Loss/seq after 00900 batchs: 439.3647155761719
INFO:root:Train (Epoch 182): Loss/seq after 00950 batchs: 436.68597412109375
INFO:root:Train (Epoch 182): Loss/seq after 01000 batchs: 429.2593688964844
INFO:root:Train (Epoch 182): Loss/seq after 01050 batchs: 421.83734130859375
INFO:root:Train (Epoch 182): Loss/seq after 01100 batchs: 413.802734375
INFO:root:Train (Epoch 182): Loss/seq after 01150 batchs: 403.1654357910156
INFO:root:Train (Epoch 182): Loss/seq after 01200 batchs: 405.8907775878906
INFO:root:Train (Epoch 182): Loss/seq after 01250 batchs: 406.7768859863281
INFO:root:Train (Epoch 182): Loss/seq after 01300 batchs: 398.5129699707031
INFO:root:Train (Epoch 182): Loss/seq after 01350 batchs: 391.86688232421875
INFO:root:Train (Epoch 182): Loss/seq after 01400 batchs: 393.44183349609375
INFO:root:Train (Epoch 182): Loss/seq after 01450 batchs: 396.785400390625
INFO:root:Train (Epoch 182): Loss/seq after 01500 batchs: 404.185302734375
INFO:root:Train (Epoch 182): Loss/seq after 01550 batchs: 404.16717529296875
INFO:root:Train (Epoch 182): Loss/seq after 01600 batchs: 400.84796142578125
INFO:root:Train (Epoch 182): Loss/seq after 01650 batchs: 399.34991455078125
INFO:root:Train (Epoch 182): Loss/seq after 01700 batchs: 404.15533447265625
INFO:root:Train (Epoch 182): Loss/seq after 01750 batchs: 402.8023681640625
INFO:root:Train (Epoch 182): Loss/seq after 01800 batchs: 401.2890930175781
INFO:root:Train (Epoch 182): Loss/seq after 01850 batchs: 399.4947204589844
INFO:root:Train (Epoch 182): Loss/seq after 01900 batchs: 398.93524169921875
INFO:root:Train (Epoch 182): Loss/seq after 01950 batchs: 398.6966552734375
INFO:root:Train (Epoch 182): Loss/seq after 02000 batchs: 399.7651062011719
INFO:root:Train (Epoch 182): Loss/seq after 02050 batchs: 400.0391845703125
INFO:root:Train (Epoch 182): Loss/seq after 02100 batchs: 398.9845886230469
INFO:root:Train (Epoch 182): Loss/seq after 02150 batchs: 397.9168395996094
INFO:root:Train (Epoch 182): Loss/seq after 02200 batchs: 396.60693359375
INFO:root:Train (Epoch 182): Loss/seq after 02250 batchs: 395.6567077636719
INFO:root:Train (Epoch 182): Loss/seq after 02300 batchs: 392.7647399902344
INFO:root:Train (Epoch 182): Loss/seq after 02350 batchs: 390.31500244140625
INFO:root:Train (Epoch 182): Loss/seq after 02400 batchs: 391.0680236816406
INFO:root:Train (Epoch 182): Loss/seq after 02450 batchs: 388.1604309082031
INFO:root:Train (Epoch 182): Loss/seq after 02500 batchs: 382.52838134765625
INFO:root:Train (Epoch 182): Loss/seq after 02550 batchs: 377.3387451171875
INFO:root:Train (Epoch 182): Loss/seq after 02600 batchs: 375.662841796875
INFO:root:Train (Epoch 182): Loss/seq after 02650 batchs: 372.0805358886719
INFO:root:Train (Epoch 182): Loss/seq after 02700 batchs: 369.74798583984375
INFO:root:Train (Epoch 182): Loss/seq after 02750 batchs: 366.5162658691406
INFO:root:Train (Epoch 182): Loss/seq after 02800 batchs: 364.40740966796875
INFO:root:Train (Epoch 182): Loss/seq after 02850 batchs: 364.30450439453125
INFO:root:Train (Epoch 182): Loss/seq after 02900 batchs: 365.6689758300781
INFO:root:Train (Epoch 182): Loss/seq after 02950 batchs: 366.1412353515625
INFO:root:Train (Epoch 182): Loss/seq after 03000 batchs: 371.7576904296875
INFO:root:Train (Epoch 182): Loss/seq after 03050 batchs: 374.0826416015625
INFO:root:Train (Epoch 182): Loss/seq after 03100 batchs: 375.64385986328125
INFO:root:Train (Epoch 182): Loss/seq after 03150 batchs: 375.5158386230469
INFO:root:Train (Epoch 182): Loss/seq after 03200 batchs: 375.6078186035156
INFO:root:Train (Epoch 182): Loss/seq after 03250 batchs: 376.0263366699219
INFO:root:Train (Epoch 182): Loss/seq after 03300 batchs: 375.6424255371094
INFO:root:Train (Epoch 182): Loss/seq after 03350 batchs: 374.231689453125
INFO:root:Train (Epoch 182): Loss/seq after 03400 batchs: 371.5475158691406
INFO:root:Train (Epoch 182): Loss/seq after 03450 batchs: 370.7064208984375
INFO:root:Train (Epoch 182): Loss/seq after 03500 batchs: 371.81927490234375
INFO:root:Train (Epoch 182): Loss/seq after 03550 batchs: 370.1769714355469
INFO:root:Train (Epoch 182): Loss/seq after 03600 batchs: 376.7439270019531
INFO:root:Train (Epoch 182): Loss/seq after 03650 batchs: 375.3501892089844
INFO:root:Train (Epoch 182): Loss/seq after 03700 batchs: 377.73541259765625
INFO:root:Train (Epoch 182): Loss/seq after 03750 batchs: 381.984130859375
INFO:root:Train (Epoch 182): Loss/seq after 03800 batchs: 381.2441711425781
INFO:root:Train (Epoch 182): Loss/seq after 03850 batchs: 380.59149169921875
INFO:root:Train (Epoch 182): Loss/seq after 03900 batchs: 381.98858642578125
INFO:root:Train (Epoch 182): Loss/seq after 03950 batchs: 384.42669677734375
INFO:root:Train (Epoch 182): Loss/seq after 04000 batchs: 382.0857238769531
INFO:root:Train (Epoch 182): Loss/seq after 04050 batchs: 379.8288879394531
INFO:root:Train (Epoch 182): Loss/seq after 04100 batchs: 379.2409362792969
INFO:root:Train (Epoch 182): Loss/seq after 04150 batchs: 379.37677001953125
INFO:root:Train (Epoch 182): Loss/seq after 04200 batchs: 378.5968933105469
INFO:root:Train (Epoch 182): Loss/seq after 04250 batchs: 377.3514404296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 182): Loss/seq after 00000 batches: 334.360595703125
INFO:root:# Valid (Epoch 182): Loss/seq after 00050 batches: 488.91253662109375
INFO:root:# Valid (Epoch 182): Loss/seq after 00100 batches: 511.3966064453125
INFO:root:# Valid (Epoch 182): Loss/seq after 00150 batches: 394.0796813964844
INFO:root:# Valid (Epoch 182): Loss/seq after 00200 batches: 373.65765380859375
INFO:root:Artifacts: Make stick videos for epoch 182
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_182_on_20220413_105133.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_182_index_1606_on_20220413_105133.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 183): Loss/seq after 00000 batchs: 646.576171875
INFO:root:Train (Epoch 183): Loss/seq after 00050 batchs: 508.8408508300781
INFO:root:Train (Epoch 183): Loss/seq after 00100 batchs: 486.8846130371094
INFO:root:Train (Epoch 183): Loss/seq after 00150 batchs: 457.70965576171875
INFO:root:Train (Epoch 183): Loss/seq after 00200 batchs: 507.46612548828125
INFO:root:Train (Epoch 183): Loss/seq after 00250 batchs: 572.0411376953125
INFO:root:Train (Epoch 183): Loss/seq after 00300 batchs: 585.3261108398438
INFO:root:Train (Epoch 183): Loss/seq after 00350 batchs: 552.8632202148438
INFO:root:Train (Epoch 183): Loss/seq after 00400 batchs: 536.5748291015625
INFO:root:Train (Epoch 183): Loss/seq after 00450 batchs: 543.481201171875
INFO:root:Train (Epoch 183): Loss/seq after 00500 batchs: 525.1604614257812
INFO:root:Train (Epoch 183): Loss/seq after 00550 batchs: 514.6381225585938
INFO:root:Train (Epoch 183): Loss/seq after 00600 batchs: 498.22601318359375
INFO:root:Train (Epoch 183): Loss/seq after 00650 batchs: 479.5439758300781
INFO:root:Train (Epoch 183): Loss/seq after 00700 batchs: 459.3517761230469
INFO:root:Train (Epoch 183): Loss/seq after 00750 batchs: 455.4239196777344
INFO:root:Train (Epoch 183): Loss/seq after 00800 batchs: 460.0909423828125
INFO:root:Train (Epoch 183): Loss/seq after 00850 batchs: 446.3470153808594
INFO:root:Train (Epoch 183): Loss/seq after 00900 batchs: 435.97332763671875
INFO:root:Train (Epoch 183): Loss/seq after 00950 batchs: 433.2061462402344
INFO:root:Train (Epoch 183): Loss/seq after 01000 batchs: 425.8974609375
INFO:root:Train (Epoch 183): Loss/seq after 01050 batchs: 418.777587890625
INFO:root:Train (Epoch 183): Loss/seq after 01100 batchs: 410.6708984375
INFO:root:Train (Epoch 183): Loss/seq after 01150 batchs: 399.97808837890625
INFO:root:Train (Epoch 183): Loss/seq after 01200 batchs: 403.7362976074219
INFO:root:Train (Epoch 183): Loss/seq after 01250 batchs: 405.0514831542969
INFO:root:Train (Epoch 183): Loss/seq after 01300 batchs: 396.6286315917969
INFO:root:Train (Epoch 183): Loss/seq after 01350 batchs: 390.1129150390625
INFO:root:Train (Epoch 183): Loss/seq after 01400 batchs: 391.78497314453125
INFO:root:Train (Epoch 183): Loss/seq after 01450 batchs: 394.9206237792969
INFO:root:Train (Epoch 183): Loss/seq after 01500 batchs: 402.5884094238281
INFO:root:Train (Epoch 183): Loss/seq after 01550 batchs: 402.8013916015625
INFO:root:Train (Epoch 183): Loss/seq after 01600 batchs: 399.7402648925781
INFO:root:Train (Epoch 183): Loss/seq after 01650 batchs: 398.3506164550781
INFO:root:Train (Epoch 183): Loss/seq after 01700 batchs: 402.9449157714844
INFO:root:Train (Epoch 183): Loss/seq after 01750 batchs: 401.67913818359375
INFO:root:Train (Epoch 183): Loss/seq after 01800 batchs: 400.0328369140625
INFO:root:Train (Epoch 183): Loss/seq after 01850 batchs: 398.3096618652344
INFO:root:Train (Epoch 183): Loss/seq after 01900 batchs: 397.6555480957031
INFO:root:Train (Epoch 183): Loss/seq after 01950 batchs: 397.0207214355469
INFO:root:Train (Epoch 183): Loss/seq after 02000 batchs: 398.0334167480469
INFO:root:Train (Epoch 183): Loss/seq after 02050 batchs: 398.2390441894531
INFO:root:Train (Epoch 183): Loss/seq after 02100 batchs: 397.1307067871094
INFO:root:Train (Epoch 183): Loss/seq after 02150 batchs: 396.09765625
INFO:root:Train (Epoch 183): Loss/seq after 02200 batchs: 394.7806091308594
INFO:root:Train (Epoch 183): Loss/seq after 02250 batchs: 393.7574768066406
INFO:root:Train (Epoch 183): Loss/seq after 02300 batchs: 390.80865478515625
INFO:root:Train (Epoch 183): Loss/seq after 02350 batchs: 388.3548583984375
INFO:root:Train (Epoch 183): Loss/seq after 02400 batchs: 389.17596435546875
INFO:root:Train (Epoch 183): Loss/seq after 02450 batchs: 386.19390869140625
INFO:root:Train (Epoch 183): Loss/seq after 02500 batchs: 380.56146240234375
INFO:root:Train (Epoch 183): Loss/seq after 02550 batchs: 375.3931579589844
INFO:root:Train (Epoch 183): Loss/seq after 02600 batchs: 373.6024475097656
INFO:root:Train (Epoch 183): Loss/seq after 02650 batchs: 369.9661560058594
INFO:root:Train (Epoch 183): Loss/seq after 02700 batchs: 367.5723876953125
INFO:root:Train (Epoch 183): Loss/seq after 02750 batchs: 364.34002685546875
INFO:root:Train (Epoch 183): Loss/seq after 02800 batchs: 362.2472839355469
INFO:root:Train (Epoch 183): Loss/seq after 02850 batchs: 361.9328918457031
INFO:root:Train (Epoch 183): Loss/seq after 02900 batchs: 363.17596435546875
INFO:root:Train (Epoch 183): Loss/seq after 02950 batchs: 363.5823059082031
INFO:root:Train (Epoch 183): Loss/seq after 03000 batchs: 369.14251708984375
INFO:root:Train (Epoch 183): Loss/seq after 03050 batchs: 371.5455017089844
INFO:root:Train (Epoch 183): Loss/seq after 03100 batchs: 373.16510009765625
INFO:root:Train (Epoch 183): Loss/seq after 03150 batchs: 372.89385986328125
INFO:root:Train (Epoch 183): Loss/seq after 03200 batchs: 372.5513610839844
INFO:root:Train (Epoch 183): Loss/seq after 03250 batchs: 372.9668884277344
INFO:root:Train (Epoch 183): Loss/seq after 03300 batchs: 372.6515808105469
INFO:root:Train (Epoch 183): Loss/seq after 03350 batchs: 371.1610107421875
INFO:root:Train (Epoch 183): Loss/seq after 03400 batchs: 368.51458740234375
INFO:root:Train (Epoch 183): Loss/seq after 03450 batchs: 367.6303405761719
INFO:root:Train (Epoch 183): Loss/seq after 03500 batchs: 368.528076171875
INFO:root:Train (Epoch 183): Loss/seq after 03550 batchs: 366.6419677734375
INFO:root:Train (Epoch 183): Loss/seq after 03600 batchs: 372.9717712402344
INFO:root:Train (Epoch 183): Loss/seq after 03650 batchs: 371.7208557128906
INFO:root:Train (Epoch 183): Loss/seq after 03700 batchs: 373.9382629394531
INFO:root:Train (Epoch 183): Loss/seq after 03750 batchs: 378.20526123046875
INFO:root:Train (Epoch 183): Loss/seq after 03800 batchs: 377.5091247558594
INFO:root:Train (Epoch 183): Loss/seq after 03850 batchs: 376.7933044433594
INFO:root:Train (Epoch 183): Loss/seq after 03900 batchs: 378.43511962890625
INFO:root:Train (Epoch 183): Loss/seq after 03950 batchs: 380.7778625488281
INFO:root:Train (Epoch 183): Loss/seq after 04000 batchs: 378.49261474609375
INFO:root:Train (Epoch 183): Loss/seq after 04050 batchs: 376.25421142578125
INFO:root:Train (Epoch 183): Loss/seq after 04100 batchs: 375.6156005859375
INFO:root:Train (Epoch 183): Loss/seq after 04150 batchs: 375.82061767578125
INFO:root:Train (Epoch 183): Loss/seq after 04200 batchs: 375.0800476074219
INFO:root:Train (Epoch 183): Loss/seq after 04250 batchs: 373.8503112792969
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 183): Loss/seq after 00000 batches: 325.78302001953125
INFO:root:# Valid (Epoch 183): Loss/seq after 00050 batches: 481.9765319824219
INFO:root:# Valid (Epoch 183): Loss/seq after 00100 batches: 496.0101013183594
INFO:root:# Valid (Epoch 183): Loss/seq after 00150 batches: 379.7242736816406
INFO:root:# Valid (Epoch 183): Loss/seq after 00200 batches: 359.9572448730469
INFO:root:Artifacts: Make stick videos for epoch 183
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_183_on_20220413_105655.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_183_index_1259_on_20220413_105655.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 184): Loss/seq after 00000 batchs: 606.9254150390625
INFO:root:Train (Epoch 184): Loss/seq after 00050 batchs: 508.9359436035156
INFO:root:Train (Epoch 184): Loss/seq after 00100 batchs: 485.37432861328125
INFO:root:Train (Epoch 184): Loss/seq after 00150 batchs: 456.32208251953125
INFO:root:Train (Epoch 184): Loss/seq after 00200 batchs: 500.8197326660156
INFO:root:Train (Epoch 184): Loss/seq after 00250 batchs: 556.9733276367188
INFO:root:Train (Epoch 184): Loss/seq after 00300 batchs: 571.7537841796875
INFO:root:Train (Epoch 184): Loss/seq after 00350 batchs: 540.3627319335938
INFO:root:Train (Epoch 184): Loss/seq after 00400 batchs: 524.1559448242188
INFO:root:Train (Epoch 184): Loss/seq after 00450 batchs: 532.3052368164062
INFO:root:Train (Epoch 184): Loss/seq after 00500 batchs: 513.9959106445312
INFO:root:Train (Epoch 184): Loss/seq after 00550 batchs: 504.3611145019531
INFO:root:Train (Epoch 184): Loss/seq after 00600 batchs: 489.1464538574219
INFO:root:Train (Epoch 184): Loss/seq after 00650 batchs: 470.2439880371094
INFO:root:Train (Epoch 184): Loss/seq after 00700 batchs: 450.3974914550781
INFO:root:Train (Epoch 184): Loss/seq after 00750 batchs: 445.9402160644531
INFO:root:Train (Epoch 184): Loss/seq after 00800 batchs: 451.37884521484375
INFO:root:Train (Epoch 184): Loss/seq after 00850 batchs: 437.9808654785156
INFO:root:Train (Epoch 184): Loss/seq after 00900 batchs: 428.2901306152344
INFO:root:Train (Epoch 184): Loss/seq after 00950 batchs: 426.60491943359375
INFO:root:Train (Epoch 184): Loss/seq after 01000 batchs: 419.4449462890625
INFO:root:Train (Epoch 184): Loss/seq after 01050 batchs: 412.4613037109375
INFO:root:Train (Epoch 184): Loss/seq after 01100 batchs: 404.6336669921875
INFO:root:Train (Epoch 184): Loss/seq after 01150 batchs: 393.9418640136719
INFO:root:Train (Epoch 184): Loss/seq after 01200 batchs: 396.9725341796875
INFO:root:Train (Epoch 184): Loss/seq after 01250 batchs: 398.0584411621094
INFO:root:Train (Epoch 184): Loss/seq after 01300 batchs: 390.04852294921875
INFO:root:Train (Epoch 184): Loss/seq after 01350 batchs: 383.9363098144531
INFO:root:Train (Epoch 184): Loss/seq after 01400 batchs: 385.677978515625
INFO:root:Train (Epoch 184): Loss/seq after 01450 batchs: 389.1078186035156
INFO:root:Train (Epoch 184): Loss/seq after 01500 batchs: 396.95758056640625
INFO:root:Train (Epoch 184): Loss/seq after 01550 batchs: 397.45062255859375
INFO:root:Train (Epoch 184): Loss/seq after 01600 batchs: 394.6964416503906
INFO:root:Train (Epoch 184): Loss/seq after 01650 batchs: 393.14239501953125
INFO:root:Train (Epoch 184): Loss/seq after 01700 batchs: 397.90582275390625
INFO:root:Train (Epoch 184): Loss/seq after 01750 batchs: 396.55877685546875
INFO:root:Train (Epoch 184): Loss/seq after 01800 batchs: 394.9533386230469
INFO:root:Train (Epoch 184): Loss/seq after 01850 batchs: 393.2397766113281
INFO:root:Train (Epoch 184): Loss/seq after 01900 batchs: 392.72479248046875
INFO:root:Train (Epoch 184): Loss/seq after 01950 batchs: 392.3734130859375
INFO:root:Train (Epoch 184): Loss/seq after 02000 batchs: 393.4764709472656
INFO:root:Train (Epoch 184): Loss/seq after 02050 batchs: 393.8274230957031
INFO:root:Train (Epoch 184): Loss/seq after 02100 batchs: 392.8653869628906
INFO:root:Train (Epoch 184): Loss/seq after 02150 batchs: 392.0231018066406
INFO:root:Train (Epoch 184): Loss/seq after 02200 batchs: 390.86895751953125
INFO:root:Train (Epoch 184): Loss/seq after 02250 batchs: 389.6690368652344
INFO:root:Train (Epoch 184): Loss/seq after 02300 batchs: 386.6689147949219
INFO:root:Train (Epoch 184): Loss/seq after 02350 batchs: 384.3973083496094
INFO:root:Train (Epoch 184): Loss/seq after 02400 batchs: 385.280029296875
INFO:root:Train (Epoch 184): Loss/seq after 02450 batchs: 382.4624328613281
INFO:root:Train (Epoch 184): Loss/seq after 02500 batchs: 376.890869140625
INFO:root:Train (Epoch 184): Loss/seq after 02550 batchs: 371.69671630859375
INFO:root:Train (Epoch 184): Loss/seq after 02600 batchs: 369.9330749511719
INFO:root:Train (Epoch 184): Loss/seq after 02650 batchs: 366.3352355957031
INFO:root:Train (Epoch 184): Loss/seq after 02700 batchs: 363.9460144042969
INFO:root:Train (Epoch 184): Loss/seq after 02750 batchs: 360.8006286621094
INFO:root:Train (Epoch 184): Loss/seq after 02800 batchs: 358.9250183105469
INFO:root:Train (Epoch 184): Loss/seq after 02850 batchs: 358.7181091308594
INFO:root:Train (Epoch 184): Loss/seq after 02900 batchs: 359.95489501953125
INFO:root:Train (Epoch 184): Loss/seq after 02950 batchs: 360.3987731933594
INFO:root:Train (Epoch 184): Loss/seq after 03000 batchs: 366.0389709472656
INFO:root:Train (Epoch 184): Loss/seq after 03050 batchs: 368.44818115234375
INFO:root:Train (Epoch 184): Loss/seq after 03100 batchs: 369.9427795410156
INFO:root:Train (Epoch 184): Loss/seq after 03150 batchs: 369.87493896484375
INFO:root:Train (Epoch 184): Loss/seq after 03200 batchs: 369.6376037597656
INFO:root:Train (Epoch 184): Loss/seq after 03250 batchs: 370.3978271484375
INFO:root:Train (Epoch 184): Loss/seq after 03300 batchs: 370.1764831542969
INFO:root:Train (Epoch 184): Loss/seq after 03350 batchs: 368.97454833984375
INFO:root:Train (Epoch 184): Loss/seq after 03400 batchs: 366.3974914550781
INFO:root:Train (Epoch 184): Loss/seq after 03450 batchs: 365.5423278808594
INFO:root:Train (Epoch 184): Loss/seq after 03500 batchs: 366.60302734375
INFO:root:Train (Epoch 184): Loss/seq after 03550 batchs: 364.8155517578125
INFO:root:Train (Epoch 184): Loss/seq after 03600 batchs: 371.1937561035156
INFO:root:Train (Epoch 184): Loss/seq after 03650 batchs: 369.96099853515625
INFO:root:Train (Epoch 184): Loss/seq after 03700 batchs: 372.1224060058594
INFO:root:Train (Epoch 184): Loss/seq after 03750 batchs: 376.2956237792969
INFO:root:Train (Epoch 184): Loss/seq after 03800 batchs: 375.6180114746094
INFO:root:Train (Epoch 184): Loss/seq after 03850 batchs: 374.97705078125
INFO:root:Train (Epoch 184): Loss/seq after 03900 batchs: 376.684326171875
INFO:root:Train (Epoch 184): Loss/seq after 03950 batchs: 378.90924072265625
INFO:root:Train (Epoch 184): Loss/seq after 04000 batchs: 376.6522521972656
INFO:root:Train (Epoch 184): Loss/seq after 04050 batchs: 374.4373779296875
INFO:root:Train (Epoch 184): Loss/seq after 04100 batchs: 373.834716796875
INFO:root:Train (Epoch 184): Loss/seq after 04150 batchs: 373.95867919921875
INFO:root:Train (Epoch 184): Loss/seq after 04200 batchs: 373.0989074707031
INFO:root:Train (Epoch 184): Loss/seq after 04250 batchs: 371.8441162109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 184): Loss/seq after 00000 batches: 300.6811218261719
INFO:root:# Valid (Epoch 184): Loss/seq after 00050 batches: 480.87176513671875
INFO:root:# Valid (Epoch 184): Loss/seq after 00100 batches: 500.6659851074219
INFO:root:# Valid (Epoch 184): Loss/seq after 00150 batches: 385.8525695800781
INFO:root:# Valid (Epoch 184): Loss/seq after 00200 batches: 365.65216064453125
INFO:root:Artifacts: Make stick videos for epoch 184
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_184_on_20220413_110218.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_184_index_399_on_20220413_110218.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 185): Loss/seq after 00000 batchs: 524.7999877929688
INFO:root:Train (Epoch 185): Loss/seq after 00050 batchs: 498.09869384765625
INFO:root:Train (Epoch 185): Loss/seq after 00100 batchs: 477.01220703125
INFO:root:Train (Epoch 185): Loss/seq after 00150 batchs: 450.0331726074219
INFO:root:Train (Epoch 185): Loss/seq after 00200 batchs: 498.69134521484375
INFO:root:Train (Epoch 185): Loss/seq after 00250 batchs: 558.0955200195312
INFO:root:Train (Epoch 185): Loss/seq after 00300 batchs: 574.9275512695312
INFO:root:Train (Epoch 185): Loss/seq after 00350 batchs: 542.6512451171875
INFO:root:Train (Epoch 185): Loss/seq after 00400 batchs: 525.7124633789062
INFO:root:Train (Epoch 185): Loss/seq after 00450 batchs: 533.36279296875
INFO:root:Train (Epoch 185): Loss/seq after 00500 batchs: 516.5609741210938
INFO:root:Train (Epoch 185): Loss/seq after 00550 batchs: 507.2655334472656
INFO:root:Train (Epoch 185): Loss/seq after 00600 batchs: 491.6182861328125
INFO:root:Train (Epoch 185): Loss/seq after 00650 batchs: 472.9254455566406
INFO:root:Train (Epoch 185): Loss/seq after 00700 batchs: 453.46832275390625
INFO:root:Train (Epoch 185): Loss/seq after 00750 batchs: 449.09552001953125
INFO:root:Train (Epoch 185): Loss/seq after 00800 batchs: 453.80804443359375
INFO:root:Train (Epoch 185): Loss/seq after 00850 batchs: 440.7548828125
INFO:root:Train (Epoch 185): Loss/seq after 00900 batchs: 431.2047424316406
INFO:root:Train (Epoch 185): Loss/seq after 00950 batchs: 428.7871398925781
INFO:root:Train (Epoch 185): Loss/seq after 01000 batchs: 421.6503601074219
INFO:root:Train (Epoch 185): Loss/seq after 01050 batchs: 415.28326416015625
INFO:root:Train (Epoch 185): Loss/seq after 01100 batchs: 408.14837646484375
INFO:root:Train (Epoch 185): Loss/seq after 01150 batchs: 397.7809753417969
INFO:root:Train (Epoch 185): Loss/seq after 01200 batchs: 400.33984375
INFO:root:Train (Epoch 185): Loss/seq after 01250 batchs: 401.5716247558594
INFO:root:Train (Epoch 185): Loss/seq after 01300 batchs: 393.68817138671875
INFO:root:Train (Epoch 185): Loss/seq after 01350 batchs: 387.2581481933594
INFO:root:Train (Epoch 185): Loss/seq after 01400 batchs: 389.23724365234375
INFO:root:Train (Epoch 185): Loss/seq after 01450 batchs: 392.53936767578125
INFO:root:Train (Epoch 185): Loss/seq after 01500 batchs: 400.1721496582031
INFO:root:Train (Epoch 185): Loss/seq after 01550 batchs: 400.3200378417969
INFO:root:Train (Epoch 185): Loss/seq after 01600 batchs: 397.11761474609375
INFO:root:Train (Epoch 185): Loss/seq after 01650 batchs: 395.5354919433594
INFO:root:Train (Epoch 185): Loss/seq after 01700 batchs: 400.1477966308594
INFO:root:Train (Epoch 185): Loss/seq after 01750 batchs: 398.7500915527344
INFO:root:Train (Epoch 185): Loss/seq after 01800 batchs: 397.0274658203125
INFO:root:Train (Epoch 185): Loss/seq after 01850 batchs: 395.3341064453125
INFO:root:Train (Epoch 185): Loss/seq after 01900 batchs: 394.8188781738281
INFO:root:Train (Epoch 185): Loss/seq after 01950 batchs: 394.33587646484375
INFO:root:Train (Epoch 185): Loss/seq after 02000 batchs: 395.43829345703125
INFO:root:Train (Epoch 185): Loss/seq after 02050 batchs: 395.5569763183594
INFO:root:Train (Epoch 185): Loss/seq after 02100 batchs: 394.4231872558594
INFO:root:Train (Epoch 185): Loss/seq after 02150 batchs: 393.5354309082031
INFO:root:Train (Epoch 185): Loss/seq after 02200 batchs: 392.137939453125
INFO:root:Train (Epoch 185): Loss/seq after 02250 batchs: 391.0419616699219
INFO:root:Train (Epoch 185): Loss/seq after 02300 batchs: 388.1837463378906
INFO:root:Train (Epoch 185): Loss/seq after 02350 batchs: 386.02484130859375
INFO:root:Train (Epoch 185): Loss/seq after 02400 batchs: 386.7630920410156
INFO:root:Train (Epoch 185): Loss/seq after 02450 batchs: 383.86810302734375
INFO:root:Train (Epoch 185): Loss/seq after 02500 batchs: 378.2170715332031
INFO:root:Train (Epoch 185): Loss/seq after 02550 batchs: 373.089599609375
INFO:root:Train (Epoch 185): Loss/seq after 02600 batchs: 371.33953857421875
INFO:root:Train (Epoch 185): Loss/seq after 02650 batchs: 367.6690368652344
INFO:root:Train (Epoch 185): Loss/seq after 02700 batchs: 365.33575439453125
INFO:root:Train (Epoch 185): Loss/seq after 02750 batchs: 362.1888732910156
INFO:root:Train (Epoch 185): Loss/seq after 02800 batchs: 360.35272216796875
INFO:root:Train (Epoch 185): Loss/seq after 02850 batchs: 360.08404541015625
INFO:root:Train (Epoch 185): Loss/seq after 02900 batchs: 361.52734375
INFO:root:Train (Epoch 185): Loss/seq after 02950 batchs: 361.97662353515625
INFO:root:Train (Epoch 185): Loss/seq after 03000 batchs: 367.6104431152344
INFO:root:Train (Epoch 185): Loss/seq after 03050 batchs: 369.9366760253906
INFO:root:Train (Epoch 185): Loss/seq after 03100 batchs: 371.5978698730469
INFO:root:Train (Epoch 185): Loss/seq after 03150 batchs: 371.2153625488281
INFO:root:Train (Epoch 185): Loss/seq after 03200 batchs: 370.9250793457031
INFO:root:Train (Epoch 185): Loss/seq after 03250 batchs: 371.6212158203125
INFO:root:Train (Epoch 185): Loss/seq after 03300 batchs: 371.4271545410156
INFO:root:Train (Epoch 185): Loss/seq after 03350 batchs: 370.1573181152344
INFO:root:Train (Epoch 185): Loss/seq after 03400 batchs: 367.5874328613281
INFO:root:Train (Epoch 185): Loss/seq after 03450 batchs: 366.7032470703125
INFO:root:Train (Epoch 185): Loss/seq after 03500 batchs: 367.4754638671875
INFO:root:Train (Epoch 185): Loss/seq after 03550 batchs: 365.5412292480469
INFO:root:Train (Epoch 185): Loss/seq after 03600 batchs: 372.00933837890625
INFO:root:Train (Epoch 185): Loss/seq after 03650 batchs: 370.73345947265625
INFO:root:Train (Epoch 185): Loss/seq after 03700 batchs: 373.0015563964844
INFO:root:Train (Epoch 185): Loss/seq after 03750 batchs: 377.2882385253906
INFO:root:Train (Epoch 185): Loss/seq after 03800 batchs: 376.6658020019531
INFO:root:Train (Epoch 185): Loss/seq after 03850 batchs: 375.9456481933594
INFO:root:Train (Epoch 185): Loss/seq after 03900 batchs: 377.6689147949219
INFO:root:Train (Epoch 185): Loss/seq after 03950 batchs: 379.8875732421875
INFO:root:Train (Epoch 185): Loss/seq after 04000 batchs: 377.6202697753906
INFO:root:Train (Epoch 185): Loss/seq after 04050 batchs: 375.4066162109375
INFO:root:Train (Epoch 185): Loss/seq after 04100 batchs: 374.762939453125
INFO:root:Train (Epoch 185): Loss/seq after 04150 batchs: 374.8404541015625
INFO:root:Train (Epoch 185): Loss/seq after 04200 batchs: 374.0066833496094
INFO:root:Train (Epoch 185): Loss/seq after 04250 batchs: 372.7434387207031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 185): Loss/seq after 00000 batches: 297.1969299316406
INFO:root:# Valid (Epoch 185): Loss/seq after 00050 batches: 461.3531799316406
INFO:root:# Valid (Epoch 185): Loss/seq after 00100 batches: 466.7109375
INFO:root:# Valid (Epoch 185): Loss/seq after 00150 batches: 360.6221008300781
INFO:root:# Valid (Epoch 185): Loss/seq after 00200 batches: 343.6442565917969
INFO:root:Artifacts: Make stick videos for epoch 185
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_185_on_20220413_110741.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_185_index_49_on_20220413_110741.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 186): Loss/seq after 00000 batchs: 675.30419921875
INFO:root:Train (Epoch 186): Loss/seq after 00050 batchs: 495.842041015625
INFO:root:Train (Epoch 186): Loss/seq after 00100 batchs: 481.51641845703125
INFO:root:Train (Epoch 186): Loss/seq after 00150 batchs: 457.44805908203125
INFO:root:Train (Epoch 186): Loss/seq after 00200 batchs: 505.0812683105469
INFO:root:Train (Epoch 186): Loss/seq after 00250 batchs: 557.8472290039062
INFO:root:Train (Epoch 186): Loss/seq after 00300 batchs: 573.7891235351562
INFO:root:Train (Epoch 186): Loss/seq after 00350 batchs: 542.2025146484375
INFO:root:Train (Epoch 186): Loss/seq after 00400 batchs: 526.0136108398438
INFO:root:Train (Epoch 186): Loss/seq after 00450 batchs: 533.4805297851562
INFO:root:Train (Epoch 186): Loss/seq after 00500 batchs: 516.201416015625
INFO:root:Train (Epoch 186): Loss/seq after 00550 batchs: 506.6431579589844
INFO:root:Train (Epoch 186): Loss/seq after 00600 batchs: 490.8508605957031
INFO:root:Train (Epoch 186): Loss/seq after 00650 batchs: 472.4108581542969
INFO:root:Train (Epoch 186): Loss/seq after 00700 batchs: 453.6785888671875
INFO:root:Train (Epoch 186): Loss/seq after 00750 batchs: 449.41180419921875
INFO:root:Train (Epoch 186): Loss/seq after 00800 batchs: 454.7125244140625
INFO:root:Train (Epoch 186): Loss/seq after 00850 batchs: 441.1589660644531
INFO:root:Train (Epoch 186): Loss/seq after 00900 batchs: 431.1238098144531
INFO:root:Train (Epoch 186): Loss/seq after 00950 batchs: 428.21087646484375
INFO:root:Train (Epoch 186): Loss/seq after 01000 batchs: 421.16058349609375
INFO:root:Train (Epoch 186): Loss/seq after 01050 batchs: 414.1315002441406
INFO:root:Train (Epoch 186): Loss/seq after 01100 batchs: 406.2519226074219
INFO:root:Train (Epoch 186): Loss/seq after 01150 batchs: 395.5140075683594
INFO:root:Train (Epoch 186): Loss/seq after 01200 batchs: 398.7695007324219
INFO:root:Train (Epoch 186): Loss/seq after 01250 batchs: 399.60894775390625
INFO:root:Train (Epoch 186): Loss/seq after 01300 batchs: 391.33697509765625
INFO:root:Train (Epoch 186): Loss/seq after 01350 batchs: 384.85662841796875
INFO:root:Train (Epoch 186): Loss/seq after 01400 batchs: 386.44342041015625
INFO:root:Train (Epoch 186): Loss/seq after 01450 batchs: 389.8331298828125
INFO:root:Train (Epoch 186): Loss/seq after 01500 batchs: 397.7837829589844
INFO:root:Train (Epoch 186): Loss/seq after 01550 batchs: 397.9374084472656
INFO:root:Train (Epoch 186): Loss/seq after 01600 batchs: 394.8251647949219
INFO:root:Train (Epoch 186): Loss/seq after 01650 batchs: 393.242919921875
INFO:root:Train (Epoch 186): Loss/seq after 01700 batchs: 397.79583740234375
INFO:root:Train (Epoch 186): Loss/seq after 01750 batchs: 396.4576110839844
INFO:root:Train (Epoch 186): Loss/seq after 01800 batchs: 395.0572509765625
INFO:root:Train (Epoch 186): Loss/seq after 01850 batchs: 393.24664306640625
INFO:root:Train (Epoch 186): Loss/seq after 01900 batchs: 392.7019348144531
INFO:root:Train (Epoch 186): Loss/seq after 01950 batchs: 392.0860290527344
INFO:root:Train (Epoch 186): Loss/seq after 02000 batchs: 393.10498046875
INFO:root:Train (Epoch 186): Loss/seq after 02050 batchs: 393.38385009765625
INFO:root:Train (Epoch 186): Loss/seq after 02100 batchs: 392.2789001464844
INFO:root:Train (Epoch 186): Loss/seq after 02150 batchs: 391.36273193359375
INFO:root:Train (Epoch 186): Loss/seq after 02200 batchs: 390.1318054199219
INFO:root:Train (Epoch 186): Loss/seq after 02250 batchs: 389.1073913574219
INFO:root:Train (Epoch 186): Loss/seq after 02300 batchs: 386.31170654296875
INFO:root:Train (Epoch 186): Loss/seq after 02350 batchs: 383.9686279296875
INFO:root:Train (Epoch 186): Loss/seq after 02400 batchs: 384.7723083496094
INFO:root:Train (Epoch 186): Loss/seq after 02450 batchs: 381.8707275390625
INFO:root:Train (Epoch 186): Loss/seq after 02500 batchs: 376.27386474609375
INFO:root:Train (Epoch 186): Loss/seq after 02550 batchs: 371.1006774902344
INFO:root:Train (Epoch 186): Loss/seq after 02600 batchs: 369.20465087890625
INFO:root:Train (Epoch 186): Loss/seq after 02650 batchs: 365.5336608886719
INFO:root:Train (Epoch 186): Loss/seq after 02700 batchs: 363.2030334472656
INFO:root:Train (Epoch 186): Loss/seq after 02750 batchs: 359.9878234863281
INFO:root:Train (Epoch 186): Loss/seq after 02800 batchs: 358.1496276855469
INFO:root:Train (Epoch 186): Loss/seq after 02850 batchs: 357.95660400390625
INFO:root:Train (Epoch 186): Loss/seq after 02900 batchs: 359.3646545410156
INFO:root:Train (Epoch 186): Loss/seq after 02950 batchs: 359.85064697265625
INFO:root:Train (Epoch 186): Loss/seq after 03000 batchs: 365.4789733886719
INFO:root:Train (Epoch 186): Loss/seq after 03050 batchs: 367.9686584472656
INFO:root:Train (Epoch 186): Loss/seq after 03100 batchs: 369.5242614746094
INFO:root:Train (Epoch 186): Loss/seq after 03150 batchs: 369.181884765625
INFO:root:Train (Epoch 186): Loss/seq after 03200 batchs: 369.0864562988281
INFO:root:Train (Epoch 186): Loss/seq after 03250 batchs: 369.5209045410156
INFO:root:Train (Epoch 186): Loss/seq after 03300 batchs: 368.87115478515625
INFO:root:Train (Epoch 186): Loss/seq after 03350 batchs: 367.4011535644531
INFO:root:Train (Epoch 186): Loss/seq after 03400 batchs: 364.8266296386719
INFO:root:Train (Epoch 186): Loss/seq after 03450 batchs: 363.8704528808594
INFO:root:Train (Epoch 186): Loss/seq after 03500 batchs: 364.78680419921875
INFO:root:Train (Epoch 186): Loss/seq after 03550 batchs: 362.8398742675781
INFO:root:Train (Epoch 186): Loss/seq after 03600 batchs: 369.0688781738281
INFO:root:Train (Epoch 186): Loss/seq after 03650 batchs: 367.7073669433594
INFO:root:Train (Epoch 186): Loss/seq after 03700 batchs: 369.999267578125
INFO:root:Train (Epoch 186): Loss/seq after 03750 batchs: 374.3295593261719
INFO:root:Train (Epoch 186): Loss/seq after 03800 batchs: 373.6634521484375
INFO:root:Train (Epoch 186): Loss/seq after 03850 batchs: 372.96148681640625
INFO:root:Train (Epoch 186): Loss/seq after 03900 batchs: 374.6102294921875
INFO:root:Train (Epoch 186): Loss/seq after 03950 batchs: 376.76959228515625
INFO:root:Train (Epoch 186): Loss/seq after 04000 batchs: 374.5179138183594
INFO:root:Train (Epoch 186): Loss/seq after 04050 batchs: 372.3117980957031
INFO:root:Train (Epoch 186): Loss/seq after 04100 batchs: 371.71966552734375
INFO:root:Train (Epoch 186): Loss/seq after 04150 batchs: 371.8513488769531
INFO:root:Train (Epoch 186): Loss/seq after 04200 batchs: 371.0633544921875
INFO:root:Train (Epoch 186): Loss/seq after 04250 batchs: 369.8675842285156
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 186): Loss/seq after 00000 batches: 321.6896667480469
INFO:root:# Valid (Epoch 186): Loss/seq after 00050 batches: 501.5582580566406
INFO:root:# Valid (Epoch 186): Loss/seq after 00100 batches: 499.3521728515625
INFO:root:# Valid (Epoch 186): Loss/seq after 00150 batches: 386.412109375
INFO:root:# Valid (Epoch 186): Loss/seq after 00200 batches: 370.69708251953125
INFO:root:Artifacts: Make stick videos for epoch 186
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_186_on_20220413_111301.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_186_index_1774_on_20220413_111301.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 187): Loss/seq after 00000 batchs: 631.957763671875
INFO:root:Train (Epoch 187): Loss/seq after 00050 batchs: 497.1744689941406
INFO:root:Train (Epoch 187): Loss/seq after 00100 batchs: 478.41876220703125
INFO:root:Train (Epoch 187): Loss/seq after 00150 batchs: 451.0611572265625
INFO:root:Train (Epoch 187): Loss/seq after 00200 batchs: 492.6258850097656
INFO:root:Train (Epoch 187): Loss/seq after 00250 batchs: 548.5618286132812
INFO:root:Train (Epoch 187): Loss/seq after 00300 batchs: 565.7913818359375
INFO:root:Train (Epoch 187): Loss/seq after 00350 batchs: 534.5974731445312
INFO:root:Train (Epoch 187): Loss/seq after 00400 batchs: 517.615234375
INFO:root:Train (Epoch 187): Loss/seq after 00450 batchs: 526.0040893554688
INFO:root:Train (Epoch 187): Loss/seq after 00500 batchs: 508.1748046875
INFO:root:Train (Epoch 187): Loss/seq after 00550 batchs: 498.54742431640625
INFO:root:Train (Epoch 187): Loss/seq after 00600 batchs: 482.8061828613281
INFO:root:Train (Epoch 187): Loss/seq after 00650 batchs: 463.91058349609375
INFO:root:Train (Epoch 187): Loss/seq after 00700 batchs: 444.40948486328125
INFO:root:Train (Epoch 187): Loss/seq after 00750 batchs: 440.2676696777344
INFO:root:Train (Epoch 187): Loss/seq after 00800 batchs: 446.1451721191406
INFO:root:Train (Epoch 187): Loss/seq after 00850 batchs: 433.0735168457031
INFO:root:Train (Epoch 187): Loss/seq after 00900 batchs: 423.6347351074219
INFO:root:Train (Epoch 187): Loss/seq after 00950 batchs: 421.267578125
INFO:root:Train (Epoch 187): Loss/seq after 01000 batchs: 414.4560241699219
INFO:root:Train (Epoch 187): Loss/seq after 01050 batchs: 407.49530029296875
INFO:root:Train (Epoch 187): Loss/seq after 01100 batchs: 399.7901306152344
INFO:root:Train (Epoch 187): Loss/seq after 01150 batchs: 389.5127868652344
INFO:root:Train (Epoch 187): Loss/seq after 01200 batchs: 392.3733825683594
INFO:root:Train (Epoch 187): Loss/seq after 01250 batchs: 393.59698486328125
INFO:root:Train (Epoch 187): Loss/seq after 01300 batchs: 385.8741149902344
INFO:root:Train (Epoch 187): Loss/seq after 01350 batchs: 379.59124755859375
INFO:root:Train (Epoch 187): Loss/seq after 01400 batchs: 381.2285461425781
INFO:root:Train (Epoch 187): Loss/seq after 01450 batchs: 384.6138000488281
INFO:root:Train (Epoch 187): Loss/seq after 01500 batchs: 391.9067077636719
INFO:root:Train (Epoch 187): Loss/seq after 01550 batchs: 392.1033020019531
INFO:root:Train (Epoch 187): Loss/seq after 01600 batchs: 389.0218505859375
INFO:root:Train (Epoch 187): Loss/seq after 01650 batchs: 387.7300109863281
INFO:root:Train (Epoch 187): Loss/seq after 01700 batchs: 392.4531555175781
INFO:root:Train (Epoch 187): Loss/seq after 01750 batchs: 391.19989013671875
INFO:root:Train (Epoch 187): Loss/seq after 01800 batchs: 389.7215881347656
INFO:root:Train (Epoch 187): Loss/seq after 01850 batchs: 387.92431640625
INFO:root:Train (Epoch 187): Loss/seq after 01900 batchs: 387.4638977050781
INFO:root:Train (Epoch 187): Loss/seq after 01950 batchs: 387.1934814453125
INFO:root:Train (Epoch 187): Loss/seq after 02000 batchs: 388.3819885253906
INFO:root:Train (Epoch 187): Loss/seq after 02050 batchs: 388.6494445800781
INFO:root:Train (Epoch 187): Loss/seq after 02100 batchs: 387.47027587890625
INFO:root:Train (Epoch 187): Loss/seq after 02150 batchs: 386.7281188964844
INFO:root:Train (Epoch 187): Loss/seq after 02200 batchs: 385.5716857910156
INFO:root:Train (Epoch 187): Loss/seq after 02250 batchs: 384.5211181640625
INFO:root:Train (Epoch 187): Loss/seq after 02300 batchs: 381.5457458496094
INFO:root:Train (Epoch 187): Loss/seq after 02350 batchs: 379.1330871582031
INFO:root:Train (Epoch 187): Loss/seq after 02400 batchs: 379.9472961425781
INFO:root:Train (Epoch 187): Loss/seq after 02450 batchs: 377.0477294921875
INFO:root:Train (Epoch 187): Loss/seq after 02500 batchs: 371.5058898925781
INFO:root:Train (Epoch 187): Loss/seq after 02550 batchs: 366.4346008300781
INFO:root:Train (Epoch 187): Loss/seq after 02600 batchs: 364.6089782714844
INFO:root:Train (Epoch 187): Loss/seq after 02650 batchs: 361.03338623046875
INFO:root:Train (Epoch 187): Loss/seq after 02700 batchs: 358.74017333984375
INFO:root:Train (Epoch 187): Loss/seq after 02750 batchs: 355.6390380859375
INFO:root:Train (Epoch 187): Loss/seq after 02800 batchs: 353.6024475097656
INFO:root:Train (Epoch 187): Loss/seq after 02850 batchs: 353.43121337890625
INFO:root:Train (Epoch 187): Loss/seq after 02900 batchs: 354.7252502441406
INFO:root:Train (Epoch 187): Loss/seq after 02950 batchs: 355.2943420410156
INFO:root:Train (Epoch 187): Loss/seq after 03000 batchs: 360.9765625
INFO:root:Train (Epoch 187): Loss/seq after 03050 batchs: 363.19580078125
INFO:root:Train (Epoch 187): Loss/seq after 03100 batchs: 364.8603515625
INFO:root:Train (Epoch 187): Loss/seq after 03150 batchs: 364.6153564453125
INFO:root:Train (Epoch 187): Loss/seq after 03200 batchs: 364.41607666015625
INFO:root:Train (Epoch 187): Loss/seq after 03250 batchs: 364.9326171875
INFO:root:Train (Epoch 187): Loss/seq after 03300 batchs: 364.4194030761719
INFO:root:Train (Epoch 187): Loss/seq after 03350 batchs: 363.0596618652344
INFO:root:Train (Epoch 187): Loss/seq after 03400 batchs: 360.5247802734375
INFO:root:Train (Epoch 187): Loss/seq after 03450 batchs: 359.6974182128906
INFO:root:Train (Epoch 187): Loss/seq after 03500 batchs: 360.52520751953125
INFO:root:Train (Epoch 187): Loss/seq after 03550 batchs: 358.7173156738281
INFO:root:Train (Epoch 187): Loss/seq after 03600 batchs: 365.078369140625
INFO:root:Train (Epoch 187): Loss/seq after 03650 batchs: 363.80859375
INFO:root:Train (Epoch 187): Loss/seq after 03700 batchs: 366.14117431640625
INFO:root:Train (Epoch 187): Loss/seq after 03750 batchs: 370.4376525878906
INFO:root:Train (Epoch 187): Loss/seq after 03800 batchs: 369.8397216796875
INFO:root:Train (Epoch 187): Loss/seq after 03850 batchs: 369.21881103515625
INFO:root:Train (Epoch 187): Loss/seq after 03900 batchs: 370.7750244140625
INFO:root:Train (Epoch 187): Loss/seq after 03950 batchs: 372.94818115234375
INFO:root:Train (Epoch 187): Loss/seq after 04000 batchs: 370.7638244628906
INFO:root:Train (Epoch 187): Loss/seq after 04050 batchs: 368.57391357421875
INFO:root:Train (Epoch 187): Loss/seq after 04100 batchs: 368.0462951660156
INFO:root:Train (Epoch 187): Loss/seq after 04150 batchs: 368.17657470703125
INFO:root:Train (Epoch 187): Loss/seq after 04200 batchs: 367.33404541015625
INFO:root:Train (Epoch 187): Loss/seq after 04250 batchs: 366.1062927246094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 187): Loss/seq after 00000 batches: 284.69708251953125
INFO:root:# Valid (Epoch 187): Loss/seq after 00050 batches: 463.5113220214844
INFO:root:# Valid (Epoch 187): Loss/seq after 00100 batches: 476.6516418457031
INFO:root:# Valid (Epoch 187): Loss/seq after 00150 batches: 367.0444641113281
INFO:root:# Valid (Epoch 187): Loss/seq after 00200 batches: 347.9485168457031
INFO:root:Artifacts: Make stick videos for epoch 187
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_187_on_20220413_111823.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_187_index_98_on_20220413_111823.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 188): Loss/seq after 00000 batchs: 610.790771484375
INFO:root:Train (Epoch 188): Loss/seq after 00050 batchs: 473.5153503417969
INFO:root:Train (Epoch 188): Loss/seq after 00100 batchs: 467.7173767089844
INFO:root:Train (Epoch 188): Loss/seq after 00150 batchs: 444.0906982421875
INFO:root:Train (Epoch 188): Loss/seq after 00200 batchs: 493.30419921875
INFO:root:Train (Epoch 188): Loss/seq after 00250 batchs: 548.8849487304688
INFO:root:Train (Epoch 188): Loss/seq after 00300 batchs: 564.882080078125
INFO:root:Train (Epoch 188): Loss/seq after 00350 batchs: 534.1490478515625
INFO:root:Train (Epoch 188): Loss/seq after 00400 batchs: 518.4336547851562
INFO:root:Train (Epoch 188): Loss/seq after 00450 batchs: 526.4755859375
INFO:root:Train (Epoch 188): Loss/seq after 00500 batchs: 509.4282531738281
INFO:root:Train (Epoch 188): Loss/seq after 00550 batchs: 499.7085876464844
INFO:root:Train (Epoch 188): Loss/seq after 00600 batchs: 484.51385498046875
INFO:root:Train (Epoch 188): Loss/seq after 00650 batchs: 466.1412353515625
INFO:root:Train (Epoch 188): Loss/seq after 00700 batchs: 446.6924133300781
INFO:root:Train (Epoch 188): Loss/seq after 00750 batchs: 442.5595703125
INFO:root:Train (Epoch 188): Loss/seq after 00800 batchs: 448.1769714355469
INFO:root:Train (Epoch 188): Loss/seq after 00850 batchs: 434.9963684082031
INFO:root:Train (Epoch 188): Loss/seq after 00900 batchs: 425.3063659667969
INFO:root:Train (Epoch 188): Loss/seq after 00950 batchs: 422.86761474609375
INFO:root:Train (Epoch 188): Loss/seq after 01000 batchs: 415.58819580078125
INFO:root:Train (Epoch 188): Loss/seq after 01050 batchs: 408.7347412109375
INFO:root:Train (Epoch 188): Loss/seq after 01100 batchs: 401.0328369140625
INFO:root:Train (Epoch 188): Loss/seq after 01150 batchs: 390.6282043457031
INFO:root:Train (Epoch 188): Loss/seq after 01200 batchs: 393.1305847167969
INFO:root:Train (Epoch 188): Loss/seq after 01250 batchs: 394.3424377441406
INFO:root:Train (Epoch 188): Loss/seq after 01300 batchs: 386.6288146972656
INFO:root:Train (Epoch 188): Loss/seq after 01350 batchs: 380.27099609375
INFO:root:Train (Epoch 188): Loss/seq after 01400 batchs: 381.7742614746094
INFO:root:Train (Epoch 188): Loss/seq after 01450 batchs: 385.0519104003906
INFO:root:Train (Epoch 188): Loss/seq after 01500 batchs: 392.73968505859375
INFO:root:Train (Epoch 188): Loss/seq after 01550 batchs: 392.8500061035156
INFO:root:Train (Epoch 188): Loss/seq after 01600 batchs: 389.69244384765625
INFO:root:Train (Epoch 188): Loss/seq after 01650 batchs: 388.3094787597656
INFO:root:Train (Epoch 188): Loss/seq after 01700 batchs: 393.0958251953125
INFO:root:Train (Epoch 188): Loss/seq after 01750 batchs: 391.85455322265625
INFO:root:Train (Epoch 188): Loss/seq after 01800 batchs: 389.9981384277344
INFO:root:Train (Epoch 188): Loss/seq after 01850 batchs: 388.2556457519531
INFO:root:Train (Epoch 188): Loss/seq after 01900 batchs: 387.7005920410156
INFO:root:Train (Epoch 188): Loss/seq after 01950 batchs: 387.2326965332031
INFO:root:Train (Epoch 188): Loss/seq after 02000 batchs: 388.3074645996094
INFO:root:Train (Epoch 188): Loss/seq after 02050 batchs: 388.4674072265625
INFO:root:Train (Epoch 188): Loss/seq after 02100 batchs: 387.3363342285156
INFO:root:Train (Epoch 188): Loss/seq after 02150 batchs: 386.50592041015625
INFO:root:Train (Epoch 188): Loss/seq after 02200 batchs: 385.1686096191406
INFO:root:Train (Epoch 188): Loss/seq after 02250 batchs: 384.2620849609375
INFO:root:Train (Epoch 188): Loss/seq after 02300 batchs: 381.28533935546875
INFO:root:Train (Epoch 188): Loss/seq after 02350 batchs: 379.0405578613281
INFO:root:Train (Epoch 188): Loss/seq after 02400 batchs: 379.7901611328125
INFO:root:Train (Epoch 188): Loss/seq after 02450 batchs: 376.9848327636719
INFO:root:Train (Epoch 188): Loss/seq after 02500 batchs: 371.46392822265625
INFO:root:Train (Epoch 188): Loss/seq after 02550 batchs: 366.37835693359375
INFO:root:Train (Epoch 188): Loss/seq after 02600 batchs: 364.5141906738281
INFO:root:Train (Epoch 188): Loss/seq after 02650 batchs: 360.9797668457031
INFO:root:Train (Epoch 188): Loss/seq after 02700 batchs: 358.6663513183594
INFO:root:Train (Epoch 188): Loss/seq after 02750 batchs: 355.515869140625
INFO:root:Train (Epoch 188): Loss/seq after 02800 batchs: 353.5837097167969
INFO:root:Train (Epoch 188): Loss/seq after 02850 batchs: 353.38128662109375
INFO:root:Train (Epoch 188): Loss/seq after 02900 batchs: 354.75390625
INFO:root:Train (Epoch 188): Loss/seq after 02950 batchs: 355.30499267578125
INFO:root:Train (Epoch 188): Loss/seq after 03000 batchs: 360.9482421875
INFO:root:Train (Epoch 188): Loss/seq after 03050 batchs: 363.2955017089844
INFO:root:Train (Epoch 188): Loss/seq after 03100 batchs: 364.753662109375
INFO:root:Train (Epoch 188): Loss/seq after 03150 batchs: 364.1400451660156
INFO:root:Train (Epoch 188): Loss/seq after 03200 batchs: 363.9910583496094
INFO:root:Train (Epoch 188): Loss/seq after 03250 batchs: 364.347900390625
INFO:root:Train (Epoch 188): Loss/seq after 03300 batchs: 364.05621337890625
INFO:root:Train (Epoch 188): Loss/seq after 03350 batchs: 362.8113098144531
INFO:root:Train (Epoch 188): Loss/seq after 03400 batchs: 360.2239685058594
INFO:root:Train (Epoch 188): Loss/seq after 03450 batchs: 359.3438720703125
INFO:root:Train (Epoch 188): Loss/seq after 03500 batchs: 360.1997985839844
INFO:root:Train (Epoch 188): Loss/seq after 03550 batchs: 358.398681640625
INFO:root:Train (Epoch 188): Loss/seq after 03600 batchs: 364.6851806640625
INFO:root:Train (Epoch 188): Loss/seq after 03650 batchs: 363.39263916015625
INFO:root:Train (Epoch 188): Loss/seq after 03700 batchs: 365.55181884765625
INFO:root:Train (Epoch 188): Loss/seq after 03750 batchs: 369.8182373046875
INFO:root:Train (Epoch 188): Loss/seq after 03800 batchs: 369.1231689453125
INFO:root:Train (Epoch 188): Loss/seq after 03850 batchs: 368.4197998046875
INFO:root:Train (Epoch 188): Loss/seq after 03900 batchs: 369.8738708496094
INFO:root:Train (Epoch 188): Loss/seq after 03950 batchs: 372.0016784667969
INFO:root:Train (Epoch 188): Loss/seq after 04000 batchs: 369.82391357421875
INFO:root:Train (Epoch 188): Loss/seq after 04050 batchs: 367.6580505371094
INFO:root:Train (Epoch 188): Loss/seq after 04100 batchs: 367.1192626953125
INFO:root:Train (Epoch 188): Loss/seq after 04150 batchs: 367.23126220703125
INFO:root:Train (Epoch 188): Loss/seq after 04200 batchs: 366.43743896484375
INFO:root:Train (Epoch 188): Loss/seq after 04250 batchs: 365.1850891113281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 188): Loss/seq after 00000 batches: 326.5476989746094
INFO:root:# Valid (Epoch 188): Loss/seq after 00050 batches: 462.75799560546875
INFO:root:# Valid (Epoch 188): Loss/seq after 00100 batches: 494.2063293457031
INFO:root:# Valid (Epoch 188): Loss/seq after 00150 batches: 379.53948974609375
INFO:root:# Valid (Epoch 188): Loss/seq after 00200 batches: 357.50390625
INFO:root:Artifacts: Make stick videos for epoch 188
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_188_on_20220413_112346.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_188_index_978_on_20220413_112346.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 189): Loss/seq after 00000 batchs: 646.7074584960938
INFO:root:Train (Epoch 189): Loss/seq after 00050 batchs: 469.2642517089844
INFO:root:Train (Epoch 189): Loss/seq after 00100 batchs: 462.7753601074219
INFO:root:Train (Epoch 189): Loss/seq after 00150 batchs: 439.1639099121094
INFO:root:Train (Epoch 189): Loss/seq after 00200 batchs: 486.0940246582031
INFO:root:Train (Epoch 189): Loss/seq after 00250 batchs: 542.13232421875
INFO:root:Train (Epoch 189): Loss/seq after 00300 batchs: 558.9614868164062
INFO:root:Train (Epoch 189): Loss/seq after 00350 batchs: 529.2553100585938
INFO:root:Train (Epoch 189): Loss/seq after 00400 batchs: 513.667236328125
INFO:root:Train (Epoch 189): Loss/seq after 00450 batchs: 521.8524169921875
INFO:root:Train (Epoch 189): Loss/seq after 00500 batchs: 504.0220947265625
INFO:root:Train (Epoch 189): Loss/seq after 00550 batchs: 494.7322998046875
INFO:root:Train (Epoch 189): Loss/seq after 00600 batchs: 479.30194091796875
INFO:root:Train (Epoch 189): Loss/seq after 00650 batchs: 460.45037841796875
INFO:root:Train (Epoch 189): Loss/seq after 00700 batchs: 441.0809631347656
INFO:root:Train (Epoch 189): Loss/seq after 00750 batchs: 436.44232177734375
INFO:root:Train (Epoch 189): Loss/seq after 00800 batchs: 441.6581115722656
INFO:root:Train (Epoch 189): Loss/seq after 00850 batchs: 428.9788513183594
INFO:root:Train (Epoch 189): Loss/seq after 00900 batchs: 419.62664794921875
INFO:root:Train (Epoch 189): Loss/seq after 00950 batchs: 418.02825927734375
INFO:root:Train (Epoch 189): Loss/seq after 01000 batchs: 410.918212890625
INFO:root:Train (Epoch 189): Loss/seq after 01050 batchs: 404.084228515625
INFO:root:Train (Epoch 189): Loss/seq after 01100 batchs: 396.2059020996094
INFO:root:Train (Epoch 189): Loss/seq after 01150 batchs: 386.0659484863281
INFO:root:Train (Epoch 189): Loss/seq after 01200 batchs: 388.39764404296875
INFO:root:Train (Epoch 189): Loss/seq after 01250 batchs: 389.450439453125
INFO:root:Train (Epoch 189): Loss/seq after 01300 batchs: 381.5838623046875
INFO:root:Train (Epoch 189): Loss/seq after 01350 batchs: 375.3742370605469
INFO:root:Train (Epoch 189): Loss/seq after 01400 batchs: 376.9234313964844
INFO:root:Train (Epoch 189): Loss/seq after 01450 batchs: 380.22802734375
INFO:root:Train (Epoch 189): Loss/seq after 01500 batchs: 387.88568115234375
INFO:root:Train (Epoch 189): Loss/seq after 01550 batchs: 388.0317077636719
INFO:root:Train (Epoch 189): Loss/seq after 01600 batchs: 385.2132568359375
INFO:root:Train (Epoch 189): Loss/seq after 01650 batchs: 383.9418640136719
INFO:root:Train (Epoch 189): Loss/seq after 01700 batchs: 388.488037109375
INFO:root:Train (Epoch 189): Loss/seq after 01750 batchs: 387.31280517578125
INFO:root:Train (Epoch 189): Loss/seq after 01800 batchs: 385.51300048828125
INFO:root:Train (Epoch 189): Loss/seq after 01850 batchs: 383.9131774902344
INFO:root:Train (Epoch 189): Loss/seq after 01900 batchs: 383.3892822265625
INFO:root:Train (Epoch 189): Loss/seq after 01950 batchs: 383.2446594238281
INFO:root:Train (Epoch 189): Loss/seq after 02000 batchs: 384.3679504394531
INFO:root:Train (Epoch 189): Loss/seq after 02050 batchs: 384.73284912109375
INFO:root:Train (Epoch 189): Loss/seq after 02100 batchs: 383.68280029296875
INFO:root:Train (Epoch 189): Loss/seq after 02150 batchs: 382.9643859863281
INFO:root:Train (Epoch 189): Loss/seq after 02200 batchs: 381.7669372558594
INFO:root:Train (Epoch 189): Loss/seq after 02250 batchs: 380.70635986328125
INFO:root:Train (Epoch 189): Loss/seq after 02300 batchs: 377.785400390625
INFO:root:Train (Epoch 189): Loss/seq after 02350 batchs: 375.5025634765625
INFO:root:Train (Epoch 189): Loss/seq after 02400 batchs: 376.2908935546875
INFO:root:Train (Epoch 189): Loss/seq after 02450 batchs: 373.5506896972656
INFO:root:Train (Epoch 189): Loss/seq after 02500 batchs: 368.0270690917969
INFO:root:Train (Epoch 189): Loss/seq after 02550 batchs: 363.0048828125
INFO:root:Train (Epoch 189): Loss/seq after 02600 batchs: 361.2552795410156
INFO:root:Train (Epoch 189): Loss/seq after 02650 batchs: 357.6807556152344
INFO:root:Train (Epoch 189): Loss/seq after 02700 batchs: 355.4897766113281
INFO:root:Train (Epoch 189): Loss/seq after 02750 batchs: 352.2964172363281
INFO:root:Train (Epoch 189): Loss/seq after 02800 batchs: 350.4892272949219
INFO:root:Train (Epoch 189): Loss/seq after 02850 batchs: 350.2423400878906
INFO:root:Train (Epoch 189): Loss/seq after 02900 batchs: 351.60455322265625
INFO:root:Train (Epoch 189): Loss/seq after 02950 batchs: 352.165771484375
INFO:root:Train (Epoch 189): Loss/seq after 03000 batchs: 357.87762451171875
INFO:root:Train (Epoch 189): Loss/seq after 03050 batchs: 360.17877197265625
INFO:root:Train (Epoch 189): Loss/seq after 03100 batchs: 361.6673889160156
INFO:root:Train (Epoch 189): Loss/seq after 03150 batchs: 361.34796142578125
INFO:root:Train (Epoch 189): Loss/seq after 03200 batchs: 361.39520263671875
INFO:root:Train (Epoch 189): Loss/seq after 03250 batchs: 362.0954284667969
INFO:root:Train (Epoch 189): Loss/seq after 03300 batchs: 361.6506042480469
INFO:root:Train (Epoch 189): Loss/seq after 03350 batchs: 360.2434387207031
INFO:root:Train (Epoch 189): Loss/seq after 03400 batchs: 357.7560729980469
INFO:root:Train (Epoch 189): Loss/seq after 03450 batchs: 356.7898864746094
INFO:root:Train (Epoch 189): Loss/seq after 03500 batchs: 357.6251525878906
INFO:root:Train (Epoch 189): Loss/seq after 03550 batchs: 355.73992919921875
INFO:root:Train (Epoch 189): Loss/seq after 03600 batchs: 362.0096740722656
INFO:root:Train (Epoch 189): Loss/seq after 03650 batchs: 360.79400634765625
INFO:root:Train (Epoch 189): Loss/seq after 03700 batchs: 362.9798889160156
INFO:root:Train (Epoch 189): Loss/seq after 03750 batchs: 367.2151794433594
INFO:root:Train (Epoch 189): Loss/seq after 03800 batchs: 366.61688232421875
INFO:root:Train (Epoch 189): Loss/seq after 03850 batchs: 365.9317932128906
INFO:root:Train (Epoch 189): Loss/seq after 03900 batchs: 367.43145751953125
INFO:root:Train (Epoch 189): Loss/seq after 03950 batchs: 369.48675537109375
INFO:root:Train (Epoch 189): Loss/seq after 04000 batchs: 367.29010009765625
INFO:root:Train (Epoch 189): Loss/seq after 04050 batchs: 365.1328430175781
INFO:root:Train (Epoch 189): Loss/seq after 04100 batchs: 364.6289367675781
INFO:root:Train (Epoch 189): Loss/seq after 04150 batchs: 364.7388916015625
INFO:root:Train (Epoch 189): Loss/seq after 04200 batchs: 363.9883117675781
INFO:root:Train (Epoch 189): Loss/seq after 04250 batchs: 362.73956298828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 189): Loss/seq after 00000 batches: 298.1471862792969
INFO:root:# Valid (Epoch 189): Loss/seq after 00050 batches: 463.8315734863281
INFO:root:# Valid (Epoch 189): Loss/seq after 00100 batches: 471.638427734375
INFO:root:# Valid (Epoch 189): Loss/seq after 00150 batches: 364.9943542480469
INFO:root:# Valid (Epoch 189): Loss/seq after 00200 batches: 346.68212890625
INFO:root:Artifacts: Make stick videos for epoch 189
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_189_on_20220413_112908.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_189_index_1882_on_20220413_112908.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 190): Loss/seq after 00000 batchs: 627.0304565429688
INFO:root:Train (Epoch 190): Loss/seq after 00050 batchs: 473.69598388671875
INFO:root:Train (Epoch 190): Loss/seq after 00100 batchs: 461.747802734375
INFO:root:Train (Epoch 190): Loss/seq after 00150 batchs: 440.84039306640625
INFO:root:Train (Epoch 190): Loss/seq after 00200 batchs: 485.9017639160156
INFO:root:Train (Epoch 190): Loss/seq after 00250 batchs: 553.0108032226562
INFO:root:Train (Epoch 190): Loss/seq after 00300 batchs: 567.3754272460938
INFO:root:Train (Epoch 190): Loss/seq after 00350 batchs: 535.5631103515625
INFO:root:Train (Epoch 190): Loss/seq after 00400 batchs: 519.6751708984375
INFO:root:Train (Epoch 190): Loss/seq after 00450 batchs: 527.3160400390625
INFO:root:Train (Epoch 190): Loss/seq after 00500 batchs: 508.7033996582031
INFO:root:Train (Epoch 190): Loss/seq after 00550 batchs: 498.01751708984375
INFO:root:Train (Epoch 190): Loss/seq after 00600 batchs: 482.37554931640625
INFO:root:Train (Epoch 190): Loss/seq after 00650 batchs: 463.3977966308594
INFO:root:Train (Epoch 190): Loss/seq after 00700 batchs: 444.052490234375
INFO:root:Train (Epoch 190): Loss/seq after 00750 batchs: 439.78436279296875
INFO:root:Train (Epoch 190): Loss/seq after 00800 batchs: 443.7428894042969
INFO:root:Train (Epoch 190): Loss/seq after 00850 batchs: 430.7717590332031
INFO:root:Train (Epoch 190): Loss/seq after 00900 batchs: 421.248779296875
INFO:root:Train (Epoch 190): Loss/seq after 00950 batchs: 418.4662170410156
INFO:root:Train (Epoch 190): Loss/seq after 01000 batchs: 411.6059875488281
INFO:root:Train (Epoch 190): Loss/seq after 01050 batchs: 404.4073486328125
INFO:root:Train (Epoch 190): Loss/seq after 01100 batchs: 396.7362365722656
INFO:root:Train (Epoch 190): Loss/seq after 01150 batchs: 386.4617614746094
INFO:root:Train (Epoch 190): Loss/seq after 01200 batchs: 388.6472473144531
INFO:root:Train (Epoch 190): Loss/seq after 01250 batchs: 389.6157531738281
INFO:root:Train (Epoch 190): Loss/seq after 01300 batchs: 381.7572326660156
INFO:root:Train (Epoch 190): Loss/seq after 01350 batchs: 375.8097839355469
INFO:root:Train (Epoch 190): Loss/seq after 01400 batchs: 377.36517333984375
INFO:root:Train (Epoch 190): Loss/seq after 01450 batchs: 380.6571350097656
INFO:root:Train (Epoch 190): Loss/seq after 01500 batchs: 387.91485595703125
INFO:root:Train (Epoch 190): Loss/seq after 01550 batchs: 387.7161865234375
INFO:root:Train (Epoch 190): Loss/seq after 01600 batchs: 384.8364562988281
INFO:root:Train (Epoch 190): Loss/seq after 01650 batchs: 383.42010498046875
INFO:root:Train (Epoch 190): Loss/seq after 01700 batchs: 388.171142578125
INFO:root:Train (Epoch 190): Loss/seq after 01750 batchs: 386.7865295410156
INFO:root:Train (Epoch 190): Loss/seq after 01800 batchs: 385.1324157714844
INFO:root:Train (Epoch 190): Loss/seq after 01850 batchs: 383.4161376953125
INFO:root:Train (Epoch 190): Loss/seq after 01900 batchs: 382.660400390625
INFO:root:Train (Epoch 190): Loss/seq after 01950 batchs: 382.12664794921875
INFO:root:Train (Epoch 190): Loss/seq after 02000 batchs: 383.2234802246094
INFO:root:Train (Epoch 190): Loss/seq after 02050 batchs: 383.277099609375
INFO:root:Train (Epoch 190): Loss/seq after 02100 batchs: 382.2055969238281
INFO:root:Train (Epoch 190): Loss/seq after 02150 batchs: 381.3686828613281
INFO:root:Train (Epoch 190): Loss/seq after 02200 batchs: 380.31640625
INFO:root:Train (Epoch 190): Loss/seq after 02250 batchs: 379.24761962890625
INFO:root:Train (Epoch 190): Loss/seq after 02300 batchs: 376.3609313964844
INFO:root:Train (Epoch 190): Loss/seq after 02350 batchs: 374.1484069824219
INFO:root:Train (Epoch 190): Loss/seq after 02400 batchs: 375.0335693359375
INFO:root:Train (Epoch 190): Loss/seq after 02450 batchs: 372.2567443847656
INFO:root:Train (Epoch 190): Loss/seq after 02500 batchs: 366.8022155761719
INFO:root:Train (Epoch 190): Loss/seq after 02550 batchs: 361.813720703125
INFO:root:Train (Epoch 190): Loss/seq after 02600 batchs: 360.0380554199219
INFO:root:Train (Epoch 190): Loss/seq after 02650 batchs: 356.4207458496094
INFO:root:Train (Epoch 190): Loss/seq after 02700 batchs: 354.1590881347656
INFO:root:Train (Epoch 190): Loss/seq after 02750 batchs: 351.0365295410156
INFO:root:Train (Epoch 190): Loss/seq after 02800 batchs: 349.07861328125
INFO:root:Train (Epoch 190): Loss/seq after 02850 batchs: 348.89093017578125
INFO:root:Train (Epoch 190): Loss/seq after 02900 batchs: 350.3310546875
INFO:root:Train (Epoch 190): Loss/seq after 02950 batchs: 350.8776550292969
INFO:root:Train (Epoch 190): Loss/seq after 03000 batchs: 356.6720886230469
INFO:root:Train (Epoch 190): Loss/seq after 03050 batchs: 359.0318603515625
INFO:root:Train (Epoch 190): Loss/seq after 03100 batchs: 360.76470947265625
INFO:root:Train (Epoch 190): Loss/seq after 03150 batchs: 360.25616455078125
INFO:root:Train (Epoch 190): Loss/seq after 03200 batchs: 359.8794860839844
INFO:root:Train (Epoch 190): Loss/seq after 03250 batchs: 360.1394958496094
INFO:root:Train (Epoch 190): Loss/seq after 03300 batchs: 359.6797790527344
INFO:root:Train (Epoch 190): Loss/seq after 03350 batchs: 358.1973571777344
INFO:root:Train (Epoch 190): Loss/seq after 03400 batchs: 355.7528381347656
INFO:root:Train (Epoch 190): Loss/seq after 03450 batchs: 354.9100036621094
INFO:root:Train (Epoch 190): Loss/seq after 03500 batchs: 355.7306213378906
INFO:root:Train (Epoch 190): Loss/seq after 03550 batchs: 353.8293151855469
INFO:root:Train (Epoch 190): Loss/seq after 03600 batchs: 360.12359619140625
INFO:root:Train (Epoch 190): Loss/seq after 03650 batchs: 358.8467102050781
INFO:root:Train (Epoch 190): Loss/seq after 03700 batchs: 361.1089172363281
INFO:root:Train (Epoch 190): Loss/seq after 03750 batchs: 365.4562683105469
INFO:root:Train (Epoch 190): Loss/seq after 03800 batchs: 364.88739013671875
INFO:root:Train (Epoch 190): Loss/seq after 03850 batchs: 364.3283996582031
INFO:root:Train (Epoch 190): Loss/seq after 03900 batchs: 365.7764587402344
INFO:root:Train (Epoch 190): Loss/seq after 03950 batchs: 367.87872314453125
INFO:root:Train (Epoch 190): Loss/seq after 04000 batchs: 365.75128173828125
INFO:root:Train (Epoch 190): Loss/seq after 04050 batchs: 363.62506103515625
INFO:root:Train (Epoch 190): Loss/seq after 04100 batchs: 363.0853576660156
INFO:root:Train (Epoch 190): Loss/seq after 04150 batchs: 363.2280578613281
INFO:root:Train (Epoch 190): Loss/seq after 04200 batchs: 362.440673828125
INFO:root:Train (Epoch 190): Loss/seq after 04250 batchs: 361.2486267089844
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 190): Loss/seq after 00000 batches: 305.55609130859375
INFO:root:# Valid (Epoch 190): Loss/seq after 00050 batches: 483.3462829589844
INFO:root:# Valid (Epoch 190): Loss/seq after 00100 batches: 486.54022216796875
INFO:root:# Valid (Epoch 190): Loss/seq after 00150 batches: 375.9276123046875
INFO:root:# Valid (Epoch 190): Loss/seq after 00200 batches: 357.9132385253906
INFO:root:Artifacts: Make stick videos for epoch 190
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_190_on_20220413_113430.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_190_index_1723_on_20220413_113430.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 191): Loss/seq after 00000 batchs: 541.4348754882812
INFO:root:Train (Epoch 191): Loss/seq after 00050 batchs: 471.43023681640625
INFO:root:Train (Epoch 191): Loss/seq after 00100 batchs: 451.9355163574219
INFO:root:Train (Epoch 191): Loss/seq after 00150 batchs: 429.1383972167969
INFO:root:Train (Epoch 191): Loss/seq after 00200 batchs: 478.7054748535156
INFO:root:Train (Epoch 191): Loss/seq after 00250 batchs: 530.1237182617188
INFO:root:Train (Epoch 191): Loss/seq after 00300 batchs: 549.669189453125
INFO:root:Train (Epoch 191): Loss/seq after 00350 batchs: 520.474609375
INFO:root:Train (Epoch 191): Loss/seq after 00400 batchs: 505.787353515625
INFO:root:Train (Epoch 191): Loss/seq after 00450 batchs: 515.2175903320312
INFO:root:Train (Epoch 191): Loss/seq after 00500 batchs: 498.0257568359375
INFO:root:Train (Epoch 191): Loss/seq after 00550 batchs: 489.1248779296875
INFO:root:Train (Epoch 191): Loss/seq after 00600 batchs: 474.10919189453125
INFO:root:Train (Epoch 191): Loss/seq after 00650 batchs: 456.3980407714844
INFO:root:Train (Epoch 191): Loss/seq after 00700 batchs: 437.4826354980469
INFO:root:Train (Epoch 191): Loss/seq after 00750 batchs: 433.1878967285156
INFO:root:Train (Epoch 191): Loss/seq after 00800 batchs: 437.3496398925781
INFO:root:Train (Epoch 191): Loss/seq after 00850 batchs: 424.255126953125
INFO:root:Train (Epoch 191): Loss/seq after 00900 batchs: 414.64697265625
INFO:root:Train (Epoch 191): Loss/seq after 00950 batchs: 412.22247314453125
INFO:root:Train (Epoch 191): Loss/seq after 01000 batchs: 405.2587890625
INFO:root:Train (Epoch 191): Loss/seq after 01050 batchs: 398.56219482421875
INFO:root:Train (Epoch 191): Loss/seq after 01100 batchs: 391.102783203125
INFO:root:Train (Epoch 191): Loss/seq after 01150 batchs: 381.0333251953125
INFO:root:Train (Epoch 191): Loss/seq after 01200 batchs: 384.7955322265625
INFO:root:Train (Epoch 191): Loss/seq after 01250 batchs: 386.37921142578125
INFO:root:Train (Epoch 191): Loss/seq after 01300 batchs: 378.43731689453125
INFO:root:Train (Epoch 191): Loss/seq after 01350 batchs: 372.2447204589844
INFO:root:Train (Epoch 191): Loss/seq after 01400 batchs: 374.0505065917969
INFO:root:Train (Epoch 191): Loss/seq after 01450 batchs: 377.4662170410156
INFO:root:Train (Epoch 191): Loss/seq after 01500 batchs: 384.9815979003906
INFO:root:Train (Epoch 191): Loss/seq after 01550 batchs: 384.81689453125
INFO:root:Train (Epoch 191): Loss/seq after 01600 batchs: 381.7900695800781
INFO:root:Train (Epoch 191): Loss/seq after 01650 batchs: 380.51312255859375
INFO:root:Train (Epoch 191): Loss/seq after 01700 batchs: 385.3213195800781
INFO:root:Train (Epoch 191): Loss/seq after 01750 batchs: 384.04766845703125
INFO:root:Train (Epoch 191): Loss/seq after 01800 batchs: 382.6002197265625
INFO:root:Train (Epoch 191): Loss/seq after 01850 batchs: 380.9786682128906
INFO:root:Train (Epoch 191): Loss/seq after 01900 batchs: 380.33795166015625
INFO:root:Train (Epoch 191): Loss/seq after 01950 batchs: 380.2872314453125
INFO:root:Train (Epoch 191): Loss/seq after 02000 batchs: 381.3813781738281
INFO:root:Train (Epoch 191): Loss/seq after 02050 batchs: 381.8005676269531
INFO:root:Train (Epoch 191): Loss/seq after 02100 batchs: 380.7973327636719
INFO:root:Train (Epoch 191): Loss/seq after 02150 batchs: 380.0697021484375
INFO:root:Train (Epoch 191): Loss/seq after 02200 batchs: 378.9565124511719
INFO:root:Train (Epoch 191): Loss/seq after 02250 batchs: 377.90673828125
INFO:root:Train (Epoch 191): Loss/seq after 02300 batchs: 374.96063232421875
INFO:root:Train (Epoch 191): Loss/seq after 02350 batchs: 372.8592529296875
INFO:root:Train (Epoch 191): Loss/seq after 02400 batchs: 373.71807861328125
INFO:root:Train (Epoch 191): Loss/seq after 02450 batchs: 370.99951171875
INFO:root:Train (Epoch 191): Loss/seq after 02500 batchs: 365.5315246582031
INFO:root:Train (Epoch 191): Loss/seq after 02550 batchs: 360.468505859375
INFO:root:Train (Epoch 191): Loss/seq after 02600 batchs: 358.67578125
INFO:root:Train (Epoch 191): Loss/seq after 02650 batchs: 355.15576171875
INFO:root:Train (Epoch 191): Loss/seq after 02700 batchs: 352.88726806640625
INFO:root:Train (Epoch 191): Loss/seq after 02750 batchs: 349.6474914550781
INFO:root:Train (Epoch 191): Loss/seq after 02800 batchs: 347.6133728027344
INFO:root:Train (Epoch 191): Loss/seq after 02850 batchs: 347.31884765625
INFO:root:Train (Epoch 191): Loss/seq after 02900 batchs: 348.6146545410156
INFO:root:Train (Epoch 191): Loss/seq after 02950 batchs: 349.1940612792969
INFO:root:Train (Epoch 191): Loss/seq after 03000 batchs: 354.78326416015625
INFO:root:Train (Epoch 191): Loss/seq after 03050 batchs: 357.0595703125
INFO:root:Train (Epoch 191): Loss/seq after 03100 batchs: 358.5061950683594
INFO:root:Train (Epoch 191): Loss/seq after 03150 batchs: 358.0012512207031
INFO:root:Train (Epoch 191): Loss/seq after 03200 batchs: 357.7861328125
INFO:root:Train (Epoch 191): Loss/seq after 03250 batchs: 358.2430725097656
INFO:root:Train (Epoch 191): Loss/seq after 03300 batchs: 357.696044921875
INFO:root:Train (Epoch 191): Loss/seq after 03350 batchs: 356.2151794433594
INFO:root:Train (Epoch 191): Loss/seq after 03400 batchs: 353.7111511230469
INFO:root:Train (Epoch 191): Loss/seq after 03450 batchs: 352.8348083496094
INFO:root:Train (Epoch 191): Loss/seq after 03500 batchs: 353.642578125
INFO:root:Train (Epoch 191): Loss/seq after 03550 batchs: 351.833740234375
INFO:root:Train (Epoch 191): Loss/seq after 03600 batchs: 358.12396240234375
INFO:root:Train (Epoch 191): Loss/seq after 03650 batchs: 357.0150451660156
INFO:root:Train (Epoch 191): Loss/seq after 03700 batchs: 359.1938171386719
INFO:root:Train (Epoch 191): Loss/seq after 03750 batchs: 363.48699951171875
INFO:root:Train (Epoch 191): Loss/seq after 03800 batchs: 362.8848876953125
INFO:root:Train (Epoch 191): Loss/seq after 03850 batchs: 362.2800598144531
INFO:root:Train (Epoch 191): Loss/seq after 03900 batchs: 363.85113525390625
INFO:root:Train (Epoch 191): Loss/seq after 03950 batchs: 366.0278625488281
INFO:root:Train (Epoch 191): Loss/seq after 04000 batchs: 363.8899230957031
INFO:root:Train (Epoch 191): Loss/seq after 04050 batchs: 361.7631530761719
INFO:root:Train (Epoch 191): Loss/seq after 04100 batchs: 361.3231506347656
INFO:root:Train (Epoch 191): Loss/seq after 04150 batchs: 361.42254638671875
INFO:root:Train (Epoch 191): Loss/seq after 04200 batchs: 360.60113525390625
INFO:root:Train (Epoch 191): Loss/seq after 04250 batchs: 359.4102478027344
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 191): Loss/seq after 00000 batches: 330.24969482421875
INFO:root:# Valid (Epoch 191): Loss/seq after 00050 batches: 464.57476806640625
INFO:root:# Valid (Epoch 191): Loss/seq after 00100 batches: 468.8843078613281
INFO:root:# Valid (Epoch 191): Loss/seq after 00150 batches: 362.4436950683594
INFO:root:# Valid (Epoch 191): Loss/seq after 00200 batches: 344.04876708984375
INFO:root:Artifacts: Make stick videos for epoch 191
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_191_on_20220413_113953.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_191_index_928_on_20220413_113953.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 192): Loss/seq after 00000 batchs: 580.2343139648438
INFO:root:Train (Epoch 192): Loss/seq after 00050 batchs: 471.1097717285156
INFO:root:Train (Epoch 192): Loss/seq after 00100 batchs: 464.2377624511719
INFO:root:Train (Epoch 192): Loss/seq after 00150 batchs: 440.7305908203125
INFO:root:Train (Epoch 192): Loss/seq after 00200 batchs: 485.4065246582031
INFO:root:Train (Epoch 192): Loss/seq after 00250 batchs: 532.469482421875
INFO:root:Train (Epoch 192): Loss/seq after 00300 batchs: 550.1255493164062
INFO:root:Train (Epoch 192): Loss/seq after 00350 batchs: 520.1210327148438
INFO:root:Train (Epoch 192): Loss/seq after 00400 batchs: 502.3377380371094
INFO:root:Train (Epoch 192): Loss/seq after 00450 batchs: 511.0431213378906
INFO:root:Train (Epoch 192): Loss/seq after 00500 batchs: 493.77752685546875
INFO:root:Train (Epoch 192): Loss/seq after 00550 batchs: 484.4029541015625
INFO:root:Train (Epoch 192): Loss/seq after 00600 batchs: 469.5333557128906
INFO:root:Train (Epoch 192): Loss/seq after 00650 batchs: 451.6212463378906
INFO:root:Train (Epoch 192): Loss/seq after 00700 batchs: 433.00238037109375
INFO:root:Train (Epoch 192): Loss/seq after 00750 batchs: 427.7667236328125
INFO:root:Train (Epoch 192): Loss/seq after 00800 batchs: 432.9225158691406
INFO:root:Train (Epoch 192): Loss/seq after 00850 batchs: 420.3995361328125
INFO:root:Train (Epoch 192): Loss/seq after 00900 batchs: 411.07586669921875
INFO:root:Train (Epoch 192): Loss/seq after 00950 batchs: 409.21185302734375
INFO:root:Train (Epoch 192): Loss/seq after 01000 batchs: 402.6664123535156
INFO:root:Train (Epoch 192): Loss/seq after 01050 batchs: 396.0323791503906
INFO:root:Train (Epoch 192): Loss/seq after 01100 batchs: 388.7799377441406
INFO:root:Train (Epoch 192): Loss/seq after 01150 batchs: 378.92633056640625
INFO:root:Train (Epoch 192): Loss/seq after 01200 batchs: 382.2435302734375
INFO:root:Train (Epoch 192): Loss/seq after 01250 batchs: 383.6108703613281
INFO:root:Train (Epoch 192): Loss/seq after 01300 batchs: 375.7421875
INFO:root:Train (Epoch 192): Loss/seq after 01350 batchs: 369.5914611816406
INFO:root:Train (Epoch 192): Loss/seq after 01400 batchs: 371.12652587890625
INFO:root:Train (Epoch 192): Loss/seq after 01450 batchs: 374.47149658203125
INFO:root:Train (Epoch 192): Loss/seq after 01500 batchs: 382.0065002441406
INFO:root:Train (Epoch 192): Loss/seq after 01550 batchs: 382.1200866699219
INFO:root:Train (Epoch 192): Loss/seq after 01600 batchs: 378.9158020019531
INFO:root:Train (Epoch 192): Loss/seq after 01650 batchs: 377.6086730957031
INFO:root:Train (Epoch 192): Loss/seq after 01700 batchs: 382.5843200683594
INFO:root:Train (Epoch 192): Loss/seq after 01750 batchs: 381.4134521484375
INFO:root:Train (Epoch 192): Loss/seq after 01800 batchs: 379.8354187011719
INFO:root:Train (Epoch 192): Loss/seq after 01850 batchs: 378.169921875
INFO:root:Train (Epoch 192): Loss/seq after 01900 batchs: 377.5434875488281
INFO:root:Train (Epoch 192): Loss/seq after 01950 batchs: 377.382568359375
INFO:root:Train (Epoch 192): Loss/seq after 02000 batchs: 378.54248046875
INFO:root:Train (Epoch 192): Loss/seq after 02050 batchs: 378.85382080078125
INFO:root:Train (Epoch 192): Loss/seq after 02100 batchs: 377.8067321777344
INFO:root:Train (Epoch 192): Loss/seq after 02150 batchs: 377.0980529785156
INFO:root:Train (Epoch 192): Loss/seq after 02200 batchs: 375.9674987792969
INFO:root:Train (Epoch 192): Loss/seq after 02250 batchs: 374.892578125
INFO:root:Train (Epoch 192): Loss/seq after 02300 batchs: 371.9542236328125
INFO:root:Train (Epoch 192): Loss/seq after 02350 batchs: 369.8907165527344
INFO:root:Train (Epoch 192): Loss/seq after 02400 batchs: 370.815185546875
INFO:root:Train (Epoch 192): Loss/seq after 02450 batchs: 368.018798828125
INFO:root:Train (Epoch 192): Loss/seq after 02500 batchs: 362.63690185546875
INFO:root:Train (Epoch 192): Loss/seq after 02550 batchs: 357.7315673828125
INFO:root:Train (Epoch 192): Loss/seq after 02600 batchs: 355.90838623046875
INFO:root:Train (Epoch 192): Loss/seq after 02650 batchs: 352.33380126953125
INFO:root:Train (Epoch 192): Loss/seq after 02700 batchs: 350.115234375
INFO:root:Train (Epoch 192): Loss/seq after 02750 batchs: 346.93743896484375
INFO:root:Train (Epoch 192): Loss/seq after 02800 batchs: 345.2575988769531
INFO:root:Train (Epoch 192): Loss/seq after 02850 batchs: 344.99896240234375
INFO:root:Train (Epoch 192): Loss/seq after 02900 batchs: 346.30975341796875
INFO:root:Train (Epoch 192): Loss/seq after 02950 batchs: 346.8429870605469
INFO:root:Train (Epoch 192): Loss/seq after 03000 batchs: 352.47369384765625
INFO:root:Train (Epoch 192): Loss/seq after 03050 batchs: 354.82818603515625
INFO:root:Train (Epoch 192): Loss/seq after 03100 batchs: 356.3103332519531
INFO:root:Train (Epoch 192): Loss/seq after 03150 batchs: 355.581298828125
INFO:root:Train (Epoch 192): Loss/seq after 03200 batchs: 355.3357238769531
INFO:root:Train (Epoch 192): Loss/seq after 03250 batchs: 355.5928039550781
INFO:root:Train (Epoch 192): Loss/seq after 03300 batchs: 355.10986328125
INFO:root:Train (Epoch 192): Loss/seq after 03350 batchs: 353.5916748046875
INFO:root:Train (Epoch 192): Loss/seq after 03400 batchs: 351.2225036621094
INFO:root:Train (Epoch 192): Loss/seq after 03450 batchs: 350.3388671875
INFO:root:Train (Epoch 192): Loss/seq after 03500 batchs: 351.1379699707031
INFO:root:Train (Epoch 192): Loss/seq after 03550 batchs: 349.2733459472656
INFO:root:Train (Epoch 192): Loss/seq after 03600 batchs: 355.5196228027344
INFO:root:Train (Epoch 192): Loss/seq after 03650 batchs: 354.2136535644531
INFO:root:Train (Epoch 192): Loss/seq after 03700 batchs: 356.506591796875
INFO:root:Train (Epoch 192): Loss/seq after 03750 batchs: 360.6767883300781
INFO:root:Train (Epoch 192): Loss/seq after 03800 batchs: 360.0617980957031
INFO:root:Train (Epoch 192): Loss/seq after 03850 batchs: 359.5029296875
INFO:root:Train (Epoch 192): Loss/seq after 03900 batchs: 361.0289001464844
INFO:root:Train (Epoch 192): Loss/seq after 03950 batchs: 363.0359191894531
INFO:root:Train (Epoch 192): Loss/seq after 04000 batchs: 360.9283752441406
INFO:root:Train (Epoch 192): Loss/seq after 04050 batchs: 358.8012390136719
INFO:root:Train (Epoch 192): Loss/seq after 04100 batchs: 358.274658203125
INFO:root:Train (Epoch 192): Loss/seq after 04150 batchs: 358.4140319824219
INFO:root:Train (Epoch 192): Loss/seq after 04200 batchs: 357.7078857421875
INFO:root:Train (Epoch 192): Loss/seq after 04250 batchs: 356.5403137207031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 192): Loss/seq after 00000 batches: 286.03741455078125
INFO:root:# Valid (Epoch 192): Loss/seq after 00050 batches: 465.7144470214844
INFO:root:# Valid (Epoch 192): Loss/seq after 00100 batches: 478.5600891113281
INFO:root:# Valid (Epoch 192): Loss/seq after 00150 batches: 368.9649963378906
INFO:root:# Valid (Epoch 192): Loss/seq after 00200 batches: 350.6244812011719
INFO:root:Artifacts: Make stick videos for epoch 192
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_192_on_20220413_114515.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_192_index_1728_on_20220413_114515.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 193): Loss/seq after 00000 batchs: 604.9840698242188
INFO:root:Train (Epoch 193): Loss/seq after 00050 batchs: 452.9596862792969
INFO:root:Train (Epoch 193): Loss/seq after 00100 batchs: 440.788330078125
INFO:root:Train (Epoch 193): Loss/seq after 00150 batchs: 420.46142578125
INFO:root:Train (Epoch 193): Loss/seq after 00200 batchs: 465.23565673828125
INFO:root:Train (Epoch 193): Loss/seq after 00250 batchs: 520.9326782226562
INFO:root:Train (Epoch 193): Loss/seq after 00300 batchs: 541.3692016601562
INFO:root:Train (Epoch 193): Loss/seq after 00350 batchs: 512.4732666015625
INFO:root:Train (Epoch 193): Loss/seq after 00400 batchs: 497.2768249511719
INFO:root:Train (Epoch 193): Loss/seq after 00450 batchs: 506.54266357421875
INFO:root:Train (Epoch 193): Loss/seq after 00500 batchs: 491.989013671875
INFO:root:Train (Epoch 193): Loss/seq after 00550 batchs: 483.51513671875
INFO:root:Train (Epoch 193): Loss/seq after 00600 batchs: 468.8592224121094
INFO:root:Train (Epoch 193): Loss/seq after 00650 batchs: 451.5208740234375
INFO:root:Train (Epoch 193): Loss/seq after 00700 batchs: 432.3362731933594
INFO:root:Train (Epoch 193): Loss/seq after 00750 batchs: 427.6386413574219
INFO:root:Train (Epoch 193): Loss/seq after 00800 batchs: 434.37176513671875
INFO:root:Train (Epoch 193): Loss/seq after 00850 batchs: 421.9657287597656
INFO:root:Train (Epoch 193): Loss/seq after 00900 batchs: 412.6874694824219
INFO:root:Train (Epoch 193): Loss/seq after 00950 batchs: 410.2295837402344
INFO:root:Train (Epoch 193): Loss/seq after 01000 batchs: 403.3799133300781
INFO:root:Train (Epoch 193): Loss/seq after 01050 batchs: 396.4591979980469
INFO:root:Train (Epoch 193): Loss/seq after 01100 batchs: 389.2825622558594
INFO:root:Train (Epoch 193): Loss/seq after 01150 batchs: 379.19293212890625
INFO:root:Train (Epoch 193): Loss/seq after 01200 batchs: 381.96099853515625
INFO:root:Train (Epoch 193): Loss/seq after 01250 batchs: 383.0158996582031
INFO:root:Train (Epoch 193): Loss/seq after 01300 batchs: 375.2987060546875
INFO:root:Train (Epoch 193): Loss/seq after 01350 batchs: 369.1393737792969
INFO:root:Train (Epoch 193): Loss/seq after 01400 batchs: 370.8939208984375
INFO:root:Train (Epoch 193): Loss/seq after 01450 batchs: 374.3023681640625
INFO:root:Train (Epoch 193): Loss/seq after 01500 batchs: 381.5414733886719
INFO:root:Train (Epoch 193): Loss/seq after 01550 batchs: 381.6582336425781
INFO:root:Train (Epoch 193): Loss/seq after 01600 batchs: 378.7646484375
INFO:root:Train (Epoch 193): Loss/seq after 01650 batchs: 377.4473876953125
INFO:root:Train (Epoch 193): Loss/seq after 01700 batchs: 382.15020751953125
INFO:root:Train (Epoch 193): Loss/seq after 01750 batchs: 380.9241027832031
INFO:root:Train (Epoch 193): Loss/seq after 01800 batchs: 379.1087951660156
INFO:root:Train (Epoch 193): Loss/seq after 01850 batchs: 377.4381103515625
INFO:root:Train (Epoch 193): Loss/seq after 01900 batchs: 376.86102294921875
INFO:root:Train (Epoch 193): Loss/seq after 01950 batchs: 376.4501647949219
INFO:root:Train (Epoch 193): Loss/seq after 02000 batchs: 377.6064758300781
INFO:root:Train (Epoch 193): Loss/seq after 02050 batchs: 378.0121154785156
INFO:root:Train (Epoch 193): Loss/seq after 02100 batchs: 376.96905517578125
INFO:root:Train (Epoch 193): Loss/seq after 02150 batchs: 376.1418151855469
INFO:root:Train (Epoch 193): Loss/seq after 02200 batchs: 375.06365966796875
INFO:root:Train (Epoch 193): Loss/seq after 02250 batchs: 374.059326171875
INFO:root:Train (Epoch 193): Loss/seq after 02300 batchs: 371.34063720703125
INFO:root:Train (Epoch 193): Loss/seq after 02350 batchs: 369.2140808105469
INFO:root:Train (Epoch 193): Loss/seq after 02400 batchs: 370.1026306152344
INFO:root:Train (Epoch 193): Loss/seq after 02450 batchs: 367.4662780761719
INFO:root:Train (Epoch 193): Loss/seq after 02500 batchs: 362.0496520996094
INFO:root:Train (Epoch 193): Loss/seq after 02550 batchs: 357.12261962890625
INFO:root:Train (Epoch 193): Loss/seq after 02600 batchs: 355.2958068847656
INFO:root:Train (Epoch 193): Loss/seq after 02650 batchs: 351.7487487792969
INFO:root:Train (Epoch 193): Loss/seq after 02700 batchs: 349.41644287109375
INFO:root:Train (Epoch 193): Loss/seq after 02750 batchs: 346.3058166503906
INFO:root:Train (Epoch 193): Loss/seq after 02800 batchs: 344.5975036621094
INFO:root:Train (Epoch 193): Loss/seq after 02850 batchs: 344.3997802734375
INFO:root:Train (Epoch 193): Loss/seq after 02900 batchs: 345.7207336425781
INFO:root:Train (Epoch 193): Loss/seq after 02950 batchs: 346.29412841796875
INFO:root:Train (Epoch 193): Loss/seq after 03000 batchs: 351.93585205078125
INFO:root:Train (Epoch 193): Loss/seq after 03050 batchs: 354.2646789550781
INFO:root:Train (Epoch 193): Loss/seq after 03100 batchs: 355.692626953125
INFO:root:Train (Epoch 193): Loss/seq after 03150 batchs: 354.8836669921875
INFO:root:Train (Epoch 193): Loss/seq after 03200 batchs: 354.466552734375
INFO:root:Train (Epoch 193): Loss/seq after 03250 batchs: 354.6788635253906
INFO:root:Train (Epoch 193): Loss/seq after 03300 batchs: 354.4759216308594
INFO:root:Train (Epoch 193): Loss/seq after 03350 batchs: 352.925048828125
INFO:root:Train (Epoch 193): Loss/seq after 03400 batchs: 350.491943359375
INFO:root:Train (Epoch 193): Loss/seq after 03450 batchs: 349.6858825683594
INFO:root:Train (Epoch 193): Loss/seq after 03500 batchs: 350.5855407714844
INFO:root:Train (Epoch 193): Loss/seq after 03550 batchs: 348.72265625
INFO:root:Train (Epoch 193): Loss/seq after 03600 batchs: 354.864501953125
INFO:root:Train (Epoch 193): Loss/seq after 03650 batchs: 353.60888671875
INFO:root:Train (Epoch 193): Loss/seq after 03700 batchs: 355.94171142578125
INFO:root:Train (Epoch 193): Loss/seq after 03750 batchs: 360.10528564453125
INFO:root:Train (Epoch 193): Loss/seq after 03800 batchs: 359.5689392089844
INFO:root:Train (Epoch 193): Loss/seq after 03850 batchs: 358.9903564453125
INFO:root:Train (Epoch 193): Loss/seq after 03900 batchs: 360.4959411621094
INFO:root:Train (Epoch 193): Loss/seq after 03950 batchs: 362.5735778808594
INFO:root:Train (Epoch 193): Loss/seq after 04000 batchs: 360.45794677734375
INFO:root:Train (Epoch 193): Loss/seq after 04050 batchs: 358.3348083496094
INFO:root:Train (Epoch 193): Loss/seq after 04100 batchs: 357.8415832519531
INFO:root:Train (Epoch 193): Loss/seq after 04150 batchs: 357.95013427734375
INFO:root:Train (Epoch 193): Loss/seq after 04200 batchs: 357.1571350097656
INFO:root:Train (Epoch 193): Loss/seq after 04250 batchs: 355.9337463378906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 193): Loss/seq after 00000 batches: 289.740966796875
INFO:root:# Valid (Epoch 193): Loss/seq after 00050 batches: 454.1077880859375
INFO:root:# Valid (Epoch 193): Loss/seq after 00100 batches: 470.1190490722656
INFO:root:# Valid (Epoch 193): Loss/seq after 00150 batches: 363.31988525390625
INFO:root:# Valid (Epoch 193): Loss/seq after 00200 batches: 344.1368408203125
INFO:root:Artifacts: Make stick videos for epoch 193
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_193_on_20220413_115038.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_193_index_1678_on_20220413_115038.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 194): Loss/seq after 00000 batchs: 570.8687744140625
INFO:root:Train (Epoch 194): Loss/seq after 00050 batchs: 445.4743957519531
INFO:root:Train (Epoch 194): Loss/seq after 00100 batchs: 444.55267333984375
INFO:root:Train (Epoch 194): Loss/seq after 00150 batchs: 425.33160400390625
INFO:root:Train (Epoch 194): Loss/seq after 00200 batchs: 469.4390869140625
INFO:root:Train (Epoch 194): Loss/seq after 00250 batchs: 529.987060546875
INFO:root:Train (Epoch 194): Loss/seq after 00300 batchs: 547.2684326171875
INFO:root:Train (Epoch 194): Loss/seq after 00350 batchs: 517.6594848632812
INFO:root:Train (Epoch 194): Loss/seq after 00400 batchs: 500.9764099121094
INFO:root:Train (Epoch 194): Loss/seq after 00450 batchs: 509.6912841796875
INFO:root:Train (Epoch 194): Loss/seq after 00500 batchs: 490.83856201171875
INFO:root:Train (Epoch 194): Loss/seq after 00550 batchs: 482.0487060546875
INFO:root:Train (Epoch 194): Loss/seq after 00600 batchs: 467.1318054199219
INFO:root:Train (Epoch 194): Loss/seq after 00650 batchs: 448.1142883300781
INFO:root:Train (Epoch 194): Loss/seq after 00700 batchs: 429.09130859375
INFO:root:Train (Epoch 194): Loss/seq after 00750 batchs: 424.696044921875
INFO:root:Train (Epoch 194): Loss/seq after 00800 batchs: 428.96441650390625
INFO:root:Train (Epoch 194): Loss/seq after 00850 batchs: 416.4774475097656
INFO:root:Train (Epoch 194): Loss/seq after 00900 batchs: 406.9339294433594
INFO:root:Train (Epoch 194): Loss/seq after 00950 batchs: 404.7379455566406
INFO:root:Train (Epoch 194): Loss/seq after 01000 batchs: 397.8496398925781
INFO:root:Train (Epoch 194): Loss/seq after 01050 batchs: 391.2441101074219
INFO:root:Train (Epoch 194): Loss/seq after 01100 batchs: 383.82891845703125
INFO:root:Train (Epoch 194): Loss/seq after 01150 batchs: 373.89361572265625
INFO:root:Train (Epoch 194): Loss/seq after 01200 batchs: 377.0830383300781
INFO:root:Train (Epoch 194): Loss/seq after 01250 batchs: 378.3892517089844
INFO:root:Train (Epoch 194): Loss/seq after 01300 batchs: 370.6316833496094
INFO:root:Train (Epoch 194): Loss/seq after 01350 batchs: 364.451904296875
INFO:root:Train (Epoch 194): Loss/seq after 01400 batchs: 366.0755310058594
INFO:root:Train (Epoch 194): Loss/seq after 01450 batchs: 369.5278625488281
INFO:root:Train (Epoch 194): Loss/seq after 01500 batchs: 377.35711669921875
INFO:root:Train (Epoch 194): Loss/seq after 01550 batchs: 377.4416809082031
INFO:root:Train (Epoch 194): Loss/seq after 01600 batchs: 374.6182556152344
INFO:root:Train (Epoch 194): Loss/seq after 01650 batchs: 373.3055419921875
INFO:root:Train (Epoch 194): Loss/seq after 01700 batchs: 378.1604919433594
INFO:root:Train (Epoch 194): Loss/seq after 01750 batchs: 377.0484313964844
INFO:root:Train (Epoch 194): Loss/seq after 01800 batchs: 375.4038391113281
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 194): Loss/seq after 01850 batchs: 373.8011169433594
INFO:root:Train (Epoch 194): Loss/seq after 01900 batchs: 373.14697265625
INFO:root:Train (Epoch 194): Loss/seq after 01950 batchs: 372.94049072265625
INFO:root:Train (Epoch 194): Loss/seq after 02000 batchs: 374.0928955078125
INFO:root:Train (Epoch 194): Loss/seq after 02050 batchs: 374.2875671386719
INFO:root:Train (Epoch 194): Loss/seq after 02100 batchs: 373.4905090332031
INFO:root:Train (Epoch 194): Loss/seq after 02150 batchs: 372.697265625
INFO:root:Train (Epoch 194): Loss/seq after 02200 batchs: 371.5934143066406
INFO:root:Train (Epoch 194): Loss/seq after 02250 batchs: 370.6232604980469
INFO:root:Train (Epoch 194): Loss/seq after 02300 batchs: 367.8301086425781
wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)
INFO:root:Train (Epoch 194): Loss/seq after 02350 batchs: 365.7515563964844
INFO:root:Train (Epoch 194): Loss/seq after 02400 batchs: 366.7040100097656
INFO:root:Train (Epoch 194): Loss/seq after 02450 batchs: 364.0280456542969
INFO:root:Train (Epoch 194): Loss/seq after 02500 batchs: 358.6387634277344
INFO:root:Train (Epoch 194): Loss/seq after 02550 batchs: 353.7463684082031
INFO:root:Train (Epoch 194): Loss/seq after 02600 batchs: 351.8478088378906
INFO:root:Train (Epoch 194): Loss/seq after 02650 batchs: 348.36602783203125
INFO:root:Train (Epoch 194): Loss/seq after 02700 batchs: 346.1240234375
INFO:root:Train (Epoch 194): Loss/seq after 02750 batchs: 343.02783203125
INFO:root:Train (Epoch 194): Loss/seq after 02800 batchs: 340.83404541015625
INFO:root:Train (Epoch 194): Loss/seq after 02850 batchs: 340.648681640625
INFO:root:Train (Epoch 194): Loss/seq after 02900 batchs: 342.05108642578125
INFO:root:Train (Epoch 194): Loss/seq after 02950 batchs: 342.62109375
INFO:root:Train (Epoch 194): Loss/seq after 03000 batchs: 348.3455505371094
INFO:root:Train (Epoch 194): Loss/seq after 03050 batchs: 350.7769775390625
INFO:root:Train (Epoch 194): Loss/seq after 03100 batchs: 352.2026672363281
INFO:root:Train (Epoch 194): Loss/seq after 03150 batchs: 351.437255859375
INFO:root:Train (Epoch 194): Loss/seq after 03200 batchs: 351.2173156738281
INFO:root:Train (Epoch 194): Loss/seq after 03250 batchs: 351.48095703125
INFO:root:Train (Epoch 194): Loss/seq after 03300 batchs: 351.06463623046875
INFO:root:Train (Epoch 194): Loss/seq after 03350 batchs: 349.62762451171875
INFO:root:Train (Epoch 194): Loss/seq after 03400 batchs: 347.1900634765625
INFO:root:Train (Epoch 194): Loss/seq after 03450 batchs: 346.2882385253906
INFO:root:Train (Epoch 194): Loss/seq after 03500 batchs: 347.0871887207031
INFO:root:Train (Epoch 194): Loss/seq after 03550 batchs: 345.4158935546875
INFO:root:Train (Epoch 194): Loss/seq after 03600 batchs: 351.47540283203125
INFO:root:Train (Epoch 194): Loss/seq after 03650 batchs: 350.3234558105469
INFO:root:Train (Epoch 194): Loss/seq after 03700 batchs: 352.7784423828125
INFO:root:Train (Epoch 194): Loss/seq after 03750 batchs: 356.99346923828125
INFO:root:Train (Epoch 194): Loss/seq after 03800 batchs: 356.41558837890625
INFO:root:Train (Epoch 194): Loss/seq after 03850 batchs: 355.8085021972656
INFO:root:Train (Epoch 194): Loss/seq after 03900 batchs: 357.33251953125
INFO:root:Train (Epoch 194): Loss/seq after 03950 batchs: 359.44622802734375
INFO:root:Train (Epoch 194): Loss/seq after 04000 batchs: 357.39007568359375
INFO:root:Train (Epoch 194): Loss/seq after 04050 batchs: 355.31597900390625
INFO:root:Train (Epoch 194): Loss/seq after 04100 batchs: 354.850341796875
INFO:root:Train (Epoch 194): Loss/seq after 04150 batchs: 354.9450378417969
INFO:root:Train (Epoch 194): Loss/seq after 04200 batchs: 354.1853332519531
INFO:root:Train (Epoch 194): Loss/seq after 04250 batchs: 352.92547607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 194): Loss/seq after 00000 batches: 292.67572021484375
INFO:root:# Valid (Epoch 194): Loss/seq after 00050 batches: 456.5913391113281
INFO:root:# Valid (Epoch 194): Loss/seq after 00100 batches: 461.89300537109375
INFO:root:# Valid (Epoch 194): Loss/seq after 00150 batches: 361.09552001953125
INFO:root:# Valid (Epoch 194): Loss/seq after 00200 batches: 345.805908203125
INFO:root:Artifacts: Make stick videos for epoch 194
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_194_on_20220413_115558.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_194_index_85_on_20220413_115558.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 195): Loss/seq after 00000 batchs: 756.8480224609375
INFO:root:Train (Epoch 195): Loss/seq after 00050 batchs: 449.0803527832031
INFO:root:Train (Epoch 195): Loss/seq after 00100 batchs: 437.25335693359375
INFO:root:Train (Epoch 195): Loss/seq after 00150 batchs: 418.3370666503906
INFO:root:Train (Epoch 195): Loss/seq after 00200 batchs: 458.3879699707031
INFO:root:Train (Epoch 195): Loss/seq after 00250 batchs: 507.8727111816406
INFO:root:Train (Epoch 195): Loss/seq after 00300 batchs: 528.3307495117188
INFO:root:Train (Epoch 195): Loss/seq after 00350 batchs: 501.1300354003906
INFO:root:Train (Epoch 195): Loss/seq after 00400 batchs: 487.0337219238281
INFO:root:Train (Epoch 195): Loss/seq after 00450 batchs: 497.8367919921875
INFO:root:Train (Epoch 195): Loss/seq after 00500 batchs: 482.37615966796875
INFO:root:Train (Epoch 195): Loss/seq after 00550 batchs: 474.6332092285156
INFO:root:Train (Epoch 195): Loss/seq after 00600 batchs: 460.780029296875
INFO:root:Train (Epoch 195): Loss/seq after 00650 batchs: 443.3712463378906
INFO:root:Train (Epoch 195): Loss/seq after 00700 batchs: 424.8271484375
INFO:root:Train (Epoch 195): Loss/seq after 00750 batchs: 420.2588195800781
INFO:root:Train (Epoch 195): Loss/seq after 00800 batchs: 425.5140686035156
INFO:root:Train (Epoch 195): Loss/seq after 00850 batchs: 413.2973327636719
INFO:root:Train (Epoch 195): Loss/seq after 00900 batchs: 404.1495056152344
INFO:root:Train (Epoch 195): Loss/seq after 00950 batchs: 401.9763488769531
INFO:root:Train (Epoch 195): Loss/seq after 01000 batchs: 395.583984375
INFO:root:Train (Epoch 195): Loss/seq after 01050 batchs: 389.2870178222656
INFO:root:Train (Epoch 195): Loss/seq after 01100 batchs: 381.8816833496094
INFO:root:Train (Epoch 195): Loss/seq after 01150 batchs: 372.1707458496094
INFO:root:Train (Epoch 195): Loss/seq after 01200 batchs: 374.104248046875
INFO:root:Train (Epoch 195): Loss/seq after 01250 batchs: 375.5831298828125
INFO:root:Train (Epoch 195): Loss/seq after 01300 batchs: 368.0873107910156
INFO:root:Train (Epoch 195): Loss/seq after 01350 batchs: 362.0000915527344
INFO:root:Train (Epoch 195): Loss/seq after 01400 batchs: 363.77703857421875
INFO:root:Train (Epoch 195): Loss/seq after 01450 batchs: 367.2999267578125
INFO:root:Train (Epoch 195): Loss/seq after 01500 batchs: 375.0035400390625
INFO:root:Train (Epoch 195): Loss/seq after 01550 batchs: 374.9762878417969
INFO:root:Train (Epoch 195): Loss/seq after 01600 batchs: 371.9842834472656
INFO:root:Train (Epoch 195): Loss/seq after 01650 batchs: 370.8075256347656
INFO:root:Train (Epoch 195): Loss/seq after 01700 batchs: 375.8254699707031
INFO:root:Train (Epoch 195): Loss/seq after 01750 batchs: 374.5928649902344
INFO:root:Train (Epoch 195): Loss/seq after 01800 batchs: 373.1028137207031
INFO:root:Train (Epoch 195): Loss/seq after 01850 batchs: 371.5652160644531
INFO:root:Train (Epoch 195): Loss/seq after 01900 batchs: 370.9960632324219
INFO:root:Train (Epoch 195): Loss/seq after 01950 batchs: 370.70501708984375
INFO:root:Train (Epoch 195): Loss/seq after 02000 batchs: 371.92138671875
INFO:root:Train (Epoch 195): Loss/seq after 02050 batchs: 372.25054931640625
INFO:root:Train (Epoch 195): Loss/seq after 02100 batchs: 371.3594055175781
INFO:root:Train (Epoch 195): Loss/seq after 02150 batchs: 370.6386413574219
INFO:root:Train (Epoch 195): Loss/seq after 02200 batchs: 369.5966491699219
INFO:root:Train (Epoch 195): Loss/seq after 02250 batchs: 368.4703674316406
INFO:root:Train (Epoch 195): Loss/seq after 02300 batchs: 365.61517333984375
INFO:root:Train (Epoch 195): Loss/seq after 02350 batchs: 363.4228515625
INFO:root:Train (Epoch 195): Loss/seq after 02400 batchs: 364.33447265625
INFO:root:Train (Epoch 195): Loss/seq after 02450 batchs: 361.6273498535156
INFO:root:Train (Epoch 195): Loss/seq after 02500 batchs: 356.3147888183594
INFO:root:Train (Epoch 195): Loss/seq after 02550 batchs: 351.4488220214844
INFO:root:Train (Epoch 195): Loss/seq after 02600 batchs: 349.7005615234375
INFO:root:Train (Epoch 195): Loss/seq after 02650 batchs: 346.185791015625
INFO:root:Train (Epoch 195): Loss/seq after 02700 batchs: 343.9906311035156
INFO:root:Train (Epoch 195): Loss/seq after 02750 batchs: 340.9159851074219
INFO:root:Train (Epoch 195): Loss/seq after 02800 batchs: 339.08154296875
INFO:root:Train (Epoch 195): Loss/seq after 02850 batchs: 338.9085998535156
INFO:root:Train (Epoch 195): Loss/seq after 02900 batchs: 340.2678527832031
INFO:root:Train (Epoch 195): Loss/seq after 02950 batchs: 340.93804931640625
INFO:root:Train (Epoch 195): Loss/seq after 03000 batchs: 346.5705261230469
INFO:root:Train (Epoch 195): Loss/seq after 03050 batchs: 348.9675598144531
INFO:root:Train (Epoch 195): Loss/seq after 03100 batchs: 350.5557861328125
INFO:root:Train (Epoch 195): Loss/seq after 03150 batchs: 350.16094970703125
INFO:root:Train (Epoch 195): Loss/seq after 03200 batchs: 349.9188232421875
INFO:root:Train (Epoch 195): Loss/seq after 03250 batchs: 350.1593017578125
INFO:root:Train (Epoch 195): Loss/seq after 03300 batchs: 349.8808288574219
INFO:root:Train (Epoch 195): Loss/seq after 03350 batchs: 348.51171875
INFO:root:Train (Epoch 195): Loss/seq after 03400 batchs: 346.0718688964844
INFO:root:Train (Epoch 195): Loss/seq after 03450 batchs: 345.200439453125
INFO:root:Train (Epoch 195): Loss/seq after 03500 batchs: 346.2522888183594
INFO:root:Train (Epoch 195): Loss/seq after 03550 batchs: 344.51983642578125
INFO:root:Train (Epoch 195): Loss/seq after 03600 batchs: 350.7389221191406
INFO:root:Train (Epoch 195): Loss/seq after 03650 batchs: 349.58099365234375
INFO:root:Train (Epoch 195): Loss/seq after 03700 batchs: 351.82073974609375
INFO:root:Train (Epoch 195): Loss/seq after 03750 batchs: 356.0472106933594
INFO:root:Train (Epoch 195): Loss/seq after 03800 batchs: 355.5203552246094
INFO:root:Train (Epoch 195): Loss/seq after 03850 batchs: 354.9747619628906
INFO:root:Train (Epoch 195): Loss/seq after 03900 batchs: 356.4725341796875
INFO:root:Train (Epoch 195): Loss/seq after 03950 batchs: 358.60479736328125
INFO:root:Train (Epoch 195): Loss/seq after 04000 batchs: 356.5927429199219
INFO:root:Train (Epoch 195): Loss/seq after 04050 batchs: 354.5224609375
INFO:root:Train (Epoch 195): Loss/seq after 04100 batchs: 354.0738830566406
INFO:root:Train (Epoch 195): Loss/seq after 04150 batchs: 354.1765441894531
INFO:root:Train (Epoch 195): Loss/seq after 04200 batchs: 353.44635009765625
INFO:root:Train (Epoch 195): Loss/seq after 04250 batchs: 352.2216796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 195): Loss/seq after 00000 batches: 301.30816650390625
INFO:root:# Valid (Epoch 195): Loss/seq after 00050 batches: 472.9808654785156
INFO:root:# Valid (Epoch 195): Loss/seq after 00100 batches: 470.608642578125
INFO:root:# Valid (Epoch 195): Loss/seq after 00150 batches: 363.340087890625
INFO:root:# Valid (Epoch 195): Loss/seq after 00200 batches: 344.9072265625
INFO:root:Artifacts: Make stick videos for epoch 195
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_195_on_20220413_120120.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_195_index_476_on_20220413_120120.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 196): Loss/seq after 00000 batchs: 530.65380859375
INFO:root:Train (Epoch 196): Loss/seq after 00050 batchs: 451.3631591796875
INFO:root:Train (Epoch 196): Loss/seq after 00100 batchs: 442.966064453125
INFO:root:Train (Epoch 196): Loss/seq after 00150 batchs: 420.0039978027344
INFO:root:Train (Epoch 196): Loss/seq after 00200 batchs: 462.0540466308594
INFO:root:Train (Epoch 196): Loss/seq after 00250 batchs: 517.7501220703125
INFO:root:Train (Epoch 196): Loss/seq after 00300 batchs: 535.5899658203125
INFO:root:Train (Epoch 196): Loss/seq after 00350 batchs: 507.5887756347656
INFO:root:Train (Epoch 196): Loss/seq after 00400 batchs: 493.9598388671875
INFO:root:Train (Epoch 196): Loss/seq after 00450 batchs: 503.66595458984375
INFO:root:Train (Epoch 196): Loss/seq after 00500 batchs: 487.7740783691406
INFO:root:Train (Epoch 196): Loss/seq after 00550 batchs: 479.46240234375
INFO:root:Train (Epoch 196): Loss/seq after 00600 batchs: 464.641357421875
INFO:root:Train (Epoch 196): Loss/seq after 00650 batchs: 446.2966613769531
INFO:root:Train (Epoch 196): Loss/seq after 00700 batchs: 427.7944641113281
INFO:root:Train (Epoch 196): Loss/seq after 00750 batchs: 424.0238952636719
INFO:root:Train (Epoch 196): Loss/seq after 00800 batchs: 428.917724609375
INFO:root:Train (Epoch 196): Loss/seq after 00850 batchs: 416.627197265625
INFO:root:Train (Epoch 196): Loss/seq after 00900 batchs: 407.02813720703125
INFO:root:Train (Epoch 196): Loss/seq after 00950 batchs: 405.0460205078125
INFO:root:Train (Epoch 196): Loss/seq after 01000 batchs: 398.2417297363281
INFO:root:Train (Epoch 196): Loss/seq after 01050 batchs: 391.2676086425781
INFO:root:Train (Epoch 196): Loss/seq after 01100 batchs: 383.6940612792969
INFO:root:Train (Epoch 196): Loss/seq after 01150 batchs: 373.8831787109375
INFO:root:Train (Epoch 196): Loss/seq after 01200 batchs: 376.0619201660156
INFO:root:Train (Epoch 196): Loss/seq after 01250 batchs: 377.12457275390625
INFO:root:Train (Epoch 196): Loss/seq after 01300 batchs: 369.494384765625
INFO:root:Train (Epoch 196): Loss/seq after 01350 batchs: 363.3681640625
INFO:root:Train (Epoch 196): Loss/seq after 01400 batchs: 364.8247985839844
INFO:root:Train (Epoch 196): Loss/seq after 01450 batchs: 367.97637939453125
INFO:root:Train (Epoch 196): Loss/seq after 01500 batchs: 375.23944091796875
INFO:root:Train (Epoch 196): Loss/seq after 01550 batchs: 375.0965881347656
INFO:root:Train (Epoch 196): Loss/seq after 01600 batchs: 372.2405700683594
INFO:root:Train (Epoch 196): Loss/seq after 01650 batchs: 370.96197509765625
INFO:root:Train (Epoch 196): Loss/seq after 01700 batchs: 375.7972106933594
INFO:root:Train (Epoch 196): Loss/seq after 01750 batchs: 374.6013488769531
INFO:root:Train (Epoch 196): Loss/seq after 01800 batchs: 372.97265625
INFO:root:Train (Epoch 196): Loss/seq after 01850 batchs: 371.3681640625
INFO:root:Train (Epoch 196): Loss/seq after 01900 batchs: 370.75830078125
INFO:root:Train (Epoch 196): Loss/seq after 01950 batchs: 370.6929931640625
INFO:root:Train (Epoch 196): Loss/seq after 02000 batchs: 371.9486999511719
INFO:root:Train (Epoch 196): Loss/seq after 02050 batchs: 372.3223571777344
INFO:root:Train (Epoch 196): Loss/seq after 02100 batchs: 371.4996032714844
INFO:root:Train (Epoch 196): Loss/seq after 02150 batchs: 370.8213195800781
INFO:root:Train (Epoch 196): Loss/seq after 02200 batchs: 369.8510437011719
INFO:root:Train (Epoch 196): Loss/seq after 02250 batchs: 368.7417297363281
INFO:root:Train (Epoch 196): Loss/seq after 02300 batchs: 365.86993408203125
INFO:root:Train (Epoch 196): Loss/seq after 02350 batchs: 363.67352294921875
INFO:root:Train (Epoch 196): Loss/seq after 02400 batchs: 364.54815673828125
INFO:root:Train (Epoch 196): Loss/seq after 02450 batchs: 361.82342529296875
INFO:root:Train (Epoch 196): Loss/seq after 02500 batchs: 356.5140075683594
INFO:root:Train (Epoch 196): Loss/seq after 02550 batchs: 351.6181945800781
INFO:root:Train (Epoch 196): Loss/seq after 02600 batchs: 349.6732482910156
INFO:root:Train (Epoch 196): Loss/seq after 02650 batchs: 346.1619873046875
INFO:root:Train (Epoch 196): Loss/seq after 02700 batchs: 343.9012451171875
INFO:root:Train (Epoch 196): Loss/seq after 02750 batchs: 340.7615661621094
INFO:root:Train (Epoch 196): Loss/seq after 02800 batchs: 338.8095703125
INFO:root:Train (Epoch 196): Loss/seq after 02850 batchs: 338.6520690917969
INFO:root:Train (Epoch 196): Loss/seq after 02900 batchs: 339.9211730957031
INFO:root:Train (Epoch 196): Loss/seq after 02950 batchs: 340.5191345214844
INFO:root:Train (Epoch 196): Loss/seq after 03000 batchs: 346.0908203125
INFO:root:Train (Epoch 196): Loss/seq after 03050 batchs: 348.4031677246094
INFO:root:Train (Epoch 196): Loss/seq after 03100 batchs: 349.96734619140625
INFO:root:Train (Epoch 196): Loss/seq after 03150 batchs: 349.27734375
INFO:root:Train (Epoch 196): Loss/seq after 03200 batchs: 348.8896484375
INFO:root:Train (Epoch 196): Loss/seq after 03250 batchs: 349.4097595214844
INFO:root:Train (Epoch 196): Loss/seq after 03300 batchs: 349.1415100097656
INFO:root:Train (Epoch 196): Loss/seq after 03350 batchs: 347.8805847167969
INFO:root:Train (Epoch 196): Loss/seq after 03400 batchs: 345.4938659667969
INFO:root:Train (Epoch 196): Loss/seq after 03450 batchs: 344.6729431152344
INFO:root:Train (Epoch 196): Loss/seq after 03500 batchs: 345.64691162109375
INFO:root:Train (Epoch 196): Loss/seq after 03550 batchs: 343.7501220703125
INFO:root:Train (Epoch 196): Loss/seq after 03600 batchs: 349.7026062011719
INFO:root:Train (Epoch 196): Loss/seq after 03650 batchs: 348.43963623046875
INFO:root:Train (Epoch 196): Loss/seq after 03700 batchs: 350.5281066894531
INFO:root:Train (Epoch 196): Loss/seq after 03750 batchs: 354.67303466796875
INFO:root:Train (Epoch 196): Loss/seq after 03800 batchs: 354.1264343261719
INFO:root:Train (Epoch 196): Loss/seq after 03850 batchs: 353.5422668457031
INFO:root:Train (Epoch 196): Loss/seq after 03900 batchs: 354.9399108886719
INFO:root:Train (Epoch 196): Loss/seq after 03950 batchs: 357.00848388671875
INFO:root:Train (Epoch 196): Loss/seq after 04000 batchs: 354.965576171875
INFO:root:Train (Epoch 196): Loss/seq after 04050 batchs: 352.8940734863281
INFO:root:Train (Epoch 196): Loss/seq after 04100 batchs: 352.4697570800781
INFO:root:Train (Epoch 196): Loss/seq after 04150 batchs: 352.5843505859375
INFO:root:Train (Epoch 196): Loss/seq after 04200 batchs: 351.8285827636719
INFO:root:Train (Epoch 196): Loss/seq after 04250 batchs: 350.62060546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 196): Loss/seq after 00000 batches: 292.63385009765625
INFO:root:# Valid (Epoch 196): Loss/seq after 00050 batches: 467.28912353515625
INFO:root:# Valid (Epoch 196): Loss/seq after 00100 batches: 473.43609619140625
INFO:root:# Valid (Epoch 196): Loss/seq after 00150 batches: 364.8191833496094
INFO:root:# Valid (Epoch 196): Loss/seq after 00200 batches: 348.421875
INFO:root:Artifacts: Make stick videos for epoch 196
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_196_on_20220413_120642.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_196_index_1659_on_20220413_120642.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 197): Loss/seq after 00000 batchs: 696.9459838867188
INFO:root:Train (Epoch 197): Loss/seq after 00050 batchs: 457.0858459472656
INFO:root:Train (Epoch 197): Loss/seq after 00100 batchs: 441.9427185058594
INFO:root:Train (Epoch 197): Loss/seq after 00150 batchs: 421.5992736816406
INFO:root:Train (Epoch 197): Loss/seq after 00200 batchs: 470.7649230957031
INFO:root:Train (Epoch 197): Loss/seq after 00250 batchs: 519.2659912109375
INFO:root:Train (Epoch 197): Loss/seq after 00300 batchs: 537.0787963867188
INFO:root:Train (Epoch 197): Loss/seq after 00350 batchs: 508.7237854003906
INFO:root:Train (Epoch 197): Loss/seq after 00400 batchs: 493.26812744140625
INFO:root:Train (Epoch 197): Loss/seq after 00450 batchs: 502.5936279296875
INFO:root:Train (Epoch 197): Loss/seq after 00500 batchs: 486.24224853515625
INFO:root:Train (Epoch 197): Loss/seq after 00550 batchs: 477.76373291015625
INFO:root:Train (Epoch 197): Loss/seq after 00600 batchs: 463.05352783203125
INFO:root:Train (Epoch 197): Loss/seq after 00650 batchs: 444.70098876953125
INFO:root:Train (Epoch 197): Loss/seq after 00700 batchs: 426.0465393066406
INFO:root:Train (Epoch 197): Loss/seq after 00750 batchs: 421.3747863769531
INFO:root:Train (Epoch 197): Loss/seq after 00800 batchs: 426.0179748535156
INFO:root:Train (Epoch 197): Loss/seq after 00850 batchs: 413.22698974609375
INFO:root:Train (Epoch 197): Loss/seq after 00900 batchs: 403.8075866699219
INFO:root:Train (Epoch 197): Loss/seq after 00950 batchs: 401.6548156738281
INFO:root:Train (Epoch 197): Loss/seq after 01000 batchs: 395.0194396972656
INFO:root:Train (Epoch 197): Loss/seq after 01050 batchs: 388.4911193847656
INFO:root:Train (Epoch 197): Loss/seq after 01100 batchs: 381.11151123046875
INFO:root:Train (Epoch 197): Loss/seq after 01150 batchs: 371.2525329589844
INFO:root:Train (Epoch 197): Loss/seq after 01200 batchs: 374.48046875
INFO:root:Train (Epoch 197): Loss/seq after 01250 batchs: 375.94830322265625
INFO:root:Train (Epoch 197): Loss/seq after 01300 batchs: 368.33319091796875
INFO:root:Train (Epoch 197): Loss/seq after 01350 batchs: 362.1597900390625
INFO:root:Train (Epoch 197): Loss/seq after 01400 batchs: 363.5867004394531
INFO:root:Train (Epoch 197): Loss/seq after 01450 batchs: 366.8559265136719
INFO:root:Train (Epoch 197): Loss/seq after 01500 batchs: 374.7146301269531
INFO:root:Train (Epoch 197): Loss/seq after 01550 batchs: 374.7098388671875
INFO:root:Train (Epoch 197): Loss/seq after 01600 batchs: 372.2524108886719
INFO:root:Train (Epoch 197): Loss/seq after 01650 batchs: 371.0104064941406
INFO:root:Train (Epoch 197): Loss/seq after 01700 batchs: 375.66412353515625
INFO:root:Train (Epoch 197): Loss/seq after 01750 batchs: 374.3983154296875
INFO:root:Train (Epoch 197): Loss/seq after 01800 batchs: 372.5093994140625
INFO:root:Train (Epoch 197): Loss/seq after 01850 batchs: 370.8475341796875
INFO:root:Train (Epoch 197): Loss/seq after 01900 batchs: 370.0234680175781
INFO:root:Train (Epoch 197): Loss/seq after 01950 batchs: 370.0752868652344
INFO:root:Train (Epoch 197): Loss/seq after 02000 batchs: 371.1964111328125
INFO:root:Train (Epoch 197): Loss/seq after 02050 batchs: 371.4366455078125
INFO:root:Train (Epoch 197): Loss/seq after 02100 batchs: 370.3976135253906
INFO:root:Train (Epoch 197): Loss/seq after 02150 batchs: 369.63690185546875
INFO:root:Train (Epoch 197): Loss/seq after 02200 batchs: 368.6429138183594
INFO:root:Train (Epoch 197): Loss/seq after 02250 batchs: 367.5234375
INFO:root:Train (Epoch 197): Loss/seq after 02300 batchs: 364.7424621582031
INFO:root:Train (Epoch 197): Loss/seq after 02350 batchs: 362.5199890136719
INFO:root:Train (Epoch 197): Loss/seq after 02400 batchs: 363.41619873046875
INFO:root:Train (Epoch 197): Loss/seq after 02450 batchs: 360.6962890625
INFO:root:Train (Epoch 197): Loss/seq after 02500 batchs: 355.38330078125
INFO:root:Train (Epoch 197): Loss/seq after 02550 batchs: 350.50250244140625
INFO:root:Train (Epoch 197): Loss/seq after 02600 batchs: 348.6053161621094
INFO:root:Train (Epoch 197): Loss/seq after 02650 batchs: 345.0847473144531
INFO:root:Train (Epoch 197): Loss/seq after 02700 batchs: 342.7977294921875
INFO:root:Train (Epoch 197): Loss/seq after 02750 batchs: 339.63421630859375
INFO:root:Train (Epoch 197): Loss/seq after 02800 batchs: 337.61407470703125
INFO:root:Train (Epoch 197): Loss/seq after 02850 batchs: 337.38922119140625
INFO:root:Train (Epoch 197): Loss/seq after 02900 batchs: 338.6778564453125
INFO:root:Train (Epoch 197): Loss/seq after 02950 batchs: 339.3092956542969
INFO:root:Train (Epoch 197): Loss/seq after 03000 batchs: 344.9534912109375
INFO:root:Train (Epoch 197): Loss/seq after 03050 batchs: 347.4248046875
INFO:root:Train (Epoch 197): Loss/seq after 03100 batchs: 348.8008728027344
INFO:root:Train (Epoch 197): Loss/seq after 03150 batchs: 348.0957336425781
INFO:root:Train (Epoch 197): Loss/seq after 03200 batchs: 347.64276123046875
INFO:root:Train (Epoch 197): Loss/seq after 03250 batchs: 348.0531311035156
INFO:root:Train (Epoch 197): Loss/seq after 03300 batchs: 347.53131103515625
INFO:root:Train (Epoch 197): Loss/seq after 03350 batchs: 346.04107666015625
INFO:root:Train (Epoch 197): Loss/seq after 03400 batchs: 343.6667175292969
INFO:root:Train (Epoch 197): Loss/seq after 03450 batchs: 342.8060607910156
INFO:root:Train (Epoch 197): Loss/seq after 03500 batchs: 343.66680908203125
INFO:root:Train (Epoch 197): Loss/seq after 03550 batchs: 341.9263610839844
INFO:root:Train (Epoch 197): Loss/seq after 03600 batchs: 348.1049499511719
INFO:root:Train (Epoch 197): Loss/seq after 03650 batchs: 346.9177551269531
INFO:root:Train (Epoch 197): Loss/seq after 03700 batchs: 349.18084716796875
INFO:root:Train (Epoch 197): Loss/seq after 03750 batchs: 353.52789306640625
INFO:root:Train (Epoch 197): Loss/seq after 03800 batchs: 352.9945068359375
INFO:root:Train (Epoch 197): Loss/seq after 03850 batchs: 352.4411926269531
INFO:root:Train (Epoch 197): Loss/seq after 03900 batchs: 354.0575866699219
INFO:root:Train (Epoch 197): Loss/seq after 03950 batchs: 356.1632385253906
INFO:root:Train (Epoch 197): Loss/seq after 04000 batchs: 354.141357421875
INFO:root:Train (Epoch 197): Loss/seq after 04050 batchs: 352.1069641113281
INFO:root:Train (Epoch 197): Loss/seq after 04100 batchs: 351.6739807128906
INFO:root:Train (Epoch 197): Loss/seq after 04150 batchs: 351.7893981933594
INFO:root:Train (Epoch 197): Loss/seq after 04200 batchs: 351.0228576660156
INFO:root:Train (Epoch 197): Loss/seq after 04250 batchs: 349.88323974609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 197): Loss/seq after 00000 batches: 299.5829772949219
INFO:root:# Valid (Epoch 197): Loss/seq after 00050 batches: 472.93292236328125
INFO:root:# Valid (Epoch 197): Loss/seq after 00100 batches: 493.9382629394531
INFO:root:# Valid (Epoch 197): Loss/seq after 00150 batches: 382.8824157714844
INFO:root:# Valid (Epoch 197): Loss/seq after 00200 batches: 368.29791259765625
INFO:root:Artifacts: Make stick videos for epoch 197
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_197_on_20220413_121205.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_197_index_140_on_20220413_121205.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 198): Loss/seq after 00000 batchs: 587.3991088867188
INFO:root:Train (Epoch 198): Loss/seq after 00050 batchs: 459.0603332519531
INFO:root:Train (Epoch 198): Loss/seq after 00100 batchs: 441.6157531738281
INFO:root:Train (Epoch 198): Loss/seq after 00150 batchs: 422.541259765625
INFO:root:Train (Epoch 198): Loss/seq after 00200 batchs: 461.7718200683594
INFO:root:Train (Epoch 198): Loss/seq after 00250 batchs: 514.6212768554688
INFO:root:Train (Epoch 198): Loss/seq after 00300 batchs: 533.2030029296875
INFO:root:Train (Epoch 198): Loss/seq after 00350 batchs: 505.0793151855469
INFO:root:Train (Epoch 198): Loss/seq after 00400 batchs: 491.2533264160156
INFO:root:Train (Epoch 198): Loss/seq after 00450 batchs: 501.1357116699219
INFO:root:Train (Epoch 198): Loss/seq after 00500 batchs: 484.0522766113281
INFO:root:Train (Epoch 198): Loss/seq after 00550 batchs: 475.7720031738281
INFO:root:Train (Epoch 198): Loss/seq after 00600 batchs: 460.49853515625
INFO:root:Train (Epoch 198): Loss/seq after 00650 batchs: 442.31024169921875
INFO:root:Train (Epoch 198): Loss/seq after 00700 batchs: 423.3115234375
INFO:root:Train (Epoch 198): Loss/seq after 00750 batchs: 418.447021484375
INFO:root:Train (Epoch 198): Loss/seq after 00800 batchs: 422.67657470703125
INFO:root:Train (Epoch 198): Loss/seq after 00850 batchs: 410.42193603515625
INFO:root:Train (Epoch 198): Loss/seq after 00900 batchs: 401.1197509765625
INFO:root:Train (Epoch 198): Loss/seq after 00950 batchs: 398.60760498046875
INFO:root:Train (Epoch 198): Loss/seq after 01000 batchs: 392.023681640625
INFO:root:Train (Epoch 198): Loss/seq after 01050 batchs: 385.1893005371094
INFO:root:Train (Epoch 198): Loss/seq after 01100 batchs: 377.56207275390625
INFO:root:Train (Epoch 198): Loss/seq after 01150 batchs: 367.70001220703125
INFO:root:Train (Epoch 198): Loss/seq after 01200 batchs: 370.2508239746094
INFO:root:Train (Epoch 198): Loss/seq after 01250 batchs: 371.55596923828125
INFO:root:Train (Epoch 198): Loss/seq after 01300 batchs: 364.0909729003906
INFO:root:Train (Epoch 198): Loss/seq after 01350 batchs: 357.99676513671875
INFO:root:Train (Epoch 198): Loss/seq after 01400 batchs: 359.5452880859375
INFO:root:Train (Epoch 198): Loss/seq after 01450 batchs: 363.0502624511719
INFO:root:Train (Epoch 198): Loss/seq after 01500 batchs: 370.71533203125
INFO:root:Train (Epoch 198): Loss/seq after 01550 batchs: 370.70233154296875
INFO:root:Train (Epoch 198): Loss/seq after 01600 batchs: 368.062255859375
INFO:root:Train (Epoch 198): Loss/seq after 01650 batchs: 366.7978210449219
INFO:root:Train (Epoch 198): Loss/seq after 01700 batchs: 371.7870178222656
INFO:root:Train (Epoch 198): Loss/seq after 01750 batchs: 370.62030029296875
INFO:root:Train (Epoch 198): Loss/seq after 01800 batchs: 368.934814453125
INFO:root:Train (Epoch 198): Loss/seq after 01850 batchs: 367.3796691894531
INFO:root:Train (Epoch 198): Loss/seq after 01900 batchs: 366.8078918457031
INFO:root:Train (Epoch 198): Loss/seq after 01950 batchs: 366.68341064453125
INFO:root:Train (Epoch 198): Loss/seq after 02000 batchs: 367.8611755371094
INFO:root:Train (Epoch 198): Loss/seq after 02050 batchs: 368.1737976074219
INFO:root:Train (Epoch 198): Loss/seq after 02100 batchs: 367.0880126953125
INFO:root:Train (Epoch 198): Loss/seq after 02150 batchs: 366.4056701660156
INFO:root:Train (Epoch 198): Loss/seq after 02200 batchs: 365.4703674316406
INFO:root:Train (Epoch 198): Loss/seq after 02250 batchs: 364.377685546875
INFO:root:Train (Epoch 198): Loss/seq after 02300 batchs: 361.5611267089844
INFO:root:Train (Epoch 198): Loss/seq after 02350 batchs: 359.450439453125
INFO:root:Train (Epoch 198): Loss/seq after 02400 batchs: 360.3353576660156
INFO:root:Train (Epoch 198): Loss/seq after 02450 batchs: 357.6017150878906
INFO:root:Train (Epoch 198): Loss/seq after 02500 batchs: 352.3033142089844
INFO:root:Train (Epoch 198): Loss/seq after 02550 batchs: 347.4715881347656
INFO:root:Train (Epoch 198): Loss/seq after 02600 batchs: 345.5397644042969
INFO:root:Train (Epoch 198): Loss/seq after 02650 batchs: 341.9691467285156
INFO:root:Train (Epoch 198): Loss/seq after 02700 batchs: 339.752685546875
INFO:root:Train (Epoch 198): Loss/seq after 02750 batchs: 336.7374267578125
INFO:root:Train (Epoch 198): Loss/seq after 02800 batchs: 334.88446044921875
INFO:root:Train (Epoch 198): Loss/seq after 02850 batchs: 334.7060546875
INFO:root:Train (Epoch 198): Loss/seq after 02900 batchs: 336.00439453125
INFO:root:Train (Epoch 198): Loss/seq after 02950 batchs: 336.71380615234375
INFO:root:Train (Epoch 198): Loss/seq after 03000 batchs: 342.327880859375
INFO:root:Train (Epoch 198): Loss/seq after 03050 batchs: 344.6255187988281
INFO:root:Train (Epoch 198): Loss/seq after 03100 batchs: 346.0057067871094
INFO:root:Train (Epoch 198): Loss/seq after 03150 batchs: 345.45050048828125
INFO:root:Train (Epoch 198): Loss/seq after 03200 batchs: 345.11431884765625
INFO:root:Train (Epoch 198): Loss/seq after 03250 batchs: 345.2818298339844
INFO:root:Train (Epoch 198): Loss/seq after 03300 batchs: 344.9656982421875
INFO:root:Train (Epoch 198): Loss/seq after 03350 batchs: 343.5510559082031
INFO:root:Train (Epoch 198): Loss/seq after 03400 batchs: 341.17926025390625
INFO:root:Train (Epoch 198): Loss/seq after 03450 batchs: 340.2241516113281
INFO:root:Train (Epoch 198): Loss/seq after 03500 batchs: 340.9951477050781
INFO:root:Train (Epoch 198): Loss/seq after 03550 batchs: 339.21954345703125
INFO:root:Train (Epoch 198): Loss/seq after 03600 batchs: 345.24395751953125
INFO:root:Train (Epoch 198): Loss/seq after 03650 batchs: 343.99005126953125
INFO:root:Train (Epoch 198): Loss/seq after 03700 batchs: 346.2492980957031
INFO:root:Train (Epoch 198): Loss/seq after 03750 batchs: 350.45111083984375
INFO:root:Train (Epoch 198): Loss/seq after 03800 batchs: 349.976318359375
INFO:root:Train (Epoch 198): Loss/seq after 03850 batchs: 349.4256286621094
INFO:root:Train (Epoch 198): Loss/seq after 03900 batchs: 350.712890625
INFO:root:Train (Epoch 198): Loss/seq after 03950 batchs: 352.7544250488281
INFO:root:Train (Epoch 198): Loss/seq after 04000 batchs: 350.74639892578125
INFO:root:Train (Epoch 198): Loss/seq after 04050 batchs: 348.720947265625
INFO:root:Train (Epoch 198): Loss/seq after 04100 batchs: 348.2960205078125
INFO:root:Train (Epoch 198): Loss/seq after 04150 batchs: 348.4280090332031
INFO:root:Train (Epoch 198): Loss/seq after 04200 batchs: 347.7086486816406
INFO:root:Train (Epoch 198): Loss/seq after 04250 batchs: 346.5487976074219
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 198): Loss/seq after 00000 batches: 292.4530029296875
INFO:root:# Valid (Epoch 198): Loss/seq after 00050 batches: 458.4778137207031
INFO:root:# Valid (Epoch 198): Loss/seq after 00100 batches: 471.3794860839844
INFO:root:# Valid (Epoch 198): Loss/seq after 00150 batches: 364.20965576171875
INFO:root:# Valid (Epoch 198): Loss/seq after 00200 batches: 349.3270568847656
INFO:root:Artifacts: Make stick videos for epoch 198
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_198_on_20220413_121727.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_198_index_1158_on_20220413_121727.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 199): Loss/seq after 00000 batchs: 527.665283203125
INFO:root:Train (Epoch 199): Loss/seq after 00050 batchs: 452.2958984375
INFO:root:Train (Epoch 199): Loss/seq after 00100 batchs: 438.1099548339844
INFO:root:Train (Epoch 199): Loss/seq after 00150 batchs: 417.4857177734375
INFO:root:Train (Epoch 199): Loss/seq after 00200 batchs: 458.64056396484375
INFO:root:Train (Epoch 199): Loss/seq after 00250 batchs: 510.85418701171875
INFO:root:Train (Epoch 199): Loss/seq after 00300 batchs: 530.9983520507812
INFO:root:Train (Epoch 199): Loss/seq after 00350 batchs: 502.16400146484375
INFO:root:Train (Epoch 199): Loss/seq after 00400 batchs: 485.24560546875
INFO:root:Train (Epoch 199): Loss/seq after 00450 batchs: 495.0917663574219
INFO:root:Train (Epoch 199): Loss/seq after 00500 batchs: 477.2466735839844
INFO:root:Train (Epoch 199): Loss/seq after 00550 batchs: 468.8330993652344
INFO:root:Train (Epoch 199): Loss/seq after 00600 batchs: 454.8563232421875
INFO:root:Train (Epoch 199): Loss/seq after 00650 batchs: 437.2424011230469
INFO:root:Train (Epoch 199): Loss/seq after 00700 batchs: 418.6924133300781
INFO:root:Train (Epoch 199): Loss/seq after 00750 batchs: 413.47076416015625
INFO:root:Train (Epoch 199): Loss/seq after 00800 batchs: 418.5484313964844
INFO:root:Train (Epoch 199): Loss/seq after 00850 batchs: 406.3508605957031
INFO:root:Train (Epoch 199): Loss/seq after 00900 batchs: 397.39044189453125
INFO:root:Train (Epoch 199): Loss/seq after 00950 batchs: 394.8210754394531
INFO:root:Train (Epoch 199): Loss/seq after 01000 batchs: 388.5201110839844
INFO:root:Train (Epoch 199): Loss/seq after 01050 batchs: 382.4148254394531
INFO:root:Train (Epoch 199): Loss/seq after 01100 batchs: 375.36029052734375
INFO:root:Train (Epoch 199): Loss/seq after 01150 batchs: 365.6522216796875
INFO:root:Train (Epoch 199): Loss/seq after 01200 batchs: 368.09942626953125
INFO:root:Train (Epoch 199): Loss/seq after 01250 batchs: 369.57220458984375
INFO:root:Train (Epoch 199): Loss/seq after 01300 batchs: 361.79803466796875
INFO:root:Train (Epoch 199): Loss/seq after 01350 batchs: 355.5780944824219
INFO:root:Train (Epoch 199): Loss/seq after 01400 batchs: 357.1871643066406
INFO:root:Train (Epoch 199): Loss/seq after 01450 batchs: 360.6226806640625
INFO:root:Train (Epoch 199): Loss/seq after 01500 batchs: 368.5066833496094
INFO:root:Train (Epoch 199): Loss/seq after 01550 batchs: 369.0059509277344
INFO:root:Train (Epoch 199): Loss/seq after 01600 batchs: 366.5775451660156
INFO:root:Train (Epoch 199): Loss/seq after 01650 batchs: 365.4375305175781
INFO:root:Train (Epoch 199): Loss/seq after 01700 batchs: 370.10467529296875
INFO:root:Train (Epoch 199): Loss/seq after 01750 batchs: 369.0293884277344
INFO:root:Train (Epoch 199): Loss/seq after 01800 batchs: 367.40826416015625
INFO:root:Train (Epoch 199): Loss/seq after 01850 batchs: 365.8223571777344
INFO:root:Train (Epoch 199): Loss/seq after 01900 batchs: 364.984619140625
INFO:root:Train (Epoch 199): Loss/seq after 01950 batchs: 365.0689697265625
INFO:root:Train (Epoch 199): Loss/seq after 02000 batchs: 366.4299011230469
INFO:root:Train (Epoch 199): Loss/seq after 02050 batchs: 366.73712158203125
INFO:root:Train (Epoch 199): Loss/seq after 02100 batchs: 365.82208251953125
INFO:root:Train (Epoch 199): Loss/seq after 02150 batchs: 365.20745849609375
INFO:root:Train (Epoch 199): Loss/seq after 02200 batchs: 364.1825256347656
INFO:root:Train (Epoch 199): Loss/seq after 02250 batchs: 363.0331726074219
INFO:root:Train (Epoch 199): Loss/seq after 02300 batchs: 360.22332763671875
INFO:root:Train (Epoch 199): Loss/seq after 02350 batchs: 358.19622802734375
INFO:root:Train (Epoch 199): Loss/seq after 02400 batchs: 359.10198974609375
INFO:root:Train (Epoch 199): Loss/seq after 02450 batchs: 356.41534423828125
INFO:root:Train (Epoch 199): Loss/seq after 02500 batchs: 351.17523193359375
INFO:root:Train (Epoch 199): Loss/seq after 02550 batchs: 346.34527587890625
INFO:root:Train (Epoch 199): Loss/seq after 02600 batchs: 344.4236145019531
INFO:root:Train (Epoch 199): Loss/seq after 02650 batchs: 340.8841247558594
INFO:root:Train (Epoch 199): Loss/seq after 02700 batchs: 338.6187438964844
INFO:root:Train (Epoch 199): Loss/seq after 02750 batchs: 335.3601989746094
INFO:root:Train (Epoch 199): Loss/seq after 02800 batchs: 333.44342041015625
INFO:root:Train (Epoch 199): Loss/seq after 02850 batchs: 333.3740539550781
INFO:root:Train (Epoch 199): Loss/seq after 02900 batchs: 334.72393798828125
INFO:root:Train (Epoch 199): Loss/seq after 02950 batchs: 335.4508361816406
INFO:root:Train (Epoch 199): Loss/seq after 03000 batchs: 341.1632385253906
INFO:root:Train (Epoch 199): Loss/seq after 03050 batchs: 343.4311828613281
INFO:root:Train (Epoch 199): Loss/seq after 03100 batchs: 344.6368103027344
INFO:root:Train (Epoch 199): Loss/seq after 03150 batchs: 343.87109375
INFO:root:Train (Epoch 199): Loss/seq after 03200 batchs: 343.52874755859375
INFO:root:Train (Epoch 199): Loss/seq after 03250 batchs: 343.5851135253906
INFO:root:Train (Epoch 199): Loss/seq after 03300 batchs: 343.0173645019531
INFO:root:Train (Epoch 199): Loss/seq after 03350 batchs: 341.67230224609375
INFO:root:Train (Epoch 199): Loss/seq after 03400 batchs: 339.3919677734375
INFO:root:Train (Epoch 199): Loss/seq after 03450 batchs: 338.5583801269531
INFO:root:Train (Epoch 199): Loss/seq after 03500 batchs: 339.2623291015625
INFO:root:Train (Epoch 199): Loss/seq after 03550 batchs: 337.53143310546875
INFO:root:Train (Epoch 199): Loss/seq after 03600 batchs: 343.4841613769531
INFO:root:Train (Epoch 199): Loss/seq after 03650 batchs: 342.31915283203125
INFO:root:Train (Epoch 199): Loss/seq after 03700 batchs: 344.6051330566406
INFO:root:Train (Epoch 199): Loss/seq after 03750 batchs: 348.7401428222656
INFO:root:Train (Epoch 199): Loss/seq after 03800 batchs: 348.3026123046875
INFO:root:Train (Epoch 199): Loss/seq after 03850 batchs: 347.7506103515625
INFO:root:Train (Epoch 199): Loss/seq after 03900 batchs: 349.052001953125
INFO:root:Train (Epoch 199): Loss/seq after 03950 batchs: 350.9621887207031
INFO:root:Train (Epoch 199): Loss/seq after 04000 batchs: 348.9852294921875
INFO:root:Train (Epoch 199): Loss/seq after 04050 batchs: 346.9914855957031
INFO:root:Train (Epoch 199): Loss/seq after 04100 batchs: 346.5298156738281
INFO:root:Train (Epoch 199): Loss/seq after 04150 batchs: 346.7614440917969
INFO:root:Train (Epoch 199): Loss/seq after 04200 batchs: 346.0598449707031
INFO:root:Train (Epoch 199): Loss/seq after 04250 batchs: 344.8878479003906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 199): Loss/seq after 00000 batches: 301.99774169921875
INFO:root:# Valid (Epoch 199): Loss/seq after 00050 batches: 461.5262451171875
INFO:root:# Valid (Epoch 199): Loss/seq after 00100 batches: 469.05267333984375
INFO:root:# Valid (Epoch 199): Loss/seq after 00150 batches: 363.3774108886719
INFO:root:# Valid (Epoch 199): Loss/seq after 00200 batches: 345.81268310546875
INFO:root:Artifacts: Make stick videos for epoch 199
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_199_on_20220413_122249.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_199_index_763_on_20220413_122249.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Done training.

wandb: Waiting for W&B process to finish, PID 107182... (success).
wandb: - 446.62MB of 446.62MB uploaded (0.00MB deduped)wandb: \ 446.62MB of 446.62MB uploaded (0.00MB deduped)wandb: | 446.62MB of 446.62MB uploaded (0.00MB deduped)wandb: / 446.62MB of 448.15MB uploaded (0.00MB deduped)wandb: - 446.62MB of 448.15MB uploaded (0.00MB deduped)wandb: \ 446.62MB of 448.15MB uploaded (0.00MB deduped)wandb: | 447.08MB of 448.15MB uploaded (0.00MB deduped)wandb: / 447.73MB of 448.15MB uploaded (0.00MB deduped)wandb: - 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb: \ 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb: | 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb: / 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb: - 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb: \ 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb: | 448.15MB of 448.15MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:        epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:         loss ██▇▇▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:   valid_loss █▆▄▅▆█▅▅▆▄▃▄▃▂▃▃▄▂▂▄▃▂▂▃▂▂▂▂▁▁▂▂▁▁▂▁▁▁▂▂
wandb: 
wandb: Run summary:
wandb:        epoch 199
wandb:         loss 344.88785
wandb:   valid_loss 345.81268
wandb: 
wandb: Synced 6 W&B file(s), 0 media file(s), 400 artifact file(s) and 0 other file(s)
wandb: Synced polished-sweep-2: https://wandb.ai/mathildepapillon/move-move/runs/pdklsq2h
wandb: Find logs at: ./wandb/run-20220412_182535-pdklsq2h/logs/debug.log
wandb: 

2022-04-13 12:23:32,555 - wandb.wandb_agent - INFO - Cleaning up finished run: pdklsq2h
2022-04-13 12:23:33,150 - wandb.wandb_agent - INFO - Agent received command: run
2022-04-13 12:23:33,151 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 256
	learning_rate: 0.001
2022-04-13 12:23:33,186 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python main.py --batch_size=256 --learning_rate=0.001
2022-04-13 12:23:38,202 - wandb.wandb_agent - INFO - Running runs: ['7gysds1n']
INFO:root:Using device cuda
wandb: Currently logged in as: mathildepapillon (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
TORCH
1.10.0+cu102
wandb: wandb version 0.12.14 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run lemon-sweep-3
wandb: ⭐️ View project at https://wandb.ai/mathildepapillon/move-move
wandb: 🧹 View sweep at https://wandb.ai/mathildepapillon/move-move/sweeps/tld50t54
wandb: 🚀 View run at https://wandb.ai/mathildepapillon/move-move/runs/7gysds1n
wandb: Run data is saved locally in /home/papillon/move/move/wandb/run-20220413_122403-7gysds1n
wandb: Run `wandb offline` to turn off syncing.
INFO:root:Config: {config}
INFO:root:Run server specific commands
INFO:root:Initialize model
INFO:root:Loading raw datasets:
INFO:root:- data/mariel_betternot_and_retrograde.npy of shape (9925, 53, 3)
INFO:root:- data/mariel_beyond.npy of shape (5803, 53, 3)
INFO:root:- data/mariel_chunli.npy of shape (3866, 53, 3)
INFO:root:- data/mariel_honey.npy of shape (5309, 53, 3)
INFO:root:- data/mariel_knownbetter.npy of shape (6649, 53, 3)
INFO:root:- data/mariel_penelope.npy of shape (6757, 53, 3)
INFO:root:Preprocessing: Load seq_data of shape (38181, 128, 159)
INFO:root:>> Train ds has shape (34363, 128, 159)
INFO:root:>> Valid ds has shape (1909, 128, 159)
INFO:root:>> Test ds has shape (1909, 128, 159)
INFO:root:Preprocessing: Convert into torch dataloader
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 0): Loss/seq after 00000 batchs: 221379.796875
INFO:root:Train (Epoch 0): Loss/seq after 00050 batchs: 103524.015625
INFO:root:Train (Epoch 0): Loss/seq after 00100 batchs: 83747.8671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 0): Loss/seq after 00000 batches: 41168.703125
INFO:root:Artifacts: Make stick videos for epoch 0
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_0_on_20220413_122449.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_0_index_318_on_20220413_122449.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 1): Loss/seq after 00000 batchs: 98807.140625
INFO:root:Train (Epoch 1): Loss/seq after 00050 batchs: 82558.90625
INFO:root:Train (Epoch 1): Loss/seq after 00100 batchs: 72912.0703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 1): Loss/seq after 00000 batches: 41558.56640625
INFO:root:Artifacts: Make stick videos for epoch 1
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_1_on_20220413_122530.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_1_index_1670_on_20220413_122530.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 2): Loss/seq after 00000 batchs: 95726.7734375
INFO:root:Train (Epoch 2): Loss/seq after 00050 batchs: 81854.6875
INFO:root:Train (Epoch 2): Loss/seq after 00100 batchs: 72423.359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 2): Loss/seq after 00000 batches: 46932.68359375
INFO:root:Artifacts: Make stick videos for epoch 2
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_2_on_20220413_122612.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_2_index_1221_on_20220413_122612.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 3): Loss/seq after 00000 batchs: 81823.828125
INFO:root:Train (Epoch 3): Loss/seq after 00050 batchs: 80197.953125
INFO:root:Train (Epoch 3): Loss/seq after 00100 batchs: 72651.1015625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 3): Loss/seq after 00000 batches: 39682.76171875
INFO:root:Artifacts: Make stick videos for epoch 3
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_3_on_20220413_122654.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_3_index_82_on_20220413_122654.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 4): Loss/seq after 00000 batchs: 89551.0546875
INFO:root:Train (Epoch 4): Loss/seq after 00050 batchs: 81313.421875
INFO:root:Train (Epoch 4): Loss/seq after 00100 batchs: 72930.34375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 4): Loss/seq after 00000 batches: 42034.62109375
INFO:root:Artifacts: Make stick videos for epoch 4
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_4_on_20220413_122735.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_4_index_814_on_20220413_122735.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 5): Loss/seq after 00000 batchs: 86340.7890625
INFO:root:Train (Epoch 5): Loss/seq after 00050 batchs: 80865.3046875
INFO:root:Train (Epoch 5): Loss/seq after 00100 batchs: 72335.1640625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 5): Loss/seq after 00000 batches: 46354.6015625
INFO:root:Artifacts: Make stick videos for epoch 5
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_5_on_20220413_122816.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_5_index_907_on_20220413_122816.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 6): Loss/seq after 00000 batchs: 88756.5078125
INFO:root:Train (Epoch 6): Loss/seq after 00050 batchs: 80104.5234375
INFO:root:Train (Epoch 6): Loss/seq after 00100 batchs: 72485.953125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 6): Loss/seq after 00000 batches: 42307.0546875
INFO:root:Artifacts: Make stick videos for epoch 6
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_6_on_20220413_122857.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_6_index_459_on_20220413_122857.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 7): Loss/seq after 00000 batchs: 86139.8984375
INFO:root:Train (Epoch 7): Loss/seq after 00050 batchs: 80803.3203125
INFO:root:Train (Epoch 7): Loss/seq after 00100 batchs: 72390.5625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 7): Loss/seq after 00000 batches: 39766.44921875
INFO:root:Artifacts: Make stick videos for epoch 7
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_7_on_20220413_122938.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_7_index_1254_on_20220413_122938.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 8): Loss/seq after 00000 batchs: 80437.9453125
INFO:root:Train (Epoch 8): Loss/seq after 00050 batchs: 81139.40625
INFO:root:Train (Epoch 8): Loss/seq after 00100 batchs: 72544.7890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 8): Loss/seq after 00000 batches: 49239.421875
INFO:root:Artifacts: Make stick videos for epoch 8
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_8_on_20220413_123020.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_8_index_219_on_20220413_123020.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 9): Loss/seq after 00000 batchs: 86905.0546875
INFO:root:Train (Epoch 9): Loss/seq after 00050 batchs: 80831.265625
INFO:root:Train (Epoch 9): Loss/seq after 00100 batchs: 72523.9921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 9): Loss/seq after 00000 batches: 50303.3125
INFO:root:Artifacts: Make stick videos for epoch 9
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_9_on_20220413_123101.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_9_index_891_on_20220413_123101.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 10): Loss/seq after 00000 batchs: 82120.5
INFO:root:Train (Epoch 10): Loss/seq after 00050 batchs: 81229.234375
INFO:root:Train (Epoch 10): Loss/seq after 00100 batchs: 72557.7578125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 10): Loss/seq after 00000 batches: 51455.546875
INFO:root:Artifacts: Make stick videos for epoch 10
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_10_on_20220413_123142.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_10_index_631_on_20220413_123142.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 11): Loss/seq after 00000 batchs: 87346.9921875
INFO:root:Train (Epoch 11): Loss/seq after 00050 batchs: 80340.7734375
INFO:root:Train (Epoch 11): Loss/seq after 00100 batchs: 71806.40625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 11): Loss/seq after 00000 batches: 42891.60546875
INFO:root:Artifacts: Make stick videos for epoch 11
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_11_on_20220413_123224.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_11_index_1826_on_20220413_123224.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 12): Loss/seq after 00000 batchs: 87707.1015625
INFO:root:Train (Epoch 12): Loss/seq after 00050 batchs: 79677.6953125
INFO:root:Train (Epoch 12): Loss/seq after 00100 batchs: 70941.0703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 12): Loss/seq after 00000 batches: 40731.4296875
INFO:root:Artifacts: Make stick videos for epoch 12
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_12_on_20220413_123306.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_12_index_1826_on_20220413_123306.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 13): Loss/seq after 00000 batchs: 88053.703125
INFO:root:Train (Epoch 13): Loss/seq after 00050 batchs: 78922.6171875
INFO:root:Train (Epoch 13): Loss/seq after 00100 batchs: 71044.3046875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 13): Loss/seq after 00000 batches: 43909.53125
INFO:root:Artifacts: Make stick videos for epoch 13
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_13_on_20220413_123347.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_13_index_1905_on_20220413_123347.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 14): Loss/seq after 00000 batchs: 91615.4609375
INFO:root:Train (Epoch 14): Loss/seq after 00050 batchs: 80654.5546875
INFO:root:Train (Epoch 14): Loss/seq after 00100 batchs: 72489.0
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 14): Loss/seq after 00000 batches: 40129.55859375
INFO:root:Artifacts: Make stick videos for epoch 14
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_14_on_20220413_123428.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_14_index_260_on_20220413_123428.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 15): Loss/seq after 00000 batchs: 81653.046875
INFO:root:Train (Epoch 15): Loss/seq after 00050 batchs: 80833.59375
INFO:root:Train (Epoch 15): Loss/seq after 00100 batchs: 73535.796875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 15): Loss/seq after 00000 batches: 43199.65625
INFO:root:Artifacts: Make stick videos for epoch 15
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_15_on_20220413_123511.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_15_index_1543_on_20220413_123511.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 16): Loss/seq after 00000 batchs: 91045.3046875
INFO:root:Train (Epoch 16): Loss/seq after 00050 batchs: 82053.6484375
INFO:root:Train (Epoch 16): Loss/seq after 00100 batchs: 73376.09375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 16): Loss/seq after 00000 batches: 47860.48828125
INFO:root:Artifacts: Make stick videos for epoch 16
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_16_on_20220413_123553.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_16_index_514_on_20220413_123553.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 17): Loss/seq after 00000 batchs: 85575.5546875
INFO:root:Train (Epoch 17): Loss/seq after 00050 batchs: 81808.234375
INFO:root:Train (Epoch 17): Loss/seq after 00100 batchs: 72998.78125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 17): Loss/seq after 00000 batches: 47984.03125
INFO:root:Artifacts: Make stick videos for epoch 17
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_17_on_20220413_123634.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_17_index_1411_on_20220413_123634.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 18): Loss/seq after 00000 batchs: 86105.859375
INFO:root:Train (Epoch 18): Loss/seq after 00050 batchs: 81813.3203125
INFO:root:Train (Epoch 18): Loss/seq after 00100 batchs: 72854.9296875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 18): Loss/seq after 00000 batches: 48192.2421875
INFO:root:Artifacts: Make stick videos for epoch 18
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_18_on_20220413_123715.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_18_index_752_on_20220413_123715.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 19): Loss/seq after 00000 batchs: 85876.3515625
INFO:root:Train (Epoch 19): Loss/seq after 00050 batchs: 81763.4609375
INFO:root:Train (Epoch 19): Loss/seq after 00100 batchs: 72797.71875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 19): Loss/seq after 00000 batches: 47199.80078125
INFO:root:Artifacts: Make stick videos for epoch 19
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_19_on_20220413_123756.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_19_index_1859_on_20220413_123756.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 20): Loss/seq after 00000 batchs: 86451.421875
INFO:root:Train (Epoch 20): Loss/seq after 00050 batchs: 81793.90625
INFO:root:Train (Epoch 20): Loss/seq after 00100 batchs: 72740.6953125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 20): Loss/seq after 00000 batches: 47787.125
INFO:root:Artifacts: Make stick videos for epoch 20
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_20_on_20220413_123837.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_20_index_1101_on_20220413_123837.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 21): Loss/seq after 00000 batchs: 85949.546875
INFO:root:Train (Epoch 21): Loss/seq after 00050 batchs: 81798.15625
INFO:root:Train (Epoch 21): Loss/seq after 00100 batchs: 72725.3828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 21): Loss/seq after 00000 batches: 47448.4375
INFO:root:Artifacts: Make stick videos for epoch 21
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_21_on_20220413_123918.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_21_index_1772_on_20220413_123918.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 22): Loss/seq after 00000 batchs: 86539.59375
INFO:root:Train (Epoch 22): Loss/seq after 00050 batchs: 81790.109375
INFO:root:Train (Epoch 22): Loss/seq after 00100 batchs: 72676.984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 22): Loss/seq after 00000 batches: 47427.625
INFO:root:Artifacts: Make stick videos for epoch 22
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_22_on_20220413_124000.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_22_index_1212_on_20220413_124000.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 23): Loss/seq after 00000 batchs: 86259.6171875
INFO:root:Train (Epoch 23): Loss/seq after 00050 batchs: 81805.046875
INFO:root:Train (Epoch 23): Loss/seq after 00100 batchs: 72634.5
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 23): Loss/seq after 00000 batches: 47562.8046875
INFO:root:Artifacts: Make stick videos for epoch 23
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_23_on_20220413_124042.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_23_index_1546_on_20220413_124042.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 24): Loss/seq after 00000 batchs: 86372.5078125
INFO:root:Train (Epoch 24): Loss/seq after 00050 batchs: 81795.96875
INFO:root:Train (Epoch 24): Loss/seq after 00100 batchs: 72593.609375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 24): Loss/seq after 00000 batches: 47306.41015625
INFO:root:Artifacts: Make stick videos for epoch 24
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_24_on_20220413_124124.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_24_index_371_on_20220413_124124.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 25): Loss/seq after 00000 batchs: 86579.2578125
INFO:root:Train (Epoch 25): Loss/seq after 00050 batchs: 81816.875
INFO:root:Train (Epoch 25): Loss/seq after 00100 batchs: 72600.8203125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 25): Loss/seq after 00000 batches: 47525.23828125
INFO:root:Artifacts: Make stick videos for epoch 25
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_25_on_20220413_124205.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_25_index_562_on_20220413_124205.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 26): Loss/seq after 00000 batchs: 86352.0234375
INFO:root:Train (Epoch 26): Loss/seq after 00050 batchs: 81800.2890625
INFO:root:Train (Epoch 26): Loss/seq after 00100 batchs: 72550.21875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 26): Loss/seq after 00000 batches: 47492.49609375
INFO:root:Artifacts: Make stick videos for epoch 26
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_26_on_20220413_124247.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_26_index_1141_on_20220413_124247.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 27): Loss/seq after 00000 batchs: 86905.046875
INFO:root:Train (Epoch 27): Loss/seq after 00050 batchs: 81813.3828125
INFO:root:Train (Epoch 27): Loss/seq after 00100 batchs: 72556.25
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 27): Loss/seq after 00000 batches: 47814.6328125
INFO:root:Artifacts: Make stick videos for epoch 27
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_27_on_20220413_124328.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_27_index_893_on_20220413_124328.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 28): Loss/seq after 00000 batchs: 86224.6484375
INFO:root:Train (Epoch 28): Loss/seq after 00050 batchs: 81768.8984375
INFO:root:Train (Epoch 28): Loss/seq after 00100 batchs: 72542.3984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 28): Loss/seq after 00000 batches: 47853.1640625
INFO:root:Artifacts: Make stick videos for epoch 28
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_28_on_20220413_124409.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_28_index_524_on_20220413_124409.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 29): Loss/seq after 00000 batchs: 86786.84375
INFO:root:Train (Epoch 29): Loss/seq after 00050 batchs: 81740.9296875
INFO:root:Train (Epoch 29): Loss/seq after 00100 batchs: 72466.5234375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 29): Loss/seq after 00000 batches: 47518.5078125
INFO:root:Artifacts: Make stick videos for epoch 29
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_29_on_20220413_124450.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_29_index_952_on_20220413_124450.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 30): Loss/seq after 00000 batchs: 86859.078125
INFO:root:Train (Epoch 30): Loss/seq after 00050 batchs: 81793.3515625
INFO:root:Train (Epoch 30): Loss/seq after 00100 batchs: 72523.3046875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 30): Loss/seq after 00000 batches: 47781.359375
INFO:root:Artifacts: Make stick videos for epoch 30
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_30_on_20220413_124532.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_30_index_1298_on_20220413_124532.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 31): Loss/seq after 00000 batchs: 85948.3515625
INFO:root:Train (Epoch 31): Loss/seq after 00050 batchs: 81715.9609375
INFO:root:Train (Epoch 31): Loss/seq after 00100 batchs: 72461.4375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 31): Loss/seq after 00000 batches: 47764.4375
INFO:root:Artifacts: Make stick videos for epoch 31
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_31_on_20220413_124613.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_31_index_920_on_20220413_124613.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 32): Loss/seq after 00000 batchs: 86039.6484375
INFO:root:Train (Epoch 32): Loss/seq after 00050 batchs: 81756.7265625
INFO:root:Train (Epoch 32): Loss/seq after 00100 batchs: 72463.5
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 32): Loss/seq after 00000 batches: 47529.25390625
INFO:root:Artifacts: Make stick videos for epoch 32
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_32_on_20220413_124655.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_32_index_856_on_20220413_124655.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 33): Loss/seq after 00000 batchs: 86593.3046875
INFO:root:Train (Epoch 33): Loss/seq after 00050 batchs: 81796.171875
INFO:root:Train (Epoch 33): Loss/seq after 00100 batchs: 72475.5703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 33): Loss/seq after 00000 batches: 47290.63671875
INFO:root:Artifacts: Make stick videos for epoch 33
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_33_on_20220413_124737.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_33_index_551_on_20220413_124737.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 34): Loss/seq after 00000 batchs: 86540.7265625
INFO:root:Train (Epoch 34): Loss/seq after 00050 batchs: 81750.3203125
INFO:root:Train (Epoch 34): Loss/seq after 00100 batchs: 72448.8984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 34): Loss/seq after 00000 batches: 47502.59765625
INFO:root:Artifacts: Make stick videos for epoch 34
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_34_on_20220413_124818.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_34_index_1650_on_20220413_124818.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 35): Loss/seq after 00000 batchs: 86765.0390625
INFO:root:Train (Epoch 35): Loss/seq after 00050 batchs: 81828.15625
INFO:root:Train (Epoch 35): Loss/seq after 00100 batchs: 72493.6640625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 35): Loss/seq after 00000 batches: 47464.3125
INFO:root:Artifacts: Make stick videos for epoch 35
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_35_on_20220413_124902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_35_index_866_on_20220413_124902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 36): Loss/seq after 00000 batchs: 86417.953125
INFO:root:Train (Epoch 36): Loss/seq after 00050 batchs: 81761.90625
INFO:root:Train (Epoch 36): Loss/seq after 00100 batchs: 72450.53125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 36): Loss/seq after 00000 batches: 47532.3046875
INFO:root:Artifacts: Make stick videos for epoch 36
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_36_on_20220413_124943.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_36_index_1061_on_20220413_124943.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 37): Loss/seq after 00000 batchs: 86231.046875
INFO:root:Train (Epoch 37): Loss/seq after 00050 batchs: 81760.703125
INFO:root:Train (Epoch 37): Loss/seq after 00100 batchs: 72441.1875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 37): Loss/seq after 00000 batches: 47692.3203125
INFO:root:Artifacts: Make stick videos for epoch 37
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_37_on_20220413_125024.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_37_index_406_on_20220413_125024.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 38): Loss/seq after 00000 batchs: 86287.03125
INFO:root:Train (Epoch 38): Loss/seq after 00050 batchs: 81759.6171875
INFO:root:Train (Epoch 38): Loss/seq after 00100 batchs: 72430.203125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 38): Loss/seq after 00000 batches: 47424.85546875
INFO:root:Artifacts: Make stick videos for epoch 38
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_38_on_20220413_125105.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_38_index_1853_on_20220413_125105.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 39): Loss/seq after 00000 batchs: 86419.7265625
INFO:root:Train (Epoch 39): Loss/seq after 00050 batchs: 81756.328125
INFO:root:Train (Epoch 39): Loss/seq after 00100 batchs: 72416.625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 39): Loss/seq after 00000 batches: 47833.73046875
INFO:root:Artifacts: Make stick videos for epoch 39
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_39_on_20220413_125146.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_39_index_283_on_20220413_125146.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 40): Loss/seq after 00000 batchs: 86097.6796875
INFO:root:Train (Epoch 40): Loss/seq after 00050 batchs: 81737.34375
INFO:root:Train (Epoch 40): Loss/seq after 00100 batchs: 72431.8984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 40): Loss/seq after 00000 batches: 47637.8828125
INFO:root:Artifacts: Make stick videos for epoch 40
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_40_on_20220413_125228.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_40_index_880_on_20220413_125228.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 41): Loss/seq after 00000 batchs: 86357.640625
INFO:root:Train (Epoch 41): Loss/seq after 00050 batchs: 81726.546875
INFO:root:Train (Epoch 41): Loss/seq after 00100 batchs: 72410.0546875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 41): Loss/seq after 00000 batches: 47632.06640625
INFO:root:Artifacts: Make stick videos for epoch 41
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_41_on_20220413_125310.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_41_index_665_on_20220413_125310.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 42): Loss/seq after 00000 batchs: 86401.1640625
INFO:root:Train (Epoch 42): Loss/seq after 00050 batchs: 81729.5546875
INFO:root:Train (Epoch 42): Loss/seq after 00100 batchs: 72394.8046875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 42): Loss/seq after 00000 batches: 47541.75
INFO:root:Artifacts: Make stick videos for epoch 42
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_42_on_20220413_125351.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_42_index_1633_on_20220413_125351.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 43): Loss/seq after 00000 batchs: 86409.78125
INFO:root:Train (Epoch 43): Loss/seq after 00050 batchs: 81795.3671875
INFO:root:Train (Epoch 43): Loss/seq after 00100 batchs: 72421.3359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 43): Loss/seq after 00000 batches: 47649.62890625
INFO:root:Artifacts: Make stick videos for epoch 43
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_43_on_20220413_125435.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_43_index_264_on_20220413_125435.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 44): Loss/seq after 00000 batchs: 86503.3828125
INFO:root:Train (Epoch 44): Loss/seq after 00050 batchs: 81763.0703125
INFO:root:Train (Epoch 44): Loss/seq after 00100 batchs: 72399.109375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 44): Loss/seq after 00000 batches: 47499.58203125
INFO:root:Artifacts: Make stick videos for epoch 44
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_44_on_20220413_125517.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_44_index_969_on_20220413_125517.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 45): Loss/seq after 00000 batchs: 86208.0234375
INFO:root:Train (Epoch 45): Loss/seq after 00050 batchs: 81738.7265625
INFO:root:Train (Epoch 45): Loss/seq after 00100 batchs: 72368.9453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 45): Loss/seq after 00000 batches: 47302.7890625
INFO:root:Artifacts: Make stick videos for epoch 45
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_45_on_20220413_125559.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_45_index_1587_on_20220413_125559.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 46): Loss/seq after 00000 batchs: 86370.7421875
INFO:root:Train (Epoch 46): Loss/seq after 00050 batchs: 81748.4453125
INFO:root:Train (Epoch 46): Loss/seq after 00100 batchs: 72387.8203125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 46): Loss/seq after 00000 batches: 47818.1171875
INFO:root:Artifacts: Make stick videos for epoch 46
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_46_on_20220413_125641.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_46_index_976_on_20220413_125641.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 47): Loss/seq after 00000 batchs: 86365.0
INFO:root:Train (Epoch 47): Loss/seq after 00050 batchs: 81750.359375
INFO:root:Train (Epoch 47): Loss/seq after 00100 batchs: 72392.140625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 47): Loss/seq after 00000 batches: 47654.87890625
INFO:root:Artifacts: Make stick videos for epoch 47
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_47_on_20220413_125723.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_47_index_1386_on_20220413_125723.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 48): Loss/seq after 00000 batchs: 86281.15625
INFO:root:Train (Epoch 48): Loss/seq after 00050 batchs: 81746.6328125
INFO:root:Train (Epoch 48): Loss/seq after 00100 batchs: 72371.34375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 48): Loss/seq after 00000 batches: 47526.6796875
INFO:root:Artifacts: Make stick videos for epoch 48
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_48_on_20220413_125805.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_48_index_1473_on_20220413_125805.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 49): Loss/seq after 00000 batchs: 86190.9765625
INFO:root:Train (Epoch 49): Loss/seq after 00050 batchs: 81741.625
INFO:root:Train (Epoch 49): Loss/seq after 00100 batchs: 72351.34375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 49): Loss/seq after 00000 batches: 47625.23828125
INFO:root:Artifacts: Make stick videos for epoch 49
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_49_on_20220413_125846.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_49_index_508_on_20220413_125846.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 50): Loss/seq after 00000 batchs: 86561.921875
INFO:root:Train (Epoch 50): Loss/seq after 00050 batchs: 81763.8125
INFO:root:Train (Epoch 50): Loss/seq after 00100 batchs: 72385.703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 50): Loss/seq after 00000 batches: 47608.60546875
INFO:root:Artifacts: Make stick videos for epoch 50
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_50_on_20220413_125927.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_50_index_686_on_20220413_125927.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 51): Loss/seq after 00000 batchs: 86295.1328125
INFO:root:Train (Epoch 51): Loss/seq after 00050 batchs: 81750.984375
INFO:root:Train (Epoch 51): Loss/seq after 00100 batchs: 72366.4375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 51): Loss/seq after 00000 batches: 47494.06640625
INFO:root:Artifacts: Make stick videos for epoch 51
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_51_on_20220413_130010.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_51_index_89_on_20220413_130010.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 52): Loss/seq after 00000 batchs: 86360.3359375
INFO:root:Train (Epoch 52): Loss/seq after 00050 batchs: 81733.578125
INFO:root:Train (Epoch 52): Loss/seq after 00100 batchs: 72349.90625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 52): Loss/seq after 00000 batches: 47642.87109375
INFO:root:Artifacts: Make stick videos for epoch 52
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_52_on_20220413_130052.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_52_index_22_on_20220413_130052.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 53): Loss/seq after 00000 batchs: 86439.53125
INFO:root:Train (Epoch 53): Loss/seq after 00050 batchs: 81697.4453125
INFO:root:Train (Epoch 53): Loss/seq after 00100 batchs: 72350.9453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 53): Loss/seq after 00000 batches: 47595.546875
INFO:root:Artifacts: Make stick videos for epoch 53
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_53_on_20220413_130134.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_53_index_1381_on_20220413_130134.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 54): Loss/seq after 00000 batchs: 86598.1640625
INFO:root:Train (Epoch 54): Loss/seq after 00050 batchs: 81773.078125
INFO:root:Train (Epoch 54): Loss/seq after 00100 batchs: 72362.4375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 54): Loss/seq after 00000 batches: 47582.875
INFO:root:Artifacts: Make stick videos for epoch 54
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_54_on_20220413_130216.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_54_index_70_on_20220413_130216.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 55): Loss/seq after 00000 batchs: 86538.75
INFO:root:Train (Epoch 55): Loss/seq after 00050 batchs: 81722.6484375
INFO:root:Train (Epoch 55): Loss/seq after 00100 batchs: 72348.2890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 55): Loss/seq after 00000 batches: 47693.30078125
INFO:root:Artifacts: Make stick videos for epoch 55
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_55_on_20220413_130257.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_55_index_1814_on_20220413_130257.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 56): Loss/seq after 00000 batchs: 86308.6796875
INFO:root:Train (Epoch 56): Loss/seq after 00050 batchs: 81754.5625
INFO:root:Train (Epoch 56): Loss/seq after 00100 batchs: 72347.875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 56): Loss/seq after 00000 batches: 47591.31640625
INFO:root:Artifacts: Make stick videos for epoch 56
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_56_on_20220413_130339.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_56_index_1393_on_20220413_130339.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 57): Loss/seq after 00000 batchs: 86377.6015625
INFO:root:Train (Epoch 57): Loss/seq after 00050 batchs: 81754.40625
INFO:root:Train (Epoch 57): Loss/seq after 00100 batchs: 72341.046875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 57): Loss/seq after 00000 batches: 47571.77734375
INFO:root:Artifacts: Make stick videos for epoch 57
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_57_on_20220413_130420.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_57_index_848_on_20220413_130420.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 58): Loss/seq after 00000 batchs: 86380.3515625
INFO:root:Train (Epoch 58): Loss/seq after 00050 batchs: 81747.9921875
INFO:root:Train (Epoch 58): Loss/seq after 00100 batchs: 72337.53125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 58): Loss/seq after 00000 batches: 47599.65625
INFO:root:Artifacts: Make stick videos for epoch 58
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_58_on_20220413_130502.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_58_index_321_on_20220413_130502.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 59): Loss/seq after 00000 batchs: 86359.8984375
INFO:root:Train (Epoch 59): Loss/seq after 00050 batchs: 81733.3984375
INFO:root:Train (Epoch 59): Loss/seq after 00100 batchs: 72330.90625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 59): Loss/seq after 00000 batches: 47531.94921875
INFO:root:Artifacts: Make stick videos for epoch 59
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_59_on_20220413_130543.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_59_index_176_on_20220413_130543.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 60): Loss/seq after 00000 batchs: 86417.15625
INFO:root:Train (Epoch 60): Loss/seq after 00050 batchs: 81754.6953125
INFO:root:Train (Epoch 60): Loss/seq after 00100 batchs: 72336.6953125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 60): Loss/seq after 00000 batches: 47615.36328125
INFO:root:Artifacts: Make stick videos for epoch 60
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_60_on_20220413_130625.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_60_index_1608_on_20220413_130625.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 61): Loss/seq after 00000 batchs: 86376.875
INFO:root:Train (Epoch 61): Loss/seq after 00050 batchs: 81737.6875
INFO:root:Train (Epoch 61): Loss/seq after 00100 batchs: 72327.9921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 61): Loss/seq after 00000 batches: 47621.34375
INFO:root:Artifacts: Make stick videos for epoch 61
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_61_on_20220413_130706.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_61_index_384_on_20220413_130706.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 62): Loss/seq after 00000 batchs: 86375.1953125
INFO:root:Train (Epoch 62): Loss/seq after 00050 batchs: 81746.4375
INFO:root:Train (Epoch 62): Loss/seq after 00100 batchs: 72324.3671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 62): Loss/seq after 00000 batches: 47550.09765625
INFO:root:Artifacts: Make stick videos for epoch 62
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_62_on_20220413_130748.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_62_index_1366_on_20220413_130748.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 63): Loss/seq after 00000 batchs: 86391.7109375
INFO:root:Train (Epoch 63): Loss/seq after 00050 batchs: 81754.1796875
INFO:root:Train (Epoch 63): Loss/seq after 00100 batchs: 72677.7734375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 63): Loss/seq after 00000 batches: 37213.41015625
INFO:root:Artifacts: Make stick videos for epoch 63
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_63_on_20220413_130829.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_63_index_767_on_20220413_130829.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 64): Loss/seq after 00000 batchs: 95421.4296875
INFO:root:Train (Epoch 64): Loss/seq after 00050 batchs: 83135.90625
INFO:root:Train (Epoch 64): Loss/seq after 00100 batchs: 73913.2890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 64): Loss/seq after 00000 batches: 42452.20703125
INFO:root:Artifacts: Make stick videos for epoch 64
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_64_on_20220413_130911.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_64_index_1782_on_20220413_130911.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 65): Loss/seq after 00000 batchs: 90879.5234375
INFO:root:Train (Epoch 65): Loss/seq after 00050 batchs: 83102.484375
INFO:root:Train (Epoch 65): Loss/seq after 00100 batchs: 74048.0546875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 65): Loss/seq after 00000 batches: 47375.19921875
INFO:root:Artifacts: Make stick videos for epoch 65
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_65_on_20220413_130953.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_65_index_784_on_20220413_130953.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 66): Loss/seq after 00000 batchs: 87377.2734375
INFO:root:Train (Epoch 66): Loss/seq after 00050 batchs: 82318.296875
INFO:root:Train (Epoch 66): Loss/seq after 00100 batchs: 73490.0
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 66): Loss/seq after 00000 batches: 47439.81640625
INFO:root:Artifacts: Make stick videos for epoch 66
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_66_on_20220413_131034.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_66_index_1844_on_20220413_131034.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 67): Loss/seq after 00000 batchs: 87027.046875
INFO:root:Train (Epoch 67): Loss/seq after 00050 batchs: 82117.109375
INFO:root:Train (Epoch 67): Loss/seq after 00100 batchs: 73258.6875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 67): Loss/seq after 00000 batches: 47315.27734375
INFO:root:Artifacts: Make stick videos for epoch 67
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_67_on_20220413_131116.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_67_index_421_on_20220413_131116.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 68): Loss/seq after 00000 batchs: 86803.9921875
INFO:root:Train (Epoch 68): Loss/seq after 00050 batchs: 82029.078125
INFO:root:Train (Epoch 68): Loss/seq after 00100 batchs: 73130.265625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 68): Loss/seq after 00000 batches: 45350.46484375
INFO:root:Artifacts: Make stick videos for epoch 68
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_68_on_20220413_131157.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_68_index_1344_on_20220413_131157.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 69): Loss/seq after 00000 batchs: 88781.1328125
INFO:root:Train (Epoch 69): Loss/seq after 00050 batchs: 82539.171875
INFO:root:Train (Epoch 69): Loss/seq after 00100 batchs: 73310.453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 69): Loss/seq after 00000 batches: 47307.03515625
INFO:root:Artifacts: Make stick videos for epoch 69
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_69_on_20220413_131238.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_69_index_22_on_20220413_131238.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 70): Loss/seq after 00000 batchs: 86726.2265625
INFO:root:Train (Epoch 70): Loss/seq after 00050 batchs: 81988.0390625
INFO:root:Train (Epoch 70): Loss/seq after 00100 batchs: 72996.15625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 70): Loss/seq after 00000 batches: 47281.8203125
INFO:root:Artifacts: Make stick videos for epoch 70
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_70_on_20220413_131319.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_70_index_991_on_20220413_131319.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 71): Loss/seq after 00000 batchs: 86733.0546875
INFO:root:Train (Epoch 71): Loss/seq after 00050 batchs: 81957.3828125
INFO:root:Train (Epoch 71): Loss/seq after 00100 batchs: 72912.7578125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 71): Loss/seq after 00000 batches: 47186.98046875
INFO:root:Artifacts: Make stick videos for epoch 71
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_71_on_20220413_131401.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_71_index_1900_on_20220413_131401.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 72): Loss/seq after 00000 batchs: 86802.3359375
INFO:root:Train (Epoch 72): Loss/seq after 00050 batchs: 81942.09375
INFO:root:Train (Epoch 72): Loss/seq after 00100 batchs: 72878.1796875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 72): Loss/seq after 00000 batches: 47207.26171875
INFO:root:Artifacts: Make stick videos for epoch 72
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_72_on_20220413_131442.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_72_index_140_on_20220413_131442.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 73): Loss/seq after 00000 batchs: 86778.8359375
INFO:root:Train (Epoch 73): Loss/seq after 00050 batchs: 81936.640625
INFO:root:Train (Epoch 73): Loss/seq after 00100 batchs: 72858.0625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 73): Loss/seq after 00000 batches: 47167.57421875
INFO:root:Artifacts: Make stick videos for epoch 73
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_73_on_20220413_131524.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_73_index_1525_on_20220413_131524.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 74): Loss/seq after 00000 batchs: 86773.6875
INFO:root:Train (Epoch 74): Loss/seq after 00050 batchs: 81927.546875
INFO:root:Train (Epoch 74): Loss/seq after 00100 batchs: 72831.3828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 74): Loss/seq after 00000 batches: 47199.8359375
INFO:root:Artifacts: Make stick videos for epoch 74
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_74_on_20220413_131605.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_74_index_979_on_20220413_131605.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 75): Loss/seq after 00000 batchs: 86727.7109375
INFO:root:Train (Epoch 75): Loss/seq after 00050 batchs: 81932.7734375
INFO:root:Train (Epoch 75): Loss/seq after 00100 batchs: 72817.6796875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 75): Loss/seq after 00000 batches: 47245.578125
INFO:root:Artifacts: Make stick videos for epoch 75
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_75_on_20220413_131646.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_75_index_120_on_20220413_131646.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 76): Loss/seq after 00000 batchs: 86726.96875
INFO:root:Train (Epoch 76): Loss/seq after 00050 batchs: 81920.671875
INFO:root:Train (Epoch 76): Loss/seq after 00100 batchs: 72805.640625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 76): Loss/seq after 00000 batches: 47191.51171875
INFO:root:Artifacts: Make stick videos for epoch 76
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_76_on_20220413_131727.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_76_index_273_on_20220413_131727.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 77): Loss/seq after 00000 batchs: 86721.53125
INFO:root:Train (Epoch 77): Loss/seq after 00050 batchs: 81928.1015625
INFO:root:Train (Epoch 77): Loss/seq after 00100 batchs: 72790.3515625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 77): Loss/seq after 00000 batches: 47305.1640625
INFO:root:Artifacts: Make stick videos for epoch 77
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_77_on_20220413_131809.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_77_index_1009_on_20220413_131809.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 78): Loss/seq after 00000 batchs: 86726.9296875
INFO:root:Train (Epoch 78): Loss/seq after 00050 batchs: 81919.421875
INFO:root:Train (Epoch 78): Loss/seq after 00100 batchs: 72775.03125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 78): Loss/seq after 00000 batches: 47239.80859375
INFO:root:Artifacts: Make stick videos for epoch 78
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_78_on_20220413_131851.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_78_index_1596_on_20220413_131851.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 79): Loss/seq after 00000 batchs: 86710.90625
INFO:root:Train (Epoch 79): Loss/seq after 00050 batchs: 81920.34375
INFO:root:Train (Epoch 79): Loss/seq after 00100 batchs: 72766.3359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 79): Loss/seq after 00000 batches: 47211.69921875
INFO:root:Artifacts: Make stick videos for epoch 79
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_79_on_20220413_131932.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_79_index_1621_on_20220413_131932.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 80): Loss/seq after 00000 batchs: 86726.1640625
INFO:root:Train (Epoch 80): Loss/seq after 00050 batchs: 81914.2109375
INFO:root:Train (Epoch 80): Loss/seq after 00100 batchs: 72754.2578125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 80): Loss/seq after 00000 batches: 47221.69140625
INFO:root:Artifacts: Make stick videos for epoch 80
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_80_on_20220413_132013.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_80_index_162_on_20220413_132013.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 81): Loss/seq after 00000 batchs: 86753.265625
INFO:root:Train (Epoch 81): Loss/seq after 00050 batchs: 81910.8671875
INFO:root:Train (Epoch 81): Loss/seq after 00100 batchs: 72737.3828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 81): Loss/seq after 00000 batches: 47200.41796875
INFO:root:Artifacts: Make stick videos for epoch 81
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_81_on_20220413_132054.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_81_index_304_on_20220413_132054.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 82): Loss/seq after 00000 batchs: 86689.625
INFO:root:Train (Epoch 82): Loss/seq after 00050 batchs: 81909.4453125
INFO:root:Train (Epoch 82): Loss/seq after 00100 batchs: 72728.9921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 82): Loss/seq after 00000 batches: 47313.48046875
INFO:root:Artifacts: Make stick videos for epoch 82
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_82_on_20220413_132141.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_82_index_1019_on_20220413_132141.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 83): Loss/seq after 00000 batchs: 86771.8984375
INFO:root:Train (Epoch 83): Loss/seq after 00050 batchs: 81919.0234375
INFO:root:Train (Epoch 83): Loss/seq after 00100 batchs: 72731.9921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 83): Loss/seq after 00000 batches: 47293.74609375
INFO:root:Artifacts: Make stick videos for epoch 83
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_83_on_20220413_132223.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_83_index_200_on_20220413_132223.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 84): Loss/seq after 00000 batchs: 86657.3046875
INFO:root:Train (Epoch 84): Loss/seq after 00050 batchs: 81899.265625
INFO:root:Train (Epoch 84): Loss/seq after 00100 batchs: 72717.3984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 84): Loss/seq after 00000 batches: 47299.40625
INFO:root:Artifacts: Make stick videos for epoch 84
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_84_on_20220413_132304.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_84_index_846_on_20220413_132304.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 85): Loss/seq after 00000 batchs: 86723.2734375
INFO:root:Train (Epoch 85): Loss/seq after 00050 batchs: 81911.421875
INFO:root:Train (Epoch 85): Loss/seq after 00100 batchs: 72712.5
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 85): Loss/seq after 00000 batches: 47264.921875
INFO:root:Artifacts: Make stick videos for epoch 85
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_85_on_20220413_132345.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_85_index_1094_on_20220413_132345.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 86): Loss/seq after 00000 batchs: 86685.9296875
INFO:root:Train (Epoch 86): Loss/seq after 00050 batchs: 81904.3125
INFO:root:Train (Epoch 86): Loss/seq after 00100 batchs: 72701.078125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 86): Loss/seq after 00000 batches: 47245.3359375
INFO:root:Artifacts: Make stick videos for epoch 86
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_86_on_20220413_132426.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_86_index_1827_on_20220413_132426.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 87): Loss/seq after 00000 batchs: 86770.0078125
INFO:root:Train (Epoch 87): Loss/seq after 00050 batchs: 81904.9453125
INFO:root:Train (Epoch 87): Loss/seq after 00100 batchs: 72694.453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 87): Loss/seq after 00000 batches: 47326.703125
INFO:root:Artifacts: Make stick videos for epoch 87
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_87_on_20220413_132507.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_87_index_583_on_20220413_132507.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 88): Loss/seq after 00000 batchs: 86655.8984375
INFO:root:Train (Epoch 88): Loss/seq after 00050 batchs: 81893.28125
INFO:root:Train (Epoch 88): Loss/seq after 00100 batchs: 72680.828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 88): Loss/seq after 00000 batches: 47370.9921875
INFO:root:Artifacts: Make stick videos for epoch 88
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_88_on_20220413_132549.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_88_index_850_on_20220413_132549.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 89): Loss/seq after 00000 batchs: 86638.984375
INFO:root:Train (Epoch 89): Loss/seq after 00050 batchs: 81901.0859375
INFO:root:Train (Epoch 89): Loss/seq after 00100 batchs: 72684.0
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 89): Loss/seq after 00000 batches: 47270.671875
INFO:root:Artifacts: Make stick videos for epoch 89
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_89_on_20220413_132630.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_89_index_77_on_20220413_132630.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 90): Loss/seq after 00000 batchs: 86639.65625
INFO:root:Train (Epoch 90): Loss/seq after 00050 batchs: 81911.8671875
INFO:root:Train (Epoch 90): Loss/seq after 00100 batchs: 72675.9453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 90): Loss/seq after 00000 batches: 47352.796875
INFO:root:Artifacts: Make stick videos for epoch 90
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_90_on_20220413_132712.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_90_index_1013_on_20220413_132712.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 91): Loss/seq after 00000 batchs: 86686.171875
INFO:root:Train (Epoch 91): Loss/seq after 00050 batchs: 81909.7734375
INFO:root:Train (Epoch 91): Loss/seq after 00100 batchs: 72665.0
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 91): Loss/seq after 00000 batches: 47148.50390625
INFO:root:Artifacts: Make stick videos for epoch 91
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_91_on_20220413_132753.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_91_index_1038_on_20220413_132753.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 92): Loss/seq after 00000 batchs: 86457.640625
INFO:root:Train (Epoch 92): Loss/seq after 00050 batchs: 81920.34375
INFO:root:Train (Epoch 92): Loss/seq after 00100 batchs: 72669.046875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 92): Loss/seq after 00000 batches: 47265.30078125
INFO:root:Artifacts: Make stick videos for epoch 92
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_92_on_20220413_132835.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_92_index_1468_on_20220413_132835.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 93): Loss/seq after 00000 batchs: 86628.6015625
INFO:root:Train (Epoch 93): Loss/seq after 00050 batchs: 81888.1328125
INFO:root:Train (Epoch 93): Loss/seq after 00100 batchs: 72654.2734375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 93): Loss/seq after 00000 batches: 47250.33203125
INFO:root:Artifacts: Make stick videos for epoch 93
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_93_on_20220413_132916.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_93_index_607_on_20220413_132916.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 94): Loss/seq after 00000 batchs: 86634.5078125
INFO:root:Train (Epoch 94): Loss/seq after 00050 batchs: 81897.515625
INFO:root:Train (Epoch 94): Loss/seq after 00100 batchs: 72649.6015625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 94): Loss/seq after 00000 batches: 47267.43359375
INFO:root:Artifacts: Make stick videos for epoch 94
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_94_on_20220413_132958.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_94_index_1402_on_20220413_132958.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 95): Loss/seq after 00000 batchs: 86672.4921875
INFO:root:Train (Epoch 95): Loss/seq after 00050 batchs: 81899.4765625
INFO:root:Train (Epoch 95): Loss/seq after 00100 batchs: 72641.6328125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 95): Loss/seq after 00000 batches: 47264.265625
INFO:root:Artifacts: Make stick videos for epoch 95
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_95_on_20220413_133039.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_95_index_1214_on_20220413_133039.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 96): Loss/seq after 00000 batchs: 86661.671875
INFO:root:Train (Epoch 96): Loss/seq after 00050 batchs: 81889.8984375
INFO:root:Train (Epoch 96): Loss/seq after 00100 batchs: 72633.8359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 96): Loss/seq after 00000 batches: 47362.55859375
INFO:root:Artifacts: Make stick videos for epoch 96
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_96_on_20220413_133121.gif.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_96_index_1427_on_20220413_133121.gif.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 97): Loss/seq after 00000 batchs: 86684.8671875
INFO:root:Train (Epoch 97): Loss/seq after 00050 batchs: 81895.75
INFO:root:Train (Epoch 97): Loss/seq after 00100 batchs: 72631.8515625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 97): Loss/seq after 00000 batches: 47356.4375
INFO:root:Artifacts: Make stick videos for epoch 97
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_97_on_20220413_133302.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_97_index_599_on_20220413_133302.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 98): Loss/seq after 00000 batchs: 86655.1171875
INFO:root:Train (Epoch 98): Loss/seq after 00050 batchs: 81893.1328125
INFO:root:Train (Epoch 98): Loss/seq after 00100 batchs: 72625.453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 98): Loss/seq after 00000 batches: 47332.76171875
INFO:root:Artifacts: Make stick videos for epoch 98
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_98_on_20220413_133343.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_98_index_1520_on_20220413_133343.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 99): Loss/seq after 00000 batchs: 86671.28125
INFO:root:Train (Epoch 99): Loss/seq after 00050 batchs: 81900.3671875
INFO:root:Train (Epoch 99): Loss/seq after 00100 batchs: 72617.6484375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 99): Loss/seq after 00000 batches: 47257.7734375
INFO:root:Artifacts: Make stick videos for epoch 99
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_99_on_20220413_133425.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_99_index_677_on_20220413_133425.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 100): Loss/seq after 00000 batchs: 86643.46875
INFO:root:Train (Epoch 100): Loss/seq after 00050 batchs: 81902.703125
INFO:root:Train (Epoch 100): Loss/seq after 00100 batchs: 72616.7578125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 100): Loss/seq after 00000 batches: 47289.26171875
INFO:root:Artifacts: Make stick videos for epoch 100
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_100_on_20220413_133506.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_100_index_664_on_20220413_133506.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 101): Loss/seq after 00000 batchs: 86652.6953125
INFO:root:Train (Epoch 101): Loss/seq after 00050 batchs: 81896.0625
INFO:root:Train (Epoch 101): Loss/seq after 00100 batchs: 72612.3984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 101): Loss/seq after 00000 batches: 47333.5234375
INFO:root:Artifacts: Make stick videos for epoch 101
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_101_on_20220413_133548.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_101_index_1000_on_20220413_133548.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 102): Loss/seq after 00000 batchs: 86665.3203125
INFO:root:Train (Epoch 102): Loss/seq after 00050 batchs: 81896.84375
INFO:root:Train (Epoch 102): Loss/seq after 00100 batchs: 72603.8671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 102): Loss/seq after 00000 batches: 47291.7109375
INFO:root:Artifacts: Make stick videos for epoch 102
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_102_on_20220413_133629.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_102_index_691_on_20220413_133629.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 103): Loss/seq after 00000 batchs: 86682.296875
INFO:root:Train (Epoch 103): Loss/seq after 00050 batchs: 81893.1484375
INFO:root:Train (Epoch 103): Loss/seq after 00100 batchs: 72596.9765625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 103): Loss/seq after 00000 batches: 47346.671875
INFO:root:Artifacts: Make stick videos for epoch 103
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_103_on_20220413_133710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_103_index_214_on_20220413_133710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 104): Loss/seq after 00000 batchs: 86674.0078125
INFO:root:Train (Epoch 104): Loss/seq after 00050 batchs: 81889.890625
INFO:root:Train (Epoch 104): Loss/seq after 00100 batchs: 72589.3125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 104): Loss/seq after 00000 batches: 47356.27734375
INFO:root:Artifacts: Make stick videos for epoch 104
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_104_on_20220413_133751.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_104_index_195_on_20220413_133751.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 105): Loss/seq after 00000 batchs: 86628.7265625
INFO:root:Train (Epoch 105): Loss/seq after 00050 batchs: 81890.234375
INFO:root:Train (Epoch 105): Loss/seq after 00100 batchs: 72587.5625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 105): Loss/seq after 00000 batches: 47304.0
INFO:root:Artifacts: Make stick videos for epoch 105
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_105_on_20220413_133833.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_105_index_213_on_20220413_133833.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 106): Loss/seq after 00000 batchs: 86736.0234375
INFO:root:Train (Epoch 106): Loss/seq after 00050 batchs: 81890.90625
INFO:root:Train (Epoch 106): Loss/seq after 00100 batchs: 72580.53125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 106): Loss/seq after 00000 batches: 47321.92578125
INFO:root:Artifacts: Make stick videos for epoch 106
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_106_on_20220413_133914.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_106_index_830_on_20220413_133914.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 107): Loss/seq after 00000 batchs: 86618.7421875
INFO:root:Train (Epoch 107): Loss/seq after 00050 batchs: 81893.8515625
INFO:root:Train (Epoch 107): Loss/seq after 00100 batchs: 72580.109375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 107): Loss/seq after 00000 batches: 47341.703125
INFO:root:Artifacts: Make stick videos for epoch 107
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_107_on_20220413_133956.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_107_index_33_on_20220413_133956.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 108): Loss/seq after 00000 batchs: 86737.1640625
INFO:root:Train (Epoch 108): Loss/seq after 00050 batchs: 81890.6796875
INFO:root:Train (Epoch 108): Loss/seq after 00100 batchs: 72570.8125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 108): Loss/seq after 00000 batches: 47294.40625
INFO:root:Artifacts: Make stick videos for epoch 108
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_108_on_20220413_134037.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_108_index_1780_on_20220413_134037.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 109): Loss/seq after 00000 batchs: 86750.03125
INFO:root:Train (Epoch 109): Loss/seq after 00050 batchs: 81884.03125
INFO:root:Train (Epoch 109): Loss/seq after 00100 batchs: 72564.546875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 109): Loss/seq after 00000 batches: 47278.4765625
INFO:root:Artifacts: Make stick videos for epoch 109
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_109_on_20220413_134119.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_109_index_1358_on_20220413_134119.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 110): Loss/seq after 00000 batchs: 86723.78125
INFO:root:Train (Epoch 110): Loss/seq after 00050 batchs: 81894.3203125
INFO:root:Train (Epoch 110): Loss/seq after 00100 batchs: 72651.2421875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 110): Loss/seq after 00000 batches: 47161.24609375
INFO:root:Artifacts: Make stick videos for epoch 110
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_110_on_20220413_134200.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_110_index_927_on_20220413_134200.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 111): Loss/seq after 00000 batchs: 86752.84375
INFO:root:Train (Epoch 111): Loss/seq after 00050 batchs: 81923.0
INFO:root:Train (Epoch 111): Loss/seq after 00100 batchs: 72632.546875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 111): Loss/seq after 00000 batches: 47333.51953125
INFO:root:Artifacts: Make stick videos for epoch 111
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_111_on_20220413_134242.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_111_index_334_on_20220413_134242.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 112): Loss/seq after 00000 batchs: 86790.421875
INFO:root:Train (Epoch 112): Loss/seq after 00050 batchs: 81909.6875
INFO:root:Train (Epoch 112): Loss/seq after 00100 batchs: 72594.3984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 112): Loss/seq after 00000 batches: 47349.91015625
INFO:root:Artifacts: Make stick videos for epoch 112
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_112_on_20220413_134324.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_112_index_555_on_20220413_134324.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 113): Loss/seq after 00000 batchs: 86763.9453125
INFO:root:Train (Epoch 113): Loss/seq after 00050 batchs: 81903.171875
INFO:root:Train (Epoch 113): Loss/seq after 00100 batchs: 72581.8984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 113): Loss/seq after 00000 batches: 47285.8984375
INFO:root:Artifacts: Make stick videos for epoch 113
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_113_on_20220413_134406.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_113_index_462_on_20220413_134406.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 114): Loss/seq after 00000 batchs: 86758.1328125
INFO:root:Train (Epoch 114): Loss/seq after 00050 batchs: 81909.9140625
INFO:root:Train (Epoch 114): Loss/seq after 00100 batchs: 72574.8359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 114): Loss/seq after 00000 batches: 47282.578125
INFO:root:Artifacts: Make stick videos for epoch 114
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_114_on_20220413_134447.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_114_index_366_on_20220413_134447.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 115): Loss/seq after 00000 batchs: 86747.546875
INFO:root:Train (Epoch 115): Loss/seq after 00050 batchs: 81891.0390625
INFO:root:Train (Epoch 115): Loss/seq after 00100 batchs: 72566.703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 115): Loss/seq after 00000 batches: 47369.15234375
INFO:root:Artifacts: Make stick videos for epoch 115
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_115_on_20220413_134529.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_115_index_1416_on_20220413_134529.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 116): Loss/seq after 00000 batchs: 86791.6015625
INFO:root:Train (Epoch 116): Loss/seq after 00050 batchs: 81904.8984375
INFO:root:Train (Epoch 116): Loss/seq after 00100 batchs: 72558.09375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 116): Loss/seq after 00000 batches: 47313.8125
INFO:root:Artifacts: Make stick videos for epoch 116
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_116_on_20220413_134611.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_116_index_1242_on_20220413_134611.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 117): Loss/seq after 00000 batchs: 86666.53125
INFO:root:Train (Epoch 117): Loss/seq after 00050 batchs: 81903.359375
INFO:root:Train (Epoch 117): Loss/seq after 00100 batchs: 72550.2734375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 117): Loss/seq after 00000 batches: 47292.7109375
INFO:root:Artifacts: Make stick videos for epoch 117
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_117_on_20220413_134653.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_117_index_1394_on_20220413_134653.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 118): Loss/seq after 00000 batchs: 86737.484375
INFO:root:Train (Epoch 118): Loss/seq after 00050 batchs: 81901.3359375
INFO:root:Train (Epoch 118): Loss/seq after 00100 batchs: 72540.3203125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 118): Loss/seq after 00000 batches: 47341.2734375
INFO:root:Artifacts: Make stick videos for epoch 118
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_118_on_20220413_134734.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_118_index_1195_on_20220413_134734.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 119): Loss/seq after 00000 batchs: 86768.46875
INFO:root:Train (Epoch 119): Loss/seq after 00050 batchs: 81898.25
INFO:root:Train (Epoch 119): Loss/seq after 00100 batchs: 72537.53125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 119): Loss/seq after 00000 batches: 47296.32421875
INFO:root:Artifacts: Make stick videos for epoch 119
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_119_on_20220413_134814.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_119_index_337_on_20220413_134814.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 120): Loss/seq after 00000 batchs: 86678.4609375
INFO:root:Train (Epoch 120): Loss/seq after 00050 batchs: 81901.359375
INFO:root:Train (Epoch 120): Loss/seq after 00100 batchs: 72532.546875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 120): Loss/seq after 00000 batches: 47327.4140625
INFO:root:Artifacts: Make stick videos for epoch 120
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_120_on_20220413_134855.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_120_index_1864_on_20220413_134855.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 121): Loss/seq after 00000 batchs: 86683.2265625
INFO:root:Train (Epoch 121): Loss/seq after 00050 batchs: 81890.9609375
INFO:root:Train (Epoch 121): Loss/seq after 00100 batchs: 72523.328125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 121): Loss/seq after 00000 batches: 47303.53515625
INFO:root:Artifacts: Make stick videos for epoch 121
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_121_on_20220413_134936.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_121_index_1225_on_20220413_134936.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 122): Loss/seq after 00000 batchs: 86771.6875
INFO:root:Train (Epoch 122): Loss/seq after 00050 batchs: 81904.609375
INFO:root:Train (Epoch 122): Loss/seq after 00100 batchs: 72523.921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 122): Loss/seq after 00000 batches: 47338.796875
INFO:root:Artifacts: Make stick videos for epoch 122
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_122_on_20220413_135017.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_122_index_13_on_20220413_135017.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 123): Loss/seq after 00000 batchs: 86750.5859375
INFO:root:Train (Epoch 123): Loss/seq after 00050 batchs: 81898.203125
INFO:root:Train (Epoch 123): Loss/seq after 00100 batchs: 72516.3828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 123): Loss/seq after 00000 batches: 47317.25390625
INFO:root:Artifacts: Make stick videos for epoch 123
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_123_on_20220413_135058.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_123_index_1843_on_20220413_135058.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 124): Loss/seq after 00000 batchs: 86764.0234375
INFO:root:Train (Epoch 124): Loss/seq after 00050 batchs: 81902.171875
INFO:root:Train (Epoch 124): Loss/seq after 00100 batchs: 72513.40625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 124): Loss/seq after 00000 batches: 47359.6875
INFO:root:Artifacts: Make stick videos for epoch 124
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_124_on_20220413_135140.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_124_index_352_on_20220413_135140.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 125): Loss/seq after 00000 batchs: 86697.046875
INFO:root:Train (Epoch 125): Loss/seq after 00050 batchs: 81899.78125
INFO:root:Train (Epoch 125): Loss/seq after 00100 batchs: 72506.40625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 125): Loss/seq after 00000 batches: 47354.0390625
INFO:root:Artifacts: Make stick videos for epoch 125
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_125_on_20220413_135220.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_125_index_1560_on_20220413_135220.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 126): Loss/seq after 00000 batchs: 86689.6015625
INFO:root:Train (Epoch 126): Loss/seq after 00050 batchs: 81897.90625
INFO:root:Train (Epoch 126): Loss/seq after 00100 batchs: 72503.0625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 126): Loss/seq after 00000 batches: 47328.15625
INFO:root:Artifacts: Make stick videos for epoch 126
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_126_on_20220413_135302.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_126_index_1603_on_20220413_135302.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 127): Loss/seq after 00000 batchs: 86668.328125
INFO:root:Train (Epoch 127): Loss/seq after 00050 batchs: 81899.46875
INFO:root:Train (Epoch 127): Loss/seq after 00100 batchs: 72500.203125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 127): Loss/seq after 00000 batches: 47315.734375
INFO:root:Artifacts: Make stick videos for epoch 127
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_127_on_20220413_135343.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_127_index_198_on_20220413_135343.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 128): Loss/seq after 00000 batchs: 86719.9375
INFO:root:Train (Epoch 128): Loss/seq after 00050 batchs: 81897.390625
INFO:root:Train (Epoch 128): Loss/seq after 00100 batchs: 72493.25
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 128): Loss/seq after 00000 batches: 47260.05078125
INFO:root:Artifacts: Make stick videos for epoch 128
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_128_on_20220413_135424.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_128_index_1266_on_20220413_135424.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 129): Loss/seq after 00000 batchs: 86630.453125
INFO:root:Train (Epoch 129): Loss/seq after 00050 batchs: 81887.234375
INFO:root:Train (Epoch 129): Loss/seq after 00100 batchs: 72486.71875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 129): Loss/seq after 00000 batches: 47462.59375
INFO:root:Artifacts: Make stick videos for epoch 129
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_129_on_20220413_135505.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_129_index_1042_on_20220413_135505.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 130): Loss/seq after 00000 batchs: 86567.1640625
INFO:root:Train (Epoch 130): Loss/seq after 00050 batchs: 81895.515625
INFO:root:Train (Epoch 130): Loss/seq after 00100 batchs: 72489.890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 130): Loss/seq after 00000 batches: 47354.17578125
INFO:root:Artifacts: Make stick videos for epoch 130
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_130_on_20220413_135545.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_130_index_1685_on_20220413_135545.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 131): Loss/seq after 00000 batchs: 86719.2421875
INFO:root:Train (Epoch 131): Loss/seq after 00050 batchs: 81901.75
INFO:root:Train (Epoch 131): Loss/seq after 00100 batchs: 72484.5078125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 131): Loss/seq after 00000 batches: 47325.05078125
INFO:root:Artifacts: Make stick videos for epoch 131
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_131_on_20220413_135626.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_131_index_1132_on_20220413_135626.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 132): Loss/seq after 00000 batchs: 86756.796875
INFO:root:Train (Epoch 132): Loss/seq after 00050 batchs: 81900.0390625
INFO:root:Train (Epoch 132): Loss/seq after 00100 batchs: 72479.9140625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 132): Loss/seq after 00000 batches: 47320.51171875
INFO:root:Artifacts: Make stick videos for epoch 132
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_132_on_20220413_135708.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_132_index_69_on_20220413_135708.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 133): Loss/seq after 00000 batchs: 86681.7734375
INFO:root:Train (Epoch 133): Loss/seq after 00050 batchs: 81889.7265625
INFO:root:Train (Epoch 133): Loss/seq after 00100 batchs: 72471.015625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 133): Loss/seq after 00000 batches: 47327.73828125
INFO:root:Artifacts: Make stick videos for epoch 133
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_133_on_20220413_135750.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_133_index_557_on_20220413_135750.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 134): Loss/seq after 00000 batchs: 86673.3125
INFO:root:Train (Epoch 134): Loss/seq after 00050 batchs: 81899.0625
INFO:root:Train (Epoch 134): Loss/seq after 00100 batchs: 72471.2734375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 134): Loss/seq after 00000 batches: 47381.85546875
INFO:root:Artifacts: Make stick videos for epoch 134
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_134_on_20220413_135831.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_134_index_961_on_20220413_135831.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 135): Loss/seq after 00000 batchs: 86719.4140625
INFO:root:Train (Epoch 135): Loss/seq after 00050 batchs: 81890.765625
INFO:root:Train (Epoch 135): Loss/seq after 00100 batchs: 72463.8828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 135): Loss/seq after 00000 batches: 47386.8125
INFO:root:Artifacts: Make stick videos for epoch 135
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_135_on_20220413_135913.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_135_index_1319_on_20220413_135913.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 136): Loss/seq after 00000 batchs: 86730.5625
INFO:root:Train (Epoch 136): Loss/seq after 00050 batchs: 81894.015625
INFO:root:Train (Epoch 136): Loss/seq after 00100 batchs: 72460.7265625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 136): Loss/seq after 00000 batches: 47339.16015625
INFO:root:Artifacts: Make stick videos for epoch 136
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_136_on_20220413_135954.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_136_index_1131_on_20220413_135954.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 137): Loss/seq after 00000 batchs: 86734.5546875
INFO:root:Train (Epoch 137): Loss/seq after 00050 batchs: 81895.46875
INFO:root:Train (Epoch 137): Loss/seq after 00100 batchs: 72460.921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 137): Loss/seq after 00000 batches: 47409.01953125
INFO:root:Artifacts: Make stick videos for epoch 137
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_137_on_20220413_140037.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_137_index_1775_on_20220413_140037.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 138): Loss/seq after 00000 batchs: 86735.9921875
INFO:root:Train (Epoch 138): Loss/seq after 00050 batchs: 81875.859375
INFO:root:Train (Epoch 138): Loss/seq after 00100 batchs: 72446.703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 138): Loss/seq after 00000 batches: 47390.4921875
INFO:root:Artifacts: Make stick videos for epoch 138
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_138_on_20220413_140118.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_138_index_1617_on_20220413_140118.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 139): Loss/seq after 00000 batchs: 86731.6875
INFO:root:Train (Epoch 139): Loss/seq after 00050 batchs: 81889.7265625
INFO:root:Train (Epoch 139): Loss/seq after 00100 batchs: 72444.4453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 139): Loss/seq after 00000 batches: 47413.89453125
INFO:root:Artifacts: Make stick videos for epoch 139
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_139_on_20220413_140200.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_139_index_278_on_20220413_140200.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 140): Loss/seq after 00000 batchs: 86738.5703125
INFO:root:Train (Epoch 140): Loss/seq after 00050 batchs: 81890.1328125
INFO:root:Train (Epoch 140): Loss/seq after 00100 batchs: 72443.8984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 140): Loss/seq after 00000 batches: 47348.63671875
INFO:root:Artifacts: Make stick videos for epoch 140
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_140_on_20220413_140241.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_140_index_637_on_20220413_140241.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 141): Loss/seq after 00000 batchs: 86719.359375
INFO:root:Train (Epoch 141): Loss/seq after 00050 batchs: 81884.328125
INFO:root:Train (Epoch 141): Loss/seq after 00100 batchs: 72435.859375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 141): Loss/seq after 00000 batches: 47393.09375
INFO:root:Artifacts: Make stick videos for epoch 141
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_141_on_20220413_140323.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_141_index_1393_on_20220413_140323.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 142): Loss/seq after 00000 batchs: 86664.703125
INFO:root:Train (Epoch 142): Loss/seq after 00050 batchs: 81883.2421875
INFO:root:Train (Epoch 142): Loss/seq after 00100 batchs: 72429.0234375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 142): Loss/seq after 00000 batches: 47438.1484375
INFO:root:Artifacts: Make stick videos for epoch 142
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_142_on_20220413_140405.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_142_index_1076_on_20220413_140405.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 143): Loss/seq after 00000 batchs: 86743.90625
INFO:root:Train (Epoch 143): Loss/seq after 00050 batchs: 81899.671875
INFO:root:Train (Epoch 143): Loss/seq after 00100 batchs: 72436.3515625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 143): Loss/seq after 00000 batches: 47404.33984375
INFO:root:Artifacts: Make stick videos for epoch 143
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_143_on_20220413_140446.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_143_index_4_on_20220413_140446.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 144): Loss/seq after 00000 batchs: 86680.7734375
INFO:root:Train (Epoch 144): Loss/seq after 00050 batchs: 81889.8984375
INFO:root:Train (Epoch 144): Loss/seq after 00100 batchs: 72427.9921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 144): Loss/seq after 00000 batches: 47383.54296875
INFO:root:Artifacts: Make stick videos for epoch 144
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_144_on_20220413_140527.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_144_index_1156_on_20220413_140527.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 145): Loss/seq after 00000 batchs: 86710.109375
INFO:root:Train (Epoch 145): Loss/seq after 00050 batchs: 81886.5546875
INFO:root:Train (Epoch 145): Loss/seq after 00100 batchs: 72420.3671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 145): Loss/seq after 00000 batches: 47422.79296875
INFO:root:Artifacts: Make stick videos for epoch 145
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_145_on_20220413_140609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_145_index_253_on_20220413_140609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 146): Loss/seq after 00000 batchs: 86725.828125
INFO:root:Train (Epoch 146): Loss/seq after 00050 batchs: 81891.8671875
INFO:root:Train (Epoch 146): Loss/seq after 00100 batchs: 72419.84375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 146): Loss/seq after 00000 batches: 47400.01171875
INFO:root:Artifacts: Make stick videos for epoch 146
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_146_on_20220413_140651.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_146_index_81_on_20220413_140651.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 147): Loss/seq after 00000 batchs: 86721.1640625
INFO:root:Train (Epoch 147): Loss/seq after 00050 batchs: 81885.703125
INFO:root:Train (Epoch 147): Loss/seq after 00100 batchs: 72412.5
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 147): Loss/seq after 00000 batches: 47418.671875
INFO:root:Artifacts: Make stick videos for epoch 147
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_147_on_20220413_140732.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_147_index_1843_on_20220413_140732.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 148): Loss/seq after 00000 batchs: 86721.2734375
INFO:root:Train (Epoch 148): Loss/seq after 00050 batchs: 81885.0703125
INFO:root:Train (Epoch 148): Loss/seq after 00100 batchs: 72407.59375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 148): Loss/seq after 00000 batches: 47417.78515625
INFO:root:Artifacts: Make stick videos for epoch 148
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_148_on_20220413_140815.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_148_index_397_on_20220413_140815.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 149): Loss/seq after 00000 batchs: 86669.34375
INFO:root:Train (Epoch 149): Loss/seq after 00050 batchs: 81883.0234375
INFO:root:Train (Epoch 149): Loss/seq after 00100 batchs: 72403.125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 149): Loss/seq after 00000 batches: 47415.23828125
INFO:root:Artifacts: Make stick videos for epoch 149
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_149_on_20220413_140857.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_149_index_726_on_20220413_140857.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 150): Loss/seq after 00000 batchs: 86738.5390625
INFO:root:Train (Epoch 150): Loss/seq after 00050 batchs: 81879.6171875
INFO:root:Train (Epoch 150): Loss/seq after 00100 batchs: 72398.15625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 150): Loss/seq after 00000 batches: 47435.64453125
INFO:root:Artifacts: Make stick videos for epoch 150
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_150_on_20220413_140939.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_150_index_260_on_20220413_140939.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 151): Loss/seq after 00000 batchs: 86708.3828125
INFO:root:Train (Epoch 151): Loss/seq after 00050 batchs: 81881.6484375
INFO:root:Train (Epoch 151): Loss/seq after 00100 batchs: 72394.0859375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 151): Loss/seq after 00000 batches: 47441.18359375
INFO:root:Artifacts: Make stick videos for epoch 151
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_151_on_20220413_141021.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_151_index_1715_on_20220413_141021.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 152): Loss/seq after 00000 batchs: 86685.78125
INFO:root:Train (Epoch 152): Loss/seq after 00050 batchs: 81886.1328125
INFO:root:Train (Epoch 152): Loss/seq after 00100 batchs: 72389.8359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 152): Loss/seq after 00000 batches: 47446.66796875
INFO:root:Artifacts: Make stick videos for epoch 152
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_152_on_20220413_141103.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_152_index_305_on_20220413_141103.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 153): Loss/seq after 00000 batchs: 86739.71875
INFO:root:Train (Epoch 153): Loss/seq after 00050 batchs: 81881.9453125
INFO:root:Train (Epoch 153): Loss/seq after 00100 batchs: 72383.3828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 153): Loss/seq after 00000 batches: 47445.9609375
INFO:root:Artifacts: Make stick videos for epoch 153
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_153_on_20220413_141144.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_153_index_285_on_20220413_141144.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 154): Loss/seq after 00000 batchs: 86750.203125
INFO:root:Train (Epoch 154): Loss/seq after 00050 batchs: 81879.6796875
INFO:root:Train (Epoch 154): Loss/seq after 00100 batchs: 72381.7890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 154): Loss/seq after 00000 batches: 47425.03515625
INFO:root:Artifacts: Make stick videos for epoch 154
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_154_on_20220413_141226.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_154_index_308_on_20220413_141226.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 155): Loss/seq after 00000 batchs: 86741.109375
INFO:root:Train (Epoch 155): Loss/seq after 00050 batchs: 81887.59375
INFO:root:Train (Epoch 155): Loss/seq after 00100 batchs: 72380.4921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 155): Loss/seq after 00000 batches: 47447.49609375
INFO:root:Artifacts: Make stick videos for epoch 155
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_155_on_20220413_141307.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_155_index_184_on_20220413_141307.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 156): Loss/seq after 00000 batchs: 86712.3984375
INFO:root:Train (Epoch 156): Loss/seq after 00050 batchs: 81881.40625
INFO:root:Train (Epoch 156): Loss/seq after 00100 batchs: 72375.0
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 156): Loss/seq after 00000 batches: 47446.74609375
INFO:root:Artifacts: Make stick videos for epoch 156
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_156_on_20220413_141350.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_156_index_1247_on_20220413_141350.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 157): Loss/seq after 00000 batchs: 86703.90625
INFO:root:Train (Epoch 157): Loss/seq after 00050 batchs: 81879.5078125
INFO:root:Train (Epoch 157): Loss/seq after 00100 batchs: 72368.0
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 157): Loss/seq after 00000 batches: 47442.1953125
INFO:root:Artifacts: Make stick videos for epoch 157
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_157_on_20220413_141437.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_157_index_1578_on_20220413_141437.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 158): Loss/seq after 00000 batchs: 86753.859375
INFO:root:Train (Epoch 158): Loss/seq after 00050 batchs: 81879.6171875
INFO:root:Train (Epoch 158): Loss/seq after 00100 batchs: 72363.3671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 158): Loss/seq after 00000 batches: 47462.41796875
INFO:root:Artifacts: Make stick videos for epoch 158
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_158_on_20220413_141525.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_158_index_1071_on_20220413_141525.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 159): Loss/seq after 00000 batchs: 86705.21875
INFO:root:Train (Epoch 159): Loss/seq after 00050 batchs: 81881.7265625
INFO:root:Train (Epoch 159): Loss/seq after 00100 batchs: 72360.8984375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 159): Loss/seq after 00000 batches: 47448.109375
INFO:root:Artifacts: Make stick videos for epoch 159
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_159_on_20220413_141611.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_159_index_565_on_20220413_141611.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 160): Loss/seq after 00000 batchs: 86709.140625
INFO:root:Train (Epoch 160): Loss/seq after 00050 batchs: 81876.5390625
INFO:root:Train (Epoch 160): Loss/seq after 00100 batchs: 72357.8671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 160): Loss/seq after 00000 batches: 47459.68359375
INFO:root:Artifacts: Make stick videos for epoch 160
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_160_on_20220413_141652.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_160_index_1641_on_20220413_141652.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 161): Loss/seq after 00000 batchs: 86710.3984375
INFO:root:Train (Epoch 161): Loss/seq after 00050 batchs: 81875.0
INFO:root:Train (Epoch 161): Loss/seq after 00100 batchs: 72350.8671875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 161): Loss/seq after 00000 batches: 47444.0703125
INFO:root:Artifacts: Make stick videos for epoch 161
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_161_on_20220413_141734.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_161_index_1072_on_20220413_141734.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 162): Loss/seq after 00000 batchs: 86765.8359375
INFO:root:Train (Epoch 162): Loss/seq after 00050 batchs: 81871.9375
INFO:root:Train (Epoch 162): Loss/seq after 00100 batchs: 72349.4375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 162): Loss/seq after 00000 batches: 47441.3828125
INFO:root:Artifacts: Make stick videos for epoch 162
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_162_on_20220413_141816.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_162_index_452_on_20220413_141816.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 163): Loss/seq after 00000 batchs: 86715.0390625
INFO:root:Train (Epoch 163): Loss/seq after 00050 batchs: 81880.6484375
INFO:root:Train (Epoch 163): Loss/seq after 00100 batchs: 72345.1953125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 163): Loss/seq after 00000 batches: 47464.49609375
INFO:root:Artifacts: Make stick videos for epoch 163
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_163_on_20220413_141858.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_163_index_1885_on_20220413_141858.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 164): Loss/seq after 00000 batchs: 86740.34375
INFO:root:Train (Epoch 164): Loss/seq after 00050 batchs: 81879.03125
INFO:root:Train (Epoch 164): Loss/seq after 00100 batchs: 72340.53125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 164): Loss/seq after 00000 batches: 47467.2109375
INFO:root:Artifacts: Make stick videos for epoch 164
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_164_on_20220413_141940.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_164_index_462_on_20220413_141940.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 165): Loss/seq after 00000 batchs: 86761.625
INFO:root:Train (Epoch 165): Loss/seq after 00050 batchs: 81877.609375
INFO:root:Train (Epoch 165): Loss/seq after 00100 batchs: 72336.7734375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 165): Loss/seq after 00000 batches: 47459.1640625
INFO:root:Artifacts: Make stick videos for epoch 165
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_165_on_20220413_142021.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_165_index_292_on_20220413_142021.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 166): Loss/seq after 00000 batchs: 86734.359375
INFO:root:Train (Epoch 166): Loss/seq after 00050 batchs: 81877.515625
INFO:root:Train (Epoch 166): Loss/seq after 00100 batchs: 72331.7890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 166): Loss/seq after 00000 batches: 47465.56640625
INFO:root:Artifacts: Make stick videos for epoch 166
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_166_on_20220413_142102.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_166_index_563_on_20220413_142102.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 167): Loss/seq after 00000 batchs: 86772.3125
INFO:root:Train (Epoch 167): Loss/seq after 00050 batchs: 81878.3046875
INFO:root:Train (Epoch 167): Loss/seq after 00100 batchs: 72327.9296875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 167): Loss/seq after 00000 batches: 47467.8203125
INFO:root:Artifacts: Make stick videos for epoch 167
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_167_on_20220413_142143.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_167_index_1013_on_20220413_142143.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 168): Loss/seq after 00000 batchs: 86747.4375
INFO:root:Train (Epoch 168): Loss/seq after 00050 batchs: 81879.90625
INFO:root:Train (Epoch 168): Loss/seq after 00100 batchs: 72326.609375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 168): Loss/seq after 00000 batches: 47431.6953125
INFO:root:Artifacts: Make stick videos for epoch 168
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_168_on_20220413_142225.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_168_index_110_on_20220413_142225.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 169): Loss/seq after 00000 batchs: 86759.703125
INFO:root:Train (Epoch 169): Loss/seq after 00050 batchs: 81876.171875
INFO:root:Train (Epoch 169): Loss/seq after 00100 batchs: 72320.125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 169): Loss/seq after 00000 batches: 47428.36328125
INFO:root:Artifacts: Make stick videos for epoch 169
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_169_on_20220413_142306.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_169_index_1796_on_20220413_142306.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 170): Loss/seq after 00000 batchs: 86805.75
INFO:root:Train (Epoch 170): Loss/seq after 00050 batchs: 81877.6953125
INFO:root:Train (Epoch 170): Loss/seq after 00100 batchs: 72316.09375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 170): Loss/seq after 00000 batches: 47472.58984375
INFO:root:Artifacts: Make stick videos for epoch 170
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_170_on_20220413_142348.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_170_index_565_on_20220413_142348.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 171): Loss/seq after 00000 batchs: 86807.4921875
INFO:root:Train (Epoch 171): Loss/seq after 00050 batchs: 81878.53125
INFO:root:Train (Epoch 171): Loss/seq after 00100 batchs: 72312.8046875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 171): Loss/seq after 00000 batches: 47469.26953125
INFO:root:Artifacts: Make stick videos for epoch 171
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_171_on_20220413_142429.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_171_index_311_on_20220413_142429.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 172): Loss/seq after 00000 batchs: 86753.03125
INFO:root:Train (Epoch 172): Loss/seq after 00050 batchs: 81877.609375
INFO:root:Train (Epoch 172): Loss/seq after 00100 batchs: 72314.3828125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 172): Loss/seq after 00000 batches: 47468.6484375
INFO:root:Artifacts: Make stick videos for epoch 172
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_172_on_20220413_142509.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_172_index_1618_on_20220413_142509.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 173): Loss/seq after 00000 batchs: 86768.1015625
INFO:root:Train (Epoch 173): Loss/seq after 00050 batchs: 81878.828125
INFO:root:Train (Epoch 173): Loss/seq after 00100 batchs: 72307.9453125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 173): Loss/seq after 00000 batches: 47430.94921875
INFO:root:Artifacts: Make stick videos for epoch 173
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_173_on_20220413_142550.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_173_index_33_on_20220413_142550.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 174): Loss/seq after 00000 batchs: 86774.0078125
INFO:root:Train (Epoch 174): Loss/seq after 00050 batchs: 81878.0546875
INFO:root:Train (Epoch 174): Loss/seq after 00100 batchs: 72304.7890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 174): Loss/seq after 00000 batches: 47466.9140625
INFO:root:Artifacts: Make stick videos for epoch 174
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_174_on_20220413_142632.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_174_index_806_on_20220413_142632.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 175): Loss/seq after 00000 batchs: 86815.703125
INFO:root:Train (Epoch 175): Loss/seq after 00050 batchs: 81881.3984375
INFO:root:Train (Epoch 175): Loss/seq after 00100 batchs: 72303.1484375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 175): Loss/seq after 00000 batches: 47441.47265625
INFO:root:Artifacts: Make stick videos for epoch 175
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_175_on_20220413_142713.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_175_index_916_on_20220413_142713.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 176): Loss/seq after 00000 batchs: 86808.71875
INFO:root:Train (Epoch 176): Loss/seq after 00050 batchs: 81880.9296875
INFO:root:Train (Epoch 176): Loss/seq after 00100 batchs: 72300.5234375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 176): Loss/seq after 00000 batches: 47441.08203125
INFO:root:Artifacts: Make stick videos for epoch 176
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_176_on_20220413_142756.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_176_index_1382_on_20220413_142756.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 177): Loss/seq after 00000 batchs: 86780.7109375
INFO:root:Train (Epoch 177): Loss/seq after 00050 batchs: 81883.078125
INFO:root:Train (Epoch 177): Loss/seq after 00100 batchs: 72297.4921875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 177): Loss/seq after 00000 batches: 47447.96875
INFO:root:Artifacts: Make stick videos for epoch 177
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_177_on_20220413_142837.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_177_index_1769_on_20220413_142837.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 178): Loss/seq after 00000 batchs: 86785.2421875
INFO:root:Train (Epoch 178): Loss/seq after 00050 batchs: 81882.2578125
INFO:root:Train (Epoch 178): Loss/seq after 00100 batchs: 72292.90625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 178): Loss/seq after 00000 batches: 47458.6640625
INFO:root:Artifacts: Make stick videos for epoch 178
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_178_on_20220413_142918.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_178_index_1580_on_20220413_142918.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 179): Loss/seq after 00000 batchs: 86834.1015625
INFO:root:Train (Epoch 179): Loss/seq after 00050 batchs: 81885.59375
INFO:root:Train (Epoch 179): Loss/seq after 00100 batchs: 72294.0703125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 179): Loss/seq after 00000 batches: 47444.6875
INFO:root:Artifacts: Make stick videos for epoch 179
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_179_on_20220413_143000.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_179_index_1635_on_20220413_143000.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 180): Loss/seq after 00000 batchs: 86821.8203125
INFO:root:Train (Epoch 180): Loss/seq after 00050 batchs: 81883.796875
INFO:root:Train (Epoch 180): Loss/seq after 00100 batchs: 72289.140625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 180): Loss/seq after 00000 batches: 47430.89453125
INFO:root:Artifacts: Make stick videos for epoch 180
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_180_on_20220413_143041.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_180_index_1500_on_20220413_143041.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 181): Loss/seq after 00000 batchs: 86830.2578125
INFO:root:Train (Epoch 181): Loss/seq after 00050 batchs: 81883.921875
INFO:root:Train (Epoch 181): Loss/seq after 00100 batchs: 72287.8125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 181): Loss/seq after 00000 batches: 47443.546875
INFO:root:Artifacts: Make stick videos for epoch 181
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_181_on_20220413_143122.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_181_index_765_on_20220413_143122.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 182): Loss/seq after 00000 batchs: 86825.6171875
INFO:root:Train (Epoch 182): Loss/seq after 00050 batchs: 81886.921875
INFO:root:Train (Epoch 182): Loss/seq after 00100 batchs: 72286.78125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 182): Loss/seq after 00000 batches: 47451.83203125
INFO:root:Artifacts: Make stick videos for epoch 182
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_182_on_20220413_143206.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_182_index_266_on_20220413_143206.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 183): Loss/seq after 00000 batchs: 86826.359375
INFO:root:Train (Epoch 183): Loss/seq after 00050 batchs: 81884.7890625
INFO:root:Train (Epoch 183): Loss/seq after 00100 batchs: 72282.4140625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 183): Loss/seq after 00000 batches: 47455.921875
INFO:root:Artifacts: Make stick videos for epoch 183
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_183_on_20220413_143248.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_183_index_254_on_20220413_143248.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 184): Loss/seq after 00000 batchs: 86815.0
INFO:root:Train (Epoch 184): Loss/seq after 00050 batchs: 81886.2265625
INFO:root:Train (Epoch 184): Loss/seq after 00100 batchs: 72282.2109375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 184): Loss/seq after 00000 batches: 47445.66015625
INFO:root:Artifacts: Make stick videos for epoch 184
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_184_on_20220413_143330.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_184_index_1255_on_20220413_143330.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 185): Loss/seq after 00000 batchs: 86821.703125
INFO:root:Train (Epoch 185): Loss/seq after 00050 batchs: 81885.1796875
INFO:root:Train (Epoch 185): Loss/seq after 00100 batchs: 72279.359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 185): Loss/seq after 00000 batches: 47419.5546875
INFO:root:Artifacts: Make stick videos for epoch 185
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_185_on_20220413_143411.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_185_index_557_on_20220413_143411.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 186): Loss/seq after 00000 batchs: 86823.8359375
INFO:root:Train (Epoch 186): Loss/seq after 00050 batchs: 81883.859375
INFO:root:Train (Epoch 186): Loss/seq after 00100 batchs: 72275.8359375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 186): Loss/seq after 00000 batches: 47451.01953125
INFO:root:Artifacts: Make stick videos for epoch 186
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_186_on_20220413_143453.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_186_index_235_on_20220413_143453.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 187): Loss/seq after 00000 batchs: 86818.078125
INFO:root:Train (Epoch 187): Loss/seq after 00050 batchs: 81884.0546875
INFO:root:Train (Epoch 187): Loss/seq after 00100 batchs: 72275.2890625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 187): Loss/seq after 00000 batches: 47426.26171875
INFO:root:Artifacts: Make stick videos for epoch 187
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_187_on_20220413_143536.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_187_index_720_on_20220413_143536.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 188): Loss/seq after 00000 batchs: 86804.1796875
INFO:root:Train (Epoch 188): Loss/seq after 00050 batchs: 81885.8828125
INFO:root:Train (Epoch 188): Loss/seq after 00100 batchs: 72273.6796875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 188): Loss/seq after 00000 batches: 47450.03125
INFO:root:Artifacts: Make stick videos for epoch 188
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_188_on_20220413_143617.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_188_index_1292_on_20220413_143617.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 189): Loss/seq after 00000 batchs: 86797.640625
INFO:root:Train (Epoch 189): Loss/seq after 00050 batchs: 81886.46875
INFO:root:Train (Epoch 189): Loss/seq after 00100 batchs: 72270.9765625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 189): Loss/seq after 00000 batches: 47438.73828125
INFO:root:Artifacts: Make stick videos for epoch 189
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_189_on_20220413_143659.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_189_index_126_on_20220413_143659.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 190): Loss/seq after 00000 batchs: 86809.375
INFO:root:Train (Epoch 190): Loss/seq after 00050 batchs: 81887.0546875
INFO:root:Train (Epoch 190): Loss/seq after 00100 batchs: 72270.21875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 190): Loss/seq after 00000 batches: 47408.8984375
INFO:root:Artifacts: Make stick videos for epoch 190
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_190_on_20220413_143740.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_190_index_1814_on_20220413_143740.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 191): Loss/seq after 00000 batchs: 86825.296875
INFO:root:Train (Epoch 191): Loss/seq after 00050 batchs: 81887.5390625
INFO:root:Train (Epoch 191): Loss/seq after 00100 batchs: 72269.09375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 191): Loss/seq after 00000 batches: 47418.21484375
INFO:root:Artifacts: Make stick videos for epoch 191
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_191_on_20220413_143821.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_191_index_109_on_20220413_143821.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 192): Loss/seq after 00000 batchs: 86825.0703125
INFO:root:Train (Epoch 192): Loss/seq after 00050 batchs: 81888.765625
INFO:root:Train (Epoch 192): Loss/seq after 00100 batchs: 72269.2265625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 192): Loss/seq after 00000 batches: 47439.01171875
INFO:root:Artifacts: Make stick videos for epoch 192
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_192_on_20220413_143902.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_192_index_910_on_20220413_143902.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 193): Loss/seq after 00000 batchs: 86798.609375
INFO:root:Train (Epoch 193): Loss/seq after 00050 batchs: 81890.296875
INFO:root:Train (Epoch 193): Loss/seq after 00100 batchs: 72267.9296875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 193): Loss/seq after 00000 batches: 47411.078125
INFO:root:Artifacts: Make stick videos for epoch 193
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_193_on_20220413_143944.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_193_index_105_on_20220413_143944.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 194): Loss/seq after 00000 batchs: 86802.4453125
INFO:root:Train (Epoch 194): Loss/seq after 00050 batchs: 81888.7265625
INFO:root:Train (Epoch 194): Loss/seq after 00100 batchs: 72265.421875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 194): Loss/seq after 00000 batches: 47415.12890625
INFO:root:Artifacts: Make stick videos for epoch 194
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_194_on_20220413_144025.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_194_index_1198_on_20220413_144025.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 195): Loss/seq after 00000 batchs: 86789.5078125
INFO:root:Train (Epoch 195): Loss/seq after 00050 batchs: 81888.671875
INFO:root:Train (Epoch 195): Loss/seq after 00100 batchs: 72264.0859375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 195): Loss/seq after 00000 batches: 47431.6328125
INFO:root:Artifacts: Make stick videos for epoch 195
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_195_on_20220413_144106.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_195_index_1663_on_20220413_144106.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 196): Loss/seq after 00000 batchs: 86789.1640625
INFO:root:Train (Epoch 196): Loss/seq after 00050 batchs: 81887.390625
INFO:root:Train (Epoch 196): Loss/seq after 00100 batchs: 72262.8515625
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 196): Loss/seq after 00000 batches: 47428.859375
INFO:root:Artifacts: Make stick videos for epoch 196
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_196_on_20220413_144147.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_196_index_1643_on_20220413_144147.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 197): Loss/seq after 00000 batchs: 86792.59375
INFO:root:Train (Epoch 197): Loss/seq after 00050 batchs: 81889.53125
INFO:root:Train (Epoch 197): Loss/seq after 00100 batchs: 72262.171875
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 197): Loss/seq after 00000 batches: 47428.015625
INFO:root:Artifacts: Make stick videos for epoch 197
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_197_on_20220413_144228.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_197_index_1723_on_20220413_144228.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 198): Loss/seq after 00000 batchs: 86784.3359375
INFO:root:Train (Epoch 198): Loss/seq after 00050 batchs: 81888.578125
INFO:root:Train (Epoch 198): Loss/seq after 00100 batchs: 72259.6328125
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 198): Loss/seq after 00000 batches: 47413.12109375
INFO:root:Artifacts: Make stick videos for epoch 198
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_198_on_20220413_144309.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_198_index_84_on_20220413_144309.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:Train (Epoch 199): Loss/seq after 00000 batchs: 86782.4375
INFO:root:Train (Epoch 199): Loss/seq after 00050 batchs: 81889.015625
INFO:root:Train (Epoch 199): Loss/seq after 00100 batchs: 72259.0859375
INFO:root:Valid minibatch x of shape: torch.Size([256, 128, 159])
INFO:root:# Valid (Epoch 199): Loss/seq after 00000 batches: 47415.75
INFO:root:Artifacts: Make stick videos for epoch 199
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_199_on_20220413_144351.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_199_index_1885_on_20220413_144351.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Done training.

wandb: Waiting for W&B process to finish, PID 176530... (success).
wandb: - 317.56MB of 317.56MB uploaded (0.00MB deduped)wandb: \ 317.56MB of 317.56MB uploaded (0.00MB deduped)wandb: | 317.56MB of 317.65MB uploaded (0.00MB deduped)wandb: / 317.56MB of 317.84MB uploaded (0.00MB deduped)wandb: - 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb: \ 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb: | 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb: / 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb: - 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb: \ 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb: | 317.84MB of 317.84MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:        epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:         loss ▆█▅▂█▆▁█▆▁▆▁█▆▁█▆▁█▆█▆▁█▆▁█▆▁█▁█▆▁█▆▁█▆▁
wandb:   valid_loss ▁▆▃▃█████▇███▇▇▇▇█▇████▇▇▇██████████████
wandb: 
wandb: Run summary:
wandb:        epoch 199
wandb:         loss 72259.08594
wandb:   valid_loss 47415.75
wandb: 
wandb: Synced 6 W&B file(s), 0 media file(s), 400 artifact file(s) and 0 other file(s)
wandb: Synced lemon-sweep-3: https://wandb.ai/mathildepapillon/move-move/runs/7gysds1n
wandb: Find logs at: ./wandb/run-20220413_122403-7gysds1n/logs/debug.log
wandb: 

2022-04-13 14:44:13,863 - wandb.wandb_agent - INFO - Cleaning up finished run: 7gysds1n
2022-04-13 14:44:14,454 - wandb.wandb_agent - INFO - Agent received command: run
2022-04-13 14:44:14,454 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 8
	learning_rate: 1e-05
2022-04-13 14:44:14,473 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python main.py --batch_size=8 --learning_rate=1e-05
2022-04-13 14:44:19,486 - wandb.wandb_agent - INFO - Running runs: ['d5k0u3jz']
INFO:root:Using device cuda
wandb: Currently logged in as: mathildepapillon (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
TORCH
1.10.0+cu102
wandb: wandb version 0.12.14 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run smart-sweep-4
wandb: ⭐️ View project at https://wandb.ai/mathildepapillon/move-move
wandb: 🧹 View sweep at https://wandb.ai/mathildepapillon/move-move/sweeps/tld50t54
wandb: 🚀 View run at https://wandb.ai/mathildepapillon/move-move/runs/d5k0u3jz
wandb: Run data is saved locally in /home/papillon/move/move/wandb/run-20220413_144429-d5k0u3jz
wandb: Run `wandb offline` to turn off syncing.
INFO:root:Config: {config}
INFO:root:Run server specific commands
INFO:root:Initialize model
INFO:root:Loading raw datasets:
INFO:root:- data/mariel_betternot_and_retrograde.npy of shape (9925, 53, 3)
INFO:root:- data/mariel_beyond.npy of shape (5803, 53, 3)
INFO:root:- data/mariel_chunli.npy of shape (3866, 53, 3)
INFO:root:- data/mariel_honey.npy of shape (5309, 53, 3)
INFO:root:- data/mariel_knownbetter.npy of shape (6649, 53, 3)
INFO:root:- data/mariel_penelope.npy of shape (6757, 53, 3)
INFO:root:Preprocessing: Load seq_data of shape (38181, 128, 159)
INFO:root:>> Train ds has shape (34363, 128, 159)
INFO:root:>> Valid ds has shape (1909, 128, 159)
INFO:root:>> Test ds has shape (1909, 128, 159)
INFO:root:Preprocessing: Convert into torch dataloader
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 0): Loss/seq after 00000 batchs: 3882.910888671875
INFO:root:Train (Epoch 0): Loss/seq after 00050 batchs: 7517.974609375
INFO:root:Train (Epoch 0): Loss/seq after 00100 batchs: 6531.56787109375
INFO:root:Train (Epoch 0): Loss/seq after 00150 batchs: 6650.6376953125
INFO:root:Train (Epoch 0): Loss/seq after 00200 batchs: 5670.60693359375
INFO:root:Train (Epoch 0): Loss/seq after 00250 batchs: 5161.845703125
INFO:root:Train (Epoch 0): Loss/seq after 00300 batchs: 4600.13037109375
INFO:root:Train (Epoch 0): Loss/seq after 00350 batchs: 4116.2255859375
INFO:root:Train (Epoch 0): Loss/seq after 00400 batchs: 4089.0126953125
INFO:root:Train (Epoch 0): Loss/seq after 00450 batchs: 3803.66357421875
INFO:root:Train (Epoch 0): Loss/seq after 00500 batchs: 3701.640625
INFO:root:Train (Epoch 0): Loss/seq after 00550 batchs: 3489.560546875
INFO:root:Train (Epoch 0): Loss/seq after 00600 batchs: 3329.89208984375
INFO:root:Train (Epoch 0): Loss/seq after 00650 batchs: 3314.6767578125
INFO:root:Train (Epoch 0): Loss/seq after 00700 batchs: 3286.11572265625
INFO:root:Train (Epoch 0): Loss/seq after 00750 batchs: 3226.011962890625
INFO:root:Train (Epoch 0): Loss/seq after 00800 batchs: 3179.303955078125
INFO:root:Train (Epoch 0): Loss/seq after 00850 batchs: 3060.787841796875
INFO:root:Train (Epoch 0): Loss/seq after 00900 batchs: 3003.600830078125
INFO:root:Train (Epoch 0): Loss/seq after 00950 batchs: 3068.177490234375
INFO:root:Train (Epoch 0): Loss/seq after 01000 batchs: 3028.93115234375
INFO:root:Train (Epoch 0): Loss/seq after 01050 batchs: 2968.3583984375
INFO:root:Train (Epoch 0): Loss/seq after 01100 batchs: 2919.69384765625
INFO:root:Train (Epoch 0): Loss/seq after 01150 batchs: 2844.50634765625
INFO:root:Train (Epoch 0): Loss/seq after 01200 batchs: 2781.613525390625
INFO:root:Train (Epoch 0): Loss/seq after 01250 batchs: 2734.10791015625
INFO:root:Train (Epoch 0): Loss/seq after 01300 batchs: 2707.6171875
INFO:root:Train (Epoch 0): Loss/seq after 01350 batchs: 2670.107666015625
INFO:root:Train (Epoch 0): Loss/seq after 01400 batchs: 2689.103759765625
INFO:root:Train (Epoch 0): Loss/seq after 01450 batchs: 2648.818603515625
INFO:root:Train (Epoch 0): Loss/seq after 01500 batchs: 2602.458984375
INFO:root:Train (Epoch 0): Loss/seq after 01550 batchs: 2581.708251953125
INFO:root:Train (Epoch 0): Loss/seq after 01600 batchs: 2532.310302734375
INFO:root:Train (Epoch 0): Loss/seq after 01650 batchs: 2501.10888671875
INFO:root:Train (Epoch 0): Loss/seq after 01700 batchs: 2462.51220703125
INFO:root:Train (Epoch 0): Loss/seq after 01750 batchs: 2423.376220703125
INFO:root:Train (Epoch 0): Loss/seq after 01800 batchs: 2383.324462890625
INFO:root:Train (Epoch 0): Loss/seq after 01850 batchs: 2344.3720703125
INFO:root:Train (Epoch 0): Loss/seq after 01900 batchs: 2319.791015625
INFO:root:Train (Epoch 0): Loss/seq after 01950 batchs: 2291.71337890625
INFO:root:Train (Epoch 0): Loss/seq after 02000 batchs: 2260.72802734375
INFO:root:Train (Epoch 0): Loss/seq after 02050 batchs: 2231.743896484375
INFO:root:Train (Epoch 0): Loss/seq after 02100 batchs: 2200.76611328125
INFO:root:Train (Epoch 0): Loss/seq after 02150 batchs: 2171.71484375
INFO:root:Train (Epoch 0): Loss/seq after 02200 batchs: 2142.12451171875
INFO:root:Train (Epoch 0): Loss/seq after 02250 batchs: 2136.573486328125
INFO:root:Train (Epoch 0): Loss/seq after 02300 batchs: 2131.776611328125
INFO:root:Train (Epoch 0): Loss/seq after 02350 batchs: 2108.782470703125
INFO:root:Train (Epoch 0): Loss/seq after 02400 batchs: 2090.336669921875
INFO:root:Train (Epoch 0): Loss/seq after 02450 batchs: 2063.91845703125
INFO:root:Train (Epoch 0): Loss/seq after 02500 batchs: 2032.2642822265625
INFO:root:Train (Epoch 0): Loss/seq after 02550 batchs: 2010.9962158203125
INFO:root:Train (Epoch 0): Loss/seq after 02600 batchs: 1999.490966796875
INFO:root:Train (Epoch 0): Loss/seq after 02650 batchs: 1984.0394287109375
INFO:root:Train (Epoch 0): Loss/seq after 02700 batchs: 1972.5009765625
INFO:root:Train (Epoch 0): Loss/seq after 02750 batchs: 1993.96630859375
INFO:root:Train (Epoch 0): Loss/seq after 02800 batchs: 1996.25146484375
INFO:root:Train (Epoch 0): Loss/seq after 02850 batchs: 1987.4207763671875
INFO:root:Train (Epoch 0): Loss/seq after 02900 batchs: 1975.8035888671875
INFO:root:Train (Epoch 0): Loss/seq after 02950 batchs: 1958.8358154296875
INFO:root:Train (Epoch 0): Loss/seq after 03000 batchs: 1946.0543212890625
INFO:root:Train (Epoch 0): Loss/seq after 03050 batchs: 1938.4088134765625
INFO:root:Train (Epoch 0): Loss/seq after 03100 batchs: 1949.849853515625
INFO:root:Train (Epoch 0): Loss/seq after 03150 batchs: 1964.2802734375
INFO:root:Train (Epoch 0): Loss/seq after 03200 batchs: 1969.9595947265625
INFO:root:Train (Epoch 0): Loss/seq after 03250 batchs: 1974.3553466796875
INFO:root:Train (Epoch 0): Loss/seq after 03300 batchs: 1967.766845703125
INFO:root:Train (Epoch 0): Loss/seq after 03350 batchs: 1960.582763671875
INFO:root:Train (Epoch 0): Loss/seq after 03400 batchs: 1942.8070068359375
INFO:root:Train (Epoch 0): Loss/seq after 03450 batchs: 1930.5791015625
INFO:root:Train (Epoch 0): Loss/seq after 03500 batchs: 1927.4864501953125
INFO:root:Train (Epoch 0): Loss/seq after 03550 batchs: 1916.703125
INFO:root:Train (Epoch 0): Loss/seq after 03600 batchs: 1916.0482177734375
INFO:root:Train (Epoch 0): Loss/seq after 03650 batchs: 1905.4041748046875
INFO:root:Train (Epoch 0): Loss/seq after 03700 batchs: 1897.7047119140625
INFO:root:Train (Epoch 0): Loss/seq after 03750 batchs: 1889.939697265625
INFO:root:Train (Epoch 0): Loss/seq after 03800 batchs: 1875.6558837890625
INFO:root:Train (Epoch 0): Loss/seq after 03850 batchs: 1864.3612060546875
INFO:root:Train (Epoch 0): Loss/seq after 03900 batchs: 1872.845947265625
INFO:root:Train (Epoch 0): Loss/seq after 03950 batchs: 1876.2894287109375
INFO:root:Train (Epoch 0): Loss/seq after 04000 batchs: 1861.6444091796875
INFO:root:Train (Epoch 0): Loss/seq after 04050 batchs: 1846.86572265625
INFO:root:Train (Epoch 0): Loss/seq after 04100 batchs: 1837.594482421875
INFO:root:Train (Epoch 0): Loss/seq after 04150 batchs: 1826.2515869140625
INFO:root:Train (Epoch 0): Loss/seq after 04200 batchs: 1816.689453125
INFO:root:Train (Epoch 0): Loss/seq after 04250 batchs: 1806.6015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 0): Loss/seq after 00000 batches: 1094.367919921875
INFO:root:# Valid (Epoch 0): Loss/seq after 00050 batches: 1240.7271728515625
INFO:root:# Valid (Epoch 0): Loss/seq after 00100 batches: 1623.484375
INFO:root:# Valid (Epoch 0): Loss/seq after 00150 batches: 1340.6072998046875
INFO:root:# Valid (Epoch 0): Loss/seq after 00200 batches: 1211.062255859375
INFO:root:Artifacts: Make stick videos for epoch 0
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_0_on_20220413_144947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_0_index_1035_on_20220413_144947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 1): Loss/seq after 00000 batchs: 2530.439697265625
INFO:root:Train (Epoch 1): Loss/seq after 00050 batchs: 2024.2431640625
INFO:root:Train (Epoch 1): Loss/seq after 00100 batchs: 1916.2999267578125
INFO:root:Train (Epoch 1): Loss/seq after 00150 batchs: 1706.495361328125
INFO:root:Train (Epoch 1): Loss/seq after 00200 batchs: 1825.34033203125
INFO:root:Train (Epoch 1): Loss/seq after 00250 batchs: 1948.7078857421875
INFO:root:Train (Epoch 1): Loss/seq after 00300 batchs: 1840.64306640625
INFO:root:Train (Epoch 1): Loss/seq after 00350 batchs: 1718.31103515625
INFO:root:Train (Epoch 1): Loss/seq after 00400 batchs: 1792.1602783203125
INFO:root:Train (Epoch 1): Loss/seq after 00450 batchs: 1701.900146484375
INFO:root:Train (Epoch 1): Loss/seq after 00500 batchs: 1749.06591796875
INFO:root:Train (Epoch 1): Loss/seq after 00550 batchs: 1677.0458984375
INFO:root:Train (Epoch 1): Loss/seq after 00600 batchs: 1650.7218017578125
INFO:root:Train (Epoch 1): Loss/seq after 00650 batchs: 1706.0439453125
INFO:root:Train (Epoch 1): Loss/seq after 00700 batchs: 1782.365234375
INFO:root:Train (Epoch 1): Loss/seq after 00750 batchs: 1816.843994140625
INFO:root:Train (Epoch 1): Loss/seq after 00800 batchs: 1796.93603515625
INFO:root:Train (Epoch 1): Loss/seq after 00850 batchs: 1752.064208984375
INFO:root:Train (Epoch 1): Loss/seq after 00900 batchs: 1759.7894287109375
INFO:root:Train (Epoch 1): Loss/seq after 00950 batchs: 1857.9842529296875
INFO:root:Train (Epoch 1): Loss/seq after 01000 batchs: 1861.87744140625
INFO:root:Train (Epoch 1): Loss/seq after 01050 batchs: 1839.51953125
INFO:root:Train (Epoch 1): Loss/seq after 01100 batchs: 1826.867919921875
INFO:root:Train (Epoch 1): Loss/seq after 01150 batchs: 1796.8314208984375
INFO:root:Train (Epoch 1): Loss/seq after 01200 batchs: 1772.7659912109375
INFO:root:Train (Epoch 1): Loss/seq after 01250 batchs: 1763.7816162109375
INFO:root:Train (Epoch 1): Loss/seq after 01300 batchs: 1771.1292724609375
INFO:root:Train (Epoch 1): Loss/seq after 01350 batchs: 1765.1195068359375
INFO:root:Train (Epoch 1): Loss/seq after 01400 batchs: 1812.7928466796875
INFO:root:Train (Epoch 1): Loss/seq after 01450 batchs: 1792.2940673828125
INFO:root:Train (Epoch 1): Loss/seq after 01500 batchs: 1770.7120361328125
INFO:root:Train (Epoch 1): Loss/seq after 01550 batchs: 1773.9271240234375
INFO:root:Train (Epoch 1): Loss/seq after 01600 batchs: 1746.03955078125
INFO:root:Train (Epoch 1): Loss/seq after 01650 batchs: 1734.7900390625
INFO:root:Train (Epoch 1): Loss/seq after 01700 batchs: 1716.3052978515625
INFO:root:Train (Epoch 1): Loss/seq after 01750 batchs: 1695.633056640625
INFO:root:Train (Epoch 1): Loss/seq after 01800 batchs: 1673.34423828125
INFO:root:Train (Epoch 1): Loss/seq after 01850 batchs: 1651.2095947265625
INFO:root:Train (Epoch 1): Loss/seq after 01900 batchs: 1642.5401611328125
INFO:root:Train (Epoch 1): Loss/seq after 01950 batchs: 1630.0191650390625
INFO:root:Train (Epoch 1): Loss/seq after 02000 batchs: 1613.47705078125
INFO:root:Train (Epoch 1): Loss/seq after 02050 batchs: 1598.5999755859375
INFO:root:Train (Epoch 1): Loss/seq after 02100 batchs: 1580.822021484375
INFO:root:Train (Epoch 1): Loss/seq after 02150 batchs: 1564.5579833984375
INFO:root:Train (Epoch 1): Loss/seq after 02200 batchs: 1547.2313232421875
INFO:root:Train (Epoch 1): Loss/seq after 02250 batchs: 1551.927490234375
INFO:root:Train (Epoch 1): Loss/seq after 02300 batchs: 1553.663330078125
INFO:root:Train (Epoch 1): Loss/seq after 02350 batchs: 1540.597900390625
INFO:root:Train (Epoch 1): Loss/seq after 02400 batchs: 1532.373046875
INFO:root:Train (Epoch 1): Loss/seq after 02450 batchs: 1516.0438232421875
INFO:root:Train (Epoch 1): Loss/seq after 02500 batchs: 1493.9638671875
INFO:root:Train (Epoch 1): Loss/seq after 02550 batchs: 1482.335205078125
INFO:root:Train (Epoch 1): Loss/seq after 02600 batchs: 1478.9788818359375
INFO:root:Train (Epoch 1): Loss/seq after 02650 batchs: 1472.213134765625
INFO:root:Train (Epoch 1): Loss/seq after 02700 batchs: 1468.16650390625
INFO:root:Train (Epoch 1): Loss/seq after 02750 batchs: 1498.8131103515625
INFO:root:Train (Epoch 1): Loss/seq after 02800 batchs: 1507.5501708984375
INFO:root:Train (Epoch 1): Loss/seq after 02850 batchs: 1504.59912109375
INFO:root:Train (Epoch 1): Loss/seq after 02900 batchs: 1499.839111328125
INFO:root:Train (Epoch 1): Loss/seq after 02950 batchs: 1489.4322509765625
INFO:root:Train (Epoch 1): Loss/seq after 03000 batchs: 1483.4830322265625
INFO:root:Train (Epoch 1): Loss/seq after 03050 batchs: 1482.5035400390625
INFO:root:Train (Epoch 1): Loss/seq after 03100 batchs: 1499.939697265625
INFO:root:Train (Epoch 1): Loss/seq after 03150 batchs: 1520.7679443359375
INFO:root:Train (Epoch 1): Loss/seq after 03200 batchs: 1532.565673828125
INFO:root:Train (Epoch 1): Loss/seq after 03250 batchs: 1543.089599609375
INFO:root:Train (Epoch 1): Loss/seq after 03300 batchs: 1543.1990966796875
INFO:root:Train (Epoch 1): Loss/seq after 03350 batchs: 1541.230712890625
INFO:root:Train (Epoch 1): Loss/seq after 03400 batchs: 1528.7998046875
INFO:root:Train (Epoch 1): Loss/seq after 03450 batchs: 1520.335205078125
INFO:root:Train (Epoch 1): Loss/seq after 03500 batchs: 1518.3748779296875
INFO:root:Train (Epoch 1): Loss/seq after 03550 batchs: 1511.2249755859375
INFO:root:Train (Epoch 1): Loss/seq after 03600 batchs: 1514.91552734375
INFO:root:Train (Epoch 1): Loss/seq after 03650 batchs: 1509.390625
INFO:root:Train (Epoch 1): Loss/seq after 03700 batchs: 1506.2882080078125
INFO:root:Train (Epoch 1): Loss/seq after 03750 batchs: 1503.1124267578125
INFO:root:Train (Epoch 1): Loss/seq after 03800 batchs: 1493.2449951171875
INFO:root:Train (Epoch 1): Loss/seq after 03850 batchs: 1486.244384765625
INFO:root:Train (Epoch 1): Loss/seq after 03900 batchs: 1497.0838623046875
INFO:root:Train (Epoch 1): Loss/seq after 03950 batchs: 1504.988037109375
INFO:root:Train (Epoch 1): Loss/seq after 04000 batchs: 1493.351318359375
INFO:root:Train (Epoch 1): Loss/seq after 04050 batchs: 1482.4761962890625
INFO:root:Train (Epoch 1): Loss/seq after 04100 batchs: 1476.9940185546875
INFO:root:Train (Epoch 1): Loss/seq after 04150 batchs: 1469.4599609375
INFO:root:Train (Epoch 1): Loss/seq after 04200 batchs: 1463.644775390625
INFO:root:Train (Epoch 1): Loss/seq after 04250 batchs: 1457.260986328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 1): Loss/seq after 00000 batches: 1066.079833984375
INFO:root:# Valid (Epoch 1): Loss/seq after 00050 batches: 1197.4173583984375
INFO:root:# Valid (Epoch 1): Loss/seq after 00100 batches: 1575.65869140625
INFO:root:# Valid (Epoch 1): Loss/seq after 00150 batches: 1297.19189453125
INFO:root:# Valid (Epoch 1): Loss/seq after 00200 batches: 1168.3505859375
INFO:root:Artifacts: Make stick videos for epoch 1
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_1_on_20220413_145504.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_1_index_1864_on_20220413_145504.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 2): Loss/seq after 00000 batchs: 2454.417724609375
INFO:root:Train (Epoch 2): Loss/seq after 00050 batchs: 1923.6993408203125
INFO:root:Train (Epoch 2): Loss/seq after 00100 batchs: 1839.1197509765625
INFO:root:Train (Epoch 2): Loss/seq after 00150 batchs: 1647.6444091796875
INFO:root:Train (Epoch 2): Loss/seq after 00200 batchs: 1767.2005615234375
INFO:root:Train (Epoch 2): Loss/seq after 00250 batchs: 1888.0360107421875
INFO:root:Train (Epoch 2): Loss/seq after 00300 batchs: 1778.7847900390625
INFO:root:Train (Epoch 2): Loss/seq after 00350 batchs: 1659.8094482421875
INFO:root:Train (Epoch 2): Loss/seq after 00400 batchs: 1735.1976318359375
INFO:root:Train (Epoch 2): Loss/seq after 00450 batchs: 1646.0860595703125
INFO:root:Train (Epoch 2): Loss/seq after 00500 batchs: 1710.4493408203125
INFO:root:Train (Epoch 2): Loss/seq after 00550 batchs: 1638.2991943359375
INFO:root:Train (Epoch 2): Loss/seq after 00600 batchs: 1611.6053466796875
INFO:root:Train (Epoch 2): Loss/seq after 00650 batchs: 1667.9285888671875
INFO:root:Train (Epoch 2): Loss/seq after 00700 batchs: 1745.9945068359375
INFO:root:Train (Epoch 2): Loss/seq after 00750 batchs: 1780.5927734375
INFO:root:Train (Epoch 2): Loss/seq after 00800 batchs: 1761.53955078125
INFO:root:Train (Epoch 2): Loss/seq after 00850 batchs: 1716.89111328125
INFO:root:Train (Epoch 2): Loss/seq after 00900 batchs: 1728.0836181640625
INFO:root:Train (Epoch 2): Loss/seq after 00950 batchs: 1829.05615234375
INFO:root:Train (Epoch 2): Loss/seq after 01000 batchs: 1833.963623046875
INFO:root:Train (Epoch 2): Loss/seq after 01050 batchs: 1823.206298828125
INFO:root:Train (Epoch 2): Loss/seq after 01100 batchs: 1812.091552734375
INFO:root:Train (Epoch 2): Loss/seq after 01150 batchs: 1779.2171630859375
INFO:root:Train (Epoch 2): Loss/seq after 01200 batchs: 1755.9952392578125
INFO:root:Train (Epoch 2): Loss/seq after 01250 batchs: 1743.1544189453125
INFO:root:Train (Epoch 2): Loss/seq after 01300 batchs: 1748.6553955078125
INFO:root:Train (Epoch 2): Loss/seq after 01350 batchs: 1742.8232421875
INFO:root:Train (Epoch 2): Loss/seq after 01400 batchs: 1793.7874755859375
INFO:root:Train (Epoch 2): Loss/seq after 01450 batchs: 1776.103759765625
INFO:root:Train (Epoch 2): Loss/seq after 01500 batchs: 1754.342529296875
INFO:root:Train (Epoch 2): Loss/seq after 01550 batchs: 1753.972900390625
INFO:root:Train (Epoch 2): Loss/seq after 01600 batchs: 1726.2412109375
INFO:root:Train (Epoch 2): Loss/seq after 01650 batchs: 1715.1324462890625
INFO:root:Train (Epoch 2): Loss/seq after 01700 batchs: 1696.83251953125
INFO:root:Train (Epoch 2): Loss/seq after 01750 batchs: 1675.96875
INFO:root:Train (Epoch 2): Loss/seq after 01800 batchs: 1653.60498046875
INFO:root:Train (Epoch 2): Loss/seq after 01850 batchs: 1631.2662353515625
INFO:root:Train (Epoch 2): Loss/seq after 01900 batchs: 1622.37060546875
INFO:root:Train (Epoch 2): Loss/seq after 01950 batchs: 1609.764892578125
INFO:root:Train (Epoch 2): Loss/seq after 02000 batchs: 1593.0535888671875
INFO:root:Train (Epoch 2): Loss/seq after 02050 batchs: 1578.119384765625
INFO:root:Train (Epoch 2): Loss/seq after 02100 batchs: 1560.197998046875
INFO:root:Train (Epoch 2): Loss/seq after 02150 batchs: 1543.88330078125
INFO:root:Train (Epoch 2): Loss/seq after 02200 batchs: 1526.5162353515625
INFO:root:Train (Epoch 2): Loss/seq after 02250 batchs: 1531.0068359375
INFO:root:Train (Epoch 2): Loss/seq after 02300 batchs: 1531.9361572265625
INFO:root:Train (Epoch 2): Loss/seq after 02350 batchs: 1518.7215576171875
INFO:root:Train (Epoch 2): Loss/seq after 02400 batchs: 1510.3995361328125
INFO:root:Train (Epoch 2): Loss/seq after 02450 batchs: 1494.0560302734375
INFO:root:Train (Epoch 2): Loss/seq after 02500 batchs: 1471.974609375
INFO:root:Train (Epoch 2): Loss/seq after 02550 batchs: 1461.093505859375
INFO:root:Train (Epoch 2): Loss/seq after 02600 batchs: 1458.00244140625
INFO:root:Train (Epoch 2): Loss/seq after 02650 batchs: 1451.2880859375
INFO:root:Train (Epoch 2): Loss/seq after 02700 batchs: 1447.5819091796875
INFO:root:Train (Epoch 2): Loss/seq after 02750 batchs: 1478.4197998046875
INFO:root:Train (Epoch 2): Loss/seq after 02800 batchs: 1487.6602783203125
INFO:root:Train (Epoch 2): Loss/seq after 02850 batchs: 1485.321533203125
INFO:root:Train (Epoch 2): Loss/seq after 02900 batchs: 1483.196044921875
INFO:root:Train (Epoch 2): Loss/seq after 02950 batchs: 1473.69140625
INFO:root:Train (Epoch 2): Loss/seq after 03000 batchs: 1467.8314208984375
INFO:root:Train (Epoch 2): Loss/seq after 03050 batchs: 1466.68115234375
INFO:root:Train (Epoch 2): Loss/seq after 03100 batchs: 1487.8157958984375
INFO:root:Train (Epoch 2): Loss/seq after 03150 batchs: 1509.4447021484375
INFO:root:Train (Epoch 2): Loss/seq after 03200 batchs: 1521.3846435546875
INFO:root:Train (Epoch 2): Loss/seq after 03250 batchs: 1532.41357421875
INFO:root:Train (Epoch 2): Loss/seq after 03300 batchs: 1532.5191650390625
INFO:root:Train (Epoch 2): Loss/seq after 03350 batchs: 1530.2904052734375
INFO:root:Train (Epoch 2): Loss/seq after 03400 batchs: 1517.6973876953125
INFO:root:Train (Epoch 2): Loss/seq after 03450 batchs: 1508.82421875
INFO:root:Train (Epoch 2): Loss/seq after 03500 batchs: 1507.701904296875
INFO:root:Train (Epoch 2): Loss/seq after 03550 batchs: 1500.2506103515625
INFO:root:Train (Epoch 2): Loss/seq after 03600 batchs: 1503.4268798828125
INFO:root:Train (Epoch 2): Loss/seq after 03650 batchs: 1496.77392578125
INFO:root:Train (Epoch 2): Loss/seq after 03700 batchs: 1493.7513427734375
INFO:root:Train (Epoch 2): Loss/seq after 03750 batchs: 1490.426513671875
INFO:root:Train (Epoch 2): Loss/seq after 03800 batchs: 1480.5413818359375
INFO:root:Train (Epoch 2): Loss/seq after 03850 batchs: 1473.371337890625
INFO:root:Train (Epoch 2): Loss/seq after 03900 batchs: 1484.43017578125
INFO:root:Train (Epoch 2): Loss/seq after 03950 batchs: 1491.2860107421875
INFO:root:Train (Epoch 2): Loss/seq after 04000 batchs: 1479.3212890625
INFO:root:Train (Epoch 2): Loss/seq after 04050 batchs: 1468.3729248046875
INFO:root:Train (Epoch 2): Loss/seq after 04100 batchs: 1462.81884765625
INFO:root:Train (Epoch 2): Loss/seq after 04150 batchs: 1455.2254638671875
INFO:root:Train (Epoch 2): Loss/seq after 04200 batchs: 1449.31787109375
INFO:root:Train (Epoch 2): Loss/seq after 04250 batchs: 1442.8118896484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 2): Loss/seq after 00000 batches: 1052.05078125
INFO:root:# Valid (Epoch 2): Loss/seq after 00050 batches: 1177.336181640625
INFO:root:# Valid (Epoch 2): Loss/seq after 00100 batches: 1535.7418212890625
INFO:root:# Valid (Epoch 2): Loss/seq after 00150 batches: 1263.2242431640625
INFO:root:# Valid (Epoch 2): Loss/seq after 00200 batches: 1138.1959228515625
INFO:root:Artifacts: Make stick videos for epoch 2
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_2_on_20220413_150020.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_2_index_1562_on_20220413_150020.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 3): Loss/seq after 00000 batchs: 2397.567626953125
INFO:root:Train (Epoch 3): Loss/seq after 00050 batchs: 1865.2142333984375
INFO:root:Train (Epoch 3): Loss/seq after 00100 batchs: 1827.8199462890625
INFO:root:Train (Epoch 3): Loss/seq after 00150 batchs: 1636.1463623046875
INFO:root:Train (Epoch 3): Loss/seq after 00200 batchs: 1754.4969482421875
INFO:root:Train (Epoch 3): Loss/seq after 00250 batchs: 1866.8900146484375
INFO:root:Train (Epoch 3): Loss/seq after 00300 batchs: 1755.9185791015625
INFO:root:Train (Epoch 3): Loss/seq after 00350 batchs: 1637.796630859375
INFO:root:Train (Epoch 3): Loss/seq after 00400 batchs: 1718.4749755859375
INFO:root:Train (Epoch 3): Loss/seq after 00450 batchs: 1629.3106689453125
INFO:root:Train (Epoch 3): Loss/seq after 00500 batchs: 1671.9736328125
INFO:root:Train (Epoch 3): Loss/seq after 00550 batchs: 1601.3492431640625
INFO:root:Train (Epoch 3): Loss/seq after 00600 batchs: 1566.00830078125
INFO:root:Train (Epoch 3): Loss/seq after 00650 batchs: 1626.3143310546875
INFO:root:Train (Epoch 3): Loss/seq after 00700 batchs: 1706.7734375
INFO:root:Train (Epoch 3): Loss/seq after 00750 batchs: 1744.031494140625
INFO:root:Train (Epoch 3): Loss/seq after 00800 batchs: 1723.064453125
INFO:root:Train (Epoch 3): Loss/seq after 00850 batchs: 1680.0587158203125
INFO:root:Train (Epoch 3): Loss/seq after 00900 batchs: 1685.1893310546875
INFO:root:Train (Epoch 3): Loss/seq after 00950 batchs: 1786.6883544921875
INFO:root:Train (Epoch 3): Loss/seq after 01000 batchs: 1785.255126953125
INFO:root:Train (Epoch 3): Loss/seq after 01050 batchs: 1762.1695556640625
INFO:root:Train (Epoch 3): Loss/seq after 01100 batchs: 1752.6864013671875
INFO:root:Train (Epoch 3): Loss/seq after 01150 batchs: 1721.6541748046875
INFO:root:Train (Epoch 3): Loss/seq after 01200 batchs: 1699.317626953125
INFO:root:Train (Epoch 3): Loss/seq after 01250 batchs: 1687.026123046875
INFO:root:Train (Epoch 3): Loss/seq after 01300 batchs: 1695.032470703125
INFO:root:Train (Epoch 3): Loss/seq after 01350 batchs: 1690.889892578125
INFO:root:Train (Epoch 3): Loss/seq after 01400 batchs: 1741.6171875
INFO:root:Train (Epoch 3): Loss/seq after 01450 batchs: 1721.0103759765625
INFO:root:Train (Epoch 3): Loss/seq after 01500 batchs: 1700.144775390625
INFO:root:Train (Epoch 3): Loss/seq after 01550 batchs: 1697.1842041015625
INFO:root:Train (Epoch 3): Loss/seq after 01600 batchs: 1670.608642578125
INFO:root:Train (Epoch 3): Loss/seq after 01650 batchs: 1658.3994140625
INFO:root:Train (Epoch 3): Loss/seq after 01700 batchs: 1641.2459716796875
INFO:root:Train (Epoch 3): Loss/seq after 01750 batchs: 1621.4383544921875
INFO:root:Train (Epoch 3): Loss/seq after 01800 batchs: 1600.0462646484375
INFO:root:Train (Epoch 3): Loss/seq after 01850 batchs: 1578.7735595703125
INFO:root:Train (Epoch 3): Loss/seq after 01900 batchs: 1570.9110107421875
INFO:root:Train (Epoch 3): Loss/seq after 01950 batchs: 1559.374755859375
INFO:root:Train (Epoch 3): Loss/seq after 02000 batchs: 1543.6029052734375
INFO:root:Train (Epoch 3): Loss/seq after 02050 batchs: 1529.59130859375
INFO:root:Train (Epoch 3): Loss/seq after 02100 batchs: 1512.553466796875
INFO:root:Train (Epoch 3): Loss/seq after 02150 batchs: 1497.088623046875
INFO:root:Train (Epoch 3): Loss/seq after 02200 batchs: 1480.5185546875
INFO:root:Train (Epoch 3): Loss/seq after 02250 batchs: 1484.295654296875
INFO:root:Train (Epoch 3): Loss/seq after 02300 batchs: 1486.4576416015625
INFO:root:Train (Epoch 3): Loss/seq after 02350 batchs: 1474.2061767578125
INFO:root:Train (Epoch 3): Loss/seq after 02400 batchs: 1466.5784912109375
INFO:root:Train (Epoch 3): Loss/seq after 02450 batchs: 1450.9407958984375
INFO:root:Train (Epoch 3): Loss/seq after 02500 batchs: 1429.5357666015625
INFO:root:Train (Epoch 3): Loss/seq after 02550 batchs: 1417.4132080078125
INFO:root:Train (Epoch 3): Loss/seq after 02600 batchs: 1414.7559814453125
INFO:root:Train (Epoch 3): Loss/seq after 02650 batchs: 1407.8623046875
INFO:root:Train (Epoch 3): Loss/seq after 02700 batchs: 1403.4000244140625
INFO:root:Train (Epoch 3): Loss/seq after 02750 batchs: 1433.8681640625
INFO:root:Train (Epoch 3): Loss/seq after 02800 batchs: 1443.34375
INFO:root:Train (Epoch 3): Loss/seq after 02850 batchs: 1440.6607666015625
INFO:root:Train (Epoch 3): Loss/seq after 02900 batchs: 1438.767333984375
INFO:root:Train (Epoch 3): Loss/seq after 02950 batchs: 1429.3118896484375
INFO:root:Train (Epoch 3): Loss/seq after 03000 batchs: 1423.9522705078125
INFO:root:Train (Epoch 3): Loss/seq after 03050 batchs: 1423.4088134765625
INFO:root:Train (Epoch 3): Loss/seq after 03100 batchs: 1439.79345703125
INFO:root:Train (Epoch 3): Loss/seq after 03150 batchs: 1461.62890625
INFO:root:Train (Epoch 3): Loss/seq after 03200 batchs: 1473.8250732421875
INFO:root:Train (Epoch 3): Loss/seq after 03250 batchs: 1485.169189453125
INFO:root:Train (Epoch 3): Loss/seq after 03300 batchs: 1483.9776611328125
INFO:root:Train (Epoch 3): Loss/seq after 03350 batchs: 1482.57763671875
INFO:root:Train (Epoch 3): Loss/seq after 03400 batchs: 1470.7509765625
INFO:root:Train (Epoch 3): Loss/seq after 03450 batchs: 1462.797119140625
INFO:root:Train (Epoch 3): Loss/seq after 03500 batchs: 1462.7110595703125
INFO:root:Train (Epoch 3): Loss/seq after 03550 batchs: 1456.3043212890625
INFO:root:Train (Epoch 3): Loss/seq after 03600 batchs: 1460.5196533203125
INFO:root:Train (Epoch 3): Loss/seq after 03650 batchs: 1454.560791015625
INFO:root:Train (Epoch 3): Loss/seq after 03700 batchs: 1452.6654052734375
INFO:root:Train (Epoch 3): Loss/seq after 03750 batchs: 1449.8609619140625
INFO:root:Train (Epoch 3): Loss/seq after 03800 batchs: 1440.4945068359375
INFO:root:Train (Epoch 3): Loss/seq after 03850 batchs: 1433.89892578125
INFO:root:Train (Epoch 3): Loss/seq after 03900 batchs: 1441.2452392578125
INFO:root:Train (Epoch 3): Loss/seq after 03950 batchs: 1449.2508544921875
INFO:root:Train (Epoch 3): Loss/seq after 04000 batchs: 1437.769775390625
INFO:root:Train (Epoch 3): Loss/seq after 04050 batchs: 1427.2117919921875
INFO:root:Train (Epoch 3): Loss/seq after 04100 batchs: 1422.0029296875
INFO:root:Train (Epoch 3): Loss/seq after 04150 batchs: 1414.78564453125
INFO:root:Train (Epoch 3): Loss/seq after 04200 batchs: 1408.8016357421875
INFO:root:Train (Epoch 3): Loss/seq after 04250 batchs: 1402.7269287109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 3): Loss/seq after 00000 batches: 1028.998291015625
INFO:root:# Valid (Epoch 3): Loss/seq after 00050 batches: 1161.9566650390625
INFO:root:# Valid (Epoch 3): Loss/seq after 00100 batches: 1512.3408203125
INFO:root:# Valid (Epoch 3): Loss/seq after 00150 batches: 1246.07421875
INFO:root:# Valid (Epoch 3): Loss/seq after 00200 batches: 1123.6146240234375
INFO:root:Artifacts: Make stick videos for epoch 3
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_3_on_20220413_150535.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_3_index_1810_on_20220413_150535.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 4): Loss/seq after 00000 batchs: 2355.894287109375
INFO:root:Train (Epoch 4): Loss/seq after 00050 batchs: 1870.8314208984375
INFO:root:Train (Epoch 4): Loss/seq after 00100 batchs: 1829.819580078125
INFO:root:Train (Epoch 4): Loss/seq after 00150 batchs: 1609.837890625
INFO:root:Train (Epoch 4): Loss/seq after 00200 batchs: 1778.10888671875
INFO:root:Train (Epoch 4): Loss/seq after 00250 batchs: 1982.4383544921875
INFO:root:Train (Epoch 4): Loss/seq after 00300 batchs: 1872.1839599609375
INFO:root:Train (Epoch 4): Loss/seq after 00350 batchs: 1737.44921875
INFO:root:Train (Epoch 4): Loss/seq after 00400 batchs: 1828.91796875
INFO:root:Train (Epoch 4): Loss/seq after 00450 batchs: 1731.8997802734375
INFO:root:Train (Epoch 4): Loss/seq after 00500 batchs: 1778.6689453125
INFO:root:Train (Epoch 4): Loss/seq after 00550 batchs: 1702.6365966796875
INFO:root:Train (Epoch 4): Loss/seq after 00600 batchs: 1665.7008056640625
INFO:root:Train (Epoch 4): Loss/seq after 00650 batchs: 1715.3828125
INFO:root:Train (Epoch 4): Loss/seq after 00700 batchs: 1787.0675048828125
INFO:root:Train (Epoch 4): Loss/seq after 00750 batchs: 1815.0943603515625
INFO:root:Train (Epoch 4): Loss/seq after 00800 batchs: 1790.62109375
INFO:root:Train (Epoch 4): Loss/seq after 00850 batchs: 1742.8056640625
INFO:root:Train (Epoch 4): Loss/seq after 00900 batchs: 1741.2857666015625
INFO:root:Train (Epoch 4): Loss/seq after 00950 batchs: 1829.2659912109375
INFO:root:Train (Epoch 4): Loss/seq after 01000 batchs: 1825.9718017578125
INFO:root:Train (Epoch 4): Loss/seq after 01050 batchs: 1803.4437255859375
INFO:root:Train (Epoch 4): Loss/seq after 01100 batchs: 1779.881591796875
INFO:root:Train (Epoch 4): Loss/seq after 01150 batchs: 1748.1273193359375
INFO:root:Train (Epoch 4): Loss/seq after 01200 batchs: 1725.779052734375
INFO:root:Train (Epoch 4): Loss/seq after 01250 batchs: 1711.5072021484375
INFO:root:Train (Epoch 4): Loss/seq after 01300 batchs: 1717.90966796875
INFO:root:Train (Epoch 4): Loss/seq after 01350 batchs: 1712.85546875
INFO:root:Train (Epoch 4): Loss/seq after 01400 batchs: 1760.566162109375
INFO:root:Train (Epoch 4): Loss/seq after 01450 batchs: 1740.1658935546875
INFO:root:Train (Epoch 4): Loss/seq after 01500 batchs: 1718.333984375
INFO:root:Train (Epoch 4): Loss/seq after 01550 batchs: 1712.854248046875
INFO:root:Train (Epoch 4): Loss/seq after 01600 batchs: 1686.05859375
INFO:root:Train (Epoch 4): Loss/seq after 01650 batchs: 1674.743896484375
INFO:root:Train (Epoch 4): Loss/seq after 01700 batchs: 1657.05615234375
INFO:root:Train (Epoch 4): Loss/seq after 01750 batchs: 1636.4249267578125
INFO:root:Train (Epoch 4): Loss/seq after 01800 batchs: 1614.4608154296875
INFO:root:Train (Epoch 4): Loss/seq after 01850 batchs: 1592.58984375
INFO:root:Train (Epoch 4): Loss/seq after 01900 batchs: 1584.12646484375
INFO:root:Train (Epoch 4): Loss/seq after 01950 batchs: 1572.09033203125
INFO:root:Train (Epoch 4): Loss/seq after 02000 batchs: 1555.806640625
INFO:root:Train (Epoch 4): Loss/seq after 02050 batchs: 1541.34521484375
INFO:root:Train (Epoch 4): Loss/seq after 02100 batchs: 1523.8447265625
INFO:root:Train (Epoch 4): Loss/seq after 02150 batchs: 1507.9539794921875
INFO:root:Train (Epoch 4): Loss/seq after 02200 batchs: 1491.0059814453125
INFO:root:Train (Epoch 4): Loss/seq after 02250 batchs: 1495.8951416015625
INFO:root:Train (Epoch 4): Loss/seq after 02300 batchs: 1499.1187744140625
INFO:root:Train (Epoch 4): Loss/seq after 02350 batchs: 1486.424560546875
INFO:root:Train (Epoch 4): Loss/seq after 02400 batchs: 1478.5064697265625
INFO:root:Train (Epoch 4): Loss/seq after 02450 batchs: 1462.537353515625
INFO:root:Train (Epoch 4): Loss/seq after 02500 batchs: 1440.85791015625
INFO:root:Train (Epoch 4): Loss/seq after 02550 batchs: 1430.2630615234375
INFO:root:Train (Epoch 4): Loss/seq after 02600 batchs: 1427.56884765625
INFO:root:Train (Epoch 4): Loss/seq after 02650 batchs: 1421.0980224609375
INFO:root:Train (Epoch 4): Loss/seq after 02700 batchs: 1416.85791015625
INFO:root:Train (Epoch 4): Loss/seq after 02750 batchs: 1446.67919921875
INFO:root:Train (Epoch 4): Loss/seq after 02800 batchs: 1456.4659423828125
INFO:root:Train (Epoch 4): Loss/seq after 02850 batchs: 1453.2664794921875
INFO:root:Train (Epoch 4): Loss/seq after 02900 batchs: 1451.4498291015625
INFO:root:Train (Epoch 4): Loss/seq after 02950 batchs: 1441.6300048828125
INFO:root:Train (Epoch 4): Loss/seq after 03000 batchs: 1436.0152587890625
INFO:root:Train (Epoch 4): Loss/seq after 03050 batchs: 1435.186767578125
INFO:root:Train (Epoch 4): Loss/seq after 03100 batchs: 1454.4359130859375
INFO:root:Train (Epoch 4): Loss/seq after 03150 batchs: 1474.044189453125
INFO:root:Train (Epoch 4): Loss/seq after 03200 batchs: 1486.2701416015625
INFO:root:Train (Epoch 4): Loss/seq after 03250 batchs: 1496.9742431640625
INFO:root:Train (Epoch 4): Loss/seq after 03300 batchs: 1495.6595458984375
INFO:root:Train (Epoch 4): Loss/seq after 03350 batchs: 1494.3780517578125
INFO:root:Train (Epoch 4): Loss/seq after 03400 batchs: 1482.1578369140625
INFO:root:Train (Epoch 4): Loss/seq after 03450 batchs: 1474.3057861328125
INFO:root:Train (Epoch 4): Loss/seq after 03500 batchs: 1472.7056884765625
INFO:root:Train (Epoch 4): Loss/seq after 03550 batchs: 1465.3779296875
INFO:root:Train (Epoch 4): Loss/seq after 03600 batchs: 1468.4996337890625
INFO:root:Train (Epoch 4): Loss/seq after 03650 batchs: 1461.8436279296875
INFO:root:Train (Epoch 4): Loss/seq after 03700 batchs: 1458.6058349609375
INFO:root:Train (Epoch 4): Loss/seq after 03750 batchs: 1455.650634765625
INFO:root:Train (Epoch 4): Loss/seq after 03800 batchs: 1446.024658203125
INFO:root:Train (Epoch 4): Loss/seq after 03850 batchs: 1439.0540771484375
INFO:root:Train (Epoch 4): Loss/seq after 03900 batchs: 1445.9090576171875
INFO:root:Train (Epoch 4): Loss/seq after 03950 batchs: 1455.5067138671875
INFO:root:Train (Epoch 4): Loss/seq after 04000 batchs: 1443.8204345703125
INFO:root:Train (Epoch 4): Loss/seq after 04050 batchs: 1433.1453857421875
INFO:root:Train (Epoch 4): Loss/seq after 04100 batchs: 1427.658935546875
INFO:root:Train (Epoch 4): Loss/seq after 04150 batchs: 1420.3134765625
INFO:root:Train (Epoch 4): Loss/seq after 04200 batchs: 1413.5106201171875
INFO:root:Train (Epoch 4): Loss/seq after 04250 batchs: 1407.1121826171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 4): Loss/seq after 00000 batches: 983.5863647460938
INFO:root:# Valid (Epoch 4): Loss/seq after 00050 batches: 1142.2325439453125
INFO:root:# Valid (Epoch 4): Loss/seq after 00100 batches: 1479.8890380859375
INFO:root:# Valid (Epoch 4): Loss/seq after 00150 batches: 1226.93408203125
INFO:root:# Valid (Epoch 4): Loss/seq after 00200 batches: 1111.2825927734375
INFO:root:Artifacts: Make stick videos for epoch 4
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_4_on_20220413_151052.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_4_index_1437_on_20220413_151052.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 5): Loss/seq after 00000 batchs: 2462.65380859375
INFO:root:Train (Epoch 5): Loss/seq after 00050 batchs: 1834.46484375
INFO:root:Train (Epoch 5): Loss/seq after 00100 batchs: 1827.2303466796875
INFO:root:Train (Epoch 5): Loss/seq after 00150 batchs: 1637.8785400390625
INFO:root:Train (Epoch 5): Loss/seq after 00200 batchs: 1750.4871826171875
INFO:root:Train (Epoch 5): Loss/seq after 00250 batchs: 1851.8040771484375
INFO:root:Train (Epoch 5): Loss/seq after 00300 batchs: 1733.44580078125
INFO:root:Train (Epoch 5): Loss/seq after 00350 batchs: 1615.04931640625
INFO:root:Train (Epoch 5): Loss/seq after 00400 batchs: 1679.578125
INFO:root:Train (Epoch 5): Loss/seq after 00450 batchs: 1591.9410400390625
INFO:root:Train (Epoch 5): Loss/seq after 00500 batchs: 1630.3466796875
INFO:root:Train (Epoch 5): Loss/seq after 00550 batchs: 1562.082763671875
INFO:root:Train (Epoch 5): Loss/seq after 00600 batchs: 1525.51806640625
INFO:root:Train (Epoch 5): Loss/seq after 00650 batchs: 1585.3228759765625
INFO:root:Train (Epoch 5): Loss/seq after 00700 batchs: 1666.01123046875
INFO:root:Train (Epoch 5): Loss/seq after 00750 batchs: 1701.087158203125
INFO:root:Train (Epoch 5): Loss/seq after 00800 batchs: 1683.2017822265625
INFO:root:Train (Epoch 5): Loss/seq after 00850 batchs: 1642.0103759765625
INFO:root:Train (Epoch 5): Loss/seq after 00900 batchs: 1639.7352294921875
INFO:root:Train (Epoch 5): Loss/seq after 00950 batchs: 1734.9119873046875
INFO:root:Train (Epoch 5): Loss/seq after 01000 batchs: 1736.9132080078125
INFO:root:Train (Epoch 5): Loss/seq after 01050 batchs: 1713.6151123046875
INFO:root:Train (Epoch 5): Loss/seq after 01100 batchs: 1701.8477783203125
INFO:root:Train (Epoch 5): Loss/seq after 01150 batchs: 1672.318115234375
INFO:root:Train (Epoch 5): Loss/seq after 01200 batchs: 1651.1651611328125
INFO:root:Train (Epoch 5): Loss/seq after 01250 batchs: 1638.0667724609375
INFO:root:Train (Epoch 5): Loss/seq after 01300 batchs: 1647.61376953125
INFO:root:Train (Epoch 5): Loss/seq after 01350 batchs: 1645.0023193359375
INFO:root:Train (Epoch 5): Loss/seq after 01400 batchs: 1696.5838623046875
INFO:root:Train (Epoch 5): Loss/seq after 01450 batchs: 1676.1068115234375
INFO:root:Train (Epoch 5): Loss/seq after 01500 batchs: 1656.5118408203125
INFO:root:Train (Epoch 5): Loss/seq after 01550 batchs: 1651.6026611328125
INFO:root:Train (Epoch 5): Loss/seq after 01600 batchs: 1626.092041015625
INFO:root:Train (Epoch 5): Loss/seq after 01650 batchs: 1614.17236328125
INFO:root:Train (Epoch 5): Loss/seq after 01700 batchs: 1597.764404296875
INFO:root:Train (Epoch 5): Loss/seq after 01750 batchs: 1578.5693359375
INFO:root:Train (Epoch 5): Loss/seq after 01800 batchs: 1557.9820556640625
INFO:root:Train (Epoch 5): Loss/seq after 01850 batchs: 1537.513916015625
INFO:root:Train (Epoch 5): Loss/seq after 01900 batchs: 1530.3353271484375
INFO:root:Train (Epoch 5): Loss/seq after 01950 batchs: 1519.584716796875
INFO:root:Train (Epoch 5): Loss/seq after 02000 batchs: 1504.45458984375
INFO:root:Train (Epoch 5): Loss/seq after 02050 batchs: 1491.1722412109375
INFO:root:Train (Epoch 5): Loss/seq after 02100 batchs: 1474.7222900390625
INFO:root:Train (Epoch 5): Loss/seq after 02150 batchs: 1459.7735595703125
INFO:root:Train (Epoch 5): Loss/seq after 02200 batchs: 1443.726318359375
INFO:root:Train (Epoch 5): Loss/seq after 02250 batchs: 1446.4140625
INFO:root:Train (Epoch 5): Loss/seq after 02300 batchs: 1450.0555419921875
INFO:root:Train (Epoch 5): Loss/seq after 02350 batchs: 1438.798828125
INFO:root:Train (Epoch 5): Loss/seq after 02400 batchs: 1431.7523193359375
INFO:root:Train (Epoch 5): Loss/seq after 02450 batchs: 1416.6812744140625
INFO:root:Train (Epoch 5): Loss/seq after 02500 batchs: 1395.8193359375
INFO:root:Train (Epoch 5): Loss/seq after 02550 batchs: 1386.275390625
INFO:root:Train (Epoch 5): Loss/seq after 02600 batchs: 1384.6180419921875
INFO:root:Train (Epoch 5): Loss/seq after 02650 batchs: 1378.841796875
INFO:root:Train (Epoch 5): Loss/seq after 02700 batchs: 1373.709228515625
INFO:root:Train (Epoch 5): Loss/seq after 02750 batchs: 1402.953125
INFO:root:Train (Epoch 5): Loss/seq after 02800 batchs: 1411.833984375
INFO:root:Train (Epoch 5): Loss/seq after 02850 batchs: 1407.64892578125
INFO:root:Train (Epoch 5): Loss/seq after 02900 batchs: 1403.6273193359375
INFO:root:Train (Epoch 5): Loss/seq after 02950 batchs: 1393.7047119140625
INFO:root:Train (Epoch 5): Loss/seq after 03000 batchs: 1388.692138671875
INFO:root:Train (Epoch 5): Loss/seq after 03050 batchs: 1388.61474609375
INFO:root:Train (Epoch 5): Loss/seq after 03100 batchs: 1406.3006591796875
INFO:root:Train (Epoch 5): Loss/seq after 03150 batchs: 1424.946533203125
INFO:root:Train (Epoch 5): Loss/seq after 03200 batchs: 1437.11279296875
INFO:root:Train (Epoch 5): Loss/seq after 03250 batchs: 1448.6085205078125
INFO:root:Train (Epoch 5): Loss/seq after 03300 batchs: 1445.84814453125
INFO:root:Train (Epoch 5): Loss/seq after 03350 batchs: 1443.7877197265625
INFO:root:Train (Epoch 5): Loss/seq after 03400 batchs: 1432.310302734375
INFO:root:Train (Epoch 5): Loss/seq after 03450 batchs: 1426.3131103515625
INFO:root:Train (Epoch 5): Loss/seq after 03500 batchs: 1426.5166015625
INFO:root:Train (Epoch 5): Loss/seq after 03550 batchs: 1420.5877685546875
INFO:root:Train (Epoch 5): Loss/seq after 03600 batchs: 1425.237060546875
INFO:root:Train (Epoch 5): Loss/seq after 03650 batchs: 1420.0533447265625
INFO:root:Train (Epoch 5): Loss/seq after 03700 batchs: 1417.9765625
INFO:root:Train (Epoch 5): Loss/seq after 03750 batchs: 1415.5196533203125
INFO:root:Train (Epoch 5): Loss/seq after 03800 batchs: 1406.4774169921875
INFO:root:Train (Epoch 5): Loss/seq after 03850 batchs: 1400.2115478515625
INFO:root:Train (Epoch 5): Loss/seq after 03900 batchs: 1407.0584716796875
INFO:root:Train (Epoch 5): Loss/seq after 03950 batchs: 1414.78955078125
INFO:root:Train (Epoch 5): Loss/seq after 04000 batchs: 1403.595947265625
INFO:root:Train (Epoch 5): Loss/seq after 04050 batchs: 1393.381591796875
INFO:root:Train (Epoch 5): Loss/seq after 04100 batchs: 1388.4512939453125
INFO:root:Train (Epoch 5): Loss/seq after 04150 batchs: 1381.5135498046875
INFO:root:Train (Epoch 5): Loss/seq after 04200 batchs: 1375.9893798828125
INFO:root:Train (Epoch 5): Loss/seq after 04250 batchs: 1370.22119140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 5): Loss/seq after 00000 batches: 991.9613647460938
INFO:root:# Valid (Epoch 5): Loss/seq after 00050 batches: 1143.2503662109375
INFO:root:# Valid (Epoch 5): Loss/seq after 00100 batches: 1487.3507080078125
INFO:root:# Valid (Epoch 5): Loss/seq after 00150 batches: 1231.0799560546875
INFO:root:# Valid (Epoch 5): Loss/seq after 00200 batches: 1112.814453125
INFO:root:Artifacts: Make stick videos for epoch 5
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_5_on_20220413_151609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_5_index_1549_on_20220413_151609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 6): Loss/seq after 00000 batchs: 2478.684326171875
INFO:root:Train (Epoch 6): Loss/seq after 00050 batchs: 1843.4912109375
INFO:root:Train (Epoch 6): Loss/seq after 00100 batchs: 1854.378173828125
INFO:root:Train (Epoch 6): Loss/seq after 00150 batchs: 1645.4365234375
INFO:root:Train (Epoch 6): Loss/seq after 00200 batchs: 1760.5137939453125
INFO:root:Train (Epoch 6): Loss/seq after 00250 batchs: 1864.6671142578125
INFO:root:Train (Epoch 6): Loss/seq after 00300 batchs: 1748.4586181640625
INFO:root:Train (Epoch 6): Loss/seq after 00350 batchs: 1628.1790771484375
INFO:root:Train (Epoch 6): Loss/seq after 00400 batchs: 1696.02099609375
INFO:root:Train (Epoch 6): Loss/seq after 00450 batchs: 1606.665283203125
INFO:root:Train (Epoch 6): Loss/seq after 00500 batchs: 1648.0789794921875
INFO:root:Train (Epoch 6): Loss/seq after 00550 batchs: 1574.857177734375
INFO:root:Train (Epoch 6): Loss/seq after 00600 batchs: 1534.5621337890625
INFO:root:Train (Epoch 6): Loss/seq after 00650 batchs: 1590.818115234375
INFO:root:Train (Epoch 6): Loss/seq after 00700 batchs: 1671.203857421875
INFO:root:Train (Epoch 6): Loss/seq after 00750 batchs: 1703.32421875
INFO:root:Train (Epoch 6): Loss/seq after 00800 batchs: 1683.8587646484375
INFO:root:Train (Epoch 6): Loss/seq after 00850 batchs: 1642.489990234375
INFO:root:Train (Epoch 6): Loss/seq after 00900 batchs: 1638.673583984375
INFO:root:Train (Epoch 6): Loss/seq after 00950 batchs: 1730.67236328125
INFO:root:Train (Epoch 6): Loss/seq after 01000 batchs: 1728.2430419921875
INFO:root:Train (Epoch 6): Loss/seq after 01050 batchs: 1704.1119384765625
INFO:root:Train (Epoch 6): Loss/seq after 01100 batchs: 1688.2684326171875
INFO:root:Train (Epoch 6): Loss/seq after 01150 batchs: 1661.150634765625
INFO:root:Train (Epoch 6): Loss/seq after 01200 batchs: 1642.8968505859375
INFO:root:Train (Epoch 6): Loss/seq after 01250 batchs: 1637.824951171875
INFO:root:Train (Epoch 6): Loss/seq after 01300 batchs: 1646.8638916015625
INFO:root:Train (Epoch 6): Loss/seq after 01350 batchs: 1644.2027587890625
INFO:root:Train (Epoch 6): Loss/seq after 01400 batchs: 1704.7978515625
INFO:root:Train (Epoch 6): Loss/seq after 01450 batchs: 1687.151611328125
INFO:root:Train (Epoch 6): Loss/seq after 01500 batchs: 1666.482666015625
INFO:root:Train (Epoch 6): Loss/seq after 01550 batchs: 1664.139404296875
INFO:root:Train (Epoch 6): Loss/seq after 01600 batchs: 1639.0948486328125
INFO:root:Train (Epoch 6): Loss/seq after 01650 batchs: 1625.92724609375
INFO:root:Train (Epoch 6): Loss/seq after 01700 batchs: 1609.4893798828125
INFO:root:Train (Epoch 6): Loss/seq after 01750 batchs: 1589.7144775390625
INFO:root:Train (Epoch 6): Loss/seq after 01800 batchs: 1568.650146484375
INFO:root:Train (Epoch 6): Loss/seq after 01850 batchs: 1547.7843017578125
INFO:root:Train (Epoch 6): Loss/seq after 01900 batchs: 1540.0887451171875
INFO:root:Train (Epoch 6): Loss/seq after 01950 batchs: 1529.0225830078125
INFO:root:Train (Epoch 6): Loss/seq after 02000 batchs: 1513.3096923828125
INFO:root:Train (Epoch 6): Loss/seq after 02050 batchs: 1499.504638671875
INFO:root:Train (Epoch 6): Loss/seq after 02100 batchs: 1482.7509765625
INFO:root:Train (Epoch 6): Loss/seq after 02150 batchs: 1467.273193359375
INFO:root:Train (Epoch 6): Loss/seq after 02200 batchs: 1451.0216064453125
INFO:root:Train (Epoch 6): Loss/seq after 02250 batchs: 1453.6474609375
INFO:root:Train (Epoch 6): Loss/seq after 02300 batchs: 1455.5718994140625
INFO:root:Train (Epoch 6): Loss/seq after 02350 batchs: 1442.3731689453125
INFO:root:Train (Epoch 6): Loss/seq after 02400 batchs: 1434.62353515625
INFO:root:Train (Epoch 6): Loss/seq after 02450 batchs: 1418.46484375
INFO:root:Train (Epoch 6): Loss/seq after 02500 batchs: 1397.55810546875
INFO:root:Train (Epoch 6): Loss/seq after 02550 batchs: 1383.8297119140625
INFO:root:Train (Epoch 6): Loss/seq after 02600 batchs: 1379.3076171875
INFO:root:Train (Epoch 6): Loss/seq after 02650 batchs: 1371.5810546875
INFO:root:Train (Epoch 6): Loss/seq after 02700 batchs: 1367.2291259765625
INFO:root:Train (Epoch 6): Loss/seq after 02750 batchs: 1396.2239990234375
INFO:root:Train (Epoch 6): Loss/seq after 02800 batchs: 1404.258056640625
INFO:root:Train (Epoch 6): Loss/seq after 02850 batchs: 1399.8709716796875
INFO:root:Train (Epoch 6): Loss/seq after 02900 batchs: 1396.104248046875
INFO:root:Train (Epoch 6): Loss/seq after 02950 batchs: 1386.191162109375
INFO:root:Train (Epoch 6): Loss/seq after 03000 batchs: 1381.259033203125
INFO:root:Train (Epoch 6): Loss/seq after 03050 batchs: 1381.283935546875
INFO:root:Train (Epoch 6): Loss/seq after 03100 batchs: 1397.68212890625
INFO:root:Train (Epoch 6): Loss/seq after 03150 batchs: 1417.6944580078125
INFO:root:Train (Epoch 6): Loss/seq after 03200 batchs: 1430.9207763671875
INFO:root:Train (Epoch 6): Loss/seq after 03250 batchs: 1443.2679443359375
INFO:root:Train (Epoch 6): Loss/seq after 03300 batchs: 1442.4910888671875
INFO:root:Train (Epoch 6): Loss/seq after 03350 batchs: 1440.9676513671875
INFO:root:Train (Epoch 6): Loss/seq after 03400 batchs: 1429.49560546875
INFO:root:Train (Epoch 6): Loss/seq after 03450 batchs: 1421.05224609375
INFO:root:Train (Epoch 6): Loss/seq after 03500 batchs: 1419.8653564453125
INFO:root:Train (Epoch 6): Loss/seq after 03550 batchs: 1413.323486328125
INFO:root:Train (Epoch 6): Loss/seq after 03600 batchs: 1416.869873046875
INFO:root:Train (Epoch 6): Loss/seq after 03650 batchs: 1410.7803955078125
INFO:root:Train (Epoch 6): Loss/seq after 03700 batchs: 1408.3326416015625
INFO:root:Train (Epoch 6): Loss/seq after 03750 batchs: 1406.010498046875
INFO:root:Train (Epoch 6): Loss/seq after 03800 batchs: 1396.88818359375
INFO:root:Train (Epoch 6): Loss/seq after 03850 batchs: 1390.3297119140625
INFO:root:Train (Epoch 6): Loss/seq after 03900 batchs: 1397.8201904296875
INFO:root:Train (Epoch 6): Loss/seq after 03950 batchs: 1406.7801513671875
INFO:root:Train (Epoch 6): Loss/seq after 04000 batchs: 1395.6890869140625
INFO:root:Train (Epoch 6): Loss/seq after 04050 batchs: 1385.5426025390625
INFO:root:Train (Epoch 6): Loss/seq after 04100 batchs: 1380.051513671875
INFO:root:Train (Epoch 6): Loss/seq after 04150 batchs: 1373.251220703125
INFO:root:Train (Epoch 6): Loss/seq after 04200 batchs: 1367.3818359375
INFO:root:Train (Epoch 6): Loss/seq after 04250 batchs: 1361.5833740234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 6): Loss/seq after 00000 batches: 973.2214965820312
INFO:root:# Valid (Epoch 6): Loss/seq after 00050 batches: 1132.72607421875
INFO:root:# Valid (Epoch 6): Loss/seq after 00100 batches: 1467.441650390625
INFO:root:# Valid (Epoch 6): Loss/seq after 00150 batches: 1221.9156494140625
INFO:root:# Valid (Epoch 6): Loss/seq after 00200 batches: 1108.7667236328125
INFO:root:Artifacts: Make stick videos for epoch 6
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_6_on_20220413_152126.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_6_index_1351_on_20220413_152126.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 7): Loss/seq after 00000 batchs: 2417.1630859375
INFO:root:Train (Epoch 7): Loss/seq after 00050 batchs: 1827.064453125
INFO:root:Train (Epoch 7): Loss/seq after 00100 batchs: 1775.1142578125
INFO:root:Train (Epoch 7): Loss/seq after 00150 batchs: 1582.7872314453125
INFO:root:Train (Epoch 7): Loss/seq after 00200 batchs: 1715.0323486328125
INFO:root:Train (Epoch 7): Loss/seq after 00250 batchs: 1836.6710205078125
INFO:root:Train (Epoch 7): Loss/seq after 00300 batchs: 1718.1612548828125
INFO:root:Train (Epoch 7): Loss/seq after 00350 batchs: 1602.0389404296875
INFO:root:Train (Epoch 7): Loss/seq after 00400 batchs: 1668.767333984375
INFO:root:Train (Epoch 7): Loss/seq after 00450 batchs: 1581.655029296875
INFO:root:Train (Epoch 7): Loss/seq after 00500 batchs: 1610.224365234375
INFO:root:Train (Epoch 7): Loss/seq after 00550 batchs: 1540.0850830078125
INFO:root:Train (Epoch 7): Loss/seq after 00600 batchs: 1502.5001220703125
INFO:root:Train (Epoch 7): Loss/seq after 00650 batchs: 1567.474853515625
INFO:root:Train (Epoch 7): Loss/seq after 00700 batchs: 1651.5606689453125
INFO:root:Train (Epoch 7): Loss/seq after 00750 batchs: 1692.2012939453125
INFO:root:Train (Epoch 7): Loss/seq after 00800 batchs: 1673.512939453125
INFO:root:Train (Epoch 7): Loss/seq after 00850 batchs: 1632.833251953125
INFO:root:Train (Epoch 7): Loss/seq after 00900 batchs: 1632.7093505859375
INFO:root:Train (Epoch 7): Loss/seq after 00950 batchs: 1730.1463623046875
INFO:root:Train (Epoch 7): Loss/seq after 01000 batchs: 1734.5208740234375
INFO:root:Train (Epoch 7): Loss/seq after 01050 batchs: 1708.352294921875
INFO:root:Train (Epoch 7): Loss/seq after 01100 batchs: 1689.3818359375
INFO:root:Train (Epoch 7): Loss/seq after 01150 batchs: 1660.129150390625
INFO:root:Train (Epoch 7): Loss/seq after 01200 batchs: 1640.1470947265625
INFO:root:Train (Epoch 7): Loss/seq after 01250 batchs: 1628.0079345703125
INFO:root:Train (Epoch 7): Loss/seq after 01300 batchs: 1637.0416259765625
INFO:root:Train (Epoch 7): Loss/seq after 01350 batchs: 1634.949462890625
INFO:root:Train (Epoch 7): Loss/seq after 01400 batchs: 1685.61181640625
INFO:root:Train (Epoch 7): Loss/seq after 01450 batchs: 1665.1090087890625
INFO:root:Train (Epoch 7): Loss/seq after 01500 batchs: 1645.5716552734375
INFO:root:Train (Epoch 7): Loss/seq after 01550 batchs: 1641.65966796875
INFO:root:Train (Epoch 7): Loss/seq after 01600 batchs: 1616.5908203125
INFO:root:Train (Epoch 7): Loss/seq after 01650 batchs: 1606.1556396484375
INFO:root:Train (Epoch 7): Loss/seq after 01700 batchs: 1590.7005615234375
INFO:root:Train (Epoch 7): Loss/seq after 01750 batchs: 1571.6768798828125
INFO:root:Train (Epoch 7): Loss/seq after 01800 batchs: 1551.2554931640625
INFO:root:Train (Epoch 7): Loss/seq after 01850 batchs: 1530.837646484375
INFO:root:Train (Epoch 7): Loss/seq after 01900 batchs: 1523.7171630859375
INFO:root:Train (Epoch 7): Loss/seq after 01950 batchs: 1513.04541015625
INFO:root:Train (Epoch 7): Loss/seq after 02000 batchs: 1497.9796142578125
INFO:root:Train (Epoch 7): Loss/seq after 02050 batchs: 1484.6873779296875
INFO:root:Train (Epoch 7): Loss/seq after 02100 batchs: 1468.34912109375
INFO:root:Train (Epoch 7): Loss/seq after 02150 batchs: 1453.635009765625
INFO:root:Train (Epoch 7): Loss/seq after 02200 batchs: 1437.7080078125
INFO:root:Train (Epoch 7): Loss/seq after 02250 batchs: 1438.62158203125
INFO:root:Train (Epoch 7): Loss/seq after 02300 batchs: 1440.9283447265625
INFO:root:Train (Epoch 7): Loss/seq after 02350 batchs: 1428.31982421875
INFO:root:Train (Epoch 7): Loss/seq after 02400 batchs: 1420.995361328125
INFO:root:Train (Epoch 7): Loss/seq after 02450 batchs: 1405.3323974609375
INFO:root:Train (Epoch 7): Loss/seq after 02500 batchs: 1384.7376708984375
INFO:root:Train (Epoch 7): Loss/seq after 02550 batchs: 1371.3502197265625
INFO:root:Train (Epoch 7): Loss/seq after 02600 batchs: 1368.4937744140625
INFO:root:Train (Epoch 7): Loss/seq after 02650 batchs: 1361.5777587890625
INFO:root:Train (Epoch 7): Loss/seq after 02700 batchs: 1358.9677734375
INFO:root:Train (Epoch 7): Loss/seq after 02750 batchs: 1388.8944091796875
INFO:root:Train (Epoch 7): Loss/seq after 02800 batchs: 1397.2333984375
INFO:root:Train (Epoch 7): Loss/seq after 02850 batchs: 1392.9661865234375
INFO:root:Train (Epoch 7): Loss/seq after 02900 batchs: 1389.001953125
INFO:root:Train (Epoch 7): Loss/seq after 02950 batchs: 1379.2904052734375
INFO:root:Train (Epoch 7): Loss/seq after 03000 batchs: 1374.4393310546875
INFO:root:Train (Epoch 7): Loss/seq after 03050 batchs: 1374.5316162109375
INFO:root:Train (Epoch 7): Loss/seq after 03100 batchs: 1391.968017578125
INFO:root:Train (Epoch 7): Loss/seq after 03150 batchs: 1411.168701171875
INFO:root:Train (Epoch 7): Loss/seq after 03200 batchs: 1424.4200439453125
INFO:root:Train (Epoch 7): Loss/seq after 03250 batchs: 1436.821044921875
INFO:root:Train (Epoch 7): Loss/seq after 03300 batchs: 1435.6162109375
INFO:root:Train (Epoch 7): Loss/seq after 03350 batchs: 1434.149169921875
INFO:root:Train (Epoch 7): Loss/seq after 03400 batchs: 1422.698974609375
INFO:root:Train (Epoch 7): Loss/seq after 03450 batchs: 1414.1759033203125
INFO:root:Train (Epoch 7): Loss/seq after 03500 batchs: 1412.305419921875
INFO:root:Train (Epoch 7): Loss/seq after 03550 batchs: 1405.48095703125
INFO:root:Train (Epoch 7): Loss/seq after 03600 batchs: 1409.31787109375
INFO:root:Train (Epoch 7): Loss/seq after 03650 batchs: 1403.5828857421875
INFO:root:Train (Epoch 7): Loss/seq after 03700 batchs: 1401.2755126953125
INFO:root:Train (Epoch 7): Loss/seq after 03750 batchs: 1399.093505859375
INFO:root:Train (Epoch 7): Loss/seq after 03800 batchs: 1390.223876953125
INFO:root:Train (Epoch 7): Loss/seq after 03850 batchs: 1384.048095703125
INFO:root:Train (Epoch 7): Loss/seq after 03900 batchs: 1391.2474365234375
INFO:root:Train (Epoch 7): Loss/seq after 03950 batchs: 1398.9229736328125
INFO:root:Train (Epoch 7): Loss/seq after 04000 batchs: 1387.8204345703125
INFO:root:Train (Epoch 7): Loss/seq after 04050 batchs: 1377.76025390625
INFO:root:Train (Epoch 7): Loss/seq after 04100 batchs: 1372.7935791015625
INFO:root:Train (Epoch 7): Loss/seq after 04150 batchs: 1366.018310546875
INFO:root:Train (Epoch 7): Loss/seq after 04200 batchs: 1359.39013671875
INFO:root:Train (Epoch 7): Loss/seq after 04250 batchs: 1353.48046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 7): Loss/seq after 00000 batches: 949.0238037109375
INFO:root:# Valid (Epoch 7): Loss/seq after 00050 batches: 1121.761962890625
INFO:root:# Valid (Epoch 7): Loss/seq after 00100 batches: 1459.2635498046875
INFO:root:# Valid (Epoch 7): Loss/seq after 00150 batches: 1219.0965576171875
INFO:root:# Valid (Epoch 7): Loss/seq after 00200 batches: 1106.9129638671875
INFO:root:Artifacts: Make stick videos for epoch 7
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_7_on_20220413_152643.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_7_index_1613_on_20220413_152643.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 8): Loss/seq after 00000 batchs: 2371.948486328125
INFO:root:Train (Epoch 8): Loss/seq after 00050 batchs: 1783.868896484375
INFO:root:Train (Epoch 8): Loss/seq after 00100 batchs: 1769.5849609375
INFO:root:Train (Epoch 8): Loss/seq after 00150 batchs: 1560.11181640625
INFO:root:Train (Epoch 8): Loss/seq after 00200 batchs: 1694.9892578125
INFO:root:Train (Epoch 8): Loss/seq after 00250 batchs: 1799.0050048828125
INFO:root:Train (Epoch 8): Loss/seq after 00300 batchs: 1687.134521484375
INFO:root:Train (Epoch 8): Loss/seq after 00350 batchs: 1572.8199462890625
INFO:root:Train (Epoch 8): Loss/seq after 00400 batchs: 1640.5992431640625
INFO:root:Train (Epoch 8): Loss/seq after 00450 batchs: 1556.2535400390625
INFO:root:Train (Epoch 8): Loss/seq after 00500 batchs: 1587.001220703125
INFO:root:Train (Epoch 8): Loss/seq after 00550 batchs: 1520.345458984375
INFO:root:Train (Epoch 8): Loss/seq after 00600 batchs: 1483.8482666015625
INFO:root:Train (Epoch 8): Loss/seq after 00650 batchs: 1546.681884765625
INFO:root:Train (Epoch 8): Loss/seq after 00700 batchs: 1630.403564453125
INFO:root:Train (Epoch 8): Loss/seq after 00750 batchs: 1666.1925048828125
INFO:root:Train (Epoch 8): Loss/seq after 00800 batchs: 1649.009521484375
INFO:root:Train (Epoch 8): Loss/seq after 00850 batchs: 1610.240478515625
INFO:root:Train (Epoch 8): Loss/seq after 00900 batchs: 1610.38671875
INFO:root:Train (Epoch 8): Loss/seq after 00950 batchs: 1705.2891845703125
INFO:root:Train (Epoch 8): Loss/seq after 01000 batchs: 1704.3775634765625
INFO:root:Train (Epoch 8): Loss/seq after 01050 batchs: 1679.2557373046875
INFO:root:Train (Epoch 8): Loss/seq after 01100 batchs: 1665.9892578125
INFO:root:Train (Epoch 8): Loss/seq after 01150 batchs: 1638.82373046875
INFO:root:Train (Epoch 8): Loss/seq after 01200 batchs: 1619.53955078125
INFO:root:Train (Epoch 8): Loss/seq after 01250 batchs: 1607.7384033203125
INFO:root:Train (Epoch 8): Loss/seq after 01300 batchs: 1617.4544677734375
INFO:root:Train (Epoch 8): Loss/seq after 01350 batchs: 1615.4725341796875
INFO:root:Train (Epoch 8): Loss/seq after 01400 batchs: 1665.0849609375
INFO:root:Train (Epoch 8): Loss/seq after 01450 batchs: 1646.516357421875
INFO:root:Train (Epoch 8): Loss/seq after 01500 batchs: 1627.3087158203125
INFO:root:Train (Epoch 8): Loss/seq after 01550 batchs: 1623.2742919921875
INFO:root:Train (Epoch 8): Loss/seq after 01600 batchs: 1598.09521484375
INFO:root:Train (Epoch 8): Loss/seq after 01650 batchs: 1586.3895263671875
INFO:root:Train (Epoch 8): Loss/seq after 01700 batchs: 1570.8697509765625
INFO:root:Train (Epoch 8): Loss/seq after 01750 batchs: 1552.4000244140625
INFO:root:Train (Epoch 8): Loss/seq after 01800 batchs: 1532.462646484375
INFO:root:Train (Epoch 8): Loss/seq after 01850 batchs: 1512.5255126953125
INFO:root:Train (Epoch 8): Loss/seq after 01900 batchs: 1505.8104248046875
INFO:root:Train (Epoch 8): Loss/seq after 01950 batchs: 1495.501220703125
INFO:root:Train (Epoch 8): Loss/seq after 02000 batchs: 1480.8497314453125
INFO:root:Train (Epoch 8): Loss/seq after 02050 batchs: 1468.0458984375
INFO:root:Train (Epoch 8): Loss/seq after 02100 batchs: 1452.0755615234375
INFO:root:Train (Epoch 8): Loss/seq after 02150 batchs: 1437.7354736328125
INFO:root:Train (Epoch 8): Loss/seq after 02200 batchs: 1422.1943359375
INFO:root:Train (Epoch 8): Loss/seq after 02250 batchs: 1423.396728515625
INFO:root:Train (Epoch 8): Loss/seq after 02300 batchs: 1424.9290771484375
INFO:root:Train (Epoch 8): Loss/seq after 02350 batchs: 1412.6768798828125
INFO:root:Train (Epoch 8): Loss/seq after 02400 batchs: 1405.5107421875
INFO:root:Train (Epoch 8): Loss/seq after 02450 batchs: 1389.880859375
INFO:root:Train (Epoch 8): Loss/seq after 02500 batchs: 1369.4967041015625
INFO:root:Train (Epoch 8): Loss/seq after 02550 batchs: 1355.896728515625
INFO:root:Train (Epoch 8): Loss/seq after 02600 batchs: 1352.1611328125
INFO:root:Train (Epoch 8): Loss/seq after 02650 batchs: 1344.9332275390625
INFO:root:Train (Epoch 8): Loss/seq after 02700 batchs: 1340.5286865234375
INFO:root:Train (Epoch 8): Loss/seq after 02750 batchs: 1369.6995849609375
INFO:root:Train (Epoch 8): Loss/seq after 02800 batchs: 1377.8939208984375
INFO:root:Train (Epoch 8): Loss/seq after 02850 batchs: 1373.7054443359375
INFO:root:Train (Epoch 8): Loss/seq after 02900 batchs: 1370.0579833984375
INFO:root:Train (Epoch 8): Loss/seq after 02950 batchs: 1360.5299072265625
INFO:root:Train (Epoch 8): Loss/seq after 03000 batchs: 1355.9912109375
INFO:root:Train (Epoch 8): Loss/seq after 03050 batchs: 1356.3853759765625
INFO:root:Train (Epoch 8): Loss/seq after 03100 batchs: 1374.223388671875
INFO:root:Train (Epoch 8): Loss/seq after 03150 batchs: 1393.27587890625
INFO:root:Train (Epoch 8): Loss/seq after 03200 batchs: 1406.24560546875
INFO:root:Train (Epoch 8): Loss/seq after 03250 batchs: 1418.712890625
INFO:root:Train (Epoch 8): Loss/seq after 03300 batchs: 1416.394775390625
INFO:root:Train (Epoch 8): Loss/seq after 03350 batchs: 1414.4593505859375
INFO:root:Train (Epoch 8): Loss/seq after 03400 batchs: 1403.329345703125
INFO:root:Train (Epoch 8): Loss/seq after 03450 batchs: 1394.772705078125
INFO:root:Train (Epoch 8): Loss/seq after 03500 batchs: 1393.4150390625
INFO:root:Train (Epoch 8): Loss/seq after 03550 batchs: 1387.4141845703125
INFO:root:Train (Epoch 8): Loss/seq after 03600 batchs: 1391.566162109375
INFO:root:Train (Epoch 8): Loss/seq after 03650 batchs: 1385.931396484375
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 8): Loss/seq after 03700 batchs: 1383.684326171875
INFO:root:Train (Epoch 8): Loss/seq after 03750 batchs: 1381.56396484375
INFO:root:Train (Epoch 8): Loss/seq after 03800 batchs: 1372.7066650390625
INFO:root:Train (Epoch 8): Loss/seq after 03850 batchs: 1366.51171875
INFO:root:Train (Epoch 8): Loss/seq after 03900 batchs: 1373.31201171875
INFO:root:Train (Epoch 8): Loss/seq after 03950 batchs: 1382.5841064453125
INFO:root:Train (Epoch 8): Loss/seq after 04000 batchs: 1371.67578125
INFO:root:Train (Epoch 8): Loss/seq after 04050 batchs: 1361.8026123046875
INFO:root:Train (Epoch 8): Loss/seq after 04100 batchs: 1356.483642578125
INFO:root:Train (Epoch 8): Loss/seq after 04150 batchs: 1349.4752197265625
INFO:root:Train (Epoch 8): Loss/seq after 04200 batchs: 1343.1156005859375
INFO:root:Train (Epoch 8): Loss/seq after 04250 batchs: 1337.3525390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 8): Loss/seq after 00000 batches: 940.8213500976562
INFO:root:# Valid (Epoch 8): Loss/seq after 00050 batches: 1119.11474609375
INFO:root:# Valid (Epoch 8): Loss/seq after 00100 batches: 1460.5772705078125
INFO:root:# Valid (Epoch 8): Loss/seq after 00150 batches: 1223.5380859375
INFO:root:# Valid (Epoch 8): Loss/seq after 00200 batches: 1111.8309326171875
INFO:root:Artifacts: Make stick videos for epoch 8
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_8_on_20220413_153203.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_8_index_1663_on_20220413_153203.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 9): Loss/seq after 00000 batchs: 2486.9814453125
INFO:root:Train (Epoch 9): Loss/seq after 00050 batchs: 1831.262451171875
INFO:root:Train (Epoch 9): Loss/seq after 00100 batchs: 1740.575927734375
INFO:root:Train (Epoch 9): Loss/seq after 00150 batchs: 1534.76904296875
INFO:root:Train (Epoch 9): Loss/seq after 00200 batchs: 1664.2391357421875
INFO:root:Train (Epoch 9): Loss/seq after 00250 batchs: 1772.9468994140625
INFO:root:Train (Epoch 9): Loss/seq after 00300 batchs: 1663.270263671875
INFO:root:Train (Epoch 9): Loss/seq after 00350 batchs: 1552.3323974609375
INFO:root:Train (Epoch 9): Loss/seq after 00400 batchs: 1617.77978515625
INFO:root:Train (Epoch 9): Loss/seq after 00450 batchs: 1535.869384765625
INFO:root:Train (Epoch 9): Loss/seq after 00500 batchs: 1566.3798828125
INFO:root:Train (Epoch 9): Loss/seq after 00550 batchs: 1499.401611328125
INFO:root:Train (Epoch 9): Loss/seq after 00600 batchs: 1463.746826171875
INFO:root:Train (Epoch 9): Loss/seq after 00650 batchs: 1531.709716796875
INFO:root:Train (Epoch 9): Loss/seq after 00700 batchs: 1617.4593505859375
INFO:root:Train (Epoch 9): Loss/seq after 00750 batchs: 1658.9365234375
INFO:root:Train (Epoch 9): Loss/seq after 00800 batchs: 1640.835693359375
INFO:root:Train (Epoch 9): Loss/seq after 00850 batchs: 1602.9085693359375
INFO:root:Train (Epoch 9): Loss/seq after 00900 batchs: 1600.423095703125
INFO:root:Train (Epoch 9): Loss/seq after 00950 batchs: 1699.6199951171875
INFO:root:Train (Epoch 9): Loss/seq after 01000 batchs: 1700.677001953125
INFO:root:Train (Epoch 9): Loss/seq after 01050 batchs: 1675.5389404296875
INFO:root:Train (Epoch 9): Loss/seq after 01100 batchs: 1657.8074951171875
INFO:root:Train (Epoch 9): Loss/seq after 01150 batchs: 1629.546142578125
INFO:root:Train (Epoch 9): Loss/seq after 01200 batchs: 1610.4227294921875
INFO:root:Train (Epoch 9): Loss/seq after 01250 batchs: 1599.7161865234375
INFO:root:Train (Epoch 9): Loss/seq after 01300 batchs: 1609.1422119140625
INFO:root:Train (Epoch 9): Loss/seq after 01350 batchs: 1607.443115234375
INFO:root:Train (Epoch 9): Loss/seq after 01400 batchs: 1657.9935302734375
INFO:root:Train (Epoch 9): Loss/seq after 01450 batchs: 1639.7545166015625
INFO:root:Train (Epoch 9): Loss/seq after 01500 batchs: 1620.9444580078125
INFO:root:Train (Epoch 9): Loss/seq after 01550 batchs: 1617.632080078125
INFO:root:Train (Epoch 9): Loss/seq after 01600 batchs: 1593.396240234375
INFO:root:Train (Epoch 9): Loss/seq after 01650 batchs: 1582.8472900390625
INFO:root:Train (Epoch 9): Loss/seq after 01700 batchs: 1567.5074462890625
INFO:root:Train (Epoch 9): Loss/seq after 01750 batchs: 1549.126953125
INFO:root:Train (Epoch 9): Loss/seq after 01800 batchs: 1529.2735595703125
INFO:root:Train (Epoch 9): Loss/seq after 01850 batchs: 1509.3895263671875
INFO:root:Train (Epoch 9): Loss/seq after 01900 batchs: 1502.769775390625
INFO:root:Train (Epoch 9): Loss/seq after 01950 batchs: 1492.586669921875
INFO:root:Train (Epoch 9): Loss/seq after 02000 batchs: 1478.0179443359375
INFO:root:Train (Epoch 9): Loss/seq after 02050 batchs: 1465.427978515625
INFO:root:Train (Epoch 9): Loss/seq after 02100 batchs: 1449.5283203125
INFO:root:Train (Epoch 9): Loss/seq after 02150 batchs: 1435.25146484375
INFO:root:Train (Epoch 9): Loss/seq after 02200 batchs: 1419.7608642578125
INFO:root:Train (Epoch 9): Loss/seq after 02250 batchs: 1421.03369140625
INFO:root:Train (Epoch 9): Loss/seq after 02300 batchs: 1422.543701171875
INFO:root:Train (Epoch 9): Loss/seq after 02350 batchs: 1410.4608154296875
INFO:root:Train (Epoch 9): Loss/seq after 02400 batchs: 1403.258056640625
INFO:root:Train (Epoch 9): Loss/seq after 02450 batchs: 1387.6517333984375
INFO:root:Train (Epoch 9): Loss/seq after 02500 batchs: 1367.32470703125
INFO:root:Train (Epoch 9): Loss/seq after 02550 batchs: 1353.8048095703125
INFO:root:Train (Epoch 9): Loss/seq after 02600 batchs: 1350.205810546875
INFO:root:Train (Epoch 9): Loss/seq after 02650 batchs: 1342.8897705078125
INFO:root:Train (Epoch 9): Loss/seq after 02700 batchs: 1337.982177734375
INFO:root:Train (Epoch 9): Loss/seq after 02750 batchs: 1367.6732177734375
INFO:root:Train (Epoch 9): Loss/seq after 02800 batchs: 1376.1854248046875
INFO:root:Train (Epoch 9): Loss/seq after 02850 batchs: 1371.915771484375
INFO:root:Train (Epoch 9): Loss/seq after 02900 batchs: 1368.7481689453125
INFO:root:Train (Epoch 9): Loss/seq after 02950 batchs: 1358.9051513671875
INFO:root:Train (Epoch 9): Loss/seq after 03000 batchs: 1354.3572998046875
INFO:root:Train (Epoch 9): Loss/seq after 03050 batchs: 1354.5628662109375
INFO:root:Train (Epoch 9): Loss/seq after 03100 batchs: 1371.0869140625
INFO:root:Train (Epoch 9): Loss/seq after 03150 batchs: 1390.0157470703125
INFO:root:Train (Epoch 9): Loss/seq after 03200 batchs: 1403.169921875
INFO:root:Train (Epoch 9): Loss/seq after 03250 batchs: 1415.4796142578125
INFO:root:Train (Epoch 9): Loss/seq after 03300 batchs: 1416.739013671875
INFO:root:Train (Epoch 9): Loss/seq after 03350 batchs: 1415.4036865234375
INFO:root:Train (Epoch 9): Loss/seq after 03400 batchs: 1404.336181640625
INFO:root:Train (Epoch 9): Loss/seq after 03450 batchs: 1396.0718994140625
INFO:root:Train (Epoch 9): Loss/seq after 03500 batchs: 1394.6810302734375
INFO:root:Train (Epoch 9): Loss/seq after 03550 batchs: 1387.9862060546875
INFO:root:Train (Epoch 9): Loss/seq after 03600 batchs: 1391.890625
INFO:root:Train (Epoch 9): Loss/seq after 03650 batchs: 1386.3543701171875
INFO:root:Train (Epoch 9): Loss/seq after 03700 batchs: 1384.140869140625
INFO:root:Train (Epoch 9): Loss/seq after 03750 batchs: 1382.24267578125
INFO:root:Train (Epoch 9): Loss/seq after 03800 batchs: 1373.4205322265625
INFO:root:Train (Epoch 9): Loss/seq after 03850 batchs: 1367.1571044921875
INFO:root:Train (Epoch 9): Loss/seq after 03900 batchs: 1374.5821533203125
INFO:root:Train (Epoch 9): Loss/seq after 03950 batchs: 1383.286865234375
INFO:root:Train (Epoch 9): Loss/seq after 04000 batchs: 1372.4033203125
INFO:root:Train (Epoch 9): Loss/seq after 04050 batchs: 1362.523681640625
INFO:root:Train (Epoch 9): Loss/seq after 04100 batchs: 1356.794921875
INFO:root:Train (Epoch 9): Loss/seq after 04150 batchs: 1349.935302734375
INFO:root:Train (Epoch 9): Loss/seq after 04200 batchs: 1343.9892578125
INFO:root:Train (Epoch 9): Loss/seq after 04250 batchs: 1338.3714599609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 9): Loss/seq after 00000 batches: 913.2937622070312
INFO:root:# Valid (Epoch 9): Loss/seq after 00050 batches: 1110.1796875
INFO:root:# Valid (Epoch 9): Loss/seq after 00100 batches: 1443.012451171875
INFO:root:# Valid (Epoch 9): Loss/seq after 00150 batches: 1213.635986328125
INFO:root:# Valid (Epoch 9): Loss/seq after 00200 batches: 1105.10986328125
INFO:root:Artifacts: Make stick videos for epoch 9
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_9_on_20220413_153720.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_9_index_34_on_20220413_153720.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 10): Loss/seq after 00000 batchs: 2425.6943359375
INFO:root:Train (Epoch 10): Loss/seq after 00050 batchs: 1811.8974609375
INFO:root:Train (Epoch 10): Loss/seq after 00100 batchs: 1767.17724609375
INFO:root:Train (Epoch 10): Loss/seq after 00150 batchs: 1584.4249267578125
INFO:root:Train (Epoch 10): Loss/seq after 00200 batchs: 1695.167236328125
INFO:root:Train (Epoch 10): Loss/seq after 00250 batchs: 1805.0799560546875
INFO:root:Train (Epoch 10): Loss/seq after 00300 batchs: 1694.3931884765625
INFO:root:Train (Epoch 10): Loss/seq after 00350 batchs: 1579.8609619140625
INFO:root:Train (Epoch 10): Loss/seq after 00400 batchs: 1643.7662353515625
INFO:root:Train (Epoch 10): Loss/seq after 00450 batchs: 1559.36083984375
INFO:root:Train (Epoch 10): Loss/seq after 00500 batchs: 1588.991943359375
INFO:root:Train (Epoch 10): Loss/seq after 00550 batchs: 1519.4930419921875
INFO:root:Train (Epoch 10): Loss/seq after 00600 batchs: 1480.80419921875
INFO:root:Train (Epoch 10): Loss/seq after 00650 batchs: 1541.279052734375
INFO:root:Train (Epoch 10): Loss/seq after 00700 batchs: 1624.8240966796875
INFO:root:Train (Epoch 10): Loss/seq after 00750 batchs: 1659.412353515625
INFO:root:Train (Epoch 10): Loss/seq after 00800 batchs: 1641.9295654296875
INFO:root:Train (Epoch 10): Loss/seq after 00850 batchs: 1604.5654296875
INFO:root:Train (Epoch 10): Loss/seq after 00900 batchs: 1603.7763671875
INFO:root:Train (Epoch 10): Loss/seq after 00950 batchs: 1696.326171875
INFO:root:Train (Epoch 10): Loss/seq after 01000 batchs: 1695.697509765625
INFO:root:Train (Epoch 10): Loss/seq after 01050 batchs: 1670.544189453125
INFO:root:Train (Epoch 10): Loss/seq after 01100 batchs: 1651.2679443359375
INFO:root:Train (Epoch 10): Loss/seq after 01150 batchs: 1622.724853515625
INFO:root:Train (Epoch 10): Loss/seq after 01200 batchs: 1601.122802734375
INFO:root:Train (Epoch 10): Loss/seq after 01250 batchs: 1589.682861328125
INFO:root:Train (Epoch 10): Loss/seq after 01300 batchs: 1599.952392578125
INFO:root:Train (Epoch 10): Loss/seq after 01350 batchs: 1598.6783447265625
INFO:root:Train (Epoch 10): Loss/seq after 01400 batchs: 1649.6043701171875
INFO:root:Train (Epoch 10): Loss/seq after 01450 batchs: 1630.034912109375
INFO:root:Train (Epoch 10): Loss/seq after 01500 batchs: 1612.07177734375
INFO:root:Train (Epoch 10): Loss/seq after 01550 batchs: 1608.6185302734375
INFO:root:Train (Epoch 10): Loss/seq after 01600 batchs: 1584.1607666015625
INFO:root:Train (Epoch 10): Loss/seq after 01650 batchs: 1573.4844970703125
INFO:root:Train (Epoch 10): Loss/seq after 01700 batchs: 1558.5830078125
INFO:root:Train (Epoch 10): Loss/seq after 01750 batchs: 1540.4881591796875
INFO:root:Train (Epoch 10): Loss/seq after 01800 batchs: 1520.9241943359375
INFO:root:Train (Epoch 10): Loss/seq after 01850 batchs: 1501.296875
INFO:root:Train (Epoch 10): Loss/seq after 01900 batchs: 1494.9169921875
INFO:root:Train (Epoch 10): Loss/seq after 01950 batchs: 1484.949951171875
INFO:root:Train (Epoch 10): Loss/seq after 02000 batchs: 1470.581787109375
INFO:root:Train (Epoch 10): Loss/seq after 02050 batchs: 1458.0478515625
INFO:root:Train (Epoch 10): Loss/seq after 02100 batchs: 1442.2911376953125
INFO:root:Train (Epoch 10): Loss/seq after 02150 batchs: 1428.136474609375
INFO:root:Train (Epoch 10): Loss/seq after 02200 batchs: 1412.8265380859375
INFO:root:Train (Epoch 10): Loss/seq after 02250 batchs: 1415.7347412109375
INFO:root:Train (Epoch 10): Loss/seq after 02300 batchs: 1419.75244140625
INFO:root:Train (Epoch 10): Loss/seq after 02350 batchs: 1407.9957275390625
INFO:root:Train (Epoch 10): Loss/seq after 02400 batchs: 1400.9337158203125
INFO:root:Train (Epoch 10): Loss/seq after 02450 batchs: 1385.5069580078125
INFO:root:Train (Epoch 10): Loss/seq after 02500 batchs: 1365.1881103515625
INFO:root:Train (Epoch 10): Loss/seq after 02550 batchs: 1351.8748779296875
INFO:root:Train (Epoch 10): Loss/seq after 02600 batchs: 1348.92333984375
INFO:root:Train (Epoch 10): Loss/seq after 02650 batchs: 1341.879150390625
INFO:root:Train (Epoch 10): Loss/seq after 02700 batchs: 1337.4635009765625
INFO:root:Train (Epoch 10): Loss/seq after 02750 batchs: 1367.8035888671875
INFO:root:Train (Epoch 10): Loss/seq after 02800 batchs: 1376.0516357421875
INFO:root:Train (Epoch 10): Loss/seq after 02850 batchs: 1371.9180908203125
INFO:root:Train (Epoch 10): Loss/seq after 02900 batchs: 1368.7281494140625
INFO:root:Train (Epoch 10): Loss/seq after 02950 batchs: 1359.3046875
INFO:root:Train (Epoch 10): Loss/seq after 03000 batchs: 1354.8017578125
INFO:root:Train (Epoch 10): Loss/seq after 03050 batchs: 1355.205078125
INFO:root:Train (Epoch 10): Loss/seq after 03100 batchs: 1372.1363525390625
INFO:root:Train (Epoch 10): Loss/seq after 03150 batchs: 1391.13916015625
INFO:root:Train (Epoch 10): Loss/seq after 03200 batchs: 1404.7200927734375
INFO:root:Train (Epoch 10): Loss/seq after 03250 batchs: 1417.3377685546875
INFO:root:Train (Epoch 10): Loss/seq after 03300 batchs: 1417.705322265625
INFO:root:Train (Epoch 10): Loss/seq after 03350 batchs: 1416.2265625
INFO:root:Train (Epoch 10): Loss/seq after 03400 batchs: 1405.1474609375
INFO:root:Train (Epoch 10): Loss/seq after 03450 batchs: 1397.138916015625
INFO:root:Train (Epoch 10): Loss/seq after 03500 batchs: 1395.4228515625
INFO:root:Train (Epoch 10): Loss/seq after 03550 batchs: 1388.9921875
INFO:root:Train (Epoch 10): Loss/seq after 03600 batchs: 1392.922119140625
INFO:root:Train (Epoch 10): Loss/seq after 03650 batchs: 1387.329345703125
INFO:root:Train (Epoch 10): Loss/seq after 03700 batchs: 1385.064453125
INFO:root:Train (Epoch 10): Loss/seq after 03750 batchs: 1382.890625
INFO:root:Train (Epoch 10): Loss/seq after 03800 batchs: 1373.9610595703125
INFO:root:Train (Epoch 10): Loss/seq after 03850 batchs: 1367.6055908203125
INFO:root:Train (Epoch 10): Loss/seq after 03900 batchs: 1374.6043701171875
INFO:root:Train (Epoch 10): Loss/seq after 03950 batchs: 1382.9986572265625
INFO:root:Train (Epoch 10): Loss/seq after 04000 batchs: 1372.138427734375
INFO:root:Train (Epoch 10): Loss/seq after 04050 batchs: 1362.2679443359375
INFO:root:Train (Epoch 10): Loss/seq after 04100 batchs: 1356.4183349609375
INFO:root:Train (Epoch 10): Loss/seq after 04150 batchs: 1349.2354736328125
INFO:root:Train (Epoch 10): Loss/seq after 04200 batchs: 1343.1595458984375
INFO:root:Train (Epoch 10): Loss/seq after 04250 batchs: 1337.2569580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 10): Loss/seq after 00000 batches: 922.927001953125
INFO:root:# Valid (Epoch 10): Loss/seq after 00050 batches: 1112.7955322265625
INFO:root:# Valid (Epoch 10): Loss/seq after 00100 batches: 1450.8546142578125
INFO:root:# Valid (Epoch 10): Loss/seq after 00150 batches: 1221.920166015625
INFO:root:# Valid (Epoch 10): Loss/seq after 00200 batches: 1112.05615234375
INFO:root:Artifacts: Make stick videos for epoch 10
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_10_on_20220413_154237.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_10_index_536_on_20220413_154237.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 11): Loss/seq after 00000 batchs: 2486.98974609375
INFO:root:Train (Epoch 11): Loss/seq after 00050 batchs: 1813.0560302734375
INFO:root:Train (Epoch 11): Loss/seq after 00100 batchs: 1741.1292724609375
INFO:root:Train (Epoch 11): Loss/seq after 00150 batchs: 1535.33935546875
INFO:root:Train (Epoch 11): Loss/seq after 00200 batchs: 1658.213623046875
INFO:root:Train (Epoch 11): Loss/seq after 00250 batchs: 1769.2117919921875
INFO:root:Train (Epoch 11): Loss/seq after 00300 batchs: 1660.255615234375
INFO:root:Train (Epoch 11): Loss/seq after 00350 batchs: 1549.7391357421875
INFO:root:Train (Epoch 11): Loss/seq after 00400 batchs: 1614.72119140625
INFO:root:Train (Epoch 11): Loss/seq after 00450 batchs: 1533.0325927734375
INFO:root:Train (Epoch 11): Loss/seq after 00500 batchs: 1563.0089111328125
INFO:root:Train (Epoch 11): Loss/seq after 00550 batchs: 1495.610595703125
INFO:root:Train (Epoch 11): Loss/seq after 00600 batchs: 1459.2479248046875
INFO:root:Train (Epoch 11): Loss/seq after 00650 batchs: 1521.6898193359375
INFO:root:Train (Epoch 11): Loss/seq after 00700 batchs: 1605.396484375
INFO:root:Train (Epoch 11): Loss/seq after 00750 batchs: 1644.31396484375
INFO:root:Train (Epoch 11): Loss/seq after 00800 batchs: 1627.3172607421875
INFO:root:Train (Epoch 11): Loss/seq after 00850 batchs: 1590.6734619140625
INFO:root:Train (Epoch 11): Loss/seq after 00900 batchs: 1592.6685791015625
INFO:root:Train (Epoch 11): Loss/seq after 00950 batchs: 1688.1678466796875
INFO:root:Train (Epoch 11): Loss/seq after 01000 batchs: 1688.354248046875
INFO:root:Train (Epoch 11): Loss/seq after 01050 batchs: 1663.203369140625
INFO:root:Train (Epoch 11): Loss/seq after 01100 batchs: 1645.694091796875
INFO:root:Train (Epoch 11): Loss/seq after 01150 batchs: 1617.6851806640625
INFO:root:Train (Epoch 11): Loss/seq after 01200 batchs: 1599.56640625
INFO:root:Train (Epoch 11): Loss/seq after 01250 batchs: 1589.8970947265625
INFO:root:Train (Epoch 11): Loss/seq after 01300 batchs: 1600.2138671875
INFO:root:Train (Epoch 11): Loss/seq after 01350 batchs: 1598.662841796875
INFO:root:Train (Epoch 11): Loss/seq after 01400 batchs: 1649.5084228515625
INFO:root:Train (Epoch 11): Loss/seq after 01450 batchs: 1631.87158203125
INFO:root:Train (Epoch 11): Loss/seq after 01500 batchs: 1613.2869873046875
INFO:root:Train (Epoch 11): Loss/seq after 01550 batchs: 1611.690185546875
INFO:root:Train (Epoch 11): Loss/seq after 01600 batchs: 1587.581787109375
INFO:root:Train (Epoch 11): Loss/seq after 01650 batchs: 1577.3006591796875
INFO:root:Train (Epoch 11): Loss/seq after 01700 batchs: 1562.3411865234375
INFO:root:Train (Epoch 11): Loss/seq after 01750 batchs: 1544.121826171875
INFO:root:Train (Epoch 11): Loss/seq after 01800 batchs: 1524.41064453125
INFO:root:Train (Epoch 11): Loss/seq after 01850 batchs: 1504.65625
INFO:root:Train (Epoch 11): Loss/seq after 01900 batchs: 1498.0665283203125
INFO:root:Train (Epoch 11): Loss/seq after 01950 batchs: 1488.1705322265625
INFO:root:Train (Epoch 11): Loss/seq after 02000 batchs: 1473.6907958984375
INFO:root:Train (Epoch 11): Loss/seq after 02050 batchs: 1461.0692138671875
INFO:root:Train (Epoch 11): Loss/seq after 02100 batchs: 1445.24072265625
INFO:root:Train (Epoch 11): Loss/seq after 02150 batchs: 1430.9991455078125
INFO:root:Train (Epoch 11): Loss/seq after 02200 batchs: 1415.615478515625
INFO:root:Train (Epoch 11): Loss/seq after 02250 batchs: 1417.2999267578125
INFO:root:Train (Epoch 11): Loss/seq after 02300 batchs: 1418.9666748046875
INFO:root:Train (Epoch 11): Loss/seq after 02350 batchs: 1406.72119140625
INFO:root:Train (Epoch 11): Loss/seq after 02400 batchs: 1399.6512451171875
INFO:root:Train (Epoch 11): Loss/seq after 02450 batchs: 1384.1214599609375
INFO:root:Train (Epoch 11): Loss/seq after 02500 batchs: 1363.8629150390625
INFO:root:Train (Epoch 11): Loss/seq after 02550 batchs: 1350.4844970703125
INFO:root:Train (Epoch 11): Loss/seq after 02600 batchs: 1347.969970703125
INFO:root:Train (Epoch 11): Loss/seq after 02650 batchs: 1341.045654296875
INFO:root:Train (Epoch 11): Loss/seq after 02700 batchs: 1336.68505859375
INFO:root:Train (Epoch 11): Loss/seq after 02750 batchs: 1366.4698486328125
INFO:root:Train (Epoch 11): Loss/seq after 02800 batchs: 1375.0814208984375
INFO:root:Train (Epoch 11): Loss/seq after 02850 batchs: 1371.35205078125
INFO:root:Train (Epoch 11): Loss/seq after 02900 batchs: 1368.527099609375
INFO:root:Train (Epoch 11): Loss/seq after 02950 batchs: 1359.160400390625
INFO:root:Train (Epoch 11): Loss/seq after 03000 batchs: 1354.6624755859375
INFO:root:Train (Epoch 11): Loss/seq after 03050 batchs: 1355.0621337890625
INFO:root:Train (Epoch 11): Loss/seq after 03100 batchs: 1370.911865234375
INFO:root:Train (Epoch 11): Loss/seq after 03150 batchs: 1389.46337890625
INFO:root:Train (Epoch 11): Loss/seq after 03200 batchs: 1402.56689453125
INFO:root:Train (Epoch 11): Loss/seq after 03250 batchs: 1414.6593017578125
INFO:root:Train (Epoch 11): Loss/seq after 03300 batchs: 1412.881591796875
INFO:root:Train (Epoch 11): Loss/seq after 03350 batchs: 1411.2474365234375
INFO:root:Train (Epoch 11): Loss/seq after 03400 batchs: 1400.2642822265625
INFO:root:Train (Epoch 11): Loss/seq after 03450 batchs: 1392.1068115234375
INFO:root:Train (Epoch 11): Loss/seq after 03500 batchs: 1390.4334716796875
INFO:root:Train (Epoch 11): Loss/seq after 03550 batchs: 1383.8507080078125
INFO:root:Train (Epoch 11): Loss/seq after 03600 batchs: 1387.836669921875
INFO:root:Train (Epoch 11): Loss/seq after 03650 batchs: 1382.2613525390625
INFO:root:Train (Epoch 11): Loss/seq after 03700 batchs: 1380.4410400390625
INFO:root:Train (Epoch 11): Loss/seq after 03750 batchs: 1378.24072265625
INFO:root:Train (Epoch 11): Loss/seq after 03800 batchs: 1369.3582763671875
INFO:root:Train (Epoch 11): Loss/seq after 03850 batchs: 1363.070068359375
INFO:root:Train (Epoch 11): Loss/seq after 03900 batchs: 1369.8890380859375
INFO:root:Train (Epoch 11): Loss/seq after 03950 batchs: 1378.2012939453125
INFO:root:Train (Epoch 11): Loss/seq after 04000 batchs: 1367.4063720703125
INFO:root:Train (Epoch 11): Loss/seq after 04050 batchs: 1357.597900390625
INFO:root:Train (Epoch 11): Loss/seq after 04100 batchs: 1352.2550048828125
INFO:root:Train (Epoch 11): Loss/seq after 04150 batchs: 1345.7490234375
INFO:root:Train (Epoch 11): Loss/seq after 04200 batchs: 1339.2894287109375
INFO:root:Train (Epoch 11): Loss/seq after 04250 batchs: 1333.5545654296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 11): Loss/seq after 00000 batches: 949.6643676757812
INFO:root:# Valid (Epoch 11): Loss/seq after 00050 batches: 1122.0400390625
INFO:root:# Valid (Epoch 11): Loss/seq after 00100 batches: 1467.2552490234375
INFO:root:# Valid (Epoch 11): Loss/seq after 00150 batches: 1232.0506591796875
INFO:root:# Valid (Epoch 11): Loss/seq after 00200 batches: 1121.3475341796875
INFO:root:Artifacts: Make stick videos for epoch 11
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_11_on_20220413_154755.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_11_index_547_on_20220413_154755.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 12): Loss/seq after 00000 batchs: 2541.46484375
INFO:root:Train (Epoch 12): Loss/seq after 00050 batchs: 1797.9896240234375
INFO:root:Train (Epoch 12): Loss/seq after 00100 batchs: 1727.365478515625
INFO:root:Train (Epoch 12): Loss/seq after 00150 batchs: 1527.7098388671875
INFO:root:Train (Epoch 12): Loss/seq after 00200 batchs: 1653.8292236328125
INFO:root:Train (Epoch 12): Loss/seq after 00250 batchs: 1768.648193359375
INFO:root:Train (Epoch 12): Loss/seq after 00300 batchs: 1660.5029296875
INFO:root:Train (Epoch 12): Loss/seq after 00350 batchs: 1549.7567138671875
INFO:root:Train (Epoch 12): Loss/seq after 00400 batchs: 1615.140625
INFO:root:Train (Epoch 12): Loss/seq after 00450 batchs: 1533.4010009765625
INFO:root:Train (Epoch 12): Loss/seq after 00500 batchs: 1563.89794921875
INFO:root:Train (Epoch 12): Loss/seq after 00550 batchs: 1496.827880859375
INFO:root:Train (Epoch 12): Loss/seq after 00600 batchs: 1460.2108154296875
INFO:root:Train (Epoch 12): Loss/seq after 00650 batchs: 1520.2691650390625
INFO:root:Train (Epoch 12): Loss/seq after 00700 batchs: 1603.808837890625
INFO:root:Train (Epoch 12): Loss/seq after 00750 batchs: 1641.2222900390625
INFO:root:Train (Epoch 12): Loss/seq after 00800 batchs: 1624.4560546875
INFO:root:Train (Epoch 12): Loss/seq after 00850 batchs: 1587.3948974609375
INFO:root:Train (Epoch 12): Loss/seq after 00900 batchs: 1587.7884521484375
INFO:root:Train (Epoch 12): Loss/seq after 00950 batchs: 1684.2281494140625
INFO:root:Train (Epoch 12): Loss/seq after 01000 batchs: 1684.1612548828125
INFO:root:Train (Epoch 12): Loss/seq after 01050 batchs: 1660.580810546875
INFO:root:Train (Epoch 12): Loss/seq after 01100 batchs: 1645.45166015625
INFO:root:Train (Epoch 12): Loss/seq after 01150 batchs: 1617.230224609375
INFO:root:Train (Epoch 12): Loss/seq after 01200 batchs: 1596.614013671875
INFO:root:Train (Epoch 12): Loss/seq after 01250 batchs: 1585.49755859375
INFO:root:Train (Epoch 12): Loss/seq after 01300 batchs: 1596.6043701171875
INFO:root:Train (Epoch 12): Loss/seq after 01350 batchs: 1595.5538330078125
INFO:root:Train (Epoch 12): Loss/seq after 01400 batchs: 1645.2003173828125
INFO:root:Train (Epoch 12): Loss/seq after 01450 batchs: 1625.740966796875
INFO:root:Train (Epoch 12): Loss/seq after 01500 batchs: 1607.4586181640625
INFO:root:Train (Epoch 12): Loss/seq after 01550 batchs: 1603.9691162109375
INFO:root:Train (Epoch 12): Loss/seq after 01600 batchs: 1579.3856201171875
INFO:root:Train (Epoch 12): Loss/seq after 01650 batchs: 1567.3709716796875
INFO:root:Train (Epoch 12): Loss/seq after 01700 batchs: 1551.7747802734375
INFO:root:Train (Epoch 12): Loss/seq after 01750 batchs: 1533.28564453125
INFO:root:Train (Epoch 12): Loss/seq after 01800 batchs: 1513.1995849609375
INFO:root:Train (Epoch 12): Loss/seq after 01850 batchs: 1493.8551025390625
INFO:root:Train (Epoch 12): Loss/seq after 01900 batchs: 1487.4215087890625
INFO:root:Train (Epoch 12): Loss/seq after 01950 batchs: 1477.6837158203125
INFO:root:Train (Epoch 12): Loss/seq after 02000 batchs: 1463.167236328125
INFO:root:Train (Epoch 12): Loss/seq after 02050 batchs: 1450.6910400390625
INFO:root:Train (Epoch 12): Loss/seq after 02100 batchs: 1435.05810546875
INFO:root:Train (Epoch 12): Loss/seq after 02150 batchs: 1420.840087890625
INFO:root:Train (Epoch 12): Loss/seq after 02200 batchs: 1405.667236328125
INFO:root:Train (Epoch 12): Loss/seq after 02250 batchs: 1407.524169921875
INFO:root:Train (Epoch 12): Loss/seq after 02300 batchs: 1409.5234375
INFO:root:Train (Epoch 12): Loss/seq after 02350 batchs: 1397.5306396484375
INFO:root:Train (Epoch 12): Loss/seq after 02400 batchs: 1390.858642578125
INFO:root:Train (Epoch 12): Loss/seq after 02450 batchs: 1375.989990234375
INFO:root:Train (Epoch 12): Loss/seq after 02500 batchs: 1356.037841796875
INFO:root:Train (Epoch 12): Loss/seq after 02550 batchs: 1342.71240234375
INFO:root:Train (Epoch 12): Loss/seq after 02600 batchs: 1338.885986328125
INFO:root:Train (Epoch 12): Loss/seq after 02650 batchs: 1331.770751953125
INFO:root:Train (Epoch 12): Loss/seq after 02700 batchs: 1327.398193359375
INFO:root:Train (Epoch 12): Loss/seq after 02750 batchs: 1356.9609375
INFO:root:Train (Epoch 12): Loss/seq after 02800 batchs: 1365.3028564453125
INFO:root:Train (Epoch 12): Loss/seq after 02850 batchs: 1361.537841796875
INFO:root:Train (Epoch 12): Loss/seq after 02900 batchs: 1358.2115478515625
INFO:root:Train (Epoch 12): Loss/seq after 02950 batchs: 1348.8482666015625
INFO:root:Train (Epoch 12): Loss/seq after 03000 batchs: 1344.5155029296875
INFO:root:Train (Epoch 12): Loss/seq after 03050 batchs: 1345.1046142578125
INFO:root:Train (Epoch 12): Loss/seq after 03100 batchs: 1361.03173828125
INFO:root:Train (Epoch 12): Loss/seq after 03150 batchs: 1379.5714111328125
INFO:root:Train (Epoch 12): Loss/seq after 03200 batchs: 1392.6160888671875
INFO:root:Train (Epoch 12): Loss/seq after 03250 batchs: 1405.2982177734375
INFO:root:Train (Epoch 12): Loss/seq after 03300 batchs: 1403.4864501953125
INFO:root:Train (Epoch 12): Loss/seq after 03350 batchs: 1401.637451171875
INFO:root:Train (Epoch 12): Loss/seq after 03400 batchs: 1390.56982421875
INFO:root:Train (Epoch 12): Loss/seq after 03450 batchs: 1381.766357421875
INFO:root:Train (Epoch 12): Loss/seq after 03500 batchs: 1380.209228515625
INFO:root:Train (Epoch 12): Loss/seq after 03550 batchs: 1373.6763916015625
INFO:root:Train (Epoch 12): Loss/seq after 03600 batchs: 1377.7542724609375
INFO:root:Train (Epoch 12): Loss/seq after 03650 batchs: 1372.3116455078125
INFO:root:Train (Epoch 12): Loss/seq after 03700 batchs: 1370.700439453125
INFO:root:Train (Epoch 12): Loss/seq after 03750 batchs: 1368.6959228515625
INFO:root:Train (Epoch 12): Loss/seq after 03800 batchs: 1359.9615478515625
INFO:root:Train (Epoch 12): Loss/seq after 03850 batchs: 1353.84814453125
INFO:root:Train (Epoch 12): Loss/seq after 03900 batchs: 1360.943359375
INFO:root:Train (Epoch 12): Loss/seq after 03950 batchs: 1369.8140869140625
INFO:root:Train (Epoch 12): Loss/seq after 04000 batchs: 1359.1055908203125
INFO:root:Train (Epoch 12): Loss/seq after 04050 batchs: 1349.39599609375
INFO:root:Train (Epoch 12): Loss/seq after 04100 batchs: 1344.0804443359375
INFO:root:Train (Epoch 12): Loss/seq after 04150 batchs: 1337.660400390625
INFO:root:Train (Epoch 12): Loss/seq after 04200 batchs: 1331.5389404296875
INFO:root:Train (Epoch 12): Loss/seq after 04250 batchs: 1325.7982177734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 12): Loss/seq after 00000 batches: 944.0223999023438
INFO:root:# Valid (Epoch 12): Loss/seq after 00050 batches: 1118.3411865234375
INFO:root:# Valid (Epoch 12): Loss/seq after 00100 batches: 1468.2852783203125
INFO:root:# Valid (Epoch 12): Loss/seq after 00150 batches: 1236.274658203125
INFO:root:# Valid (Epoch 12): Loss/seq after 00200 batches: 1126.9578857421875
INFO:root:Artifacts: Make stick videos for epoch 12
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_12_on_20220413_155312.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_12_index_716_on_20220413_155312.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 13): Loss/seq after 00000 batchs: 2400.2802734375
INFO:root:Train (Epoch 13): Loss/seq after 00050 batchs: 1794.4215087890625
INFO:root:Train (Epoch 13): Loss/seq after 00100 batchs: 1735.447265625
INFO:root:Train (Epoch 13): Loss/seq after 00150 batchs: 1562.341552734375
INFO:root:Train (Epoch 13): Loss/seq after 00200 batchs: 1679.753173828125
INFO:root:Train (Epoch 13): Loss/seq after 00250 batchs: 1786.8509521484375
INFO:root:Train (Epoch 13): Loss/seq after 00300 batchs: 1677.1683349609375
INFO:root:Train (Epoch 13): Loss/seq after 00350 batchs: 1564.416259765625
INFO:root:Train (Epoch 13): Loss/seq after 00400 batchs: 1628.3736572265625
INFO:root:Train (Epoch 13): Loss/seq after 00450 batchs: 1545.49462890625
INFO:root:Train (Epoch 13): Loss/seq after 00500 batchs: 1577.142822265625
INFO:root:Train (Epoch 13): Loss/seq after 00550 batchs: 1509.159912109375
INFO:root:Train (Epoch 13): Loss/seq after 00600 batchs: 1473.074951171875
INFO:root:Train (Epoch 13): Loss/seq after 00650 batchs: 1537.6715087890625
INFO:root:Train (Epoch 13): Loss/seq after 00700 batchs: 1621.5062255859375
INFO:root:Train (Epoch 13): Loss/seq after 00750 batchs: 1662.3843994140625
INFO:root:Train (Epoch 13): Loss/seq after 00800 batchs: 1643.7354736328125
INFO:root:Train (Epoch 13): Loss/seq after 00850 batchs: 1605.2401123046875
INFO:root:Train (Epoch 13): Loss/seq after 00900 batchs: 1602.54443359375
INFO:root:Train (Epoch 13): Loss/seq after 00950 batchs: 1700.751220703125
INFO:root:Train (Epoch 13): Loss/seq after 01000 batchs: 1702.0750732421875
INFO:root:Train (Epoch 13): Loss/seq after 01050 batchs: 1676.25390625
INFO:root:Train (Epoch 13): Loss/seq after 01100 batchs: 1658.0523681640625
INFO:root:Train (Epoch 13): Loss/seq after 01150 batchs: 1628.9412841796875
INFO:root:Train (Epoch 13): Loss/seq after 01200 batchs: 1607.7642822265625
INFO:root:Train (Epoch 13): Loss/seq after 01250 batchs: 1597.065185546875
INFO:root:Train (Epoch 13): Loss/seq after 01300 batchs: 1607.33642578125
INFO:root:Train (Epoch 13): Loss/seq after 01350 batchs: 1605.80419921875
INFO:root:Train (Epoch 13): Loss/seq after 01400 batchs: 1655.877685546875
INFO:root:Train (Epoch 13): Loss/seq after 01450 batchs: 1636.3797607421875
INFO:root:Train (Epoch 13): Loss/seq after 01500 batchs: 1618.1995849609375
INFO:root:Train (Epoch 13): Loss/seq after 01550 batchs: 1614.5963134765625
INFO:root:Train (Epoch 13): Loss/seq after 01600 batchs: 1590.014404296875
INFO:root:Train (Epoch 13): Loss/seq after 01650 batchs: 1578.1651611328125
INFO:root:Train (Epoch 13): Loss/seq after 01700 batchs: 1563.0137939453125
INFO:root:Train (Epoch 13): Loss/seq after 01750 batchs: 1544.7742919921875
INFO:root:Train (Epoch 13): Loss/seq after 01800 batchs: 1524.986572265625
INFO:root:Train (Epoch 13): Loss/seq after 01850 batchs: 1505.2215576171875
INFO:root:Train (Epoch 13): Loss/seq after 01900 batchs: 1498.6756591796875
INFO:root:Train (Epoch 13): Loss/seq after 01950 batchs: 1488.555908203125
INFO:root:Train (Epoch 13): Loss/seq after 02000 batchs: 1474.06689453125
INFO:root:Train (Epoch 13): Loss/seq after 02050 batchs: 1461.384765625
INFO:root:Train (Epoch 13): Loss/seq after 02100 batchs: 1445.5582275390625
INFO:root:Train (Epoch 13): Loss/seq after 02150 batchs: 1431.4324951171875
INFO:root:Train (Epoch 13): Loss/seq after 02200 batchs: 1416.03857421875
INFO:root:Train (Epoch 13): Loss/seq after 02250 batchs: 1417.6556396484375
INFO:root:Train (Epoch 13): Loss/seq after 02300 batchs: 1419.57958984375
INFO:root:Train (Epoch 13): Loss/seq after 02350 batchs: 1407.208251953125
INFO:root:Train (Epoch 13): Loss/seq after 02400 batchs: 1400.1575927734375
INFO:root:Train (Epoch 13): Loss/seq after 02450 batchs: 1384.53662109375
INFO:root:Train (Epoch 13): Loss/seq after 02500 batchs: 1364.1912841796875
INFO:root:Train (Epoch 13): Loss/seq after 02550 batchs: 1350.5882568359375
INFO:root:Train (Epoch 13): Loss/seq after 02600 batchs: 1346.3887939453125
INFO:root:Train (Epoch 13): Loss/seq after 02650 batchs: 1339.34033203125
INFO:root:Train (Epoch 13): Loss/seq after 02700 batchs: 1335.4862060546875
INFO:root:Train (Epoch 13): Loss/seq after 02750 batchs: 1364.855712890625
INFO:root:Train (Epoch 13): Loss/seq after 02800 batchs: 1372.9927978515625
INFO:root:Train (Epoch 13): Loss/seq after 02850 batchs: 1368.8497314453125
INFO:root:Train (Epoch 13): Loss/seq after 02900 batchs: 1365.1602783203125
INFO:root:Train (Epoch 13): Loss/seq after 02950 batchs: 1355.362548828125
INFO:root:Train (Epoch 13): Loss/seq after 03000 batchs: 1350.8916015625
INFO:root:Train (Epoch 13): Loss/seq after 03050 batchs: 1351.338134765625
INFO:root:Train (Epoch 13): Loss/seq after 03100 batchs: 1367.472412109375
INFO:root:Train (Epoch 13): Loss/seq after 03150 batchs: 1386.4376220703125
INFO:root:Train (Epoch 13): Loss/seq after 03200 batchs: 1400.0997314453125
INFO:root:Train (Epoch 13): Loss/seq after 03250 batchs: 1412.6151123046875
INFO:root:Train (Epoch 13): Loss/seq after 03300 batchs: 1411.4979248046875
INFO:root:Train (Epoch 13): Loss/seq after 03350 batchs: 1409.7008056640625
INFO:root:Train (Epoch 13): Loss/seq after 03400 batchs: 1398.65380859375
INFO:root:Train (Epoch 13): Loss/seq after 03450 batchs: 1390.1229248046875
INFO:root:Train (Epoch 13): Loss/seq after 03500 batchs: 1388.6207275390625
INFO:root:Train (Epoch 13): Loss/seq after 03550 batchs: 1382.1455078125
INFO:root:Train (Epoch 13): Loss/seq after 03600 batchs: 1386.0211181640625
INFO:root:Train (Epoch 13): Loss/seq after 03650 batchs: 1380.052734375
INFO:root:Train (Epoch 13): Loss/seq after 03700 batchs: 1377.9345703125
INFO:root:Train (Epoch 13): Loss/seq after 03750 batchs: 1375.7935791015625
INFO:root:Train (Epoch 13): Loss/seq after 03800 batchs: 1366.9608154296875
INFO:root:Train (Epoch 13): Loss/seq after 03850 batchs: 1360.6566162109375
INFO:root:Train (Epoch 13): Loss/seq after 03900 batchs: 1367.5572509765625
INFO:root:Train (Epoch 13): Loss/seq after 03950 batchs: 1375.500244140625
INFO:root:Train (Epoch 13): Loss/seq after 04000 batchs: 1364.6876220703125
INFO:root:Train (Epoch 13): Loss/seq after 04050 batchs: 1354.8985595703125
INFO:root:Train (Epoch 13): Loss/seq after 04100 batchs: 1349.3031005859375
INFO:root:Train (Epoch 13): Loss/seq after 04150 batchs: 1342.59521484375
INFO:root:Train (Epoch 13): Loss/seq after 04200 batchs: 1336.3243408203125
INFO:root:Train (Epoch 13): Loss/seq after 04250 batchs: 1330.5428466796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 13): Loss/seq after 00000 batches: 929.3015747070312
INFO:root:# Valid (Epoch 13): Loss/seq after 00050 batches: 1115.0626220703125
INFO:root:# Valid (Epoch 13): Loss/seq after 00100 batches: 1450.1966552734375
INFO:root:# Valid (Epoch 13): Loss/seq after 00150 batches: 1219.7281494140625
INFO:root:# Valid (Epoch 13): Loss/seq after 00200 batches: 1114.9822998046875
INFO:root:Artifacts: Make stick videos for epoch 13
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_13_on_20220413_155831.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_13_index_628_on_20220413_155831.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 14): Loss/seq after 00000 batchs: 2533.065673828125
INFO:root:Train (Epoch 14): Loss/seq after 00050 batchs: 1783.8497314453125
INFO:root:Train (Epoch 14): Loss/seq after 00100 batchs: 1732.8978271484375
INFO:root:Train (Epoch 14): Loss/seq after 00150 batchs: 1537.1727294921875
INFO:root:Train (Epoch 14): Loss/seq after 00200 batchs: 1657.0511474609375
INFO:root:Train (Epoch 14): Loss/seq after 00250 batchs: 1770.2421875
INFO:root:Train (Epoch 14): Loss/seq after 00300 batchs: 1661.505859375
INFO:root:Train (Epoch 14): Loss/seq after 00350 batchs: 1550.5396728515625
INFO:root:Train (Epoch 14): Loss/seq after 00400 batchs: 1612.5872802734375
INFO:root:Train (Epoch 14): Loss/seq after 00450 batchs: 1531.2691650390625
INFO:root:Train (Epoch 14): Loss/seq after 00500 batchs: 1562.875732421875
INFO:root:Train (Epoch 14): Loss/seq after 00550 batchs: 1496.31640625
INFO:root:Train (Epoch 14): Loss/seq after 00600 batchs: 1459.281005859375
INFO:root:Train (Epoch 14): Loss/seq after 00650 batchs: 1519.7022705078125
INFO:root:Train (Epoch 14): Loss/seq after 00700 batchs: 1603.8494873046875
INFO:root:Train (Epoch 14): Loss/seq after 00750 batchs: 1640.049072265625
INFO:root:Train (Epoch 14): Loss/seq after 00800 batchs: 1623.1043701171875
INFO:root:Train (Epoch 14): Loss/seq after 00850 batchs: 1586.7943115234375
INFO:root:Train (Epoch 14): Loss/seq after 00900 batchs: 1585.42626953125
INFO:root:Train (Epoch 14): Loss/seq after 00950 batchs: 1681.4388427734375
INFO:root:Train (Epoch 14): Loss/seq after 01000 batchs: 1681.38427734375
INFO:root:Train (Epoch 14): Loss/seq after 01050 batchs: 1656.4151611328125
INFO:root:Train (Epoch 14): Loss/seq after 01100 batchs: 1639.24951171875
INFO:root:Train (Epoch 14): Loss/seq after 01150 batchs: 1611.00390625
INFO:root:Train (Epoch 14): Loss/seq after 01200 batchs: 1590.2366943359375
INFO:root:Train (Epoch 14): Loss/seq after 01250 batchs: 1579.0218505859375
INFO:root:Train (Epoch 14): Loss/seq after 01300 batchs: 1589.8956298828125
INFO:root:Train (Epoch 14): Loss/seq after 01350 batchs: 1588.998779296875
INFO:root:Train (Epoch 14): Loss/seq after 01400 batchs: 1638.712890625
INFO:root:Train (Epoch 14): Loss/seq after 01450 batchs: 1619.158447265625
INFO:root:Train (Epoch 14): Loss/seq after 01500 batchs: 1600.9322509765625
INFO:root:Train (Epoch 14): Loss/seq after 01550 batchs: 1598.36767578125
INFO:root:Train (Epoch 14): Loss/seq after 01600 batchs: 1574.09814453125
INFO:root:Train (Epoch 14): Loss/seq after 01650 batchs: 1562.092041015625
INFO:root:Train (Epoch 14): Loss/seq after 01700 batchs: 1546.7479248046875
INFO:root:Train (Epoch 14): Loss/seq after 01750 batchs: 1528.42431640625
INFO:root:Train (Epoch 14): Loss/seq after 01800 batchs: 1508.48583984375
INFO:root:Train (Epoch 14): Loss/seq after 01850 batchs: 1489.245849609375
INFO:root:Train (Epoch 14): Loss/seq after 01900 batchs: 1482.9688720703125
INFO:root:Train (Epoch 14): Loss/seq after 01950 batchs: 1473.40380859375
INFO:root:Train (Epoch 14): Loss/seq after 02000 batchs: 1459.00146484375
INFO:root:Train (Epoch 14): Loss/seq after 02050 batchs: 1446.58154296875
INFO:root:Train (Epoch 14): Loss/seq after 02100 batchs: 1430.9476318359375
INFO:root:Train (Epoch 14): Loss/seq after 02150 batchs: 1416.760009765625
INFO:root:Train (Epoch 14): Loss/seq after 02200 batchs: 1401.645263671875
INFO:root:Train (Epoch 14): Loss/seq after 02250 batchs: 1403.8121337890625
INFO:root:Train (Epoch 14): Loss/seq after 02300 batchs: 1405.85888671875
INFO:root:Train (Epoch 14): Loss/seq after 02350 batchs: 1393.8480224609375
INFO:root:Train (Epoch 14): Loss/seq after 02400 batchs: 1387.2130126953125
INFO:root:Train (Epoch 14): Loss/seq after 02450 batchs: 1372.0958251953125
INFO:root:Train (Epoch 14): Loss/seq after 02500 batchs: 1352.015625
INFO:root:Train (Epoch 14): Loss/seq after 02550 batchs: 1338.6630859375
INFO:root:Train (Epoch 14): Loss/seq after 02600 batchs: 1334.40380859375
INFO:root:Train (Epoch 14): Loss/seq after 02650 batchs: 1327.38427734375
INFO:root:Train (Epoch 14): Loss/seq after 02700 batchs: 1323.380615234375
INFO:root:Train (Epoch 14): Loss/seq after 02750 batchs: 1353.2899169921875
INFO:root:Train (Epoch 14): Loss/seq after 02800 batchs: 1361.55517578125
INFO:root:Train (Epoch 14): Loss/seq after 02850 batchs: 1357.6785888671875
INFO:root:Train (Epoch 14): Loss/seq after 02900 batchs: 1354.5032958984375
INFO:root:Train (Epoch 14): Loss/seq after 02950 batchs: 1345.2071533203125
INFO:root:Train (Epoch 14): Loss/seq after 03000 batchs: 1340.9310302734375
INFO:root:Train (Epoch 14): Loss/seq after 03050 batchs: 1341.576904296875
INFO:root:Train (Epoch 14): Loss/seq after 03100 batchs: 1357.25390625
INFO:root:Train (Epoch 14): Loss/seq after 03150 batchs: 1375.68896484375
INFO:root:Train (Epoch 14): Loss/seq after 03200 batchs: 1388.52490234375
INFO:root:Train (Epoch 14): Loss/seq after 03250 batchs: 1401.099609375
INFO:root:Train (Epoch 14): Loss/seq after 03300 batchs: 1399.39794921875
INFO:root:Train (Epoch 14): Loss/seq after 03350 batchs: 1397.7462158203125
INFO:root:Train (Epoch 14): Loss/seq after 03400 batchs: 1386.8699951171875
INFO:root:Train (Epoch 14): Loss/seq after 03450 batchs: 1378.4874267578125
INFO:root:Train (Epoch 14): Loss/seq after 03500 batchs: 1376.9501953125
INFO:root:Train (Epoch 14): Loss/seq after 03550 batchs: 1370.79052734375
INFO:root:Train (Epoch 14): Loss/seq after 03600 batchs: 1374.879150390625
INFO:root:Train (Epoch 14): Loss/seq after 03650 batchs: 1369.01904296875
INFO:root:Train (Epoch 14): Loss/seq after 03700 batchs: 1366.892578125
INFO:root:Train (Epoch 14): Loss/seq after 03750 batchs: 1364.90380859375
INFO:root:Train (Epoch 14): Loss/seq after 03800 batchs: 1356.1478271484375
INFO:root:Train (Epoch 14): Loss/seq after 03850 batchs: 1349.98388671875
INFO:root:Train (Epoch 14): Loss/seq after 03900 batchs: 1356.841796875
INFO:root:Train (Epoch 14): Loss/seq after 03950 batchs: 1364.7208251953125
INFO:root:Train (Epoch 14): Loss/seq after 04000 batchs: 1354.019287109375
INFO:root:Train (Epoch 14): Loss/seq after 04050 batchs: 1344.3541259765625
INFO:root:Train (Epoch 14): Loss/seq after 04100 batchs: 1338.4835205078125
INFO:root:Train (Epoch 14): Loss/seq after 04150 batchs: 1331.47607421875
INFO:root:Train (Epoch 14): Loss/seq after 04200 batchs: 1325.2662353515625
INFO:root:Train (Epoch 14): Loss/seq after 04250 batchs: 1319.4837646484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 14): Loss/seq after 00000 batches: 913.5816040039062
INFO:root:# Valid (Epoch 14): Loss/seq after 00050 batches: 1111.0084228515625
INFO:root:# Valid (Epoch 14): Loss/seq after 00100 batches: 1446.110107421875
INFO:root:# Valid (Epoch 14): Loss/seq after 00150 batches: 1235.1121826171875
INFO:root:# Valid (Epoch 14): Loss/seq after 00200 batches: 1136.1414794921875
INFO:root:Artifacts: Make stick videos for epoch 14
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_14_on_20220413_160351.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_14_index_854_on_20220413_160351.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 15): Loss/seq after 00000 batchs: 2386.87890625
INFO:root:Train (Epoch 15): Loss/seq after 00050 batchs: 1774.0460205078125
INFO:root:Train (Epoch 15): Loss/seq after 00100 batchs: 1708.32568359375
INFO:root:Train (Epoch 15): Loss/seq after 00150 batchs: 1513.1434326171875
INFO:root:Train (Epoch 15): Loss/seq after 00200 batchs: 1638.586669921875
INFO:root:Train (Epoch 15): Loss/seq after 00250 batchs: 1749.326416015625
INFO:root:Train (Epoch 15): Loss/seq after 00300 batchs: 1643.7821044921875
INFO:root:Train (Epoch 15): Loss/seq after 00350 batchs: 1534.6064453125
INFO:root:Train (Epoch 15): Loss/seq after 00400 batchs: 1597.1724853515625
INFO:root:Train (Epoch 15): Loss/seq after 00450 batchs: 1517.611328125
INFO:root:Train (Epoch 15): Loss/seq after 00500 batchs: 1549.4808349609375
INFO:root:Train (Epoch 15): Loss/seq after 00550 batchs: 1484.641845703125
INFO:root:Train (Epoch 15): Loss/seq after 00600 batchs: 1449.3546142578125
INFO:root:Train (Epoch 15): Loss/seq after 00650 batchs: 1510.0726318359375
INFO:root:Train (Epoch 15): Loss/seq after 00700 batchs: 1593.8585205078125
INFO:root:Train (Epoch 15): Loss/seq after 00750 batchs: 1628.2227783203125
INFO:root:Train (Epoch 15): Loss/seq after 00800 batchs: 1611.97314453125
INFO:root:Train (Epoch 15): Loss/seq after 00850 batchs: 1574.772705078125
INFO:root:Train (Epoch 15): Loss/seq after 00900 batchs: 1574.0897216796875
INFO:root:Train (Epoch 15): Loss/seq after 00950 batchs: 1667.9173583984375
INFO:root:Train (Epoch 15): Loss/seq after 01000 batchs: 1667.1827392578125
INFO:root:Train (Epoch 15): Loss/seq after 01050 batchs: 1641.718994140625
INFO:root:Train (Epoch 15): Loss/seq after 01100 batchs: 1626.2979736328125
INFO:root:Train (Epoch 15): Loss/seq after 01150 batchs: 1599.996337890625
INFO:root:Train (Epoch 15): Loss/seq after 01200 batchs: 1580.1109619140625
INFO:root:Train (Epoch 15): Loss/seq after 01250 batchs: 1568.9364013671875
INFO:root:Train (Epoch 15): Loss/seq after 01300 batchs: 1579.9766845703125
INFO:root:Train (Epoch 15): Loss/seq after 01350 batchs: 1579.3983154296875
INFO:root:Train (Epoch 15): Loss/seq after 01400 batchs: 1629.64599609375
INFO:root:Train (Epoch 15): Loss/seq after 01450 batchs: 1610.4169921875
INFO:root:Train (Epoch 15): Loss/seq after 01500 batchs: 1592.631103515625
INFO:root:Train (Epoch 15): Loss/seq after 01550 batchs: 1589.7215576171875
INFO:root:Train (Epoch 15): Loss/seq after 01600 batchs: 1565.283935546875
INFO:root:Train (Epoch 15): Loss/seq after 01650 batchs: 1553.4912109375
INFO:root:Train (Epoch 15): Loss/seq after 01700 batchs: 1538.0140380859375
INFO:root:Train (Epoch 15): Loss/seq after 01750 batchs: 1519.9393310546875
INFO:root:Train (Epoch 15): Loss/seq after 01800 batchs: 1500.273681640625
INFO:root:Train (Epoch 15): Loss/seq after 01850 batchs: 1481.28955078125
INFO:root:Train (Epoch 15): Loss/seq after 01900 batchs: 1475.181640625
INFO:root:Train (Epoch 15): Loss/seq after 01950 batchs: 1465.7620849609375
INFO:root:Train (Epoch 15): Loss/seq after 02000 batchs: 1451.640625
INFO:root:Train (Epoch 15): Loss/seq after 02050 batchs: 1439.4761962890625
INFO:root:Train (Epoch 15): Loss/seq after 02100 batchs: 1424.09912109375
INFO:root:Train (Epoch 15): Loss/seq after 02150 batchs: 1410.10205078125
INFO:root:Train (Epoch 15): Loss/seq after 02200 batchs: 1395.1185302734375
INFO:root:Train (Epoch 15): Loss/seq after 02250 batchs: 1397.020751953125
INFO:root:Train (Epoch 15): Loss/seq after 02300 batchs: 1399.224609375
INFO:root:Train (Epoch 15): Loss/seq after 02350 batchs: 1387.1876220703125
INFO:root:Train (Epoch 15): Loss/seq after 02400 batchs: 1380.4708251953125
INFO:root:Train (Epoch 15): Loss/seq after 02450 batchs: 1365.030029296875
INFO:root:Train (Epoch 15): Loss/seq after 02500 batchs: 1345.01708984375
INFO:root:Train (Epoch 15): Loss/seq after 02550 batchs: 1332.0323486328125
INFO:root:Train (Epoch 15): Loss/seq after 02600 batchs: 1327.865234375
INFO:root:Train (Epoch 15): Loss/seq after 02650 batchs: 1321.401123046875
INFO:root:Train (Epoch 15): Loss/seq after 02700 batchs: 1317.5479736328125
INFO:root:Train (Epoch 15): Loss/seq after 02750 batchs: 1347.545166015625
INFO:root:Train (Epoch 15): Loss/seq after 02800 batchs: 1355.876953125
INFO:root:Train (Epoch 15): Loss/seq after 02850 batchs: 1352.06005859375
INFO:root:Train (Epoch 15): Loss/seq after 02900 batchs: 1348.87158203125
INFO:root:Train (Epoch 15): Loss/seq after 02950 batchs: 1339.666259765625
INFO:root:Train (Epoch 15): Loss/seq after 03000 batchs: 1335.4803466796875
INFO:root:Train (Epoch 15): Loss/seq after 03050 batchs: 1336.2161865234375
INFO:root:Train (Epoch 15): Loss/seq after 03100 batchs: 1351.9156494140625
INFO:root:Train (Epoch 15): Loss/seq after 03150 batchs: 1370.4873046875
INFO:root:Train (Epoch 15): Loss/seq after 03200 batchs: 1383.5267333984375
INFO:root:Train (Epoch 15): Loss/seq after 03250 batchs: 1395.6728515625
INFO:root:Train (Epoch 15): Loss/seq after 03300 batchs: 1393.1776123046875
INFO:root:Train (Epoch 15): Loss/seq after 03350 batchs: 1391.4608154296875
INFO:root:Train (Epoch 15): Loss/seq after 03400 batchs: 1380.5655517578125
INFO:root:Train (Epoch 15): Loss/seq after 03450 batchs: 1372.1561279296875
INFO:root:Train (Epoch 15): Loss/seq after 03500 batchs: 1370.732177734375
INFO:root:Train (Epoch 15): Loss/seq after 03550 batchs: 1364.3255615234375
INFO:root:Train (Epoch 15): Loss/seq after 03600 batchs: 1368.463623046875
INFO:root:Train (Epoch 15): Loss/seq after 03650 batchs: 1362.77490234375
INFO:root:Train (Epoch 15): Loss/seq after 03700 batchs: 1360.85009765625
INFO:root:Train (Epoch 15): Loss/seq after 03750 batchs: 1358.962890625
INFO:root:Train (Epoch 15): Loss/seq after 03800 batchs: 1350.3106689453125
INFO:root:Train (Epoch 15): Loss/seq after 03850 batchs: 1344.2552490234375
INFO:root:Train (Epoch 15): Loss/seq after 03900 batchs: 1350.9918212890625
INFO:root:Train (Epoch 15): Loss/seq after 03950 batchs: 1359.563720703125
INFO:root:Train (Epoch 15): Loss/seq after 04000 batchs: 1348.90087890625
INFO:root:Train (Epoch 15): Loss/seq after 04050 batchs: 1339.2943115234375
INFO:root:Train (Epoch 15): Loss/seq after 04100 batchs: 1333.34814453125
INFO:root:Train (Epoch 15): Loss/seq after 04150 batchs: 1326.2415771484375
INFO:root:Train (Epoch 15): Loss/seq after 04200 batchs: 1319.9833984375
INFO:root:Train (Epoch 15): Loss/seq after 04250 batchs: 1314.411376953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 15): Loss/seq after 00000 batches: 910.5890502929688
INFO:root:# Valid (Epoch 15): Loss/seq after 00050 batches: 1107.94775390625
INFO:root:# Valid (Epoch 15): Loss/seq after 00100 batches: 1435.09375
INFO:root:# Valid (Epoch 15): Loss/seq after 00150 batches: 1170.803955078125
INFO:root:# Valid (Epoch 15): Loss/seq after 00200 batches: 1061.14208984375
INFO:root:Artifacts: Make stick videos for epoch 15
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_15_on_20220413_160910.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_15_index_1108_on_20220413_160910.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 16): Loss/seq after 00000 batchs: 2450.788330078125
INFO:root:Train (Epoch 16): Loss/seq after 00050 batchs: 1795.865234375
INFO:root:Train (Epoch 16): Loss/seq after 00100 batchs: 1735.144775390625
INFO:root:Train (Epoch 16): Loss/seq after 00150 batchs: 1540.830322265625
INFO:root:Train (Epoch 16): Loss/seq after 00200 batchs: 1661.385009765625
INFO:root:Train (Epoch 16): Loss/seq after 00250 batchs: 1774.9384765625
INFO:root:Train (Epoch 16): Loss/seq after 00300 batchs: 1665.354248046875
INFO:root:Train (Epoch 16): Loss/seq after 00350 batchs: 1553.7333984375
INFO:root:Train (Epoch 16): Loss/seq after 00400 batchs: 1617.5103759765625
INFO:root:Train (Epoch 16): Loss/seq after 00450 batchs: 1535.477783203125
INFO:root:Train (Epoch 16): Loss/seq after 00500 batchs: 1567.3638916015625
INFO:root:Train (Epoch 16): Loss/seq after 00550 batchs: 1499.7147216796875
INFO:root:Train (Epoch 16): Loss/seq after 00600 batchs: 1461.9222412109375
INFO:root:Train (Epoch 16): Loss/seq after 00650 batchs: 1522.8133544921875
INFO:root:Train (Epoch 16): Loss/seq after 00700 batchs: 1607.2537841796875
INFO:root:Train (Epoch 16): Loss/seq after 00750 batchs: 1642.4483642578125
INFO:root:Train (Epoch 16): Loss/seq after 00800 batchs: 1624.87890625
INFO:root:Train (Epoch 16): Loss/seq after 00850 batchs: 1586.718994140625
INFO:root:Train (Epoch 16): Loss/seq after 00900 batchs: 1585.3480224609375
INFO:root:Train (Epoch 16): Loss/seq after 00950 batchs: 1679.2171630859375
INFO:root:Train (Epoch 16): Loss/seq after 01000 batchs: 1676.7991943359375
INFO:root:Train (Epoch 16): Loss/seq after 01050 batchs: 1650.3887939453125
INFO:root:Train (Epoch 16): Loss/seq after 01100 batchs: 1634.0469970703125
INFO:root:Train (Epoch 16): Loss/seq after 01150 batchs: 1607.1595458984375
INFO:root:Train (Epoch 16): Loss/seq after 01200 batchs: 1586.9288330078125
INFO:root:Train (Epoch 16): Loss/seq after 01250 batchs: 1575.24462890625
INFO:root:Train (Epoch 16): Loss/seq after 01300 batchs: 1586.07275390625
INFO:root:Train (Epoch 16): Loss/seq after 01350 batchs: 1585.0037841796875
INFO:root:Train (Epoch 16): Loss/seq after 01400 batchs: 1635.3763427734375
INFO:root:Train (Epoch 16): Loss/seq after 01450 batchs: 1617.14990234375
INFO:root:Train (Epoch 16): Loss/seq after 01500 batchs: 1599.6927490234375
INFO:root:Train (Epoch 16): Loss/seq after 01550 batchs: 1596.953369140625
INFO:root:Train (Epoch 16): Loss/seq after 01600 batchs: 1572.5762939453125
INFO:root:Train (Epoch 16): Loss/seq after 01650 batchs: 1560.8564453125
INFO:root:Train (Epoch 16): Loss/seq after 01700 batchs: 1545.3541259765625
INFO:root:Train (Epoch 16): Loss/seq after 01750 batchs: 1527.2540283203125
INFO:root:Train (Epoch 16): Loss/seq after 01800 batchs: 1507.5528564453125
INFO:root:Train (Epoch 16): Loss/seq after 01850 batchs: 1488.281494140625
INFO:root:Train (Epoch 16): Loss/seq after 01900 batchs: 1482.0638427734375
INFO:root:Train (Epoch 16): Loss/seq after 01950 batchs: 1472.4908447265625
INFO:root:Train (Epoch 16): Loss/seq after 02000 batchs: 1458.2083740234375
INFO:root:Train (Epoch 16): Loss/seq after 02050 batchs: 1445.9766845703125
INFO:root:Train (Epoch 16): Loss/seq after 02100 batchs: 1430.3612060546875
INFO:root:Train (Epoch 16): Loss/seq after 02150 batchs: 1416.0140380859375
INFO:root:Train (Epoch 16): Loss/seq after 02200 batchs: 1400.8880615234375
INFO:root:Train (Epoch 16): Loss/seq after 02250 batchs: 1402.4205322265625
INFO:root:Train (Epoch 16): Loss/seq after 02300 batchs: 1404.293701171875
INFO:root:Train (Epoch 16): Loss/seq after 02350 batchs: 1392.139404296875
INFO:root:Train (Epoch 16): Loss/seq after 02400 batchs: 1385.6405029296875
INFO:root:Train (Epoch 16): Loss/seq after 02450 batchs: 1370.672119140625
INFO:root:Train (Epoch 16): Loss/seq after 02500 batchs: 1350.6312255859375
INFO:root:Train (Epoch 16): Loss/seq after 02550 batchs: 1337.3743896484375
INFO:root:Train (Epoch 16): Loss/seq after 02600 batchs: 1332.784912109375
INFO:root:Train (Epoch 16): Loss/seq after 02650 batchs: 1325.686279296875
INFO:root:Train (Epoch 16): Loss/seq after 02700 batchs: 1321.164306640625
INFO:root:Train (Epoch 16): Loss/seq after 02750 batchs: 1351.2568359375
INFO:root:Train (Epoch 16): Loss/seq after 02800 batchs: 1359.7086181640625
INFO:root:Train (Epoch 16): Loss/seq after 02850 batchs: 1355.3345947265625
INFO:root:Train (Epoch 16): Loss/seq after 02900 batchs: 1351.739501953125
INFO:root:Train (Epoch 16): Loss/seq after 02950 batchs: 1342.0660400390625
INFO:root:Train (Epoch 16): Loss/seq after 03000 batchs: 1337.8289794921875
INFO:root:Train (Epoch 16): Loss/seq after 03050 batchs: 1338.4656982421875
INFO:root:Train (Epoch 16): Loss/seq after 03100 batchs: 1354.32373046875
INFO:root:Train (Epoch 16): Loss/seq after 03150 batchs: 1373.093994140625
INFO:root:Train (Epoch 16): Loss/seq after 03200 batchs: 1386.155029296875
INFO:root:Train (Epoch 16): Loss/seq after 03250 batchs: 1398.3892822265625
INFO:root:Train (Epoch 16): Loss/seq after 03300 batchs: 1396.022705078125
INFO:root:Train (Epoch 16): Loss/seq after 03350 batchs: 1394.2769775390625
INFO:root:Train (Epoch 16): Loss/seq after 03400 batchs: 1383.3426513671875
INFO:root:Train (Epoch 16): Loss/seq after 03450 batchs: 1374.6168212890625
INFO:root:Train (Epoch 16): Loss/seq after 03500 batchs: 1372.93505859375
INFO:root:Train (Epoch 16): Loss/seq after 03550 batchs: 1366.999267578125
INFO:root:Train (Epoch 16): Loss/seq after 03600 batchs: 1371.0521240234375
INFO:root:Train (Epoch 16): Loss/seq after 03650 batchs: 1365.1689453125
INFO:root:Train (Epoch 16): Loss/seq after 03700 batchs: 1363.280029296875
INFO:root:Train (Epoch 16): Loss/seq after 03750 batchs: 1361.388427734375
INFO:root:Train (Epoch 16): Loss/seq after 03800 batchs: 1352.68994140625
INFO:root:Train (Epoch 16): Loss/seq after 03850 batchs: 1346.54931640625
INFO:root:Train (Epoch 16): Loss/seq after 03900 batchs: 1353.253662109375
INFO:root:Train (Epoch 16): Loss/seq after 03950 batchs: 1361.1519775390625
INFO:root:Train (Epoch 16): Loss/seq after 04000 batchs: 1350.4366455078125
INFO:root:Train (Epoch 16): Loss/seq after 04050 batchs: 1340.805908203125
INFO:root:Train (Epoch 16): Loss/seq after 04100 batchs: 1334.567138671875
INFO:root:Train (Epoch 16): Loss/seq after 04150 batchs: 1327.3900146484375
INFO:root:Train (Epoch 16): Loss/seq after 04200 batchs: 1321.0404052734375
INFO:root:Train (Epoch 16): Loss/seq after 04250 batchs: 1315.75927734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 16): Loss/seq after 00000 batches: 895.5070190429688
INFO:root:# Valid (Epoch 16): Loss/seq after 00050 batches: 1108.9658203125
INFO:root:# Valid (Epoch 16): Loss/seq after 00100 batches: 1429.51806640625
INFO:root:# Valid (Epoch 16): Loss/seq after 00150 batches: 1165.4276123046875
INFO:root:# Valid (Epoch 16): Loss/seq after 00200 batches: 1053.4403076171875
INFO:root:Artifacts: Make stick videos for epoch 16
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_16_on_20220413_161428.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_16_index_344_on_20220413_161428.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 17): Loss/seq after 00000 batchs: 2398.0078125
INFO:root:Train (Epoch 17): Loss/seq after 00050 batchs: 1755.319580078125
INFO:root:Train (Epoch 17): Loss/seq after 00100 batchs: 1704.7449951171875
INFO:root:Train (Epoch 17): Loss/seq after 00150 batchs: 1509.6259765625
INFO:root:Train (Epoch 17): Loss/seq after 00200 batchs: 1639.762451171875
INFO:root:Train (Epoch 17): Loss/seq after 00250 batchs: 1747.602294921875
INFO:root:Train (Epoch 17): Loss/seq after 00300 batchs: 1642.0262451171875
INFO:root:Train (Epoch 17): Loss/seq after 00350 batchs: 1533.0797119140625
INFO:root:Train (Epoch 17): Loss/seq after 00400 batchs: 1595.9483642578125
INFO:root:Train (Epoch 17): Loss/seq after 00450 batchs: 1516.3995361328125
INFO:root:Train (Epoch 17): Loss/seq after 00500 batchs: 1546.9658203125
INFO:root:Train (Epoch 17): Loss/seq after 00550 batchs: 1480.73828125
INFO:root:Train (Epoch 17): Loss/seq after 00600 batchs: 1444.936279296875
INFO:root:Train (Epoch 17): Loss/seq after 00650 batchs: 1505.9998779296875
INFO:root:Train (Epoch 17): Loss/seq after 00700 batchs: 1587.4368896484375
INFO:root:Train (Epoch 17): Loss/seq after 00750 batchs: 1622.2965087890625
INFO:root:Train (Epoch 17): Loss/seq after 00800 batchs: 1605.6368408203125
INFO:root:Train (Epoch 17): Loss/seq after 00850 batchs: 1566.3187255859375
INFO:root:Train (Epoch 17): Loss/seq after 00900 batchs: 1565.960205078125
INFO:root:Train (Epoch 17): Loss/seq after 00950 batchs: 1659.594970703125
INFO:root:Train (Epoch 17): Loss/seq after 01000 batchs: 1657.320556640625
INFO:root:Train (Epoch 17): Loss/seq after 01050 batchs: 1630.6563720703125
INFO:root:Train (Epoch 17): Loss/seq after 01100 batchs: 1614.2901611328125
INFO:root:Train (Epoch 17): Loss/seq after 01150 batchs: 1586.853271484375
INFO:root:Train (Epoch 17): Loss/seq after 01200 batchs: 1568.0135498046875
INFO:root:Train (Epoch 17): Loss/seq after 01250 batchs: 1556.765380859375
INFO:root:Train (Epoch 17): Loss/seq after 01300 batchs: 1568.024169921875
INFO:root:Train (Epoch 17): Loss/seq after 01350 batchs: 1567.52734375
INFO:root:Train (Epoch 17): Loss/seq after 01400 batchs: 1617.695556640625
INFO:root:Train (Epoch 17): Loss/seq after 01450 batchs: 1598.9808349609375
INFO:root:Train (Epoch 17): Loss/seq after 01500 batchs: 1582.3458251953125
INFO:root:Train (Epoch 17): Loss/seq after 01550 batchs: 1579.816162109375
INFO:root:Train (Epoch 17): Loss/seq after 01600 batchs: 1555.84130859375
INFO:root:Train (Epoch 17): Loss/seq after 01650 batchs: 1543.9342041015625
INFO:root:Train (Epoch 17): Loss/seq after 01700 batchs: 1528.837646484375
INFO:root:Train (Epoch 17): Loss/seq after 01750 batchs: 1510.8994140625
INFO:root:Train (Epoch 17): Loss/seq after 01800 batchs: 1491.35791015625
INFO:root:Train (Epoch 17): Loss/seq after 01850 batchs: 1472.5494384765625
INFO:root:Train (Epoch 17): Loss/seq after 01900 batchs: 1466.762451171875
INFO:root:Train (Epoch 17): Loss/seq after 01950 batchs: 1457.8431396484375
INFO:root:Train (Epoch 17): Loss/seq after 02000 batchs: 1443.93310546875
INFO:root:Train (Epoch 17): Loss/seq after 02050 batchs: 1431.8790283203125
INFO:root:Train (Epoch 17): Loss/seq after 02100 batchs: 1416.604736328125
INFO:root:Train (Epoch 17): Loss/seq after 02150 batchs: 1402.55810546875
INFO:root:Train (Epoch 17): Loss/seq after 02200 batchs: 1387.697021484375
INFO:root:Train (Epoch 17): Loss/seq after 02250 batchs: 1389.6212158203125
INFO:root:Train (Epoch 17): Loss/seq after 02300 batchs: 1391.7242431640625
INFO:root:Train (Epoch 17): Loss/seq after 02350 batchs: 1380.0086669921875
INFO:root:Train (Epoch 17): Loss/seq after 02400 batchs: 1373.90576171875
INFO:root:Train (Epoch 17): Loss/seq after 02450 batchs: 1359.1385498046875
INFO:root:Train (Epoch 17): Loss/seq after 02500 batchs: 1339.2974853515625
INFO:root:Train (Epoch 17): Loss/seq after 02550 batchs: 1327.2042236328125
INFO:root:Train (Epoch 17): Loss/seq after 02600 batchs: 1324.15673828125
INFO:root:Train (Epoch 17): Loss/seq after 02650 batchs: 1317.8875732421875
INFO:root:Train (Epoch 17): Loss/seq after 02700 batchs: 1313.904296875
INFO:root:Train (Epoch 17): Loss/seq after 02750 batchs: 1344.0274658203125
INFO:root:Train (Epoch 17): Loss/seq after 02800 batchs: 1352.469482421875
INFO:root:Train (Epoch 17): Loss/seq after 02850 batchs: 1348.2408447265625
INFO:root:Train (Epoch 17): Loss/seq after 02900 batchs: 1344.72509765625
INFO:root:Train (Epoch 17): Loss/seq after 02950 batchs: 1335.2950439453125
INFO:root:Train (Epoch 17): Loss/seq after 03000 batchs: 1331.1751708984375
INFO:root:Train (Epoch 17): Loss/seq after 03050 batchs: 1331.907958984375
INFO:root:Train (Epoch 17): Loss/seq after 03100 batchs: 1347.8992919921875
INFO:root:Train (Epoch 17): Loss/seq after 03150 batchs: 1366.26025390625
INFO:root:Train (Epoch 17): Loss/seq after 03200 batchs: 1379.0687255859375
INFO:root:Train (Epoch 17): Loss/seq after 03250 batchs: 1391.2470703125
INFO:root:Train (Epoch 17): Loss/seq after 03300 batchs: 1388.9757080078125
INFO:root:Train (Epoch 17): Loss/seq after 03350 batchs: 1387.5888671875
INFO:root:Train (Epoch 17): Loss/seq after 03400 batchs: 1376.770751953125
INFO:root:Train (Epoch 17): Loss/seq after 03450 batchs: 1368.5802001953125
INFO:root:Train (Epoch 17): Loss/seq after 03500 batchs: 1367.138427734375
INFO:root:Train (Epoch 17): Loss/seq after 03550 batchs: 1360.634765625
INFO:root:Train (Epoch 17): Loss/seq after 03600 batchs: 1364.7366943359375
INFO:root:Train (Epoch 17): Loss/seq after 03650 batchs: 1358.8624267578125
INFO:root:Train (Epoch 17): Loss/seq after 03700 batchs: 1356.96435546875
INFO:root:Train (Epoch 17): Loss/seq after 03750 batchs: 1355.2110595703125
INFO:root:Train (Epoch 17): Loss/seq after 03800 batchs: 1346.617431640625
INFO:root:Train (Epoch 17): Loss/seq after 03850 batchs: 1340.587646484375
INFO:root:Train (Epoch 17): Loss/seq after 03900 batchs: 1347.0880126953125
INFO:root:Train (Epoch 17): Loss/seq after 03950 batchs: 1354.87939453125
INFO:root:Train (Epoch 17): Loss/seq after 04000 batchs: 1344.2767333984375
INFO:root:Train (Epoch 17): Loss/seq after 04050 batchs: 1334.72509765625
INFO:root:Train (Epoch 17): Loss/seq after 04100 batchs: 1328.6522216796875
INFO:root:Train (Epoch 17): Loss/seq after 04150 batchs: 1321.6192626953125
INFO:root:Train (Epoch 17): Loss/seq after 04200 batchs: 1315.563720703125
INFO:root:Train (Epoch 17): Loss/seq after 04250 batchs: 1309.9852294921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 17): Loss/seq after 00000 batches: 890.2800903320312
INFO:root:# Valid (Epoch 17): Loss/seq after 00050 batches: 1111.667236328125
INFO:root:# Valid (Epoch 17): Loss/seq after 00100 batches: 1456.162109375
INFO:root:# Valid (Epoch 17): Loss/seq after 00150 batches: 1261.4364013671875
INFO:root:# Valid (Epoch 17): Loss/seq after 00200 batches: 1169.619140625
INFO:root:Artifacts: Make stick videos for epoch 17
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_17_on_20220413_161947.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_17_index_395_on_20220413_161947.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 18): Loss/seq after 00000 batchs: 2347.483642578125
INFO:root:Train (Epoch 18): Loss/seq after 00050 batchs: 1784.229736328125
INFO:root:Train (Epoch 18): Loss/seq after 00100 batchs: 1710.81005859375
INFO:root:Train (Epoch 18): Loss/seq after 00150 batchs: 1515.124267578125
INFO:root:Train (Epoch 18): Loss/seq after 00200 batchs: 1639.51318359375
INFO:root:Train (Epoch 18): Loss/seq after 00250 batchs: 1747.621826171875
INFO:root:Train (Epoch 18): Loss/seq after 00300 batchs: 1641.714111328125
INFO:root:Train (Epoch 18): Loss/seq after 00350 batchs: 1532.172119140625
INFO:root:Train (Epoch 18): Loss/seq after 00400 batchs: 1594.591064453125
INFO:root:Train (Epoch 18): Loss/seq after 00450 batchs: 1515.0240478515625
INFO:root:Train (Epoch 18): Loss/seq after 00500 batchs: 1547.031494140625
INFO:root:Train (Epoch 18): Loss/seq after 00550 batchs: 1482.259765625
INFO:root:Train (Epoch 18): Loss/seq after 00600 batchs: 1446.2032470703125
INFO:root:Train (Epoch 18): Loss/seq after 00650 batchs: 1507.2703857421875
INFO:root:Train (Epoch 18): Loss/seq after 00700 batchs: 1588.0421142578125
INFO:root:Train (Epoch 18): Loss/seq after 00750 batchs: 1622.4012451171875
INFO:root:Train (Epoch 18): Loss/seq after 00800 batchs: 1605.810791015625
INFO:root:Train (Epoch 18): Loss/seq after 00850 batchs: 1567.3062744140625
INFO:root:Train (Epoch 18): Loss/seq after 00900 batchs: 1566.0394287109375
INFO:root:Train (Epoch 18): Loss/seq after 00950 batchs: 1653.4324951171875
INFO:root:Train (Epoch 18): Loss/seq after 01000 batchs: 1649.8575439453125
INFO:root:Train (Epoch 18): Loss/seq after 01050 batchs: 1624.2197265625
INFO:root:Train (Epoch 18): Loss/seq after 01100 batchs: 1607.7235107421875
INFO:root:Train (Epoch 18): Loss/seq after 01150 batchs: 1580.2904052734375
INFO:root:Train (Epoch 18): Loss/seq after 01200 batchs: 1560.0316162109375
INFO:root:Train (Epoch 18): Loss/seq after 01250 batchs: 1549.1168212890625
INFO:root:Train (Epoch 18): Loss/seq after 01300 batchs: 1561.3348388671875
INFO:root:Train (Epoch 18): Loss/seq after 01350 batchs: 1561.20849609375
INFO:root:Train (Epoch 18): Loss/seq after 01400 batchs: 1606.8214111328125
INFO:root:Train (Epoch 18): Loss/seq after 01450 batchs: 1588.534423828125
INFO:root:Train (Epoch 18): Loss/seq after 01500 batchs: 1570.80078125
INFO:root:Train (Epoch 18): Loss/seq after 01550 batchs: 1568.4200439453125
INFO:root:Train (Epoch 18): Loss/seq after 01600 batchs: 1544.745849609375
INFO:root:Train (Epoch 18): Loss/seq after 01650 batchs: 1533.1910400390625
INFO:root:Train (Epoch 18): Loss/seq after 01700 batchs: 1518.330078125
INFO:root:Train (Epoch 18): Loss/seq after 01750 batchs: 1500.6900634765625
INFO:root:Train (Epoch 18): Loss/seq after 01800 batchs: 1481.345703125
INFO:root:Train (Epoch 18): Loss/seq after 01850 batchs: 1462.80908203125
INFO:root:Train (Epoch 18): Loss/seq after 01900 batchs: 1456.9581298828125
INFO:root:Train (Epoch 18): Loss/seq after 01950 batchs: 1447.7637939453125
INFO:root:Train (Epoch 18): Loss/seq after 02000 batchs: 1433.986572265625
INFO:root:Train (Epoch 18): Loss/seq after 02050 batchs: 1422.139404296875
INFO:root:Train (Epoch 18): Loss/seq after 02100 batchs: 1407.1353759765625
INFO:root:Train (Epoch 18): Loss/seq after 02150 batchs: 1393.23193359375
INFO:root:Train (Epoch 18): Loss/seq after 02200 batchs: 1378.648193359375
INFO:root:Train (Epoch 18): Loss/seq after 02250 batchs: 1380.8961181640625
INFO:root:Train (Epoch 18): Loss/seq after 02300 batchs: 1383.311279296875
INFO:root:Train (Epoch 18): Loss/seq after 02350 batchs: 1371.685302734375
INFO:root:Train (Epoch 18): Loss/seq after 02400 batchs: 1365.6339111328125
INFO:root:Train (Epoch 18): Loss/seq after 02450 batchs: 1350.8955078125
INFO:root:Train (Epoch 18): Loss/seq after 02500 batchs: 1331.198974609375
INFO:root:Train (Epoch 18): Loss/seq after 02550 batchs: 1318.334228515625
INFO:root:Train (Epoch 18): Loss/seq after 02600 batchs: 1314.7552490234375
INFO:root:Train (Epoch 18): Loss/seq after 02650 batchs: 1308.5501708984375
INFO:root:Train (Epoch 18): Loss/seq after 02700 batchs: 1304.0947265625
INFO:root:Train (Epoch 18): Loss/seq after 02750 batchs: 1334.4840087890625
INFO:root:Train (Epoch 18): Loss/seq after 02800 batchs: 1343.0748291015625
INFO:root:Train (Epoch 18): Loss/seq after 02850 batchs: 1338.6749267578125
INFO:root:Train (Epoch 18): Loss/seq after 02900 batchs: 1335.20751953125
INFO:root:Train (Epoch 18): Loss/seq after 02950 batchs: 1325.7430419921875
INFO:root:Train (Epoch 18): Loss/seq after 03000 batchs: 1321.775390625
INFO:root:Train (Epoch 18): Loss/seq after 03050 batchs: 1322.652587890625
INFO:root:Train (Epoch 18): Loss/seq after 03100 batchs: 1338.3941650390625
INFO:root:Train (Epoch 18): Loss/seq after 03150 batchs: 1357.778564453125
INFO:root:Train (Epoch 18): Loss/seq after 03200 batchs: 1369.346923828125
INFO:root:Train (Epoch 18): Loss/seq after 03250 batchs: 1379.6646728515625
INFO:root:Train (Epoch 18): Loss/seq after 03300 batchs: 1378.006591796875
INFO:root:Train (Epoch 18): Loss/seq after 03350 batchs: 1376.5245361328125
INFO:root:Train (Epoch 18): Loss/seq after 03400 batchs: 1365.90283203125
INFO:root:Train (Epoch 18): Loss/seq after 03450 batchs: 1357.23046875
INFO:root:Train (Epoch 18): Loss/seq after 03500 batchs: 1355.80517578125
INFO:root:Train (Epoch 18): Loss/seq after 03550 batchs: 1349.4962158203125
INFO:root:Train (Epoch 18): Loss/seq after 03600 batchs: 1353.76611328125
INFO:root:Train (Epoch 18): Loss/seq after 03650 batchs: 1348.1014404296875
INFO:root:Train (Epoch 18): Loss/seq after 03700 batchs: 1346.430419921875
INFO:root:Train (Epoch 18): Loss/seq after 03750 batchs: 1344.78759765625
INFO:root:Train (Epoch 18): Loss/seq after 03800 batchs: 1336.3602294921875
INFO:root:Train (Epoch 18): Loss/seq after 03850 batchs: 1330.44189453125
INFO:root:Train (Epoch 18): Loss/seq after 03900 batchs: 1336.5457763671875
INFO:root:Train (Epoch 18): Loss/seq after 03950 batchs: 1343.3177490234375
INFO:root:Train (Epoch 18): Loss/seq after 04000 batchs: 1332.8402099609375
INFO:root:Train (Epoch 18): Loss/seq after 04050 batchs: 1323.4302978515625
INFO:root:Train (Epoch 18): Loss/seq after 04100 batchs: 1317.0987548828125
INFO:root:Train (Epoch 18): Loss/seq after 04150 batchs: 1310.048828125
INFO:root:Train (Epoch 18): Loss/seq after 04200 batchs: 1304.0416259765625
INFO:root:Train (Epoch 18): Loss/seq after 04250 batchs: 1298.5845947265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 18): Loss/seq after 00000 batches: 886.2855224609375
INFO:root:# Valid (Epoch 18): Loss/seq after 00050 batches: 1116.415283203125
INFO:root:# Valid (Epoch 18): Loss/seq after 00100 batches: 1430.830078125
INFO:root:# Valid (Epoch 18): Loss/seq after 00150 batches: 1166.4996337890625
INFO:root:# Valid (Epoch 18): Loss/seq after 00200 batches: 1062.3702392578125
INFO:root:Artifacts: Make stick videos for epoch 18
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_18_on_20220413_162505.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_18_index_1480_on_20220413_162505.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 19): Loss/seq after 00000 batchs: 2204.521728515625
INFO:root:Train (Epoch 19): Loss/seq after 00050 batchs: 1779.565185546875
INFO:root:Train (Epoch 19): Loss/seq after 00100 batchs: 1715.7882080078125
INFO:root:Train (Epoch 19): Loss/seq after 00150 batchs: 1520.1600341796875
INFO:root:Train (Epoch 19): Loss/seq after 00200 batchs: 1644.3212890625
INFO:root:Train (Epoch 19): Loss/seq after 00250 batchs: 1753.6612548828125
INFO:root:Train (Epoch 19): Loss/seq after 00300 batchs: 1646.613037109375
INFO:root:Train (Epoch 19): Loss/seq after 00350 batchs: 1536.197265625
INFO:root:Train (Epoch 19): Loss/seq after 00400 batchs: 1595.576904296875
INFO:root:Train (Epoch 19): Loss/seq after 00450 batchs: 1516.1241455078125
INFO:root:Train (Epoch 19): Loss/seq after 00500 batchs: 1545.826416015625
INFO:root:Train (Epoch 19): Loss/seq after 00550 batchs: 1479.9547119140625
INFO:root:Train (Epoch 19): Loss/seq after 00600 batchs: 1444.4788818359375
INFO:root:Train (Epoch 19): Loss/seq after 00650 batchs: 1496.4989013671875
INFO:root:Train (Epoch 19): Loss/seq after 00700 batchs: 1552.37646484375
INFO:root:Train (Epoch 19): Loss/seq after 00750 batchs: 1591.6224365234375
INFO:root:Train (Epoch 19): Loss/seq after 00800 batchs: 1576.5616455078125
INFO:root:Train (Epoch 19): Loss/seq after 00850 batchs: 1538.856201171875
INFO:root:Train (Epoch 19): Loss/seq after 00900 batchs: 1539.9102783203125
INFO:root:Train (Epoch 19): Loss/seq after 00950 batchs: 1613.173828125
INFO:root:Train (Epoch 19): Loss/seq after 01000 batchs: 1608.0556640625
INFO:root:Train (Epoch 19): Loss/seq after 01050 batchs: 1583.8560791015625
INFO:root:Train (Epoch 19): Loss/seq after 01100 batchs: 1570.2135009765625
INFO:root:Train (Epoch 19): Loss/seq after 01150 batchs: 1544.66796875
INFO:root:Train (Epoch 19): Loss/seq after 01200 batchs: 1525.954345703125
INFO:root:Train (Epoch 19): Loss/seq after 01250 batchs: 1515.9710693359375
INFO:root:Train (Epoch 19): Loss/seq after 01300 batchs: 1524.548583984375
INFO:root:Train (Epoch 19): Loss/seq after 01350 batchs: 1524.007080078125
INFO:root:Train (Epoch 19): Loss/seq after 01400 batchs: 1566.712890625
INFO:root:Train (Epoch 19): Loss/seq after 01450 batchs: 1549.1475830078125
INFO:root:Train (Epoch 19): Loss/seq after 01500 batchs: 1532.5634765625
INFO:root:Train (Epoch 19): Loss/seq after 01550 batchs: 1531.1171875
INFO:root:Train (Epoch 19): Loss/seq after 01600 batchs: 1508.38720703125
INFO:root:Train (Epoch 19): Loss/seq after 01650 batchs: 1498.1065673828125
INFO:root:Train (Epoch 19): Loss/seq after 01700 batchs: 1484.2298583984375
INFO:root:Train (Epoch 19): Loss/seq after 01750 batchs: 1467.540771484375
INFO:root:Train (Epoch 19): Loss/seq after 01800 batchs: 1449.2210693359375
INFO:root:Train (Epoch 19): Loss/seq after 01850 batchs: 1431.614990234375
INFO:root:Train (Epoch 19): Loss/seq after 01900 batchs: 1426.669921875
INFO:root:Train (Epoch 19): Loss/seq after 01950 batchs: 1418.6429443359375
INFO:root:Train (Epoch 19): Loss/seq after 02000 batchs: 1405.6131591796875
INFO:root:Train (Epoch 19): Loss/seq after 02050 batchs: 1394.4329833984375
INFO:root:Train (Epoch 19): Loss/seq after 02100 batchs: 1380.04638671875
INFO:root:Train (Epoch 19): Loss/seq after 02150 batchs: 1366.801513671875
INFO:root:Train (Epoch 19): Loss/seq after 02200 batchs: 1352.8133544921875
INFO:root:Train (Epoch 19): Loss/seq after 02250 batchs: 1355.5328369140625
INFO:root:Train (Epoch 19): Loss/seq after 02300 batchs: 1358.5220947265625
INFO:root:Train (Epoch 19): Loss/seq after 02350 batchs: 1347.6546630859375
INFO:root:Train (Epoch 19): Loss/seq after 02400 batchs: 1342.0858154296875
INFO:root:Train (Epoch 19): Loss/seq after 02450 batchs: 1327.9595947265625
INFO:root:Train (Epoch 19): Loss/seq after 02500 batchs: 1308.7239990234375
INFO:root:Train (Epoch 19): Loss/seq after 02550 batchs: 1296.5660400390625
INFO:root:Train (Epoch 19): Loss/seq after 02600 batchs: 1293.0919189453125
INFO:root:Train (Epoch 19): Loss/seq after 02650 batchs: 1287.247802734375
INFO:root:Train (Epoch 19): Loss/seq after 02700 batchs: 1283.070068359375
INFO:root:Train (Epoch 19): Loss/seq after 02750 batchs: 1313.9586181640625
INFO:root:Train (Epoch 19): Loss/seq after 02800 batchs: 1322.1258544921875
INFO:root:Train (Epoch 19): Loss/seq after 02850 batchs: 1317.77783203125
INFO:root:Train (Epoch 19): Loss/seq after 02900 batchs: 1314.6741943359375
INFO:root:Train (Epoch 19): Loss/seq after 02950 batchs: 1305.308837890625
INFO:root:Train (Epoch 19): Loss/seq after 03000 batchs: 1301.647705078125
INFO:root:Train (Epoch 19): Loss/seq after 03050 batchs: 1302.776611328125
INFO:root:Train (Epoch 19): Loss/seq after 03100 batchs: 1318.0263671875
INFO:root:Train (Epoch 19): Loss/seq after 03150 batchs: 1334.3253173828125
INFO:root:Train (Epoch 19): Loss/seq after 03200 batchs: 1344.849609375
INFO:root:Train (Epoch 19): Loss/seq after 03250 batchs: 1352.412109375
INFO:root:Train (Epoch 19): Loss/seq after 03300 batchs: 1351.0504150390625
INFO:root:Train (Epoch 19): Loss/seq after 03350 batchs: 1350.3170166015625
INFO:root:Train (Epoch 19): Loss/seq after 03400 batchs: 1340.1103515625
INFO:root:Train (Epoch 19): Loss/seq after 03450 batchs: 1332.470947265625
INFO:root:Train (Epoch 19): Loss/seq after 03500 batchs: 1331.4906005859375
INFO:root:Train (Epoch 19): Loss/seq after 03550 batchs: 1325.2567138671875
INFO:root:Train (Epoch 19): Loss/seq after 03600 batchs: 1329.811279296875
INFO:root:Train (Epoch 19): Loss/seq after 03650 batchs: 1324.3885498046875
INFO:root:Train (Epoch 19): Loss/seq after 03700 batchs: 1322.93994140625
INFO:root:Train (Epoch 19): Loss/seq after 03750 batchs: 1321.5782470703125
INFO:root:Train (Epoch 19): Loss/seq after 03800 batchs: 1313.367919921875
INFO:root:Train (Epoch 19): Loss/seq after 03850 batchs: 1307.697021484375
INFO:root:Train (Epoch 19): Loss/seq after 03900 batchs: 1313.4576416015625
INFO:root:Train (Epoch 19): Loss/seq after 03950 batchs: 1319.4652099609375
INFO:root:Train (Epoch 19): Loss/seq after 04000 batchs: 1309.2764892578125
INFO:root:Train (Epoch 19): Loss/seq after 04050 batchs: 1300.1568603515625
INFO:root:Train (Epoch 19): Loss/seq after 04100 batchs: 1294.10791015625
INFO:root:Train (Epoch 19): Loss/seq after 04150 batchs: 1287.373779296875
INFO:root:Train (Epoch 19): Loss/seq after 04200 batchs: 1281.5203857421875
INFO:root:Train (Epoch 19): Loss/seq after 04250 batchs: 1276.35009765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 19): Loss/seq after 00000 batches: 881.6807250976562
INFO:root:# Valid (Epoch 19): Loss/seq after 00050 batches: 1100.984130859375
INFO:root:# Valid (Epoch 19): Loss/seq after 00100 batches: 1422.5447998046875
INFO:root:# Valid (Epoch 19): Loss/seq after 00150 batches: 1149.6856689453125
INFO:root:# Valid (Epoch 19): Loss/seq after 00200 batches: 1036.1187744140625
INFO:root:Artifacts: Make stick videos for epoch 19
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_19_on_20220413_163022.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_19_index_1334_on_20220413_163022.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 20): Loss/seq after 00000 batchs: 1989.96484375
INFO:root:Train (Epoch 20): Loss/seq after 00050 batchs: 1733.0748291015625
INFO:root:Train (Epoch 20): Loss/seq after 00100 batchs: 1708.2900390625
INFO:root:Train (Epoch 20): Loss/seq after 00150 batchs: 1515.7642822265625
INFO:root:Train (Epoch 20): Loss/seq after 00200 batchs: 1629.1883544921875
INFO:root:Train (Epoch 20): Loss/seq after 00250 batchs: 1741.3731689453125
INFO:root:Train (Epoch 20): Loss/seq after 00300 batchs: 1635.93115234375
INFO:root:Train (Epoch 20): Loss/seq after 00350 batchs: 1526.7196044921875
INFO:root:Train (Epoch 20): Loss/seq after 00400 batchs: 1581.2177734375
INFO:root:Train (Epoch 20): Loss/seq after 00450 batchs: 1503.2806396484375
INFO:root:Train (Epoch 20): Loss/seq after 00500 batchs: 1533.20654296875
INFO:root:Train (Epoch 20): Loss/seq after 00550 batchs: 1468.7113037109375
INFO:root:Train (Epoch 20): Loss/seq after 00600 batchs: 1433.0277099609375
INFO:root:Train (Epoch 20): Loss/seq after 00650 batchs: 1474.7601318359375
INFO:root:Train (Epoch 20): Loss/seq after 00700 batchs: 1529.3818359375
INFO:root:Train (Epoch 20): Loss/seq after 00750 batchs: 1564.2342529296875
INFO:root:Train (Epoch 20): Loss/seq after 00800 batchs: 1551.143798828125
INFO:root:Train (Epoch 20): Loss/seq after 00850 batchs: 1515.4034423828125
INFO:root:Train (Epoch 20): Loss/seq after 00900 batchs: 1518.7532958984375
INFO:root:Train (Epoch 20): Loss/seq after 00950 batchs: 1588.041748046875
INFO:root:Train (Epoch 20): Loss/seq after 01000 batchs: 1582.2520751953125
INFO:root:Train (Epoch 20): Loss/seq after 01050 batchs: 1559.544921875
INFO:root:Train (Epoch 20): Loss/seq after 01100 batchs: 1548.2674560546875
INFO:root:Train (Epoch 20): Loss/seq after 01150 batchs: 1523.097900390625
INFO:root:Train (Epoch 20): Loss/seq after 01200 batchs: 1505.0838623046875
INFO:root:Train (Epoch 20): Loss/seq after 01250 batchs: 1497.1256103515625
INFO:root:Train (Epoch 20): Loss/seq after 01300 batchs: 1502.647216796875
INFO:root:Train (Epoch 20): Loss/seq after 01350 batchs: 1501.3948974609375
INFO:root:Train (Epoch 20): Loss/seq after 01400 batchs: 1542.1619873046875
INFO:root:Train (Epoch 20): Loss/seq after 01450 batchs: 1525.3790283203125
INFO:root:Train (Epoch 20): Loss/seq after 01500 batchs: 1509.703125
INFO:root:Train (Epoch 20): Loss/seq after 01550 batchs: 1511.7017822265625
INFO:root:Train (Epoch 20): Loss/seq after 01600 batchs: 1489.635009765625
INFO:root:Train (Epoch 20): Loss/seq after 01650 batchs: 1481.305419921875
INFO:root:Train (Epoch 20): Loss/seq after 01700 batchs: 1468.0289306640625
INFO:root:Train (Epoch 20): Loss/seq after 01750 batchs: 1451.837158203125
INFO:root:Train (Epoch 20): Loss/seq after 01800 batchs: 1434.7562255859375
INFO:root:Train (Epoch 20): Loss/seq after 01850 batchs: 1417.482421875
INFO:root:Train (Epoch 20): Loss/seq after 01900 batchs: 1413.1146240234375
INFO:root:Train (Epoch 20): Loss/seq after 01950 batchs: 1405.2857666015625
INFO:root:Train (Epoch 20): Loss/seq after 02000 batchs: 1392.64404296875
INFO:root:Train (Epoch 20): Loss/seq after 02050 batchs: 1381.690185546875
INFO:root:Train (Epoch 20): Loss/seq after 02100 batchs: 1367.5833740234375
INFO:root:Train (Epoch 20): Loss/seq after 02150 batchs: 1354.6419677734375
INFO:root:Train (Epoch 20): Loss/seq after 02200 batchs: 1340.8765869140625
INFO:root:Train (Epoch 20): Loss/seq after 02250 batchs: 1343.8270263671875
INFO:root:Train (Epoch 20): Loss/seq after 02300 batchs: 1347.213134765625
INFO:root:Train (Epoch 20): Loss/seq after 02350 batchs: 1336.3984375
INFO:root:Train (Epoch 20): Loss/seq after 02400 batchs: 1330.8238525390625
INFO:root:Train (Epoch 20): Loss/seq after 02450 batchs: 1316.390380859375
INFO:root:Train (Epoch 20): Loss/seq after 02500 batchs: 1297.3551025390625
INFO:root:Train (Epoch 20): Loss/seq after 02550 batchs: 1284.9403076171875
INFO:root:Train (Epoch 20): Loss/seq after 02600 batchs: 1281.2469482421875
INFO:root:Train (Epoch 20): Loss/seq after 02650 batchs: 1275.1754150390625
INFO:root:Train (Epoch 20): Loss/seq after 02700 batchs: 1270.41162109375
INFO:root:Train (Epoch 20): Loss/seq after 02750 batchs: 1301.0821533203125
INFO:root:Train (Epoch 20): Loss/seq after 02800 batchs: 1310.2833251953125
INFO:root:Train (Epoch 20): Loss/seq after 02850 batchs: 1306.139404296875
INFO:root:Train (Epoch 20): Loss/seq after 02900 batchs: 1303.2283935546875
INFO:root:Train (Epoch 20): Loss/seq after 02950 batchs: 1294.0003662109375
INFO:root:Train (Epoch 20): Loss/seq after 03000 batchs: 1290.552001953125
INFO:root:Train (Epoch 20): Loss/seq after 03050 batchs: 1291.87548828125
INFO:root:Train (Epoch 20): Loss/seq after 03100 batchs: 1306.69921875
INFO:root:Train (Epoch 20): Loss/seq after 03150 batchs: 1323.5592041015625
INFO:root:Train (Epoch 20): Loss/seq after 03200 batchs: 1333.9891357421875
INFO:root:Train (Epoch 20): Loss/seq after 03250 batchs: 1341.9449462890625
INFO:root:Train (Epoch 20): Loss/seq after 03300 batchs: 1341.5499267578125
INFO:root:Train (Epoch 20): Loss/seq after 03350 batchs: 1340.7213134765625
INFO:root:Train (Epoch 20): Loss/seq after 03400 batchs: 1330.5745849609375
INFO:root:Train (Epoch 20): Loss/seq after 03450 batchs: 1322.3189697265625
INFO:root:Train (Epoch 20): Loss/seq after 03500 batchs: 1321.4263916015625
INFO:root:Train (Epoch 20): Loss/seq after 03550 batchs: 1315.362548828125
INFO:root:Train (Epoch 20): Loss/seq after 03600 batchs: 1320.05224609375
INFO:root:Train (Epoch 20): Loss/seq after 03650 batchs: 1314.7523193359375
INFO:root:Train (Epoch 20): Loss/seq after 03700 batchs: 1313.474609375
INFO:root:Train (Epoch 20): Loss/seq after 03750 batchs: 1312.2857666015625
INFO:root:Train (Epoch 20): Loss/seq after 03800 batchs: 1304.2845458984375
INFO:root:Train (Epoch 20): Loss/seq after 03850 batchs: 1298.7972412109375
INFO:root:Train (Epoch 20): Loss/seq after 03900 batchs: 1305.13623046875
INFO:root:Train (Epoch 20): Loss/seq after 03950 batchs: 1311.238525390625
INFO:root:Train (Epoch 20): Loss/seq after 04000 batchs: 1301.1558837890625
INFO:root:Train (Epoch 20): Loss/seq after 04050 batchs: 1292.1314697265625
INFO:root:Train (Epoch 20): Loss/seq after 04100 batchs: 1286.037353515625
INFO:root:Train (Epoch 20): Loss/seq after 04150 batchs: 1279.4710693359375
INFO:root:Train (Epoch 20): Loss/seq after 04200 batchs: 1273.8651123046875
INFO:root:Train (Epoch 20): Loss/seq after 04250 batchs: 1268.7269287109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 20): Loss/seq after 00000 batches: 880.0454711914062
INFO:root:# Valid (Epoch 20): Loss/seq after 00050 batches: 1104.897216796875
INFO:root:# Valid (Epoch 20): Loss/seq after 00100 batches: 1417.7840576171875
INFO:root:# Valid (Epoch 20): Loss/seq after 00150 batches: 1146.641357421875
INFO:root:# Valid (Epoch 20): Loss/seq after 00200 batches: 1037.79345703125
INFO:root:Artifacts: Make stick videos for epoch 20
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_20_on_20220413_163541.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_20_index_1888_on_20220413_163541.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 21): Loss/seq after 00000 batchs: 2031.874755859375
INFO:root:Train (Epoch 21): Loss/seq after 00050 batchs: 1754.741943359375
INFO:root:Train (Epoch 21): Loss/seq after 00100 batchs: 1703.4351806640625
INFO:root:Train (Epoch 21): Loss/seq after 00150 batchs: 1512.8924560546875
INFO:root:Train (Epoch 21): Loss/seq after 00200 batchs: 1629.9696044921875
INFO:root:Train (Epoch 21): Loss/seq after 00250 batchs: 1741.3643798828125
INFO:root:Train (Epoch 21): Loss/seq after 00300 batchs: 1636.421630859375
INFO:root:Train (Epoch 21): Loss/seq after 00350 batchs: 1527.72705078125
INFO:root:Train (Epoch 21): Loss/seq after 00400 batchs: 1578.4580078125
INFO:root:Train (Epoch 21): Loss/seq after 00450 batchs: 1500.6754150390625
INFO:root:Train (Epoch 21): Loss/seq after 00500 batchs: 1535.4197998046875
INFO:root:Train (Epoch 21): Loss/seq after 00550 batchs: 1470.924560546875
INFO:root:Train (Epoch 21): Loss/seq after 00600 batchs: 1433.512939453125
INFO:root:Train (Epoch 21): Loss/seq after 00650 batchs: 1470.7191162109375
INFO:root:Train (Epoch 21): Loss/seq after 00700 batchs: 1515.4979248046875
INFO:root:Train (Epoch 21): Loss/seq after 00750 batchs: 1551.2235107421875
INFO:root:Train (Epoch 21): Loss/seq after 00800 batchs: 1539.2215576171875
INFO:root:Train (Epoch 21): Loss/seq after 00850 batchs: 1504.3511962890625
INFO:root:Train (Epoch 21): Loss/seq after 00900 batchs: 1508.27490234375
INFO:root:Train (Epoch 21): Loss/seq after 00950 batchs: 1572.77783203125
INFO:root:Train (Epoch 21): Loss/seq after 01000 batchs: 1570.0462646484375
INFO:root:Train (Epoch 21): Loss/seq after 01050 batchs: 1548.218017578125
INFO:root:Train (Epoch 21): Loss/seq after 01100 batchs: 1535.8780517578125
INFO:root:Train (Epoch 21): Loss/seq after 01150 batchs: 1511.785400390625
INFO:root:Train (Epoch 21): Loss/seq after 01200 batchs: 1494.974853515625
INFO:root:Train (Epoch 21): Loss/seq after 01250 batchs: 1488.8612060546875
INFO:root:Train (Epoch 21): Loss/seq after 01300 batchs: 1493.24658203125
INFO:root:Train (Epoch 21): Loss/seq after 01350 batchs: 1493.071533203125
INFO:root:Train (Epoch 21): Loss/seq after 01400 batchs: 1534.8408203125
INFO:root:Train (Epoch 21): Loss/seq after 01450 batchs: 1518.5030517578125
INFO:root:Train (Epoch 21): Loss/seq after 01500 batchs: 1503.2188720703125
INFO:root:Train (Epoch 21): Loss/seq after 01550 batchs: 1503.0855712890625
INFO:root:Train (Epoch 21): Loss/seq after 01600 batchs: 1481.3497314453125
INFO:root:Train (Epoch 21): Loss/seq after 01650 batchs: 1472.48583984375
INFO:root:Train (Epoch 21): Loss/seq after 01700 batchs: 1459.307373046875
INFO:root:Train (Epoch 21): Loss/seq after 01750 batchs: 1443.332275390625
INFO:root:Train (Epoch 21): Loss/seq after 01800 batchs: 1425.6380615234375
INFO:root:Train (Epoch 21): Loss/seq after 01850 batchs: 1408.505615234375
INFO:root:Train (Epoch 21): Loss/seq after 01900 batchs: 1404.2264404296875
INFO:root:Train (Epoch 21): Loss/seq after 01950 batchs: 1396.4798583984375
INFO:root:Train (Epoch 21): Loss/seq after 02000 batchs: 1383.973388671875
INFO:root:Train (Epoch 21): Loss/seq after 02050 batchs: 1373.2493896484375
INFO:root:Train (Epoch 21): Loss/seq after 02100 batchs: 1359.33251953125
INFO:root:Train (Epoch 21): Loss/seq after 02150 batchs: 1346.4234619140625
INFO:root:Train (Epoch 21): Loss/seq after 02200 batchs: 1332.8265380859375
INFO:root:Train (Epoch 21): Loss/seq after 02250 batchs: 1335.6392822265625
INFO:root:Train (Epoch 21): Loss/seq after 02300 batchs: 1339.023681640625
INFO:root:Train (Epoch 21): Loss/seq after 02350 batchs: 1328.0531005859375
INFO:root:Train (Epoch 21): Loss/seq after 02400 batchs: 1322.569091796875
INFO:root:Train (Epoch 21): Loss/seq after 02450 batchs: 1308.4573974609375
INFO:root:Train (Epoch 21): Loss/seq after 02500 batchs: 1289.5567626953125
INFO:root:Train (Epoch 21): Loss/seq after 02550 batchs: 1277.0526123046875
INFO:root:Train (Epoch 21): Loss/seq after 02600 batchs: 1273.238037109375
INFO:root:Train (Epoch 21): Loss/seq after 02650 batchs: 1267.188720703125
INFO:root:Train (Epoch 21): Loss/seq after 02700 batchs: 1262.561279296875
INFO:root:Train (Epoch 21): Loss/seq after 02750 batchs: 1293.379150390625
INFO:root:Train (Epoch 21): Loss/seq after 02800 batchs: 1300.025390625
INFO:root:Train (Epoch 21): Loss/seq after 02850 batchs: 1296.007080078125
INFO:root:Train (Epoch 21): Loss/seq after 02900 batchs: 1293.3839111328125
INFO:root:Train (Epoch 21): Loss/seq after 02950 batchs: 1284.2646484375
INFO:root:Train (Epoch 21): Loss/seq after 03000 batchs: 1281.0537109375
INFO:root:Train (Epoch 21): Loss/seq after 03050 batchs: 1282.569091796875
INFO:root:Train (Epoch 21): Loss/seq after 03100 batchs: 1298.292236328125
INFO:root:Train (Epoch 21): Loss/seq after 03150 batchs: 1313.7611083984375
INFO:root:Train (Epoch 21): Loss/seq after 03200 batchs: 1320.806640625
INFO:root:Train (Epoch 21): Loss/seq after 03250 batchs: 1327.6734619140625
INFO:root:Train (Epoch 21): Loss/seq after 03300 batchs: 1328.8651123046875
INFO:root:Train (Epoch 21): Loss/seq after 03350 batchs: 1328.781494140625
INFO:root:Train (Epoch 21): Loss/seq after 03400 batchs: 1318.80810546875
INFO:root:Train (Epoch 21): Loss/seq after 03450 batchs: 1310.6143798828125
INFO:root:Train (Epoch 21): Loss/seq after 03500 batchs: 1309.8272705078125
INFO:root:Train (Epoch 21): Loss/seq after 03550 batchs: 1303.9854736328125
INFO:root:Train (Epoch 21): Loss/seq after 03600 batchs: 1308.8223876953125
INFO:root:Train (Epoch 21): Loss/seq after 03650 batchs: 1303.55712890625
INFO:root:Train (Epoch 21): Loss/seq after 03700 batchs: 1302.352783203125
INFO:root:Train (Epoch 21): Loss/seq after 03750 batchs: 1301.2188720703125
INFO:root:Train (Epoch 21): Loss/seq after 03800 batchs: 1293.2901611328125
INFO:root:Train (Epoch 21): Loss/seq after 03850 batchs: 1287.893310546875
INFO:root:Train (Epoch 21): Loss/seq after 03900 batchs: 1293.7347412109375
INFO:root:Train (Epoch 21): Loss/seq after 03950 batchs: 1300.0294189453125
INFO:root:Train (Epoch 21): Loss/seq after 04000 batchs: 1290.086181640625
INFO:root:Train (Epoch 21): Loss/seq after 04050 batchs: 1281.19580078125
INFO:root:Train (Epoch 21): Loss/seq after 04100 batchs: 1275.115234375
INFO:root:Train (Epoch 21): Loss/seq after 04150 batchs: 1268.522705078125
INFO:root:Train (Epoch 21): Loss/seq after 04200 batchs: 1262.970947265625
INFO:root:Train (Epoch 21): Loss/seq after 04250 batchs: 1257.9766845703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 21): Loss/seq after 00000 batches: 885.6094360351562
INFO:root:# Valid (Epoch 21): Loss/seq after 00050 batches: 1106.9283447265625
INFO:root:# Valid (Epoch 21): Loss/seq after 00100 batches: 1433.7811279296875
INFO:root:# Valid (Epoch 21): Loss/seq after 00150 batches: 1153.718994140625
INFO:root:# Valid (Epoch 21): Loss/seq after 00200 batches: 1037.290771484375
INFO:root:Artifacts: Make stick videos for epoch 21
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_21_on_20220413_164101.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_21_index_280_on_20220413_164101.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 22): Loss/seq after 00000 batchs: 2296.6279296875
INFO:root:Train (Epoch 22): Loss/seq after 00050 batchs: 1721.290771484375
INFO:root:Train (Epoch 22): Loss/seq after 00100 batchs: 1681.3638916015625
INFO:root:Train (Epoch 22): Loss/seq after 00150 batchs: 1494.77880859375
INFO:root:Train (Epoch 22): Loss/seq after 00200 batchs: 1608.7291259765625
INFO:root:Train (Epoch 22): Loss/seq after 00250 batchs: 1722.76025390625
INFO:root:Train (Epoch 22): Loss/seq after 00300 batchs: 1620.4207763671875
INFO:root:Train (Epoch 22): Loss/seq after 00350 batchs: 1513.8970947265625
INFO:root:Train (Epoch 22): Loss/seq after 00400 batchs: 1570.3203125
INFO:root:Train (Epoch 22): Loss/seq after 00450 batchs: 1493.5311279296875
INFO:root:Train (Epoch 22): Loss/seq after 00500 batchs: 1523.9808349609375
INFO:root:Train (Epoch 22): Loss/seq after 00550 batchs: 1460.063232421875
INFO:root:Train (Epoch 22): Loss/seq after 00600 batchs: 1425.2591552734375
INFO:root:Train (Epoch 22): Loss/seq after 00650 batchs: 1461.53369140625
INFO:root:Train (Epoch 22): Loss/seq after 00700 batchs: 1480.0858154296875
INFO:root:Train (Epoch 22): Loss/seq after 00750 batchs: 1516.9853515625
INFO:root:Train (Epoch 22): Loss/seq after 00800 batchs: 1506.7962646484375
INFO:root:Train (Epoch 22): Loss/seq after 00850 batchs: 1473.416259765625
INFO:root:Train (Epoch 22): Loss/seq after 00900 batchs: 1482.013427734375
INFO:root:Train (Epoch 22): Loss/seq after 00950 batchs: 1543.7493896484375
INFO:root:Train (Epoch 22): Loss/seq after 01000 batchs: 1542.5863037109375
INFO:root:Train (Epoch 22): Loss/seq after 01050 batchs: 1520.80712890625
INFO:root:Train (Epoch 22): Loss/seq after 01100 batchs: 1511.09521484375
INFO:root:Train (Epoch 22): Loss/seq after 01150 batchs: 1488.4283447265625
INFO:root:Train (Epoch 22): Loss/seq after 01200 batchs: 1472.5450439453125
INFO:root:Train (Epoch 22): Loss/seq after 01250 batchs: 1467.371337890625
INFO:root:Train (Epoch 22): Loss/seq after 01300 batchs: 1471.693603515625
INFO:root:Train (Epoch 22): Loss/seq after 01350 batchs: 1470.7442626953125
INFO:root:Train (Epoch 22): Loss/seq after 01400 batchs: 1510.82421875
INFO:root:Train (Epoch 22): Loss/seq after 01450 batchs: 1496.16259765625
INFO:root:Train (Epoch 22): Loss/seq after 01500 batchs: 1481.7303466796875
INFO:root:Train (Epoch 22): Loss/seq after 01550 batchs: 1481.941650390625
INFO:root:Train (Epoch 22): Loss/seq after 01600 batchs: 1460.8175048828125
INFO:root:Train (Epoch 22): Loss/seq after 01650 batchs: 1451.8856201171875
INFO:root:Train (Epoch 22): Loss/seq after 01700 batchs: 1439.43896484375
INFO:root:Train (Epoch 22): Loss/seq after 01750 batchs: 1424.029052734375
INFO:root:Train (Epoch 22): Loss/seq after 01800 batchs: 1406.7567138671875
INFO:root:Train (Epoch 22): Loss/seq after 01850 batchs: 1390.0198974609375
INFO:root:Train (Epoch 22): Loss/seq after 01900 batchs: 1386.15234375
INFO:root:Train (Epoch 22): Loss/seq after 01950 batchs: 1378.8016357421875
INFO:root:Train (Epoch 22): Loss/seq after 02000 batchs: 1366.760498046875
INFO:root:Train (Epoch 22): Loss/seq after 02050 batchs: 1356.360107421875
INFO:root:Train (Epoch 22): Loss/seq after 02100 batchs: 1342.83544921875
INFO:root:Train (Epoch 22): Loss/seq after 02150 batchs: 1330.2532958984375
INFO:root:Train (Epoch 22): Loss/seq after 02200 batchs: 1316.994873046875
INFO:root:Train (Epoch 22): Loss/seq after 02250 batchs: 1319.9942626953125
INFO:root:Train (Epoch 22): Loss/seq after 02300 batchs: 1324.003173828125
INFO:root:Train (Epoch 22): Loss/seq after 02350 batchs: 1313.585693359375
INFO:root:Train (Epoch 22): Loss/seq after 02400 batchs: 1308.25244140625
INFO:root:Train (Epoch 22): Loss/seq after 02450 batchs: 1294.22119140625
INFO:root:Train (Epoch 22): Loss/seq after 02500 batchs: 1275.599853515625
INFO:root:Train (Epoch 22): Loss/seq after 02550 batchs: 1263.280517578125
INFO:root:Train (Epoch 22): Loss/seq after 02600 batchs: 1259.5460205078125
INFO:root:Train (Epoch 22): Loss/seq after 02650 batchs: 1253.82275390625
INFO:root:Train (Epoch 22): Loss/seq after 02700 batchs: 1249.5804443359375
INFO:root:Train (Epoch 22): Loss/seq after 02750 batchs: 1280.1004638671875
INFO:root:Train (Epoch 22): Loss/seq after 02800 batchs: 1287.06884765625
INFO:root:Train (Epoch 22): Loss/seq after 02850 batchs: 1283.170166015625
INFO:root:Train (Epoch 22): Loss/seq after 02900 batchs: 1280.46044921875
INFO:root:Train (Epoch 22): Loss/seq after 02950 batchs: 1271.9901123046875
INFO:root:Train (Epoch 22): Loss/seq after 03000 batchs: 1268.881591796875
INFO:root:Train (Epoch 22): Loss/seq after 03050 batchs: 1270.527099609375
INFO:root:Train (Epoch 22): Loss/seq after 03100 batchs: 1286.2230224609375
INFO:root:Train (Epoch 22): Loss/seq after 03150 batchs: 1301.5357666015625
INFO:root:Train (Epoch 22): Loss/seq after 03200 batchs: 1311.0836181640625
INFO:root:Train (Epoch 22): Loss/seq after 03250 batchs: 1318.137451171875
INFO:root:Train (Epoch 22): Loss/seq after 03300 batchs: 1318.78515625
INFO:root:Train (Epoch 22): Loss/seq after 03350 batchs: 1318.5545654296875
INFO:root:Train (Epoch 22): Loss/seq after 03400 batchs: 1308.65673828125
INFO:root:Train (Epoch 22): Loss/seq after 03450 batchs: 1300.5653076171875
INFO:root:Train (Epoch 22): Loss/seq after 03500 batchs: 1300.060791015625
INFO:root:Train (Epoch 22): Loss/seq after 03550 batchs: 1294.4285888671875
INFO:root:Train (Epoch 22): Loss/seq after 03600 batchs: 1299.3133544921875
INFO:root:Train (Epoch 22): Loss/seq after 03650 batchs: 1294.2098388671875
INFO:root:Train (Epoch 22): Loss/seq after 03700 batchs: 1292.9981689453125
INFO:root:Train (Epoch 22): Loss/seq after 03750 batchs: 1292.047119140625
INFO:root:Train (Epoch 22): Loss/seq after 03800 batchs: 1284.2257080078125
INFO:root:Train (Epoch 22): Loss/seq after 03850 batchs: 1278.920654296875
INFO:root:Train (Epoch 22): Loss/seq after 03900 batchs: 1285.43212890625
INFO:root:Train (Epoch 22): Loss/seq after 03950 batchs: 1291.5108642578125
INFO:root:Train (Epoch 22): Loss/seq after 04000 batchs: 1281.6973876953125
INFO:root:Train (Epoch 22): Loss/seq after 04050 batchs: 1272.9124755859375
INFO:root:Train (Epoch 22): Loss/seq after 04100 batchs: 1266.566162109375
INFO:root:Train (Epoch 22): Loss/seq after 04150 batchs: 1260.05517578125
INFO:root:Train (Epoch 22): Loss/seq after 04200 batchs: 1254.596435546875
INFO:root:Train (Epoch 22): Loss/seq after 04250 batchs: 1249.63916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 22): Loss/seq after 00000 batches: 888.03564453125
INFO:root:# Valid (Epoch 22): Loss/seq after 00050 batches: 1120.3077392578125
INFO:root:# Valid (Epoch 22): Loss/seq after 00100 batches: 1417.7119140625
INFO:root:# Valid (Epoch 22): Loss/seq after 00150 batches: 1140.684814453125
INFO:root:# Valid (Epoch 22): Loss/seq after 00200 batches: 1027.2384033203125
INFO:root:Artifacts: Make stick videos for epoch 22
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_22_on_20220413_164620.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_22_index_587_on_20220413_164620.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 23): Loss/seq after 00000 batchs: 1620.6812744140625
INFO:root:Train (Epoch 23): Loss/seq after 00050 batchs: 1701.3203125
INFO:root:Train (Epoch 23): Loss/seq after 00100 batchs: 1657.6778564453125
INFO:root:Train (Epoch 23): Loss/seq after 00150 batchs: 1477.760009765625
INFO:root:Train (Epoch 23): Loss/seq after 00200 batchs: 1581.954833984375
INFO:root:Train (Epoch 23): Loss/seq after 00250 batchs: 1699.28466796875
INFO:root:Train (Epoch 23): Loss/seq after 00300 batchs: 1600.5054931640625
INFO:root:Train (Epoch 23): Loss/seq after 00350 batchs: 1496.112548828125
INFO:root:Train (Epoch 23): Loss/seq after 00400 batchs: 1552.343994140625
INFO:root:Train (Epoch 23): Loss/seq after 00450 batchs: 1477.3642578125
INFO:root:Train (Epoch 23): Loss/seq after 00500 batchs: 1510.84423828125
INFO:root:Train (Epoch 23): Loss/seq after 00550 batchs: 1448.4271240234375
INFO:root:Train (Epoch 23): Loss/seq after 00600 batchs: 1413.8546142578125
INFO:root:Train (Epoch 23): Loss/seq after 00650 batchs: 1447.2435302734375
INFO:root:Train (Epoch 23): Loss/seq after 00700 batchs: 1477.625
INFO:root:Train (Epoch 23): Loss/seq after 00750 batchs: 1513.23583984375
INFO:root:Train (Epoch 23): Loss/seq after 00800 batchs: 1502.88427734375
INFO:root:Train (Epoch 23): Loss/seq after 00850 batchs: 1468.4688720703125
INFO:root:Train (Epoch 23): Loss/seq after 00900 batchs: 1475.00537109375
INFO:root:Train (Epoch 23): Loss/seq after 00950 batchs: 1534.5240478515625
INFO:root:Train (Epoch 23): Loss/seq after 01000 batchs: 1530.3634033203125
INFO:root:Train (Epoch 23): Loss/seq after 01050 batchs: 1508.71240234375
INFO:root:Train (Epoch 23): Loss/seq after 01100 batchs: 1496.964599609375
INFO:root:Train (Epoch 23): Loss/seq after 01150 batchs: 1473.8818359375
INFO:root:Train (Epoch 23): Loss/seq after 01200 batchs: 1457.713623046875
INFO:root:Train (Epoch 23): Loss/seq after 01250 batchs: 1448.361328125
INFO:root:Train (Epoch 23): Loss/seq after 01300 batchs: 1455.1640625
INFO:root:Train (Epoch 23): Loss/seq after 01350 batchs: 1455.03759765625
INFO:root:Train (Epoch 23): Loss/seq after 01400 batchs: 1492.087158203125
INFO:root:Train (Epoch 23): Loss/seq after 01450 batchs: 1477.4503173828125
INFO:root:Train (Epoch 23): Loss/seq after 01500 batchs: 1463.367919921875
INFO:root:Train (Epoch 23): Loss/seq after 01550 batchs: 1463.734130859375
INFO:root:Train (Epoch 23): Loss/seq after 01600 batchs: 1442.9913330078125
INFO:root:Train (Epoch 23): Loss/seq after 01650 batchs: 1434.5977783203125
INFO:root:Train (Epoch 23): Loss/seq after 01700 batchs: 1422.5888671875
INFO:root:Train (Epoch 23): Loss/seq after 01750 batchs: 1407.5858154296875
INFO:root:Train (Epoch 23): Loss/seq after 01800 batchs: 1390.7991943359375
INFO:root:Train (Epoch 23): Loss/seq after 01850 batchs: 1374.5443115234375
INFO:root:Train (Epoch 23): Loss/seq after 01900 batchs: 1371.119384765625
INFO:root:Train (Epoch 23): Loss/seq after 01950 batchs: 1364.128662109375
INFO:root:Train (Epoch 23): Loss/seq after 02000 batchs: 1352.3843994140625
INFO:root:Train (Epoch 23): Loss/seq after 02050 batchs: 1342.3055419921875
INFO:root:Train (Epoch 23): Loss/seq after 02100 batchs: 1329.13330078125
INFO:root:Train (Epoch 23): Loss/seq after 02150 batchs: 1316.8948974609375
INFO:root:Train (Epoch 23): Loss/seq after 02200 batchs: 1303.9130859375
INFO:root:Train (Epoch 23): Loss/seq after 02250 batchs: 1307.2666015625
INFO:root:Train (Epoch 23): Loss/seq after 02300 batchs: 1311.1153564453125
INFO:root:Train (Epoch 23): Loss/seq after 02350 batchs: 1300.85986328125
INFO:root:Train (Epoch 23): Loss/seq after 02400 batchs: 1295.8895263671875
INFO:root:Train (Epoch 23): Loss/seq after 02450 batchs: 1282.072509765625
INFO:root:Train (Epoch 23): Loss/seq after 02500 batchs: 1263.65380859375
INFO:root:Train (Epoch 23): Loss/seq after 02550 batchs: 1251.728271484375
INFO:root:Train (Epoch 23): Loss/seq after 02600 batchs: 1249.140625
INFO:root:Train (Epoch 23): Loss/seq after 02650 batchs: 1243.8070068359375
INFO:root:Train (Epoch 23): Loss/seq after 02700 batchs: 1239.9932861328125
INFO:root:Train (Epoch 23): Loss/seq after 02750 batchs: 1271.1546630859375
INFO:root:Train (Epoch 23): Loss/seq after 02800 batchs: 1278.93505859375
INFO:root:Train (Epoch 23): Loss/seq after 02850 batchs: 1275.20068359375
INFO:root:Train (Epoch 23): Loss/seq after 02900 batchs: 1272.6678466796875
INFO:root:Train (Epoch 23): Loss/seq after 02950 batchs: 1263.7822265625
INFO:root:Train (Epoch 23): Loss/seq after 03000 batchs: 1260.8585205078125
INFO:root:Train (Epoch 23): Loss/seq after 03050 batchs: 1262.619140625
INFO:root:Train (Epoch 23): Loss/seq after 03100 batchs: 1277.3590087890625
INFO:root:Train (Epoch 23): Loss/seq after 03150 batchs: 1291.7413330078125
INFO:root:Train (Epoch 23): Loss/seq after 03200 batchs: 1300.599853515625
INFO:root:Train (Epoch 23): Loss/seq after 03250 batchs: 1306.7359619140625
INFO:root:Train (Epoch 23): Loss/seq after 03300 batchs: 1306.2147216796875
INFO:root:Train (Epoch 23): Loss/seq after 03350 batchs: 1306.220703125
INFO:root:Train (Epoch 23): Loss/seq after 03400 batchs: 1296.6666259765625
INFO:root:Train (Epoch 23): Loss/seq after 03450 batchs: 1289.03662109375
INFO:root:Train (Epoch 23): Loss/seq after 03500 batchs: 1288.543212890625
INFO:root:Train (Epoch 23): Loss/seq after 03550 batchs: 1282.832275390625
INFO:root:Train (Epoch 23): Loss/seq after 03600 batchs: 1288.0107421875
INFO:root:Train (Epoch 23): Loss/seq after 03650 batchs: 1283.0518798828125
INFO:root:Train (Epoch 23): Loss/seq after 03700 batchs: 1282.049072265625
INFO:root:Train (Epoch 23): Loss/seq after 03750 batchs: 1281.2757568359375
INFO:root:Train (Epoch 23): Loss/seq after 03800 batchs: 1273.6197509765625
INFO:root:Train (Epoch 23): Loss/seq after 03850 batchs: 1268.4468994140625
INFO:root:Train (Epoch 23): Loss/seq after 03900 batchs: 1274.796630859375
INFO:root:Train (Epoch 23): Loss/seq after 03950 batchs: 1281.02685546875
INFO:root:Train (Epoch 23): Loss/seq after 04000 batchs: 1271.315673828125
INFO:root:Train (Epoch 23): Loss/seq after 04050 batchs: 1262.658935546875
INFO:root:Train (Epoch 23): Loss/seq after 04100 batchs: 1257.13623046875
INFO:root:Train (Epoch 23): Loss/seq after 04150 batchs: 1250.89990234375
INFO:root:Train (Epoch 23): Loss/seq after 04200 batchs: 1245.396240234375
INFO:root:Train (Epoch 23): Loss/seq after 04250 batchs: 1240.553955078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 23): Loss/seq after 00000 batches: 882.5562744140625
INFO:root:# Valid (Epoch 23): Loss/seq after 00050 batches: 1101.651123046875
INFO:root:# Valid (Epoch 23): Loss/seq after 00100 batches: 1410.2388916015625
INFO:root:# Valid (Epoch 23): Loss/seq after 00150 batches: 1136.727783203125
INFO:root:# Valid (Epoch 23): Loss/seq after 00200 batches: 1025.046875
INFO:root:Artifacts: Make stick videos for epoch 23
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_23_on_20220413_165140.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_23_index_4_on_20220413_165140.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 24): Loss/seq after 00000 batchs: 1759.5411376953125
INFO:root:Train (Epoch 24): Loss/seq after 00050 batchs: 1689.7513427734375
INFO:root:Train (Epoch 24): Loss/seq after 00100 batchs: 1638.7327880859375
INFO:root:Train (Epoch 24): Loss/seq after 00150 batchs: 1463.9132080078125
INFO:root:Train (Epoch 24): Loss/seq after 00200 batchs: 1576.05517578125
INFO:root:Train (Epoch 24): Loss/seq after 00250 batchs: 1695.6834716796875
INFO:root:Train (Epoch 24): Loss/seq after 00300 batchs: 1597.4993896484375
INFO:root:Train (Epoch 24): Loss/seq after 00350 batchs: 1493.408935546875
INFO:root:Train (Epoch 24): Loss/seq after 00400 batchs: 1546.3878173828125
INFO:root:Train (Epoch 24): Loss/seq after 00450 batchs: 1472.092041015625
INFO:root:Train (Epoch 24): Loss/seq after 00500 batchs: 1507.04541015625
INFO:root:Train (Epoch 24): Loss/seq after 00550 batchs: 1444.3046875
INFO:root:Train (Epoch 24): Loss/seq after 00600 batchs: 1409.44384765625
INFO:root:Train (Epoch 24): Loss/seq after 00650 batchs: 1428.6141357421875
INFO:root:Train (Epoch 24): Loss/seq after 00700 batchs: 1470.7523193359375
INFO:root:Train (Epoch 24): Loss/seq after 00750 batchs: 1505.7159423828125
INFO:root:Train (Epoch 24): Loss/seq after 00800 batchs: 1496.6929931640625
INFO:root:Train (Epoch 24): Loss/seq after 00850 batchs: 1463.04150390625
INFO:root:Train (Epoch 24): Loss/seq after 00900 batchs: 1467.6610107421875
INFO:root:Train (Epoch 24): Loss/seq after 00950 batchs: 1537.212890625
INFO:root:Train (Epoch 24): Loss/seq after 01000 batchs: 1534.249755859375
INFO:root:Train (Epoch 24): Loss/seq after 01050 batchs: 1512.1318359375
INFO:root:Train (Epoch 24): Loss/seq after 01100 batchs: 1500.900390625
INFO:root:Train (Epoch 24): Loss/seq after 01150 batchs: 1478.4205322265625
INFO:root:Train (Epoch 24): Loss/seq after 01200 batchs: 1462.9388427734375
INFO:root:Train (Epoch 24): Loss/seq after 01250 batchs: 1455.1451416015625
INFO:root:Train (Epoch 24): Loss/seq after 01300 batchs: 1458.6793212890625
INFO:root:Train (Epoch 24): Loss/seq after 01350 batchs: 1457.5853271484375
INFO:root:Train (Epoch 24): Loss/seq after 01400 batchs: 1487.34375
INFO:root:Train (Epoch 24): Loss/seq after 01450 batchs: 1473.365966796875
INFO:root:Train (Epoch 24): Loss/seq after 01500 batchs: 1459.40673828125
INFO:root:Train (Epoch 24): Loss/seq after 01550 batchs: 1462.94091796875
INFO:root:Train (Epoch 24): Loss/seq after 01600 batchs: 1442.23095703125
INFO:root:Train (Epoch 24): Loss/seq after 01650 batchs: 1436.294921875
INFO:root:Train (Epoch 24): Loss/seq after 01700 batchs: 1424.7255859375
INFO:root:Train (Epoch 24): Loss/seq after 01750 batchs: 1409.9644775390625
INFO:root:Train (Epoch 24): Loss/seq after 01800 batchs: 1394.3055419921875
INFO:root:Train (Epoch 24): Loss/seq after 01850 batchs: 1378.0794677734375
INFO:root:Train (Epoch 24): Loss/seq after 01900 batchs: 1374.852294921875
INFO:root:Train (Epoch 24): Loss/seq after 01950 batchs: 1367.91748046875
INFO:root:Train (Epoch 24): Loss/seq after 02000 batchs: 1356.3438720703125
INFO:root:Train (Epoch 24): Loss/seq after 02050 batchs: 1346.4912109375
INFO:root:Train (Epoch 24): Loss/seq after 02100 batchs: 1333.3994140625
INFO:root:Train (Epoch 24): Loss/seq after 02150 batchs: 1321.6978759765625
INFO:root:Train (Epoch 24): Loss/seq after 02200 batchs: 1308.680419921875
INFO:root:Train (Epoch 24): Loss/seq after 02250 batchs: 1314.2374267578125
INFO:root:Train (Epoch 24): Loss/seq after 02300 batchs: 1318.43310546875
INFO:root:Train (Epoch 24): Loss/seq after 02350 batchs: 1308.163818359375
INFO:root:Train (Epoch 24): Loss/seq after 02400 batchs: 1303.01611328125
INFO:root:Train (Epoch 24): Loss/seq after 02450 batchs: 1289.212890625
INFO:root:Train (Epoch 24): Loss/seq after 02500 batchs: 1270.7314453125
INFO:root:Train (Epoch 24): Loss/seq after 02550 batchs: 1258.8165283203125
INFO:root:Train (Epoch 24): Loss/seq after 02600 batchs: 1257.6873779296875
INFO:root:Train (Epoch 24): Loss/seq after 02650 batchs: 1252.7222900390625
INFO:root:Train (Epoch 24): Loss/seq after 02700 batchs: 1249.84765625
INFO:root:Train (Epoch 24): Loss/seq after 02750 batchs: 1280.877197265625
INFO:root:Train (Epoch 24): Loss/seq after 02800 batchs: 1289.0445556640625
INFO:root:Train (Epoch 24): Loss/seq after 02850 batchs: 1286.1544189453125
INFO:root:Train (Epoch 24): Loss/seq after 02900 batchs: 1283.5142822265625
INFO:root:Train (Epoch 24): Loss/seq after 02950 batchs: 1275.0433349609375
INFO:root:Train (Epoch 24): Loss/seq after 03000 batchs: 1271.92333984375
INFO:root:Train (Epoch 24): Loss/seq after 03050 batchs: 1273.530517578125
INFO:root:Train (Epoch 24): Loss/seq after 03100 batchs: 1288.1265869140625
INFO:root:Train (Epoch 24): Loss/seq after 03150 batchs: 1301.93359375
INFO:root:Train (Epoch 24): Loss/seq after 03200 batchs: 1310.7900390625
INFO:root:Train (Epoch 24): Loss/seq after 03250 batchs: 1317.528076171875
INFO:root:Train (Epoch 24): Loss/seq after 03300 batchs: 1316.4241943359375
INFO:root:Train (Epoch 24): Loss/seq after 03350 batchs: 1315.9393310546875
INFO:root:Train (Epoch 24): Loss/seq after 03400 batchs: 1306.172607421875
INFO:root:Train (Epoch 24): Loss/seq after 03450 batchs: 1298.5028076171875
INFO:root:Train (Epoch 24): Loss/seq after 03500 batchs: 1297.8843994140625
INFO:root:Train (Epoch 24): Loss/seq after 03550 batchs: 1292.0760498046875
INFO:root:Train (Epoch 24): Loss/seq after 03600 batchs: 1296.993408203125
INFO:root:Train (Epoch 24): Loss/seq after 03650 batchs: 1291.87744140625
INFO:root:Train (Epoch 24): Loss/seq after 03700 batchs: 1290.712158203125
INFO:root:Train (Epoch 24): Loss/seq after 03750 batchs: 1289.8060302734375
INFO:root:Train (Epoch 24): Loss/seq after 03800 batchs: 1282.0435791015625
INFO:root:Train (Epoch 24): Loss/seq after 03850 batchs: 1276.755126953125
INFO:root:Train (Epoch 24): Loss/seq after 03900 batchs: 1282.97216796875
INFO:root:Train (Epoch 24): Loss/seq after 03950 batchs: 1288.701416015625
INFO:root:Train (Epoch 24): Loss/seq after 04000 batchs: 1278.9273681640625
INFO:root:Train (Epoch 24): Loss/seq after 04050 batchs: 1270.18212890625
INFO:root:Train (Epoch 24): Loss/seq after 04100 batchs: 1264.297119140625
INFO:root:Train (Epoch 24): Loss/seq after 04150 batchs: 1257.89990234375
INFO:root:Train (Epoch 24): Loss/seq after 04200 batchs: 1252.18701171875
INFO:root:Train (Epoch 24): Loss/seq after 04250 batchs: 1247.203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 24): Loss/seq after 00000 batches: 882.7457885742188
INFO:root:# Valid (Epoch 24): Loss/seq after 00050 batches: 1102.5345458984375
INFO:root:# Valid (Epoch 24): Loss/seq after 00100 batches: 1424.4805908203125
INFO:root:# Valid (Epoch 24): Loss/seq after 00150 batches: 1162.018310546875
INFO:root:# Valid (Epoch 24): Loss/seq after 00200 batches: 1049.499755859375
INFO:root:Artifacts: Make stick videos for epoch 24
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_24_on_20220413_165659.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_24_index_1583_on_20220413_165659.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 25): Loss/seq after 00000 batchs: 1960.5438232421875
INFO:root:Train (Epoch 25): Loss/seq after 00050 batchs: 1707.8887939453125
INFO:root:Train (Epoch 25): Loss/seq after 00100 batchs: 1660.30810546875
INFO:root:Train (Epoch 25): Loss/seq after 00150 batchs: 1478.259033203125
INFO:root:Train (Epoch 25): Loss/seq after 00200 batchs: 1585.6080322265625
INFO:root:Train (Epoch 25): Loss/seq after 00250 batchs: 1707.4869384765625
INFO:root:Train (Epoch 25): Loss/seq after 00300 batchs: 1607.056396484375
INFO:root:Train (Epoch 25): Loss/seq after 00350 batchs: 1501.838134765625
INFO:root:Train (Epoch 25): Loss/seq after 00400 batchs: 1557.7510986328125
INFO:root:Train (Epoch 25): Loss/seq after 00450 batchs: 1482.5677490234375
INFO:root:Train (Epoch 25): Loss/seq after 00500 batchs: 1514.3917236328125
INFO:root:Train (Epoch 25): Loss/seq after 00550 batchs: 1450.86279296875
INFO:root:Train (Epoch 25): Loss/seq after 00600 batchs: 1414.20556640625
INFO:root:Train (Epoch 25): Loss/seq after 00650 batchs: 1443.8294677734375
INFO:root:Train (Epoch 25): Loss/seq after 00700 batchs: 1471.9984130859375
INFO:root:Train (Epoch 25): Loss/seq after 00750 batchs: 1500.59228515625
INFO:root:Train (Epoch 25): Loss/seq after 00800 batchs: 1491.1981201171875
INFO:root:Train (Epoch 25): Loss/seq after 00850 batchs: 1456.789794921875
INFO:root:Train (Epoch 25): Loss/seq after 00900 batchs: 1460.94482421875
INFO:root:Train (Epoch 25): Loss/seq after 00950 batchs: 1512.904541015625
INFO:root:Train (Epoch 25): Loss/seq after 01000 batchs: 1506.0562744140625
INFO:root:Train (Epoch 25): Loss/seq after 01050 batchs: 1483.908447265625
INFO:root:Train (Epoch 25): Loss/seq after 01100 batchs: 1472.7919921875
INFO:root:Train (Epoch 25): Loss/seq after 01150 batchs: 1450.6724853515625
INFO:root:Train (Epoch 25): Loss/seq after 01200 batchs: 1435.5894775390625
INFO:root:Train (Epoch 25): Loss/seq after 01250 batchs: 1426.766845703125
INFO:root:Train (Epoch 25): Loss/seq after 01300 batchs: 1431.7222900390625
INFO:root:Train (Epoch 25): Loss/seq after 01350 batchs: 1430.6597900390625
INFO:root:Train (Epoch 25): Loss/seq after 01400 batchs: 1456.2481689453125
INFO:root:Train (Epoch 25): Loss/seq after 01450 batchs: 1443.2647705078125
INFO:root:Train (Epoch 25): Loss/seq after 01500 batchs: 1430.507080078125
INFO:root:Train (Epoch 25): Loss/seq after 01550 batchs: 1432.484619140625
INFO:root:Train (Epoch 25): Loss/seq after 01600 batchs: 1412.96337890625
INFO:root:Train (Epoch 25): Loss/seq after 01650 batchs: 1407.6370849609375
INFO:root:Train (Epoch 25): Loss/seq after 01700 batchs: 1396.6387939453125
INFO:root:Train (Epoch 25): Loss/seq after 01750 batchs: 1382.547119140625
INFO:root:Train (Epoch 25): Loss/seq after 01800 batchs: 1367.4423828125
INFO:root:Train (Epoch 25): Loss/seq after 01850 batchs: 1351.9527587890625
INFO:root:Train (Epoch 25): Loss/seq after 01900 batchs: 1349.2738037109375
INFO:root:Train (Epoch 25): Loss/seq after 01950 batchs: 1342.8385009765625
INFO:root:Train (Epoch 25): Loss/seq after 02000 batchs: 1331.652587890625
INFO:root:Train (Epoch 25): Loss/seq after 02050 batchs: 1322.1494140625
INFO:root:Train (Epoch 25): Loss/seq after 02100 batchs: 1309.421142578125
INFO:root:Train (Epoch 25): Loss/seq after 02150 batchs: 1297.7724609375
INFO:root:Train (Epoch 25): Loss/seq after 02200 batchs: 1285.243896484375
INFO:root:Train (Epoch 25): Loss/seq after 02250 batchs: 1289.00732421875
INFO:root:Train (Epoch 25): Loss/seq after 02300 batchs: 1294.10888671875
INFO:root:Train (Epoch 25): Loss/seq after 02350 batchs: 1284.0792236328125
INFO:root:Train (Epoch 25): Loss/seq after 02400 batchs: 1279.290283203125
INFO:root:Train (Epoch 25): Loss/seq after 02450 batchs: 1265.803955078125
INFO:root:Train (Epoch 25): Loss/seq after 02500 batchs: 1247.77099609375
INFO:root:Train (Epoch 25): Loss/seq after 02550 batchs: 1236.2548828125
INFO:root:Train (Epoch 25): Loss/seq after 02600 batchs: 1233.1796875
INFO:root:Train (Epoch 25): Loss/seq after 02650 batchs: 1227.823486328125
INFO:root:Train (Epoch 25): Loss/seq after 02700 batchs: 1223.949951171875
INFO:root:Train (Epoch 25): Loss/seq after 02750 batchs: 1254.6173095703125
INFO:root:Train (Epoch 25): Loss/seq after 02800 batchs: 1261.8626708984375
INFO:root:Train (Epoch 25): Loss/seq after 02850 batchs: 1258.4193115234375
INFO:root:Train (Epoch 25): Loss/seq after 02900 batchs: 1255.8382568359375
INFO:root:Train (Epoch 25): Loss/seq after 02950 batchs: 1247.438720703125
INFO:root:Train (Epoch 25): Loss/seq after 03000 batchs: 1244.7628173828125
INFO:root:Train (Epoch 25): Loss/seq after 03050 batchs: 1246.8277587890625
INFO:root:Train (Epoch 25): Loss/seq after 03100 batchs: 1261.275146484375
INFO:root:Train (Epoch 25): Loss/seq after 03150 batchs: 1274.4970703125
INFO:root:Train (Epoch 25): Loss/seq after 03200 batchs: 1280.958984375
INFO:root:Train (Epoch 25): Loss/seq after 03250 batchs: 1288.0078125
INFO:root:Train (Epoch 25): Loss/seq after 03300 batchs: 1287.02587890625
INFO:root:Train (Epoch 25): Loss/seq after 03350 batchs: 1286.9801025390625
INFO:root:Train (Epoch 25): Loss/seq after 03400 batchs: 1277.6385498046875
INFO:root:Train (Epoch 25): Loss/seq after 03450 batchs: 1270.5875244140625
INFO:root:Train (Epoch 25): Loss/seq after 03500 batchs: 1270.015869140625
INFO:root:Train (Epoch 25): Loss/seq after 03550 batchs: 1264.6748046875
INFO:root:Train (Epoch 25): Loss/seq after 03600 batchs: 1269.938232421875
INFO:root:Train (Epoch 25): Loss/seq after 03650 batchs: 1265.151611328125
INFO:root:Train (Epoch 25): Loss/seq after 03700 batchs: 1264.362060546875
INFO:root:Train (Epoch 25): Loss/seq after 03750 batchs: 1263.7322998046875
INFO:root:Train (Epoch 25): Loss/seq after 03800 batchs: 1256.256591796875
INFO:root:Train (Epoch 25): Loss/seq after 03850 batchs: 1251.3392333984375
INFO:root:Train (Epoch 25): Loss/seq after 03900 batchs: 1257.8719482421875
INFO:root:Train (Epoch 25): Loss/seq after 03950 batchs: 1263.6124267578125
INFO:root:Train (Epoch 25): Loss/seq after 04000 batchs: 1254.1622314453125
INFO:root:Train (Epoch 25): Loss/seq after 04050 batchs: 1245.7227783203125
INFO:root:Train (Epoch 25): Loss/seq after 04100 batchs: 1240.2054443359375
INFO:root:Train (Epoch 25): Loss/seq after 04150 batchs: 1234.2396240234375
INFO:root:Train (Epoch 25): Loss/seq after 04200 batchs: 1228.884521484375
INFO:root:Train (Epoch 25): Loss/seq after 04250 batchs: 1224.3778076171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 25): Loss/seq after 00000 batches: 906.6585083007812
INFO:root:# Valid (Epoch 25): Loss/seq after 00050 batches: 1110.0396728515625
INFO:root:# Valid (Epoch 25): Loss/seq after 00100 batches: 1418.235595703125
INFO:root:# Valid (Epoch 25): Loss/seq after 00150 batches: 1144.7698974609375
INFO:root:# Valid (Epoch 25): Loss/seq after 00200 batches: 1029.5760498046875
INFO:root:Artifacts: Make stick videos for epoch 25
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_25_on_20220413_170215.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_25_index_786_on_20220413_170215.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 26): Loss/seq after 00000 batchs: 2391.209716796875
INFO:root:Train (Epoch 26): Loss/seq after 00050 batchs: 1682.8240966796875
INFO:root:Train (Epoch 26): Loss/seq after 00100 batchs: 1635.6678466796875
INFO:root:Train (Epoch 26): Loss/seq after 00150 batchs: 1456.920654296875
INFO:root:Train (Epoch 26): Loss/seq after 00200 batchs: 1555.9427490234375
INFO:root:Train (Epoch 26): Loss/seq after 00250 batchs: 1680.572998046875
INFO:root:Train (Epoch 26): Loss/seq after 00300 batchs: 1584.670654296875
INFO:root:Train (Epoch 26): Loss/seq after 00350 batchs: 1480.501220703125
INFO:root:Train (Epoch 26): Loss/seq after 00400 batchs: 1529.900146484375
INFO:root:Train (Epoch 26): Loss/seq after 00450 batchs: 1457.4891357421875
INFO:root:Train (Epoch 26): Loss/seq after 00500 batchs: 1479.9881591796875
INFO:root:Train (Epoch 26): Loss/seq after 00550 batchs: 1419.8140869140625
INFO:root:Train (Epoch 26): Loss/seq after 00600 batchs: 1385.449462890625
INFO:root:Train (Epoch 26): Loss/seq after 00650 batchs: 1411.8968505859375
INFO:root:Train (Epoch 26): Loss/seq after 00700 batchs: 1444.48486328125
INFO:root:Train (Epoch 26): Loss/seq after 00750 batchs: 1479.7337646484375
INFO:root:Train (Epoch 26): Loss/seq after 00800 batchs: 1474.1053466796875
INFO:root:Train (Epoch 26): Loss/seq after 00850 batchs: 1440.9676513671875
INFO:root:Train (Epoch 26): Loss/seq after 00900 batchs: 1445.838134765625
INFO:root:Train (Epoch 26): Loss/seq after 00950 batchs: 1501.9410400390625
INFO:root:Train (Epoch 26): Loss/seq after 01000 batchs: 1497.220458984375
INFO:root:Train (Epoch 26): Loss/seq after 01050 batchs: 1472.58251953125
INFO:root:Train (Epoch 26): Loss/seq after 01100 batchs: 1461.8466796875
INFO:root:Train (Epoch 26): Loss/seq after 01150 batchs: 1440.448974609375
INFO:root:Train (Epoch 26): Loss/seq after 01200 batchs: 1426.500732421875
INFO:root:Train (Epoch 26): Loss/seq after 01250 batchs: 1417.9171142578125
INFO:root:Train (Epoch 26): Loss/seq after 01300 batchs: 1420.6466064453125
INFO:root:Train (Epoch 26): Loss/seq after 01350 batchs: 1421.894775390625
INFO:root:Train (Epoch 26): Loss/seq after 01400 batchs: 1457.9278564453125
INFO:root:Train (Epoch 26): Loss/seq after 01450 batchs: 1444.2943115234375
INFO:root:Train (Epoch 26): Loss/seq after 01500 batchs: 1431.413818359375
INFO:root:Train (Epoch 26): Loss/seq after 01550 batchs: 1432.4356689453125
INFO:root:Train (Epoch 26): Loss/seq after 01600 batchs: 1412.7535400390625
INFO:root:Train (Epoch 26): Loss/seq after 01650 batchs: 1405.742431640625
INFO:root:Train (Epoch 26): Loss/seq after 01700 batchs: 1394.647216796875
INFO:root:Train (Epoch 26): Loss/seq after 01750 batchs: 1380.5262451171875
INFO:root:Train (Epoch 26): Loss/seq after 01800 batchs: 1364.4537353515625
INFO:root:Train (Epoch 26): Loss/seq after 01850 batchs: 1348.909912109375
INFO:root:Train (Epoch 26): Loss/seq after 01900 batchs: 1346.1083984375
INFO:root:Train (Epoch 26): Loss/seq after 01950 batchs: 1339.68115234375
INFO:root:Train (Epoch 26): Loss/seq after 02000 batchs: 1328.5438232421875
INFO:root:Train (Epoch 26): Loss/seq after 02050 batchs: 1319.02783203125
INFO:root:Train (Epoch 26): Loss/seq after 02100 batchs: 1306.37158203125
INFO:root:Train (Epoch 26): Loss/seq after 02150 batchs: 1294.549072265625
INFO:root:Train (Epoch 26): Loss/seq after 02200 batchs: 1282.066162109375
INFO:root:Train (Epoch 26): Loss/seq after 02250 batchs: 1284.4248046875
INFO:root:Train (Epoch 26): Loss/seq after 02300 batchs: 1288.1986083984375
INFO:root:Train (Epoch 26): Loss/seq after 02350 batchs: 1278.0594482421875
INFO:root:Train (Epoch 26): Loss/seq after 02400 batchs: 1272.98779296875
INFO:root:Train (Epoch 26): Loss/seq after 02450 batchs: 1259.6715087890625
INFO:root:Train (Epoch 26): Loss/seq after 02500 batchs: 1241.752197265625
INFO:root:Train (Epoch 26): Loss/seq after 02550 batchs: 1230.147216796875
INFO:root:Train (Epoch 26): Loss/seq after 02600 batchs: 1226.8172607421875
INFO:root:Train (Epoch 26): Loss/seq after 02650 batchs: 1221.6539306640625
INFO:root:Train (Epoch 26): Loss/seq after 02700 batchs: 1217.4166259765625
INFO:root:Train (Epoch 26): Loss/seq after 02750 batchs: 1248.26708984375
INFO:root:Train (Epoch 26): Loss/seq after 02800 batchs: 1255.320556640625
INFO:root:Train (Epoch 26): Loss/seq after 02850 batchs: 1251.2628173828125
INFO:root:Train (Epoch 26): Loss/seq after 02900 batchs: 1248.7012939453125
INFO:root:Train (Epoch 26): Loss/seq after 02950 batchs: 1240.19921875
INFO:root:Train (Epoch 26): Loss/seq after 03000 batchs: 1237.6341552734375
INFO:root:Train (Epoch 26): Loss/seq after 03050 batchs: 1239.76220703125
INFO:root:Train (Epoch 26): Loss/seq after 03100 batchs: 1252.9638671875
INFO:root:Train (Epoch 26): Loss/seq after 03150 batchs: 1264.727294921875
INFO:root:Train (Epoch 26): Loss/seq after 03200 batchs: 1272.42822265625
INFO:root:Train (Epoch 26): Loss/seq after 03250 batchs: 1279.5472412109375
INFO:root:Train (Epoch 26): Loss/seq after 03300 batchs: 1279.190185546875
INFO:root:Train (Epoch 26): Loss/seq after 03350 batchs: 1279.3104248046875
INFO:root:Train (Epoch 26): Loss/seq after 03400 batchs: 1270.2552490234375
INFO:root:Train (Epoch 26): Loss/seq after 03450 batchs: 1264.4459228515625
INFO:root:Train (Epoch 26): Loss/seq after 03500 batchs: 1265.035888671875
INFO:root:Train (Epoch 26): Loss/seq after 03550 batchs: 1260.103271484375
INFO:root:Train (Epoch 26): Loss/seq after 03600 batchs: 1265.57421875
INFO:root:Train (Epoch 26): Loss/seq after 03650 batchs: 1261.1141357421875
INFO:root:Train (Epoch 26): Loss/seq after 03700 batchs: 1260.6009521484375
INFO:root:Train (Epoch 26): Loss/seq after 03750 batchs: 1260.2303466796875
INFO:root:Train (Epoch 26): Loss/seq after 03800 batchs: 1252.9002685546875
INFO:root:Train (Epoch 26): Loss/seq after 03850 batchs: 1247.9810791015625
INFO:root:Train (Epoch 26): Loss/seq after 03900 batchs: 1253.1964111328125
INFO:root:Train (Epoch 26): Loss/seq after 03950 batchs: 1259.0543212890625
INFO:root:Train (Epoch 26): Loss/seq after 04000 batchs: 1249.6845703125
INFO:root:Train (Epoch 26): Loss/seq after 04050 batchs: 1241.310546875
INFO:root:Train (Epoch 26): Loss/seq after 04100 batchs: 1235.7581787109375
INFO:root:Train (Epoch 26): Loss/seq after 04150 batchs: 1229.631591796875
INFO:root:Train (Epoch 26): Loss/seq after 04200 batchs: 1224.29345703125
INFO:root:Train (Epoch 26): Loss/seq after 04250 batchs: 1219.7664794921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 26): Loss/seq after 00000 batches: 885.4181518554688
INFO:root:# Valid (Epoch 26): Loss/seq after 00050 batches: 1111.151123046875
INFO:root:# Valid (Epoch 26): Loss/seq after 00100 batches: 1405.51416015625
INFO:root:# Valid (Epoch 26): Loss/seq after 00150 batches: 1137.6400146484375
INFO:root:# Valid (Epoch 26): Loss/seq after 00200 batches: 1030.175048828125
INFO:root:Artifacts: Make stick videos for epoch 26
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_26_on_20220413_170732.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_26_index_1902_on_20220413_170732.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 27): Loss/seq after 00000 batchs: 1903.3629150390625
INFO:root:Train (Epoch 27): Loss/seq after 00050 batchs: 1670.4757080078125
INFO:root:Train (Epoch 27): Loss/seq after 00100 batchs: 1620.9932861328125
INFO:root:Train (Epoch 27): Loss/seq after 00150 batchs: 1446.6490478515625
INFO:root:Train (Epoch 27): Loss/seq after 00200 batchs: 1534.9747314453125
INFO:root:Train (Epoch 27): Loss/seq after 00250 batchs: 1669.7303466796875
INFO:root:Train (Epoch 27): Loss/seq after 00300 batchs: 1576.031982421875
INFO:root:Train (Epoch 27): Loss/seq after 00350 batchs: 1471.3448486328125
INFO:root:Train (Epoch 27): Loss/seq after 00400 batchs: 1512.9541015625
INFO:root:Train (Epoch 27): Loss/seq after 00450 batchs: 1442.310791015625
INFO:root:Train (Epoch 27): Loss/seq after 00500 batchs: 1468.677001953125
INFO:root:Train (Epoch 27): Loss/seq after 00550 batchs: 1408.80224609375
INFO:root:Train (Epoch 27): Loss/seq after 00600 batchs: 1370.1966552734375
INFO:root:Train (Epoch 27): Loss/seq after 00650 batchs: 1408.448486328125
INFO:root:Train (Epoch 27): Loss/seq after 00700 batchs: 1441.7244873046875
INFO:root:Train (Epoch 27): Loss/seq after 00750 batchs: 1472.7598876953125
INFO:root:Train (Epoch 27): Loss/seq after 00800 batchs: 1464.63427734375
INFO:root:Train (Epoch 27): Loss/seq after 00850 batchs: 1432.029541015625
INFO:root:Train (Epoch 27): Loss/seq after 00900 batchs: 1437.5291748046875
INFO:root:Train (Epoch 27): Loss/seq after 00950 batchs: 1494.5408935546875
INFO:root:Train (Epoch 27): Loss/seq after 01000 batchs: 1491.9906005859375
INFO:root:Train (Epoch 27): Loss/seq after 01050 batchs: 1466.177001953125
INFO:root:Train (Epoch 27): Loss/seq after 01100 batchs: 1462.0120849609375
INFO:root:Train (Epoch 27): Loss/seq after 01150 batchs: 1441.7742919921875
INFO:root:Train (Epoch 27): Loss/seq after 01200 batchs: 1427.997314453125
INFO:root:Train (Epoch 27): Loss/seq after 01250 batchs: 1426.9849853515625
INFO:root:Train (Epoch 27): Loss/seq after 01300 batchs: 1431.4368896484375
INFO:root:Train (Epoch 27): Loss/seq after 01350 batchs: 1432.04931640625
INFO:root:Train (Epoch 27): Loss/seq after 01400 batchs: 1464.4871826171875
INFO:root:Train (Epoch 27): Loss/seq after 01450 batchs: 1451.9708251953125
INFO:root:Train (Epoch 27): Loss/seq after 01500 batchs: 1438.97216796875
INFO:root:Train (Epoch 27): Loss/seq after 01550 batchs: 1438.8463134765625
INFO:root:Train (Epoch 27): Loss/seq after 01600 batchs: 1419.4053955078125
INFO:root:Train (Epoch 27): Loss/seq after 01650 batchs: 1411.179931640625
INFO:root:Train (Epoch 27): Loss/seq after 01700 batchs: 1400.893798828125
INFO:root:Train (Epoch 27): Loss/seq after 01750 batchs: 1386.7513427734375
INFO:root:Train (Epoch 27): Loss/seq after 01800 batchs: 1370.62841796875
INFO:root:Train (Epoch 27): Loss/seq after 01850 batchs: 1354.798095703125
INFO:root:Train (Epoch 27): Loss/seq after 01900 batchs: 1351.531982421875
INFO:root:Train (Epoch 27): Loss/seq after 01950 batchs: 1344.5599365234375
INFO:root:Train (Epoch 27): Loss/seq after 02000 batchs: 1333.129150390625
INFO:root:Train (Epoch 27): Loss/seq after 02050 batchs: 1323.2672119140625
INFO:root:Train (Epoch 27): Loss/seq after 02100 batchs: 1310.2667236328125
INFO:root:Train (Epoch 27): Loss/seq after 02150 batchs: 1298.2281494140625
INFO:root:Train (Epoch 27): Loss/seq after 02200 batchs: 1285.5498046875
INFO:root:Train (Epoch 27): Loss/seq after 02250 batchs: 1286.530517578125
INFO:root:Train (Epoch 27): Loss/seq after 02300 batchs: 1289.8092041015625
INFO:root:Train (Epoch 27): Loss/seq after 02350 batchs: 1279.850830078125
INFO:root:Train (Epoch 27): Loss/seq after 02400 batchs: 1275.1783447265625
INFO:root:Train (Epoch 27): Loss/seq after 02450 batchs: 1261.9302978515625
INFO:root:Train (Epoch 27): Loss/seq after 02500 batchs: 1243.996337890625
INFO:root:Train (Epoch 27): Loss/seq after 02550 batchs: 1232.3671875
INFO:root:Train (Epoch 27): Loss/seq after 02600 batchs: 1229.728515625
INFO:root:Train (Epoch 27): Loss/seq after 02650 batchs: 1224.5401611328125
INFO:root:Train (Epoch 27): Loss/seq after 02700 batchs: 1220.14501953125
INFO:root:Train (Epoch 27): Loss/seq after 02750 batchs: 1250.9039306640625
INFO:root:Train (Epoch 27): Loss/seq after 02800 batchs: 1258.4742431640625
INFO:root:Train (Epoch 27): Loss/seq after 02850 batchs: 1254.2225341796875
INFO:root:Train (Epoch 27): Loss/seq after 02900 batchs: 1251.257080078125
INFO:root:Train (Epoch 27): Loss/seq after 02950 batchs: 1242.6904296875
INFO:root:Train (Epoch 27): Loss/seq after 03000 batchs: 1240.0609130859375
INFO:root:Train (Epoch 27): Loss/seq after 03050 batchs: 1242.08984375
INFO:root:Train (Epoch 27): Loss/seq after 03100 batchs: 1253.7425537109375
INFO:root:Train (Epoch 27): Loss/seq after 03150 batchs: 1264.085693359375
INFO:root:Train (Epoch 27): Loss/seq after 03200 batchs: 1271.202880859375
INFO:root:Train (Epoch 27): Loss/seq after 03250 batchs: 1278.5604248046875
INFO:root:Train (Epoch 27): Loss/seq after 03300 batchs: 1276.8248291015625
INFO:root:Train (Epoch 27): Loss/seq after 03350 batchs: 1277.3150634765625
INFO:root:Train (Epoch 27): Loss/seq after 03400 batchs: 1268.2130126953125
INFO:root:Train (Epoch 27): Loss/seq after 03450 batchs: 1261.18896484375
INFO:root:Train (Epoch 27): Loss/seq after 03500 batchs: 1260.294677734375
INFO:root:Train (Epoch 27): Loss/seq after 03550 batchs: 1254.644287109375
INFO:root:Train (Epoch 27): Loss/seq after 03600 batchs: 1259.83935546875
INFO:root:Train (Epoch 27): Loss/seq after 03650 batchs: 1254.784912109375
INFO:root:Train (Epoch 27): Loss/seq after 03700 batchs: 1253.9136962890625
INFO:root:Train (Epoch 27): Loss/seq after 03750 batchs: 1253.500244140625
INFO:root:Train (Epoch 27): Loss/seq after 03800 batchs: 1246.0721435546875
INFO:root:Train (Epoch 27): Loss/seq after 03850 batchs: 1241.19384765625
INFO:root:Train (Epoch 27): Loss/seq after 03900 batchs: 1246.7330322265625
INFO:root:Train (Epoch 27): Loss/seq after 03950 batchs: 1253.0660400390625
INFO:root:Train (Epoch 27): Loss/seq after 04000 batchs: 1243.724853515625
INFO:root:Train (Epoch 27): Loss/seq after 04050 batchs: 1235.406494140625
INFO:root:Train (Epoch 27): Loss/seq after 04100 batchs: 1229.720458984375
INFO:root:Train (Epoch 27): Loss/seq after 04150 batchs: 1223.75146484375
INFO:root:Train (Epoch 27): Loss/seq after 04200 batchs: 1218.3277587890625
INFO:root:Train (Epoch 27): Loss/seq after 04250 batchs: 1213.8443603515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 27): Loss/seq after 00000 batches: 879.3427734375
INFO:root:# Valid (Epoch 27): Loss/seq after 00050 batches: 1096.5223388671875
INFO:root:# Valid (Epoch 27): Loss/seq after 00100 batches: 1394.9639892578125
INFO:root:# Valid (Epoch 27): Loss/seq after 00150 batches: 1123.50146484375
INFO:root:# Valid (Epoch 27): Loss/seq after 00200 batches: 1011.7718505859375
INFO:root:Artifacts: Make stick videos for epoch 27
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_27_on_20220413_171251.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_27_index_1787_on_20220413_171251.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 28): Loss/seq after 00000 batchs: 1646.2113037109375
INFO:root:Train (Epoch 28): Loss/seq after 00050 batchs: 1630.263671875
INFO:root:Train (Epoch 28): Loss/seq after 00100 batchs: 1606.2252197265625
INFO:root:Train (Epoch 28): Loss/seq after 00150 batchs: 1445.14404296875
INFO:root:Train (Epoch 28): Loss/seq after 00200 batchs: 1530.1939697265625
INFO:root:Train (Epoch 28): Loss/seq after 00250 batchs: 1667.0633544921875
INFO:root:Train (Epoch 28): Loss/seq after 00300 batchs: 1573.969970703125
INFO:root:Train (Epoch 28): Loss/seq after 00350 batchs: 1472.7264404296875
INFO:root:Train (Epoch 28): Loss/seq after 00400 batchs: 1521.6485595703125
INFO:root:Train (Epoch 28): Loss/seq after 00450 batchs: 1450.1558837890625
INFO:root:Train (Epoch 28): Loss/seq after 00500 batchs: 1475.4232177734375
INFO:root:Train (Epoch 28): Loss/seq after 00550 batchs: 1415.4383544921875
INFO:root:Train (Epoch 28): Loss/seq after 00600 batchs: 1376.3995361328125
INFO:root:Train (Epoch 28): Loss/seq after 00650 batchs: 1411.3734130859375
INFO:root:Train (Epoch 28): Loss/seq after 00700 batchs: 1448.228515625
INFO:root:Train (Epoch 28): Loss/seq after 00750 batchs: 1479.67919921875
INFO:root:Train (Epoch 28): Loss/seq after 00800 batchs: 1470.6016845703125
INFO:root:Train (Epoch 28): Loss/seq after 00850 batchs: 1438.6859130859375
INFO:root:Train (Epoch 28): Loss/seq after 00900 batchs: 1444.1947021484375
INFO:root:Train (Epoch 28): Loss/seq after 00950 batchs: 1498.697509765625
INFO:root:Train (Epoch 28): Loss/seq after 01000 batchs: 1491.057373046875
INFO:root:Train (Epoch 28): Loss/seq after 01050 batchs: 1465.6259765625
INFO:root:Train (Epoch 28): Loss/seq after 01100 batchs: 1455.7459716796875
INFO:root:Train (Epoch 28): Loss/seq after 01150 batchs: 1434.191162109375
INFO:root:Train (Epoch 28): Loss/seq after 01200 batchs: 1419.351318359375
INFO:root:Train (Epoch 28): Loss/seq after 01250 batchs: 1408.9490966796875
INFO:root:Train (Epoch 28): Loss/seq after 01300 batchs: 1414.23291015625
INFO:root:Train (Epoch 28): Loss/seq after 01350 batchs: 1413.597900390625
INFO:root:Train (Epoch 28): Loss/seq after 01400 batchs: 1444.462646484375
INFO:root:Train (Epoch 28): Loss/seq after 01450 batchs: 1432.352783203125
INFO:root:Train (Epoch 28): Loss/seq after 01500 batchs: 1420.111328125
INFO:root:Train (Epoch 28): Loss/seq after 01550 batchs: 1421.5521240234375
INFO:root:Train (Epoch 28): Loss/seq after 01600 batchs: 1402.1796875
INFO:root:Train (Epoch 28): Loss/seq after 01650 batchs: 1392.358642578125
INFO:root:Train (Epoch 28): Loss/seq after 01700 batchs: 1381.6044921875
INFO:root:Train (Epoch 28): Loss/seq after 01750 batchs: 1367.6446533203125
INFO:root:Train (Epoch 28): Loss/seq after 01800 batchs: 1352.0364990234375
INFO:root:Train (Epoch 28): Loss/seq after 01850 batchs: 1336.5531005859375
INFO:root:Train (Epoch 28): Loss/seq after 01900 batchs: 1333.3709716796875
INFO:root:Train (Epoch 28): Loss/seq after 01950 batchs: 1326.240478515625
INFO:root:Train (Epoch 28): Loss/seq after 02000 batchs: 1315.136962890625
INFO:root:Train (Epoch 28): Loss/seq after 02050 batchs: 1305.5718994140625
INFO:root:Train (Epoch 28): Loss/seq after 02100 batchs: 1292.8096923828125
INFO:root:Train (Epoch 28): Loss/seq after 02150 batchs: 1281.10107421875
INFO:root:Train (Epoch 28): Loss/seq after 02200 batchs: 1268.75732421875
INFO:root:Train (Epoch 28): Loss/seq after 02250 batchs: 1270.1201171875
INFO:root:Train (Epoch 28): Loss/seq after 02300 batchs: 1274.8291015625
INFO:root:Train (Epoch 28): Loss/seq after 02350 batchs: 1265.443603515625
INFO:root:Train (Epoch 28): Loss/seq after 02400 batchs: 1260.4815673828125
INFO:root:Train (Epoch 28): Loss/seq after 02450 batchs: 1247.5579833984375
INFO:root:Train (Epoch 28): Loss/seq after 02500 batchs: 1229.9952392578125
INFO:root:Train (Epoch 28): Loss/seq after 02550 batchs: 1218.52783203125
INFO:root:Train (Epoch 28): Loss/seq after 02600 batchs: 1215.297607421875
INFO:root:Train (Epoch 28): Loss/seq after 02650 batchs: 1210.1734619140625
INFO:root:Train (Epoch 28): Loss/seq after 02700 batchs: 1205.0941162109375
INFO:root:Train (Epoch 28): Loss/seq after 02750 batchs: 1235.732177734375
INFO:root:Train (Epoch 28): Loss/seq after 02800 batchs: 1242.92578125
INFO:root:Train (Epoch 28): Loss/seq after 02850 batchs: 1238.4305419921875
INFO:root:Train (Epoch 28): Loss/seq after 02900 batchs: 1235.8052978515625
INFO:root:Train (Epoch 28): Loss/seq after 02950 batchs: 1227.643798828125
INFO:root:Train (Epoch 28): Loss/seq after 03000 batchs: 1225.2796630859375
INFO:root:Train (Epoch 28): Loss/seq after 03050 batchs: 1227.621337890625
INFO:root:Train (Epoch 28): Loss/seq after 03100 batchs: 1241.1427001953125
INFO:root:Train (Epoch 28): Loss/seq after 03150 batchs: 1252.454833984375
INFO:root:Train (Epoch 28): Loss/seq after 03200 batchs: 1259.021240234375
INFO:root:Train (Epoch 28): Loss/seq after 03250 batchs: 1266.61328125
INFO:root:Train (Epoch 28): Loss/seq after 03300 batchs: 1265.324951171875
INFO:root:Train (Epoch 28): Loss/seq after 03350 batchs: 1265.4842529296875
INFO:root:Train (Epoch 28): Loss/seq after 03400 batchs: 1256.651123046875
INFO:root:Train (Epoch 28): Loss/seq after 03450 batchs: 1251.077880859375
INFO:root:Train (Epoch 28): Loss/seq after 03500 batchs: 1251.5552978515625
INFO:root:Train (Epoch 28): Loss/seq after 03550 batchs: 1246.416259765625
INFO:root:Train (Epoch 28): Loss/seq after 03600 batchs: 1251.7965087890625
INFO:root:Train (Epoch 28): Loss/seq after 03650 batchs: 1246.92431640625
INFO:root:Train (Epoch 28): Loss/seq after 03700 batchs: 1246.1610107421875
INFO:root:Train (Epoch 28): Loss/seq after 03750 batchs: 1245.7781982421875
INFO:root:Train (Epoch 28): Loss/seq after 03800 batchs: 1238.47998046875
INFO:root:Train (Epoch 28): Loss/seq after 03850 batchs: 1233.718994140625
INFO:root:Train (Epoch 28): Loss/seq after 03900 batchs: 1238.6571044921875
INFO:root:Train (Epoch 28): Loss/seq after 03950 batchs: 1245.537841796875
INFO:root:Train (Epoch 28): Loss/seq after 04000 batchs: 1236.424560546875
INFO:root:Train (Epoch 28): Loss/seq after 04050 batchs: 1228.22119140625
INFO:root:Train (Epoch 28): Loss/seq after 04100 batchs: 1223.7996826171875
INFO:root:Train (Epoch 28): Loss/seq after 04150 batchs: 1218.5008544921875
INFO:root:Train (Epoch 28): Loss/seq after 04200 batchs: 1214.2388916015625
INFO:root:Train (Epoch 28): Loss/seq after 04250 batchs: 1209.8062744140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 28): Loss/seq after 00000 batches: 894.1929321289062
INFO:root:# Valid (Epoch 28): Loss/seq after 00050 batches: 1101.99462890625
INFO:root:# Valid (Epoch 28): Loss/seq after 00100 batches: 1402.5811767578125
INFO:root:# Valid (Epoch 28): Loss/seq after 00150 batches: 1124.986328125
INFO:root:# Valid (Epoch 28): Loss/seq after 00200 batches: 1012.636962890625
INFO:root:Artifacts: Make stick videos for epoch 28
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_28_on_20220413_171809.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_28_index_1433_on_20220413_171809.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 29): Loss/seq after 00000 batchs: 2520.97412109375
INFO:root:Train (Epoch 29): Loss/seq after 00050 batchs: 1616.7958984375
INFO:root:Train (Epoch 29): Loss/seq after 00100 batchs: 1581.1759033203125
INFO:root:Train (Epoch 29): Loss/seq after 00150 batchs: 1422.0782470703125
INFO:root:Train (Epoch 29): Loss/seq after 00200 batchs: 1499.9825439453125
INFO:root:Train (Epoch 29): Loss/seq after 00250 batchs: 1632.8238525390625
INFO:root:Train (Epoch 29): Loss/seq after 00300 batchs: 1545.078857421875
INFO:root:Train (Epoch 29): Loss/seq after 00350 batchs: 1445.8291015625
INFO:root:Train (Epoch 29): Loss/seq after 00400 batchs: 1490.6275634765625
INFO:root:Train (Epoch 29): Loss/seq after 00450 batchs: 1422.570556640625
INFO:root:Train (Epoch 29): Loss/seq after 00500 batchs: 1450.282470703125
INFO:root:Train (Epoch 29): Loss/seq after 00550 batchs: 1396.82470703125
INFO:root:Train (Epoch 29): Loss/seq after 00600 batchs: 1360.1458740234375
INFO:root:Train (Epoch 29): Loss/seq after 00650 batchs: 1386.5152587890625
INFO:root:Train (Epoch 29): Loss/seq after 00700 batchs: 1421.721923828125
INFO:root:Train (Epoch 29): Loss/seq after 00750 batchs: 1454.728759765625
INFO:root:Train (Epoch 29): Loss/seq after 00800 batchs: 1447.8228759765625
INFO:root:Train (Epoch 29): Loss/seq after 00850 batchs: 1417.2752685546875
INFO:root:Train (Epoch 29): Loss/seq after 00900 batchs: 1421.8641357421875
INFO:root:Train (Epoch 29): Loss/seq after 00950 batchs: 1471.3992919921875
INFO:root:Train (Epoch 29): Loss/seq after 01000 batchs: 1468.5308837890625
INFO:root:Train (Epoch 29): Loss/seq after 01050 batchs: 1441.7215576171875
INFO:root:Train (Epoch 29): Loss/seq after 01100 batchs: 1431.31298828125
INFO:root:Train (Epoch 29): Loss/seq after 01150 batchs: 1411.070068359375
INFO:root:Train (Epoch 29): Loss/seq after 01200 batchs: 1397.1689453125
INFO:root:Train (Epoch 29): Loss/seq after 01250 batchs: 1385.1212158203125
INFO:root:Train (Epoch 29): Loss/seq after 01300 batchs: 1387.774169921875
INFO:root:Train (Epoch 29): Loss/seq after 01350 batchs: 1386.46826171875
INFO:root:Train (Epoch 29): Loss/seq after 01400 batchs: 1423.9017333984375
INFO:root:Train (Epoch 29): Loss/seq after 01450 batchs: 1411.7296142578125
INFO:root:Train (Epoch 29): Loss/seq after 01500 batchs: 1400.1502685546875
INFO:root:Train (Epoch 29): Loss/seq after 01550 batchs: 1401.7467041015625
INFO:root:Train (Epoch 29): Loss/seq after 01600 batchs: 1382.8662109375
INFO:root:Train (Epoch 29): Loss/seq after 01650 batchs: 1372.723388671875
INFO:root:Train (Epoch 29): Loss/seq after 01700 batchs: 1361.919677734375
INFO:root:Train (Epoch 29): Loss/seq after 01750 batchs: 1348.8321533203125
INFO:root:Train (Epoch 29): Loss/seq after 01800 batchs: 1333.56298828125
INFO:root:Train (Epoch 29): Loss/seq after 01850 batchs: 1318.636474609375
INFO:root:Train (Epoch 29): Loss/seq after 01900 batchs: 1316.2681884765625
INFO:root:Train (Epoch 29): Loss/seq after 01950 batchs: 1309.987060546875
INFO:root:Train (Epoch 29): Loss/seq after 02000 batchs: 1299.25244140625
INFO:root:Train (Epoch 29): Loss/seq after 02050 batchs: 1290.00732421875
INFO:root:Train (Epoch 29): Loss/seq after 02100 batchs: 1277.6021728515625
INFO:root:Train (Epoch 29): Loss/seq after 02150 batchs: 1266.293701171875
INFO:root:Train (Epoch 29): Loss/seq after 02200 batchs: 1254.3201904296875
INFO:root:Train (Epoch 29): Loss/seq after 02250 batchs: 1255.7012939453125
INFO:root:Train (Epoch 29): Loss/seq after 02300 batchs: 1259.8995361328125
INFO:root:Train (Epoch 29): Loss/seq after 02350 batchs: 1250.9178466796875
INFO:root:Train (Epoch 29): Loss/seq after 02400 batchs: 1246.590576171875
INFO:root:Train (Epoch 29): Loss/seq after 02450 batchs: 1233.993408203125
INFO:root:Train (Epoch 29): Loss/seq after 02500 batchs: 1216.8092041015625
INFO:root:Train (Epoch 29): Loss/seq after 02550 batchs: 1205.4027099609375
INFO:root:Train (Epoch 29): Loss/seq after 02600 batchs: 1203.0164794921875
INFO:root:Train (Epoch 29): Loss/seq after 02650 batchs: 1198.0670166015625
INFO:root:Train (Epoch 29): Loss/seq after 02700 batchs: 1193.2685546875
INFO:root:Train (Epoch 29): Loss/seq after 02750 batchs: 1224.2877197265625
INFO:root:Train (Epoch 29): Loss/seq after 02800 batchs: 1231.877685546875
INFO:root:Train (Epoch 29): Loss/seq after 02850 batchs: 1227.5126953125
INFO:root:Train (Epoch 29): Loss/seq after 02900 batchs: 1224.913818359375
INFO:root:Train (Epoch 29): Loss/seq after 02950 batchs: 1216.675537109375
INFO:root:Train (Epoch 29): Loss/seq after 03000 batchs: 1214.47509765625
INFO:root:Train (Epoch 29): Loss/seq after 03050 batchs: 1216.904296875
INFO:root:Train (Epoch 29): Loss/seq after 03100 batchs: 1230.0166015625
INFO:root:Train (Epoch 29): Loss/seq after 03150 batchs: 1241.9716796875
INFO:root:Train (Epoch 29): Loss/seq after 03200 batchs: 1250.3240966796875
INFO:root:Train (Epoch 29): Loss/seq after 03250 batchs: 1257.7392578125
INFO:root:Train (Epoch 29): Loss/seq after 03300 batchs: 1256.71484375
INFO:root:Train (Epoch 29): Loss/seq after 03350 batchs: 1256.052978515625
INFO:root:Train (Epoch 29): Loss/seq after 03400 batchs: 1247.2958984375
INFO:root:Train (Epoch 29): Loss/seq after 03450 batchs: 1240.14404296875
INFO:root:Train (Epoch 29): Loss/seq after 03500 batchs: 1239.0496826171875
INFO:root:Train (Epoch 29): Loss/seq after 03550 batchs: 1232.9925537109375
INFO:root:Train (Epoch 29): Loss/seq after 03600 batchs: 1238.443603515625
INFO:root:Train (Epoch 29): Loss/seq after 03650 batchs: 1233.4739990234375
INFO:root:Train (Epoch 29): Loss/seq after 03700 batchs: 1232.5423583984375
INFO:root:Train (Epoch 29): Loss/seq after 03750 batchs: 1232.4268798828125
INFO:root:Train (Epoch 29): Loss/seq after 03800 batchs: 1225.2266845703125
INFO:root:Train (Epoch 29): Loss/seq after 03850 batchs: 1220.5391845703125
INFO:root:Train (Epoch 29): Loss/seq after 03900 batchs: 1224.993896484375
INFO:root:Train (Epoch 29): Loss/seq after 03950 batchs: 1230.818359375
INFO:root:Train (Epoch 29): Loss/seq after 04000 batchs: 1221.833251953125
INFO:root:Train (Epoch 29): Loss/seq after 04050 batchs: 1213.79296875
INFO:root:Train (Epoch 29): Loss/seq after 04100 batchs: 1208.808837890625
INFO:root:Train (Epoch 29): Loss/seq after 04150 batchs: 1203.530517578125
INFO:root:Train (Epoch 29): Loss/seq after 04200 batchs: 1199.4354248046875
INFO:root:Train (Epoch 29): Loss/seq after 04250 batchs: 1195.251953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 29): Loss/seq after 00000 batches: 887.0006713867188
INFO:root:# Valid (Epoch 29): Loss/seq after 00050 batches: 1109.1656494140625
INFO:root:# Valid (Epoch 29): Loss/seq after 00100 batches: 1400.6800537109375
INFO:root:# Valid (Epoch 29): Loss/seq after 00150 batches: 1121.2333984375
INFO:root:# Valid (Epoch 29): Loss/seq after 00200 batches: 1012.0204467773438
INFO:root:Artifacts: Make stick videos for epoch 29
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_29_on_20220413_172329.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_29_index_557_on_20220413_172329.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 30): Loss/seq after 00000 batchs: 2122.314208984375
INFO:root:Train (Epoch 30): Loss/seq after 00050 batchs: 1582.8641357421875
INFO:root:Train (Epoch 30): Loss/seq after 00100 batchs: 1559.776611328125
INFO:root:Train (Epoch 30): Loss/seq after 00150 batchs: 1388.556884765625
INFO:root:Train (Epoch 30): Loss/seq after 00200 batchs: 1474.17626953125
INFO:root:Train (Epoch 30): Loss/seq after 00250 batchs: 1617.8023681640625
INFO:root:Train (Epoch 30): Loss/seq after 00300 batchs: 1533.7293701171875
INFO:root:Train (Epoch 30): Loss/seq after 00350 batchs: 1432.5228271484375
INFO:root:Train (Epoch 30): Loss/seq after 00400 batchs: 1464.990234375
INFO:root:Train (Epoch 30): Loss/seq after 00450 batchs: 1399.935791015625
INFO:root:Train (Epoch 30): Loss/seq after 00500 batchs: 1412.0986328125
INFO:root:Train (Epoch 30): Loss/seq after 00550 batchs: 1356.70166015625
INFO:root:Train (Epoch 30): Loss/seq after 00600 batchs: 1319.5738525390625
INFO:root:Train (Epoch 30): Loss/seq after 00650 batchs: 1348.36962890625
INFO:root:Train (Epoch 30): Loss/seq after 00700 batchs: 1367.3984375
INFO:root:Train (Epoch 30): Loss/seq after 00750 batchs: 1400.845947265625
INFO:root:Train (Epoch 30): Loss/seq after 00800 batchs: 1393.433349609375
INFO:root:Train (Epoch 30): Loss/seq after 00850 batchs: 1365.2662353515625
INFO:root:Train (Epoch 30): Loss/seq after 00900 batchs: 1371.119384765625
INFO:root:Train (Epoch 30): Loss/seq after 00950 batchs: 1426.13671875
INFO:root:Train (Epoch 30): Loss/seq after 01000 batchs: 1417.1080322265625
INFO:root:Train (Epoch 30): Loss/seq after 01050 batchs: 1393.0513916015625
INFO:root:Train (Epoch 30): Loss/seq after 01100 batchs: 1384.012451171875
INFO:root:Train (Epoch 30): Loss/seq after 01150 batchs: 1367.3621826171875
INFO:root:Train (Epoch 30): Loss/seq after 01200 batchs: 1355.934326171875
INFO:root:Train (Epoch 30): Loss/seq after 01250 batchs: 1347.4560546875
INFO:root:Train (Epoch 30): Loss/seq after 01300 batchs: 1352.2139892578125
INFO:root:Train (Epoch 30): Loss/seq after 01350 batchs: 1354.291015625
INFO:root:Train (Epoch 30): Loss/seq after 01400 batchs: 1387.57470703125
INFO:root:Train (Epoch 30): Loss/seq after 01450 batchs: 1375.86669921875
INFO:root:Train (Epoch 30): Loss/seq after 01500 batchs: 1364.985595703125
INFO:root:Train (Epoch 30): Loss/seq after 01550 batchs: 1364.5784912109375
INFO:root:Train (Epoch 30): Loss/seq after 01600 batchs: 1346.5706787109375
INFO:root:Train (Epoch 30): Loss/seq after 01650 batchs: 1337.656982421875
INFO:root:Train (Epoch 30): Loss/seq after 01700 batchs: 1328.0238037109375
INFO:root:Train (Epoch 30): Loss/seq after 01750 batchs: 1316.4276123046875
INFO:root:Train (Epoch 30): Loss/seq after 01800 batchs: 1302.4515380859375
INFO:root:Train (Epoch 30): Loss/seq after 01850 batchs: 1288.6859130859375
INFO:root:Train (Epoch 30): Loss/seq after 01900 batchs: 1287.4974365234375
INFO:root:Train (Epoch 30): Loss/seq after 01950 batchs: 1282.5269775390625
INFO:root:Train (Epoch 30): Loss/seq after 02000 batchs: 1273.2205810546875
INFO:root:Train (Epoch 30): Loss/seq after 02050 batchs: 1265.2655029296875
INFO:root:Train (Epoch 30): Loss/seq after 02100 batchs: 1254.0821533203125
INFO:root:Train (Epoch 30): Loss/seq after 02150 batchs: 1243.9808349609375
INFO:root:Train (Epoch 30): Loss/seq after 02200 batchs: 1232.8492431640625
INFO:root:Train (Epoch 30): Loss/seq after 02250 batchs: 1237.3590087890625
INFO:root:Train (Epoch 30): Loss/seq after 02300 batchs: 1241.5482177734375
INFO:root:Train (Epoch 30): Loss/seq after 02350 batchs: 1232.8643798828125
INFO:root:Train (Epoch 30): Loss/seq after 02400 batchs: 1229.1195068359375
INFO:root:Train (Epoch 30): Loss/seq after 02450 batchs: 1216.5628662109375
INFO:root:Train (Epoch 30): Loss/seq after 02500 batchs: 1199.531005859375
INFO:root:Train (Epoch 30): Loss/seq after 02550 batchs: 1188.53466796875
INFO:root:Train (Epoch 30): Loss/seq after 02600 batchs: 1186.139892578125
INFO:root:Train (Epoch 30): Loss/seq after 02650 batchs: 1181.6614990234375
INFO:root:Train (Epoch 30): Loss/seq after 02700 batchs: 1178.1661376953125
INFO:root:Train (Epoch 30): Loss/seq after 02750 batchs: 1208.7926025390625
INFO:root:Train (Epoch 30): Loss/seq after 02800 batchs: 1218.21728515625
INFO:root:Train (Epoch 30): Loss/seq after 02850 batchs: 1214.3804931640625
INFO:root:Train (Epoch 30): Loss/seq after 02900 batchs: 1212.56884765625
INFO:root:Train (Epoch 30): Loss/seq after 02950 batchs: 1204.668701171875
INFO:root:Train (Epoch 30): Loss/seq after 03000 batchs: 1202.6998291015625
INFO:root:Train (Epoch 30): Loss/seq after 03050 batchs: 1205.3004150390625
INFO:root:Train (Epoch 30): Loss/seq after 03100 batchs: 1216.610595703125
INFO:root:Train (Epoch 30): Loss/seq after 03150 batchs: 1224.414794921875
INFO:root:Train (Epoch 30): Loss/seq after 03200 batchs: 1231.8642578125
INFO:root:Train (Epoch 30): Loss/seq after 03250 batchs: 1238.250732421875
INFO:root:Train (Epoch 30): Loss/seq after 03300 batchs: 1236.896240234375
INFO:root:Train (Epoch 30): Loss/seq after 03350 batchs: 1236.2801513671875
INFO:root:Train (Epoch 30): Loss/seq after 03400 batchs: 1227.6688232421875
INFO:root:Train (Epoch 30): Loss/seq after 03450 batchs: 1221.4168701171875
INFO:root:Train (Epoch 30): Loss/seq after 03500 batchs: 1221.16796875
INFO:root:Train (Epoch 30): Loss/seq after 03550 batchs: 1215.897216796875
INFO:root:Train (Epoch 30): Loss/seq after 03600 batchs: 1221.6529541015625
INFO:root:Train (Epoch 30): Loss/seq after 03650 batchs: 1216.6397705078125
INFO:root:Train (Epoch 30): Loss/seq after 03700 batchs: 1215.94140625
INFO:root:Train (Epoch 30): Loss/seq after 03750 batchs: 1215.9903564453125
INFO:root:Train (Epoch 30): Loss/seq after 03800 batchs: 1209.053466796875
INFO:root:Train (Epoch 30): Loss/seq after 03850 batchs: 1204.6376953125
INFO:root:Train (Epoch 30): Loss/seq after 03900 batchs: 1209.4073486328125
INFO:root:Train (Epoch 30): Loss/seq after 03950 batchs: 1215.3541259765625
INFO:root:Train (Epoch 30): Loss/seq after 04000 batchs: 1206.475341796875
INFO:root:Train (Epoch 30): Loss/seq after 04050 batchs: 1198.615478515625
INFO:root:Train (Epoch 30): Loss/seq after 04100 batchs: 1193.2022705078125
INFO:root:Train (Epoch 30): Loss/seq after 04150 batchs: 1187.5728759765625
INFO:root:Train (Epoch 30): Loss/seq after 04200 batchs: 1183.1099853515625
INFO:root:Train (Epoch 30): Loss/seq after 04250 batchs: 1179.1026611328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 30): Loss/seq after 00000 batches: 886.360595703125
INFO:root:# Valid (Epoch 30): Loss/seq after 00050 batches: 1105.951171875
INFO:root:# Valid (Epoch 30): Loss/seq after 00100 batches: 1414.5435791015625
INFO:root:# Valid (Epoch 30): Loss/seq after 00150 batches: 1130.63916015625
INFO:root:# Valid (Epoch 30): Loss/seq after 00200 batches: 1016.1389770507812
INFO:root:Artifacts: Make stick videos for epoch 30
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_30_on_20220413_172847.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_30_index_574_on_20220413_172847.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 31): Loss/seq after 00000 batchs: 1639.1199951171875
INFO:root:Train (Epoch 31): Loss/seq after 00050 batchs: 1599.25146484375
INFO:root:Train (Epoch 31): Loss/seq after 00100 batchs: 1575.873779296875
INFO:root:Train (Epoch 31): Loss/seq after 00150 batchs: 1416.4007568359375
INFO:root:Train (Epoch 31): Loss/seq after 00200 batchs: 1497.634033203125
INFO:root:Train (Epoch 31): Loss/seq after 00250 batchs: 1625.5089111328125
INFO:root:Train (Epoch 31): Loss/seq after 00300 batchs: 1538.9677734375
INFO:root:Train (Epoch 31): Loss/seq after 00350 batchs: 1437.152099609375
INFO:root:Train (Epoch 31): Loss/seq after 00400 batchs: 1476.0819091796875
INFO:root:Train (Epoch 31): Loss/seq after 00450 batchs: 1409.9864501953125
INFO:root:Train (Epoch 31): Loss/seq after 00500 batchs: 1432.058837890625
INFO:root:Train (Epoch 31): Loss/seq after 00550 batchs: 1372.0679931640625
INFO:root:Train (Epoch 31): Loss/seq after 00600 batchs: 1332.0552978515625
INFO:root:Train (Epoch 31): Loss/seq after 00650 batchs: 1366.9989013671875
INFO:root:Train (Epoch 31): Loss/seq after 00700 batchs: 1388.1676025390625
INFO:root:Train (Epoch 31): Loss/seq after 00750 batchs: 1419.9505615234375
INFO:root:Train (Epoch 31): Loss/seq after 00800 batchs: 1410.212158203125
INFO:root:Train (Epoch 31): Loss/seq after 00850 batchs: 1380.2320556640625
INFO:root:Train (Epoch 31): Loss/seq after 00900 batchs: 1382.48486328125
INFO:root:Train (Epoch 31): Loss/seq after 00950 batchs: 1429.19970703125
INFO:root:Train (Epoch 31): Loss/seq after 01000 batchs: 1423.7930908203125
INFO:root:Train (Epoch 31): Loss/seq after 01050 batchs: 1401.1806640625
INFO:root:Train (Epoch 31): Loss/seq after 01100 batchs: 1395.2515869140625
INFO:root:Train (Epoch 31): Loss/seq after 01150 batchs: 1378.1573486328125
INFO:root:Train (Epoch 31): Loss/seq after 01200 batchs: 1366.673828125
INFO:root:Train (Epoch 31): Loss/seq after 01250 batchs: 1365.347412109375
INFO:root:Train (Epoch 31): Loss/seq after 01300 batchs: 1374.7333984375
INFO:root:Train (Epoch 31): Loss/seq after 01350 batchs: 1375.3485107421875
INFO:root:Train (Epoch 31): Loss/seq after 01400 batchs: 1405.9716796875
INFO:root:Train (Epoch 31): Loss/seq after 01450 batchs: 1395.6884765625
INFO:root:Train (Epoch 31): Loss/seq after 01500 batchs: 1385.0408935546875
INFO:root:Train (Epoch 31): Loss/seq after 01550 batchs: 1387.336181640625
INFO:root:Train (Epoch 31): Loss/seq after 01600 batchs: 1369.2274169921875
INFO:root:Train (Epoch 31): Loss/seq after 01650 batchs: 1361.0626220703125
INFO:root:Train (Epoch 31): Loss/seq after 01700 batchs: 1350.7998046875
INFO:root:Train (Epoch 31): Loss/seq after 01750 batchs: 1337.7637939453125
INFO:root:Train (Epoch 31): Loss/seq after 01800 batchs: 1322.768798828125
INFO:root:Train (Epoch 31): Loss/seq after 01850 batchs: 1308.0322265625
INFO:root:Train (Epoch 31): Loss/seq after 01900 batchs: 1305.4288330078125
INFO:root:Train (Epoch 31): Loss/seq after 01950 batchs: 1298.69677734375
INFO:root:Train (Epoch 31): Loss/seq after 02000 batchs: 1288.2254638671875
INFO:root:Train (Epoch 31): Loss/seq after 02050 batchs: 1279.3232421875
INFO:root:Train (Epoch 31): Loss/seq after 02100 batchs: 1267.167236328125
INFO:root:Train (Epoch 31): Loss/seq after 02150 batchs: 1256.0850830078125
INFO:root:Train (Epoch 31): Loss/seq after 02200 batchs: 1244.3062744140625
INFO:root:Train (Epoch 31): Loss/seq after 02250 batchs: 1245.435546875
INFO:root:Train (Epoch 31): Loss/seq after 02300 batchs: 1250.4825439453125
INFO:root:Train (Epoch 31): Loss/seq after 02350 batchs: 1241.5816650390625
INFO:root:Train (Epoch 31): Loss/seq after 02400 batchs: 1237.6119384765625
INFO:root:Train (Epoch 31): Loss/seq after 02450 batchs: 1224.93359375
INFO:root:Train (Epoch 31): Loss/seq after 02500 batchs: 1207.84521484375
INFO:root:Train (Epoch 31): Loss/seq after 02550 batchs: 1196.698974609375
INFO:root:Train (Epoch 31): Loss/seq after 02600 batchs: 1194.5618896484375
INFO:root:Train (Epoch 31): Loss/seq after 02650 batchs: 1189.7464599609375
INFO:root:Train (Epoch 31): Loss/seq after 02700 batchs: 1185.8392333984375
INFO:root:Train (Epoch 31): Loss/seq after 02750 batchs: 1216.623779296875
INFO:root:Train (Epoch 31): Loss/seq after 02800 batchs: 1223.8519287109375
INFO:root:Train (Epoch 31): Loss/seq after 02850 batchs: 1220.3233642578125
INFO:root:Train (Epoch 31): Loss/seq after 02900 batchs: 1217.58447265625
INFO:root:Train (Epoch 31): Loss/seq after 02950 batchs: 1209.8564453125
INFO:root:Train (Epoch 31): Loss/seq after 03000 batchs: 1207.7568359375
INFO:root:Train (Epoch 31): Loss/seq after 03050 batchs: 1210.2396240234375
INFO:root:Train (Epoch 31): Loss/seq after 03100 batchs: 1222.8685302734375
INFO:root:Train (Epoch 31): Loss/seq after 03150 batchs: 1233.9295654296875
INFO:root:Train (Epoch 31): Loss/seq after 03200 batchs: 1241.0238037109375
INFO:root:Train (Epoch 31): Loss/seq after 03250 batchs: 1247.7762451171875
INFO:root:Train (Epoch 31): Loss/seq after 03300 batchs: 1246.5263671875
INFO:root:Train (Epoch 31): Loss/seq after 03350 batchs: 1245.689453125
INFO:root:Train (Epoch 31): Loss/seq after 03400 batchs: 1236.923095703125
INFO:root:Train (Epoch 31): Loss/seq after 03450 batchs: 1229.7381591796875
INFO:root:Train (Epoch 31): Loss/seq after 03500 batchs: 1229.35693359375
INFO:root:Train (Epoch 31): Loss/seq after 03550 batchs: 1223.59130859375
INFO:root:Train (Epoch 31): Loss/seq after 03600 batchs: 1229.655517578125
INFO:root:Train (Epoch 31): Loss/seq after 03650 batchs: 1224.0828857421875
INFO:root:Train (Epoch 31): Loss/seq after 03700 batchs: 1223.173095703125
INFO:root:Train (Epoch 31): Loss/seq after 03750 batchs: 1223.0738525390625
INFO:root:Train (Epoch 31): Loss/seq after 03800 batchs: 1216.0091552734375
INFO:root:Train (Epoch 31): Loss/seq after 03850 batchs: 1211.4537353515625
INFO:root:Train (Epoch 31): Loss/seq after 03900 batchs: 1215.859619140625
INFO:root:Train (Epoch 31): Loss/seq after 03950 batchs: 1221.5616455078125
INFO:root:Train (Epoch 31): Loss/seq after 04000 batchs: 1212.654541015625
INFO:root:Train (Epoch 31): Loss/seq after 04050 batchs: 1204.73486328125
INFO:root:Train (Epoch 31): Loss/seq after 04100 batchs: 1199.70849609375
INFO:root:Train (Epoch 31): Loss/seq after 04150 batchs: 1194.235595703125
INFO:root:Train (Epoch 31): Loss/seq after 04200 batchs: 1188.982177734375
INFO:root:Train (Epoch 31): Loss/seq after 04250 batchs: 1184.88427734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 31): Loss/seq after 00000 batches: 875.231689453125
INFO:root:# Valid (Epoch 31): Loss/seq after 00050 batches: 1096.4769287109375
INFO:root:# Valid (Epoch 31): Loss/seq after 00100 batches: 1393.920654296875
INFO:root:# Valid (Epoch 31): Loss/seq after 00150 batches: 1122.0784912109375
INFO:root:# Valid (Epoch 31): Loss/seq after 00200 batches: 1013.0078125
INFO:root:Artifacts: Make stick videos for epoch 31
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_31_on_20220413_173405.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_31_index_1146_on_20220413_173405.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 32): Loss/seq after 00000 batchs: 2111.780517578125
INFO:root:Train (Epoch 32): Loss/seq after 00050 batchs: 1545.8609619140625
INFO:root:Train (Epoch 32): Loss/seq after 00100 batchs: 1491.137939453125
INFO:root:Train (Epoch 32): Loss/seq after 00150 batchs: 1335.68212890625
INFO:root:Train (Epoch 32): Loss/seq after 00200 batchs: 1421.64111328125
INFO:root:Train (Epoch 32): Loss/seq after 00250 batchs: 1564.2811279296875
INFO:root:Train (Epoch 32): Loss/seq after 00300 batchs: 1487.671630859375
INFO:root:Train (Epoch 32): Loss/seq after 00350 batchs: 1399.1282958984375
INFO:root:Train (Epoch 32): Loss/seq after 00400 batchs: 1448.66064453125
INFO:root:Train (Epoch 32): Loss/seq after 00450 batchs: 1386.03515625
INFO:root:Train (Epoch 32): Loss/seq after 00500 batchs: 1410.197021484375
INFO:root:Train (Epoch 32): Loss/seq after 00550 batchs: 1353.400390625
INFO:root:Train (Epoch 32): Loss/seq after 00600 batchs: 1317.803466796875
INFO:root:Train (Epoch 32): Loss/seq after 00650 batchs: 1347.65673828125
INFO:root:Train (Epoch 32): Loss/seq after 00700 batchs: 1373.863037109375
INFO:root:Train (Epoch 32): Loss/seq after 00750 batchs: 1406.92724609375
INFO:root:Train (Epoch 32): Loss/seq after 00800 batchs: 1397.4461669921875
INFO:root:Train (Epoch 32): Loss/seq after 00850 batchs: 1368.74853515625
INFO:root:Train (Epoch 32): Loss/seq after 00900 batchs: 1375.887939453125
INFO:root:Train (Epoch 32): Loss/seq after 00950 batchs: 1431.318115234375
INFO:root:Train (Epoch 32): Loss/seq after 01000 batchs: 1425.9107666015625
INFO:root:Train (Epoch 32): Loss/seq after 01050 batchs: 1405.1927490234375
INFO:root:Train (Epoch 32): Loss/seq after 01100 batchs: 1398.216796875
INFO:root:Train (Epoch 32): Loss/seq after 01150 batchs: 1379.1561279296875
INFO:root:Train (Epoch 32): Loss/seq after 01200 batchs: 1366.330322265625
INFO:root:Train (Epoch 32): Loss/seq after 01250 batchs: 1354.115478515625
INFO:root:Train (Epoch 32): Loss/seq after 01300 batchs: 1357.8553466796875
INFO:root:Train (Epoch 32): Loss/seq after 01350 batchs: 1355.7066650390625
INFO:root:Train (Epoch 32): Loss/seq after 01400 batchs: 1386.1044921875
INFO:root:Train (Epoch 32): Loss/seq after 01450 batchs: 1374.89794921875
INFO:root:Train (Epoch 32): Loss/seq after 01500 batchs: 1364.0289306640625
INFO:root:Train (Epoch 32): Loss/seq after 01550 batchs: 1362.4476318359375
INFO:root:Train (Epoch 32): Loss/seq after 01600 batchs: 1344.463623046875
INFO:root:Train (Epoch 32): Loss/seq after 01650 batchs: 1334.36865234375
INFO:root:Train (Epoch 32): Loss/seq after 01700 batchs: 1323.71923828125
INFO:root:Train (Epoch 32): Loss/seq after 01750 batchs: 1311.4163818359375
INFO:root:Train (Epoch 32): Loss/seq after 01800 batchs: 1296.912841796875
INFO:root:Train (Epoch 32): Loss/seq after 01850 batchs: 1282.5732421875
INFO:root:Train (Epoch 32): Loss/seq after 01900 batchs: 1280.2816162109375
INFO:root:Train (Epoch 32): Loss/seq after 01950 batchs: 1274.39453125
INFO:root:Train (Epoch 32): Loss/seq after 02000 batchs: 1264.3409423828125
INFO:root:Train (Epoch 32): Loss/seq after 02050 batchs: 1255.9403076171875
INFO:root:Train (Epoch 32): Loss/seq after 02100 batchs: 1244.236083984375
INFO:root:Train (Epoch 32): Loss/seq after 02150 batchs: 1233.416748046875
INFO:root:Train (Epoch 32): Loss/seq after 02200 batchs: 1222.0819091796875
INFO:root:Train (Epoch 32): Loss/seq after 02250 batchs: 1222.1129150390625
INFO:root:Train (Epoch 32): Loss/seq after 02300 batchs: 1224.853515625
INFO:root:Train (Epoch 32): Loss/seq after 02350 batchs: 1215.927978515625
INFO:root:Train (Epoch 32): Loss/seq after 02400 batchs: 1212.0074462890625
INFO:root:Train (Epoch 32): Loss/seq after 02450 batchs: 1199.654296875
INFO:root:Train (Epoch 32): Loss/seq after 02500 batchs: 1182.9390869140625
INFO:root:Train (Epoch 32): Loss/seq after 02550 batchs: 1171.59521484375
INFO:root:Train (Epoch 32): Loss/seq after 02600 batchs: 1169.046142578125
INFO:root:Train (Epoch 32): Loss/seq after 02650 batchs: 1164.632568359375
INFO:root:Train (Epoch 32): Loss/seq after 02700 batchs: 1160.3125
INFO:root:Train (Epoch 32): Loss/seq after 02750 batchs: 1190.42431640625
INFO:root:Train (Epoch 32): Loss/seq after 02800 batchs: 1197.3863525390625
INFO:root:Train (Epoch 32): Loss/seq after 02850 batchs: 1193.547119140625
INFO:root:Train (Epoch 32): Loss/seq after 02900 batchs: 1192.2406005859375
INFO:root:Train (Epoch 32): Loss/seq after 02950 batchs: 1184.6934814453125
INFO:root:Train (Epoch 32): Loss/seq after 03000 batchs: 1183.0198974609375
INFO:root:Train (Epoch 32): Loss/seq after 03050 batchs: 1185.8851318359375
INFO:root:Train (Epoch 32): Loss/seq after 03100 batchs: 1198.183349609375
INFO:root:Train (Epoch 32): Loss/seq after 03150 batchs: 1207.1280517578125
INFO:root:Train (Epoch 32): Loss/seq after 03200 batchs: 1215.8707275390625
INFO:root:Train (Epoch 32): Loss/seq after 03250 batchs: 1222.275634765625
INFO:root:Train (Epoch 32): Loss/seq after 03300 batchs: 1220.5506591796875
INFO:root:Train (Epoch 32): Loss/seq after 03350 batchs: 1219.484375
INFO:root:Train (Epoch 32): Loss/seq after 03400 batchs: 1211.1617431640625
INFO:root:Train (Epoch 32): Loss/seq after 03450 batchs: 1206.07470703125
INFO:root:Train (Epoch 32): Loss/seq after 03500 batchs: 1206.0078125
INFO:root:Train (Epoch 32): Loss/seq after 03550 batchs: 1200.7813720703125
INFO:root:Train (Epoch 32): Loss/seq after 03600 batchs: 1206.7762451171875
INFO:root:Train (Epoch 32): Loss/seq after 03650 batchs: 1202.222412109375
INFO:root:Train (Epoch 32): Loss/seq after 03700 batchs: 1201.8291015625
INFO:root:Train (Epoch 32): Loss/seq after 03750 batchs: 1201.931884765625
INFO:root:Train (Epoch 32): Loss/seq after 03800 batchs: 1195.118408203125
INFO:root:Train (Epoch 32): Loss/seq after 03850 batchs: 1190.808349609375
INFO:root:Train (Epoch 32): Loss/seq after 03900 batchs: 1195.609375
INFO:root:Train (Epoch 32): Loss/seq after 03950 batchs: 1201.462158203125
INFO:root:Train (Epoch 32): Loss/seq after 04000 batchs: 1192.758544921875
INFO:root:Train (Epoch 32): Loss/seq after 04050 batchs: 1185.0673828125
INFO:root:Train (Epoch 32): Loss/seq after 04100 batchs: 1179.56494140625
INFO:root:Train (Epoch 32): Loss/seq after 04150 batchs: 1174.08056640625
INFO:root:Train (Epoch 32): Loss/seq after 04200 batchs: 1169.29345703125
INFO:root:Train (Epoch 32): Loss/seq after 04250 batchs: 1165.54931640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 32): Loss/seq after 00000 batches: 887.9059448242188
INFO:root:# Valid (Epoch 32): Loss/seq after 00050 batches: 1112.23828125
INFO:root:# Valid (Epoch 32): Loss/seq after 00100 batches: 1411.3524169921875
INFO:root:# Valid (Epoch 32): Loss/seq after 00150 batches: 1124.8280029296875
INFO:root:# Valid (Epoch 32): Loss/seq after 00200 batches: 1012.632080078125
INFO:root:Artifacts: Make stick videos for epoch 32
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_32_on_20220413_173924.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_32_index_1036_on_20220413_173924.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 33): Loss/seq after 00000 batchs: 1749.486572265625
INFO:root:Train (Epoch 33): Loss/seq after 00050 batchs: 1535.20166015625
INFO:root:Train (Epoch 33): Loss/seq after 00100 batchs: 1515.9154052734375
INFO:root:Train (Epoch 33): Loss/seq after 00150 batchs: 1352.4677734375
INFO:root:Train (Epoch 33): Loss/seq after 00200 batchs: 1447.0584716796875
INFO:root:Train (Epoch 33): Loss/seq after 00250 batchs: 1575.708984375
INFO:root:Train (Epoch 33): Loss/seq after 00300 batchs: 1496.1231689453125
INFO:root:Train (Epoch 33): Loss/seq after 00350 batchs: 1397.8311767578125
INFO:root:Train (Epoch 33): Loss/seq after 00400 batchs: 1435.39892578125
INFO:root:Train (Epoch 33): Loss/seq after 00450 batchs: 1374.1331787109375
INFO:root:Train (Epoch 33): Loss/seq after 00500 batchs: 1392.350830078125
INFO:root:Train (Epoch 33): Loss/seq after 00550 batchs: 1335.4422607421875
INFO:root:Train (Epoch 33): Loss/seq after 00600 batchs: 1298.2462158203125
INFO:root:Train (Epoch 33): Loss/seq after 00650 batchs: 1339.065185546875
INFO:root:Train (Epoch 33): Loss/seq after 00700 batchs: 1372.6025390625
INFO:root:Train (Epoch 33): Loss/seq after 00750 batchs: 1407.540771484375
INFO:root:Train (Epoch 33): Loss/seq after 00800 batchs: 1396.136474609375
INFO:root:Train (Epoch 33): Loss/seq after 00850 batchs: 1366.7679443359375
INFO:root:Train (Epoch 33): Loss/seq after 00900 batchs: 1370.540283203125
INFO:root:Train (Epoch 33): Loss/seq after 00950 batchs: 1425.2947998046875
INFO:root:Train (Epoch 33): Loss/seq after 01000 batchs: 1420.8173828125
INFO:root:Train (Epoch 33): Loss/seq after 01050 batchs: 1395.0010986328125
INFO:root:Train (Epoch 33): Loss/seq after 01100 batchs: 1388.026123046875
INFO:root:Train (Epoch 33): Loss/seq after 01150 batchs: 1370.2083740234375
INFO:root:Train (Epoch 33): Loss/seq after 01200 batchs: 1359.056640625
INFO:root:Train (Epoch 33): Loss/seq after 01250 batchs: 1353.2081298828125
INFO:root:Train (Epoch 33): Loss/seq after 01300 batchs: 1358.7535400390625
INFO:root:Train (Epoch 33): Loss/seq after 01350 batchs: 1359.9927978515625
INFO:root:Train (Epoch 33): Loss/seq after 01400 batchs: 1390.9803466796875
INFO:root:Train (Epoch 33): Loss/seq after 01450 batchs: 1380.9698486328125
INFO:root:Train (Epoch 33): Loss/seq after 01500 batchs: 1370.768310546875
INFO:root:Train (Epoch 33): Loss/seq after 01550 batchs: 1369.1448974609375
INFO:root:Train (Epoch 33): Loss/seq after 01600 batchs: 1351.01806640625
INFO:root:Train (Epoch 33): Loss/seq after 01650 batchs: 1340.415771484375
INFO:root:Train (Epoch 33): Loss/seq after 01700 batchs: 1330.120361328125
INFO:root:Train (Epoch 33): Loss/seq after 01750 batchs: 1317.4912109375
INFO:root:Train (Epoch 33): Loss/seq after 01800 batchs: 1302.7796630859375
INFO:root:Train (Epoch 33): Loss/seq after 01850 batchs: 1288.237548828125
INFO:root:Train (Epoch 33): Loss/seq after 01900 batchs: 1285.570068359375
INFO:root:Train (Epoch 33): Loss/seq after 01950 batchs: 1278.679443359375
INFO:root:Train (Epoch 33): Loss/seq after 02000 batchs: 1268.6005859375
INFO:root:Train (Epoch 33): Loss/seq after 02050 batchs: 1259.7650146484375
INFO:root:Train (Epoch 33): Loss/seq after 02100 batchs: 1247.8865966796875
INFO:root:Train (Epoch 33): Loss/seq after 02150 batchs: 1236.937255859375
INFO:root:Train (Epoch 33): Loss/seq after 02200 batchs: 1225.4798583984375
INFO:root:Train (Epoch 33): Loss/seq after 02250 batchs: 1226.078369140625
INFO:root:Train (Epoch 33): Loss/seq after 02300 batchs: 1229.35693359375
INFO:root:Train (Epoch 33): Loss/seq after 02350 batchs: 1220.083740234375
INFO:root:Train (Epoch 33): Loss/seq after 02400 batchs: 1215.8701171875
INFO:root:Train (Epoch 33): Loss/seq after 02450 batchs: 1203.0706787109375
INFO:root:Train (Epoch 33): Loss/seq after 02500 batchs: 1186.27294921875
INFO:root:Train (Epoch 33): Loss/seq after 02550 batchs: 1174.7476806640625
INFO:root:Train (Epoch 33): Loss/seq after 02600 batchs: 1172.2484130859375
INFO:root:Train (Epoch 33): Loss/seq after 02650 batchs: 1167.6612548828125
INFO:root:Train (Epoch 33): Loss/seq after 02700 batchs: 1163.5667724609375
INFO:root:Train (Epoch 33): Loss/seq after 02750 batchs: 1193.7091064453125
INFO:root:Train (Epoch 33): Loss/seq after 02800 batchs: 1199.92578125
INFO:root:Train (Epoch 33): Loss/seq after 02850 batchs: 1195.9329833984375
INFO:root:Train (Epoch 33): Loss/seq after 02900 batchs: 1194.9384765625
INFO:root:Train (Epoch 33): Loss/seq after 02950 batchs: 1187.5609130859375
INFO:root:Train (Epoch 33): Loss/seq after 03000 batchs: 1185.8226318359375
INFO:root:Train (Epoch 33): Loss/seq after 03050 batchs: 1188.57177734375
INFO:root:Train (Epoch 33): Loss/seq after 03100 batchs: 1199.0513916015625
INFO:root:Train (Epoch 33): Loss/seq after 03150 batchs: 1207.8172607421875
INFO:root:Train (Epoch 33): Loss/seq after 03200 batchs: 1216.0
INFO:root:Train (Epoch 33): Loss/seq after 03250 batchs: 1220.751220703125
INFO:root:Train (Epoch 33): Loss/seq after 03300 batchs: 1218.59912109375
INFO:root:Train (Epoch 33): Loss/seq after 03350 batchs: 1217.71240234375
INFO:root:Train (Epoch 33): Loss/seq after 03400 batchs: 1209.688232421875
INFO:root:Train (Epoch 33): Loss/seq after 03450 batchs: 1204.6068115234375
INFO:root:Train (Epoch 33): Loss/seq after 03500 batchs: 1204.2935791015625
INFO:root:Train (Epoch 33): Loss/seq after 03550 batchs: 1198.5780029296875
INFO:root:Train (Epoch 33): Loss/seq after 03600 batchs: 1204.61328125
INFO:root:Train (Epoch 33): Loss/seq after 03650 batchs: 1199.7215576171875
INFO:root:Train (Epoch 33): Loss/seq after 03700 batchs: 1199.141357421875
INFO:root:Train (Epoch 33): Loss/seq after 03750 batchs: 1199.2989501953125
INFO:root:Train (Epoch 33): Loss/seq after 03800 batchs: 1192.5262451171875
INFO:root:Train (Epoch 33): Loss/seq after 03850 batchs: 1188.20703125
INFO:root:Train (Epoch 33): Loss/seq after 03900 batchs: 1193.2313232421875
INFO:root:Train (Epoch 33): Loss/seq after 03950 batchs: 1198.553466796875
INFO:root:Train (Epoch 33): Loss/seq after 04000 batchs: 1189.8936767578125
INFO:root:Train (Epoch 33): Loss/seq after 04050 batchs: 1182.2386474609375
INFO:root:Train (Epoch 33): Loss/seq after 04100 batchs: 1177.0997314453125
INFO:root:Train (Epoch 33): Loss/seq after 04150 batchs: 1171.789306640625
INFO:root:Train (Epoch 33): Loss/seq after 04200 batchs: 1166.73046875
INFO:root:Train (Epoch 33): Loss/seq after 04250 batchs: 1162.8194580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 33): Loss/seq after 00000 batches: 897.2479858398438
INFO:root:# Valid (Epoch 33): Loss/seq after 00050 batches: 1135.294189453125
INFO:root:# Valid (Epoch 33): Loss/seq after 00100 batches: 1425.4090576171875
INFO:root:# Valid (Epoch 33): Loss/seq after 00150 batches: 1155.220947265625
INFO:root:# Valid (Epoch 33): Loss/seq after 00200 batches: 1044.00634765625
INFO:root:Artifacts: Make stick videos for epoch 33
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_33_on_20220413_174442.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_33_index_802_on_20220413_174442.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 34): Loss/seq after 00000 batchs: 2229.624755859375
INFO:root:Train (Epoch 34): Loss/seq after 00050 batchs: 1509.18408203125
INFO:root:Train (Epoch 34): Loss/seq after 00100 batchs: 1489.3271484375
INFO:root:Train (Epoch 34): Loss/seq after 00150 batchs: 1329.853759765625
INFO:root:Train (Epoch 34): Loss/seq after 00200 batchs: 1423.981201171875
INFO:root:Train (Epoch 34): Loss/seq after 00250 batchs: 1578.2275390625
INFO:root:Train (Epoch 34): Loss/seq after 00300 batchs: 1498.4384765625
INFO:root:Train (Epoch 34): Loss/seq after 00350 batchs: 1406.0714111328125
INFO:root:Train (Epoch 34): Loss/seq after 00400 batchs: 1450.2213134765625
INFO:root:Train (Epoch 34): Loss/seq after 00450 batchs: 1387.278076171875
INFO:root:Train (Epoch 34): Loss/seq after 00500 batchs: 1415.1357421875
INFO:root:Train (Epoch 34): Loss/seq after 00550 batchs: 1357.35107421875
INFO:root:Train (Epoch 34): Loss/seq after 00600 batchs: 1321.739501953125
INFO:root:Train (Epoch 34): Loss/seq after 00650 batchs: 1358.476806640625
INFO:root:Train (Epoch 34): Loss/seq after 00700 batchs: 1384.3187255859375
INFO:root:Train (Epoch 34): Loss/seq after 00750 batchs: 1418.6412353515625
INFO:root:Train (Epoch 34): Loss/seq after 00800 batchs: 1406.54736328125
INFO:root:Train (Epoch 34): Loss/seq after 00850 batchs: 1376.013427734375
INFO:root:Train (Epoch 34): Loss/seq after 00900 batchs: 1378.62255859375
INFO:root:Train (Epoch 34): Loss/seq after 00950 batchs: 1427.3380126953125
INFO:root:Train (Epoch 34): Loss/seq after 01000 batchs: 1421.3201904296875
INFO:root:Train (Epoch 34): Loss/seq after 01050 batchs: 1396.61767578125
INFO:root:Train (Epoch 34): Loss/seq after 01100 batchs: 1387.389892578125
INFO:root:Train (Epoch 34): Loss/seq after 01150 batchs: 1368.5286865234375
INFO:root:Train (Epoch 34): Loss/seq after 01200 batchs: 1355.302001953125
INFO:root:Train (Epoch 34): Loss/seq after 01250 batchs: 1345.166015625
INFO:root:Train (Epoch 34): Loss/seq after 01300 batchs: 1348.269287109375
INFO:root:Train (Epoch 34): Loss/seq after 01350 batchs: 1349.5074462890625
INFO:root:Train (Epoch 34): Loss/seq after 01400 batchs: 1377.44970703125
INFO:root:Train (Epoch 34): Loss/seq after 01450 batchs: 1365.13916015625
INFO:root:Train (Epoch 34): Loss/seq after 01500 batchs: 1354.4232177734375
INFO:root:Train (Epoch 34): Loss/seq after 01550 batchs: 1351.766845703125
INFO:root:Train (Epoch 34): Loss/seq after 01600 batchs: 1334.0260009765625
INFO:root:Train (Epoch 34): Loss/seq after 01650 batchs: 1323.7930908203125
INFO:root:Train (Epoch 34): Loss/seq after 01700 batchs: 1314.1226806640625
INFO:root:Train (Epoch 34): Loss/seq after 01750 batchs: 1301.9285888671875
INFO:root:Train (Epoch 34): Loss/seq after 01800 batchs: 1287.5413818359375
INFO:root:Train (Epoch 34): Loss/seq after 01850 batchs: 1273.4661865234375
INFO:root:Train (Epoch 34): Loss/seq after 01900 batchs: 1270.9212646484375
INFO:root:Train (Epoch 34): Loss/seq after 01950 batchs: 1264.04150390625
INFO:root:Train (Epoch 34): Loss/seq after 02000 batchs: 1254.20068359375
INFO:root:Train (Epoch 34): Loss/seq after 02050 batchs: 1245.65283203125
INFO:root:Train (Epoch 34): Loss/seq after 02100 batchs: 1234.0689697265625
INFO:root:Train (Epoch 34): Loss/seq after 02150 batchs: 1223.386474609375
INFO:root:Train (Epoch 34): Loss/seq after 02200 batchs: 1212.3009033203125
INFO:root:Train (Epoch 34): Loss/seq after 02250 batchs: 1212.7139892578125
INFO:root:Train (Epoch 34): Loss/seq after 02300 batchs: 1216.0262451171875
INFO:root:Train (Epoch 34): Loss/seq after 02350 batchs: 1206.91650390625
INFO:root:Train (Epoch 34): Loss/seq after 02400 batchs: 1202.6817626953125
INFO:root:Train (Epoch 34): Loss/seq after 02450 batchs: 1190.044921875
INFO:root:Train (Epoch 34): Loss/seq after 02500 batchs: 1173.4718017578125
INFO:root:Train (Epoch 34): Loss/seq after 02550 batchs: 1162.4345703125
INFO:root:Train (Epoch 34): Loss/seq after 02600 batchs: 1160.2279052734375
INFO:root:Train (Epoch 34): Loss/seq after 02650 batchs: 1155.8204345703125
INFO:root:Train (Epoch 34): Loss/seq after 02700 batchs: 1152.3238525390625
INFO:root:Train (Epoch 34): Loss/seq after 02750 batchs: 1182.464111328125
INFO:root:Train (Epoch 34): Loss/seq after 02800 batchs: 1188.9512939453125
INFO:root:Train (Epoch 34): Loss/seq after 02850 batchs: 1184.967529296875
INFO:root:Train (Epoch 34): Loss/seq after 02900 batchs: 1182.175537109375
INFO:root:Train (Epoch 34): Loss/seq after 02950 batchs: 1174.5433349609375
INFO:root:Train (Epoch 34): Loss/seq after 03000 batchs: 1173.015869140625
INFO:root:Train (Epoch 34): Loss/seq after 03050 batchs: 1175.8779296875
INFO:root:Train (Epoch 34): Loss/seq after 03100 batchs: 1186.4268798828125
INFO:root:Train (Epoch 34): Loss/seq after 03150 batchs: 1193.4290771484375
INFO:root:Train (Epoch 34): Loss/seq after 03200 batchs: 1201.9869384765625
INFO:root:Train (Epoch 34): Loss/seq after 03250 batchs: 1208.01416015625
INFO:root:Train (Epoch 34): Loss/seq after 03300 batchs: 1206.450927734375
INFO:root:Train (Epoch 34): Loss/seq after 03350 batchs: 1206.69873046875
INFO:root:Train (Epoch 34): Loss/seq after 03400 batchs: 1198.5140380859375
INFO:root:Train (Epoch 34): Loss/seq after 03450 batchs: 1192.3328857421875
INFO:root:Train (Epoch 34): Loss/seq after 03500 batchs: 1192.1533203125
INFO:root:Train (Epoch 34): Loss/seq after 03550 batchs: 1186.20654296875
INFO:root:Train (Epoch 34): Loss/seq after 03600 batchs: 1192.4122314453125
INFO:root:Train (Epoch 34): Loss/seq after 03650 batchs: 1186.9190673828125
INFO:root:Train (Epoch 34): Loss/seq after 03700 batchs: 1186.5362548828125
INFO:root:Train (Epoch 34): Loss/seq after 03750 batchs: 1186.854736328125
INFO:root:Train (Epoch 34): Loss/seq after 03800 batchs: 1180.18896484375
INFO:root:Train (Epoch 34): Loss/seq after 03850 batchs: 1175.945068359375
INFO:root:Train (Epoch 34): Loss/seq after 03900 batchs: 1180.0867919921875
INFO:root:Train (Epoch 34): Loss/seq after 03950 batchs: 1185.62548828125
INFO:root:Train (Epoch 34): Loss/seq after 04000 batchs: 1177.08935546875
INFO:root:Train (Epoch 34): Loss/seq after 04050 batchs: 1169.5838623046875
INFO:root:Train (Epoch 34): Loss/seq after 04100 batchs: 1164.1490478515625
INFO:root:Train (Epoch 34): Loss/seq after 04150 batchs: 1158.727294921875
INFO:root:Train (Epoch 34): Loss/seq after 04200 batchs: 1154.2154541015625
INFO:root:Train (Epoch 34): Loss/seq after 04250 batchs: 1151.0223388671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 34): Loss/seq after 00000 batches: 925.0470581054688
INFO:root:# Valid (Epoch 34): Loss/seq after 00050 batches: 1112.7266845703125
INFO:root:# Valid (Epoch 34): Loss/seq after 00100 batches: 1488.628662109375
INFO:root:# Valid (Epoch 34): Loss/seq after 00150 batches: 1249.3697509765625
INFO:root:# Valid (Epoch 34): Loss/seq after 00200 batches: 1142.8128662109375
INFO:root:Artifacts: Make stick videos for epoch 34
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_34_on_20220413_175001.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_34_index_846_on_20220413_175001.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 35): Loss/seq after 00000 batchs: 1716.89013671875
INFO:root:Train (Epoch 35): Loss/seq after 00050 batchs: 1619.8692626953125
INFO:root:Train (Epoch 35): Loss/seq after 00100 batchs: 1555.037353515625
INFO:root:Train (Epoch 35): Loss/seq after 00150 batchs: 1373.387451171875
INFO:root:Train (Epoch 35): Loss/seq after 00200 batchs: 1456.8988037109375
INFO:root:Train (Epoch 35): Loss/seq after 00250 batchs: 1598.4862060546875
INFO:root:Train (Epoch 35): Loss/seq after 00300 batchs: 1517.341064453125
INFO:root:Train (Epoch 35): Loss/seq after 00350 batchs: 1416.9080810546875
INFO:root:Train (Epoch 35): Loss/seq after 00400 batchs: 1455.1142578125
INFO:root:Train (Epoch 35): Loss/seq after 00450 batchs: 1391.1934814453125
INFO:root:Train (Epoch 35): Loss/seq after 00500 batchs: 1400.7303466796875
INFO:root:Train (Epoch 35): Loss/seq after 00550 batchs: 1342.219482421875
INFO:root:Train (Epoch 35): Loss/seq after 00600 batchs: 1303.12158203125
INFO:root:Train (Epoch 35): Loss/seq after 00650 batchs: 1331.2857666015625
INFO:root:Train (Epoch 35): Loss/seq after 00700 batchs: 1343.8988037109375
INFO:root:Train (Epoch 35): Loss/seq after 00750 batchs: 1373.0250244140625
INFO:root:Train (Epoch 35): Loss/seq after 00800 batchs: 1362.7872314453125
INFO:root:Train (Epoch 35): Loss/seq after 00850 batchs: 1334.9056396484375
INFO:root:Train (Epoch 35): Loss/seq after 00900 batchs: 1340.693115234375
INFO:root:Train (Epoch 35): Loss/seq after 00950 batchs: 1382.1158447265625
INFO:root:Train (Epoch 35): Loss/seq after 01000 batchs: 1378.1204833984375
INFO:root:Train (Epoch 35): Loss/seq after 01050 batchs: 1354.30517578125
INFO:root:Train (Epoch 35): Loss/seq after 01100 batchs: 1349.1063232421875
INFO:root:Train (Epoch 35): Loss/seq after 01150 batchs: 1333.088623046875
INFO:root:Train (Epoch 35): Loss/seq after 01200 batchs: 1321.6041259765625
INFO:root:Train (Epoch 35): Loss/seq after 01250 batchs: 1312.3277587890625
INFO:root:Train (Epoch 35): Loss/seq after 01300 batchs: 1316.2493896484375
INFO:root:Train (Epoch 35): Loss/seq after 01350 batchs: 1315.8837890625
INFO:root:Train (Epoch 35): Loss/seq after 01400 batchs: 1335.2958984375
INFO:root:Train (Epoch 35): Loss/seq after 01450 batchs: 1324.709716796875
INFO:root:Train (Epoch 35): Loss/seq after 01500 batchs: 1315.1905517578125
INFO:root:Train (Epoch 35): Loss/seq after 01550 batchs: 1314.39892578125
INFO:root:Train (Epoch 35): Loss/seq after 01600 batchs: 1298.2630615234375
INFO:root:Train (Epoch 35): Loss/seq after 01650 batchs: 1289.6595458984375
INFO:root:Train (Epoch 35): Loss/seq after 01700 batchs: 1281.2374267578125
INFO:root:Train (Epoch 35): Loss/seq after 01750 batchs: 1270.427001953125
INFO:root:Train (Epoch 35): Loss/seq after 01800 batchs: 1257.2176513671875
INFO:root:Train (Epoch 35): Loss/seq after 01850 batchs: 1244.0914306640625
INFO:root:Train (Epoch 35): Loss/seq after 01900 batchs: 1242.880126953125
INFO:root:Train (Epoch 35): Loss/seq after 01950 batchs: 1236.9364013671875
INFO:root:Train (Epoch 35): Loss/seq after 02000 batchs: 1227.8326416015625
INFO:root:Train (Epoch 35): Loss/seq after 02050 batchs: 1219.9542236328125
INFO:root:Train (Epoch 35): Loss/seq after 02100 batchs: 1208.98974609375
INFO:root:Train (Epoch 35): Loss/seq after 02150 batchs: 1198.9361572265625
INFO:root:Train (Epoch 35): Loss/seq after 02200 batchs: 1188.3428955078125
INFO:root:Train (Epoch 35): Loss/seq after 02250 batchs: 1189.547607421875
INFO:root:Train (Epoch 35): Loss/seq after 02300 batchs: 1193.75732421875
INFO:root:Train (Epoch 35): Loss/seq after 02350 batchs: 1185.390869140625
INFO:root:Train (Epoch 35): Loss/seq after 02400 batchs: 1181.6649169921875
INFO:root:Train (Epoch 35): Loss/seq after 02450 batchs: 1169.59765625
INFO:root:Train (Epoch 35): Loss/seq after 02500 batchs: 1153.46240234375
INFO:root:Train (Epoch 35): Loss/seq after 02550 batchs: 1143.067626953125
INFO:root:Train (Epoch 35): Loss/seq after 02600 batchs: 1140.87158203125
INFO:root:Train (Epoch 35): Loss/seq after 02650 batchs: 1136.74609375
INFO:root:Train (Epoch 35): Loss/seq after 02700 batchs: 1132.5374755859375
INFO:root:Train (Epoch 35): Loss/seq after 02750 batchs: 1163.22509765625
INFO:root:Train (Epoch 35): Loss/seq after 02800 batchs: 1170.2242431640625
INFO:root:Train (Epoch 35): Loss/seq after 02850 batchs: 1166.208740234375
INFO:root:Train (Epoch 35): Loss/seq after 02900 batchs: 1163.7110595703125
INFO:root:Train (Epoch 35): Loss/seq after 02950 batchs: 1156.1318359375
INFO:root:Train (Epoch 35): Loss/seq after 03000 batchs: 1154.8740234375
INFO:root:Train (Epoch 35): Loss/seq after 03050 batchs: 1158.080078125
INFO:root:Train (Epoch 35): Loss/seq after 03100 batchs: 1167.95703125
INFO:root:Train (Epoch 35): Loss/seq after 03150 batchs: 1175.0008544921875
INFO:root:Train (Epoch 35): Loss/seq after 03200 batchs: 1182.29052734375
INFO:root:Train (Epoch 35): Loss/seq after 03250 batchs: 1185.439208984375
INFO:root:Train (Epoch 35): Loss/seq after 03300 batchs: 1185.004150390625
INFO:root:Train (Epoch 35): Loss/seq after 03350 batchs: 1185.204345703125
INFO:root:Train (Epoch 35): Loss/seq after 03400 batchs: 1177.430908203125
INFO:root:Train (Epoch 35): Loss/seq after 03450 batchs: 1171.9951171875
INFO:root:Train (Epoch 35): Loss/seq after 03500 batchs: 1174.7325439453125
INFO:root:Train (Epoch 35): Loss/seq after 03550 batchs: 1170.2564697265625
INFO:root:Train (Epoch 35): Loss/seq after 03600 batchs: 1176.349609375
INFO:root:Train (Epoch 35): Loss/seq after 03650 batchs: 1172.450439453125
INFO:root:Train (Epoch 35): Loss/seq after 03700 batchs: 1172.3232421875
INFO:root:Train (Epoch 35): Loss/seq after 03750 batchs: 1172.795654296875
INFO:root:Train (Epoch 35): Loss/seq after 03800 batchs: 1166.317138671875
INFO:root:Train (Epoch 35): Loss/seq after 03850 batchs: 1162.287841796875
INFO:root:Train (Epoch 35): Loss/seq after 03900 batchs: 1167.6109619140625
INFO:root:Train (Epoch 35): Loss/seq after 03950 batchs: 1172.74658203125
INFO:root:Train (Epoch 35): Loss/seq after 04000 batchs: 1164.459716796875
INFO:root:Train (Epoch 35): Loss/seq after 04050 batchs: 1157.1181640625
INFO:root:Train (Epoch 35): Loss/seq after 04100 batchs: 1151.8583984375
INFO:root:Train (Epoch 35): Loss/seq after 04150 batchs: 1146.705810546875
INFO:root:Train (Epoch 35): Loss/seq after 04200 batchs: 1142.0858154296875
INFO:root:Train (Epoch 35): Loss/seq after 04250 batchs: 1138.385986328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 35): Loss/seq after 00000 batches: 896.081298828125
INFO:root:# Valid (Epoch 35): Loss/seq after 00050 batches: 1113.5697021484375
INFO:root:# Valid (Epoch 35): Loss/seq after 00100 batches: 1401.0047607421875
INFO:root:# Valid (Epoch 35): Loss/seq after 00150 batches: 1114.48046875
INFO:root:# Valid (Epoch 35): Loss/seq after 00200 batches: 1002.2964477539062
INFO:root:Artifacts: Make stick videos for epoch 35
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_35_on_20220413_175518.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_35_index_1167_on_20220413_175518.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 36): Loss/seq after 00000 batchs: 1985.4776611328125
INFO:root:Train (Epoch 36): Loss/seq after 00050 batchs: 1496.4599609375
INFO:root:Train (Epoch 36): Loss/seq after 00100 batchs: 1444.934326171875
INFO:root:Train (Epoch 36): Loss/seq after 00150 batchs: 1291.5140380859375
INFO:root:Train (Epoch 36): Loss/seq after 00200 batchs: 1386.777587890625
INFO:root:Train (Epoch 36): Loss/seq after 00250 batchs: 1518.637939453125
INFO:root:Train (Epoch 36): Loss/seq after 00300 batchs: 1448.9256591796875
INFO:root:Train (Epoch 36): Loss/seq after 00350 batchs: 1353.123779296875
INFO:root:Train (Epoch 36): Loss/seq after 00400 batchs: 1384.0126953125
INFO:root:Train (Epoch 36): Loss/seq after 00450 batchs: 1327.468994140625
INFO:root:Train (Epoch 36): Loss/seq after 00500 batchs: 1342.764404296875
INFO:root:Train (Epoch 36): Loss/seq after 00550 batchs: 1288.3525390625
INFO:root:Train (Epoch 36): Loss/seq after 00600 batchs: 1256.6966552734375
INFO:root:Train (Epoch 36): Loss/seq after 00650 batchs: 1273.057373046875
INFO:root:Train (Epoch 36): Loss/seq after 00700 batchs: 1264.0426025390625
INFO:root:Train (Epoch 36): Loss/seq after 00750 batchs: 1297.156005859375
INFO:root:Train (Epoch 36): Loss/seq after 00800 batchs: 1296.8402099609375
INFO:root:Train (Epoch 36): Loss/seq after 00850 batchs: 1279.8714599609375
INFO:root:Train (Epoch 36): Loss/seq after 00900 batchs: 1294.5152587890625
INFO:root:Train (Epoch 36): Loss/seq after 00950 batchs: 1332.6890869140625
INFO:root:Train (Epoch 36): Loss/seq after 01000 batchs: 1325.807861328125
INFO:root:Train (Epoch 36): Loss/seq after 01050 batchs: 1304.405029296875
INFO:root:Train (Epoch 36): Loss/seq after 01100 batchs: 1298.410400390625
INFO:root:Train (Epoch 36): Loss/seq after 01150 batchs: 1283.2891845703125
INFO:root:Train (Epoch 36): Loss/seq after 01200 batchs: 1273.8951416015625
INFO:root:Train (Epoch 36): Loss/seq after 01250 batchs: 1266.345458984375
INFO:root:Train (Epoch 36): Loss/seq after 01300 batchs: 1270.53515625
INFO:root:Train (Epoch 36): Loss/seq after 01350 batchs: 1273.3885498046875
INFO:root:Train (Epoch 36): Loss/seq after 01400 batchs: 1291.728271484375
INFO:root:Train (Epoch 36): Loss/seq after 01450 batchs: 1283.1683349609375
INFO:root:Train (Epoch 36): Loss/seq after 01500 batchs: 1275.141357421875
INFO:root:Train (Epoch 36): Loss/seq after 01550 batchs: 1276.1300048828125
INFO:root:Train (Epoch 36): Loss/seq after 01600 batchs: 1260.6912841796875
INFO:root:Train (Epoch 36): Loss/seq after 01650 batchs: 1252.994384765625
INFO:root:Train (Epoch 36): Loss/seq after 01700 batchs: 1245.1412353515625
INFO:root:Train (Epoch 36): Loss/seq after 01750 batchs: 1235.3656005859375
INFO:root:Train (Epoch 36): Loss/seq after 01800 batchs: 1223.037353515625
INFO:root:Train (Epoch 36): Loss/seq after 01850 batchs: 1210.7574462890625
INFO:root:Train (Epoch 36): Loss/seq after 01900 batchs: 1211.18994140625
INFO:root:Train (Epoch 36): Loss/seq after 01950 batchs: 1206.83642578125
INFO:root:Train (Epoch 36): Loss/seq after 02000 batchs: 1198.4921875
INFO:root:Train (Epoch 36): Loss/seq after 02050 batchs: 1191.2913818359375
INFO:root:Train (Epoch 36): Loss/seq after 02100 batchs: 1181.0343017578125
INFO:root:Train (Epoch 36): Loss/seq after 02150 batchs: 1171.640869140625
INFO:root:Train (Epoch 36): Loss/seq after 02200 batchs: 1161.6905517578125
INFO:root:Train (Epoch 36): Loss/seq after 02250 batchs: 1162.6279296875
INFO:root:Train (Epoch 36): Loss/seq after 02300 batchs: 1166.7266845703125
INFO:root:Train (Epoch 36): Loss/seq after 02350 batchs: 1158.0927734375
INFO:root:Train (Epoch 36): Loss/seq after 02400 batchs: 1154.7127685546875
INFO:root:Train (Epoch 36): Loss/seq after 02450 batchs: 1142.875732421875
INFO:root:Train (Epoch 36): Loss/seq after 02500 batchs: 1127.2132568359375
INFO:root:Train (Epoch 36): Loss/seq after 02550 batchs: 1116.8448486328125
INFO:root:Train (Epoch 36): Loss/seq after 02600 batchs: 1115.5557861328125
INFO:root:Train (Epoch 36): Loss/seq after 02650 batchs: 1111.998779296875
INFO:root:Train (Epoch 36): Loss/seq after 02700 batchs: 1108.92578125
INFO:root:Train (Epoch 36): Loss/seq after 02750 batchs: 1140.132568359375
INFO:root:Train (Epoch 36): Loss/seq after 02800 batchs: 1146.8209228515625
INFO:root:Train (Epoch 36): Loss/seq after 02850 batchs: 1143.2603759765625
INFO:root:Train (Epoch 36): Loss/seq after 02900 batchs: 1142.1663818359375
INFO:root:Train (Epoch 36): Loss/seq after 02950 batchs: 1135.2288818359375
INFO:root:Train (Epoch 36): Loss/seq after 03000 batchs: 1134.312255859375
INFO:root:Train (Epoch 36): Loss/seq after 03050 batchs: 1137.83154296875
INFO:root:Train (Epoch 36): Loss/seq after 03100 batchs: 1146.9383544921875
INFO:root:Train (Epoch 36): Loss/seq after 03150 batchs: 1152.8553466796875
INFO:root:Train (Epoch 36): Loss/seq after 03200 batchs: 1159.5562744140625
INFO:root:Train (Epoch 36): Loss/seq after 03250 batchs: 1163.4986572265625
INFO:root:Train (Epoch 36): Loss/seq after 03300 batchs: 1165.02880859375
INFO:root:Train (Epoch 36): Loss/seq after 03350 batchs: 1166.418212890625
INFO:root:Train (Epoch 36): Loss/seq after 03400 batchs: 1159.349365234375
INFO:root:Train (Epoch 36): Loss/seq after 03450 batchs: 1154.5487060546875
INFO:root:Train (Epoch 36): Loss/seq after 03500 batchs: 1154.97021484375
INFO:root:Train (Epoch 36): Loss/seq after 03550 batchs: 1149.6015625
INFO:root:Train (Epoch 36): Loss/seq after 03600 batchs: 1155.80078125
INFO:root:Train (Epoch 36): Loss/seq after 03650 batchs: 1151.5384521484375
INFO:root:Train (Epoch 36): Loss/seq after 03700 batchs: 1151.8349609375
INFO:root:Train (Epoch 36): Loss/seq after 03750 batchs: 1152.571533203125
INFO:root:Train (Epoch 36): Loss/seq after 03800 batchs: 1146.406005859375
INFO:root:Train (Epoch 36): Loss/seq after 03850 batchs: 1142.6414794921875
INFO:root:Train (Epoch 36): Loss/seq after 03900 batchs: 1146.91455078125
INFO:root:Train (Epoch 36): Loss/seq after 03950 batchs: 1151.494384765625
INFO:root:Train (Epoch 36): Loss/seq after 04000 batchs: 1143.4010009765625
INFO:root:Train (Epoch 36): Loss/seq after 04050 batchs: 1136.308349609375
INFO:root:Train (Epoch 36): Loss/seq after 04100 batchs: 1131.0098876953125
INFO:root:Train (Epoch 36): Loss/seq after 04150 batchs: 1125.9044189453125
INFO:root:Train (Epoch 36): Loss/seq after 04200 batchs: 1121.144287109375
INFO:root:Train (Epoch 36): Loss/seq after 04250 batchs: 1117.5513916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 36): Loss/seq after 00000 batches: 879.60498046875
INFO:root:# Valid (Epoch 36): Loss/seq after 00050 batches: 1110.3017578125
INFO:root:# Valid (Epoch 36): Loss/seq after 00100 batches: 1406.1611328125
INFO:root:# Valid (Epoch 36): Loss/seq after 00150 batches: 1130.546142578125
INFO:root:# Valid (Epoch 36): Loss/seq after 00200 batches: 1020.0247802734375
INFO:root:Artifacts: Make stick videos for epoch 36
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_36_on_20220413_180036.gif.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
wandb: Network error (ReadTimeout), entering retry loop.
[34m[1mwandb[0m: [33mWARNING[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_36_index_611_on_20220413_180036.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 37): Loss/seq after 00000 batchs: 1570.935546875
INFO:root:Train (Epoch 37): Loss/seq after 00050 batchs: 1478.476318359375
INFO:root:Train (Epoch 37): Loss/seq after 00100 batchs: 1431.7252197265625
INFO:root:Train (Epoch 37): Loss/seq after 00150 batchs: 1286.2425537109375
INFO:root:Train (Epoch 37): Loss/seq after 00200 batchs: 1378.0909423828125
INFO:root:Train (Epoch 37): Loss/seq after 00250 batchs: 1522.5421142578125
INFO:root:Train (Epoch 37): Loss/seq after 00300 batchs: 1451.8370361328125
INFO:root:Train (Epoch 37): Loss/seq after 00350 batchs: 1356.634033203125
INFO:root:Train (Epoch 37): Loss/seq after 00400 batchs: 1388.021728515625
INFO:root:Train (Epoch 37): Loss/seq after 00450 batchs: 1331.386474609375
INFO:root:Train (Epoch 37): Loss/seq after 00500 batchs: 1342.87646484375
INFO:root:Train (Epoch 37): Loss/seq after 00550 batchs: 1288.35791015625
INFO:root:Train (Epoch 37): Loss/seq after 00600 batchs: 1255.0064697265625
INFO:root:Train (Epoch 37): Loss/seq after 00650 batchs: 1273.58056640625
INFO:root:Train (Epoch 37): Loss/seq after 00700 batchs: 1266.2952880859375
INFO:root:Train (Epoch 37): Loss/seq after 00750 batchs: 1300.7071533203125
INFO:root:Train (Epoch 37): Loss/seq after 00800 batchs: 1298.4708251953125
INFO:root:Train (Epoch 37): Loss/seq after 00850 batchs: 1280.4266357421875
INFO:root:Train (Epoch 37): Loss/seq after 00900 batchs: 1289.9639892578125
INFO:root:Train (Epoch 37): Loss/seq after 00950 batchs: 1317.1240234375
INFO:root:Train (Epoch 37): Loss/seq after 01000 batchs: 1308.1011962890625
INFO:root:Train (Epoch 37): Loss/seq after 01050 batchs: 1286.904052734375
INFO:root:Train (Epoch 37): Loss/seq after 01100 batchs: 1282.4228515625
INFO:root:Train (Epoch 37): Loss/seq after 01150 batchs: 1268.0657958984375
INFO:root:Train (Epoch 37): Loss/seq after 01200 batchs: 1258.6815185546875
INFO:root:Train (Epoch 37): Loss/seq after 01250 batchs: 1250.7672119140625
INFO:root:Train (Epoch 37): Loss/seq after 01300 batchs: 1251.860595703125
INFO:root:Train (Epoch 37): Loss/seq after 01350 batchs: 1252.3187255859375
INFO:root:Train (Epoch 37): Loss/seq after 01400 batchs: 1270.077392578125
INFO:root:Train (Epoch 37): Loss/seq after 01450 batchs: 1261.6175537109375
INFO:root:Train (Epoch 37): Loss/seq after 01500 batchs: 1254.2235107421875
INFO:root:Train (Epoch 37): Loss/seq after 01550 batchs: 1254.5809326171875
INFO:root:Train (Epoch 37): Loss/seq after 01600 batchs: 1239.77490234375
INFO:root:Train (Epoch 37): Loss/seq after 01650 batchs: 1231.500732421875
INFO:root:Train (Epoch 37): Loss/seq after 01700 batchs: 1223.7828369140625
INFO:root:Train (Epoch 37): Loss/seq after 01750 batchs: 1214.7283935546875
INFO:root:Train (Epoch 37): Loss/seq after 01800 batchs: 1203.131103515625
INFO:root:Train (Epoch 37): Loss/seq after 01850 batchs: 1191.525146484375
INFO:root:Train (Epoch 37): Loss/seq after 01900 batchs: 1191.5968017578125
INFO:root:Train (Epoch 37): Loss/seq after 01950 batchs: 1186.59326171875
INFO:root:Train (Epoch 37): Loss/seq after 02000 batchs: 1178.64306640625
INFO:root:Train (Epoch 37): Loss/seq after 02050 batchs: 1171.8818359375
INFO:root:Train (Epoch 37): Loss/seq after 02100 batchs: 1162.041259765625
INFO:root:Train (Epoch 37): Loss/seq after 02150 batchs: 1153.037109375
INFO:root:Train (Epoch 37): Loss/seq after 02200 batchs: 1143.4906005859375
INFO:root:Train (Epoch 37): Loss/seq after 02250 batchs: 1144.487548828125
INFO:root:Train (Epoch 37): Loss/seq after 02300 batchs: 1149.888671875
INFO:root:Train (Epoch 37): Loss/seq after 02350 batchs: 1141.2330322265625
INFO:root:Train (Epoch 37): Loss/seq after 02400 batchs: 1138.02685546875
INFO:root:Train (Epoch 37): Loss/seq after 02450 batchs: 1126.52392578125
INFO:root:Train (Epoch 37): Loss/seq after 02500 batchs: 1111.2110595703125
INFO:root:Train (Epoch 37): Loss/seq after 02550 batchs: 1101.14990234375
INFO:root:Train (Epoch 37): Loss/seq after 02600 batchs: 1099.65380859375
INFO:root:Train (Epoch 37): Loss/seq after 02650 batchs: 1096.29248046875
INFO:root:Train (Epoch 37): Loss/seq after 02700 batchs: 1092.7244873046875
INFO:root:Train (Epoch 37): Loss/seq after 02750 batchs: 1123.4171142578125
INFO:root:Train (Epoch 37): Loss/seq after 02800 batchs: 1130.2884521484375
INFO:root:Train (Epoch 37): Loss/seq after 02850 batchs: 1126.952880859375
INFO:root:Train (Epoch 37): Loss/seq after 02900 batchs: 1125.1864013671875
INFO:root:Train (Epoch 37): Loss/seq after 02950 batchs: 1118.2371826171875
INFO:root:Train (Epoch 37): Loss/seq after 03000 batchs: 1117.58740234375
INFO:root:Train (Epoch 37): Loss/seq after 03050 batchs: 1121.271240234375
INFO:root:Train (Epoch 37): Loss/seq after 03100 batchs: 1130.1187744140625
INFO:root:Train (Epoch 37): Loss/seq after 03150 batchs: 1137.365234375
INFO:root:Train (Epoch 37): Loss/seq after 03200 batchs: 1143.931396484375
INFO:root:Train (Epoch 37): Loss/seq after 03250 batchs: 1147.759765625
INFO:root:Train (Epoch 37): Loss/seq after 03300 batchs: 1146.7352294921875
INFO:root:Train (Epoch 37): Loss/seq after 03350 batchs: 1147.7584228515625
INFO:root:Train (Epoch 37): Loss/seq after 03400 batchs: 1140.453857421875
INFO:root:Train (Epoch 37): Loss/seq after 03450 batchs: 1134.8253173828125
INFO:root:Train (Epoch 37): Loss/seq after 03500 batchs: 1134.8089599609375
INFO:root:Train (Epoch 37): Loss/seq after 03550 batchs: 1128.9940185546875
INFO:root:Train (Epoch 37): Loss/seq after 03600 batchs: 1135.7283935546875
INFO:root:Train (Epoch 37): Loss/seq after 03650 batchs: 1130.8148193359375
INFO:root:Train (Epoch 37): Loss/seq after 03700 batchs: 1130.9156494140625
INFO:root:Train (Epoch 37): Loss/seq after 03750 batchs: 1131.965087890625
INFO:root:Train (Epoch 37): Loss/seq after 03800 batchs: 1126.0504150390625
INFO:root:Train (Epoch 37): Loss/seq after 03850 batchs: 1122.5631103515625
INFO:root:Train (Epoch 37): Loss/seq after 03900 batchs: 1127.6546630859375
INFO:root:Train (Epoch 37): Loss/seq after 03950 batchs: 1131.2198486328125
INFO:root:Train (Epoch 37): Loss/seq after 04000 batchs: 1123.3687744140625
INFO:root:Train (Epoch 37): Loss/seq after 04050 batchs: 1116.5244140625
INFO:root:Train (Epoch 37): Loss/seq after 04100 batchs: 1111.5428466796875
INFO:root:Train (Epoch 37): Loss/seq after 04150 batchs: 1106.7481689453125
INFO:root:Train (Epoch 37): Loss/seq after 04200 batchs: 1102.1221923828125
INFO:root:Train (Epoch 37): Loss/seq after 04250 batchs: 1098.5904541015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 37): Loss/seq after 00000 batches: 890.3043823242188
INFO:root:# Valid (Epoch 37): Loss/seq after 00050 batches: 1102.7733154296875
INFO:root:# Valid (Epoch 37): Loss/seq after 00100 batches: 1406.9525146484375
INFO:root:# Valid (Epoch 37): Loss/seq after 00150 batches: 1129.135498046875
INFO:root:# Valid (Epoch 37): Loss/seq after 00200 batches: 1017.8375854492188
INFO:root:Artifacts: Make stick videos for epoch 37
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_37_on_20220413_180632.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_37_index_1370_on_20220413_180632.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 38): Loss/seq after 00000 batchs: 1608.50439453125
INFO:root:Train (Epoch 38): Loss/seq after 00050 batchs: 1462.6138916015625
INFO:root:Train (Epoch 38): Loss/seq after 00100 batchs: 1475.8118896484375
INFO:root:Train (Epoch 38): Loss/seq after 00150 batchs: 1325.0902099609375
INFO:root:Train (Epoch 38): Loss/seq after 00200 batchs: 1418.7359619140625
INFO:root:Train (Epoch 38): Loss/seq after 00250 batchs: 1558.0341796875
INFO:root:Train (Epoch 38): Loss/seq after 00300 batchs: 1481.0003662109375
INFO:root:Train (Epoch 38): Loss/seq after 00350 batchs: 1385.889892578125
INFO:root:Train (Epoch 38): Loss/seq after 00400 batchs: 1415.8251953125
INFO:root:Train (Epoch 38): Loss/seq after 00450 batchs: 1356.5965576171875
INFO:root:Train (Epoch 38): Loss/seq after 00500 batchs: 1365.830322265625
INFO:root:Train (Epoch 38): Loss/seq after 00550 batchs: 1310.9156494140625
INFO:root:Train (Epoch 38): Loss/seq after 00600 batchs: 1273.9390869140625
INFO:root:Train (Epoch 38): Loss/seq after 00650 batchs: 1287.755859375
INFO:root:Train (Epoch 38): Loss/seq after 00700 batchs: 1289.3466796875
INFO:root:Train (Epoch 38): Loss/seq after 00750 batchs: 1322.2261962890625
INFO:root:Train (Epoch 38): Loss/seq after 00800 batchs: 1312.82763671875
INFO:root:Train (Epoch 38): Loss/seq after 00850 batchs: 1287.103271484375
INFO:root:Train (Epoch 38): Loss/seq after 00900 batchs: 1295.66015625
INFO:root:Train (Epoch 38): Loss/seq after 00950 batchs: 1324.9921875
INFO:root:Train (Epoch 38): Loss/seq after 01000 batchs: 1319.5357666015625
INFO:root:Train (Epoch 38): Loss/seq after 01050 batchs: 1296.555908203125
INFO:root:Train (Epoch 38): Loss/seq after 01100 batchs: 1298.1300048828125
INFO:root:Train (Epoch 38): Loss/seq after 01150 batchs: 1283.6749267578125
INFO:root:Train (Epoch 38): Loss/seq after 01200 batchs: 1274.193603515625
INFO:root:Train (Epoch 38): Loss/seq after 01250 batchs: 1267.0908203125
INFO:root:Train (Epoch 38): Loss/seq after 01300 batchs: 1268.363525390625
INFO:root:Train (Epoch 38): Loss/seq after 01350 batchs: 1268.8402099609375
INFO:root:Train (Epoch 38): Loss/seq after 01400 batchs: 1285.25634765625
INFO:root:Train (Epoch 38): Loss/seq after 01450 batchs: 1276.1075439453125
INFO:root:Train (Epoch 38): Loss/seq after 01500 batchs: 1268.2403564453125
INFO:root:Train (Epoch 38): Loss/seq after 01550 batchs: 1268.625
INFO:root:Train (Epoch 38): Loss/seq after 01600 batchs: 1253.540771484375
INFO:root:Train (Epoch 38): Loss/seq after 01650 batchs: 1244.9991455078125
INFO:root:Train (Epoch 38): Loss/seq after 01700 batchs: 1237.4039306640625
INFO:root:Train (Epoch 38): Loss/seq after 01750 batchs: 1227.4805908203125
INFO:root:Train (Epoch 38): Loss/seq after 01800 batchs: 1215.4111328125
INFO:root:Train (Epoch 38): Loss/seq after 01850 batchs: 1203.3385009765625
INFO:root:Train (Epoch 38): Loss/seq after 01900 batchs: 1202.6246337890625
INFO:root:Train (Epoch 38): Loss/seq after 01950 batchs: 1198.2720947265625
INFO:root:Train (Epoch 38): Loss/seq after 02000 batchs: 1190.2342529296875
INFO:root:Train (Epoch 38): Loss/seq after 02050 batchs: 1183.17236328125
INFO:root:Train (Epoch 38): Loss/seq after 02100 batchs: 1173.0821533203125
INFO:root:Train (Epoch 38): Loss/seq after 02150 batchs: 1163.7342529296875
INFO:root:Train (Epoch 38): Loss/seq after 02200 batchs: 1153.8990478515625
INFO:root:Train (Epoch 38): Loss/seq after 02250 batchs: 1155.48046875
INFO:root:Train (Epoch 38): Loss/seq after 02300 batchs: 1161.1619873046875
INFO:root:Train (Epoch 38): Loss/seq after 02350 batchs: 1152.6922607421875
INFO:root:Train (Epoch 38): Loss/seq after 02400 batchs: 1149.410400390625
INFO:root:Train (Epoch 38): Loss/seq after 02450 batchs: 1137.656005859375
INFO:root:Train (Epoch 38): Loss/seq after 02500 batchs: 1122.0968017578125
INFO:root:Train (Epoch 38): Loss/seq after 02550 batchs: 1111.574462890625
INFO:root:Train (Epoch 38): Loss/seq after 02600 batchs: 1109.8875732421875
INFO:root:Train (Epoch 38): Loss/seq after 02650 batchs: 1106.34326171875
INFO:root:Train (Epoch 38): Loss/seq after 02700 batchs: 1102.749267578125
INFO:root:Train (Epoch 38): Loss/seq after 02750 batchs: 1133.310302734375
INFO:root:Train (Epoch 38): Loss/seq after 02800 batchs: 1139.36669921875
INFO:root:Train (Epoch 38): Loss/seq after 02850 batchs: 1135.837646484375
INFO:root:Train (Epoch 38): Loss/seq after 02900 batchs: 1134.238525390625
INFO:root:Train (Epoch 38): Loss/seq after 02950 batchs: 1127.0670166015625
INFO:root:Train (Epoch 38): Loss/seq after 03000 batchs: 1126.2618408203125
INFO:root:Train (Epoch 38): Loss/seq after 03050 batchs: 1129.784423828125
INFO:root:Train (Epoch 38): Loss/seq after 03100 batchs: 1139.091064453125
INFO:root:Train (Epoch 38): Loss/seq after 03150 batchs: 1145.5367431640625
INFO:root:Train (Epoch 38): Loss/seq after 03200 batchs: 1150.3634033203125
INFO:root:Train (Epoch 38): Loss/seq after 03250 batchs: 1153.4775390625
INFO:root:Train (Epoch 38): Loss/seq after 03300 batchs: 1153.0548095703125
INFO:root:Train (Epoch 38): Loss/seq after 03350 batchs: 1153.1868896484375
INFO:root:Train (Epoch 38): Loss/seq after 03400 batchs: 1145.8848876953125
INFO:root:Train (Epoch 38): Loss/seq after 03450 batchs: 1141.3990478515625
INFO:root:Train (Epoch 38): Loss/seq after 03500 batchs: 1142.15625
INFO:root:Train (Epoch 38): Loss/seq after 03550 batchs: 1136.6060791015625
INFO:root:Train (Epoch 38): Loss/seq after 03600 batchs: 1143.243896484375
INFO:root:Train (Epoch 38): Loss/seq after 03650 batchs: 1138.5501708984375
INFO:root:Train (Epoch 38): Loss/seq after 03700 batchs: 1138.765625
INFO:root:Train (Epoch 38): Loss/seq after 03750 batchs: 1139.739990234375
INFO:root:Train (Epoch 38): Loss/seq after 03800 batchs: 1133.76171875
INFO:root:Train (Epoch 38): Loss/seq after 03850 batchs: 1130.1318359375
INFO:root:Train (Epoch 38): Loss/seq after 03900 batchs: 1135.4459228515625
INFO:root:Train (Epoch 38): Loss/seq after 03950 batchs: 1139.192138671875
INFO:root:Train (Epoch 38): Loss/seq after 04000 batchs: 1131.2884521484375
INFO:root:Train (Epoch 38): Loss/seq after 04050 batchs: 1124.3642578125
INFO:root:Train (Epoch 38): Loss/seq after 04100 batchs: 1119.237060546875
INFO:root:Train (Epoch 38): Loss/seq after 04150 batchs: 1114.4134521484375
INFO:root:Train (Epoch 38): Loss/seq after 04200 batchs: 1109.8812255859375
INFO:root:Train (Epoch 38): Loss/seq after 04250 batchs: 1106.301513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 38): Loss/seq after 00000 batches: 885.471435546875
INFO:root:# Valid (Epoch 38): Loss/seq after 00050 batches: 1094.756591796875
INFO:root:# Valid (Epoch 38): Loss/seq after 00100 batches: 1393.7568359375
INFO:root:# Valid (Epoch 38): Loss/seq after 00150 batches: 1109.4879150390625
INFO:root:# Valid (Epoch 38): Loss/seq after 00200 batches: 997.960693359375
INFO:root:Artifacts: Make stick videos for epoch 38
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_38_on_20220413_181150.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_38_index_961_on_20220413_181150.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 39): Loss/seq after 00000 batchs: 1814.78466796875
INFO:root:Train (Epoch 39): Loss/seq after 00050 batchs: 1435.05517578125
INFO:root:Train (Epoch 39): Loss/seq after 00100 batchs: 1403.812744140625
INFO:root:Train (Epoch 39): Loss/seq after 00150 batchs: 1274.19189453125
INFO:root:Train (Epoch 39): Loss/seq after 00200 batchs: 1367.79150390625
INFO:root:Train (Epoch 39): Loss/seq after 00250 batchs: 1505.09716796875
INFO:root:Train (Epoch 39): Loss/seq after 00300 batchs: 1437.939697265625
INFO:root:Train (Epoch 39): Loss/seq after 00350 batchs: 1344.8052978515625
INFO:root:Train (Epoch 39): Loss/seq after 00400 batchs: 1371.3675537109375
INFO:root:Train (Epoch 39): Loss/seq after 00450 batchs: 1316.6192626953125
INFO:root:Train (Epoch 39): Loss/seq after 00500 batchs: 1332.596435546875
INFO:root:Train (Epoch 39): Loss/seq after 00550 batchs: 1278.9453125
INFO:root:Train (Epoch 39): Loss/seq after 00600 batchs: 1246.5631103515625
INFO:root:Train (Epoch 39): Loss/seq after 00650 batchs: 1255.20166015625
INFO:root:Train (Epoch 39): Loss/seq after 00700 batchs: 1242.801513671875
INFO:root:Train (Epoch 39): Loss/seq after 00750 batchs: 1275.4085693359375
INFO:root:Train (Epoch 39): Loss/seq after 00800 batchs: 1274.06689453125
INFO:root:Train (Epoch 39): Loss/seq after 00850 batchs: 1251.6165771484375
INFO:root:Train (Epoch 39): Loss/seq after 00900 batchs: 1264.5252685546875
INFO:root:Train (Epoch 39): Loss/seq after 00950 batchs: 1290.6820068359375
INFO:root:Train (Epoch 39): Loss/seq after 01000 batchs: 1282.6153564453125
INFO:root:Train (Epoch 39): Loss/seq after 01050 batchs: 1263.019287109375
INFO:root:Train (Epoch 39): Loss/seq after 01100 batchs: 1260.595458984375
INFO:root:Train (Epoch 39): Loss/seq after 01150 batchs: 1246.756591796875
INFO:root:Train (Epoch 39): Loss/seq after 01200 batchs: 1238.8712158203125
INFO:root:Train (Epoch 39): Loss/seq after 01250 batchs: 1232.43359375
INFO:root:Train (Epoch 39): Loss/seq after 01300 batchs: 1234.2337646484375
INFO:root:Train (Epoch 39): Loss/seq after 01350 batchs: 1235.6922607421875
INFO:root:Train (Epoch 39): Loss/seq after 01400 batchs: 1253.53662109375
INFO:root:Train (Epoch 39): Loss/seq after 01450 batchs: 1245.4888916015625
INFO:root:Train (Epoch 39): Loss/seq after 01500 batchs: 1238.7603759765625
INFO:root:Train (Epoch 39): Loss/seq after 01550 batchs: 1239.5986328125
INFO:root:Train (Epoch 39): Loss/seq after 01600 batchs: 1224.9669189453125
INFO:root:Train (Epoch 39): Loss/seq after 01650 batchs: 1217.943603515625
INFO:root:Train (Epoch 39): Loss/seq after 01700 batchs: 1210.43603515625
INFO:root:Train (Epoch 39): Loss/seq after 01750 batchs: 1201.443359375
INFO:root:Train (Epoch 39): Loss/seq after 01800 batchs: 1189.9061279296875
INFO:root:Train (Epoch 39): Loss/seq after 01850 batchs: 1178.556396484375
INFO:root:Train (Epoch 39): Loss/seq after 01900 batchs: 1179.7135009765625
INFO:root:Train (Epoch 39): Loss/seq after 01950 batchs: 1175.82080078125
INFO:root:Train (Epoch 39): Loss/seq after 02000 batchs: 1168.2279052734375
INFO:root:Train (Epoch 39): Loss/seq after 02050 batchs: 1161.68798828125
INFO:root:Train (Epoch 39): Loss/seq after 02100 batchs: 1152.1817626953125
INFO:root:Train (Epoch 39): Loss/seq after 02150 batchs: 1143.380859375
INFO:root:Train (Epoch 39): Loss/seq after 02200 batchs: 1134.0384521484375
INFO:root:Train (Epoch 39): Loss/seq after 02250 batchs: 1135.18017578125
INFO:root:Train (Epoch 39): Loss/seq after 02300 batchs: 1140.576171875
INFO:root:Train (Epoch 39): Loss/seq after 02350 batchs: 1132.6199951171875
INFO:root:Train (Epoch 39): Loss/seq after 02400 batchs: 1129.71337890625
INFO:root:Train (Epoch 39): Loss/seq after 02450 batchs: 1118.427734375
INFO:root:Train (Epoch 39): Loss/seq after 02500 batchs: 1103.2576904296875
INFO:root:Train (Epoch 39): Loss/seq after 02550 batchs: 1092.9775390625
INFO:root:Train (Epoch 39): Loss/seq after 02600 batchs: 1092.0848388671875
INFO:root:Train (Epoch 39): Loss/seq after 02650 batchs: 1088.9951171875
INFO:root:Train (Epoch 39): Loss/seq after 02700 batchs: 1085.9639892578125
INFO:root:Train (Epoch 39): Loss/seq after 02750 batchs: 1117.440185546875
INFO:root:Train (Epoch 39): Loss/seq after 02800 batchs: 1124.5069580078125
INFO:root:Train (Epoch 39): Loss/seq after 02850 batchs: 1121.2291259765625
INFO:root:Train (Epoch 39): Loss/seq after 02900 batchs: 1119.4075927734375
INFO:root:Train (Epoch 39): Loss/seq after 02950 batchs: 1112.4498291015625
INFO:root:Train (Epoch 39): Loss/seq after 03000 batchs: 1111.909423828125
INFO:root:Train (Epoch 39): Loss/seq after 03050 batchs: 1115.680419921875
INFO:root:Train (Epoch 39): Loss/seq after 03100 batchs: 1124.9119873046875
INFO:root:Train (Epoch 39): Loss/seq after 03150 batchs: 1129.649169921875
INFO:root:Train (Epoch 39): Loss/seq after 03200 batchs: 1135.339111328125
INFO:root:Train (Epoch 39): Loss/seq after 03250 batchs: 1138.0689697265625
INFO:root:Train (Epoch 39): Loss/seq after 03300 batchs: 1137.8529052734375
INFO:root:Train (Epoch 39): Loss/seq after 03350 batchs: 1138.10400390625
INFO:root:Train (Epoch 39): Loss/seq after 03400 batchs: 1130.94873046875
INFO:root:Train (Epoch 39): Loss/seq after 03450 batchs: 1125.8521728515625
INFO:root:Train (Epoch 39): Loss/seq after 03500 batchs: 1125.392333984375
INFO:root:Train (Epoch 39): Loss/seq after 03550 batchs: 1119.67724609375
INFO:root:Train (Epoch 39): Loss/seq after 03600 batchs: 1126.4364013671875
INFO:root:Train (Epoch 39): Loss/seq after 03650 batchs: 1121.4276123046875
INFO:root:Train (Epoch 39): Loss/seq after 03700 batchs: 1121.6556396484375
INFO:root:Train (Epoch 39): Loss/seq after 03750 batchs: 1122.7559814453125
INFO:root:Train (Epoch 39): Loss/seq after 03800 batchs: 1116.9083251953125
INFO:root:Train (Epoch 39): Loss/seq after 03850 batchs: 1113.493408203125
INFO:root:Train (Epoch 39): Loss/seq after 03900 batchs: 1118.2880859375
INFO:root:Train (Epoch 39): Loss/seq after 03950 batchs: 1122.02099609375
INFO:root:Train (Epoch 39): Loss/seq after 04000 batchs: 1114.3043212890625
INFO:root:Train (Epoch 39): Loss/seq after 04050 batchs: 1107.5743408203125
INFO:root:Train (Epoch 39): Loss/seq after 04100 batchs: 1102.8834228515625
INFO:root:Train (Epoch 39): Loss/seq after 04150 batchs: 1098.30859375
INFO:root:Train (Epoch 39): Loss/seq after 04200 batchs: 1094.2275390625
INFO:root:Train (Epoch 39): Loss/seq after 04250 batchs: 1091.1033935546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 39): Loss/seq after 00000 batches: 878.3787841796875
INFO:root:# Valid (Epoch 39): Loss/seq after 00050 batches: 1094.825927734375
INFO:root:# Valid (Epoch 39): Loss/seq after 00100 batches: 1389.662841796875
INFO:root:# Valid (Epoch 39): Loss/seq after 00150 batches: 1116.8636474609375
INFO:root:# Valid (Epoch 39): Loss/seq after 00200 batches: 1008.3521118164062
INFO:root:Artifacts: Make stick videos for epoch 39
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_39_on_20220413_181710.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_39_index_1663_on_20220413_181710.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 40): Loss/seq after 00000 batchs: 1527.5787353515625
INFO:root:Train (Epoch 40): Loss/seq after 00050 batchs: 1437.3912353515625
INFO:root:Train (Epoch 40): Loss/seq after 00100 batchs: 1449.5787353515625
INFO:root:Train (Epoch 40): Loss/seq after 00150 batchs: 1317.191162109375
INFO:root:Train (Epoch 40): Loss/seq after 00200 batchs: 1407.5340576171875
INFO:root:Train (Epoch 40): Loss/seq after 00250 batchs: 1550.02197265625
INFO:root:Train (Epoch 40): Loss/seq after 00300 batchs: 1474.5865478515625
INFO:root:Train (Epoch 40): Loss/seq after 00350 batchs: 1380.5980224609375
INFO:root:Train (Epoch 40): Loss/seq after 00400 batchs: 1405.5882568359375
INFO:root:Train (Epoch 40): Loss/seq after 00450 batchs: 1347.10693359375
INFO:root:Train (Epoch 40): Loss/seq after 00500 batchs: 1359.1566162109375
INFO:root:Train (Epoch 40): Loss/seq after 00550 batchs: 1305.39990234375
INFO:root:Train (Epoch 40): Loss/seq after 00600 batchs: 1268.885009765625
INFO:root:Train (Epoch 40): Loss/seq after 00650 batchs: 1274.6732177734375
INFO:root:Train (Epoch 40): Loss/seq after 00700 batchs: 1259.3568115234375
INFO:root:Train (Epoch 40): Loss/seq after 00750 batchs: 1290.6968994140625
INFO:root:Train (Epoch 40): Loss/seq after 00800 batchs: 1287.261474609375
INFO:root:Train (Epoch 40): Loss/seq after 00850 batchs: 1263.5755615234375
INFO:root:Train (Epoch 40): Loss/seq after 00900 batchs: 1272.99169921875
INFO:root:Train (Epoch 40): Loss/seq after 00950 batchs: 1302.5367431640625
INFO:root:Train (Epoch 40): Loss/seq after 01000 batchs: 1295.030517578125
INFO:root:Train (Epoch 40): Loss/seq after 01050 batchs: 1274.4139404296875
INFO:root:Train (Epoch 40): Loss/seq after 01100 batchs: 1271.6458740234375
INFO:root:Train (Epoch 40): Loss/seq after 01150 batchs: 1257.3934326171875
INFO:root:Train (Epoch 40): Loss/seq after 01200 batchs: 1248.15185546875
INFO:root:Train (Epoch 40): Loss/seq after 01250 batchs: 1239.9287109375
INFO:root:Train (Epoch 40): Loss/seq after 01300 batchs: 1239.2681884765625
INFO:root:Train (Epoch 40): Loss/seq after 01350 batchs: 1240.79248046875
INFO:root:Train (Epoch 40): Loss/seq after 01400 batchs: 1254.7899169921875
INFO:root:Train (Epoch 40): Loss/seq after 01450 batchs: 1247.3695068359375
INFO:root:Train (Epoch 40): Loss/seq after 01500 batchs: 1240.546630859375
INFO:root:Train (Epoch 40): Loss/seq after 01550 batchs: 1240.56103515625
INFO:root:Train (Epoch 40): Loss/seq after 01600 batchs: 1226.7305908203125
INFO:root:Train (Epoch 40): Loss/seq after 01650 batchs: 1219.57666015625
INFO:root:Train (Epoch 40): Loss/seq after 01700 batchs: 1212.1248779296875
INFO:root:Train (Epoch 40): Loss/seq after 01750 batchs: 1203.17724609375
INFO:root:Train (Epoch 40): Loss/seq after 01800 batchs: 1191.8260498046875
INFO:root:Train (Epoch 40): Loss/seq after 01850 batchs: 1180.2830810546875
INFO:root:Train (Epoch 40): Loss/seq after 01900 batchs: 1180.5177001953125
INFO:root:Train (Epoch 40): Loss/seq after 01950 batchs: 1175.986572265625
INFO:root:Train (Epoch 40): Loss/seq after 02000 batchs: 1168.2313232421875
INFO:root:Train (Epoch 40): Loss/seq after 02050 batchs: 1161.704833984375
INFO:root:Train (Epoch 40): Loss/seq after 02100 batchs: 1152.142333984375
INFO:root:Train (Epoch 40): Loss/seq after 02150 batchs: 1143.2650146484375
INFO:root:Train (Epoch 40): Loss/seq after 02200 batchs: 1133.8822021484375
INFO:root:Train (Epoch 40): Loss/seq after 02250 batchs: 1135.0750732421875
INFO:root:Train (Epoch 40): Loss/seq after 02300 batchs: 1140.5740966796875
INFO:root:Train (Epoch 40): Loss/seq after 02350 batchs: 1132.3074951171875
INFO:root:Train (Epoch 40): Loss/seq after 02400 batchs: 1129.3740234375
INFO:root:Train (Epoch 40): Loss/seq after 02450 batchs: 1118.1444091796875
INFO:root:Train (Epoch 40): Loss/seq after 02500 batchs: 1102.98095703125
INFO:root:Train (Epoch 40): Loss/seq after 02550 batchs: 1092.7362060546875
INFO:root:Train (Epoch 40): Loss/seq after 02600 batchs: 1091.955322265625
INFO:root:Train (Epoch 40): Loss/seq after 02650 batchs: 1088.9710693359375
INFO:root:Train (Epoch 40): Loss/seq after 02700 batchs: 1085.6646728515625
INFO:root:Train (Epoch 40): Loss/seq after 02750 batchs: 1116.416259765625
INFO:root:Train (Epoch 40): Loss/seq after 02800 batchs: 1122.5301513671875
INFO:root:Train (Epoch 40): Loss/seq after 02850 batchs: 1119.3759765625
INFO:root:Train (Epoch 40): Loss/seq after 02900 batchs: 1117.3818359375
INFO:root:Train (Epoch 40): Loss/seq after 02950 batchs: 1110.5189208984375
INFO:root:Train (Epoch 40): Loss/seq after 03000 batchs: 1110.02197265625
INFO:root:Train (Epoch 40): Loss/seq after 03050 batchs: 1113.82421875
INFO:root:Train (Epoch 40): Loss/seq after 03100 batchs: 1123.06005859375
INFO:root:Train (Epoch 40): Loss/seq after 03150 batchs: 1128.5604248046875
INFO:root:Train (Epoch 40): Loss/seq after 03200 batchs: 1132.468017578125
INFO:root:Train (Epoch 40): Loss/seq after 03250 batchs: 1134.428466796875
INFO:root:Train (Epoch 40): Loss/seq after 03300 batchs: 1133.9205322265625
INFO:root:Train (Epoch 40): Loss/seq after 03350 batchs: 1134.7896728515625
INFO:root:Train (Epoch 40): Loss/seq after 03400 batchs: 1127.7471923828125
INFO:root:Train (Epoch 40): Loss/seq after 03450 batchs: 1122.8416748046875
INFO:root:Train (Epoch 40): Loss/seq after 03500 batchs: 1123.1915283203125
INFO:root:Train (Epoch 40): Loss/seq after 03550 batchs: 1117.8426513671875
INFO:root:Train (Epoch 40): Loss/seq after 03600 batchs: 1124.49609375
INFO:root:Train (Epoch 40): Loss/seq after 03650 batchs: 1119.4888916015625
INFO:root:Train (Epoch 40): Loss/seq after 03700 batchs: 1119.7696533203125
INFO:root:Train (Epoch 40): Loss/seq after 03750 batchs: 1120.969482421875
INFO:root:Train (Epoch 40): Loss/seq after 03800 batchs: 1115.1431884765625
INFO:root:Train (Epoch 40): Loss/seq after 03850 batchs: 1111.74755859375
INFO:root:Train (Epoch 40): Loss/seq after 03900 batchs: 1116.056396484375
INFO:root:Train (Epoch 40): Loss/seq after 03950 batchs: 1119.7105712890625
INFO:root:Train (Epoch 40): Loss/seq after 04000 batchs: 1112.00146484375
INFO:root:Train (Epoch 40): Loss/seq after 04050 batchs: 1105.2919921875
INFO:root:Train (Epoch 40): Loss/seq after 04100 batchs: 1100.40087890625
INFO:root:Train (Epoch 40): Loss/seq after 04150 batchs: 1095.6595458984375
INFO:root:Train (Epoch 40): Loss/seq after 04200 batchs: 1091.13720703125
INFO:root:Train (Epoch 40): Loss/seq after 04250 batchs: 1087.7093505859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 40): Loss/seq after 00000 batches: 881.2719116210938
INFO:root:# Valid (Epoch 40): Loss/seq after 00050 batches: 1089.5390625
INFO:root:# Valid (Epoch 40): Loss/seq after 00100 batches: 1389.8489990234375
INFO:root:# Valid (Epoch 40): Loss/seq after 00150 batches: 1109.9635009765625
INFO:root:# Valid (Epoch 40): Loss/seq after 00200 batches: 999.211181640625
INFO:root:Artifacts: Make stick videos for epoch 40
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_40_on_20220413_182227.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_40_index_717_on_20220413_182227.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 41): Loss/seq after 00000 batchs: 1752.9185791015625
INFO:root:Train (Epoch 41): Loss/seq after 00050 batchs: 1430.40869140625
INFO:root:Train (Epoch 41): Loss/seq after 00100 batchs: 1404.2628173828125
INFO:root:Train (Epoch 41): Loss/seq after 00150 batchs: 1276.0960693359375
INFO:root:Train (Epoch 41): Loss/seq after 00200 batchs: 1372.574462890625
INFO:root:Train (Epoch 41): Loss/seq after 00250 batchs: 1512.3089599609375
INFO:root:Train (Epoch 41): Loss/seq after 00300 batchs: 1442.8709716796875
INFO:root:Train (Epoch 41): Loss/seq after 00350 batchs: 1351.449462890625
INFO:root:Train (Epoch 41): Loss/seq after 00400 batchs: 1379.05615234375
INFO:root:Train (Epoch 41): Loss/seq after 00450 batchs: 1323.517578125
INFO:root:Train (Epoch 41): Loss/seq after 00500 batchs: 1333.0262451171875
INFO:root:Train (Epoch 41): Loss/seq after 00550 batchs: 1280.512451171875
INFO:root:Train (Epoch 41): Loss/seq after 00600 batchs: 1245.830322265625
INFO:root:Train (Epoch 41): Loss/seq after 00650 batchs: 1250.664794921875
INFO:root:Train (Epoch 41): Loss/seq after 00700 batchs: 1236.166015625
INFO:root:Train (Epoch 41): Loss/seq after 00750 batchs: 1266.85986328125
INFO:root:Train (Epoch 41): Loss/seq after 00800 batchs: 1262.9061279296875
INFO:root:Train (Epoch 41): Loss/seq after 00850 batchs: 1239.4735107421875
INFO:root:Train (Epoch 41): Loss/seq after 00900 batchs: 1249.426513671875
INFO:root:Train (Epoch 41): Loss/seq after 00950 batchs: 1276.5643310546875
INFO:root:Train (Epoch 41): Loss/seq after 01000 batchs: 1266.8887939453125
INFO:root:Train (Epoch 41): Loss/seq after 01050 batchs: 1247.0784912109375
INFO:root:Train (Epoch 41): Loss/seq after 01100 batchs: 1247.4337158203125
INFO:root:Train (Epoch 41): Loss/seq after 01150 batchs: 1234.4586181640625
INFO:root:Train (Epoch 41): Loss/seq after 01200 batchs: 1226.321533203125
INFO:root:Train (Epoch 41): Loss/seq after 01250 batchs: 1218.715576171875
INFO:root:Train (Epoch 41): Loss/seq after 01300 batchs: 1219.98779296875
INFO:root:Train (Epoch 41): Loss/seq after 01350 batchs: 1220.326416015625
INFO:root:Train (Epoch 41): Loss/seq after 01400 batchs: 1233.9505615234375
INFO:root:Train (Epoch 41): Loss/seq after 01450 batchs: 1226.751220703125
INFO:root:Train (Epoch 41): Loss/seq after 01500 batchs: 1220.6695556640625
INFO:root:Train (Epoch 41): Loss/seq after 01550 batchs: 1221.925537109375
INFO:root:Train (Epoch 41): Loss/seq after 01600 batchs: 1208.2437744140625
INFO:root:Train (Epoch 41): Loss/seq after 01650 batchs: 1201.5140380859375
INFO:root:Train (Epoch 41): Loss/seq after 01700 batchs: 1194.778076171875
INFO:root:Train (Epoch 41): Loss/seq after 01750 batchs: 1186.2974853515625
INFO:root:Train (Epoch 41): Loss/seq after 01800 batchs: 1175.356201171875
INFO:root:Train (Epoch 41): Loss/seq after 01850 batchs: 1164.321533203125
INFO:root:Train (Epoch 41): Loss/seq after 01900 batchs: 1164.740966796875
INFO:root:Train (Epoch 41): Loss/seq after 01950 batchs: 1160.1722412109375
INFO:root:Train (Epoch 41): Loss/seq after 02000 batchs: 1152.786865234375
INFO:root:Train (Epoch 41): Loss/seq after 02050 batchs: 1146.5660400390625
INFO:root:Train (Epoch 41): Loss/seq after 02100 batchs: 1137.267822265625
INFO:root:Train (Epoch 41): Loss/seq after 02150 batchs: 1128.6226806640625
INFO:root:Train (Epoch 41): Loss/seq after 02200 batchs: 1119.5521240234375
INFO:root:Train (Epoch 41): Loss/seq after 02250 batchs: 1120.5970458984375
INFO:root:Train (Epoch 41): Loss/seq after 02300 batchs: 1126.0379638671875
INFO:root:Train (Epoch 41): Loss/seq after 02350 batchs: 1117.9254150390625
INFO:root:Train (Epoch 41): Loss/seq after 02400 batchs: 1115.1270751953125
INFO:root:Train (Epoch 41): Loss/seq after 02450 batchs: 1104.0771484375
INFO:root:Train (Epoch 41): Loss/seq after 02500 batchs: 1089.181396484375
INFO:root:Train (Epoch 41): Loss/seq after 02550 batchs: 1079.047607421875
INFO:root:Train (Epoch 41): Loss/seq after 02600 batchs: 1077.95849609375
INFO:root:Train (Epoch 41): Loss/seq after 02650 batchs: 1075.02880859375
INFO:root:Train (Epoch 41): Loss/seq after 02700 batchs: 1071.6356201171875
INFO:root:Train (Epoch 41): Loss/seq after 02750 batchs: 1101.983154296875
INFO:root:Train (Epoch 41): Loss/seq after 02800 batchs: 1107.3861083984375
INFO:root:Train (Epoch 41): Loss/seq after 02850 batchs: 1104.1724853515625
INFO:root:Train (Epoch 41): Loss/seq after 02900 batchs: 1102.8865966796875
INFO:root:Train (Epoch 41): Loss/seq after 02950 batchs: 1096.2208251953125
INFO:root:Train (Epoch 41): Loss/seq after 03000 batchs: 1095.938232421875
INFO:root:Train (Epoch 41): Loss/seq after 03050 batchs: 1099.9404296875
INFO:root:Train (Epoch 41): Loss/seq after 03100 batchs: 1109.3924560546875
INFO:root:Train (Epoch 41): Loss/seq after 03150 batchs: 1114.9840087890625
INFO:root:Train (Epoch 41): Loss/seq after 03200 batchs: 1119.945556640625
INFO:root:Train (Epoch 41): Loss/seq after 03250 batchs: 1121.6884765625
INFO:root:Train (Epoch 41): Loss/seq after 03300 batchs: 1121.399169921875
INFO:root:Train (Epoch 41): Loss/seq after 03350 batchs: 1123.1971435546875
INFO:root:Train (Epoch 41): Loss/seq after 03400 batchs: 1116.2911376953125
INFO:root:Train (Epoch 41): Loss/seq after 03450 batchs: 1111.66064453125
INFO:root:Train (Epoch 41): Loss/seq after 03500 batchs: 1111.9920654296875
INFO:root:Train (Epoch 41): Loss/seq after 03550 batchs: 1106.847900390625
INFO:root:Train (Epoch 41): Loss/seq after 03600 batchs: 1113.661865234375
INFO:root:Train (Epoch 41): Loss/seq after 03650 batchs: 1108.763916015625
INFO:root:Train (Epoch 41): Loss/seq after 03700 batchs: 1109.306884765625
INFO:root:Train (Epoch 41): Loss/seq after 03750 batchs: 1110.6224365234375
INFO:root:Train (Epoch 41): Loss/seq after 03800 batchs: 1104.9129638671875
INFO:root:Train (Epoch 41): Loss/seq after 03850 batchs: 1101.656005859375
INFO:root:Train (Epoch 41): Loss/seq after 03900 batchs: 1106.4501953125
INFO:root:Train (Epoch 41): Loss/seq after 03950 batchs: 1109.630126953125
INFO:root:Train (Epoch 41): Loss/seq after 04000 batchs: 1102.0634765625
INFO:root:Train (Epoch 41): Loss/seq after 04050 batchs: 1095.4716796875
INFO:root:Train (Epoch 41): Loss/seq after 04100 batchs: 1090.9140625
INFO:root:Train (Epoch 41): Loss/seq after 04150 batchs: 1086.55078125
INFO:root:Train (Epoch 41): Loss/seq after 04200 batchs: 1082.31201171875
INFO:root:Train (Epoch 41): Loss/seq after 04250 batchs: 1079.0965576171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 41): Loss/seq after 00000 batches: 897.14404296875
INFO:root:# Valid (Epoch 41): Loss/seq after 00050 batches: 1122.8912353515625
INFO:root:# Valid (Epoch 41): Loss/seq after 00100 batches: 1424.4735107421875
INFO:root:# Valid (Epoch 41): Loss/seq after 00150 batches: 1145.9609375
INFO:root:# Valid (Epoch 41): Loss/seq after 00200 batches: 1031.137451171875
INFO:root:Artifacts: Make stick videos for epoch 41
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_41_on_20220413_182744.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_41_index_671_on_20220413_182744.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 42): Loss/seq after 00000 batchs: 1476.9290771484375
INFO:root:Train (Epoch 42): Loss/seq after 00050 batchs: 1401.415283203125
INFO:root:Train (Epoch 42): Loss/seq after 00100 batchs: 1410.64306640625
INFO:root:Train (Epoch 42): Loss/seq after 00150 batchs: 1264.9805908203125
INFO:root:Train (Epoch 42): Loss/seq after 00200 batchs: 1353.2879638671875
INFO:root:Train (Epoch 42): Loss/seq after 00250 batchs: 1487.8292236328125
INFO:root:Train (Epoch 42): Loss/seq after 00300 batchs: 1422.2445068359375
INFO:root:Train (Epoch 42): Loss/seq after 00350 batchs: 1329.9100341796875
INFO:root:Train (Epoch 42): Loss/seq after 00400 batchs: 1358.31787109375
INFO:root:Train (Epoch 42): Loss/seq after 00450 batchs: 1304.71533203125
INFO:root:Train (Epoch 42): Loss/seq after 00500 batchs: 1316.455078125
INFO:root:Train (Epoch 42): Loss/seq after 00550 batchs: 1264.263427734375
INFO:root:Train (Epoch 42): Loss/seq after 00600 batchs: 1233.151611328125
INFO:root:Train (Epoch 42): Loss/seq after 00650 batchs: 1241.0264892578125
INFO:root:Train (Epoch 42): Loss/seq after 00700 batchs: 1222.375
INFO:root:Train (Epoch 42): Loss/seq after 00750 batchs: 1253.6866455078125
INFO:root:Train (Epoch 42): Loss/seq after 00800 batchs: 1250.6201171875
INFO:root:Train (Epoch 42): Loss/seq after 00850 batchs: 1227.62744140625
INFO:root:Train (Epoch 42): Loss/seq after 00900 batchs: 1238.561767578125
INFO:root:Train (Epoch 42): Loss/seq after 00950 batchs: 1259.0284423828125
INFO:root:Train (Epoch 42): Loss/seq after 01000 batchs: 1252.791748046875
INFO:root:Train (Epoch 42): Loss/seq after 01050 batchs: 1232.902587890625
INFO:root:Train (Epoch 42): Loss/seq after 01100 batchs: 1231.478515625
INFO:root:Train (Epoch 42): Loss/seq after 01150 batchs: 1219.5810546875
INFO:root:Train (Epoch 42): Loss/seq after 01200 batchs: 1212.966796875
INFO:root:Train (Epoch 42): Loss/seq after 01250 batchs: 1207.4615478515625
INFO:root:Train (Epoch 42): Loss/seq after 01300 batchs: 1208.52734375
INFO:root:Train (Epoch 42): Loss/seq after 01350 batchs: 1210.6656494140625
INFO:root:Train (Epoch 42): Loss/seq after 01400 batchs: 1223.324462890625
INFO:root:Train (Epoch 42): Loss/seq after 01450 batchs: 1217.0484619140625
INFO:root:Train (Epoch 42): Loss/seq after 01500 batchs: 1211.5020751953125
INFO:root:Train (Epoch 42): Loss/seq after 01550 batchs: 1213.048095703125
INFO:root:Train (Epoch 42): Loss/seq after 01600 batchs: 1199.351806640625
INFO:root:Train (Epoch 42): Loss/seq after 01650 batchs: 1192.623779296875
INFO:root:Train (Epoch 42): Loss/seq after 01700 batchs: 1186.572509765625
INFO:root:Train (Epoch 42): Loss/seq after 01750 batchs: 1178.6275634765625
INFO:root:Train (Epoch 42): Loss/seq after 01800 batchs: 1168.052490234375
INFO:root:Train (Epoch 42): Loss/seq after 01850 batchs: 1157.141357421875
INFO:root:Train (Epoch 42): Loss/seq after 01900 batchs: 1157.994140625
INFO:root:Train (Epoch 42): Loss/seq after 01950 batchs: 1153.77783203125
INFO:root:Train (Epoch 42): Loss/seq after 02000 batchs: 1146.587158203125
INFO:root:Train (Epoch 42): Loss/seq after 02050 batchs: 1140.4425048828125
INFO:root:Train (Epoch 42): Loss/seq after 02100 batchs: 1131.2138671875
INFO:root:Train (Epoch 42): Loss/seq after 02150 batchs: 1122.669189453125
INFO:root:Train (Epoch 42): Loss/seq after 02200 batchs: 1113.7244873046875
INFO:root:Train (Epoch 42): Loss/seq after 02250 batchs: 1114.7864990234375
INFO:root:Train (Epoch 42): Loss/seq after 02300 batchs: 1120.3619384765625
INFO:root:Train (Epoch 42): Loss/seq after 02350 batchs: 1112.2635498046875
INFO:root:Train (Epoch 42): Loss/seq after 02400 batchs: 1109.552978515625
INFO:root:Train (Epoch 42): Loss/seq after 02450 batchs: 1098.7093505859375
INFO:root:Train (Epoch 42): Loss/seq after 02500 batchs: 1083.9521484375
INFO:root:Train (Epoch 42): Loss/seq after 02550 batchs: 1073.9130859375
INFO:root:Train (Epoch 42): Loss/seq after 02600 batchs: 1072.926025390625
INFO:root:Train (Epoch 42): Loss/seq after 02650 batchs: 1070.037353515625
INFO:root:Train (Epoch 42): Loss/seq after 02700 batchs: 1066.7767333984375
INFO:root:Train (Epoch 42): Loss/seq after 02750 batchs: 1097.7791748046875
INFO:root:Train (Epoch 42): Loss/seq after 02800 batchs: 1103.39990234375
INFO:root:Train (Epoch 42): Loss/seq after 02850 batchs: 1100.5576171875
INFO:root:Train (Epoch 42): Loss/seq after 02900 batchs: 1100.4390869140625
INFO:root:Train (Epoch 42): Loss/seq after 02950 batchs: 1093.893798828125
INFO:root:Train (Epoch 42): Loss/seq after 03000 batchs: 1093.6822509765625
INFO:root:Train (Epoch 42): Loss/seq after 03050 batchs: 1097.7275390625
INFO:root:Train (Epoch 42): Loss/seq after 03100 batchs: 1106.3778076171875
INFO:root:Train (Epoch 42): Loss/seq after 03150 batchs: 1111.2581787109375
INFO:root:Train (Epoch 42): Loss/seq after 03200 batchs: 1115.6341552734375
INFO:root:Train (Epoch 42): Loss/seq after 03250 batchs: 1117.734619140625
INFO:root:Train (Epoch 42): Loss/seq after 03300 batchs: 1116.57763671875
INFO:root:Train (Epoch 42): Loss/seq after 03350 batchs: 1116.6700439453125
INFO:root:Train (Epoch 42): Loss/seq after 03400 batchs: 1109.799560546875
INFO:root:Train (Epoch 42): Loss/seq after 03450 batchs: 1104.15771484375
INFO:root:Train (Epoch 42): Loss/seq after 03500 batchs: 1103.609130859375
INFO:root:Train (Epoch 42): Loss/seq after 03550 batchs: 1098.1737060546875
INFO:root:Train (Epoch 42): Loss/seq after 03600 batchs: 1104.905029296875
INFO:root:Train (Epoch 42): Loss/seq after 03650 batchs: 1100.2794189453125
INFO:root:Train (Epoch 42): Loss/seq after 03700 batchs: 1100.8170166015625
INFO:root:Train (Epoch 42): Loss/seq after 03750 batchs: 1102.2625732421875
INFO:root:Train (Epoch 42): Loss/seq after 03800 batchs: 1096.70703125
INFO:root:Train (Epoch 42): Loss/seq after 03850 batchs: 1093.6927490234375
INFO:root:Train (Epoch 42): Loss/seq after 03900 batchs: 1099.391845703125
INFO:root:Train (Epoch 42): Loss/seq after 03950 batchs: 1103.1712646484375
INFO:root:Train (Epoch 42): Loss/seq after 04000 batchs: 1095.6783447265625
INFO:root:Train (Epoch 42): Loss/seq after 04050 batchs: 1089.1719970703125
INFO:root:Train (Epoch 42): Loss/seq after 04100 batchs: 1084.414794921875
INFO:root:Train (Epoch 42): Loss/seq after 04150 batchs: 1079.921630859375
INFO:root:Train (Epoch 42): Loss/seq after 04200 batchs: 1076.06689453125
INFO:root:Train (Epoch 42): Loss/seq after 04250 batchs: 1072.98681640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 42): Loss/seq after 00000 batches: 898.3037719726562
INFO:root:# Valid (Epoch 42): Loss/seq after 00050 batches: 1111.3411865234375
INFO:root:# Valid (Epoch 42): Loss/seq after 00100 batches: 1401.4210205078125
INFO:root:# Valid (Epoch 42): Loss/seq after 00150 batches: 1115.365234375
INFO:root:# Valid (Epoch 42): Loss/seq after 00200 batches: 1002.2271728515625
INFO:root:Artifacts: Make stick videos for epoch 42
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_42_on_20220413_183302.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_42_index_996_on_20220413_183302.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 43): Loss/seq after 00000 batchs: 1416.7784423828125
INFO:root:Train (Epoch 43): Loss/seq after 00050 batchs: 1416.4957275390625
INFO:root:Train (Epoch 43): Loss/seq after 00100 batchs: 1396.8623046875
INFO:root:Train (Epoch 43): Loss/seq after 00150 batchs: 1272.3616943359375
INFO:root:Train (Epoch 43): Loss/seq after 00200 batchs: 1363.1944580078125
INFO:root:Train (Epoch 43): Loss/seq after 00250 batchs: 1498.6470947265625
INFO:root:Train (Epoch 43): Loss/seq after 00300 batchs: 1432.0660400390625
INFO:root:Train (Epoch 43): Loss/seq after 00350 batchs: 1339.82958984375
INFO:root:Train (Epoch 43): Loss/seq after 00400 batchs: 1363.4427490234375
INFO:root:Train (Epoch 43): Loss/seq after 00450 batchs: 1309.049560546875
INFO:root:Train (Epoch 43): Loss/seq after 00500 batchs: 1320.9195556640625
INFO:root:Train (Epoch 43): Loss/seq after 00550 batchs: 1269.0299072265625
INFO:root:Train (Epoch 43): Loss/seq after 00600 batchs: 1236.7802734375
INFO:root:Train (Epoch 43): Loss/seq after 00650 batchs: 1237.2491455078125
INFO:root:Train (Epoch 43): Loss/seq after 00700 batchs: 1214.710693359375
INFO:root:Train (Epoch 43): Loss/seq after 00750 batchs: 1249.0648193359375
INFO:root:Train (Epoch 43): Loss/seq after 00800 batchs: 1245.704833984375
INFO:root:Train (Epoch 43): Loss/seq after 00850 batchs: 1224.728271484375
INFO:root:Train (Epoch 43): Loss/seq after 00900 batchs: 1237.042724609375
INFO:root:Train (Epoch 43): Loss/seq after 00950 batchs: 1260.1890869140625
INFO:root:Train (Epoch 43): Loss/seq after 01000 batchs: 1252.32080078125
INFO:root:Train (Epoch 43): Loss/seq after 01050 batchs: 1234.326171875
INFO:root:Train (Epoch 43): Loss/seq after 01100 batchs: 1232.89599609375
INFO:root:Train (Epoch 43): Loss/seq after 01150 batchs: 1220.2689208984375
INFO:root:Train (Epoch 43): Loss/seq after 01200 batchs: 1212.854248046875
INFO:root:Train (Epoch 43): Loss/seq after 01250 batchs: 1206.0115966796875
INFO:root:Train (Epoch 43): Loss/seq after 01300 batchs: 1204.302001953125
INFO:root:Train (Epoch 43): Loss/seq after 01350 batchs: 1205.80615234375
INFO:root:Train (Epoch 43): Loss/seq after 01400 batchs: 1220.0712890625
INFO:root:Train (Epoch 43): Loss/seq after 01450 batchs: 1213.5787353515625
INFO:root:Train (Epoch 43): Loss/seq after 01500 batchs: 1207.9461669921875
INFO:root:Train (Epoch 43): Loss/seq after 01550 batchs: 1209.643310546875
INFO:root:Train (Epoch 43): Loss/seq after 01600 batchs: 1195.91015625
INFO:root:Train (Epoch 43): Loss/seq after 01650 batchs: 1188.7103271484375
INFO:root:Train (Epoch 43): Loss/seq after 01700 batchs: 1181.9752197265625
INFO:root:Train (Epoch 43): Loss/seq after 01750 batchs: 1173.6190185546875
INFO:root:Train (Epoch 43): Loss/seq after 01800 batchs: 1162.583251953125
INFO:root:Train (Epoch 43): Loss/seq after 01850 batchs: 1151.6466064453125
INFO:root:Train (Epoch 43): Loss/seq after 01900 batchs: 1152.160888671875
INFO:root:Train (Epoch 43): Loss/seq after 01950 batchs: 1147.78076171875
INFO:root:Train (Epoch 43): Loss/seq after 02000 batchs: 1140.74267578125
INFO:root:Train (Epoch 43): Loss/seq after 02050 batchs: 1134.6497802734375
INFO:root:Train (Epoch 43): Loss/seq after 02100 batchs: 1125.5771484375
INFO:root:Train (Epoch 43): Loss/seq after 02150 batchs: 1117.1036376953125
INFO:root:Train (Epoch 43): Loss/seq after 02200 batchs: 1108.2562255859375
INFO:root:Train (Epoch 43): Loss/seq after 02250 batchs: 1109.627685546875
INFO:root:Train (Epoch 43): Loss/seq after 02300 batchs: 1115.048828125
INFO:root:Train (Epoch 43): Loss/seq after 02350 batchs: 1107.2242431640625
INFO:root:Train (Epoch 43): Loss/seq after 02400 batchs: 1104.7459716796875
INFO:root:Train (Epoch 43): Loss/seq after 02450 batchs: 1093.8734130859375
INFO:root:Train (Epoch 43): Loss/seq after 02500 batchs: 1079.206787109375
INFO:root:Train (Epoch 43): Loss/seq after 02550 batchs: 1069.196044921875
INFO:root:Train (Epoch 43): Loss/seq after 02600 batchs: 1068.4935302734375
INFO:root:Train (Epoch 43): Loss/seq after 02650 batchs: 1065.7601318359375
INFO:root:Train (Epoch 43): Loss/seq after 02700 batchs: 1062.4844970703125
INFO:root:Train (Epoch 43): Loss/seq after 02750 batchs: 1092.962646484375
INFO:root:Train (Epoch 43): Loss/seq after 02800 batchs: 1098.0213623046875
INFO:root:Train (Epoch 43): Loss/seq after 02850 batchs: 1094.947998046875
INFO:root:Train (Epoch 43): Loss/seq after 02900 batchs: 1093.3753662109375
INFO:root:Train (Epoch 43): Loss/seq after 02950 batchs: 1086.7054443359375
INFO:root:Train (Epoch 43): Loss/seq after 03000 batchs: 1086.574462890625
INFO:root:Train (Epoch 43): Loss/seq after 03050 batchs: 1090.712890625
INFO:root:Train (Epoch 43): Loss/seq after 03100 batchs: 1099.0811767578125
INFO:root:Train (Epoch 43): Loss/seq after 03150 batchs: 1102.887451171875
INFO:root:Train (Epoch 43): Loss/seq after 03200 batchs: 1108.029296875
INFO:root:Train (Epoch 43): Loss/seq after 03250 batchs: 1109.997802734375
INFO:root:Train (Epoch 43): Loss/seq after 03300 batchs: 1108.8453369140625
INFO:root:Train (Epoch 43): Loss/seq after 03350 batchs: 1108.7178955078125
INFO:root:Train (Epoch 43): Loss/seq after 03400 batchs: 1102.0169677734375
INFO:root:Train (Epoch 43): Loss/seq after 03450 batchs: 1097.2823486328125
INFO:root:Train (Epoch 43): Loss/seq after 03500 batchs: 1097.120849609375
INFO:root:Train (Epoch 43): Loss/seq after 03550 batchs: 1091.6275634765625
INFO:root:Train (Epoch 43): Loss/seq after 03600 batchs: 1098.5584716796875
INFO:root:Train (Epoch 43): Loss/seq after 03650 batchs: 1093.82958984375
INFO:root:Train (Epoch 43): Loss/seq after 03700 batchs: 1094.2247314453125
INFO:root:Train (Epoch 43): Loss/seq after 03750 batchs: 1095.75048828125
INFO:root:Train (Epoch 43): Loss/seq after 03800 batchs: 1090.2174072265625
INFO:root:Train (Epoch 43): Loss/seq after 03850 batchs: 1087.2021484375
INFO:root:Train (Epoch 43): Loss/seq after 03900 batchs: 1092.0235595703125
INFO:root:Train (Epoch 43): Loss/seq after 03950 batchs: 1095.356201171875
INFO:root:Train (Epoch 43): Loss/seq after 04000 batchs: 1087.9385986328125
INFO:root:Train (Epoch 43): Loss/seq after 04050 batchs: 1081.5343017578125
INFO:root:Train (Epoch 43): Loss/seq after 04100 batchs: 1076.5361328125
INFO:root:Train (Epoch 43): Loss/seq after 04150 batchs: 1072.0543212890625
INFO:root:Train (Epoch 43): Loss/seq after 04200 batchs: 1067.9517822265625
INFO:root:Train (Epoch 43): Loss/seq after 04250 batchs: 1064.9259033203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 43): Loss/seq after 00000 batches: 909.8313598632812
INFO:root:# Valid (Epoch 43): Loss/seq after 00050 batches: 1120.64697265625
INFO:root:# Valid (Epoch 43): Loss/seq after 00100 batches: 1406.5538330078125
INFO:root:# Valid (Epoch 43): Loss/seq after 00150 batches: 1128.9136962890625
INFO:root:# Valid (Epoch 43): Loss/seq after 00200 batches: 1018.3972778320312
INFO:root:Artifacts: Make stick videos for epoch 43
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_43_on_20220413_183819.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_43_index_827_on_20220413_183819.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 44): Loss/seq after 00000 batchs: 1532.50732421875
INFO:root:Train (Epoch 44): Loss/seq after 00050 batchs: 1355.490234375
INFO:root:Train (Epoch 44): Loss/seq after 00100 batchs: 1354.86181640625
INFO:root:Train (Epoch 44): Loss/seq after 00150 batchs: 1228.3697509765625
INFO:root:Train (Epoch 44): Loss/seq after 00200 batchs: 1321.177734375
INFO:root:Train (Epoch 44): Loss/seq after 00250 batchs: 1468.1357421875
INFO:root:Train (Epoch 44): Loss/seq after 00300 batchs: 1406.36083984375
INFO:root:Train (Epoch 44): Loss/seq after 00350 batchs: 1321.652587890625
INFO:root:Train (Epoch 44): Loss/seq after 00400 batchs: 1351.706298828125
INFO:root:Train (Epoch 44): Loss/seq after 00450 batchs: 1299.184326171875
INFO:root:Train (Epoch 44): Loss/seq after 00500 batchs: 1306.3643798828125
INFO:root:Train (Epoch 44): Loss/seq after 00550 batchs: 1255.4827880859375
INFO:root:Train (Epoch 44): Loss/seq after 00600 batchs: 1222.485595703125
INFO:root:Train (Epoch 44): Loss/seq after 00650 batchs: 1225.379150390625
INFO:root:Train (Epoch 44): Loss/seq after 00700 batchs: 1202.7537841796875
INFO:root:Train (Epoch 44): Loss/seq after 00750 batchs: 1230.978271484375
INFO:root:Train (Epoch 44): Loss/seq after 00800 batchs: 1228.0721435546875
INFO:root:Train (Epoch 44): Loss/seq after 00850 batchs: 1207.004638671875
INFO:root:Train (Epoch 44): Loss/seq after 00900 batchs: 1218.070556640625
INFO:root:Train (Epoch 44): Loss/seq after 00950 batchs: 1231.543701171875
INFO:root:Train (Epoch 44): Loss/seq after 01000 batchs: 1223.853515625
INFO:root:Train (Epoch 44): Loss/seq after 01050 batchs: 1205.3701171875
INFO:root:Train (Epoch 44): Loss/seq after 01100 batchs: 1203.7220458984375
INFO:root:Train (Epoch 44): Loss/seq after 01150 batchs: 1192.335693359375
INFO:root:Train (Epoch 44): Loss/seq after 01200 batchs: 1185.7279052734375
INFO:root:Train (Epoch 44): Loss/seq after 01250 batchs: 1178.6505126953125
INFO:root:Train (Epoch 44): Loss/seq after 01300 batchs: 1177.94677734375
INFO:root:Train (Epoch 44): Loss/seq after 01350 batchs: 1179.601318359375
INFO:root:Train (Epoch 44): Loss/seq after 01400 batchs: 1191.302490234375
INFO:root:Train (Epoch 44): Loss/seq after 01450 batchs: 1185.1319580078125
INFO:root:Train (Epoch 44): Loss/seq after 01500 batchs: 1180.303466796875
INFO:root:Train (Epoch 44): Loss/seq after 01550 batchs: 1182.60107421875
INFO:root:Train (Epoch 44): Loss/seq after 01600 batchs: 1169.57763671875
INFO:root:Train (Epoch 44): Loss/seq after 01650 batchs: 1162.238037109375
INFO:root:Train (Epoch 44): Loss/seq after 01700 batchs: 1156.384765625
INFO:root:Train (Epoch 44): Loss/seq after 01750 batchs: 1148.6011962890625
INFO:root:Train (Epoch 44): Loss/seq after 01800 batchs: 1138.263671875
INFO:root:Train (Epoch 44): Loss/seq after 01850 batchs: 1128.0142822265625
INFO:root:Train (Epoch 44): Loss/seq after 01900 batchs: 1128.82080078125
INFO:root:Train (Epoch 44): Loss/seq after 01950 batchs: 1124.7618408203125
INFO:root:Train (Epoch 44): Loss/seq after 02000 batchs: 1118.37109375
INFO:root:Train (Epoch 44): Loss/seq after 02050 batchs: 1112.79931640625
INFO:root:Train (Epoch 44): Loss/seq after 02100 batchs: 1104.15869140625
INFO:root:Train (Epoch 44): Loss/seq after 02150 batchs: 1096.16455078125
INFO:root:Train (Epoch 44): Loss/seq after 02200 batchs: 1087.8472900390625
INFO:root:Train (Epoch 44): Loss/seq after 02250 batchs: 1089.4996337890625
INFO:root:Train (Epoch 44): Loss/seq after 02300 batchs: 1095.0838623046875
INFO:root:Train (Epoch 44): Loss/seq after 02350 batchs: 1088.7254638671875
INFO:root:Train (Epoch 44): Loss/seq after 02400 batchs: 1086.86767578125
INFO:root:Train (Epoch 44): Loss/seq after 02450 batchs: 1076.7593994140625
INFO:root:Train (Epoch 44): Loss/seq after 02500 batchs: 1062.427978515625
INFO:root:Train (Epoch 44): Loss/seq after 02550 batchs: 1052.8956298828125
INFO:root:Train (Epoch 44): Loss/seq after 02600 batchs: 1052.2208251953125
INFO:root:Train (Epoch 44): Loss/seq after 02650 batchs: 1049.574951171875
INFO:root:Train (Epoch 44): Loss/seq after 02700 batchs: 1046.9189453125
INFO:root:Train (Epoch 44): Loss/seq after 02750 batchs: 1078.32373046875
INFO:root:Train (Epoch 44): Loss/seq after 02800 batchs: 1083.8594970703125
INFO:root:Train (Epoch 44): Loss/seq after 02850 batchs: 1080.9267578125
INFO:root:Train (Epoch 44): Loss/seq after 02900 batchs: 1079.9228515625
INFO:root:Train (Epoch 44): Loss/seq after 02950 batchs: 1073.6087646484375
INFO:root:Train (Epoch 44): Loss/seq after 03000 batchs: 1073.7333984375
INFO:root:Train (Epoch 44): Loss/seq after 03050 batchs: 1078.08544921875
INFO:root:Train (Epoch 44): Loss/seq after 03100 batchs: 1086.802490234375
INFO:root:Train (Epoch 44): Loss/seq after 03150 batchs: 1091.7344970703125
INFO:root:Train (Epoch 44): Loss/seq after 03200 batchs: 1095.919677734375
INFO:root:Train (Epoch 44): Loss/seq after 03250 batchs: 1097.51953125
INFO:root:Train (Epoch 44): Loss/seq after 03300 batchs: 1097.172119140625
INFO:root:Train (Epoch 44): Loss/seq after 03350 batchs: 1098.686279296875
INFO:root:Train (Epoch 44): Loss/seq after 03400 batchs: 1092.1116943359375
INFO:root:Train (Epoch 44): Loss/seq after 03450 batchs: 1087.33056640625
INFO:root:Train (Epoch 44): Loss/seq after 03500 batchs: 1087.5634765625
INFO:root:Train (Epoch 44): Loss/seq after 03550 batchs: 1082.6888427734375
INFO:root:Train (Epoch 44): Loss/seq after 03600 batchs: 1089.6600341796875
INFO:root:Train (Epoch 44): Loss/seq after 03650 batchs: 1085.2147216796875
INFO:root:Train (Epoch 44): Loss/seq after 03700 batchs: 1085.7479248046875
INFO:root:Train (Epoch 44): Loss/seq after 03750 batchs: 1087.3463134765625
INFO:root:Train (Epoch 44): Loss/seq after 03800 batchs: 1081.8939208984375
INFO:root:Train (Epoch 44): Loss/seq after 03850 batchs: 1078.825439453125
INFO:root:Train (Epoch 44): Loss/seq after 03900 batchs: 1082.978515625
INFO:root:Train (Epoch 44): Loss/seq after 03950 batchs: 1086.13671875
INFO:root:Train (Epoch 44): Loss/seq after 04000 batchs: 1078.84228515625
INFO:root:Train (Epoch 44): Loss/seq after 04050 batchs: 1072.516357421875
INFO:root:Train (Epoch 44): Loss/seq after 04100 batchs: 1067.71240234375
INFO:root:Train (Epoch 44): Loss/seq after 04150 batchs: 1063.4779052734375
INFO:root:Train (Epoch 44): Loss/seq after 04200 batchs: 1059.482177734375
INFO:root:Train (Epoch 44): Loss/seq after 04250 batchs: 1056.4071044921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 44): Loss/seq after 00000 batches: 914.0540161132812
INFO:root:# Valid (Epoch 44): Loss/seq after 00050 batches: 1110.1751708984375
INFO:root:# Valid (Epoch 44): Loss/seq after 00100 batches: 1405.5596923828125
INFO:root:# Valid (Epoch 44): Loss/seq after 00150 batches: 1119.789794921875
INFO:root:# Valid (Epoch 44): Loss/seq after 00200 batches: 1005.9795532226562
INFO:root:Artifacts: Make stick videos for epoch 44
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_44_on_20220413_184336.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_44_index_1276_on_20220413_184336.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 45): Loss/seq after 00000 batchs: 1590.6693115234375
INFO:root:Train (Epoch 45): Loss/seq after 00050 batchs: 1350.413818359375
INFO:root:Train (Epoch 45): Loss/seq after 00100 batchs: 1340.9149169921875
INFO:root:Train (Epoch 45): Loss/seq after 00150 batchs: 1213.1014404296875
INFO:root:Train (Epoch 45): Loss/seq after 00200 batchs: 1312.7930908203125
INFO:root:Train (Epoch 45): Loss/seq after 00250 batchs: 1459.6087646484375
INFO:root:Train (Epoch 45): Loss/seq after 00300 batchs: 1399.5404052734375
INFO:root:Train (Epoch 45): Loss/seq after 00350 batchs: 1310.8018798828125
INFO:root:Train (Epoch 45): Loss/seq after 00400 batchs: 1338.9886474609375
INFO:root:Train (Epoch 45): Loss/seq after 00450 batchs: 1287.556884765625
INFO:root:Train (Epoch 45): Loss/seq after 00500 batchs: 1296.4874267578125
INFO:root:Train (Epoch 45): Loss/seq after 00550 batchs: 1246.064453125
INFO:root:Train (Epoch 45): Loss/seq after 00600 batchs: 1214.6160888671875
INFO:root:Train (Epoch 45): Loss/seq after 00650 batchs: 1215.1805419921875
INFO:root:Train (Epoch 45): Loss/seq after 00700 batchs: 1191.1668701171875
INFO:root:Train (Epoch 45): Loss/seq after 00750 batchs: 1219.910888671875
INFO:root:Train (Epoch 45): Loss/seq after 00800 batchs: 1221.4112548828125
INFO:root:Train (Epoch 45): Loss/seq after 00850 batchs: 1200.3822021484375
INFO:root:Train (Epoch 45): Loss/seq after 00900 batchs: 1217.74169921875
INFO:root:Train (Epoch 45): Loss/seq after 00950 batchs: 1230.453857421875
INFO:root:Train (Epoch 45): Loss/seq after 01000 batchs: 1222.3199462890625
INFO:root:Train (Epoch 45): Loss/seq after 01050 batchs: 1205.0684814453125
INFO:root:Train (Epoch 45): Loss/seq after 01100 batchs: 1205.4765625
INFO:root:Train (Epoch 45): Loss/seq after 01150 batchs: 1194.7552490234375
INFO:root:Train (Epoch 45): Loss/seq after 01200 batchs: 1188.42578125
INFO:root:Train (Epoch 45): Loss/seq after 01250 batchs: 1182.436279296875
INFO:root:Train (Epoch 45): Loss/seq after 01300 batchs: 1181.1689453125
INFO:root:Train (Epoch 45): Loss/seq after 01350 batchs: 1183.0244140625
INFO:root:Train (Epoch 45): Loss/seq after 01400 batchs: 1194.5960693359375
INFO:root:Train (Epoch 45): Loss/seq after 01450 batchs: 1188.2972412109375
INFO:root:Train (Epoch 45): Loss/seq after 01500 batchs: 1183.3343505859375
INFO:root:Train (Epoch 45): Loss/seq after 01550 batchs: 1185.530517578125
INFO:root:Train (Epoch 45): Loss/seq after 01600 batchs: 1172.5386962890625
INFO:root:Train (Epoch 45): Loss/seq after 01650 batchs: 1165.046630859375
INFO:root:Train (Epoch 45): Loss/seq after 01700 batchs: 1158.9052734375
INFO:root:Train (Epoch 45): Loss/seq after 01750 batchs: 1150.936767578125
INFO:root:Train (Epoch 45): Loss/seq after 01800 batchs: 1140.4302978515625
INFO:root:Train (Epoch 45): Loss/seq after 01850 batchs: 1129.9969482421875
INFO:root:Train (Epoch 45): Loss/seq after 01900 batchs: 1130.3974609375
INFO:root:Train (Epoch 45): Loss/seq after 01950 batchs: 1126.7286376953125
INFO:root:Train (Epoch 45): Loss/seq after 02000 batchs: 1120.143310546875
INFO:root:Train (Epoch 45): Loss/seq after 02050 batchs: 1114.4359130859375
INFO:root:Train (Epoch 45): Loss/seq after 02100 batchs: 1105.73974609375
INFO:root:Train (Epoch 45): Loss/seq after 02150 batchs: 1097.72119140625
INFO:root:Train (Epoch 45): Loss/seq after 02200 batchs: 1089.3096923828125
INFO:root:Train (Epoch 45): Loss/seq after 02250 batchs: 1092.0438232421875
INFO:root:Train (Epoch 45): Loss/seq after 02300 batchs: 1099.7120361328125
INFO:root:Train (Epoch 45): Loss/seq after 02350 batchs: 1093.47216796875
INFO:root:Train (Epoch 45): Loss/seq after 02400 batchs: 1091.577392578125
INFO:root:Train (Epoch 45): Loss/seq after 02450 batchs: 1081.5633544921875
INFO:root:Train (Epoch 45): Loss/seq after 02500 batchs: 1067.1634521484375
INFO:root:Train (Epoch 45): Loss/seq after 02550 batchs: 1058.3282470703125
INFO:root:Train (Epoch 45): Loss/seq after 02600 batchs: 1057.974853515625
INFO:root:Train (Epoch 45): Loss/seq after 02650 batchs: 1055.385986328125
INFO:root:Train (Epoch 45): Loss/seq after 02700 batchs: 1052.130859375
INFO:root:Train (Epoch 45): Loss/seq after 02750 batchs: 1082.7330322265625
INFO:root:Train (Epoch 45): Loss/seq after 02800 batchs: 1087.4012451171875
INFO:root:Train (Epoch 45): Loss/seq after 02850 batchs: 1084.3797607421875
INFO:root:Train (Epoch 45): Loss/seq after 02900 batchs: 1083.470947265625
INFO:root:Train (Epoch 45): Loss/seq after 02950 batchs: 1077.0418701171875
INFO:root:Train (Epoch 45): Loss/seq after 03000 batchs: 1077.1024169921875
INFO:root:Train (Epoch 45): Loss/seq after 03050 batchs: 1081.4573974609375
INFO:root:Train (Epoch 45): Loss/seq after 03100 batchs: 1090.6087646484375
INFO:root:Train (Epoch 45): Loss/seq after 03150 batchs: 1095.4456787109375
INFO:root:Train (Epoch 45): Loss/seq after 03200 batchs: 1099.4388427734375
INFO:root:Train (Epoch 45): Loss/seq after 03250 batchs: 1100.7545166015625
INFO:root:Train (Epoch 45): Loss/seq after 03300 batchs: 1099.5208740234375
INFO:root:Train (Epoch 45): Loss/seq after 03350 batchs: 1099.394287109375
INFO:root:Train (Epoch 45): Loss/seq after 03400 batchs: 1092.9417724609375
INFO:root:Train (Epoch 45): Loss/seq after 03450 batchs: 1087.8203125
INFO:root:Train (Epoch 45): Loss/seq after 03500 batchs: 1088.0753173828125
INFO:root:Train (Epoch 45): Loss/seq after 03550 batchs: 1082.728515625
INFO:root:Train (Epoch 45): Loss/seq after 03600 batchs: 1089.88330078125
INFO:root:Train (Epoch 45): Loss/seq after 03650 batchs: 1085.3214111328125
INFO:root:Train (Epoch 45): Loss/seq after 03700 batchs: 1085.7825927734375
INFO:root:Train (Epoch 45): Loss/seq after 03750 batchs: 1087.3409423828125
INFO:root:Train (Epoch 45): Loss/seq after 03800 batchs: 1081.8724365234375
INFO:root:Train (Epoch 45): Loss/seq after 03850 batchs: 1078.8204345703125
INFO:root:Train (Epoch 45): Loss/seq after 03900 batchs: 1082.8682861328125
INFO:root:Train (Epoch 45): Loss/seq after 03950 batchs: 1086.49658203125
INFO:root:Train (Epoch 45): Loss/seq after 04000 batchs: 1079.1878662109375
INFO:root:Train (Epoch 45): Loss/seq after 04050 batchs: 1072.8599853515625
INFO:root:Train (Epoch 45): Loss/seq after 04100 batchs: 1068.033935546875
INFO:root:Train (Epoch 45): Loss/seq after 04150 batchs: 1063.8154296875
INFO:root:Train (Epoch 45): Loss/seq after 04200 batchs: 1059.5904541015625
INFO:root:Train (Epoch 45): Loss/seq after 04250 batchs: 1056.4901123046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 45): Loss/seq after 00000 batches: 882.149658203125
INFO:root:# Valid (Epoch 45): Loss/seq after 00050 batches: 1117.8043212890625
INFO:root:# Valid (Epoch 45): Loss/seq after 00100 batches: 1411.2508544921875
INFO:root:# Valid (Epoch 45): Loss/seq after 00150 batches: 1127.3255615234375
INFO:root:# Valid (Epoch 45): Loss/seq after 00200 batches: 1014.8997192382812
INFO:root:Artifacts: Make stick videos for epoch 45
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_45_on_20220413_184855.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_45_index_1176_on_20220413_184855.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 46): Loss/seq after 00000 batchs: 1532.601806640625
INFO:root:Train (Epoch 46): Loss/seq after 00050 batchs: 1328.32373046875
INFO:root:Train (Epoch 46): Loss/seq after 00100 batchs: 1317.33154296875
INFO:root:Train (Epoch 46): Loss/seq after 00150 batchs: 1194.528564453125
INFO:root:Train (Epoch 46): Loss/seq after 00200 batchs: 1292.960205078125
INFO:root:Train (Epoch 46): Loss/seq after 00250 batchs: 1441.61181640625
INFO:root:Train (Epoch 46): Loss/seq after 00300 batchs: 1383.6947021484375
INFO:root:Train (Epoch 46): Loss/seq after 00350 batchs: 1297.0008544921875
INFO:root:Train (Epoch 46): Loss/seq after 00400 batchs: 1331.80224609375
INFO:root:Train (Epoch 46): Loss/seq after 00450 batchs: 1281.2294921875
INFO:root:Train (Epoch 46): Loss/seq after 00500 batchs: 1288.96142578125
INFO:root:Train (Epoch 46): Loss/seq after 00550 batchs: 1239.50146484375
INFO:root:Train (Epoch 46): Loss/seq after 00600 batchs: 1207.2689208984375
INFO:root:Train (Epoch 46): Loss/seq after 00650 batchs: 1209.203125
INFO:root:Train (Epoch 46): Loss/seq after 00700 batchs: 1185.549560546875
INFO:root:Train (Epoch 46): Loss/seq after 00750 batchs: 1214.967041015625
INFO:root:Train (Epoch 46): Loss/seq after 00800 batchs: 1218.77978515625
INFO:root:Train (Epoch 46): Loss/seq after 00850 batchs: 1200.0079345703125
INFO:root:Train (Epoch 46): Loss/seq after 00900 batchs: 1215.5020751953125
INFO:root:Train (Epoch 46): Loss/seq after 00950 batchs: 1231.47314453125
INFO:root:Train (Epoch 46): Loss/seq after 01000 batchs: 1224.4346923828125
INFO:root:Train (Epoch 46): Loss/seq after 01050 batchs: 1205.39599609375
INFO:root:Train (Epoch 46): Loss/seq after 01100 batchs: 1203.433349609375
INFO:root:Train (Epoch 46): Loss/seq after 01150 batchs: 1192.576171875
INFO:root:Train (Epoch 46): Loss/seq after 01200 batchs: 1186.4007568359375
INFO:root:Train (Epoch 46): Loss/seq after 01250 batchs: 1179.5733642578125
INFO:root:Train (Epoch 46): Loss/seq after 01300 batchs: 1177.7193603515625
INFO:root:Train (Epoch 46): Loss/seq after 01350 batchs: 1179.5804443359375
INFO:root:Train (Epoch 46): Loss/seq after 01400 batchs: 1190.6181640625
INFO:root:Train (Epoch 46): Loss/seq after 01450 batchs: 1184.52880859375
INFO:root:Train (Epoch 46): Loss/seq after 01500 batchs: 1179.7381591796875
INFO:root:Train (Epoch 46): Loss/seq after 01550 batchs: 1181.765625
INFO:root:Train (Epoch 46): Loss/seq after 01600 batchs: 1169.02392578125
INFO:root:Train (Epoch 46): Loss/seq after 01650 batchs: 1162.205078125
INFO:root:Train (Epoch 46): Loss/seq after 01700 batchs: 1156.9215087890625
INFO:root:Train (Epoch 46): Loss/seq after 01750 batchs: 1149.4759521484375
INFO:root:Train (Epoch 46): Loss/seq after 01800 batchs: 1139.4443359375
INFO:root:Train (Epoch 46): Loss/seq after 01850 batchs: 1129.22900390625
INFO:root:Train (Epoch 46): Loss/seq after 01900 batchs: 1129.6971435546875
INFO:root:Train (Epoch 46): Loss/seq after 01950 batchs: 1125.19287109375
INFO:root:Train (Epoch 46): Loss/seq after 02000 batchs: 1118.5902099609375
INFO:root:Train (Epoch 46): Loss/seq after 02050 batchs: 1113.25244140625
INFO:root:Train (Epoch 46): Loss/seq after 02100 batchs: 1104.611572265625
INFO:root:Train (Epoch 46): Loss/seq after 02150 batchs: 1096.6337890625
INFO:root:Train (Epoch 46): Loss/seq after 02200 batchs: 1088.1844482421875
INFO:root:Train (Epoch 46): Loss/seq after 02250 batchs: 1090.223876953125
INFO:root:Train (Epoch 46): Loss/seq after 02300 batchs: 1096.968994140625
INFO:root:Train (Epoch 46): Loss/seq after 02350 batchs: 1090.1842041015625
INFO:root:Train (Epoch 46): Loss/seq after 02400 batchs: 1087.96923828125
INFO:root:Train (Epoch 46): Loss/seq after 02450 batchs: 1077.5755615234375
INFO:root:Train (Epoch 46): Loss/seq after 02500 batchs: 1063.2154541015625
INFO:root:Train (Epoch 46): Loss/seq after 02550 batchs: 1053.923828125
INFO:root:Train (Epoch 46): Loss/seq after 02600 batchs: 1053.3785400390625
INFO:root:Train (Epoch 46): Loss/seq after 02650 batchs: 1050.838134765625
INFO:root:Train (Epoch 46): Loss/seq after 02700 batchs: 1047.8782958984375
INFO:root:Train (Epoch 46): Loss/seq after 02750 batchs: 1078.4771728515625
INFO:root:Train (Epoch 46): Loss/seq after 02800 batchs: 1083.5130615234375
INFO:root:Train (Epoch 46): Loss/seq after 02850 batchs: 1080.5699462890625
INFO:root:Train (Epoch 46): Loss/seq after 02900 batchs: 1079.3028564453125
INFO:root:Train (Epoch 46): Loss/seq after 02950 batchs: 1072.871337890625
INFO:root:Train (Epoch 46): Loss/seq after 03000 batchs: 1072.9954833984375
INFO:root:Train (Epoch 46): Loss/seq after 03050 batchs: 1077.235595703125
INFO:root:Train (Epoch 46): Loss/seq after 03100 batchs: 1085.8509521484375
INFO:root:Train (Epoch 46): Loss/seq after 03150 batchs: 1088.5992431640625
INFO:root:Train (Epoch 46): Loss/seq after 03200 batchs: 1092.9561767578125
INFO:root:Train (Epoch 46): Loss/seq after 03250 batchs: 1094.1859130859375
INFO:root:Train (Epoch 46): Loss/seq after 03300 batchs: 1093.0386962890625
INFO:root:Train (Epoch 46): Loss/seq after 03350 batchs: 1093.119384765625
INFO:root:Train (Epoch 46): Loss/seq after 03400 batchs: 1086.5477294921875
INFO:root:Train (Epoch 46): Loss/seq after 03450 batchs: 1081.5125732421875
INFO:root:Train (Epoch 46): Loss/seq after 03500 batchs: 1081.8582763671875
INFO:root:Train (Epoch 46): Loss/seq after 03550 batchs: 1077.1119384765625
INFO:root:Train (Epoch 46): Loss/seq after 03600 batchs: 1084.258056640625
INFO:root:Train (Epoch 46): Loss/seq after 03650 batchs: 1080.1051025390625
INFO:root:Train (Epoch 46): Loss/seq after 03700 batchs: 1080.604736328125
INFO:root:Train (Epoch 46): Loss/seq after 03750 batchs: 1082.4708251953125
INFO:root:Train (Epoch 46): Loss/seq after 03800 batchs: 1077.1727294921875
INFO:root:Train (Epoch 46): Loss/seq after 03850 batchs: 1074.3414306640625
INFO:root:Train (Epoch 46): Loss/seq after 03900 batchs: 1078.208251953125
INFO:root:Train (Epoch 46): Loss/seq after 03950 batchs: 1081.586669921875
INFO:root:Train (Epoch 46): Loss/seq after 04000 batchs: 1074.3433837890625
INFO:root:Train (Epoch 46): Loss/seq after 04050 batchs: 1068.074462890625
INFO:root:Train (Epoch 46): Loss/seq after 04100 batchs: 1063.239501953125
INFO:root:Train (Epoch 46): Loss/seq after 04150 batchs: 1058.9312744140625
INFO:root:Train (Epoch 46): Loss/seq after 04200 batchs: 1054.656982421875
INFO:root:Train (Epoch 46): Loss/seq after 04250 batchs: 1051.53515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 46): Loss/seq after 00000 batches: 879.6634521484375
INFO:root:# Valid (Epoch 46): Loss/seq after 00050 batches: 1107.962158203125
INFO:root:# Valid (Epoch 46): Loss/seq after 00100 batches: 1391.7432861328125
INFO:root:# Valid (Epoch 46): Loss/seq after 00150 batches: 1107.677490234375
INFO:root:# Valid (Epoch 46): Loss/seq after 00200 batches: 996.8977661132812
INFO:root:Artifacts: Make stick videos for epoch 46
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_46_on_20220413_185413.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_46_index_501_on_20220413_185413.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 47): Loss/seq after 00000 batchs: 1632.8958740234375
INFO:root:Train (Epoch 47): Loss/seq after 00050 batchs: 1339.8287353515625
INFO:root:Train (Epoch 47): Loss/seq after 00100 batchs: 1319.9586181640625
INFO:root:Train (Epoch 47): Loss/seq after 00150 batchs: 1203.322998046875
INFO:root:Train (Epoch 47): Loss/seq after 00200 batchs: 1303.8985595703125
INFO:root:Train (Epoch 47): Loss/seq after 00250 batchs: 1453.91064453125
INFO:root:Train (Epoch 47): Loss/seq after 00300 batchs: 1394.1563720703125
INFO:root:Train (Epoch 47): Loss/seq after 00350 batchs: 1306.630615234375
INFO:root:Train (Epoch 47): Loss/seq after 00400 batchs: 1339.468505859375
INFO:root:Train (Epoch 47): Loss/seq after 00450 batchs: 1287.916015625
INFO:root:Train (Epoch 47): Loss/seq after 00500 batchs: 1291.64794921875
INFO:root:Train (Epoch 47): Loss/seq after 00550 batchs: 1244.6221923828125
INFO:root:Train (Epoch 47): Loss/seq after 00600 batchs: 1211.5029296875
INFO:root:Train (Epoch 47): Loss/seq after 00650 batchs: 1213.058349609375
INFO:root:Train (Epoch 47): Loss/seq after 00700 batchs: 1187.423095703125
INFO:root:Train (Epoch 47): Loss/seq after 00750 batchs: 1216.0740966796875
INFO:root:Train (Epoch 47): Loss/seq after 00800 batchs: 1211.1605224609375
INFO:root:Train (Epoch 47): Loss/seq after 00850 batchs: 1189.2989501953125
INFO:root:Train (Epoch 47): Loss/seq after 00900 batchs: 1199.4305419921875
INFO:root:Train (Epoch 47): Loss/seq after 00950 batchs: 1215.323486328125
INFO:root:Train (Epoch 47): Loss/seq after 01000 batchs: 1208.667724609375
INFO:root:Train (Epoch 47): Loss/seq after 01050 batchs: 1193.4136962890625
INFO:root:Train (Epoch 47): Loss/seq after 01100 batchs: 1193.229248046875
INFO:root:Train (Epoch 47): Loss/seq after 01150 batchs: 1182.535400390625
INFO:root:Train (Epoch 47): Loss/seq after 01200 batchs: 1176.52783203125
INFO:root:Train (Epoch 47): Loss/seq after 01250 batchs: 1170.097900390625
INFO:root:Train (Epoch 47): Loss/seq after 01300 batchs: 1168.9432373046875
INFO:root:Train (Epoch 47): Loss/seq after 01350 batchs: 1170.5130615234375
INFO:root:Train (Epoch 47): Loss/seq after 01400 batchs: 1180.7288818359375
INFO:root:Train (Epoch 47): Loss/seq after 01450 batchs: 1175.222900390625
INFO:root:Train (Epoch 47): Loss/seq after 01500 batchs: 1170.779541015625
INFO:root:Train (Epoch 47): Loss/seq after 01550 batchs: 1174.143310546875
INFO:root:Train (Epoch 47): Loss/seq after 01600 batchs: 1161.4129638671875
INFO:root:Train (Epoch 47): Loss/seq after 01650 batchs: 1155.03759765625
INFO:root:Train (Epoch 47): Loss/seq after 01700 batchs: 1149.132080078125
INFO:root:Train (Epoch 47): Loss/seq after 01750 batchs: 1141.5528564453125
INFO:root:Train (Epoch 47): Loss/seq after 01800 batchs: 1131.2625732421875
INFO:root:Train (Epoch 47): Loss/seq after 01850 batchs: 1120.9466552734375
INFO:root:Train (Epoch 47): Loss/seq after 01900 batchs: 1121.5753173828125
INFO:root:Train (Epoch 47): Loss/seq after 01950 batchs: 1117.5189208984375
INFO:root:Train (Epoch 47): Loss/seq after 02000 batchs: 1110.9549560546875
INFO:root:Train (Epoch 47): Loss/seq after 02050 batchs: 1105.1590576171875
INFO:root:Train (Epoch 47): Loss/seq after 02100 batchs: 1096.5386962890625
INFO:root:Train (Epoch 47): Loss/seq after 02150 batchs: 1088.786376953125
INFO:root:Train (Epoch 47): Loss/seq after 02200 batchs: 1080.467529296875
INFO:root:Train (Epoch 47): Loss/seq after 02250 batchs: 1084.4044189453125
INFO:root:Train (Epoch 47): Loss/seq after 02300 batchs: 1091.9439697265625
INFO:root:Train (Epoch 47): Loss/seq after 02350 batchs: 1085.8292236328125
INFO:root:Train (Epoch 47): Loss/seq after 02400 batchs: 1084.31201171875
INFO:root:Train (Epoch 47): Loss/seq after 02450 batchs: 1074.6146240234375
INFO:root:Train (Epoch 47): Loss/seq after 02500 batchs: 1060.3497314453125
INFO:root:Train (Epoch 47): Loss/seq after 02550 batchs: 1052.0526123046875
INFO:root:Train (Epoch 47): Loss/seq after 02600 batchs: 1051.838134765625
INFO:root:Train (Epoch 47): Loss/seq after 02650 batchs: 1049.33349609375
INFO:root:Train (Epoch 47): Loss/seq after 02700 batchs: 1046.1348876953125
INFO:root:Train (Epoch 47): Loss/seq after 02750 batchs: 1077.17724609375
INFO:root:Train (Epoch 47): Loss/seq after 02800 batchs: 1081.009033203125
INFO:root:Train (Epoch 47): Loss/seq after 02850 batchs: 1078.1639404296875
INFO:root:Train (Epoch 47): Loss/seq after 02900 batchs: 1077.4320068359375
INFO:root:Train (Epoch 47): Loss/seq after 02950 batchs: 1071.567138671875
INFO:root:Train (Epoch 47): Loss/seq after 03000 batchs: 1071.7276611328125
INFO:root:Train (Epoch 47): Loss/seq after 03050 batchs: 1076.263671875
INFO:root:Train (Epoch 47): Loss/seq after 03100 batchs: 1085.635986328125
INFO:root:Train (Epoch 47): Loss/seq after 03150 batchs: 1089.4019775390625
INFO:root:Train (Epoch 47): Loss/seq after 03200 batchs: 1093.7213134765625
INFO:root:Train (Epoch 47): Loss/seq after 03250 batchs: 1094.69580078125
INFO:root:Train (Epoch 47): Loss/seq after 03300 batchs: 1092.9085693359375
INFO:root:Train (Epoch 47): Loss/seq after 03350 batchs: 1092.9552001953125
INFO:root:Train (Epoch 47): Loss/seq after 03400 batchs: 1086.2650146484375
INFO:root:Train (Epoch 47): Loss/seq after 03450 batchs: 1080.9649658203125
INFO:root:Train (Epoch 47): Loss/seq after 03500 batchs: 1080.8687744140625
INFO:root:Train (Epoch 47): Loss/seq after 03550 batchs: 1075.642822265625
INFO:root:Train (Epoch 47): Loss/seq after 03600 batchs: 1082.62744140625
INFO:root:Train (Epoch 47): Loss/seq after 03650 batchs: 1078.2130126953125
INFO:root:Train (Epoch 47): Loss/seq after 03700 batchs: 1078.649658203125
INFO:root:Train (Epoch 47): Loss/seq after 03750 batchs: 1080.3017578125
INFO:root:Train (Epoch 47): Loss/seq after 03800 batchs: 1074.9041748046875
INFO:root:Train (Epoch 47): Loss/seq after 03850 batchs: 1071.8817138671875
INFO:root:Train (Epoch 47): Loss/seq after 03900 batchs: 1076.1927490234375
INFO:root:Train (Epoch 47): Loss/seq after 03950 batchs: 1079.6641845703125
INFO:root:Train (Epoch 47): Loss/seq after 04000 batchs: 1072.463134765625
INFO:root:Train (Epoch 47): Loss/seq after 04050 batchs: 1066.2117919921875
INFO:root:Train (Epoch 47): Loss/seq after 04100 batchs: 1061.380615234375
INFO:root:Train (Epoch 47): Loss/seq after 04150 batchs: 1057.3043212890625
INFO:root:Train (Epoch 47): Loss/seq after 04200 batchs: 1053.208251953125
INFO:root:Train (Epoch 47): Loss/seq after 04250 batchs: 1050.125732421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 47): Loss/seq after 00000 batches: 887.1507568359375
INFO:root:# Valid (Epoch 47): Loss/seq after 00050 batches: 1093.7706298828125
INFO:root:# Valid (Epoch 47): Loss/seq after 00100 batches: 1377.6702880859375
INFO:root:# Valid (Epoch 47): Loss/seq after 00150 batches: 1100.805908203125
INFO:root:# Valid (Epoch 47): Loss/seq after 00200 batches: 991.2836303710938
INFO:root:Artifacts: Make stick videos for epoch 47
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_47_on_20220413_185931.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_47_index_15_on_20220413_185931.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 48): Loss/seq after 00000 batchs: 1497.29443359375
INFO:root:Train (Epoch 48): Loss/seq after 00050 batchs: 1344.255859375
INFO:root:Train (Epoch 48): Loss/seq after 00100 batchs: 1340.1336669921875
INFO:root:Train (Epoch 48): Loss/seq after 00150 batchs: 1212.6572265625
INFO:root:Train (Epoch 48): Loss/seq after 00200 batchs: 1303.21875
INFO:root:Train (Epoch 48): Loss/seq after 00250 batchs: 1445.6004638671875
INFO:root:Train (Epoch 48): Loss/seq after 00300 batchs: 1387.1202392578125
INFO:root:Train (Epoch 48): Loss/seq after 00350 batchs: 1298.5614013671875
INFO:root:Train (Epoch 48): Loss/seq after 00400 batchs: 1325.4298095703125
INFO:root:Train (Epoch 48): Loss/seq after 00450 batchs: 1275.005615234375
INFO:root:Train (Epoch 48): Loss/seq after 00500 batchs: 1282.85595703125
INFO:root:Train (Epoch 48): Loss/seq after 00550 batchs: 1235.3092041015625
INFO:root:Train (Epoch 48): Loss/seq after 00600 batchs: 1203.480712890625
INFO:root:Train (Epoch 48): Loss/seq after 00650 batchs: 1204.451416015625
INFO:root:Train (Epoch 48): Loss/seq after 00700 batchs: 1177.7799072265625
INFO:root:Train (Epoch 48): Loss/seq after 00750 batchs: 1204.4573974609375
INFO:root:Train (Epoch 48): Loss/seq after 00800 batchs: 1199.73046875
INFO:root:Train (Epoch 48): Loss/seq after 00850 batchs: 1178.804931640625
INFO:root:Train (Epoch 48): Loss/seq after 00900 batchs: 1192.303466796875
INFO:root:Train (Epoch 48): Loss/seq after 00950 batchs: 1208.0087890625
INFO:root:Train (Epoch 48): Loss/seq after 01000 batchs: 1199.583984375
INFO:root:Train (Epoch 48): Loss/seq after 01050 batchs: 1184.9193115234375
INFO:root:Train (Epoch 48): Loss/seq after 01100 batchs: 1182.4686279296875
INFO:root:Train (Epoch 48): Loss/seq after 01150 batchs: 1171.8338623046875
INFO:root:Train (Epoch 48): Loss/seq after 01200 batchs: 1166.2340087890625
INFO:root:Train (Epoch 48): Loss/seq after 01250 batchs: 1159.1539306640625
INFO:root:Train (Epoch 48): Loss/seq after 01300 batchs: 1157.19873046875
INFO:root:Train (Epoch 48): Loss/seq after 01350 batchs: 1157.1707763671875
INFO:root:Train (Epoch 48): Loss/seq after 01400 batchs: 1167.16162109375
INFO:root:Train (Epoch 48): Loss/seq after 01450 batchs: 1161.621826171875
INFO:root:Train (Epoch 48): Loss/seq after 01500 batchs: 1157.4501953125
INFO:root:Train (Epoch 48): Loss/seq after 01550 batchs: 1160.4952392578125
INFO:root:Train (Epoch 48): Loss/seq after 01600 batchs: 1148.384033203125
INFO:root:Train (Epoch 48): Loss/seq after 01650 batchs: 1141.8714599609375
INFO:root:Train (Epoch 48): Loss/seq after 01700 batchs: 1137.233154296875
INFO:root:Train (Epoch 48): Loss/seq after 01750 batchs: 1130.06640625
INFO:root:Train (Epoch 48): Loss/seq after 01800 batchs: 1120.16748046875
INFO:root:Train (Epoch 48): Loss/seq after 01850 batchs: 1110.266357421875
INFO:root:Train (Epoch 48): Loss/seq after 01900 batchs: 1111.4012451171875
INFO:root:Train (Epoch 48): Loss/seq after 01950 batchs: 1107.00927734375
INFO:root:Train (Epoch 48): Loss/seq after 02000 batchs: 1100.7308349609375
INFO:root:Train (Epoch 48): Loss/seq after 02050 batchs: 1095.254638671875
INFO:root:Train (Epoch 48): Loss/seq after 02100 batchs: 1087.009521484375
INFO:root:Train (Epoch 48): Loss/seq after 02150 batchs: 1079.3653564453125
INFO:root:Train (Epoch 48): Loss/seq after 02200 batchs: 1071.2393798828125
INFO:root:Train (Epoch 48): Loss/seq after 02250 batchs: 1072.5252685546875
INFO:root:Train (Epoch 48): Loss/seq after 02300 batchs: 1078.1861572265625
INFO:root:Train (Epoch 48): Loss/seq after 02350 batchs: 1071.3466796875
INFO:root:Train (Epoch 48): Loss/seq after 02400 batchs: 1069.5123291015625
INFO:root:Train (Epoch 48): Loss/seq after 02450 batchs: 1059.593994140625
INFO:root:Train (Epoch 48): Loss/seq after 02500 batchs: 1045.561767578125
INFO:root:Train (Epoch 48): Loss/seq after 02550 batchs: 1036.5589599609375
INFO:root:Train (Epoch 48): Loss/seq after 02600 batchs: 1036.906982421875
INFO:root:Train (Epoch 48): Loss/seq after 02650 batchs: 1034.77880859375
INFO:root:Train (Epoch 48): Loss/seq after 02700 batchs: 1032.2332763671875
INFO:root:Train (Epoch 48): Loss/seq after 02750 batchs: 1062.6634521484375
INFO:root:Train (Epoch 48): Loss/seq after 02800 batchs: 1067.0601806640625
INFO:root:Train (Epoch 48): Loss/seq after 02850 batchs: 1064.473388671875
INFO:root:Train (Epoch 48): Loss/seq after 02900 batchs: 1063.2415771484375
INFO:root:Train (Epoch 48): Loss/seq after 02950 batchs: 1057.05078125
INFO:root:Train (Epoch 48): Loss/seq after 03000 batchs: 1057.386962890625
INFO:root:Train (Epoch 48): Loss/seq after 03050 batchs: 1061.8990478515625
INFO:root:Train (Epoch 48): Loss/seq after 03100 batchs: 1071.3826904296875
INFO:root:Train (Epoch 48): Loss/seq after 03150 batchs: 1076.1934814453125
INFO:root:Train (Epoch 48): Loss/seq after 03200 batchs: 1081.249267578125
INFO:root:Train (Epoch 48): Loss/seq after 03250 batchs: 1083.415771484375
INFO:root:Train (Epoch 48): Loss/seq after 03300 batchs: 1081.78369140625
INFO:root:Train (Epoch 48): Loss/seq after 03350 batchs: 1082.858154296875
INFO:root:Train (Epoch 48): Loss/seq after 03400 batchs: 1076.3414306640625
INFO:root:Train (Epoch 48): Loss/seq after 03450 batchs: 1070.6787109375
INFO:root:Train (Epoch 48): Loss/seq after 03500 batchs: 1070.3946533203125
INFO:root:Train (Epoch 48): Loss/seq after 03550 batchs: 1065.18896484375
INFO:root:Train (Epoch 48): Loss/seq after 03600 batchs: 1072.29931640625
INFO:root:Train (Epoch 48): Loss/seq after 03650 batchs: 1067.9415283203125
INFO:root:Train (Epoch 48): Loss/seq after 03700 batchs: 1068.679931640625
INFO:root:Train (Epoch 48): Loss/seq after 03750 batchs: 1070.5283203125
INFO:root:Train (Epoch 48): Loss/seq after 03800 batchs: 1065.347412109375
INFO:root:Train (Epoch 48): Loss/seq after 03850 batchs: 1062.4332275390625
INFO:root:Train (Epoch 48): Loss/seq after 03900 batchs: 1066.255859375
INFO:root:Train (Epoch 48): Loss/seq after 03950 batchs: 1069.726806640625
INFO:root:Train (Epoch 48): Loss/seq after 04000 batchs: 1062.638916015625
INFO:root:Train (Epoch 48): Loss/seq after 04050 batchs: 1056.5167236328125
INFO:root:Train (Epoch 48): Loss/seq after 04100 batchs: 1051.8350830078125
INFO:root:Train (Epoch 48): Loss/seq after 04150 batchs: 1047.8699951171875
INFO:root:Train (Epoch 48): Loss/seq after 04200 batchs: 1043.6461181640625
INFO:root:Train (Epoch 48): Loss/seq after 04250 batchs: 1040.6116943359375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 48): Loss/seq after 00000 batches: 870.398681640625
INFO:root:# Valid (Epoch 48): Loss/seq after 00050 batches: 1089.5853271484375
INFO:root:# Valid (Epoch 48): Loss/seq after 00100 batches: 1370.6026611328125
INFO:root:# Valid (Epoch 48): Loss/seq after 00150 batches: 1091.69091796875
INFO:root:# Valid (Epoch 48): Loss/seq after 00200 batches: 982.8174438476562
INFO:root:Artifacts: Make stick videos for epoch 48
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_48_on_20220413_190451.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_48_index_816_on_20220413_190451.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 49): Loss/seq after 00000 batchs: 1760.1376953125
INFO:root:Train (Epoch 49): Loss/seq after 00050 batchs: 1363.123046875
INFO:root:Train (Epoch 49): Loss/seq after 00100 batchs: 1342.8629150390625
INFO:root:Train (Epoch 49): Loss/seq after 00150 batchs: 1211.903564453125
INFO:root:Train (Epoch 49): Loss/seq after 00200 batchs: 1304.7301025390625
INFO:root:Train (Epoch 49): Loss/seq after 00250 batchs: 1454.6494140625
INFO:root:Train (Epoch 49): Loss/seq after 00300 batchs: 1394.125244140625
INFO:root:Train (Epoch 49): Loss/seq after 00350 batchs: 1306.9339599609375
INFO:root:Train (Epoch 49): Loss/seq after 00400 batchs: 1334.5369873046875
INFO:root:Train (Epoch 49): Loss/seq after 00450 batchs: 1283.8123779296875
INFO:root:Train (Epoch 49): Loss/seq after 00500 batchs: 1291.2996826171875
INFO:root:Train (Epoch 49): Loss/seq after 00550 batchs: 1240.6337890625
INFO:root:Train (Epoch 49): Loss/seq after 00600 batchs: 1209.8302001953125
INFO:root:Train (Epoch 49): Loss/seq after 00650 batchs: 1212.4332275390625
INFO:root:Train (Epoch 49): Loss/seq after 00700 batchs: 1189.26416015625
INFO:root:Train (Epoch 49): Loss/seq after 00750 batchs: 1215.2703857421875
INFO:root:Train (Epoch 49): Loss/seq after 00800 batchs: 1210.7191162109375
INFO:root:Train (Epoch 49): Loss/seq after 00850 batchs: 1188.63427734375
INFO:root:Train (Epoch 49): Loss/seq after 00900 batchs: 1198.8341064453125
INFO:root:Train (Epoch 49): Loss/seq after 00950 batchs: 1209.563720703125
INFO:root:Train (Epoch 49): Loss/seq after 01000 batchs: 1201.4708251953125
INFO:root:Train (Epoch 49): Loss/seq after 01050 batchs: 1184.6082763671875
INFO:root:Train (Epoch 49): Loss/seq after 01100 batchs: 1182.8465576171875
INFO:root:Train (Epoch 49): Loss/seq after 01150 batchs: 1172.1715087890625
INFO:root:Train (Epoch 49): Loss/seq after 01200 batchs: 1166.2171630859375
INFO:root:Train (Epoch 49): Loss/seq after 01250 batchs: 1158.69677734375
INFO:root:Train (Epoch 49): Loss/seq after 01300 batchs: 1155.89794921875
INFO:root:Train (Epoch 49): Loss/seq after 01350 batchs: 1156.5592041015625
INFO:root:Train (Epoch 49): Loss/seq after 01400 batchs: 1166.7391357421875
INFO:root:Train (Epoch 49): Loss/seq after 01450 batchs: 1161.0728759765625
INFO:root:Train (Epoch 49): Loss/seq after 01500 batchs: 1156.911376953125
INFO:root:Train (Epoch 49): Loss/seq after 01550 batchs: 1158.6632080078125
INFO:root:Train (Epoch 49): Loss/seq after 01600 batchs: 1146.1856689453125
INFO:root:Train (Epoch 49): Loss/seq after 01650 batchs: 1139.0545654296875
INFO:root:Train (Epoch 49): Loss/seq after 01700 batchs: 1133.6168212890625
INFO:root:Train (Epoch 49): Loss/seq after 01750 batchs: 1126.2774658203125
INFO:root:Train (Epoch 49): Loss/seq after 01800 batchs: 1116.324951171875
INFO:root:Train (Epoch 49): Loss/seq after 01850 batchs: 1106.56396484375
INFO:root:Train (Epoch 49): Loss/seq after 01900 batchs: 1107.5843505859375
INFO:root:Train (Epoch 49): Loss/seq after 01950 batchs: 1103.2613525390625
INFO:root:Train (Epoch 49): Loss/seq after 02000 batchs: 1096.995849609375
INFO:root:Train (Epoch 49): Loss/seq after 02050 batchs: 1091.5233154296875
INFO:root:Train (Epoch 49): Loss/seq after 02100 batchs: 1083.61962890625
INFO:root:Train (Epoch 49): Loss/seq after 02150 batchs: 1076.037841796875
INFO:root:Train (Epoch 49): Loss/seq after 02200 batchs: 1067.9403076171875
INFO:root:Train (Epoch 49): Loss/seq after 02250 batchs: 1068.90283203125
INFO:root:Train (Epoch 49): Loss/seq after 02300 batchs: 1074.8818359375
INFO:root:Train (Epoch 49): Loss/seq after 02350 batchs: 1067.7718505859375
INFO:root:Train (Epoch 49): Loss/seq after 02400 batchs: 1065.6795654296875
INFO:root:Train (Epoch 49): Loss/seq after 02450 batchs: 1055.599365234375
INFO:root:Train (Epoch 49): Loss/seq after 02500 batchs: 1041.61669921875
INFO:root:Train (Epoch 49): Loss/seq after 02550 batchs: 1032.48486328125
INFO:root:Train (Epoch 49): Loss/seq after 02600 batchs: 1032.5823974609375
INFO:root:Train (Epoch 49): Loss/seq after 02650 batchs: 1030.286376953125
INFO:root:Train (Epoch 49): Loss/seq after 02700 batchs: 1027.621337890625
INFO:root:Train (Epoch 49): Loss/seq after 02750 batchs: 1058.5390625
INFO:root:Train (Epoch 49): Loss/seq after 02800 batchs: 1063.00048828125
INFO:root:Train (Epoch 49): Loss/seq after 02850 batchs: 1060.449462890625
INFO:root:Train (Epoch 49): Loss/seq after 02900 batchs: 1059.3426513671875
INFO:root:Train (Epoch 49): Loss/seq after 02950 batchs: 1053.1396484375
INFO:root:Train (Epoch 49): Loss/seq after 03000 batchs: 1053.5201416015625
INFO:root:Train (Epoch 49): Loss/seq after 03050 batchs: 1058.0775146484375
INFO:root:Train (Epoch 49): Loss/seq after 03100 batchs: 1066.69189453125
INFO:root:Train (Epoch 49): Loss/seq after 03150 batchs: 1070.7830810546875
INFO:root:Train (Epoch 49): Loss/seq after 03200 batchs: 1075.1318359375
INFO:root:Train (Epoch 49): Loss/seq after 03250 batchs: 1076.3919677734375
INFO:root:Train (Epoch 49): Loss/seq after 03300 batchs: 1074.48583984375
INFO:root:Train (Epoch 49): Loss/seq after 03350 batchs: 1074.8194580078125
INFO:root:Train (Epoch 49): Loss/seq after 03400 batchs: 1068.6741943359375
INFO:root:Train (Epoch 49): Loss/seq after 03450 batchs: 1063.907958984375
INFO:root:Train (Epoch 49): Loss/seq after 03500 batchs: 1064.1396484375
INFO:root:Train (Epoch 49): Loss/seq after 03550 batchs: 1058.8388671875
INFO:root:Train (Epoch 49): Loss/seq after 03600 batchs: 1065.9017333984375
INFO:root:Train (Epoch 49): Loss/seq after 03650 batchs: 1061.4052734375
INFO:root:Train (Epoch 49): Loss/seq after 03700 batchs: 1062.457763671875
INFO:root:Train (Epoch 49): Loss/seq after 03750 batchs: 1064.39892578125
INFO:root:Train (Epoch 49): Loss/seq after 03800 batchs: 1059.327880859375
INFO:root:Train (Epoch 49): Loss/seq after 03850 batchs: 1056.4827880859375
INFO:root:Train (Epoch 49): Loss/seq after 03900 batchs: 1060.3094482421875
INFO:root:Train (Epoch 49): Loss/seq after 03950 batchs: 1063.5750732421875
INFO:root:Train (Epoch 49): Loss/seq after 04000 batchs: 1056.566650390625
INFO:root:Train (Epoch 49): Loss/seq after 04050 batchs: 1050.49560546875
INFO:root:Train (Epoch 49): Loss/seq after 04100 batchs: 1045.7591552734375
INFO:root:Train (Epoch 49): Loss/seq after 04150 batchs: 1041.738037109375
INFO:root:Train (Epoch 49): Loss/seq after 04200 batchs: 1037.9012451171875
INFO:root:Train (Epoch 49): Loss/seq after 04250 batchs: 1034.997802734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 49): Loss/seq after 00000 batches: 874.6936645507812
INFO:root:# Valid (Epoch 49): Loss/seq after 00050 batches: 1110.701904296875
INFO:root:# Valid (Epoch 49): Loss/seq after 00100 batches: 1392.0946044921875
INFO:root:# Valid (Epoch 49): Loss/seq after 00150 batches: 1126.522216796875
INFO:root:# Valid (Epoch 49): Loss/seq after 00200 batches: 1017.5242919921875
INFO:root:Artifacts: Make stick videos for epoch 49
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_49_on_20220413_191008.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_49_index_1744_on_20220413_191008.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 50): Loss/seq after 00000 batchs: 1473.9124755859375
INFO:root:Train (Epoch 50): Loss/seq after 00050 batchs: 1359.5125732421875
INFO:root:Train (Epoch 50): Loss/seq after 00100 batchs: 1335.775146484375
INFO:root:Train (Epoch 50): Loss/seq after 00150 batchs: 1218.19189453125
INFO:root:Train (Epoch 50): Loss/seq after 00200 batchs: 1312.1956787109375
INFO:root:Train (Epoch 50): Loss/seq after 00250 batchs: 1451.8729248046875
INFO:root:Train (Epoch 50): Loss/seq after 00300 batchs: 1392.8056640625
INFO:root:Train (Epoch 50): Loss/seq after 00350 batchs: 1306.9259033203125
INFO:root:Train (Epoch 50): Loss/seq after 00400 batchs: 1337.4532470703125
INFO:root:Train (Epoch 50): Loss/seq after 00450 batchs: 1287.473876953125
INFO:root:Train (Epoch 50): Loss/seq after 00500 batchs: 1287.9183349609375
INFO:root:Train (Epoch 50): Loss/seq after 00550 batchs: 1237.0360107421875
INFO:root:Train (Epoch 50): Loss/seq after 00600 batchs: 1204.5828857421875
INFO:root:Train (Epoch 50): Loss/seq after 00650 batchs: 1203.5771484375
INFO:root:Train (Epoch 50): Loss/seq after 00700 batchs: 1179.183837890625
INFO:root:Train (Epoch 50): Loss/seq after 00750 batchs: 1205.97900390625
INFO:root:Train (Epoch 50): Loss/seq after 00800 batchs: 1201.6871337890625
INFO:root:Train (Epoch 50): Loss/seq after 00850 batchs: 1180.0216064453125
INFO:root:Train (Epoch 50): Loss/seq after 00900 batchs: 1191.995361328125
INFO:root:Train (Epoch 50): Loss/seq after 00950 batchs: 1203.510986328125
INFO:root:Train (Epoch 50): Loss/seq after 01000 batchs: 1196.837158203125
INFO:root:Train (Epoch 50): Loss/seq after 01050 batchs: 1180.70458984375
INFO:root:Train (Epoch 50): Loss/seq after 01100 batchs: 1178.837646484375
INFO:root:Train (Epoch 50): Loss/seq after 01150 batchs: 1168.5372314453125
INFO:root:Train (Epoch 50): Loss/seq after 01200 batchs: 1163.593505859375
INFO:root:Train (Epoch 50): Loss/seq after 01250 batchs: 1156.563232421875
INFO:root:Train (Epoch 50): Loss/seq after 01300 batchs: 1155.4129638671875
INFO:root:Train (Epoch 50): Loss/seq after 01350 batchs: 1155.2154541015625
INFO:root:Train (Epoch 50): Loss/seq after 01400 batchs: 1165.5914306640625
INFO:root:Train (Epoch 50): Loss/seq after 01450 batchs: 1160.0849609375
INFO:root:Train (Epoch 50): Loss/seq after 01500 batchs: 1155.885986328125
INFO:root:Train (Epoch 50): Loss/seq after 01550 batchs: 1158.575439453125
INFO:root:Train (Epoch 50): Loss/seq after 01600 batchs: 1146.27490234375
INFO:root:Train (Epoch 50): Loss/seq after 01650 batchs: 1139.3941650390625
INFO:root:Train (Epoch 50): Loss/seq after 01700 batchs: 1133.846923828125
INFO:root:Train (Epoch 50): Loss/seq after 01750 batchs: 1126.4794921875
INFO:root:Train (Epoch 50): Loss/seq after 01800 batchs: 1116.548095703125
INFO:root:Train (Epoch 50): Loss/seq after 01850 batchs: 1106.552734375
INFO:root:Train (Epoch 50): Loss/seq after 01900 batchs: 1106.9493408203125
INFO:root:Train (Epoch 50): Loss/seq after 01950 batchs: 1102.4814453125
INFO:root:Train (Epoch 50): Loss/seq after 02000 batchs: 1096.285400390625
INFO:root:Train (Epoch 50): Loss/seq after 02050 batchs: 1090.8458251953125
INFO:root:Train (Epoch 50): Loss/seq after 02100 batchs: 1082.5938720703125
INFO:root:Train (Epoch 50): Loss/seq after 02150 batchs: 1075.07861328125
INFO:root:Train (Epoch 50): Loss/seq after 02200 batchs: 1066.986328125
INFO:root:Train (Epoch 50): Loss/seq after 02250 batchs: 1068.3553466796875
INFO:root:Train (Epoch 50): Loss/seq after 02300 batchs: 1074.2847900390625
INFO:root:Train (Epoch 50): Loss/seq after 02350 batchs: 1067.151611328125
INFO:root:Train (Epoch 50): Loss/seq after 02400 batchs: 1064.958984375
INFO:root:Train (Epoch 50): Loss/seq after 02450 batchs: 1054.8773193359375
INFO:root:Train (Epoch 50): Loss/seq after 02500 batchs: 1040.9443359375
INFO:root:Train (Epoch 50): Loss/seq after 02550 batchs: 1031.640869140625
INFO:root:Train (Epoch 50): Loss/seq after 02600 batchs: 1031.8128662109375
INFO:root:Train (Epoch 50): Loss/seq after 02650 batchs: 1029.50390625
INFO:root:Train (Epoch 50): Loss/seq after 02700 batchs: 1026.701904296875
INFO:root:Train (Epoch 50): Loss/seq after 02750 batchs: 1056.896240234375
INFO:root:Train (Epoch 50): Loss/seq after 02800 batchs: 1061.2249755859375
INFO:root:Train (Epoch 50): Loss/seq after 02850 batchs: 1058.6414794921875
INFO:root:Train (Epoch 50): Loss/seq after 02900 batchs: 1057.871337890625
INFO:root:Train (Epoch 50): Loss/seq after 02950 batchs: 1051.785888671875
INFO:root:Train (Epoch 50): Loss/seq after 03000 batchs: 1052.146240234375
INFO:root:Train (Epoch 50): Loss/seq after 03050 batchs: 1056.7122802734375
INFO:root:Train (Epoch 50): Loss/seq after 03100 batchs: 1065.5225830078125
INFO:root:Train (Epoch 50): Loss/seq after 03150 batchs: 1068.220458984375
INFO:root:Train (Epoch 50): Loss/seq after 03200 batchs: 1071.931640625
INFO:root:Train (Epoch 50): Loss/seq after 03250 batchs: 1073.4114990234375
INFO:root:Train (Epoch 50): Loss/seq after 03300 batchs: 1072.0491943359375
INFO:root:Train (Epoch 50): Loss/seq after 03350 batchs: 1072.4698486328125
INFO:root:Train (Epoch 50): Loss/seq after 03400 batchs: 1066.552734375
INFO:root:Train (Epoch 50): Loss/seq after 03450 batchs: 1062.811279296875
INFO:root:Train (Epoch 50): Loss/seq after 03500 batchs: 1063.2669677734375
INFO:root:Train (Epoch 50): Loss/seq after 03550 batchs: 1058.4725341796875
INFO:root:Train (Epoch 50): Loss/seq after 03600 batchs: 1065.5914306640625
INFO:root:Train (Epoch 50): Loss/seq after 03650 batchs: 1061.39208984375
INFO:root:Train (Epoch 50): Loss/seq after 03700 batchs: 1062.3409423828125
INFO:root:Train (Epoch 50): Loss/seq after 03750 batchs: 1064.19091796875
INFO:root:Train (Epoch 50): Loss/seq after 03800 batchs: 1059.0076904296875
INFO:root:Train (Epoch 50): Loss/seq after 03850 batchs: 1056.1624755859375
INFO:root:Train (Epoch 50): Loss/seq after 03900 batchs: 1060.5997314453125
INFO:root:Train (Epoch 50): Loss/seq after 03950 batchs: 1063.914794921875
INFO:root:Train (Epoch 50): Loss/seq after 04000 batchs: 1056.88037109375
INFO:root:Train (Epoch 50): Loss/seq after 04050 batchs: 1050.8084716796875
INFO:root:Train (Epoch 50): Loss/seq after 04100 batchs: 1046.12109375
INFO:root:Train (Epoch 50): Loss/seq after 04150 batchs: 1042.1932373046875
INFO:root:Train (Epoch 50): Loss/seq after 04200 batchs: 1037.9752197265625
INFO:root:Train (Epoch 50): Loss/seq after 04250 batchs: 1035.0177001953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 50): Loss/seq after 00000 batches: 871.8651733398438
INFO:root:# Valid (Epoch 50): Loss/seq after 00050 batches: 1108.557373046875
INFO:root:# Valid (Epoch 50): Loss/seq after 00100 batches: 1390.396484375
INFO:root:# Valid (Epoch 50): Loss/seq after 00150 batches: 1118.4371337890625
INFO:root:# Valid (Epoch 50): Loss/seq after 00200 batches: 1009.1417846679688
INFO:root:Artifacts: Make stick videos for epoch 50
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_50_on_20220413_191526.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_50_index_71_on_20220413_191526.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 51): Loss/seq after 00000 batchs: 1639.367919921875
INFO:root:Train (Epoch 51): Loss/seq after 00050 batchs: 1306.5072021484375
INFO:root:Train (Epoch 51): Loss/seq after 00100 batchs: 1303.7386474609375
INFO:root:Train (Epoch 51): Loss/seq after 00150 batchs: 1192.6312255859375
INFO:root:Train (Epoch 51): Loss/seq after 00200 batchs: 1297.434326171875
INFO:root:Train (Epoch 51): Loss/seq after 00250 batchs: 1451.905029296875
INFO:root:Train (Epoch 51): Loss/seq after 00300 batchs: 1393.06005859375
INFO:root:Train (Epoch 51): Loss/seq after 00350 batchs: 1307.75732421875
INFO:root:Train (Epoch 51): Loss/seq after 00400 batchs: 1327.1748046875
INFO:root:Train (Epoch 51): Loss/seq after 00450 batchs: 1277.0189208984375
INFO:root:Train (Epoch 51): Loss/seq after 00500 batchs: 1282.848876953125
INFO:root:Train (Epoch 51): Loss/seq after 00550 batchs: 1232.4530029296875
INFO:root:Train (Epoch 51): Loss/seq after 00600 batchs: 1202.283203125
INFO:root:Train (Epoch 51): Loss/seq after 00650 batchs: 1206.153564453125
INFO:root:Train (Epoch 51): Loss/seq after 00700 batchs: 1181.4892578125
INFO:root:Train (Epoch 51): Loss/seq after 00750 batchs: 1207.0697021484375
INFO:root:Train (Epoch 51): Loss/seq after 00800 batchs: 1202.7791748046875
INFO:root:Train (Epoch 51): Loss/seq after 00850 batchs: 1181.969970703125
INFO:root:Train (Epoch 51): Loss/seq after 00900 batchs: 1195.899169921875
INFO:root:Train (Epoch 51): Loss/seq after 00950 batchs: 1209.501220703125
INFO:root:Train (Epoch 51): Loss/seq after 01000 batchs: 1202.194091796875
INFO:root:Train (Epoch 51): Loss/seq after 01050 batchs: 1184.8831787109375
INFO:root:Train (Epoch 51): Loss/seq after 01100 batchs: 1182.844970703125
INFO:root:Train (Epoch 51): Loss/seq after 01150 batchs: 1172.05810546875
INFO:root:Train (Epoch 51): Loss/seq after 01200 batchs: 1165.88037109375
INFO:root:Train (Epoch 51): Loss/seq after 01250 batchs: 1158.23681640625
INFO:root:Train (Epoch 51): Loss/seq after 01300 batchs: 1154.2347412109375
INFO:root:Train (Epoch 51): Loss/seq after 01350 batchs: 1154.6610107421875
INFO:root:Train (Epoch 51): Loss/seq after 01400 batchs: 1165.8194580078125
INFO:root:Train (Epoch 51): Loss/seq after 01450 batchs: 1160.09521484375
INFO:root:Train (Epoch 51): Loss/seq after 01500 batchs: 1155.9095458984375
INFO:root:Train (Epoch 51): Loss/seq after 01550 batchs: 1157.2034912109375
INFO:root:Train (Epoch 51): Loss/seq after 01600 batchs: 1144.757568359375
INFO:root:Train (Epoch 51): Loss/seq after 01650 batchs: 1137.4305419921875
INFO:root:Train (Epoch 51): Loss/seq after 01700 batchs: 1131.8597412109375
INFO:root:Train (Epoch 51): Loss/seq after 01750 batchs: 1124.5125732421875
INFO:root:Train (Epoch 51): Loss/seq after 01800 batchs: 1114.6802978515625
INFO:root:Train (Epoch 51): Loss/seq after 01850 batchs: 1104.728759765625
INFO:root:Train (Epoch 51): Loss/seq after 01900 batchs: 1105.2117919921875
INFO:root:Train (Epoch 51): Loss/seq after 01950 batchs: 1100.69921875
INFO:root:Train (Epoch 51): Loss/seq after 02000 batchs: 1094.4156494140625
INFO:root:Train (Epoch 51): Loss/seq after 02050 batchs: 1088.9993896484375
INFO:root:Train (Epoch 51): Loss/seq after 02100 batchs: 1080.8345947265625
INFO:root:Train (Epoch 51): Loss/seq after 02150 batchs: 1073.265380859375
INFO:root:Train (Epoch 51): Loss/seq after 02200 batchs: 1065.1724853515625
INFO:root:Train (Epoch 51): Loss/seq after 02250 batchs: 1067.10302734375
INFO:root:Train (Epoch 51): Loss/seq after 02300 batchs: 1073.7757568359375
INFO:root:Train (Epoch 51): Loss/seq after 02350 batchs: 1067.2249755859375
INFO:root:Train (Epoch 51): Loss/seq after 02400 batchs: 1065.23388671875
INFO:root:Train (Epoch 51): Loss/seq after 02450 batchs: 1055.366943359375
INFO:root:Train (Epoch 51): Loss/seq after 02500 batchs: 1041.448974609375
INFO:root:Train (Epoch 51): Loss/seq after 02550 batchs: 1032.76611328125
INFO:root:Train (Epoch 51): Loss/seq after 02600 batchs: 1032.6837158203125
INFO:root:Train (Epoch 51): Loss/seq after 02650 batchs: 1030.3231201171875
INFO:root:Train (Epoch 51): Loss/seq after 02700 batchs: 1027.1644287109375
INFO:root:Train (Epoch 51): Loss/seq after 02750 batchs: 1057.0111083984375
INFO:root:Train (Epoch 51): Loss/seq after 02800 batchs: 1060.380615234375
INFO:root:Train (Epoch 51): Loss/seq after 02850 batchs: 1057.700927734375
INFO:root:Train (Epoch 51): Loss/seq after 02900 batchs: 1056.4356689453125
INFO:root:Train (Epoch 51): Loss/seq after 02950 batchs: 1050.1759033203125
INFO:root:Train (Epoch 51): Loss/seq after 03000 batchs: 1050.6195068359375
INFO:root:Train (Epoch 51): Loss/seq after 03050 batchs: 1055.1025390625
INFO:root:Train (Epoch 51): Loss/seq after 03100 batchs: 1063.5572509765625
INFO:root:Train (Epoch 51): Loss/seq after 03150 batchs: 1069.72607421875
INFO:root:Train (Epoch 51): Loss/seq after 03200 batchs: 1074.0716552734375
INFO:root:Train (Epoch 51): Loss/seq after 03250 batchs: 1075.4937744140625
INFO:root:Train (Epoch 51): Loss/seq after 03300 batchs: 1074.5439453125
INFO:root:Train (Epoch 51): Loss/seq after 03350 batchs: 1075.028564453125
INFO:root:Train (Epoch 51): Loss/seq after 03400 batchs: 1068.990478515625
INFO:root:Train (Epoch 51): Loss/seq after 03450 batchs: 1065.0577392578125
INFO:root:Train (Epoch 51): Loss/seq after 03500 batchs: 1065.576171875
INFO:root:Train (Epoch 51): Loss/seq after 03550 batchs: 1060.7530517578125
INFO:root:Train (Epoch 51): Loss/seq after 03600 batchs: 1068.1690673828125
INFO:root:Train (Epoch 51): Loss/seq after 03650 batchs: 1063.909912109375
INFO:root:Train (Epoch 51): Loss/seq after 03700 batchs: 1064.80322265625
INFO:root:Train (Epoch 51): Loss/seq after 03750 batchs: 1066.591552734375
INFO:root:Train (Epoch 51): Loss/seq after 03800 batchs: 1061.336669921875
INFO:root:Train (Epoch 51): Loss/seq after 03850 batchs: 1058.4534912109375
INFO:root:Train (Epoch 51): Loss/seq after 03900 batchs: 1062.687744140625
INFO:root:Train (Epoch 51): Loss/seq after 03950 batchs: 1066.0198974609375
INFO:root:Train (Epoch 51): Loss/seq after 04000 batchs: 1059.0084228515625
INFO:root:Train (Epoch 51): Loss/seq after 04050 batchs: 1052.928955078125
INFO:root:Train (Epoch 51): Loss/seq after 04100 batchs: 1048.163818359375
INFO:root:Train (Epoch 51): Loss/seq after 04150 batchs: 1044.1982421875
INFO:root:Train (Epoch 51): Loss/seq after 04200 batchs: 1040.9859619140625
INFO:root:Train (Epoch 51): Loss/seq after 04250 batchs: 1038.0447998046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 51): Loss/seq after 00000 batches: 867.755859375
INFO:root:# Valid (Epoch 51): Loss/seq after 00050 batches: 1097.78125
INFO:root:# Valid (Epoch 51): Loss/seq after 00100 batches: 1382.740966796875
INFO:root:# Valid (Epoch 51): Loss/seq after 00150 batches: 1110.41943359375
INFO:root:# Valid (Epoch 51): Loss/seq after 00200 batches: 999.7037353515625
INFO:root:Artifacts: Make stick videos for epoch 51
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_51_on_20220413_192045.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_51_index_1479_on_20220413_192045.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 52): Loss/seq after 00000 batchs: 1618.7532958984375
INFO:root:Train (Epoch 52): Loss/seq after 00050 batchs: 1347.86474609375
INFO:root:Train (Epoch 52): Loss/seq after 00100 batchs: 1342.6773681640625
INFO:root:Train (Epoch 52): Loss/seq after 00150 batchs: 1212.4892578125
INFO:root:Train (Epoch 52): Loss/seq after 00200 batchs: 1308.9400634765625
INFO:root:Train (Epoch 52): Loss/seq after 00250 batchs: 1446.653076171875
INFO:root:Train (Epoch 52): Loss/seq after 00300 batchs: 1388.14990234375
INFO:root:Train (Epoch 52): Loss/seq after 00350 batchs: 1304.1129150390625
INFO:root:Train (Epoch 52): Loss/seq after 00400 batchs: 1337.292236328125
INFO:root:Train (Epoch 52): Loss/seq after 00450 batchs: 1286.584716796875
INFO:root:Train (Epoch 52): Loss/seq after 00500 batchs: 1299.001220703125
INFO:root:Train (Epoch 52): Loss/seq after 00550 batchs: 1247.765380859375
INFO:root:Train (Epoch 52): Loss/seq after 00600 batchs: 1215.562255859375
INFO:root:Train (Epoch 52): Loss/seq after 00650 batchs: 1217.766357421875
INFO:root:Train (Epoch 52): Loss/seq after 00700 batchs: 1191.8182373046875
INFO:root:Train (Epoch 52): Loss/seq after 00750 batchs: 1219.158203125
INFO:root:Train (Epoch 52): Loss/seq after 00800 batchs: 1214.0546875
INFO:root:Train (Epoch 52): Loss/seq after 00850 batchs: 1192.525634765625
INFO:root:Train (Epoch 52): Loss/seq after 00900 batchs: 1206.3253173828125
INFO:root:Train (Epoch 52): Loss/seq after 00950 batchs: 1217.6600341796875
INFO:root:Train (Epoch 52): Loss/seq after 01000 batchs: 1207.82373046875
INFO:root:Train (Epoch 52): Loss/seq after 01050 batchs: 1191.8604736328125
INFO:root:Train (Epoch 52): Loss/seq after 01100 batchs: 1193.9686279296875
INFO:root:Train (Epoch 52): Loss/seq after 01150 batchs: 1185.131103515625
INFO:root:Train (Epoch 52): Loss/seq after 01200 batchs: 1181.4053955078125
INFO:root:Train (Epoch 52): Loss/seq after 01250 batchs: 1175.544677734375
INFO:root:Train (Epoch 52): Loss/seq after 01300 batchs: 1173.5457763671875
INFO:root:Train (Epoch 52): Loss/seq after 01350 batchs: 1173.726318359375
INFO:root:Train (Epoch 52): Loss/seq after 01400 batchs: 1185.992431640625
INFO:root:Train (Epoch 52): Loss/seq after 01450 batchs: 1180.5037841796875
INFO:root:Train (Epoch 52): Loss/seq after 01500 batchs: 1175.847900390625
INFO:root:Train (Epoch 52): Loss/seq after 01550 batchs: 1178.5830078125
INFO:root:Train (Epoch 52): Loss/seq after 01600 batchs: 1165.70068359375
INFO:root:Train (Epoch 52): Loss/seq after 01650 batchs: 1158.6622314453125
INFO:root:Train (Epoch 52): Loss/seq after 01700 batchs: 1152.6224365234375
INFO:root:Train (Epoch 52): Loss/seq after 01750 batchs: 1144.83740234375
INFO:root:Train (Epoch 52): Loss/seq after 01800 batchs: 1134.2628173828125
INFO:root:Train (Epoch 52): Loss/seq after 01850 batchs: 1123.73388671875
INFO:root:Train (Epoch 52): Loss/seq after 01900 batchs: 1124.000244140625
INFO:root:Train (Epoch 52): Loss/seq after 01950 batchs: 1120.07275390625
INFO:root:Train (Epoch 52): Loss/seq after 02000 batchs: 1113.3955078125
INFO:root:Train (Epoch 52): Loss/seq after 02050 batchs: 1107.6785888671875
INFO:root:Train (Epoch 52): Loss/seq after 02100 batchs: 1098.93798828125
INFO:root:Train (Epoch 52): Loss/seq after 02150 batchs: 1090.840576171875
INFO:root:Train (Epoch 52): Loss/seq after 02200 batchs: 1082.3798828125
INFO:root:Train (Epoch 52): Loss/seq after 02250 batchs: 1084.2218017578125
INFO:root:Train (Epoch 52): Loss/seq after 02300 batchs: 1090.73291015625
INFO:root:Train (Epoch 52): Loss/seq after 02350 batchs: 1082.5570068359375
INFO:root:Train (Epoch 52): Loss/seq after 02400 batchs: 1080.1304931640625
INFO:root:Train (Epoch 52): Loss/seq after 02450 batchs: 1069.5887451171875
INFO:root:Train (Epoch 52): Loss/seq after 02500 batchs: 1055.36669921875
INFO:root:Train (Epoch 52): Loss/seq after 02550 batchs: 1045.68115234375
INFO:root:Train (Epoch 52): Loss/seq after 02600 batchs: 1045.7564697265625
INFO:root:Train (Epoch 52): Loss/seq after 02650 batchs: 1043.049072265625
INFO:root:Train (Epoch 52): Loss/seq after 02700 batchs: 1039.9359130859375
INFO:root:Train (Epoch 52): Loss/seq after 02750 batchs: 1069.703369140625
INFO:root:Train (Epoch 52): Loss/seq after 02800 batchs: 1072.8841552734375
INFO:root:Train (Epoch 52): Loss/seq after 02850 batchs: 1069.885986328125
INFO:root:Train (Epoch 52): Loss/seq after 02900 batchs: 1068.41064453125
INFO:root:Train (Epoch 52): Loss/seq after 02950 batchs: 1062.019287109375
INFO:root:Train (Epoch 52): Loss/seq after 03000 batchs: 1062.2103271484375
INFO:root:Train (Epoch 52): Loss/seq after 03050 batchs: 1066.4776611328125
INFO:root:Train (Epoch 52): Loss/seq after 03100 batchs: 1075.72216796875
INFO:root:Train (Epoch 52): Loss/seq after 03150 batchs: 1079.683349609375
INFO:root:Train (Epoch 52): Loss/seq after 03200 batchs: 1083.8026123046875
INFO:root:Train (Epoch 52): Loss/seq after 03250 batchs: 1085.395263671875
INFO:root:Train (Epoch 52): Loss/seq after 03300 batchs: 1082.9276123046875
INFO:root:Train (Epoch 52): Loss/seq after 03350 batchs: 1081.7442626953125
INFO:root:Train (Epoch 52): Loss/seq after 03400 batchs: 1075.316650390625
INFO:root:Train (Epoch 52): Loss/seq after 03450 batchs: 1069.8802490234375
INFO:root:Train (Epoch 52): Loss/seq after 03500 batchs: 1069.0701904296875
INFO:root:Train (Epoch 52): Loss/seq after 03550 batchs: 1064.272705078125
INFO:root:Train (Epoch 52): Loss/seq after 03600 batchs: 1071.2635498046875
INFO:root:Train (Epoch 52): Loss/seq after 03650 batchs: 1066.75
INFO:root:Train (Epoch 52): Loss/seq after 03700 batchs: 1067.4500732421875
INFO:root:Train (Epoch 52): Loss/seq after 03750 batchs: 1069.2376708984375
INFO:root:Train (Epoch 52): Loss/seq after 03800 batchs: 1063.982177734375
INFO:root:Train (Epoch 52): Loss/seq after 03850 batchs: 1060.9959716796875
INFO:root:Train (Epoch 52): Loss/seq after 03900 batchs: 1064.5244140625
INFO:root:Train (Epoch 52): Loss/seq after 03950 batchs: 1067.6435546875
INFO:root:Train (Epoch 52): Loss/seq after 04000 batchs: 1060.541748046875
INFO:root:Train (Epoch 52): Loss/seq after 04050 batchs: 1054.37060546875
INFO:root:Train (Epoch 52): Loss/seq after 04100 batchs: 1049.396728515625
INFO:root:Train (Epoch 52): Loss/seq after 04150 batchs: 1045.2413330078125
INFO:root:Train (Epoch 52): Loss/seq after 04200 batchs: 1041.1917724609375
INFO:root:Train (Epoch 52): Loss/seq after 04250 batchs: 1038.3306884765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 52): Loss/seq after 00000 batches: 912.5450439453125
INFO:root:# Valid (Epoch 52): Loss/seq after 00050 batches: 1101.3677978515625
INFO:root:# Valid (Epoch 52): Loss/seq after 00100 batches: 1385.3004150390625
INFO:root:# Valid (Epoch 52): Loss/seq after 00150 batches: 1106.5352783203125
INFO:root:# Valid (Epoch 52): Loss/seq after 00200 batches: 996.943359375
INFO:root:Artifacts: Make stick videos for epoch 52
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_52_on_20220413_192602.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_52_index_1240_on_20220413_192602.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 53): Loss/seq after 00000 batchs: 1518.818115234375
INFO:root:Train (Epoch 53): Loss/seq after 00050 batchs: 1289.623779296875
INFO:root:Train (Epoch 53): Loss/seq after 00100 batchs: 1320.935302734375
INFO:root:Train (Epoch 53): Loss/seq after 00150 batchs: 1201.67529296875
INFO:root:Train (Epoch 53): Loss/seq after 00200 batchs: 1296.1690673828125
INFO:root:Train (Epoch 53): Loss/seq after 00250 batchs: 1442.1141357421875
INFO:root:Train (Epoch 53): Loss/seq after 00300 batchs: 1383.8883056640625
INFO:root:Train (Epoch 53): Loss/seq after 00350 batchs: 1296.4810791015625
INFO:root:Train (Epoch 53): Loss/seq after 00400 batchs: 1317.8409423828125
INFO:root:Train (Epoch 53): Loss/seq after 00450 batchs: 1267.9727783203125
INFO:root:Train (Epoch 53): Loss/seq after 00500 batchs: 1274.7943115234375
INFO:root:Train (Epoch 53): Loss/seq after 00550 batchs: 1225.5631103515625
INFO:root:Train (Epoch 53): Loss/seq after 00600 batchs: 1197.2379150390625
INFO:root:Train (Epoch 53): Loss/seq after 00650 batchs: 1198.786865234375
INFO:root:Train (Epoch 53): Loss/seq after 00700 batchs: 1170.8341064453125
INFO:root:Train (Epoch 53): Loss/seq after 00750 batchs: 1196.2879638671875
INFO:root:Train (Epoch 53): Loss/seq after 00800 batchs: 1192.5093994140625
INFO:root:Train (Epoch 53): Loss/seq after 00850 batchs: 1170.757568359375
INFO:root:Train (Epoch 53): Loss/seq after 00900 batchs: 1182.2529296875
INFO:root:Train (Epoch 53): Loss/seq after 00950 batchs: 1196.8131103515625
INFO:root:Train (Epoch 53): Loss/seq after 01000 batchs: 1189.11767578125
INFO:root:Train (Epoch 53): Loss/seq after 01050 batchs: 1172.9556884765625
INFO:root:Train (Epoch 53): Loss/seq after 01100 batchs: 1169.3956298828125
INFO:root:Train (Epoch 53): Loss/seq after 01150 batchs: 1159.4105224609375
INFO:root:Train (Epoch 53): Loss/seq after 01200 batchs: 1153.725830078125
INFO:root:Train (Epoch 53): Loss/seq after 01250 batchs: 1146.633544921875
INFO:root:Train (Epoch 53): Loss/seq after 01300 batchs: 1142.9639892578125
INFO:root:Train (Epoch 53): Loss/seq after 01350 batchs: 1143.2061767578125
INFO:root:Train (Epoch 53): Loss/seq after 01400 batchs: 1153.244140625
INFO:root:Train (Epoch 53): Loss/seq after 01450 batchs: 1147.924072265625
INFO:root:Train (Epoch 53): Loss/seq after 01500 batchs: 1144.073486328125
INFO:root:Train (Epoch 53): Loss/seq after 01550 batchs: 1145.9515380859375
INFO:root:Train (Epoch 53): Loss/seq after 01600 batchs: 1133.9107666015625
INFO:root:Train (Epoch 53): Loss/seq after 01650 batchs: 1127.251220703125
INFO:root:Train (Epoch 53): Loss/seq after 01700 batchs: 1123.2828369140625
INFO:root:Train (Epoch 53): Loss/seq after 01750 batchs: 1116.711181640625
INFO:root:Train (Epoch 53): Loss/seq after 01800 batchs: 1107.350830078125
INFO:root:Train (Epoch 53): Loss/seq after 01850 batchs: 1097.8223876953125
INFO:root:Train (Epoch 53): Loss/seq after 01900 batchs: 1098.8941650390625
INFO:root:Train (Epoch 53): Loss/seq after 01950 batchs: 1094.879638671875
INFO:root:Train (Epoch 53): Loss/seq after 02000 batchs: 1088.98876953125
INFO:root:Train (Epoch 53): Loss/seq after 02050 batchs: 1083.6964111328125
INFO:root:Train (Epoch 53): Loss/seq after 02100 batchs: 1075.554931640625
INFO:root:Train (Epoch 53): Loss/seq after 02150 batchs: 1068.1881103515625
INFO:root:Train (Epoch 53): Loss/seq after 02200 batchs: 1060.1881103515625
INFO:root:Train (Epoch 53): Loss/seq after 02250 batchs: 1060.677734375
INFO:root:Train (Epoch 53): Loss/seq after 02300 batchs: 1066.721435546875
INFO:root:Train (Epoch 53): Loss/seq after 02350 batchs: 1059.6080322265625
INFO:root:Train (Epoch 53): Loss/seq after 02400 batchs: 1058.4451904296875
INFO:root:Train (Epoch 53): Loss/seq after 02450 batchs: 1048.9364013671875
INFO:root:Train (Epoch 53): Loss/seq after 02500 batchs: 1035.1357421875
INFO:root:Train (Epoch 53): Loss/seq after 02550 batchs: 1025.8719482421875
INFO:root:Train (Epoch 53): Loss/seq after 02600 batchs: 1025.939453125
INFO:root:Train (Epoch 53): Loss/seq after 02650 batchs: 1023.6987915039062
INFO:root:Train (Epoch 53): Loss/seq after 02700 batchs: 1020.5440063476562
INFO:root:Train (Epoch 53): Loss/seq after 02750 batchs: 1050.7236328125
INFO:root:Train (Epoch 53): Loss/seq after 02800 batchs: 1054.830078125
INFO:root:Train (Epoch 53): Loss/seq after 02850 batchs: 1052.179931640625
INFO:root:Train (Epoch 53): Loss/seq after 02900 batchs: 1051.09765625
INFO:root:Train (Epoch 53): Loss/seq after 02950 batchs: 1045.22021484375
INFO:root:Train (Epoch 53): Loss/seq after 03000 batchs: 1045.733154296875
INFO:root:Train (Epoch 53): Loss/seq after 03050 batchs: 1050.3609619140625
INFO:root:Train (Epoch 53): Loss/seq after 03100 batchs: 1059.1534423828125
INFO:root:Train (Epoch 53): Loss/seq after 03150 batchs: 1062.54296875
INFO:root:Train (Epoch 53): Loss/seq after 03200 batchs: 1067.1639404296875
INFO:root:Train (Epoch 53): Loss/seq after 03250 batchs: 1068.1824951171875
INFO:root:Train (Epoch 53): Loss/seq after 03300 batchs: 1066.84423828125
INFO:root:Train (Epoch 53): Loss/seq after 03350 batchs: 1066.9224853515625
INFO:root:Train (Epoch 53): Loss/seq after 03400 batchs: 1060.7357177734375
INFO:root:Train (Epoch 53): Loss/seq after 03450 batchs: 1056.17919921875
INFO:root:Train (Epoch 53): Loss/seq after 03500 batchs: 1056.393798828125
INFO:root:Train (Epoch 53): Loss/seq after 03550 batchs: 1051.6204833984375
INFO:root:Train (Epoch 53): Loss/seq after 03600 batchs: 1058.629150390625
INFO:root:Train (Epoch 53): Loss/seq after 03650 batchs: 1054.6353759765625
INFO:root:Train (Epoch 53): Loss/seq after 03700 batchs: 1055.5107421875
INFO:root:Train (Epoch 53): Loss/seq after 03750 batchs: 1057.48681640625
INFO:root:Train (Epoch 53): Loss/seq after 03800 batchs: 1052.37939453125
INFO:root:Train (Epoch 53): Loss/seq after 03850 batchs: 1049.5745849609375
INFO:root:Train (Epoch 53): Loss/seq after 03900 batchs: 1054.4644775390625
INFO:root:Train (Epoch 53): Loss/seq after 03950 batchs: 1057.7940673828125
INFO:root:Train (Epoch 53): Loss/seq after 04000 batchs: 1050.8397216796875
INFO:root:Train (Epoch 53): Loss/seq after 04050 batchs: 1044.859130859375
INFO:root:Train (Epoch 53): Loss/seq after 04100 batchs: 1040.12548828125
INFO:root:Train (Epoch 53): Loss/seq after 04150 batchs: 1036.314453125
INFO:root:Train (Epoch 53): Loss/seq after 04200 batchs: 1032.5413818359375
INFO:root:Train (Epoch 53): Loss/seq after 04250 batchs: 1029.763916015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 53): Loss/seq after 00000 batches: 918.5997924804688
INFO:root:# Valid (Epoch 53): Loss/seq after 00050 batches: 1101.6583251953125
INFO:root:# Valid (Epoch 53): Loss/seq after 00100 batches: 1379.279541015625
INFO:root:# Valid (Epoch 53): Loss/seq after 00150 batches: 1097.253173828125
INFO:root:# Valid (Epoch 53): Loss/seq after 00200 batches: 986.9409790039062
INFO:root:Artifacts: Make stick videos for epoch 53
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_53_on_20220413_193122.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_53_index_430_on_20220413_193122.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 54): Loss/seq after 00000 batchs: 1677.163818359375
INFO:root:Train (Epoch 54): Loss/seq after 00050 batchs: 1297.2288818359375
INFO:root:Train (Epoch 54): Loss/seq after 00100 batchs: 1287.2554931640625
INFO:root:Train (Epoch 54): Loss/seq after 00150 batchs: 1169.1593017578125
INFO:root:Train (Epoch 54): Loss/seq after 00200 batchs: 1267.4364013671875
INFO:root:Train (Epoch 54): Loss/seq after 00250 batchs: 1413.276123046875
INFO:root:Train (Epoch 54): Loss/seq after 00300 batchs: 1359.3497314453125
INFO:root:Train (Epoch 54): Loss/seq after 00350 batchs: 1275.9852294921875
INFO:root:Train (Epoch 54): Loss/seq after 00400 batchs: 1304.0616455078125
INFO:root:Train (Epoch 54): Loss/seq after 00450 batchs: 1256.63525390625
INFO:root:Train (Epoch 54): Loss/seq after 00500 batchs: 1264.9727783203125
INFO:root:Train (Epoch 54): Loss/seq after 00550 batchs: 1216.84521484375
INFO:root:Train (Epoch 54): Loss/seq after 00600 batchs: 1190.330078125
INFO:root:Train (Epoch 54): Loss/seq after 00650 batchs: 1193.1778564453125
INFO:root:Train (Epoch 54): Loss/seq after 00700 batchs: 1166.7080078125
INFO:root:Train (Epoch 54): Loss/seq after 00750 batchs: 1195.39697265625
INFO:root:Train (Epoch 54): Loss/seq after 00800 batchs: 1192.34716796875
INFO:root:Train (Epoch 54): Loss/seq after 00850 batchs: 1171.2567138671875
INFO:root:Train (Epoch 54): Loss/seq after 00900 batchs: 1184.1522216796875
INFO:root:Train (Epoch 54): Loss/seq after 00950 batchs: 1200.6253662109375
INFO:root:Train (Epoch 54): Loss/seq after 01000 batchs: 1195.281005859375
INFO:root:Train (Epoch 54): Loss/seq after 01050 batchs: 1178.390380859375
INFO:root:Train (Epoch 54): Loss/seq after 01100 batchs: 1175.8304443359375
INFO:root:Train (Epoch 54): Loss/seq after 01150 batchs: 1165.56396484375
INFO:root:Train (Epoch 54): Loss/seq after 01200 batchs: 1159.7869873046875
INFO:root:Train (Epoch 54): Loss/seq after 01250 batchs: 1153.58642578125
INFO:root:Train (Epoch 54): Loss/seq after 01300 batchs: 1150.4981689453125
INFO:root:Train (Epoch 54): Loss/seq after 01350 batchs: 1150.5887451171875
INFO:root:Train (Epoch 54): Loss/seq after 01400 batchs: 1162.4136962890625
INFO:root:Train (Epoch 54): Loss/seq after 01450 batchs: 1157.2421875
INFO:root:Train (Epoch 54): Loss/seq after 01500 batchs: 1153.2001953125
INFO:root:Train (Epoch 54): Loss/seq after 01550 batchs: 1154.958251953125
INFO:root:Train (Epoch 54): Loss/seq after 01600 batchs: 1142.6539306640625
INFO:root:Train (Epoch 54): Loss/seq after 01650 batchs: 1134.8648681640625
INFO:root:Train (Epoch 54): Loss/seq after 01700 batchs: 1130.1431884765625
INFO:root:Train (Epoch 54): Loss/seq after 01750 batchs: 1123.0897216796875
INFO:root:Train (Epoch 54): Loss/seq after 01800 batchs: 1113.2720947265625
INFO:root:Train (Epoch 54): Loss/seq after 01850 batchs: 1103.52197265625
INFO:root:Train (Epoch 54): Loss/seq after 01900 batchs: 1104.818115234375
INFO:root:Train (Epoch 54): Loss/seq after 01950 batchs: 1101.4517822265625
INFO:root:Train (Epoch 54): Loss/seq after 02000 batchs: 1095.411865234375
INFO:root:Train (Epoch 54): Loss/seq after 02050 batchs: 1089.962646484375
INFO:root:Train (Epoch 54): Loss/seq after 02100 batchs: 1081.66357421875
INFO:root:Train (Epoch 54): Loss/seq after 02150 batchs: 1074.0740966796875
INFO:root:Train (Epoch 54): Loss/seq after 02200 batchs: 1065.9288330078125
INFO:root:Train (Epoch 54): Loss/seq after 02250 batchs: 1067.02587890625
INFO:root:Train (Epoch 54): Loss/seq after 02300 batchs: 1072.9171142578125
INFO:root:Train (Epoch 54): Loss/seq after 02350 batchs: 1065.4559326171875
INFO:root:Train (Epoch 54): Loss/seq after 02400 batchs: 1063.3834228515625
INFO:root:Train (Epoch 54): Loss/seq after 02450 batchs: 1053.3436279296875
INFO:root:Train (Epoch 54): Loss/seq after 02500 batchs: 1039.4420166015625
INFO:root:Train (Epoch 54): Loss/seq after 02550 batchs: 1030.441162109375
INFO:root:Train (Epoch 54): Loss/seq after 02600 batchs: 1030.208251953125
INFO:root:Train (Epoch 54): Loss/seq after 02650 batchs: 1027.6395263671875
INFO:root:Train (Epoch 54): Loss/seq after 02700 batchs: 1024.355224609375
INFO:root:Train (Epoch 54): Loss/seq after 02750 batchs: 1054.2279052734375
INFO:root:Train (Epoch 54): Loss/seq after 02800 batchs: 1057.206298828125
INFO:root:Train (Epoch 54): Loss/seq after 02850 batchs: 1054.551025390625
INFO:root:Train (Epoch 54): Loss/seq after 02900 batchs: 1053.27783203125
INFO:root:Train (Epoch 54): Loss/seq after 02950 batchs: 1047.0657958984375
INFO:root:Train (Epoch 54): Loss/seq after 03000 batchs: 1047.5203857421875
INFO:root:Train (Epoch 54): Loss/seq after 03050 batchs: 1052.0455322265625
INFO:root:Train (Epoch 54): Loss/seq after 03100 batchs: 1060.579345703125
INFO:root:Train (Epoch 54): Loss/seq after 03150 batchs: 1063.5987548828125
INFO:root:Train (Epoch 54): Loss/seq after 03200 batchs: 1068.050048828125
INFO:root:Train (Epoch 54): Loss/seq after 03250 batchs: 1069.30908203125
INFO:root:Train (Epoch 54): Loss/seq after 03300 batchs: 1066.867431640625
INFO:root:Train (Epoch 54): Loss/seq after 03350 batchs: 1066.4068603515625
INFO:root:Train (Epoch 54): Loss/seq after 03400 batchs: 1060.0291748046875
INFO:root:Train (Epoch 54): Loss/seq after 03450 batchs: 1054.536376953125
INFO:root:Train (Epoch 54): Loss/seq after 03500 batchs: 1054.4385986328125
INFO:root:Train (Epoch 54): Loss/seq after 03550 batchs: 1048.9627685546875
INFO:root:Train (Epoch 54): Loss/seq after 03600 batchs: 1055.8638916015625
INFO:root:Train (Epoch 54): Loss/seq after 03650 batchs: 1051.3302001953125
INFO:root:Train (Epoch 54): Loss/seq after 03700 batchs: 1051.9500732421875
INFO:root:Train (Epoch 54): Loss/seq after 03750 batchs: 1054.02197265625
INFO:root:Train (Epoch 54): Loss/seq after 03800 batchs: 1048.89208984375
INFO:root:Train (Epoch 54): Loss/seq after 03850 batchs: 1046.0616455078125
INFO:root:Train (Epoch 54): Loss/seq after 03900 batchs: 1049.9464111328125
INFO:root:Train (Epoch 54): Loss/seq after 03950 batchs: 1053.1878662109375
INFO:root:Train (Epoch 54): Loss/seq after 04000 batchs: 1046.2720947265625
INFO:root:Train (Epoch 54): Loss/seq after 04050 batchs: 1040.28515625
INFO:root:Train (Epoch 54): Loss/seq after 04100 batchs: 1035.3424072265625
INFO:root:Train (Epoch 54): Loss/seq after 04150 batchs: 1031.408203125
INFO:root:Train (Epoch 54): Loss/seq after 04200 batchs: 1027.539306640625
INFO:root:Train (Epoch 54): Loss/seq after 04250 batchs: 1024.6400146484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 54): Loss/seq after 00000 batches: 862.6319580078125
INFO:root:# Valid (Epoch 54): Loss/seq after 00050 batches: 1114.3521728515625
INFO:root:# Valid (Epoch 54): Loss/seq after 00100 batches: 1406.4119873046875
INFO:root:# Valid (Epoch 54): Loss/seq after 00150 batches: 1127.1881103515625
INFO:root:# Valid (Epoch 54): Loss/seq after 00200 batches: 1015.9248046875
INFO:root:Artifacts: Make stick videos for epoch 54
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_54_on_20220413_193639.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_54_index_544_on_20220413_193639.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 55): Loss/seq after 00000 batchs: 1815.1318359375
INFO:root:Train (Epoch 55): Loss/seq after 00050 batchs: 1299.079345703125
INFO:root:Train (Epoch 55): Loss/seq after 00100 batchs: 1283.16455078125
INFO:root:Train (Epoch 55): Loss/seq after 00150 batchs: 1170.645263671875
INFO:root:Train (Epoch 55): Loss/seq after 00200 batchs: 1279.357666015625
INFO:root:Train (Epoch 55): Loss/seq after 00250 batchs: 1422.235107421875
INFO:root:Train (Epoch 55): Loss/seq after 00300 batchs: 1366.7327880859375
INFO:root:Train (Epoch 55): Loss/seq after 00350 batchs: 1281.1041259765625
INFO:root:Train (Epoch 55): Loss/seq after 00400 batchs: 1300.3995361328125
INFO:root:Train (Epoch 55): Loss/seq after 00450 batchs: 1252.3770751953125
INFO:root:Train (Epoch 55): Loss/seq after 00500 batchs: 1255.2296142578125
INFO:root:Train (Epoch 55): Loss/seq after 00550 batchs: 1207.4217529296875
INFO:root:Train (Epoch 55): Loss/seq after 00600 batchs: 1177.5181884765625
INFO:root:Train (Epoch 55): Loss/seq after 00650 batchs: 1183.697265625
INFO:root:Train (Epoch 55): Loss/seq after 00700 batchs: 1159.1185302734375
INFO:root:Train (Epoch 55): Loss/seq after 00750 batchs: 1183.9422607421875
INFO:root:Train (Epoch 55): Loss/seq after 00800 batchs: 1177.2852783203125
INFO:root:Train (Epoch 55): Loss/seq after 00850 batchs: 1156.029296875
INFO:root:Train (Epoch 55): Loss/seq after 00900 batchs: 1167.0142822265625
INFO:root:Train (Epoch 55): Loss/seq after 00950 batchs: 1182.5733642578125
INFO:root:Train (Epoch 55): Loss/seq after 01000 batchs: 1175.1820068359375
INFO:root:Train (Epoch 55): Loss/seq after 01050 batchs: 1161.5654296875
INFO:root:Train (Epoch 55): Loss/seq after 01100 batchs: 1159.123779296875
INFO:root:Train (Epoch 55): Loss/seq after 01150 batchs: 1149.467529296875
INFO:root:Train (Epoch 55): Loss/seq after 01200 batchs: 1143.706787109375
INFO:root:Train (Epoch 55): Loss/seq after 01250 batchs: 1137.935546875
INFO:root:Train (Epoch 55): Loss/seq after 01300 batchs: 1134.72802734375
INFO:root:Train (Epoch 55): Loss/seq after 01350 batchs: 1133.5474853515625
INFO:root:Train (Epoch 55): Loss/seq after 01400 batchs: 1145.605224609375
INFO:root:Train (Epoch 55): Loss/seq after 01450 batchs: 1140.1728515625
INFO:root:Train (Epoch 55): Loss/seq after 01500 batchs: 1136.5296630859375
INFO:root:Train (Epoch 55): Loss/seq after 01550 batchs: 1138.7950439453125
INFO:root:Train (Epoch 55): Loss/seq after 01600 batchs: 1126.994140625
INFO:root:Train (Epoch 55): Loss/seq after 01650 batchs: 1120.126708984375
INFO:root:Train (Epoch 55): Loss/seq after 01700 batchs: 1114.8760986328125
INFO:root:Train (Epoch 55): Loss/seq after 01750 batchs: 1108.010986328125
INFO:root:Train (Epoch 55): Loss/seq after 01800 batchs: 1098.506103515625
INFO:root:Train (Epoch 55): Loss/seq after 01850 batchs: 1088.84765625
INFO:root:Train (Epoch 55): Loss/seq after 01900 batchs: 1089.393310546875
INFO:root:Train (Epoch 55): Loss/seq after 01950 batchs: 1085.0767822265625
INFO:root:Train (Epoch 55): Loss/seq after 02000 batchs: 1079.110107421875
INFO:root:Train (Epoch 55): Loss/seq after 02050 batchs: 1073.94287109375
INFO:root:Train (Epoch 55): Loss/seq after 02100 batchs: 1066.1378173828125
INFO:root:Train (Epoch 55): Loss/seq after 02150 batchs: 1058.8089599609375
INFO:root:Train (Epoch 55): Loss/seq after 02200 batchs: 1050.941650390625
INFO:root:Train (Epoch 55): Loss/seq after 02250 batchs: 1051.703125
INFO:root:Train (Epoch 55): Loss/seq after 02300 batchs: 1058.0836181640625
INFO:root:Train (Epoch 55): Loss/seq after 02350 batchs: 1050.360107421875
INFO:root:Train (Epoch 55): Loss/seq after 02400 batchs: 1048.535888671875
INFO:root:Train (Epoch 55): Loss/seq after 02450 batchs: 1038.580810546875
INFO:root:Train (Epoch 55): Loss/seq after 02500 batchs: 1024.942138671875
INFO:root:Train (Epoch 55): Loss/seq after 02550 batchs: 1015.6605834960938
INFO:root:Train (Epoch 55): Loss/seq after 02600 batchs: 1016.3135986328125
INFO:root:Train (Epoch 55): Loss/seq after 02650 batchs: 1014.1829223632812
INFO:root:Train (Epoch 55): Loss/seq after 02700 batchs: 1011.3119506835938
INFO:root:Train (Epoch 55): Loss/seq after 02750 batchs: 1042.0789794921875
INFO:root:Train (Epoch 55): Loss/seq after 02800 batchs: 1046.4259033203125
INFO:root:Train (Epoch 55): Loss/seq after 02850 batchs: 1043.8433837890625
INFO:root:Train (Epoch 55): Loss/seq after 02900 batchs: 1042.5970458984375
INFO:root:Train (Epoch 55): Loss/seq after 02950 batchs: 1036.5765380859375
INFO:root:Train (Epoch 55): Loss/seq after 03000 batchs: 1037.1976318359375
INFO:root:Train (Epoch 55): Loss/seq after 03050 batchs: 1041.8648681640625
INFO:root:Train (Epoch 55): Loss/seq after 03100 batchs: 1049.8599853515625
INFO:root:Train (Epoch 55): Loss/seq after 03150 batchs: 1055.1217041015625
INFO:root:Train (Epoch 55): Loss/seq after 03200 batchs: 1059.52685546875
INFO:root:Train (Epoch 55): Loss/seq after 03250 batchs: 1061.024169921875
INFO:root:Train (Epoch 55): Loss/seq after 03300 batchs: 1058.930908203125
INFO:root:Train (Epoch 55): Loss/seq after 03350 batchs: 1057.5364990234375
INFO:root:Train (Epoch 55): Loss/seq after 03400 batchs: 1051.370361328125
INFO:root:Train (Epoch 55): Loss/seq after 03450 batchs: 1045.8685302734375
INFO:root:Train (Epoch 55): Loss/seq after 03500 batchs: 1045.4158935546875
INFO:root:Train (Epoch 55): Loss/seq after 03550 batchs: 1039.938720703125
INFO:root:Train (Epoch 55): Loss/seq after 03600 batchs: 1046.9091796875
INFO:root:Train (Epoch 55): Loss/seq after 03650 batchs: 1042.386474609375
INFO:root:Train (Epoch 55): Loss/seq after 03700 batchs: 1043.416259765625
INFO:root:Train (Epoch 55): Loss/seq after 03750 batchs: 1045.5418701171875
INFO:root:Train (Epoch 55): Loss/seq after 03800 batchs: 1040.53759765625
INFO:root:Train (Epoch 55): Loss/seq after 03850 batchs: 1037.823974609375
INFO:root:Train (Epoch 55): Loss/seq after 03900 batchs: 1041.654052734375
INFO:root:Train (Epoch 55): Loss/seq after 03950 batchs: 1045.011962890625
INFO:root:Train (Epoch 55): Loss/seq after 04000 batchs: 1038.2213134765625
INFO:root:Train (Epoch 55): Loss/seq after 04050 batchs: 1032.3648681640625
INFO:root:Train (Epoch 55): Loss/seq after 04100 batchs: 1027.58837890625
INFO:root:Train (Epoch 55): Loss/seq after 04150 batchs: 1023.74658203125
INFO:root:Train (Epoch 55): Loss/seq after 04200 batchs: 1019.9886474609375
INFO:root:Train (Epoch 55): Loss/seq after 04250 batchs: 1017.2750244140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 55): Loss/seq after 00000 batches: 882.9806518554688
INFO:root:# Valid (Epoch 55): Loss/seq after 00050 batches: 1101.7255859375
INFO:root:# Valid (Epoch 55): Loss/seq after 00100 batches: 1383.745361328125
INFO:root:# Valid (Epoch 55): Loss/seq after 00150 batches: 1106.137451171875
INFO:root:# Valid (Epoch 55): Loss/seq after 00200 batches: 996.2188110351562
INFO:root:Artifacts: Make stick videos for epoch 55
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_55_on_20220413_194157.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_55_index_1193_on_20220413_194157.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 56): Loss/seq after 00000 batchs: 1647.4810791015625
INFO:root:Train (Epoch 56): Loss/seq after 00050 batchs: 1272.8846435546875
INFO:root:Train (Epoch 56): Loss/seq after 00100 batchs: 1310.684326171875
INFO:root:Train (Epoch 56): Loss/seq after 00150 batchs: 1190.644775390625
INFO:root:Train (Epoch 56): Loss/seq after 00200 batchs: 1290.8125
INFO:root:Train (Epoch 56): Loss/seq after 00250 batchs: 1431.926513671875
INFO:root:Train (Epoch 56): Loss/seq after 00300 batchs: 1376.59912109375
INFO:root:Train (Epoch 56): Loss/seq after 00350 batchs: 1291.445556640625
INFO:root:Train (Epoch 56): Loss/seq after 00400 batchs: 1312.8568115234375
INFO:root:Train (Epoch 56): Loss/seq after 00450 batchs: 1264.2232666015625
INFO:root:Train (Epoch 56): Loss/seq after 00500 batchs: 1265.0787353515625
INFO:root:Train (Epoch 56): Loss/seq after 00550 batchs: 1217.501220703125
INFO:root:Train (Epoch 56): Loss/seq after 00600 batchs: 1186.8470458984375
INFO:root:Train (Epoch 56): Loss/seq after 00650 batchs: 1193.0174560546875
INFO:root:Train (Epoch 56): Loss/seq after 00700 batchs: 1168.5302734375
INFO:root:Train (Epoch 56): Loss/seq after 00750 batchs: 1193.43359375
INFO:root:Train (Epoch 56): Loss/seq after 00800 batchs: 1187.7921142578125
INFO:root:Train (Epoch 56): Loss/seq after 00850 batchs: 1165.9715576171875
INFO:root:Train (Epoch 56): Loss/seq after 00900 batchs: 1177.8358154296875
INFO:root:Train (Epoch 56): Loss/seq after 00950 batchs: 1187.566650390625
INFO:root:Train (Epoch 56): Loss/seq after 01000 batchs: 1178.6141357421875
INFO:root:Train (Epoch 56): Loss/seq after 01050 batchs: 1163.803955078125
INFO:root:Train (Epoch 56): Loss/seq after 01100 batchs: 1161.6533203125
INFO:root:Train (Epoch 56): Loss/seq after 01150 batchs: 1151.95263671875
INFO:root:Train (Epoch 56): Loss/seq after 01200 batchs: 1146.6634521484375
INFO:root:Train (Epoch 56): Loss/seq after 01250 batchs: 1139.9493408203125
INFO:root:Train (Epoch 56): Loss/seq after 01300 batchs: 1136.124755859375
INFO:root:Train (Epoch 56): Loss/seq after 01350 batchs: 1134.8302001953125
INFO:root:Train (Epoch 56): Loss/seq after 01400 batchs: 1145.076416015625
INFO:root:Train (Epoch 56): Loss/seq after 01450 batchs: 1140.2802734375
INFO:root:Train (Epoch 56): Loss/seq after 01500 batchs: 1137.11181640625
INFO:root:Train (Epoch 56): Loss/seq after 01550 batchs: 1140.65576171875
INFO:root:Train (Epoch 56): Loss/seq after 01600 batchs: 1128.8162841796875
INFO:root:Train (Epoch 56): Loss/seq after 01650 batchs: 1121.4669189453125
INFO:root:Train (Epoch 56): Loss/seq after 01700 batchs: 1116.3504638671875
INFO:root:Train (Epoch 56): Loss/seq after 01750 batchs: 1109.39306640625
INFO:root:Train (Epoch 56): Loss/seq after 01800 batchs: 1099.8492431640625
INFO:root:Train (Epoch 56): Loss/seq after 01850 batchs: 1090.1798095703125
INFO:root:Train (Epoch 56): Loss/seq after 01900 batchs: 1090.427734375
INFO:root:Train (Epoch 56): Loss/seq after 01950 batchs: 1086.6966552734375
INFO:root:Train (Epoch 56): Loss/seq after 02000 batchs: 1081.0350341796875
INFO:root:Train (Epoch 56): Loss/seq after 02050 batchs: 1075.9337158203125
INFO:root:Train (Epoch 56): Loss/seq after 02100 batchs: 1068.212890625
INFO:root:Train (Epoch 56): Loss/seq after 02150 batchs: 1060.8892822265625
INFO:root:Train (Epoch 56): Loss/seq after 02200 batchs: 1053.072265625
INFO:root:Train (Epoch 56): Loss/seq after 02250 batchs: 1054.053466796875
INFO:root:Train (Epoch 56): Loss/seq after 02300 batchs: 1060.25341796875
INFO:root:Train (Epoch 56): Loss/seq after 02350 batchs: 1052.70849609375
INFO:root:Train (Epoch 56): Loss/seq after 02400 batchs: 1050.7115478515625
INFO:root:Train (Epoch 56): Loss/seq after 02450 batchs: 1040.642822265625
INFO:root:Train (Epoch 56): Loss/seq after 02500 batchs: 1026.9964599609375
INFO:root:Train (Epoch 56): Loss/seq after 02550 batchs: 1017.9535522460938
INFO:root:Train (Epoch 56): Loss/seq after 02600 batchs: 1018.1691284179688
INFO:root:Train (Epoch 56): Loss/seq after 02650 batchs: 1015.9713134765625
INFO:root:Train (Epoch 56): Loss/seq after 02700 batchs: 1012.951171875
INFO:root:Train (Epoch 56): Loss/seq after 02750 batchs: 1042.7757568359375
INFO:root:Train (Epoch 56): Loss/seq after 02800 batchs: 1046.8709716796875
INFO:root:Train (Epoch 56): Loss/seq after 02850 batchs: 1044.26513671875
INFO:root:Train (Epoch 56): Loss/seq after 02900 batchs: 1043.0096435546875
INFO:root:Train (Epoch 56): Loss/seq after 02950 batchs: 1037.069091796875
INFO:root:Train (Epoch 56): Loss/seq after 03000 batchs: 1037.697509765625
INFO:root:Train (Epoch 56): Loss/seq after 03050 batchs: 1042.431396484375
INFO:root:Train (Epoch 56): Loss/seq after 03100 batchs: 1051.22705078125
INFO:root:Train (Epoch 56): Loss/seq after 03150 batchs: 1053.74560546875
INFO:root:Train (Epoch 56): Loss/seq after 03200 batchs: 1058.3492431640625
INFO:root:Train (Epoch 56): Loss/seq after 03250 batchs: 1060.06884765625
INFO:root:Train (Epoch 56): Loss/seq after 03300 batchs: 1058.23681640625
INFO:root:Train (Epoch 56): Loss/seq after 03350 batchs: 1058.2708740234375
INFO:root:Train (Epoch 56): Loss/seq after 03400 batchs: 1052.4278564453125
INFO:root:Train (Epoch 56): Loss/seq after 03450 batchs: 1048.3846435546875
INFO:root:Train (Epoch 56): Loss/seq after 03500 batchs: 1048.76708984375
INFO:root:Train (Epoch 56): Loss/seq after 03550 batchs: 1043.96435546875
INFO:root:Train (Epoch 56): Loss/seq after 03600 batchs: 1051.1151123046875
INFO:root:Train (Epoch 56): Loss/seq after 03650 batchs: 1046.74365234375
INFO:root:Train (Epoch 56): Loss/seq after 03700 batchs: 1048.59912109375
INFO:root:Train (Epoch 56): Loss/seq after 03750 batchs: 1050.6781005859375
INFO:root:Train (Epoch 56): Loss/seq after 03800 batchs: 1045.7769775390625
INFO:root:Train (Epoch 56): Loss/seq after 03850 batchs: 1043.1107177734375
INFO:root:Train (Epoch 56): Loss/seq after 03900 batchs: 1046.6591796875
INFO:root:Train (Epoch 56): Loss/seq after 03950 batchs: 1049.863525390625
INFO:root:Train (Epoch 56): Loss/seq after 04000 batchs: 1043.0107421875
INFO:root:Train (Epoch 56): Loss/seq after 04050 batchs: 1037.0684814453125
INFO:root:Train (Epoch 56): Loss/seq after 04100 batchs: 1032.342041015625
INFO:root:Train (Epoch 56): Loss/seq after 04150 batchs: 1028.3709716796875
INFO:root:Train (Epoch 56): Loss/seq after 04200 batchs: 1024.3583984375
INFO:root:Train (Epoch 56): Loss/seq after 04250 batchs: 1021.5577392578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 56): Loss/seq after 00000 batches: 882.3897094726562
INFO:root:# Valid (Epoch 56): Loss/seq after 00050 batches: 1096.101806640625
INFO:root:# Valid (Epoch 56): Loss/seq after 00100 batches: 1381.063232421875
INFO:root:# Valid (Epoch 56): Loss/seq after 00150 batches: 1106.9202880859375
INFO:root:# Valid (Epoch 56): Loss/seq after 00200 batches: 997.3140869140625
INFO:root:Artifacts: Make stick videos for epoch 56
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_56_on_20220413_194715.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_56_index_1236_on_20220413_194715.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 57): Loss/seq after 00000 batchs: 1551.007080078125
INFO:root:Train (Epoch 57): Loss/seq after 00050 batchs: 1255.7994384765625
INFO:root:Train (Epoch 57): Loss/seq after 00100 batchs: 1275.3687744140625
INFO:root:Train (Epoch 57): Loss/seq after 00150 batchs: 1162.9432373046875
INFO:root:Train (Epoch 57): Loss/seq after 00200 batchs: 1266.54248046875
INFO:root:Train (Epoch 57): Loss/seq after 00250 batchs: 1408.623779296875
INFO:root:Train (Epoch 57): Loss/seq after 00300 batchs: 1354.989013671875
INFO:root:Train (Epoch 57): Loss/seq after 00350 batchs: 1273.097412109375
INFO:root:Train (Epoch 57): Loss/seq after 00400 batchs: 1296.022216796875
INFO:root:Train (Epoch 57): Loss/seq after 00450 batchs: 1248.9967041015625
INFO:root:Train (Epoch 57): Loss/seq after 00500 batchs: 1248.4866943359375
INFO:root:Train (Epoch 57): Loss/seq after 00550 batchs: 1201.4180908203125
INFO:root:Train (Epoch 57): Loss/seq after 00600 batchs: 1174.9515380859375
INFO:root:Train (Epoch 57): Loss/seq after 00650 batchs: 1178.7470703125
INFO:root:Train (Epoch 57): Loss/seq after 00700 batchs: 1151.125244140625
INFO:root:Train (Epoch 57): Loss/seq after 00750 batchs: 1181.2344970703125
INFO:root:Train (Epoch 57): Loss/seq after 00800 batchs: 1178.1923828125
INFO:root:Train (Epoch 57): Loss/seq after 00850 batchs: 1157.2867431640625
INFO:root:Train (Epoch 57): Loss/seq after 00900 batchs: 1172.7418212890625
INFO:root:Train (Epoch 57): Loss/seq after 00950 batchs: 1183.75927734375
INFO:root:Train (Epoch 57): Loss/seq after 01000 batchs: 1176.499267578125
INFO:root:Train (Epoch 57): Loss/seq after 01050 batchs: 1162.750732421875
INFO:root:Train (Epoch 57): Loss/seq after 01100 batchs: 1161.3681640625
INFO:root:Train (Epoch 57): Loss/seq after 01150 batchs: 1153.360107421875
INFO:root:Train (Epoch 57): Loss/seq after 01200 batchs: 1150.419189453125
INFO:root:Train (Epoch 57): Loss/seq after 01250 batchs: 1144.5811767578125
INFO:root:Train (Epoch 57): Loss/seq after 01300 batchs: 1141.3427734375
INFO:root:Train (Epoch 57): Loss/seq after 01350 batchs: 1140.486572265625
INFO:root:Train (Epoch 57): Loss/seq after 01400 batchs: 1152.4068603515625
INFO:root:Train (Epoch 57): Loss/seq after 01450 batchs: 1147.6744384765625
INFO:root:Train (Epoch 57): Loss/seq after 01500 batchs: 1144.107666015625
INFO:root:Train (Epoch 57): Loss/seq after 01550 batchs: 1146.956787109375
INFO:root:Train (Epoch 57): Loss/seq after 01600 batchs: 1134.6866455078125
INFO:root:Train (Epoch 57): Loss/seq after 01650 batchs: 1128.197998046875
INFO:root:Train (Epoch 57): Loss/seq after 01700 batchs: 1122.7203369140625
INFO:root:Train (Epoch 57): Loss/seq after 01750 batchs: 1115.7237548828125
INFO:root:Train (Epoch 57): Loss/seq after 01800 batchs: 1106.0379638671875
INFO:root:Train (Epoch 57): Loss/seq after 01850 batchs: 1096.156982421875
INFO:root:Train (Epoch 57): Loss/seq after 01900 batchs: 1096.3189697265625
INFO:root:Train (Epoch 57): Loss/seq after 01950 batchs: 1091.8197021484375
INFO:root:Train (Epoch 57): Loss/seq after 02000 batchs: 1085.7669677734375
INFO:root:Train (Epoch 57): Loss/seq after 02050 batchs: 1080.332763671875
INFO:root:Train (Epoch 57): Loss/seq after 02100 batchs: 1072.1746826171875
INFO:root:Train (Epoch 57): Loss/seq after 02150 batchs: 1064.692138671875
INFO:root:Train (Epoch 57): Loss/seq after 02200 batchs: 1056.704833984375
INFO:root:Train (Epoch 57): Loss/seq after 02250 batchs: 1058.8499755859375
INFO:root:Train (Epoch 57): Loss/seq after 02300 batchs: 1065.3804931640625
INFO:root:Train (Epoch 57): Loss/seq after 02350 batchs: 1058.7755126953125
INFO:root:Train (Epoch 57): Loss/seq after 02400 batchs: 1056.7242431640625
INFO:root:Train (Epoch 57): Loss/seq after 02450 batchs: 1046.7669677734375
INFO:root:Train (Epoch 57): Loss/seq after 02500 batchs: 1032.9793701171875
INFO:root:Train (Epoch 57): Loss/seq after 02550 batchs: 1023.8460083007812
INFO:root:Train (Epoch 57): Loss/seq after 02600 batchs: 1023.9013671875
INFO:root:Train (Epoch 57): Loss/seq after 02650 batchs: 1021.4742431640625
INFO:root:Train (Epoch 57): Loss/seq after 02700 batchs: 1018.4602661132812
INFO:root:Train (Epoch 57): Loss/seq after 02750 batchs: 1048.99267578125
INFO:root:Train (Epoch 57): Loss/seq after 02800 batchs: 1052.0137939453125
INFO:root:Train (Epoch 57): Loss/seq after 02850 batchs: 1049.295654296875
INFO:root:Train (Epoch 57): Loss/seq after 02900 batchs: 1048.71044921875
INFO:root:Train (Epoch 57): Loss/seq after 02950 batchs: 1042.297607421875
INFO:root:Train (Epoch 57): Loss/seq after 03000 batchs: 1042.831787109375
INFO:root:Train (Epoch 57): Loss/seq after 03050 batchs: 1047.3994140625
INFO:root:Train (Epoch 57): Loss/seq after 03100 batchs: 1055.7557373046875
INFO:root:Train (Epoch 57): Loss/seq after 03150 batchs: 1058.4124755859375
INFO:root:Train (Epoch 57): Loss/seq after 03200 batchs: 1063.0029296875
INFO:root:Train (Epoch 57): Loss/seq after 03250 batchs: 1064.74755859375
INFO:root:Train (Epoch 57): Loss/seq after 03300 batchs: 1062.8382568359375
INFO:root:Train (Epoch 57): Loss/seq after 03350 batchs: 1061.255126953125
INFO:root:Train (Epoch 57): Loss/seq after 03400 batchs: 1054.9613037109375
INFO:root:Train (Epoch 57): Loss/seq after 03450 batchs: 1050.0062255859375
INFO:root:Train (Epoch 57): Loss/seq after 03500 batchs: 1049.9847412109375
INFO:root:Train (Epoch 57): Loss/seq after 03550 batchs: 1044.435546875
INFO:root:Train (Epoch 57): Loss/seq after 03600 batchs: 1051.2022705078125
INFO:root:Train (Epoch 57): Loss/seq after 03650 batchs: 1046.7379150390625
INFO:root:Train (Epoch 57): Loss/seq after 03700 batchs: 1047.451416015625
INFO:root:Train (Epoch 57): Loss/seq after 03750 batchs: 1049.5970458984375
INFO:root:Train (Epoch 57): Loss/seq after 03800 batchs: 1044.544921875
INFO:root:Train (Epoch 57): Loss/seq after 03850 batchs: 1041.7420654296875
INFO:root:Train (Epoch 57): Loss/seq after 03900 batchs: 1045.4473876953125
INFO:root:Train (Epoch 57): Loss/seq after 03950 batchs: 1048.8790283203125
INFO:root:Train (Epoch 57): Loss/seq after 04000 batchs: 1042.0113525390625
INFO:root:Train (Epoch 57): Loss/seq after 04050 batchs: 1036.0726318359375
INFO:root:Train (Epoch 57): Loss/seq after 04100 batchs: 1031.29248046875
INFO:root:Train (Epoch 57): Loss/seq after 04150 batchs: 1027.3670654296875
INFO:root:Train (Epoch 57): Loss/seq after 04200 batchs: 1023.5428466796875
INFO:root:Train (Epoch 57): Loss/seq after 04250 batchs: 1020.6755981445312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 57): Loss/seq after 00000 batches: 887.99853515625
INFO:root:# Valid (Epoch 57): Loss/seq after 00050 batches: 1110.6878662109375
INFO:root:# Valid (Epoch 57): Loss/seq after 00100 batches: 1391.5701904296875
INFO:root:# Valid (Epoch 57): Loss/seq after 00150 batches: 1114.8343505859375
INFO:root:# Valid (Epoch 57): Loss/seq after 00200 batches: 1003.9244995117188
INFO:root:Artifacts: Make stick videos for epoch 57
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_57_on_20220413_195231.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_57_index_784_on_20220413_195231.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 58): Loss/seq after 00000 batchs: 1413.6885986328125
INFO:root:Train (Epoch 58): Loss/seq after 00050 batchs: 1239.94775390625
INFO:root:Train (Epoch 58): Loss/seq after 00100 batchs: 1257.77294921875
INFO:root:Train (Epoch 58): Loss/seq after 00150 batchs: 1159.085693359375
INFO:root:Train (Epoch 58): Loss/seq after 00200 batchs: 1277.0638427734375
INFO:root:Train (Epoch 58): Loss/seq after 00250 batchs: 1426.7532958984375
INFO:root:Train (Epoch 58): Loss/seq after 00300 batchs: 1370.8843994140625
INFO:root:Train (Epoch 58): Loss/seq after 00350 batchs: 1289.5728759765625
INFO:root:Train (Epoch 58): Loss/seq after 00400 batchs: 1312.0540771484375
INFO:root:Train (Epoch 58): Loss/seq after 00450 batchs: 1263.049072265625
INFO:root:Train (Epoch 58): Loss/seq after 00500 batchs: 1263.45166015625
INFO:root:Train (Epoch 58): Loss/seq after 00550 batchs: 1215.4100341796875
INFO:root:Train (Epoch 58): Loss/seq after 00600 batchs: 1184.2542724609375
INFO:root:Train (Epoch 58): Loss/seq after 00650 batchs: 1187.7021484375
INFO:root:Train (Epoch 58): Loss/seq after 00700 batchs: 1159.9593505859375
INFO:root:Train (Epoch 58): Loss/seq after 00750 batchs: 1186.4278564453125
INFO:root:Train (Epoch 58): Loss/seq after 00800 batchs: 1180.9027099609375
INFO:root:Train (Epoch 58): Loss/seq after 00850 batchs: 1158.9429931640625
INFO:root:Train (Epoch 58): Loss/seq after 00900 batchs: 1171.25537109375
INFO:root:Train (Epoch 58): Loss/seq after 00950 batchs: 1181.44140625
INFO:root:Train (Epoch 58): Loss/seq after 01000 batchs: 1172.8023681640625
INFO:root:Train (Epoch 58): Loss/seq after 01050 batchs: 1156.372802734375
INFO:root:Train (Epoch 58): Loss/seq after 01100 batchs: 1154.31201171875
INFO:root:Train (Epoch 58): Loss/seq after 01150 batchs: 1144.9169921875
INFO:root:Train (Epoch 58): Loss/seq after 01200 batchs: 1139.483642578125
INFO:root:Train (Epoch 58): Loss/seq after 01250 batchs: 1132.9708251953125
INFO:root:Train (Epoch 58): Loss/seq after 01300 batchs: 1128.470703125
INFO:root:Train (Epoch 58): Loss/seq after 01350 batchs: 1125.8946533203125
INFO:root:Train (Epoch 58): Loss/seq after 01400 batchs: 1136.751220703125
INFO:root:Train (Epoch 58): Loss/seq after 01450 batchs: 1132.3775634765625
INFO:root:Train (Epoch 58): Loss/seq after 01500 batchs: 1129.1243896484375
INFO:root:Train (Epoch 58): Loss/seq after 01550 batchs: 1132.2679443359375
INFO:root:Train (Epoch 58): Loss/seq after 01600 batchs: 1120.589111328125
INFO:root:Train (Epoch 58): Loss/seq after 01650 batchs: 1114.0491943359375
INFO:root:Train (Epoch 58): Loss/seq after 01700 batchs: 1109.0888671875
INFO:root:Train (Epoch 58): Loss/seq after 01750 batchs: 1102.3814697265625
INFO:root:Train (Epoch 58): Loss/seq after 01800 batchs: 1093.05517578125
INFO:root:Train (Epoch 58): Loss/seq after 01850 batchs: 1083.463134765625
INFO:root:Train (Epoch 58): Loss/seq after 01900 batchs: 1083.4951171875
INFO:root:Train (Epoch 58): Loss/seq after 01950 batchs: 1079.0118408203125
INFO:root:Train (Epoch 58): Loss/seq after 02000 batchs: 1073.3336181640625
INFO:root:Train (Epoch 58): Loss/seq after 02050 batchs: 1068.3836669921875
INFO:root:Train (Epoch 58): Loss/seq after 02100 batchs: 1060.533203125
INFO:root:Train (Epoch 58): Loss/seq after 02150 batchs: 1053.2916259765625
INFO:root:Train (Epoch 58): Loss/seq after 02200 batchs: 1045.58544921875
INFO:root:Train (Epoch 58): Loss/seq after 02250 batchs: 1045.9852294921875
INFO:root:Train (Epoch 58): Loss/seq after 02300 batchs: 1053.1419677734375
INFO:root:Train (Epoch 58): Loss/seq after 02350 batchs: 1045.9071044921875
INFO:root:Train (Epoch 58): Loss/seq after 02400 batchs: 1044.4512939453125
INFO:root:Train (Epoch 58): Loss/seq after 02450 batchs: 1034.7830810546875
INFO:root:Train (Epoch 58): Loss/seq after 02500 batchs: 1021.2575073242188
INFO:root:Train (Epoch 58): Loss/seq after 02550 batchs: 1012.1542358398438
INFO:root:Train (Epoch 58): Loss/seq after 02600 batchs: 1012.49853515625
INFO:root:Train (Epoch 58): Loss/seq after 02650 batchs: 1010.221923828125
INFO:root:Train (Epoch 58): Loss/seq after 02700 batchs: 1007.3123168945312
INFO:root:Train (Epoch 58): Loss/seq after 02750 batchs: 1037.2801513671875
INFO:root:Train (Epoch 58): Loss/seq after 02800 batchs: 1040.063232421875
INFO:root:Train (Epoch 58): Loss/seq after 02850 batchs: 1037.78369140625
INFO:root:Train (Epoch 58): Loss/seq after 02900 batchs: 1036.561279296875
INFO:root:Train (Epoch 58): Loss/seq after 02950 batchs: 1030.7208251953125
INFO:root:Train (Epoch 58): Loss/seq after 03000 batchs: 1031.4425048828125
INFO:root:Train (Epoch 58): Loss/seq after 03050 batchs: 1036.25830078125
INFO:root:Train (Epoch 58): Loss/seq after 03100 batchs: 1043.8953857421875
INFO:root:Train (Epoch 58): Loss/seq after 03150 batchs: 1046.8812255859375
INFO:root:Train (Epoch 58): Loss/seq after 03200 batchs: 1051.7735595703125
INFO:root:Train (Epoch 58): Loss/seq after 03250 batchs: 1053.71533203125
INFO:root:Train (Epoch 58): Loss/seq after 03300 batchs: 1051.4459228515625
INFO:root:Train (Epoch 58): Loss/seq after 03350 batchs: 1049.9913330078125
INFO:root:Train (Epoch 58): Loss/seq after 03400 batchs: 1043.895751953125
INFO:root:Train (Epoch 58): Loss/seq after 03450 batchs: 1038.92138671875
INFO:root:Train (Epoch 58): Loss/seq after 03500 batchs: 1039.112060546875
INFO:root:Train (Epoch 58): Loss/seq after 03550 batchs: 1033.8802490234375
INFO:root:Train (Epoch 58): Loss/seq after 03600 batchs: 1040.889404296875
INFO:root:Train (Epoch 58): Loss/seq after 03650 batchs: 1036.9351806640625
INFO:root:Train (Epoch 58): Loss/seq after 03700 batchs: 1038.2642822265625
INFO:root:Train (Epoch 58): Loss/seq after 03750 batchs: 1040.5474853515625
INFO:root:Train (Epoch 58): Loss/seq after 03800 batchs: 1035.679443359375
INFO:root:Train (Epoch 58): Loss/seq after 03850 batchs: 1033.0189208984375
INFO:root:Train (Epoch 58): Loss/seq after 03900 batchs: 1036.66162109375
INFO:root:Train (Epoch 58): Loss/seq after 03950 batchs: 1039.980712890625
INFO:root:Train (Epoch 58): Loss/seq after 04000 batchs: 1033.2603759765625
INFO:root:Train (Epoch 58): Loss/seq after 04050 batchs: 1027.4769287109375
INFO:root:Train (Epoch 58): Loss/seq after 04100 batchs: 1022.97998046875
INFO:root:Train (Epoch 58): Loss/seq after 04150 batchs: 1019.1710205078125
INFO:root:Train (Epoch 58): Loss/seq after 04200 batchs: 1015.2509765625
INFO:root:Train (Epoch 58): Loss/seq after 04250 batchs: 1012.5792846679688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 58): Loss/seq after 00000 batches: 862.4699096679688
INFO:root:# Valid (Epoch 58): Loss/seq after 00050 batches: 1086.47119140625
INFO:root:# Valid (Epoch 58): Loss/seq after 00100 batches: 1367.867919921875
INFO:root:# Valid (Epoch 58): Loss/seq after 00150 batches: 1087.3868408203125
INFO:root:# Valid (Epoch 58): Loss/seq after 00200 batches: 979.825439453125
INFO:root:Artifacts: Make stick videos for epoch 58
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_58_on_20220413_195749.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_58_index_668_on_20220413_195749.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 59): Loss/seq after 00000 batchs: 1447.0736083984375
INFO:root:Train (Epoch 59): Loss/seq after 00050 batchs: 1222.2061767578125
INFO:root:Train (Epoch 59): Loss/seq after 00100 batchs: 1252.72802734375
INFO:root:Train (Epoch 59): Loss/seq after 00150 batchs: 1142.12744140625
INFO:root:Train (Epoch 59): Loss/seq after 00200 batchs: 1248.9210205078125
INFO:root:Train (Epoch 59): Loss/seq after 00250 batchs: 1389.7275390625
INFO:root:Train (Epoch 59): Loss/seq after 00300 batchs: 1339.2855224609375
INFO:root:Train (Epoch 59): Loss/seq after 00350 batchs: 1258.3079833984375
INFO:root:Train (Epoch 59): Loss/seq after 00400 batchs: 1276.7822265625
INFO:root:Train (Epoch 59): Loss/seq after 00450 batchs: 1231.58544921875
INFO:root:Train (Epoch 59): Loss/seq after 00500 batchs: 1238.07958984375
INFO:root:Train (Epoch 59): Loss/seq after 00550 batchs: 1192.07421875
INFO:root:Train (Epoch 59): Loss/seq after 00600 batchs: 1170.122802734375
INFO:root:Train (Epoch 59): Loss/seq after 00650 batchs: 1173.6314697265625
INFO:root:Train (Epoch 59): Loss/seq after 00700 batchs: 1148.1976318359375
INFO:root:Train (Epoch 59): Loss/seq after 00750 batchs: 1174.61767578125
INFO:root:Train (Epoch 59): Loss/seq after 00800 batchs: 1170.027099609375
INFO:root:Train (Epoch 59): Loss/seq after 00850 batchs: 1148.5673828125
INFO:root:Train (Epoch 59): Loss/seq after 00900 batchs: 1160.326171875
INFO:root:Train (Epoch 59): Loss/seq after 00950 batchs: 1172.80712890625
INFO:root:Train (Epoch 59): Loss/seq after 01000 batchs: 1168.1375732421875
INFO:root:Train (Epoch 59): Loss/seq after 01050 batchs: 1152.485107421875
INFO:root:Train (Epoch 59): Loss/seq after 01100 batchs: 1150.12158203125
INFO:root:Train (Epoch 59): Loss/seq after 01150 batchs: 1140.5399169921875
INFO:root:Train (Epoch 59): Loss/seq after 01200 batchs: 1135.1041259765625
INFO:root:Train (Epoch 59): Loss/seq after 01250 batchs: 1128.19677734375
INFO:root:Train (Epoch 59): Loss/seq after 01300 batchs: 1123.6390380859375
INFO:root:Train (Epoch 59): Loss/seq after 01350 batchs: 1122.209716796875
INFO:root:Train (Epoch 59): Loss/seq after 01400 batchs: 1133.6890869140625
INFO:root:Train (Epoch 59): Loss/seq after 01450 batchs: 1128.771728515625
INFO:root:Train (Epoch 59): Loss/seq after 01500 batchs: 1125.4996337890625
INFO:root:Train (Epoch 59): Loss/seq after 01550 batchs: 1127.924560546875
INFO:root:Train (Epoch 59): Loss/seq after 01600 batchs: 1116.665771484375
INFO:root:Train (Epoch 59): Loss/seq after 01650 batchs: 1110.0074462890625
INFO:root:Train (Epoch 59): Loss/seq after 01700 batchs: 1105.22119140625
INFO:root:Train (Epoch 59): Loss/seq after 01750 batchs: 1098.488525390625
INFO:root:Train (Epoch 59): Loss/seq after 01800 batchs: 1089.1558837890625
INFO:root:Train (Epoch 59): Loss/seq after 01850 batchs: 1079.6160888671875
INFO:root:Train (Epoch 59): Loss/seq after 01900 batchs: 1079.4532470703125
INFO:root:Train (Epoch 59): Loss/seq after 01950 batchs: 1074.89990234375
INFO:root:Train (Epoch 59): Loss/seq after 02000 batchs: 1069.1600341796875
INFO:root:Train (Epoch 59): Loss/seq after 02050 batchs: 1064.0958251953125
INFO:root:Train (Epoch 59): Loss/seq after 02100 batchs: 1056.575927734375
INFO:root:Train (Epoch 59): Loss/seq after 02150 batchs: 1049.3878173828125
INFO:root:Train (Epoch 59): Loss/seq after 02200 batchs: 1041.7196044921875
INFO:root:Train (Epoch 59): Loss/seq after 02250 batchs: 1042.3665771484375
INFO:root:Train (Epoch 59): Loss/seq after 02300 batchs: 1049.6080322265625
INFO:root:Train (Epoch 59): Loss/seq after 02350 batchs: 1041.951416015625
INFO:root:Train (Epoch 59): Loss/seq after 02400 batchs: 1040.069091796875
INFO:root:Train (Epoch 59): Loss/seq after 02450 batchs: 1030.2281494140625
INFO:root:Train (Epoch 59): Loss/seq after 02500 batchs: 1016.7650146484375
INFO:root:Train (Epoch 59): Loss/seq after 02550 batchs: 1007.7994995117188
INFO:root:Train (Epoch 59): Loss/seq after 02600 batchs: 1008.257568359375
INFO:root:Train (Epoch 59): Loss/seq after 02650 batchs: 1006.0764770507812
INFO:root:Train (Epoch 59): Loss/seq after 02700 batchs: 1003.2515869140625
INFO:root:Train (Epoch 59): Loss/seq after 02750 batchs: 1033.3858642578125
wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)
INFO:root:Train (Epoch 59): Loss/seq after 02800 batchs: 1036.2828369140625
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 59): Loss/seq after 02850 batchs: 1033.8785400390625
INFO:root:Train (Epoch 59): Loss/seq after 02900 batchs: 1033.5233154296875
INFO:root:Train (Epoch 59): Loss/seq after 02950 batchs: 1027.7227783203125
INFO:root:Train (Epoch 59): Loss/seq after 03000 batchs: 1028.4703369140625
INFO:root:Train (Epoch 59): Loss/seq after 03050 batchs: 1033.303955078125
INFO:root:Train (Epoch 59): Loss/seq after 03100 batchs: 1041.1080322265625
INFO:root:Train (Epoch 59): Loss/seq after 03150 batchs: 1045.3974609375
INFO:root:Train (Epoch 59): Loss/seq after 03200 batchs: 1050.003173828125
INFO:root:Train (Epoch 59): Loss/seq after 03250 batchs: 1051.17041015625
INFO:root:Train (Epoch 59): Loss/seq after 03300 batchs: 1048.5701904296875
INFO:root:Train (Epoch 59): Loss/seq after 03350 batchs: 1048.15869140625
INFO:root:Train (Epoch 59): Loss/seq after 03400 batchs: 1042.0277099609375
INFO:root:Train (Epoch 59): Loss/seq after 03450 batchs: 1036.5615234375
INFO:root:Train (Epoch 59): Loss/seq after 03500 batchs: 1035.744384765625
INFO:root:Train (Epoch 59): Loss/seq after 03550 batchs: 1029.882568359375
INFO:root:Train (Epoch 59): Loss/seq after 03600 batchs: 1036.8756103515625
INFO:root:Train (Epoch 59): Loss/seq after 03650 batchs: 1033.0386962890625
INFO:root:Train (Epoch 59): Loss/seq after 03700 batchs: 1034.3262939453125
INFO:root:Train (Epoch 59): Loss/seq after 03750 batchs: 1036.76171875
INFO:root:Train (Epoch 59): Loss/seq after 03800 batchs: 1031.9361572265625
INFO:root:Train (Epoch 59): Loss/seq after 03850 batchs: 1029.309326171875
INFO:root:Train (Epoch 59): Loss/seq after 03900 batchs: 1033.5260009765625
INFO:root:Train (Epoch 59): Loss/seq after 03950 batchs: 1036.537841796875
INFO:root:Train (Epoch 59): Loss/seq after 04000 batchs: 1029.830078125
INFO:root:Train (Epoch 59): Loss/seq after 04050 batchs: 1024.0892333984375
INFO:root:Train (Epoch 59): Loss/seq after 04100 batchs: 1019.3712158203125
INFO:root:Train (Epoch 59): Loss/seq after 04150 batchs: 1015.6858520507812
INFO:root:Train (Epoch 59): Loss/seq after 04200 batchs: 1011.7907104492188
INFO:root:Train (Epoch 59): Loss/seq after 04250 batchs: 1009.121826171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 59): Loss/seq after 00000 batches: 885.891357421875
INFO:root:# Valid (Epoch 59): Loss/seq after 00050 batches: 1109.763916015625
INFO:root:# Valid (Epoch 59): Loss/seq after 00100 batches: 1388.70166015625
INFO:root:# Valid (Epoch 59): Loss/seq after 00150 batches: 1104.2403564453125
INFO:root:# Valid (Epoch 59): Loss/seq after 00200 batches: 991.6968994140625
INFO:root:Artifacts: Make stick videos for epoch 59
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_59_on_20220413_200309.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_59_index_1440_on_20220413_200309.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 60): Loss/seq after 00000 batchs: 1542.1094970703125
INFO:root:Train (Epoch 60): Loss/seq after 00050 batchs: 1238.217529296875
INFO:root:Train (Epoch 60): Loss/seq after 00100 batchs: 1237.948486328125
INFO:root:Train (Epoch 60): Loss/seq after 00150 batchs: 1133.4468994140625
INFO:root:Train (Epoch 60): Loss/seq after 00200 batchs: 1247.7318115234375
INFO:root:Train (Epoch 60): Loss/seq after 00250 batchs: 1393.9461669921875
INFO:root:Train (Epoch 60): Loss/seq after 00300 batchs: 1343.1160888671875
INFO:root:Train (Epoch 60): Loss/seq after 00350 batchs: 1262.8026123046875
INFO:root:Train (Epoch 60): Loss/seq after 00400 batchs: 1289.1156005859375
INFO:root:Train (Epoch 60): Loss/seq after 00450 batchs: 1242.5748291015625
INFO:root:Train (Epoch 60): Loss/seq after 00500 batchs: 1240.31005859375
INFO:root:Train (Epoch 60): Loss/seq after 00550 batchs: 1193.9136962890625
INFO:root:Train (Epoch 60): Loss/seq after 00600 batchs: 1164.8038330078125
INFO:root:Train (Epoch 60): Loss/seq after 00650 batchs: 1171.0977783203125
INFO:root:Train (Epoch 60): Loss/seq after 00700 batchs: 1144.5999755859375
INFO:root:Train (Epoch 60): Loss/seq after 00750 batchs: 1169.7713623046875
INFO:root:Train (Epoch 60): Loss/seq after 00800 batchs: 1164.0655517578125
INFO:root:Train (Epoch 60): Loss/seq after 00850 batchs: 1142.5546875
INFO:root:Train (Epoch 60): Loss/seq after 00900 batchs: 1155.1153564453125
INFO:root:Train (Epoch 60): Loss/seq after 00950 batchs: 1162.9405517578125
INFO:root:Train (Epoch 60): Loss/seq after 01000 batchs: 1159.1060791015625
INFO:root:Train (Epoch 60): Loss/seq after 01050 batchs: 1145.6552734375
INFO:root:Train (Epoch 60): Loss/seq after 01100 batchs: 1146.4307861328125
INFO:root:Train (Epoch 60): Loss/seq after 01150 batchs: 1137.4141845703125
INFO:root:Train (Epoch 60): Loss/seq after 01200 batchs: 1132.342041015625
INFO:root:Train (Epoch 60): Loss/seq after 01250 batchs: 1126.6676025390625
INFO:root:Train (Epoch 60): Loss/seq after 01300 batchs: 1122.7774658203125
INFO:root:Train (Epoch 60): Loss/seq after 01350 batchs: 1119.8826904296875
INFO:root:Train (Epoch 60): Loss/seq after 01400 batchs: 1132.677490234375
INFO:root:Train (Epoch 60): Loss/seq after 01450 batchs: 1128.3515625
INFO:root:Train (Epoch 60): Loss/seq after 01500 batchs: 1125.2247314453125
INFO:root:Train (Epoch 60): Loss/seq after 01550 batchs: 1128.1181640625
INFO:root:Train (Epoch 60): Loss/seq after 01600 batchs: 1116.596435546875
INFO:root:Train (Epoch 60): Loss/seq after 01650 batchs: 1109.1904296875
INFO:root:Train (Epoch 60): Loss/seq after 01700 batchs: 1104.1351318359375
INFO:root:Train (Epoch 60): Loss/seq after 01750 batchs: 1097.4412841796875
INFO:root:Train (Epoch 60): Loss/seq after 01800 batchs: 1088.064453125
INFO:root:Train (Epoch 60): Loss/seq after 01850 batchs: 1078.51025390625
INFO:root:Train (Epoch 60): Loss/seq after 01900 batchs: 1078.431396484375
INFO:root:Train (Epoch 60): Loss/seq after 01950 batchs: 1075.1514892578125
INFO:root:Train (Epoch 60): Loss/seq after 02000 batchs: 1069.583740234375
INFO:root:Train (Epoch 60): Loss/seq after 02050 batchs: 1064.6346435546875
INFO:root:Train (Epoch 60): Loss/seq after 02100 batchs: 1056.9468994140625
INFO:root:Train (Epoch 60): Loss/seq after 02150 batchs: 1049.9176025390625
INFO:root:Train (Epoch 60): Loss/seq after 02200 batchs: 1042.290283203125
INFO:root:Train (Epoch 60): Loss/seq after 02250 batchs: 1042.8624267578125
INFO:root:Train (Epoch 60): Loss/seq after 02300 batchs: 1049.4796142578125
INFO:root:Train (Epoch 60): Loss/seq after 02350 batchs: 1041.9810791015625
INFO:root:Train (Epoch 60): Loss/seq after 02400 batchs: 1040.8985595703125
INFO:root:Train (Epoch 60): Loss/seq after 02450 batchs: 1031.214111328125
INFO:root:Train (Epoch 60): Loss/seq after 02500 batchs: 1017.74609375
INFO:root:Train (Epoch 60): Loss/seq after 02550 batchs: 1008.5319213867188
INFO:root:Train (Epoch 60): Loss/seq after 02600 batchs: 1008.7318115234375
INFO:root:Train (Epoch 60): Loss/seq after 02650 batchs: 1006.4698486328125
INFO:root:Train (Epoch 60): Loss/seq after 02700 batchs: 1003.52587890625
INFO:root:Train (Epoch 60): Loss/seq after 02750 batchs: 1033.2294921875
INFO:root:Train (Epoch 60): Loss/seq after 02800 batchs: 1036.098388671875
INFO:root:Train (Epoch 60): Loss/seq after 02850 batchs: 1033.7657470703125
INFO:root:Train (Epoch 60): Loss/seq after 02900 batchs: 1032.814208984375
INFO:root:Train (Epoch 60): Loss/seq after 02950 batchs: 1027.0062255859375
INFO:root:Train (Epoch 60): Loss/seq after 03000 batchs: 1027.7904052734375
INFO:root:Train (Epoch 60): Loss/seq after 03050 batchs: 1032.7083740234375
INFO:root:Train (Epoch 60): Loss/seq after 03100 batchs: 1040.903564453125
INFO:root:Train (Epoch 60): Loss/seq after 03150 batchs: 1046.864013671875
INFO:root:Train (Epoch 60): Loss/seq after 03200 batchs: 1051.8408203125
INFO:root:Train (Epoch 60): Loss/seq after 03250 batchs: 1053.573974609375
INFO:root:Train (Epoch 60): Loss/seq after 03300 batchs: 1051.0361328125
INFO:root:Train (Epoch 60): Loss/seq after 03350 batchs: 1050.608642578125
INFO:root:Train (Epoch 60): Loss/seq after 03400 batchs: 1044.7633056640625
INFO:root:Train (Epoch 60): Loss/seq after 03450 batchs: 1039.90283203125
INFO:root:Train (Epoch 60): Loss/seq after 03500 batchs: 1039.352294921875
INFO:root:Train (Epoch 60): Loss/seq after 03550 batchs: 1033.7060546875
INFO:root:Train (Epoch 60): Loss/seq after 03600 batchs: 1040.4356689453125
INFO:root:Train (Epoch 60): Loss/seq after 03650 batchs: 1035.8302001953125
INFO:root:Train (Epoch 60): Loss/seq after 03700 batchs: 1036.82958984375
INFO:root:Train (Epoch 60): Loss/seq after 03750 batchs: 1038.9947509765625
INFO:root:Train (Epoch 60): Loss/seq after 03800 batchs: 1034.143798828125
INFO:root:Train (Epoch 60): Loss/seq after 03850 batchs: 1031.47412109375
INFO:root:Train (Epoch 60): Loss/seq after 03900 batchs: 1035.1317138671875
INFO:root:Train (Epoch 60): Loss/seq after 03950 batchs: 1038.0150146484375
INFO:root:Train (Epoch 60): Loss/seq after 04000 batchs: 1031.293701171875
INFO:root:Train (Epoch 60): Loss/seq after 04050 batchs: 1025.4813232421875
INFO:root:Train (Epoch 60): Loss/seq after 04100 batchs: 1020.8157958984375
INFO:root:Train (Epoch 60): Loss/seq after 04150 batchs: 1016.9737548828125
INFO:root:Train (Epoch 60): Loss/seq after 04200 batchs: 1012.9808349609375
INFO:root:Train (Epoch 60): Loss/seq after 04250 batchs: 1010.297119140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 60): Loss/seq after 00000 batches: 884.10546875
INFO:root:# Valid (Epoch 60): Loss/seq after 00050 batches: 1101.0975341796875
INFO:root:# Valid (Epoch 60): Loss/seq after 00100 batches: 1382.486083984375
INFO:root:# Valid (Epoch 60): Loss/seq after 00150 batches: 1107.2685546875
INFO:root:# Valid (Epoch 60): Loss/seq after 00200 batches: 996.8165283203125
INFO:root:Artifacts: Make stick videos for epoch 60
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_60_on_20220413_200827.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_60_index_363_on_20220413_200827.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 61): Loss/seq after 00000 batchs: 1938.3194580078125
INFO:root:Train (Epoch 61): Loss/seq after 00050 batchs: 1260.45703125
INFO:root:Train (Epoch 61): Loss/seq after 00100 batchs: 1267.55712890625
INFO:root:Train (Epoch 61): Loss/seq after 00150 batchs: 1155.3311767578125
INFO:root:Train (Epoch 61): Loss/seq after 00200 batchs: 1253.97314453125
INFO:root:Train (Epoch 61): Loss/seq after 00250 batchs: 1390.2633056640625
INFO:root:Train (Epoch 61): Loss/seq after 00300 batchs: 1339.2230224609375
INFO:root:Train (Epoch 61): Loss/seq after 00350 batchs: 1257.2452392578125
INFO:root:Train (Epoch 61): Loss/seq after 00400 batchs: 1280.213623046875
INFO:root:Train (Epoch 61): Loss/seq after 00450 batchs: 1234.609375
INFO:root:Train (Epoch 61): Loss/seq after 00500 batchs: 1234.3848876953125
INFO:root:Train (Epoch 61): Loss/seq after 00550 batchs: 1189.439208984375
INFO:root:Train (Epoch 61): Loss/seq after 00600 batchs: 1160.11767578125
INFO:root:Train (Epoch 61): Loss/seq after 00650 batchs: 1167.441650390625
INFO:root:Train (Epoch 61): Loss/seq after 00700 batchs: 1140.3431396484375
INFO:root:Train (Epoch 61): Loss/seq after 00750 batchs: 1166.4403076171875
INFO:root:Train (Epoch 61): Loss/seq after 00800 batchs: 1160.167236328125
INFO:root:Train (Epoch 61): Loss/seq after 00850 batchs: 1139.474609375
INFO:root:Train (Epoch 61): Loss/seq after 00900 batchs: 1151.7919921875
INFO:root:Train (Epoch 61): Loss/seq after 00950 batchs: 1163.839599609375
INFO:root:Train (Epoch 61): Loss/seq after 01000 batchs: 1156.5147705078125
INFO:root:Train (Epoch 61): Loss/seq after 01050 batchs: 1141.3236083984375
INFO:root:Train (Epoch 61): Loss/seq after 01100 batchs: 1137.8951416015625
INFO:root:Train (Epoch 61): Loss/seq after 01150 batchs: 1128.7794189453125
INFO:root:Train (Epoch 61): Loss/seq after 01200 batchs: 1123.82080078125
INFO:root:Train (Epoch 61): Loss/seq after 01250 batchs: 1116.6566162109375
INFO:root:Train (Epoch 61): Loss/seq after 01300 batchs: 1111.12158203125
INFO:root:Train (Epoch 61): Loss/seq after 01350 batchs: 1107.95263671875
INFO:root:Train (Epoch 61): Loss/seq after 01400 batchs: 1118.78271484375
INFO:root:Train (Epoch 61): Loss/seq after 01450 batchs: 1114.390380859375
INFO:root:Train (Epoch 61): Loss/seq after 01500 batchs: 1111.640380859375
INFO:root:Train (Epoch 61): Loss/seq after 01550 batchs: 1113.5582275390625
INFO:root:Train (Epoch 61): Loss/seq after 01600 batchs: 1102.44970703125
INFO:root:Train (Epoch 61): Loss/seq after 01650 batchs: 1095.7943115234375
INFO:root:Train (Epoch 61): Loss/seq after 01700 batchs: 1091.220947265625
INFO:root:Train (Epoch 61): Loss/seq after 01750 batchs: 1084.975830078125
INFO:root:Train (Epoch 61): Loss/seq after 01800 batchs: 1075.971923828125
INFO:root:Train (Epoch 61): Loss/seq after 01850 batchs: 1066.6094970703125
INFO:root:Train (Epoch 61): Loss/seq after 01900 batchs: 1066.3863525390625
INFO:root:Train (Epoch 61): Loss/seq after 01950 batchs: 1061.6414794921875
INFO:root:Train (Epoch 61): Loss/seq after 02000 batchs: 1056.214111328125
INFO:root:Train (Epoch 61): Loss/seq after 02050 batchs: 1051.7430419921875
INFO:root:Train (Epoch 61): Loss/seq after 02100 batchs: 1044.234619140625
INFO:root:Train (Epoch 61): Loss/seq after 02150 batchs: 1037.296142578125
INFO:root:Train (Epoch 61): Loss/seq after 02200 batchs: 1029.9344482421875
INFO:root:Train (Epoch 61): Loss/seq after 02250 batchs: 1030.1214599609375
INFO:root:Train (Epoch 61): Loss/seq after 02300 batchs: 1037.6712646484375
INFO:root:Train (Epoch 61): Loss/seq after 02350 batchs: 1030.6834716796875
INFO:root:Train (Epoch 61): Loss/seq after 02400 batchs: 1030.08984375
INFO:root:Train (Epoch 61): Loss/seq after 02450 batchs: 1021.004150390625
INFO:root:Train (Epoch 61): Loss/seq after 02500 batchs: 1007.77197265625
INFO:root:Train (Epoch 61): Loss/seq after 02550 batchs: 999.0511474609375
INFO:root:Train (Epoch 61): Loss/seq after 02600 batchs: 999.6182861328125
INFO:root:Train (Epoch 61): Loss/seq after 02650 batchs: 997.7319946289062
INFO:root:Train (Epoch 61): Loss/seq after 02700 batchs: 995.3024291992188
INFO:root:Train (Epoch 61): Loss/seq after 02750 batchs: 1025.4095458984375
INFO:root:Train (Epoch 61): Loss/seq after 02800 batchs: 1028.5906982421875
INFO:root:Train (Epoch 61): Loss/seq after 02850 batchs: 1026.19970703125
INFO:root:Train (Epoch 61): Loss/seq after 02900 batchs: 1025.024169921875
INFO:root:Train (Epoch 61): Loss/seq after 02950 batchs: 1019.222900390625
INFO:root:Train (Epoch 61): Loss/seq after 03000 batchs: 1020.0957641601562
INFO:root:Train (Epoch 61): Loss/seq after 03050 batchs: 1025.0201416015625
INFO:root:Train (Epoch 61): Loss/seq after 03100 batchs: 1032.09765625
INFO:root:Train (Epoch 61): Loss/seq after 03150 batchs: 1036.517822265625
INFO:root:Train (Epoch 61): Loss/seq after 03200 batchs: 1041.0238037109375
INFO:root:Train (Epoch 61): Loss/seq after 03250 batchs: 1042.5987548828125
INFO:root:Train (Epoch 61): Loss/seq after 03300 batchs: 1040.208251953125
INFO:root:Train (Epoch 61): Loss/seq after 03350 batchs: 1039.4422607421875
INFO:root:Train (Epoch 61): Loss/seq after 03400 batchs: 1033.551025390625
INFO:root:Train (Epoch 61): Loss/seq after 03450 batchs: 1028.5126953125
INFO:root:Train (Epoch 61): Loss/seq after 03500 batchs: 1028.1236572265625
INFO:root:Train (Epoch 61): Loss/seq after 03550 batchs: 1022.993408203125
INFO:root:Train (Epoch 61): Loss/seq after 03600 batchs: 1030.1060791015625
INFO:root:Train (Epoch 61): Loss/seq after 03650 batchs: 1025.8712158203125
INFO:root:Train (Epoch 61): Loss/seq after 03700 batchs: 1026.939208984375
INFO:root:Train (Epoch 61): Loss/seq after 03750 batchs: 1029.490234375
INFO:root:Train (Epoch 61): Loss/seq after 03800 batchs: 1024.720703125
INFO:root:Train (Epoch 61): Loss/seq after 03850 batchs: 1022.1597290039062
INFO:root:Train (Epoch 61): Loss/seq after 03900 batchs: 1026.30126953125
INFO:root:Train (Epoch 61): Loss/seq after 03950 batchs: 1029.5186767578125
INFO:root:Train (Epoch 61): Loss/seq after 04000 batchs: 1022.8981323242188
INFO:root:Train (Epoch 61): Loss/seq after 04050 batchs: 1017.2098388671875
INFO:root:Train (Epoch 61): Loss/seq after 04100 batchs: 1012.93017578125
INFO:root:Train (Epoch 61): Loss/seq after 04150 batchs: 1009.363037109375
INFO:root:Train (Epoch 61): Loss/seq after 04200 batchs: 1005.6442260742188
INFO:root:Train (Epoch 61): Loss/seq after 04250 batchs: 1003.0562133789062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 61): Loss/seq after 00000 batches: 878.62353515625
INFO:root:# Valid (Epoch 61): Loss/seq after 00050 batches: 1097.5301513671875
INFO:root:# Valid (Epoch 61): Loss/seq after 00100 batches: 1381.3895263671875
INFO:root:# Valid (Epoch 61): Loss/seq after 00150 batches: 1098.023193359375
INFO:root:# Valid (Epoch 61): Loss/seq after 00200 batches: 987.5082397460938
INFO:root:Artifacts: Make stick videos for epoch 61
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_61_on_20220413_201345.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_61_index_1181_on_20220413_201345.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 62): Loss/seq after 00000 batchs: 1459.1368408203125
INFO:root:Train (Epoch 62): Loss/seq after 00050 batchs: 1232.1505126953125
INFO:root:Train (Epoch 62): Loss/seq after 00100 batchs: 1242.079833984375
INFO:root:Train (Epoch 62): Loss/seq after 00150 batchs: 1138.998779296875
INFO:root:Train (Epoch 62): Loss/seq after 00200 batchs: 1258.036865234375
INFO:root:Train (Epoch 62): Loss/seq after 00250 batchs: 1388.072998046875
INFO:root:Train (Epoch 62): Loss/seq after 00300 batchs: 1339.6646728515625
INFO:root:Train (Epoch 62): Loss/seq after 00350 batchs: 1259.244873046875
INFO:root:Train (Epoch 62): Loss/seq after 00400 batchs: 1279.2379150390625
INFO:root:Train (Epoch 62): Loss/seq after 00450 batchs: 1233.6790771484375
INFO:root:Train (Epoch 62): Loss/seq after 00500 batchs: 1227.2603759765625
INFO:root:Train (Epoch 62): Loss/seq after 00550 batchs: 1181.73486328125
INFO:root:Train (Epoch 62): Loss/seq after 00600 batchs: 1153.6153564453125
INFO:root:Train (Epoch 62): Loss/seq after 00650 batchs: 1164.2381591796875
INFO:root:Train (Epoch 62): Loss/seq after 00700 batchs: 1137.67529296875
INFO:root:Train (Epoch 62): Loss/seq after 00750 batchs: 1161.464111328125
INFO:root:Train (Epoch 62): Loss/seq after 00800 batchs: 1155.546142578125
INFO:root:Train (Epoch 62): Loss/seq after 00850 batchs: 1134.5169677734375
INFO:root:Train (Epoch 62): Loss/seq after 00900 batchs: 1145.7144775390625
INFO:root:Train (Epoch 62): Loss/seq after 00950 batchs: 1156.3009033203125
INFO:root:Train (Epoch 62): Loss/seq after 01000 batchs: 1150.155029296875
INFO:root:Train (Epoch 62): Loss/seq after 01050 batchs: 1133.7950439453125
INFO:root:Train (Epoch 62): Loss/seq after 01100 batchs: 1130.802978515625
INFO:root:Train (Epoch 62): Loss/seq after 01150 batchs: 1122.347900390625
INFO:root:Train (Epoch 62): Loss/seq after 01200 batchs: 1117.5037841796875
INFO:root:Train (Epoch 62): Loss/seq after 01250 batchs: 1111.12548828125
INFO:root:Train (Epoch 62): Loss/seq after 01300 batchs: 1104.962158203125
INFO:root:Train (Epoch 62): Loss/seq after 01350 batchs: 1101.9017333984375
INFO:root:Train (Epoch 62): Loss/seq after 01400 batchs: 1112.684814453125
INFO:root:Train (Epoch 62): Loss/seq after 01450 batchs: 1108.5638427734375
INFO:root:Train (Epoch 62): Loss/seq after 01500 batchs: 1105.9281005859375
INFO:root:Train (Epoch 62): Loss/seq after 01550 batchs: 1108.0831298828125
INFO:root:Train (Epoch 62): Loss/seq after 01600 batchs: 1097.0771484375
INFO:root:Train (Epoch 62): Loss/seq after 01650 batchs: 1089.8204345703125
INFO:root:Train (Epoch 62): Loss/seq after 01700 batchs: 1085.31689453125
INFO:root:Train (Epoch 62): Loss/seq after 01750 batchs: 1079.192138671875
INFO:root:Train (Epoch 62): Loss/seq after 01800 batchs: 1070.39794921875
INFO:root:Train (Epoch 62): Loss/seq after 01850 batchs: 1061.3641357421875
INFO:root:Train (Epoch 62): Loss/seq after 01900 batchs: 1061.068115234375
INFO:root:Train (Epoch 62): Loss/seq after 01950 batchs: 1057.0181884765625
INFO:root:Train (Epoch 62): Loss/seq after 02000 batchs: 1051.948974609375
INFO:root:Train (Epoch 62): Loss/seq after 02050 batchs: 1047.4754638671875
INFO:root:Train (Epoch 62): Loss/seq after 02100 batchs: 1040.08203125
INFO:root:Train (Epoch 62): Loss/seq after 02150 batchs: 1033.3851318359375
INFO:root:Train (Epoch 62): Loss/seq after 02200 batchs: 1026.073486328125
INFO:root:Train (Epoch 62): Loss/seq after 02250 batchs: 1026.9007568359375
INFO:root:Train (Epoch 62): Loss/seq after 02300 batchs: 1033.5782470703125
INFO:root:Train (Epoch 62): Loss/seq after 02350 batchs: 1026.1640625
INFO:root:Train (Epoch 62): Loss/seq after 02400 batchs: 1024.6551513671875
INFO:root:Train (Epoch 62): Loss/seq after 02450 batchs: 1015.0952758789062
INFO:root:Train (Epoch 62): Loss/seq after 02500 batchs: 1001.9132080078125
INFO:root:Train (Epoch 62): Loss/seq after 02550 batchs: 993.4744262695312
INFO:root:Train (Epoch 62): Loss/seq after 02600 batchs: 994.2095336914062
INFO:root:Train (Epoch 62): Loss/seq after 02650 batchs: 992.3154296875
INFO:root:Train (Epoch 62): Loss/seq after 02700 batchs: 989.7438354492188
INFO:root:Train (Epoch 62): Loss/seq after 02750 batchs: 1020.0234985351562
INFO:root:Train (Epoch 62): Loss/seq after 02800 batchs: 1024.348876953125
INFO:root:Train (Epoch 62): Loss/seq after 02850 batchs: 1022.0242919921875
INFO:root:Train (Epoch 62): Loss/seq after 02900 batchs: 1021.3321533203125
INFO:root:Train (Epoch 62): Loss/seq after 02950 batchs: 1015.7405395507812
INFO:root:Train (Epoch 62): Loss/seq after 03000 batchs: 1016.724609375
INFO:root:Train (Epoch 62): Loss/seq after 03050 batchs: 1021.7702026367188
INFO:root:Train (Epoch 62): Loss/seq after 03100 batchs: 1029.0152587890625
INFO:root:Train (Epoch 62): Loss/seq after 03150 batchs: 1033.401123046875
INFO:root:Train (Epoch 62): Loss/seq after 03200 batchs: 1038.1751708984375
INFO:root:Train (Epoch 62): Loss/seq after 03250 batchs: 1040.1378173828125
INFO:root:Train (Epoch 62): Loss/seq after 03300 batchs: 1038.1883544921875
INFO:root:Train (Epoch 62): Loss/seq after 03350 batchs: 1037.5709228515625
INFO:root:Train (Epoch 62): Loss/seq after 03400 batchs: 1031.81787109375
INFO:root:Train (Epoch 62): Loss/seq after 03450 batchs: 1026.5340576171875
INFO:root:Train (Epoch 62): Loss/seq after 03500 batchs: 1025.647216796875
INFO:root:Train (Epoch 62): Loss/seq after 03550 batchs: 1020.3928833007812
INFO:root:Train (Epoch 62): Loss/seq after 03600 batchs: 1027.509765625
INFO:root:Train (Epoch 62): Loss/seq after 03650 batchs: 1023.1396484375
INFO:root:Train (Epoch 62): Loss/seq after 03700 batchs: 1024.0302734375
INFO:root:Train (Epoch 62): Loss/seq after 03750 batchs: 1026.5211181640625
INFO:root:Train (Epoch 62): Loss/seq after 03800 batchs: 1021.7255249023438
INFO:root:Train (Epoch 62): Loss/seq after 03850 batchs: 1019.2172241210938
INFO:root:Train (Epoch 62): Loss/seq after 03900 batchs: 1022.72802734375
INFO:root:Train (Epoch 62): Loss/seq after 03950 batchs: 1025.7099609375
INFO:root:Train (Epoch 62): Loss/seq after 04000 batchs: 1019.1419067382812
INFO:root:Train (Epoch 62): Loss/seq after 04050 batchs: 1013.490966796875
INFO:root:Train (Epoch 62): Loss/seq after 04100 batchs: 1008.83056640625
INFO:root:Train (Epoch 62): Loss/seq after 04150 batchs: 1005.1702880859375
INFO:root:Train (Epoch 62): Loss/seq after 04200 batchs: 1001.2994384765625
INFO:root:Train (Epoch 62): Loss/seq after 04250 batchs: 998.7108764648438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 62): Loss/seq after 00000 batches: 883.5239868164062
INFO:root:# Valid (Epoch 62): Loss/seq after 00050 batches: 1093.9830322265625
INFO:root:# Valid (Epoch 62): Loss/seq after 00100 batches: 1375.2894287109375
INFO:root:# Valid (Epoch 62): Loss/seq after 00150 batches: 1096.50244140625
INFO:root:# Valid (Epoch 62): Loss/seq after 00200 batches: 987.6358642578125
INFO:root:Artifacts: Make stick videos for epoch 62
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_62_on_20220413_201904.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_62_index_1805_on_20220413_201904.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 63): Loss/seq after 00000 batchs: 1527.4259033203125
INFO:root:Train (Epoch 63): Loss/seq after 00050 batchs: 1220.1685791015625
INFO:root:Train (Epoch 63): Loss/seq after 00100 batchs: 1248.6263427734375
INFO:root:Train (Epoch 63): Loss/seq after 00150 batchs: 1141.82373046875
INFO:root:Train (Epoch 63): Loss/seq after 00200 batchs: 1244.7325439453125
INFO:root:Train (Epoch 63): Loss/seq after 00250 batchs: 1388.119873046875
INFO:root:Train (Epoch 63): Loss/seq after 00300 batchs: 1338.5343017578125
INFO:root:Train (Epoch 63): Loss/seq after 00350 batchs: 1257.2333984375
INFO:root:Train (Epoch 63): Loss/seq after 00400 batchs: 1277.9525146484375
INFO:root:Train (Epoch 63): Loss/seq after 00450 batchs: 1232.50537109375
INFO:root:Train (Epoch 63): Loss/seq after 00500 batchs: 1224.99462890625
INFO:root:Train (Epoch 63): Loss/seq after 00550 batchs: 1180.96337890625
INFO:root:Train (Epoch 63): Loss/seq after 00600 batchs: 1153.1837158203125
INFO:root:Train (Epoch 63): Loss/seq after 00650 batchs: 1159.9066162109375
INFO:root:Train (Epoch 63): Loss/seq after 00700 batchs: 1134.162109375
INFO:root:Train (Epoch 63): Loss/seq after 00750 batchs: 1161.91650390625
INFO:root:Train (Epoch 63): Loss/seq after 00800 batchs: 1158.2794189453125
INFO:root:Train (Epoch 63): Loss/seq after 00850 batchs: 1137.2696533203125
INFO:root:Train (Epoch 63): Loss/seq after 00900 batchs: 1148.0577392578125
INFO:root:Train (Epoch 63): Loss/seq after 00950 batchs: 1153.86083984375
INFO:root:Train (Epoch 63): Loss/seq after 01000 batchs: 1147.3809814453125
INFO:root:Train (Epoch 63): Loss/seq after 01050 batchs: 1130.0784912109375
INFO:root:Train (Epoch 63): Loss/seq after 01100 batchs: 1128.2767333984375
INFO:root:Train (Epoch 63): Loss/seq after 01150 batchs: 1119.66162109375
INFO:root:Train (Epoch 63): Loss/seq after 01200 batchs: 1114.95947265625
INFO:root:Train (Epoch 63): Loss/seq after 01250 batchs: 1108.18798828125
INFO:root:Train (Epoch 63): Loss/seq after 01300 batchs: 1103.7528076171875
INFO:root:Train (Epoch 63): Loss/seq after 01350 batchs: 1100.6888427734375
INFO:root:Train (Epoch 63): Loss/seq after 01400 batchs: 1111.762939453125
INFO:root:Train (Epoch 63): Loss/seq after 01450 batchs: 1107.3221435546875
INFO:root:Train (Epoch 63): Loss/seq after 01500 batchs: 1104.8292236328125
INFO:root:Train (Epoch 63): Loss/seq after 01550 batchs: 1106.90966796875
INFO:root:Train (Epoch 63): Loss/seq after 01600 batchs: 1096.41455078125
INFO:root:Train (Epoch 63): Loss/seq after 01650 batchs: 1089.828369140625
INFO:root:Train (Epoch 63): Loss/seq after 01700 batchs: 1085.5924072265625
INFO:root:Train (Epoch 63): Loss/seq after 01750 batchs: 1079.442626953125
INFO:root:Train (Epoch 63): Loss/seq after 01800 batchs: 1070.572021484375
INFO:root:Train (Epoch 63): Loss/seq after 01850 batchs: 1061.4283447265625
INFO:root:Train (Epoch 63): Loss/seq after 01900 batchs: 1061.1298828125
INFO:root:Train (Epoch 63): Loss/seq after 01950 batchs: 1057.1607666015625
INFO:root:Train (Epoch 63): Loss/seq after 02000 batchs: 1052.3123779296875
INFO:root:Train (Epoch 63): Loss/seq after 02050 batchs: 1047.7935791015625
INFO:root:Train (Epoch 63): Loss/seq after 02100 batchs: 1040.385986328125
INFO:root:Train (Epoch 63): Loss/seq after 02150 batchs: 1033.518310546875
INFO:root:Train (Epoch 63): Loss/seq after 02200 batchs: 1026.1947021484375
INFO:root:Train (Epoch 63): Loss/seq after 02250 batchs: 1026.4346923828125
INFO:root:Train (Epoch 63): Loss/seq after 02300 batchs: 1033.23046875
INFO:root:Train (Epoch 63): Loss/seq after 02350 batchs: 1025.72314453125
INFO:root:Train (Epoch 63): Loss/seq after 02400 batchs: 1024.41064453125
INFO:root:Train (Epoch 63): Loss/seq after 02450 batchs: 1014.9319458007812
INFO:root:Train (Epoch 63): Loss/seq after 02500 batchs: 1001.7803955078125
INFO:root:Train (Epoch 63): Loss/seq after 02550 batchs: 992.620849609375
INFO:root:Train (Epoch 63): Loss/seq after 02600 batchs: 993.0305786132812
INFO:root:Train (Epoch 63): Loss/seq after 02650 batchs: 990.8631591796875
INFO:root:Train (Epoch 63): Loss/seq after 02700 batchs: 987.98291015625
INFO:root:Train (Epoch 63): Loss/seq after 02750 batchs: 1017.6731567382812
INFO:root:Train (Epoch 63): Loss/seq after 02800 batchs: 1020.3035278320312
INFO:root:Train (Epoch 63): Loss/seq after 02850 batchs: 1018.0130004882812
INFO:root:Train (Epoch 63): Loss/seq after 02900 batchs: 1017.1832885742188
INFO:root:Train (Epoch 63): Loss/seq after 02950 batchs: 1011.6146240234375
INFO:root:Train (Epoch 63): Loss/seq after 03000 batchs: 1012.660888671875
INFO:root:Train (Epoch 63): Loss/seq after 03050 batchs: 1017.7132568359375
INFO:root:Train (Epoch 63): Loss/seq after 03100 batchs: 1025.7823486328125
INFO:root:Train (Epoch 63): Loss/seq after 03150 batchs: 1030.1680908203125
INFO:root:Train (Epoch 63): Loss/seq after 03200 batchs: 1035.2371826171875
INFO:root:Train (Epoch 63): Loss/seq after 03250 batchs: 1036.945556640625
INFO:root:Train (Epoch 63): Loss/seq after 03300 batchs: 1036.230224609375
INFO:root:Train (Epoch 63): Loss/seq after 03350 batchs: 1035.0523681640625
INFO:root:Train (Epoch 63): Loss/seq after 03400 batchs: 1029.24951171875
INFO:root:Train (Epoch 63): Loss/seq after 03450 batchs: 1025.7091064453125
INFO:root:Train (Epoch 63): Loss/seq after 03500 batchs: 1026.36669921875
INFO:root:Train (Epoch 63): Loss/seq after 03550 batchs: 1020.8843383789062
INFO:root:Train (Epoch 63): Loss/seq after 03600 batchs: 1027.6239013671875
INFO:root:Train (Epoch 63): Loss/seq after 03650 batchs: 1023.0244750976562
INFO:root:Train (Epoch 63): Loss/seq after 03700 batchs: 1024.3167724609375
INFO:root:Train (Epoch 63): Loss/seq after 03750 batchs: 1026.696044921875
INFO:root:Train (Epoch 63): Loss/seq after 03800 batchs: 1021.9629516601562
INFO:root:Train (Epoch 63): Loss/seq after 03850 batchs: 1019.445068359375
INFO:root:Train (Epoch 63): Loss/seq after 03900 batchs: 1023.4176025390625
INFO:root:Train (Epoch 63): Loss/seq after 03950 batchs: 1026.71533203125
INFO:root:Train (Epoch 63): Loss/seq after 04000 batchs: 1020.1198120117188
INFO:root:Train (Epoch 63): Loss/seq after 04050 batchs: 1014.4265747070312
INFO:root:Train (Epoch 63): Loss/seq after 04100 batchs: 1009.7431030273438
INFO:root:Train (Epoch 63): Loss/seq after 04150 batchs: 1006.10546875
INFO:root:Train (Epoch 63): Loss/seq after 04200 batchs: 1002.2261352539062
INFO:root:Train (Epoch 63): Loss/seq after 04250 batchs: 999.5592651367188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 63): Loss/seq after 00000 batches: 866.3489990234375
INFO:root:# Valid (Epoch 63): Loss/seq after 00050 batches: 1095.9588623046875
INFO:root:# Valid (Epoch 63): Loss/seq after 00100 batches: 1377.5531005859375
INFO:root:# Valid (Epoch 63): Loss/seq after 00150 batches: 1099.341064453125
INFO:root:# Valid (Epoch 63): Loss/seq after 00200 batches: 991.6004028320312
INFO:root:Artifacts: Make stick videos for epoch 63
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_63_on_20220413_202422.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_63_index_1635_on_20220413_202422.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 64): Loss/seq after 00000 batchs: 1663.5787353515625
INFO:root:Train (Epoch 64): Loss/seq after 00050 batchs: 1217.8013916015625
INFO:root:Train (Epoch 64): Loss/seq after 00100 batchs: 1243.143310546875
INFO:root:Train (Epoch 64): Loss/seq after 00150 batchs: 1130.8934326171875
INFO:root:Train (Epoch 64): Loss/seq after 00200 batchs: 1243.6314697265625
INFO:root:Train (Epoch 64): Loss/seq after 00250 batchs: 1366.91650390625
INFO:root:Train (Epoch 64): Loss/seq after 00300 batchs: 1321.1038818359375
INFO:root:Train (Epoch 64): Loss/seq after 00350 batchs: 1241.81201171875
INFO:root:Train (Epoch 64): Loss/seq after 00400 batchs: 1265.8262939453125
INFO:root:Train (Epoch 64): Loss/seq after 00450 batchs: 1221.9892578125
INFO:root:Train (Epoch 64): Loss/seq after 00500 batchs: 1220.626708984375
INFO:root:Train (Epoch 64): Loss/seq after 00550 batchs: 1175.8341064453125
INFO:root:Train (Epoch 64): Loss/seq after 00600 batchs: 1146.0426025390625
INFO:root:Train (Epoch 64): Loss/seq after 00650 batchs: 1152.6923828125
INFO:root:Train (Epoch 64): Loss/seq after 00700 batchs: 1125.4742431640625
INFO:root:Train (Epoch 64): Loss/seq after 00750 batchs: 1153.03857421875
INFO:root:Train (Epoch 64): Loss/seq after 00800 batchs: 1146.936767578125
INFO:root:Train (Epoch 64): Loss/seq after 00850 batchs: 1126.031982421875
INFO:root:Train (Epoch 64): Loss/seq after 00900 batchs: 1137.1993408203125
INFO:root:Train (Epoch 64): Loss/seq after 00950 batchs: 1146.384521484375
INFO:root:Train (Epoch 64): Loss/seq after 01000 batchs: 1139.543701171875
INFO:root:Train (Epoch 64): Loss/seq after 01050 batchs: 1123.2791748046875
INFO:root:Train (Epoch 64): Loss/seq after 01100 batchs: 1119.0377197265625
INFO:root:Train (Epoch 64): Loss/seq after 01150 batchs: 1110.9146728515625
INFO:root:Train (Epoch 64): Loss/seq after 01200 batchs: 1107.094482421875
INFO:root:Train (Epoch 64): Loss/seq after 01250 batchs: 1100.7674560546875
INFO:root:Train (Epoch 64): Loss/seq after 01300 batchs: 1096.568115234375
INFO:root:Train (Epoch 64): Loss/seq after 01350 batchs: 1093.56689453125
INFO:root:Train (Epoch 64): Loss/seq after 01400 batchs: 1104.747802734375
INFO:root:Train (Epoch 64): Loss/seq after 01450 batchs: 1100.6702880859375
INFO:root:Train (Epoch 64): Loss/seq after 01500 batchs: 1098.3385009765625
INFO:root:Train (Epoch 64): Loss/seq after 01550 batchs: 1100.63232421875
INFO:root:Train (Epoch 64): Loss/seq after 01600 batchs: 1089.8587646484375
INFO:root:Train (Epoch 64): Loss/seq after 01650 batchs: 1082.760498046875
INFO:root:Train (Epoch 64): Loss/seq after 01700 batchs: 1078.66845703125
INFO:root:Train (Epoch 64): Loss/seq after 01750 batchs: 1072.6932373046875
INFO:root:Train (Epoch 64): Loss/seq after 01800 batchs: 1064.0283203125
INFO:root:Train (Epoch 64): Loss/seq after 01850 batchs: 1054.9930419921875
INFO:root:Train (Epoch 64): Loss/seq after 01900 batchs: 1054.869140625
INFO:root:Train (Epoch 64): Loss/seq after 01950 batchs: 1050.867919921875
INFO:root:Train (Epoch 64): Loss/seq after 02000 batchs: 1046.227294921875
INFO:root:Train (Epoch 64): Loss/seq after 02050 batchs: 1041.814697265625
INFO:root:Train (Epoch 64): Loss/seq after 02100 batchs: 1034.468017578125
INFO:root:Train (Epoch 64): Loss/seq after 02150 batchs: 1027.6817626953125
INFO:root:Train (Epoch 64): Loss/seq after 02200 batchs: 1020.477294921875
INFO:root:Train (Epoch 64): Loss/seq after 02250 batchs: 1021.2202758789062
INFO:root:Train (Epoch 64): Loss/seq after 02300 batchs: 1026.6092529296875
INFO:root:Train (Epoch 64): Loss/seq after 02350 batchs: 1019.3362426757812
INFO:root:Train (Epoch 64): Loss/seq after 02400 batchs: 1017.7498168945312
INFO:root:Train (Epoch 64): Loss/seq after 02450 batchs: 1008.2942504882812
INFO:root:Train (Epoch 64): Loss/seq after 02500 batchs: 995.257080078125
INFO:root:Train (Epoch 64): Loss/seq after 02550 batchs: 986.273193359375
INFO:root:Train (Epoch 64): Loss/seq after 02600 batchs: 986.866943359375
INFO:root:Train (Epoch 64): Loss/seq after 02650 batchs: 984.8665771484375
INFO:root:Train (Epoch 64): Loss/seq after 02700 batchs: 981.6734008789062
INFO:root:Train (Epoch 64): Loss/seq after 02750 batchs: 1010.656982421875
INFO:root:Train (Epoch 64): Loss/seq after 02800 batchs: 1013.5499877929688
INFO:root:Train (Epoch 64): Loss/seq after 02850 batchs: 1011.5054321289062
INFO:root:Train (Epoch 64): Loss/seq after 02900 batchs: 1010.5074462890625
INFO:root:Train (Epoch 64): Loss/seq after 02950 batchs: 1004.8447265625
INFO:root:Train (Epoch 64): Loss/seq after 03000 batchs: 1006.0160522460938
INFO:root:Train (Epoch 64): Loss/seq after 03050 batchs: 1011.2056274414062
INFO:root:Train (Epoch 64): Loss/seq after 03100 batchs: 1017.7674560546875
INFO:root:Train (Epoch 64): Loss/seq after 03150 batchs: 1021.057373046875
INFO:root:Train (Epoch 64): Loss/seq after 03200 batchs: 1026.3941650390625
INFO:root:Train (Epoch 64): Loss/seq after 03250 batchs: 1028.3720703125
INFO:root:Train (Epoch 64): Loss/seq after 03300 batchs: 1026.3792724609375
INFO:root:Train (Epoch 64): Loss/seq after 03350 batchs: 1025.1640625
INFO:root:Train (Epoch 64): Loss/seq after 03400 batchs: 1019.4536743164062
INFO:root:Train (Epoch 64): Loss/seq after 03450 batchs: 1014.6522216796875
INFO:root:Train (Epoch 64): Loss/seq after 03500 batchs: 1013.8489990234375
INFO:root:Train (Epoch 64): Loss/seq after 03550 batchs: 1008.754150390625
INFO:root:Train (Epoch 64): Loss/seq after 03600 batchs: 1015.7479858398438
INFO:root:Train (Epoch 64): Loss/seq after 03650 batchs: 1011.1334838867188
INFO:root:Train (Epoch 64): Loss/seq after 03700 batchs: 1012.348876953125
INFO:root:Train (Epoch 64): Loss/seq after 03750 batchs: 1014.9532470703125
INFO:root:Train (Epoch 64): Loss/seq after 03800 batchs: 1010.456298828125
INFO:root:Train (Epoch 64): Loss/seq after 03850 batchs: 1008.0996704101562
INFO:root:Train (Epoch 64): Loss/seq after 03900 batchs: 1011.638427734375
INFO:root:Train (Epoch 64): Loss/seq after 03950 batchs: 1014.5760498046875
INFO:root:Train (Epoch 64): Loss/seq after 04000 batchs: 1008.1256713867188
INFO:root:Train (Epoch 64): Loss/seq after 04050 batchs: 1002.5886840820312
INFO:root:Train (Epoch 64): Loss/seq after 04100 batchs: 997.9878540039062
INFO:root:Train (Epoch 64): Loss/seq after 04150 batchs: 994.391357421875
INFO:root:Train (Epoch 64): Loss/seq after 04200 batchs: 990.6683349609375
INFO:root:Train (Epoch 64): Loss/seq after 04250 batchs: 988.1688842773438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 64): Loss/seq after 00000 batches: 872.97802734375
INFO:root:# Valid (Epoch 64): Loss/seq after 00050 batches: 1089.0234375
INFO:root:# Valid (Epoch 64): Loss/seq after 00100 batches: 1370.0855712890625
INFO:root:# Valid (Epoch 64): Loss/seq after 00150 batches: 1093.8084716796875
INFO:root:# Valid (Epoch 64): Loss/seq after 00200 batches: 984.4977416992188
INFO:root:Artifacts: Make stick videos for epoch 64
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_64_on_20220413_202940.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_64_index_1094_on_20220413_202940.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 65): Loss/seq after 00000 batchs: 1750.4473876953125
INFO:root:Train (Epoch 65): Loss/seq after 00050 batchs: 1222.9520263671875
INFO:root:Train (Epoch 65): Loss/seq after 00100 batchs: 1216.447265625
INFO:root:Train (Epoch 65): Loss/seq after 00150 batchs: 1113.222412109375
INFO:root:Train (Epoch 65): Loss/seq after 00200 batchs: 1223.969482421875
INFO:root:Train (Epoch 65): Loss/seq after 00250 batchs: 1365.1932373046875
INFO:root:Train (Epoch 65): Loss/seq after 00300 batchs: 1318.79345703125
INFO:root:Train (Epoch 65): Loss/seq after 00350 batchs: 1241.6861572265625
INFO:root:Train (Epoch 65): Loss/seq after 00400 batchs: 1265.840087890625
INFO:root:Train (Epoch 65): Loss/seq after 00450 batchs: 1221.8641357421875
INFO:root:Train (Epoch 65): Loss/seq after 00500 batchs: 1217.549072265625
INFO:root:Train (Epoch 65): Loss/seq after 00550 batchs: 1173.14990234375
INFO:root:Train (Epoch 65): Loss/seq after 00600 batchs: 1143.4755859375
INFO:root:Train (Epoch 65): Loss/seq after 00650 batchs: 1150.9722900390625
INFO:root:Train (Epoch 65): Loss/seq after 00700 batchs: 1123.593017578125
INFO:root:Train (Epoch 65): Loss/seq after 00750 batchs: 1150.9627685546875
INFO:root:Train (Epoch 65): Loss/seq after 00800 batchs: 1147.678955078125
INFO:root:Train (Epoch 65): Loss/seq after 00850 batchs: 1127.706298828125
INFO:root:Train (Epoch 65): Loss/seq after 00900 batchs: 1138.1162109375
INFO:root:Train (Epoch 65): Loss/seq after 00950 batchs: 1148.4078369140625
INFO:root:Train (Epoch 65): Loss/seq after 01000 batchs: 1143.133544921875
INFO:root:Train (Epoch 65): Loss/seq after 01050 batchs: 1127.7415771484375
INFO:root:Train (Epoch 65): Loss/seq after 01100 batchs: 1122.2672119140625
INFO:root:Train (Epoch 65): Loss/seq after 01150 batchs: 1113.583984375
INFO:root:Train (Epoch 65): Loss/seq after 01200 batchs: 1109.5811767578125
INFO:root:Train (Epoch 65): Loss/seq after 01250 batchs: 1103.0848388671875
INFO:root:Train (Epoch 65): Loss/seq after 01300 batchs: 1098.064208984375
INFO:root:Train (Epoch 65): Loss/seq after 01350 batchs: 1094.2967529296875
INFO:root:Train (Epoch 65): Loss/seq after 01400 batchs: 1106.34716796875
INFO:root:Train (Epoch 65): Loss/seq after 01450 batchs: 1102.42626953125
INFO:root:Train (Epoch 65): Loss/seq after 01500 batchs: 1100.0623779296875
INFO:root:Train (Epoch 65): Loss/seq after 01550 batchs: 1102.3792724609375
INFO:root:Train (Epoch 65): Loss/seq after 01600 batchs: 1091.6043701171875
INFO:root:Train (Epoch 65): Loss/seq after 01650 batchs: 1084.3675537109375
INFO:root:Train (Epoch 65): Loss/seq after 01700 batchs: 1080.2255859375
INFO:root:Train (Epoch 65): Loss/seq after 01750 batchs: 1074.25146484375
INFO:root:Train (Epoch 65): Loss/seq after 01800 batchs: 1065.5751953125
INFO:root:Train (Epoch 65): Loss/seq after 01850 batchs: 1056.32421875
INFO:root:Train (Epoch 65): Loss/seq after 01900 batchs: 1055.824951171875
INFO:root:Train (Epoch 65): Loss/seq after 01950 batchs: 1050.6898193359375
INFO:root:Train (Epoch 65): Loss/seq after 02000 batchs: 1045.5106201171875
INFO:root:Train (Epoch 65): Loss/seq after 02050 batchs: 1041.04638671875
INFO:root:Train (Epoch 65): Loss/seq after 02100 batchs: 1033.67333984375
INFO:root:Train (Epoch 65): Loss/seq after 02150 batchs: 1026.8936767578125
INFO:root:Train (Epoch 65): Loss/seq after 02200 batchs: 1019.663818359375
INFO:root:Train (Epoch 65): Loss/seq after 02250 batchs: 1018.9797973632812
INFO:root:Train (Epoch 65): Loss/seq after 02300 batchs: 1024.8773193359375
INFO:root:Train (Epoch 65): Loss/seq after 02350 batchs: 1017.5048828125
INFO:root:Train (Epoch 65): Loss/seq after 02400 batchs: 1016.0738525390625
INFO:root:Train (Epoch 65): Loss/seq after 02450 batchs: 1006.66943359375
INFO:root:Train (Epoch 65): Loss/seq after 02500 batchs: 993.6847534179688
INFO:root:Train (Epoch 65): Loss/seq after 02550 batchs: 984.6119995117188
INFO:root:Train (Epoch 65): Loss/seq after 02600 batchs: 984.8615112304688
INFO:root:Train (Epoch 65): Loss/seq after 02650 batchs: 982.4124145507812
INFO:root:Train (Epoch 65): Loss/seq after 02700 batchs: 979.2646484375
INFO:root:Train (Epoch 65): Loss/seq after 02750 batchs: 1008.115478515625
INFO:root:Train (Epoch 65): Loss/seq after 02800 batchs: 1011.655029296875
INFO:root:Train (Epoch 65): Loss/seq after 02850 batchs: 1009.19189453125
INFO:root:Train (Epoch 65): Loss/seq after 02900 batchs: 1008.8222045898438
INFO:root:Train (Epoch 65): Loss/seq after 02950 batchs: 1003.4886474609375
INFO:root:Train (Epoch 65): Loss/seq after 03000 batchs: 1004.626708984375
INFO:root:Train (Epoch 65): Loss/seq after 03050 batchs: 1009.849365234375
INFO:root:Train (Epoch 65): Loss/seq after 03100 batchs: 1016.6475830078125
INFO:root:Train (Epoch 65): Loss/seq after 03150 batchs: 1019.8969116210938
INFO:root:Train (Epoch 65): Loss/seq after 03200 batchs: 1025.16796875
INFO:root:Train (Epoch 65): Loss/seq after 03250 batchs: 1027.3148193359375
INFO:root:Train (Epoch 65): Loss/seq after 03300 batchs: 1025.5400390625
INFO:root:Train (Epoch 65): Loss/seq after 03350 batchs: 1024.763916015625
INFO:root:Train (Epoch 65): Loss/seq after 03400 batchs: 1018.8401489257812
INFO:root:Train (Epoch 65): Loss/seq after 03450 batchs: 1013.531982421875
INFO:root:Train (Epoch 65): Loss/seq after 03500 batchs: 1012.9529418945312
INFO:root:Train (Epoch 65): Loss/seq after 03550 batchs: 1007.4064331054688
INFO:root:Train (Epoch 65): Loss/seq after 03600 batchs: 1014.4447021484375
INFO:root:Train (Epoch 65): Loss/seq after 03650 batchs: 1010.263671875
INFO:root:Train (Epoch 65): Loss/seq after 03700 batchs: 1011.2235107421875
INFO:root:Train (Epoch 65): Loss/seq after 03750 batchs: 1013.7366333007812
INFO:root:Train (Epoch 65): Loss/seq after 03800 batchs: 1009.07470703125
INFO:root:Train (Epoch 65): Loss/seq after 03850 batchs: 1006.6358642578125
INFO:root:Train (Epoch 65): Loss/seq after 03900 batchs: 1010.1442260742188
INFO:root:Train (Epoch 65): Loss/seq after 03950 batchs: 1013.13818359375
INFO:root:Train (Epoch 65): Loss/seq after 04000 batchs: 1006.6839599609375
INFO:root:Train (Epoch 65): Loss/seq after 04050 batchs: 1001.078369140625
INFO:root:Train (Epoch 65): Loss/seq after 04100 batchs: 996.4952392578125
INFO:root:Train (Epoch 65): Loss/seq after 04150 batchs: 992.8367919921875
INFO:root:Train (Epoch 65): Loss/seq after 04200 batchs: 989.0086669921875
INFO:root:Train (Epoch 65): Loss/seq after 04250 batchs: 986.217529296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 65): Loss/seq after 00000 batches: 899.426025390625
INFO:root:# Valid (Epoch 65): Loss/seq after 00050 batches: 1109.53515625
INFO:root:# Valid (Epoch 65): Loss/seq after 00100 batches: 1399.865966796875
INFO:root:# Valid (Epoch 65): Loss/seq after 00150 batches: 1116.0699462890625
INFO:root:# Valid (Epoch 65): Loss/seq after 00200 batches: 1006.100830078125
INFO:root:Artifacts: Make stick videos for epoch 65
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_65_on_20220413_203459.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_65_index_1891_on_20220413_203459.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 66): Loss/seq after 00000 batchs: 1406.64501953125
INFO:root:Train (Epoch 66): Loss/seq after 00050 batchs: 1186.6357421875
INFO:root:Train (Epoch 66): Loss/seq after 00100 batchs: 1220.37890625
INFO:root:Train (Epoch 66): Loss/seq after 00150 batchs: 1120.2081298828125
INFO:root:Train (Epoch 66): Loss/seq after 00200 batchs: 1228.2509765625
INFO:root:Train (Epoch 66): Loss/seq after 00250 batchs: 1354.4661865234375
INFO:root:Train (Epoch 66): Loss/seq after 00300 batchs: 1309.8297119140625
INFO:root:Train (Epoch 66): Loss/seq after 00350 batchs: 1231.6571044921875
INFO:root:Train (Epoch 66): Loss/seq after 00400 batchs: 1248.7142333984375
INFO:root:Train (Epoch 66): Loss/seq after 00450 batchs: 1206.4246826171875
INFO:root:Train (Epoch 66): Loss/seq after 00500 batchs: 1201.87548828125
INFO:root:Train (Epoch 66): Loss/seq after 00550 batchs: 1158.83056640625
INFO:root:Train (Epoch 66): Loss/seq after 00600 batchs: 1128.2156982421875
INFO:root:Train (Epoch 66): Loss/seq after 00650 batchs: 1134.696044921875
INFO:root:Train (Epoch 66): Loss/seq after 00700 batchs: 1108.5283203125
INFO:root:Train (Epoch 66): Loss/seq after 00750 batchs: 1136.6976318359375
INFO:root:Train (Epoch 66): Loss/seq after 00800 batchs: 1131.5262451171875
INFO:root:Train (Epoch 66): Loss/seq after 00850 batchs: 1109.339111328125
INFO:root:Train (Epoch 66): Loss/seq after 00900 batchs: 1114.0799560546875
INFO:root:Train (Epoch 66): Loss/seq after 00950 batchs: 1124.2579345703125
INFO:root:Train (Epoch 66): Loss/seq after 01000 batchs: 1119.10498046875
INFO:root:Train (Epoch 66): Loss/seq after 01050 batchs: 1106.331298828125
INFO:root:Train (Epoch 66): Loss/seq after 01100 batchs: 1099.335693359375
INFO:root:Train (Epoch 66): Loss/seq after 01150 batchs: 1089.1700439453125
INFO:root:Train (Epoch 66): Loss/seq after 01200 batchs: 1085.75732421875
INFO:root:Train (Epoch 66): Loss/seq after 01250 batchs: 1080.4656982421875
INFO:root:Train (Epoch 66): Loss/seq after 01300 batchs: 1075.4771728515625
INFO:root:Train (Epoch 66): Loss/seq after 01350 batchs: 1071.6544189453125
INFO:root:Train (Epoch 66): Loss/seq after 01400 batchs: 1083.3143310546875
INFO:root:Train (Epoch 66): Loss/seq after 01450 batchs: 1080.056884765625
INFO:root:Train (Epoch 66): Loss/seq after 01500 batchs: 1078.116943359375
INFO:root:Train (Epoch 66): Loss/seq after 01550 batchs: 1079.565185546875
INFO:root:Train (Epoch 66): Loss/seq after 01600 batchs: 1068.98779296875
INFO:root:Train (Epoch 66): Loss/seq after 01650 batchs: 1062.06640625
INFO:root:Train (Epoch 66): Loss/seq after 01700 batchs: 1057.67529296875
INFO:root:Train (Epoch 66): Loss/seq after 01750 batchs: 1051.7803955078125
INFO:root:Train (Epoch 66): Loss/seq after 01800 batchs: 1043.213134765625
INFO:root:Train (Epoch 66): Loss/seq after 01850 batchs: 1034.13671875
INFO:root:Train (Epoch 66): Loss/seq after 01900 batchs: 1033.9083251953125
INFO:root:Train (Epoch 66): Loss/seq after 01950 batchs: 1028.7763671875
INFO:root:Train (Epoch 66): Loss/seq after 02000 batchs: 1023.9551391601562
INFO:root:Train (Epoch 66): Loss/seq after 02050 batchs: 1019.5602416992188
INFO:root:Train (Epoch 66): Loss/seq after 02100 batchs: 1012.3035888671875
INFO:root:Train (Epoch 66): Loss/seq after 02150 batchs: 1005.740234375
INFO:root:Train (Epoch 66): Loss/seq after 02200 batchs: 998.4915771484375
INFO:root:Train (Epoch 66): Loss/seq after 02250 batchs: 997.852294921875
INFO:root:Train (Epoch 66): Loss/seq after 02300 batchs: 1003.37060546875
INFO:root:Train (Epoch 66): Loss/seq after 02350 batchs: 996.2586059570312
INFO:root:Train (Epoch 66): Loss/seq after 02400 batchs: 993.885986328125
INFO:root:Train (Epoch 66): Loss/seq after 02450 batchs: 984.7239990234375
INFO:root:Train (Epoch 66): Loss/seq after 02500 batchs: 971.6217651367188
INFO:root:Train (Epoch 66): Loss/seq after 02550 batchs: 962.5628051757812
INFO:root:Train (Epoch 66): Loss/seq after 02600 batchs: 961.9801635742188
INFO:root:Train (Epoch 66): Loss/seq after 02650 batchs: 958.5081176757812
INFO:root:Train (Epoch 66): Loss/seq after 02700 batchs: 955.8474731445312
INFO:root:Train (Epoch 66): Loss/seq after 02750 batchs: 983.236328125
INFO:root:Train (Epoch 66): Loss/seq after 02800 batchs: 986.8082885742188
INFO:root:Train (Epoch 66): Loss/seq after 02850 batchs: 985.0401611328125
INFO:root:Train (Epoch 66): Loss/seq after 02900 batchs: 984.4237670898438
INFO:root:Train (Epoch 66): Loss/seq after 02950 batchs: 979.3870849609375
INFO:root:Train (Epoch 66): Loss/seq after 03000 batchs: 980.7078857421875
INFO:root:Train (Epoch 66): Loss/seq after 03050 batchs: 986.0390625
INFO:root:Train (Epoch 66): Loss/seq after 03100 batchs: 993.4647216796875
INFO:root:Train (Epoch 66): Loss/seq after 03150 batchs: 996.754150390625
INFO:root:Train (Epoch 66): Loss/seq after 03200 batchs: 1001.7159423828125
INFO:root:Train (Epoch 66): Loss/seq after 03250 batchs: 1003.9383544921875
INFO:root:Train (Epoch 66): Loss/seq after 03300 batchs: 1001.9366455078125
INFO:root:Train (Epoch 66): Loss/seq after 03350 batchs: 1000.9664916992188
INFO:root:Train (Epoch 66): Loss/seq after 03400 batchs: 994.7963256835938
INFO:root:Train (Epoch 66): Loss/seq after 03450 batchs: 989.7216796875
INFO:root:Train (Epoch 66): Loss/seq after 03500 batchs: 988.737548828125
INFO:root:Train (Epoch 66): Loss/seq after 03550 batchs: 983.0926513671875
INFO:root:Train (Epoch 66): Loss/seq after 03600 batchs: 990.3942260742188
INFO:root:Train (Epoch 66): Loss/seq after 03650 batchs: 985.9456787109375
INFO:root:Train (Epoch 66): Loss/seq after 03700 batchs: 986.8375854492188
INFO:root:Train (Epoch 66): Loss/seq after 03750 batchs: 989.548828125
INFO:root:Train (Epoch 66): Loss/seq after 03800 batchs: 984.863525390625
INFO:root:Train (Epoch 66): Loss/seq after 03850 batchs: 982.5580444335938
INFO:root:Train (Epoch 66): Loss/seq after 03900 batchs: 985.9466552734375
INFO:root:Train (Epoch 66): Loss/seq after 03950 batchs: 989.4727172851562
INFO:root:Train (Epoch 66): Loss/seq after 04000 batchs: 983.2124633789062
INFO:root:Train (Epoch 66): Loss/seq after 04050 batchs: 977.540283203125
INFO:root:Train (Epoch 66): Loss/seq after 04100 batchs: 973.0999145507812
INFO:root:Train (Epoch 66): Loss/seq after 04150 batchs: 969.640625
INFO:root:Train (Epoch 66): Loss/seq after 04200 batchs: 965.7544555664062
INFO:root:Train (Epoch 66): Loss/seq after 04250 batchs: 962.846923828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 66): Loss/seq after 00000 batches: 758.921875
INFO:root:# Valid (Epoch 66): Loss/seq after 00050 batches: 1017.04443359375
INFO:root:# Valid (Epoch 66): Loss/seq after 00100 batches: 1314.8743896484375
INFO:root:# Valid (Epoch 66): Loss/seq after 00150 batches: 1044.026611328125
INFO:root:# Valid (Epoch 66): Loss/seq after 00200 batches: 949.0892333984375
INFO:root:Artifacts: Make stick videos for epoch 66
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_66_on_20220413_204017.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_66_index_1154_on_20220413_204017.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 67): Loss/seq after 00000 batchs: 1730.0906982421875
INFO:root:Train (Epoch 67): Loss/seq after 00050 batchs: 1179.79833984375
INFO:root:Train (Epoch 67): Loss/seq after 00100 batchs: 1188.9578857421875
INFO:root:Train (Epoch 67): Loss/seq after 00150 batchs: 1094.5645751953125
INFO:root:Train (Epoch 67): Loss/seq after 00200 batchs: 1209.9761962890625
INFO:root:Train (Epoch 67): Loss/seq after 00250 batchs: 1330.5810546875
INFO:root:Train (Epoch 67): Loss/seq after 00300 batchs: 1287.3988037109375
INFO:root:Train (Epoch 67): Loss/seq after 00350 batchs: 1210.6346435546875
INFO:root:Train (Epoch 67): Loss/seq after 00400 batchs: 1234.603271484375
INFO:root:Train (Epoch 67): Loss/seq after 00450 batchs: 1192.92822265625
INFO:root:Train (Epoch 67): Loss/seq after 00500 batchs: 1183.31640625
INFO:root:Train (Epoch 67): Loss/seq after 00550 batchs: 1142.1177978515625
INFO:root:Train (Epoch 67): Loss/seq after 00600 batchs: 1113.3538818359375
INFO:root:Train (Epoch 67): Loss/seq after 00650 batchs: 1121.6597900390625
INFO:root:Train (Epoch 67): Loss/seq after 00700 batchs: 1095.4427490234375
INFO:root:Train (Epoch 67): Loss/seq after 00750 batchs: 1123.267822265625
INFO:root:Train (Epoch 67): Loss/seq after 00800 batchs: 1116.5682373046875
INFO:root:Train (Epoch 67): Loss/seq after 00850 batchs: 1092.8011474609375
INFO:root:Train (Epoch 67): Loss/seq after 00900 batchs: 1095.9971923828125
INFO:root:Train (Epoch 67): Loss/seq after 00950 batchs: 1105.4573974609375
INFO:root:Train (Epoch 67): Loss/seq after 01000 batchs: 1101.729736328125
INFO:root:Train (Epoch 67): Loss/seq after 01050 batchs: 1085.8433837890625
INFO:root:Train (Epoch 67): Loss/seq after 01100 batchs: 1077.6864013671875
INFO:root:Train (Epoch 67): Loss/seq after 01150 batchs: 1062.952880859375
INFO:root:Train (Epoch 67): Loss/seq after 01200 batchs: 1059.5638427734375
INFO:root:Train (Epoch 67): Loss/seq after 01250 batchs: 1053.719482421875
INFO:root:Train (Epoch 67): Loss/seq after 01300 batchs: 1047.3311767578125
INFO:root:Train (Epoch 67): Loss/seq after 01350 batchs: 1042.5225830078125
INFO:root:Train (Epoch 67): Loss/seq after 01400 batchs: 1056.0323486328125
INFO:root:Train (Epoch 67): Loss/seq after 01450 batchs: 1052.371337890625
INFO:root:Train (Epoch 67): Loss/seq after 01500 batchs: 1050.864501953125
INFO:root:Train (Epoch 67): Loss/seq after 01550 batchs: 1053.025634765625
INFO:root:Train (Epoch 67): Loss/seq after 01600 batchs: 1042.984619140625
INFO:root:Train (Epoch 67): Loss/seq after 01650 batchs: 1035.548828125
INFO:root:Train (Epoch 67): Loss/seq after 01700 batchs: 1032.1865234375
INFO:root:Train (Epoch 67): Loss/seq after 01750 batchs: 1026.1800537109375
INFO:root:Train (Epoch 67): Loss/seq after 01800 batchs: 1018.0372924804688
INFO:root:Train (Epoch 67): Loss/seq after 01850 batchs: 1009.1641235351562
INFO:root:Train (Epoch 67): Loss/seq after 01900 batchs: 1009.2842407226562
INFO:root:Train (Epoch 67): Loss/seq after 01950 batchs: 1004.1343994140625
INFO:root:Train (Epoch 67): Loss/seq after 02000 batchs: 999.3975830078125
INFO:root:Train (Epoch 67): Loss/seq after 02050 batchs: 995.3681030273438
INFO:root:Train (Epoch 67): Loss/seq after 02100 batchs: 988.3999633789062
INFO:root:Train (Epoch 67): Loss/seq after 02150 batchs: 982.312744140625
INFO:root:Train (Epoch 67): Loss/seq after 02200 batchs: 975.2282104492188
INFO:root:Train (Epoch 67): Loss/seq after 02250 batchs: 975.35986328125
INFO:root:Train (Epoch 67): Loss/seq after 02300 batchs: 981.353759765625
INFO:root:Train (Epoch 67): Loss/seq after 02350 batchs: 974.2756958007812
INFO:root:Train (Epoch 67): Loss/seq after 02400 batchs: 972.222412109375
INFO:root:Train (Epoch 67): Loss/seq after 02450 batchs: 963.37890625
INFO:root:Train (Epoch 67): Loss/seq after 02500 batchs: 950.418212890625
INFO:root:Train (Epoch 67): Loss/seq after 02550 batchs: 941.3059692382812
INFO:root:Train (Epoch 67): Loss/seq after 02600 batchs: 940.6575317382812
INFO:root:Train (Epoch 67): Loss/seq after 02650 batchs: 937.4204711914062
INFO:root:Train (Epoch 67): Loss/seq after 02700 batchs: 934.9703979492188
INFO:root:Train (Epoch 67): Loss/seq after 02750 batchs: 963.1651611328125
INFO:root:Train (Epoch 67): Loss/seq after 02800 batchs: 968.22265625
INFO:root:Train (Epoch 67): Loss/seq after 02850 batchs: 966.6808471679688
INFO:root:Train (Epoch 67): Loss/seq after 02900 batchs: 966.2806396484375
INFO:root:Train (Epoch 67): Loss/seq after 02950 batchs: 961.316650390625
INFO:root:Train (Epoch 67): Loss/seq after 03000 batchs: 962.7623291015625
INFO:root:Train (Epoch 67): Loss/seq after 03050 batchs: 968.0663452148438
INFO:root:Train (Epoch 67): Loss/seq after 03100 batchs: 974.7472534179688
INFO:root:Train (Epoch 67): Loss/seq after 03150 batchs: 979.8392944335938
INFO:root:Train (Epoch 67): Loss/seq after 03200 batchs: 985.849609375
INFO:root:Train (Epoch 67): Loss/seq after 03250 batchs: 988.1554565429688
INFO:root:Train (Epoch 67): Loss/seq after 03300 batchs: 987.2241821289062
INFO:root:Train (Epoch 67): Loss/seq after 03350 batchs: 986.8560791015625
INFO:root:Train (Epoch 67): Loss/seq after 03400 batchs: 980.7151489257812
INFO:root:Train (Epoch 67): Loss/seq after 03450 batchs: 975.7695922851562
INFO:root:Train (Epoch 67): Loss/seq after 03500 batchs: 975.0946655273438
INFO:root:Train (Epoch 67): Loss/seq after 03550 batchs: 969.76708984375
INFO:root:Train (Epoch 67): Loss/seq after 03600 batchs: 976.526611328125
INFO:root:Train (Epoch 67): Loss/seq after 03650 batchs: 971.7574462890625
INFO:root:Train (Epoch 67): Loss/seq after 03700 batchs: 972.2102661132812
INFO:root:Train (Epoch 67): Loss/seq after 03750 batchs: 975.0010986328125
INFO:root:Train (Epoch 67): Loss/seq after 03800 batchs: 970.350341796875
INFO:root:Train (Epoch 67): Loss/seq after 03850 batchs: 968.0620727539062
INFO:root:Train (Epoch 67): Loss/seq after 03900 batchs: 971.8397827148438
INFO:root:Train (Epoch 67): Loss/seq after 03950 batchs: 975.667236328125
INFO:root:Train (Epoch 67): Loss/seq after 04000 batchs: 969.570068359375
INFO:root:Train (Epoch 67): Loss/seq after 04050 batchs: 964.0052490234375
INFO:root:Train (Epoch 67): Loss/seq after 04100 batchs: 959.3839721679688
INFO:root:Train (Epoch 67): Loss/seq after 04150 batchs: 956.0029296875
INFO:root:Train (Epoch 67): Loss/seq after 04200 batchs: 952.3782348632812
INFO:root:Train (Epoch 67): Loss/seq after 04250 batchs: 949.6534423828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 67): Loss/seq after 00000 batches: 745.945556640625
INFO:root:# Valid (Epoch 67): Loss/seq after 00050 batches: 984.0821533203125
INFO:root:# Valid (Epoch 67): Loss/seq after 00100 batches: 1273.0242919921875
INFO:root:# Valid (Epoch 67): Loss/seq after 00150 batches: 998.1190185546875
INFO:root:# Valid (Epoch 67): Loss/seq after 00200 batches: 907.0100708007812
INFO:root:Artifacts: Make stick videos for epoch 67
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_67_on_20220413_204536.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_67_index_1660_on_20220413_204536.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 68): Loss/seq after 00000 batchs: 1430.1451416015625
INFO:root:Train (Epoch 68): Loss/seq after 00050 batchs: 1223.0841064453125
INFO:root:Train (Epoch 68): Loss/seq after 00100 batchs: 1205.6849365234375
INFO:root:Train (Epoch 68): Loss/seq after 00150 batchs: 1106.035888671875
INFO:root:Train (Epoch 68): Loss/seq after 00200 batchs: 1233.7952880859375
INFO:root:Train (Epoch 68): Loss/seq after 00250 batchs: 1361.2901611328125
INFO:root:Train (Epoch 68): Loss/seq after 00300 batchs: 1311.9376220703125
INFO:root:Train (Epoch 68): Loss/seq after 00350 batchs: 1230.0382080078125
INFO:root:Train (Epoch 68): Loss/seq after 00400 batchs: 1253.718994140625
INFO:root:Train (Epoch 68): Loss/seq after 00450 batchs: 1210.3931884765625
INFO:root:Train (Epoch 68): Loss/seq after 00500 batchs: 1198.89208984375
INFO:root:Train (Epoch 68): Loss/seq after 00550 batchs: 1154.31005859375
INFO:root:Train (Epoch 68): Loss/seq after 00600 batchs: 1119.5296630859375
INFO:root:Train (Epoch 68): Loss/seq after 00650 batchs: 1128.26953125
INFO:root:Train (Epoch 68): Loss/seq after 00700 batchs: 1101.889404296875
INFO:root:Train (Epoch 68): Loss/seq after 00750 batchs: 1130.0162353515625
INFO:root:Train (Epoch 68): Loss/seq after 00800 batchs: 1123.75
INFO:root:Train (Epoch 68): Loss/seq after 00850 batchs: 1096.63720703125
INFO:root:Train (Epoch 68): Loss/seq after 00900 batchs: 1096.5550537109375
INFO:root:Train (Epoch 68): Loss/seq after 00950 batchs: 1111.1119384765625
INFO:root:Train (Epoch 68): Loss/seq after 01000 batchs: 1105.4537353515625
INFO:root:Train (Epoch 68): Loss/seq after 01050 batchs: 1089.3079833984375
INFO:root:Train (Epoch 68): Loss/seq after 01100 batchs: 1081.232421875
INFO:root:Train (Epoch 68): Loss/seq after 01150 batchs: 1065.7049560546875
INFO:root:Train (Epoch 68): Loss/seq after 01200 batchs: 1062.3651123046875
INFO:root:Train (Epoch 68): Loss/seq after 01250 batchs: 1056.1839599609375
INFO:root:Train (Epoch 68): Loss/seq after 01300 batchs: 1050.340087890625
INFO:root:Train (Epoch 68): Loss/seq after 01350 batchs: 1046.7135009765625
INFO:root:Train (Epoch 68): Loss/seq after 01400 batchs: 1058.2127685546875
INFO:root:Train (Epoch 68): Loss/seq after 01450 batchs: 1054.7568359375
INFO:root:Train (Epoch 68): Loss/seq after 01500 batchs: 1053.126708984375
INFO:root:Train (Epoch 68): Loss/seq after 01550 batchs: 1056.021728515625
INFO:root:Train (Epoch 68): Loss/seq after 01600 batchs: 1046.5687255859375
INFO:root:Train (Epoch 68): Loss/seq after 01650 batchs: 1040.121826171875
INFO:root:Train (Epoch 68): Loss/seq after 01700 batchs: 1035.787109375
INFO:root:Train (Epoch 68): Loss/seq after 01750 batchs: 1029.13818359375
INFO:root:Train (Epoch 68): Loss/seq after 01800 batchs: 1020.7337036132812
INFO:root:Train (Epoch 68): Loss/seq after 01850 batchs: 1011.3150634765625
INFO:root:Train (Epoch 68): Loss/seq after 01900 batchs: 1011.3961791992188
INFO:root:Train (Epoch 68): Loss/seq after 01950 batchs: 1006.3401489257812
INFO:root:Train (Epoch 68): Loss/seq after 02000 batchs: 1001.9463500976562
INFO:root:Train (Epoch 68): Loss/seq after 02050 batchs: 997.7784423828125
INFO:root:Train (Epoch 68): Loss/seq after 02100 batchs: 990.19921875
INFO:root:Train (Epoch 68): Loss/seq after 02150 batchs: 983.8607788085938
INFO:root:Train (Epoch 68): Loss/seq after 02200 batchs: 976.7131958007812
INFO:root:Train (Epoch 68): Loss/seq after 02250 batchs: 977.7724609375
INFO:root:Train (Epoch 68): Loss/seq after 02300 batchs: 982.9972534179688
INFO:root:Train (Epoch 68): Loss/seq after 02350 batchs: 975.062744140625
INFO:root:Train (Epoch 68): Loss/seq after 02400 batchs: 972.6946411132812
INFO:root:Train (Epoch 68): Loss/seq after 02450 batchs: 963.5671997070312
INFO:root:Train (Epoch 68): Loss/seq after 02500 batchs: 950.4572143554688
INFO:root:Train (Epoch 68): Loss/seq after 02550 batchs: 940.8380737304688
INFO:root:Train (Epoch 68): Loss/seq after 02600 batchs: 940.2362670898438
INFO:root:Train (Epoch 68): Loss/seq after 02650 batchs: 937.0302734375
INFO:root:Train (Epoch 68): Loss/seq after 02700 batchs: 934.1685791015625
INFO:root:Train (Epoch 68): Loss/seq after 02750 batchs: 962.6547241210938
INFO:root:Train (Epoch 68): Loss/seq after 02800 batchs: 966.2102661132812
INFO:root:Train (Epoch 68): Loss/seq after 02850 batchs: 963.8196411132812
INFO:root:Train (Epoch 68): Loss/seq after 02900 batchs: 963.2321166992188
INFO:root:Train (Epoch 68): Loss/seq after 02950 batchs: 957.9931640625
INFO:root:Train (Epoch 68): Loss/seq after 03000 batchs: 959.4168090820312
INFO:root:Train (Epoch 68): Loss/seq after 03050 batchs: 964.4292602539062
INFO:root:Train (Epoch 68): Loss/seq after 03100 batchs: 971.0792846679688
INFO:root:Train (Epoch 68): Loss/seq after 03150 batchs: 975.2986450195312
INFO:root:Train (Epoch 68): Loss/seq after 03200 batchs: 980.8395385742188
INFO:root:Train (Epoch 68): Loss/seq after 03250 batchs: 983.4059448242188
INFO:root:Train (Epoch 68): Loss/seq after 03300 batchs: 980.7451171875
INFO:root:Train (Epoch 68): Loss/seq after 03350 batchs: 979.3522338867188
INFO:root:Train (Epoch 68): Loss/seq after 03400 batchs: 972.8506469726562
INFO:root:Train (Epoch 68): Loss/seq after 03450 batchs: 967.4849853515625
INFO:root:Train (Epoch 68): Loss/seq after 03500 batchs: 966.7048950195312
INFO:root:Train (Epoch 68): Loss/seq after 03550 batchs: 961.1321411132812
INFO:root:Train (Epoch 68): Loss/seq after 03600 batchs: 967.8429565429688
INFO:root:Train (Epoch 68): Loss/seq after 03650 batchs: 963.40283203125
INFO:root:Train (Epoch 68): Loss/seq after 03700 batchs: 963.9932250976562
INFO:root:Train (Epoch 68): Loss/seq after 03750 batchs: 967.0484619140625
INFO:root:Train (Epoch 68): Loss/seq after 03800 batchs: 962.1672973632812
INFO:root:Train (Epoch 68): Loss/seq after 03850 batchs: 959.8562622070312
INFO:root:Train (Epoch 68): Loss/seq after 03900 batchs: 963.3616333007812
INFO:root:Train (Epoch 68): Loss/seq after 03950 batchs: 966.8829956054688
INFO:root:Train (Epoch 68): Loss/seq after 04000 batchs: 960.86181640625
INFO:root:Train (Epoch 68): Loss/seq after 04050 batchs: 955.2546997070312
INFO:root:Train (Epoch 68): Loss/seq after 04100 batchs: 950.8358154296875
INFO:root:Train (Epoch 68): Loss/seq after 04150 batchs: 947.5799560546875
INFO:root:Train (Epoch 68): Loss/seq after 04200 batchs: 944.0926513671875
INFO:root:Train (Epoch 68): Loss/seq after 04250 batchs: 941.1719970703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 68): Loss/seq after 00000 batches: 834.0882568359375
INFO:root:# Valid (Epoch 68): Loss/seq after 00050 batches: 1009.7977294921875
INFO:root:# Valid (Epoch 68): Loss/seq after 00100 batches: 1297.4168701171875
INFO:root:# Valid (Epoch 68): Loss/seq after 00150 batches: 1014.8179931640625
INFO:root:# Valid (Epoch 68): Loss/seq after 00200 batches: 917.9016723632812
INFO:root:Artifacts: Make stick videos for epoch 68
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_68_on_20220413_205053.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_68_index_1044_on_20220413_205053.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 69): Loss/seq after 00000 batchs: 1336.9093017578125
INFO:root:Train (Epoch 69): Loss/seq after 00050 batchs: 1150.6580810546875
INFO:root:Train (Epoch 69): Loss/seq after 00100 batchs: 1178.389404296875
INFO:root:Train (Epoch 69): Loss/seq after 00150 batchs: 1075.9522705078125
INFO:root:Train (Epoch 69): Loss/seq after 00200 batchs: 1193.3565673828125
INFO:root:Train (Epoch 69): Loss/seq after 00250 batchs: 1315.5069580078125
INFO:root:Train (Epoch 69): Loss/seq after 00300 batchs: 1272.618408203125
INFO:root:Train (Epoch 69): Loss/seq after 00350 batchs: 1192.52734375
INFO:root:Train (Epoch 69): Loss/seq after 00400 batchs: 1213.3248291015625
INFO:root:Train (Epoch 69): Loss/seq after 00450 batchs: 1173.343505859375
INFO:root:Train (Epoch 69): Loss/seq after 00500 batchs: 1166.4498291015625
INFO:root:Train (Epoch 69): Loss/seq after 00550 batchs: 1125.1866455078125
INFO:root:Train (Epoch 69): Loss/seq after 00600 batchs: 1095.324462890625
INFO:root:Train (Epoch 69): Loss/seq after 00650 batchs: 1107.09912109375
INFO:root:Train (Epoch 69): Loss/seq after 00700 batchs: 1083.473388671875
INFO:root:Train (Epoch 69): Loss/seq after 00750 batchs: 1111.35986328125
INFO:root:Train (Epoch 69): Loss/seq after 00800 batchs: 1107.73095703125
INFO:root:Train (Epoch 69): Loss/seq after 00850 batchs: 1084.69775390625
INFO:root:Train (Epoch 69): Loss/seq after 00900 batchs: 1084.9268798828125
INFO:root:Train (Epoch 69): Loss/seq after 00950 batchs: 1094.627197265625
INFO:root:Train (Epoch 69): Loss/seq after 01000 batchs: 1088.7232666015625
INFO:root:Train (Epoch 69): Loss/seq after 01050 batchs: 1074.06201171875
INFO:root:Train (Epoch 69): Loss/seq after 01100 batchs: 1066.4490966796875
INFO:root:Train (Epoch 69): Loss/seq after 01150 batchs: 1051.6688232421875
INFO:root:Train (Epoch 69): Loss/seq after 01200 batchs: 1048.0689697265625
INFO:root:Train (Epoch 69): Loss/seq after 01250 batchs: 1042.7529296875
INFO:root:Train (Epoch 69): Loss/seq after 01300 batchs: 1035.475341796875
INFO:root:Train (Epoch 69): Loss/seq after 01350 batchs: 1030.1024169921875
INFO:root:Train (Epoch 69): Loss/seq after 01400 batchs: 1043.596435546875
INFO:root:Train (Epoch 69): Loss/seq after 01450 batchs: 1040.310791015625
INFO:root:Train (Epoch 69): Loss/seq after 01500 batchs: 1038.846923828125
INFO:root:Train (Epoch 69): Loss/seq after 01550 batchs: 1041.9351806640625
INFO:root:Train (Epoch 69): Loss/seq after 01600 batchs: 1032.157958984375
INFO:root:Train (Epoch 69): Loss/seq after 01650 batchs: 1025.640625
INFO:root:Train (Epoch 69): Loss/seq after 01700 batchs: 1022.8284301757812
INFO:root:Train (Epoch 69): Loss/seq after 01750 batchs: 1016.6929321289062
INFO:root:Train (Epoch 69): Loss/seq after 01800 batchs: 1008.5352783203125
INFO:root:Train (Epoch 69): Loss/seq after 01850 batchs: 999.87353515625
INFO:root:Train (Epoch 69): Loss/seq after 01900 batchs: 1000.485595703125
INFO:root:Train (Epoch 69): Loss/seq after 01950 batchs: 995.4801025390625
INFO:root:Train (Epoch 69): Loss/seq after 02000 batchs: 991.1161499023438
INFO:root:Train (Epoch 69): Loss/seq after 02050 batchs: 986.8706665039062
INFO:root:Train (Epoch 69): Loss/seq after 02100 batchs: 979.5364990234375
INFO:root:Train (Epoch 69): Loss/seq after 02150 batchs: 973.3777465820312
INFO:root:Train (Epoch 69): Loss/seq after 02200 batchs: 966.3063354492188
INFO:root:Train (Epoch 69): Loss/seq after 02250 batchs: 966.9896850585938
INFO:root:Train (Epoch 69): Loss/seq after 02300 batchs: 972.8035278320312
INFO:root:Train (Epoch 69): Loss/seq after 02350 batchs: 965.261474609375
INFO:root:Train (Epoch 69): Loss/seq after 02400 batchs: 963.42919921875
INFO:root:Train (Epoch 69): Loss/seq after 02450 batchs: 954.4559326171875
INFO:root:Train (Epoch 69): Loss/seq after 02500 batchs: 941.2852172851562
INFO:root:Train (Epoch 69): Loss/seq after 02550 batchs: 931.8458251953125
INFO:root:Train (Epoch 69): Loss/seq after 02600 batchs: 930.9384765625
INFO:root:Train (Epoch 69): Loss/seq after 02650 batchs: 927.9598388671875
INFO:root:Train (Epoch 69): Loss/seq after 02700 batchs: 925.4555053710938
INFO:root:Train (Epoch 69): Loss/seq after 02750 batchs: 952.948974609375
INFO:root:Train (Epoch 69): Loss/seq after 02800 batchs: 956.8380737304688
INFO:root:Train (Epoch 69): Loss/seq after 02850 batchs: 954.5389404296875
INFO:root:Train (Epoch 69): Loss/seq after 02900 batchs: 953.669921875
INFO:root:Train (Epoch 69): Loss/seq after 02950 batchs: 948.593505859375
INFO:root:Train (Epoch 69): Loss/seq after 03000 batchs: 950.1441650390625
INFO:root:Train (Epoch 69): Loss/seq after 03050 batchs: 955.3164672851562
INFO:root:Train (Epoch 69): Loss/seq after 03100 batchs: 962.1685180664062
INFO:root:Train (Epoch 69): Loss/seq after 03150 batchs: 966.0051879882812
INFO:root:Train (Epoch 69): Loss/seq after 03200 batchs: 971.0504150390625
INFO:root:Train (Epoch 69): Loss/seq after 03250 batchs: 973.8841552734375
INFO:root:Train (Epoch 69): Loss/seq after 03300 batchs: 971.6875610351562
INFO:root:Train (Epoch 69): Loss/seq after 03350 batchs: 970.1091918945312
INFO:root:Train (Epoch 69): Loss/seq after 03400 batchs: 963.6442260742188
INFO:root:Train (Epoch 69): Loss/seq after 03450 batchs: 958.6558837890625
INFO:root:Train (Epoch 69): Loss/seq after 03500 batchs: 957.7091674804688
INFO:root:Train (Epoch 69): Loss/seq after 03550 batchs: 952.4335327148438
INFO:root:Train (Epoch 69): Loss/seq after 03600 batchs: 959.256591796875
INFO:root:Train (Epoch 69): Loss/seq after 03650 batchs: 954.719482421875
INFO:root:Train (Epoch 69): Loss/seq after 03700 batchs: 955.2354736328125
INFO:root:Train (Epoch 69): Loss/seq after 03750 batchs: 958.2680053710938
INFO:root:Train (Epoch 69): Loss/seq after 03800 batchs: 953.5759887695312
INFO:root:Train (Epoch 69): Loss/seq after 03850 batchs: 951.2807006835938
INFO:root:Train (Epoch 69): Loss/seq after 03900 batchs: 955.1759643554688
INFO:root:Train (Epoch 69): Loss/seq after 03950 batchs: 958.796875
INFO:root:Train (Epoch 69): Loss/seq after 04000 batchs: 952.8729858398438
INFO:root:Train (Epoch 69): Loss/seq after 04050 batchs: 947.343505859375
INFO:root:Train (Epoch 69): Loss/seq after 04100 batchs: 943.0744018554688
INFO:root:Train (Epoch 69): Loss/seq after 04150 batchs: 939.8493041992188
INFO:root:Train (Epoch 69): Loss/seq after 04200 batchs: 936.3528442382812
INFO:root:Train (Epoch 69): Loss/seq after 04250 batchs: 933.6580200195312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 69): Loss/seq after 00000 batches: 767.9881591796875
INFO:root:# Valid (Epoch 69): Loss/seq after 00050 batches: 979.9884033203125
INFO:root:# Valid (Epoch 69): Loss/seq after 00100 batches: 1287.2071533203125
INFO:root:# Valid (Epoch 69): Loss/seq after 00150 batches: 1023.5966186523438
INFO:root:# Valid (Epoch 69): Loss/seq after 00200 batches: 932.207763671875
INFO:root:Artifacts: Make stick videos for epoch 69
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_69_on_20220413_205611.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_69_index_333_on_20220413_205611.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 70): Loss/seq after 00000 batchs: 1419.3092041015625
INFO:root:Train (Epoch 70): Loss/seq after 00050 batchs: 1177.43994140625
INFO:root:Train (Epoch 70): Loss/seq after 00100 batchs: 1193.861328125
INFO:root:Train (Epoch 70): Loss/seq after 00150 batchs: 1086.26904296875
INFO:root:Train (Epoch 70): Loss/seq after 00200 batchs: 1202.421142578125
INFO:root:Train (Epoch 70): Loss/seq after 00250 batchs: 1332.196533203125
INFO:root:Train (Epoch 70): Loss/seq after 00300 batchs: 1287.363037109375
INFO:root:Train (Epoch 70): Loss/seq after 00350 batchs: 1205.36669921875
INFO:root:Train (Epoch 70): Loss/seq after 00400 batchs: 1223.62548828125
INFO:root:Train (Epoch 70): Loss/seq after 00450 batchs: 1182.4193115234375
INFO:root:Train (Epoch 70): Loss/seq after 00500 batchs: 1177.62451171875
INFO:root:Train (Epoch 70): Loss/seq after 00550 batchs: 1134.0672607421875
INFO:root:Train (Epoch 70): Loss/seq after 00600 batchs: 1104.211181640625
INFO:root:Train (Epoch 70): Loss/seq after 00650 batchs: 1113.3717041015625
INFO:root:Train (Epoch 70): Loss/seq after 00700 batchs: 1087.3143310546875
INFO:root:Train (Epoch 70): Loss/seq after 00750 batchs: 1116.9962158203125
INFO:root:Train (Epoch 70): Loss/seq after 00800 batchs: 1110.5992431640625
INFO:root:Train (Epoch 70): Loss/seq after 00850 batchs: 1085.7445068359375
INFO:root:Train (Epoch 70): Loss/seq after 00900 batchs: 1083.9461669921875
INFO:root:Train (Epoch 70): Loss/seq after 00950 batchs: 1095.3377685546875
INFO:root:Train (Epoch 70): Loss/seq after 01000 batchs: 1092.4068603515625
INFO:root:Train (Epoch 70): Loss/seq after 01050 batchs: 1077.60302734375
INFO:root:Train (Epoch 70): Loss/seq after 01100 batchs: 1068.49951171875
INFO:root:Train (Epoch 70): Loss/seq after 01150 batchs: 1053.7628173828125
INFO:root:Train (Epoch 70): Loss/seq after 01200 batchs: 1050.0323486328125
INFO:root:Train (Epoch 70): Loss/seq after 01250 batchs: 1044.86328125
INFO:root:Train (Epoch 70): Loss/seq after 01300 batchs: 1038.688720703125
INFO:root:Train (Epoch 70): Loss/seq after 01350 batchs: 1032.01953125
INFO:root:Train (Epoch 70): Loss/seq after 01400 batchs: 1045.255859375
INFO:root:Train (Epoch 70): Loss/seq after 01450 batchs: 1041.7708740234375
INFO:root:Train (Epoch 70): Loss/seq after 01500 batchs: 1040.220458984375
INFO:root:Train (Epoch 70): Loss/seq after 01550 batchs: 1042.51025390625
INFO:root:Train (Epoch 70): Loss/seq after 01600 batchs: 1032.4642333984375
INFO:root:Train (Epoch 70): Loss/seq after 01650 batchs: 1024.8746337890625
INFO:root:Train (Epoch 70): Loss/seq after 01700 batchs: 1020.9814453125
INFO:root:Train (Epoch 70): Loss/seq after 01750 batchs: 1014.745361328125
INFO:root:Train (Epoch 70): Loss/seq after 01800 batchs: 1006.3553466796875
INFO:root:Train (Epoch 70): Loss/seq after 01850 batchs: 996.7922973632812
INFO:root:Train (Epoch 70): Loss/seq after 01900 batchs: 996.9892578125
INFO:root:Train (Epoch 70): Loss/seq after 01950 batchs: 992.1665649414062
INFO:root:Train (Epoch 70): Loss/seq after 02000 batchs: 987.846435546875
INFO:root:Train (Epoch 70): Loss/seq after 02050 batchs: 983.384521484375
INFO:root:Train (Epoch 70): Loss/seq after 02100 batchs: 976.1958618164062
INFO:root:Train (Epoch 70): Loss/seq after 02150 batchs: 970.1195678710938
INFO:root:Train (Epoch 70): Loss/seq after 02200 batchs: 963.2246704101562
INFO:root:Train (Epoch 70): Loss/seq after 02250 batchs: 963.3062133789062
INFO:root:Train (Epoch 70): Loss/seq after 02300 batchs: 976.3231811523438
INFO:root:Train (Epoch 70): Loss/seq after 02350 batchs: 968.4352416992188
INFO:root:Train (Epoch 70): Loss/seq after 02400 batchs: 966.4971923828125
INFO:root:Train (Epoch 70): Loss/seq after 02450 batchs: 957.2941284179688
INFO:root:Train (Epoch 70): Loss/seq after 02500 batchs: 943.8673706054688
INFO:root:Train (Epoch 70): Loss/seq after 02550 batchs: 934.2754516601562
INFO:root:Train (Epoch 70): Loss/seq after 02600 batchs: 933.5499877929688
INFO:root:Train (Epoch 70): Loss/seq after 02650 batchs: 929.517822265625
INFO:root:Train (Epoch 70): Loss/seq after 02700 batchs: 926.8751831054688
INFO:root:Train (Epoch 70): Loss/seq after 02750 batchs: 954.4376220703125
INFO:root:Train (Epoch 70): Loss/seq after 02800 batchs: 959.7703247070312
INFO:root:Train (Epoch 70): Loss/seq after 02850 batchs: 957.3070678710938
INFO:root:Train (Epoch 70): Loss/seq after 02900 batchs: 956.8056030273438
INFO:root:Train (Epoch 70): Loss/seq after 02950 batchs: 951.7130737304688
INFO:root:Train (Epoch 70): Loss/seq after 03000 batchs: 953.059326171875
INFO:root:Train (Epoch 70): Loss/seq after 03050 batchs: 958.3099975585938
INFO:root:Train (Epoch 70): Loss/seq after 03100 batchs: 965.1325073242188
INFO:root:Train (Epoch 70): Loss/seq after 03150 batchs: 968.6700439453125
INFO:root:Train (Epoch 70): Loss/seq after 03200 batchs: 974.28125
INFO:root:Train (Epoch 70): Loss/seq after 03250 batchs: 977.1885375976562
INFO:root:Train (Epoch 70): Loss/seq after 03300 batchs: 975.5526123046875
INFO:root:Train (Epoch 70): Loss/seq after 03350 batchs: 974.2937622070312
INFO:root:Train (Epoch 70): Loss/seq after 03400 batchs: 967.5081787109375
INFO:root:Train (Epoch 70): Loss/seq after 03450 batchs: 962.4420776367188
INFO:root:Train (Epoch 70): Loss/seq after 03500 batchs: 961.58935546875
INFO:root:Train (Epoch 70): Loss/seq after 03550 batchs: 956.1513671875
INFO:root:Train (Epoch 70): Loss/seq after 03600 batchs: 963.0890502929688
INFO:root:Train (Epoch 70): Loss/seq after 03650 batchs: 958.382080078125
INFO:root:Train (Epoch 70): Loss/seq after 03700 batchs: 959.2714233398438
INFO:root:Train (Epoch 70): Loss/seq after 03750 batchs: 962.1758422851562
INFO:root:Train (Epoch 70): Loss/seq after 03800 batchs: 957.5477905273438
INFO:root:Train (Epoch 70): Loss/seq after 03850 batchs: 955.1595458984375
INFO:root:Train (Epoch 70): Loss/seq after 03900 batchs: 958.2269287109375
INFO:root:Train (Epoch 70): Loss/seq after 03950 batchs: 961.5794067382812
INFO:root:Train (Epoch 70): Loss/seq after 04000 batchs: 955.5631103515625
INFO:root:Train (Epoch 70): Loss/seq after 04050 batchs: 949.6787109375
INFO:root:Train (Epoch 70): Loss/seq after 04100 batchs: 945.3313598632812
INFO:root:Train (Epoch 70): Loss/seq after 04150 batchs: 942.050537109375
INFO:root:Train (Epoch 70): Loss/seq after 04200 batchs: 938.2489013671875
INFO:root:Train (Epoch 70): Loss/seq after 04250 batchs: 935.0657958984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 70): Loss/seq after 00000 batches: 711.2987670898438
INFO:root:# Valid (Epoch 70): Loss/seq after 00050 batches: 915.1007690429688
INFO:root:# Valid (Epoch 70): Loss/seq after 00100 batches: 1231.72216796875
INFO:root:# Valid (Epoch 70): Loss/seq after 00150 batches: 964.872314453125
INFO:root:# Valid (Epoch 70): Loss/seq after 00200 batches: 883.2466430664062
INFO:root:Artifacts: Make stick videos for epoch 70
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_70_on_20220413_210129.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_70_index_403_on_20220413_210129.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 71): Loss/seq after 00000 batchs: 1356.05419921875
INFO:root:Train (Epoch 71): Loss/seq after 00050 batchs: 1134.968505859375
INFO:root:Train (Epoch 71): Loss/seq after 00100 batchs: 1171.0181884765625
INFO:root:Train (Epoch 71): Loss/seq after 00150 batchs: 1061.6402587890625
INFO:root:Train (Epoch 71): Loss/seq after 00200 batchs: 1181.740478515625
INFO:root:Train (Epoch 71): Loss/seq after 00250 batchs: 1314.4554443359375
INFO:root:Train (Epoch 71): Loss/seq after 00300 batchs: 1271.6103515625
INFO:root:Train (Epoch 71): Loss/seq after 00350 batchs: 1191.9853515625
INFO:root:Train (Epoch 71): Loss/seq after 00400 batchs: 1210.211181640625
INFO:root:Train (Epoch 71): Loss/seq after 00450 batchs: 1171.064453125
INFO:root:Train (Epoch 71): Loss/seq after 00500 batchs: 1164.1256103515625
INFO:root:Train (Epoch 71): Loss/seq after 00550 batchs: 1121.7333984375
INFO:root:Train (Epoch 71): Loss/seq after 00600 batchs: 1090.439697265625
INFO:root:Train (Epoch 71): Loss/seq after 00650 batchs: 1099.920654296875
INFO:root:Train (Epoch 71): Loss/seq after 00700 batchs: 1075.87646484375
INFO:root:Train (Epoch 71): Loss/seq after 00750 batchs: 1104.0308837890625
INFO:root:Train (Epoch 71): Loss/seq after 00800 batchs: 1097.9366455078125
INFO:root:Train (Epoch 71): Loss/seq after 00850 batchs: 1073.384033203125
INFO:root:Train (Epoch 71): Loss/seq after 00900 batchs: 1073.6014404296875
INFO:root:Train (Epoch 71): Loss/seq after 00950 batchs: 1085.664306640625
INFO:root:Train (Epoch 71): Loss/seq after 01000 batchs: 1081.3887939453125
INFO:root:Train (Epoch 71): Loss/seq after 01050 batchs: 1064.1644287109375
INFO:root:Train (Epoch 71): Loss/seq after 01100 batchs: 1055.1895751953125
INFO:root:Train (Epoch 71): Loss/seq after 01150 batchs: 1039.28466796875
INFO:root:Train (Epoch 71): Loss/seq after 01200 batchs: 1035.4150390625
INFO:root:Train (Epoch 71): Loss/seq after 01250 batchs: 1030.36865234375
INFO:root:Train (Epoch 71): Loss/seq after 01300 batchs: 1026.9739990234375
INFO:root:Train (Epoch 71): Loss/seq after 01350 batchs: 1020.5130004882812
INFO:root:Train (Epoch 71): Loss/seq after 01400 batchs: 1033.6903076171875
INFO:root:Train (Epoch 71): Loss/seq after 01450 batchs: 1029.6849365234375
INFO:root:Train (Epoch 71): Loss/seq after 01500 batchs: 1028.49267578125
INFO:root:Train (Epoch 71): Loss/seq after 01550 batchs: 1030.3133544921875
INFO:root:Train (Epoch 71): Loss/seq after 01600 batchs: 1020.82568359375
INFO:root:Train (Epoch 71): Loss/seq after 01650 batchs: 1013.5886840820312
INFO:root:Train (Epoch 71): Loss/seq after 01700 batchs: 1010.0089111328125
INFO:root:Train (Epoch 71): Loss/seq after 01750 batchs: 1003.5377197265625
INFO:root:Train (Epoch 71): Loss/seq after 01800 batchs: 995.5972900390625
INFO:root:Train (Epoch 71): Loss/seq after 01850 batchs: 986.8552856445312
INFO:root:Train (Epoch 71): Loss/seq after 01900 batchs: 987.3007202148438
INFO:root:Train (Epoch 71): Loss/seq after 01950 batchs: 983.1493530273438
INFO:root:Train (Epoch 71): Loss/seq after 02000 batchs: 979.0045166015625
INFO:root:Train (Epoch 71): Loss/seq after 02050 batchs: 975.134521484375
INFO:root:Train (Epoch 71): Loss/seq after 02100 batchs: 968.142822265625
INFO:root:Train (Epoch 71): Loss/seq after 02150 batchs: 961.97216796875
INFO:root:Train (Epoch 71): Loss/seq after 02200 batchs: 955.3130493164062
INFO:root:Train (Epoch 71): Loss/seq after 02250 batchs: 955.8807373046875
INFO:root:Train (Epoch 71): Loss/seq after 02300 batchs: 961.8650512695312
INFO:root:Train (Epoch 71): Loss/seq after 02350 batchs: 954.1729736328125
INFO:root:Train (Epoch 71): Loss/seq after 02400 batchs: 952.3772583007812
INFO:root:Train (Epoch 71): Loss/seq after 02450 batchs: 943.49365234375
INFO:root:Train (Epoch 71): Loss/seq after 02500 batchs: 930.3907470703125
INFO:root:Train (Epoch 71): Loss/seq after 02550 batchs: 921.0592041015625
INFO:root:Train (Epoch 71): Loss/seq after 02600 batchs: 919.9005126953125
INFO:root:Train (Epoch 71): Loss/seq after 02650 batchs: 916.5133666992188
INFO:root:Train (Epoch 71): Loss/seq after 02700 batchs: 913.984375
INFO:root:Train (Epoch 71): Loss/seq after 02750 batchs: 941.7491455078125
INFO:root:Train (Epoch 71): Loss/seq after 02800 batchs: 945.7946166992188
INFO:root:Train (Epoch 71): Loss/seq after 02850 batchs: 943.5276489257812
INFO:root:Train (Epoch 71): Loss/seq after 02900 batchs: 943.1345825195312
INFO:root:Train (Epoch 71): Loss/seq after 02950 batchs: 938.2664184570312
INFO:root:Train (Epoch 71): Loss/seq after 03000 batchs: 939.8908081054688
INFO:root:Train (Epoch 71): Loss/seq after 03050 batchs: 945.1402587890625
INFO:root:Train (Epoch 71): Loss/seq after 03100 batchs: 951.9432983398438
INFO:root:Train (Epoch 71): Loss/seq after 03150 batchs: 954.9720458984375
INFO:root:Train (Epoch 71): Loss/seq after 03200 batchs: 960.9472045898438
INFO:root:Train (Epoch 71): Loss/seq after 03250 batchs: 963.63623046875
INFO:root:Train (Epoch 71): Loss/seq after 03300 batchs: 962.0748291015625
INFO:root:Train (Epoch 71): Loss/seq after 03350 batchs: 961.3357543945312
INFO:root:Train (Epoch 71): Loss/seq after 03400 batchs: 954.9977416992188
INFO:root:Train (Epoch 71): Loss/seq after 03450 batchs: 950.3401489257812
INFO:root:Train (Epoch 71): Loss/seq after 03500 batchs: 949.57177734375
INFO:root:Train (Epoch 71): Loss/seq after 03550 batchs: 944.1856079101562
INFO:root:Train (Epoch 71): Loss/seq after 03600 batchs: 951.158447265625
INFO:root:Train (Epoch 71): Loss/seq after 03650 batchs: 946.5860595703125
INFO:root:Train (Epoch 71): Loss/seq after 03700 batchs: 947.6953735351562
INFO:root:Train (Epoch 71): Loss/seq after 03750 batchs: 950.805908203125
INFO:root:Train (Epoch 71): Loss/seq after 03800 batchs: 946.1863403320312
INFO:root:Train (Epoch 71): Loss/seq after 03850 batchs: 944.0478515625
INFO:root:Train (Epoch 71): Loss/seq after 03900 batchs: 948.00830078125
INFO:root:Train (Epoch 71): Loss/seq after 03950 batchs: 951.908447265625
INFO:root:Train (Epoch 71): Loss/seq after 04000 batchs: 945.9926147460938
INFO:root:Train (Epoch 71): Loss/seq after 04050 batchs: 940.4005126953125
INFO:root:Train (Epoch 71): Loss/seq after 04100 batchs: 936.0352172851562
INFO:root:Train (Epoch 71): Loss/seq after 04150 batchs: 932.8638305664062
INFO:root:Train (Epoch 71): Loss/seq after 04200 batchs: 929.4844360351562
INFO:root:Train (Epoch 71): Loss/seq after 04250 batchs: 926.2373657226562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 71): Loss/seq after 00000 batches: 633.1693115234375
INFO:root:# Valid (Epoch 71): Loss/seq after 00050 batches: 937.8955688476562
INFO:root:# Valid (Epoch 71): Loss/seq after 00100 batches: 1214.626953125
INFO:root:# Valid (Epoch 71): Loss/seq after 00150 batches: 955.828125
INFO:root:# Valid (Epoch 71): Loss/seq after 00200 batches: 872.0910034179688
INFO:root:Artifacts: Make stick videos for epoch 71
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_71_on_20220413_210645.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_71_index_494_on_20220413_210645.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 72): Loss/seq after 00000 batchs: 1432.1658935546875
INFO:root:Train (Epoch 72): Loss/seq after 00050 batchs: 1148.5850830078125
INFO:root:Train (Epoch 72): Loss/seq after 00100 batchs: 1201.791259765625
INFO:root:Train (Epoch 72): Loss/seq after 00150 batchs: 1089.517333984375
INFO:root:Train (Epoch 72): Loss/seq after 00200 batchs: 1200.7962646484375
INFO:root:Train (Epoch 72): Loss/seq after 00250 batchs: 1316.1572265625
INFO:root:Train (Epoch 72): Loss/seq after 00300 batchs: 1273.080322265625
INFO:root:Train (Epoch 72): Loss/seq after 00350 batchs: 1190.131591796875
INFO:root:Train (Epoch 72): Loss/seq after 00400 batchs: 1209.04052734375
INFO:root:Train (Epoch 72): Loss/seq after 00450 batchs: 1169.462890625
INFO:root:Train (Epoch 72): Loss/seq after 00500 batchs: 1158.4539794921875
INFO:root:Train (Epoch 72): Loss/seq after 00550 batchs: 1115.42041015625
INFO:root:Train (Epoch 72): Loss/seq after 00600 batchs: 1083.7913818359375
INFO:root:Train (Epoch 72): Loss/seq after 00650 batchs: 1094.2034912109375
INFO:root:Train (Epoch 72): Loss/seq after 00700 batchs: 1069.7069091796875
INFO:root:Train (Epoch 72): Loss/seq after 00750 batchs: 1099.3477783203125
INFO:root:Train (Epoch 72): Loss/seq after 00800 batchs: 1094.8463134765625
INFO:root:Train (Epoch 72): Loss/seq after 00850 batchs: 1069.2972412109375
INFO:root:Train (Epoch 72): Loss/seq after 00900 batchs: 1070.9725341796875
INFO:root:Train (Epoch 72): Loss/seq after 00950 batchs: 1082.422119140625
INFO:root:Train (Epoch 72): Loss/seq after 01000 batchs: 1076.23291015625
INFO:root:Train (Epoch 72): Loss/seq after 01050 batchs: 1059.18603515625
INFO:root:Train (Epoch 72): Loss/seq after 01100 batchs: 1048.565673828125
INFO:root:Train (Epoch 72): Loss/seq after 01150 batchs: 1031.6693115234375
INFO:root:Train (Epoch 72): Loss/seq after 01200 batchs: 1028.3065185546875
INFO:root:Train (Epoch 72): Loss/seq after 01250 batchs: 1023.2116088867188
INFO:root:Train (Epoch 72): Loss/seq after 01300 batchs: 1016.5264892578125
INFO:root:Train (Epoch 72): Loss/seq after 01350 batchs: 1009.2000732421875
INFO:root:Train (Epoch 72): Loss/seq after 01400 batchs: 1022.1142578125
INFO:root:Train (Epoch 72): Loss/seq after 01450 batchs: 1019.1937255859375
INFO:root:Train (Epoch 72): Loss/seq after 01500 batchs: 1018.1004638671875
INFO:root:Train (Epoch 72): Loss/seq after 01550 batchs: 1020.8655395507812
INFO:root:Train (Epoch 72): Loss/seq after 01600 batchs: 1011.9136962890625
INFO:root:Train (Epoch 72): Loss/seq after 01650 batchs: 1005.0621948242188
INFO:root:Train (Epoch 72): Loss/seq after 01700 batchs: 1002.2577514648438
INFO:root:Train (Epoch 72): Loss/seq after 01750 batchs: 996.98779296875
INFO:root:Train (Epoch 72): Loss/seq after 01800 batchs: 989.0360717773438
INFO:root:Train (Epoch 72): Loss/seq after 01850 batchs: 980.3151245117188
INFO:root:Train (Epoch 72): Loss/seq after 01900 batchs: 980.8502197265625
INFO:root:Train (Epoch 72): Loss/seq after 01950 batchs: 976.06787109375
INFO:root:Train (Epoch 72): Loss/seq after 02000 batchs: 972.2618408203125
INFO:root:Train (Epoch 72): Loss/seq after 02050 batchs: 968.2152099609375
INFO:root:Train (Epoch 72): Loss/seq after 02100 batchs: 961.4722290039062
INFO:root:Train (Epoch 72): Loss/seq after 02150 batchs: 955.4466552734375
INFO:root:Train (Epoch 72): Loss/seq after 02200 batchs: 948.8614501953125
INFO:root:Train (Epoch 72): Loss/seq after 02250 batchs: 949.3077392578125
INFO:root:Train (Epoch 72): Loss/seq after 02300 batchs: 955.3536376953125
INFO:root:Train (Epoch 72): Loss/seq after 02350 batchs: 947.98486328125
INFO:root:Train (Epoch 72): Loss/seq after 02400 batchs: 946.090576171875
INFO:root:Train (Epoch 72): Loss/seq after 02450 batchs: 937.3804321289062
INFO:root:Train (Epoch 72): Loss/seq after 02500 batchs: 924.293212890625
INFO:root:Train (Epoch 72): Loss/seq after 02550 batchs: 914.878662109375
INFO:root:Train (Epoch 72): Loss/seq after 02600 batchs: 913.9068603515625
INFO:root:Train (Epoch 72): Loss/seq after 02650 batchs: 910.4164428710938
INFO:root:Train (Epoch 72): Loss/seq after 02700 batchs: 907.50048828125
INFO:root:Train (Epoch 72): Loss/seq after 02750 batchs: 934.6730346679688
INFO:root:Train (Epoch 72): Loss/seq after 02800 batchs: 939.05078125
INFO:root:Train (Epoch 72): Loss/seq after 02850 batchs: 936.9342651367188
INFO:root:Train (Epoch 72): Loss/seq after 02900 batchs: 936.7695922851562
INFO:root:Train (Epoch 72): Loss/seq after 02950 batchs: 931.8930053710938
INFO:root:Train (Epoch 72): Loss/seq after 03000 batchs: 933.6016845703125
INFO:root:Train (Epoch 72): Loss/seq after 03050 batchs: 939.1348266601562
INFO:root:Train (Epoch 72): Loss/seq after 03100 batchs: 945.545654296875
INFO:root:Train (Epoch 72): Loss/seq after 03150 batchs: 949.1517333984375
INFO:root:Train (Epoch 72): Loss/seq after 03200 batchs: 954.5736694335938
INFO:root:Train (Epoch 72): Loss/seq after 03250 batchs: 957.606689453125
INFO:root:Train (Epoch 72): Loss/seq after 03300 batchs: 955.5485229492188
INFO:root:Train (Epoch 72): Loss/seq after 03350 batchs: 954.3394775390625
INFO:root:Train (Epoch 72): Loss/seq after 03400 batchs: 947.5499267578125
INFO:root:Train (Epoch 72): Loss/seq after 03450 batchs: 942.7764892578125
INFO:root:Train (Epoch 72): Loss/seq after 03500 batchs: 941.5703125
INFO:root:Train (Epoch 72): Loss/seq after 03550 batchs: 936.671142578125
INFO:root:Train (Epoch 72): Loss/seq after 03600 batchs: 944.7330322265625
INFO:root:Train (Epoch 72): Loss/seq after 03650 batchs: 940.0433959960938
INFO:root:Train (Epoch 72): Loss/seq after 03700 batchs: 940.2647094726562
INFO:root:Train (Epoch 72): Loss/seq after 03750 batchs: 943.5673217773438
INFO:root:Train (Epoch 72): Loss/seq after 03800 batchs: 939.0468139648438
INFO:root:Train (Epoch 72): Loss/seq after 03850 batchs: 936.8372192382812
INFO:root:Train (Epoch 72): Loss/seq after 03900 batchs: 940.4202270507812
INFO:root:Train (Epoch 72): Loss/seq after 03950 batchs: 944.1988525390625
INFO:root:Train (Epoch 72): Loss/seq after 04000 batchs: 938.3590698242188
INFO:root:Train (Epoch 72): Loss/seq after 04050 batchs: 932.7125244140625
INFO:root:Train (Epoch 72): Loss/seq after 04100 batchs: 928.3714599609375
INFO:root:Train (Epoch 72): Loss/seq after 04150 batchs: 925.3644409179688
INFO:root:Train (Epoch 72): Loss/seq after 04200 batchs: 921.8197631835938
INFO:root:Train (Epoch 72): Loss/seq after 04250 batchs: 918.8540649414062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 72): Loss/seq after 00000 batches: 764.2755737304688
INFO:root:# Valid (Epoch 72): Loss/seq after 00050 batches: 928.044921875
INFO:root:# Valid (Epoch 72): Loss/seq after 00100 batches: 1217.25341796875
INFO:root:# Valid (Epoch 72): Loss/seq after 00150 batches: 954.9945068359375
INFO:root:# Valid (Epoch 72): Loss/seq after 00200 batches: 875.1014404296875
INFO:root:Artifacts: Make stick videos for epoch 72
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_72_on_20220413_211204.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_72_index_430_on_20220413_211204.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 73): Loss/seq after 00000 batchs: 1702.02392578125
INFO:root:Train (Epoch 73): Loss/seq after 00050 batchs: 1153.170654296875
INFO:root:Train (Epoch 73): Loss/seq after 00100 batchs: 1175.5701904296875
INFO:root:Train (Epoch 73): Loss/seq after 00150 batchs: 1067.7135009765625
INFO:root:Train (Epoch 73): Loss/seq after 00200 batchs: 1186.3707275390625
INFO:root:Train (Epoch 73): Loss/seq after 00250 batchs: 1308.9036865234375
INFO:root:Train (Epoch 73): Loss/seq after 00300 batchs: 1266.041259765625
INFO:root:Train (Epoch 73): Loss/seq after 00350 batchs: 1185.435302734375
INFO:root:Train (Epoch 73): Loss/seq after 00400 batchs: 1205.9681396484375
INFO:root:Train (Epoch 73): Loss/seq after 00450 batchs: 1166.8433837890625
INFO:root:Train (Epoch 73): Loss/seq after 00500 batchs: 1154.3787841796875
INFO:root:Train (Epoch 73): Loss/seq after 00550 batchs: 1113.0748291015625
INFO:root:Train (Epoch 73): Loss/seq after 00600 batchs: 1077.80224609375
INFO:root:Train (Epoch 73): Loss/seq after 00650 batchs: 1089.1146240234375
INFO:root:Train (Epoch 73): Loss/seq after 00700 batchs: 1064.35595703125
INFO:root:Train (Epoch 73): Loss/seq after 00750 batchs: 1093.503173828125
INFO:root:Train (Epoch 73): Loss/seq after 00800 batchs: 1087.5594482421875
INFO:root:Train (Epoch 73): Loss/seq after 00850 batchs: 1062.4739990234375
INFO:root:Train (Epoch 73): Loss/seq after 00900 batchs: 1058.6241455078125
INFO:root:Train (Epoch 73): Loss/seq after 00950 batchs: 1068.1953125
INFO:root:Train (Epoch 73): Loss/seq after 01000 batchs: 1065.5654296875
INFO:root:Train (Epoch 73): Loss/seq after 01050 batchs: 1048.33056640625
INFO:root:Train (Epoch 73): Loss/seq after 01100 batchs: 1041.465087890625
INFO:root:Train (Epoch 73): Loss/seq after 01150 batchs: 1025.7777099609375
INFO:root:Train (Epoch 73): Loss/seq after 01200 batchs: 1022.5540161132812
INFO:root:Train (Epoch 73): Loss/seq after 01250 batchs: 1017.1580810546875
INFO:root:Train (Epoch 73): Loss/seq after 01300 batchs: 1011.48583984375
INFO:root:Train (Epoch 73): Loss/seq after 01350 batchs: 1004.2604370117188
INFO:root:Train (Epoch 73): Loss/seq after 01400 batchs: 1018.2140502929688
INFO:root:Train (Epoch 73): Loss/seq after 01450 batchs: 1015.3557739257812
INFO:root:Train (Epoch 73): Loss/seq after 01500 batchs: 1014.8795166015625
INFO:root:Train (Epoch 73): Loss/seq after 01550 batchs: 1016.355224609375
INFO:root:Train (Epoch 73): Loss/seq after 01600 batchs: 1006.7034301757812
INFO:root:Train (Epoch 73): Loss/seq after 01650 batchs: 999.7765502929688
INFO:root:Train (Epoch 73): Loss/seq after 01700 batchs: 996.6776733398438
INFO:root:Train (Epoch 73): Loss/seq after 01750 batchs: 990.9473876953125
INFO:root:Train (Epoch 73): Loss/seq after 01800 batchs: 982.8228759765625
INFO:root:Train (Epoch 73): Loss/seq after 01850 batchs: 974.3577270507812
INFO:root:Train (Epoch 73): Loss/seq after 01900 batchs: 974.8274536132812
INFO:root:Train (Epoch 73): Loss/seq after 01950 batchs: 970.6318969726562
INFO:root:Train (Epoch 73): Loss/seq after 02000 batchs: 966.78125
INFO:root:Train (Epoch 73): Loss/seq after 02050 batchs: 962.6498413085938
INFO:root:Train (Epoch 73): Loss/seq after 02100 batchs: 955.8467407226562
INFO:root:Train (Epoch 73): Loss/seq after 02150 batchs: 949.82373046875
INFO:root:Train (Epoch 73): Loss/seq after 02200 batchs: 943.357177734375
INFO:root:Train (Epoch 73): Loss/seq after 02250 batchs: 943.2747802734375
INFO:root:Train (Epoch 73): Loss/seq after 02300 batchs: 951.0025024414062
INFO:root:Train (Epoch 73): Loss/seq after 02350 batchs: 943.4471435546875
INFO:root:Train (Epoch 73): Loss/seq after 02400 batchs: 941.8518676757812
INFO:root:Train (Epoch 73): Loss/seq after 02450 batchs: 933.088623046875
INFO:root:Train (Epoch 73): Loss/seq after 02500 batchs: 919.8545532226562
INFO:root:Train (Epoch 73): Loss/seq after 02550 batchs: 910.8263549804688
INFO:root:Train (Epoch 73): Loss/seq after 02600 batchs: 910.0294189453125
INFO:root:Train (Epoch 73): Loss/seq after 02650 batchs: 906.1925659179688
INFO:root:Train (Epoch 73): Loss/seq after 02700 batchs: 903.9326782226562
INFO:root:Train (Epoch 73): Loss/seq after 02750 batchs: 932.2296752929688
INFO:root:Train (Epoch 73): Loss/seq after 02800 batchs: 936.567626953125
INFO:root:Train (Epoch 73): Loss/seq after 02850 batchs: 934.421630859375
INFO:root:Train (Epoch 73): Loss/seq after 02900 batchs: 933.9781494140625
INFO:root:Train (Epoch 73): Loss/seq after 02950 batchs: 928.9888916015625
INFO:root:Train (Epoch 73): Loss/seq after 03000 batchs: 930.7487182617188
INFO:root:Train (Epoch 73): Loss/seq after 03050 batchs: 936.2201538085938
INFO:root:Train (Epoch 73): Loss/seq after 03100 batchs: 942.4109497070312
INFO:root:Train (Epoch 73): Loss/seq after 03150 batchs: 946.36376953125
INFO:root:Train (Epoch 73): Loss/seq after 03200 batchs: 952.4331665039062
INFO:root:Train (Epoch 73): Loss/seq after 03250 batchs: 955.5458374023438
INFO:root:Train (Epoch 73): Loss/seq after 03300 batchs: 953.8858032226562
INFO:root:Train (Epoch 73): Loss/seq after 03350 batchs: 953.7776489257812
INFO:root:Train (Epoch 73): Loss/seq after 03400 batchs: 947.0703735351562
INFO:root:Train (Epoch 73): Loss/seq after 03450 batchs: 942.119873046875
INFO:root:Train (Epoch 73): Loss/seq after 03500 batchs: 940.802001953125
INFO:root:Train (Epoch 73): Loss/seq after 03550 batchs: 935.4268188476562
INFO:root:Train (Epoch 73): Loss/seq after 03600 batchs: 942.1659545898438
INFO:root:Train (Epoch 73): Loss/seq after 03650 batchs: 937.50537109375
INFO:root:Train (Epoch 73): Loss/seq after 03700 batchs: 938.0469360351562
INFO:root:Train (Epoch 73): Loss/seq after 03750 batchs: 941.34521484375
INFO:root:Train (Epoch 73): Loss/seq after 03800 batchs: 936.756103515625
INFO:root:Train (Epoch 73): Loss/seq after 03850 batchs: 934.6051635742188
INFO:root:Train (Epoch 73): Loss/seq after 03900 batchs: 938.090576171875
INFO:root:Train (Epoch 73): Loss/seq after 03950 batchs: 941.96435546875
INFO:root:Train (Epoch 73): Loss/seq after 04000 batchs: 936.150146484375
INFO:root:Train (Epoch 73): Loss/seq after 04050 batchs: 930.64501953125
INFO:root:Train (Epoch 73): Loss/seq after 04100 batchs: 926.4641723632812
INFO:root:Train (Epoch 73): Loss/seq after 04150 batchs: 923.3377685546875
INFO:root:Train (Epoch 73): Loss/seq after 04200 batchs: 920.0780029296875
INFO:root:Train (Epoch 73): Loss/seq after 04250 batchs: 917.5658569335938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 73): Loss/seq after 00000 batches: 642.1885375976562
INFO:root:# Valid (Epoch 73): Loss/seq after 00050 batches: 951.3456420898438
INFO:root:# Valid (Epoch 73): Loss/seq after 00100 batches: 1252.914306640625
INFO:root:# Valid (Epoch 73): Loss/seq after 00150 batches: 995.79296875
INFO:root:# Valid (Epoch 73): Loss/seq after 00200 batches: 909.0563354492188
INFO:root:Artifacts: Make stick videos for epoch 73
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_73_on_20220413_211724.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_73_index_734_on_20220413_211724.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 74): Loss/seq after 00000 batchs: 1976.27587890625
INFO:root:Train (Epoch 74): Loss/seq after 00050 batchs: 1214.564208984375
INFO:root:Train (Epoch 74): Loss/seq after 00100 batchs: 1218.802001953125
INFO:root:Train (Epoch 74): Loss/seq after 00150 batchs: 1104.317626953125
INFO:root:Train (Epoch 74): Loss/seq after 00200 batchs: 1207.6221923828125
INFO:root:Train (Epoch 74): Loss/seq after 00250 batchs: 1316.3106689453125
INFO:root:Train (Epoch 74): Loss/seq after 00300 batchs: 1271.21875
INFO:root:Train (Epoch 74): Loss/seq after 00350 batchs: 1191.8814697265625
INFO:root:Train (Epoch 74): Loss/seq after 00400 batchs: 1207.2105712890625
INFO:root:Train (Epoch 74): Loss/seq after 00450 batchs: 1167.6383056640625
INFO:root:Train (Epoch 74): Loss/seq after 00500 batchs: 1156.948974609375
INFO:root:Train (Epoch 74): Loss/seq after 00550 batchs: 1116.0899658203125
INFO:root:Train (Epoch 74): Loss/seq after 00600 batchs: 1080.7884521484375
INFO:root:Train (Epoch 74): Loss/seq after 00650 batchs: 1088.0205078125
INFO:root:Train (Epoch 74): Loss/seq after 00700 batchs: 1062.111083984375
INFO:root:Train (Epoch 74): Loss/seq after 00750 batchs: 1089.908203125
INFO:root:Train (Epoch 74): Loss/seq after 00800 batchs: 1082.508544921875
INFO:root:Train (Epoch 74): Loss/seq after 00850 batchs: 1058.1806640625
INFO:root:Train (Epoch 74): Loss/seq after 00900 batchs: 1054.3995361328125
INFO:root:Train (Epoch 74): Loss/seq after 00950 batchs: 1063.31787109375
INFO:root:Train (Epoch 74): Loss/seq after 01000 batchs: 1058.8323974609375
INFO:root:Train (Epoch 74): Loss/seq after 01050 batchs: 1040.4246826171875
INFO:root:Train (Epoch 74): Loss/seq after 01100 batchs: 1030.4486083984375
INFO:root:Train (Epoch 74): Loss/seq after 01150 batchs: 1013.7049560546875
INFO:root:Train (Epoch 74): Loss/seq after 01200 batchs: 1011.9386596679688
INFO:root:Train (Epoch 74): Loss/seq after 01250 batchs: 1008.132568359375
INFO:root:Train (Epoch 74): Loss/seq after 01300 batchs: 1001.5828247070312
INFO:root:Train (Epoch 74): Loss/seq after 01350 batchs: 994.8646850585938
INFO:root:Train (Epoch 74): Loss/seq after 01400 batchs: 1008.0101318359375
INFO:root:Train (Epoch 74): Loss/seq after 01450 batchs: 1005.4154663085938
INFO:root:Train (Epoch 74): Loss/seq after 01500 batchs: 1005.0509643554688
INFO:root:Train (Epoch 74): Loss/seq after 01550 batchs: 1006.8951416015625
INFO:root:Train (Epoch 74): Loss/seq after 01600 batchs: 998.13427734375
INFO:root:Train (Epoch 74): Loss/seq after 01650 batchs: 991.4983520507812
INFO:root:Train (Epoch 74): Loss/seq after 01700 batchs: 988.6111450195312
INFO:root:Train (Epoch 74): Loss/seq after 01750 batchs: 982.6732177734375
INFO:root:Train (Epoch 74): Loss/seq after 01800 batchs: 974.9117431640625
INFO:root:Train (Epoch 74): Loss/seq after 01850 batchs: 966.3756713867188
INFO:root:Train (Epoch 74): Loss/seq after 01900 batchs: 967.1472778320312
INFO:root:Train (Epoch 74): Loss/seq after 01950 batchs: 962.6715698242188
INFO:root:Train (Epoch 74): Loss/seq after 02000 batchs: 958.6560668945312
INFO:root:Train (Epoch 74): Loss/seq after 02050 batchs: 954.9620971679688
INFO:root:Train (Epoch 74): Loss/seq after 02100 batchs: 948.2008666992188
INFO:root:Train (Epoch 74): Loss/seq after 02150 batchs: 942.7410278320312
INFO:root:Train (Epoch 74): Loss/seq after 02200 batchs: 936.384521484375
INFO:root:Train (Epoch 74): Loss/seq after 02250 batchs: 935.9044189453125
INFO:root:Train (Epoch 74): Loss/seq after 02300 batchs: 943.182861328125
INFO:root:Train (Epoch 74): Loss/seq after 02350 batchs: 935.80859375
INFO:root:Train (Epoch 74): Loss/seq after 02400 batchs: 933.9323120117188
INFO:root:Train (Epoch 74): Loss/seq after 02450 batchs: 925.2945556640625
INFO:root:Train (Epoch 74): Loss/seq after 02500 batchs: 912.2952880859375
INFO:root:Train (Epoch 74): Loss/seq after 02550 batchs: 903.1260986328125
INFO:root:Train (Epoch 74): Loss/seq after 02600 batchs: 901.613525390625
INFO:root:Train (Epoch 74): Loss/seq after 02650 batchs: 898.4510498046875
INFO:root:Train (Epoch 74): Loss/seq after 02700 batchs: 895.90185546875
INFO:root:Train (Epoch 74): Loss/seq after 02750 batchs: 923.8053588867188
INFO:root:Train (Epoch 74): Loss/seq after 02800 batchs: 928.2501831054688
INFO:root:Train (Epoch 74): Loss/seq after 02850 batchs: 925.6919555664062
INFO:root:Train (Epoch 74): Loss/seq after 02900 batchs: 925.2971801757812
INFO:root:Train (Epoch 74): Loss/seq after 02950 batchs: 920.4293212890625
INFO:root:Train (Epoch 74): Loss/seq after 03000 batchs: 922.2252197265625
INFO:root:Train (Epoch 74): Loss/seq after 03050 batchs: 927.3603515625
INFO:root:Train (Epoch 74): Loss/seq after 03100 batchs: 933.00439453125
INFO:root:Train (Epoch 74): Loss/seq after 03150 batchs: 936.9301147460938
INFO:root:Train (Epoch 74): Loss/seq after 03200 batchs: 942.9322509765625
INFO:root:Train (Epoch 74): Loss/seq after 03250 batchs: 946.0906372070312
INFO:root:Train (Epoch 74): Loss/seq after 03300 batchs: 944.8895874023438
INFO:root:Train (Epoch 74): Loss/seq after 03350 batchs: 943.9000854492188
INFO:root:Train (Epoch 74): Loss/seq after 03400 batchs: 937.20068359375
INFO:root:Train (Epoch 74): Loss/seq after 03450 batchs: 932.66796875
INFO:root:Train (Epoch 74): Loss/seq after 03500 batchs: 931.7723388671875
INFO:root:Train (Epoch 74): Loss/seq after 03550 batchs: 926.401123046875
INFO:root:Train (Epoch 74): Loss/seq after 03600 batchs: 933.18017578125
INFO:root:Train (Epoch 74): Loss/seq after 03650 batchs: 928.4949951171875
INFO:root:Train (Epoch 74): Loss/seq after 03700 batchs: 929.2289428710938
INFO:root:Train (Epoch 74): Loss/seq after 03750 batchs: 932.5090942382812
INFO:root:Train (Epoch 74): Loss/seq after 03800 batchs: 927.9480590820312
INFO:root:Train (Epoch 74): Loss/seq after 03850 batchs: 925.912841796875
INFO:root:Train (Epoch 74): Loss/seq after 03900 batchs: 929.2589111328125
INFO:root:Train (Epoch 74): Loss/seq after 03950 batchs: 932.9324951171875
INFO:root:Train (Epoch 74): Loss/seq after 04000 batchs: 927.2374877929688
INFO:root:Train (Epoch 74): Loss/seq after 04050 batchs: 921.7371826171875
INFO:root:Train (Epoch 74): Loss/seq after 04100 batchs: 917.6544799804688
INFO:root:Train (Epoch 74): Loss/seq after 04150 batchs: 914.6975708007812
INFO:root:Train (Epoch 74): Loss/seq after 04200 batchs: 911.4335327148438
INFO:root:Train (Epoch 74): Loss/seq after 04250 batchs: 908.7973022460938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 74): Loss/seq after 00000 batches: 752.2882080078125
INFO:root:# Valid (Epoch 74): Loss/seq after 00050 batches: 932.3556518554688
INFO:root:# Valid (Epoch 74): Loss/seq after 00100 batches: 1220.7030029296875
INFO:root:# Valid (Epoch 74): Loss/seq after 00150 batches: 958.7989501953125
INFO:root:# Valid (Epoch 74): Loss/seq after 00200 batches: 876.843017578125
INFO:root:Artifacts: Make stick videos for epoch 74
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_74_on_20220413_212241.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_74_index_1165_on_20220413_212241.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 75): Loss/seq after 00000 batchs: 1479.02734375
INFO:root:Train (Epoch 75): Loss/seq after 00050 batchs: 1174.12451171875
INFO:root:Train (Epoch 75): Loss/seq after 00100 batchs: 1167.232177734375
INFO:root:Train (Epoch 75): Loss/seq after 00150 batchs: 1066.567138671875
INFO:root:Train (Epoch 75): Loss/seq after 00200 batchs: 1176.9991455078125
INFO:root:Train (Epoch 75): Loss/seq after 00250 batchs: 1289.323486328125
INFO:root:Train (Epoch 75): Loss/seq after 00300 batchs: 1249.80224609375
INFO:root:Train (Epoch 75): Loss/seq after 00350 batchs: 1170.38818359375
INFO:root:Train (Epoch 75): Loss/seq after 00400 batchs: 1188.552734375
INFO:root:Train (Epoch 75): Loss/seq after 00450 batchs: 1150.77197265625
INFO:root:Train (Epoch 75): Loss/seq after 00500 batchs: 1136.7115478515625
INFO:root:Train (Epoch 75): Loss/seq after 00550 batchs: 1096.2236328125
INFO:root:Train (Epoch 75): Loss/seq after 00600 batchs: 1065.6810302734375
INFO:root:Train (Epoch 75): Loss/seq after 00650 batchs: 1075.2401123046875
INFO:root:Train (Epoch 75): Loss/seq after 00700 batchs: 1052.502685546875
INFO:root:Train (Epoch 75): Loss/seq after 00750 batchs: 1084.392333984375
INFO:root:Train (Epoch 75): Loss/seq after 00800 batchs: 1074.9842529296875
INFO:root:Train (Epoch 75): Loss/seq after 00850 batchs: 1049.6351318359375
INFO:root:Train (Epoch 75): Loss/seq after 00900 batchs: 1045.1533203125
INFO:root:Train (Epoch 75): Loss/seq after 00950 batchs: 1055.2908935546875
INFO:root:Train (Epoch 75): Loss/seq after 01000 batchs: 1050.1138916015625
INFO:root:Train (Epoch 75): Loss/seq after 01050 batchs: 1032.6341552734375
INFO:root:Train (Epoch 75): Loss/seq after 01100 batchs: 1022.4207763671875
INFO:root:Train (Epoch 75): Loss/seq after 01150 batchs: 1007.949951171875
INFO:root:Train (Epoch 75): Loss/seq after 01200 batchs: 1005.6028442382812
INFO:root:Train (Epoch 75): Loss/seq after 01250 batchs: 1002.0519409179688
INFO:root:Train (Epoch 75): Loss/seq after 01300 batchs: 997.0145874023438
INFO:root:Train (Epoch 75): Loss/seq after 01350 batchs: 990.2996215820312
INFO:root:Train (Epoch 75): Loss/seq after 01400 batchs: 1003.3421630859375
INFO:root:Train (Epoch 75): Loss/seq after 01450 batchs: 1001.1007690429688
INFO:root:Train (Epoch 75): Loss/seq after 01500 batchs: 1000.972900390625
INFO:root:Train (Epoch 75): Loss/seq after 01550 batchs: 1003.5645751953125
INFO:root:Train (Epoch 75): Loss/seq after 01600 batchs: 994.0404663085938
INFO:root:Train (Epoch 75): Loss/seq after 01650 batchs: 986.9136962890625
INFO:root:Train (Epoch 75): Loss/seq after 01700 batchs: 983.5321655273438
INFO:root:Train (Epoch 75): Loss/seq after 01750 batchs: 978.1828002929688
INFO:root:Train (Epoch 75): Loss/seq after 01800 batchs: 970.62841796875
INFO:root:Train (Epoch 75): Loss/seq after 01850 batchs: 962.51171875
INFO:root:Train (Epoch 75): Loss/seq after 01900 batchs: 963.17431640625
INFO:root:Train (Epoch 75): Loss/seq after 01950 batchs: 958.3765869140625
INFO:root:Train (Epoch 75): Loss/seq after 02000 batchs: 954.6050415039062
INFO:root:Train (Epoch 75): Loss/seq after 02050 batchs: 950.9832153320312
INFO:root:Train (Epoch 75): Loss/seq after 02100 batchs: 944.4170532226562
INFO:root:Train (Epoch 75): Loss/seq after 02150 batchs: 938.772216796875
INFO:root:Train (Epoch 75): Loss/seq after 02200 batchs: 932.4857788085938
INFO:root:Train (Epoch 75): Loss/seq after 02250 batchs: 931.8896484375
INFO:root:Train (Epoch 75): Loss/seq after 02300 batchs: 938.78369140625
INFO:root:Train (Epoch 75): Loss/seq after 02350 batchs: 931.5087890625
INFO:root:Train (Epoch 75): Loss/seq after 02400 batchs: 930.1015014648438
INFO:root:Train (Epoch 75): Loss/seq after 02450 batchs: 921.5389404296875
INFO:root:Train (Epoch 75): Loss/seq after 02500 batchs: 908.7166137695312
INFO:root:Train (Epoch 75): Loss/seq after 02550 batchs: 899.5257568359375
INFO:root:Train (Epoch 75): Loss/seq after 02600 batchs: 898.3797607421875
INFO:root:Train (Epoch 75): Loss/seq after 02650 batchs: 895.3493041992188
INFO:root:Train (Epoch 75): Loss/seq after 02700 batchs: 892.4191284179688
INFO:root:Train (Epoch 75): Loss/seq after 02750 batchs: 918.6328125
INFO:root:Train (Epoch 75): Loss/seq after 02800 batchs: 922.3198852539062
INFO:root:Train (Epoch 75): Loss/seq after 02850 batchs: 920.324462890625
INFO:root:Train (Epoch 75): Loss/seq after 02900 batchs: 920.589599609375
INFO:root:Train (Epoch 75): Loss/seq after 02950 batchs: 915.9993896484375
INFO:root:Train (Epoch 75): Loss/seq after 03000 batchs: 917.8125610351562
INFO:root:Train (Epoch 75): Loss/seq after 03050 batchs: 923.1927490234375
INFO:root:Train (Epoch 75): Loss/seq after 03100 batchs: 928.715576171875
INFO:root:Train (Epoch 75): Loss/seq after 03150 batchs: 933.6986694335938
INFO:root:Train (Epoch 75): Loss/seq after 03200 batchs: 939.643310546875
INFO:root:Train (Epoch 75): Loss/seq after 03250 batchs: 942.718505859375
INFO:root:Train (Epoch 75): Loss/seq after 03300 batchs: 940.5736694335938
INFO:root:Train (Epoch 75): Loss/seq after 03350 batchs: 939.2491455078125
INFO:root:Train (Epoch 75): Loss/seq after 03400 batchs: 932.4669799804688
INFO:root:Train (Epoch 75): Loss/seq after 03450 batchs: 927.9901733398438
INFO:root:Train (Epoch 75): Loss/seq after 03500 batchs: 927.3261108398438
INFO:root:Train (Epoch 75): Loss/seq after 03550 batchs: 922.385986328125
INFO:root:Train (Epoch 75): Loss/seq after 03600 batchs: 929.2450561523438
INFO:root:Train (Epoch 75): Loss/seq after 03650 batchs: 925.0823364257812
INFO:root:Train (Epoch 75): Loss/seq after 03700 batchs: 925.2255249023438
INFO:root:Train (Epoch 75): Loss/seq after 03750 batchs: 928.6272583007812
INFO:root:Train (Epoch 75): Loss/seq after 03800 batchs: 924.2156372070312
INFO:root:Train (Epoch 75): Loss/seq after 03850 batchs: 922.1895141601562
INFO:root:Train (Epoch 75): Loss/seq after 03900 batchs: 925.9688110351562
INFO:root:Train (Epoch 75): Loss/seq after 03950 batchs: 929.7528686523438
INFO:root:Train (Epoch 75): Loss/seq after 04000 batchs: 924.1112670898438
INFO:root:Train (Epoch 75): Loss/seq after 04050 batchs: 918.6166381835938
INFO:root:Train (Epoch 75): Loss/seq after 04100 batchs: 914.6712646484375
INFO:root:Train (Epoch 75): Loss/seq after 04150 batchs: 911.8233642578125
INFO:root:Train (Epoch 75): Loss/seq after 04200 batchs: 908.3886108398438
INFO:root:Train (Epoch 75): Loss/seq after 04250 batchs: 905.4697875976562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 75): Loss/seq after 00000 batches: 595.9370727539062
INFO:root:# Valid (Epoch 75): Loss/seq after 00050 batches: 897.1475219726562
INFO:root:# Valid (Epoch 75): Loss/seq after 00100 batches: 1172.4722900390625
INFO:root:# Valid (Epoch 75): Loss/seq after 00150 batches: 927.979736328125
INFO:root:# Valid (Epoch 75): Loss/seq after 00200 batches: 849.4066772460938
INFO:root:Artifacts: Make stick videos for epoch 75
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_75_on_20220413_212800.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_75_index_762_on_20220413_212800.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 76): Loss/seq after 00000 batchs: 1538.833251953125
INFO:root:Train (Epoch 76): Loss/seq after 00050 batchs: 1145.8616943359375
INFO:root:Train (Epoch 76): Loss/seq after 00100 batchs: 1153.15966796875
INFO:root:Train (Epoch 76): Loss/seq after 00150 batchs: 1050.699951171875
INFO:root:Train (Epoch 76): Loss/seq after 00200 batchs: 1151.9952392578125
INFO:root:Train (Epoch 76): Loss/seq after 00250 batchs: 1269.837158203125
INFO:root:Train (Epoch 76): Loss/seq after 00300 batchs: 1233.88525390625
INFO:root:Train (Epoch 76): Loss/seq after 00350 batchs: 1156.3924560546875
INFO:root:Train (Epoch 76): Loss/seq after 00400 batchs: 1175.34765625
INFO:root:Train (Epoch 76): Loss/seq after 00450 batchs: 1139.20947265625
INFO:root:Train (Epoch 76): Loss/seq after 00500 batchs: 1126.2470703125
INFO:root:Train (Epoch 76): Loss/seq after 00550 batchs: 1087.0467529296875
INFO:root:Train (Epoch 76): Loss/seq after 00600 batchs: 1053.43701171875
INFO:root:Train (Epoch 76): Loss/seq after 00650 batchs: 1064.9888916015625
INFO:root:Train (Epoch 76): Loss/seq after 00700 batchs: 1040.8070068359375
INFO:root:Train (Epoch 76): Loss/seq after 00750 batchs: 1071.3773193359375
INFO:root:Train (Epoch 76): Loss/seq after 00800 batchs: 1064.0748291015625
INFO:root:Train (Epoch 76): Loss/seq after 00850 batchs: 1039.7711181640625
INFO:root:Train (Epoch 76): Loss/seq after 00900 batchs: 1038.25927734375
INFO:root:Train (Epoch 76): Loss/seq after 00950 batchs: 1049.05419921875
INFO:root:Train (Epoch 76): Loss/seq after 01000 batchs: 1043.3721923828125
INFO:root:Train (Epoch 76): Loss/seq after 01050 batchs: 1027.5377197265625
INFO:root:Train (Epoch 76): Loss/seq after 01100 batchs: 1015.695556640625
INFO:root:Train (Epoch 76): Loss/seq after 01150 batchs: 1002.256103515625
INFO:root:Train (Epoch 76): Loss/seq after 01200 batchs: 999.4920043945312
INFO:root:Train (Epoch 76): Loss/seq after 01250 batchs: 996.0337524414062
INFO:root:Train (Epoch 76): Loss/seq after 01300 batchs: 988.3076171875
INFO:root:Train (Epoch 76): Loss/seq after 01350 batchs: 981.9220581054688
INFO:root:Train (Epoch 76): Loss/seq after 01400 batchs: 996.0230712890625
INFO:root:Train (Epoch 76): Loss/seq after 01450 batchs: 993.1490478515625
INFO:root:Train (Epoch 76): Loss/seq after 01500 batchs: 993.0974731445312
INFO:root:Train (Epoch 76): Loss/seq after 01550 batchs: 995.20361328125
INFO:root:Train (Epoch 76): Loss/seq after 01600 batchs: 985.9774780273438
INFO:root:Train (Epoch 76): Loss/seq after 01650 batchs: 979.1661376953125
INFO:root:Train (Epoch 76): Loss/seq after 01700 batchs: 975.8046264648438
INFO:root:Train (Epoch 76): Loss/seq after 01750 batchs: 970.7045288085938
INFO:root:Train (Epoch 76): Loss/seq after 01800 batchs: 963.27294921875
INFO:root:Train (Epoch 76): Loss/seq after 01850 batchs: 955.2401123046875
INFO:root:Train (Epoch 76): Loss/seq after 01900 batchs: 955.8444213867188
INFO:root:Train (Epoch 76): Loss/seq after 01950 batchs: 951.970458984375
INFO:root:Train (Epoch 76): Loss/seq after 02000 batchs: 948.4707641601562
INFO:root:Train (Epoch 76): Loss/seq after 02050 batchs: 944.9531860351562
INFO:root:Train (Epoch 76): Loss/seq after 02100 batchs: 938.5394287109375
INFO:root:Train (Epoch 76): Loss/seq after 02150 batchs: 932.9320068359375
INFO:root:Train (Epoch 76): Loss/seq after 02200 batchs: 926.73388671875
INFO:root:Train (Epoch 76): Loss/seq after 02250 batchs: 926.2401733398438
INFO:root:Train (Epoch 76): Loss/seq after 02300 batchs: 933.0568237304688
INFO:root:Train (Epoch 76): Loss/seq after 02350 batchs: 926.0653686523438
INFO:root:Train (Epoch 76): Loss/seq after 02400 batchs: 924.6122436523438
INFO:root:Train (Epoch 76): Loss/seq after 02450 batchs: 916.2870483398438
INFO:root:Train (Epoch 76): Loss/seq after 02500 batchs: 902.9747314453125
INFO:root:Train (Epoch 76): Loss/seq after 02550 batchs: 893.5780029296875
INFO:root:Train (Epoch 76): Loss/seq after 02600 batchs: 892.7088623046875
INFO:root:Train (Epoch 76): Loss/seq after 02650 batchs: 889.4910278320312
INFO:root:Train (Epoch 76): Loss/seq after 02700 batchs: 886.3632202148438
INFO:root:Train (Epoch 76): Loss/seq after 02750 batchs: 911.62451171875
INFO:root:Train (Epoch 76): Loss/seq after 02800 batchs: 915.3331909179688
INFO:root:Train (Epoch 76): Loss/seq after 02850 batchs: 913.2239990234375
INFO:root:Train (Epoch 76): Loss/seq after 02900 batchs: 913.0706176757812
INFO:root:Train (Epoch 76): Loss/seq after 02950 batchs: 908.4080810546875
INFO:root:Train (Epoch 76): Loss/seq after 03000 batchs: 910.40478515625
INFO:root:Train (Epoch 76): Loss/seq after 03050 batchs: 915.4293212890625
INFO:root:Train (Epoch 76): Loss/seq after 03100 batchs: 921.4249877929688
INFO:root:Train (Epoch 76): Loss/seq after 03150 batchs: 926.3732299804688
INFO:root:Train (Epoch 76): Loss/seq after 03200 batchs: 932.636474609375
INFO:root:Train (Epoch 76): Loss/seq after 03250 batchs: 935.69287109375
INFO:root:Train (Epoch 76): Loss/seq after 03300 batchs: 934.173095703125
INFO:root:Train (Epoch 76): Loss/seq after 03350 batchs: 933.3731689453125
INFO:root:Train (Epoch 76): Loss/seq after 03400 batchs: 927.3012084960938
INFO:root:Train (Epoch 76): Loss/seq after 03450 batchs: 922.4373779296875
INFO:root:Train (Epoch 76): Loss/seq after 03500 batchs: 921.6458129882812
INFO:root:Train (Epoch 76): Loss/seq after 03550 batchs: 916.5989379882812
INFO:root:Train (Epoch 76): Loss/seq after 03600 batchs: 923.5291137695312
INFO:root:Train (Epoch 76): Loss/seq after 03650 batchs: 918.9876708984375
INFO:root:Train (Epoch 76): Loss/seq after 03700 batchs: 919.3773193359375
INFO:root:Train (Epoch 76): Loss/seq after 03750 batchs: 922.7374267578125
INFO:root:Train (Epoch 76): Loss/seq after 03800 batchs: 918.091796875
INFO:root:Train (Epoch 76): Loss/seq after 03850 batchs: 916.1171875
INFO:root:Train (Epoch 76): Loss/seq after 03900 batchs: 919.9308471679688
INFO:root:Train (Epoch 76): Loss/seq after 03950 batchs: 924.0611572265625
INFO:root:Train (Epoch 76): Loss/seq after 04000 batchs: 918.4471435546875
INFO:root:Train (Epoch 76): Loss/seq after 04050 batchs: 913.0848999023438
INFO:root:Train (Epoch 76): Loss/seq after 04100 batchs: 909.0933837890625
INFO:root:Train (Epoch 76): Loss/seq after 04150 batchs: 906.1858520507812
INFO:root:Train (Epoch 76): Loss/seq after 04200 batchs: 902.8326416015625
INFO:root:Train (Epoch 76): Loss/seq after 04250 batchs: 899.8668823242188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 76): Loss/seq after 00000 batches: 742.2136840820312
INFO:root:# Valid (Epoch 76): Loss/seq after 00050 batches: 909.742431640625
INFO:root:# Valid (Epoch 76): Loss/seq after 00100 batches: 1167.4466552734375
INFO:root:# Valid (Epoch 76): Loss/seq after 00150 batches: 908.6536865234375
INFO:root:# Valid (Epoch 76): Loss/seq after 00200 batches: 832.228515625
INFO:root:Artifacts: Make stick videos for epoch 76
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_76_on_20220413_213319.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_76_index_161_on_20220413_213319.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 77): Loss/seq after 00000 batchs: 1509.744873046875
INFO:root:Train (Epoch 77): Loss/seq after 00050 batchs: 1100.9429931640625
INFO:root:Train (Epoch 77): Loss/seq after 00100 batchs: 1130.303955078125
INFO:root:Train (Epoch 77): Loss/seq after 00150 batchs: 1034.4517822265625
INFO:root:Train (Epoch 77): Loss/seq after 00200 batchs: 1148.08984375
INFO:root:Train (Epoch 77): Loss/seq after 00250 batchs: 1258.4881591796875
INFO:root:Train (Epoch 77): Loss/seq after 00300 batchs: 1221.6507568359375
INFO:root:Train (Epoch 77): Loss/seq after 00350 batchs: 1143.845947265625
INFO:root:Train (Epoch 77): Loss/seq after 00400 batchs: 1165.377685546875
INFO:root:Train (Epoch 77): Loss/seq after 00450 batchs: 1129.8009033203125
INFO:root:Train (Epoch 77): Loss/seq after 00500 batchs: 1115.060546875
INFO:root:Train (Epoch 77): Loss/seq after 00550 batchs: 1076.884765625
INFO:root:Train (Epoch 77): Loss/seq after 00600 batchs: 1043.104736328125
INFO:root:Train (Epoch 77): Loss/seq after 00650 batchs: 1054.566162109375
INFO:root:Train (Epoch 77): Loss/seq after 00700 batchs: 1030.5718994140625
INFO:root:Train (Epoch 77): Loss/seq after 00750 batchs: 1066.213623046875
INFO:root:Train (Epoch 77): Loss/seq after 00800 batchs: 1060.3763427734375
INFO:root:Train (Epoch 77): Loss/seq after 00850 batchs: 1034.49169921875
INFO:root:Train (Epoch 77): Loss/seq after 00900 batchs: 1025.683837890625
INFO:root:Train (Epoch 77): Loss/seq after 00950 batchs: 1035.581298828125
INFO:root:Train (Epoch 77): Loss/seq after 01000 batchs: 1032.9876708984375
INFO:root:Train (Epoch 77): Loss/seq after 01050 batchs: 1015.759521484375
INFO:root:Train (Epoch 77): Loss/seq after 01100 batchs: 1002.5989379882812
INFO:root:Train (Epoch 77): Loss/seq after 01150 batchs: 983.7821655273438
INFO:root:Train (Epoch 77): Loss/seq after 01200 batchs: 982.0174560546875
INFO:root:Train (Epoch 77): Loss/seq after 01250 batchs: 979.1055297851562
INFO:root:Train (Epoch 77): Loss/seq after 01300 batchs: 974.0194702148438
INFO:root:Train (Epoch 77): Loss/seq after 01350 batchs: 969.4882202148438
INFO:root:Train (Epoch 77): Loss/seq after 01400 batchs: 984.7988891601562
INFO:root:Train (Epoch 77): Loss/seq after 01450 batchs: 982.476318359375
INFO:root:Train (Epoch 77): Loss/seq after 01500 batchs: 982.7887573242188
INFO:root:Train (Epoch 77): Loss/seq after 01550 batchs: 985.212890625
INFO:root:Train (Epoch 77): Loss/seq after 01600 batchs: 976.35546875
INFO:root:Train (Epoch 77): Loss/seq after 01650 batchs: 969.0690307617188
INFO:root:Train (Epoch 77): Loss/seq after 01700 batchs: 965.6549072265625
INFO:root:Train (Epoch 77): Loss/seq after 01750 batchs: 960.4715576171875
INFO:root:Train (Epoch 77): Loss/seq after 01800 batchs: 953.0462646484375
INFO:root:Train (Epoch 77): Loss/seq after 01850 batchs: 944.5687866210938
INFO:root:Train (Epoch 77): Loss/seq after 01900 batchs: 945.3363647460938
INFO:root:Train (Epoch 77): Loss/seq after 01950 batchs: 940.3429565429688
INFO:root:Train (Epoch 77): Loss/seq after 02000 batchs: 937.0471801757812
INFO:root:Train (Epoch 77): Loss/seq after 02050 batchs: 933.2161254882812
INFO:root:Train (Epoch 77): Loss/seq after 02100 batchs: 926.4366455078125
INFO:root:Train (Epoch 77): Loss/seq after 02150 batchs: 921.0798950195312
INFO:root:Train (Epoch 77): Loss/seq after 02200 batchs: 914.683837890625
INFO:root:Train (Epoch 77): Loss/seq after 02250 batchs: 914.8339233398438
INFO:root:Train (Epoch 77): Loss/seq after 02300 batchs: 921.2301025390625
INFO:root:Train (Epoch 77): Loss/seq after 02350 batchs: 913.4590454101562
INFO:root:Train (Epoch 77): Loss/seq after 02400 batchs: 911.16650390625
INFO:root:Train (Epoch 77): Loss/seq after 02450 batchs: 902.9563598632812
INFO:root:Train (Epoch 77): Loss/seq after 02500 batchs: 889.4918823242188
INFO:root:Train (Epoch 77): Loss/seq after 02550 batchs: 879.52978515625
INFO:root:Train (Epoch 77): Loss/seq after 02600 batchs: 877.7557373046875
INFO:root:Train (Epoch 77): Loss/seq after 02650 batchs: 873.4547119140625
INFO:root:Train (Epoch 77): Loss/seq after 02700 batchs: 870.2103271484375
INFO:root:Train (Epoch 77): Loss/seq after 02750 batchs: 895.7274169921875
INFO:root:Train (Epoch 77): Loss/seq after 02800 batchs: 899.7256469726562
INFO:root:Train (Epoch 77): Loss/seq after 02850 batchs: 897.9031372070312
INFO:root:Train (Epoch 77): Loss/seq after 02900 batchs: 897.4080200195312
INFO:root:Train (Epoch 77): Loss/seq after 02950 batchs: 893.0682983398438
INFO:root:Train (Epoch 77): Loss/seq after 03000 batchs: 895.0150146484375
INFO:root:Train (Epoch 77): Loss/seq after 03050 batchs: 899.993896484375
INFO:root:Train (Epoch 77): Loss/seq after 03100 batchs: 905.9420166015625
INFO:root:Train (Epoch 77): Loss/seq after 03150 batchs: 909.9896240234375
INFO:root:Train (Epoch 77): Loss/seq after 03200 batchs: 916.7123413085938
INFO:root:Train (Epoch 77): Loss/seq after 03250 batchs: 919.787109375
INFO:root:Train (Epoch 77): Loss/seq after 03300 batchs: 917.5750122070312
INFO:root:Train (Epoch 77): Loss/seq after 03350 batchs: 915.9055786132812
INFO:root:Train (Epoch 77): Loss/seq after 03400 batchs: 908.6155395507812
INFO:root:Train (Epoch 77): Loss/seq after 03450 batchs: 903.6761474609375
INFO:root:Train (Epoch 77): Loss/seq after 03500 batchs: 902.5367431640625
INFO:root:Train (Epoch 77): Loss/seq after 03550 batchs: 897.1851806640625
INFO:root:Train (Epoch 77): Loss/seq after 03600 batchs: 903.9366455078125
INFO:root:Train (Epoch 77): Loss/seq after 03650 batchs: 899.1357421875
INFO:root:Train (Epoch 77): Loss/seq after 03700 batchs: 899.252685546875
INFO:root:Train (Epoch 77): Loss/seq after 03750 batchs: 902.696044921875
INFO:root:Train (Epoch 77): Loss/seq after 03800 batchs: 897.950927734375
INFO:root:Train (Epoch 77): Loss/seq after 03850 batchs: 895.7894897460938
INFO:root:Train (Epoch 77): Loss/seq after 03900 batchs: 899.0167846679688
INFO:root:Train (Epoch 77): Loss/seq after 03950 batchs: 903.3388061523438
INFO:root:Train (Epoch 77): Loss/seq after 04000 batchs: 897.873046875
INFO:root:Train (Epoch 77): Loss/seq after 04050 batchs: 892.1671142578125
INFO:root:Train (Epoch 77): Loss/seq after 04100 batchs: 888.265625
INFO:root:Train (Epoch 77): Loss/seq after 04150 batchs: 885.5574951171875
INFO:root:Train (Epoch 77): Loss/seq after 04200 batchs: 882.3133544921875
INFO:root:Train (Epoch 77): Loss/seq after 04250 batchs: 879.3651733398438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 77): Loss/seq after 00000 batches: 761.74365234375
INFO:root:# Valid (Epoch 77): Loss/seq after 00050 batches: 848.5881958007812
INFO:root:# Valid (Epoch 77): Loss/seq after 00100 batches: 1135.2276611328125
INFO:root:# Valid (Epoch 77): Loss/seq after 00150 batches: 875.8364868164062
INFO:root:# Valid (Epoch 77): Loss/seq after 00200 batches: 809.519775390625
INFO:root:Artifacts: Make stick videos for epoch 77
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_77_on_20220413_213837.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_77_index_540_on_20220413_213837.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 78): Loss/seq after 00000 batchs: 1462.3363037109375
INFO:root:Train (Epoch 78): Loss/seq after 00050 batchs: 1095.58447265625
INFO:root:Train (Epoch 78): Loss/seq after 00100 batchs: 1131.7027587890625
INFO:root:Train (Epoch 78): Loss/seq after 00150 batchs: 1028.97314453125
INFO:root:Train (Epoch 78): Loss/seq after 00200 batchs: 1147.4681396484375
INFO:root:Train (Epoch 78): Loss/seq after 00250 batchs: 1260.898193359375
INFO:root:Train (Epoch 78): Loss/seq after 00300 batchs: 1221.396728515625
INFO:root:Train (Epoch 78): Loss/seq after 00350 batchs: 1140.23388671875
INFO:root:Train (Epoch 78): Loss/seq after 00400 batchs: 1159.7462158203125
INFO:root:Train (Epoch 78): Loss/seq after 00450 batchs: 1123.9696044921875
INFO:root:Train (Epoch 78): Loss/seq after 00500 batchs: 1106.80322265625
INFO:root:Train (Epoch 78): Loss/seq after 00550 batchs: 1068.5196533203125
INFO:root:Train (Epoch 78): Loss/seq after 00600 batchs: 1031.7259521484375
INFO:root:Train (Epoch 78): Loss/seq after 00650 batchs: 1045.321044921875
INFO:root:Train (Epoch 78): Loss/seq after 00700 batchs: 1022.279296875
INFO:root:Train (Epoch 78): Loss/seq after 00750 batchs: 1054.5091552734375
INFO:root:Train (Epoch 78): Loss/seq after 00800 batchs: 1046.28857421875
INFO:root:Train (Epoch 78): Loss/seq after 00850 batchs: 1016.671630859375
INFO:root:Train (Epoch 78): Loss/seq after 00900 batchs: 1003.86572265625
INFO:root:Train (Epoch 78): Loss/seq after 00950 batchs: 1016.5215454101562
INFO:root:Train (Epoch 78): Loss/seq after 01000 batchs: 1013.3070068359375
INFO:root:Train (Epoch 78): Loss/seq after 01050 batchs: 996.1996459960938
INFO:root:Train (Epoch 78): Loss/seq after 01100 batchs: 981.5385131835938
INFO:root:Train (Epoch 78): Loss/seq after 01150 batchs: 958.8055419921875
INFO:root:Train (Epoch 78): Loss/seq after 01200 batchs: 958.405517578125
INFO:root:Train (Epoch 78): Loss/seq after 01250 batchs: 954.9993286132812
INFO:root:Train (Epoch 78): Loss/seq after 01300 batchs: 950.1322631835938
INFO:root:Train (Epoch 78): Loss/seq after 01350 batchs: 946.6039428710938
INFO:root:Train (Epoch 78): Loss/seq after 01400 batchs: 965.1221313476562
INFO:root:Train (Epoch 78): Loss/seq after 01450 batchs: 963.697021484375
INFO:root:Train (Epoch 78): Loss/seq after 01500 batchs: 963.9432373046875
INFO:root:Train (Epoch 78): Loss/seq after 01550 batchs: 966.5328369140625
INFO:root:Train (Epoch 78): Loss/seq after 01600 batchs: 957.6080932617188
INFO:root:Train (Epoch 78): Loss/seq after 01650 batchs: 950.0997314453125
INFO:root:Train (Epoch 78): Loss/seq after 01700 batchs: 946.8406982421875
INFO:root:Train (Epoch 78): Loss/seq after 01750 batchs: 941.1599731445312
INFO:root:Train (Epoch 78): Loss/seq after 01800 batchs: 933.67529296875
INFO:root:Train (Epoch 78): Loss/seq after 01850 batchs: 925.0138549804688
INFO:root:Train (Epoch 78): Loss/seq after 01900 batchs: 926.1329345703125
INFO:root:Train (Epoch 78): Loss/seq after 01950 batchs: 920.8082275390625
INFO:root:Train (Epoch 78): Loss/seq after 02000 batchs: 917.2456665039062
INFO:root:Train (Epoch 78): Loss/seq after 02050 batchs: 913.2686157226562
INFO:root:Train (Epoch 78): Loss/seq after 02100 batchs: 906.3884887695312
INFO:root:Train (Epoch 78): Loss/seq after 02150 batchs: 901.1116943359375
INFO:root:Train (Epoch 78): Loss/seq after 02200 batchs: 894.6884765625
INFO:root:Train (Epoch 78): Loss/seq after 02250 batchs: 895.4484252929688
INFO:root:Train (Epoch 78): Loss/seq after 02300 batchs: 902.350341796875
INFO:root:Train (Epoch 78): Loss/seq after 02350 batchs: 895.2703857421875
INFO:root:Train (Epoch 78): Loss/seq after 02400 batchs: 892.9945068359375
INFO:root:Train (Epoch 78): Loss/seq after 02450 batchs: 884.7280883789062
INFO:root:Train (Epoch 78): Loss/seq after 02500 batchs: 871.0101928710938
INFO:root:Train (Epoch 78): Loss/seq after 02550 batchs: 861.048583984375
INFO:root:Train (Epoch 78): Loss/seq after 02600 batchs: 858.9274291992188
INFO:root:Train (Epoch 78): Loss/seq after 02650 batchs: 854.6136474609375
INFO:root:Train (Epoch 78): Loss/seq after 02700 batchs: 851.6055297851562
INFO:root:Train (Epoch 78): Loss/seq after 02750 batchs: 877.615234375
INFO:root:Train (Epoch 78): Loss/seq after 02800 batchs: 882.7236938476562
INFO:root:Train (Epoch 78): Loss/seq after 02850 batchs: 880.7049560546875
INFO:root:Train (Epoch 78): Loss/seq after 02900 batchs: 881.0850219726562
INFO:root:Train (Epoch 78): Loss/seq after 02950 batchs: 876.7189331054688
INFO:root:Train (Epoch 78): Loss/seq after 03000 batchs: 878.769775390625
INFO:root:Train (Epoch 78): Loss/seq after 03050 batchs: 883.7089233398438
INFO:root:Train (Epoch 78): Loss/seq after 03100 batchs: 890.0491333007812
INFO:root:Train (Epoch 78): Loss/seq after 03150 batchs: 894.1137084960938
INFO:root:Train (Epoch 78): Loss/seq after 03200 batchs: 900.926513671875
INFO:root:Train (Epoch 78): Loss/seq after 03250 batchs: 904.4555053710938
INFO:root:Train (Epoch 78): Loss/seq after 03300 batchs: 902.6121215820312
INFO:root:Train (Epoch 78): Loss/seq after 03350 batchs: 901.072509765625
INFO:root:Train (Epoch 78): Loss/seq after 03400 batchs: 893.4823608398438
INFO:root:Train (Epoch 78): Loss/seq after 03450 batchs: 888.7830200195312
INFO:root:Train (Epoch 78): Loss/seq after 03500 batchs: 887.4839477539062
INFO:root:Train (Epoch 78): Loss/seq after 03550 batchs: 882.3002319335938
INFO:root:Train (Epoch 78): Loss/seq after 03600 batchs: 889.1484985351562
INFO:root:Train (Epoch 78): Loss/seq after 03650 batchs: 884.1449584960938
INFO:root:Train (Epoch 78): Loss/seq after 03700 batchs: 883.8763427734375
INFO:root:Train (Epoch 78): Loss/seq after 03750 batchs: 887.4507446289062
INFO:root:Train (Epoch 78): Loss/seq after 03800 batchs: 882.5390625
INFO:root:Train (Epoch 78): Loss/seq after 03850 batchs: 880.340087890625
INFO:root:Train (Epoch 78): Loss/seq after 03900 batchs: 883.8491821289062
INFO:root:Train (Epoch 78): Loss/seq after 03950 batchs: 888.0851440429688
INFO:root:Train (Epoch 78): Loss/seq after 04000 batchs: 882.7490234375
INFO:root:Train (Epoch 78): Loss/seq after 04050 batchs: 876.9799194335938
INFO:root:Train (Epoch 78): Loss/seq after 04100 batchs: 873.2186889648438
INFO:root:Train (Epoch 78): Loss/seq after 04150 batchs: 870.5958862304688
INFO:root:Train (Epoch 78): Loss/seq after 04200 batchs: 867.4231567382812
INFO:root:Train (Epoch 78): Loss/seq after 04250 batchs: 864.3095092773438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 78): Loss/seq after 00000 batches: 563.085693359375
INFO:root:# Valid (Epoch 78): Loss/seq after 00050 batches: 805.7598876953125
INFO:root:# Valid (Epoch 78): Loss/seq after 00100 batches: 1098.9326171875
INFO:root:# Valid (Epoch 78): Loss/seq after 00150 batches: 845.682373046875
INFO:root:# Valid (Epoch 78): Loss/seq after 00200 batches: 788.4552001953125
INFO:root:Artifacts: Make stick videos for epoch 78
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_78_on_20220413_214355.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_78_index_1467_on_20220413_214355.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 79): Loss/seq after 00000 batchs: 1541.5078125
INFO:root:Train (Epoch 79): Loss/seq after 00050 batchs: 1089.7412109375
INFO:root:Train (Epoch 79): Loss/seq after 00100 batchs: 1117.47314453125
INFO:root:Train (Epoch 79): Loss/seq after 00150 batchs: 1017.8324584960938
INFO:root:Train (Epoch 79): Loss/seq after 00200 batchs: 1131.6162109375
INFO:root:Train (Epoch 79): Loss/seq after 00250 batchs: 1244.6727294921875
INFO:root:Train (Epoch 79): Loss/seq after 00300 batchs: 1206.195556640625
INFO:root:Train (Epoch 79): Loss/seq after 00350 batchs: 1125.275146484375
INFO:root:Train (Epoch 79): Loss/seq after 00400 batchs: 1144.16357421875
INFO:root:Train (Epoch 79): Loss/seq after 00450 batchs: 1109.90087890625
INFO:root:Train (Epoch 79): Loss/seq after 00500 batchs: 1092.1865234375
INFO:root:Train (Epoch 79): Loss/seq after 00550 batchs: 1053.4886474609375
INFO:root:Train (Epoch 79): Loss/seq after 00600 batchs: 1015.8515625
INFO:root:Train (Epoch 79): Loss/seq after 00650 batchs: 1028.78271484375
INFO:root:Train (Epoch 79): Loss/seq after 00700 batchs: 1008.357177734375
INFO:root:Train (Epoch 79): Loss/seq after 00750 batchs: 1041.25341796875
INFO:root:Train (Epoch 79): Loss/seq after 00800 batchs: 1031.74462890625
INFO:root:Train (Epoch 79): Loss/seq after 00850 batchs: 1001.3143920898438
INFO:root:Train (Epoch 79): Loss/seq after 00900 batchs: 984.878662109375
INFO:root:Train (Epoch 79): Loss/seq after 00950 batchs: 996.31787109375
INFO:root:Train (Epoch 79): Loss/seq after 01000 batchs: 991.0
INFO:root:Train (Epoch 79): Loss/seq after 01050 batchs: 972.7272338867188
INFO:root:Train (Epoch 79): Loss/seq after 01100 batchs: 958.373779296875
INFO:root:Train (Epoch 79): Loss/seq after 01150 batchs: 935.091552734375
INFO:root:Train (Epoch 79): Loss/seq after 01200 batchs: 935.8104858398438
INFO:root:Train (Epoch 79): Loss/seq after 01250 batchs: 932.6298828125
INFO:root:Train (Epoch 79): Loss/seq after 01300 batchs: 928.64306640625
INFO:root:Train (Epoch 79): Loss/seq after 01350 batchs: 924.1117553710938
INFO:root:Train (Epoch 79): Loss/seq after 01400 batchs: 942.0430908203125
INFO:root:Train (Epoch 79): Loss/seq after 01450 batchs: 940.4229736328125
INFO:root:Train (Epoch 79): Loss/seq after 01500 batchs: 941.7717895507812
INFO:root:Train (Epoch 79): Loss/seq after 01550 batchs: 945.0759887695312
INFO:root:Train (Epoch 79): Loss/seq after 01600 batchs: 937.8611450195312
INFO:root:Train (Epoch 79): Loss/seq after 01650 batchs: 932.29638671875
INFO:root:Train (Epoch 79): Loss/seq after 01700 batchs: 929.328369140625
INFO:root:Train (Epoch 79): Loss/seq after 01750 batchs: 923.8221435546875
INFO:root:Train (Epoch 79): Loss/seq after 01800 batchs: 916.4608154296875
INFO:root:Train (Epoch 79): Loss/seq after 01850 batchs: 907.9216918945312
INFO:root:Train (Epoch 79): Loss/seq after 01900 batchs: 909.204345703125
INFO:root:Train (Epoch 79): Loss/seq after 01950 batchs: 904.3526000976562
INFO:root:Train (Epoch 79): Loss/seq after 02000 batchs: 901.3596801757812
INFO:root:Train (Epoch 79): Loss/seq after 02050 batchs: 897.7796630859375
INFO:root:Train (Epoch 79): Loss/seq after 02100 batchs: 891.092041015625
INFO:root:Train (Epoch 79): Loss/seq after 02150 batchs: 885.947265625
INFO:root:Train (Epoch 79): Loss/seq after 02200 batchs: 879.7996215820312
INFO:root:Train (Epoch 79): Loss/seq after 02250 batchs: 880.5430297851562
INFO:root:Train (Epoch 79): Loss/seq after 02300 batchs: 887.4938354492188
INFO:root:Train (Epoch 79): Loss/seq after 02350 batchs: 880.0027465820312
INFO:root:Train (Epoch 79): Loss/seq after 02400 batchs: 877.9427490234375
INFO:root:Train (Epoch 79): Loss/seq after 02450 batchs: 869.909423828125
INFO:root:Train (Epoch 79): Loss/seq after 02500 batchs: 856.3644409179688
INFO:root:Train (Epoch 79): Loss/seq after 02550 batchs: 846.5231323242188
INFO:root:Train (Epoch 79): Loss/seq after 02600 batchs: 844.2869262695312
INFO:root:Train (Epoch 79): Loss/seq after 02650 batchs: 840.0712890625
INFO:root:Train (Epoch 79): Loss/seq after 02700 batchs: 836.9524536132812
INFO:root:Train (Epoch 79): Loss/seq after 02750 batchs: 862.0245971679688
INFO:root:Train (Epoch 79): Loss/seq after 02800 batchs: 865.9912719726562
INFO:root:Train (Epoch 79): Loss/seq after 02850 batchs: 863.9947509765625
INFO:root:Train (Epoch 79): Loss/seq after 02900 batchs: 863.8805541992188
INFO:root:Train (Epoch 79): Loss/seq after 02950 batchs: 859.5786743164062
INFO:root:Train (Epoch 79): Loss/seq after 03000 batchs: 861.8255004882812
INFO:root:Train (Epoch 79): Loss/seq after 03050 batchs: 867.1149291992188
INFO:root:Train (Epoch 79): Loss/seq after 03100 batchs: 873.0762329101562
INFO:root:Train (Epoch 79): Loss/seq after 03150 batchs: 878.2811889648438
INFO:root:Train (Epoch 79): Loss/seq after 03200 batchs: 884.6007080078125
INFO:root:Train (Epoch 79): Loss/seq after 03250 batchs: 888.5237426757812
INFO:root:Train (Epoch 79): Loss/seq after 03300 batchs: 888.0248413085938
INFO:root:Train (Epoch 79): Loss/seq after 03350 batchs: 886.67333984375
INFO:root:Train (Epoch 79): Loss/seq after 03400 batchs: 879.1737670898438
INFO:root:Train (Epoch 79): Loss/seq after 03450 batchs: 874.396728515625
INFO:root:Train (Epoch 79): Loss/seq after 03500 batchs: 873.458740234375
INFO:root:Train (Epoch 79): Loss/seq after 03550 batchs: 868.4181518554688
INFO:root:Train (Epoch 79): Loss/seq after 03600 batchs: 875.297119140625
INFO:root:Train (Epoch 79): Loss/seq after 03650 batchs: 870.6043701171875
INFO:root:Train (Epoch 79): Loss/seq after 03700 batchs: 870.7262573242188
INFO:root:Train (Epoch 79): Loss/seq after 03750 batchs: 874.3632202148438
INFO:root:Train (Epoch 79): Loss/seq after 03800 batchs: 869.5503540039062
INFO:root:Train (Epoch 79): Loss/seq after 03850 batchs: 867.4505004882812
INFO:root:Train (Epoch 79): Loss/seq after 03900 batchs: 871.2025756835938
INFO:root:Train (Epoch 79): Loss/seq after 03950 batchs: 875.6992797851562
INFO:root:Train (Epoch 79): Loss/seq after 04000 batchs: 870.4711303710938
INFO:root:Train (Epoch 79): Loss/seq after 04050 batchs: 864.7349243164062
INFO:root:Train (Epoch 79): Loss/seq after 04100 batchs: 860.8225708007812
INFO:root:Train (Epoch 79): Loss/seq after 04150 batchs: 858.3619995117188
INFO:root:Train (Epoch 79): Loss/seq after 04200 batchs: 855.2373046875
INFO:root:Train (Epoch 79): Loss/seq after 04250 batchs: 852.1991577148438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 79): Loss/seq after 00000 batches: 556.31494140625
INFO:root:# Valid (Epoch 79): Loss/seq after 00050 batches: 779.0674438476562
INFO:root:# Valid (Epoch 79): Loss/seq after 00100 batches: 1084.85791015625
INFO:root:# Valid (Epoch 79): Loss/seq after 00150 batches: 832.2879028320312
INFO:root:# Valid (Epoch 79): Loss/seq after 00200 batches: 777.1953125
INFO:root:Artifacts: Make stick videos for epoch 79
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_79_on_20220413_214914.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_79_index_735_on_20220413_214914.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 80): Loss/seq after 00000 batchs: 1418.7442626953125
INFO:root:Train (Epoch 80): Loss/seq after 00050 batchs: 1088.8773193359375
INFO:root:Train (Epoch 80): Loss/seq after 00100 batchs: 1110.51171875
INFO:root:Train (Epoch 80): Loss/seq after 00150 batchs: 1007.682861328125
INFO:root:Train (Epoch 80): Loss/seq after 00200 batchs: 1122.8018798828125
INFO:root:Train (Epoch 80): Loss/seq after 00250 batchs: 1243.8817138671875
INFO:root:Train (Epoch 80): Loss/seq after 00300 batchs: 1205.7244873046875
INFO:root:Train (Epoch 80): Loss/seq after 00350 batchs: 1123.8751220703125
INFO:root:Train (Epoch 80): Loss/seq after 00400 batchs: 1143.1741943359375
INFO:root:Train (Epoch 80): Loss/seq after 00450 batchs: 1108.6043701171875
INFO:root:Train (Epoch 80): Loss/seq after 00500 batchs: 1090.7999267578125
INFO:root:Train (Epoch 80): Loss/seq after 00550 batchs: 1052.6258544921875
INFO:root:Train (Epoch 80): Loss/seq after 00600 batchs: 1014.8890380859375
INFO:root:Train (Epoch 80): Loss/seq after 00650 batchs: 1025.53662109375
INFO:root:Train (Epoch 80): Loss/seq after 00700 batchs: 1003.589111328125
INFO:root:Train (Epoch 80): Loss/seq after 00750 batchs: 1035.08203125
INFO:root:Train (Epoch 80): Loss/seq after 00800 batchs: 1024.9696044921875
INFO:root:Train (Epoch 80): Loss/seq after 00850 batchs: 993.8636474609375
INFO:root:Train (Epoch 80): Loss/seq after 00900 batchs: 976.7901000976562
INFO:root:Train (Epoch 80): Loss/seq after 00950 batchs: 989.2166137695312
INFO:root:Train (Epoch 80): Loss/seq after 01000 batchs: 984.9695434570312
INFO:root:Train (Epoch 80): Loss/seq after 01050 batchs: 968.4226684570312
INFO:root:Train (Epoch 80): Loss/seq after 01100 batchs: 952.8709106445312
INFO:root:Train (Epoch 80): Loss/seq after 01150 batchs: 929.99658203125
INFO:root:Train (Epoch 80): Loss/seq after 01200 batchs: 930.1294555664062
INFO:root:Train (Epoch 80): Loss/seq after 01250 batchs: 929.985595703125
INFO:root:Train (Epoch 80): Loss/seq after 01300 batchs: 926.000244140625
INFO:root:Train (Epoch 80): Loss/seq after 01350 batchs: 920.1648559570312
INFO:root:Train (Epoch 80): Loss/seq after 01400 batchs: 935.4554443359375
INFO:root:Train (Epoch 80): Loss/seq after 01450 batchs: 934.682373046875
INFO:root:Train (Epoch 80): Loss/seq after 01500 batchs: 935.6187133789062
INFO:root:Train (Epoch 80): Loss/seq after 01550 batchs: 938.819091796875
INFO:root:Train (Epoch 80): Loss/seq after 01600 batchs: 930.1209106445312
INFO:root:Train (Epoch 80): Loss/seq after 01650 batchs: 923.3734741210938
INFO:root:Train (Epoch 80): Loss/seq after 01700 batchs: 920.4944458007812
INFO:root:Train (Epoch 80): Loss/seq after 01750 batchs: 915.0861206054688
INFO:root:Train (Epoch 80): Loss/seq after 01800 batchs: 907.839111328125
INFO:root:Train (Epoch 80): Loss/seq after 01850 batchs: 899.4970092773438
INFO:root:Train (Epoch 80): Loss/seq after 01900 batchs: 900.5684814453125
INFO:root:Train (Epoch 80): Loss/seq after 01950 batchs: 895.4722290039062
INFO:root:Train (Epoch 80): Loss/seq after 02000 batchs: 892.1292724609375
INFO:root:Train (Epoch 80): Loss/seq after 02050 batchs: 888.56689453125
INFO:root:Train (Epoch 80): Loss/seq after 02100 batchs: 881.95068359375
INFO:root:Train (Epoch 80): Loss/seq after 02150 batchs: 877.0437622070312
INFO:root:Train (Epoch 80): Loss/seq after 02200 batchs: 871.1185302734375
INFO:root:Train (Epoch 80): Loss/seq after 02250 batchs: 871.9935302734375
INFO:root:Train (Epoch 80): Loss/seq after 02300 batchs: 880.24267578125
INFO:root:Train (Epoch 80): Loss/seq after 02350 batchs: 872.6904907226562
INFO:root:Train (Epoch 80): Loss/seq after 02400 batchs: 870.461669921875
INFO:root:Train (Epoch 80): Loss/seq after 02450 batchs: 862.5755615234375
INFO:root:Train (Epoch 80): Loss/seq after 02500 batchs: 849.1201782226562
INFO:root:Train (Epoch 80): Loss/seq after 02550 batchs: 839.3582763671875
INFO:root:Train (Epoch 80): Loss/seq after 02600 batchs: 836.9940185546875
INFO:root:Train (Epoch 80): Loss/seq after 02650 batchs: 832.7510986328125
INFO:root:Train (Epoch 80): Loss/seq after 02700 batchs: 829.7666625976562
INFO:root:Train (Epoch 80): Loss/seq after 02750 batchs: 855.5371704101562
INFO:root:Train (Epoch 80): Loss/seq after 02800 batchs: 860.5186767578125
INFO:root:Train (Epoch 80): Loss/seq after 02850 batchs: 858.4959106445312
INFO:root:Train (Epoch 80): Loss/seq after 02900 batchs: 858.4439697265625
INFO:root:Train (Epoch 80): Loss/seq after 02950 batchs: 854.1834716796875
INFO:root:Train (Epoch 80): Loss/seq after 03000 batchs: 856.4268798828125
INFO:root:Train (Epoch 80): Loss/seq after 03050 batchs: 861.696533203125
INFO:root:Train (Epoch 80): Loss/seq after 03100 batchs: 867.8812255859375
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 80): Loss/seq after 03150 batchs: 874.390869140625
INFO:root:Train (Epoch 80): Loss/seq after 03200 batchs: 881.4705200195312
INFO:root:Train (Epoch 80): Loss/seq after 03250 batchs: 885.2596435546875
INFO:root:Train (Epoch 80): Loss/seq after 03300 batchs: 883.984375
INFO:root:Train (Epoch 80): Loss/seq after 03350 batchs: 883.1469116210938
INFO:root:Train (Epoch 80): Loss/seq after 03400 batchs: 875.7037353515625
INFO:root:Train (Epoch 80): Loss/seq after 03450 batchs: 871.281494140625
INFO:root:Train (Epoch 80): Loss/seq after 03500 batchs: 870.8375244140625
INFO:root:Train (Epoch 80): Loss/seq after 03550 batchs: 866.291748046875
INFO:root:Train (Epoch 80): Loss/seq after 03600 batchs: 873.3257446289062
INFO:root:Train (Epoch 80): Loss/seq after 03650 batchs: 868.6486206054688
INFO:root:Train (Epoch 80): Loss/seq after 03700 batchs: 868.5723876953125
INFO:root:Train (Epoch 80): Loss/seq after 03750 batchs: 872.3238525390625
INFO:root:Train (Epoch 80): Loss/seq after 03800 batchs: 867.5398559570312
INFO:root:Train (Epoch 80): Loss/seq after 03850 batchs: 865.54345703125
INFO:root:Train (Epoch 80): Loss/seq after 03900 batchs: 869.2647705078125
INFO:root:Train (Epoch 80): Loss/seq after 03950 batchs: 873.7440795898438
INFO:root:Train (Epoch 80): Loss/seq after 04000 batchs: 868.4805908203125
INFO:root:Train (Epoch 80): Loss/seq after 04050 batchs: 862.7261962890625
INFO:root:Train (Epoch 80): Loss/seq after 04100 batchs: 858.982666015625
INFO:root:Train (Epoch 80): Loss/seq after 04150 batchs: 856.4974365234375
INFO:root:Train (Epoch 80): Loss/seq after 04200 batchs: 853.399658203125
INFO:root:Train (Epoch 80): Loss/seq after 04250 batchs: 850.3958740234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 80): Loss/seq after 00000 batches: 534.6571044921875
INFO:root:# Valid (Epoch 80): Loss/seq after 00050 batches: 779.3286743164062
INFO:root:# Valid (Epoch 80): Loss/seq after 00100 batches: 1065.7462158203125
INFO:root:# Valid (Epoch 80): Loss/seq after 00150 batches: 823.556884765625
INFO:root:# Valid (Epoch 80): Loss/seq after 00200 batches: 768.3268432617188
INFO:root:Artifacts: Make stick videos for epoch 80
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_80_on_20220413_215433.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_80_index_827_on_20220413_215433.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 81): Loss/seq after 00000 batchs: 1383.91162109375
INFO:root:Train (Epoch 81): Loss/seq after 00050 batchs: 1060.4432373046875
INFO:root:Train (Epoch 81): Loss/seq after 00100 batchs: 1108.5501708984375
INFO:root:Train (Epoch 81): Loss/seq after 00150 batchs: 1006.7332153320312
INFO:root:Train (Epoch 81): Loss/seq after 00200 batchs: 1120.98388671875
INFO:root:Train (Epoch 81): Loss/seq after 00250 batchs: 1238.655029296875
INFO:root:Train (Epoch 81): Loss/seq after 00300 batchs: 1200.1116943359375
INFO:root:Train (Epoch 81): Loss/seq after 00350 batchs: 1119.22265625
INFO:root:Train (Epoch 81): Loss/seq after 00400 batchs: 1140.88037109375
INFO:root:Train (Epoch 81): Loss/seq after 00450 batchs: 1106.0478515625
INFO:root:Train (Epoch 81): Loss/seq after 00500 batchs: 1093.1761474609375
INFO:root:Train (Epoch 81): Loss/seq after 00550 batchs: 1054.408203125
INFO:root:Train (Epoch 81): Loss/seq after 00600 batchs: 1015.9830932617188
INFO:root:Train (Epoch 81): Loss/seq after 00650 batchs: 1027.381591796875
INFO:root:Train (Epoch 81): Loss/seq after 00700 batchs: 1005.0357055664062
INFO:root:Train (Epoch 81): Loss/seq after 00750 batchs: 1035.8450927734375
INFO:root:Train (Epoch 81): Loss/seq after 00800 batchs: 1026.5867919921875
INFO:root:Train (Epoch 81): Loss/seq after 00850 batchs: 995.1550903320312
INFO:root:Train (Epoch 81): Loss/seq after 00900 batchs: 976.5354614257812
INFO:root:Train (Epoch 81): Loss/seq after 00950 batchs: 987.9469604492188
INFO:root:Train (Epoch 81): Loss/seq after 01000 batchs: 983.7874145507812
INFO:root:Train (Epoch 81): Loss/seq after 01050 batchs: 964.7254638671875
INFO:root:Train (Epoch 81): Loss/seq after 01100 batchs: 948.5087890625
INFO:root:Train (Epoch 81): Loss/seq after 01150 batchs: 924.8049926757812
INFO:root:Train (Epoch 81): Loss/seq after 01200 batchs: 924.1597290039062
INFO:root:Train (Epoch 81): Loss/seq after 01250 batchs: 920.5050659179688
INFO:root:Train (Epoch 81): Loss/seq after 01300 batchs: 917.4326171875
INFO:root:Train (Epoch 81): Loss/seq after 01350 batchs: 913.068359375
INFO:root:Train (Epoch 81): Loss/seq after 01400 batchs: 928.9487915039062
INFO:root:Train (Epoch 81): Loss/seq after 01450 batchs: 927.213623046875
INFO:root:Train (Epoch 81): Loss/seq after 01500 batchs: 928.5184326171875
INFO:root:Train (Epoch 81): Loss/seq after 01550 batchs: 931.2964477539062
INFO:root:Train (Epoch 81): Loss/seq after 01600 batchs: 922.9656372070312
INFO:root:Train (Epoch 81): Loss/seq after 01650 batchs: 916.0460815429688
INFO:root:Train (Epoch 81): Loss/seq after 01700 batchs: 913.3626098632812
INFO:root:Train (Epoch 81): Loss/seq after 01750 batchs: 907.9558715820312
INFO:root:Train (Epoch 81): Loss/seq after 01800 batchs: 900.8146362304688
INFO:root:Train (Epoch 81): Loss/seq after 01850 batchs: 892.51318359375
INFO:root:Train (Epoch 81): Loss/seq after 01900 batchs: 893.94873046875
INFO:root:Train (Epoch 81): Loss/seq after 01950 batchs: 888.8084716796875
INFO:root:Train (Epoch 81): Loss/seq after 02000 batchs: 885.5711669921875
INFO:root:Train (Epoch 81): Loss/seq after 02050 batchs: 882.1564331054688
INFO:root:Train (Epoch 81): Loss/seq after 02100 batchs: 875.6607666015625
INFO:root:Train (Epoch 81): Loss/seq after 02150 batchs: 870.9193115234375
INFO:root:Train (Epoch 81): Loss/seq after 02200 batchs: 865.1522827148438
INFO:root:Train (Epoch 81): Loss/seq after 02250 batchs: 865.6345825195312
INFO:root:Train (Epoch 81): Loss/seq after 02300 batchs: 871.32421875
INFO:root:Train (Epoch 81): Loss/seq after 02350 batchs: 863.9374389648438
INFO:root:Train (Epoch 81): Loss/seq after 02400 batchs: 861.8660278320312
INFO:root:Train (Epoch 81): Loss/seq after 02450 batchs: 854.0712280273438
INFO:root:Train (Epoch 81): Loss/seq after 02500 batchs: 840.6800537109375
INFO:root:Train (Epoch 81): Loss/seq after 02550 batchs: 830.9951782226562
INFO:root:Train (Epoch 81): Loss/seq after 02600 batchs: 828.5964965820312
INFO:root:Train (Epoch 81): Loss/seq after 02650 batchs: 824.5023803710938
INFO:root:Train (Epoch 81): Loss/seq after 02700 batchs: 821.4869995117188
INFO:root:Train (Epoch 81): Loss/seq after 02750 batchs: 846.404052734375
INFO:root:Train (Epoch 81): Loss/seq after 02800 batchs: 850.5938720703125
INFO:root:Train (Epoch 81): Loss/seq after 02850 batchs: 848.8855590820312
INFO:root:Train (Epoch 81): Loss/seq after 02900 batchs: 850.0198974609375
INFO:root:Train (Epoch 81): Loss/seq after 02950 batchs: 846.0252685546875
INFO:root:Train (Epoch 81): Loss/seq after 03000 batchs: 848.381591796875
INFO:root:Train (Epoch 81): Loss/seq after 03050 batchs: 853.675537109375
INFO:root:Train (Epoch 81): Loss/seq after 03100 batchs: 859.3198852539062
INFO:root:Train (Epoch 81): Loss/seq after 03150 batchs: 863.8825073242188
INFO:root:Train (Epoch 81): Loss/seq after 03200 batchs: 870.9940795898438
INFO:root:Train (Epoch 81): Loss/seq after 03250 batchs: 874.8313598632812
INFO:root:Train (Epoch 81): Loss/seq after 03300 batchs: 873.320068359375
INFO:root:Train (Epoch 81): Loss/seq after 03350 batchs: 871.8641967773438
INFO:root:Train (Epoch 81): Loss/seq after 03400 batchs: 864.4085083007812
INFO:root:Train (Epoch 81): Loss/seq after 03450 batchs: 860.2532958984375
INFO:root:Train (Epoch 81): Loss/seq after 03500 batchs: 859.4635620117188
INFO:root:Train (Epoch 81): Loss/seq after 03550 batchs: 854.7781982421875
INFO:root:Train (Epoch 81): Loss/seq after 03600 batchs: 861.8606567382812
INFO:root:Train (Epoch 81): Loss/seq after 03650 batchs: 857.3687744140625
INFO:root:Train (Epoch 81): Loss/seq after 03700 batchs: 857.5137329101562
INFO:root:Train (Epoch 81): Loss/seq after 03750 batchs: 861.2379150390625
INFO:root:Train (Epoch 81): Loss/seq after 03800 batchs: 856.5935668945312
INFO:root:Train (Epoch 81): Loss/seq after 03850 batchs: 854.7592163085938
INFO:root:Train (Epoch 81): Loss/seq after 03900 batchs: 858.3731689453125
INFO:root:Train (Epoch 81): Loss/seq after 03950 batchs: 862.7736206054688
INFO:root:Train (Epoch 81): Loss/seq after 04000 batchs: 857.6685180664062
INFO:root:Train (Epoch 81): Loss/seq after 04050 batchs: 852.02734375
INFO:root:Train (Epoch 81): Loss/seq after 04100 batchs: 848.2974243164062
INFO:root:Train (Epoch 81): Loss/seq after 04150 batchs: 845.8737182617188
INFO:root:Train (Epoch 81): Loss/seq after 04200 batchs: 842.8905029296875
INFO:root:Train (Epoch 81): Loss/seq after 04250 batchs: 839.8349609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 81): Loss/seq after 00000 batches: 568.1005859375
INFO:root:# Valid (Epoch 81): Loss/seq after 00050 batches: 759.7185668945312
INFO:root:# Valid (Epoch 81): Loss/seq after 00100 batches: 1043.04638671875
INFO:root:# Valid (Epoch 81): Loss/seq after 00150 batches: 800.4989624023438
INFO:root:# Valid (Epoch 81): Loss/seq after 00200 batches: 748.4839477539062
INFO:root:Artifacts: Make stick videos for epoch 81
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_81_on_20220413_215951.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_81_index_1339_on_20220413_215951.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 82): Loss/seq after 00000 batchs: 1363.6715087890625
INFO:root:Train (Epoch 82): Loss/seq after 00050 batchs: 1083.284423828125
INFO:root:Train (Epoch 82): Loss/seq after 00100 batchs: 1115.8265380859375
INFO:root:Train (Epoch 82): Loss/seq after 00150 batchs: 1013.0184936523438
INFO:root:Train (Epoch 82): Loss/seq after 00200 batchs: 1117.17578125
INFO:root:Train (Epoch 82): Loss/seq after 00250 batchs: 1232.1876220703125
INFO:root:Train (Epoch 82): Loss/seq after 00300 batchs: 1194.337646484375
INFO:root:Train (Epoch 82): Loss/seq after 00350 batchs: 1114.333740234375
INFO:root:Train (Epoch 82): Loss/seq after 00400 batchs: 1135.0836181640625
INFO:root:Train (Epoch 82): Loss/seq after 00450 batchs: 1101.4459228515625
INFO:root:Train (Epoch 82): Loss/seq after 00500 batchs: 1089.5601806640625
INFO:root:Train (Epoch 82): Loss/seq after 00550 batchs: 1050.734375
INFO:root:Train (Epoch 82): Loss/seq after 00600 batchs: 1013.5255737304688
INFO:root:Train (Epoch 82): Loss/seq after 00650 batchs: 1025.2401123046875
INFO:root:Train (Epoch 82): Loss/seq after 00700 batchs: 1003.1156616210938
INFO:root:Train (Epoch 82): Loss/seq after 00750 batchs: 1035.206298828125
INFO:root:Train (Epoch 82): Loss/seq after 00800 batchs: 1029.56396484375
INFO:root:Train (Epoch 82): Loss/seq after 00850 batchs: 1000.6422119140625
INFO:root:Train (Epoch 82): Loss/seq after 00900 batchs: 983.2129516601562
INFO:root:Train (Epoch 82): Loss/seq after 00950 batchs: 995.0153198242188
INFO:root:Train (Epoch 82): Loss/seq after 01000 batchs: 992.160400390625
INFO:root:Train (Epoch 82): Loss/seq after 01050 batchs: 973.8741455078125
INFO:root:Train (Epoch 82): Loss/seq after 01100 batchs: 957.0139770507812
INFO:root:Train (Epoch 82): Loss/seq after 01150 batchs: 933.1946411132812
INFO:root:Train (Epoch 82): Loss/seq after 01200 batchs: 932.3763427734375
INFO:root:Train (Epoch 82): Loss/seq after 01250 batchs: 927.7617797851562
INFO:root:Train (Epoch 82): Loss/seq after 01300 batchs: 922.2085571289062
INFO:root:Train (Epoch 82): Loss/seq after 01350 batchs: 917.0130004882812
INFO:root:Train (Epoch 82): Loss/seq after 01400 batchs: 935.1596069335938
INFO:root:Train (Epoch 82): Loss/seq after 01450 batchs: 932.6395263671875
INFO:root:Train (Epoch 82): Loss/seq after 01500 batchs: 933.521728515625
INFO:root:Train (Epoch 82): Loss/seq after 01550 batchs: 936.5782470703125
INFO:root:Train (Epoch 82): Loss/seq after 01600 batchs: 927.9473266601562
INFO:root:Train (Epoch 82): Loss/seq after 01650 batchs: 920.7861328125
INFO:root:Train (Epoch 82): Loss/seq after 01700 batchs: 917.862548828125
INFO:root:Train (Epoch 82): Loss/seq after 01750 batchs: 912.1196899414062
INFO:root:Train (Epoch 82): Loss/seq after 01800 batchs: 904.78173828125
INFO:root:Train (Epoch 82): Loss/seq after 01850 batchs: 896.4859008789062
INFO:root:Train (Epoch 82): Loss/seq after 01900 batchs: 897.539794921875
INFO:root:Train (Epoch 82): Loss/seq after 01950 batchs: 892.03662109375
INFO:root:Train (Epoch 82): Loss/seq after 02000 batchs: 888.6950073242188
INFO:root:Train (Epoch 82): Loss/seq after 02050 batchs: 885.21826171875
INFO:root:Train (Epoch 82): Loss/seq after 02100 batchs: 878.5722045898438
INFO:root:Train (Epoch 82): Loss/seq after 02150 batchs: 873.640380859375
INFO:root:Train (Epoch 82): Loss/seq after 02200 batchs: 867.6351928710938
INFO:root:Train (Epoch 82): Loss/seq after 02250 batchs: 868.2139892578125
INFO:root:Train (Epoch 82): Loss/seq after 02300 batchs: 876.0104370117188
INFO:root:Train (Epoch 82): Loss/seq after 02350 batchs: 868.7100830078125
INFO:root:Train (Epoch 82): Loss/seq after 02400 batchs: 866.4300537109375
INFO:root:Train (Epoch 82): Loss/seq after 02450 batchs: 858.4253540039062
INFO:root:Train (Epoch 82): Loss/seq after 02500 batchs: 844.9459228515625
INFO:root:Train (Epoch 82): Loss/seq after 02550 batchs: 834.9163818359375
INFO:root:Train (Epoch 82): Loss/seq after 02600 batchs: 832.5847778320312
INFO:root:Train (Epoch 82): Loss/seq after 02650 batchs: 828.3485717773438
INFO:root:Train (Epoch 82): Loss/seq after 02700 batchs: 825.0094604492188
INFO:root:Train (Epoch 82): Loss/seq after 02750 batchs: 849.6101684570312
INFO:root:Train (Epoch 82): Loss/seq after 02800 batchs: 853.7048950195312
INFO:root:Train (Epoch 82): Loss/seq after 02850 batchs: 851.7791137695312
INFO:root:Train (Epoch 82): Loss/seq after 02900 batchs: 851.6595458984375
INFO:root:Train (Epoch 82): Loss/seq after 02950 batchs: 847.4986572265625
INFO:root:Train (Epoch 82): Loss/seq after 03000 batchs: 849.762451171875
INFO:root:Train (Epoch 82): Loss/seq after 03050 batchs: 854.8418579101562
INFO:root:Train (Epoch 82): Loss/seq after 03100 batchs: 859.81640625
INFO:root:Train (Epoch 82): Loss/seq after 03150 batchs: 865.0966796875
INFO:root:Train (Epoch 82): Loss/seq after 03200 batchs: 871.788330078125
INFO:root:Train (Epoch 82): Loss/seq after 03250 batchs: 875.813720703125
INFO:root:Train (Epoch 82): Loss/seq after 03300 batchs: 874.2744750976562
INFO:root:Train (Epoch 82): Loss/seq after 03350 batchs: 872.7174072265625
INFO:root:Train (Epoch 82): Loss/seq after 03400 batchs: 865.3544311523438
INFO:root:Train (Epoch 82): Loss/seq after 03450 batchs: 860.9429321289062
INFO:root:Train (Epoch 82): Loss/seq after 03500 batchs: 860.1175537109375
INFO:root:Train (Epoch 82): Loss/seq after 03550 batchs: 855.1016235351562
INFO:root:Train (Epoch 82): Loss/seq after 03600 batchs: 861.8652954101562
INFO:root:Train (Epoch 82): Loss/seq after 03650 batchs: 857.3035888671875
INFO:root:Train (Epoch 82): Loss/seq after 03700 batchs: 857.5723876953125
INFO:root:Train (Epoch 82): Loss/seq after 03750 batchs: 861.320556640625
INFO:root:Train (Epoch 82): Loss/seq after 03800 batchs: 856.579833984375
INFO:root:Train (Epoch 82): Loss/seq after 03850 batchs: 854.640380859375
INFO:root:Train (Epoch 82): Loss/seq after 03900 batchs: 858.3469848632812
INFO:root:Train (Epoch 82): Loss/seq after 03950 batchs: 862.90380859375
INFO:root:Train (Epoch 82): Loss/seq after 04000 batchs: 857.6873168945312
INFO:root:Train (Epoch 82): Loss/seq after 04050 batchs: 851.967041015625
INFO:root:Train (Epoch 82): Loss/seq after 04100 batchs: 848.2147827148438
INFO:root:Train (Epoch 82): Loss/seq after 04150 batchs: 845.9100341796875
INFO:root:Train (Epoch 82): Loss/seq after 04200 batchs: 842.8551635742188
INFO:root:Train (Epoch 82): Loss/seq after 04250 batchs: 839.8629150390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 82): Loss/seq after 00000 batches: 608.8330688476562
INFO:root:# Valid (Epoch 82): Loss/seq after 00050 batches: 768.1383666992188
INFO:root:# Valid (Epoch 82): Loss/seq after 00100 batches: 1065.375
INFO:root:# Valid (Epoch 82): Loss/seq after 00150 batches: 818.4656982421875
INFO:root:# Valid (Epoch 82): Loss/seq after 00200 batches: 763.7129516601562
INFO:root:Artifacts: Make stick videos for epoch 82
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_82_on_20220413_220510.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_82_index_1314_on_20220413_220510.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 83): Loss/seq after 00000 batchs: 1397.7279052734375
INFO:root:Train (Epoch 83): Loss/seq after 00050 batchs: 1070.2998046875
INFO:root:Train (Epoch 83): Loss/seq after 00100 batchs: 1106.3179931640625
INFO:root:Train (Epoch 83): Loss/seq after 00150 batchs: 1003.2225952148438
INFO:root:Train (Epoch 83): Loss/seq after 00200 batchs: 1115.362060546875
INFO:root:Train (Epoch 83): Loss/seq after 00250 batchs: 1231.5921630859375
INFO:root:Train (Epoch 83): Loss/seq after 00300 batchs: 1192.7620849609375
INFO:root:Train (Epoch 83): Loss/seq after 00350 batchs: 1112.625
INFO:root:Train (Epoch 83): Loss/seq after 00400 batchs: 1131.4859619140625
INFO:root:Train (Epoch 83): Loss/seq after 00450 batchs: 1096.76123046875
INFO:root:Train (Epoch 83): Loss/seq after 00500 batchs: 1079.566650390625
INFO:root:Train (Epoch 83): Loss/seq after 00550 batchs: 1042.0872802734375
INFO:root:Train (Epoch 83): Loss/seq after 00600 batchs: 1004.6228637695312
INFO:root:Train (Epoch 83): Loss/seq after 00650 batchs: 1016.6173095703125
INFO:root:Train (Epoch 83): Loss/seq after 00700 batchs: 994.9603271484375
INFO:root:Train (Epoch 83): Loss/seq after 00750 batchs: 1024.7957763671875
INFO:root:Train (Epoch 83): Loss/seq after 00800 batchs: 1016.2549438476562
INFO:root:Train (Epoch 83): Loss/seq after 00850 batchs: 985.2053833007812
INFO:root:Train (Epoch 83): Loss/seq after 00900 batchs: 966.44775390625
INFO:root:Train (Epoch 83): Loss/seq after 00950 batchs: 978.0294189453125
INFO:root:Train (Epoch 83): Loss/seq after 01000 batchs: 972.9762573242188
INFO:root:Train (Epoch 83): Loss/seq after 01050 batchs: 953.1533813476562
INFO:root:Train (Epoch 83): Loss/seq after 01100 batchs: 935.379150390625
INFO:root:Train (Epoch 83): Loss/seq after 01150 batchs: 911.7180786132812
INFO:root:Train (Epoch 83): Loss/seq after 01200 batchs: 911.0675659179688
INFO:root:Train (Epoch 83): Loss/seq after 01250 batchs: 906.9992065429688
INFO:root:Train (Epoch 83): Loss/seq after 01300 batchs: 900.8093872070312
INFO:root:Train (Epoch 83): Loss/seq after 01350 batchs: 895.198974609375
INFO:root:Train (Epoch 83): Loss/seq after 01400 batchs: 912.5330810546875
INFO:root:Train (Epoch 83): Loss/seq after 01450 batchs: 911.5708618164062
INFO:root:Train (Epoch 83): Loss/seq after 01500 batchs: 913.1046142578125
INFO:root:Train (Epoch 83): Loss/seq after 01550 batchs: 916.1851806640625
INFO:root:Train (Epoch 83): Loss/seq after 01600 batchs: 908.263916015625
INFO:root:Train (Epoch 83): Loss/seq after 01650 batchs: 902.0897827148438
INFO:root:Train (Epoch 83): Loss/seq after 01700 batchs: 899.5643310546875
INFO:root:Train (Epoch 83): Loss/seq after 01750 batchs: 894.3994140625
INFO:root:Train (Epoch 83): Loss/seq after 01800 batchs: 887.5447387695312
INFO:root:Train (Epoch 83): Loss/seq after 01850 batchs: 879.625244140625
INFO:root:Train (Epoch 83): Loss/seq after 01900 batchs: 880.8348388671875
INFO:root:Train (Epoch 83): Loss/seq after 01950 batchs: 876.0107421875
INFO:root:Train (Epoch 83): Loss/seq after 02000 batchs: 872.85791015625
INFO:root:Train (Epoch 83): Loss/seq after 02050 batchs: 869.2946166992188
INFO:root:Train (Epoch 83): Loss/seq after 02100 batchs: 863.1795043945312
INFO:root:Train (Epoch 83): Loss/seq after 02150 batchs: 858.5554809570312
INFO:root:Train (Epoch 83): Loss/seq after 02200 batchs: 852.8311157226562
INFO:root:Train (Epoch 83): Loss/seq after 02250 batchs: 853.3526611328125
INFO:root:Train (Epoch 83): Loss/seq after 02300 batchs: 860.6878662109375
INFO:root:Train (Epoch 83): Loss/seq after 02350 batchs: 852.9500732421875
INFO:root:Train (Epoch 83): Loss/seq after 02400 batchs: 851.127197265625
INFO:root:Train (Epoch 83): Loss/seq after 02450 batchs: 843.4546508789062
INFO:root:Train (Epoch 83): Loss/seq after 02500 batchs: 830.269287109375
INFO:root:Train (Epoch 83): Loss/seq after 02550 batchs: 820.7060546875
INFO:root:Train (Epoch 83): Loss/seq after 02600 batchs: 818.3474731445312
INFO:root:Train (Epoch 83): Loss/seq after 02650 batchs: 814.5313110351562
INFO:root:Train (Epoch 83): Loss/seq after 02700 batchs: 811.41357421875
INFO:root:Train (Epoch 83): Loss/seq after 02750 batchs: 836.3492431640625
INFO:root:Train (Epoch 83): Loss/seq after 02800 batchs: 840.5197143554688
INFO:root:Train (Epoch 83): Loss/seq after 02850 batchs: 838.7513427734375
INFO:root:Train (Epoch 83): Loss/seq after 02900 batchs: 838.7739868164062
INFO:root:Train (Epoch 83): Loss/seq after 02950 batchs: 834.7252807617188
INFO:root:Train (Epoch 83): Loss/seq after 03000 batchs: 837.2455444335938
INFO:root:Train (Epoch 83): Loss/seq after 03050 batchs: 842.4739990234375
INFO:root:Train (Epoch 83): Loss/seq after 03100 batchs: 848.9119262695312
INFO:root:Train (Epoch 83): Loss/seq after 03150 batchs: 854.6568603515625
INFO:root:Train (Epoch 83): Loss/seq after 03200 batchs: 861.4053344726562
INFO:root:Train (Epoch 83): Loss/seq after 03250 batchs: 865.5039672851562
INFO:root:Train (Epoch 83): Loss/seq after 03300 batchs: 863.7725830078125
INFO:root:Train (Epoch 83): Loss/seq after 03350 batchs: 862.3677368164062
INFO:root:Train (Epoch 83): Loss/seq after 03400 batchs: 855.0075073242188
INFO:root:Train (Epoch 83): Loss/seq after 03450 batchs: 850.7450561523438
INFO:root:Train (Epoch 83): Loss/seq after 03500 batchs: 849.8817749023438
INFO:root:Train (Epoch 83): Loss/seq after 03550 batchs: 845.1024169921875
INFO:root:Train (Epoch 83): Loss/seq after 03600 batchs: 852.12255859375
INFO:root:Train (Epoch 83): Loss/seq after 03650 batchs: 847.80517578125
INFO:root:Train (Epoch 83): Loss/seq after 03700 batchs: 848.165283203125
INFO:root:Train (Epoch 83): Loss/seq after 03750 batchs: 851.9598388671875
INFO:root:Train (Epoch 83): Loss/seq after 03800 batchs: 847.2966918945312
INFO:root:Train (Epoch 83): Loss/seq after 03850 batchs: 845.4765625
INFO:root:Train (Epoch 83): Loss/seq after 03900 batchs: 849.3922729492188
INFO:root:Train (Epoch 83): Loss/seq after 03950 batchs: 853.7070922851562
INFO:root:Train (Epoch 83): Loss/seq after 04000 batchs: 848.5869140625
INFO:root:Train (Epoch 83): Loss/seq after 04050 batchs: 842.962646484375
INFO:root:Train (Epoch 83): Loss/seq after 04100 batchs: 839.2897338867188
INFO:root:Train (Epoch 83): Loss/seq after 04150 batchs: 837.04541015625
INFO:root:Train (Epoch 83): Loss/seq after 04200 batchs: 833.9631958007812
INFO:root:Train (Epoch 83): Loss/seq after 04250 batchs: 831.074462890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 83): Loss/seq after 00000 batches: 558.8172607421875
INFO:root:# Valid (Epoch 83): Loss/seq after 00050 batches: 758.9315795898438
INFO:root:# Valid (Epoch 83): Loss/seq after 00100 batches: 1044.8636474609375
INFO:root:# Valid (Epoch 83): Loss/seq after 00150 batches: 801.3742065429688
INFO:root:# Valid (Epoch 83): Loss/seq after 00200 batches: 749.01708984375
INFO:root:Artifacts: Make stick videos for epoch 83
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_83_on_20220413_221031.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_83_index_399_on_20220413_221031.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 84): Loss/seq after 00000 batchs: 1545.7474365234375
INFO:root:Train (Epoch 84): Loss/seq after 00050 batchs: 1071.2266845703125
INFO:root:Train (Epoch 84): Loss/seq after 00100 batchs: 1106.87060546875
INFO:root:Train (Epoch 84): Loss/seq after 00150 batchs: 1011.0838012695312
INFO:root:Train (Epoch 84): Loss/seq after 00200 batchs: 1131.5789794921875
INFO:root:Train (Epoch 84): Loss/seq after 00250 batchs: 1239.66650390625
INFO:root:Train (Epoch 84): Loss/seq after 00300 batchs: 1199.3919677734375
INFO:root:Train (Epoch 84): Loss/seq after 00350 batchs: 1117.745849609375
INFO:root:Train (Epoch 84): Loss/seq after 00400 batchs: 1142.8629150390625
INFO:root:Train (Epoch 84): Loss/seq after 00450 batchs: 1105.91650390625
INFO:root:Train (Epoch 84): Loss/seq after 00500 batchs: 1092.834716796875
INFO:root:Train (Epoch 84): Loss/seq after 00550 batchs: 1055.8021240234375
INFO:root:Train (Epoch 84): Loss/seq after 00600 batchs: 1017.3607177734375
INFO:root:Train (Epoch 84): Loss/seq after 00650 batchs: 1027.767822265625
INFO:root:Train (Epoch 84): Loss/seq after 00700 batchs: 1005.0442504882812
INFO:root:Train (Epoch 84): Loss/seq after 00750 batchs: 1036.6982421875
INFO:root:Train (Epoch 84): Loss/seq after 00800 batchs: 1027.388427734375
INFO:root:Train (Epoch 84): Loss/seq after 00850 batchs: 996.6281127929688
INFO:root:Train (Epoch 84): Loss/seq after 00900 batchs: 978.2420654296875
INFO:root:Train (Epoch 84): Loss/seq after 00950 batchs: 987.329833984375
INFO:root:Train (Epoch 84): Loss/seq after 01000 batchs: 981.6392211914062
INFO:root:Train (Epoch 84): Loss/seq after 01050 batchs: 961.228759765625
INFO:root:Train (Epoch 84): Loss/seq after 01100 batchs: 943.2947387695312
INFO:root:Train (Epoch 84): Loss/seq after 01150 batchs: 919.42333984375
INFO:root:Train (Epoch 84): Loss/seq after 01200 batchs: 917.9722290039062
INFO:root:Train (Epoch 84): Loss/seq after 01250 batchs: 912.7479248046875
INFO:root:Train (Epoch 84): Loss/seq after 01300 batchs: 907.2875366210938
INFO:root:Train (Epoch 84): Loss/seq after 01350 batchs: 901.7020263671875
INFO:root:Train (Epoch 84): Loss/seq after 01400 batchs: 917.8040771484375
INFO:root:Train (Epoch 84): Loss/seq after 01450 batchs: 916.4802856445312
INFO:root:Train (Epoch 84): Loss/seq after 01500 batchs: 917.684814453125
INFO:root:Train (Epoch 84): Loss/seq after 01550 batchs: 920.514892578125
INFO:root:Train (Epoch 84): Loss/seq after 01600 batchs: 912.0510864257812
INFO:root:Train (Epoch 84): Loss/seq after 01650 batchs: 905.196533203125
INFO:root:Train (Epoch 84): Loss/seq after 01700 batchs: 902.2507934570312
INFO:root:Train (Epoch 84): Loss/seq after 01750 batchs: 896.91064453125
INFO:root:Train (Epoch 84): Loss/seq after 01800 batchs: 889.9824829101562
INFO:root:Train (Epoch 84): Loss/seq after 01850 batchs: 881.8211669921875
INFO:root:Train (Epoch 84): Loss/seq after 01900 batchs: 883.0604248046875
INFO:root:Train (Epoch 84): Loss/seq after 01950 batchs: 877.9974365234375
INFO:root:Train (Epoch 84): Loss/seq after 02000 batchs: 874.6836547851562
INFO:root:Train (Epoch 84): Loss/seq after 02050 batchs: 871.2014770507812
INFO:root:Train (Epoch 84): Loss/seq after 02100 batchs: 864.9497680664062
INFO:root:Train (Epoch 84): Loss/seq after 02150 batchs: 859.9690551757812
INFO:root:Train (Epoch 84): Loss/seq after 02200 batchs: 854.1311645507812
INFO:root:Train (Epoch 84): Loss/seq after 02250 batchs: 854.4735107421875
INFO:root:Train (Epoch 84): Loss/seq after 02300 batchs: 860.6256103515625
INFO:root:Train (Epoch 84): Loss/seq after 02350 batchs: 852.76806640625
INFO:root:Train (Epoch 84): Loss/seq after 02400 batchs: 850.7791137695312
INFO:root:Train (Epoch 84): Loss/seq after 02450 batchs: 843.0322875976562
INFO:root:Train (Epoch 84): Loss/seq after 02500 batchs: 829.7951049804688
INFO:root:Train (Epoch 84): Loss/seq after 02550 batchs: 819.9799194335938
INFO:root:Train (Epoch 84): Loss/seq after 02600 batchs: 817.4202270507812
INFO:root:Train (Epoch 84): Loss/seq after 02650 batchs: 813.27001953125
INFO:root:Train (Epoch 84): Loss/seq after 02700 batchs: 810.048095703125
INFO:root:Train (Epoch 84): Loss/seq after 02750 batchs: 833.953125
INFO:root:Train (Epoch 84): Loss/seq after 02800 batchs: 838.6818237304688
INFO:root:Train (Epoch 84): Loss/seq after 02850 batchs: 836.9722290039062
INFO:root:Train (Epoch 84): Loss/seq after 02900 batchs: 837.129150390625
INFO:root:Train (Epoch 84): Loss/seq after 02950 batchs: 833.1716918945312
INFO:root:Train (Epoch 84): Loss/seq after 03000 batchs: 835.5528564453125
INFO:root:Train (Epoch 84): Loss/seq after 03050 batchs: 840.7472534179688
INFO:root:Train (Epoch 84): Loss/seq after 03100 batchs: 846.042236328125
INFO:root:Train (Epoch 84): Loss/seq after 03150 batchs: 850.8859252929688
INFO:root:Train (Epoch 84): Loss/seq after 03200 batchs: 857.34375
INFO:root:Train (Epoch 84): Loss/seq after 03250 batchs: 861.4662475585938
INFO:root:Train (Epoch 84): Loss/seq after 03300 batchs: 859.7504272460938
INFO:root:Train (Epoch 84): Loss/seq after 03350 batchs: 858.2713012695312
INFO:root:Train (Epoch 84): Loss/seq after 03400 batchs: 850.9226684570312
INFO:root:Train (Epoch 84): Loss/seq after 03450 batchs: 846.6283569335938
INFO:root:Train (Epoch 84): Loss/seq after 03500 batchs: 845.5470581054688
INFO:root:Train (Epoch 84): Loss/seq after 03550 batchs: 840.9378662109375
INFO:root:Train (Epoch 84): Loss/seq after 03600 batchs: 848.133544921875
INFO:root:Train (Epoch 84): Loss/seq after 03650 batchs: 843.879150390625
INFO:root:Train (Epoch 84): Loss/seq after 03700 batchs: 843.978271484375
INFO:root:Train (Epoch 84): Loss/seq after 03750 batchs: 847.8130493164062
INFO:root:Train (Epoch 84): Loss/seq after 03800 batchs: 843.2085571289062
INFO:root:Train (Epoch 84): Loss/seq after 03850 batchs: 841.401611328125
INFO:root:Train (Epoch 84): Loss/seq after 03900 batchs: 845.3011474609375
INFO:root:Train (Epoch 84): Loss/seq after 03950 batchs: 849.5278930664062
INFO:root:Train (Epoch 84): Loss/seq after 04000 batchs: 844.3668212890625
INFO:root:Train (Epoch 84): Loss/seq after 04050 batchs: 838.5987548828125
INFO:root:Train (Epoch 84): Loss/seq after 04100 batchs: 834.9291381835938
INFO:root:Train (Epoch 84): Loss/seq after 04150 batchs: 832.6634521484375
INFO:root:Train (Epoch 84): Loss/seq after 04200 batchs: 829.529052734375
INFO:root:Train (Epoch 84): Loss/seq after 04250 batchs: 826.5482177734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 84): Loss/seq after 00000 batches: 570.3600463867188
INFO:root:# Valid (Epoch 84): Loss/seq after 00050 batches: 732.6246948242188
INFO:root:# Valid (Epoch 84): Loss/seq after 00100 batches: 1015.4835205078125
INFO:root:# Valid (Epoch 84): Loss/seq after 00150 batches: 774.8023681640625
INFO:root:# Valid (Epoch 84): Loss/seq after 00200 batches: 723.5051879882812
INFO:root:Artifacts: Make stick videos for epoch 84
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_84_on_20220413_221548.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_84_index_1147_on_20220413_221548.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 85): Loss/seq after 00000 batchs: 1552.360595703125
INFO:root:Train (Epoch 85): Loss/seq after 00050 batchs: 1063.4339599609375
INFO:root:Train (Epoch 85): Loss/seq after 00100 batchs: 1086.673583984375
INFO:root:Train (Epoch 85): Loss/seq after 00150 batchs: 984.8303833007812
INFO:root:Train (Epoch 85): Loss/seq after 00200 batchs: 1096.338623046875
INFO:root:Train (Epoch 85): Loss/seq after 00250 batchs: 1206.8018798828125
INFO:root:Train (Epoch 85): Loss/seq after 00300 batchs: 1173.1676025390625
INFO:root:Train (Epoch 85): Loss/seq after 00350 batchs: 1095.0491943359375
INFO:root:Train (Epoch 85): Loss/seq after 00400 batchs: 1113.0172119140625
INFO:root:Train (Epoch 85): Loss/seq after 00450 batchs: 1079.5068359375
INFO:root:Train (Epoch 85): Loss/seq after 00500 batchs: 1059.8818359375
INFO:root:Train (Epoch 85): Loss/seq after 00550 batchs: 1023.6572265625
INFO:root:Train (Epoch 85): Loss/seq after 00600 batchs: 986.941650390625
INFO:root:Train (Epoch 85): Loss/seq after 00650 batchs: 999.9376831054688
INFO:root:Train (Epoch 85): Loss/seq after 00700 batchs: 979.7532958984375
INFO:root:Train (Epoch 85): Loss/seq after 00750 batchs: 1014.1368408203125
INFO:root:Train (Epoch 85): Loss/seq after 00800 batchs: 1007.9734497070312
INFO:root:Train (Epoch 85): Loss/seq after 00850 batchs: 978.6529541015625
INFO:root:Train (Epoch 85): Loss/seq after 00900 batchs: 962.5287475585938
INFO:root:Train (Epoch 85): Loss/seq after 00950 batchs: 976.0708618164062
INFO:root:Train (Epoch 85): Loss/seq after 01000 batchs: 970.1834106445312
INFO:root:Train (Epoch 85): Loss/seq after 01050 batchs: 951.3597412109375
INFO:root:Train (Epoch 85): Loss/seq after 01100 batchs: 935.9188842773438
INFO:root:Train (Epoch 85): Loss/seq after 01150 batchs: 912.8209228515625
INFO:root:Train (Epoch 85): Loss/seq after 01200 batchs: 912.4442138671875
INFO:root:Train (Epoch 85): Loss/seq after 01250 batchs: 907.91796875
INFO:root:Train (Epoch 85): Loss/seq after 01300 batchs: 901.0088500976562
INFO:root:Train (Epoch 85): Loss/seq after 01350 batchs: 894.204833984375
INFO:root:Train (Epoch 85): Loss/seq after 01400 batchs: 911.9161987304688
INFO:root:Train (Epoch 85): Loss/seq after 01450 batchs: 910.3035888671875
INFO:root:Train (Epoch 85): Loss/seq after 01500 batchs: 911.6775512695312
INFO:root:Train (Epoch 85): Loss/seq after 01550 batchs: 914.9783935546875
INFO:root:Train (Epoch 85): Loss/seq after 01600 batchs: 907.0616455078125
INFO:root:Train (Epoch 85): Loss/seq after 01650 batchs: 900.6879272460938
INFO:root:Train (Epoch 85): Loss/seq after 01700 batchs: 898.0711059570312
INFO:root:Train (Epoch 85): Loss/seq after 01750 batchs: 892.440673828125
INFO:root:Train (Epoch 85): Loss/seq after 01800 batchs: 885.5167236328125
INFO:root:Train (Epoch 85): Loss/seq after 01850 batchs: 877.6928100585938
INFO:root:Train (Epoch 85): Loss/seq after 01900 batchs: 878.8616943359375
INFO:root:Train (Epoch 85): Loss/seq after 01950 batchs: 874.0115356445312
INFO:root:Train (Epoch 85): Loss/seq after 02000 batchs: 870.679931640625
INFO:root:Train (Epoch 85): Loss/seq after 02050 batchs: 867.7828979492188
INFO:root:Train (Epoch 85): Loss/seq after 02100 batchs: 861.4274291992188
INFO:root:Train (Epoch 85): Loss/seq after 02150 batchs: 856.5537109375
INFO:root:Train (Epoch 85): Loss/seq after 02200 batchs: 850.7393188476562
INFO:root:Train (Epoch 85): Loss/seq after 02250 batchs: 851.0255737304688
INFO:root:Train (Epoch 85): Loss/seq after 02300 batchs: 856.8301391601562
INFO:root:Train (Epoch 85): Loss/seq after 02350 batchs: 849.1155395507812
INFO:root:Train (Epoch 85): Loss/seq after 02400 batchs: 847.1156616210938
INFO:root:Train (Epoch 85): Loss/seq after 02450 batchs: 839.3624267578125
INFO:root:Train (Epoch 85): Loss/seq after 02500 batchs: 826.185546875
INFO:root:Train (Epoch 85): Loss/seq after 02550 batchs: 816.4502563476562
INFO:root:Train (Epoch 85): Loss/seq after 02600 batchs: 814.0326538085938
INFO:root:Train (Epoch 85): Loss/seq after 02650 batchs: 810.1143798828125
INFO:root:Train (Epoch 85): Loss/seq after 02700 batchs: 807.1024780273438
INFO:root:Train (Epoch 85): Loss/seq after 02750 batchs: 831.5984497070312
INFO:root:Train (Epoch 85): Loss/seq after 02800 batchs: 834.961181640625
INFO:root:Train (Epoch 85): Loss/seq after 02850 batchs: 833.2535400390625
INFO:root:Train (Epoch 85): Loss/seq after 02900 batchs: 833.3203735351562
INFO:root:Train (Epoch 85): Loss/seq after 02950 batchs: 829.3944702148438
INFO:root:Train (Epoch 85): Loss/seq after 03000 batchs: 831.7650146484375
INFO:root:Train (Epoch 85): Loss/seq after 03050 batchs: 837.0223999023438
INFO:root:Train (Epoch 85): Loss/seq after 03100 batchs: 842.7699584960938
INFO:root:Train (Epoch 85): Loss/seq after 03150 batchs: 848.1470947265625
INFO:root:Train (Epoch 85): Loss/seq after 03200 batchs: 855.2374267578125
INFO:root:Train (Epoch 85): Loss/seq after 03250 batchs: 859.409423828125
INFO:root:Train (Epoch 85): Loss/seq after 03300 batchs: 857.829833984375
INFO:root:Train (Epoch 85): Loss/seq after 03350 batchs: 856.396240234375
INFO:root:Train (Epoch 85): Loss/seq after 03400 batchs: 849.0989379882812
INFO:root:Train (Epoch 85): Loss/seq after 03450 batchs: 844.8510131835938
INFO:root:Train (Epoch 85): Loss/seq after 03500 batchs: 844.0856323242188
INFO:root:Train (Epoch 85): Loss/seq after 03550 batchs: 839.3125
INFO:root:Train (Epoch 85): Loss/seq after 03600 batchs: 846.6980590820312
INFO:root:Train (Epoch 85): Loss/seq after 03650 batchs: 842.4986572265625
INFO:root:Train (Epoch 85): Loss/seq after 03700 batchs: 842.802978515625
INFO:root:Train (Epoch 85): Loss/seq after 03750 batchs: 846.4741821289062
INFO:root:Train (Epoch 85): Loss/seq after 03800 batchs: 841.7567749023438
INFO:root:Train (Epoch 85): Loss/seq after 03850 batchs: 839.9608154296875
INFO:root:Train (Epoch 85): Loss/seq after 03900 batchs: 843.7150268554688
INFO:root:Train (Epoch 85): Loss/seq after 03950 batchs: 847.7476196289062
INFO:root:Train (Epoch 85): Loss/seq after 04000 batchs: 842.5248413085938
INFO:root:Train (Epoch 85): Loss/seq after 04050 batchs: 836.7384033203125
INFO:root:Train (Epoch 85): Loss/seq after 04100 batchs: 833.170654296875
INFO:root:Train (Epoch 85): Loss/seq after 04150 batchs: 831.0143432617188
INFO:root:Train (Epoch 85): Loss/seq after 04200 batchs: 828.1654052734375
INFO:root:Train (Epoch 85): Loss/seq after 04250 batchs: 825.3078002929688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 85): Loss/seq after 00000 batches: 570.9510498046875
INFO:root:# Valid (Epoch 85): Loss/seq after 00050 batches: 741.1704711914062
INFO:root:# Valid (Epoch 85): Loss/seq after 00100 batches: 1013.915771484375
INFO:root:# Valid (Epoch 85): Loss/seq after 00150 batches: 770.9549560546875
INFO:root:# Valid (Epoch 85): Loss/seq after 00200 batches: 716.8401489257812
INFO:root:Artifacts: Make stick videos for epoch 85
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_85_on_20220413_222106.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_85_index_1183_on_20220413_222106.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 86): Loss/seq after 00000 batchs: 1487.5316162109375
INFO:root:Train (Epoch 86): Loss/seq after 00050 batchs: 1055.1680908203125
INFO:root:Train (Epoch 86): Loss/seq after 00100 batchs: 1087.6810302734375
INFO:root:Train (Epoch 86): Loss/seq after 00150 batchs: 992.0663452148438
INFO:root:Train (Epoch 86): Loss/seq after 00200 batchs: 1102.8411865234375
INFO:root:Train (Epoch 86): Loss/seq after 00250 batchs: 1214.4041748046875
INFO:root:Train (Epoch 86): Loss/seq after 00300 batchs: 1177.20166015625
INFO:root:Train (Epoch 86): Loss/seq after 00350 batchs: 1097.61572265625
INFO:root:Train (Epoch 86): Loss/seq after 00400 batchs: 1116.6380615234375
INFO:root:Train (Epoch 86): Loss/seq after 00450 batchs: 1080.786865234375
INFO:root:Train (Epoch 86): Loss/seq after 00500 batchs: 1062.998046875
INFO:root:Train (Epoch 86): Loss/seq after 00550 batchs: 1025.502197265625
INFO:root:Train (Epoch 86): Loss/seq after 00600 batchs: 989.5339965820312
INFO:root:Train (Epoch 86): Loss/seq after 00650 batchs: 1001.0131225585938
INFO:root:Train (Epoch 86): Loss/seq after 00700 batchs: 979.1216430664062
INFO:root:Train (Epoch 86): Loss/seq after 00750 batchs: 1010.50537109375
INFO:root:Train (Epoch 86): Loss/seq after 00800 batchs: 1003.1600341796875
INFO:root:Train (Epoch 86): Loss/seq after 00850 batchs: 972.3615112304688
INFO:root:Train (Epoch 86): Loss/seq after 00900 batchs: 953.2984008789062
INFO:root:Train (Epoch 86): Loss/seq after 00950 batchs: 965.021240234375
INFO:root:Train (Epoch 86): Loss/seq after 01000 batchs: 960.9158935546875
INFO:root:Train (Epoch 86): Loss/seq after 01050 batchs: 943.3068237304688
INFO:root:Train (Epoch 86): Loss/seq after 01100 batchs: 929.4319458007812
INFO:root:Train (Epoch 86): Loss/seq after 01150 batchs: 906.5381469726562
INFO:root:Train (Epoch 86): Loss/seq after 01200 batchs: 906.6133422851562
INFO:root:Train (Epoch 86): Loss/seq after 01250 batchs: 902.4041748046875
INFO:root:Train (Epoch 86): Loss/seq after 01300 batchs: 898.7495727539062
INFO:root:Train (Epoch 86): Loss/seq after 01350 batchs: 892.0127563476562
INFO:root:Train (Epoch 86): Loss/seq after 01400 batchs: 909.0176391601562
INFO:root:Train (Epoch 86): Loss/seq after 01450 batchs: 906.8199462890625
INFO:root:Train (Epoch 86): Loss/seq after 01500 batchs: 908.0977172851562
INFO:root:Train (Epoch 86): Loss/seq after 01550 batchs: 911.211669921875
INFO:root:Train (Epoch 86): Loss/seq after 01600 batchs: 902.6011962890625
INFO:root:Train (Epoch 86): Loss/seq after 01650 batchs: 896.279052734375
INFO:root:Train (Epoch 86): Loss/seq after 01700 batchs: 893.8356323242188
INFO:root:Train (Epoch 86): Loss/seq after 01750 batchs: 888.1958618164062
INFO:root:Train (Epoch 86): Loss/seq after 01800 batchs: 881.3341674804688
INFO:root:Train (Epoch 86): Loss/seq after 01850 batchs: 873.5286254882812
INFO:root:Train (Epoch 86): Loss/seq after 01900 batchs: 874.4254150390625
INFO:root:Train (Epoch 86): Loss/seq after 01950 batchs: 869.81396484375
INFO:root:Train (Epoch 86): Loss/seq after 02000 batchs: 866.5656127929688
INFO:root:Train (Epoch 86): Loss/seq after 02050 batchs: 863.5103759765625
INFO:root:Train (Epoch 86): Loss/seq after 02100 batchs: 857.5582885742188
INFO:root:Train (Epoch 86): Loss/seq after 02150 batchs: 853.0394897460938
INFO:root:Train (Epoch 86): Loss/seq after 02200 batchs: 847.2322998046875
INFO:root:Train (Epoch 86): Loss/seq after 02250 batchs: 849.8685913085938
INFO:root:Train (Epoch 86): Loss/seq after 02300 batchs: 856.4871215820312
INFO:root:Train (Epoch 86): Loss/seq after 02350 batchs: 849.2360229492188
INFO:root:Train (Epoch 86): Loss/seq after 02400 batchs: 847.4714965820312
INFO:root:Train (Epoch 86): Loss/seq after 02450 batchs: 839.7447509765625
INFO:root:Train (Epoch 86): Loss/seq after 02500 batchs: 826.5512084960938
INFO:root:Train (Epoch 86): Loss/seq after 02550 batchs: 817.1438598632812
INFO:root:Train (Epoch 86): Loss/seq after 02600 batchs: 814.67138671875
INFO:root:Train (Epoch 86): Loss/seq after 02650 batchs: 810.6261596679688
INFO:root:Train (Epoch 86): Loss/seq after 02700 batchs: 807.4953002929688
INFO:root:Train (Epoch 86): Loss/seq after 02750 batchs: 833.1356811523438
INFO:root:Train (Epoch 86): Loss/seq after 02800 batchs: 837.3234252929688
INFO:root:Train (Epoch 86): Loss/seq after 02850 batchs: 835.685546875
INFO:root:Train (Epoch 86): Loss/seq after 02900 batchs: 836.4879150390625
INFO:root:Train (Epoch 86): Loss/seq after 02950 batchs: 832.423095703125
INFO:root:Train (Epoch 86): Loss/seq after 03000 batchs: 834.788330078125
INFO:root:Train (Epoch 86): Loss/seq after 03050 batchs: 839.852783203125
INFO:root:Train (Epoch 86): Loss/seq after 03100 batchs: 845.2058715820312
INFO:root:Train (Epoch 86): Loss/seq after 03150 batchs: 851.1898193359375
INFO:root:Train (Epoch 86): Loss/seq after 03200 batchs: 857.7454223632812
INFO:root:Train (Epoch 86): Loss/seq after 03250 batchs: 861.852783203125
INFO:root:Train (Epoch 86): Loss/seq after 03300 batchs: 860.7743530273438
INFO:root:Train (Epoch 86): Loss/seq after 03350 batchs: 859.90625
INFO:root:Train (Epoch 86): Loss/seq after 03400 batchs: 852.4992065429688
INFO:root:Train (Epoch 86): Loss/seq after 03450 batchs: 848.635498046875
INFO:root:Train (Epoch 86): Loss/seq after 03500 batchs: 848.0171508789062
INFO:root:Train (Epoch 86): Loss/seq after 03550 batchs: 843.562255859375
INFO:root:Train (Epoch 86): Loss/seq after 03600 batchs: 850.5950317382812
INFO:root:Train (Epoch 86): Loss/seq after 03650 batchs: 846.0307006835938
INFO:root:Train (Epoch 86): Loss/seq after 03700 batchs: 846.0643920898438
INFO:root:Train (Epoch 86): Loss/seq after 03750 batchs: 849.8643798828125
INFO:root:Train (Epoch 86): Loss/seq after 03800 batchs: 845.0389404296875
INFO:root:Train (Epoch 86): Loss/seq after 03850 batchs: 843.1728515625
INFO:root:Train (Epoch 86): Loss/seq after 03900 batchs: 847.2317504882812
INFO:root:Train (Epoch 86): Loss/seq after 03950 batchs: 851.3724365234375
INFO:root:Train (Epoch 86): Loss/seq after 04000 batchs: 846.063232421875
INFO:root:Train (Epoch 86): Loss/seq after 04050 batchs: 840.224365234375
INFO:root:Train (Epoch 86): Loss/seq after 04100 batchs: 836.6921997070312
INFO:root:Train (Epoch 86): Loss/seq after 04150 batchs: 834.6685791015625
INFO:root:Train (Epoch 86): Loss/seq after 04200 batchs: 831.6856689453125
INFO:root:Train (Epoch 86): Loss/seq after 04250 batchs: 828.6849365234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 86): Loss/seq after 00000 batches: 571.2992553710938
INFO:root:# Valid (Epoch 86): Loss/seq after 00050 batches: 748.550048828125
INFO:root:# Valid (Epoch 86): Loss/seq after 00100 batches: 1020.1817626953125
INFO:root:# Valid (Epoch 86): Loss/seq after 00150 batches: 775.4481811523438
INFO:root:# Valid (Epoch 86): Loss/seq after 00200 batches: 721.406982421875
INFO:root:Artifacts: Make stick videos for epoch 86
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_86_on_20220413_222625.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_86_index_38_on_20220413_222625.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 87): Loss/seq after 00000 batchs: 1361.9566650390625
INFO:root:Train (Epoch 87): Loss/seq after 00050 batchs: 1072.47314453125
INFO:root:Train (Epoch 87): Loss/seq after 00100 batchs: 1092.6864013671875
INFO:root:Train (Epoch 87): Loss/seq after 00150 batchs: 991.1273803710938
INFO:root:Train (Epoch 87): Loss/seq after 00200 batchs: 1107.580078125
INFO:root:Train (Epoch 87): Loss/seq after 00250 batchs: 1220.749755859375
INFO:root:Train (Epoch 87): Loss/seq after 00300 batchs: 1183.491943359375
INFO:root:Train (Epoch 87): Loss/seq after 00350 batchs: 1101.9000244140625
INFO:root:Train (Epoch 87): Loss/seq after 00400 batchs: 1117.3868408203125
INFO:root:Train (Epoch 87): Loss/seq after 00450 batchs: 1081.16748046875
INFO:root:Train (Epoch 87): Loss/seq after 00500 batchs: 1061.7181396484375
INFO:root:Train (Epoch 87): Loss/seq after 00550 batchs: 1024.0487060546875
INFO:root:Train (Epoch 87): Loss/seq after 00600 batchs: 987.833984375
INFO:root:Train (Epoch 87): Loss/seq after 00650 batchs: 999.315185546875
INFO:root:Train (Epoch 87): Loss/seq after 00700 batchs: 978.6404418945312
INFO:root:Train (Epoch 87): Loss/seq after 00750 batchs: 1011.6031494140625
INFO:root:Train (Epoch 87): Loss/seq after 00800 batchs: 1003.50830078125
INFO:root:Train (Epoch 87): Loss/seq after 00850 batchs: 972.7359008789062
INFO:root:Train (Epoch 87): Loss/seq after 00900 batchs: 953.2957153320312
INFO:root:Train (Epoch 87): Loss/seq after 00950 batchs: 964.8595581054688
INFO:root:Train (Epoch 87): Loss/seq after 01000 batchs: 959.3501586914062
INFO:root:Train (Epoch 87): Loss/seq after 01050 batchs: 940.2551879882812
INFO:root:Train (Epoch 87): Loss/seq after 01100 batchs: 924.6427001953125
INFO:root:Train (Epoch 87): Loss/seq after 01150 batchs: 901.459228515625
INFO:root:Train (Epoch 87): Loss/seq after 01200 batchs: 901.633544921875
INFO:root:Train (Epoch 87): Loss/seq after 01250 batchs: 898.306640625
INFO:root:Train (Epoch 87): Loss/seq after 01300 batchs: 892.2879638671875
INFO:root:Train (Epoch 87): Loss/seq after 01350 batchs: 885.4737548828125
INFO:root:Train (Epoch 87): Loss/seq after 01400 batchs: 900.502197265625
INFO:root:Train (Epoch 87): Loss/seq after 01450 batchs: 899.0498657226562
INFO:root:Train (Epoch 87): Loss/seq after 01500 batchs: 900.2510986328125
INFO:root:Train (Epoch 87): Loss/seq after 01550 batchs: 903.73583984375
INFO:root:Train (Epoch 87): Loss/seq after 01600 batchs: 895.2974243164062
INFO:root:Train (Epoch 87): Loss/seq after 01650 batchs: 889.0292358398438
INFO:root:Train (Epoch 87): Loss/seq after 01700 batchs: 886.3207397460938
INFO:root:Train (Epoch 87): Loss/seq after 01750 batchs: 880.6459350585938
INFO:root:Train (Epoch 87): Loss/seq after 01800 batchs: 873.9061279296875
INFO:root:Train (Epoch 87): Loss/seq after 01850 batchs: 866.2803344726562
INFO:root:Train (Epoch 87): Loss/seq after 01900 batchs: 867.3262939453125
INFO:root:Train (Epoch 87): Loss/seq after 01950 batchs: 862.4661865234375
INFO:root:Train (Epoch 87): Loss/seq after 02000 batchs: 858.9939575195312
INFO:root:Train (Epoch 87): Loss/seq after 02050 batchs: 856.0181884765625
INFO:root:Train (Epoch 87): Loss/seq after 02100 batchs: 850.0303344726562
INFO:root:Train (Epoch 87): Loss/seq after 02150 batchs: 845.5928344726562
INFO:root:Train (Epoch 87): Loss/seq after 02200 batchs: 839.9349975585938
INFO:root:Train (Epoch 87): Loss/seq after 02250 batchs: 840.2901000976562
INFO:root:Train (Epoch 87): Loss/seq after 02300 batchs: 846.8695068359375
INFO:root:Train (Epoch 87): Loss/seq after 02350 batchs: 839.0670776367188
INFO:root:Train (Epoch 87): Loss/seq after 02400 batchs: 837.2144165039062
INFO:root:Train (Epoch 87): Loss/seq after 02450 batchs: 829.3784790039062
INFO:root:Train (Epoch 87): Loss/seq after 02500 batchs: 816.3624267578125
INFO:root:Train (Epoch 87): Loss/seq after 02550 batchs: 806.9435424804688
INFO:root:Train (Epoch 87): Loss/seq after 02600 batchs: 804.4804077148438
INFO:root:Train (Epoch 87): Loss/seq after 02650 batchs: 800.6807861328125
INFO:root:Train (Epoch 87): Loss/seq after 02700 batchs: 797.4320068359375
INFO:root:Train (Epoch 87): Loss/seq after 02750 batchs: 822.0592041015625
INFO:root:Train (Epoch 87): Loss/seq after 02800 batchs: 826.1884765625
INFO:root:Train (Epoch 87): Loss/seq after 02850 batchs: 824.665283203125
INFO:root:Train (Epoch 87): Loss/seq after 02900 batchs: 824.895263671875
INFO:root:Train (Epoch 87): Loss/seq after 02950 batchs: 821.0918579101562
INFO:root:Train (Epoch 87): Loss/seq after 03000 batchs: 823.6165771484375
INFO:root:Train (Epoch 87): Loss/seq after 03050 batchs: 828.7591552734375
INFO:root:Train (Epoch 87): Loss/seq after 03100 batchs: 833.7329711914062
INFO:root:Train (Epoch 87): Loss/seq after 03150 batchs: 839.118896484375
INFO:root:Train (Epoch 87): Loss/seq after 03200 batchs: 845.3912353515625
INFO:root:Train (Epoch 87): Loss/seq after 03250 batchs: 849.7210083007812
INFO:root:Train (Epoch 87): Loss/seq after 03300 batchs: 848.1004638671875
INFO:root:Train (Epoch 87): Loss/seq after 03350 batchs: 846.5520629882812
INFO:root:Train (Epoch 87): Loss/seq after 03400 batchs: 839.314453125
INFO:root:Train (Epoch 87): Loss/seq after 03450 batchs: 835.1314086914062
INFO:root:Train (Epoch 87): Loss/seq after 03500 batchs: 834.0079345703125
INFO:root:Train (Epoch 87): Loss/seq after 03550 batchs: 829.1453247070312
INFO:root:Train (Epoch 87): Loss/seq after 03600 batchs: 836.252685546875
INFO:root:Train (Epoch 87): Loss/seq after 03650 batchs: 831.72705078125
INFO:root:Train (Epoch 87): Loss/seq after 03700 batchs: 831.9093017578125
INFO:root:Train (Epoch 87): Loss/seq after 03750 batchs: 835.69189453125
INFO:root:Train (Epoch 87): Loss/seq after 03800 batchs: 831.095703125
INFO:root:Train (Epoch 87): Loss/seq after 03850 batchs: 829.3209838867188
INFO:root:Train (Epoch 87): Loss/seq after 03900 batchs: 833.1163940429688
INFO:root:Train (Epoch 87): Loss/seq after 03950 batchs: 837.2026977539062
INFO:root:Train (Epoch 87): Loss/seq after 04000 batchs: 831.892578125
INFO:root:Train (Epoch 87): Loss/seq after 04050 batchs: 826.1614990234375
INFO:root:Train (Epoch 87): Loss/seq after 04100 batchs: 822.6030883789062
INFO:root:Train (Epoch 87): Loss/seq after 04150 batchs: 820.6276245117188
INFO:root:Train (Epoch 87): Loss/seq after 04200 batchs: 817.68603515625
INFO:root:Train (Epoch 87): Loss/seq after 04250 batchs: 814.873046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 87): Loss/seq after 00000 batches: 594.1903686523438
INFO:root:# Valid (Epoch 87): Loss/seq after 00050 batches: 750.50439453125
INFO:root:# Valid (Epoch 87): Loss/seq after 00100 batches: 1010.5790405273438
INFO:root:# Valid (Epoch 87): Loss/seq after 00150 batches: 770.0692138671875
INFO:root:# Valid (Epoch 87): Loss/seq after 00200 batches: 717.315185546875
INFO:root:Artifacts: Make stick videos for epoch 87
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_87_on_20220413_223144.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_87_index_569_on_20220413_223144.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 88): Loss/seq after 00000 batchs: 1346.7015380859375
INFO:root:Train (Epoch 88): Loss/seq after 00050 batchs: 1057.468994140625
INFO:root:Train (Epoch 88): Loss/seq after 00100 batchs: 1088.3197021484375
INFO:root:Train (Epoch 88): Loss/seq after 00150 batchs: 986.9199829101562
INFO:root:Train (Epoch 88): Loss/seq after 00200 batchs: 1104.6298828125
INFO:root:Train (Epoch 88): Loss/seq after 00250 batchs: 1222.273681640625
INFO:root:Train (Epoch 88): Loss/seq after 00300 batchs: 1183.54833984375
INFO:root:Train (Epoch 88): Loss/seq after 00350 batchs: 1101.018798828125
INFO:root:Train (Epoch 88): Loss/seq after 00400 batchs: 1120.1834716796875
INFO:root:Train (Epoch 88): Loss/seq after 00450 batchs: 1082.83349609375
INFO:root:Train (Epoch 88): Loss/seq after 00500 batchs: 1065.630126953125
INFO:root:Train (Epoch 88): Loss/seq after 00550 batchs: 1027.1513671875
INFO:root:Train (Epoch 88): Loss/seq after 00600 batchs: 989.9739990234375
INFO:root:Train (Epoch 88): Loss/seq after 00650 batchs: 1002.9892578125
INFO:root:Train (Epoch 88): Loss/seq after 00700 batchs: 981.2642822265625
INFO:root:Train (Epoch 88): Loss/seq after 00750 batchs: 1011.4474487304688
INFO:root:Train (Epoch 88): Loss/seq after 00800 batchs: 1002.01416015625
INFO:root:Train (Epoch 88): Loss/seq after 00850 batchs: 971.2005615234375
INFO:root:Train (Epoch 88): Loss/seq after 00900 batchs: 951.8425903320312
INFO:root:Train (Epoch 88): Loss/seq after 00950 batchs: 963.3988037109375
INFO:root:Train (Epoch 88): Loss/seq after 01000 batchs: 959.1641235351562
INFO:root:Train (Epoch 88): Loss/seq after 01050 batchs: 938.9287719726562
INFO:root:Train (Epoch 88): Loss/seq after 01100 batchs: 922.2914428710938
INFO:root:Train (Epoch 88): Loss/seq after 01150 batchs: 898.8521118164062
INFO:root:Train (Epoch 88): Loss/seq after 01200 batchs: 898.2616577148438
INFO:root:Train (Epoch 88): Loss/seq after 01250 batchs: 894.1221313476562
INFO:root:Train (Epoch 88): Loss/seq after 01300 batchs: 887.2402954101562
INFO:root:Train (Epoch 88): Loss/seq after 01350 batchs: 880.5818481445312
INFO:root:Train (Epoch 88): Loss/seq after 01400 batchs: 896.3458862304688
INFO:root:Train (Epoch 88): Loss/seq after 01450 batchs: 895.3920288085938
INFO:root:Train (Epoch 88): Loss/seq after 01500 batchs: 897.114013671875
INFO:root:Train (Epoch 88): Loss/seq after 01550 batchs: 900.32373046875
INFO:root:Train (Epoch 88): Loss/seq after 01600 batchs: 891.9227905273438
INFO:root:Train (Epoch 88): Loss/seq after 01650 batchs: 885.5101928710938
INFO:root:Train (Epoch 88): Loss/seq after 01700 batchs: 882.7938232421875
INFO:root:Train (Epoch 88): Loss/seq after 01750 batchs: 877.12548828125
INFO:root:Train (Epoch 88): Loss/seq after 01800 batchs: 870.3818969726562
INFO:root:Train (Epoch 88): Loss/seq after 01850 batchs: 862.7230834960938
INFO:root:Train (Epoch 88): Loss/seq after 01900 batchs: 863.366943359375
INFO:root:Train (Epoch 88): Loss/seq after 01950 batchs: 858.8814086914062
INFO:root:Train (Epoch 88): Loss/seq after 02000 batchs: 855.68701171875
INFO:root:Train (Epoch 88): Loss/seq after 02050 batchs: 853.139892578125
INFO:root:Train (Epoch 88): Loss/seq after 02100 batchs: 847.0712280273438
INFO:root:Train (Epoch 88): Loss/seq after 02150 batchs: 842.5010986328125
INFO:root:Train (Epoch 88): Loss/seq after 02200 batchs: 836.7896118164062
INFO:root:Train (Epoch 88): Loss/seq after 02250 batchs: 838.7879028320312
INFO:root:Train (Epoch 88): Loss/seq after 02300 batchs: 844.4827880859375
INFO:root:Train (Epoch 88): Loss/seq after 02350 batchs: 837.278564453125
INFO:root:Train (Epoch 88): Loss/seq after 02400 batchs: 835.5859375
INFO:root:Train (Epoch 88): Loss/seq after 02450 batchs: 827.7789306640625
INFO:root:Train (Epoch 88): Loss/seq after 02500 batchs: 814.8203735351562
INFO:root:Train (Epoch 88): Loss/seq after 02550 batchs: 805.3333129882812
INFO:root:Train (Epoch 88): Loss/seq after 02600 batchs: 803.0249633789062
INFO:root:Train (Epoch 88): Loss/seq after 02650 batchs: 799.2105102539062
INFO:root:Train (Epoch 88): Loss/seq after 02700 batchs: 795.9100341796875
INFO:root:Train (Epoch 88): Loss/seq after 02750 batchs: 819.7237548828125
INFO:root:Train (Epoch 88): Loss/seq after 02800 batchs: 823.4077758789062
INFO:root:Train (Epoch 88): Loss/seq after 02850 batchs: 821.940673828125
INFO:root:Train (Epoch 88): Loss/seq after 02900 batchs: 822.7572631835938
INFO:root:Train (Epoch 88): Loss/seq after 02950 batchs: 818.9898071289062
INFO:root:Train (Epoch 88): Loss/seq after 03000 batchs: 821.3745727539062
INFO:root:Train (Epoch 88): Loss/seq after 03050 batchs: 826.2705078125
INFO:root:Train (Epoch 88): Loss/seq after 03100 batchs: 831.3749389648438
INFO:root:Train (Epoch 88): Loss/seq after 03150 batchs: 836.64599609375
INFO:root:Train (Epoch 88): Loss/seq after 03200 batchs: 843.6940307617188
INFO:root:Train (Epoch 88): Loss/seq after 03250 batchs: 848.2225952148438
INFO:root:Train (Epoch 88): Loss/seq after 03300 batchs: 846.4976806640625
INFO:root:Train (Epoch 88): Loss/seq after 03350 batchs: 844.6841430664062
INFO:root:Train (Epoch 88): Loss/seq after 03400 batchs: 837.3147583007812
INFO:root:Train (Epoch 88): Loss/seq after 03450 batchs: 833.1355590820312
INFO:root:Train (Epoch 88): Loss/seq after 03500 batchs: 832.1217041015625
INFO:root:Train (Epoch 88): Loss/seq after 03550 batchs: 827.495361328125
INFO:root:Train (Epoch 88): Loss/seq after 03600 batchs: 834.781005859375
INFO:root:Train (Epoch 88): Loss/seq after 03650 batchs: 830.5494995117188
INFO:root:Train (Epoch 88): Loss/seq after 03700 batchs: 830.889404296875
INFO:root:Train (Epoch 88): Loss/seq after 03750 batchs: 834.463134765625
INFO:root:Train (Epoch 88): Loss/seq after 03800 batchs: 829.730712890625
INFO:root:Train (Epoch 88): Loss/seq after 03850 batchs: 828.0180053710938
INFO:root:Train (Epoch 88): Loss/seq after 03900 batchs: 832.1470336914062
INFO:root:Train (Epoch 88): Loss/seq after 03950 batchs: 836.1902465820312
INFO:root:Train (Epoch 88): Loss/seq after 04000 batchs: 830.8811645507812
INFO:root:Train (Epoch 88): Loss/seq after 04050 batchs: 825.0988159179688
INFO:root:Train (Epoch 88): Loss/seq after 04100 batchs: 821.7072143554688
INFO:root:Train (Epoch 88): Loss/seq after 04150 batchs: 819.7993774414062
INFO:root:Train (Epoch 88): Loss/seq after 04200 batchs: 816.9767456054688
INFO:root:Train (Epoch 88): Loss/seq after 04250 batchs: 814.223388671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 88): Loss/seq after 00000 batches: 572.155517578125
INFO:root:# Valid (Epoch 88): Loss/seq after 00050 batches: 731.6101684570312
INFO:root:# Valid (Epoch 88): Loss/seq after 00100 batches: 1005.6561279296875
INFO:root:# Valid (Epoch 88): Loss/seq after 00150 batches: 766.6251831054688
INFO:root:# Valid (Epoch 88): Loss/seq after 00200 batches: 715.1766967773438
INFO:root:Artifacts: Make stick videos for epoch 88
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_88_on_20220413_223702.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_88_index_658_on_20220413_223702.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 89): Loss/seq after 00000 batchs: 1448.7469482421875
INFO:root:Train (Epoch 89): Loss/seq after 00050 batchs: 1045.209228515625
INFO:root:Train (Epoch 89): Loss/seq after 00100 batchs: 1063.529296875
INFO:root:Train (Epoch 89): Loss/seq after 00150 batchs: 968.9892578125
INFO:root:Train (Epoch 89): Loss/seq after 00200 batchs: 1081.8824462890625
INFO:root:Train (Epoch 89): Loss/seq after 00250 batchs: 1200.0968017578125
INFO:root:Train (Epoch 89): Loss/seq after 00300 batchs: 1164.7418212890625
INFO:root:Train (Epoch 89): Loss/seq after 00350 batchs: 1084.6435546875
INFO:root:Train (Epoch 89): Loss/seq after 00400 batchs: 1100.8330078125
INFO:root:Train (Epoch 89): Loss/seq after 00450 batchs: 1065.6656494140625
INFO:root:Train (Epoch 89): Loss/seq after 00500 batchs: 1048.540283203125
INFO:root:Train (Epoch 89): Loss/seq after 00550 batchs: 1012.4949951171875
INFO:root:Train (Epoch 89): Loss/seq after 00600 batchs: 976.789794921875
INFO:root:Train (Epoch 89): Loss/seq after 00650 batchs: 989.7158203125
INFO:root:Train (Epoch 89): Loss/seq after 00700 batchs: 968.6744995117188
INFO:root:Train (Epoch 89): Loss/seq after 00750 batchs: 1001.29345703125
INFO:root:Train (Epoch 89): Loss/seq after 00800 batchs: 992.0895385742188
INFO:root:Train (Epoch 89): Loss/seq after 00850 batchs: 961.8042602539062
INFO:root:Train (Epoch 89): Loss/seq after 00900 batchs: 942.301513671875
INFO:root:Train (Epoch 89): Loss/seq after 00950 batchs: 953.4732666015625
INFO:root:Train (Epoch 89): Loss/seq after 01000 batchs: 948.9119873046875
INFO:root:Train (Epoch 89): Loss/seq after 01050 batchs: 929.5090942382812
INFO:root:Train (Epoch 89): Loss/seq after 01100 batchs: 913.2927856445312
INFO:root:Train (Epoch 89): Loss/seq after 01150 batchs: 890.2440795898438
INFO:root:Train (Epoch 89): Loss/seq after 01200 batchs: 889.90185546875
INFO:root:Train (Epoch 89): Loss/seq after 01250 batchs: 885.1182861328125
INFO:root:Train (Epoch 89): Loss/seq after 01300 batchs: 876.7977294921875
INFO:root:Train (Epoch 89): Loss/seq after 01350 batchs: 870.6200561523438
INFO:root:Train (Epoch 89): Loss/seq after 01400 batchs: 888.618408203125
INFO:root:Train (Epoch 89): Loss/seq after 01450 batchs: 886.9808959960938
INFO:root:Train (Epoch 89): Loss/seq after 01500 batchs: 888.4302368164062
INFO:root:Train (Epoch 89): Loss/seq after 01550 batchs: 892.2420654296875
INFO:root:Train (Epoch 89): Loss/seq after 01600 batchs: 883.8973388671875
INFO:root:Train (Epoch 89): Loss/seq after 01650 batchs: 877.875732421875
INFO:root:Train (Epoch 89): Loss/seq after 01700 batchs: 875.1505737304688
INFO:root:Train (Epoch 89): Loss/seq after 01750 batchs: 869.4708862304688
INFO:root:Train (Epoch 89): Loss/seq after 01800 batchs: 862.9030151367188
INFO:root:Train (Epoch 89): Loss/seq after 01850 batchs: 855.585693359375
INFO:root:Train (Epoch 89): Loss/seq after 01900 batchs: 856.823974609375
INFO:root:Train (Epoch 89): Loss/seq after 01950 batchs: 852.1092529296875
INFO:root:Train (Epoch 89): Loss/seq after 02000 batchs: 848.6913452148438
INFO:root:Train (Epoch 89): Loss/seq after 02050 batchs: 846.13916015625
INFO:root:Train (Epoch 89): Loss/seq after 02100 batchs: 840.081787109375
INFO:root:Train (Epoch 89): Loss/seq after 02150 batchs: 835.5258178710938
INFO:root:Train (Epoch 89): Loss/seq after 02200 batchs: 829.9852905273438
INFO:root:Train (Epoch 89): Loss/seq after 02250 batchs: 830.216064453125
INFO:root:Train (Epoch 89): Loss/seq after 02300 batchs: 836.295654296875
INFO:root:Train (Epoch 89): Loss/seq after 02350 batchs: 828.6277465820312
INFO:root:Train (Epoch 89): Loss/seq after 02400 batchs: 826.8170166015625
INFO:root:Train (Epoch 89): Loss/seq after 02450 batchs: 819.0992431640625
INFO:root:Train (Epoch 89): Loss/seq after 02500 batchs: 806.2659301757812
INFO:root:Train (Epoch 89): Loss/seq after 02550 batchs: 796.9578247070312
INFO:root:Train (Epoch 89): Loss/seq after 02600 batchs: 794.6661376953125
INFO:root:Train (Epoch 89): Loss/seq after 02650 batchs: 790.8326416015625
INFO:root:Train (Epoch 89): Loss/seq after 02700 batchs: 787.4960327148438
INFO:root:Train (Epoch 89): Loss/seq after 02750 batchs: 811.1837158203125
INFO:root:Train (Epoch 89): Loss/seq after 02800 batchs: 814.75927734375
INFO:root:Train (Epoch 89): Loss/seq after 02850 batchs: 813.5331420898438
INFO:root:Train (Epoch 89): Loss/seq after 02900 batchs: 813.9653930664062
INFO:root:Train (Epoch 89): Loss/seq after 02950 batchs: 810.2085571289062
INFO:root:Train (Epoch 89): Loss/seq after 03000 batchs: 812.6824340820312
INFO:root:Train (Epoch 89): Loss/seq after 03050 batchs: 817.806396484375
INFO:root:Train (Epoch 89): Loss/seq after 03100 batchs: 824.308349609375
INFO:root:Train (Epoch 89): Loss/seq after 03150 batchs: 829.7664184570312
INFO:root:Train (Epoch 89): Loss/seq after 03200 batchs: 836.5382690429688
INFO:root:Train (Epoch 89): Loss/seq after 03250 batchs: 841.1470947265625
INFO:root:Train (Epoch 89): Loss/seq after 03300 batchs: 839.910888671875
INFO:root:Train (Epoch 89): Loss/seq after 03350 batchs: 838.35205078125
INFO:root:Train (Epoch 89): Loss/seq after 03400 batchs: 831.1221923828125
INFO:root:Train (Epoch 89): Loss/seq after 03450 batchs: 827.02734375
INFO:root:Train (Epoch 89): Loss/seq after 03500 batchs: 825.8280029296875
INFO:root:Train (Epoch 89): Loss/seq after 03550 batchs: 821.0892944335938
INFO:root:Train (Epoch 89): Loss/seq after 03600 batchs: 828.2035522460938
INFO:root:Train (Epoch 89): Loss/seq after 03650 batchs: 823.6834716796875
INFO:root:Train (Epoch 89): Loss/seq after 03700 batchs: 824.0125122070312
INFO:root:Train (Epoch 89): Loss/seq after 03750 batchs: 827.7277221679688
INFO:root:Train (Epoch 89): Loss/seq after 03800 batchs: 823.03173828125
INFO:root:Train (Epoch 89): Loss/seq after 03850 batchs: 821.1954956054688
INFO:root:Train (Epoch 89): Loss/seq after 03900 batchs: 825.0687866210938
INFO:root:Train (Epoch 89): Loss/seq after 03950 batchs: 829.4459838867188
INFO:root:Train (Epoch 89): Loss/seq after 04000 batchs: 823.9951171875
INFO:root:Train (Epoch 89): Loss/seq after 04050 batchs: 818.2408447265625
INFO:root:Train (Epoch 89): Loss/seq after 04100 batchs: 814.7083129882812
INFO:root:Train (Epoch 89): Loss/seq after 04150 batchs: 812.735595703125
INFO:root:Train (Epoch 89): Loss/seq after 04200 batchs: 809.8846435546875
INFO:root:Train (Epoch 89): Loss/seq after 04250 batchs: 807.2024536132812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 89): Loss/seq after 00000 batches: 555.2218017578125
INFO:root:# Valid (Epoch 89): Loss/seq after 00050 batches: 734.3575439453125
INFO:root:# Valid (Epoch 89): Loss/seq after 00100 batches: 1013.0492553710938
INFO:root:# Valid (Epoch 89): Loss/seq after 00150 batches: 774.7991943359375
INFO:root:# Valid (Epoch 89): Loss/seq after 00200 batches: 724.0193481445312
INFO:root:Artifacts: Make stick videos for epoch 89
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_89_on_20220413_224220.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_89_index_738_on_20220413_224220.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 90): Loss/seq after 00000 batchs: 1429.2001953125
INFO:root:Train (Epoch 90): Loss/seq after 00050 batchs: 1051.6016845703125
INFO:root:Train (Epoch 90): Loss/seq after 00100 batchs: 1074.8826904296875
INFO:root:Train (Epoch 90): Loss/seq after 00150 batchs: 981.4220581054688
INFO:root:Train (Epoch 90): Loss/seq after 00200 batchs: 1103.60595703125
INFO:root:Train (Epoch 90): Loss/seq after 00250 batchs: 1215.315185546875
INFO:root:Train (Epoch 90): Loss/seq after 00300 batchs: 1176.9852294921875
INFO:root:Train (Epoch 90): Loss/seq after 00350 batchs: 1094.5093994140625
INFO:root:Train (Epoch 90): Loss/seq after 00400 batchs: 1113.5230712890625
INFO:root:Train (Epoch 90): Loss/seq after 00450 batchs: 1076.2364501953125
INFO:root:Train (Epoch 90): Loss/seq after 00500 batchs: 1056.9188232421875
INFO:root:Train (Epoch 90): Loss/seq after 00550 batchs: 1019.4124145507812
INFO:root:Train (Epoch 90): Loss/seq after 00600 batchs: 982.0486450195312
INFO:root:Train (Epoch 90): Loss/seq after 00650 batchs: 995.8892211914062
INFO:root:Train (Epoch 90): Loss/seq after 00700 batchs: 974.8822631835938
INFO:root:Train (Epoch 90): Loss/seq after 00750 batchs: 1005.1344604492188
INFO:root:Train (Epoch 90): Loss/seq after 00800 batchs: 996.3643188476562
INFO:root:Train (Epoch 90): Loss/seq after 00850 batchs: 965.2755126953125
INFO:root:Train (Epoch 90): Loss/seq after 00900 batchs: 945.16650390625
INFO:root:Train (Epoch 90): Loss/seq after 00950 batchs: 958.3900146484375
INFO:root:Train (Epoch 90): Loss/seq after 01000 batchs: 952.06005859375
INFO:root:Train (Epoch 90): Loss/seq after 01050 batchs: 932.2119750976562
INFO:root:Train (Epoch 90): Loss/seq after 01100 batchs: 916.0769653320312
INFO:root:Train (Epoch 90): Loss/seq after 01150 batchs: 892.7422485351562
INFO:root:Train (Epoch 90): Loss/seq after 01200 batchs: 892.6973266601562
INFO:root:Train (Epoch 90): Loss/seq after 01250 batchs: 888.55224609375
INFO:root:Train (Epoch 90): Loss/seq after 01300 batchs: 880.6646728515625
INFO:root:Train (Epoch 90): Loss/seq after 01350 batchs: 873.23388671875
INFO:root:Train (Epoch 90): Loss/seq after 01400 batchs: 891.66650390625
INFO:root:Train (Epoch 90): Loss/seq after 01450 batchs: 890.2954711914062
INFO:root:Train (Epoch 90): Loss/seq after 01500 batchs: 891.4820556640625
INFO:root:Train (Epoch 90): Loss/seq after 01550 batchs: 894.46484375
INFO:root:Train (Epoch 90): Loss/seq after 01600 batchs: 885.8460693359375
INFO:root:Train (Epoch 90): Loss/seq after 01650 batchs: 879.7105102539062
INFO:root:Train (Epoch 90): Loss/seq after 01700 batchs: 876.82080078125
INFO:root:Train (Epoch 90): Loss/seq after 01750 batchs: 870.7530517578125
INFO:root:Train (Epoch 90): Loss/seq after 01800 batchs: 864.1114501953125
INFO:root:Train (Epoch 90): Loss/seq after 01850 batchs: 856.7435302734375
INFO:root:Train (Epoch 90): Loss/seq after 01900 batchs: 857.4364013671875
INFO:root:Train (Epoch 90): Loss/seq after 01950 batchs: 852.5947265625
INFO:root:Train (Epoch 90): Loss/seq after 02000 batchs: 848.7109375
INFO:root:Train (Epoch 90): Loss/seq after 02050 batchs: 845.3326416015625
INFO:root:Train (Epoch 90): Loss/seq after 02100 batchs: 839.3134155273438
INFO:root:Train (Epoch 90): Loss/seq after 02150 batchs: 834.760986328125
INFO:root:Train (Epoch 90): Loss/seq after 02200 batchs: 829.2205200195312
INFO:root:Train (Epoch 90): Loss/seq after 02250 batchs: 829.9112548828125
INFO:root:Train (Epoch 90): Loss/seq after 02300 batchs: 836.1478881835938
INFO:root:Train (Epoch 90): Loss/seq after 02350 batchs: 828.4693603515625
INFO:root:Train (Epoch 90): Loss/seq after 02400 batchs: 826.6724853515625
INFO:root:Train (Epoch 90): Loss/seq after 02450 batchs: 818.9108276367188
INFO:root:Train (Epoch 90): Loss/seq after 02500 batchs: 806.0465087890625
INFO:root:Train (Epoch 90): Loss/seq after 02550 batchs: 796.5457763671875
INFO:root:Train (Epoch 90): Loss/seq after 02600 batchs: 794.2183227539062
INFO:root:Train (Epoch 90): Loss/seq after 02650 batchs: 790.39990234375
INFO:root:Train (Epoch 90): Loss/seq after 02700 batchs: 787.1642456054688
INFO:root:Train (Epoch 90): Loss/seq after 02750 batchs: 811.083740234375
INFO:root:Train (Epoch 90): Loss/seq after 02800 batchs: 814.8187255859375
INFO:root:Train (Epoch 90): Loss/seq after 02850 batchs: 813.2826538085938
INFO:root:Train (Epoch 90): Loss/seq after 02900 batchs: 813.9503173828125
INFO:root:Train (Epoch 90): Loss/seq after 02950 batchs: 810.1091918945312
INFO:root:Train (Epoch 90): Loss/seq after 03000 batchs: 812.47705078125
INFO:root:Train (Epoch 90): Loss/seq after 03050 batchs: 817.340576171875
INFO:root:Train (Epoch 90): Loss/seq after 03100 batchs: 823.1319580078125
INFO:root:Train (Epoch 90): Loss/seq after 03150 batchs: 828.6204833984375
INFO:root:Train (Epoch 90): Loss/seq after 03200 batchs: 835.2493896484375
INFO:root:Train (Epoch 90): Loss/seq after 03250 batchs: 839.7742919921875
INFO:root:Train (Epoch 90): Loss/seq after 03300 batchs: 838.6153564453125
INFO:root:Train (Epoch 90): Loss/seq after 03350 batchs: 837.2010498046875
INFO:root:Train (Epoch 90): Loss/seq after 03400 batchs: 829.835205078125
INFO:root:Train (Epoch 90): Loss/seq after 03450 batchs: 825.8698120117188
INFO:root:Train (Epoch 90): Loss/seq after 03500 batchs: 824.9625854492188
INFO:root:Train (Epoch 90): Loss/seq after 03550 batchs: 820.6737670898438
INFO:root:Train (Epoch 90): Loss/seq after 03600 batchs: 828.1389770507812
INFO:root:Train (Epoch 90): Loss/seq after 03650 batchs: 824.3790283203125
INFO:root:Train (Epoch 90): Loss/seq after 03700 batchs: 824.6882934570312
INFO:root:Train (Epoch 90): Loss/seq after 03750 batchs: 828.16015625
INFO:root:Train (Epoch 90): Loss/seq after 03800 batchs: 823.5018310546875
INFO:root:Train (Epoch 90): Loss/seq after 03850 batchs: 821.782958984375
INFO:root:Train (Epoch 90): Loss/seq after 03900 batchs: 825.5827026367188
INFO:root:Train (Epoch 90): Loss/seq after 03950 batchs: 829.8907470703125
INFO:root:Train (Epoch 90): Loss/seq after 04000 batchs: 824.6093139648438
INFO:root:Train (Epoch 90): Loss/seq after 04050 batchs: 818.792236328125
INFO:root:Train (Epoch 90): Loss/seq after 04100 batchs: 815.3040161132812
INFO:root:Train (Epoch 90): Loss/seq after 04150 batchs: 813.2335205078125
INFO:root:Train (Epoch 90): Loss/seq after 04200 batchs: 810.4346313476562
INFO:root:Train (Epoch 90): Loss/seq after 04250 batchs: 807.6303100585938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 90): Loss/seq after 00000 batches: 575.9070434570312
INFO:root:# Valid (Epoch 90): Loss/seq after 00050 batches: 750.8136596679688
INFO:root:# Valid (Epoch 90): Loss/seq after 00100 batches: 1013.0032958984375
INFO:root:# Valid (Epoch 90): Loss/seq after 00150 batches: 772.654052734375
INFO:root:# Valid (Epoch 90): Loss/seq after 00200 batches: 716.80908203125
INFO:root:Artifacts: Make stick videos for epoch 90
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_90_on_20220413_224737.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_90_index_1163_on_20220413_224737.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 91): Loss/seq after 00000 batchs: 1345.4561767578125
INFO:root:Train (Epoch 91): Loss/seq after 00050 batchs: 1028.618408203125
INFO:root:Train (Epoch 91): Loss/seq after 00100 batchs: 1054.529052734375
INFO:root:Train (Epoch 91): Loss/seq after 00150 batchs: 957.177490234375
INFO:root:Train (Epoch 91): Loss/seq after 00200 batchs: 1077.4608154296875
INFO:root:Train (Epoch 91): Loss/seq after 00250 batchs: 1189.2730712890625
INFO:root:Train (Epoch 91): Loss/seq after 00300 batchs: 1154.5098876953125
INFO:root:Train (Epoch 91): Loss/seq after 00350 batchs: 1074.915283203125
INFO:root:Train (Epoch 91): Loss/seq after 00400 batchs: 1089.91015625
INFO:root:Train (Epoch 91): Loss/seq after 00450 batchs: 1054.330322265625
INFO:root:Train (Epoch 91): Loss/seq after 00500 batchs: 1036.3836669921875
INFO:root:Train (Epoch 91): Loss/seq after 00550 batchs: 1000.1773071289062
INFO:root:Train (Epoch 91): Loss/seq after 00600 batchs: 964.814208984375
INFO:root:Train (Epoch 91): Loss/seq after 00650 batchs: 977.280517578125
INFO:root:Train (Epoch 91): Loss/seq after 00700 batchs: 957.9668579101562
INFO:root:Train (Epoch 91): Loss/seq after 00750 batchs: 991.8078002929688
INFO:root:Train (Epoch 91): Loss/seq after 00800 batchs: 984.5806884765625
INFO:root:Train (Epoch 91): Loss/seq after 00850 batchs: 954.1171875
INFO:root:Train (Epoch 91): Loss/seq after 00900 batchs: 934.8270874023438
INFO:root:Train (Epoch 91): Loss/seq after 00950 batchs: 946.5106201171875
INFO:root:Train (Epoch 91): Loss/seq after 01000 batchs: 940.9635009765625
INFO:root:Train (Epoch 91): Loss/seq after 01050 batchs: 921.5969848632812
INFO:root:Train (Epoch 91): Loss/seq after 01100 batchs: 905.2232055664062
INFO:root:Train (Epoch 91): Loss/seq after 01150 batchs: 882.1424560546875
INFO:root:Train (Epoch 91): Loss/seq after 01200 batchs: 881.7991333007812
INFO:root:Train (Epoch 91): Loss/seq after 01250 batchs: 877.1072387695312
INFO:root:Train (Epoch 91): Loss/seq after 01300 batchs: 869.7962036132812
INFO:root:Train (Epoch 91): Loss/seq after 01350 batchs: 861.6205444335938
INFO:root:Train (Epoch 91): Loss/seq after 01400 batchs: 880.223388671875
INFO:root:Train (Epoch 91): Loss/seq after 01450 batchs: 878.8052368164062
INFO:root:Train (Epoch 91): Loss/seq after 01500 batchs: 880.4370727539062
INFO:root:Train (Epoch 91): Loss/seq after 01550 batchs: 883.0134887695312
INFO:root:Train (Epoch 91): Loss/seq after 01600 batchs: 874.419677734375
INFO:root:Train (Epoch 91): Loss/seq after 01650 batchs: 868.3336791992188
INFO:root:Train (Epoch 91): Loss/seq after 01700 batchs: 865.4193115234375
INFO:root:Train (Epoch 91): Loss/seq after 01750 batchs: 859.6484375
INFO:root:Train (Epoch 91): Loss/seq after 01800 batchs: 853.1722412109375
INFO:root:Train (Epoch 91): Loss/seq after 01850 batchs: 845.9961547851562
INFO:root:Train (Epoch 91): Loss/seq after 01900 batchs: 845.8703002929688
INFO:root:Train (Epoch 91): Loss/seq after 01950 batchs: 841.354736328125
INFO:root:Train (Epoch 91): Loss/seq after 02000 batchs: 837.2322387695312
INFO:root:Train (Epoch 91): Loss/seq after 02050 batchs: 834.1478881835938
INFO:root:Train (Epoch 91): Loss/seq after 02100 batchs: 827.9329223632812
INFO:root:Train (Epoch 91): Loss/seq after 02150 batchs: 823.311767578125
INFO:root:Train (Epoch 91): Loss/seq after 02200 batchs: 817.8788452148438
INFO:root:Train (Epoch 91): Loss/seq after 02250 batchs: 817.9805908203125
INFO:root:Train (Epoch 91): Loss/seq after 02300 batchs: 824.5598754882812
INFO:root:Train (Epoch 91): Loss/seq after 02350 batchs: 817.1551513671875
INFO:root:Train (Epoch 91): Loss/seq after 02400 batchs: 815.6158447265625
INFO:root:Train (Epoch 91): Loss/seq after 02450 batchs: 808.1550903320312
INFO:root:Train (Epoch 91): Loss/seq after 02500 batchs: 795.4982299804688
INFO:root:Train (Epoch 91): Loss/seq after 02550 batchs: 786.1529541015625
INFO:root:Train (Epoch 91): Loss/seq after 02600 batchs: 783.9677124023438
INFO:root:Train (Epoch 91): Loss/seq after 02650 batchs: 780.2776489257812
INFO:root:Train (Epoch 91): Loss/seq after 02700 batchs: 777.4428100585938
INFO:root:Train (Epoch 91): Loss/seq after 02750 batchs: 800.394775390625
INFO:root:Train (Epoch 91): Loss/seq after 02800 batchs: 803.9705200195312
INFO:root:Train (Epoch 91): Loss/seq after 02850 batchs: 802.81787109375
INFO:root:Train (Epoch 91): Loss/seq after 02900 batchs: 803.1806640625
INFO:root:Train (Epoch 91): Loss/seq after 02950 batchs: 799.5308227539062
INFO:root:Train (Epoch 91): Loss/seq after 03000 batchs: 802.0535888671875
INFO:root:Train (Epoch 91): Loss/seq after 03050 batchs: 807.1192626953125
INFO:root:Train (Epoch 91): Loss/seq after 03100 batchs: 812.525146484375
INFO:root:Train (Epoch 91): Loss/seq after 03150 batchs: 818.2340698242188
INFO:root:Train (Epoch 91): Loss/seq after 03200 batchs: 825.9593505859375
INFO:root:Train (Epoch 91): Loss/seq after 03250 batchs: 830.5724487304688
INFO:root:Train (Epoch 91): Loss/seq after 03300 batchs: 829.135498046875
INFO:root:Train (Epoch 91): Loss/seq after 03350 batchs: 827.6304321289062
INFO:root:Train (Epoch 91): Loss/seq after 03400 batchs: 820.4171752929688
INFO:root:Train (Epoch 91): Loss/seq after 03450 batchs: 816.32373046875
INFO:root:Train (Epoch 91): Loss/seq after 03500 batchs: 815.2589721679688
INFO:root:Train (Epoch 91): Loss/seq after 03550 batchs: 810.5462036132812
INFO:root:Train (Epoch 91): Loss/seq after 03600 batchs: 817.7849731445312
INFO:root:Train (Epoch 91): Loss/seq after 03650 batchs: 813.4974365234375
INFO:root:Train (Epoch 91): Loss/seq after 03700 batchs: 813.93994140625
INFO:root:Train (Epoch 91): Loss/seq after 03750 batchs: 817.5281372070312
INFO:root:Train (Epoch 91): Loss/seq after 03800 batchs: 812.9307861328125
INFO:root:Train (Epoch 91): Loss/seq after 03850 batchs: 811.1178588867188
INFO:root:Train (Epoch 91): Loss/seq after 03900 batchs: 815.024169921875
INFO:root:Train (Epoch 91): Loss/seq after 03950 batchs: 819.2160034179688
INFO:root:Train (Epoch 91): Loss/seq after 04000 batchs: 814.0399780273438
INFO:root:Train (Epoch 91): Loss/seq after 04050 batchs: 808.3029174804688
INFO:root:Train (Epoch 91): Loss/seq after 04100 batchs: 804.8236083984375
INFO:root:Train (Epoch 91): Loss/seq after 04150 batchs: 802.8411254882812
INFO:root:Train (Epoch 91): Loss/seq after 04200 batchs: 800.2628173828125
INFO:root:Train (Epoch 91): Loss/seq after 04250 batchs: 797.6566772460938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 91): Loss/seq after 00000 batches: 562.9423217773438
INFO:root:# Valid (Epoch 91): Loss/seq after 00050 batches: 749.457763671875
INFO:root:# Valid (Epoch 91): Loss/seq after 00100 batches: 1009.777587890625
INFO:root:# Valid (Epoch 91): Loss/seq after 00150 batches: 771.362060546875
INFO:root:# Valid (Epoch 91): Loss/seq after 00200 batches: 717.9509887695312
INFO:root:Artifacts: Make stick videos for epoch 91
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_91_on_20220413_225254.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_91_index_1785_on_20220413_225254.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 92): Loss/seq after 00000 batchs: 1288.983642578125
INFO:root:Train (Epoch 92): Loss/seq after 00050 batchs: 1038.865234375
INFO:root:Train (Epoch 92): Loss/seq after 00100 batchs: 1072.297119140625
INFO:root:Train (Epoch 92): Loss/seq after 00150 batchs: 976.052978515625
INFO:root:Train (Epoch 92): Loss/seq after 00200 batchs: 1087.2322998046875
INFO:root:Train (Epoch 92): Loss/seq after 00250 batchs: 1197.50732421875
INFO:root:Train (Epoch 92): Loss/seq after 00300 batchs: 1160.5362548828125
INFO:root:Train (Epoch 92): Loss/seq after 00350 batchs: 1077.4090576171875
INFO:root:Train (Epoch 92): Loss/seq after 00400 batchs: 1093.2088623046875
INFO:root:Train (Epoch 92): Loss/seq after 00450 batchs: 1057.049072265625
INFO:root:Train (Epoch 92): Loss/seq after 00500 batchs: 1037.143798828125
INFO:root:Train (Epoch 92): Loss/seq after 00550 batchs: 999.9430541992188
INFO:root:Train (Epoch 92): Loss/seq after 00600 batchs: 963.031982421875
INFO:root:Train (Epoch 92): Loss/seq after 00650 batchs: 972.8389282226562
INFO:root:Train (Epoch 92): Loss/seq after 00700 batchs: 953.6508178710938
INFO:root:Train (Epoch 92): Loss/seq after 00750 batchs: 984.8916015625
INFO:root:Train (Epoch 92): Loss/seq after 00800 batchs: 976.6161499023438
INFO:root:Train (Epoch 92): Loss/seq after 00850 batchs: 945.870361328125
INFO:root:Train (Epoch 92): Loss/seq after 00900 batchs: 926.14599609375
INFO:root:Train (Epoch 92): Loss/seq after 00950 batchs: 937.3086547851562
INFO:root:Train (Epoch 92): Loss/seq after 01000 batchs: 931.93701171875
INFO:root:Train (Epoch 92): Loss/seq after 01050 batchs: 911.9417114257812
INFO:root:Train (Epoch 92): Loss/seq after 01100 batchs: 895.0493774414062
INFO:root:Train (Epoch 92): Loss/seq after 01150 batchs: 871.920166015625
INFO:root:Train (Epoch 92): Loss/seq after 01200 batchs: 871.5262451171875
INFO:root:Train (Epoch 92): Loss/seq after 01250 batchs: 867.03759765625
INFO:root:Train (Epoch 92): Loss/seq after 01300 batchs: 859.4876708984375
INFO:root:Train (Epoch 92): Loss/seq after 01350 batchs: 851.6119995117188
INFO:root:Train (Epoch 92): Loss/seq after 01400 batchs: 869.297607421875
INFO:root:Train (Epoch 92): Loss/seq after 01450 batchs: 868.010009765625
INFO:root:Train (Epoch 92): Loss/seq after 01500 batchs: 869.6940307617188
INFO:root:Train (Epoch 92): Loss/seq after 01550 batchs: 872.1489868164062
INFO:root:Train (Epoch 92): Loss/seq after 01600 batchs: 863.5818481445312
INFO:root:Train (Epoch 92): Loss/seq after 01650 batchs: 858.2337646484375
INFO:root:Train (Epoch 92): Loss/seq after 01700 batchs: 855.9606323242188
INFO:root:Train (Epoch 92): Loss/seq after 01750 batchs: 850.49951171875
INFO:root:Train (Epoch 92): Loss/seq after 01800 batchs: 844.1542358398438
INFO:root:Train (Epoch 92): Loss/seq after 01850 batchs: 836.9439697265625
INFO:root:Train (Epoch 92): Loss/seq after 01900 batchs: 837.9525146484375
INFO:root:Train (Epoch 92): Loss/seq after 01950 batchs: 833.7327270507812
INFO:root:Train (Epoch 92): Loss/seq after 02000 batchs: 829.9763793945312
INFO:root:Train (Epoch 92): Loss/seq after 02050 batchs: 827.1448364257812
INFO:root:Train (Epoch 92): Loss/seq after 02100 batchs: 821.3667602539062
INFO:root:Train (Epoch 92): Loss/seq after 02150 batchs: 816.9006958007812
INFO:root:Train (Epoch 92): Loss/seq after 02200 batchs: 811.3690185546875
INFO:root:Train (Epoch 92): Loss/seq after 02250 batchs: 811.5738525390625
INFO:root:Train (Epoch 92): Loss/seq after 02300 batchs: 818.7123413085938
INFO:root:Train (Epoch 92): Loss/seq after 02350 batchs: 810.931884765625
INFO:root:Train (Epoch 92): Loss/seq after 02400 batchs: 809.3872680664062
INFO:root:Train (Epoch 92): Loss/seq after 02450 batchs: 801.7525634765625
INFO:root:Train (Epoch 92): Loss/seq after 02500 batchs: 789.2493896484375
INFO:root:Train (Epoch 92): Loss/seq after 02550 batchs: 779.8494262695312
INFO:root:Train (Epoch 92): Loss/seq after 02600 batchs: 777.7545776367188
INFO:root:Train (Epoch 92): Loss/seq after 02650 batchs: 774.0953369140625
INFO:root:Train (Epoch 92): Loss/seq after 02700 batchs: 771.201416015625
INFO:root:Train (Epoch 92): Loss/seq after 02750 batchs: 794.7295532226562
INFO:root:Train (Epoch 92): Loss/seq after 02800 batchs: 798.3035278320312
INFO:root:Train (Epoch 92): Loss/seq after 02850 batchs: 797.1881713867188
INFO:root:Train (Epoch 92): Loss/seq after 02900 batchs: 798.1819458007812
INFO:root:Train (Epoch 92): Loss/seq after 02950 batchs: 794.6131591796875
INFO:root:Train (Epoch 92): Loss/seq after 03000 batchs: 797.26904296875
INFO:root:Train (Epoch 92): Loss/seq after 03050 batchs: 802.5531005859375
INFO:root:Train (Epoch 92): Loss/seq after 03100 batchs: 807.45361328125
INFO:root:Train (Epoch 92): Loss/seq after 03150 batchs: 813.4599609375
INFO:root:Train (Epoch 92): Loss/seq after 03200 batchs: 820.5993041992188
INFO:root:Train (Epoch 92): Loss/seq after 03250 batchs: 825.4036254882812
INFO:root:Train (Epoch 92): Loss/seq after 03300 batchs: 823.748291015625
INFO:root:Train (Epoch 92): Loss/seq after 03350 batchs: 822.8583374023438
INFO:root:Train (Epoch 92): Loss/seq after 03400 batchs: 815.63916015625
INFO:root:Train (Epoch 92): Loss/seq after 03450 batchs: 811.5714721679688
INFO:root:Train (Epoch 92): Loss/seq after 03500 batchs: 810.8722534179688
INFO:root:Train (Epoch 92): Loss/seq after 03550 batchs: 806.2828979492188
INFO:root:Train (Epoch 92): Loss/seq after 03600 batchs: 813.4657592773438
INFO:root:Train (Epoch 92): Loss/seq after 03650 batchs: 809.2741088867188
INFO:root:Train (Epoch 92): Loss/seq after 03700 batchs: 809.69140625
INFO:root:Train (Epoch 92): Loss/seq after 03750 batchs: 813.2561645507812
INFO:root:Train (Epoch 92): Loss/seq after 03800 batchs: 808.5621337890625
INFO:root:Train (Epoch 92): Loss/seq after 03850 batchs: 806.7059326171875
INFO:root:Train (Epoch 92): Loss/seq after 03900 batchs: 810.5573120117188
INFO:root:Train (Epoch 92): Loss/seq after 03950 batchs: 814.6792602539062
INFO:root:Train (Epoch 92): Loss/seq after 04000 batchs: 809.5255126953125
INFO:root:Train (Epoch 92): Loss/seq after 04050 batchs: 803.816162109375
INFO:root:Train (Epoch 92): Loss/seq after 04100 batchs: 800.3900756835938
INFO:root:Train (Epoch 92): Loss/seq after 04150 batchs: 798.5010986328125
INFO:root:Train (Epoch 92): Loss/seq after 04200 batchs: 795.9796752929688
INFO:root:Train (Epoch 92): Loss/seq after 04250 batchs: 793.2564086914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 92): Loss/seq after 00000 batches: 629.11572265625
INFO:root:# Valid (Epoch 92): Loss/seq after 00050 batches: 736.4602661132812
INFO:root:# Valid (Epoch 92): Loss/seq after 00100 batches: 982.0745239257812
INFO:root:# Valid (Epoch 92): Loss/seq after 00150 batches: 750.9996337890625
INFO:root:# Valid (Epoch 92): Loss/seq after 00200 batches: 700.0677490234375
INFO:root:Artifacts: Make stick videos for epoch 92
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_92_on_20220413_225812.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_92_index_1039_on_20220413_225812.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 93): Loss/seq after 00000 batchs: 1362.5489501953125
INFO:root:Train (Epoch 93): Loss/seq after 00050 batchs: 1040.5006103515625
INFO:root:Train (Epoch 93): Loss/seq after 00100 batchs: 1076.80078125
INFO:root:Train (Epoch 93): Loss/seq after 00150 batchs: 966.7623901367188
INFO:root:Train (Epoch 93): Loss/seq after 00200 batchs: 1082.5802001953125
INFO:root:Train (Epoch 93): Loss/seq after 00250 batchs: 1193.18701171875
INFO:root:Train (Epoch 93): Loss/seq after 00300 batchs: 1156.161865234375
INFO:root:Train (Epoch 93): Loss/seq after 00350 batchs: 1074.443603515625
INFO:root:Train (Epoch 93): Loss/seq after 00400 batchs: 1091.9901123046875
INFO:root:Train (Epoch 93): Loss/seq after 00450 batchs: 1054.9769287109375
INFO:root:Train (Epoch 93): Loss/seq after 00500 batchs: 1036.2723388671875
INFO:root:Train (Epoch 93): Loss/seq after 00550 batchs: 998.9075317382812
INFO:root:Train (Epoch 93): Loss/seq after 00600 batchs: 961.1965942382812
INFO:root:Train (Epoch 93): Loss/seq after 00650 batchs: 974.5277709960938
INFO:root:Train (Epoch 93): Loss/seq after 00700 batchs: 954.1727294921875
INFO:root:Train (Epoch 93): Loss/seq after 00750 batchs: 983.0117797851562
INFO:root:Train (Epoch 93): Loss/seq after 00800 batchs: 973.54833984375
INFO:root:Train (Epoch 93): Loss/seq after 00850 batchs: 943.6566162109375
INFO:root:Train (Epoch 93): Loss/seq after 00900 batchs: 924.3522338867188
INFO:root:Train (Epoch 93): Loss/seq after 00950 batchs: 936.74658203125
INFO:root:Train (Epoch 93): Loss/seq after 01000 batchs: 931.846923828125
INFO:root:Train (Epoch 93): Loss/seq after 01050 batchs: 912.73876953125
INFO:root:Train (Epoch 93): Loss/seq after 01100 batchs: 897.86181640625
INFO:root:Train (Epoch 93): Loss/seq after 01150 batchs: 875.045166015625
INFO:root:Train (Epoch 93): Loss/seq after 01200 batchs: 874.1219482421875
INFO:root:Train (Epoch 93): Loss/seq after 01250 batchs: 869.9420166015625
INFO:root:Train (Epoch 93): Loss/seq after 01300 batchs: 865.6892700195312
INFO:root:Train (Epoch 93): Loss/seq after 01350 batchs: 857.2010498046875
INFO:root:Train (Epoch 93): Loss/seq after 01400 batchs: 872.6024780273438
INFO:root:Train (Epoch 93): Loss/seq after 01450 batchs: 870.0075073242188
INFO:root:Train (Epoch 93): Loss/seq after 01500 batchs: 871.5352783203125
INFO:root:Train (Epoch 93): Loss/seq after 01550 batchs: 873.6979370117188
INFO:root:Train (Epoch 93): Loss/seq after 01600 batchs: 864.8648681640625
INFO:root:Train (Epoch 93): Loss/seq after 01650 batchs: 858.979248046875
INFO:root:Train (Epoch 93): Loss/seq after 01700 batchs: 855.9447021484375
INFO:root:Train (Epoch 93): Loss/seq after 01750 batchs: 850.24853515625
INFO:root:Train (Epoch 93): Loss/seq after 01800 batchs: 843.5711059570312
INFO:root:Train (Epoch 93): Loss/seq after 01850 batchs: 836.2129516601562
INFO:root:Train (Epoch 93): Loss/seq after 01900 batchs: 836.8019409179688
INFO:root:Train (Epoch 93): Loss/seq after 01950 batchs: 832.1803588867188
INFO:root:Train (Epoch 93): Loss/seq after 02000 batchs: 828.156494140625
INFO:root:Train (Epoch 93): Loss/seq after 02050 batchs: 824.968994140625
INFO:root:Train (Epoch 93): Loss/seq after 02100 batchs: 818.9877319335938
INFO:root:Train (Epoch 93): Loss/seq after 02150 batchs: 814.397705078125
INFO:root:Train (Epoch 93): Loss/seq after 02200 batchs: 808.6939697265625
INFO:root:Train (Epoch 93): Loss/seq after 02250 batchs: 808.9054565429688
INFO:root:Train (Epoch 93): Loss/seq after 02300 batchs: 814.4462890625
INFO:root:Train (Epoch 93): Loss/seq after 02350 batchs: 807.0086669921875
INFO:root:Train (Epoch 93): Loss/seq after 02400 batchs: 805.5117797851562
INFO:root:Train (Epoch 93): Loss/seq after 02450 batchs: 797.7744750976562
INFO:root:Train (Epoch 93): Loss/seq after 02500 batchs: 785.31298828125
INFO:root:Train (Epoch 93): Loss/seq after 02550 batchs: 776.1102294921875
INFO:root:Train (Epoch 93): Loss/seq after 02600 batchs: 773.9267578125
INFO:root:Train (Epoch 93): Loss/seq after 02650 batchs: 770.0525512695312
INFO:root:Train (Epoch 93): Loss/seq after 02700 batchs: 767.072021484375
INFO:root:Train (Epoch 93): Loss/seq after 02750 batchs: 790.1639404296875
INFO:root:Train (Epoch 93): Loss/seq after 02800 batchs: 794.0133056640625
INFO:root:Train (Epoch 93): Loss/seq after 02850 batchs: 793.0159912109375
INFO:root:Train (Epoch 93): Loss/seq after 02900 batchs: 794.3176879882812
INFO:root:Train (Epoch 93): Loss/seq after 02950 batchs: 791.0034790039062
INFO:root:Train (Epoch 93): Loss/seq after 03000 batchs: 793.6665649414062
INFO:root:Train (Epoch 93): Loss/seq after 03050 batchs: 798.741943359375
INFO:root:Train (Epoch 93): Loss/seq after 03100 batchs: 803.7223510742188
INFO:root:Train (Epoch 93): Loss/seq after 03150 batchs: 809.1536254882812
INFO:root:Train (Epoch 93): Loss/seq after 03200 batchs: 815.7960815429688
INFO:root:Train (Epoch 93): Loss/seq after 03250 batchs: 820.6665649414062
INFO:root:Train (Epoch 93): Loss/seq after 03300 batchs: 819.539794921875
INFO:root:Train (Epoch 93): Loss/seq after 03350 batchs: 818.162841796875
INFO:root:Train (Epoch 93): Loss/seq after 03400 batchs: 810.994873046875
INFO:root:Train (Epoch 93): Loss/seq after 03450 batchs: 807.1099243164062
INFO:root:Train (Epoch 93): Loss/seq after 03500 batchs: 806.2066040039062
INFO:root:Train (Epoch 93): Loss/seq after 03550 batchs: 801.49951171875
INFO:root:Train (Epoch 93): Loss/seq after 03600 batchs: 808.59326171875
INFO:root:Train (Epoch 93): Loss/seq after 03650 batchs: 804.6101684570312
INFO:root:Train (Epoch 93): Loss/seq after 03700 batchs: 805.159912109375
INFO:root:Train (Epoch 93): Loss/seq after 03750 batchs: 808.695068359375
INFO:root:Train (Epoch 93): Loss/seq after 03800 batchs: 804.0750732421875
INFO:root:Train (Epoch 93): Loss/seq after 03850 batchs: 802.3270263671875
INFO:root:Train (Epoch 93): Loss/seq after 03900 batchs: 806.1777954101562
INFO:root:Train (Epoch 93): Loss/seq after 03950 batchs: 809.986572265625
INFO:root:Train (Epoch 93): Loss/seq after 04000 batchs: 804.8073120117188
INFO:root:Train (Epoch 93): Loss/seq after 04050 batchs: 799.0579223632812
INFO:root:Train (Epoch 93): Loss/seq after 04100 batchs: 795.7819213867188
INFO:root:Train (Epoch 93): Loss/seq after 04150 batchs: 793.8316040039062
INFO:root:Train (Epoch 93): Loss/seq after 04200 batchs: 791.1185913085938
INFO:root:Train (Epoch 93): Loss/seq after 04250 batchs: 788.355224609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 93): Loss/seq after 00000 batches: 560.9064331054688
INFO:root:# Valid (Epoch 93): Loss/seq after 00050 batches: 736.8067016601562
INFO:root:# Valid (Epoch 93): Loss/seq after 00100 batches: 987.23583984375
INFO:root:# Valid (Epoch 93): Loss/seq after 00150 batches: 751.3174438476562
INFO:root:# Valid (Epoch 93): Loss/seq after 00200 batches: 695.8015747070312
INFO:root:Artifacts: Make stick videos for epoch 93
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_93_on_20220413_230330.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_93_index_966_on_20220413_230330.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 94): Loss/seq after 00000 batchs: 1345.400146484375
INFO:root:Train (Epoch 94): Loss/seq after 00050 batchs: 1012.2119140625
INFO:root:Train (Epoch 94): Loss/seq after 00100 batchs: 1052.4185791015625
INFO:root:Train (Epoch 94): Loss/seq after 00150 batchs: 953.65966796875
INFO:root:Train (Epoch 94): Loss/seq after 00200 batchs: 1079.67138671875
INFO:root:Train (Epoch 94): Loss/seq after 00250 batchs: 1190.2137451171875
INFO:root:Train (Epoch 94): Loss/seq after 00300 batchs: 1153.234619140625
INFO:root:Train (Epoch 94): Loss/seq after 00350 batchs: 1070.1666259765625
INFO:root:Train (Epoch 94): Loss/seq after 00400 batchs: 1088.20361328125
INFO:root:Train (Epoch 94): Loss/seq after 00450 batchs: 1051.139892578125
INFO:root:Train (Epoch 94): Loss/seq after 00500 batchs: 1033.568359375
INFO:root:Train (Epoch 94): Loss/seq after 00550 batchs: 996.9134521484375
INFO:root:Train (Epoch 94): Loss/seq after 00600 batchs: 960.5460205078125
INFO:root:Train (Epoch 94): Loss/seq after 00650 batchs: 971.1620483398438
INFO:root:Train (Epoch 94): Loss/seq after 00700 batchs: 951.1390991210938
INFO:root:Train (Epoch 94): Loss/seq after 00750 batchs: 980.3173828125
INFO:root:Train (Epoch 94): Loss/seq after 00800 batchs: 971.6219482421875
INFO:root:Train (Epoch 94): Loss/seq after 00850 batchs: 941.3645629882812
INFO:root:Train (Epoch 94): Loss/seq after 00900 batchs: 921.9042358398438
INFO:root:Train (Epoch 94): Loss/seq after 00950 batchs: 932.2037963867188
INFO:root:Train (Epoch 94): Loss/seq after 01000 batchs: 926.4747314453125
INFO:root:Train (Epoch 94): Loss/seq after 01050 batchs: 907.3881225585938
INFO:root:Train (Epoch 94): Loss/seq after 01100 batchs: 891.1930541992188
INFO:root:Train (Epoch 94): Loss/seq after 01150 batchs: 868.1700439453125
INFO:root:Train (Epoch 94): Loss/seq after 01200 batchs: 867.3599853515625
INFO:root:Train (Epoch 94): Loss/seq after 01250 batchs: 862.5887451171875
INFO:root:Train (Epoch 94): Loss/seq after 01300 batchs: 854.1392211914062
INFO:root:Train (Epoch 94): Loss/seq after 01350 batchs: 846.1783447265625
INFO:root:Train (Epoch 94): Loss/seq after 01400 batchs: 862.8754272460938
INFO:root:Train (Epoch 94): Loss/seq after 01450 batchs: 861.00048828125
INFO:root:Train (Epoch 94): Loss/seq after 01500 batchs: 862.552734375
INFO:root:Train (Epoch 94): Loss/seq after 01550 batchs: 864.6591186523438
INFO:root:Train (Epoch 94): Loss/seq after 01600 batchs: 855.8787841796875
INFO:root:Train (Epoch 94): Loss/seq after 01650 batchs: 850.0010986328125
INFO:root:Train (Epoch 94): Loss/seq after 01700 batchs: 847.3933715820312
INFO:root:Train (Epoch 94): Loss/seq after 01750 batchs: 841.5130004882812
INFO:root:Train (Epoch 94): Loss/seq after 01800 batchs: 835.1340942382812
INFO:root:Train (Epoch 94): Loss/seq after 01850 batchs: 828.303955078125
INFO:root:Train (Epoch 94): Loss/seq after 01900 batchs: 828.7810668945312
INFO:root:Train (Epoch 94): Loss/seq after 01950 batchs: 824.5511474609375
INFO:root:Train (Epoch 94): Loss/seq after 02000 batchs: 820.8502807617188
INFO:root:Train (Epoch 94): Loss/seq after 02050 batchs: 817.4342041015625
INFO:root:Train (Epoch 94): Loss/seq after 02100 batchs: 811.490234375
INFO:root:Train (Epoch 94): Loss/seq after 02150 batchs: 806.8252563476562
INFO:root:Train (Epoch 94): Loss/seq after 02200 batchs: 801.3273315429688
INFO:root:Train (Epoch 94): Loss/seq after 02250 batchs: 801.6912231445312
INFO:root:Train (Epoch 94): Loss/seq after 02300 batchs: 806.1985473632812
INFO:root:Train (Epoch 94): Loss/seq after 02350 batchs: 799.0747680664062
INFO:root:Train (Epoch 94): Loss/seq after 02400 batchs: 797.7457275390625
INFO:root:Train (Epoch 94): Loss/seq after 02450 batchs: 790.03564453125
INFO:root:Train (Epoch 94): Loss/seq after 02500 batchs: 777.7073974609375
INFO:root:Train (Epoch 94): Loss/seq after 02550 batchs: 768.5650024414062
INFO:root:Train (Epoch 94): Loss/seq after 02600 batchs: 766.3211669921875
INFO:root:Train (Epoch 94): Loss/seq after 02650 batchs: 762.6619873046875
INFO:root:Train (Epoch 94): Loss/seq after 02700 batchs: 759.3842163085938
INFO:root:Train (Epoch 94): Loss/seq after 02750 batchs: 781.240478515625
INFO:root:Train (Epoch 94): Loss/seq after 02800 batchs: 784.5983276367188
INFO:root:Train (Epoch 94): Loss/seq after 02850 batchs: 783.5115966796875
INFO:root:Train (Epoch 94): Loss/seq after 02900 batchs: 783.8936157226562
INFO:root:Train (Epoch 94): Loss/seq after 02950 batchs: 780.5388793945312
INFO:root:Train (Epoch 94): Loss/seq after 03000 batchs: 783.2051391601562
INFO:root:Train (Epoch 94): Loss/seq after 03050 batchs: 788.0322265625
INFO:root:Train (Epoch 94): Loss/seq after 03100 batchs: 792.7615966796875
INFO:root:Train (Epoch 94): Loss/seq after 03150 batchs: 798.9366455078125
INFO:root:Train (Epoch 94): Loss/seq after 03200 batchs: 806.1436157226562
INFO:root:Train (Epoch 94): Loss/seq after 03250 batchs: 811.1038818359375
INFO:root:Train (Epoch 94): Loss/seq after 03300 batchs: 810.3052978515625
INFO:root:Train (Epoch 94): Loss/seq after 03350 batchs: 809.2645263671875
INFO:root:Train (Epoch 94): Loss/seq after 03400 batchs: 802.1632690429688
INFO:root:Train (Epoch 94): Loss/seq after 03450 batchs: 798.3650512695312
INFO:root:Train (Epoch 94): Loss/seq after 03500 batchs: 797.5743408203125
INFO:root:Train (Epoch 94): Loss/seq after 03550 batchs: 793.054443359375
INFO:root:Train (Epoch 94): Loss/seq after 03600 batchs: 800.4267578125
INFO:root:Train (Epoch 94): Loss/seq after 03650 batchs: 796.4351196289062
INFO:root:Train (Epoch 94): Loss/seq after 03700 batchs: 797.1742553710938
INFO:root:Train (Epoch 94): Loss/seq after 03750 batchs: 800.6172485351562
INFO:root:Train (Epoch 94): Loss/seq after 03800 batchs: 796.0481567382812
INFO:root:Train (Epoch 94): Loss/seq after 03850 batchs: 794.3941650390625
INFO:root:Train (Epoch 94): Loss/seq after 03900 batchs: 798.3845825195312
INFO:root:Train (Epoch 94): Loss/seq after 03950 batchs: 802.4719848632812
INFO:root:Train (Epoch 94): Loss/seq after 04000 batchs: 797.3442993164062
INFO:root:Train (Epoch 94): Loss/seq after 04050 batchs: 791.7958374023438
INFO:root:Train (Epoch 94): Loss/seq after 04100 batchs: 788.3260498046875
INFO:root:Train (Epoch 94): Loss/seq after 04150 batchs: 786.3623046875
INFO:root:Train (Epoch 94): Loss/seq after 04200 batchs: 783.751220703125
INFO:root:Train (Epoch 94): Loss/seq after 04250 batchs: 780.9951782226562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 94): Loss/seq after 00000 batches: 593.845703125
INFO:root:# Valid (Epoch 94): Loss/seq after 00050 batches: 732.5392456054688
INFO:root:# Valid (Epoch 94): Loss/seq after 00100 batches: 989.4625244140625
INFO:root:# Valid (Epoch 94): Loss/seq after 00150 batches: 754.9990234375
INFO:root:# Valid (Epoch 94): Loss/seq after 00200 batches: 702.1678466796875
INFO:root:Artifacts: Make stick videos for epoch 94
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_94_on_20220413_230848.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_94_index_422_on_20220413_230848.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 95): Loss/seq after 00000 batchs: 1385.0523681640625
INFO:root:Train (Epoch 95): Loss/seq after 00050 batchs: 998.7615966796875
INFO:root:Train (Epoch 95): Loss/seq after 00100 batchs: 1034.716064453125
INFO:root:Train (Epoch 95): Loss/seq after 00150 batchs: 942.8065185546875
INFO:root:Train (Epoch 95): Loss/seq after 00200 batchs: 1073.1658935546875
INFO:root:Train (Epoch 95): Loss/seq after 00250 batchs: 1186.3822021484375
INFO:root:Train (Epoch 95): Loss/seq after 00300 batchs: 1150.1029052734375
INFO:root:Train (Epoch 95): Loss/seq after 00350 batchs: 1067.8363037109375
INFO:root:Train (Epoch 95): Loss/seq after 00400 batchs: 1081.6842041015625
INFO:root:Train (Epoch 95): Loss/seq after 00450 batchs: 1045.2626953125
INFO:root:Train (Epoch 95): Loss/seq after 00500 batchs: 1023.8408813476562
INFO:root:Train (Epoch 95): Loss/seq after 00550 batchs: 987.4375
INFO:root:Train (Epoch 95): Loss/seq after 00600 batchs: 950.1474609375
INFO:root:Train (Epoch 95): Loss/seq after 00650 batchs: 963.9719848632812
INFO:root:Train (Epoch 95): Loss/seq after 00700 batchs: 944.3890991210938
INFO:root:Train (Epoch 95): Loss/seq after 00750 batchs: 980.718017578125
INFO:root:Train (Epoch 95): Loss/seq after 00800 batchs: 972.5521240234375
INFO:root:Train (Epoch 95): Loss/seq after 00850 batchs: 942.7705688476562
INFO:root:Train (Epoch 95): Loss/seq after 00900 batchs: 923.53564453125
INFO:root:Train (Epoch 95): Loss/seq after 00950 batchs: 934.5125732421875
INFO:root:Train (Epoch 95): Loss/seq after 01000 batchs: 929.64501953125
INFO:root:Train (Epoch 95): Loss/seq after 01050 batchs: 910.2080688476562
INFO:root:Train (Epoch 95): Loss/seq after 01100 batchs: 894.04052734375
INFO:root:Train (Epoch 95): Loss/seq after 01150 batchs: 870.6727294921875
INFO:root:Train (Epoch 95): Loss/seq after 01200 batchs: 869.7769775390625
INFO:root:Train (Epoch 95): Loss/seq after 01250 batchs: 864.7261352539062
INFO:root:Train (Epoch 95): Loss/seq after 01300 batchs: 857.1260375976562
INFO:root:Train (Epoch 95): Loss/seq after 01350 batchs: 847.93408203125
INFO:root:Train (Epoch 95): Loss/seq after 01400 batchs: 864.3216552734375
INFO:root:Train (Epoch 95): Loss/seq after 01450 batchs: 861.7598876953125
INFO:root:Train (Epoch 95): Loss/seq after 01500 batchs: 863.1370849609375
INFO:root:Train (Epoch 95): Loss/seq after 01550 batchs: 865.2213745117188
INFO:root:Train (Epoch 95): Loss/seq after 01600 batchs: 855.4425048828125
INFO:root:Train (Epoch 95): Loss/seq after 01650 batchs: 849.50390625
INFO:root:Train (Epoch 95): Loss/seq after 01700 batchs: 846.9691162109375
INFO:root:Train (Epoch 95): Loss/seq after 01750 batchs: 840.83935546875
INFO:root:Train (Epoch 95): Loss/seq after 01800 batchs: 834.817138671875
INFO:root:Train (Epoch 95): Loss/seq after 01850 batchs: 827.7979736328125
INFO:root:Train (Epoch 95): Loss/seq after 01900 batchs: 828.0322875976562
INFO:root:Train (Epoch 95): Loss/seq after 01950 batchs: 823.6040649414062
INFO:root:Train (Epoch 95): Loss/seq after 02000 batchs: 819.207275390625
INFO:root:Train (Epoch 95): Loss/seq after 02050 batchs: 815.9560546875
INFO:root:Train (Epoch 95): Loss/seq after 02100 batchs: 810.0679321289062
INFO:root:Train (Epoch 95): Loss/seq after 02150 batchs: 805.6578979492188
INFO:root:Train (Epoch 95): Loss/seq after 02200 batchs: 799.9954833984375
INFO:root:Train (Epoch 95): Loss/seq after 02250 batchs: 800.5374145507812
INFO:root:Train (Epoch 95): Loss/seq after 02300 batchs: 805.8892211914062
INFO:root:Train (Epoch 95): Loss/seq after 02350 batchs: 798.6115112304688
INFO:root:Train (Epoch 95): Loss/seq after 02400 batchs: 796.85205078125
INFO:root:Train (Epoch 95): Loss/seq after 02450 batchs: 789.1546020507812
INFO:root:Train (Epoch 95): Loss/seq after 02500 batchs: 776.8345947265625
INFO:root:Train (Epoch 95): Loss/seq after 02550 batchs: 767.577880859375
INFO:root:Train (Epoch 95): Loss/seq after 02600 batchs: 765.388916015625
INFO:root:Train (Epoch 95): Loss/seq after 02650 batchs: 761.7531127929688
INFO:root:Train (Epoch 95): Loss/seq after 02700 batchs: 758.7474975585938
INFO:root:Train (Epoch 95): Loss/seq after 02750 batchs: 779.490478515625
INFO:root:Train (Epoch 95): Loss/seq after 02800 batchs: 782.7374267578125
INFO:root:Train (Epoch 95): Loss/seq after 02850 batchs: 781.843994140625
INFO:root:Train (Epoch 95): Loss/seq after 02900 batchs: 782.190185546875
INFO:root:Train (Epoch 95): Loss/seq after 02950 batchs: 778.8433837890625
INFO:root:Train (Epoch 95): Loss/seq after 03000 batchs: 781.4912719726562
INFO:root:Train (Epoch 95): Loss/seq after 03050 batchs: 785.9287109375
INFO:root:Train (Epoch 95): Loss/seq after 03100 batchs: 790.8057861328125
INFO:root:Train (Epoch 95): Loss/seq after 03150 batchs: 796.085693359375
INFO:root:Train (Epoch 95): Loss/seq after 03200 batchs: 803.3862915039062
INFO:root:Train (Epoch 95): Loss/seq after 03250 batchs: 808.215087890625
INFO:root:Train (Epoch 95): Loss/seq after 03300 batchs: 806.8045043945312
INFO:root:Train (Epoch 95): Loss/seq after 03350 batchs: 805.9407958984375
INFO:root:Train (Epoch 95): Loss/seq after 03400 batchs: 798.8596801757812
INFO:root:Train (Epoch 95): Loss/seq after 03450 batchs: 794.9278564453125
INFO:root:Train (Epoch 95): Loss/seq after 03500 batchs: 793.9854125976562
INFO:root:Train (Epoch 95): Loss/seq after 03550 batchs: 789.4910278320312
INFO:root:Train (Epoch 95): Loss/seq after 03600 batchs: 796.6983032226562
INFO:root:Train (Epoch 95): Loss/seq after 03650 batchs: 792.6611328125
INFO:root:Train (Epoch 95): Loss/seq after 03700 batchs: 793.259765625
INFO:root:Train (Epoch 95): Loss/seq after 03750 batchs: 796.7975463867188
INFO:root:Train (Epoch 95): Loss/seq after 03800 batchs: 792.208251953125
INFO:root:Train (Epoch 95): Loss/seq after 03850 batchs: 790.4539794921875
INFO:root:Train (Epoch 95): Loss/seq after 03900 batchs: 794.265869140625
INFO:root:Train (Epoch 95): Loss/seq after 03950 batchs: 798.314697265625
INFO:root:Train (Epoch 95): Loss/seq after 04000 batchs: 793.2676391601562
INFO:root:Train (Epoch 95): Loss/seq after 04050 batchs: 787.5885009765625
INFO:root:Train (Epoch 95): Loss/seq after 04100 batchs: 784.2833862304688
INFO:root:Train (Epoch 95): Loss/seq after 04150 batchs: 782.3444213867188
INFO:root:Train (Epoch 95): Loss/seq after 04200 batchs: 779.617431640625
INFO:root:Train (Epoch 95): Loss/seq after 04250 batchs: 776.9120483398438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 95): Loss/seq after 00000 batches: 648.4031982421875
INFO:root:# Valid (Epoch 95): Loss/seq after 00050 batches: 740.02294921875
INFO:root:# Valid (Epoch 95): Loss/seq after 00100 batches: 975.2244873046875
INFO:root:# Valid (Epoch 95): Loss/seq after 00150 batches: 739.3533325195312
INFO:root:# Valid (Epoch 95): Loss/seq after 00200 batches: 684.541259765625
INFO:root:Artifacts: Make stick videos for epoch 95
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_95_on_20220413_231405.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_95_index_1628_on_20220413_231405.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 96): Loss/seq after 00000 batchs: 1366.6002197265625
INFO:root:Train (Epoch 96): Loss/seq after 00050 batchs: 1010.328369140625
INFO:root:Train (Epoch 96): Loss/seq after 00100 batchs: 1054.6162109375
INFO:root:Train (Epoch 96): Loss/seq after 00150 batchs: 946.9505615234375
INFO:root:Train (Epoch 96): Loss/seq after 00200 batchs: 1067.9078369140625
INFO:root:Train (Epoch 96): Loss/seq after 00250 batchs: 1177.365966796875
INFO:root:Train (Epoch 96): Loss/seq after 00300 batchs: 1142.4814453125
INFO:root:Train (Epoch 96): Loss/seq after 00350 batchs: 1062.5032958984375
INFO:root:Train (Epoch 96): Loss/seq after 00400 batchs: 1078.140869140625
INFO:root:Train (Epoch 96): Loss/seq after 00450 batchs: 1041.4471435546875
INFO:root:Train (Epoch 96): Loss/seq after 00500 batchs: 1018.8648071289062
INFO:root:Train (Epoch 96): Loss/seq after 00550 batchs: 982.7529296875
INFO:root:Train (Epoch 96): Loss/seq after 00600 batchs: 945.7099609375
INFO:root:Train (Epoch 96): Loss/seq after 00650 batchs: 956.6865234375
INFO:root:Train (Epoch 96): Loss/seq after 00700 batchs: 936.509033203125
INFO:root:Train (Epoch 96): Loss/seq after 00750 batchs: 963.58984375
INFO:root:Train (Epoch 96): Loss/seq after 00800 batchs: 954.6475219726562
INFO:root:Train (Epoch 96): Loss/seq after 00850 batchs: 924.8533935546875
INFO:root:Train (Epoch 96): Loss/seq after 00900 batchs: 905.472900390625
INFO:root:Train (Epoch 96): Loss/seq after 00950 batchs: 915.4251708984375
INFO:root:Train (Epoch 96): Loss/seq after 01000 batchs: 909.4422607421875
INFO:root:Train (Epoch 96): Loss/seq after 01050 batchs: 890.2446899414062
INFO:root:Train (Epoch 96): Loss/seq after 01100 batchs: 874.7371826171875
INFO:root:Train (Epoch 96): Loss/seq after 01150 batchs: 851.9981689453125
INFO:root:Train (Epoch 96): Loss/seq after 01200 batchs: 851.0538940429688
INFO:root:Train (Epoch 96): Loss/seq after 01250 batchs: 846.5869140625
INFO:root:Train (Epoch 96): Loss/seq after 01300 batchs: 837.24951171875
INFO:root:Train (Epoch 96): Loss/seq after 01350 batchs: 828.6702270507812
INFO:root:Train (Epoch 96): Loss/seq after 01400 batchs: 845.6868286132812
INFO:root:Train (Epoch 96): Loss/seq after 01450 batchs: 843.54150390625
INFO:root:Train (Epoch 96): Loss/seq after 01500 batchs: 845.287353515625
INFO:root:Train (Epoch 96): Loss/seq after 01550 batchs: 847.1539916992188
INFO:root:Train (Epoch 96): Loss/seq after 01600 batchs: 838.2098388671875
INFO:root:Train (Epoch 96): Loss/seq after 01650 batchs: 832.96875
INFO:root:Train (Epoch 96): Loss/seq after 01700 batchs: 830.3550415039062
INFO:root:Train (Epoch 96): Loss/seq after 01750 batchs: 824.7443237304688
INFO:root:Train (Epoch 96): Loss/seq after 01800 batchs: 818.7276000976562
INFO:root:Train (Epoch 96): Loss/seq after 01850 batchs: 811.896240234375
INFO:root:Train (Epoch 96): Loss/seq after 01900 batchs: 811.885009765625
INFO:root:Train (Epoch 96): Loss/seq after 01950 batchs: 807.9825439453125
INFO:root:Train (Epoch 96): Loss/seq after 02000 batchs: 804.0650024414062
INFO:root:Train (Epoch 96): Loss/seq after 02050 batchs: 800.7882080078125
INFO:root:Train (Epoch 96): Loss/seq after 02100 batchs: 795.1253662109375
INFO:root:Train (Epoch 96): Loss/seq after 02150 batchs: 790.9401245117188
INFO:root:Train (Epoch 96): Loss/seq after 02200 batchs: 785.607666015625
INFO:root:Train (Epoch 96): Loss/seq after 02250 batchs: 785.8182983398438
INFO:root:Train (Epoch 96): Loss/seq after 02300 batchs: 790.2377319335938
INFO:root:Train (Epoch 96): Loss/seq after 02350 batchs: 783.0842895507812
INFO:root:Train (Epoch 96): Loss/seq after 02400 batchs: 781.7040405273438
INFO:root:Train (Epoch 96): Loss/seq after 02450 batchs: 774.119140625
INFO:root:Train (Epoch 96): Loss/seq after 02500 batchs: 762.0885009765625
INFO:root:Train (Epoch 96): Loss/seq after 02550 batchs: 753.0562744140625
INFO:root:Train (Epoch 96): Loss/seq after 02600 batchs: 751.0488891601562
INFO:root:Train (Epoch 96): Loss/seq after 02650 batchs: 747.4703369140625
INFO:root:Train (Epoch 96): Loss/seq after 02700 batchs: 744.3897705078125
INFO:root:Train (Epoch 96): Loss/seq after 02750 batchs: 764.9884643554688
INFO:root:Train (Epoch 96): Loss/seq after 02800 batchs: 768.4738159179688
INFO:root:Train (Epoch 96): Loss/seq after 02850 batchs: 768.0526123046875
INFO:root:Train (Epoch 96): Loss/seq after 02900 batchs: 768.8153686523438
INFO:root:Train (Epoch 96): Loss/seq after 02950 batchs: 765.807861328125
INFO:root:Train (Epoch 96): Loss/seq after 03000 batchs: 768.703857421875
INFO:root:Train (Epoch 96): Loss/seq after 03050 batchs: 773.2257690429688
INFO:root:Train (Epoch 96): Loss/seq after 03100 batchs: 778.1284790039062
INFO:root:Train (Epoch 96): Loss/seq after 03150 batchs: 783.737060546875
INFO:root:Train (Epoch 96): Loss/seq after 03200 batchs: 790.4231567382812
INFO:root:Train (Epoch 96): Loss/seq after 03250 batchs: 795.4666748046875
INFO:root:Train (Epoch 96): Loss/seq after 03300 batchs: 794.8272705078125
INFO:root:Train (Epoch 96): Loss/seq after 03350 batchs: 794.263916015625
INFO:root:Train (Epoch 96): Loss/seq after 03400 batchs: 787.3870239257812
INFO:root:Train (Epoch 96): Loss/seq after 03450 batchs: 783.5374145507812
INFO:root:Train (Epoch 96): Loss/seq after 03500 batchs: 783.049560546875
INFO:root:Train (Epoch 96): Loss/seq after 03550 batchs: 778.6826782226562
INFO:root:Train (Epoch 96): Loss/seq after 03600 batchs: 786.1090698242188
INFO:root:Train (Epoch 96): Loss/seq after 03650 batchs: 782.200439453125
INFO:root:Train (Epoch 96): Loss/seq after 03700 batchs: 783.1573486328125
INFO:root:Train (Epoch 96): Loss/seq after 03750 batchs: 786.658447265625
INFO:root:Train (Epoch 96): Loss/seq after 03800 batchs: 782.1560668945312
INFO:root:Train (Epoch 96): Loss/seq after 03850 batchs: 780.4813842773438
INFO:root:Train (Epoch 96): Loss/seq after 03900 batchs: 784.4902954101562
INFO:root:Train (Epoch 96): Loss/seq after 03950 batchs: 788.565185546875
INFO:root:Train (Epoch 96): Loss/seq after 04000 batchs: 783.5238647460938
INFO:root:Train (Epoch 96): Loss/seq after 04050 batchs: 777.974609375
INFO:root:Train (Epoch 96): Loss/seq after 04100 batchs: 774.6687622070312
INFO:root:Train (Epoch 96): Loss/seq after 04150 batchs: 772.8174438476562
INFO:root:Train (Epoch 96): Loss/seq after 04200 batchs: 770.3418579101562
INFO:root:Train (Epoch 96): Loss/seq after 04250 batchs: 767.6517333984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 96): Loss/seq after 00000 batches: 564.049560546875
INFO:root:# Valid (Epoch 96): Loss/seq after 00050 batches: 714.72607421875
INFO:root:# Valid (Epoch 96): Loss/seq after 00100 batches: 944.1784057617188
INFO:root:# Valid (Epoch 96): Loss/seq after 00150 batches: 714.0394287109375
INFO:root:# Valid (Epoch 96): Loss/seq after 00200 batches: 663.269287109375
INFO:root:Artifacts: Make stick videos for epoch 96
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_96_on_20220413_231923.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_96_index_338_on_20220413_231923.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 97): Loss/seq after 00000 batchs: 1281.058349609375
INFO:root:Train (Epoch 97): Loss/seq after 00050 batchs: 1021.4259033203125
INFO:root:Train (Epoch 97): Loss/seq after 00100 batchs: 1052.1627197265625
INFO:root:Train (Epoch 97): Loss/seq after 00150 batchs: 948.189453125
INFO:root:Train (Epoch 97): Loss/seq after 00200 batchs: 1059.390869140625
INFO:root:Train (Epoch 97): Loss/seq after 00250 batchs: 1169.918701171875
INFO:root:Train (Epoch 97): Loss/seq after 00300 batchs: 1135.4395751953125
INFO:root:Train (Epoch 97): Loss/seq after 00350 batchs: 1054.0499267578125
INFO:root:Train (Epoch 97): Loss/seq after 00400 batchs: 1066.089599609375
INFO:root:Train (Epoch 97): Loss/seq after 00450 batchs: 1030.5247802734375
INFO:root:Train (Epoch 97): Loss/seq after 00500 batchs: 1009.8155517578125
INFO:root:Train (Epoch 97): Loss/seq after 00550 batchs: 973.4168701171875
INFO:root:Train (Epoch 97): Loss/seq after 00600 batchs: 937.3556518554688
INFO:root:Train (Epoch 97): Loss/seq after 00650 batchs: 946.9431762695312
INFO:root:Train (Epoch 97): Loss/seq after 00700 batchs: 928.119873046875
INFO:root:Train (Epoch 97): Loss/seq after 00750 batchs: 959.2169189453125
INFO:root:Train (Epoch 97): Loss/seq after 00800 batchs: 951.274658203125
INFO:root:Train (Epoch 97): Loss/seq after 00850 batchs: 921.4266967773438
INFO:root:Train (Epoch 97): Loss/seq after 00900 batchs: 901.7367553710938
INFO:root:Train (Epoch 97): Loss/seq after 00950 batchs: 913.9119873046875
INFO:root:Train (Epoch 97): Loss/seq after 01000 batchs: 908.3497924804688
INFO:root:Train (Epoch 97): Loss/seq after 01050 batchs: 889.4835205078125
INFO:root:Train (Epoch 97): Loss/seq after 01100 batchs: 873.62158203125
INFO:root:Train (Epoch 97): Loss/seq after 01150 batchs: 851.399169921875
INFO:root:Train (Epoch 97): Loss/seq after 01200 batchs: 850.6954345703125
INFO:root:Train (Epoch 97): Loss/seq after 01250 batchs: 846.5942993164062
INFO:root:Train (Epoch 97): Loss/seq after 01300 batchs: 838.1812133789062
INFO:root:Train (Epoch 97): Loss/seq after 01350 batchs: 829.2958374023438
INFO:root:Train (Epoch 97): Loss/seq after 01400 batchs: 846.0277099609375
INFO:root:Train (Epoch 97): Loss/seq after 01450 batchs: 843.7916870117188
INFO:root:Train (Epoch 97): Loss/seq after 01500 batchs: 845.7632446289062
INFO:root:Train (Epoch 97): Loss/seq after 01550 batchs: 846.8778076171875
INFO:root:Train (Epoch 97): Loss/seq after 01600 batchs: 837.5939331054688
INFO:root:Train (Epoch 97): Loss/seq after 01650 batchs: 831.8846435546875
INFO:root:Train (Epoch 97): Loss/seq after 01700 batchs: 829.1954956054688
INFO:root:Train (Epoch 97): Loss/seq after 01750 batchs: 823.3773193359375
INFO:root:Train (Epoch 97): Loss/seq after 01800 batchs: 817.13671875
INFO:root:Train (Epoch 97): Loss/seq after 01850 batchs: 810.0968627929688
INFO:root:Train (Epoch 97): Loss/seq after 01900 batchs: 809.5594482421875
INFO:root:Train (Epoch 97): Loss/seq after 01950 batchs: 805.189208984375
INFO:root:Train (Epoch 97): Loss/seq after 02000 batchs: 801.0729370117188
INFO:root:Train (Epoch 97): Loss/seq after 02050 batchs: 797.7533569335938
INFO:root:Train (Epoch 97): Loss/seq after 02100 batchs: 792.10986328125
INFO:root:Train (Epoch 97): Loss/seq after 02150 batchs: 787.7833862304688
INFO:root:Train (Epoch 97): Loss/seq after 02200 batchs: 782.2897338867188
INFO:root:Train (Epoch 97): Loss/seq after 02250 batchs: 782.1935424804688
INFO:root:Train (Epoch 97): Loss/seq after 02300 batchs: 787.1280517578125
INFO:root:Train (Epoch 97): Loss/seq after 02350 batchs: 780.1967163085938
INFO:root:Train (Epoch 97): Loss/seq after 02400 batchs: 778.7578735351562
INFO:root:Train (Epoch 97): Loss/seq after 02450 batchs: 771.14990234375
INFO:root:Train (Epoch 97): Loss/seq after 02500 batchs: 759.1502685546875
INFO:root:Train (Epoch 97): Loss/seq after 02550 batchs: 750.1735229492188
INFO:root:Train (Epoch 97): Loss/seq after 02600 batchs: 748.1868896484375
INFO:root:Train (Epoch 97): Loss/seq after 02650 batchs: 744.5811157226562
INFO:root:Train (Epoch 97): Loss/seq after 02700 batchs: 741.5532836914062
INFO:root:Train (Epoch 97): Loss/seq after 02750 batchs: 761.744873046875
INFO:root:Train (Epoch 97): Loss/seq after 02800 batchs: 764.9586791992188
INFO:root:Train (Epoch 97): Loss/seq after 02850 batchs: 764.3915405273438
INFO:root:Train (Epoch 97): Loss/seq after 02900 batchs: 765.13623046875
INFO:root:Train (Epoch 97): Loss/seq after 02950 batchs: 762.2344970703125
INFO:root:Train (Epoch 97): Loss/seq after 03000 batchs: 765.0775146484375
INFO:root:Train (Epoch 97): Loss/seq after 03050 batchs: 769.4989013671875
INFO:root:Train (Epoch 97): Loss/seq after 03100 batchs: 775.3091430664062
INFO:root:Train (Epoch 97): Loss/seq after 03150 batchs: 781.5963134765625
INFO:root:Train (Epoch 97): Loss/seq after 03200 batchs: 788.980224609375
INFO:root:Train (Epoch 97): Loss/seq after 03250 batchs: 794.232421875
INFO:root:Train (Epoch 97): Loss/seq after 03300 batchs: 792.788330078125
INFO:root:Train (Epoch 97): Loss/seq after 03350 batchs: 791.7664184570312
INFO:root:Train (Epoch 97): Loss/seq after 03400 batchs: 784.8329467773438
INFO:root:Train (Epoch 97): Loss/seq after 03450 batchs: 781.0803833007812
INFO:root:Train (Epoch 97): Loss/seq after 03500 batchs: 780.0127563476562
INFO:root:Train (Epoch 97): Loss/seq after 03550 batchs: 775.4453125
INFO:root:Train (Epoch 97): Loss/seq after 03600 batchs: 782.5927734375
INFO:root:Train (Epoch 97): Loss/seq after 03650 batchs: 778.3418579101562
INFO:root:Train (Epoch 97): Loss/seq after 03700 batchs: 778.9395751953125
INFO:root:Train (Epoch 97): Loss/seq after 03750 batchs: 782.5040893554688
INFO:root:Train (Epoch 97): Loss/seq after 03800 batchs: 777.9793701171875
INFO:root:Train (Epoch 97): Loss/seq after 03850 batchs: 776.2083740234375
INFO:root:Train (Epoch 97): Loss/seq after 03900 batchs: 780.3950805664062
INFO:root:Train (Epoch 97): Loss/seq after 03950 batchs: 784.3916625976562
INFO:root:Train (Epoch 97): Loss/seq after 04000 batchs: 779.360107421875
INFO:root:Train (Epoch 97): Loss/seq after 04050 batchs: 773.8486328125
INFO:root:Train (Epoch 97): Loss/seq after 04100 batchs: 770.5504150390625
INFO:root:Train (Epoch 97): Loss/seq after 04150 batchs: 768.6945190429688
INFO:root:Train (Epoch 97): Loss/seq after 04200 batchs: 766.0355834960938
INFO:root:Train (Epoch 97): Loss/seq after 04250 batchs: 763.2662963867188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 97): Loss/seq after 00000 batches: 551.2337036132812
INFO:root:# Valid (Epoch 97): Loss/seq after 00050 batches: 720.8090209960938
INFO:root:# Valid (Epoch 97): Loss/seq after 00100 batches: 953.386962890625
INFO:root:# Valid (Epoch 97): Loss/seq after 00150 batches: 718.410888671875
INFO:root:# Valid (Epoch 97): Loss/seq after 00200 batches: 664.5692749023438
INFO:root:Artifacts: Make stick videos for epoch 97
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_97_on_20220413_232441.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_97_index_274_on_20220413_232441.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 98): Loss/seq after 00000 batchs: 1252.5361328125
INFO:root:Train (Epoch 98): Loss/seq after 00050 batchs: 990.8845825195312
INFO:root:Train (Epoch 98): Loss/seq after 00100 batchs: 1045.1781005859375
INFO:root:Train (Epoch 98): Loss/seq after 00150 batchs: 936.5965576171875
INFO:root:Train (Epoch 98): Loss/seq after 00200 batchs: 1051.2879638671875
INFO:root:Train (Epoch 98): Loss/seq after 00250 batchs: 1168.871826171875
INFO:root:Train (Epoch 98): Loss/seq after 00300 batchs: 1134.1041259765625
INFO:root:Train (Epoch 98): Loss/seq after 00350 batchs: 1054.498779296875
INFO:root:Train (Epoch 98): Loss/seq after 00400 batchs: 1071.2288818359375
INFO:root:Train (Epoch 98): Loss/seq after 00450 batchs: 1035.1524658203125
INFO:root:Train (Epoch 98): Loss/seq after 00500 batchs: 1012.9118041992188
INFO:root:Train (Epoch 98): Loss/seq after 00550 batchs: 976.3405151367188
INFO:root:Train (Epoch 98): Loss/seq after 00600 batchs: 938.6069946289062
INFO:root:Train (Epoch 98): Loss/seq after 00650 batchs: 948.519775390625
INFO:root:Train (Epoch 98): Loss/seq after 00700 batchs: 928.58447265625
INFO:root:Train (Epoch 98): Loss/seq after 00750 batchs: 955.6708374023438
INFO:root:Train (Epoch 98): Loss/seq after 00800 batchs: 947.4132080078125
INFO:root:Train (Epoch 98): Loss/seq after 00850 batchs: 918.3074340820312
INFO:root:Train (Epoch 98): Loss/seq after 00900 batchs: 899.4745483398438
INFO:root:Train (Epoch 98): Loss/seq after 00950 batchs: 910.8511352539062
INFO:root:Train (Epoch 98): Loss/seq after 01000 batchs: 905.0161743164062
INFO:root:Train (Epoch 98): Loss/seq after 01050 batchs: 887.9664916992188
INFO:root:Train (Epoch 98): Loss/seq after 01100 batchs: 872.5621948242188
INFO:root:Train (Epoch 98): Loss/seq after 01150 batchs: 850.09765625
INFO:root:Train (Epoch 98): Loss/seq after 01200 batchs: 849.40771484375
INFO:root:Train (Epoch 98): Loss/seq after 01250 batchs: 844.3934936523438
INFO:root:Train (Epoch 98): Loss/seq after 01300 batchs: 835.0955200195312
INFO:root:Train (Epoch 98): Loss/seq after 01350 batchs: 826.0562133789062
INFO:root:Train (Epoch 98): Loss/seq after 01400 batchs: 844.1119384765625
INFO:root:Train (Epoch 98): Loss/seq after 01450 batchs: 841.4252319335938
INFO:root:Train (Epoch 98): Loss/seq after 01500 batchs: 843.1160888671875
INFO:root:Train (Epoch 98): Loss/seq after 01550 batchs: 844.3157958984375
INFO:root:Train (Epoch 98): Loss/seq after 01600 batchs: 834.828125
INFO:root:Train (Epoch 98): Loss/seq after 01650 batchs: 829.49609375
INFO:root:Train (Epoch 98): Loss/seq after 01700 batchs: 827.0263061523438
INFO:root:Train (Epoch 98): Loss/seq after 01750 batchs: 821.1840209960938
INFO:root:Train (Epoch 98): Loss/seq after 01800 batchs: 814.8630981445312
INFO:root:Train (Epoch 98): Loss/seq after 01850 batchs: 808.11279296875
INFO:root:Train (Epoch 98): Loss/seq after 01900 batchs: 807.7388916015625
INFO:root:Train (Epoch 98): Loss/seq after 01950 batchs: 803.4224853515625
INFO:root:Train (Epoch 98): Loss/seq after 02000 batchs: 799.4222412109375
INFO:root:Train (Epoch 98): Loss/seq after 02050 batchs: 795.837890625
INFO:root:Train (Epoch 98): Loss/seq after 02100 batchs: 790.011474609375
INFO:root:Train (Epoch 98): Loss/seq after 02150 batchs: 785.718994140625
INFO:root:Train (Epoch 98): Loss/seq after 02200 batchs: 780.2781982421875
INFO:root:Train (Epoch 98): Loss/seq after 02250 batchs: 780.2211303710938
INFO:root:Train (Epoch 98): Loss/seq after 02300 batchs: 785.60693359375
INFO:root:Train (Epoch 98): Loss/seq after 02350 batchs: 778.3901977539062
INFO:root:Train (Epoch 98): Loss/seq after 02400 batchs: 776.75537109375
INFO:root:Train (Epoch 98): Loss/seq after 02450 batchs: 769.1192016601562
INFO:root:Train (Epoch 98): Loss/seq after 02500 batchs: 757.1634521484375
INFO:root:Train (Epoch 98): Loss/seq after 02550 batchs: 748.181884765625
INFO:root:Train (Epoch 98): Loss/seq after 02600 batchs: 746.0584106445312
INFO:root:Train (Epoch 98): Loss/seq after 02650 batchs: 742.414306640625
INFO:root:Train (Epoch 98): Loss/seq after 02700 batchs: 739.3981323242188
INFO:root:Train (Epoch 98): Loss/seq after 02750 batchs: 758.9354248046875
INFO:root:Train (Epoch 98): Loss/seq after 02800 batchs: 762.0060424804688
INFO:root:Train (Epoch 98): Loss/seq after 02850 batchs: 761.1502075195312
INFO:root:Train (Epoch 98): Loss/seq after 02900 batchs: 761.716552734375
INFO:root:Train (Epoch 98): Loss/seq after 02950 batchs: 758.7564086914062
INFO:root:Train (Epoch 98): Loss/seq after 03000 batchs: 761.65869140625
INFO:root:Train (Epoch 98): Loss/seq after 03050 batchs: 766.4047241210938
INFO:root:Train (Epoch 98): Loss/seq after 03100 batchs: 771.1777954101562
INFO:root:Train (Epoch 98): Loss/seq after 03150 batchs: 776.7105712890625
INFO:root:Train (Epoch 98): Loss/seq after 03200 batchs: 784.2438354492188
INFO:root:Train (Epoch 98): Loss/seq after 03250 batchs: 788.9908447265625
INFO:root:Train (Epoch 98): Loss/seq after 03300 batchs: 788.691650390625
INFO:root:Train (Epoch 98): Loss/seq after 03350 batchs: 788.2001342773438
INFO:root:Train (Epoch 98): Loss/seq after 03400 batchs: 781.3595581054688
INFO:root:Train (Epoch 98): Loss/seq after 03450 batchs: 777.69140625
INFO:root:Train (Epoch 98): Loss/seq after 03500 batchs: 777.16650390625
INFO:root:Train (Epoch 98): Loss/seq after 03550 batchs: 772.7283935546875
INFO:root:Train (Epoch 98): Loss/seq after 03600 batchs: 780.0354614257812
INFO:root:Train (Epoch 98): Loss/seq after 03650 batchs: 775.7941284179688
INFO:root:Train (Epoch 98): Loss/seq after 03700 batchs: 776.4929809570312
INFO:root:Train (Epoch 98): Loss/seq after 03750 batchs: 780.0629272460938
INFO:root:Train (Epoch 98): Loss/seq after 03800 batchs: 775.5850830078125
INFO:root:Train (Epoch 98): Loss/seq after 03850 batchs: 773.8303833007812
INFO:root:Train (Epoch 98): Loss/seq after 03900 batchs: 777.9364013671875
INFO:root:Train (Epoch 98): Loss/seq after 03950 batchs: 781.9346923828125
INFO:root:Train (Epoch 98): Loss/seq after 04000 batchs: 776.9570922851562
INFO:root:Train (Epoch 98): Loss/seq after 04050 batchs: 771.3869018554688
INFO:root:Train (Epoch 98): Loss/seq after 04100 batchs: 768.159912109375
INFO:root:Train (Epoch 98): Loss/seq after 04150 batchs: 766.38916015625
INFO:root:Train (Epoch 98): Loss/seq after 04200 batchs: 763.6680908203125
INFO:root:Train (Epoch 98): Loss/seq after 04250 batchs: 760.8701171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 98): Loss/seq after 00000 batches: 549.4436645507812
INFO:root:# Valid (Epoch 98): Loss/seq after 00050 batches: 714.3998413085938
INFO:root:# Valid (Epoch 98): Loss/seq after 00100 batches: 943.7362670898438
INFO:root:# Valid (Epoch 98): Loss/seq after 00150 batches: 712.4539794921875
INFO:root:# Valid (Epoch 98): Loss/seq after 00200 batches: 661.0993041992188
INFO:root:Artifacts: Make stick videos for epoch 98
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_98_on_20220413_233000.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_98_index_1907_on_20220413_233000.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 99): Loss/seq after 00000 batchs: 1368.85791015625
INFO:root:Train (Epoch 99): Loss/seq after 00050 batchs: 996.9674682617188
INFO:root:Train (Epoch 99): Loss/seq after 00100 batchs: 1038.2169189453125
INFO:root:Train (Epoch 99): Loss/seq after 00150 batchs: 930.6859741210938
INFO:root:Train (Epoch 99): Loss/seq after 00200 batchs: 1044.2708740234375
INFO:root:Train (Epoch 99): Loss/seq after 00250 batchs: 1159.1112060546875
INFO:root:Train (Epoch 99): Loss/seq after 00300 batchs: 1125.7252197265625
INFO:root:Train (Epoch 99): Loss/seq after 00350 batchs: 1046.794189453125
INFO:root:Train (Epoch 99): Loss/seq after 00400 batchs: 1059.8868408203125
INFO:root:Train (Epoch 99): Loss/seq after 00450 batchs: 1024.933349609375
INFO:root:Train (Epoch 99): Loss/seq after 00500 batchs: 1003.480224609375
INFO:root:Train (Epoch 99): Loss/seq after 00550 batchs: 966.708740234375
INFO:root:Train (Epoch 99): Loss/seq after 00600 batchs: 929.763916015625
INFO:root:Train (Epoch 99): Loss/seq after 00650 batchs: 938.359130859375
INFO:root:Train (Epoch 99): Loss/seq after 00700 batchs: 918.5067138671875
INFO:root:Train (Epoch 99): Loss/seq after 00750 batchs: 949.182861328125
INFO:root:Train (Epoch 99): Loss/seq after 00800 batchs: 941.2396850585938
INFO:root:Train (Epoch 99): Loss/seq after 00850 batchs: 911.9503784179688
INFO:root:Train (Epoch 99): Loss/seq after 00900 batchs: 892.951171875
INFO:root:Train (Epoch 99): Loss/seq after 00950 batchs: 905.41357421875
INFO:root:Train (Epoch 99): Loss/seq after 01000 batchs: 901.4964599609375
INFO:root:Train (Epoch 99): Loss/seq after 01050 batchs: 882.671875
INFO:root:Train (Epoch 99): Loss/seq after 01100 batchs: 868.1924438476562
INFO:root:Train (Epoch 99): Loss/seq after 01150 batchs: 846.0501708984375
INFO:root:Train (Epoch 99): Loss/seq after 01200 batchs: 845.2825317382812
INFO:root:Train (Epoch 99): Loss/seq after 01250 batchs: 840.3372192382812
INFO:root:Train (Epoch 99): Loss/seq after 01300 batchs: 831.2975463867188
INFO:root:Train (Epoch 99): Loss/seq after 01350 batchs: 821.7012329101562
INFO:root:Train (Epoch 99): Loss/seq after 01400 batchs: 837.6012573242188
INFO:root:Train (Epoch 99): Loss/seq after 01450 batchs: 834.857666015625
INFO:root:Train (Epoch 99): Loss/seq after 01500 batchs: 836.9398803710938
INFO:root:Train (Epoch 99): Loss/seq after 01550 batchs: 838.5015869140625
INFO:root:Train (Epoch 99): Loss/seq after 01600 batchs: 829.6300048828125
INFO:root:Train (Epoch 99): Loss/seq after 01650 batchs: 823.7252197265625
INFO:root:Train (Epoch 99): Loss/seq after 01700 batchs: 821.2190551757812
INFO:root:Train (Epoch 99): Loss/seq after 01750 batchs: 815.5538330078125
INFO:root:Train (Epoch 99): Loss/seq after 01800 batchs: 809.3010864257812
INFO:root:Train (Epoch 99): Loss/seq after 01850 batchs: 802.7106323242188
INFO:root:Train (Epoch 99): Loss/seq after 01900 batchs: 801.8426513671875
INFO:root:Train (Epoch 99): Loss/seq after 01950 batchs: 798.0311889648438
INFO:root:Train (Epoch 99): Loss/seq after 02000 batchs: 793.8692016601562
INFO:root:Train (Epoch 99): Loss/seq after 02050 batchs: 790.3155517578125
INFO:root:Train (Epoch 99): Loss/seq after 02100 batchs: 784.720458984375
INFO:root:Train (Epoch 99): Loss/seq after 02150 batchs: 780.4754028320312
INFO:root:Train (Epoch 99): Loss/seq after 02200 batchs: 775.2877807617188
INFO:root:Train (Epoch 99): Loss/seq after 02250 batchs: 774.894775390625
INFO:root:Train (Epoch 99): Loss/seq after 02300 batchs: 777.79296875
INFO:root:Train (Epoch 99): Loss/seq after 02350 batchs: 770.5350952148438
INFO:root:Train (Epoch 99): Loss/seq after 02400 batchs: 769.4171142578125
INFO:root:Train (Epoch 99): Loss/seq after 02450 batchs: 761.8810424804688
INFO:root:Train (Epoch 99): Loss/seq after 02500 batchs: 750.0488891601562
INFO:root:Train (Epoch 99): Loss/seq after 02550 batchs: 741.1722412109375
INFO:root:Train (Epoch 99): Loss/seq after 02600 batchs: 739.3333740234375
INFO:root:Train (Epoch 99): Loss/seq after 02650 batchs: 735.813232421875
INFO:root:Train (Epoch 99): Loss/seq after 02700 batchs: 732.763671875
INFO:root:Train (Epoch 99): Loss/seq after 02750 batchs: 749.4025268554688
INFO:root:Train (Epoch 99): Loss/seq after 02800 batchs: 751.720703125
INFO:root:Train (Epoch 99): Loss/seq after 02850 batchs: 751.3704833984375
INFO:root:Train (Epoch 99): Loss/seq after 02900 batchs: 751.8751220703125
INFO:root:Train (Epoch 99): Loss/seq after 02950 batchs: 748.8844604492188
INFO:root:Train (Epoch 99): Loss/seq after 03000 batchs: 751.8846435546875
INFO:root:Train (Epoch 99): Loss/seq after 03050 batchs: 756.29052734375
INFO:root:Train (Epoch 99): Loss/seq after 03100 batchs: 761.1372680664062
INFO:root:Train (Epoch 99): Loss/seq after 03150 batchs: 767.7550659179688
INFO:root:Train (Epoch 99): Loss/seq after 03200 batchs: 774.66259765625
INFO:root:Train (Epoch 99): Loss/seq after 03250 batchs: 780.0008544921875
INFO:root:Train (Epoch 99): Loss/seq after 03300 batchs: 779.2213134765625
INFO:root:Train (Epoch 99): Loss/seq after 03350 batchs: 779.0088500976562
INFO:root:Train (Epoch 99): Loss/seq after 03400 batchs: 772.2713012695312
INFO:root:Train (Epoch 99): Loss/seq after 03450 batchs: 768.615966796875
INFO:root:Train (Epoch 99): Loss/seq after 03500 batchs: 767.9454956054688
INFO:root:Train (Epoch 99): Loss/seq after 03550 batchs: 763.4883422851562
INFO:root:Train (Epoch 99): Loss/seq after 03600 batchs: 770.8414916992188
INFO:root:Train (Epoch 99): Loss/seq after 03650 batchs: 767.03857421875
INFO:root:Train (Epoch 99): Loss/seq after 03700 batchs: 767.90283203125
INFO:root:Train (Epoch 99): Loss/seq after 03750 batchs: 771.5108642578125
INFO:root:Train (Epoch 99): Loss/seq after 03800 batchs: 767.092041015625
INFO:root:Train (Epoch 99): Loss/seq after 03850 batchs: 765.4558715820312
INFO:root:Train (Epoch 99): Loss/seq after 03900 batchs: 769.3482055664062
INFO:root:Train (Epoch 99): Loss/seq after 03950 batchs: 773.4476928710938
INFO:root:Train (Epoch 99): Loss/seq after 04000 batchs: 768.5692749023438
INFO:root:Train (Epoch 99): Loss/seq after 04050 batchs: 763.1361694335938
INFO:root:Train (Epoch 99): Loss/seq after 04100 batchs: 759.871826171875
INFO:root:Train (Epoch 99): Loss/seq after 04150 batchs: 758.1139526367188
INFO:root:Train (Epoch 99): Loss/seq after 04200 batchs: 755.637939453125
INFO:root:Train (Epoch 99): Loss/seq after 04250 batchs: 753.0264892578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 99): Loss/seq after 00000 batches: 550.5492553710938
INFO:root:# Valid (Epoch 99): Loss/seq after 00050 batches: 730.7438354492188
INFO:root:# Valid (Epoch 99): Loss/seq after 00100 batches: 940.094970703125
INFO:root:# Valid (Epoch 99): Loss/seq after 00150 batches: 713.6011352539062
INFO:root:# Valid (Epoch 99): Loss/seq after 00200 batches: 663.5918579101562
INFO:root:Artifacts: Make stick videos for epoch 99
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_99_on_20220413_233516.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_99_index_355_on_20220413_233516.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 100): Loss/seq after 00000 batchs: 1254.4609375
INFO:root:Train (Epoch 100): Loss/seq after 00050 batchs: 982.4939575195312
INFO:root:Train (Epoch 100): Loss/seq after 00100 batchs: 1031.49609375
INFO:root:Train (Epoch 100): Loss/seq after 00150 batchs: 925.48779296875
INFO:root:Train (Epoch 100): Loss/seq after 00200 batchs: 1051.2364501953125
INFO:root:Train (Epoch 100): Loss/seq after 00250 batchs: 1169.700927734375
INFO:root:Train (Epoch 100): Loss/seq after 00300 batchs: 1135.550537109375
INFO:root:Train (Epoch 100): Loss/seq after 00350 batchs: 1053.3353271484375
INFO:root:Train (Epoch 100): Loss/seq after 00400 batchs: 1065.9368896484375
INFO:root:Train (Epoch 100): Loss/seq after 00450 batchs: 1029.0286865234375
INFO:root:Train (Epoch 100): Loss/seq after 00500 batchs: 1005.9346313476562
INFO:root:Train (Epoch 100): Loss/seq after 00550 batchs: 969.6516723632812
INFO:root:Train (Epoch 100): Loss/seq after 00600 batchs: 931.8406372070312
INFO:root:Train (Epoch 100): Loss/seq after 00650 batchs: 939.2611083984375
INFO:root:Train (Epoch 100): Loss/seq after 00700 batchs: 919.25634765625
INFO:root:Train (Epoch 100): Loss/seq after 00750 batchs: 947.523681640625
INFO:root:Train (Epoch 100): Loss/seq after 00800 batchs: 939.51708984375
INFO:root:Train (Epoch 100): Loss/seq after 00850 batchs: 909.6912231445312
INFO:root:Train (Epoch 100): Loss/seq after 00900 batchs: 890.6200561523438
INFO:root:Train (Epoch 100): Loss/seq after 00950 batchs: 902.4453735351562
INFO:root:Train (Epoch 100): Loss/seq after 01000 batchs: 897.8809814453125
INFO:root:Train (Epoch 100): Loss/seq after 01050 batchs: 879.3782348632812
INFO:root:Train (Epoch 100): Loss/seq after 01100 batchs: 863.5454711914062
INFO:root:Train (Epoch 100): Loss/seq after 01150 batchs: 840.9732666015625
INFO:root:Train (Epoch 100): Loss/seq after 01200 batchs: 839.7889404296875
INFO:root:Train (Epoch 100): Loss/seq after 01250 batchs: 834.5704345703125
INFO:root:Train (Epoch 100): Loss/seq after 01300 batchs: 824.8199462890625
INFO:root:Train (Epoch 100): Loss/seq after 01350 batchs: 815.859130859375
INFO:root:Train (Epoch 100): Loss/seq after 01400 batchs: 831.5130004882812
INFO:root:Train (Epoch 100): Loss/seq after 01450 batchs: 829.107421875
INFO:root:Train (Epoch 100): Loss/seq after 01500 batchs: 831.0742797851562
INFO:root:Train (Epoch 100): Loss/seq after 01550 batchs: 832.3274536132812
INFO:root:Train (Epoch 100): Loss/seq after 01600 batchs: 823.1343994140625
INFO:root:Train (Epoch 100): Loss/seq after 01650 batchs: 817.6660766601562
INFO:root:Train (Epoch 100): Loss/seq after 01700 batchs: 815.7980346679688
INFO:root:Train (Epoch 100): Loss/seq after 01750 batchs: 810.1522827148438
INFO:root:Train (Epoch 100): Loss/seq after 01800 batchs: 803.9510498046875
INFO:root:Train (Epoch 100): Loss/seq after 01850 batchs: 797.0822143554688
INFO:root:Train (Epoch 100): Loss/seq after 01900 batchs: 796.3609619140625
INFO:root:Train (Epoch 100): Loss/seq after 01950 batchs: 792.3816528320312
INFO:root:Train (Epoch 100): Loss/seq after 02000 batchs: 788.587646484375
INFO:root:Train (Epoch 100): Loss/seq after 02050 batchs: 785.4072875976562
INFO:root:Train (Epoch 100): Loss/seq after 02100 batchs: 779.9043579101562
INFO:root:Train (Epoch 100): Loss/seq after 02150 batchs: 775.5914306640625
INFO:root:Train (Epoch 100): Loss/seq after 02200 batchs: 770.4138793945312
INFO:root:Train (Epoch 100): Loss/seq after 02250 batchs: 770.1688232421875
INFO:root:Train (Epoch 100): Loss/seq after 02300 batchs: 775.8341064453125
INFO:root:Train (Epoch 100): Loss/seq after 02350 batchs: 768.7915649414062
INFO:root:Train (Epoch 100): Loss/seq after 02400 batchs: 767.4360961914062
INFO:root:Train (Epoch 100): Loss/seq after 02450 batchs: 759.9253540039062
INFO:root:Train (Epoch 100): Loss/seq after 02500 batchs: 748.1449584960938
INFO:root:Train (Epoch 100): Loss/seq after 02550 batchs: 739.2908325195312
INFO:root:Train (Epoch 100): Loss/seq after 02600 batchs: 737.3372802734375
INFO:root:Train (Epoch 100): Loss/seq after 02650 batchs: 733.7611694335938
INFO:root:Train (Epoch 100): Loss/seq after 02700 batchs: 730.6618041992188
INFO:root:Train (Epoch 100): Loss/seq after 02750 batchs: 746.0164184570312
INFO:root:Train (Epoch 100): Loss/seq after 02800 batchs: 748.1683349609375
INFO:root:Train (Epoch 100): Loss/seq after 02850 batchs: 747.5965576171875
INFO:root:Train (Epoch 100): Loss/seq after 02900 batchs: 748.0797729492188
INFO:root:Train (Epoch 100): Loss/seq after 02950 batchs: 745.164794921875
INFO:root:Train (Epoch 100): Loss/seq after 03000 batchs: 748.232666015625
INFO:root:Train (Epoch 100): Loss/seq after 03050 batchs: 752.7603759765625
INFO:root:Train (Epoch 100): Loss/seq after 03100 batchs: 758.47900390625
INFO:root:Train (Epoch 100): Loss/seq after 03150 batchs: 764.9345092773438
INFO:root:Train (Epoch 100): Loss/seq after 03200 batchs: 771.909912109375
INFO:root:Train (Epoch 100): Loss/seq after 03250 batchs: 777.2742919921875
INFO:root:Train (Epoch 100): Loss/seq after 03300 batchs: 776.1239013671875
INFO:root:Train (Epoch 100): Loss/seq after 03350 batchs: 775.4522094726562
INFO:root:Train (Epoch 100): Loss/seq after 03400 batchs: 768.71630859375
INFO:root:Train (Epoch 100): Loss/seq after 03450 batchs: 765.1838989257812
INFO:root:Train (Epoch 100): Loss/seq after 03500 batchs: 764.2755126953125
INFO:root:Train (Epoch 100): Loss/seq after 03550 batchs: 759.8541259765625
INFO:root:Train (Epoch 100): Loss/seq after 03600 batchs: 767.170166015625
INFO:root:Train (Epoch 100): Loss/seq after 03650 batchs: 763.0086059570312
INFO:root:Train (Epoch 100): Loss/seq after 03700 batchs: 763.8156127929688
INFO:root:Train (Epoch 100): Loss/seq after 03750 batchs: 767.4236450195312
INFO:root:Train (Epoch 100): Loss/seq after 03800 batchs: 763.044921875
INFO:root:Train (Epoch 100): Loss/seq after 03850 batchs: 761.3784790039062
INFO:root:Train (Epoch 100): Loss/seq after 03900 batchs: 765.578369140625
INFO:root:Train (Epoch 100): Loss/seq after 03950 batchs: 769.3723754882812
INFO:root:Train (Epoch 100): Loss/seq after 04000 batchs: 764.46435546875
INFO:root:Train (Epoch 100): Loss/seq after 04050 batchs: 759.0499267578125
INFO:root:Train (Epoch 100): Loss/seq after 04100 batchs: 755.8648071289062
INFO:root:Train (Epoch 100): Loss/seq after 04150 batchs: 754.1665649414062
INFO:root:Train (Epoch 100): Loss/seq after 04200 batchs: 751.4609985351562
INFO:root:Train (Epoch 100): Loss/seq after 04250 batchs: 748.78857421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 100): Loss/seq after 00000 batches: 565.00244140625
INFO:root:# Valid (Epoch 100): Loss/seq after 00050 batches: 737.9019165039062
INFO:root:# Valid (Epoch 100): Loss/seq after 00100 batches: 914.0162963867188
INFO:root:# Valid (Epoch 100): Loss/seq after 00150 batches: 696.2537231445312
INFO:root:# Valid (Epoch 100): Loss/seq after 00200 batches: 649.4396362304688
INFO:root:Artifacts: Make stick videos for epoch 100
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_100_on_20220413_234034.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_100_index_328_on_20220413_234034.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 101): Loss/seq after 00000 batchs: 1335.36865234375
INFO:root:Train (Epoch 101): Loss/seq after 00050 batchs: 968.5166015625
INFO:root:Train (Epoch 101): Loss/seq after 00100 batchs: 1022.7674560546875
INFO:root:Train (Epoch 101): Loss/seq after 00150 batchs: 922.06201171875
INFO:root:Train (Epoch 101): Loss/seq after 00200 batchs: 1051.6627197265625
INFO:root:Train (Epoch 101): Loss/seq after 00250 batchs: 1162.3846435546875
INFO:root:Train (Epoch 101): Loss/seq after 00300 batchs: 1128.2508544921875
INFO:root:Train (Epoch 101): Loss/seq after 00350 batchs: 1045.0433349609375
INFO:root:Train (Epoch 101): Loss/seq after 00400 batchs: 1058.5467529296875
INFO:root:Train (Epoch 101): Loss/seq after 00450 batchs: 1022.3203125
INFO:root:Train (Epoch 101): Loss/seq after 00500 batchs: 1002.9063110351562
INFO:root:Train (Epoch 101): Loss/seq after 00550 batchs: 966.634521484375
INFO:root:Train (Epoch 101): Loss/seq after 00600 batchs: 929.6246337890625
INFO:root:Train (Epoch 101): Loss/seq after 00650 batchs: 938.83984375
INFO:root:Train (Epoch 101): Loss/seq after 00700 batchs: 918.9315795898438
INFO:root:Train (Epoch 101): Loss/seq after 00750 batchs: 951.601806640625
INFO:root:Train (Epoch 101): Loss/seq after 00800 batchs: 943.931640625
INFO:root:Train (Epoch 101): Loss/seq after 00850 batchs: 914.39208984375
INFO:root:Train (Epoch 101): Loss/seq after 00900 batchs: 894.7523193359375
INFO:root:Train (Epoch 101): Loss/seq after 00950 batchs: 903.9989624023438
INFO:root:Train (Epoch 101): Loss/seq after 01000 batchs: 899.3154296875
INFO:root:Train (Epoch 101): Loss/seq after 01050 batchs: 880.2025146484375
INFO:root:Train (Epoch 101): Loss/seq after 01100 batchs: 864.1444091796875
INFO:root:Train (Epoch 101): Loss/seq after 01150 batchs: 841.826416015625
INFO:root:Train (Epoch 101): Loss/seq after 01200 batchs: 840.784423828125
INFO:root:Train (Epoch 101): Loss/seq after 01250 batchs: 835.5400390625
INFO:root:Train (Epoch 101): Loss/seq after 01300 batchs: 825.7319946289062
INFO:root:Train (Epoch 101): Loss/seq after 01350 batchs: 816.8060302734375
INFO:root:Train (Epoch 101): Loss/seq after 01400 batchs: 833.1165161132812
INFO:root:Train (Epoch 101): Loss/seq after 01450 batchs: 830.3930053710938
INFO:root:Train (Epoch 101): Loss/seq after 01500 batchs: 832.0577392578125
INFO:root:Train (Epoch 101): Loss/seq after 01550 batchs: 832.920166015625
INFO:root:Train (Epoch 101): Loss/seq after 01600 batchs: 823.7225341796875
INFO:root:Train (Epoch 101): Loss/seq after 01650 batchs: 818.265869140625
INFO:root:Train (Epoch 101): Loss/seq after 01700 batchs: 816.1581420898438
INFO:root:Train (Epoch 101): Loss/seq after 01750 batchs: 810.481689453125
INFO:root:Train (Epoch 101): Loss/seq after 01800 batchs: 804.1414794921875
INFO:root:Train (Epoch 101): Loss/seq after 01850 batchs: 797.1248779296875
INFO:root:Train (Epoch 101): Loss/seq after 01900 batchs: 796.394775390625
INFO:root:Train (Epoch 101): Loss/seq after 01950 batchs: 792.1663818359375
INFO:root:Train (Epoch 101): Loss/seq after 02000 batchs: 787.9293823242188
INFO:root:Train (Epoch 101): Loss/seq after 02050 batchs: 784.1088256835938
INFO:root:Train (Epoch 101): Loss/seq after 02100 batchs: 778.4599609375
INFO:root:Train (Epoch 101): Loss/seq after 02150 batchs: 774.26904296875
INFO:root:Train (Epoch 101): Loss/seq after 02200 batchs: 768.9929809570312
INFO:root:Train (Epoch 101): Loss/seq after 02250 batchs: 768.2802734375
INFO:root:Train (Epoch 101): Loss/seq after 02300 batchs: 772.6217041015625
INFO:root:Train (Epoch 101): Loss/seq after 02350 batchs: 765.2953491210938
INFO:root:Train (Epoch 101): Loss/seq after 02400 batchs: 763.8097534179688
INFO:root:Train (Epoch 101): Loss/seq after 02450 batchs: 756.2562255859375
INFO:root:Train (Epoch 101): Loss/seq after 02500 batchs: 744.514404296875
INFO:root:Train (Epoch 101): Loss/seq after 02550 batchs: 735.6821899414062
INFO:root:Train (Epoch 101): Loss/seq after 02600 batchs: 733.5675659179688
INFO:root:Train (Epoch 101): Loss/seq after 02650 batchs: 729.9994506835938
INFO:root:Train (Epoch 101): Loss/seq after 02700 batchs: 726.768798828125
INFO:root:Train (Epoch 101): Loss/seq after 02750 batchs: 741.1271362304688
INFO:root:Train (Epoch 101): Loss/seq after 02800 batchs: 743.5377807617188
INFO:root:Train (Epoch 101): Loss/seq after 02850 batchs: 743.017822265625
INFO:root:Train (Epoch 101): Loss/seq after 02900 batchs: 743.4691162109375
INFO:root:Train (Epoch 101): Loss/seq after 02950 batchs: 740.6900024414062
INFO:root:Train (Epoch 101): Loss/seq after 03000 batchs: 743.791748046875
INFO:root:Train (Epoch 101): Loss/seq after 03050 batchs: 748.4064331054688
INFO:root:Train (Epoch 101): Loss/seq after 03100 batchs: 753.8412475585938
INFO:root:Train (Epoch 101): Loss/seq after 03150 batchs: 760.5208129882812
INFO:root:Train (Epoch 101): Loss/seq after 03200 batchs: 768.2694702148438
INFO:root:Train (Epoch 101): Loss/seq after 03250 batchs: 773.8615112304688
INFO:root:Train (Epoch 101): Loss/seq after 03300 batchs: 772.6920776367188
INFO:root:Train (Epoch 101): Loss/seq after 03350 batchs: 772.0579223632812
INFO:root:Train (Epoch 101): Loss/seq after 03400 batchs: 765.3790893554688
INFO:root:Train (Epoch 101): Loss/seq after 03450 batchs: 761.8870849609375
INFO:root:Train (Epoch 101): Loss/seq after 03500 batchs: 760.8563232421875
INFO:root:Train (Epoch 101): Loss/seq after 03550 batchs: 756.3614501953125
INFO:root:Train (Epoch 101): Loss/seq after 03600 batchs: 763.6627807617188
INFO:root:Train (Epoch 101): Loss/seq after 03650 batchs: 759.3993530273438
INFO:root:Train (Epoch 101): Loss/seq after 03700 batchs: 760.2401123046875
INFO:root:Train (Epoch 101): Loss/seq after 03750 batchs: 763.8530883789062
INFO:root:Train (Epoch 101): Loss/seq after 03800 batchs: 759.4944458007812
INFO:root:Train (Epoch 101): Loss/seq after 03850 batchs: 757.8063354492188
INFO:root:Train (Epoch 101): Loss/seq after 03900 batchs: 762.12939453125
INFO:root:Train (Epoch 101): Loss/seq after 03950 batchs: 766.2633056640625
INFO:root:Train (Epoch 101): Loss/seq after 04000 batchs: 761.3311767578125
INFO:root:Train (Epoch 101): Loss/seq after 04050 batchs: 755.9786376953125
INFO:root:Train (Epoch 101): Loss/seq after 04100 batchs: 752.7196044921875
INFO:root:Train (Epoch 101): Loss/seq after 04150 batchs: 751.0011596679688
INFO:root:Train (Epoch 101): Loss/seq after 04200 batchs: 748.3392944335938
INFO:root:Train (Epoch 101): Loss/seq after 04250 batchs: 745.6927490234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 101): Loss/seq after 00000 batches: 578.1092529296875
INFO:root:# Valid (Epoch 101): Loss/seq after 00050 batches: 705.6763305664062
INFO:root:# Valid (Epoch 101): Loss/seq after 00100 batches: 879.1514282226562
INFO:root:# Valid (Epoch 101): Loss/seq after 00150 batches: 667.380126953125
INFO:root:# Valid (Epoch 101): Loss/seq after 00200 batches: 625.4544677734375
INFO:root:Artifacts: Make stick videos for epoch 101
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_101_on_20220413_234550.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_101_index_797_on_20220413_234550.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 102): Loss/seq after 00000 batchs: 1443.07568359375
INFO:root:Train (Epoch 102): Loss/seq after 00050 batchs: 979.2598876953125
INFO:root:Train (Epoch 102): Loss/seq after 00100 batchs: 1035.924072265625
INFO:root:Train (Epoch 102): Loss/seq after 00150 batchs: 930.10595703125
INFO:root:Train (Epoch 102): Loss/seq after 00200 batchs: 1045.169677734375
INFO:root:Train (Epoch 102): Loss/seq after 00250 batchs: 1154.11572265625
INFO:root:Train (Epoch 102): Loss/seq after 00300 batchs: 1120.189697265625
INFO:root:Train (Epoch 102): Loss/seq after 00350 batchs: 1039.1185302734375
INFO:root:Train (Epoch 102): Loss/seq after 00400 batchs: 1050.7548828125
INFO:root:Train (Epoch 102): Loss/seq after 00450 batchs: 1015.5953369140625
INFO:root:Train (Epoch 102): Loss/seq after 00500 batchs: 992.29443359375
INFO:root:Train (Epoch 102): Loss/seq after 00550 batchs: 956.3600463867188
INFO:root:Train (Epoch 102): Loss/seq after 00600 batchs: 919.9344482421875
INFO:root:Train (Epoch 102): Loss/seq after 00650 batchs: 929.6630859375
INFO:root:Train (Epoch 102): Loss/seq after 00700 batchs: 915.1417236328125
INFO:root:Train (Epoch 102): Loss/seq after 00750 batchs: 945.649169921875
INFO:root:Train (Epoch 102): Loss/seq after 00800 batchs: 937.1519165039062
INFO:root:Train (Epoch 102): Loss/seq after 00850 batchs: 907.1043701171875
INFO:root:Train (Epoch 102): Loss/seq after 00900 batchs: 887.2186889648438
INFO:root:Train (Epoch 102): Loss/seq after 00950 batchs: 895.7656860351562
INFO:root:Train (Epoch 102): Loss/seq after 01000 batchs: 893.1309204101562
INFO:root:Train (Epoch 102): Loss/seq after 01050 batchs: 877.0150146484375
INFO:root:Train (Epoch 102): Loss/seq after 01100 batchs: 861.3496704101562
INFO:root:Train (Epoch 102): Loss/seq after 01150 batchs: 838.9559936523438
INFO:root:Train (Epoch 102): Loss/seq after 01200 batchs: 838.299072265625
INFO:root:Train (Epoch 102): Loss/seq after 01250 batchs: 833.2132568359375
INFO:root:Train (Epoch 102): Loss/seq after 01300 batchs: 823.5046997070312
INFO:root:Train (Epoch 102): Loss/seq after 01350 batchs: 814.0653686523438
INFO:root:Train (Epoch 102): Loss/seq after 01400 batchs: 828.8366088867188
INFO:root:Train (Epoch 102): Loss/seq after 01450 batchs: 826.2353515625
INFO:root:Train (Epoch 102): Loss/seq after 01500 batchs: 828.1507568359375
INFO:root:Train (Epoch 102): Loss/seq after 01550 batchs: 828.9133911132812
INFO:root:Train (Epoch 102): Loss/seq after 01600 batchs: 819.8222045898438
INFO:root:Train (Epoch 102): Loss/seq after 01650 batchs: 814.2470092773438
INFO:root:Train (Epoch 102): Loss/seq after 01700 batchs: 812.0973510742188
INFO:root:Train (Epoch 102): Loss/seq after 01750 batchs: 806.2161254882812
INFO:root:Train (Epoch 102): Loss/seq after 01800 batchs: 800.3826293945312
INFO:root:Train (Epoch 102): Loss/seq after 01850 batchs: 793.699462890625
INFO:root:Train (Epoch 102): Loss/seq after 01900 batchs: 792.851318359375
INFO:root:Train (Epoch 102): Loss/seq after 01950 batchs: 788.3736572265625
INFO:root:Train (Epoch 102): Loss/seq after 02000 batchs: 784.1258544921875
INFO:root:Train (Epoch 102): Loss/seq after 02050 batchs: 780.2808837890625
INFO:root:Train (Epoch 102): Loss/seq after 02100 batchs: 774.6680297851562
INFO:root:Train (Epoch 102): Loss/seq after 02150 batchs: 770.4174194335938
INFO:root:Train (Epoch 102): Loss/seq after 02200 batchs: 765.1634521484375
INFO:root:Train (Epoch 102): Loss/seq after 02250 batchs: 764.7625732421875
INFO:root:Train (Epoch 102): Loss/seq after 02300 batchs: 771.1078491210938
INFO:root:Train (Epoch 102): Loss/seq after 02350 batchs: 764.2329711914062
INFO:root:Train (Epoch 102): Loss/seq after 02400 batchs: 763.0264282226562
INFO:root:Train (Epoch 102): Loss/seq after 02450 batchs: 755.5408935546875
INFO:root:Train (Epoch 102): Loss/seq after 02500 batchs: 743.848388671875
INFO:root:Train (Epoch 102): Loss/seq after 02550 batchs: 735.09814453125
INFO:root:Train (Epoch 102): Loss/seq after 02600 batchs: 733.1514282226562
INFO:root:Train (Epoch 102): Loss/seq after 02650 batchs: 729.5505981445312
INFO:root:Train (Epoch 102): Loss/seq after 02700 batchs: 726.3604125976562
INFO:root:Train (Epoch 102): Loss/seq after 02750 batchs: 741.36328125
INFO:root:Train (Epoch 102): Loss/seq after 02800 batchs: 743.4725341796875
INFO:root:Train (Epoch 102): Loss/seq after 02850 batchs: 742.80517578125
INFO:root:Train (Epoch 102): Loss/seq after 02900 batchs: 743.17041015625
INFO:root:Train (Epoch 102): Loss/seq after 02950 batchs: 740.4445190429688
INFO:root:Train (Epoch 102): Loss/seq after 03000 batchs: 743.57958984375
INFO:root:Train (Epoch 102): Loss/seq after 03050 batchs: 747.7845458984375
INFO:root:Train (Epoch 102): Loss/seq after 03100 batchs: 753.2809448242188
INFO:root:Train (Epoch 102): Loss/seq after 03150 batchs: 759.0507202148438
INFO:root:Train (Epoch 102): Loss/seq after 03200 batchs: 766.6162109375
INFO:root:Train (Epoch 102): Loss/seq after 03250 batchs: 772.0542602539062
INFO:root:Train (Epoch 102): Loss/seq after 03300 batchs: 770.7174072265625
INFO:root:Train (Epoch 102): Loss/seq after 03350 batchs: 769.8008422851562
INFO:root:Train (Epoch 102): Loss/seq after 03400 batchs: 763.1060791015625
INFO:root:Train (Epoch 102): Loss/seq after 03450 batchs: 759.5757446289062
INFO:root:Train (Epoch 102): Loss/seq after 03500 batchs: 758.6676025390625
INFO:root:Train (Epoch 102): Loss/seq after 03550 batchs: 754.24267578125
INFO:root:Train (Epoch 102): Loss/seq after 03600 batchs: 761.6328735351562
INFO:root:Train (Epoch 102): Loss/seq after 03650 batchs: 757.3475952148438
INFO:root:Train (Epoch 102): Loss/seq after 03700 batchs: 758.3138427734375
INFO:root:Train (Epoch 102): Loss/seq after 03750 batchs: 761.971923828125
INFO:root:Train (Epoch 102): Loss/seq after 03800 batchs: 757.5883178710938
INFO:root:Train (Epoch 102): Loss/seq after 03850 batchs: 756.060302734375
INFO:root:Train (Epoch 102): Loss/seq after 03900 batchs: 760.366455078125
INFO:root:Train (Epoch 102): Loss/seq after 03950 batchs: 764.7230834960938
INFO:root:Train (Epoch 102): Loss/seq after 04000 batchs: 759.7471923828125
INFO:root:Train (Epoch 102): Loss/seq after 04050 batchs: 754.3746337890625
INFO:root:Train (Epoch 102): Loss/seq after 04100 batchs: 751.13330078125
INFO:root:Train (Epoch 102): Loss/seq after 04150 batchs: 749.4646606445312
INFO:root:Train (Epoch 102): Loss/seq after 04200 batchs: 746.6749877929688
INFO:root:Train (Epoch 102): Loss/seq after 04250 batchs: 743.9400634765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 102): Loss/seq after 00000 batches: 546.2920532226562
INFO:root:# Valid (Epoch 102): Loss/seq after 00050 batches: 718.7227783203125
INFO:root:# Valid (Epoch 102): Loss/seq after 00100 batches: 889.489013671875
INFO:root:# Valid (Epoch 102): Loss/seq after 00150 batches: 672.9813232421875
INFO:root:# Valid (Epoch 102): Loss/seq after 00200 batches: 626.2821044921875
INFO:root:Artifacts: Make stick videos for epoch 102
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_102_on_20220413_235107.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_102_index_259_on_20220413_235107.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 103): Loss/seq after 00000 batchs: 1367.6539306640625
INFO:root:Train (Epoch 103): Loss/seq after 00050 batchs: 968.3733520507812
INFO:root:Train (Epoch 103): Loss/seq after 00100 batchs: 1025.7784423828125
INFO:root:Train (Epoch 103): Loss/seq after 00150 batchs: 919.3956909179688
INFO:root:Train (Epoch 103): Loss/seq after 00200 batchs: 1037.908447265625
INFO:root:Train (Epoch 103): Loss/seq after 00250 batchs: 1148.9622802734375
INFO:root:Train (Epoch 103): Loss/seq after 00300 batchs: 1116.414306640625
INFO:root:Train (Epoch 103): Loss/seq after 00350 batchs: 1035.733154296875
INFO:root:Train (Epoch 103): Loss/seq after 00400 batchs: 1054.248779296875
INFO:root:Train (Epoch 103): Loss/seq after 00450 batchs: 1018.5093383789062
INFO:root:Train (Epoch 103): Loss/seq after 00500 batchs: 995.6781616210938
INFO:root:Train (Epoch 103): Loss/seq after 00550 batchs: 960.1259155273438
INFO:root:Train (Epoch 103): Loss/seq after 00600 batchs: 923.155029296875
INFO:root:Train (Epoch 103): Loss/seq after 00650 batchs: 929.9796752929688
INFO:root:Train (Epoch 103): Loss/seq after 00700 batchs: 912.2232666015625
INFO:root:Train (Epoch 103): Loss/seq after 00750 batchs: 940.6988525390625
INFO:root:Train (Epoch 103): Loss/seq after 00800 batchs: 932.5546875
INFO:root:Train (Epoch 103): Loss/seq after 00850 batchs: 902.7671508789062
INFO:root:Train (Epoch 103): Loss/seq after 00900 batchs: 883.2035522460938
INFO:root:Train (Epoch 103): Loss/seq after 00950 batchs: 890.5408325195312
INFO:root:Train (Epoch 103): Loss/seq after 01000 batchs: 884.9466552734375
INFO:root:Train (Epoch 103): Loss/seq after 01050 batchs: 868.5321655273438
INFO:root:Train (Epoch 103): Loss/seq after 01100 batchs: 852.7699584960938
INFO:root:Train (Epoch 103): Loss/seq after 01150 batchs: 830.6342163085938
INFO:root:Train (Epoch 103): Loss/seq after 01200 batchs: 830.1392822265625
INFO:root:Train (Epoch 103): Loss/seq after 01250 batchs: 825.1911010742188
INFO:root:Train (Epoch 103): Loss/seq after 01300 batchs: 815.164794921875
INFO:root:Train (Epoch 103): Loss/seq after 01350 batchs: 805.6129150390625
INFO:root:Train (Epoch 103): Loss/seq after 01400 batchs: 820.5867309570312
INFO:root:Train (Epoch 103): Loss/seq after 01450 batchs: 818.0397338867188
INFO:root:Train (Epoch 103): Loss/seq after 01500 batchs: 820.1092529296875
INFO:root:Train (Epoch 103): Loss/seq after 01550 batchs: 821.1866455078125
INFO:root:Train (Epoch 103): Loss/seq after 01600 batchs: 812.4137573242188
INFO:root:Train (Epoch 103): Loss/seq after 01650 batchs: 807.23388671875
INFO:root:Train (Epoch 103): Loss/seq after 01700 batchs: 805.4207763671875
INFO:root:Train (Epoch 103): Loss/seq after 01750 batchs: 799.8167114257812
INFO:root:Train (Epoch 103): Loss/seq after 01800 batchs: 793.8672485351562
INFO:root:Train (Epoch 103): Loss/seq after 01850 batchs: 787.0421142578125
INFO:root:Train (Epoch 103): Loss/seq after 01900 batchs: 786.2938842773438
INFO:root:Train (Epoch 103): Loss/seq after 01950 batchs: 781.7285766601562
INFO:root:Train (Epoch 103): Loss/seq after 02000 batchs: 777.7268676757812
INFO:root:Train (Epoch 103): Loss/seq after 02050 batchs: 774.157958984375
INFO:root:Train (Epoch 103): Loss/seq after 02100 batchs: 768.6367797851562
INFO:root:Train (Epoch 103): Loss/seq after 02150 batchs: 764.4136962890625
INFO:root:Train (Epoch 103): Loss/seq after 02200 batchs: 759.2059326171875
INFO:root:Train (Epoch 103): Loss/seq after 02250 batchs: 758.7625122070312
INFO:root:Train (Epoch 103): Loss/seq after 02300 batchs: 763.2401733398438
INFO:root:Train (Epoch 103): Loss/seq after 02350 batchs: 756.2877807617188
INFO:root:Train (Epoch 103): Loss/seq after 02400 batchs: 755.1400146484375
INFO:root:Train (Epoch 103): Loss/seq after 02450 batchs: 747.7471923828125
INFO:root:Train (Epoch 103): Loss/seq after 02500 batchs: 736.1737670898438
INFO:root:Train (Epoch 103): Loss/seq after 02550 batchs: 727.4697265625
INFO:root:Train (Epoch 103): Loss/seq after 02600 batchs: 725.4600219726562
INFO:root:Train (Epoch 103): Loss/seq after 02650 batchs: 721.8241577148438
INFO:root:Train (Epoch 103): Loss/seq after 02700 batchs: 718.6639404296875
INFO:root:Train (Epoch 103): Loss/seq after 02750 batchs: 731.4973754882812
INFO:root:Train (Epoch 103): Loss/seq after 02800 batchs: 733.5835571289062
INFO:root:Train (Epoch 103): Loss/seq after 02850 batchs: 732.9898681640625
INFO:root:Train (Epoch 103): Loss/seq after 02900 batchs: 733.4252319335938
INFO:root:Train (Epoch 103): Loss/seq after 02950 batchs: 730.756591796875
INFO:root:Train (Epoch 103): Loss/seq after 03000 batchs: 733.8875732421875
INFO:root:Train (Epoch 103): Loss/seq after 03050 batchs: 737.552490234375
INFO:root:Train (Epoch 103): Loss/seq after 03100 batchs: 742.677001953125
INFO:root:Train (Epoch 103): Loss/seq after 03150 batchs: 749.4275512695312
INFO:root:Train (Epoch 103): Loss/seq after 03200 batchs: 756.4385375976562
INFO:root:Train (Epoch 103): Loss/seq after 03250 batchs: 761.5654907226562
INFO:root:Train (Epoch 103): Loss/seq after 03300 batchs: 760.4954223632812
INFO:root:Train (Epoch 103): Loss/seq after 03350 batchs: 760.1328125
INFO:root:Train (Epoch 103): Loss/seq after 03400 batchs: 753.5992431640625
INFO:root:Train (Epoch 103): Loss/seq after 03450 batchs: 750.107177734375
INFO:root:Train (Epoch 103): Loss/seq after 03500 batchs: 749.6873168945312
INFO:root:Train (Epoch 103): Loss/seq after 03550 batchs: 745.3316650390625
INFO:root:Train (Epoch 103): Loss/seq after 03600 batchs: 752.7869262695312
INFO:root:Train (Epoch 103): Loss/seq after 03650 batchs: 748.5070190429688
INFO:root:Train (Epoch 103): Loss/seq after 03700 batchs: 749.36767578125
INFO:root:Train (Epoch 103): Loss/seq after 03750 batchs: 753.0255126953125
INFO:root:Train (Epoch 103): Loss/seq after 03800 batchs: 748.7470092773438
INFO:root:Train (Epoch 103): Loss/seq after 03850 batchs: 747.1953125
INFO:root:Train (Epoch 103): Loss/seq after 03900 batchs: 751.455322265625
INFO:root:Train (Epoch 103): Loss/seq after 03950 batchs: 755.2701416015625
INFO:root:Train (Epoch 103): Loss/seq after 04000 batchs: 750.3170776367188
INFO:root:Train (Epoch 103): Loss/seq after 04050 batchs: 745.0030517578125
INFO:root:Train (Epoch 103): Loss/seq after 04100 batchs: 741.8067626953125
INFO:root:Train (Epoch 103): Loss/seq after 04150 batchs: 740.2175903320312
INFO:root:Train (Epoch 103): Loss/seq after 04200 batchs: 737.7813720703125
INFO:root:Train (Epoch 103): Loss/seq after 04250 batchs: 735.232177734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 103): Loss/seq after 00000 batches: 656.3368530273438
INFO:root:# Valid (Epoch 103): Loss/seq after 00050 batches: 785.5921630859375
INFO:root:# Valid (Epoch 103): Loss/seq after 00100 batches: 938.656005859375
INFO:root:# Valid (Epoch 103): Loss/seq after 00150 batches: 714.3988647460938
INFO:root:# Valid (Epoch 103): Loss/seq after 00200 batches: 660.5733032226562
INFO:root:Artifacts: Make stick videos for epoch 103
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_103_on_20220413_235625.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_103_index_1902_on_20220413_235625.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 104): Loss/seq after 00000 batchs: 1220.556884765625
INFO:root:Train (Epoch 104): Loss/seq after 00050 batchs: 964.2066040039062
INFO:root:Train (Epoch 104): Loss/seq after 00100 batchs: 1018.188232421875
INFO:root:Train (Epoch 104): Loss/seq after 00150 batchs: 913.6114501953125
INFO:root:Train (Epoch 104): Loss/seq after 00200 batchs: 1033.6282958984375
INFO:root:Train (Epoch 104): Loss/seq after 00250 batchs: 1143.4111328125
INFO:root:Train (Epoch 104): Loss/seq after 00300 batchs: 1110.92236328125
INFO:root:Train (Epoch 104): Loss/seq after 00350 batchs: 1030.50439453125
INFO:root:Train (Epoch 104): Loss/seq after 00400 batchs: 1041.2047119140625
INFO:root:Train (Epoch 104): Loss/seq after 00450 batchs: 1006.8576049804688
INFO:root:Train (Epoch 104): Loss/seq after 00500 batchs: 983.7353515625
INFO:root:Train (Epoch 104): Loss/seq after 00550 batchs: 947.8909301757812
INFO:root:Train (Epoch 104): Loss/seq after 00600 batchs: 912.2312622070312
INFO:root:Train (Epoch 104): Loss/seq after 00650 batchs: 920.3143920898438
INFO:root:Train (Epoch 104): Loss/seq after 00700 batchs: 903.2919921875
INFO:root:Train (Epoch 104): Loss/seq after 00750 batchs: 929.3438110351562
INFO:root:Train (Epoch 104): Loss/seq after 00800 batchs: 922.6009521484375
INFO:root:Train (Epoch 104): Loss/seq after 00850 batchs: 892.9308471679688
INFO:root:Train (Epoch 104): Loss/seq after 00900 batchs: 873.9719848632812
INFO:root:Train (Epoch 104): Loss/seq after 00950 batchs: 881.2982177734375
INFO:root:Train (Epoch 104): Loss/seq after 01000 batchs: 877.9056396484375
INFO:root:Train (Epoch 104): Loss/seq after 01050 batchs: 859.813720703125
INFO:root:Train (Epoch 104): Loss/seq after 01100 batchs: 844.038330078125
INFO:root:Train (Epoch 104): Loss/seq after 01150 batchs: 822.2294311523438
INFO:root:Train (Epoch 104): Loss/seq after 01200 batchs: 821.5939331054688
INFO:root:Train (Epoch 104): Loss/seq after 01250 batchs: 816.821533203125
INFO:root:Train (Epoch 104): Loss/seq after 01300 batchs: 806.5569458007812
INFO:root:Train (Epoch 104): Loss/seq after 01350 batchs: 797.1868896484375
INFO:root:Train (Epoch 104): Loss/seq after 01400 batchs: 812.0635986328125
INFO:root:Train (Epoch 104): Loss/seq after 01450 batchs: 809.7484130859375
INFO:root:Train (Epoch 104): Loss/seq after 01500 batchs: 811.960205078125
INFO:root:Train (Epoch 104): Loss/seq after 01550 batchs: 813.1187133789062
INFO:root:Train (Epoch 104): Loss/seq after 01600 batchs: 804.1455078125
INFO:root:Train (Epoch 104): Loss/seq after 01650 batchs: 799.0225830078125
INFO:root:Train (Epoch 104): Loss/seq after 01700 batchs: 797.2371215820312
INFO:root:Train (Epoch 104): Loss/seq after 01750 batchs: 791.7926635742188
INFO:root:Train (Epoch 104): Loss/seq after 01800 batchs: 785.8042602539062
INFO:root:Train (Epoch 104): Loss/seq after 01850 batchs: 779.1126098632812
INFO:root:Train (Epoch 104): Loss/seq after 01900 batchs: 778.1749267578125
INFO:root:Train (Epoch 104): Loss/seq after 01950 batchs: 773.80322265625
INFO:root:Train (Epoch 104): Loss/seq after 02000 batchs: 769.7633056640625
INFO:root:Train (Epoch 104): Loss/seq after 02050 batchs: 766.7750854492188
INFO:root:Train (Epoch 104): Loss/seq after 02100 batchs: 761.5415649414062
INFO:root:Train (Epoch 104): Loss/seq after 02150 batchs: 757.4646606445312
INFO:root:Train (Epoch 104): Loss/seq after 02200 batchs: 752.4400634765625
INFO:root:Train (Epoch 104): Loss/seq after 02250 batchs: 752.0543212890625
INFO:root:Train (Epoch 104): Loss/seq after 02300 batchs: 755.360595703125
INFO:root:Train (Epoch 104): Loss/seq after 02350 batchs: 748.358642578125
INFO:root:Train (Epoch 104): Loss/seq after 02400 batchs: 747.35791015625
INFO:root:Train (Epoch 104): Loss/seq after 02450 batchs: 740.0545043945312
INFO:root:Train (Epoch 104): Loss/seq after 02500 batchs: 728.5719604492188
INFO:root:Train (Epoch 104): Loss/seq after 02550 batchs: 720.0968017578125
INFO:root:Train (Epoch 104): Loss/seq after 02600 batchs: 718.3339233398438
INFO:root:Train (Epoch 104): Loss/seq after 02650 batchs: 714.9838256835938
INFO:root:Train (Epoch 104): Loss/seq after 02700 batchs: 711.6066284179688
INFO:root:Train (Epoch 104): Loss/seq after 02750 batchs: 724.9697265625
INFO:root:Train (Epoch 104): Loss/seq after 02800 batchs: 726.9124145507812
INFO:root:Train (Epoch 104): Loss/seq after 02850 batchs: 726.2195434570312
INFO:root:Train (Epoch 104): Loss/seq after 02900 batchs: 726.7103271484375
INFO:root:Train (Epoch 104): Loss/seq after 02950 batchs: 723.9087524414062
INFO:root:Train (Epoch 104): Loss/seq after 03000 batchs: 727.1463623046875
INFO:root:Train (Epoch 104): Loss/seq after 03050 batchs: 731.0286865234375
INFO:root:Train (Epoch 104): Loss/seq after 03100 batchs: 736.0935668945312
INFO:root:Train (Epoch 104): Loss/seq after 03150 batchs: 742.744873046875
INFO:root:Train (Epoch 104): Loss/seq after 03200 batchs: 750.3790283203125
INFO:root:Train (Epoch 104): Loss/seq after 03250 batchs: 755.5375366210938
INFO:root:Train (Epoch 104): Loss/seq after 03300 batchs: 755.3043823242188
INFO:root:Train (Epoch 104): Loss/seq after 03350 batchs: 755.2327270507812
INFO:root:Train (Epoch 104): Loss/seq after 03400 batchs: 748.8200073242188
INFO:root:Train (Epoch 104): Loss/seq after 03450 batchs: 745.8023681640625
INFO:root:Train (Epoch 104): Loss/seq after 03500 batchs: 745.4458618164062
INFO:root:Train (Epoch 104): Loss/seq after 03550 batchs: 741.22119140625
INFO:root:Train (Epoch 104): Loss/seq after 03600 batchs: 748.7178344726562
INFO:root:Train (Epoch 104): Loss/seq after 03650 batchs: 744.523193359375
INFO:root:Train (Epoch 104): Loss/seq after 03700 batchs: 745.5587158203125
INFO:root:Train (Epoch 104): Loss/seq after 03750 batchs: 749.2560424804688
INFO:root:Train (Epoch 104): Loss/seq after 03800 batchs: 745.0299072265625
INFO:root:Train (Epoch 104): Loss/seq after 03850 batchs: 743.4635620117188
INFO:root:Train (Epoch 104): Loss/seq after 03900 batchs: 747.6503295898438
INFO:root:Train (Epoch 104): Loss/seq after 03950 batchs: 751.4300537109375
INFO:root:Train (Epoch 104): Loss/seq after 04000 batchs: 746.5189208984375
INFO:root:Train (Epoch 104): Loss/seq after 04050 batchs: 741.275390625
INFO:root:Train (Epoch 104): Loss/seq after 04100 batchs: 738.1703491210938
INFO:root:Train (Epoch 104): Loss/seq after 04150 batchs: 736.5985717773438
INFO:root:Train (Epoch 104): Loss/seq after 04200 batchs: 734.064208984375
INFO:root:Train (Epoch 104): Loss/seq after 04250 batchs: 731.478759765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 104): Loss/seq after 00000 batches: 555.6695556640625
INFO:root:# Valid (Epoch 104): Loss/seq after 00050 batches: 757.6687622070312
INFO:root:# Valid (Epoch 104): Loss/seq after 00100 batches: 883.6143798828125
INFO:root:# Valid (Epoch 104): Loss/seq after 00150 batches: 674.1083374023438
INFO:root:# Valid (Epoch 104): Loss/seq after 00200 batches: 628.672119140625
INFO:root:Artifacts: Make stick videos for epoch 104
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_104_on_20220414_000143.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_104_index_62_on_20220414_000143.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 105): Loss/seq after 00000 batchs: 1230.8592529296875
INFO:root:Train (Epoch 105): Loss/seq after 00050 batchs: 959.5521850585938
INFO:root:Train (Epoch 105): Loss/seq after 00100 batchs: 1005.2389526367188
INFO:root:Train (Epoch 105): Loss/seq after 00150 batchs: 906.662353515625
INFO:root:Train (Epoch 105): Loss/seq after 00200 batchs: 1023.183837890625
INFO:root:Train (Epoch 105): Loss/seq after 00250 batchs: 1135.1429443359375
INFO:root:Train (Epoch 105): Loss/seq after 00300 batchs: 1104.05810546875
INFO:root:Train (Epoch 105): Loss/seq after 00350 batchs: 1024.44921875
INFO:root:Train (Epoch 105): Loss/seq after 00400 batchs: 1037.4625244140625
INFO:root:Train (Epoch 105): Loss/seq after 00450 batchs: 1002.4058837890625
INFO:root:Train (Epoch 105): Loss/seq after 00500 batchs: 977.6385498046875
INFO:root:Train (Epoch 105): Loss/seq after 00550 batchs: 942.1787109375
INFO:root:Train (Epoch 105): Loss/seq after 00600 batchs: 906.10595703125
INFO:root:Train (Epoch 105): Loss/seq after 00650 batchs: 913.990966796875
INFO:root:Train (Epoch 105): Loss/seq after 00700 batchs: 894.609130859375
INFO:root:Train (Epoch 105): Loss/seq after 00750 batchs: 919.86328125
INFO:root:Train (Epoch 105): Loss/seq after 00800 batchs: 911.982177734375
INFO:root:Train (Epoch 105): Loss/seq after 00850 batchs: 882.68408203125
INFO:root:Train (Epoch 105): Loss/seq after 00900 batchs: 864.5499877929688
INFO:root:Train (Epoch 105): Loss/seq after 00950 batchs: 875.1612548828125
INFO:root:Train (Epoch 105): Loss/seq after 01000 batchs: 873.0464477539062
INFO:root:Train (Epoch 105): Loss/seq after 01050 batchs: 856.7870483398438
INFO:root:Train (Epoch 105): Loss/seq after 01100 batchs: 841.1049194335938
INFO:root:Train (Epoch 105): Loss/seq after 01150 batchs: 819.3203735351562
INFO:root:Train (Epoch 105): Loss/seq after 01200 batchs: 818.9907836914062
INFO:root:Train (Epoch 105): Loss/seq after 01250 batchs: 813.945068359375
INFO:root:Train (Epoch 105): Loss/seq after 01300 batchs: 803.955078125
INFO:root:Train (Epoch 105): Loss/seq after 01350 batchs: 794.61572265625
INFO:root:Train (Epoch 105): Loss/seq after 01400 batchs: 809.3958740234375
INFO:root:Train (Epoch 105): Loss/seq after 01450 batchs: 807.0758666992188
INFO:root:Train (Epoch 105): Loss/seq after 01500 batchs: 809.3292846679688
INFO:root:Train (Epoch 105): Loss/seq after 01550 batchs: 810.2730102539062
INFO:root:Train (Epoch 105): Loss/seq after 01600 batchs: 801.4630126953125
INFO:root:Train (Epoch 105): Loss/seq after 01650 batchs: 796.6382446289062
INFO:root:Train (Epoch 105): Loss/seq after 01700 batchs: 794.990478515625
INFO:root:Train (Epoch 105): Loss/seq after 01750 batchs: 789.3453979492188
INFO:root:Train (Epoch 105): Loss/seq after 01800 batchs: 783.5408325195312
INFO:root:Train (Epoch 105): Loss/seq after 01850 batchs: 776.9808349609375
INFO:root:Train (Epoch 105): Loss/seq after 01900 batchs: 776.314697265625
INFO:root:Train (Epoch 105): Loss/seq after 01950 batchs: 772.2822265625
INFO:root:Train (Epoch 105): Loss/seq after 02000 batchs: 768.1832275390625
INFO:root:Train (Epoch 105): Loss/seq after 02050 batchs: 764.5806274414062
INFO:root:Train (Epoch 105): Loss/seq after 02100 batchs: 759.1377563476562
INFO:root:Train (Epoch 105): Loss/seq after 02150 batchs: 754.7282104492188
INFO:root:Train (Epoch 105): Loss/seq after 02200 batchs: 749.6561279296875
INFO:root:Train (Epoch 105): Loss/seq after 02250 batchs: 748.67822265625
INFO:root:Train (Epoch 105): Loss/seq after 02300 batchs: 752.4503784179688
INFO:root:Train (Epoch 105): Loss/seq after 02350 batchs: 745.6588745117188
INFO:root:Train (Epoch 105): Loss/seq after 02400 batchs: 744.5958862304688
INFO:root:Train (Epoch 105): Loss/seq after 02450 batchs: 737.27685546875
INFO:root:Train (Epoch 105): Loss/seq after 02500 batchs: 725.9058837890625
INFO:root:Train (Epoch 105): Loss/seq after 02550 batchs: 717.3716430664062
INFO:root:Train (Epoch 105): Loss/seq after 02600 batchs: 715.7653198242188
INFO:root:Train (Epoch 105): Loss/seq after 02650 batchs: 712.3001708984375
INFO:root:Train (Epoch 105): Loss/seq after 02700 batchs: 709.1986694335938
INFO:root:Train (Epoch 105): Loss/seq after 02750 batchs: 721.6561889648438
INFO:root:Train (Epoch 105): Loss/seq after 02800 batchs: 723.8117065429688
INFO:root:Train (Epoch 105): Loss/seq after 02850 batchs: 723.2355346679688
INFO:root:Train (Epoch 105): Loss/seq after 02900 batchs: 723.8607788085938
INFO:root:Train (Epoch 105): Loss/seq after 02950 batchs: 721.0877075195312
INFO:root:Train (Epoch 105): Loss/seq after 03000 batchs: 724.3861694335938
INFO:root:Train (Epoch 105): Loss/seq after 03050 batchs: 728.4475708007812
INFO:root:Train (Epoch 105): Loss/seq after 03100 batchs: 733.869873046875
INFO:root:Train (Epoch 105): Loss/seq after 03150 batchs: 740.6361083984375
INFO:root:Train (Epoch 105): Loss/seq after 03200 batchs: 748.0592651367188
INFO:root:Train (Epoch 105): Loss/seq after 03250 batchs: 753.4576416015625
INFO:root:Train (Epoch 105): Loss/seq after 03300 batchs: 752.4068603515625
INFO:root:Train (Epoch 105): Loss/seq after 03350 batchs: 752.3887329101562
INFO:root:Train (Epoch 105): Loss/seq after 03400 batchs: 746.0115966796875
INFO:root:Train (Epoch 105): Loss/seq after 03450 batchs: 742.894775390625
INFO:root:Train (Epoch 105): Loss/seq after 03500 batchs: 742.8536987304688
INFO:root:Train (Epoch 105): Loss/seq after 03550 batchs: 738.7213134765625
INFO:root:Train (Epoch 105): Loss/seq after 03600 batchs: 746.3855590820312
INFO:root:Train (Epoch 105): Loss/seq after 03650 batchs: 742.474609375
INFO:root:Train (Epoch 105): Loss/seq after 03700 batchs: 743.6572265625
INFO:root:Train (Epoch 105): Loss/seq after 03750 batchs: 747.3001708984375
INFO:root:Train (Epoch 105): Loss/seq after 03800 batchs: 743.0670776367188
INFO:root:Train (Epoch 105): Loss/seq after 03850 batchs: 741.3893432617188
INFO:root:Train (Epoch 105): Loss/seq after 03900 batchs: 745.27587890625
INFO:root:Train (Epoch 105): Loss/seq after 03950 batchs: 749.166748046875
INFO:root:Train (Epoch 105): Loss/seq after 04000 batchs: 744.2044677734375
INFO:root:Train (Epoch 105): Loss/seq after 04050 batchs: 738.9754638671875
INFO:root:Train (Epoch 105): Loss/seq after 04100 batchs: 735.8583374023438
INFO:root:Train (Epoch 105): Loss/seq after 04150 batchs: 734.307373046875
INFO:root:Train (Epoch 105): Loss/seq after 04200 batchs: 731.74951171875
INFO:root:Train (Epoch 105): Loss/seq after 04250 batchs: 729.1895141601562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 105): Loss/seq after 00000 batches: 573.8872680664062
INFO:root:# Valid (Epoch 105): Loss/seq after 00050 batches: 745.1699829101562
INFO:root:# Valid (Epoch 105): Loss/seq after 00100 batches: 856.7999267578125
INFO:root:# Valid (Epoch 105): Loss/seq after 00150 batches: 649.9603271484375
INFO:root:# Valid (Epoch 105): Loss/seq after 00200 batches: 607.09228515625
INFO:root:Artifacts: Make stick videos for epoch 105
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_105_on_20220414_000700.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_105_index_1309_on_20220414_000700.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 106): Loss/seq after 00000 batchs: 1305.3631591796875
INFO:root:Train (Epoch 106): Loss/seq after 00050 batchs: 960.4159545898438
INFO:root:Train (Epoch 106): Loss/seq after 00100 batchs: 1003.892333984375
INFO:root:Train (Epoch 106): Loss/seq after 00150 batchs: 896.8214111328125
INFO:root:Train (Epoch 106): Loss/seq after 00200 batchs: 1018.9710083007812
INFO:root:Train (Epoch 106): Loss/seq after 00250 batchs: 1131.1329345703125
INFO:root:Train (Epoch 106): Loss/seq after 00300 batchs: 1100.4932861328125
INFO:root:Train (Epoch 106): Loss/seq after 00350 batchs: 1021.2362670898438
INFO:root:Train (Epoch 106): Loss/seq after 00400 batchs: 1036.7919921875
INFO:root:Train (Epoch 106): Loss/seq after 00450 batchs: 1002.74560546875
INFO:root:Train (Epoch 106): Loss/seq after 00500 batchs: 981.015869140625
INFO:root:Train (Epoch 106): Loss/seq after 00550 batchs: 945.1577758789062
INFO:root:Train (Epoch 106): Loss/seq after 00600 batchs: 908.8091430664062
INFO:root:Train (Epoch 106): Loss/seq after 00650 batchs: 914.827880859375
INFO:root:Train (Epoch 106): Loss/seq after 00700 batchs: 895.2297973632812
INFO:root:Train (Epoch 106): Loss/seq after 00750 batchs: 919.4547119140625
INFO:root:Train (Epoch 106): Loss/seq after 00800 batchs: 911.9207153320312
INFO:root:Train (Epoch 106): Loss/seq after 00850 batchs: 882.4125366210938
INFO:root:Train (Epoch 106): Loss/seq after 00900 batchs: 863.1179809570312
INFO:root:Train (Epoch 106): Loss/seq after 00950 batchs: 870.0604858398438
INFO:root:Train (Epoch 106): Loss/seq after 01000 batchs: 868.5111083984375
INFO:root:Train (Epoch 106): Loss/seq after 01050 batchs: 851.3900146484375
INFO:root:Train (Epoch 106): Loss/seq after 01100 batchs: 835.8137817382812
INFO:root:Train (Epoch 106): Loss/seq after 01150 batchs: 814.4656982421875
INFO:root:Train (Epoch 106): Loss/seq after 01200 batchs: 814.2008666992188
INFO:root:Train (Epoch 106): Loss/seq after 01250 batchs: 808.9816284179688
INFO:root:Train (Epoch 106): Loss/seq after 01300 batchs: 798.41162109375
INFO:root:Train (Epoch 106): Loss/seq after 01350 batchs: 789.2238159179688
INFO:root:Train (Epoch 106): Loss/seq after 01400 batchs: 805.7188720703125
INFO:root:Train (Epoch 106): Loss/seq after 01450 batchs: 802.890869140625
INFO:root:Train (Epoch 106): Loss/seq after 01500 batchs: 805.1654052734375
INFO:root:Train (Epoch 106): Loss/seq after 01550 batchs: 805.832763671875
INFO:root:Train (Epoch 106): Loss/seq after 01600 batchs: 797.0502319335938
INFO:root:Train (Epoch 106): Loss/seq after 01650 batchs: 792.0933837890625
INFO:root:Train (Epoch 106): Loss/seq after 01700 batchs: 790.620849609375
INFO:root:Train (Epoch 106): Loss/seq after 01750 batchs: 785.0602416992188
INFO:root:Train (Epoch 106): Loss/seq after 01800 batchs: 779.296142578125
INFO:root:Train (Epoch 106): Loss/seq after 01850 batchs: 772.5946655273438
INFO:root:Train (Epoch 106): Loss/seq after 01900 batchs: 771.6068115234375
INFO:root:Train (Epoch 106): Loss/seq after 01950 batchs: 767.2666015625
INFO:root:Train (Epoch 106): Loss/seq after 02000 batchs: 763.1356811523438
INFO:root:Train (Epoch 106): Loss/seq after 02050 batchs: 759.5881958007812
INFO:root:Train (Epoch 106): Loss/seq after 02100 batchs: 754.3076782226562
INFO:root:Train (Epoch 106): Loss/seq after 02150 batchs: 750.0444946289062
INFO:root:Train (Epoch 106): Loss/seq after 02200 batchs: 745.0364990234375
INFO:root:Train (Epoch 106): Loss/seq after 02250 batchs: 744.0364379882812
INFO:root:Train (Epoch 106): Loss/seq after 02300 batchs: 746.6442260742188
INFO:root:Train (Epoch 106): Loss/seq after 02350 batchs: 739.5411376953125
INFO:root:Train (Epoch 106): Loss/seq after 02400 batchs: 738.384521484375
INFO:root:Train (Epoch 106): Loss/seq after 02450 batchs: 731.16064453125
INFO:root:Train (Epoch 106): Loss/seq after 02500 batchs: 719.897216796875
INFO:root:Train (Epoch 106): Loss/seq after 02550 batchs: 711.4891357421875
INFO:root:Train (Epoch 106): Loss/seq after 02600 batchs: 709.7261352539062
INFO:root:Train (Epoch 106): Loss/seq after 02650 batchs: 706.5131225585938
INFO:root:Train (Epoch 106): Loss/seq after 02700 batchs: 703.2865600585938
INFO:root:Train (Epoch 106): Loss/seq after 02750 batchs: 713.4946899414062
INFO:root:Train (Epoch 106): Loss/seq after 02800 batchs: 715.0072021484375
INFO:root:Train (Epoch 106): Loss/seq after 02850 batchs: 714.3765258789062
INFO:root:Train (Epoch 106): Loss/seq after 02900 batchs: 714.630126953125
INFO:root:Train (Epoch 106): Loss/seq after 02950 batchs: 711.8131103515625
INFO:root:Train (Epoch 106): Loss/seq after 03000 batchs: 715.0921020507812
INFO:root:Train (Epoch 106): Loss/seq after 03050 batchs: 719.2521362304688
INFO:root:Train (Epoch 106): Loss/seq after 03100 batchs: 724.3179321289062
INFO:root:Train (Epoch 106): Loss/seq after 03150 batchs: 730.8494873046875
INFO:root:Train (Epoch 106): Loss/seq after 03200 batchs: 738.0731811523438
INFO:root:Train (Epoch 106): Loss/seq after 03250 batchs: 743.6463012695312
INFO:root:Train (Epoch 106): Loss/seq after 03300 batchs: 742.7852172851562
INFO:root:Train (Epoch 106): Loss/seq after 03350 batchs: 742.7330932617188
INFO:root:Train (Epoch 106): Loss/seq after 03400 batchs: 736.5770263671875
INFO:root:Train (Epoch 106): Loss/seq after 03450 batchs: 733.3641357421875
INFO:root:Train (Epoch 106): Loss/seq after 03500 batchs: 732.7677612304688
INFO:root:Train (Epoch 106): Loss/seq after 03550 batchs: 728.5875854492188
INFO:root:Train (Epoch 106): Loss/seq after 03600 batchs: 736.1568603515625
INFO:root:Train (Epoch 106): Loss/seq after 03650 batchs: 732.1896362304688
INFO:root:Train (Epoch 106): Loss/seq after 03700 batchs: 733.1744995117188
INFO:root:Train (Epoch 106): Loss/seq after 03750 batchs: 736.9716796875
INFO:root:Train (Epoch 106): Loss/seq after 03800 batchs: 732.84130859375
INFO:root:Train (Epoch 106): Loss/seq after 03850 batchs: 731.2277221679688
INFO:root:Train (Epoch 106): Loss/seq after 03900 batchs: 735.3402709960938
INFO:root:Train (Epoch 106): Loss/seq after 03950 batchs: 739.2772216796875
INFO:root:Train (Epoch 106): Loss/seq after 04000 batchs: 734.378662109375
INFO:root:Train (Epoch 106): Loss/seq after 04050 batchs: 729.2234497070312
INFO:root:Train (Epoch 106): Loss/seq after 04100 batchs: 726.2650756835938
INFO:root:Train (Epoch 106): Loss/seq after 04150 batchs: 724.7609252929688
INFO:root:Train (Epoch 106): Loss/seq after 04200 batchs: 722.2645874023438
INFO:root:Train (Epoch 106): Loss/seq after 04250 batchs: 719.772216796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 106): Loss/seq after 00000 batches: 544.5929565429688
INFO:root:# Valid (Epoch 106): Loss/seq after 00050 batches: 699.2705688476562
INFO:root:# Valid (Epoch 106): Loss/seq after 00100 batches: 862.3171997070312
INFO:root:# Valid (Epoch 106): Loss/seq after 00150 batches: 650.044921875
INFO:root:# Valid (Epoch 106): Loss/seq after 00200 batches: 606.7677612304688
INFO:root:Artifacts: Make stick videos for epoch 106
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_106_on_20220414_001219.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_106_index_17_on_20220414_001219.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 107): Loss/seq after 00000 batchs: 1353.10986328125
INFO:root:Train (Epoch 107): Loss/seq after 00050 batchs: 963.6065673828125
INFO:root:Train (Epoch 107): Loss/seq after 00100 batchs: 1017.4503784179688
INFO:root:Train (Epoch 107): Loss/seq after 00150 batchs: 909.488525390625
INFO:root:Train (Epoch 107): Loss/seq after 00200 batchs: 1030.794677734375
INFO:root:Train (Epoch 107): Loss/seq after 00250 batchs: 1141.14697265625
INFO:root:Train (Epoch 107): Loss/seq after 00300 batchs: 1109.3038330078125
INFO:root:Train (Epoch 107): Loss/seq after 00350 batchs: 1029.21923828125
INFO:root:Train (Epoch 107): Loss/seq after 00400 batchs: 1042.3138427734375
INFO:root:Train (Epoch 107): Loss/seq after 00450 batchs: 1006.8714599609375
INFO:root:Train (Epoch 107): Loss/seq after 00500 batchs: 983.6395874023438
INFO:root:Train (Epoch 107): Loss/seq after 00550 batchs: 947.90380859375
INFO:root:Train (Epoch 107): Loss/seq after 00600 batchs: 911.2366333007812
INFO:root:Train (Epoch 107): Loss/seq after 00650 batchs: 919.7673950195312
INFO:root:Train (Epoch 107): Loss/seq after 00700 batchs: 901.2265625
INFO:root:Train (Epoch 107): Loss/seq after 00750 batchs: 924.6495361328125
INFO:root:Train (Epoch 107): Loss/seq after 00800 batchs: 915.9882202148438
INFO:root:Train (Epoch 107): Loss/seq after 00850 batchs: 886.0125122070312
INFO:root:Train (Epoch 107): Loss/seq after 00900 batchs: 865.069091796875
INFO:root:Train (Epoch 107): Loss/seq after 00950 batchs: 874.1524047851562
INFO:root:Train (Epoch 107): Loss/seq after 01000 batchs: 869.92138671875
INFO:root:Train (Epoch 107): Loss/seq after 01050 batchs: 852.5823974609375
INFO:root:Train (Epoch 107): Loss/seq after 01100 batchs: 836.862548828125
INFO:root:Train (Epoch 107): Loss/seq after 01150 batchs: 814.934814453125
INFO:root:Train (Epoch 107): Loss/seq after 01200 batchs: 814.3899536132812
INFO:root:Train (Epoch 107): Loss/seq after 01250 batchs: 808.6045532226562
INFO:root:Train (Epoch 107): Loss/seq after 01300 batchs: 797.06005859375
INFO:root:Train (Epoch 107): Loss/seq after 01350 batchs: 786.70703125
INFO:root:Train (Epoch 107): Loss/seq after 01400 batchs: 802.7044677734375
INFO:root:Train (Epoch 107): Loss/seq after 01450 batchs: 800.6723022460938
INFO:root:Train (Epoch 107): Loss/seq after 01500 batchs: 802.9719848632812
INFO:root:Train (Epoch 107): Loss/seq after 01550 batchs: 803.7830200195312
INFO:root:Train (Epoch 107): Loss/seq after 01600 batchs: 794.8203735351562
INFO:root:Train (Epoch 107): Loss/seq after 01650 batchs: 789.68994140625
INFO:root:Train (Epoch 107): Loss/seq after 01700 batchs: 788.9771118164062
INFO:root:Train (Epoch 107): Loss/seq after 01750 batchs: 783.5697021484375
INFO:root:Train (Epoch 107): Loss/seq after 01800 batchs: 777.6233520507812
INFO:root:Train (Epoch 107): Loss/seq after 01850 batchs: 770.8570556640625
INFO:root:Train (Epoch 107): Loss/seq after 01900 batchs: 769.9293212890625
INFO:root:Train (Epoch 107): Loss/seq after 01950 batchs: 765.7283325195312
INFO:root:Train (Epoch 107): Loss/seq after 02000 batchs: 761.761962890625
INFO:root:Train (Epoch 107): Loss/seq after 02050 batchs: 758.1515502929688
INFO:root:Train (Epoch 107): Loss/seq after 02100 batchs: 752.7077026367188
INFO:root:Train (Epoch 107): Loss/seq after 02150 batchs: 748.6058349609375
INFO:root:Train (Epoch 107): Loss/seq after 02200 batchs: 743.3334350585938
INFO:root:Train (Epoch 107): Loss/seq after 02250 batchs: 742.6190185546875
INFO:root:Train (Epoch 107): Loss/seq after 02300 batchs: 746.4227294921875
INFO:root:Train (Epoch 107): Loss/seq after 02350 batchs: 739.3687744140625
INFO:root:Train (Epoch 107): Loss/seq after 02400 batchs: 738.421875
INFO:root:Train (Epoch 107): Loss/seq after 02450 batchs: 731.2064819335938
INFO:root:Train (Epoch 107): Loss/seq after 02500 batchs: 719.9520263671875
INFO:root:Train (Epoch 107): Loss/seq after 02550 batchs: 711.517578125
INFO:root:Train (Epoch 107): Loss/seq after 02600 batchs: 709.7135009765625
INFO:root:Train (Epoch 107): Loss/seq after 02650 batchs: 706.212158203125
INFO:root:Train (Epoch 107): Loss/seq after 02700 batchs: 702.8370971679688
INFO:root:Train (Epoch 107): Loss/seq after 02750 batchs: 712.2733154296875
INFO:root:Train (Epoch 107): Loss/seq after 02800 batchs: 713.8447875976562
INFO:root:Train (Epoch 107): Loss/seq after 02850 batchs: 713.16796875
INFO:root:Train (Epoch 107): Loss/seq after 02900 batchs: 713.63671875
INFO:root:Train (Epoch 107): Loss/seq after 02950 batchs: 710.8772583007812
INFO:root:Train (Epoch 107): Loss/seq after 03000 batchs: 714.2127685546875
INFO:root:Train (Epoch 107): Loss/seq after 03050 batchs: 717.9537353515625
INFO:root:Train (Epoch 107): Loss/seq after 03100 batchs: 723.0025634765625
INFO:root:Train (Epoch 107): Loss/seq after 03150 batchs: 729.0101928710938
INFO:root:Train (Epoch 107): Loss/seq after 03200 batchs: 736.8094482421875
INFO:root:Train (Epoch 107): Loss/seq after 03250 batchs: 742.9031982421875
INFO:root:Train (Epoch 107): Loss/seq after 03300 batchs: 741.8685302734375
INFO:root:Train (Epoch 107): Loss/seq after 03350 batchs: 741.3131713867188
INFO:root:Train (Epoch 107): Loss/seq after 03400 batchs: 735.0121459960938
INFO:root:Train (Epoch 107): Loss/seq after 03450 batchs: 731.7884521484375
INFO:root:Train (Epoch 107): Loss/seq after 03500 batchs: 731.4520263671875
INFO:root:Train (Epoch 107): Loss/seq after 03550 batchs: 727.2196655273438
INFO:root:Train (Epoch 107): Loss/seq after 03600 batchs: 734.6858520507812
INFO:root:Train (Epoch 107): Loss/seq after 03650 batchs: 730.6045532226562
INFO:root:Train (Epoch 107): Loss/seq after 03700 batchs: 731.6366577148438
INFO:root:Train (Epoch 107): Loss/seq after 03750 batchs: 735.28955078125
INFO:root:Train (Epoch 107): Loss/seq after 03800 batchs: 731.1910400390625
INFO:root:Train (Epoch 107): Loss/seq after 03850 batchs: 729.6011352539062
INFO:root:Train (Epoch 107): Loss/seq after 03900 batchs: 733.8302612304688
INFO:root:Train (Epoch 107): Loss/seq after 03950 batchs: 737.9880981445312
INFO:root:Train (Epoch 107): Loss/seq after 04000 batchs: 733.0962524414062
INFO:root:Train (Epoch 107): Loss/seq after 04050 batchs: 727.9227294921875
INFO:root:Train (Epoch 107): Loss/seq after 04100 batchs: 724.8114013671875
INFO:root:Train (Epoch 107): Loss/seq after 04150 batchs: 723.4144287109375
INFO:root:Train (Epoch 107): Loss/seq after 04200 batchs: 720.7843017578125
INFO:root:Train (Epoch 107): Loss/seq after 04250 batchs: 718.187744140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 107): Loss/seq after 00000 batches: 573.8818969726562
INFO:root:# Valid (Epoch 107): Loss/seq after 00050 batches: 723.1766357421875
INFO:root:# Valid (Epoch 107): Loss/seq after 00100 batches: 852.8045043945312
INFO:root:# Valid (Epoch 107): Loss/seq after 00150 batches: 642.9666748046875
INFO:root:# Valid (Epoch 107): Loss/seq after 00200 batches: 599.5534057617188
INFO:root:Artifacts: Make stick videos for epoch 107
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_107_on_20220414_001737.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_107_index_1227_on_20220414_001737.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 108): Loss/seq after 00000 batchs: 1372.671142578125
INFO:root:Train (Epoch 108): Loss/seq after 00050 batchs: 956.4301147460938
INFO:root:Train (Epoch 108): Loss/seq after 00100 batchs: 999.3441772460938
INFO:root:Train (Epoch 108): Loss/seq after 00150 batchs: 887.7322998046875
INFO:root:Train (Epoch 108): Loss/seq after 00200 batchs: 1007.86083984375
INFO:root:Train (Epoch 108): Loss/seq after 00250 batchs: 1124.605224609375
INFO:root:Train (Epoch 108): Loss/seq after 00300 batchs: 1095.4161376953125
INFO:root:Train (Epoch 108): Loss/seq after 00350 batchs: 1018.01171875
INFO:root:Train (Epoch 108): Loss/seq after 00400 batchs: 1027.606689453125
INFO:root:Train (Epoch 108): Loss/seq after 00450 batchs: 993.351318359375
INFO:root:Train (Epoch 108): Loss/seq after 00500 batchs: 972.2860107421875
INFO:root:Train (Epoch 108): Loss/seq after 00550 batchs: 936.7471313476562
INFO:root:Train (Epoch 108): Loss/seq after 00600 batchs: 901.7305297851562
INFO:root:Train (Epoch 108): Loss/seq after 00650 batchs: 908.1712036132812
INFO:root:Train (Epoch 108): Loss/seq after 00700 batchs: 887.3355102539062
INFO:root:Train (Epoch 108): Loss/seq after 00750 batchs: 913.9581298828125
INFO:root:Train (Epoch 108): Loss/seq after 00800 batchs: 908.9622192382812
INFO:root:Train (Epoch 108): Loss/seq after 00850 batchs: 879.9220581054688
INFO:root:Train (Epoch 108): Loss/seq after 00900 batchs: 860.2470703125
INFO:root:Train (Epoch 108): Loss/seq after 00950 batchs: 868.7060546875
INFO:root:Train (Epoch 108): Loss/seq after 01000 batchs: 865.7277221679688
INFO:root:Train (Epoch 108): Loss/seq after 01050 batchs: 848.1340942382812
INFO:root:Train (Epoch 108): Loss/seq after 01100 batchs: 832.465087890625
INFO:root:Train (Epoch 108): Loss/seq after 01150 batchs: 810.7822265625
INFO:root:Train (Epoch 108): Loss/seq after 01200 batchs: 810.1791381835938
INFO:root:Train (Epoch 108): Loss/seq after 01250 batchs: 804.3226928710938
INFO:root:Train (Epoch 108): Loss/seq after 01300 batchs: 792.2962036132812
INFO:root:Train (Epoch 108): Loss/seq after 01350 batchs: 782.5885009765625
INFO:root:Train (Epoch 108): Loss/seq after 01400 batchs: 796.3054809570312
INFO:root:Train (Epoch 108): Loss/seq after 01450 batchs: 794.3934326171875
INFO:root:Train (Epoch 108): Loss/seq after 01500 batchs: 796.5859375
INFO:root:Train (Epoch 108): Loss/seq after 01550 batchs: 797.0828857421875
INFO:root:Train (Epoch 108): Loss/seq after 01600 batchs: 788.1838989257812
INFO:root:Train (Epoch 108): Loss/seq after 01650 batchs: 782.8118896484375
INFO:root:Train (Epoch 108): Loss/seq after 01700 batchs: 781.2954711914062
INFO:root:Train (Epoch 108): Loss/seq after 01750 batchs: 775.6616821289062
INFO:root:Train (Epoch 108): Loss/seq after 01800 batchs: 769.6890258789062
INFO:root:Train (Epoch 108): Loss/seq after 01850 batchs: 763.1157836914062
INFO:root:Train (Epoch 108): Loss/seq after 01900 batchs: 762.2191772460938
INFO:root:Train (Epoch 108): Loss/seq after 01950 batchs: 757.94091796875
INFO:root:Train (Epoch 108): Loss/seq after 02000 batchs: 753.924072265625
INFO:root:Train (Epoch 108): Loss/seq after 02050 batchs: 750.3681030273438
INFO:root:Train (Epoch 108): Loss/seq after 02100 batchs: 745.0853881835938
INFO:root:Train (Epoch 108): Loss/seq after 02150 batchs: 740.733642578125
INFO:root:Train (Epoch 108): Loss/seq after 02200 batchs: 735.64013671875
INFO:root:Train (Epoch 108): Loss/seq after 02250 batchs: 734.8126220703125
INFO:root:Train (Epoch 108): Loss/seq after 02300 batchs: 739.0789794921875
INFO:root:Train (Epoch 108): Loss/seq after 02350 batchs: 732.2744140625
INFO:root:Train (Epoch 108): Loss/seq after 02400 batchs: 731.4895629882812
INFO:root:Train (Epoch 108): Loss/seq after 02450 batchs: 724.3988037109375
INFO:root:Train (Epoch 108): Loss/seq after 02500 batchs: 713.2639770507812
INFO:root:Train (Epoch 108): Loss/seq after 02550 batchs: 705.0347900390625
INFO:root:Train (Epoch 108): Loss/seq after 02600 batchs: 703.273193359375
INFO:root:Train (Epoch 108): Loss/seq after 02650 batchs: 699.968017578125
INFO:root:Train (Epoch 108): Loss/seq after 02700 batchs: 696.940673828125
INFO:root:Train (Epoch 108): Loss/seq after 02750 batchs: 705.6664428710938
INFO:root:Train (Epoch 108): Loss/seq after 02800 batchs: 707.8660888671875
INFO:root:Train (Epoch 108): Loss/seq after 02850 batchs: 707.2051391601562
INFO:root:Train (Epoch 108): Loss/seq after 02900 batchs: 707.9181518554688
INFO:root:Train (Epoch 108): Loss/seq after 02950 batchs: 705.246826171875
INFO:root:Train (Epoch 108): Loss/seq after 03000 batchs: 708.6588745117188
INFO:root:Train (Epoch 108): Loss/seq after 03050 batchs: 712.4238891601562
INFO:root:Train (Epoch 108): Loss/seq after 03100 batchs: 717.6015625
INFO:root:Train (Epoch 108): Loss/seq after 03150 batchs: 724.052490234375
INFO:root:Train (Epoch 108): Loss/seq after 03200 batchs: 731.3840942382812
INFO:root:Train (Epoch 108): Loss/seq after 03250 batchs: 737.0672607421875
INFO:root:Train (Epoch 108): Loss/seq after 03300 batchs: 735.9546508789062
INFO:root:Train (Epoch 108): Loss/seq after 03350 batchs: 735.6593627929688
INFO:root:Train (Epoch 108): Loss/seq after 03400 batchs: 729.3768310546875
INFO:root:Train (Epoch 108): Loss/seq after 03450 batchs: 726.201904296875
INFO:root:Train (Epoch 108): Loss/seq after 03500 batchs: 725.8344116210938
INFO:root:Train (Epoch 108): Loss/seq after 03550 batchs: 721.4938354492188
INFO:root:Train (Epoch 108): Loss/seq after 03600 batchs: 728.9246215820312
INFO:root:Train (Epoch 108): Loss/seq after 03650 batchs: 724.7352905273438
INFO:root:Train (Epoch 108): Loss/seq after 03700 batchs: 725.692626953125
INFO:root:Train (Epoch 108): Loss/seq after 03750 batchs: 729.4807739257812
INFO:root:Train (Epoch 108): Loss/seq after 03800 batchs: 725.3971557617188
INFO:root:Train (Epoch 108): Loss/seq after 03850 batchs: 723.78271484375
INFO:root:Train (Epoch 108): Loss/seq after 03900 batchs: 727.9814453125
INFO:root:Train (Epoch 108): Loss/seq after 03950 batchs: 731.9307861328125
INFO:root:Train (Epoch 108): Loss/seq after 04000 batchs: 727.0189208984375
INFO:root:Train (Epoch 108): Loss/seq after 04050 batchs: 721.931396484375
INFO:root:Train (Epoch 108): Loss/seq after 04100 batchs: 718.887939453125
INFO:root:Train (Epoch 108): Loss/seq after 04150 batchs: 717.4514770507812
INFO:root:Train (Epoch 108): Loss/seq after 04200 batchs: 714.8641967773438
INFO:root:Train (Epoch 108): Loss/seq after 04250 batchs: 712.2640991210938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 108): Loss/seq after 00000 batches: 670.90283203125
INFO:root:# Valid (Epoch 108): Loss/seq after 00050 batches: 768.0003051757812
INFO:root:# Valid (Epoch 108): Loss/seq after 00100 batches: 862.1224365234375
INFO:root:# Valid (Epoch 108): Loss/seq after 00150 batches: 652.7222900390625
INFO:root:# Valid (Epoch 108): Loss/seq after 00200 batches: 607.507568359375
INFO:root:Artifacts: Make stick videos for epoch 108
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_108_on_20220414_002254.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_108_index_985_on_20220414_002254.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 109): Loss/seq after 00000 batchs: 1371.572509765625
INFO:root:Train (Epoch 109): Loss/seq after 00050 batchs: 951.8203735351562
INFO:root:Train (Epoch 109): Loss/seq after 00100 batchs: 997.57763671875
INFO:root:Train (Epoch 109): Loss/seq after 00150 batchs: 887.5269165039062
INFO:root:Train (Epoch 109): Loss/seq after 00200 batchs: 1001.5637817382812
INFO:root:Train (Epoch 109): Loss/seq after 00250 batchs: 1118.0665283203125
INFO:root:Train (Epoch 109): Loss/seq after 00300 batchs: 1088.7188720703125
INFO:root:Train (Epoch 109): Loss/seq after 00350 batchs: 1010.23876953125
INFO:root:Train (Epoch 109): Loss/seq after 00400 batchs: 1021.6304931640625
INFO:root:Train (Epoch 109): Loss/seq after 00450 batchs: 987.357177734375
INFO:root:Train (Epoch 109): Loss/seq after 00500 batchs: 961.5133056640625
INFO:root:Train (Epoch 109): Loss/seq after 00550 batchs: 926.6129150390625
INFO:root:Train (Epoch 109): Loss/seq after 00600 batchs: 890.9298706054688
INFO:root:Train (Epoch 109): Loss/seq after 00650 batchs: 899.3232421875
INFO:root:Train (Epoch 109): Loss/seq after 00700 batchs: 880.829833984375
INFO:root:Train (Epoch 109): Loss/seq after 00750 batchs: 905.3828125
INFO:root:Train (Epoch 109): Loss/seq after 00800 batchs: 898.0645751953125
INFO:root:Train (Epoch 109): Loss/seq after 00850 batchs: 868.4983520507812
INFO:root:Train (Epoch 109): Loss/seq after 00900 batchs: 849.0126953125
INFO:root:Train (Epoch 109): Loss/seq after 00950 batchs: 856.2156372070312
INFO:root:Train (Epoch 109): Loss/seq after 01000 batchs: 851.4898681640625
INFO:root:Train (Epoch 109): Loss/seq after 01050 batchs: 834.2106323242188
INFO:root:Train (Epoch 109): Loss/seq after 01100 batchs: 819.9310302734375
INFO:root:Train (Epoch 109): Loss/seq after 01150 batchs: 798.8209228515625
INFO:root:Train (Epoch 109): Loss/seq after 01200 batchs: 798.820556640625
INFO:root:Train (Epoch 109): Loss/seq after 01250 batchs: 793.4794311523438
INFO:root:Train (Epoch 109): Loss/seq after 01300 batchs: 781.9360961914062
INFO:root:Train (Epoch 109): Loss/seq after 01350 batchs: 771.75048828125
INFO:root:Train (Epoch 109): Loss/seq after 01400 batchs: 784.97216796875
INFO:root:Train (Epoch 109): Loss/seq after 01450 batchs: 782.8067016601562
INFO:root:Train (Epoch 109): Loss/seq after 01500 batchs: 785.2066040039062
INFO:root:Train (Epoch 109): Loss/seq after 01550 batchs: 785.967041015625
INFO:root:Train (Epoch 109): Loss/seq after 01600 batchs: 777.5072021484375
INFO:root:Train (Epoch 109): Loss/seq after 01650 batchs: 772.3776245117188
INFO:root:Train (Epoch 109): Loss/seq after 01700 batchs: 771.2813720703125
INFO:root:Train (Epoch 109): Loss/seq after 01750 batchs: 765.7864379882812
INFO:root:Train (Epoch 109): Loss/seq after 01800 batchs: 760.0783081054688
INFO:root:Train (Epoch 109): Loss/seq after 01850 batchs: 753.4014892578125
INFO:root:Train (Epoch 109): Loss/seq after 01900 batchs: 752.4847412109375
INFO:root:Train (Epoch 109): Loss/seq after 01950 batchs: 748.4656372070312
INFO:root:Train (Epoch 109): Loss/seq after 02000 batchs: 744.5325927734375
INFO:root:Train (Epoch 109): Loss/seq after 02050 batchs: 740.8529663085938
INFO:root:Train (Epoch 109): Loss/seq after 02100 batchs: 735.7479248046875
INFO:root:Train (Epoch 109): Loss/seq after 02150 batchs: 731.7460327148438
INFO:root:Train (Epoch 109): Loss/seq after 02200 batchs: 726.8465576171875
INFO:root:Train (Epoch 109): Loss/seq after 02250 batchs: 725.9278564453125
INFO:root:Train (Epoch 109): Loss/seq after 02300 batchs: 730.3522338867188
INFO:root:Train (Epoch 109): Loss/seq after 02350 batchs: 723.8533325195312
INFO:root:Train (Epoch 109): Loss/seq after 02400 batchs: 722.9847412109375
INFO:root:Train (Epoch 109): Loss/seq after 02450 batchs: 715.9071655273438
INFO:root:Train (Epoch 109): Loss/seq after 02500 batchs: 704.9405517578125
INFO:root:Train (Epoch 109): Loss/seq after 02550 batchs: 696.8072509765625
INFO:root:Train (Epoch 109): Loss/seq after 02600 batchs: 695.0597534179688
INFO:root:Train (Epoch 109): Loss/seq after 02650 batchs: 691.876953125
INFO:root:Train (Epoch 109): Loss/seq after 02700 batchs: 688.6897583007812
INFO:root:Train (Epoch 109): Loss/seq after 02750 batchs: 697.8504028320312
INFO:root:Train (Epoch 109): Loss/seq after 02800 batchs: 699.4951171875
INFO:root:Train (Epoch 109): Loss/seq after 02850 batchs: 698.9660034179688
INFO:root:Train (Epoch 109): Loss/seq after 02900 batchs: 699.5653686523438
INFO:root:Train (Epoch 109): Loss/seq after 02950 batchs: 696.7650146484375
INFO:root:Train (Epoch 109): Loss/seq after 03000 batchs: 700.183349609375
INFO:root:Train (Epoch 109): Loss/seq after 03050 batchs: 704.457763671875
INFO:root:Train (Epoch 109): Loss/seq after 03100 batchs: 710.4242553710938
INFO:root:Train (Epoch 109): Loss/seq after 03150 batchs: 717.2188110351562
INFO:root:Train (Epoch 109): Loss/seq after 03200 batchs: 724.996826171875
INFO:root:Train (Epoch 109): Loss/seq after 03250 batchs: 730.6190185546875
INFO:root:Train (Epoch 109): Loss/seq after 03300 batchs: 729.7196044921875
INFO:root:Train (Epoch 109): Loss/seq after 03350 batchs: 729.349853515625
INFO:root:Train (Epoch 109): Loss/seq after 03400 batchs: 723.1719360351562
INFO:root:Train (Epoch 109): Loss/seq after 03450 batchs: 720.0297241210938
INFO:root:Train (Epoch 109): Loss/seq after 03500 batchs: 719.7459716796875
INFO:root:Train (Epoch 109): Loss/seq after 03550 batchs: 715.6803588867188
INFO:root:Train (Epoch 109): Loss/seq after 03600 batchs: 723.6070556640625
INFO:root:Train (Epoch 109): Loss/seq after 03650 batchs: 719.5564575195312
INFO:root:Train (Epoch 109): Loss/seq after 03700 batchs: 720.4859008789062
INFO:root:Train (Epoch 109): Loss/seq after 03750 batchs: 724.3509521484375
INFO:root:Train (Epoch 109): Loss/seq after 03800 batchs: 720.3543701171875
INFO:root:Train (Epoch 109): Loss/seq after 03850 batchs: 718.8182983398438
INFO:root:Train (Epoch 109): Loss/seq after 03900 batchs: 723.05908203125
INFO:root:Train (Epoch 109): Loss/seq after 03950 batchs: 727.0786743164062
INFO:root:Train (Epoch 109): Loss/seq after 04000 batchs: 722.1629638671875
INFO:root:Train (Epoch 109): Loss/seq after 04050 batchs: 717.1122436523438
INFO:root:Train (Epoch 109): Loss/seq after 04100 batchs: 714.1435546875
INFO:root:Train (Epoch 109): Loss/seq after 04150 batchs: 712.7830200195312
INFO:root:Train (Epoch 109): Loss/seq after 04200 batchs: 710.2017822265625
INFO:root:Train (Epoch 109): Loss/seq after 04250 batchs: 707.6465454101562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 109): Loss/seq after 00000 batches: 520.120849609375
INFO:root:# Valid (Epoch 109): Loss/seq after 00050 batches: 720.1240844726562
INFO:root:# Valid (Epoch 109): Loss/seq after 00100 batches: 852.5454711914062
INFO:root:# Valid (Epoch 109): Loss/seq after 00150 batches: 648.3866577148438
INFO:root:# Valid (Epoch 109): Loss/seq after 00200 batches: 609.9446411132812
INFO:root:Artifacts: Make stick videos for epoch 109
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_109_on_20220414_002813.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_109_index_1191_on_20220414_002813.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 110): Loss/seq after 00000 batchs: 1303.579345703125
INFO:root:Train (Epoch 110): Loss/seq after 00050 batchs: 926.0833740234375
INFO:root:Train (Epoch 110): Loss/seq after 00100 batchs: 979.3159790039062
INFO:root:Train (Epoch 110): Loss/seq after 00150 batchs: 876.1826171875
INFO:root:Train (Epoch 110): Loss/seq after 00200 batchs: 994.223388671875
INFO:root:Train (Epoch 110): Loss/seq after 00250 batchs: 1107.042724609375
INFO:root:Train (Epoch 110): Loss/seq after 00300 batchs: 1077.915283203125
INFO:root:Train (Epoch 110): Loss/seq after 00350 batchs: 1001.3521728515625
INFO:root:Train (Epoch 110): Loss/seq after 00400 batchs: 1013.360595703125
INFO:root:Train (Epoch 110): Loss/seq after 00450 batchs: 979.9122924804688
INFO:root:Train (Epoch 110): Loss/seq after 00500 batchs: 953.1489868164062
INFO:root:Train (Epoch 110): Loss/seq after 00550 batchs: 918.93017578125
INFO:root:Train (Epoch 110): Loss/seq after 00600 batchs: 884.009765625
INFO:root:Train (Epoch 110): Loss/seq after 00650 batchs: 889.4255981445312
INFO:root:Train (Epoch 110): Loss/seq after 00700 batchs: 870.4237670898438
INFO:root:Train (Epoch 110): Loss/seq after 00750 batchs: 893.0706176757812
INFO:root:Train (Epoch 110): Loss/seq after 00800 batchs: 887.2423095703125
INFO:root:Train (Epoch 110): Loss/seq after 00850 batchs: 858.4468383789062
INFO:root:Train (Epoch 110): Loss/seq after 00900 batchs: 838.767578125
INFO:root:Train (Epoch 110): Loss/seq after 00950 batchs: 844.9418334960938
INFO:root:Train (Epoch 110): Loss/seq after 01000 batchs: 840.1940307617188
INFO:root:Train (Epoch 110): Loss/seq after 01050 batchs: 822.9229125976562
INFO:root:Train (Epoch 110): Loss/seq after 01100 batchs: 808.6740112304688
INFO:root:Train (Epoch 110): Loss/seq after 01150 batchs: 788.4036254882812
INFO:root:Train (Epoch 110): Loss/seq after 01200 batchs: 788.2382202148438
INFO:root:Train (Epoch 110): Loss/seq after 01250 batchs: 783.4669189453125
INFO:root:Train (Epoch 110): Loss/seq after 01300 batchs: 771.5377197265625
INFO:root:Train (Epoch 110): Loss/seq after 01350 batchs: 761.7493286132812
INFO:root:Train (Epoch 110): Loss/seq after 01400 batchs: 774.8365478515625
INFO:root:Train (Epoch 110): Loss/seq after 01450 batchs: 772.6153564453125
INFO:root:Train (Epoch 110): Loss/seq after 01500 batchs: 775.4237670898438
INFO:root:Train (Epoch 110): Loss/seq after 01550 batchs: 776.1514282226562
INFO:root:Train (Epoch 110): Loss/seq after 01600 batchs: 767.66357421875
INFO:root:Train (Epoch 110): Loss/seq after 01650 batchs: 762.917236328125
INFO:root:Train (Epoch 110): Loss/seq after 01700 batchs: 761.8926391601562
INFO:root:Train (Epoch 110): Loss/seq after 01750 batchs: 756.64208984375
INFO:root:Train (Epoch 110): Loss/seq after 01800 batchs: 751.21533203125
INFO:root:Train (Epoch 110): Loss/seq after 01850 batchs: 744.8164672851562
INFO:root:Train (Epoch 110): Loss/seq after 01900 batchs: 743.9747314453125
INFO:root:Train (Epoch 110): Loss/seq after 01950 batchs: 740.0795288085938
INFO:root:Train (Epoch 110): Loss/seq after 02000 batchs: 736.2207641601562
INFO:root:Train (Epoch 110): Loss/seq after 02050 batchs: 732.9797973632812
INFO:root:Train (Epoch 110): Loss/seq after 02100 batchs: 728.091552734375
INFO:root:Train (Epoch 110): Loss/seq after 02150 batchs: 724.299072265625
INFO:root:Train (Epoch 110): Loss/seq after 02200 batchs: 719.458740234375
INFO:root:Train (Epoch 110): Loss/seq after 02250 batchs: 718.7034301757812
INFO:root:Train (Epoch 110): Loss/seq after 02300 batchs: 722.2488403320312
INFO:root:Train (Epoch 110): Loss/seq after 02350 batchs: 716.2747802734375
INFO:root:Train (Epoch 110): Loss/seq after 02400 batchs: 715.5258178710938
INFO:root:Train (Epoch 110): Loss/seq after 02450 batchs: 708.5889892578125
INFO:root:Train (Epoch 110): Loss/seq after 02500 batchs: 697.8261108398438
INFO:root:Train (Epoch 110): Loss/seq after 02550 batchs: 689.7386474609375
INFO:root:Train (Epoch 110): Loss/seq after 02600 batchs: 688.03466796875
INFO:root:Train (Epoch 110): Loss/seq after 02650 batchs: 684.8836669921875
INFO:root:Train (Epoch 110): Loss/seq after 02700 batchs: 681.848388671875
INFO:root:Train (Epoch 110): Loss/seq after 02750 batchs: 688.548583984375
INFO:root:Train (Epoch 110): Loss/seq after 02800 batchs: 690.0194702148438
INFO:root:Train (Epoch 110): Loss/seq after 02850 batchs: 689.6041259765625
INFO:root:Train (Epoch 110): Loss/seq after 02900 batchs: 690.3350219726562
INFO:root:Train (Epoch 110): Loss/seq after 02950 batchs: 687.7120361328125
INFO:root:Train (Epoch 110): Loss/seq after 03000 batchs: 691.1943969726562
INFO:root:Train (Epoch 110): Loss/seq after 03050 batchs: 695.476318359375
INFO:root:Train (Epoch 110): Loss/seq after 03100 batchs: 700.5076293945312
INFO:root:Train (Epoch 110): Loss/seq after 03150 batchs: 707.2192993164062
INFO:root:Train (Epoch 110): Loss/seq after 03200 batchs: 714.4560546875
INFO:root:Train (Epoch 110): Loss/seq after 03250 batchs: 720.5698852539062
INFO:root:Train (Epoch 110): Loss/seq after 03300 batchs: 719.32763671875
INFO:root:Train (Epoch 110): Loss/seq after 03350 batchs: 719.3052368164062
INFO:root:Train (Epoch 110): Loss/seq after 03400 batchs: 713.2085571289062
INFO:root:Train (Epoch 110): Loss/seq after 03450 batchs: 710.12548828125
INFO:root:Train (Epoch 110): Loss/seq after 03500 batchs: 709.6898193359375
INFO:root:Train (Epoch 110): Loss/seq after 03550 batchs: 705.6118774414062
INFO:root:Train (Epoch 110): Loss/seq after 03600 batchs: 713.1489868164062
INFO:root:Train (Epoch 110): Loss/seq after 03650 batchs: 709.3636474609375
INFO:root:Train (Epoch 110): Loss/seq after 03700 batchs: 710.4682006835938
INFO:root:Train (Epoch 110): Loss/seq after 03750 batchs: 714.3600463867188
INFO:root:Train (Epoch 110): Loss/seq after 03800 batchs: 710.4157104492188
INFO:root:Train (Epoch 110): Loss/seq after 03850 batchs: 709.0512084960938
INFO:root:Train (Epoch 110): Loss/seq after 03900 batchs: 713.169189453125
INFO:root:Train (Epoch 110): Loss/seq after 03950 batchs: 717.1179809570312
INFO:root:Train (Epoch 110): Loss/seq after 04000 batchs: 712.2780151367188
INFO:root:Train (Epoch 110): Loss/seq after 04050 batchs: 707.3156127929688
INFO:root:Train (Epoch 110): Loss/seq after 04100 batchs: 704.3972778320312
INFO:root:Train (Epoch 110): Loss/seq after 04150 batchs: 703.0792236328125
INFO:root:Train (Epoch 110): Loss/seq after 04200 batchs: 700.5684204101562
INFO:root:Train (Epoch 110): Loss/seq after 04250 batchs: 698.1333618164062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 110): Loss/seq after 00000 batches: 554.0897216796875
INFO:root:# Valid (Epoch 110): Loss/seq after 00050 batches: 761.12890625
INFO:root:# Valid (Epoch 110): Loss/seq after 00100 batches: 848.2244873046875
INFO:root:# Valid (Epoch 110): Loss/seq after 00150 batches: 642.0750732421875
INFO:root:# Valid (Epoch 110): Loss/seq after 00200 batches: 596.6227416992188
INFO:root:Artifacts: Make stick videos for epoch 110
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_110_on_20220414_003331.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_110_index_1298_on_20220414_003331.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 111): Loss/seq after 00000 batchs: 1358.9090576171875
INFO:root:Train (Epoch 111): Loss/seq after 00050 batchs: 927.4586791992188
INFO:root:Train (Epoch 111): Loss/seq after 00100 batchs: 985.5301513671875
INFO:root:Train (Epoch 111): Loss/seq after 00150 batchs: 879.110107421875
INFO:root:Train (Epoch 111): Loss/seq after 00200 batchs: 1000.9752807617188
INFO:root:Train (Epoch 111): Loss/seq after 00250 batchs: 1117.9776611328125
INFO:root:Train (Epoch 111): Loss/seq after 00300 batchs: 1087.5023193359375
INFO:root:Train (Epoch 111): Loss/seq after 00350 batchs: 1008.0149536132812
INFO:root:Train (Epoch 111): Loss/seq after 00400 batchs: 1020.4143676757812
INFO:root:Train (Epoch 111): Loss/seq after 00450 batchs: 986.0706176757812
INFO:root:Train (Epoch 111): Loss/seq after 00500 batchs: 959.2775268554688
INFO:root:Train (Epoch 111): Loss/seq after 00550 batchs: 924.1505126953125
INFO:root:Train (Epoch 111): Loss/seq after 00600 batchs: 888.1207885742188
INFO:root:Train (Epoch 111): Loss/seq after 00650 batchs: 894.6327514648438
INFO:root:Train (Epoch 111): Loss/seq after 00700 batchs: 875.1676635742188
INFO:root:Train (Epoch 111): Loss/seq after 00750 batchs: 897.4581909179688
INFO:root:Train (Epoch 111): Loss/seq after 00800 batchs: 890.4656372070312
INFO:root:Train (Epoch 111): Loss/seq after 00850 batchs: 861.0665893554688
INFO:root:Train (Epoch 111): Loss/seq after 00900 batchs: 841.7400512695312
INFO:root:Train (Epoch 111): Loss/seq after 00950 batchs: 848.1237182617188
INFO:root:Train (Epoch 111): Loss/seq after 01000 batchs: 844.3145751953125
INFO:root:Train (Epoch 111): Loss/seq after 01050 batchs: 826.7203979492188
INFO:root:Train (Epoch 111): Loss/seq after 01100 batchs: 811.49951171875
INFO:root:Train (Epoch 111): Loss/seq after 01150 batchs: 790.4815063476562
INFO:root:Train (Epoch 111): Loss/seq after 01200 batchs: 790.1105346679688
INFO:root:Train (Epoch 111): Loss/seq after 01250 batchs: 784.3290405273438
INFO:root:Train (Epoch 111): Loss/seq after 01300 batchs: 772.665771484375
INFO:root:Train (Epoch 111): Loss/seq after 01350 batchs: 761.8232421875
INFO:root:Train (Epoch 111): Loss/seq after 01400 batchs: 776.2061767578125
INFO:root:Train (Epoch 111): Loss/seq after 01450 batchs: 774.0224609375
INFO:root:Train (Epoch 111): Loss/seq after 01500 batchs: 776.6197509765625
INFO:root:Train (Epoch 111): Loss/seq after 01550 batchs: 776.8506469726562
INFO:root:Train (Epoch 111): Loss/seq after 01600 batchs: 768.4271850585938
INFO:root:Train (Epoch 111): Loss/seq after 01650 batchs: 763.3145751953125
INFO:root:Train (Epoch 111): Loss/seq after 01700 batchs: 762.5346069335938
INFO:root:Train (Epoch 111): Loss/seq after 01750 batchs: 757.3233642578125
INFO:root:Train (Epoch 111): Loss/seq after 01800 batchs: 751.8118896484375
INFO:root:Train (Epoch 111): Loss/seq after 01850 batchs: 745.2515258789062
INFO:root:Train (Epoch 111): Loss/seq after 01900 batchs: 744.3888549804688
INFO:root:Train (Epoch 111): Loss/seq after 01950 batchs: 741.0599365234375
INFO:root:Train (Epoch 111): Loss/seq after 02000 batchs: 737.3092041015625
INFO:root:Train (Epoch 111): Loss/seq after 02050 batchs: 733.9115600585938
INFO:root:Train (Epoch 111): Loss/seq after 02100 batchs: 728.7723999023438
INFO:root:Train (Epoch 111): Loss/seq after 02150 batchs: 724.9881591796875
INFO:root:Train (Epoch 111): Loss/seq after 02200 batchs: 719.9932861328125
INFO:root:Train (Epoch 111): Loss/seq after 02250 batchs: 719.178955078125
INFO:root:Train (Epoch 111): Loss/seq after 02300 batchs: 721.9403076171875
INFO:root:Train (Epoch 111): Loss/seq after 02350 batchs: 715.3760986328125
INFO:root:Train (Epoch 111): Loss/seq after 02400 batchs: 714.7254028320312
INFO:root:Train (Epoch 111): Loss/seq after 02450 batchs: 707.6956787109375
INFO:root:Train (Epoch 111): Loss/seq after 02500 batchs: 696.910888671875
INFO:root:Train (Epoch 111): Loss/seq after 02550 batchs: 689.0145263671875
INFO:root:Train (Epoch 111): Loss/seq after 02600 batchs: 687.2182006835938
INFO:root:Train (Epoch 111): Loss/seq after 02650 batchs: 684.07275390625
INFO:root:Train (Epoch 111): Loss/seq after 02700 batchs: 680.9080810546875
INFO:root:Train (Epoch 111): Loss/seq after 02750 batchs: 688.2391967773438
INFO:root:Train (Epoch 111): Loss/seq after 02800 batchs: 689.7320556640625
INFO:root:Train (Epoch 111): Loss/seq after 02850 batchs: 689.6323852539062
INFO:root:Train (Epoch 111): Loss/seq after 02900 batchs: 690.2687377929688
INFO:root:Train (Epoch 111): Loss/seq after 02950 batchs: 687.6873779296875
INFO:root:Train (Epoch 111): Loss/seq after 03000 batchs: 691.1343994140625
INFO:root:Train (Epoch 111): Loss/seq after 03050 batchs: 694.2893676757812
INFO:root:Train (Epoch 111): Loss/seq after 03100 batchs: 699.2382202148438
INFO:root:Train (Epoch 111): Loss/seq after 03150 batchs: 706.0199584960938
INFO:root:Train (Epoch 111): Loss/seq after 03200 batchs: 713.8577880859375
INFO:root:Train (Epoch 111): Loss/seq after 03250 batchs: 719.9130859375
INFO:root:Train (Epoch 111): Loss/seq after 03300 batchs: 718.60546875
INFO:root:Train (Epoch 111): Loss/seq after 03350 batchs: 718.2454833984375
INFO:root:Train (Epoch 111): Loss/seq after 03400 batchs: 712.1644287109375
INFO:root:Train (Epoch 111): Loss/seq after 03450 batchs: 709.1250610351562
INFO:root:Train (Epoch 111): Loss/seq after 03500 batchs: 708.8931884765625
INFO:root:Train (Epoch 111): Loss/seq after 03550 batchs: 704.9906005859375
INFO:root:Train (Epoch 111): Loss/seq after 03600 batchs: 712.7809448242188
INFO:root:Train (Epoch 111): Loss/seq after 03650 batchs: 708.8875122070312
INFO:root:Train (Epoch 111): Loss/seq after 03700 batchs: 710.0880737304688
INFO:root:Train (Epoch 111): Loss/seq after 03750 batchs: 713.9086303710938
INFO:root:Train (Epoch 111): Loss/seq after 03800 batchs: 709.9522094726562
INFO:root:Train (Epoch 111): Loss/seq after 03850 batchs: 708.5298461914062
INFO:root:Train (Epoch 111): Loss/seq after 03900 batchs: 712.7288818359375
INFO:root:Train (Epoch 111): Loss/seq after 03950 batchs: 717.1654052734375
INFO:root:Train (Epoch 111): Loss/seq after 04000 batchs: 712.378173828125
INFO:root:Train (Epoch 111): Loss/seq after 04050 batchs: 707.4208984375
INFO:root:Train (Epoch 111): Loss/seq after 04100 batchs: 704.3892211914062
INFO:root:Train (Epoch 111): Loss/seq after 04150 batchs: 703.0701904296875
INFO:root:Train (Epoch 111): Loss/seq after 04200 batchs: 700.6282958984375
INFO:root:Train (Epoch 111): Loss/seq after 04250 batchs: 698.1619873046875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 111): Loss/seq after 00000 batches: 575.8379516601562
INFO:root:# Valid (Epoch 111): Loss/seq after 00050 batches: 711.1586303710938
INFO:root:# Valid (Epoch 111): Loss/seq after 00100 batches: 836.9117431640625
INFO:root:# Valid (Epoch 111): Loss/seq after 00150 batches: 630.2655639648438
INFO:root:# Valid (Epoch 111): Loss/seq after 00200 batches: 589.2044067382812
INFO:root:Artifacts: Make stick videos for epoch 111
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_111_on_20220414_003850.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_111_index_79_on_20220414_003850.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 112): Loss/seq after 00000 batchs: 1321.310302734375
INFO:root:Train (Epoch 112): Loss/seq after 00050 batchs: 933.6033325195312
INFO:root:Train (Epoch 112): Loss/seq after 00100 batchs: 979.6233520507812
INFO:root:Train (Epoch 112): Loss/seq after 00150 batchs: 873.6568603515625
INFO:root:Train (Epoch 112): Loss/seq after 00200 batchs: 994.5846557617188
INFO:root:Train (Epoch 112): Loss/seq after 00250 batchs: 1104.657470703125
INFO:root:Train (Epoch 112): Loss/seq after 00300 batchs: 1074.8814697265625
INFO:root:Train (Epoch 112): Loss/seq after 00350 batchs: 998.8154296875
INFO:root:Train (Epoch 112): Loss/seq after 00400 batchs: 1010.4655151367188
INFO:root:Train (Epoch 112): Loss/seq after 00450 batchs: 976.7077026367188
INFO:root:Train (Epoch 112): Loss/seq after 00500 batchs: 950.0113525390625
INFO:root:Train (Epoch 112): Loss/seq after 00550 batchs: 914.3709106445312
INFO:root:Train (Epoch 112): Loss/seq after 00600 batchs: 878.5869140625
INFO:root:Train (Epoch 112): Loss/seq after 00650 batchs: 884.0011596679688
INFO:root:Train (Epoch 112): Loss/seq after 00700 batchs: 866.9990234375
INFO:root:Train (Epoch 112): Loss/seq after 00750 batchs: 891.416259765625
INFO:root:Train (Epoch 112): Loss/seq after 00800 batchs: 884.1324462890625
INFO:root:Train (Epoch 112): Loss/seq after 00850 batchs: 854.8440551757812
INFO:root:Train (Epoch 112): Loss/seq after 00900 batchs: 835.604248046875
INFO:root:Train (Epoch 112): Loss/seq after 00950 batchs: 840.2719116210938
INFO:root:Train (Epoch 112): Loss/seq after 01000 batchs: 835.9736328125
INFO:root:Train (Epoch 112): Loss/seq after 01050 batchs: 819.4133911132812
INFO:root:Train (Epoch 112): Loss/seq after 01100 batchs: 804.402587890625
INFO:root:Train (Epoch 112): Loss/seq after 01150 batchs: 783.5671997070312
INFO:root:Train (Epoch 112): Loss/seq after 01200 batchs: 783.8482055664062
INFO:root:Train (Epoch 112): Loss/seq after 01250 batchs: 778.508544921875
INFO:root:Train (Epoch 112): Loss/seq after 01300 batchs: 767.3233642578125
INFO:root:Train (Epoch 112): Loss/seq after 01350 batchs: 756.9609985351562
INFO:root:Train (Epoch 112): Loss/seq after 01400 batchs: 770.3497314453125
INFO:root:Train (Epoch 112): Loss/seq after 01450 batchs: 768.0238647460938
INFO:root:Train (Epoch 112): Loss/seq after 01500 batchs: 770.4828491210938
INFO:root:Train (Epoch 112): Loss/seq after 01550 batchs: 770.8400268554688
INFO:root:Train (Epoch 112): Loss/seq after 01600 batchs: 762.0586547851562
INFO:root:Train (Epoch 112): Loss/seq after 01650 batchs: 757.062744140625
INFO:root:Train (Epoch 112): Loss/seq after 01700 batchs: 756.1279907226562
INFO:root:Train (Epoch 112): Loss/seq after 01750 batchs: 750.8457641601562
INFO:root:Train (Epoch 112): Loss/seq after 01800 batchs: 745.3807983398438
INFO:root:Train (Epoch 112): Loss/seq after 01850 batchs: 738.79248046875
INFO:root:Train (Epoch 112): Loss/seq after 01900 batchs: 737.79052734375
INFO:root:Train (Epoch 112): Loss/seq after 01950 batchs: 734.1503295898438
INFO:root:Train (Epoch 112): Loss/seq after 02000 batchs: 730.4505615234375
INFO:root:Train (Epoch 112): Loss/seq after 02050 batchs: 727.1456298828125
INFO:root:Train (Epoch 112): Loss/seq after 02100 batchs: 722.0485229492188
INFO:root:Train (Epoch 112): Loss/seq after 02150 batchs: 718.1167602539062
INFO:root:Train (Epoch 112): Loss/seq after 02200 batchs: 713.0943603515625
INFO:root:Train (Epoch 112): Loss/seq after 02250 batchs: 711.8566284179688
INFO:root:Train (Epoch 112): Loss/seq after 02300 batchs: 714.4412841796875
INFO:root:Train (Epoch 112): Loss/seq after 02350 batchs: 707.9310913085938
INFO:root:Train (Epoch 112): Loss/seq after 02400 batchs: 707.4176635742188
INFO:root:Train (Epoch 112): Loss/seq after 02450 batchs: 700.545654296875
INFO:root:Train (Epoch 112): Loss/seq after 02500 batchs: 689.9217529296875
INFO:root:Train (Epoch 112): Loss/seq after 02550 batchs: 681.9520874023438
INFO:root:Train (Epoch 112): Loss/seq after 02600 batchs: 680.3935546875
INFO:root:Train (Epoch 112): Loss/seq after 02650 batchs: 677.1995239257812
INFO:root:Train (Epoch 112): Loss/seq after 02700 batchs: 674.0185546875
INFO:root:Train (Epoch 112): Loss/seq after 02750 batchs: 679.5910034179688
INFO:root:Train (Epoch 112): Loss/seq after 02800 batchs: 681.41455078125
INFO:root:Train (Epoch 112): Loss/seq after 02850 batchs: 680.5260009765625
INFO:root:Train (Epoch 112): Loss/seq after 02900 batchs: 681.3875732421875
INFO:root:Train (Epoch 112): Loss/seq after 02950 batchs: 678.9026489257812
INFO:root:Train (Epoch 112): Loss/seq after 03000 batchs: 682.4849243164062
INFO:root:Train (Epoch 112): Loss/seq after 03050 batchs: 685.914306640625
INFO:root:Train (Epoch 112): Loss/seq after 03100 batchs: 690.90869140625
INFO:root:Train (Epoch 112): Loss/seq after 03150 batchs: 697.7362060546875
INFO:root:Train (Epoch 112): Loss/seq after 03200 batchs: 705.2846069335938
INFO:root:Train (Epoch 112): Loss/seq after 03250 batchs: 711.276123046875
INFO:root:Train (Epoch 112): Loss/seq after 03300 batchs: 709.9682006835938
INFO:root:Train (Epoch 112): Loss/seq after 03350 batchs: 709.9684448242188
INFO:root:Train (Epoch 112): Loss/seq after 03400 batchs: 703.9634399414062
INFO:root:Train (Epoch 112): Loss/seq after 03450 batchs: 700.9900512695312
INFO:root:Train (Epoch 112): Loss/seq after 03500 batchs: 700.6641235351562
INFO:root:Train (Epoch 112): Loss/seq after 03550 batchs: 696.5533447265625
INFO:root:Train (Epoch 112): Loss/seq after 03600 batchs: 704.1356201171875
INFO:root:Train (Epoch 112): Loss/seq after 03650 batchs: 700.24365234375
INFO:root:Train (Epoch 112): Loss/seq after 03700 batchs: 701.55126953125
INFO:root:Train (Epoch 112): Loss/seq after 03750 batchs: 705.336181640625
INFO:root:Train (Epoch 112): Loss/seq after 03800 batchs: 701.5436401367188
INFO:root:Train (Epoch 112): Loss/seq after 03850 batchs: 700.1681518554688
INFO:root:Train (Epoch 112): Loss/seq after 03900 batchs: 704.6170654296875
INFO:root:Train (Epoch 112): Loss/seq after 03950 batchs: 708.6555786132812
INFO:root:Train (Epoch 112): Loss/seq after 04000 batchs: 703.78466796875
INFO:root:Train (Epoch 112): Loss/seq after 04050 batchs: 698.9329833984375
INFO:root:Train (Epoch 112): Loss/seq after 04100 batchs: 696.0275268554688
INFO:root:Train (Epoch 112): Loss/seq after 04150 batchs: 694.7905883789062
INFO:root:Train (Epoch 112): Loss/seq after 04200 batchs: 692.4542846679688
INFO:root:Train (Epoch 112): Loss/seq after 04250 batchs: 689.994384765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 112): Loss/seq after 00000 batches: 546.3019409179688
INFO:root:# Valid (Epoch 112): Loss/seq after 00050 batches: 782.5421752929688
INFO:root:# Valid (Epoch 112): Loss/seq after 00100 batches: 853.7650146484375
INFO:root:# Valid (Epoch 112): Loss/seq after 00150 batches: 642.9403686523438
INFO:root:# Valid (Epoch 112): Loss/seq after 00200 batches: 597.0801391601562
INFO:root:Artifacts: Make stick videos for epoch 112
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_112_on_20220414_004409.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_112_index_907_on_20220414_004409.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 113): Loss/seq after 00000 batchs: 1270.71337890625
INFO:root:Train (Epoch 113): Loss/seq after 00050 batchs: 919.2382202148438
INFO:root:Train (Epoch 113): Loss/seq after 00100 batchs: 970.9724731445312
INFO:root:Train (Epoch 113): Loss/seq after 00150 batchs: 868.0452270507812
INFO:root:Train (Epoch 113): Loss/seq after 00200 batchs: 997.6265869140625
INFO:root:Train (Epoch 113): Loss/seq after 00250 batchs: 1106.2752685546875
INFO:root:Train (Epoch 113): Loss/seq after 00300 batchs: 1076.511962890625
INFO:root:Train (Epoch 113): Loss/seq after 00350 batchs: 998.8604125976562
INFO:root:Train (Epoch 113): Loss/seq after 00400 batchs: 1009.7889404296875
INFO:root:Train (Epoch 113): Loss/seq after 00450 batchs: 976.3262939453125
INFO:root:Train (Epoch 113): Loss/seq after 00500 batchs: 952.802490234375
INFO:root:Train (Epoch 113): Loss/seq after 00550 batchs: 917.42724609375
INFO:root:Train (Epoch 113): Loss/seq after 00600 batchs: 881.96630859375
INFO:root:Train (Epoch 113): Loss/seq after 00650 batchs: 887.3176879882812
INFO:root:Train (Epoch 113): Loss/seq after 00700 batchs: 868.3128662109375
INFO:root:Train (Epoch 113): Loss/seq after 00750 batchs: 887.2548828125
INFO:root:Train (Epoch 113): Loss/seq after 00800 batchs: 880.44775390625
INFO:root:Train (Epoch 113): Loss/seq after 00850 batchs: 851.0703125
INFO:root:Train (Epoch 113): Loss/seq after 00900 batchs: 831.4899291992188
INFO:root:Train (Epoch 113): Loss/seq after 00950 batchs: 833.8600463867188
INFO:root:Train (Epoch 113): Loss/seq after 01000 batchs: 828.7802124023438
INFO:root:Train (Epoch 113): Loss/seq after 01050 batchs: 811.5897216796875
INFO:root:Train (Epoch 113): Loss/seq after 01100 batchs: 796.9381103515625
INFO:root:Train (Epoch 113): Loss/seq after 01150 batchs: 776.2823486328125
INFO:root:Train (Epoch 113): Loss/seq after 01200 batchs: 776.0894165039062
INFO:root:Train (Epoch 113): Loss/seq after 01250 batchs: 771.0506591796875
INFO:root:Train (Epoch 113): Loss/seq after 01300 batchs: 760.2182006835938
INFO:root:Train (Epoch 113): Loss/seq after 01350 batchs: 750.290771484375
INFO:root:Train (Epoch 113): Loss/seq after 01400 batchs: 761.779052734375
INFO:root:Train (Epoch 113): Loss/seq after 01450 batchs: 760.0286865234375
INFO:root:Train (Epoch 113): Loss/seq after 01500 batchs: 762.6830444335938
INFO:root:Train (Epoch 113): Loss/seq after 01550 batchs: 763.3275146484375
INFO:root:Train (Epoch 113): Loss/seq after 01600 batchs: 755.1036987304688
INFO:root:Train (Epoch 113): Loss/seq after 01650 batchs: 750.8977661132812
INFO:root:Train (Epoch 113): Loss/seq after 01700 batchs: 750.0916748046875
INFO:root:Train (Epoch 113): Loss/seq after 01750 batchs: 745.0394897460938
INFO:root:Train (Epoch 113): Loss/seq after 01800 batchs: 739.6771850585938
INFO:root:Train (Epoch 113): Loss/seq after 01850 batchs: 733.12744140625
INFO:root:Train (Epoch 113): Loss/seq after 01900 batchs: 731.9332885742188
INFO:root:Train (Epoch 113): Loss/seq after 01950 batchs: 728.6845092773438
INFO:root:Train (Epoch 113): Loss/seq after 02000 batchs: 725.0107421875
INFO:root:Train (Epoch 113): Loss/seq after 02050 batchs: 721.7696533203125
INFO:root:Train (Epoch 113): Loss/seq after 02100 batchs: 716.7755126953125
INFO:root:Train (Epoch 113): Loss/seq after 02150 batchs: 712.9496459960938
INFO:root:Train (Epoch 113): Loss/seq after 02200 batchs: 708.1122436523438
INFO:root:Train (Epoch 113): Loss/seq after 02250 batchs: 707.2981567382812
INFO:root:Train (Epoch 113): Loss/seq after 02300 batchs: 712.9837036132812
INFO:root:Train (Epoch 113): Loss/seq after 02350 batchs: 706.752685546875
INFO:root:Train (Epoch 113): Loss/seq after 02400 batchs: 706.3132934570312
INFO:root:Train (Epoch 113): Loss/seq after 02450 batchs: 699.4734497070312
INFO:root:Train (Epoch 113): Loss/seq after 02500 batchs: 688.8215942382812
INFO:root:Train (Epoch 113): Loss/seq after 02550 batchs: 680.9322509765625
INFO:root:Train (Epoch 113): Loss/seq after 02600 batchs: 679.2846069335938
INFO:root:Train (Epoch 113): Loss/seq after 02650 batchs: 676.239990234375
INFO:root:Train (Epoch 113): Loss/seq after 02700 batchs: 673.0484619140625
INFO:root:Train (Epoch 113): Loss/seq after 02750 batchs: 678.9405517578125
INFO:root:Train (Epoch 113): Loss/seq after 02800 batchs: 680.396728515625
INFO:root:Train (Epoch 113): Loss/seq after 02850 batchs: 679.9866943359375
INFO:root:Train (Epoch 113): Loss/seq after 02900 batchs: 681.1771850585938
INFO:root:Train (Epoch 113): Loss/seq after 02950 batchs: 678.6873779296875
INFO:root:Train (Epoch 113): Loss/seq after 03000 batchs: 682.1279907226562
INFO:root:Train (Epoch 113): Loss/seq after 03050 batchs: 685.3204345703125
INFO:root:Train (Epoch 113): Loss/seq after 03100 batchs: 690.7946166992188
INFO:root:Train (Epoch 113): Loss/seq after 03150 batchs: 698.6446533203125
INFO:root:Train (Epoch 113): Loss/seq after 03200 batchs: 706.1063842773438
INFO:root:Train (Epoch 113): Loss/seq after 03250 batchs: 711.9414672851562
INFO:root:Train (Epoch 113): Loss/seq after 03300 batchs: 710.8228149414062
INFO:root:Train (Epoch 113): Loss/seq after 03350 batchs: 710.7206420898438
INFO:root:Train (Epoch 113): Loss/seq after 03400 batchs: 704.7509765625
INFO:root:Train (Epoch 113): Loss/seq after 03450 batchs: 701.7655639648438
INFO:root:Train (Epoch 113): Loss/seq after 03500 batchs: 701.3344116210938
INFO:root:Train (Epoch 113): Loss/seq after 03550 batchs: 697.2210083007812
INFO:root:Train (Epoch 113): Loss/seq after 03600 batchs: 704.81640625
INFO:root:Train (Epoch 113): Loss/seq after 03650 batchs: 700.8853759765625
INFO:root:Train (Epoch 113): Loss/seq after 03700 batchs: 701.9724731445312
INFO:root:Train (Epoch 113): Loss/seq after 03750 batchs: 705.8366088867188
INFO:root:Train (Epoch 113): Loss/seq after 03800 batchs: 701.9200439453125
INFO:root:Train (Epoch 113): Loss/seq after 03850 batchs: 700.423095703125
INFO:root:Train (Epoch 113): Loss/seq after 03900 batchs: 705.1024780273438
INFO:root:Train (Epoch 113): Loss/seq after 03950 batchs: 709.2958984375
INFO:root:Train (Epoch 113): Loss/seq after 04000 batchs: 704.3995971679688
INFO:root:Train (Epoch 113): Loss/seq after 04050 batchs: 699.53857421875
INFO:root:Train (Epoch 113): Loss/seq after 04100 batchs: 696.5950927734375
INFO:root:Train (Epoch 113): Loss/seq after 04150 batchs: 695.2880859375
INFO:root:Train (Epoch 113): Loss/seq after 04200 batchs: 692.8265380859375
INFO:root:Train (Epoch 113): Loss/seq after 04250 batchs: 690.3839111328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 113): Loss/seq after 00000 batches: 574.298583984375
INFO:root:# Valid (Epoch 113): Loss/seq after 00050 batches: 759.7738647460938
INFO:root:# Valid (Epoch 113): Loss/seq after 00100 batches: 822.2935180664062
INFO:root:# Valid (Epoch 113): Loss/seq after 00150 batches: 620.5571899414062
INFO:root:# Valid (Epoch 113): Loss/seq after 00200 batches: 576.6630249023438
INFO:root:Artifacts: Make stick videos for epoch 113
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_113_on_20220414_004927.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_113_index_766_on_20220414_004927.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 114): Loss/seq after 00000 batchs: 1372.7586669921875
INFO:root:Train (Epoch 114): Loss/seq after 00050 batchs: 939.25537109375
INFO:root:Train (Epoch 114): Loss/seq after 00100 batchs: 982.5726928710938
INFO:root:Train (Epoch 114): Loss/seq after 00150 batchs: 873.20849609375
INFO:root:Train (Epoch 114): Loss/seq after 00200 batchs: 984.1764526367188
INFO:root:Train (Epoch 114): Loss/seq after 00250 batchs: 1096.6904296875
INFO:root:Train (Epoch 114): Loss/seq after 00300 batchs: 1067.3106689453125
INFO:root:Train (Epoch 114): Loss/seq after 00350 batchs: 989.9675903320312
INFO:root:Train (Epoch 114): Loss/seq after 00400 batchs: 998.6840209960938
INFO:root:Train (Epoch 114): Loss/seq after 00450 batchs: 965.0748291015625
INFO:root:Train (Epoch 114): Loss/seq after 00500 batchs: 938.3576049804688
INFO:root:Train (Epoch 114): Loss/seq after 00550 batchs: 903.6072998046875
INFO:root:Train (Epoch 114): Loss/seq after 00600 batchs: 868.8349609375
INFO:root:Train (Epoch 114): Loss/seq after 00650 batchs: 872.7901000976562
INFO:root:Train (Epoch 114): Loss/seq after 00700 batchs: 854.6566162109375
INFO:root:Train (Epoch 114): Loss/seq after 00750 batchs: 876.2637939453125
INFO:root:Train (Epoch 114): Loss/seq after 00800 batchs: 870.6047973632812
INFO:root:Train (Epoch 114): Loss/seq after 00850 batchs: 841.711669921875
INFO:root:Train (Epoch 114): Loss/seq after 00900 batchs: 822.4392700195312
INFO:root:Train (Epoch 114): Loss/seq after 00950 batchs: 825.6931762695312
INFO:root:Train (Epoch 114): Loss/seq after 01000 batchs: 823.4619750976562
INFO:root:Train (Epoch 114): Loss/seq after 01050 batchs: 807.021728515625
INFO:root:Train (Epoch 114): Loss/seq after 01100 batchs: 792.5174560546875
INFO:root:Train (Epoch 114): Loss/seq after 01150 batchs: 771.9768676757812
INFO:root:Train (Epoch 114): Loss/seq after 01200 batchs: 772.01953125
INFO:root:Train (Epoch 114): Loss/seq after 01250 batchs: 767.062744140625
INFO:root:Train (Epoch 114): Loss/seq after 01300 batchs: 755.652587890625
INFO:root:Train (Epoch 114): Loss/seq after 01350 batchs: 746.0635986328125
INFO:root:Train (Epoch 114): Loss/seq after 01400 batchs: 758.1148071289062
INFO:root:Train (Epoch 114): Loss/seq after 01450 batchs: 756.2171630859375
INFO:root:Train (Epoch 114): Loss/seq after 01500 batchs: 758.9846801757812
INFO:root:Train (Epoch 114): Loss/seq after 01550 batchs: 759.3342895507812
INFO:root:Train (Epoch 114): Loss/seq after 01600 batchs: 750.8778686523438
INFO:root:Train (Epoch 114): Loss/seq after 01650 batchs: 745.8952026367188
INFO:root:Train (Epoch 114): Loss/seq after 01700 batchs: 745.2501831054688
INFO:root:Train (Epoch 114): Loss/seq after 01750 batchs: 740.013427734375
INFO:root:Train (Epoch 114): Loss/seq after 01800 batchs: 734.5859985351562
INFO:root:Train (Epoch 114): Loss/seq after 01850 batchs: 728.1131591796875
INFO:root:Train (Epoch 114): Loss/seq after 01900 batchs: 727.016845703125
INFO:root:Train (Epoch 114): Loss/seq after 01950 batchs: 723.6887817382812
INFO:root:Train (Epoch 114): Loss/seq after 02000 batchs: 719.8428344726562
INFO:root:Train (Epoch 114): Loss/seq after 02050 batchs: 716.5639038085938
INFO:root:Train (Epoch 114): Loss/seq after 02100 batchs: 711.5699462890625
INFO:root:Train (Epoch 114): Loss/seq after 02150 batchs: 707.6738891601562
INFO:root:Train (Epoch 114): Loss/seq after 02200 batchs: 702.7573852539062
INFO:root:Train (Epoch 114): Loss/seq after 02250 batchs: 701.6506958007812
INFO:root:Train (Epoch 114): Loss/seq after 02300 batchs: 704.9082641601562
INFO:root:Train (Epoch 114): Loss/seq after 02350 batchs: 698.8678588867188
INFO:root:Train (Epoch 114): Loss/seq after 02400 batchs: 698.5296020507812
INFO:root:Train (Epoch 114): Loss/seq after 02450 batchs: 691.7928466796875
INFO:root:Train (Epoch 114): Loss/seq after 02500 batchs: 681.3048095703125
INFO:root:Train (Epoch 114): Loss/seq after 02550 batchs: 673.5166015625
INFO:root:Train (Epoch 114): Loss/seq after 02600 batchs: 671.8482055664062
INFO:root:Train (Epoch 114): Loss/seq after 02650 batchs: 668.805908203125
INFO:root:Train (Epoch 114): Loss/seq after 02700 batchs: 665.6878051757812
INFO:root:Train (Epoch 114): Loss/seq after 02750 batchs: 670.9219970703125
INFO:root:Train (Epoch 114): Loss/seq after 02800 batchs: 672.6865844726562
INFO:root:Train (Epoch 114): Loss/seq after 02850 batchs: 671.9063720703125
INFO:root:Train (Epoch 114): Loss/seq after 02900 batchs: 672.5136108398438
INFO:root:Train (Epoch 114): Loss/seq after 02950 batchs: 670.0989379882812
INFO:root:Train (Epoch 114): Loss/seq after 03000 batchs: 673.6648559570312
INFO:root:Train (Epoch 114): Loss/seq after 03050 batchs: 676.8301391601562
INFO:root:Train (Epoch 114): Loss/seq after 03100 batchs: 681.7239379882812
INFO:root:Train (Epoch 114): Loss/seq after 03150 batchs: 688.3372802734375
INFO:root:Train (Epoch 114): Loss/seq after 03200 batchs: 695.8614501953125
INFO:root:Train (Epoch 114): Loss/seq after 03250 batchs: 702.1701049804688
INFO:root:Train (Epoch 114): Loss/seq after 03300 batchs: 701.408935546875
INFO:root:Train (Epoch 114): Loss/seq after 03350 batchs: 702.228759765625
INFO:root:Train (Epoch 114): Loss/seq after 03400 batchs: 696.401123046875
INFO:root:Train (Epoch 114): Loss/seq after 03450 batchs: 693.549072265625
INFO:root:Train (Epoch 114): Loss/seq after 03500 batchs: 693.514892578125
INFO:root:Train (Epoch 114): Loss/seq after 03550 batchs: 689.6712036132812
INFO:root:Train (Epoch 114): Loss/seq after 03600 batchs: 697.4069213867188
INFO:root:Train (Epoch 114): Loss/seq after 03650 batchs: 693.5304565429688
INFO:root:Train (Epoch 114): Loss/seq after 03700 batchs: 694.6998901367188
INFO:root:Train (Epoch 114): Loss/seq after 03750 batchs: 698.6094970703125
INFO:root:Train (Epoch 114): Loss/seq after 03800 batchs: 694.8170166015625
INFO:root:Train (Epoch 114): Loss/seq after 03850 batchs: 693.4777221679688
INFO:root:Train (Epoch 114): Loss/seq after 03900 batchs: 697.7377319335938
INFO:root:Train (Epoch 114): Loss/seq after 03950 batchs: 702.0057983398438
INFO:root:Train (Epoch 114): Loss/seq after 04000 batchs: 697.1981811523438
INFO:root:Train (Epoch 114): Loss/seq after 04050 batchs: 692.38525390625
INFO:root:Train (Epoch 114): Loss/seq after 04100 batchs: 689.489501953125
INFO:root:Train (Epoch 114): Loss/seq after 04150 batchs: 688.3261108398438
INFO:root:Train (Epoch 114): Loss/seq after 04200 batchs: 685.9672241210938
INFO:root:Train (Epoch 114): Loss/seq after 04250 batchs: 683.5418090820312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 114): Loss/seq after 00000 batches: 546.6270141601562
INFO:root:# Valid (Epoch 114): Loss/seq after 00050 batches: 788.3895263671875
INFO:root:# Valid (Epoch 114): Loss/seq after 00100 batches: 833.0170288085938
INFO:root:# Valid (Epoch 114): Loss/seq after 00150 batches: 627.4252319335938
INFO:root:# Valid (Epoch 114): Loss/seq after 00200 batches: 582.0775146484375
INFO:root:Artifacts: Make stick videos for epoch 114
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_114_on_20220414_005443.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_114_index_1505_on_20220414_005443.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 115): Loss/seq after 00000 batchs: 1265.41357421875
INFO:root:Train (Epoch 115): Loss/seq after 00050 batchs: 911.38427734375
INFO:root:Train (Epoch 115): Loss/seq after 00100 batchs: 960.6675415039062
INFO:root:Train (Epoch 115): Loss/seq after 00150 batchs: 856.807861328125
INFO:root:Train (Epoch 115): Loss/seq after 00200 batchs: 969.7283935546875
INFO:root:Train (Epoch 115): Loss/seq after 00250 batchs: 1082.9798583984375
INFO:root:Train (Epoch 115): Loss/seq after 00300 batchs: 1055.489013671875
INFO:root:Train (Epoch 115): Loss/seq after 00350 batchs: 979.6533813476562
INFO:root:Train (Epoch 115): Loss/seq after 00400 batchs: 988.019287109375
INFO:root:Train (Epoch 115): Loss/seq after 00450 batchs: 955.5109252929688
INFO:root:Train (Epoch 115): Loss/seq after 00500 batchs: 929.6756591796875
INFO:root:Train (Epoch 115): Loss/seq after 00550 batchs: 895.959228515625
INFO:root:Train (Epoch 115): Loss/seq after 00600 batchs: 861.5298461914062
INFO:root:Train (Epoch 115): Loss/seq after 00650 batchs: 863.6818237304688
INFO:root:Train (Epoch 115): Loss/seq after 00700 batchs: 843.0597534179688
INFO:root:Train (Epoch 115): Loss/seq after 00750 batchs: 864.0057373046875
INFO:root:Train (Epoch 115): Loss/seq after 00800 batchs: 858.2293090820312
INFO:root:Train (Epoch 115): Loss/seq after 00850 batchs: 830.193359375
INFO:root:Train (Epoch 115): Loss/seq after 00900 batchs: 811.2709350585938
INFO:root:Train (Epoch 115): Loss/seq after 00950 batchs: 813.5393676757812
INFO:root:Train (Epoch 115): Loss/seq after 01000 batchs: 807.3395385742188
INFO:root:Train (Epoch 115): Loss/seq after 01050 batchs: 791.8259887695312
INFO:root:Train (Epoch 115): Loss/seq after 01100 batchs: 778.757080078125
INFO:root:Train (Epoch 115): Loss/seq after 01150 batchs: 758.8452758789062
INFO:root:Train (Epoch 115): Loss/seq after 01200 batchs: 759.3087768554688
INFO:root:Train (Epoch 115): Loss/seq after 01250 batchs: 754.7175903320312
INFO:root:Train (Epoch 115): Loss/seq after 01300 batchs: 743.0579833984375
INFO:root:Train (Epoch 115): Loss/seq after 01350 batchs: 732.5963134765625
INFO:root:Train (Epoch 115): Loss/seq after 01400 batchs: 744.215087890625
INFO:root:Train (Epoch 115): Loss/seq after 01450 batchs: 742.5465698242188
INFO:root:Train (Epoch 115): Loss/seq after 01500 batchs: 745.5977783203125
INFO:root:Train (Epoch 115): Loss/seq after 01550 batchs: 746.7545166015625
INFO:root:Train (Epoch 115): Loss/seq after 01600 batchs: 738.6639404296875
INFO:root:Train (Epoch 115): Loss/seq after 01650 batchs: 734.4285278320312
INFO:root:Train (Epoch 115): Loss/seq after 01700 batchs: 734.0155639648438
INFO:root:Train (Epoch 115): Loss/seq after 01750 batchs: 728.9773559570312
INFO:root:Train (Epoch 115): Loss/seq after 01800 batchs: 723.9142456054688
INFO:root:Train (Epoch 115): Loss/seq after 01850 batchs: 717.5035400390625
INFO:root:Train (Epoch 115): Loss/seq after 01900 batchs: 716.8540649414062
INFO:root:Train (Epoch 115): Loss/seq after 01950 batchs: 713.8229370117188
INFO:root:Train (Epoch 115): Loss/seq after 02000 batchs: 710.1506958007812
INFO:root:Train (Epoch 115): Loss/seq after 02050 batchs: 706.7476196289062
INFO:root:Train (Epoch 115): Loss/seq after 02100 batchs: 701.9066162109375
INFO:root:Train (Epoch 115): Loss/seq after 02150 batchs: 698.33203125
INFO:root:Train (Epoch 115): Loss/seq after 02200 batchs: 693.5927734375
INFO:root:Train (Epoch 115): Loss/seq after 02250 batchs: 692.3070068359375
INFO:root:Train (Epoch 115): Loss/seq after 02300 batchs: 695.3899536132812
INFO:root:Train (Epoch 115): Loss/seq after 02350 batchs: 689.3323974609375
INFO:root:Train (Epoch 115): Loss/seq after 02400 batchs: 689.117431640625
INFO:root:Train (Epoch 115): Loss/seq after 02450 batchs: 682.4930419921875
INFO:root:Train (Epoch 115): Loss/seq after 02500 batchs: 672.2200927734375
INFO:root:Train (Epoch 115): Loss/seq after 02550 batchs: 664.6275024414062
INFO:root:Train (Epoch 115): Loss/seq after 02600 batchs: 663.2652587890625
INFO:root:Train (Epoch 115): Loss/seq after 02650 batchs: 660.441650390625
INFO:root:Train (Epoch 115): Loss/seq after 02700 batchs: 657.58154296875
INFO:root:Train (Epoch 115): Loss/seq after 02750 batchs: 662.0634765625
INFO:root:Train (Epoch 115): Loss/seq after 02800 batchs: 664.0989990234375
INFO:root:Train (Epoch 115): Loss/seq after 02850 batchs: 663.5350341796875
INFO:root:Train (Epoch 115): Loss/seq after 02900 batchs: 664.3590087890625
INFO:root:Train (Epoch 115): Loss/seq after 02950 batchs: 662.013916015625
INFO:root:Train (Epoch 115): Loss/seq after 03000 batchs: 665.7025146484375
INFO:root:Train (Epoch 115): Loss/seq after 03050 batchs: 668.8838500976562
INFO:root:Train (Epoch 115): Loss/seq after 03100 batchs: 673.8125
INFO:root:Train (Epoch 115): Loss/seq after 03150 batchs: 681.0150756835938
INFO:root:Train (Epoch 115): Loss/seq after 03200 batchs: 688.064208984375
INFO:root:Train (Epoch 115): Loss/seq after 03250 batchs: 694.1754760742188
INFO:root:Train (Epoch 115): Loss/seq after 03300 batchs: 692.6124877929688
INFO:root:Train (Epoch 115): Loss/seq after 03350 batchs: 692.4105224609375
INFO:root:Train (Epoch 115): Loss/seq after 03400 batchs: 686.6492309570312
INFO:root:Train (Epoch 115): Loss/seq after 03450 batchs: 683.80859375
INFO:root:Train (Epoch 115): Loss/seq after 03500 batchs: 683.6420288085938
INFO:root:Train (Epoch 115): Loss/seq after 03550 batchs: 679.6781005859375
INFO:root:Train (Epoch 115): Loss/seq after 03600 batchs: 687.5955810546875
INFO:root:Train (Epoch 115): Loss/seq after 03650 batchs: 684.1317749023438
INFO:root:Train (Epoch 115): Loss/seq after 03700 batchs: 685.4901123046875
INFO:root:Train (Epoch 115): Loss/seq after 03750 batchs: 689.5184936523438
INFO:root:Train (Epoch 115): Loss/seq after 03800 batchs: 685.8407592773438
INFO:root:Train (Epoch 115): Loss/seq after 03850 batchs: 684.5367431640625
INFO:root:Train (Epoch 115): Loss/seq after 03900 batchs: 688.7417602539062
INFO:root:Train (Epoch 115): Loss/seq after 03950 batchs: 693.1279907226562
INFO:root:Train (Epoch 115): Loss/seq after 04000 batchs: 688.3709716796875
INFO:root:Train (Epoch 115): Loss/seq after 04050 batchs: 683.70654296875
INFO:root:Train (Epoch 115): Loss/seq after 04100 batchs: 680.96875
INFO:root:Train (Epoch 115): Loss/seq after 04150 batchs: 679.8718872070312
INFO:root:Train (Epoch 115): Loss/seq after 04200 batchs: 677.50244140625
INFO:root:Train (Epoch 115): Loss/seq after 04250 batchs: 675.2112426757812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 115): Loss/seq after 00000 batches: 555.3917236328125
INFO:root:# Valid (Epoch 115): Loss/seq after 00050 batches: 721.5797119140625
INFO:root:# Valid (Epoch 115): Loss/seq after 00100 batches: 797.664794921875
INFO:root:# Valid (Epoch 115): Loss/seq after 00150 batches: 605.1056518554688
INFO:root:# Valid (Epoch 115): Loss/seq after 00200 batches: 564.1373291015625
INFO:root:Artifacts: Make stick videos for epoch 115
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_115_on_20220414_010001.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_115_index_630_on_20220414_010001.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 116): Loss/seq after 00000 batchs: 1464.2403564453125
INFO:root:Train (Epoch 116): Loss/seq after 00050 batchs: 936.1698608398438
INFO:root:Train (Epoch 116): Loss/seq after 00100 batchs: 983.2272338867188
INFO:root:Train (Epoch 116): Loss/seq after 00150 batchs: 870.9548950195312
INFO:root:Train (Epoch 116): Loss/seq after 00200 batchs: 975.4901123046875
INFO:root:Train (Epoch 116): Loss/seq after 00250 batchs: 1085.873779296875
INFO:root:Train (Epoch 116): Loss/seq after 00300 batchs: 1057.342529296875
INFO:root:Train (Epoch 116): Loss/seq after 00350 batchs: 981.0143432617188
INFO:root:Train (Epoch 116): Loss/seq after 00400 batchs: 986.8905639648438
INFO:root:Train (Epoch 116): Loss/seq after 00450 batchs: 954.4070434570312
INFO:root:Train (Epoch 116): Loss/seq after 00500 batchs: 926.3396606445312
INFO:root:Train (Epoch 116): Loss/seq after 00550 batchs: 893.0725708007812
INFO:root:Train (Epoch 116): Loss/seq after 00600 batchs: 858.7710571289062
INFO:root:Train (Epoch 116): Loss/seq after 00650 batchs: 856.9432373046875
INFO:root:Train (Epoch 116): Loss/seq after 00700 batchs: 836.3118896484375
INFO:root:Train (Epoch 116): Loss/seq after 00750 batchs: 854.0408935546875
INFO:root:Train (Epoch 116): Loss/seq after 00800 batchs: 849.5250854492188
INFO:root:Train (Epoch 116): Loss/seq after 00850 batchs: 821.959228515625
INFO:root:Train (Epoch 116): Loss/seq after 00900 batchs: 802.7943725585938
INFO:root:Train (Epoch 116): Loss/seq after 00950 batchs: 803.835205078125
INFO:root:Train (Epoch 116): Loss/seq after 01000 batchs: 798.3212280273438
INFO:root:Train (Epoch 116): Loss/seq after 01050 batchs: 782.5179443359375
INFO:root:Train (Epoch 116): Loss/seq after 01100 batchs: 768.8594970703125
INFO:root:Train (Epoch 116): Loss/seq after 01150 batchs: 749.5946655273438
INFO:root:Train (Epoch 116): Loss/seq after 01200 batchs: 750.2981567382812
INFO:root:Train (Epoch 116): Loss/seq after 01250 batchs: 745.8418579101562
INFO:root:Train (Epoch 116): Loss/seq after 01300 batchs: 734.6281127929688
INFO:root:Train (Epoch 116): Loss/seq after 01350 batchs: 724.6842041015625
INFO:root:Train (Epoch 116): Loss/seq after 01400 batchs: 735.0203247070312
INFO:root:Train (Epoch 116): Loss/seq after 01450 batchs: 733.6680908203125
INFO:root:Train (Epoch 116): Loss/seq after 01500 batchs: 736.9105834960938
INFO:root:Train (Epoch 116): Loss/seq after 01550 batchs: 737.2592163085938
INFO:root:Train (Epoch 116): Loss/seq after 01600 batchs: 729.0491333007812
INFO:root:Train (Epoch 116): Loss/seq after 01650 batchs: 724.552001953125
INFO:root:Train (Epoch 116): Loss/seq after 01700 batchs: 723.9700927734375
INFO:root:Train (Epoch 116): Loss/seq after 01750 batchs: 719.1264038085938
INFO:root:Train (Epoch 116): Loss/seq after 01800 batchs: 714.1788940429688
INFO:root:Train (Epoch 116): Loss/seq after 01850 batchs: 708.1660766601562
INFO:root:Train (Epoch 116): Loss/seq after 01900 batchs: 707.31298828125
INFO:root:Train (Epoch 116): Loss/seq after 01950 batchs: 704.2859497070312
INFO:root:Train (Epoch 116): Loss/seq after 02000 batchs: 701.0044555664062
INFO:root:Train (Epoch 116): Loss/seq after 02050 batchs: 697.8452758789062
INFO:root:Train (Epoch 116): Loss/seq after 02100 batchs: 693.177490234375
INFO:root:Train (Epoch 116): Loss/seq after 02150 batchs: 689.4701538085938
INFO:root:Train (Epoch 116): Loss/seq after 02200 batchs: 684.9107666015625
INFO:root:Train (Epoch 116): Loss/seq after 02250 batchs: 683.9617309570312
INFO:root:Train (Epoch 116): Loss/seq after 02300 batchs: 686.7154541015625
INFO:root:Train (Epoch 116): Loss/seq after 02350 batchs: 681.2860717773438
INFO:root:Train (Epoch 116): Loss/seq after 02400 batchs: 681.3750610351562
INFO:root:Train (Epoch 116): Loss/seq after 02450 batchs: 675.0591430664062
INFO:root:Train (Epoch 116): Loss/seq after 02500 batchs: 664.9232177734375
INFO:root:Train (Epoch 116): Loss/seq after 02550 batchs: 657.4764404296875
INFO:root:Train (Epoch 116): Loss/seq after 02600 batchs: 656.2970581054688
INFO:root:Train (Epoch 116): Loss/seq after 02650 batchs: 653.61474609375
INFO:root:Train (Epoch 116): Loss/seq after 02700 batchs: 650.7149658203125
INFO:root:Train (Epoch 116): Loss/seq after 02750 batchs: 655.8588256835938
INFO:root:Train (Epoch 116): Loss/seq after 02800 batchs: 657.6783447265625
INFO:root:Train (Epoch 116): Loss/seq after 02850 batchs: 656.924560546875
INFO:root:Train (Epoch 116): Loss/seq after 02900 batchs: 657.61767578125
INFO:root:Train (Epoch 116): Loss/seq after 02950 batchs: 655.3861694335938
INFO:root:Train (Epoch 116): Loss/seq after 03000 batchs: 659.1238403320312
INFO:root:Train (Epoch 116): Loss/seq after 03050 batchs: 662.123779296875
INFO:root:Train (Epoch 116): Loss/seq after 03100 batchs: 667.9007568359375
INFO:root:Train (Epoch 116): Loss/seq after 03150 batchs: 675.4598999023438
INFO:root:Train (Epoch 116): Loss/seq after 03200 batchs: 682.4661254882812
INFO:root:Train (Epoch 116): Loss/seq after 03250 batchs: 689.1643676757812
INFO:root:Train (Epoch 116): Loss/seq after 03300 batchs: 688.4884033203125
INFO:root:Train (Epoch 116): Loss/seq after 03350 batchs: 689.1554565429688
INFO:root:Train (Epoch 116): Loss/seq after 03400 batchs: 683.4810180664062
INFO:root:Train (Epoch 116): Loss/seq after 03450 batchs: 680.646484375
INFO:root:Train (Epoch 116): Loss/seq after 03500 batchs: 680.552978515625
INFO:root:Train (Epoch 116): Loss/seq after 03550 batchs: 676.6815795898438
INFO:root:Train (Epoch 116): Loss/seq after 03600 batchs: 684.7335205078125
INFO:root:Train (Epoch 116): Loss/seq after 03650 batchs: 681.206298828125
INFO:root:Train (Epoch 116): Loss/seq after 03700 batchs: 682.546630859375
INFO:root:Train (Epoch 116): Loss/seq after 03750 batchs: 686.4828491210938
INFO:root:Train (Epoch 116): Loss/seq after 03800 batchs: 682.8070068359375
INFO:root:Train (Epoch 116): Loss/seq after 03850 batchs: 681.3555908203125
INFO:root:Train (Epoch 116): Loss/seq after 03900 batchs: 685.94287109375
INFO:root:Train (Epoch 116): Loss/seq after 03950 batchs: 690.7247924804688
INFO:root:Train (Epoch 116): Loss/seq after 04000 batchs: 685.9488525390625
INFO:root:Train (Epoch 116): Loss/seq after 04050 batchs: 681.2686767578125
INFO:root:Train (Epoch 116): Loss/seq after 04100 batchs: 678.5072021484375
INFO:root:Train (Epoch 116): Loss/seq after 04150 batchs: 677.44970703125
INFO:root:Train (Epoch 116): Loss/seq after 04200 batchs: 675.107421875
INFO:root:Train (Epoch 116): Loss/seq after 04250 batchs: 672.7567138671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 116): Loss/seq after 00000 batches: 548.6838989257812
INFO:root:# Valid (Epoch 116): Loss/seq after 00050 batches: 755.0777587890625
INFO:root:# Valid (Epoch 116): Loss/seq after 00100 batches: 805.5894775390625
INFO:root:# Valid (Epoch 116): Loss/seq after 00150 batches: 606.0292358398438
INFO:root:# Valid (Epoch 116): Loss/seq after 00200 batches: 563.7787475585938
INFO:root:Artifacts: Make stick videos for epoch 116
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_116_on_20220414_010518.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_116_index_1246_on_20220414_010518.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 117): Loss/seq after 00000 batchs: 1293.9720458984375
INFO:root:Train (Epoch 117): Loss/seq after 00050 batchs: 907.124267578125
INFO:root:Train (Epoch 117): Loss/seq after 00100 batchs: 949.656982421875
INFO:root:Train (Epoch 117): Loss/seq after 00150 batchs: 848.326904296875
INFO:root:Train (Epoch 117): Loss/seq after 00200 batchs: 958.8724365234375
INFO:root:Train (Epoch 117): Loss/seq after 00250 batchs: 1068.9559326171875
INFO:root:Train (Epoch 117): Loss/seq after 00300 batchs: 1043.391357421875
INFO:root:Train (Epoch 117): Loss/seq after 00350 batchs: 967.9856567382812
INFO:root:Train (Epoch 117): Loss/seq after 00400 batchs: 976.4398803710938
INFO:root:Train (Epoch 117): Loss/seq after 00450 batchs: 944.6339721679688
INFO:root:Train (Epoch 117): Loss/seq after 00500 batchs: 917.9129028320312
INFO:root:Train (Epoch 117): Loss/seq after 00550 batchs: 884.777587890625
INFO:root:Train (Epoch 117): Loss/seq after 00600 batchs: 850.8623046875
INFO:root:Train (Epoch 117): Loss/seq after 00650 batchs: 852.8076171875
INFO:root:Train (Epoch 117): Loss/seq after 00700 batchs: 831.75537109375
INFO:root:Train (Epoch 117): Loss/seq after 00750 batchs: 850.9618530273438
INFO:root:Train (Epoch 117): Loss/seq after 00800 batchs: 846.93017578125
INFO:root:Train (Epoch 117): Loss/seq after 00850 batchs: 818.4441528320312
INFO:root:Train (Epoch 117): Loss/seq after 00900 batchs: 799.1492309570312
INFO:root:Train (Epoch 117): Loss/seq after 00950 batchs: 799.3814086914062
INFO:root:Train (Epoch 117): Loss/seq after 01000 batchs: 793.3348388671875
INFO:root:Train (Epoch 117): Loss/seq after 01050 batchs: 777.5090942382812
INFO:root:Train (Epoch 117): Loss/seq after 01100 batchs: 763.9083862304688
INFO:root:Train (Epoch 117): Loss/seq after 01150 batchs: 744.616943359375
INFO:root:Train (Epoch 117): Loss/seq after 01200 batchs: 745.0543823242188
INFO:root:Train (Epoch 117): Loss/seq after 01250 batchs: 740.29345703125
INFO:root:Train (Epoch 117): Loss/seq after 01300 batchs: 729.142822265625
INFO:root:Train (Epoch 117): Loss/seq after 01350 batchs: 718.6743774414062
INFO:root:Train (Epoch 117): Loss/seq after 01400 batchs: 729.2156982421875
INFO:root:Train (Epoch 117): Loss/seq after 01450 batchs: 727.9683837890625
INFO:root:Train (Epoch 117): Loss/seq after 01500 batchs: 731.137451171875
INFO:root:Train (Epoch 117): Loss/seq after 01550 batchs: 731.8118896484375
INFO:root:Train (Epoch 117): Loss/seq after 01600 batchs: 723.6982421875
INFO:root:Train (Epoch 117): Loss/seq after 01650 batchs: 719.1712036132812
INFO:root:Train (Epoch 117): Loss/seq after 01700 batchs: 719.0296630859375
INFO:root:Train (Epoch 117): Loss/seq after 01750 batchs: 714.4005126953125
INFO:root:Train (Epoch 117): Loss/seq after 01800 batchs: 709.5068969726562
INFO:root:Train (Epoch 117): Loss/seq after 01850 batchs: 703.3456420898438
INFO:root:Train (Epoch 117): Loss/seq after 01900 batchs: 702.8109130859375
INFO:root:Train (Epoch 117): Loss/seq after 01950 batchs: 699.5155639648438
INFO:root:Train (Epoch 117): Loss/seq after 02000 batchs: 696.1139526367188
INFO:root:Train (Epoch 117): Loss/seq after 02050 batchs: 692.8727416992188
INFO:root:Train (Epoch 117): Loss/seq after 02100 batchs: 688.2552490234375
INFO:root:Train (Epoch 117): Loss/seq after 02150 batchs: 684.738525390625
INFO:root:Train (Epoch 117): Loss/seq after 02200 batchs: 680.2398681640625
INFO:root:Train (Epoch 117): Loss/seq after 02250 batchs: 679.5618896484375
INFO:root:Train (Epoch 117): Loss/seq after 02300 batchs: 682.8084106445312
INFO:root:Train (Epoch 117): Loss/seq after 02350 batchs: 677.6353149414062
INFO:root:Train (Epoch 117): Loss/seq after 02400 batchs: 677.7020263671875
INFO:root:Train (Epoch 117): Loss/seq after 02450 batchs: 671.321533203125
INFO:root:Train (Epoch 117): Loss/seq after 02500 batchs: 661.283203125
INFO:root:Train (Epoch 117): Loss/seq after 02550 batchs: 653.7684326171875
INFO:root:Train (Epoch 117): Loss/seq after 02600 batchs: 652.50732421875
INFO:root:Train (Epoch 117): Loss/seq after 02650 batchs: 649.7625122070312
INFO:root:Train (Epoch 117): Loss/seq after 02700 batchs: 647.1387329101562
INFO:root:Train (Epoch 117): Loss/seq after 02750 batchs: 651.3084716796875
INFO:root:Train (Epoch 117): Loss/seq after 02800 batchs: 652.8331909179688
INFO:root:Train (Epoch 117): Loss/seq after 02850 batchs: 652.6038818359375
INFO:root:Train (Epoch 117): Loss/seq after 02900 batchs: 654.2240600585938
INFO:root:Train (Epoch 117): Loss/seq after 02950 batchs: 652.0846557617188
INFO:root:Train (Epoch 117): Loss/seq after 03000 batchs: 655.860595703125
INFO:root:Train (Epoch 117): Loss/seq after 03050 batchs: 659.3309936523438
INFO:root:Train (Epoch 117): Loss/seq after 03100 batchs: 665.0847778320312
INFO:root:Train (Epoch 117): Loss/seq after 03150 batchs: 672.7059936523438
INFO:root:Train (Epoch 117): Loss/seq after 03200 batchs: 679.8546752929688
INFO:root:Train (Epoch 117): Loss/seq after 03250 batchs: 686.0817260742188
INFO:root:Train (Epoch 117): Loss/seq after 03300 batchs: 685.511474609375
INFO:root:Train (Epoch 117): Loss/seq after 03350 batchs: 685.803955078125
INFO:root:Train (Epoch 117): Loss/seq after 03400 batchs: 680.1297607421875
INFO:root:Train (Epoch 117): Loss/seq after 03450 batchs: 677.447265625
INFO:root:Train (Epoch 117): Loss/seq after 03500 batchs: 677.4923706054688
INFO:root:Train (Epoch 117): Loss/seq after 03550 batchs: 673.5802001953125
INFO:root:Train (Epoch 117): Loss/seq after 03600 batchs: 681.3338623046875
INFO:root:Train (Epoch 117): Loss/seq after 03650 batchs: 677.5633544921875
INFO:root:Train (Epoch 117): Loss/seq after 03700 batchs: 678.9482421875
INFO:root:Train (Epoch 117): Loss/seq after 03750 batchs: 682.935791015625
INFO:root:Train (Epoch 117): Loss/seq after 03800 batchs: 679.2877807617188
INFO:root:Train (Epoch 117): Loss/seq after 03850 batchs: 677.9412841796875
INFO:root:Train (Epoch 117): Loss/seq after 03900 batchs: 682.6314697265625
INFO:root:Train (Epoch 117): Loss/seq after 03950 batchs: 686.6448364257812
INFO:root:Train (Epoch 117): Loss/seq after 04000 batchs: 681.9481201171875
INFO:root:Train (Epoch 117): Loss/seq after 04050 batchs: 677.3248901367188
INFO:root:Train (Epoch 117): Loss/seq after 04100 batchs: 674.5346069335938
INFO:root:Train (Epoch 117): Loss/seq after 04150 batchs: 673.4227294921875
INFO:root:Train (Epoch 117): Loss/seq after 04200 batchs: 671.068115234375
INFO:root:Train (Epoch 117): Loss/seq after 04250 batchs: 668.7142944335938
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 117): Loss/seq after 00000 batches: 638.8707885742188
INFO:root:# Valid (Epoch 117): Loss/seq after 00050 batches: 809.6708984375
INFO:root:# Valid (Epoch 117): Loss/seq after 00100 batches: 847.6582641601562
INFO:root:# Valid (Epoch 117): Loss/seq after 00150 batches: 636.2720336914062
INFO:root:# Valid (Epoch 117): Loss/seq after 00200 batches: 585.7127685546875
INFO:root:Artifacts: Make stick videos for epoch 117
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_117_on_20220414_011036.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_117_index_1486_on_20220414_011036.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 118): Loss/seq after 00000 batchs: 1306.044677734375
INFO:root:Train (Epoch 118): Loss/seq after 00050 batchs: 898.526611328125
INFO:root:Train (Epoch 118): Loss/seq after 00100 batchs: 940.0209350585938
INFO:root:Train (Epoch 118): Loss/seq after 00150 batchs: 840.182861328125
INFO:root:Train (Epoch 118): Loss/seq after 00200 batchs: 942.943603515625
INFO:root:Train (Epoch 118): Loss/seq after 00250 batchs: 1055.7481689453125
INFO:root:Train (Epoch 118): Loss/seq after 00300 batchs: 1033.2999267578125
INFO:root:Train (Epoch 118): Loss/seq after 00350 batchs: 959.3641357421875
INFO:root:Train (Epoch 118): Loss/seq after 00400 batchs: 968.533447265625
INFO:root:Train (Epoch 118): Loss/seq after 00450 batchs: 937.48046875
INFO:root:Train (Epoch 118): Loss/seq after 00500 batchs: 909.35791015625
INFO:root:Train (Epoch 118): Loss/seq after 00550 batchs: 876.7894287109375
INFO:root:Train (Epoch 118): Loss/seq after 00600 batchs: 843.9854736328125
INFO:root:Train (Epoch 118): Loss/seq after 00650 batchs: 843.9039916992188
INFO:root:Train (Epoch 118): Loss/seq after 00700 batchs: 825.6746215820312
INFO:root:Train (Epoch 118): Loss/seq after 00750 batchs: 842.6527709960938
INFO:root:Train (Epoch 118): Loss/seq after 00800 batchs: 837.423583984375
INFO:root:Train (Epoch 118): Loss/seq after 00850 batchs: 809.9365234375
INFO:root:Train (Epoch 118): Loss/seq after 00900 batchs: 791.6553955078125
INFO:root:Train (Epoch 118): Loss/seq after 00950 batchs: 793.1019287109375
INFO:root:Train (Epoch 118): Loss/seq after 01000 batchs: 787.0906982421875
INFO:root:Train (Epoch 118): Loss/seq after 01050 batchs: 772.69384765625
INFO:root:Train (Epoch 118): Loss/seq after 01100 batchs: 760.4200439453125
INFO:root:Train (Epoch 118): Loss/seq after 01150 batchs: 741.5298461914062
INFO:root:Train (Epoch 118): Loss/seq after 01200 batchs: 741.859619140625
INFO:root:Train (Epoch 118): Loss/seq after 01250 batchs: 737.7039184570312
INFO:root:Train (Epoch 118): Loss/seq after 01300 batchs: 725.822021484375
INFO:root:Train (Epoch 118): Loss/seq after 01350 batchs: 715.4948120117188
INFO:root:Train (Epoch 118): Loss/seq after 01400 batchs: 726.78173828125
INFO:root:Train (Epoch 118): Loss/seq after 01450 batchs: 725.4457397460938
INFO:root:Train (Epoch 118): Loss/seq after 01500 batchs: 728.707275390625
INFO:root:Train (Epoch 118): Loss/seq after 01550 batchs: 729.2009887695312
INFO:root:Train (Epoch 118): Loss/seq after 01600 batchs: 721.1097412109375
INFO:root:Train (Epoch 118): Loss/seq after 01650 batchs: 716.6854858398438
INFO:root:Train (Epoch 118): Loss/seq after 01700 batchs: 716.515380859375
INFO:root:Train (Epoch 118): Loss/seq after 01750 batchs: 711.6910400390625
INFO:root:Train (Epoch 118): Loss/seq after 01800 batchs: 706.7940673828125
INFO:root:Train (Epoch 118): Loss/seq after 01850 batchs: 700.7752685546875
INFO:root:Train (Epoch 118): Loss/seq after 01900 batchs: 700.07275390625
INFO:root:Train (Epoch 118): Loss/seq after 01950 batchs: 696.8716430664062
INFO:root:Train (Epoch 118): Loss/seq after 02000 batchs: 693.5514526367188
INFO:root:Train (Epoch 118): Loss/seq after 02050 batchs: 690.2687377929688
INFO:root:Train (Epoch 118): Loss/seq after 02100 batchs: 685.7020874023438
INFO:root:Train (Epoch 118): Loss/seq after 02150 batchs: 682.094482421875
INFO:root:Train (Epoch 118): Loss/seq after 02200 batchs: 677.403564453125
INFO:root:Train (Epoch 118): Loss/seq after 02250 batchs: 676.1009521484375
INFO:root:Train (Epoch 118): Loss/seq after 02300 batchs: 677.5657348632812
INFO:root:Train (Epoch 118): Loss/seq after 02350 batchs: 671.6972045898438
INFO:root:Train (Epoch 118): Loss/seq after 02400 batchs: 671.637939453125
INFO:root:Train (Epoch 118): Loss/seq after 02450 batchs: 665.3126220703125
INFO:root:Train (Epoch 118): Loss/seq after 02500 batchs: 655.3243408203125
INFO:root:Train (Epoch 118): Loss/seq after 02550 batchs: 647.9218139648438
INFO:root:Train (Epoch 118): Loss/seq after 02600 batchs: 646.5928955078125
INFO:root:Train (Epoch 118): Loss/seq after 02650 batchs: 643.854736328125
INFO:root:Train (Epoch 118): Loss/seq after 02700 batchs: 640.9957275390625
INFO:root:Train (Epoch 118): Loss/seq after 02750 batchs: 643.8859252929688
INFO:root:Train (Epoch 118): Loss/seq after 02800 batchs: 645.5709228515625
INFO:root:Train (Epoch 118): Loss/seq after 02850 batchs: 645.13134765625
INFO:root:Train (Epoch 118): Loss/seq after 02900 batchs: 646.0383911132812
INFO:root:Train (Epoch 118): Loss/seq after 02950 batchs: 643.945556640625
INFO:root:Train (Epoch 118): Loss/seq after 03000 batchs: 647.7988891601562
INFO:root:Train (Epoch 118): Loss/seq after 03050 batchs: 650.279541015625
INFO:root:Train (Epoch 118): Loss/seq after 03100 batchs: 655.1720581054688
INFO:root:Train (Epoch 118): Loss/seq after 03150 batchs: 662.3820190429688
INFO:root:Train (Epoch 118): Loss/seq after 03200 batchs: 669.1839599609375
INFO:root:Train (Epoch 118): Loss/seq after 03250 batchs: 674.9052734375
INFO:root:Train (Epoch 118): Loss/seq after 03300 batchs: 674.1043090820312
INFO:root:Train (Epoch 118): Loss/seq after 03350 batchs: 674.2452392578125
INFO:root:Train (Epoch 118): Loss/seq after 03400 batchs: 668.7197265625
INFO:root:Train (Epoch 118): Loss/seq after 03450 batchs: 666.1558837890625
INFO:root:Train (Epoch 118): Loss/seq after 03500 batchs: 666.2537231445312
INFO:root:Train (Epoch 118): Loss/seq after 03550 batchs: 662.4459228515625
INFO:root:Train (Epoch 118): Loss/seq after 03600 batchs: 670.2877197265625
INFO:root:Train (Epoch 118): Loss/seq after 03650 batchs: 666.68505859375
INFO:root:Train (Epoch 118): Loss/seq after 03700 batchs: 668.1416015625
INFO:root:Train (Epoch 118): Loss/seq after 03750 batchs: 672.2423095703125
INFO:root:Train (Epoch 118): Loss/seq after 03800 batchs: 668.740234375
INFO:root:Train (Epoch 118): Loss/seq after 03850 batchs: 667.3098754882812
INFO:root:Train (Epoch 118): Loss/seq after 03900 batchs: 671.8779907226562
INFO:root:Train (Epoch 118): Loss/seq after 03950 batchs: 675.9633178710938
INFO:root:Train (Epoch 118): Loss/seq after 04000 batchs: 671.3133544921875
INFO:root:Train (Epoch 118): Loss/seq after 04050 batchs: 666.7833862304688
INFO:root:Train (Epoch 118): Loss/seq after 04100 batchs: 664.1400146484375
INFO:root:Train (Epoch 118): Loss/seq after 04150 batchs: 663.2296142578125
INFO:root:Train (Epoch 118): Loss/seq after 04200 batchs: 660.9628295898438
INFO:root:Train (Epoch 118): Loss/seq after 04250 batchs: 658.6551513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 118): Loss/seq after 00000 batches: 529.9747314453125
INFO:root:# Valid (Epoch 118): Loss/seq after 00050 batches: 848.2925415039062
INFO:root:# Valid (Epoch 118): Loss/seq after 00100 batches: 876.0036010742188
INFO:root:# Valid (Epoch 118): Loss/seq after 00150 batches: 656.799072265625
INFO:root:# Valid (Epoch 118): Loss/seq after 00200 batches: 601.1441040039062
INFO:root:Artifacts: Make stick videos for epoch 118
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_118_on_20220414_011554.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_118_index_361_on_20220414_011554.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 119): Loss/seq after 00000 batchs: 1286.491943359375
INFO:root:Train (Epoch 119): Loss/seq after 00050 batchs: 909.9539184570312
INFO:root:Train (Epoch 119): Loss/seq after 00100 batchs: 961.2990112304688
INFO:root:Train (Epoch 119): Loss/seq after 00150 batchs: 864.5353393554688
INFO:root:Train (Epoch 119): Loss/seq after 00200 batchs: 962.8881225585938
INFO:root:Train (Epoch 119): Loss/seq after 00250 batchs: 1069.849609375
INFO:root:Train (Epoch 119): Loss/seq after 00300 batchs: 1042.3675537109375
INFO:root:Train (Epoch 119): Loss/seq after 00350 batchs: 967.5313110351562
INFO:root:Train (Epoch 119): Loss/seq after 00400 batchs: 979.0589599609375
INFO:root:Train (Epoch 119): Loss/seq after 00450 batchs: 947.4720458984375
INFO:root:Train (Epoch 119): Loss/seq after 00500 batchs: 921.070556640625
INFO:root:Train (Epoch 119): Loss/seq after 00550 batchs: 887.67431640625
INFO:root:Train (Epoch 119): Loss/seq after 00600 batchs: 853.4410400390625
INFO:root:Train (Epoch 119): Loss/seq after 00650 batchs: 848.98779296875
INFO:root:Train (Epoch 119): Loss/seq after 00700 batchs: 826.4050903320312
INFO:root:Train (Epoch 119): Loss/seq after 00750 batchs: 844.8538818359375
INFO:root:Train (Epoch 119): Loss/seq after 00800 batchs: 839.755859375
INFO:root:Train (Epoch 119): Loss/seq after 00850 batchs: 812.4041137695312
INFO:root:Train (Epoch 119): Loss/seq after 00900 batchs: 794.3995361328125
INFO:root:Train (Epoch 119): Loss/seq after 00950 batchs: 796.897216796875
INFO:root:Train (Epoch 119): Loss/seq after 01000 batchs: 790.7388305664062
INFO:root:Train (Epoch 119): Loss/seq after 01050 batchs: 775.6509399414062
INFO:root:Train (Epoch 119): Loss/seq after 01100 batchs: 762.7199096679688
INFO:root:Train (Epoch 119): Loss/seq after 01150 batchs: 743.4409790039062
INFO:root:Train (Epoch 119): Loss/seq after 01200 batchs: 744.0557250976562
INFO:root:Train (Epoch 119): Loss/seq after 01250 batchs: 739.8322143554688
INFO:root:Train (Epoch 119): Loss/seq after 01300 batchs: 728.2664794921875
INFO:root:Train (Epoch 119): Loss/seq after 01350 batchs: 717.3114624023438
INFO:root:Train (Epoch 119): Loss/seq after 01400 batchs: 727.58544921875
INFO:root:Train (Epoch 119): Loss/seq after 01450 batchs: 725.9415283203125
INFO:root:Train (Epoch 119): Loss/seq after 01500 batchs: 729.1256713867188
INFO:root:Train (Epoch 119): Loss/seq after 01550 batchs: 729.71240234375
INFO:root:Train (Epoch 119): Loss/seq after 01600 batchs: 721.5863037109375
INFO:root:Train (Epoch 119): Loss/seq after 01650 batchs: 717.094482421875
INFO:root:Train (Epoch 119): Loss/seq after 01700 batchs: 716.8892211914062
INFO:root:Train (Epoch 119): Loss/seq after 01750 batchs: 712.0230712890625
INFO:root:Train (Epoch 119): Loss/seq after 01800 batchs: 707.0708618164062
INFO:root:Train (Epoch 119): Loss/seq after 01850 batchs: 700.9176025390625
INFO:root:Train (Epoch 119): Loss/seq after 01900 batchs: 700.1149291992188
INFO:root:Train (Epoch 119): Loss/seq after 01950 batchs: 697.1885986328125
INFO:root:Train (Epoch 119): Loss/seq after 02000 batchs: 693.6531982421875
INFO:root:Train (Epoch 119): Loss/seq after 02050 batchs: 690.441162109375
INFO:root:Train (Epoch 119): Loss/seq after 02100 batchs: 685.9026489257812
INFO:root:Train (Epoch 119): Loss/seq after 02150 batchs: 682.3585815429688
INFO:root:Train (Epoch 119): Loss/seq after 02200 batchs: 677.753662109375
INFO:root:Train (Epoch 119): Loss/seq after 02250 batchs: 676.8226928710938
INFO:root:Train (Epoch 119): Loss/seq after 02300 batchs: 678.5948486328125
INFO:root:Train (Epoch 119): Loss/seq after 02350 batchs: 672.6812744140625
INFO:root:Train (Epoch 119): Loss/seq after 02400 batchs: 672.5570678710938
INFO:root:Train (Epoch 119): Loss/seq after 02450 batchs: 666.096923828125
INFO:root:Train (Epoch 119): Loss/seq after 02500 batchs: 656.0955810546875
INFO:root:Train (Epoch 119): Loss/seq after 02550 batchs: 648.6859130859375
INFO:root:Train (Epoch 119): Loss/seq after 02600 batchs: 647.2882080078125
INFO:root:Train (Epoch 119): Loss/seq after 02650 batchs: 644.4024658203125
INFO:root:Train (Epoch 119): Loss/seq after 02700 batchs: 641.4713134765625
INFO:root:Train (Epoch 119): Loss/seq after 02750 batchs: 644.1321411132812
INFO:root:Train (Epoch 119): Loss/seq after 02800 batchs: 645.9661865234375
INFO:root:Train (Epoch 119): Loss/seq after 02850 batchs: 645.3670654296875
INFO:root:Train (Epoch 119): Loss/seq after 02900 batchs: 646.2603759765625
INFO:root:Train (Epoch 119): Loss/seq after 02950 batchs: 644.1342163085938
INFO:root:Train (Epoch 119): Loss/seq after 03000 batchs: 648.0026245117188
INFO:root:Train (Epoch 119): Loss/seq after 03050 batchs: 650.6754150390625
INFO:root:Train (Epoch 119): Loss/seq after 03100 batchs: 655.3656005859375
INFO:root:Train (Epoch 119): Loss/seq after 03150 batchs: 662.4713745117188
INFO:root:Train (Epoch 119): Loss/seq after 03200 batchs: 668.6866455078125
INFO:root:Train (Epoch 119): Loss/seq after 03250 batchs: 675.4561767578125
INFO:root:Train (Epoch 119): Loss/seq after 03300 batchs: 674.399658203125
INFO:root:Train (Epoch 119): Loss/seq after 03350 batchs: 674.130859375
INFO:root:Train (Epoch 119): Loss/seq after 03400 batchs: 668.6495971679688
INFO:root:Train (Epoch 119): Loss/seq after 03450 batchs: 666.0496826171875
INFO:root:Train (Epoch 119): Loss/seq after 03500 batchs: 665.6173095703125
INFO:root:Train (Epoch 119): Loss/seq after 03550 batchs: 661.683837890625
INFO:root:Train (Epoch 119): Loss/seq after 03600 batchs: 669.485107421875
INFO:root:Train (Epoch 119): Loss/seq after 03650 batchs: 665.9171752929688
INFO:root:Train (Epoch 119): Loss/seq after 03700 batchs: 667.4002075195312
INFO:root:Train (Epoch 119): Loss/seq after 03750 batchs: 671.591552734375
INFO:root:Train (Epoch 119): Loss/seq after 03800 batchs: 668.0477294921875
INFO:root:Train (Epoch 119): Loss/seq after 03850 batchs: 666.8675537109375
INFO:root:Train (Epoch 119): Loss/seq after 03900 batchs: 671.4111938476562
INFO:root:Train (Epoch 119): Loss/seq after 03950 batchs: 675.3601684570312
INFO:root:Train (Epoch 119): Loss/seq after 04000 batchs: 670.742919921875
INFO:root:Train (Epoch 119): Loss/seq after 04050 batchs: 666.21484375
INFO:root:Train (Epoch 119): Loss/seq after 04100 batchs: 663.4705810546875
INFO:root:Train (Epoch 119): Loss/seq after 04150 batchs: 662.491455078125
INFO:root:Train (Epoch 119): Loss/seq after 04200 batchs: 660.196044921875
INFO:root:Train (Epoch 119): Loss/seq after 04250 batchs: 657.903076171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 119): Loss/seq after 00000 batches: 525.6707763671875
INFO:root:# Valid (Epoch 119): Loss/seq after 00050 batches: 762.245361328125
INFO:root:# Valid (Epoch 119): Loss/seq after 00100 batches: 787.1825561523438
INFO:root:# Valid (Epoch 119): Loss/seq after 00150 batches: 593.6774291992188
INFO:root:# Valid (Epoch 119): Loss/seq after 00200 batches: 552.8446044921875
INFO:root:Artifacts: Make stick videos for epoch 119
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_119_on_20220414_012112.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_119_index_839_on_20220414_012112.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 120): Loss/seq after 00000 batchs: 1219.85009765625
INFO:root:Train (Epoch 120): Loss/seq after 00050 batchs: 886.5298461914062
INFO:root:Train (Epoch 120): Loss/seq after 00100 batchs: 938.8040771484375
INFO:root:Train (Epoch 120): Loss/seq after 00150 batchs: 837.3049926757812
INFO:root:Train (Epoch 120): Loss/seq after 00200 batchs: 938.0177001953125
INFO:root:Train (Epoch 120): Loss/seq after 00250 batchs: 1050.9163818359375
INFO:root:Train (Epoch 120): Loss/seq after 00300 batchs: 1027.5152587890625
INFO:root:Train (Epoch 120): Loss/seq after 00350 batchs: 953.2661743164062
INFO:root:Train (Epoch 120): Loss/seq after 00400 batchs: 962.6141967773438
INFO:root:Train (Epoch 120): Loss/seq after 00450 batchs: 931.7664794921875
INFO:root:Train (Epoch 120): Loss/seq after 00500 batchs: 906.422119140625
INFO:root:Train (Epoch 120): Loss/seq after 00550 batchs: 873.8048095703125
INFO:root:Train (Epoch 120): Loss/seq after 00600 batchs: 840.7649536132812
INFO:root:Train (Epoch 120): Loss/seq after 00650 batchs: 836.56201171875
INFO:root:Train (Epoch 120): Loss/seq after 00700 batchs: 817.00732421875
INFO:root:Train (Epoch 120): Loss/seq after 00750 batchs: 831.3443603515625
INFO:root:Train (Epoch 120): Loss/seq after 00800 batchs: 826.7838745117188
INFO:root:Train (Epoch 120): Loss/seq after 00850 batchs: 799.326904296875
INFO:root:Train (Epoch 120): Loss/seq after 00900 batchs: 780.9334106445312
INFO:root:Train (Epoch 120): Loss/seq after 00950 batchs: 781.5906982421875
INFO:root:Train (Epoch 120): Loss/seq after 01000 batchs: 775.4517822265625
INFO:root:Train (Epoch 120): Loss/seq after 01050 batchs: 761.0073852539062
INFO:root:Train (Epoch 120): Loss/seq after 01100 batchs: 747.8670043945312
INFO:root:Train (Epoch 120): Loss/seq after 01150 batchs: 729.25439453125
INFO:root:Train (Epoch 120): Loss/seq after 01200 batchs: 730.183349609375
INFO:root:Train (Epoch 120): Loss/seq after 01250 batchs: 725.9324340820312
INFO:root:Train (Epoch 120): Loss/seq after 01300 batchs: 714.953369140625
INFO:root:Train (Epoch 120): Loss/seq after 01350 batchs: 704.9025268554688
INFO:root:Train (Epoch 120): Loss/seq after 01400 batchs: 715.5457763671875
INFO:root:Train (Epoch 120): Loss/seq after 01450 batchs: 714.9571533203125
INFO:root:Train (Epoch 120): Loss/seq after 01500 batchs: 718.4420776367188
INFO:root:Train (Epoch 120): Loss/seq after 01550 batchs: 719.1277465820312
INFO:root:Train (Epoch 120): Loss/seq after 01600 batchs: 711.7091064453125
INFO:root:Train (Epoch 120): Loss/seq after 01650 batchs: 707.65087890625
INFO:root:Train (Epoch 120): Loss/seq after 01700 batchs: 707.7042236328125
INFO:root:Train (Epoch 120): Loss/seq after 01750 batchs: 703.1715698242188
INFO:root:Train (Epoch 120): Loss/seq after 01800 batchs: 698.4094848632812
INFO:root:Train (Epoch 120): Loss/seq after 01850 batchs: 692.4547119140625
INFO:root:Train (Epoch 120): Loss/seq after 01900 batchs: 691.88232421875
INFO:root:Train (Epoch 120): Loss/seq after 01950 batchs: 688.9561157226562
INFO:root:Train (Epoch 120): Loss/seq after 02000 batchs: 685.5842895507812
INFO:root:Train (Epoch 120): Loss/seq after 02050 batchs: 682.330078125
INFO:root:Train (Epoch 120): Loss/seq after 02100 batchs: 677.8234252929688
INFO:root:Train (Epoch 120): Loss/seq after 02150 batchs: 674.3192749023438
INFO:root:Train (Epoch 120): Loss/seq after 02200 batchs: 669.8568725585938
INFO:root:Train (Epoch 120): Loss/seq after 02250 batchs: 668.5741577148438
INFO:root:Train (Epoch 120): Loss/seq after 02300 batchs: 669.83154296875
INFO:root:Train (Epoch 120): Loss/seq after 02350 batchs: 664.3316650390625
INFO:root:Train (Epoch 120): Loss/seq after 02400 batchs: 664.519775390625
INFO:root:Train (Epoch 120): Loss/seq after 02450 batchs: 658.321044921875
INFO:root:Train (Epoch 120): Loss/seq after 02500 batchs: 648.4603271484375
INFO:root:Train (Epoch 120): Loss/seq after 02550 batchs: 641.1704711914062
INFO:root:Train (Epoch 120): Loss/seq after 02600 batchs: 639.794921875
INFO:root:Train (Epoch 120): Loss/seq after 02650 batchs: 637.06591796875
INFO:root:Train (Epoch 120): Loss/seq after 02700 batchs: 634.433349609375
INFO:root:Train (Epoch 120): Loss/seq after 02750 batchs: 636.54736328125
INFO:root:Train (Epoch 120): Loss/seq after 02800 batchs: 638.0825805664062
INFO:root:Train (Epoch 120): Loss/seq after 02850 batchs: 637.6279296875
INFO:root:Train (Epoch 120): Loss/seq after 02900 batchs: 638.6869506835938
INFO:root:Train (Epoch 120): Loss/seq after 02950 batchs: 636.6747436523438
INFO:root:Train (Epoch 120): Loss/seq after 03000 batchs: 640.6343994140625
INFO:root:Train (Epoch 120): Loss/seq after 03050 batchs: 643.2215576171875
INFO:root:Train (Epoch 120): Loss/seq after 03100 batchs: 648.2601928710938
INFO:root:Train (Epoch 120): Loss/seq after 03150 batchs: 655.2672119140625
INFO:root:Train (Epoch 120): Loss/seq after 03200 batchs: 660.581298828125
INFO:root:Train (Epoch 120): Loss/seq after 03250 batchs: 666.942138671875
INFO:root:Train (Epoch 120): Loss/seq after 03300 batchs: 666.8370361328125
INFO:root:Train (Epoch 120): Loss/seq after 03350 batchs: 667.0175170898438
INFO:root:Train (Epoch 120): Loss/seq after 03400 batchs: 661.5848999023438
INFO:root:Train (Epoch 120): Loss/seq after 03450 batchs: 659.1774291992188
INFO:root:Train (Epoch 120): Loss/seq after 03500 batchs: 659.2860107421875
INFO:root:Train (Epoch 120): Loss/seq after 03550 batchs: 655.6668701171875
INFO:root:Train (Epoch 120): Loss/seq after 03600 batchs: 663.6791381835938
INFO:root:Train (Epoch 120): Loss/seq after 03650 batchs: 659.970947265625
INFO:root:Train (Epoch 120): Loss/seq after 03700 batchs: 661.4822387695312
INFO:root:Train (Epoch 120): Loss/seq after 03750 batchs: 665.5697021484375
INFO:root:Train (Epoch 120): Loss/seq after 03800 batchs: 662.0997314453125
INFO:root:Train (Epoch 120): Loss/seq after 03850 batchs: 660.8785400390625
INFO:root:Train (Epoch 120): Loss/seq after 03900 batchs: 665.4039306640625
INFO:root:Train (Epoch 120): Loss/seq after 03950 batchs: 669.7849731445312
INFO:root:Train (Epoch 120): Loss/seq after 04000 batchs: 665.242431640625
INFO:root:Train (Epoch 120): Loss/seq after 04050 batchs: 660.7471313476562
INFO:root:Train (Epoch 120): Loss/seq after 04100 batchs: 658.1034545898438
INFO:root:Train (Epoch 120): Loss/seq after 04150 batchs: 657.1963500976562
INFO:root:Train (Epoch 120): Loss/seq after 04200 batchs: 654.9445190429688
INFO:root:Train (Epoch 120): Loss/seq after 04250 batchs: 652.6865234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 120): Loss/seq after 00000 batches: 573.2249145507812
INFO:root:# Valid (Epoch 120): Loss/seq after 00050 batches: 756.998291015625
INFO:root:# Valid (Epoch 120): Loss/seq after 00100 batches: 793.3786010742188
INFO:root:# Valid (Epoch 120): Loss/seq after 00150 batches: 598.0552978515625
INFO:root:# Valid (Epoch 120): Loss/seq after 00200 batches: 556.8075561523438
INFO:root:Artifacts: Make stick videos for epoch 120
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_120_on_20220414_012630.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_120_index_1906_on_20220414_012630.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 121): Loss/seq after 00000 batchs: 1370.9178466796875
INFO:root:Train (Epoch 121): Loss/seq after 00050 batchs: 898.5765991210938
INFO:root:Train (Epoch 121): Loss/seq after 00100 batchs: 946.513671875
INFO:root:Train (Epoch 121): Loss/seq after 00150 batchs: 840.137939453125
INFO:root:Train (Epoch 121): Loss/seq after 00200 batchs: 940.1907348632812
INFO:root:Train (Epoch 121): Loss/seq after 00250 batchs: 1047.6456298828125
INFO:root:Train (Epoch 121): Loss/seq after 00300 batchs: 1023.7578735351562
INFO:root:Train (Epoch 121): Loss/seq after 00350 batchs: 950.9285278320312
INFO:root:Train (Epoch 121): Loss/seq after 00400 batchs: 958.2652587890625
INFO:root:Train (Epoch 121): Loss/seq after 00450 batchs: 928.1361694335938
INFO:root:Train (Epoch 121): Loss/seq after 00500 batchs: 900.8731689453125
INFO:root:Train (Epoch 121): Loss/seq after 00550 batchs: 868.829345703125
INFO:root:Train (Epoch 121): Loss/seq after 00600 batchs: 836.4425659179688
INFO:root:Train (Epoch 121): Loss/seq after 00650 batchs: 831.9086303710938
INFO:root:Train (Epoch 121): Loss/seq after 00700 batchs: 811.2919921875
INFO:root:Train (Epoch 121): Loss/seq after 00750 batchs: 829.072509765625
INFO:root:Train (Epoch 121): Loss/seq after 00800 batchs: 824.9568481445312
INFO:root:Train (Epoch 121): Loss/seq after 00850 batchs: 797.2855834960938
INFO:root:Train (Epoch 121): Loss/seq after 00900 batchs: 778.4666137695312
INFO:root:Train (Epoch 121): Loss/seq after 00950 batchs: 778.7623291015625
INFO:root:Train (Epoch 121): Loss/seq after 01000 batchs: 773.7789306640625
INFO:root:Train (Epoch 121): Loss/seq after 01050 batchs: 760.363037109375
INFO:root:Train (Epoch 121): Loss/seq after 01100 batchs: 748.056640625
INFO:root:Train (Epoch 121): Loss/seq after 01150 batchs: 729.25048828125
INFO:root:Train (Epoch 121): Loss/seq after 01200 batchs: 730.1456909179688
INFO:root:Train (Epoch 121): Loss/seq after 01250 batchs: 725.7867431640625
INFO:root:Train (Epoch 121): Loss/seq after 01300 batchs: 714.5155029296875
INFO:root:Train (Epoch 121): Loss/seq after 01350 batchs: 703.9907836914062
INFO:root:Train (Epoch 121): Loss/seq after 01400 batchs: 714.3811645507812
INFO:root:Train (Epoch 121): Loss/seq after 01450 batchs: 713.0564575195312
INFO:root:Train (Epoch 121): Loss/seq after 01500 batchs: 716.527587890625
INFO:root:Train (Epoch 121): Loss/seq after 01550 batchs: 717.0838623046875
INFO:root:Train (Epoch 121): Loss/seq after 01600 batchs: 709.1517333984375
INFO:root:Train (Epoch 121): Loss/seq after 01650 batchs: 704.8927612304688
INFO:root:Train (Epoch 121): Loss/seq after 01700 batchs: 705.0574951171875
INFO:root:Train (Epoch 121): Loss/seq after 01750 batchs: 700.3919067382812
INFO:root:Train (Epoch 121): Loss/seq after 01800 batchs: 695.5640258789062
INFO:root:Train (Epoch 121): Loss/seq after 01850 batchs: 689.6668701171875
INFO:root:Train (Epoch 121): Loss/seq after 01900 batchs: 689.071044921875
INFO:root:Train (Epoch 121): Loss/seq after 01950 batchs: 685.8408813476562
INFO:root:Train (Epoch 121): Loss/seq after 02000 batchs: 682.8130493164062
INFO:root:Train (Epoch 121): Loss/seq after 02050 batchs: 679.6993408203125
INFO:root:Train (Epoch 121): Loss/seq after 02100 batchs: 675.179443359375
INFO:root:Train (Epoch 121): Loss/seq after 02150 batchs: 671.8696899414062
INFO:root:Train (Epoch 121): Loss/seq after 02200 batchs: 667.4798583984375
INFO:root:Train (Epoch 121): Loss/seq after 02250 batchs: 666.1568603515625
INFO:root:Train (Epoch 121): Loss/seq after 02300 batchs: 668.0137939453125
INFO:root:Train (Epoch 121): Loss/seq after 02350 batchs: 662.3095703125
INFO:root:Train (Epoch 121): Loss/seq after 02400 batchs: 662.3692626953125
INFO:root:Train (Epoch 121): Loss/seq after 02450 batchs: 656.1449584960938
INFO:root:Train (Epoch 121): Loss/seq after 02500 batchs: 646.3306884765625
INFO:root:Train (Epoch 121): Loss/seq after 02550 batchs: 639.0435791015625
INFO:root:Train (Epoch 121): Loss/seq after 02600 batchs: 637.6900634765625
INFO:root:Train (Epoch 121): Loss/seq after 02650 batchs: 634.8938598632812
INFO:root:Train (Epoch 121): Loss/seq after 02700 batchs: 632.3627319335938
INFO:root:Train (Epoch 121): Loss/seq after 02750 batchs: 634.0213623046875
INFO:root:Train (Epoch 121): Loss/seq after 02800 batchs: 636.08740234375
INFO:root:Train (Epoch 121): Loss/seq after 02850 batchs: 635.52685546875
INFO:root:Train (Epoch 121): Loss/seq after 02900 batchs: 636.3319091796875
INFO:root:Train (Epoch 121): Loss/seq after 02950 batchs: 634.3995971679688
INFO:root:Train (Epoch 121): Loss/seq after 03000 batchs: 638.3814086914062
INFO:root:Train (Epoch 121): Loss/seq after 03050 batchs: 640.5328979492188
INFO:root:Train (Epoch 121): Loss/seq after 03100 batchs: 645.5164184570312
INFO:root:Train (Epoch 121): Loss/seq after 03150 batchs: 652.8299560546875
INFO:root:Train (Epoch 121): Loss/seq after 03200 batchs: 658.50146484375
INFO:root:Train (Epoch 121): Loss/seq after 03250 batchs: 664.0128784179688
INFO:root:Train (Epoch 121): Loss/seq after 03300 batchs: 662.763671875
INFO:root:Train (Epoch 121): Loss/seq after 03350 batchs: 662.9365234375
INFO:root:Train (Epoch 121): Loss/seq after 03400 batchs: 657.5538330078125
INFO:root:Train (Epoch 121): Loss/seq after 03450 batchs: 654.9910278320312
INFO:root:Train (Epoch 121): Loss/seq after 03500 batchs: 654.8104858398438
INFO:root:Train (Epoch 121): Loss/seq after 03550 batchs: 651.02978515625
INFO:root:Train (Epoch 121): Loss/seq after 03600 batchs: 658.9508056640625
INFO:root:Train (Epoch 121): Loss/seq after 03650 batchs: 655.4572143554688
INFO:root:Train (Epoch 121): Loss/seq after 03700 batchs: 657.0341796875
INFO:root:Train (Epoch 121): Loss/seq after 03750 batchs: 661.1455078125
INFO:root:Train (Epoch 121): Loss/seq after 03800 batchs: 657.7215576171875
INFO:root:Train (Epoch 121): Loss/seq after 03850 batchs: 656.447021484375
INFO:root:Train (Epoch 121): Loss/seq after 03900 batchs: 660.8655395507812
INFO:root:Train (Epoch 121): Loss/seq after 03950 batchs: 665.2865600585938
INFO:root:Train (Epoch 121): Loss/seq after 04000 batchs: 660.8172607421875
INFO:root:Train (Epoch 121): Loss/seq after 04050 batchs: 656.3778686523438
INFO:root:Train (Epoch 121): Loss/seq after 04100 batchs: 653.7125854492188
INFO:root:Train (Epoch 121): Loss/seq after 04150 batchs: 652.840087890625
INFO:root:Train (Epoch 121): Loss/seq after 04200 batchs: 650.608154296875
INFO:root:Train (Epoch 121): Loss/seq after 04250 batchs: 648.3970947265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 121): Loss/seq after 00000 batches: 554.5112915039062
INFO:root:# Valid (Epoch 121): Loss/seq after 00050 batches: 788.8256225585938
INFO:root:# Valid (Epoch 121): Loss/seq after 00100 batches: 814.155517578125
INFO:root:# Valid (Epoch 121): Loss/seq after 00150 batches: 609.8019409179688
INFO:root:# Valid (Epoch 121): Loss/seq after 00200 batches: 563.0606689453125
INFO:root:Artifacts: Make stick videos for epoch 121
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_121_on_20220414_013148.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_121_index_1005_on_20220414_013148.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 122): Loss/seq after 00000 batchs: 1230.9547119140625
INFO:root:Train (Epoch 122): Loss/seq after 00050 batchs: 893.0050048828125
INFO:root:Train (Epoch 122): Loss/seq after 00100 batchs: 918.836181640625
INFO:root:Train (Epoch 122): Loss/seq after 00150 batchs: 819.4750366210938
INFO:root:Train (Epoch 122): Loss/seq after 00200 batchs: 905.644287109375
INFO:root:Train (Epoch 122): Loss/seq after 00250 batchs: 1014.8283081054688
INFO:root:Train (Epoch 122): Loss/seq after 00300 batchs: 997.2439575195312
INFO:root:Train (Epoch 122): Loss/seq after 00350 batchs: 927.2461547851562
INFO:root:Train (Epoch 122): Loss/seq after 00400 batchs: 937.6713256835938
INFO:root:Train (Epoch 122): Loss/seq after 00450 batchs: 909.5358276367188
INFO:root:Train (Epoch 122): Loss/seq after 00500 batchs: 884.1292114257812
INFO:root:Train (Epoch 122): Loss/seq after 00550 batchs: 853.1312255859375
INFO:root:Train (Epoch 122): Loss/seq after 00600 batchs: 821.8361206054688
INFO:root:Train (Epoch 122): Loss/seq after 00650 batchs: 818.6846313476562
INFO:root:Train (Epoch 122): Loss/seq after 00700 batchs: 797.8746948242188
INFO:root:Train (Epoch 122): Loss/seq after 00750 batchs: 816.417724609375
INFO:root:Train (Epoch 122): Loss/seq after 00800 batchs: 814.0546875
INFO:root:Train (Epoch 122): Loss/seq after 00850 batchs: 787.7142944335938
INFO:root:Train (Epoch 122): Loss/seq after 00900 batchs: 769.609619140625
INFO:root:Train (Epoch 122): Loss/seq after 00950 batchs: 771.5486450195312
INFO:root:Train (Epoch 122): Loss/seq after 01000 batchs: 764.3598022460938
INFO:root:Train (Epoch 122): Loss/seq after 01050 batchs: 749.758056640625
INFO:root:Train (Epoch 122): Loss/seq after 01100 batchs: 737.5376586914062
INFO:root:Train (Epoch 122): Loss/seq after 01150 batchs: 718.9613037109375
INFO:root:Train (Epoch 122): Loss/seq after 01200 batchs: 720.3195190429688
INFO:root:Train (Epoch 122): Loss/seq after 01250 batchs: 716.6372680664062
INFO:root:Train (Epoch 122): Loss/seq after 01300 batchs: 705.4569702148438
INFO:root:Train (Epoch 122): Loss/seq after 01350 batchs: 695.0115966796875
INFO:root:Train (Epoch 122): Loss/seq after 01400 batchs: 705.9649047851562
INFO:root:Train (Epoch 122): Loss/seq after 01450 batchs: 705.4088134765625
INFO:root:Train (Epoch 122): Loss/seq after 01500 batchs: 709.2759399414062
INFO:root:Train (Epoch 122): Loss/seq after 01550 batchs: 710.5687866210938
INFO:root:Train (Epoch 122): Loss/seq after 01600 batchs: 703.0745849609375
INFO:root:Train (Epoch 122): Loss/seq after 01650 batchs: 699.089111328125
INFO:root:Train (Epoch 122): Loss/seq after 01700 batchs: 699.4013671875
INFO:root:Train (Epoch 122): Loss/seq after 01750 batchs: 694.9535522460938
INFO:root:Train (Epoch 122): Loss/seq after 01800 batchs: 690.2940063476562
INFO:root:Train (Epoch 122): Loss/seq after 01850 batchs: 684.5006103515625
INFO:root:Train (Epoch 122): Loss/seq after 01900 batchs: 683.90234375
INFO:root:Train (Epoch 122): Loss/seq after 01950 batchs: 680.7738037109375
INFO:root:Train (Epoch 122): Loss/seq after 02000 batchs: 677.6234741210938
INFO:root:Train (Epoch 122): Loss/seq after 02050 batchs: 674.4713745117188
INFO:root:Train (Epoch 122): Loss/seq after 02100 batchs: 670.1893310546875
INFO:root:Train (Epoch 122): Loss/seq after 02150 batchs: 666.8489379882812
INFO:root:Train (Epoch 122): Loss/seq after 02200 batchs: 662.5593872070312
INFO:root:Train (Epoch 122): Loss/seq after 02250 batchs: 661.4790649414062
INFO:root:Train (Epoch 122): Loss/seq after 02300 batchs: 663.8988037109375
INFO:root:Train (Epoch 122): Loss/seq after 02350 batchs: 658.153076171875
INFO:root:Train (Epoch 122): Loss/seq after 02400 batchs: 658.396728515625
INFO:root:Train (Epoch 122): Loss/seq after 02450 batchs: 652.1593627929688
INFO:root:Train (Epoch 122): Loss/seq after 02500 batchs: 642.3987426757812
INFO:root:Train (Epoch 122): Loss/seq after 02550 batchs: 635.1233520507812
INFO:root:Train (Epoch 122): Loss/seq after 02600 batchs: 633.822509765625
INFO:root:Train (Epoch 122): Loss/seq after 02650 batchs: 631.1707153320312
INFO:root:Train (Epoch 122): Loss/seq after 02700 batchs: 628.747802734375
INFO:root:Train (Epoch 122): Loss/seq after 02750 batchs: 631.5066528320312
INFO:root:Train (Epoch 122): Loss/seq after 02800 batchs: 632.91748046875
INFO:root:Train (Epoch 122): Loss/seq after 02850 batchs: 632.665283203125
INFO:root:Train (Epoch 122): Loss/seq after 02900 batchs: 633.7606811523438
INFO:root:Train (Epoch 122): Loss/seq after 02950 batchs: 631.832763671875
INFO:root:Train (Epoch 122): Loss/seq after 03000 batchs: 635.863037109375
INFO:root:Train (Epoch 122): Loss/seq after 03050 batchs: 637.8744506835938
INFO:root:Train (Epoch 122): Loss/seq after 03100 batchs: 643.0177001953125
INFO:root:Train (Epoch 122): Loss/seq after 03150 batchs: 649.83984375
INFO:root:Train (Epoch 122): Loss/seq after 03200 batchs: 655.3947143554688
INFO:root:Train (Epoch 122): Loss/seq after 03250 batchs: 660.5065307617188
INFO:root:Train (Epoch 122): Loss/seq after 03300 batchs: 660.7396240234375
INFO:root:Train (Epoch 122): Loss/seq after 03350 batchs: 661.7246704101562
INFO:root:Train (Epoch 122): Loss/seq after 03400 batchs: 656.4517822265625
INFO:root:Train (Epoch 122): Loss/seq after 03450 batchs: 653.9086303710938
INFO:root:Train (Epoch 122): Loss/seq after 03500 batchs: 654.1281127929688
INFO:root:Train (Epoch 122): Loss/seq after 03550 batchs: 650.4334716796875
INFO:root:Train (Epoch 122): Loss/seq after 03600 batchs: 658.3722534179688
INFO:root:Train (Epoch 122): Loss/seq after 03650 batchs: 654.9263916015625
INFO:root:Train (Epoch 122): Loss/seq after 03700 batchs: 656.76416015625
INFO:root:Train (Epoch 122): Loss/seq after 03750 batchs: 660.873779296875
INFO:root:Train (Epoch 122): Loss/seq after 03800 batchs: 657.4691772460938
INFO:root:Train (Epoch 122): Loss/seq after 03850 batchs: 656.1364135742188
INFO:root:Train (Epoch 122): Loss/seq after 03900 batchs: 660.8963623046875
INFO:root:Train (Epoch 122): Loss/seq after 03950 batchs: 665.1405029296875
INFO:root:Train (Epoch 122): Loss/seq after 04000 batchs: 660.5830078125
INFO:root:Train (Epoch 122): Loss/seq after 04050 batchs: 656.1489868164062
INFO:root:Train (Epoch 122): Loss/seq after 04100 batchs: 653.5224609375
INFO:root:Train (Epoch 122): Loss/seq after 04150 batchs: 652.63232421875
INFO:root:Train (Epoch 122): Loss/seq after 04200 batchs: 650.4776611328125
INFO:root:Train (Epoch 122): Loss/seq after 04250 batchs: 648.221923828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 122): Loss/seq after 00000 batches: 543.675048828125
INFO:root:# Valid (Epoch 122): Loss/seq after 00050 batches: 831.7252197265625
INFO:root:# Valid (Epoch 122): Loss/seq after 00100 batches: 846.1796875
INFO:root:# Valid (Epoch 122): Loss/seq after 00150 batches: 631.9887084960938
INFO:root:# Valid (Epoch 122): Loss/seq after 00200 batches: 580.72509765625
INFO:root:Artifacts: Make stick videos for epoch 122
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_122_on_20220414_013706.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_122_index_799_on_20220414_013706.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 123): Loss/seq after 00000 batchs: 1237.9305419921875
INFO:root:Train (Epoch 123): Loss/seq after 00050 batchs: 892.1917724609375
INFO:root:Train (Epoch 123): Loss/seq after 00100 batchs: 920.2555541992188
INFO:root:Train (Epoch 123): Loss/seq after 00150 batchs: 820.3616943359375
INFO:root:Train (Epoch 123): Loss/seq after 00200 batchs: 915.617431640625
INFO:root:Train (Epoch 123): Loss/seq after 00250 batchs: 1027.1121826171875
INFO:root:Train (Epoch 123): Loss/seq after 00300 batchs: 1007.1864624023438
INFO:root:Train (Epoch 123): Loss/seq after 00350 batchs: 935.6881103515625
INFO:root:Train (Epoch 123): Loss/seq after 00400 batchs: 940.178466796875
INFO:root:Train (Epoch 123): Loss/seq after 00450 batchs: 911.859619140625
INFO:root:Train (Epoch 123): Loss/seq after 00500 batchs: 884.0256958007812
INFO:root:Train (Epoch 123): Loss/seq after 00550 batchs: 852.815673828125
INFO:root:Train (Epoch 123): Loss/seq after 00600 batchs: 820.6734619140625
INFO:root:Train (Epoch 123): Loss/seq after 00650 batchs: 814.8303833007812
INFO:root:Train (Epoch 123): Loss/seq after 00700 batchs: 792.1314697265625
INFO:root:Train (Epoch 123): Loss/seq after 00750 batchs: 807.3643798828125
INFO:root:Train (Epoch 123): Loss/seq after 00800 batchs: 804.4340209960938
INFO:root:Train (Epoch 123): Loss/seq after 00850 batchs: 778.388916015625
INFO:root:Train (Epoch 123): Loss/seq after 00900 batchs: 761.3934326171875
INFO:root:Train (Epoch 123): Loss/seq after 00950 batchs: 761.2482299804688
INFO:root:Train (Epoch 123): Loss/seq after 01000 batchs: 755.1566772460938
INFO:root:Train (Epoch 123): Loss/seq after 01050 batchs: 740.990966796875
INFO:root:Train (Epoch 123): Loss/seq after 01100 batchs: 728.2725830078125
INFO:root:Train (Epoch 123): Loss/seq after 01150 batchs: 710.4520874023438
INFO:root:Train (Epoch 123): Loss/seq after 01200 batchs: 712.133056640625
INFO:root:Train (Epoch 123): Loss/seq after 01250 batchs: 708.5798950195312
INFO:root:Train (Epoch 123): Loss/seq after 01300 batchs: 697.5120239257812
INFO:root:Train (Epoch 123): Loss/seq after 01350 batchs: 687.3489379882812
INFO:root:Train (Epoch 123): Loss/seq after 01400 batchs: 697.5908813476562
INFO:root:Train (Epoch 123): Loss/seq after 01450 batchs: 697.0132446289062
INFO:root:Train (Epoch 123): Loss/seq after 01500 batchs: 701.1050415039062
INFO:root:Train (Epoch 123): Loss/seq after 01550 batchs: 701.8775024414062
INFO:root:Train (Epoch 123): Loss/seq after 01600 batchs: 694.5980834960938
INFO:root:Train (Epoch 123): Loss/seq after 01650 batchs: 690.727783203125
INFO:root:Train (Epoch 123): Loss/seq after 01700 batchs: 691.0203247070312
INFO:root:Train (Epoch 123): Loss/seq after 01750 batchs: 686.639892578125
INFO:root:Train (Epoch 123): Loss/seq after 01800 batchs: 682.2426147460938
INFO:root:Train (Epoch 123): Loss/seq after 01850 batchs: 676.5958862304688
INFO:root:Train (Epoch 123): Loss/seq after 01900 batchs: 676.1463012695312
INFO:root:Train (Epoch 123): Loss/seq after 01950 batchs: 673.104736328125
INFO:root:Train (Epoch 123): Loss/seq after 02000 batchs: 670.1754760742188
INFO:root:Train (Epoch 123): Loss/seq after 02050 batchs: 667.2472534179688
INFO:root:Train (Epoch 123): Loss/seq after 02100 batchs: 663.108154296875
INFO:root:Train (Epoch 123): Loss/seq after 02150 batchs: 659.853271484375
INFO:root:Train (Epoch 123): Loss/seq after 02200 batchs: 655.6779174804688
INFO:root:Train (Epoch 123): Loss/seq after 02250 batchs: 654.0487060546875
INFO:root:Train (Epoch 123): Loss/seq after 02300 batchs: 655.092041015625
INFO:root:Train (Epoch 123): Loss/seq after 02350 batchs: 650.0260620117188
INFO:root:Train (Epoch 123): Loss/seq after 02400 batchs: 650.5601806640625
INFO:root:Train (Epoch 123): Loss/seq after 02450 batchs: 644.5870361328125
INFO:root:Train (Epoch 123): Loss/seq after 02500 batchs: 635.0000610351562
INFO:root:Train (Epoch 123): Loss/seq after 02550 batchs: 627.8731079101562
INFO:root:Train (Epoch 123): Loss/seq after 02600 batchs: 626.750732421875
INFO:root:Train (Epoch 123): Loss/seq after 02650 batchs: 624.1710815429688
INFO:root:Train (Epoch 123): Loss/seq after 02700 batchs: 621.6800537109375
INFO:root:Train (Epoch 123): Loss/seq after 02750 batchs: 623.3783569335938
INFO:root:Train (Epoch 123): Loss/seq after 02800 batchs: 625.1162109375
INFO:root:Train (Epoch 123): Loss/seq after 02850 batchs: 624.65966796875
INFO:root:Train (Epoch 123): Loss/seq after 02900 batchs: 625.6721801757812
INFO:root:Train (Epoch 123): Loss/seq after 02950 batchs: 623.8167114257812
INFO:root:Train (Epoch 123): Loss/seq after 03000 batchs: 627.9593505859375
INFO:root:Train (Epoch 123): Loss/seq after 03050 batchs: 630.20751953125
INFO:root:Train (Epoch 123): Loss/seq after 03100 batchs: 635.072509765625
INFO:root:Train (Epoch 123): Loss/seq after 03150 batchs: 642.263916015625
INFO:root:Train (Epoch 123): Loss/seq after 03200 batchs: 647.64208984375
INFO:root:Train (Epoch 123): Loss/seq after 03250 batchs: 652.501220703125
INFO:root:Train (Epoch 123): Loss/seq after 03300 batchs: 651.5891723632812
INFO:root:Train (Epoch 123): Loss/seq after 03350 batchs: 651.8375854492188
INFO:root:Train (Epoch 123): Loss/seq after 03400 batchs: 646.677978515625
INFO:root:Train (Epoch 123): Loss/seq after 03450 batchs: 644.2540283203125
INFO:root:Train (Epoch 123): Loss/seq after 03500 batchs: 644.4840087890625
INFO:root:Train (Epoch 123): Loss/seq after 03550 batchs: 640.9044799804688
INFO:root:Train (Epoch 123): Loss/seq after 03600 batchs: 648.9147338867188
INFO:root:Train (Epoch 123): Loss/seq after 03650 batchs: 645.4310302734375
INFO:root:Train (Epoch 123): Loss/seq after 03700 batchs: 647.0823974609375
INFO:root:Train (Epoch 123): Loss/seq after 03750 batchs: 651.3370361328125
INFO:root:Train (Epoch 123): Loss/seq after 03800 batchs: 648.0314331054688
INFO:root:Train (Epoch 123): Loss/seq after 03850 batchs: 646.7338256835938
INFO:root:Train (Epoch 123): Loss/seq after 03900 batchs: 651.337158203125
INFO:root:Train (Epoch 123): Loss/seq after 03950 batchs: 655.8626708984375
INFO:root:Train (Epoch 123): Loss/seq after 04000 batchs: 651.487060546875
INFO:root:Train (Epoch 123): Loss/seq after 04050 batchs: 647.1856689453125
INFO:root:Train (Epoch 123): Loss/seq after 04100 batchs: 644.649658203125
INFO:root:Train (Epoch 123): Loss/seq after 04150 batchs: 643.8748168945312
INFO:root:Train (Epoch 123): Loss/seq after 04200 batchs: 641.7752075195312
INFO:root:Train (Epoch 123): Loss/seq after 04250 batchs: 639.5979614257812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 123): Loss/seq after 00000 batches: 549.412841796875
INFO:root:# Valid (Epoch 123): Loss/seq after 00050 batches: 804.3687744140625
INFO:root:# Valid (Epoch 123): Loss/seq after 00100 batches: 825.6322631835938
INFO:root:# Valid (Epoch 123): Loss/seq after 00150 batches: 618.0987548828125
INFO:root:# Valid (Epoch 123): Loss/seq after 00200 batches: 569.8783569335938
INFO:root:Artifacts: Make stick videos for epoch 123
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_123_on_20220414_014226.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_123_index_1721_on_20220414_014226.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 124): Loss/seq after 00000 batchs: 1305.371826171875
INFO:root:Train (Epoch 124): Loss/seq after 00050 batchs: 885.5540161132812
INFO:root:Train (Epoch 124): Loss/seq after 00100 batchs: 917.5751953125
INFO:root:Train (Epoch 124): Loss/seq after 00150 batchs: 820.772705078125
INFO:root:Train (Epoch 124): Loss/seq after 00200 batchs: 908.0147705078125
INFO:root:Train (Epoch 124): Loss/seq after 00250 batchs: 1014.5499877929688
INFO:root:Train (Epoch 124): Loss/seq after 00300 batchs: 997.1217651367188
INFO:root:Train (Epoch 124): Loss/seq after 00350 batchs: 927.3274536132812
INFO:root:Train (Epoch 124): Loss/seq after 00400 batchs: 936.33837890625
INFO:root:Train (Epoch 124): Loss/seq after 00450 batchs: 908.4682006835938
INFO:root:Train (Epoch 124): Loss/seq after 00500 batchs: 882.2694702148438
INFO:root:Train (Epoch 124): Loss/seq after 00550 batchs: 851.067138671875
INFO:root:Train (Epoch 124): Loss/seq after 00600 batchs: 819.37109375
INFO:root:Train (Epoch 124): Loss/seq after 00650 batchs: 812.3299560546875
INFO:root:Train (Epoch 124): Loss/seq after 00700 batchs: 790.7211303710938
INFO:root:Train (Epoch 124): Loss/seq after 00750 batchs: 807.0328979492188
INFO:root:Train (Epoch 124): Loss/seq after 00800 batchs: 804.2686157226562
INFO:root:Train (Epoch 124): Loss/seq after 00850 batchs: 777.9498901367188
INFO:root:Train (Epoch 124): Loss/seq after 00900 batchs: 760.9016723632812
INFO:root:Train (Epoch 124): Loss/seq after 00950 batchs: 761.1420288085938
INFO:root:Train (Epoch 124): Loss/seq after 01000 batchs: 754.42626953125
INFO:root:Train (Epoch 124): Loss/seq after 01050 batchs: 740.1647338867188
INFO:root:Train (Epoch 124): Loss/seq after 01100 batchs: 727.2132568359375
INFO:root:Train (Epoch 124): Loss/seq after 01150 batchs: 708.9996337890625
INFO:root:Train (Epoch 124): Loss/seq after 01200 batchs: 710.6731567382812
INFO:root:Train (Epoch 124): Loss/seq after 01250 batchs: 706.7992553710938
INFO:root:Train (Epoch 124): Loss/seq after 01300 batchs: 695.34375
INFO:root:Train (Epoch 124): Loss/seq after 01350 batchs: 685.0297241210938
INFO:root:Train (Epoch 124): Loss/seq after 01400 batchs: 694.8876342773438
INFO:root:Train (Epoch 124): Loss/seq after 01450 batchs: 694.414306640625
INFO:root:Train (Epoch 124): Loss/seq after 01500 batchs: 698.4871215820312
INFO:root:Train (Epoch 124): Loss/seq after 01550 batchs: 699.5216674804688
INFO:root:Train (Epoch 124): Loss/seq after 01600 batchs: 692.144775390625
INFO:root:Train (Epoch 124): Loss/seq after 01650 batchs: 688.3560180664062
INFO:root:Train (Epoch 124): Loss/seq after 01700 batchs: 688.8196411132812
INFO:root:Train (Epoch 124): Loss/seq after 01750 batchs: 684.5900268554688
INFO:root:Train (Epoch 124): Loss/seq after 01800 batchs: 680.1984252929688
INFO:root:Train (Epoch 124): Loss/seq after 01850 batchs: 674.4467163085938
INFO:root:Train (Epoch 124): Loss/seq after 01900 batchs: 674.1096801757812
INFO:root:Train (Epoch 124): Loss/seq after 01950 batchs: 671.2305297851562
INFO:root:Train (Epoch 124): Loss/seq after 02000 batchs: 668.1473999023438
INFO:root:Train (Epoch 124): Loss/seq after 02050 batchs: 665.1638793945312
INFO:root:Train (Epoch 124): Loss/seq after 02100 batchs: 660.9962158203125
INFO:root:Train (Epoch 124): Loss/seq after 02150 batchs: 657.9143676757812
INFO:root:Train (Epoch 124): Loss/seq after 02200 batchs: 653.6812133789062
INFO:root:Train (Epoch 124): Loss/seq after 02250 batchs: 652.4652709960938
INFO:root:Train (Epoch 124): Loss/seq after 02300 batchs: 652.974609375
INFO:root:Train (Epoch 124): Loss/seq after 02350 batchs: 647.182373046875
INFO:root:Train (Epoch 124): Loss/seq after 02400 batchs: 647.5109252929688
INFO:root:Train (Epoch 124): Loss/seq after 02450 batchs: 641.4905395507812
INFO:root:Train (Epoch 124): Loss/seq after 02500 batchs: 631.920654296875
INFO:root:Train (Epoch 124): Loss/seq after 02550 batchs: 624.8330078125
INFO:root:Train (Epoch 124): Loss/seq after 02600 batchs: 623.5655517578125
INFO:root:Train (Epoch 124): Loss/seq after 02650 batchs: 620.9907836914062
INFO:root:Train (Epoch 124): Loss/seq after 02700 batchs: 618.248291015625
INFO:root:Train (Epoch 124): Loss/seq after 02750 batchs: 619.406494140625
INFO:root:Train (Epoch 124): Loss/seq after 02800 batchs: 620.775634765625
INFO:root:Train (Epoch 124): Loss/seq after 02850 batchs: 620.4667358398438
INFO:root:Train (Epoch 124): Loss/seq after 02900 batchs: 621.4876708984375
INFO:root:Train (Epoch 124): Loss/seq after 02950 batchs: 619.7013549804688
INFO:root:Train (Epoch 124): Loss/seq after 03000 batchs: 623.8822021484375
INFO:root:Train (Epoch 124): Loss/seq after 03050 batchs: 626.0347900390625
INFO:root:Train (Epoch 124): Loss/seq after 03100 batchs: 630.323486328125
INFO:root:Train (Epoch 124): Loss/seq after 03150 batchs: 636.8983764648438
INFO:root:Train (Epoch 124): Loss/seq after 03200 batchs: 641.6473999023438
INFO:root:Train (Epoch 124): Loss/seq after 03250 batchs: 646.4588623046875
INFO:root:Train (Epoch 124): Loss/seq after 03300 batchs: 645.5555419921875
INFO:root:Train (Epoch 124): Loss/seq after 03350 batchs: 645.9412841796875
INFO:root:Train (Epoch 124): Loss/seq after 03400 batchs: 640.8177490234375
INFO:root:Train (Epoch 124): Loss/seq after 03450 batchs: 638.5223388671875
INFO:root:Train (Epoch 124): Loss/seq after 03500 batchs: 638.6358642578125
INFO:root:Train (Epoch 124): Loss/seq after 03550 batchs: 635.1092529296875
INFO:root:Train (Epoch 124): Loss/seq after 03600 batchs: 643.0890502929688
INFO:root:Train (Epoch 124): Loss/seq after 03650 batchs: 639.7570190429688
INFO:root:Train (Epoch 124): Loss/seq after 03700 batchs: 641.5806274414062
INFO:root:Train (Epoch 124): Loss/seq after 03750 batchs: 645.854248046875
INFO:root:Train (Epoch 124): Loss/seq after 03800 batchs: 642.5938110351562
INFO:root:Train (Epoch 124): Loss/seq after 03850 batchs: 641.3726196289062
INFO:root:Train (Epoch 124): Loss/seq after 03900 batchs: 646.0726928710938
INFO:root:Train (Epoch 124): Loss/seq after 03950 batchs: 650.6400756835938
INFO:root:Train (Epoch 124): Loss/seq after 04000 batchs: 646.2150268554688
INFO:root:Train (Epoch 124): Loss/seq after 04050 batchs: 641.953369140625
INFO:root:Train (Epoch 124): Loss/seq after 04100 batchs: 639.4434204101562
INFO:root:Train (Epoch 124): Loss/seq after 04150 batchs: 638.7224731445312
INFO:root:Train (Epoch 124): Loss/seq after 04200 batchs: 636.6278076171875
INFO:root:Train (Epoch 124): Loss/seq after 04250 batchs: 634.480224609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 124): Loss/seq after 00000 batches: 529.0308837890625
INFO:root:# Valid (Epoch 124): Loss/seq after 00050 batches: 824.8310546875
INFO:root:# Valid (Epoch 124): Loss/seq after 00100 batches: 840.8643798828125
INFO:root:# Valid (Epoch 124): Loss/seq after 00150 batches: 629.5890502929688
INFO:root:# Valid (Epoch 124): Loss/seq after 00200 batches: 579.1786499023438
INFO:root:Artifacts: Make stick videos for epoch 124
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_124_on_20220414_014745.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_124_index_119_on_20220414_014745.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 125): Loss/seq after 00000 batchs: 1232.550537109375
INFO:root:Train (Epoch 125): Loss/seq after 00050 batchs: 874.7294921875
INFO:root:Train (Epoch 125): Loss/seq after 00100 batchs: 900.8692016601562
INFO:root:Train (Epoch 125): Loss/seq after 00150 batchs: 807.0903930664062
INFO:root:Train (Epoch 125): Loss/seq after 00200 batchs: 885.6281127929688
INFO:root:Train (Epoch 125): Loss/seq after 00250 batchs: 998.0372924804688
INFO:root:Train (Epoch 125): Loss/seq after 00300 batchs: 983.6656494140625
INFO:root:Train (Epoch 125): Loss/seq after 00350 batchs: 915.8770141601562
INFO:root:Train (Epoch 125): Loss/seq after 00400 batchs: 923.5968017578125
INFO:root:Train (Epoch 125): Loss/seq after 00450 batchs: 897.0045166015625
INFO:root:Train (Epoch 125): Loss/seq after 00500 batchs: 869.0549926757812
INFO:root:Train (Epoch 125): Loss/seq after 00550 batchs: 838.9531860351562
INFO:root:Train (Epoch 125): Loss/seq after 00600 batchs: 808.7732543945312
INFO:root:Train (Epoch 125): Loss/seq after 00650 batchs: 799.9569702148438
INFO:root:Train (Epoch 125): Loss/seq after 00700 batchs: 779.1832275390625
INFO:root:Train (Epoch 125): Loss/seq after 00750 batchs: 793.860595703125
INFO:root:Train (Epoch 125): Loss/seq after 00800 batchs: 791.2918090820312
INFO:root:Train (Epoch 125): Loss/seq after 00850 batchs: 765.75537109375
INFO:root:Train (Epoch 125): Loss/seq after 00900 batchs: 748.4097900390625
INFO:root:Train (Epoch 125): Loss/seq after 00950 batchs: 749.1416015625
INFO:root:Train (Epoch 125): Loss/seq after 01000 batchs: 742.8860473632812
INFO:root:Train (Epoch 125): Loss/seq after 01050 batchs: 729.6702270507812
INFO:root:Train (Epoch 125): Loss/seq after 01100 batchs: 718.9422607421875
INFO:root:Train (Epoch 125): Loss/seq after 01150 batchs: 701.6316528320312
INFO:root:Train (Epoch 125): Loss/seq after 01200 batchs: 703.7642822265625
INFO:root:Train (Epoch 125): Loss/seq after 01250 batchs: 700.3114013671875
INFO:root:Train (Epoch 125): Loss/seq after 01300 batchs: 689.1094970703125
INFO:root:Train (Epoch 125): Loss/seq after 01350 batchs: 679.131103515625
INFO:root:Train (Epoch 125): Loss/seq after 01400 batchs: 688.3458862304688
INFO:root:Train (Epoch 125): Loss/seq after 01450 batchs: 688.1913452148438
INFO:root:Train (Epoch 125): Loss/seq after 01500 batchs: 692.406494140625
INFO:root:Train (Epoch 125): Loss/seq after 01550 batchs: 693.794921875
INFO:root:Train (Epoch 125): Loss/seq after 01600 batchs: 686.719970703125
INFO:root:Train (Epoch 125): Loss/seq after 01650 batchs: 683.3221435546875
INFO:root:Train (Epoch 125): Loss/seq after 01700 batchs: 683.9627075195312
INFO:root:Train (Epoch 125): Loss/seq after 01750 batchs: 679.7434692382812
INFO:root:Train (Epoch 125): Loss/seq after 01800 batchs: 675.4572143554688
INFO:root:Train (Epoch 125): Loss/seq after 01850 batchs: 669.9644165039062
INFO:root:Train (Epoch 125): Loss/seq after 01900 batchs: 669.6982421875
INFO:root:Train (Epoch 125): Loss/seq after 01950 batchs: 667.1968383789062
INFO:root:Train (Epoch 125): Loss/seq after 02000 batchs: 664.1980590820312
INFO:root:Train (Epoch 125): Loss/seq after 02050 batchs: 661.3817749023438
INFO:root:Train (Epoch 125): Loss/seq after 02100 batchs: 657.3643188476562
INFO:root:Train (Epoch 125): Loss/seq after 02150 batchs: 654.3248291015625
INFO:root:Train (Epoch 125): Loss/seq after 02200 batchs: 650.2197265625
INFO:root:Train (Epoch 125): Loss/seq after 02250 batchs: 648.8358764648438
INFO:root:Train (Epoch 125): Loss/seq after 02300 batchs: 649.82958984375
INFO:root:Train (Epoch 125): Loss/seq after 02350 batchs: 644.0943603515625
INFO:root:Train (Epoch 125): Loss/seq after 02400 batchs: 644.4552612304688
INFO:root:Train (Epoch 125): Loss/seq after 02450 batchs: 638.4849853515625
INFO:root:Train (Epoch 125): Loss/seq after 02500 batchs: 628.9447021484375
INFO:root:Train (Epoch 125): Loss/seq after 02550 batchs: 621.9053955078125
INFO:root:Train (Epoch 125): Loss/seq after 02600 batchs: 620.5310668945312
INFO:root:Train (Epoch 125): Loss/seq after 02650 batchs: 617.8621215820312
INFO:root:Train (Epoch 125): Loss/seq after 02700 batchs: 615.2877197265625
INFO:root:Train (Epoch 125): Loss/seq after 02750 batchs: 616.5969848632812
INFO:root:Train (Epoch 125): Loss/seq after 02800 batchs: 617.9241943359375
INFO:root:Train (Epoch 125): Loss/seq after 02850 batchs: 617.69189453125
INFO:root:Train (Epoch 125): Loss/seq after 02900 batchs: 618.8896484375
INFO:root:Train (Epoch 125): Loss/seq after 02950 batchs: 617.2138061523438
INFO:root:Train (Epoch 125): Loss/seq after 03000 batchs: 621.436279296875
INFO:root:Train (Epoch 125): Loss/seq after 03050 batchs: 624.3764038085938
INFO:root:Train (Epoch 125): Loss/seq after 03100 batchs: 629.251708984375
INFO:root:Train (Epoch 125): Loss/seq after 03150 batchs: 636.1985473632812
INFO:root:Train (Epoch 125): Loss/seq after 03200 batchs: 641.257080078125
INFO:root:Train (Epoch 125): Loss/seq after 03250 batchs: 646.0382080078125
INFO:root:Train (Epoch 125): Loss/seq after 03300 batchs: 645.0877685546875
INFO:root:Train (Epoch 125): Loss/seq after 03350 batchs: 645.4781494140625
INFO:root:Train (Epoch 125): Loss/seq after 03400 batchs: 640.3514404296875
INFO:root:Train (Epoch 125): Loss/seq after 03450 batchs: 638.0065307617188
INFO:root:Train (Epoch 125): Loss/seq after 03500 batchs: 637.9098510742188
INFO:root:Train (Epoch 125): Loss/seq after 03550 batchs: 634.3611450195312
INFO:root:Train (Epoch 125): Loss/seq after 03600 batchs: 642.336181640625
INFO:root:Train (Epoch 125): Loss/seq after 03650 batchs: 638.9064331054688
INFO:root:Train (Epoch 125): Loss/seq after 03700 batchs: 640.6792602539062
INFO:root:Train (Epoch 125): Loss/seq after 03750 batchs: 644.9788818359375
INFO:root:Train (Epoch 125): Loss/seq after 03800 batchs: 641.7354125976562
INFO:root:Train (Epoch 125): Loss/seq after 03850 batchs: 640.5250854492188
INFO:root:Train (Epoch 125): Loss/seq after 03900 batchs: 644.80224609375
INFO:root:Train (Epoch 125): Loss/seq after 03950 batchs: 649.0503540039062
INFO:root:Train (Epoch 125): Loss/seq after 04000 batchs: 644.6575927734375
INFO:root:Train (Epoch 125): Loss/seq after 04050 batchs: 640.3805541992188
INFO:root:Train (Epoch 125): Loss/seq after 04100 batchs: 637.84228515625
INFO:root:Train (Epoch 125): Loss/seq after 04150 batchs: 637.1300659179688
INFO:root:Train (Epoch 125): Loss/seq after 04200 batchs: 635.0457153320312
INFO:root:Train (Epoch 125): Loss/seq after 04250 batchs: 632.9207763671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 125): Loss/seq after 00000 batches: 540.9896850585938
INFO:root:# Valid (Epoch 125): Loss/seq after 00050 batches: 764.9070434570312
INFO:root:# Valid (Epoch 125): Loss/seq after 00100 batches: 782.3603515625
INFO:root:# Valid (Epoch 125): Loss/seq after 00150 batches: 589.6082153320312
INFO:root:# Valid (Epoch 125): Loss/seq after 00200 batches: 549.455322265625
INFO:root:Artifacts: Make stick videos for epoch 125
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_125_on_20220414_015303.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_125_index_1036_on_20220414_015303.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 126): Loss/seq after 00000 batchs: 1094.5316162109375
INFO:root:Train (Epoch 126): Loss/seq after 00050 batchs: 864.8554077148438
INFO:root:Train (Epoch 126): Loss/seq after 00100 batchs: 893.3125
INFO:root:Train (Epoch 126): Loss/seq after 00150 batchs: 800.2298583984375
INFO:root:Train (Epoch 126): Loss/seq after 00200 batchs: 883.21337890625
INFO:root:Train (Epoch 126): Loss/seq after 00250 batchs: 992.5905151367188
INFO:root:Train (Epoch 126): Loss/seq after 00300 batchs: 977.6155395507812
INFO:root:Train (Epoch 126): Loss/seq after 00350 batchs: 910.3092651367188
INFO:root:Train (Epoch 126): Loss/seq after 00400 batchs: 917.201171875
INFO:root:Train (Epoch 126): Loss/seq after 00450 batchs: 891.2239379882812
INFO:root:Train (Epoch 126): Loss/seq after 00500 batchs: 863.9462890625
INFO:root:Train (Epoch 126): Loss/seq after 00550 batchs: 835.0656127929688
INFO:root:Train (Epoch 126): Loss/seq after 00600 batchs: 804.5362548828125
INFO:root:Train (Epoch 126): Loss/seq after 00650 batchs: 797.587158203125
INFO:root:Train (Epoch 126): Loss/seq after 00700 batchs: 775.9569702148438
INFO:root:Train (Epoch 126): Loss/seq after 00750 batchs: 789.306640625
INFO:root:Train (Epoch 126): Loss/seq after 00800 batchs: 786.359130859375
INFO:root:Train (Epoch 126): Loss/seq after 00850 batchs: 760.6544189453125
INFO:root:Train (Epoch 126): Loss/seq after 00900 batchs: 743.3824462890625
INFO:root:Train (Epoch 126): Loss/seq after 00950 batchs: 744.6336059570312
INFO:root:Train (Epoch 126): Loss/seq after 01000 batchs: 736.6552734375
INFO:root:Train (Epoch 126): Loss/seq after 01050 batchs: 722.8421020507812
INFO:root:Train (Epoch 126): Loss/seq after 01100 batchs: 711.2257690429688
INFO:root:Train (Epoch 126): Loss/seq after 01150 batchs: 693.57568359375
INFO:root:Train (Epoch 126): Loss/seq after 01200 batchs: 695.3670654296875
INFO:root:Train (Epoch 126): Loss/seq after 01250 batchs: 691.86083984375
INFO:root:Train (Epoch 126): Loss/seq after 01300 batchs: 679.9700317382812
INFO:root:Train (Epoch 126): Loss/seq after 01350 batchs: 669.857666015625
INFO:root:Train (Epoch 126): Loss/seq after 01400 batchs: 679.2484130859375
INFO:root:Train (Epoch 126): Loss/seq after 01450 batchs: 679.0823364257812
INFO:root:Train (Epoch 126): Loss/seq after 01500 batchs: 683.53857421875
INFO:root:Train (Epoch 126): Loss/seq after 01550 batchs: 684.5360107421875
INFO:root:Train (Epoch 126): Loss/seq after 01600 batchs: 677.5126953125
INFO:root:Train (Epoch 126): Loss/seq after 01650 batchs: 673.8369140625
INFO:root:Train (Epoch 126): Loss/seq after 01700 batchs: 674.6755981445312
INFO:root:Train (Epoch 126): Loss/seq after 01750 batchs: 670.6527709960938
INFO:root:Train (Epoch 126): Loss/seq after 01800 batchs: 666.5653076171875
INFO:root:Train (Epoch 126): Loss/seq after 01850 batchs: 661.3292236328125
INFO:root:Train (Epoch 126): Loss/seq after 01900 batchs: 661.3011474609375
INFO:root:Train (Epoch 126): Loss/seq after 01950 batchs: 658.7329711914062
INFO:root:Train (Epoch 126): Loss/seq after 02000 batchs: 655.923828125
INFO:root:Train (Epoch 126): Loss/seq after 02050 batchs: 653.2333374023438
INFO:root:Train (Epoch 126): Loss/seq after 02100 batchs: 649.3546752929688
INFO:root:Train (Epoch 126): Loss/seq after 02150 batchs: 646.3263549804688
INFO:root:Train (Epoch 126): Loss/seq after 02200 batchs: 642.3781127929688
INFO:root:Train (Epoch 126): Loss/seq after 02250 batchs: 641.0215454101562
INFO:root:Train (Epoch 126): Loss/seq after 02300 batchs: 641.0055541992188
INFO:root:Train (Epoch 126): Loss/seq after 02350 batchs: 635.6719970703125
INFO:root:Train (Epoch 126): Loss/seq after 02400 batchs: 636.457763671875
INFO:root:Train (Epoch 126): Loss/seq after 02450 batchs: 630.635009765625
INFO:root:Train (Epoch 126): Loss/seq after 02500 batchs: 621.2293090820312
INFO:root:Train (Epoch 126): Loss/seq after 02550 batchs: 614.2899780273438
INFO:root:Train (Epoch 126): Loss/seq after 02600 batchs: 613.0479736328125
INFO:root:Train (Epoch 126): Loss/seq after 02650 batchs: 610.497802734375
INFO:root:Train (Epoch 126): Loss/seq after 02700 batchs: 608.0089111328125
INFO:root:Train (Epoch 126): Loss/seq after 02750 batchs: 608.5116577148438
INFO:root:Train (Epoch 126): Loss/seq after 02800 batchs: 610.0900268554688
INFO:root:Train (Epoch 126): Loss/seq after 02850 batchs: 609.8789672851562
INFO:root:Train (Epoch 126): Loss/seq after 02900 batchs: 611.1568603515625
INFO:root:Train (Epoch 126): Loss/seq after 02950 batchs: 609.4766235351562
INFO:root:Train (Epoch 126): Loss/seq after 03000 batchs: 613.7916870117188
INFO:root:Train (Epoch 126): Loss/seq after 03050 batchs: 616.1672973632812
INFO:root:Train (Epoch 126): Loss/seq after 03100 batchs: 620.6455688476562
INFO:root:Train (Epoch 126): Loss/seq after 03150 batchs: 627.8969116210938
INFO:root:Train (Epoch 126): Loss/seq after 03200 batchs: 632.3831176757812
INFO:root:Train (Epoch 126): Loss/seq after 03250 batchs: 637.1625366210938
INFO:root:Train (Epoch 126): Loss/seq after 03300 batchs: 636.30908203125
INFO:root:Train (Epoch 126): Loss/seq after 03350 batchs: 637.11328125
INFO:root:Train (Epoch 126): Loss/seq after 03400 batchs: 632.134033203125
INFO:root:Train (Epoch 126): Loss/seq after 03450 batchs: 629.93603515625
INFO:root:Train (Epoch 126): Loss/seq after 03500 batchs: 630.0231323242188
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 126): Loss/seq after 03550 batchs: 626.5899658203125
INFO:root:Train (Epoch 126): Loss/seq after 03600 batchs: 634.8631591796875
INFO:root:Train (Epoch 126): Loss/seq after 03650 batchs: 631.5863647460938
wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)
INFO:root:Train (Epoch 126): Loss/seq after 03700 batchs: 633.4502563476562
INFO:root:Train (Epoch 126): Loss/seq after 03750 batchs: 637.7869873046875
INFO:root:Train (Epoch 126): Loss/seq after 03800 batchs: 634.6464233398438
INFO:root:Train (Epoch 126): Loss/seq after 03850 batchs: 633.4635620117188
INFO:root:Train (Epoch 126): Loss/seq after 03900 batchs: 637.80078125
INFO:root:Train (Epoch 126): Loss/seq after 03950 batchs: 642.1546630859375
INFO:root:Train (Epoch 126): Loss/seq after 04000 batchs: 637.8426513671875
INFO:root:Train (Epoch 126): Loss/seq after 04050 batchs: 633.6527099609375
INFO:root:Train (Epoch 126): Loss/seq after 04100 batchs: 631.2285766601562
INFO:root:Train (Epoch 126): Loss/seq after 04150 batchs: 630.585693359375
INFO:root:Train (Epoch 126): Loss/seq after 04200 batchs: 628.6475830078125
INFO:root:Train (Epoch 126): Loss/seq after 04250 batchs: 626.4779052734375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 126): Loss/seq after 00000 batches: 522.5582885742188
INFO:root:# Valid (Epoch 126): Loss/seq after 00050 batches: 753.6322021484375
INFO:root:# Valid (Epoch 126): Loss/seq after 00100 batches: 766.1297607421875
INFO:root:# Valid (Epoch 126): Loss/seq after 00150 batches: 575.9102783203125
INFO:root:# Valid (Epoch 126): Loss/seq after 00200 batches: 537.2644653320312
INFO:root:Artifacts: Make stick videos for epoch 126
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_126_on_20220414_015820.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_126_index_469_on_20220414_015820.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 127): Loss/seq after 00000 batchs: 1095.8021240234375
INFO:root:Train (Epoch 127): Loss/seq after 00050 batchs: 849.8526000976562
INFO:root:Train (Epoch 127): Loss/seq after 00100 batchs: 896.3189697265625
INFO:root:Train (Epoch 127): Loss/seq after 00150 batchs: 804.2742919921875
INFO:root:Train (Epoch 127): Loss/seq after 00200 batchs: 880.5247192382812
INFO:root:Train (Epoch 127): Loss/seq after 00250 batchs: 991.5423583984375
INFO:root:Train (Epoch 127): Loss/seq after 00300 batchs: 976.7465209960938
INFO:root:Train (Epoch 127): Loss/seq after 00350 batchs: 909.5521850585938
INFO:root:Train (Epoch 127): Loss/seq after 00400 batchs: 923.5658569335938
INFO:root:Train (Epoch 127): Loss/seq after 00450 batchs: 896.8841552734375
INFO:root:Train (Epoch 127): Loss/seq after 00500 batchs: 873.0350952148438
INFO:root:Train (Epoch 127): Loss/seq after 00550 batchs: 843.6751708984375
INFO:root:Train (Epoch 127): Loss/seq after 00600 batchs: 812.6620483398438
INFO:root:Train (Epoch 127): Loss/seq after 00650 batchs: 801.1901245117188
INFO:root:Train (Epoch 127): Loss/seq after 00700 batchs: 780.069580078125
INFO:root:Train (Epoch 127): Loss/seq after 00750 batchs: 792.0491333007812
INFO:root:Train (Epoch 127): Loss/seq after 00800 batchs: 789.5518798828125
INFO:root:Train (Epoch 127): Loss/seq after 00850 batchs: 764.0651245117188
INFO:root:Train (Epoch 127): Loss/seq after 00900 batchs: 746.55078125
INFO:root:Train (Epoch 127): Loss/seq after 00950 batchs: 746.2324829101562
INFO:root:Train (Epoch 127): Loss/seq after 01000 batchs: 738.9949340820312
INFO:root:Train (Epoch 127): Loss/seq after 01050 batchs: 725.3856811523438
INFO:root:Train (Epoch 127): Loss/seq after 01100 batchs: 713.444580078125
INFO:root:Train (Epoch 127): Loss/seq after 01150 batchs: 695.5626220703125
INFO:root:Train (Epoch 127): Loss/seq after 01200 batchs: 697.6710205078125
INFO:root:Train (Epoch 127): Loss/seq after 01250 batchs: 694.1356811523438
INFO:root:Train (Epoch 127): Loss/seq after 01300 batchs: 682.3209228515625
INFO:root:Train (Epoch 127): Loss/seq after 01350 batchs: 671.8941040039062
INFO:root:Train (Epoch 127): Loss/seq after 01400 batchs: 680.3994140625
INFO:root:Train (Epoch 127): Loss/seq after 01450 batchs: 679.9532470703125
INFO:root:Train (Epoch 127): Loss/seq after 01500 batchs: 684.4266357421875
INFO:root:Train (Epoch 127): Loss/seq after 01550 batchs: 685.5252075195312
INFO:root:Train (Epoch 127): Loss/seq after 01600 batchs: 678.492431640625
INFO:root:Train (Epoch 127): Loss/seq after 01650 batchs: 674.8339233398438
INFO:root:Train (Epoch 127): Loss/seq after 01700 batchs: 675.5377807617188
INFO:root:Train (Epoch 127): Loss/seq after 01750 batchs: 671.51171875
INFO:root:Train (Epoch 127): Loss/seq after 01800 batchs: 667.2576904296875
INFO:root:Train (Epoch 127): Loss/seq after 01850 batchs: 662.0968017578125
INFO:root:Train (Epoch 127): Loss/seq after 01900 batchs: 661.9777221679688
INFO:root:Train (Epoch 127): Loss/seq after 01950 batchs: 659.2090454101562
INFO:root:Train (Epoch 127): Loss/seq after 02000 batchs: 656.4902954101562
INFO:root:Train (Epoch 127): Loss/seq after 02050 batchs: 653.7775268554688
INFO:root:Train (Epoch 127): Loss/seq after 02100 batchs: 649.8053588867188
INFO:root:Train (Epoch 127): Loss/seq after 02150 batchs: 646.9033203125
INFO:root:Train (Epoch 127): Loss/seq after 02200 batchs: 642.9293823242188
INFO:root:Train (Epoch 127): Loss/seq after 02250 batchs: 641.3261108398438
INFO:root:Train (Epoch 127): Loss/seq after 02300 batchs: 641.092529296875
INFO:root:Train (Epoch 127): Loss/seq after 02350 batchs: 635.89501953125
INFO:root:Train (Epoch 127): Loss/seq after 02400 batchs: 636.526611328125
INFO:root:Train (Epoch 127): Loss/seq after 02450 batchs: 630.705078125
INFO:root:Train (Epoch 127): Loss/seq after 02500 batchs: 621.3133544921875
INFO:root:Train (Epoch 127): Loss/seq after 02550 batchs: 614.3394165039062
INFO:root:Train (Epoch 127): Loss/seq after 02600 batchs: 612.9906616210938
INFO:root:Train (Epoch 127): Loss/seq after 02650 batchs: 610.499267578125
INFO:root:Train (Epoch 127): Loss/seq after 02700 batchs: 608.1312255859375
INFO:root:Train (Epoch 127): Loss/seq after 02750 batchs: 609.1138305664062
INFO:root:Train (Epoch 127): Loss/seq after 02800 batchs: 610.6220703125
INFO:root:Train (Epoch 127): Loss/seq after 02850 batchs: 610.39599609375
INFO:root:Train (Epoch 127): Loss/seq after 02900 batchs: 611.5369262695312
INFO:root:Train (Epoch 127): Loss/seq after 02950 batchs: 609.7625122070312
INFO:root:Train (Epoch 127): Loss/seq after 03000 batchs: 614.091552734375
INFO:root:Train (Epoch 127): Loss/seq after 03050 batchs: 615.9434204101562
INFO:root:Train (Epoch 127): Loss/seq after 03100 batchs: 620.0712280273438
INFO:root:Train (Epoch 127): Loss/seq after 03150 batchs: 626.5430297851562
INFO:root:Train (Epoch 127): Loss/seq after 03200 batchs: 630.3489990234375
INFO:root:Train (Epoch 127): Loss/seq after 03250 batchs: 634.7330932617188
INFO:root:Train (Epoch 127): Loss/seq after 03300 batchs: 633.8283081054688
INFO:root:Train (Epoch 127): Loss/seq after 03350 batchs: 634.2734985351562
INFO:root:Train (Epoch 127): Loss/seq after 03400 batchs: 629.3552856445312
INFO:root:Train (Epoch 127): Loss/seq after 03450 batchs: 627.1777954101562
INFO:root:Train (Epoch 127): Loss/seq after 03500 batchs: 627.157958984375
INFO:root:Train (Epoch 127): Loss/seq after 03550 batchs: 623.6939697265625
INFO:root:Train (Epoch 127): Loss/seq after 03600 batchs: 631.9121704101562
INFO:root:Train (Epoch 127): Loss/seq after 03650 batchs: 628.7874755859375
INFO:root:Train (Epoch 127): Loss/seq after 03700 batchs: 630.6715087890625
INFO:root:Train (Epoch 127): Loss/seq after 03750 batchs: 635.0426635742188
INFO:root:Train (Epoch 127): Loss/seq after 03800 batchs: 631.9583740234375
INFO:root:Train (Epoch 127): Loss/seq after 03850 batchs: 630.8899536132812
INFO:root:Train (Epoch 127): Loss/seq after 03900 batchs: 635.3777465820312
INFO:root:Train (Epoch 127): Loss/seq after 03950 batchs: 639.6107788085938
INFO:root:Train (Epoch 127): Loss/seq after 04000 batchs: 635.359130859375
INFO:root:Train (Epoch 127): Loss/seq after 04050 batchs: 631.2095947265625
INFO:root:Train (Epoch 127): Loss/seq after 04100 batchs: 628.8181762695312
INFO:root:Train (Epoch 127): Loss/seq after 04150 batchs: 628.185791015625
INFO:root:Train (Epoch 127): Loss/seq after 04200 batchs: 626.1865844726562
INFO:root:Train (Epoch 127): Loss/seq after 04250 batchs: 624.0362548828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 127): Loss/seq after 00000 batches: 528.6275634765625
INFO:root:# Valid (Epoch 127): Loss/seq after 00050 batches: 845.6666870117188
INFO:root:# Valid (Epoch 127): Loss/seq after 00100 batches: 842.4265747070312
INFO:root:# Valid (Epoch 127): Loss/seq after 00150 batches: 626.769287109375
INFO:root:# Valid (Epoch 127): Loss/seq after 00200 batches: 574.8701171875
INFO:root:Artifacts: Make stick videos for epoch 127
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_127_on_20220414_020340.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_127_index_1906_on_20220414_020340.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 128): Loss/seq after 00000 batchs: 1118.0870361328125
INFO:root:Train (Epoch 128): Loss/seq after 00050 batchs: 841.45703125
INFO:root:Train (Epoch 128): Loss/seq after 00100 batchs: 877.0635986328125
INFO:root:Train (Epoch 128): Loss/seq after 00150 batchs: 789.8743896484375
INFO:root:Train (Epoch 128): Loss/seq after 00200 batchs: 872.0867919921875
INFO:root:Train (Epoch 128): Loss/seq after 00250 batchs: 980.665283203125
INFO:root:Train (Epoch 128): Loss/seq after 00300 batchs: 967.9376831054688
INFO:root:Train (Epoch 128): Loss/seq after 00350 batchs: 903.15283203125
INFO:root:Train (Epoch 128): Loss/seq after 00400 batchs: 911.0296630859375
INFO:root:Train (Epoch 128): Loss/seq after 00450 batchs: 885.72900390625
INFO:root:Train (Epoch 128): Loss/seq after 00500 batchs: 859.4835205078125
INFO:root:Train (Epoch 128): Loss/seq after 00550 batchs: 830.551513671875
INFO:root:Train (Epoch 128): Loss/seq after 00600 batchs: 800.039306640625
INFO:root:Train (Epoch 128): Loss/seq after 00650 batchs: 791.1541137695312
INFO:root:Train (Epoch 128): Loss/seq after 00700 batchs: 770.0626831054688
INFO:root:Train (Epoch 128): Loss/seq after 00750 batchs: 780.9425659179688
INFO:root:Train (Epoch 128): Loss/seq after 00800 batchs: 778.7120361328125
INFO:root:Train (Epoch 128): Loss/seq after 00850 batchs: 753.3297729492188
INFO:root:Train (Epoch 128): Loss/seq after 00900 batchs: 736.5892333984375
INFO:root:Train (Epoch 128): Loss/seq after 00950 batchs: 736.1425170898438
INFO:root:Train (Epoch 128): Loss/seq after 01000 batchs: 727.0721435546875
INFO:root:Train (Epoch 128): Loss/seq after 01050 batchs: 713.79638671875
INFO:root:Train (Epoch 128): Loss/seq after 01100 batchs: 701.8367309570312
INFO:root:Train (Epoch 128): Loss/seq after 01150 batchs: 684.4873657226562
INFO:root:Train (Epoch 128): Loss/seq after 01200 batchs: 686.7882690429688
INFO:root:Train (Epoch 128): Loss/seq after 01250 batchs: 683.4692993164062
INFO:root:Train (Epoch 128): Loss/seq after 01300 batchs: 672.115478515625
INFO:root:Train (Epoch 128): Loss/seq after 01350 batchs: 662.473388671875
INFO:root:Train (Epoch 128): Loss/seq after 01400 batchs: 671.0635375976562
INFO:root:Train (Epoch 128): Loss/seq after 01450 batchs: 670.79833984375
INFO:root:Train (Epoch 128): Loss/seq after 01500 batchs: 675.4968872070312
INFO:root:Train (Epoch 128): Loss/seq after 01550 batchs: 676.8739013671875
INFO:root:Train (Epoch 128): Loss/seq after 01600 batchs: 670.290771484375
INFO:root:Train (Epoch 128): Loss/seq after 01650 batchs: 666.8336181640625
INFO:root:Train (Epoch 128): Loss/seq after 01700 batchs: 667.844970703125
INFO:root:Train (Epoch 128): Loss/seq after 01750 batchs: 664.017333984375
INFO:root:Train (Epoch 128): Loss/seq after 01800 batchs: 660.0275268554688
INFO:root:Train (Epoch 128): Loss/seq after 01850 batchs: 654.8589477539062
INFO:root:Train (Epoch 128): Loss/seq after 01900 batchs: 654.8446044921875
INFO:root:Train (Epoch 128): Loss/seq after 01950 batchs: 652.261962890625
INFO:root:Train (Epoch 128): Loss/seq after 02000 batchs: 649.6016235351562
INFO:root:Train (Epoch 128): Loss/seq after 02050 batchs: 647.044189453125
INFO:root:Train (Epoch 128): Loss/seq after 02100 batchs: 643.19140625
INFO:root:Train (Epoch 128): Loss/seq after 02150 batchs: 640.2855224609375
INFO:root:Train (Epoch 128): Loss/seq after 02200 batchs: 636.436767578125
INFO:root:Train (Epoch 128): Loss/seq after 02250 batchs: 635.2726440429688
INFO:root:Train (Epoch 128): Loss/seq after 02300 batchs: 634.1121826171875
INFO:root:Train (Epoch 128): Loss/seq after 02350 batchs: 629.18896484375
INFO:root:Train (Epoch 128): Loss/seq after 02400 batchs: 630.1315307617188
INFO:root:Train (Epoch 128): Loss/seq after 02450 batchs: 624.4569702148438
INFO:root:Train (Epoch 128): Loss/seq after 02500 batchs: 615.2084350585938
INFO:root:Train (Epoch 128): Loss/seq after 02550 batchs: 608.4081420898438
INFO:root:Train (Epoch 128): Loss/seq after 02600 batchs: 607.2032470703125
INFO:root:Train (Epoch 128): Loss/seq after 02650 batchs: 604.66650390625
INFO:root:Train (Epoch 128): Loss/seq after 02700 batchs: 602.44873046875
INFO:root:Train (Epoch 128): Loss/seq after 02750 batchs: 602.7159423828125
INFO:root:Train (Epoch 128): Loss/seq after 02800 batchs: 604.2197265625
INFO:root:Train (Epoch 128): Loss/seq after 02850 batchs: 604.1515502929688
INFO:root:Train (Epoch 128): Loss/seq after 02900 batchs: 605.3531494140625
INFO:root:Train (Epoch 128): Loss/seq after 02950 batchs: 603.7142944335938
INFO:root:Train (Epoch 128): Loss/seq after 03000 batchs: 608.1298217773438
INFO:root:Train (Epoch 128): Loss/seq after 03050 batchs: 610.3297729492188
INFO:root:Train (Epoch 128): Loss/seq after 03100 batchs: 614.3675537109375
INFO:root:Train (Epoch 128): Loss/seq after 03150 batchs: 620.7491455078125
INFO:root:Train (Epoch 128): Loss/seq after 03200 batchs: 624.3715209960938
INFO:root:Train (Epoch 128): Loss/seq after 03250 batchs: 628.3011474609375
INFO:root:Train (Epoch 128): Loss/seq after 03300 batchs: 627.40966796875
INFO:root:Train (Epoch 128): Loss/seq after 03350 batchs: 627.7333984375
INFO:root:Train (Epoch 128): Loss/seq after 03400 batchs: 622.8370971679688
INFO:root:Train (Epoch 128): Loss/seq after 03450 batchs: 620.64990234375
INFO:root:Train (Epoch 128): Loss/seq after 03500 batchs: 620.66796875
INFO:root:Train (Epoch 128): Loss/seq after 03550 batchs: 617.2384033203125
INFO:root:Train (Epoch 128): Loss/seq after 03600 batchs: 625.4658203125
INFO:root:Train (Epoch 128): Loss/seq after 03650 batchs: 622.3554077148438
INFO:root:Train (Epoch 128): Loss/seq after 03700 batchs: 624.5111694335938
INFO:root:Train (Epoch 128): Loss/seq after 03750 batchs: 629.0701293945312
INFO:root:Train (Epoch 128): Loss/seq after 03800 batchs: 626.0304565429688
INFO:root:Train (Epoch 128): Loss/seq after 03850 batchs: 624.9144287109375
INFO:root:Train (Epoch 128): Loss/seq after 03900 batchs: 629.373291015625
INFO:root:Train (Epoch 128): Loss/seq after 03950 batchs: 633.6852416992188
INFO:root:Train (Epoch 128): Loss/seq after 04000 batchs: 629.4332885742188
INFO:root:Train (Epoch 128): Loss/seq after 04050 batchs: 625.3848876953125
INFO:root:Train (Epoch 128): Loss/seq after 04100 batchs: 623.088623046875
INFO:root:Train (Epoch 128): Loss/seq after 04150 batchs: 622.5603637695312
INFO:root:Train (Epoch 128): Loss/seq after 04200 batchs: 620.568359375
INFO:root:Train (Epoch 128): Loss/seq after 04250 batchs: 618.4404907226562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 128): Loss/seq after 00000 batches: 574.1652221679688
INFO:root:# Valid (Epoch 128): Loss/seq after 00050 batches: 856.308837890625
INFO:root:# Valid (Epoch 128): Loss/seq after 00100 batches: 843.3308715820312
INFO:root:# Valid (Epoch 128): Loss/seq after 00150 batches: 630.2492065429688
INFO:root:# Valid (Epoch 128): Loss/seq after 00200 batches: 577.6768798828125
INFO:root:Artifacts: Make stick videos for epoch 128
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_128_on_20220414_020858.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_128_index_1800_on_20220414_020858.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 129): Loss/seq after 00000 batchs: 1147.03125
INFO:root:Train (Epoch 129): Loss/seq after 00050 batchs: 857.0381469726562
INFO:root:Train (Epoch 129): Loss/seq after 00100 batchs: 878.7639770507812
INFO:root:Train (Epoch 129): Loss/seq after 00150 batchs: 791.38671875
INFO:root:Train (Epoch 129): Loss/seq after 00200 batchs: 867.4170532226562
INFO:root:Train (Epoch 129): Loss/seq after 00250 batchs: 974.3179321289062
INFO:root:Train (Epoch 129): Loss/seq after 00300 batchs: 962.2870483398438
INFO:root:Train (Epoch 129): Loss/seq after 00350 batchs: 897.6796875
INFO:root:Train (Epoch 129): Loss/seq after 00400 batchs: 905.01318359375
INFO:root:Train (Epoch 129): Loss/seq after 00450 batchs: 880.088623046875
INFO:root:Train (Epoch 129): Loss/seq after 00500 batchs: 853.2887573242188
INFO:root:Train (Epoch 129): Loss/seq after 00550 batchs: 824.9072265625
INFO:root:Train (Epoch 129): Loss/seq after 00600 batchs: 795.2343139648438
INFO:root:Train (Epoch 129): Loss/seq after 00650 batchs: 783.535888671875
INFO:root:Train (Epoch 129): Loss/seq after 00700 batchs: 762.0606689453125
INFO:root:Train (Epoch 129): Loss/seq after 00750 batchs: 775.630859375
INFO:root:Train (Epoch 129): Loss/seq after 00800 batchs: 774.0651245117188
INFO:root:Train (Epoch 129): Loss/seq after 00850 batchs: 749.4826049804688
INFO:root:Train (Epoch 129): Loss/seq after 00900 batchs: 733.0984497070312
INFO:root:Train (Epoch 129): Loss/seq after 00950 batchs: 734.6746826171875
INFO:root:Train (Epoch 129): Loss/seq after 01000 batchs: 726.6483764648438
INFO:root:Train (Epoch 129): Loss/seq after 01050 batchs: 714.8153686523438
INFO:root:Train (Epoch 129): Loss/seq after 01100 batchs: 703.7515869140625
INFO:root:Train (Epoch 129): Loss/seq after 01150 batchs: 686.4574584960938
INFO:root:Train (Epoch 129): Loss/seq after 01200 batchs: 688.5657958984375
INFO:root:Train (Epoch 129): Loss/seq after 01250 batchs: 685.2363891601562
INFO:root:Train (Epoch 129): Loss/seq after 01300 batchs: 672.9459838867188
INFO:root:Train (Epoch 129): Loss/seq after 01350 batchs: 662.8012084960938
INFO:root:Train (Epoch 129): Loss/seq after 01400 batchs: 670.427001953125
INFO:root:Train (Epoch 129): Loss/seq after 01450 batchs: 670.4268798828125
INFO:root:Train (Epoch 129): Loss/seq after 01500 batchs: 675.089111328125
INFO:root:Train (Epoch 129): Loss/seq after 01550 batchs: 676.6220092773438
INFO:root:Train (Epoch 129): Loss/seq after 01600 batchs: 669.794921875
INFO:root:Train (Epoch 129): Loss/seq after 01650 batchs: 666.5390625
INFO:root:Train (Epoch 129): Loss/seq after 01700 batchs: 667.21728515625
INFO:root:Train (Epoch 129): Loss/seq after 01750 batchs: 663.3494262695312
INFO:root:Train (Epoch 129): Loss/seq after 01800 batchs: 659.389892578125
INFO:root:Train (Epoch 129): Loss/seq after 01850 batchs: 654.2097778320312
INFO:root:Train (Epoch 129): Loss/seq after 01900 batchs: 654.12060546875
INFO:root:Train (Epoch 129): Loss/seq after 01950 batchs: 651.5892333984375
INFO:root:Train (Epoch 129): Loss/seq after 02000 batchs: 649.0481567382812
INFO:root:Train (Epoch 129): Loss/seq after 02050 batchs: 646.4410400390625
INFO:root:Train (Epoch 129): Loss/seq after 02100 batchs: 642.6204223632812
INFO:root:Train (Epoch 129): Loss/seq after 02150 batchs: 639.9091186523438
INFO:root:Train (Epoch 129): Loss/seq after 02200 batchs: 636.1481323242188
INFO:root:Train (Epoch 129): Loss/seq after 02250 batchs: 634.5728759765625
INFO:root:Train (Epoch 129): Loss/seq after 02300 batchs: 633.5490112304688
INFO:root:Train (Epoch 129): Loss/seq after 02350 batchs: 628.2349243164062
INFO:root:Train (Epoch 129): Loss/seq after 02400 batchs: 628.9322509765625
INFO:root:Train (Epoch 129): Loss/seq after 02450 batchs: 623.2342529296875
INFO:root:Train (Epoch 129): Loss/seq after 02500 batchs: 613.9822998046875
INFO:root:Train (Epoch 129): Loss/seq after 02550 batchs: 607.0994873046875
INFO:root:Train (Epoch 129): Loss/seq after 02600 batchs: 605.6773681640625
INFO:root:Train (Epoch 129): Loss/seq after 02650 batchs: 603.2237548828125
INFO:root:Train (Epoch 129): Loss/seq after 02700 batchs: 600.8021240234375
INFO:root:Train (Epoch 129): Loss/seq after 02750 batchs: 600.5726318359375
INFO:root:Train (Epoch 129): Loss/seq after 02800 batchs: 601.9779663085938
INFO:root:Train (Epoch 129): Loss/seq after 02850 batchs: 601.7887573242188
INFO:root:Train (Epoch 129): Loss/seq after 02900 batchs: 602.866943359375
INFO:root:Train (Epoch 129): Loss/seq after 02950 batchs: 601.2511596679688
INFO:root:Train (Epoch 129): Loss/seq after 03000 batchs: 605.745361328125
INFO:root:Train (Epoch 129): Loss/seq after 03050 batchs: 607.8648071289062
INFO:root:Train (Epoch 129): Loss/seq after 03100 batchs: 611.8599853515625
INFO:root:Train (Epoch 129): Loss/seq after 03150 batchs: 618.3030395507812
INFO:root:Train (Epoch 129): Loss/seq after 03200 batchs: 622.3453369140625
INFO:root:Train (Epoch 129): Loss/seq after 03250 batchs: 626.4144287109375
INFO:root:Train (Epoch 129): Loss/seq after 03300 batchs: 625.525390625
INFO:root:Train (Epoch 129): Loss/seq after 03350 batchs: 626.4049682617188
INFO:root:Train (Epoch 129): Loss/seq after 03400 batchs: 621.5156860351562
INFO:root:Train (Epoch 129): Loss/seq after 03450 batchs: 619.4190673828125
INFO:root:Train (Epoch 129): Loss/seq after 03500 batchs: 619.4171142578125
INFO:root:Train (Epoch 129): Loss/seq after 03550 batchs: 616.080322265625
INFO:root:Train (Epoch 129): Loss/seq after 03600 batchs: 623.917236328125
INFO:root:Train (Epoch 129): Loss/seq after 03650 batchs: 620.7621459960938
INFO:root:Train (Epoch 129): Loss/seq after 03700 batchs: 622.8124389648438
INFO:root:Train (Epoch 129): Loss/seq after 03750 batchs: 627.301513671875
INFO:root:Train (Epoch 129): Loss/seq after 03800 batchs: 624.3062744140625
INFO:root:Train (Epoch 129): Loss/seq after 03850 batchs: 623.0203857421875
INFO:root:Train (Epoch 129): Loss/seq after 03900 batchs: 627.4317626953125
INFO:root:Train (Epoch 129): Loss/seq after 03950 batchs: 631.958251953125
INFO:root:Train (Epoch 129): Loss/seq after 04000 batchs: 627.7429809570312
INFO:root:Train (Epoch 129): Loss/seq after 04050 batchs: 623.7014770507812
INFO:root:Train (Epoch 129): Loss/seq after 04100 batchs: 621.4122924804688
INFO:root:Train (Epoch 129): Loss/seq after 04150 batchs: 620.8547973632812
INFO:root:Train (Epoch 129): Loss/seq after 04200 batchs: 618.8709716796875
INFO:root:Train (Epoch 129): Loss/seq after 04250 batchs: 616.94384765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 129): Loss/seq after 00000 batches: 517.7291870117188
INFO:root:# Valid (Epoch 129): Loss/seq after 00050 batches: 843.6425170898438
INFO:root:# Valid (Epoch 129): Loss/seq after 00100 batches: 826.4054565429688
INFO:root:# Valid (Epoch 129): Loss/seq after 00150 batches: 618.0947875976562
INFO:root:# Valid (Epoch 129): Loss/seq after 00200 batches: 568.505615234375
INFO:root:Artifacts: Make stick videos for epoch 129
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_129_on_20220414_021416.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_129_index_1223_on_20220414_021416.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 130): Loss/seq after 00000 batchs: 1084.4844970703125
INFO:root:Train (Epoch 130): Loss/seq after 00050 batchs: 850.9616088867188
INFO:root:Train (Epoch 130): Loss/seq after 00100 batchs: 876.7238159179688
INFO:root:Train (Epoch 130): Loss/seq after 00150 batchs: 787.251220703125
INFO:root:Train (Epoch 130): Loss/seq after 00200 batchs: 859.5390625
INFO:root:Train (Epoch 130): Loss/seq after 00250 batchs: 965.5315551757812
INFO:root:Train (Epoch 130): Loss/seq after 00300 batchs: 954.4680786132812
INFO:root:Train (Epoch 130): Loss/seq after 00350 batchs: 890.2415161132812
INFO:root:Train (Epoch 130): Loss/seq after 00400 batchs: 897.204833984375
INFO:root:Train (Epoch 130): Loss/seq after 00450 batchs: 873.0497436523438
INFO:root:Train (Epoch 130): Loss/seq after 00500 batchs: 845.7863159179688
INFO:root:Train (Epoch 130): Loss/seq after 00550 batchs: 817.614501953125
INFO:root:Train (Epoch 130): Loss/seq after 00600 batchs: 787.8151245117188
INFO:root:Train (Epoch 130): Loss/seq after 00650 batchs: 775.2103881835938
INFO:root:Train (Epoch 130): Loss/seq after 00700 batchs: 751.8715209960938
INFO:root:Train (Epoch 130): Loss/seq after 00750 batchs: 762.6822509765625
INFO:root:Train (Epoch 130): Loss/seq after 00800 batchs: 761.260498046875
INFO:root:Train (Epoch 130): Loss/seq after 00850 batchs: 736.8709716796875
INFO:root:Train (Epoch 130): Loss/seq after 00900 batchs: 720.6467895507812
INFO:root:Train (Epoch 130): Loss/seq after 00950 batchs: 720.3618774414062
INFO:root:Train (Epoch 130): Loss/seq after 01000 batchs: 712.3356323242188
INFO:root:Train (Epoch 130): Loss/seq after 01050 batchs: 699.7694091796875
INFO:root:Train (Epoch 130): Loss/seq after 01100 batchs: 688.7861938476562
INFO:root:Train (Epoch 130): Loss/seq after 01150 batchs: 671.8551025390625
INFO:root:Train (Epoch 130): Loss/seq after 01200 batchs: 674.6318359375
INFO:root:Train (Epoch 130): Loss/seq after 01250 batchs: 671.6423950195312
INFO:root:Train (Epoch 130): Loss/seq after 01300 batchs: 660.1337890625
INFO:root:Train (Epoch 130): Loss/seq after 01350 batchs: 650.7051391601562
INFO:root:Train (Epoch 130): Loss/seq after 01400 batchs: 658.0563354492188
INFO:root:Train (Epoch 130): Loss/seq after 01450 batchs: 658.3431396484375
INFO:root:Train (Epoch 130): Loss/seq after 01500 batchs: 663.4259643554688
INFO:root:Train (Epoch 130): Loss/seq after 01550 batchs: 664.8562622070312
INFO:root:Train (Epoch 130): Loss/seq after 01600 batchs: 658.3069458007812
INFO:root:Train (Epoch 130): Loss/seq after 01650 batchs: 655.2613525390625
INFO:root:Train (Epoch 130): Loss/seq after 01700 batchs: 656.7095336914062
INFO:root:Train (Epoch 130): Loss/seq after 01750 batchs: 653.2730712890625
INFO:root:Train (Epoch 130): Loss/seq after 01800 batchs: 649.4586181640625
INFO:root:Train (Epoch 130): Loss/seq after 01850 batchs: 644.5471801757812
INFO:root:Train (Epoch 130): Loss/seq after 01900 batchs: 644.7075805664062
INFO:root:Train (Epoch 130): Loss/seq after 01950 batchs: 642.2780151367188
INFO:root:Train (Epoch 130): Loss/seq after 02000 batchs: 639.9146118164062
INFO:root:Train (Epoch 130): Loss/seq after 02050 batchs: 637.496337890625
INFO:root:Train (Epoch 130): Loss/seq after 02100 batchs: 633.8500366210938
INFO:root:Train (Epoch 130): Loss/seq after 02150 batchs: 631.203857421875
INFO:root:Train (Epoch 130): Loss/seq after 02200 batchs: 627.5634765625
INFO:root:Train (Epoch 130): Loss/seq after 02250 batchs: 626.3265991210938
INFO:root:Train (Epoch 130): Loss/seq after 02300 batchs: 625.6113891601562
INFO:root:Train (Epoch 130): Loss/seq after 02350 batchs: 620.678955078125
INFO:root:Train (Epoch 130): Loss/seq after 02400 batchs: 621.5249633789062
INFO:root:Train (Epoch 130): Loss/seq after 02450 batchs: 615.9707641601562
INFO:root:Train (Epoch 130): Loss/seq after 02500 batchs: 606.8616333007812
INFO:root:Train (Epoch 130): Loss/seq after 02550 batchs: 600.0963745117188
INFO:root:Train (Epoch 130): Loss/seq after 02600 batchs: 599.2254638671875
INFO:root:Train (Epoch 130): Loss/seq after 02650 batchs: 596.8602294921875
INFO:root:Train (Epoch 130): Loss/seq after 02700 batchs: 594.6259155273438
INFO:root:Train (Epoch 130): Loss/seq after 02750 batchs: 594.5712280273438
INFO:root:Train (Epoch 130): Loss/seq after 02800 batchs: 595.7059326171875
INFO:root:Train (Epoch 130): Loss/seq after 02850 batchs: 595.617919921875
INFO:root:Train (Epoch 130): Loss/seq after 02900 batchs: 596.8853759765625
INFO:root:Train (Epoch 130): Loss/seq after 02950 batchs: 595.4808349609375
INFO:root:Train (Epoch 130): Loss/seq after 03000 batchs: 600.0166015625
INFO:root:Train (Epoch 130): Loss/seq after 03050 batchs: 601.7461547851562
INFO:root:Train (Epoch 130): Loss/seq after 03100 batchs: 606.1565551757812
INFO:root:Train (Epoch 130): Loss/seq after 03150 batchs: 612.889892578125
INFO:root:Train (Epoch 130): Loss/seq after 03200 batchs: 616.2430419921875
INFO:root:Train (Epoch 130): Loss/seq after 03250 batchs: 620.2686157226562
INFO:root:Train (Epoch 130): Loss/seq after 03300 batchs: 620.0651245117188
INFO:root:Train (Epoch 130): Loss/seq after 03350 batchs: 621.0962524414062
INFO:root:Train (Epoch 130): Loss/seq after 03400 batchs: 616.503662109375
INFO:root:Train (Epoch 130): Loss/seq after 03450 batchs: 614.4503784179688
INFO:root:Train (Epoch 130): Loss/seq after 03500 batchs: 614.6232299804688
INFO:root:Train (Epoch 130): Loss/seq after 03550 batchs: 611.42138671875
INFO:root:Train (Epoch 130): Loss/seq after 03600 batchs: 620.051513671875
INFO:root:Train (Epoch 130): Loss/seq after 03650 batchs: 616.9703979492188
INFO:root:Train (Epoch 130): Loss/seq after 03700 batchs: 619.1232299804688
INFO:root:Train (Epoch 130): Loss/seq after 03750 batchs: 623.5918579101562
INFO:root:Train (Epoch 130): Loss/seq after 03800 batchs: 620.6202392578125
INFO:root:Train (Epoch 130): Loss/seq after 03850 batchs: 619.525146484375
INFO:root:Train (Epoch 130): Loss/seq after 03900 batchs: 623.9606323242188
INFO:root:Train (Epoch 130): Loss/seq after 03950 batchs: 628.5626220703125
INFO:root:Train (Epoch 130): Loss/seq after 04000 batchs: 624.3516845703125
INFO:root:Train (Epoch 130): Loss/seq after 04050 batchs: 620.3125610351562
INFO:root:Train (Epoch 130): Loss/seq after 04100 batchs: 618.0664672851562
INFO:root:Train (Epoch 130): Loss/seq after 04150 batchs: 617.6035766601562
INFO:root:Train (Epoch 130): Loss/seq after 04200 batchs: 615.7698364257812
INFO:root:Train (Epoch 130): Loss/seq after 04250 batchs: 613.71337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 130): Loss/seq after 00000 batches: 547.4526977539062
INFO:root:# Valid (Epoch 130): Loss/seq after 00050 batches: 820.8264770507812
INFO:root:# Valid (Epoch 130): Loss/seq after 00100 batches: 837.5298461914062
INFO:root:# Valid (Epoch 130): Loss/seq after 00150 batches: 626.42431640625
INFO:root:# Valid (Epoch 130): Loss/seq after 00200 batches: 575.5741577148438
INFO:root:Artifacts: Make stick videos for epoch 130
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_130_on_20220414_021934.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_130_index_1369_on_20220414_021934.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 131): Loss/seq after 00000 batchs: 1088.841064453125
INFO:root:Train (Epoch 131): Loss/seq after 00050 batchs: 843.4388427734375
INFO:root:Train (Epoch 131): Loss/seq after 00100 batchs: 867.4046020507812
INFO:root:Train (Epoch 131): Loss/seq after 00150 batchs: 781.659423828125
INFO:root:Train (Epoch 131): Loss/seq after 00200 batchs: 857.2906494140625
INFO:root:Train (Epoch 131): Loss/seq after 00250 batchs: 960.9183959960938
INFO:root:Train (Epoch 131): Loss/seq after 00300 batchs: 950.794189453125
INFO:root:Train (Epoch 131): Loss/seq after 00350 batchs: 887.3031616210938
INFO:root:Train (Epoch 131): Loss/seq after 00400 batchs: 896.8154907226562
INFO:root:Train (Epoch 131): Loss/seq after 00450 batchs: 872.82861328125
INFO:root:Train (Epoch 131): Loss/seq after 00500 batchs: 845.344482421875
INFO:root:Train (Epoch 131): Loss/seq after 00550 batchs: 817.0335693359375
INFO:root:Train (Epoch 131): Loss/seq after 00600 batchs: 787.341552734375
INFO:root:Train (Epoch 131): Loss/seq after 00650 batchs: 774.82470703125
INFO:root:Train (Epoch 131): Loss/seq after 00700 batchs: 752.9578247070312
INFO:root:Train (Epoch 131): Loss/seq after 00750 batchs: 763.023681640625
INFO:root:Train (Epoch 131): Loss/seq after 00800 batchs: 761.6590576171875
INFO:root:Train (Epoch 131): Loss/seq after 00850 batchs: 737.4404907226562
INFO:root:Train (Epoch 131): Loss/seq after 00900 batchs: 721.3433227539062
INFO:root:Train (Epoch 131): Loss/seq after 00950 batchs: 721.4482421875
INFO:root:Train (Epoch 131): Loss/seq after 01000 batchs: 712.9360961914062
INFO:root:Train (Epoch 131): Loss/seq after 01050 batchs: 700.5809326171875
INFO:root:Train (Epoch 131): Loss/seq after 01100 batchs: 689.6295776367188
INFO:root:Train (Epoch 131): Loss/seq after 01150 batchs: 673.0263061523438
INFO:root:Train (Epoch 131): Loss/seq after 01200 batchs: 676.0001220703125
INFO:root:Train (Epoch 131): Loss/seq after 01250 batchs: 673.07763671875
INFO:root:Train (Epoch 131): Loss/seq after 01300 batchs: 662.510986328125
INFO:root:Train (Epoch 131): Loss/seq after 01350 batchs: 652.697021484375
INFO:root:Train (Epoch 131): Loss/seq after 01400 batchs: 660.0609130859375
INFO:root:Train (Epoch 131): Loss/seq after 01450 batchs: 660.4454345703125
INFO:root:Train (Epoch 131): Loss/seq after 01500 batchs: 665.476806640625
INFO:root:Train (Epoch 131): Loss/seq after 01550 batchs: 667.005126953125
INFO:root:Train (Epoch 131): Loss/seq after 01600 batchs: 660.3958129882812
INFO:root:Train (Epoch 131): Loss/seq after 01650 batchs: 657.3480834960938
INFO:root:Train (Epoch 131): Loss/seq after 01700 batchs: 658.3443603515625
INFO:root:Train (Epoch 131): Loss/seq after 01750 batchs: 654.7202758789062
INFO:root:Train (Epoch 131): Loss/seq after 01800 batchs: 650.8726806640625
INFO:root:Train (Epoch 131): Loss/seq after 01850 batchs: 645.7752075195312
INFO:root:Train (Epoch 131): Loss/seq after 01900 batchs: 645.7715454101562
INFO:root:Train (Epoch 131): Loss/seq after 01950 batchs: 643.148681640625
INFO:root:Train (Epoch 131): Loss/seq after 02000 batchs: 640.6365966796875
INFO:root:Train (Epoch 131): Loss/seq after 02050 batchs: 638.17333984375
INFO:root:Train (Epoch 131): Loss/seq after 02100 batchs: 634.4561157226562
INFO:root:Train (Epoch 131): Loss/seq after 02150 batchs: 631.7761840820312
INFO:root:Train (Epoch 131): Loss/seq after 02200 batchs: 628.1248779296875
INFO:root:Train (Epoch 131): Loss/seq after 02250 batchs: 626.6992797851562
INFO:root:Train (Epoch 131): Loss/seq after 02300 batchs: 625.241943359375
INFO:root:Train (Epoch 131): Loss/seq after 02350 batchs: 620.4386596679688
INFO:root:Train (Epoch 131): Loss/seq after 02400 batchs: 621.3898315429688
INFO:root:Train (Epoch 131): Loss/seq after 02450 batchs: 615.8375854492188
INFO:root:Train (Epoch 131): Loss/seq after 02500 batchs: 606.7120361328125
INFO:root:Train (Epoch 131): Loss/seq after 02550 batchs: 599.9891357421875
INFO:root:Train (Epoch 131): Loss/seq after 02600 batchs: 598.876953125
INFO:root:Train (Epoch 131): Loss/seq after 02650 batchs: 596.4912109375
INFO:root:Train (Epoch 131): Loss/seq after 02700 batchs: 594.0759887695312
INFO:root:Train (Epoch 131): Loss/seq after 02750 batchs: 593.8289184570312
INFO:root:Train (Epoch 131): Loss/seq after 02800 batchs: 594.2141723632812
INFO:root:Train (Epoch 131): Loss/seq after 02850 batchs: 594.0536499023438
INFO:root:Train (Epoch 131): Loss/seq after 02900 batchs: 595.14208984375
INFO:root:Train (Epoch 131): Loss/seq after 02950 batchs: 593.6723022460938
INFO:root:Train (Epoch 131): Loss/seq after 03000 batchs: 598.2293090820312
INFO:root:Train (Epoch 131): Loss/seq after 03050 batchs: 600.1340942382812
INFO:root:Train (Epoch 131): Loss/seq after 03100 batchs: 604.430419921875
INFO:root:Train (Epoch 131): Loss/seq after 03150 batchs: 610.6634521484375
INFO:root:Train (Epoch 131): Loss/seq after 03200 batchs: 614.1317749023438
INFO:root:Train (Epoch 131): Loss/seq after 03250 batchs: 618.282958984375
INFO:root:Train (Epoch 131): Loss/seq after 03300 batchs: 617.6264038085938
INFO:root:Train (Epoch 131): Loss/seq after 03350 batchs: 618.1355590820312
INFO:root:Train (Epoch 131): Loss/seq after 03400 batchs: 613.5836791992188
INFO:root:Train (Epoch 131): Loss/seq after 03450 batchs: 611.6640625
INFO:root:Train (Epoch 131): Loss/seq after 03500 batchs: 611.727783203125
INFO:root:Train (Epoch 131): Loss/seq after 03550 batchs: 608.6188354492188
INFO:root:Train (Epoch 131): Loss/seq after 03600 batchs: 616.970703125
INFO:root:Train (Epoch 131): Loss/seq after 03650 batchs: 613.83984375
INFO:root:Train (Epoch 131): Loss/seq after 03700 batchs: 615.8006591796875
INFO:root:Train (Epoch 131): Loss/seq after 03750 batchs: 620.3588256835938
INFO:root:Train (Epoch 131): Loss/seq after 03800 batchs: 617.38916015625
INFO:root:Train (Epoch 131): Loss/seq after 03850 batchs: 616.1428833007812
INFO:root:Train (Epoch 131): Loss/seq after 03900 batchs: 620.4989624023438
INFO:root:Train (Epoch 131): Loss/seq after 03950 batchs: 624.8013916015625
INFO:root:Train (Epoch 131): Loss/seq after 04000 batchs: 620.6393432617188
INFO:root:Train (Epoch 131): Loss/seq after 04050 batchs: 616.6622924804688
INFO:root:Train (Epoch 131): Loss/seq after 04100 batchs: 614.4655151367188
INFO:root:Train (Epoch 131): Loss/seq after 04150 batchs: 613.9591064453125
INFO:root:Train (Epoch 131): Loss/seq after 04200 batchs: 612.1577758789062
INFO:root:Train (Epoch 131): Loss/seq after 04250 batchs: 610.108642578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 131): Loss/seq after 00000 batches: 516.8814697265625
INFO:root:# Valid (Epoch 131): Loss/seq after 00050 batches: 807.2600708007812
INFO:root:# Valid (Epoch 131): Loss/seq after 00100 batches: 808.8907470703125
INFO:root:# Valid (Epoch 131): Loss/seq after 00150 batches: 605.4003295898438
INFO:root:# Valid (Epoch 131): Loss/seq after 00200 batches: 557.9447631835938
INFO:root:Artifacts: Make stick videos for epoch 131
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_131_on_20220414_022452.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_131_index_1360_on_20220414_022452.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 132): Loss/seq after 00000 batchs: 1071.555419921875
INFO:root:Train (Epoch 132): Loss/seq after 00050 batchs: 857.2994384765625
INFO:root:Train (Epoch 132): Loss/seq after 00100 batchs: 872.3455200195312
INFO:root:Train (Epoch 132): Loss/seq after 00150 batchs: 783.6492309570312
INFO:root:Train (Epoch 132): Loss/seq after 00200 batchs: 856.9169311523438
INFO:root:Train (Epoch 132): Loss/seq after 00250 batchs: 966.5035400390625
INFO:root:Train (Epoch 132): Loss/seq after 00300 batchs: 954.7760620117188
INFO:root:Train (Epoch 132): Loss/seq after 00350 batchs: 891.0330200195312
INFO:root:Train (Epoch 132): Loss/seq after 00400 batchs: 898.7306518554688
INFO:root:Train (Epoch 132): Loss/seq after 00450 batchs: 874.099609375
INFO:root:Train (Epoch 132): Loss/seq after 00500 batchs: 844.5955200195312
INFO:root:Train (Epoch 132): Loss/seq after 00550 batchs: 816.3321533203125
INFO:root:Train (Epoch 132): Loss/seq after 00600 batchs: 786.8702392578125
INFO:root:Train (Epoch 132): Loss/seq after 00650 batchs: 773.9619140625
INFO:root:Train (Epoch 132): Loss/seq after 00700 batchs: 752.0196533203125
INFO:root:Train (Epoch 132): Loss/seq after 00750 batchs: 761.4527587890625
INFO:root:Train (Epoch 132): Loss/seq after 00800 batchs: 760.3403930664062
INFO:root:Train (Epoch 132): Loss/seq after 00850 batchs: 735.9088134765625
INFO:root:Train (Epoch 132): Loss/seq after 00900 batchs: 719.638916015625
INFO:root:Train (Epoch 132): Loss/seq after 00950 batchs: 720.1826171875
INFO:root:Train (Epoch 132): Loss/seq after 01000 batchs: 713.0322875976562
INFO:root:Train (Epoch 132): Loss/seq after 01050 batchs: 700.9910888671875
INFO:root:Train (Epoch 132): Loss/seq after 01100 batchs: 689.7416381835938
INFO:root:Train (Epoch 132): Loss/seq after 01150 batchs: 673.0984497070312
INFO:root:Train (Epoch 132): Loss/seq after 01200 batchs: 676.0166015625
INFO:root:Train (Epoch 132): Loss/seq after 01250 batchs: 672.7822265625
INFO:root:Train (Epoch 132): Loss/seq after 01300 batchs: 661.4984130859375
INFO:root:Train (Epoch 132): Loss/seq after 01350 batchs: 651.4548950195312
INFO:root:Train (Epoch 132): Loss/seq after 01400 batchs: 658.6769409179688
INFO:root:Train (Epoch 132): Loss/seq after 01450 batchs: 659.2418823242188
INFO:root:Train (Epoch 132): Loss/seq after 01500 batchs: 664.2954711914062
INFO:root:Train (Epoch 132): Loss/seq after 01550 batchs: 665.6107177734375
INFO:root:Train (Epoch 132): Loss/seq after 01600 batchs: 658.9151611328125
INFO:root:Train (Epoch 132): Loss/seq after 01650 batchs: 655.6807250976562
INFO:root:Train (Epoch 132): Loss/seq after 01700 batchs: 656.7781982421875
INFO:root:Train (Epoch 132): Loss/seq after 01750 batchs: 653.0737915039062
INFO:root:Train (Epoch 132): Loss/seq after 01800 batchs: 649.195068359375
INFO:root:Train (Epoch 132): Loss/seq after 01850 batchs: 644.2257690429688
INFO:root:Train (Epoch 132): Loss/seq after 01900 batchs: 644.1988525390625
INFO:root:Train (Epoch 132): Loss/seq after 01950 batchs: 641.8309326171875
INFO:root:Train (Epoch 132): Loss/seq after 02000 batchs: 639.367919921875
INFO:root:Train (Epoch 132): Loss/seq after 02050 batchs: 636.8812866210938
INFO:root:Train (Epoch 132): Loss/seq after 02100 batchs: 633.0869140625
INFO:root:Train (Epoch 132): Loss/seq after 02150 batchs: 630.4370727539062
INFO:root:Train (Epoch 132): Loss/seq after 02200 batchs: 626.75732421875
INFO:root:Train (Epoch 132): Loss/seq after 02250 batchs: 625.144775390625
INFO:root:Train (Epoch 132): Loss/seq after 02300 batchs: 623.43115234375
INFO:root:Train (Epoch 132): Loss/seq after 02350 batchs: 618.20068359375
INFO:root:Train (Epoch 132): Loss/seq after 02400 batchs: 619.0150756835938
INFO:root:Train (Epoch 132): Loss/seq after 02450 batchs: 613.4216918945312
INFO:root:Train (Epoch 132): Loss/seq after 02500 batchs: 604.3238525390625
INFO:root:Train (Epoch 132): Loss/seq after 02550 batchs: 597.6573486328125
INFO:root:Train (Epoch 132): Loss/seq after 02600 batchs: 596.66064453125
INFO:root:Train (Epoch 132): Loss/seq after 02650 batchs: 594.1975708007812
INFO:root:Train (Epoch 132): Loss/seq after 02700 batchs: 591.7731323242188
INFO:root:Train (Epoch 132): Loss/seq after 02750 batchs: 591.3042602539062
INFO:root:Train (Epoch 132): Loss/seq after 02800 batchs: 592.2655029296875
INFO:root:Train (Epoch 132): Loss/seq after 02850 batchs: 592.0597534179688
INFO:root:Train (Epoch 132): Loss/seq after 02900 batchs: 593.1265258789062
INFO:root:Train (Epoch 132): Loss/seq after 02950 batchs: 591.6550903320312
INFO:root:Train (Epoch 132): Loss/seq after 03000 batchs: 596.1731567382812
INFO:root:Train (Epoch 132): Loss/seq after 03050 batchs: 598.3250732421875
INFO:root:Train (Epoch 132): Loss/seq after 03100 batchs: 602.6041870117188
INFO:root:Train (Epoch 132): Loss/seq after 03150 batchs: 608.7529296875
INFO:root:Train (Epoch 132): Loss/seq after 03200 batchs: 611.9572143554688
INFO:root:Train (Epoch 132): Loss/seq after 03250 batchs: 615.6866455078125
INFO:root:Train (Epoch 132): Loss/seq after 03300 batchs: 614.9429321289062
INFO:root:Train (Epoch 132): Loss/seq after 03350 batchs: 615.619140625
INFO:root:Train (Epoch 132): Loss/seq after 03400 batchs: 610.9232788085938
INFO:root:Train (Epoch 132): Loss/seq after 03450 batchs: 608.9877319335938
INFO:root:Train (Epoch 132): Loss/seq after 03500 batchs: 609.2506103515625
INFO:root:Train (Epoch 132): Loss/seq after 03550 batchs: 606.0181274414062
INFO:root:Train (Epoch 132): Loss/seq after 03600 batchs: 614.1052856445312
INFO:root:Train (Epoch 132): Loss/seq after 03650 batchs: 611.0947875976562
INFO:root:Train (Epoch 132): Loss/seq after 03700 batchs: 613.2964477539062
INFO:root:Train (Epoch 132): Loss/seq after 03750 batchs: 617.7828979492188
INFO:root:Train (Epoch 132): Loss/seq after 03800 batchs: 614.8523559570312
INFO:root:Train (Epoch 132): Loss/seq after 03850 batchs: 613.5310668945312
INFO:root:Train (Epoch 132): Loss/seq after 03900 batchs: 617.72509765625
INFO:root:Train (Epoch 132): Loss/seq after 03950 batchs: 621.9310302734375
INFO:root:Train (Epoch 132): Loss/seq after 04000 batchs: 617.7188110351562
INFO:root:Train (Epoch 132): Loss/seq after 04050 batchs: 613.7591552734375
INFO:root:Train (Epoch 132): Loss/seq after 04100 batchs: 611.5172729492188
INFO:root:Train (Epoch 132): Loss/seq after 04150 batchs: 611.0726928710938
INFO:root:Train (Epoch 132): Loss/seq after 04200 batchs: 609.1109008789062
INFO:root:Train (Epoch 132): Loss/seq after 04250 batchs: 607.0992431640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 132): Loss/seq after 00000 batches: 556.6473999023438
INFO:root:# Valid (Epoch 132): Loss/seq after 00050 batches: 805.9197387695312
INFO:root:# Valid (Epoch 132): Loss/seq after 00100 batches: 801.1541748046875
INFO:root:# Valid (Epoch 132): Loss/seq after 00150 batches: 601.1787719726562
INFO:root:# Valid (Epoch 132): Loss/seq after 00200 batches: 555.5714721679688
INFO:root:Artifacts: Make stick videos for epoch 132
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_132_on_20220414_023008.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_132_index_552_on_20220414_023008.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 133): Loss/seq after 00000 batchs: 1070.332275390625
INFO:root:Train (Epoch 133): Loss/seq after 00050 batchs: 829.272705078125
INFO:root:Train (Epoch 133): Loss/seq after 00100 batchs: 856.8365478515625
INFO:root:Train (Epoch 133): Loss/seq after 00150 batchs: 773.4679565429688
INFO:root:Train (Epoch 133): Loss/seq after 00200 batchs: 845.2869873046875
INFO:root:Train (Epoch 133): Loss/seq after 00250 batchs: 950.7654418945312
INFO:root:Train (Epoch 133): Loss/seq after 00300 batchs: 941.3499755859375
INFO:root:Train (Epoch 133): Loss/seq after 00350 batchs: 879.44482421875
INFO:root:Train (Epoch 133): Loss/seq after 00400 batchs: 884.069091796875
INFO:root:Train (Epoch 133): Loss/seq after 00450 batchs: 861.2862548828125
INFO:root:Train (Epoch 133): Loss/seq after 00500 batchs: 833.9054565429688
INFO:root:Train (Epoch 133): Loss/seq after 00550 batchs: 806.1803588867188
INFO:root:Train (Epoch 133): Loss/seq after 00600 batchs: 776.8324584960938
INFO:root:Train (Epoch 133): Loss/seq after 00650 batchs: 763.2279052734375
INFO:root:Train (Epoch 133): Loss/seq after 00700 batchs: 739.3572387695312
INFO:root:Train (Epoch 133): Loss/seq after 00750 batchs: 748.1482543945312
INFO:root:Train (Epoch 133): Loss/seq after 00800 batchs: 747.6475219726562
INFO:root:Train (Epoch 133): Loss/seq after 00850 batchs: 723.666259765625
INFO:root:Train (Epoch 133): Loss/seq after 00900 batchs: 708.1237182617188
INFO:root:Train (Epoch 133): Loss/seq after 00950 batchs: 708.53369140625
INFO:root:Train (Epoch 133): Loss/seq after 01000 batchs: 700.325439453125
INFO:root:Train (Epoch 133): Loss/seq after 01050 batchs: 688.384521484375
INFO:root:Train (Epoch 133): Loss/seq after 01100 batchs: 678.3630981445312
INFO:root:Train (Epoch 133): Loss/seq after 01150 batchs: 662.0389404296875
INFO:root:Train (Epoch 133): Loss/seq after 01200 batchs: 665.0986328125
INFO:root:Train (Epoch 133): Loss/seq after 01250 batchs: 662.4729614257812
INFO:root:Train (Epoch 133): Loss/seq after 01300 batchs: 651.287109375
INFO:root:Train (Epoch 133): Loss/seq after 01350 batchs: 641.3651123046875
INFO:root:Train (Epoch 133): Loss/seq after 01400 batchs: 648.720703125
INFO:root:Train (Epoch 133): Loss/seq after 01450 batchs: 649.1309204101562
INFO:root:Train (Epoch 133): Loss/seq after 01500 batchs: 654.3991088867188
INFO:root:Train (Epoch 133): Loss/seq after 01550 batchs: 656.1265869140625
INFO:root:Train (Epoch 133): Loss/seq after 01600 batchs: 650.1105346679688
INFO:root:Train (Epoch 133): Loss/seq after 01650 batchs: 647.3712158203125
INFO:root:Train (Epoch 133): Loss/seq after 01700 batchs: 649.468505859375
INFO:root:Train (Epoch 133): Loss/seq after 01750 batchs: 645.926025390625
INFO:root:Train (Epoch 133): Loss/seq after 01800 batchs: 642.275146484375
INFO:root:Train (Epoch 133): Loss/seq after 01850 batchs: 637.5485229492188
INFO:root:Train (Epoch 133): Loss/seq after 01900 batchs: 637.6924438476562
INFO:root:Train (Epoch 133): Loss/seq after 01950 batchs: 635.408447265625
INFO:root:Train (Epoch 133): Loss/seq after 02000 batchs: 633.1427001953125
INFO:root:Train (Epoch 133): Loss/seq after 02050 batchs: 630.7540893554688
INFO:root:Train (Epoch 133): Loss/seq after 02100 batchs: 627.2774047851562
INFO:root:Train (Epoch 133): Loss/seq after 02150 batchs: 624.6301879882812
INFO:root:Train (Epoch 133): Loss/seq after 02200 batchs: 620.9424438476562
INFO:root:Train (Epoch 133): Loss/seq after 02250 batchs: 619.507568359375
INFO:root:Train (Epoch 133): Loss/seq after 02300 batchs: 617.388427734375
INFO:root:Train (Epoch 133): Loss/seq after 02350 batchs: 612.1928100585938
INFO:root:Train (Epoch 133): Loss/seq after 02400 batchs: 613.2088012695312
INFO:root:Train (Epoch 133): Loss/seq after 02450 batchs: 607.7247924804688
INFO:root:Train (Epoch 133): Loss/seq after 02500 batchs: 598.7564697265625
INFO:root:Train (Epoch 133): Loss/seq after 02550 batchs: 592.0020751953125
INFO:root:Train (Epoch 133): Loss/seq after 02600 batchs: 590.7926635742188
INFO:root:Train (Epoch 133): Loss/seq after 02650 batchs: 588.490966796875
INFO:root:Train (Epoch 133): Loss/seq after 02700 batchs: 586.2550048828125
INFO:root:Train (Epoch 133): Loss/seq after 02750 batchs: 585.9043579101562
INFO:root:Train (Epoch 133): Loss/seq after 02800 batchs: 586.9014892578125
INFO:root:Train (Epoch 133): Loss/seq after 02850 batchs: 587.0906982421875
INFO:root:Train (Epoch 133): Loss/seq after 02900 batchs: 588.3366088867188
INFO:root:Train (Epoch 133): Loss/seq after 02950 batchs: 587.0054931640625
INFO:root:Train (Epoch 133): Loss/seq after 03000 batchs: 591.6263427734375
INFO:root:Train (Epoch 133): Loss/seq after 03050 batchs: 593.6591796875
INFO:root:Train (Epoch 133): Loss/seq after 03100 batchs: 598.1655883789062
INFO:root:Train (Epoch 133): Loss/seq after 03150 batchs: 604.1663208007812
INFO:root:Train (Epoch 133): Loss/seq after 03200 batchs: 607.0291748046875
INFO:root:Train (Epoch 133): Loss/seq after 03250 batchs: 611.1663818359375
INFO:root:Train (Epoch 133): Loss/seq after 03300 batchs: 610.4818115234375
INFO:root:Train (Epoch 133): Loss/seq after 03350 batchs: 611.3680419921875
INFO:root:Train (Epoch 133): Loss/seq after 03400 batchs: 606.6356811523438
INFO:root:Train (Epoch 133): Loss/seq after 03450 batchs: 604.8016357421875
INFO:root:Train (Epoch 133): Loss/seq after 03500 batchs: 605.1405029296875
INFO:root:Train (Epoch 133): Loss/seq after 03550 batchs: 601.9835815429688
INFO:root:Train (Epoch 133): Loss/seq after 03600 batchs: 609.9889526367188
INFO:root:Train (Epoch 133): Loss/seq after 03650 batchs: 606.9806518554688
INFO:root:Train (Epoch 133): Loss/seq after 03700 batchs: 609.0791015625
INFO:root:Train (Epoch 133): Loss/seq after 03750 batchs: 613.5401000976562
INFO:root:Train (Epoch 133): Loss/seq after 03800 batchs: 610.708740234375
INFO:root:Train (Epoch 133): Loss/seq after 03850 batchs: 609.4131469726562
INFO:root:Train (Epoch 133): Loss/seq after 03900 batchs: 613.8042602539062
INFO:root:Train (Epoch 133): Loss/seq after 03950 batchs: 618.1990966796875
INFO:root:Train (Epoch 133): Loss/seq after 04000 batchs: 614.0436401367188
INFO:root:Train (Epoch 133): Loss/seq after 04050 batchs: 610.1107788085938
INFO:root:Train (Epoch 133): Loss/seq after 04100 batchs: 607.9127197265625
INFO:root:Train (Epoch 133): Loss/seq after 04150 batchs: 607.3909912109375
INFO:root:Train (Epoch 133): Loss/seq after 04200 batchs: 605.5745849609375
INFO:root:Train (Epoch 133): Loss/seq after 04250 batchs: 603.5653686523438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 133): Loss/seq after 00000 batches: 551.6338500976562
INFO:root:# Valid (Epoch 133): Loss/seq after 00050 batches: 811.7808837890625
INFO:root:# Valid (Epoch 133): Loss/seq after 00100 batches: 810.7457275390625
INFO:root:# Valid (Epoch 133): Loss/seq after 00150 batches: 606.29833984375
INFO:root:# Valid (Epoch 133): Loss/seq after 00200 batches: 557.3740844726562
INFO:root:Artifacts: Make stick videos for epoch 133
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_133_on_20220414_023526.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_133_index_1545_on_20220414_023526.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 134): Loss/seq after 00000 batchs: 1136.7884521484375
INFO:root:Train (Epoch 134): Loss/seq after 00050 batchs: 832.1221923828125
INFO:root:Train (Epoch 134): Loss/seq after 00100 batchs: 855.8792114257812
INFO:root:Train (Epoch 134): Loss/seq after 00150 batchs: 771.8234252929688
INFO:root:Train (Epoch 134): Loss/seq after 00200 batchs: 840.8953247070312
INFO:root:Train (Epoch 134): Loss/seq after 00250 batchs: 944.3684692382812
INFO:root:Train (Epoch 134): Loss/seq after 00300 batchs: 936.1452026367188
INFO:root:Train (Epoch 134): Loss/seq after 00350 batchs: 873.1425170898438
INFO:root:Train (Epoch 134): Loss/seq after 00400 batchs: 879.6866455078125
INFO:root:Train (Epoch 134): Loss/seq after 00450 batchs: 857.337646484375
INFO:root:Train (Epoch 134): Loss/seq after 00500 batchs: 830.4365234375
INFO:root:Train (Epoch 134): Loss/seq after 00550 batchs: 803.3504028320312
INFO:root:Train (Epoch 134): Loss/seq after 00600 batchs: 774.7337036132812
INFO:root:Train (Epoch 134): Loss/seq after 00650 batchs: 758.8634033203125
INFO:root:Train (Epoch 134): Loss/seq after 00700 batchs: 735.4971923828125
INFO:root:Train (Epoch 134): Loss/seq after 00750 batchs: 745.2432250976562
INFO:root:Train (Epoch 134): Loss/seq after 00800 batchs: 744.5753784179688
INFO:root:Train (Epoch 134): Loss/seq after 00850 batchs: 721.120849609375
INFO:root:Train (Epoch 134): Loss/seq after 00900 batchs: 705.6637573242188
INFO:root:Train (Epoch 134): Loss/seq after 00950 batchs: 705.2223510742188
INFO:root:Train (Epoch 134): Loss/seq after 01000 batchs: 697.4370727539062
INFO:root:Train (Epoch 134): Loss/seq after 01050 batchs: 685.5131225585938
INFO:root:Train (Epoch 134): Loss/seq after 01100 batchs: 674.9597778320312
INFO:root:Train (Epoch 134): Loss/seq after 01150 batchs: 658.787353515625
INFO:root:Train (Epoch 134): Loss/seq after 01200 batchs: 661.7562255859375
INFO:root:Train (Epoch 134): Loss/seq after 01250 batchs: 658.9411010742188
INFO:root:Train (Epoch 134): Loss/seq after 01300 batchs: 647.6511840820312
INFO:root:Train (Epoch 134): Loss/seq after 01350 batchs: 638.189697265625
INFO:root:Train (Epoch 134): Loss/seq after 01400 batchs: 645.1665649414062
INFO:root:Train (Epoch 134): Loss/seq after 01450 batchs: 645.677490234375
INFO:root:Train (Epoch 134): Loss/seq after 01500 batchs: 651.0941772460938
INFO:root:Train (Epoch 134): Loss/seq after 01550 batchs: 652.5109252929688
INFO:root:Train (Epoch 134): Loss/seq after 01600 batchs: 646.1563720703125
INFO:root:Train (Epoch 134): Loss/seq after 01650 batchs: 643.2954711914062
INFO:root:Train (Epoch 134): Loss/seq after 01700 batchs: 644.9225463867188
INFO:root:Train (Epoch 134): Loss/seq after 01750 batchs: 641.4913940429688
INFO:root:Train (Epoch 134): Loss/seq after 01800 batchs: 637.7424926757812
INFO:root:Train (Epoch 134): Loss/seq after 01850 batchs: 633.0537719726562
INFO:root:Train (Epoch 134): Loss/seq after 01900 batchs: 633.2083129882812
INFO:root:Train (Epoch 134): Loss/seq after 01950 batchs: 630.9902954101562
INFO:root:Train (Epoch 134): Loss/seq after 02000 batchs: 628.6829223632812
INFO:root:Train (Epoch 134): Loss/seq after 02050 batchs: 626.4741821289062
INFO:root:Train (Epoch 134): Loss/seq after 02100 batchs: 622.8736572265625
INFO:root:Train (Epoch 134): Loss/seq after 02150 batchs: 620.4190673828125
INFO:root:Train (Epoch 134): Loss/seq after 02200 batchs: 616.9501953125
INFO:root:Train (Epoch 134): Loss/seq after 02250 batchs: 615.483154296875
INFO:root:Train (Epoch 134): Loss/seq after 02300 batchs: 613.5595092773438
INFO:root:Train (Epoch 134): Loss/seq after 02350 batchs: 608.5457153320312
INFO:root:Train (Epoch 134): Loss/seq after 02400 batchs: 609.6624755859375
INFO:root:Train (Epoch 134): Loss/seq after 02450 batchs: 604.2741088867188
INFO:root:Train (Epoch 134): Loss/seq after 02500 batchs: 595.3741455078125
INFO:root:Train (Epoch 134): Loss/seq after 02550 batchs: 588.71630859375
INFO:root:Train (Epoch 134): Loss/seq after 02600 batchs: 587.4318237304688
INFO:root:Train (Epoch 134): Loss/seq after 02650 batchs: 585.0953979492188
INFO:root:Train (Epoch 134): Loss/seq after 02700 batchs: 582.8591918945312
INFO:root:Train (Epoch 134): Loss/seq after 02750 batchs: 582.0142822265625
INFO:root:Train (Epoch 134): Loss/seq after 02800 batchs: 582.5962524414062
INFO:root:Train (Epoch 134): Loss/seq after 02850 batchs: 582.636962890625
INFO:root:Train (Epoch 134): Loss/seq after 02900 batchs: 583.8881225585938
INFO:root:Train (Epoch 134): Loss/seq after 02950 batchs: 582.4341430664062
INFO:root:Train (Epoch 134): Loss/seq after 03000 batchs: 587.1278076171875
INFO:root:Train (Epoch 134): Loss/seq after 03050 batchs: 588.7318115234375
INFO:root:Train (Epoch 134): Loss/seq after 03100 batchs: 592.9199829101562
INFO:root:Train (Epoch 134): Loss/seq after 03150 batchs: 598.5899658203125
INFO:root:Train (Epoch 134): Loss/seq after 03200 batchs: 601.4957885742188
INFO:root:Train (Epoch 134): Loss/seq after 03250 batchs: 605.2373046875
INFO:root:Train (Epoch 134): Loss/seq after 03300 batchs: 604.0885009765625
INFO:root:Train (Epoch 134): Loss/seq after 03350 batchs: 604.5050048828125
INFO:root:Train (Epoch 134): Loss/seq after 03400 batchs: 599.86572265625
INFO:root:Train (Epoch 134): Loss/seq after 03450 batchs: 597.9236450195312
INFO:root:Train (Epoch 134): Loss/seq after 03500 batchs: 598.0866088867188
INFO:root:Train (Epoch 134): Loss/seq after 03550 batchs: 594.993408203125
INFO:root:Train (Epoch 134): Loss/seq after 03600 batchs: 602.7450561523438
INFO:root:Train (Epoch 134): Loss/seq after 03650 batchs: 599.7769775390625
INFO:root:Train (Epoch 134): Loss/seq after 03700 batchs: 602.0554809570312
INFO:root:Train (Epoch 134): Loss/seq after 03750 batchs: 606.6878662109375
INFO:root:Train (Epoch 134): Loss/seq after 03800 batchs: 603.8984375
INFO:root:Train (Epoch 134): Loss/seq after 03850 batchs: 602.5252075195312
INFO:root:Train (Epoch 134): Loss/seq after 03900 batchs: 606.8372802734375
INFO:root:Train (Epoch 134): Loss/seq after 03950 batchs: 611.0468139648438
INFO:root:Train (Epoch 134): Loss/seq after 04000 batchs: 606.9078979492188
INFO:root:Train (Epoch 134): Loss/seq after 04050 batchs: 603.054931640625
INFO:root:Train (Epoch 134): Loss/seq after 04100 batchs: 600.87451171875
INFO:root:Train (Epoch 134): Loss/seq after 04150 batchs: 600.5155639648438
INFO:root:Train (Epoch 134): Loss/seq after 04200 batchs: 598.64990234375
INFO:root:Train (Epoch 134): Loss/seq after 04250 batchs: 596.6912841796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 134): Loss/seq after 00000 batches: 499.29632568359375
INFO:root:# Valid (Epoch 134): Loss/seq after 00050 batches: 849.9039306640625
INFO:root:# Valid (Epoch 134): Loss/seq after 00100 batches: 820.1316528320312
INFO:root:# Valid (Epoch 134): Loss/seq after 00150 batches: 610.8895263671875
INFO:root:# Valid (Epoch 134): Loss/seq after 00200 batches: 561.0048828125
INFO:root:Artifacts: Make stick videos for epoch 134
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_134_on_20220414_024044.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_134_index_1756_on_20220414_024044.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 135): Loss/seq after 00000 batchs: 1065.8031005859375
INFO:root:Train (Epoch 135): Loss/seq after 00050 batchs: 830.026123046875
INFO:root:Train (Epoch 135): Loss/seq after 00100 batchs: 843.81982421875
INFO:root:Train (Epoch 135): Loss/seq after 00150 batchs: 763.5952758789062
INFO:root:Train (Epoch 135): Loss/seq after 00200 batchs: 830.935791015625
INFO:root:Train (Epoch 135): Loss/seq after 00250 batchs: 932.1181030273438
INFO:root:Train (Epoch 135): Loss/seq after 00300 batchs: 924.6343994140625
INFO:root:Train (Epoch 135): Loss/seq after 00350 batchs: 863.6939086914062
INFO:root:Train (Epoch 135): Loss/seq after 00400 batchs: 869.0593872070312
INFO:root:Train (Epoch 135): Loss/seq after 00450 batchs: 847.7503662109375
INFO:root:Train (Epoch 135): Loss/seq after 00500 batchs: 823.177001953125
INFO:root:Train (Epoch 135): Loss/seq after 00550 batchs: 797.1416625976562
INFO:root:Train (Epoch 135): Loss/seq after 00600 batchs: 768.2623291015625
INFO:root:Train (Epoch 135): Loss/seq after 00650 batchs: 753.860595703125
INFO:root:Train (Epoch 135): Loss/seq after 00700 batchs: 730.5009765625
INFO:root:Train (Epoch 135): Loss/seq after 00750 batchs: 741.560302734375
INFO:root:Train (Epoch 135): Loss/seq after 00800 batchs: 740.9747924804688
INFO:root:Train (Epoch 135): Loss/seq after 00850 batchs: 717.3389892578125
INFO:root:Train (Epoch 135): Loss/seq after 00900 batchs: 701.7456665039062
INFO:root:Train (Epoch 135): Loss/seq after 00950 batchs: 700.7972412109375
INFO:root:Train (Epoch 135): Loss/seq after 01000 batchs: 692.748779296875
INFO:root:Train (Epoch 135): Loss/seq after 01050 batchs: 680.9708862304688
INFO:root:Train (Epoch 135): Loss/seq after 01100 batchs: 671.0967407226562
INFO:root:Train (Epoch 135): Loss/seq after 01150 batchs: 655.0703125
INFO:root:Train (Epoch 135): Loss/seq after 01200 batchs: 658.6914672851562
INFO:root:Train (Epoch 135): Loss/seq after 01250 batchs: 656.1876220703125
INFO:root:Train (Epoch 135): Loss/seq after 01300 batchs: 645.2366333007812
INFO:root:Train (Epoch 135): Loss/seq after 01350 batchs: 635.8998413085938
INFO:root:Train (Epoch 135): Loss/seq after 01400 batchs: 643.2280883789062
INFO:root:Train (Epoch 135): Loss/seq after 01450 batchs: 643.8756713867188
INFO:root:Train (Epoch 135): Loss/seq after 01500 batchs: 649.2351684570312
INFO:root:Train (Epoch 135): Loss/seq after 01550 batchs: 650.9159545898438
INFO:root:Train (Epoch 135): Loss/seq after 01600 batchs: 644.5103149414062
INFO:root:Train (Epoch 135): Loss/seq after 01650 batchs: 641.6036987304688
INFO:root:Train (Epoch 135): Loss/seq after 01700 batchs: 642.83935546875
INFO:root:Train (Epoch 135): Loss/seq after 01750 batchs: 639.5117797851562
INFO:root:Train (Epoch 135): Loss/seq after 01800 batchs: 635.9182739257812
INFO:root:Train (Epoch 135): Loss/seq after 01850 batchs: 631.0396728515625
INFO:root:Train (Epoch 135): Loss/seq after 01900 batchs: 631.3004760742188
INFO:root:Train (Epoch 135): Loss/seq after 01950 batchs: 629.273681640625
INFO:root:Train (Epoch 135): Loss/seq after 02000 batchs: 627.1664428710938
INFO:root:Train (Epoch 135): Loss/seq after 02050 batchs: 624.8438110351562
INFO:root:Train (Epoch 135): Loss/seq after 02100 batchs: 621.3720092773438
INFO:root:Train (Epoch 135): Loss/seq after 02150 batchs: 618.8551635742188
INFO:root:Train (Epoch 135): Loss/seq after 02200 batchs: 615.4445190429688
INFO:root:Train (Epoch 135): Loss/seq after 02250 batchs: 614.0111694335938
INFO:root:Train (Epoch 135): Loss/seq after 02300 batchs: 612.0945434570312
INFO:root:Train (Epoch 135): Loss/seq after 02350 batchs: 607.3846435546875
INFO:root:Train (Epoch 135): Loss/seq after 02400 batchs: 608.482177734375
INFO:root:Train (Epoch 135): Loss/seq after 02450 batchs: 603.02099609375
INFO:root:Train (Epoch 135): Loss/seq after 02500 batchs: 594.1471557617188
INFO:root:Train (Epoch 135): Loss/seq after 02550 batchs: 587.4933471679688
INFO:root:Train (Epoch 135): Loss/seq after 02600 batchs: 586.4535522460938
INFO:root:Train (Epoch 135): Loss/seq after 02650 batchs: 584.09521484375
INFO:root:Train (Epoch 135): Loss/seq after 02700 batchs: 581.8432006835938
INFO:root:Train (Epoch 135): Loss/seq after 02750 batchs: 580.8162231445312
INFO:root:Train (Epoch 135): Loss/seq after 02800 batchs: 581.2905883789062
INFO:root:Train (Epoch 135): Loss/seq after 02850 batchs: 581.1636352539062
INFO:root:Train (Epoch 135): Loss/seq after 02900 batchs: 582.2883911132812
INFO:root:Train (Epoch 135): Loss/seq after 02950 batchs: 581.03662109375
INFO:root:Train (Epoch 135): Loss/seq after 03000 batchs: 585.71142578125
INFO:root:Train (Epoch 135): Loss/seq after 03050 batchs: 587.5828247070312
INFO:root:Train (Epoch 135): Loss/seq after 03100 batchs: 591.547119140625
INFO:root:Train (Epoch 135): Loss/seq after 03150 batchs: 597.0988159179688
INFO:root:Train (Epoch 135): Loss/seq after 03200 batchs: 600.18603515625
INFO:root:Train (Epoch 135): Loss/seq after 03250 batchs: 604.2739868164062
INFO:root:Train (Epoch 135): Loss/seq after 03300 batchs: 603.5006713867188
INFO:root:Train (Epoch 135): Loss/seq after 03350 batchs: 603.482177734375
INFO:root:Train (Epoch 135): Loss/seq after 03400 batchs: 599.0824584960938
INFO:root:Train (Epoch 135): Loss/seq after 03450 batchs: 597.299072265625
INFO:root:Train (Epoch 135): Loss/seq after 03500 batchs: 597.3507080078125
INFO:root:Train (Epoch 135): Loss/seq after 03550 batchs: 594.1572265625
INFO:root:Train (Epoch 135): Loss/seq after 03600 batchs: 602.1270141601562
INFO:root:Train (Epoch 135): Loss/seq after 03650 batchs: 599.2408447265625
INFO:root:Train (Epoch 135): Loss/seq after 03700 batchs: 601.5518798828125
INFO:root:Train (Epoch 135): Loss/seq after 03750 batchs: 606.1174926757812
INFO:root:Train (Epoch 135): Loss/seq after 03800 batchs: 603.3892211914062
INFO:root:Train (Epoch 135): Loss/seq after 03850 batchs: 601.8806762695312
INFO:root:Train (Epoch 135): Loss/seq after 03900 batchs: 606.0016479492188
INFO:root:Train (Epoch 135): Loss/seq after 03950 batchs: 610.0560913085938
INFO:root:Train (Epoch 135): Loss/seq after 04000 batchs: 605.8947143554688
INFO:root:Train (Epoch 135): Loss/seq after 04050 batchs: 602.04736328125
INFO:root:Train (Epoch 135): Loss/seq after 04100 batchs: 599.893310546875
INFO:root:Train (Epoch 135): Loss/seq after 04150 batchs: 599.5164794921875
INFO:root:Train (Epoch 135): Loss/seq after 04200 batchs: 597.6306762695312
INFO:root:Train (Epoch 135): Loss/seq after 04250 batchs: 595.72265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 135): Loss/seq after 00000 batches: 516.8951416015625
INFO:root:# Valid (Epoch 135): Loss/seq after 00050 batches: 824.6084594726562
INFO:root:# Valid (Epoch 135): Loss/seq after 00100 batches: 806.710205078125
INFO:root:# Valid (Epoch 135): Loss/seq after 00150 batches: 604.2763061523438
INFO:root:# Valid (Epoch 135): Loss/seq after 00200 batches: 556.9148559570312
INFO:root:Artifacts: Make stick videos for epoch 135
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_135_on_20220414_024603.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_135_index_1505_on_20220414_024603.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 136): Loss/seq after 00000 batchs: 1056.8951416015625
INFO:root:Train (Epoch 136): Loss/seq after 00050 batchs: 822.03271484375
INFO:root:Train (Epoch 136): Loss/seq after 00100 batchs: 835.786865234375
INFO:root:Train (Epoch 136): Loss/seq after 00150 batchs: 755.9434204101562
INFO:root:Train (Epoch 136): Loss/seq after 00200 batchs: 827.2788696289062
INFO:root:Train (Epoch 136): Loss/seq after 00250 batchs: 930.2564697265625
INFO:root:Train (Epoch 136): Loss/seq after 00300 batchs: 924.1708374023438
INFO:root:Train (Epoch 136): Loss/seq after 00350 batchs: 863.8594360351562
INFO:root:Train (Epoch 136): Loss/seq after 00400 batchs: 870.8977661132812
INFO:root:Train (Epoch 136): Loss/seq after 00450 batchs: 849.3374633789062
INFO:root:Train (Epoch 136): Loss/seq after 00500 batchs: 823.5790405273438
INFO:root:Train (Epoch 136): Loss/seq after 00550 batchs: 796.3657836914062
INFO:root:Train (Epoch 136): Loss/seq after 00600 batchs: 767.6681518554688
INFO:root:Train (Epoch 136): Loss/seq after 00650 batchs: 751.2913818359375
INFO:root:Train (Epoch 136): Loss/seq after 00700 batchs: 729.1635131835938
INFO:root:Train (Epoch 136): Loss/seq after 00750 batchs: 737.8217163085938
INFO:root:Train (Epoch 136): Loss/seq after 00800 batchs: 739.0621948242188
INFO:root:Train (Epoch 136): Loss/seq after 00850 batchs: 715.572265625
INFO:root:Train (Epoch 136): Loss/seq after 00900 batchs: 699.6190795898438
INFO:root:Train (Epoch 136): Loss/seq after 00950 batchs: 699.6951904296875
INFO:root:Train (Epoch 136): Loss/seq after 01000 batchs: 691.1102294921875
INFO:root:Train (Epoch 136): Loss/seq after 01050 batchs: 679.6240234375
INFO:root:Train (Epoch 136): Loss/seq after 01100 batchs: 669.544677734375
INFO:root:Train (Epoch 136): Loss/seq after 01150 batchs: 653.5782470703125
INFO:root:Train (Epoch 136): Loss/seq after 01200 batchs: 656.8342895507812
INFO:root:Train (Epoch 136): Loss/seq after 01250 batchs: 654.1573486328125
INFO:root:Train (Epoch 136): Loss/seq after 01300 batchs: 642.8402709960938
INFO:root:Train (Epoch 136): Loss/seq after 01350 batchs: 633.2109985351562
INFO:root:Train (Epoch 136): Loss/seq after 01400 batchs: 639.7998657226562
INFO:root:Train (Epoch 136): Loss/seq after 01450 batchs: 640.6776733398438
INFO:root:Train (Epoch 136): Loss/seq after 01500 batchs: 646.1544799804688
INFO:root:Train (Epoch 136): Loss/seq after 01550 batchs: 647.59423828125
INFO:root:Train (Epoch 136): Loss/seq after 01600 batchs: 641.794189453125
INFO:root:Train (Epoch 136): Loss/seq after 01650 batchs: 639.2437744140625
INFO:root:Train (Epoch 136): Loss/seq after 01700 batchs: 641.1301879882812
INFO:root:Train (Epoch 136): Loss/seq after 01750 batchs: 637.8046875
INFO:root:Train (Epoch 136): Loss/seq after 01800 batchs: 634.08447265625
INFO:root:Train (Epoch 136): Loss/seq after 01850 batchs: 629.4351196289062
INFO:root:Train (Epoch 136): Loss/seq after 01900 batchs: 629.6925048828125
INFO:root:Train (Epoch 136): Loss/seq after 01950 batchs: 627.5572509765625
INFO:root:Train (Epoch 136): Loss/seq after 02000 batchs: 625.5123291015625
INFO:root:Train (Epoch 136): Loss/seq after 02050 batchs: 623.2040405273438
INFO:root:Train (Epoch 136): Loss/seq after 02100 batchs: 619.7168579101562
INFO:root:Train (Epoch 136): Loss/seq after 02150 batchs: 617.1309814453125
INFO:root:Train (Epoch 136): Loss/seq after 02200 batchs: 613.5504150390625
INFO:root:Train (Epoch 136): Loss/seq after 02250 batchs: 612.1942138671875
INFO:root:Train (Epoch 136): Loss/seq after 02300 batchs: 609.8973999023438
INFO:root:Train (Epoch 136): Loss/seq after 02350 batchs: 604.7775268554688
INFO:root:Train (Epoch 136): Loss/seq after 02400 batchs: 605.805419921875
INFO:root:Train (Epoch 136): Loss/seq after 02450 batchs: 600.413818359375
INFO:root:Train (Epoch 136): Loss/seq after 02500 batchs: 591.5565795898438
INFO:root:Train (Epoch 136): Loss/seq after 02550 batchs: 584.9791259765625
INFO:root:Train (Epoch 136): Loss/seq after 02600 batchs: 583.821044921875
INFO:root:Train (Epoch 136): Loss/seq after 02650 batchs: 581.5971069335938
INFO:root:Train (Epoch 136): Loss/seq after 02700 batchs: 579.52783203125
INFO:root:Train (Epoch 136): Loss/seq after 02750 batchs: 578.4537353515625
INFO:root:Train (Epoch 136): Loss/seq after 02800 batchs: 579.1663818359375
INFO:root:Train (Epoch 136): Loss/seq after 02850 batchs: 579.1768798828125
INFO:root:Train (Epoch 136): Loss/seq after 02900 batchs: 580.3584594726562
INFO:root:Train (Epoch 136): Loss/seq after 02950 batchs: 579.0745239257812
INFO:root:Train (Epoch 136): Loss/seq after 03000 batchs: 583.7803955078125
INFO:root:Train (Epoch 136): Loss/seq after 03050 batchs: 585.6104125976562
INFO:root:Train (Epoch 136): Loss/seq after 03100 batchs: 589.2855224609375
INFO:root:Train (Epoch 136): Loss/seq after 03150 batchs: 594.5545043945312
INFO:root:Train (Epoch 136): Loss/seq after 03200 batchs: 597.0294189453125
INFO:root:Train (Epoch 136): Loss/seq after 03250 batchs: 600.7513427734375
INFO:root:Train (Epoch 136): Loss/seq after 03300 batchs: 599.8281860351562
INFO:root:Train (Epoch 136): Loss/seq after 03350 batchs: 600.060546875
INFO:root:Train (Epoch 136): Loss/seq after 03400 batchs: 595.53466796875
INFO:root:Train (Epoch 136): Loss/seq after 03450 batchs: 593.71875
INFO:root:Train (Epoch 136): Loss/seq after 03500 batchs: 594.0131225585938
INFO:root:Train (Epoch 136): Loss/seq after 03550 batchs: 591.0598754882812
INFO:root:Train (Epoch 136): Loss/seq after 03600 batchs: 599.1957397460938
INFO:root:Train (Epoch 136): Loss/seq after 03650 batchs: 596.3499755859375
INFO:root:Train (Epoch 136): Loss/seq after 03700 batchs: 598.7400512695312
INFO:root:Train (Epoch 136): Loss/seq after 03750 batchs: 603.4624633789062
INFO:root:Train (Epoch 136): Loss/seq after 03800 batchs: 600.702392578125
INFO:root:Train (Epoch 136): Loss/seq after 03850 batchs: 599.43798828125
INFO:root:Train (Epoch 136): Loss/seq after 03900 batchs: 603.539794921875
INFO:root:Train (Epoch 136): Loss/seq after 03950 batchs: 607.716552734375
INFO:root:Train (Epoch 136): Loss/seq after 04000 batchs: 603.6163940429688
INFO:root:Train (Epoch 136): Loss/seq after 04050 batchs: 599.7655639648438
INFO:root:Train (Epoch 136): Loss/seq after 04100 batchs: 597.6665649414062
INFO:root:Train (Epoch 136): Loss/seq after 04150 batchs: 597.28466796875
INFO:root:Train (Epoch 136): Loss/seq after 04200 batchs: 595.4314575195312
INFO:root:Train (Epoch 136): Loss/seq after 04250 batchs: 593.4961547851562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 136): Loss/seq after 00000 batches: 498.1990661621094
INFO:root:# Valid (Epoch 136): Loss/seq after 00050 batches: 789.1087646484375
INFO:root:# Valid (Epoch 136): Loss/seq after 00100 batches: 796.335693359375
INFO:root:# Valid (Epoch 136): Loss/seq after 00150 batches: 594.1691284179688
INFO:root:# Valid (Epoch 136): Loss/seq after 00200 batches: 547.2051391601562
INFO:root:Artifacts: Make stick videos for epoch 136
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_136_on_20220414_025121.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_136_index_38_on_20220414_025121.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 137): Loss/seq after 00000 batchs: 1124.960693359375
INFO:root:Train (Epoch 137): Loss/seq after 00050 batchs: 818.0997314453125
INFO:root:Train (Epoch 137): Loss/seq after 00100 batchs: 828.0084228515625
INFO:root:Train (Epoch 137): Loss/seq after 00150 batchs: 750.4324951171875
INFO:root:Train (Epoch 137): Loss/seq after 00200 batchs: 816.3653564453125
INFO:root:Train (Epoch 137): Loss/seq after 00250 batchs: 921.1775512695312
INFO:root:Train (Epoch 137): Loss/seq after 00300 batchs: 915.4203491210938
INFO:root:Train (Epoch 137): Loss/seq after 00350 batchs: 855.7731323242188
INFO:root:Train (Epoch 137): Loss/seq after 00400 batchs: 860.2431030273438
INFO:root:Train (Epoch 137): Loss/seq after 00450 batchs: 839.5545043945312
INFO:root:Train (Epoch 137): Loss/seq after 00500 batchs: 814.9093627929688
INFO:root:Train (Epoch 137): Loss/seq after 00550 batchs: 788.6815185546875
INFO:root:Train (Epoch 137): Loss/seq after 00600 batchs: 760.5446166992188
INFO:root:Train (Epoch 137): Loss/seq after 00650 batchs: 744.9299926757812
INFO:root:Train (Epoch 137): Loss/seq after 00700 batchs: 721.7403564453125
INFO:root:Train (Epoch 137): Loss/seq after 00750 batchs: 731.2984619140625
INFO:root:Train (Epoch 137): Loss/seq after 00800 batchs: 731.7220458984375
INFO:root:Train (Epoch 137): Loss/seq after 00850 batchs: 708.582763671875
INFO:root:Train (Epoch 137): Loss/seq after 00900 batchs: 692.7354736328125
INFO:root:Train (Epoch 137): Loss/seq after 00950 batchs: 691.3980712890625
INFO:root:Train (Epoch 137): Loss/seq after 01000 batchs: 683.1132202148438
INFO:root:Train (Epoch 137): Loss/seq after 01050 batchs: 671.3944702148438
INFO:root:Train (Epoch 137): Loss/seq after 01100 batchs: 661.6342163085938
INFO:root:Train (Epoch 137): Loss/seq after 01150 batchs: 646.0518188476562
INFO:root:Train (Epoch 137): Loss/seq after 01200 batchs: 649.6881713867188
INFO:root:Train (Epoch 137): Loss/seq after 01250 batchs: 647.4024047851562
INFO:root:Train (Epoch 137): Loss/seq after 01300 batchs: 635.942138671875
INFO:root:Train (Epoch 137): Loss/seq after 01350 batchs: 626.2849731445312
INFO:root:Train (Epoch 137): Loss/seq after 01400 batchs: 632.6290283203125
INFO:root:Train (Epoch 137): Loss/seq after 01450 batchs: 633.3621215820312
INFO:root:Train (Epoch 137): Loss/seq after 01500 batchs: 638.962890625
INFO:root:Train (Epoch 137): Loss/seq after 01550 batchs: 640.55029296875
INFO:root:Train (Epoch 137): Loss/seq after 01600 batchs: 634.6679077148438
INFO:root:Train (Epoch 137): Loss/seq after 01650 batchs: 631.9561157226562
INFO:root:Train (Epoch 137): Loss/seq after 01700 batchs: 633.6666259765625
INFO:root:Train (Epoch 137): Loss/seq after 01750 batchs: 630.3866577148438
INFO:root:Train (Epoch 137): Loss/seq after 01800 batchs: 626.7784423828125
INFO:root:Train (Epoch 137): Loss/seq after 01850 batchs: 622.1763305664062
INFO:root:Train (Epoch 137): Loss/seq after 01900 batchs: 622.5509033203125
INFO:root:Train (Epoch 137): Loss/seq after 01950 batchs: 620.4131469726562
INFO:root:Train (Epoch 137): Loss/seq after 02000 batchs: 618.2861328125
INFO:root:Train (Epoch 137): Loss/seq after 02050 batchs: 616.10888671875
INFO:root:Train (Epoch 137): Loss/seq after 02100 batchs: 612.7259521484375
INFO:root:Train (Epoch 137): Loss/seq after 02150 batchs: 610.3848876953125
INFO:root:Train (Epoch 137): Loss/seq after 02200 batchs: 606.9642944335938
INFO:root:Train (Epoch 137): Loss/seq after 02250 batchs: 605.4174194335938
INFO:root:Train (Epoch 137): Loss/seq after 02300 batchs: 603.2042236328125
INFO:root:Train (Epoch 137): Loss/seq after 02350 batchs: 598.2579345703125
INFO:root:Train (Epoch 137): Loss/seq after 02400 batchs: 599.4849243164062
INFO:root:Train (Epoch 137): Loss/seq after 02450 batchs: 594.2423706054688
INFO:root:Train (Epoch 137): Loss/seq after 02500 batchs: 585.4990234375
INFO:root:Train (Epoch 137): Loss/seq after 02550 batchs: 578.9674072265625
INFO:root:Train (Epoch 137): Loss/seq after 02600 batchs: 577.879638671875
INFO:root:Train (Epoch 137): Loss/seq after 02650 batchs: 575.6204223632812
INFO:root:Train (Epoch 137): Loss/seq after 02700 batchs: 573.4658203125
INFO:root:Train (Epoch 137): Loss/seq after 02750 batchs: 572.2520751953125
INFO:root:Train (Epoch 137): Loss/seq after 02800 batchs: 572.8258056640625
INFO:root:Train (Epoch 137): Loss/seq after 02850 batchs: 572.7407836914062
INFO:root:Train (Epoch 137): Loss/seq after 02900 batchs: 573.956787109375
INFO:root:Train (Epoch 137): Loss/seq after 02950 batchs: 572.65380859375
INFO:root:Train (Epoch 137): Loss/seq after 03000 batchs: 577.5407104492188
INFO:root:Train (Epoch 137): Loss/seq after 03050 batchs: 579.7758178710938
INFO:root:Train (Epoch 137): Loss/seq after 03100 batchs: 583.9418334960938
INFO:root:Train (Epoch 137): Loss/seq after 03150 batchs: 589.6319580078125
INFO:root:Train (Epoch 137): Loss/seq after 03200 batchs: 592.0551147460938
INFO:root:Train (Epoch 137): Loss/seq after 03250 batchs: 595.3825073242188
INFO:root:Train (Epoch 137): Loss/seq after 03300 batchs: 594.6763305664062
INFO:root:Train (Epoch 137): Loss/seq after 03350 batchs: 595.0526733398438
INFO:root:Train (Epoch 137): Loss/seq after 03400 batchs: 590.5850219726562
INFO:root:Train (Epoch 137): Loss/seq after 03450 batchs: 588.9327392578125
INFO:root:Train (Epoch 137): Loss/seq after 03500 batchs: 589.2593383789062
INFO:root:Train (Epoch 137): Loss/seq after 03550 batchs: 586.2761840820312
INFO:root:Train (Epoch 137): Loss/seq after 03600 batchs: 594.3325805664062
INFO:root:Train (Epoch 137): Loss/seq after 03650 batchs: 591.469970703125
INFO:root:Train (Epoch 137): Loss/seq after 03700 batchs: 593.8268432617188
INFO:root:Train (Epoch 137): Loss/seq after 03750 batchs: 598.5724487304688
INFO:root:Train (Epoch 137): Loss/seq after 03800 batchs: 595.9292602539062
INFO:root:Train (Epoch 137): Loss/seq after 03850 batchs: 594.8767700195312
INFO:root:Train (Epoch 137): Loss/seq after 03900 batchs: 599.0582885742188
INFO:root:Train (Epoch 137): Loss/seq after 03950 batchs: 603.4351806640625
INFO:root:Train (Epoch 137): Loss/seq after 04000 batchs: 599.3863525390625
INFO:root:Train (Epoch 137): Loss/seq after 04050 batchs: 595.5645141601562
INFO:root:Train (Epoch 137): Loss/seq after 04100 batchs: 593.4420776367188
INFO:root:Train (Epoch 137): Loss/seq after 04150 batchs: 593.0161743164062
INFO:root:Train (Epoch 137): Loss/seq after 04200 batchs: 591.2308959960938
INFO:root:Train (Epoch 137): Loss/seq after 04250 batchs: 589.2666015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 137): Loss/seq after 00000 batches: 505.0163269042969
INFO:root:# Valid (Epoch 137): Loss/seq after 00050 batches: 794.7328491210938
INFO:root:# Valid (Epoch 137): Loss/seq after 00100 batches: 785.5738525390625
INFO:root:# Valid (Epoch 137): Loss/seq after 00150 batches: 587.6114501953125
INFO:root:# Valid (Epoch 137): Loss/seq after 00200 batches: 540.8572387695312
INFO:root:Artifacts: Make stick videos for epoch 137
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_137_on_20220414_025639.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_137_index_517_on_20220414_025639.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 138): Loss/seq after 00000 batchs: 1121.6851806640625
INFO:root:Train (Epoch 138): Loss/seq after 00050 batchs: 831.7155151367188
INFO:root:Train (Epoch 138): Loss/seq after 00100 batchs: 835.74853515625
INFO:root:Train (Epoch 138): Loss/seq after 00150 batchs: 756.6659545898438
INFO:root:Train (Epoch 138): Loss/seq after 00200 batchs: 828.6267700195312
INFO:root:Train (Epoch 138): Loss/seq after 00250 batchs: 928.4332275390625
INFO:root:Train (Epoch 138): Loss/seq after 00300 batchs: 920.7807006835938
INFO:root:Train (Epoch 138): Loss/seq after 00350 batchs: 859.7275390625
INFO:root:Train (Epoch 138): Loss/seq after 00400 batchs: 862.4949340820312
INFO:root:Train (Epoch 138): Loss/seq after 00450 batchs: 841.3530883789062
INFO:root:Train (Epoch 138): Loss/seq after 00500 batchs: 813.50439453125
INFO:root:Train (Epoch 138): Loss/seq after 00550 batchs: 787.727783203125
INFO:root:Train (Epoch 138): Loss/seq after 00600 batchs: 760.2034912109375
INFO:root:Train (Epoch 138): Loss/seq after 00650 batchs: 743.2833862304688
INFO:root:Train (Epoch 138): Loss/seq after 00700 batchs: 719.4229736328125
INFO:root:Train (Epoch 138): Loss/seq after 00750 batchs: 727.2883911132812
INFO:root:Train (Epoch 138): Loss/seq after 00800 batchs: 727.726806640625
INFO:root:Train (Epoch 138): Loss/seq after 00850 batchs: 705.0315551757812
INFO:root:Train (Epoch 138): Loss/seq after 00900 batchs: 689.65234375
INFO:root:Train (Epoch 138): Loss/seq after 00950 batchs: 688.7096557617188
INFO:root:Train (Epoch 138): Loss/seq after 01000 batchs: 679.8875122070312
INFO:root:Train (Epoch 138): Loss/seq after 01050 batchs: 668.2489013671875
INFO:root:Train (Epoch 138): Loss/seq after 01100 batchs: 658.3204345703125
INFO:root:Train (Epoch 138): Loss/seq after 01150 batchs: 642.6800537109375
INFO:root:Train (Epoch 138): Loss/seq after 01200 batchs: 646.2349853515625
INFO:root:Train (Epoch 138): Loss/seq after 01250 batchs: 643.6694946289062
INFO:root:Train (Epoch 138): Loss/seq after 01300 batchs: 631.9603881835938
INFO:root:Train (Epoch 138): Loss/seq after 01350 batchs: 622.5481567382812
INFO:root:Train (Epoch 138): Loss/seq after 01400 batchs: 628.728271484375
INFO:root:Train (Epoch 138): Loss/seq after 01450 batchs: 629.5603637695312
INFO:root:Train (Epoch 138): Loss/seq after 01500 batchs: 635.33056640625
INFO:root:Train (Epoch 138): Loss/seq after 01550 batchs: 637.3489379882812
INFO:root:Train (Epoch 138): Loss/seq after 01600 batchs: 631.4506225585938
INFO:root:Train (Epoch 138): Loss/seq after 01650 batchs: 628.6088256835938
INFO:root:Train (Epoch 138): Loss/seq after 01700 batchs: 630.3104858398438
INFO:root:Train (Epoch 138): Loss/seq after 01750 batchs: 627.2479858398438
INFO:root:Train (Epoch 138): Loss/seq after 01800 batchs: 623.7359008789062
INFO:root:Train (Epoch 138): Loss/seq after 01850 batchs: 619.20751953125
INFO:root:Train (Epoch 138): Loss/seq after 01900 batchs: 619.489013671875
INFO:root:Train (Epoch 138): Loss/seq after 01950 batchs: 617.5870971679688
INFO:root:Train (Epoch 138): Loss/seq after 02000 batchs: 615.562744140625
INFO:root:Train (Epoch 138): Loss/seq after 02050 batchs: 613.44775390625
INFO:root:Train (Epoch 138): Loss/seq after 02100 batchs: 610.1141967773438
INFO:root:Train (Epoch 138): Loss/seq after 02150 batchs: 607.7241821289062
INFO:root:Train (Epoch 138): Loss/seq after 02200 batchs: 604.3729248046875
INFO:root:Train (Epoch 138): Loss/seq after 02250 batchs: 602.7162475585938
INFO:root:Train (Epoch 138): Loss/seq after 02300 batchs: 599.968994140625
INFO:root:Train (Epoch 138): Loss/seq after 02350 batchs: 595.1137084960938
INFO:root:Train (Epoch 138): Loss/seq after 02400 batchs: 596.34423828125
INFO:root:Train (Epoch 138): Loss/seq after 02450 batchs: 591.077392578125
INFO:root:Train (Epoch 138): Loss/seq after 02500 batchs: 582.4110107421875
INFO:root:Train (Epoch 138): Loss/seq after 02550 batchs: 575.8577880859375
INFO:root:Train (Epoch 138): Loss/seq after 02600 batchs: 574.6732177734375
INFO:root:Train (Epoch 138): Loss/seq after 02650 batchs: 572.5015258789062
INFO:root:Train (Epoch 138): Loss/seq after 02700 batchs: 570.3158569335938
INFO:root:Train (Epoch 138): Loss/seq after 02750 batchs: 568.9364013671875
INFO:root:Train (Epoch 138): Loss/seq after 02800 batchs: 569.4371948242188
INFO:root:Train (Epoch 138): Loss/seq after 02850 batchs: 569.348876953125
INFO:root:Train (Epoch 138): Loss/seq after 02900 batchs: 570.4591064453125
INFO:root:Train (Epoch 138): Loss/seq after 02950 batchs: 569.2520141601562
INFO:root:Train (Epoch 138): Loss/seq after 03000 batchs: 574.1704711914062
INFO:root:Train (Epoch 138): Loss/seq after 03050 batchs: 576.154296875
INFO:root:Train (Epoch 138): Loss/seq after 03100 batchs: 579.961181640625
INFO:root:Train (Epoch 138): Loss/seq after 03150 batchs: 585.0472412109375
INFO:root:Train (Epoch 138): Loss/seq after 03200 batchs: 587.6879272460938
INFO:root:Train (Epoch 138): Loss/seq after 03250 batchs: 591.2020263671875
INFO:root:Train (Epoch 138): Loss/seq after 03300 batchs: 590.408935546875
INFO:root:Train (Epoch 138): Loss/seq after 03350 batchs: 590.8631591796875
INFO:root:Train (Epoch 138): Loss/seq after 03400 batchs: 586.431396484375
INFO:root:Train (Epoch 138): Loss/seq after 03450 batchs: 584.7129516601562
INFO:root:Train (Epoch 138): Loss/seq after 03500 batchs: 585.139892578125
INFO:root:Train (Epoch 138): Loss/seq after 03550 batchs: 582.4219360351562
INFO:root:Train (Epoch 138): Loss/seq after 03600 batchs: 590.8726806640625
INFO:root:Train (Epoch 138): Loss/seq after 03650 batchs: 588.3258666992188
INFO:root:Train (Epoch 138): Loss/seq after 03700 batchs: 591.1654052734375
INFO:root:Train (Epoch 138): Loss/seq after 03750 batchs: 595.8167724609375
INFO:root:Train (Epoch 138): Loss/seq after 03800 batchs: 593.1690063476562
INFO:root:Train (Epoch 138): Loss/seq after 03850 batchs: 591.8682250976562
INFO:root:Train (Epoch 138): Loss/seq after 03900 batchs: 595.78857421875
INFO:root:Train (Epoch 138): Loss/seq after 03950 batchs: 599.9003295898438
INFO:root:Train (Epoch 138): Loss/seq after 04000 batchs: 595.8557739257812
INFO:root:Train (Epoch 138): Loss/seq after 04050 batchs: 592.133056640625
INFO:root:Train (Epoch 138): Loss/seq after 04100 batchs: 590.0799560546875
INFO:root:Train (Epoch 138): Loss/seq after 04150 batchs: 589.7045288085938
INFO:root:Train (Epoch 138): Loss/seq after 04200 batchs: 587.9808349609375
INFO:root:Train (Epoch 138): Loss/seq after 04250 batchs: 586.00439453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 138): Loss/seq after 00000 batches: 551.9598388671875
INFO:root:# Valid (Epoch 138): Loss/seq after 00050 batches: 841.3012084960938
INFO:root:# Valid (Epoch 138): Loss/seq after 00100 batches: 826.7515869140625
INFO:root:# Valid (Epoch 138): Loss/seq after 00150 batches: 617.2620849609375
INFO:root:# Valid (Epoch 138): Loss/seq after 00200 batches: 566.552734375
INFO:root:Artifacts: Make stick videos for epoch 138
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_138_on_20220414_030157.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_138_index_1042_on_20220414_030157.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 139): Loss/seq after 00000 batchs: 948.4393310546875
INFO:root:Train (Epoch 139): Loss/seq after 00050 batchs: 810.56787109375
INFO:root:Train (Epoch 139): Loss/seq after 00100 batchs: 822.45068359375
INFO:root:Train (Epoch 139): Loss/seq after 00150 batchs: 745.8955688476562
INFO:root:Train (Epoch 139): Loss/seq after 00200 batchs: 815.5071411132812
INFO:root:Train (Epoch 139): Loss/seq after 00250 batchs: 919.296142578125
INFO:root:Train (Epoch 139): Loss/seq after 00300 batchs: 914.0108032226562
INFO:root:Train (Epoch 139): Loss/seq after 00350 batchs: 854.14208984375
INFO:root:Train (Epoch 139): Loss/seq after 00400 batchs: 859.6356811523438
INFO:root:Train (Epoch 139): Loss/seq after 00450 batchs: 839.0037841796875
INFO:root:Train (Epoch 139): Loss/seq after 00500 batchs: 814.65576171875
INFO:root:Train (Epoch 139): Loss/seq after 00550 batchs: 788.109375
INFO:root:Train (Epoch 139): Loss/seq after 00600 batchs: 760.2367553710938
INFO:root:Train (Epoch 139): Loss/seq after 00650 batchs: 742.5248413085938
INFO:root:Train (Epoch 139): Loss/seq after 00700 batchs: 718.7542114257812
INFO:root:Train (Epoch 139): Loss/seq after 00750 batchs: 727.6236572265625
INFO:root:Train (Epoch 139): Loss/seq after 00800 batchs: 728.0728759765625
INFO:root:Train (Epoch 139): Loss/seq after 00850 batchs: 705.150390625
INFO:root:Train (Epoch 139): Loss/seq after 00900 batchs: 689.9872436523438
INFO:root:Train (Epoch 139): Loss/seq after 00950 batchs: 687.2364501953125
INFO:root:Train (Epoch 139): Loss/seq after 01000 batchs: 677.8917236328125
INFO:root:Train (Epoch 139): Loss/seq after 01050 batchs: 665.9186401367188
INFO:root:Train (Epoch 139): Loss/seq after 01100 batchs: 655.9705200195312
INFO:root:Train (Epoch 139): Loss/seq after 01150 batchs: 640.2964477539062
INFO:root:Train (Epoch 139): Loss/seq after 01200 batchs: 643.82470703125
INFO:root:Train (Epoch 139): Loss/seq after 01250 batchs: 641.3426513671875
INFO:root:Train (Epoch 139): Loss/seq after 01300 batchs: 629.6570434570312
INFO:root:Train (Epoch 139): Loss/seq after 01350 batchs: 619.8984375
INFO:root:Train (Epoch 139): Loss/seq after 01400 batchs: 626.3314208984375
INFO:root:Train (Epoch 139): Loss/seq after 01450 batchs: 627.1299438476562
INFO:root:Train (Epoch 139): Loss/seq after 01500 batchs: 632.88330078125
INFO:root:Train (Epoch 139): Loss/seq after 01550 batchs: 634.724853515625
INFO:root:Train (Epoch 139): Loss/seq after 01600 batchs: 628.69970703125
INFO:root:Train (Epoch 139): Loss/seq after 01650 batchs: 626.0140991210938
INFO:root:Train (Epoch 139): Loss/seq after 01700 batchs: 627.8363037109375
INFO:root:Train (Epoch 139): Loss/seq after 01750 batchs: 624.6290283203125
INFO:root:Train (Epoch 139): Loss/seq after 01800 batchs: 621.2652587890625
INFO:root:Train (Epoch 139): Loss/seq after 01850 batchs: 616.762451171875
INFO:root:Train (Epoch 139): Loss/seq after 01900 batchs: 617.164306640625
INFO:root:Train (Epoch 139): Loss/seq after 01950 batchs: 615.2774658203125
INFO:root:Train (Epoch 139): Loss/seq after 02000 batchs: 613.325927734375
INFO:root:Train (Epoch 139): Loss/seq after 02050 batchs: 611.3150634765625
INFO:root:Train (Epoch 139): Loss/seq after 02100 batchs: 608.0324096679688
INFO:root:Train (Epoch 139): Loss/seq after 02150 batchs: 605.470703125
INFO:root:Train (Epoch 139): Loss/seq after 02200 batchs: 602.1488037109375
INFO:root:Train (Epoch 139): Loss/seq after 02250 batchs: 600.469482421875
INFO:root:Train (Epoch 139): Loss/seq after 02300 batchs: 597.843505859375
INFO:root:Train (Epoch 139): Loss/seq after 02350 batchs: 593.1171875
INFO:root:Train (Epoch 139): Loss/seq after 02400 batchs: 594.4076538085938
INFO:root:Train (Epoch 139): Loss/seq after 02450 batchs: 589.22021484375
INFO:root:Train (Epoch 139): Loss/seq after 02500 batchs: 580.5731811523438
INFO:root:Train (Epoch 139): Loss/seq after 02550 batchs: 574.2261962890625
INFO:root:Train (Epoch 139): Loss/seq after 02600 batchs: 573.08740234375
INFO:root:Train (Epoch 139): Loss/seq after 02650 batchs: 570.7384643554688
INFO:root:Train (Epoch 139): Loss/seq after 02700 batchs: 568.4442749023438
INFO:root:Train (Epoch 139): Loss/seq after 02750 batchs: 567.2142944335938
INFO:root:Train (Epoch 139): Loss/seq after 02800 batchs: 568.1589965820312
INFO:root:Train (Epoch 139): Loss/seq after 02850 batchs: 568.0662231445312
INFO:root:Train (Epoch 139): Loss/seq after 02900 batchs: 569.2233276367188
INFO:root:Train (Epoch 139): Loss/seq after 02950 batchs: 567.9385375976562
INFO:root:Train (Epoch 139): Loss/seq after 03000 batchs: 572.790771484375
INFO:root:Train (Epoch 139): Loss/seq after 03050 batchs: 574.9424438476562
INFO:root:Train (Epoch 139): Loss/seq after 03100 batchs: 578.8456420898438
INFO:root:Train (Epoch 139): Loss/seq after 03150 batchs: 583.43994140625
INFO:root:Train (Epoch 139): Loss/seq after 03200 batchs: 585.8062133789062
INFO:root:Train (Epoch 139): Loss/seq after 03250 batchs: 589.0811767578125
INFO:root:Train (Epoch 139): Loss/seq after 03300 batchs: 588.1500244140625
INFO:root:Train (Epoch 139): Loss/seq after 03350 batchs: 588.3846435546875
INFO:root:Train (Epoch 139): Loss/seq after 03400 batchs: 583.953857421875
INFO:root:Train (Epoch 139): Loss/seq after 03450 batchs: 582.2280883789062
INFO:root:Train (Epoch 139): Loss/seq after 03500 batchs: 582.6080322265625
INFO:root:Train (Epoch 139): Loss/seq after 03550 batchs: 579.70361328125
INFO:root:Train (Epoch 139): Loss/seq after 03600 batchs: 587.8218383789062
INFO:root:Train (Epoch 139): Loss/seq after 03650 batchs: 585.08740234375
INFO:root:Train (Epoch 139): Loss/seq after 03700 batchs: 587.5160522460938
INFO:root:Train (Epoch 139): Loss/seq after 03750 batchs: 592.2163696289062
INFO:root:Train (Epoch 139): Loss/seq after 03800 batchs: 589.5699462890625
INFO:root:Train (Epoch 139): Loss/seq after 03850 batchs: 588.2279052734375
INFO:root:Train (Epoch 139): Loss/seq after 03900 batchs: 592.2779541015625
INFO:root:Train (Epoch 139): Loss/seq after 03950 batchs: 596.4254150390625
INFO:root:Train (Epoch 139): Loss/seq after 04000 batchs: 592.3564453125
INFO:root:Train (Epoch 139): Loss/seq after 04050 batchs: 588.6338500976562
INFO:root:Train (Epoch 139): Loss/seq after 04100 batchs: 586.6061401367188
INFO:root:Train (Epoch 139): Loss/seq after 04150 batchs: 586.2582397460938
INFO:root:Train (Epoch 139): Loss/seq after 04200 batchs: 584.4747924804688
INFO:root:Train (Epoch 139): Loss/seq after 04250 batchs: 582.5833129882812
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 139): Loss/seq after 00000 batches: 542.3465576171875
INFO:root:# Valid (Epoch 139): Loss/seq after 00050 batches: 768.0817260742188
INFO:root:# Valid (Epoch 139): Loss/seq after 00100 batches: 773.626220703125
INFO:root:# Valid (Epoch 139): Loss/seq after 00150 batches: 579.3541259765625
INFO:root:# Valid (Epoch 139): Loss/seq after 00200 batches: 533.8638916015625
INFO:root:Artifacts: Make stick videos for epoch 139
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_139_on_20220414_030715.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_139_index_1508_on_20220414_030715.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 140): Loss/seq after 00000 batchs: 1076.067626953125
INFO:root:Train (Epoch 140): Loss/seq after 00050 batchs: 801.8899536132812
INFO:root:Train (Epoch 140): Loss/seq after 00100 batchs: 819.7207641601562
INFO:root:Train (Epoch 140): Loss/seq after 00150 batchs: 742.0634765625
INFO:root:Train (Epoch 140): Loss/seq after 00200 batchs: 810.64697265625
INFO:root:Train (Epoch 140): Loss/seq after 00250 batchs: 908.3571166992188
INFO:root:Train (Epoch 140): Loss/seq after 00300 batchs: 903.5385131835938
INFO:root:Train (Epoch 140): Loss/seq after 00350 batchs: 845.1947021484375
INFO:root:Train (Epoch 140): Loss/seq after 00400 batchs: 850.528564453125
INFO:root:Train (Epoch 140): Loss/seq after 00450 batchs: 830.6840209960938
INFO:root:Train (Epoch 140): Loss/seq after 00500 batchs: 804.0571899414062
INFO:root:Train (Epoch 140): Loss/seq after 00550 batchs: 778.191162109375
INFO:root:Train (Epoch 140): Loss/seq after 00600 batchs: 751.0770874023438
INFO:root:Train (Epoch 140): Loss/seq after 00650 batchs: 734.3028564453125
INFO:root:Train (Epoch 140): Loss/seq after 00700 batchs: 711.0601806640625
INFO:root:Train (Epoch 140): Loss/seq after 00750 batchs: 719.9238891601562
INFO:root:Train (Epoch 140): Loss/seq after 00800 batchs: 721.2400512695312
INFO:root:Train (Epoch 140): Loss/seq after 00850 batchs: 698.3807983398438
INFO:root:Train (Epoch 140): Loss/seq after 00900 batchs: 683.2974853515625
INFO:root:Train (Epoch 140): Loss/seq after 00950 batchs: 681.5712890625
INFO:root:Train (Epoch 140): Loss/seq after 01000 batchs: 672.8117065429688
INFO:root:Train (Epoch 140): Loss/seq after 01050 batchs: 661.8427734375
INFO:root:Train (Epoch 140): Loss/seq after 01100 batchs: 651.8740844726562
INFO:root:Train (Epoch 140): Loss/seq after 01150 batchs: 636.2911376953125
INFO:root:Train (Epoch 140): Loss/seq after 01200 batchs: 640.4725341796875
INFO:root:Train (Epoch 140): Loss/seq after 01250 batchs: 638.5158081054688
INFO:root:Train (Epoch 140): Loss/seq after 01300 batchs: 626.9996337890625
INFO:root:Train (Epoch 140): Loss/seq after 01350 batchs: 617.2407836914062
INFO:root:Train (Epoch 140): Loss/seq after 01400 batchs: 623.5882568359375
INFO:root:Train (Epoch 140): Loss/seq after 01450 batchs: 624.8639526367188
INFO:root:Train (Epoch 140): Loss/seq after 01500 batchs: 630.6800537109375
INFO:root:Train (Epoch 140): Loss/seq after 01550 batchs: 632.7262573242188
INFO:root:Train (Epoch 140): Loss/seq after 01600 batchs: 626.8046264648438
INFO:root:Train (Epoch 140): Loss/seq after 01650 batchs: 624.385986328125
INFO:root:Train (Epoch 140): Loss/seq after 01700 batchs: 626.5393676757812
INFO:root:Train (Epoch 140): Loss/seq after 01750 batchs: 623.3184204101562
INFO:root:Train (Epoch 140): Loss/seq after 01800 batchs: 619.7329711914062
INFO:root:Train (Epoch 140): Loss/seq after 01850 batchs: 615.2471313476562
INFO:root:Train (Epoch 140): Loss/seq after 01900 batchs: 615.5125122070312
INFO:root:Train (Epoch 140): Loss/seq after 01950 batchs: 613.4132690429688
INFO:root:Train (Epoch 140): Loss/seq after 02000 batchs: 611.4603271484375
INFO:root:Train (Epoch 140): Loss/seq after 02050 batchs: 609.4318237304688
INFO:root:Train (Epoch 140): Loss/seq after 02100 batchs: 606.050048828125
INFO:root:Train (Epoch 140): Loss/seq after 02150 batchs: 603.4649658203125
INFO:root:Train (Epoch 140): Loss/seq after 02200 batchs: 600.0767211914062
INFO:root:Train (Epoch 140): Loss/seq after 02250 batchs: 598.4359741210938
INFO:root:Train (Epoch 140): Loss/seq after 02300 batchs: 595.8623657226562
INFO:root:Train (Epoch 140): Loss/seq after 02350 batchs: 591.2086181640625
INFO:root:Train (Epoch 140): Loss/seq after 02400 batchs: 592.48046875
INFO:root:Train (Epoch 140): Loss/seq after 02450 batchs: 587.2565307617188
INFO:root:Train (Epoch 140): Loss/seq after 02500 batchs: 578.65673828125
INFO:root:Train (Epoch 140): Loss/seq after 02550 batchs: 572.2752075195312
INFO:root:Train (Epoch 140): Loss/seq after 02600 batchs: 571.0408935546875
INFO:root:Train (Epoch 140): Loss/seq after 02650 batchs: 568.8787231445312
INFO:root:Train (Epoch 140): Loss/seq after 02700 batchs: 566.787353515625
INFO:root:Train (Epoch 140): Loss/seq after 02750 batchs: 565.58837890625
INFO:root:Train (Epoch 140): Loss/seq after 02800 batchs: 566.00146484375
INFO:root:Train (Epoch 140): Loss/seq after 02850 batchs: 565.9716186523438
INFO:root:Train (Epoch 140): Loss/seq after 02900 batchs: 567.0121459960938
INFO:root:Train (Epoch 140): Loss/seq after 02950 batchs: 565.8392333984375
INFO:root:Train (Epoch 140): Loss/seq after 03000 batchs: 570.7310791015625
INFO:root:Train (Epoch 140): Loss/seq after 03050 batchs: 572.7100830078125
INFO:root:Train (Epoch 140): Loss/seq after 03100 batchs: 576.6101684570312
INFO:root:Train (Epoch 140): Loss/seq after 03150 batchs: 581.2549438476562
INFO:root:Train (Epoch 140): Loss/seq after 03200 batchs: 583.2392578125
INFO:root:Train (Epoch 140): Loss/seq after 03250 batchs: 586.7216796875
INFO:root:Train (Epoch 140): Loss/seq after 03300 batchs: 586.2838134765625
INFO:root:Train (Epoch 140): Loss/seq after 03350 batchs: 586.6881103515625
INFO:root:Train (Epoch 140): Loss/seq after 03400 batchs: 582.4951171875
INFO:root:Train (Epoch 140): Loss/seq after 03450 batchs: 580.9539794921875
INFO:root:Train (Epoch 140): Loss/seq after 03500 batchs: 581.2269897460938
INFO:root:Train (Epoch 140): Loss/seq after 03550 batchs: 578.3087768554688
INFO:root:Train (Epoch 140): Loss/seq after 03600 batchs: 585.8709716796875
INFO:root:Train (Epoch 140): Loss/seq after 03650 batchs: 582.994140625
INFO:root:Train (Epoch 140): Loss/seq after 03700 batchs: 585.57861328125
INFO:root:Train (Epoch 140): Loss/seq after 03750 batchs: 590.2039184570312
INFO:root:Train (Epoch 140): Loss/seq after 03800 batchs: 587.5758666992188
INFO:root:Train (Epoch 140): Loss/seq after 03850 batchs: 586.3430786132812
INFO:root:Train (Epoch 140): Loss/seq after 03900 batchs: 590.1514282226562
INFO:root:Train (Epoch 140): Loss/seq after 03950 batchs: 594.2915649414062
INFO:root:Train (Epoch 140): Loss/seq after 04000 batchs: 590.186767578125
INFO:root:Train (Epoch 140): Loss/seq after 04050 batchs: 586.4925537109375
INFO:root:Train (Epoch 140): Loss/seq after 04100 batchs: 584.5034790039062
INFO:root:Train (Epoch 140): Loss/seq after 04150 batchs: 584.1397705078125
INFO:root:Train (Epoch 140): Loss/seq after 04200 batchs: 582.4214477539062
INFO:root:Train (Epoch 140): Loss/seq after 04250 batchs: 580.5390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 140): Loss/seq after 00000 batches: 515.0731201171875
INFO:root:# Valid (Epoch 140): Loss/seq after 00050 batches: 807.635986328125
INFO:root:# Valid (Epoch 140): Loss/seq after 00100 batches: 789.7479248046875
INFO:root:# Valid (Epoch 140): Loss/seq after 00150 batches: 590.688232421875
INFO:root:# Valid (Epoch 140): Loss/seq after 00200 batches: 542.3762817382812
INFO:root:Artifacts: Make stick videos for epoch 140
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_140_on_20220414_031235.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_140_index_1343_on_20220414_031235.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 141): Loss/seq after 00000 batchs: 1080.655029296875
INFO:root:Train (Epoch 141): Loss/seq after 00050 batchs: 804.418701171875
INFO:root:Train (Epoch 141): Loss/seq after 00100 batchs: 814.04833984375
INFO:root:Train (Epoch 141): Loss/seq after 00150 batchs: 739.2198486328125
INFO:root:Train (Epoch 141): Loss/seq after 00200 batchs: 804.5860595703125
INFO:root:Train (Epoch 141): Loss/seq after 00250 batchs: 900.9442749023438
INFO:root:Train (Epoch 141): Loss/seq after 00300 batchs: 896.8138427734375
INFO:root:Train (Epoch 141): Loss/seq after 00350 batchs: 838.9635620117188
INFO:root:Train (Epoch 141): Loss/seq after 00400 batchs: 842.447509765625
INFO:root:Train (Epoch 141): Loss/seq after 00450 batchs: 823.6403198242188
INFO:root:Train (Epoch 141): Loss/seq after 00500 batchs: 796.3748779296875
INFO:root:Train (Epoch 141): Loss/seq after 00550 batchs: 771.178466796875
INFO:root:Train (Epoch 141): Loss/seq after 00600 batchs: 743.8631591796875
INFO:root:Train (Epoch 141): Loss/seq after 00650 batchs: 725.7568359375
INFO:root:Train (Epoch 141): Loss/seq after 00700 batchs: 701.110107421875
INFO:root:Train (Epoch 141): Loss/seq after 00750 batchs: 708.7262573242188
INFO:root:Train (Epoch 141): Loss/seq after 00800 batchs: 710.07861328125
INFO:root:Train (Epoch 141): Loss/seq after 00850 batchs: 687.63720703125
INFO:root:Train (Epoch 141): Loss/seq after 00900 batchs: 673.3017578125
INFO:root:Train (Epoch 141): Loss/seq after 00950 batchs: 670.7155151367188
INFO:root:Train (Epoch 141): Loss/seq after 01000 batchs: 662.1265869140625
INFO:root:Train (Epoch 141): Loss/seq after 01050 batchs: 650.87255859375
INFO:root:Train (Epoch 141): Loss/seq after 01100 batchs: 641.4996948242188
INFO:root:Train (Epoch 141): Loss/seq after 01150 batchs: 626.3129272460938
INFO:root:Train (Epoch 141): Loss/seq after 01200 batchs: 630.2545166015625
INFO:root:Train (Epoch 141): Loss/seq after 01250 batchs: 628.0736083984375
INFO:root:Train (Epoch 141): Loss/seq after 01300 batchs: 616.7679443359375
INFO:root:Train (Epoch 141): Loss/seq after 01350 batchs: 607.6445922851562
INFO:root:Train (Epoch 141): Loss/seq after 01400 batchs: 613.3760375976562
INFO:root:Train (Epoch 141): Loss/seq after 01450 batchs: 614.290771484375
INFO:root:Train (Epoch 141): Loss/seq after 01500 batchs: 620.4075317382812
INFO:root:Train (Epoch 141): Loss/seq after 01550 batchs: 622.5430908203125
INFO:root:Train (Epoch 141): Loss/seq after 01600 batchs: 616.7099609375
INFO:root:Train (Epoch 141): Loss/seq after 01650 batchs: 614.318603515625
INFO:root:Train (Epoch 141): Loss/seq after 01700 batchs: 616.1598510742188
INFO:root:Train (Epoch 141): Loss/seq after 01750 batchs: 613.2267456054688
INFO:root:Train (Epoch 141): Loss/seq after 01800 batchs: 609.9218139648438
INFO:root:Train (Epoch 141): Loss/seq after 01850 batchs: 605.5374755859375
INFO:root:Train (Epoch 141): Loss/seq after 01900 batchs: 606.0809936523438
INFO:root:Train (Epoch 141): Loss/seq after 01950 batchs: 604.3265991210938
INFO:root:Train (Epoch 141): Loss/seq after 02000 batchs: 602.4826049804688
INFO:root:Train (Epoch 141): Loss/seq after 02050 batchs: 600.551513671875
INFO:root:Train (Epoch 141): Loss/seq after 02100 batchs: 597.3377075195312
INFO:root:Train (Epoch 141): Loss/seq after 02150 batchs: 595.1734619140625
INFO:root:Train (Epoch 141): Loss/seq after 02200 batchs: 592.150390625
INFO:root:Train (Epoch 141): Loss/seq after 02250 batchs: 590.740966796875
INFO:root:Train (Epoch 141): Loss/seq after 02300 batchs: 588.220458984375
INFO:root:Train (Epoch 141): Loss/seq after 02350 batchs: 583.62890625
INFO:root:Train (Epoch 141): Loss/seq after 02400 batchs: 584.9969482421875
INFO:root:Train (Epoch 141): Loss/seq after 02450 batchs: 579.8660278320312
INFO:root:Train (Epoch 141): Loss/seq after 02500 batchs: 571.3792724609375
INFO:root:Train (Epoch 141): Loss/seq after 02550 batchs: 564.95556640625
INFO:root:Train (Epoch 141): Loss/seq after 02600 batchs: 563.8612670898438
INFO:root:Train (Epoch 141): Loss/seq after 02650 batchs: 561.805908203125
INFO:root:Train (Epoch 141): Loss/seq after 02700 batchs: 559.5000610351562
INFO:root:Train (Epoch 141): Loss/seq after 02750 batchs: 558.4772338867188
INFO:root:Train (Epoch 141): Loss/seq after 02800 batchs: 559.3298950195312
INFO:root:Train (Epoch 141): Loss/seq after 02850 batchs: 559.29833984375
INFO:root:Train (Epoch 141): Loss/seq after 02900 batchs: 560.545654296875
INFO:root:Train (Epoch 141): Loss/seq after 02950 batchs: 559.4752807617188
INFO:root:Train (Epoch 141): Loss/seq after 03000 batchs: 564.4821166992188
INFO:root:Train (Epoch 141): Loss/seq after 03050 batchs: 566.4697265625
INFO:root:Train (Epoch 141): Loss/seq after 03100 batchs: 570.0245361328125
INFO:root:Train (Epoch 141): Loss/seq after 03150 batchs: 574.7920532226562
INFO:root:Train (Epoch 141): Loss/seq after 03200 batchs: 576.990234375
INFO:root:Train (Epoch 141): Loss/seq after 03250 batchs: 580.0498046875
INFO:root:Train (Epoch 141): Loss/seq after 03300 batchs: 579.3174438476562
INFO:root:Train (Epoch 141): Loss/seq after 03350 batchs: 579.721435546875
INFO:root:Train (Epoch 141): Loss/seq after 03400 batchs: 575.3825073242188
INFO:root:Train (Epoch 141): Loss/seq after 03450 batchs: 573.9373168945312
INFO:root:Train (Epoch 141): Loss/seq after 03500 batchs: 574.256591796875
INFO:root:Train (Epoch 141): Loss/seq after 03550 batchs: 571.386474609375
INFO:root:Train (Epoch 141): Loss/seq after 03600 batchs: 579.6282348632812
INFO:root:Train (Epoch 141): Loss/seq after 03650 batchs: 576.8306274414062
INFO:root:Train (Epoch 141): Loss/seq after 03700 batchs: 579.3258666992188
INFO:root:Train (Epoch 141): Loss/seq after 03750 batchs: 584.0043334960938
INFO:root:Train (Epoch 141): Loss/seq after 03800 batchs: 581.47998046875
INFO:root:Train (Epoch 141): Loss/seq after 03850 batchs: 580.2111206054688
INFO:root:Train (Epoch 141): Loss/seq after 03900 batchs: 584.0950927734375
INFO:root:Train (Epoch 141): Loss/seq after 03950 batchs: 588.0999145507812
INFO:root:Train (Epoch 141): Loss/seq after 04000 batchs: 584.0401000976562
INFO:root:Train (Epoch 141): Loss/seq after 04050 batchs: 580.3455200195312
INFO:root:Train (Epoch 141): Loss/seq after 04100 batchs: 578.4002685546875
INFO:root:Train (Epoch 141): Loss/seq after 04150 batchs: 578.0372314453125
INFO:root:Train (Epoch 141): Loss/seq after 04200 batchs: 576.33837890625
INFO:root:Train (Epoch 141): Loss/seq after 04250 batchs: 574.5537719726562
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 141): Loss/seq after 00000 batches: 516.4229125976562
INFO:root:# Valid (Epoch 141): Loss/seq after 00050 batches: 768.8859252929688
INFO:root:# Valid (Epoch 141): Loss/seq after 00100 batches: 764.1990966796875
INFO:root:# Valid (Epoch 141): Loss/seq after 00150 batches: 574.5120239257812
INFO:root:# Valid (Epoch 141): Loss/seq after 00200 batches: 530.833740234375
INFO:root:Artifacts: Make stick videos for epoch 141
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_141_on_20220414_031754.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_141_index_1265_on_20220414_031754.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 142): Loss/seq after 00000 batchs: 1028.12841796875
INFO:root:Train (Epoch 142): Loss/seq after 00050 batchs: 795.0527954101562
INFO:root:Train (Epoch 142): Loss/seq after 00100 batchs: 803.5606079101562
INFO:root:Train (Epoch 142): Loss/seq after 00150 batchs: 736.6165161132812
INFO:root:Train (Epoch 142): Loss/seq after 00200 batchs: 804.2173461914062
INFO:root:Train (Epoch 142): Loss/seq after 00250 batchs: 900.1661987304688
INFO:root:Train (Epoch 142): Loss/seq after 00300 batchs: 895.5834350585938
INFO:root:Train (Epoch 142): Loss/seq after 00350 batchs: 837.830322265625
INFO:root:Train (Epoch 142): Loss/seq after 00400 batchs: 840.2355346679688
INFO:root:Train (Epoch 142): Loss/seq after 00450 batchs: 821.5133056640625
INFO:root:Train (Epoch 142): Loss/seq after 00500 batchs: 795.7044067382812
INFO:root:Train (Epoch 142): Loss/seq after 00550 batchs: 770.63623046875
INFO:root:Train (Epoch 142): Loss/seq after 00600 batchs: 743.4788818359375
INFO:root:Train (Epoch 142): Loss/seq after 00650 batchs: 724.5654296875
INFO:root:Train (Epoch 142): Loss/seq after 00700 batchs: 700.2595825195312
INFO:root:Train (Epoch 142): Loss/seq after 00750 batchs: 708.1207275390625
INFO:root:Train (Epoch 142): Loss/seq after 00800 batchs: 709.2542724609375
INFO:root:Train (Epoch 142): Loss/seq after 00850 batchs: 686.983154296875
INFO:root:Train (Epoch 142): Loss/seq after 00900 batchs: 672.4277954101562
INFO:root:Train (Epoch 142): Loss/seq after 00950 batchs: 670.1692504882812
INFO:root:Train (Epoch 142): Loss/seq after 01000 batchs: 661.4990234375
INFO:root:Train (Epoch 142): Loss/seq after 01050 batchs: 650.2685546875
INFO:root:Train (Epoch 142): Loss/seq after 01100 batchs: 640.615966796875
INFO:root:Train (Epoch 142): Loss/seq after 01150 batchs: 625.5872192382812
INFO:root:Train (Epoch 142): Loss/seq after 01200 batchs: 629.4803466796875
INFO:root:Train (Epoch 142): Loss/seq after 01250 batchs: 627.3982543945312
INFO:root:Train (Epoch 142): Loss/seq after 01300 batchs: 615.8533935546875
INFO:root:Train (Epoch 142): Loss/seq after 01350 batchs: 606.5372924804688
INFO:root:Train (Epoch 142): Loss/seq after 01400 batchs: 611.9088134765625
INFO:root:Train (Epoch 142): Loss/seq after 01450 batchs: 612.99560546875
INFO:root:Train (Epoch 142): Loss/seq after 01500 batchs: 618.7904663085938
INFO:root:Train (Epoch 142): Loss/seq after 01550 batchs: 620.7142944335938
INFO:root:Train (Epoch 142): Loss/seq after 01600 batchs: 614.8364868164062
INFO:root:Train (Epoch 142): Loss/seq after 01650 batchs: 612.4028930664062
INFO:root:Train (Epoch 142): Loss/seq after 01700 batchs: 614.04736328125
INFO:root:Train (Epoch 142): Loss/seq after 01750 batchs: 611.233154296875
INFO:root:Train (Epoch 142): Loss/seq after 01800 batchs: 607.8915405273438
INFO:root:Train (Epoch 142): Loss/seq after 01850 batchs: 603.5618896484375
INFO:root:Train (Epoch 142): Loss/seq after 01900 batchs: 604.189697265625
INFO:root:Train (Epoch 142): Loss/seq after 01950 batchs: 602.5211181640625
INFO:root:Train (Epoch 142): Loss/seq after 02000 batchs: 600.6539306640625
INFO:root:Train (Epoch 142): Loss/seq after 02050 batchs: 598.894775390625
INFO:root:Train (Epoch 142): Loss/seq after 02100 batchs: 595.68310546875
INFO:root:Train (Epoch 142): Loss/seq after 02150 batchs: 593.2945556640625
INFO:root:Train (Epoch 142): Loss/seq after 02200 batchs: 590.0692138671875
INFO:root:Train (Epoch 142): Loss/seq after 02250 batchs: 588.1259155273438
INFO:root:Train (Epoch 142): Loss/seq after 02300 batchs: 585.2710571289062
INFO:root:Train (Epoch 142): Loss/seq after 02350 batchs: 580.7544555664062
INFO:root:Train (Epoch 142): Loss/seq after 02400 batchs: 582.1731567382812
INFO:root:Train (Epoch 142): Loss/seq after 02450 batchs: 577.1065673828125
INFO:root:Train (Epoch 142): Loss/seq after 02500 batchs: 568.67431640625
INFO:root:Train (Epoch 142): Loss/seq after 02550 batchs: 562.4857788085938
INFO:root:Train (Epoch 142): Loss/seq after 02600 batchs: 561.329833984375
INFO:root:Train (Epoch 142): Loss/seq after 02650 batchs: 559.232666015625
INFO:root:Train (Epoch 142): Loss/seq after 02700 batchs: 556.9977416992188
INFO:root:Train (Epoch 142): Loss/seq after 02750 batchs: 554.971435546875
INFO:root:Train (Epoch 142): Loss/seq after 02800 batchs: 555.17236328125
INFO:root:Train (Epoch 142): Loss/seq after 02850 batchs: 555.1463012695312
INFO:root:Train (Epoch 142): Loss/seq after 02900 batchs: 556.3878784179688
INFO:root:Train (Epoch 142): Loss/seq after 02950 batchs: 555.2156982421875
INFO:root:Train (Epoch 142): Loss/seq after 03000 batchs: 560.2420043945312
INFO:root:Train (Epoch 142): Loss/seq after 03050 batchs: 562.129150390625
INFO:root:Train (Epoch 142): Loss/seq after 03100 batchs: 565.5311889648438
INFO:root:Train (Epoch 142): Loss/seq after 03150 batchs: 570.32080078125
INFO:root:Train (Epoch 142): Loss/seq after 03200 batchs: 572.7037963867188
INFO:root:Train (Epoch 142): Loss/seq after 03250 batchs: 576.3623046875
INFO:root:Train (Epoch 142): Loss/seq after 03300 batchs: 575.5477905273438
INFO:root:Train (Epoch 142): Loss/seq after 03350 batchs: 575.6346435546875
INFO:root:Train (Epoch 142): Loss/seq after 03400 batchs: 571.3544311523438
INFO:root:Train (Epoch 142): Loss/seq after 03450 batchs: 569.85888671875
INFO:root:Train (Epoch 142): Loss/seq after 03500 batchs: 570.2703857421875
INFO:root:Train (Epoch 142): Loss/seq after 03550 batchs: 567.3944702148438
INFO:root:Train (Epoch 142): Loss/seq after 03600 batchs: 574.9827880859375
INFO:root:Train (Epoch 142): Loss/seq after 03650 batchs: 572.2459106445312
INFO:root:Train (Epoch 142): Loss/seq after 03700 batchs: 574.726318359375
INFO:root:Train (Epoch 142): Loss/seq after 03750 batchs: 579.4337768554688
INFO:root:Train (Epoch 142): Loss/seq after 03800 batchs: 576.9296875
INFO:root:Train (Epoch 142): Loss/seq after 03850 batchs: 575.590087890625
INFO:root:Train (Epoch 142): Loss/seq after 03900 batchs: 579.272705078125
INFO:root:Train (Epoch 142): Loss/seq after 03950 batchs: 583.4755249023438
INFO:root:Train (Epoch 142): Loss/seq after 04000 batchs: 579.4376220703125
INFO:root:Train (Epoch 142): Loss/seq after 04050 batchs: 575.8051147460938
INFO:root:Train (Epoch 142): Loss/seq after 04100 batchs: 573.9392700195312
INFO:root:Train (Epoch 142): Loss/seq after 04150 batchs: 573.5946044921875
INFO:root:Train (Epoch 142): Loss/seq after 04200 batchs: 571.9664306640625
INFO:root:Train (Epoch 142): Loss/seq after 04250 batchs: 570.1319580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 142): Loss/seq after 00000 batches: 517.8509521484375
INFO:root:# Valid (Epoch 142): Loss/seq after 00050 batches: 770.47021484375
INFO:root:# Valid (Epoch 142): Loss/seq after 00100 batches: 762.529052734375
INFO:root:# Valid (Epoch 142): Loss/seq after 00150 batches: 573.9673461914062
INFO:root:# Valid (Epoch 142): Loss/seq after 00200 batches: 531.8904418945312
INFO:root:Artifacts: Make stick videos for epoch 142
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_142_on_20220414_032313.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_142_index_625_on_20220414_032313.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 143): Loss/seq after 00000 batchs: 1002.0257568359375
INFO:root:Train (Epoch 143): Loss/seq after 00050 batchs: 790.6369018554688
INFO:root:Train (Epoch 143): Loss/seq after 00100 batchs: 790.3556518554688
INFO:root:Train (Epoch 143): Loss/seq after 00150 batchs: 718.6320190429688
INFO:root:Train (Epoch 143): Loss/seq after 00200 batchs: 790.633544921875
INFO:root:Train (Epoch 143): Loss/seq after 00250 batchs: 888.1361083984375
INFO:root:Train (Epoch 143): Loss/seq after 00300 batchs: 886.146484375
INFO:root:Train (Epoch 143): Loss/seq after 00350 batchs: 829.2525024414062
INFO:root:Train (Epoch 143): Loss/seq after 00400 batchs: 827.6708374023438
INFO:root:Train (Epoch 143): Loss/seq after 00450 batchs: 810.0022583007812
INFO:root:Train (Epoch 143): Loss/seq after 00500 batchs: 783.5035400390625
INFO:root:Train (Epoch 143): Loss/seq after 00550 batchs: 758.7439575195312
INFO:root:Train (Epoch 143): Loss/seq after 00600 batchs: 732.5925903320312
INFO:root:Train (Epoch 143): Loss/seq after 00650 batchs: 713.7098388671875
INFO:root:Train (Epoch 143): Loss/seq after 00700 batchs: 689.4865112304688
INFO:root:Train (Epoch 143): Loss/seq after 00750 batchs: 696.8099365234375
INFO:root:Train (Epoch 143): Loss/seq after 00800 batchs: 698.873046875
INFO:root:Train (Epoch 143): Loss/seq after 00850 batchs: 676.770263671875
INFO:root:Train (Epoch 143): Loss/seq after 00900 batchs: 662.617431640625
INFO:root:Train (Epoch 143): Loss/seq after 00950 batchs: 660.4876708984375
INFO:root:Train (Epoch 143): Loss/seq after 01000 batchs: 652.5752563476562
INFO:root:Train (Epoch 143): Loss/seq after 01050 batchs: 641.3660278320312
INFO:root:Train (Epoch 143): Loss/seq after 01100 batchs: 631.729736328125
INFO:root:Train (Epoch 143): Loss/seq after 01150 batchs: 616.8971557617188
INFO:root:Train (Epoch 143): Loss/seq after 01200 batchs: 621.2232055664062
INFO:root:Train (Epoch 143): Loss/seq after 01250 batchs: 619.31396484375
INFO:root:Train (Epoch 143): Loss/seq after 01300 batchs: 607.9229736328125
INFO:root:Train (Epoch 143): Loss/seq after 01350 batchs: 598.8346557617188
INFO:root:Train (Epoch 143): Loss/seq after 01400 batchs: 604.841552734375
INFO:root:Train (Epoch 143): Loss/seq after 01450 batchs: 606.0757446289062
INFO:root:Train (Epoch 143): Loss/seq after 01500 batchs: 612.2416381835938
INFO:root:Train (Epoch 143): Loss/seq after 01550 batchs: 614.2530517578125
INFO:root:Train (Epoch 143): Loss/seq after 01600 batchs: 608.7256469726562
INFO:root:Train (Epoch 143): Loss/seq after 01650 batchs: 606.5291748046875
INFO:root:Train (Epoch 143): Loss/seq after 01700 batchs: 608.5460815429688
INFO:root:Train (Epoch 143): Loss/seq after 01750 batchs: 605.710205078125
INFO:root:Train (Epoch 143): Loss/seq after 01800 batchs: 602.3092041015625
INFO:root:Train (Epoch 143): Loss/seq after 01850 batchs: 598.0596923828125
INFO:root:Train (Epoch 143): Loss/seq after 01900 batchs: 598.6494750976562
INFO:root:Train (Epoch 143): Loss/seq after 01950 batchs: 596.9470825195312
INFO:root:Train (Epoch 143): Loss/seq after 02000 batchs: 595.3792114257812
INFO:root:Train (Epoch 143): Loss/seq after 02050 batchs: 593.6106567382812
INFO:root:Train (Epoch 143): Loss/seq after 02100 batchs: 590.4266357421875
INFO:root:Train (Epoch 143): Loss/seq after 02150 batchs: 588.0987548828125
INFO:root:Train (Epoch 143): Loss/seq after 02200 batchs: 584.9041137695312
INFO:root:Train (Epoch 143): Loss/seq after 02250 batchs: 583.0804443359375
INFO:root:Train (Epoch 143): Loss/seq after 02300 batchs: 580.3504028320312
INFO:root:Train (Epoch 143): Loss/seq after 02350 batchs: 575.8583374023438
INFO:root:Train (Epoch 143): Loss/seq after 02400 batchs: 577.2531127929688
INFO:root:Train (Epoch 143): Loss/seq after 02450 batchs: 572.1992797851562
INFO:root:Train (Epoch 143): Loss/seq after 02500 batchs: 563.859130859375
INFO:root:Train (Epoch 143): Loss/seq after 02550 batchs: 557.5314331054688
INFO:root:Train (Epoch 143): Loss/seq after 02600 batchs: 556.5491333007812
INFO:root:Train (Epoch 143): Loss/seq after 02650 batchs: 554.3946533203125
INFO:root:Train (Epoch 143): Loss/seq after 02700 batchs: 552.3622436523438
INFO:root:Train (Epoch 143): Loss/seq after 02750 batchs: 550.6259155273438
INFO:root:Train (Epoch 143): Loss/seq after 02800 batchs: 551.0148315429688
INFO:root:Train (Epoch 143): Loss/seq after 02850 batchs: 551.033203125
INFO:root:Train (Epoch 143): Loss/seq after 02900 batchs: 552.1903686523438
INFO:root:Train (Epoch 143): Loss/seq after 02950 batchs: 551.1228637695312
INFO:root:Train (Epoch 143): Loss/seq after 03000 batchs: 556.1705322265625
INFO:root:Train (Epoch 143): Loss/seq after 03050 batchs: 558.0752563476562
INFO:root:Train (Epoch 143): Loss/seq after 03100 batchs: 561.2535400390625
INFO:root:Train (Epoch 143): Loss/seq after 03150 batchs: 565.3125610351562
INFO:root:Train (Epoch 143): Loss/seq after 03200 batchs: 567.2833251953125
INFO:root:Train (Epoch 143): Loss/seq after 03250 batchs: 570.8579711914062
INFO:root:Train (Epoch 143): Loss/seq after 03300 batchs: 569.905029296875
INFO:root:Train (Epoch 143): Loss/seq after 03350 batchs: 570.1427001953125
INFO:root:Train (Epoch 143): Loss/seq after 03400 batchs: 565.9134521484375
INFO:root:Train (Epoch 143): Loss/seq after 03450 batchs: 564.440185546875
INFO:root:Train (Epoch 143): Loss/seq after 03500 batchs: 564.8704833984375
INFO:root:Train (Epoch 143): Loss/seq after 03550 batchs: 562.0901489257812
INFO:root:Train (Epoch 143): Loss/seq after 03600 batchs: 570.3782348632812
INFO:root:Train (Epoch 143): Loss/seq after 03650 batchs: 567.6594848632812
INFO:root:Train (Epoch 143): Loss/seq after 03700 batchs: 570.1050415039062
INFO:root:Train (Epoch 143): Loss/seq after 03750 batchs: 574.76220703125
INFO:root:Train (Epoch 143): Loss/seq after 03800 batchs: 572.3402709960938
INFO:root:Train (Epoch 143): Loss/seq after 03850 batchs: 571.1072998046875
INFO:root:Train (Epoch 143): Loss/seq after 03900 batchs: 574.9037475585938
INFO:root:Train (Epoch 143): Loss/seq after 03950 batchs: 578.9614868164062
INFO:root:Train (Epoch 143): Loss/seq after 04000 batchs: 574.8822631835938
INFO:root:Train (Epoch 143): Loss/seq after 04050 batchs: 571.3070068359375
INFO:root:Train (Epoch 143): Loss/seq after 04100 batchs: 569.4286499023438
INFO:root:Train (Epoch 143): Loss/seq after 04150 batchs: 569.1631469726562
INFO:root:Train (Epoch 143): Loss/seq after 04200 batchs: 567.4862670898438
INFO:root:Train (Epoch 143): Loss/seq after 04250 batchs: 565.8063354492188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 143): Loss/seq after 00000 batches: 513.7050170898438
INFO:root:# Valid (Epoch 143): Loss/seq after 00050 batches: 712.3865966796875
INFO:root:# Valid (Epoch 143): Loss/seq after 00100 batches: 734.4118041992188
INFO:root:# Valid (Epoch 143): Loss/seq after 00150 batches: 554.81298828125
INFO:root:# Valid (Epoch 143): Loss/seq after 00200 batches: 514.9008178710938
INFO:root:Artifacts: Make stick videos for epoch 143
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_143_on_20220414_032830.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_143_index_262_on_20220414_032830.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 144): Loss/seq after 00000 batchs: 1025.5360107421875
INFO:root:Train (Epoch 144): Loss/seq after 00050 batchs: 796.9569091796875
INFO:root:Train (Epoch 144): Loss/seq after 00100 batchs: 796.0878295898438
INFO:root:Train (Epoch 144): Loss/seq after 00150 batchs: 723.459716796875
INFO:root:Train (Epoch 144): Loss/seq after 00200 batchs: 785.5233764648438
INFO:root:Train (Epoch 144): Loss/seq after 00250 batchs: 878.6069946289062
INFO:root:Train (Epoch 144): Loss/seq after 00300 batchs: 877.7144775390625
INFO:root:Train (Epoch 144): Loss/seq after 00350 batchs: 821.7383422851562
INFO:root:Train (Epoch 144): Loss/seq after 00400 batchs: 822.1234741210938
INFO:root:Train (Epoch 144): Loss/seq after 00450 batchs: 804.826416015625
INFO:root:Train (Epoch 144): Loss/seq after 00500 batchs: 780.5794067382812
INFO:root:Train (Epoch 144): Loss/seq after 00550 batchs: 757.0222778320312
INFO:root:Train (Epoch 144): Loss/seq after 00600 batchs: 730.3255615234375
INFO:root:Train (Epoch 144): Loss/seq after 00650 batchs: 711.0556640625
INFO:root:Train (Epoch 144): Loss/seq after 00700 batchs: 686.1824340820312
INFO:root:Train (Epoch 144): Loss/seq after 00750 batchs: 693.5689086914062
INFO:root:Train (Epoch 144): Loss/seq after 00800 batchs: 695.4739379882812
INFO:root:Train (Epoch 144): Loss/seq after 00850 batchs: 674.0531616210938
INFO:root:Train (Epoch 144): Loss/seq after 00900 batchs: 659.8458251953125
INFO:root:Train (Epoch 144): Loss/seq after 00950 batchs: 656.9917602539062
INFO:root:Train (Epoch 144): Loss/seq after 01000 batchs: 649.0681762695312
INFO:root:Train (Epoch 144): Loss/seq after 01050 batchs: 637.8255615234375
INFO:root:Train (Epoch 144): Loss/seq after 01100 batchs: 628.7113037109375
INFO:root:Train (Epoch 144): Loss/seq after 01150 batchs: 613.916748046875
INFO:root:Train (Epoch 144): Loss/seq after 01200 batchs: 618.0300903320312
INFO:root:Train (Epoch 144): Loss/seq after 01250 batchs: 616.0601806640625
INFO:root:Train (Epoch 144): Loss/seq after 01300 batchs: 604.6284790039062
INFO:root:Train (Epoch 144): Loss/seq after 01350 batchs: 595.5757446289062
INFO:root:Train (Epoch 144): Loss/seq after 01400 batchs: 601.1980590820312
INFO:root:Train (Epoch 144): Loss/seq after 01450 batchs: 602.6908569335938
INFO:root:Train (Epoch 144): Loss/seq after 01500 batchs: 608.9156494140625
INFO:root:Train (Epoch 144): Loss/seq after 01550 batchs: 610.6002197265625
INFO:root:Train (Epoch 144): Loss/seq after 01600 batchs: 605.1849365234375
INFO:root:Train (Epoch 144): Loss/seq after 01650 batchs: 602.6961669921875
INFO:root:Train (Epoch 144): Loss/seq after 01700 batchs: 604.5095825195312
INFO:root:Train (Epoch 144): Loss/seq after 01750 batchs: 601.6657104492188
INFO:root:Train (Epoch 144): Loss/seq after 01800 batchs: 598.3637084960938
INFO:root:Train (Epoch 144): Loss/seq after 01850 batchs: 594.0794067382812
INFO:root:Train (Epoch 144): Loss/seq after 01900 batchs: 594.77685546875
INFO:root:Train (Epoch 144): Loss/seq after 01950 batchs: 593.123046875
INFO:root:Train (Epoch 144): Loss/seq after 02000 batchs: 591.6275634765625
INFO:root:Train (Epoch 144): Loss/seq after 02050 batchs: 589.9885864257812
INFO:root:Train (Epoch 144): Loss/seq after 02100 batchs: 586.7797241210938
INFO:root:Train (Epoch 144): Loss/seq after 02150 batchs: 584.5106811523438
INFO:root:Train (Epoch 144): Loss/seq after 02200 batchs: 581.4644775390625
INFO:root:Train (Epoch 144): Loss/seq after 02250 batchs: 580.0398559570312
INFO:root:Train (Epoch 144): Loss/seq after 02300 batchs: 577.133056640625
INFO:root:Train (Epoch 144): Loss/seq after 02350 batchs: 572.6226806640625
INFO:root:Train (Epoch 144): Loss/seq after 02400 batchs: 574.1602172851562
INFO:root:Train (Epoch 144): Loss/seq after 02450 batchs: 569.212890625
INFO:root:Train (Epoch 144): Loss/seq after 02500 batchs: 560.9237670898438
INFO:root:Train (Epoch 144): Loss/seq after 02550 batchs: 554.7400512695312
INFO:root:Train (Epoch 144): Loss/seq after 02600 batchs: 553.733642578125
INFO:root:Train (Epoch 144): Loss/seq after 02650 batchs: 551.59375
INFO:root:Train (Epoch 144): Loss/seq after 02700 batchs: 549.432861328125
INFO:root:Train (Epoch 144): Loss/seq after 02750 batchs: 547.3858642578125
INFO:root:Train (Epoch 144): Loss/seq after 02800 batchs: 548.1104125976562
INFO:root:Train (Epoch 144): Loss/seq after 02850 batchs: 548.2496337890625
INFO:root:Train (Epoch 144): Loss/seq after 02900 batchs: 549.8489990234375
INFO:root:Train (Epoch 144): Loss/seq after 02950 batchs: 548.8839111328125
INFO:root:Train (Epoch 144): Loss/seq after 03000 batchs: 553.9271850585938
INFO:root:Train (Epoch 144): Loss/seq after 03050 batchs: 556.021484375
INFO:root:Train (Epoch 144): Loss/seq after 03100 batchs: 559.3069458007812
INFO:root:Train (Epoch 144): Loss/seq after 03150 batchs: 563.6624755859375
INFO:root:Train (Epoch 144): Loss/seq after 03200 batchs: 565.304931640625
INFO:root:Train (Epoch 144): Loss/seq after 03250 batchs: 568.9603271484375
INFO:root:Train (Epoch 144): Loss/seq after 03300 batchs: 568.3236083984375
INFO:root:Train (Epoch 144): Loss/seq after 03350 batchs: 569.0031127929688
INFO:root:Train (Epoch 144): Loss/seq after 03400 batchs: 564.8173217773438
INFO:root:Train (Epoch 144): Loss/seq after 03450 batchs: 563.4067993164062
INFO:root:Train (Epoch 144): Loss/seq after 03500 batchs: 563.81640625
INFO:root:Train (Epoch 144): Loss/seq after 03550 batchs: 560.9318237304688
INFO:root:Train (Epoch 144): Loss/seq after 03600 batchs: 568.6015625
INFO:root:Train (Epoch 144): Loss/seq after 03650 batchs: 565.9059448242188
INFO:root:Train (Epoch 144): Loss/seq after 03700 batchs: 568.5115356445312
INFO:root:Train (Epoch 144): Loss/seq after 03750 batchs: 573.2075805664062
INFO:root:Train (Epoch 144): Loss/seq after 03800 batchs: 570.7884521484375
INFO:root:Train (Epoch 144): Loss/seq after 03850 batchs: 569.5526123046875
INFO:root:Train (Epoch 144): Loss/seq after 03900 batchs: 573.2537841796875
INFO:root:Train (Epoch 144): Loss/seq after 03950 batchs: 577.2382202148438
INFO:root:Train (Epoch 144): Loss/seq after 04000 batchs: 573.2116088867188
INFO:root:Train (Epoch 144): Loss/seq after 04050 batchs: 569.629638671875
INFO:root:Train (Epoch 144): Loss/seq after 04100 batchs: 567.7154541015625
INFO:root:Train (Epoch 144): Loss/seq after 04150 batchs: 567.4500732421875
INFO:root:Train (Epoch 144): Loss/seq after 04200 batchs: 565.8607177734375
INFO:root:Train (Epoch 144): Loss/seq after 04250 batchs: 564.0921630859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 144): Loss/seq after 00000 batches: 516.9341430664062
INFO:root:# Valid (Epoch 144): Loss/seq after 00050 batches: 785.6904296875
INFO:root:# Valid (Epoch 144): Loss/seq after 00100 batches: 774.5575561523438
INFO:root:# Valid (Epoch 144): Loss/seq after 00150 batches: 578.5112915039062
INFO:root:# Valid (Epoch 144): Loss/seq after 00200 batches: 529.9710083007812
INFO:root:Artifacts: Make stick videos for epoch 144
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_144_on_20220414_033348.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_144_index_283_on_20220414_033348.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 145): Loss/seq after 00000 batchs: 1088.6505126953125
INFO:root:Train (Epoch 145): Loss/seq after 00050 batchs: 786.14501953125
INFO:root:Train (Epoch 145): Loss/seq after 00100 batchs: 787.4176635742188
INFO:root:Train (Epoch 145): Loss/seq after 00150 batchs: 715.8289794921875
INFO:root:Train (Epoch 145): Loss/seq after 00200 batchs: 782.6351928710938
INFO:root:Train (Epoch 145): Loss/seq after 00250 batchs: 875.225830078125
INFO:root:Train (Epoch 145): Loss/seq after 00300 batchs: 874.0419311523438
INFO:root:Train (Epoch 145): Loss/seq after 00350 batchs: 818.3422241210938
INFO:root:Train (Epoch 145): Loss/seq after 00400 batchs: 821.8887939453125
INFO:root:Train (Epoch 145): Loss/seq after 00450 batchs: 804.8765869140625
INFO:root:Train (Epoch 145): Loss/seq after 00500 batchs: 778.6337280273438
INFO:root:Train (Epoch 145): Loss/seq after 00550 batchs: 754.14404296875
INFO:root:Train (Epoch 145): Loss/seq after 00600 batchs: 728.5225219726562
INFO:root:Train (Epoch 145): Loss/seq after 00650 batchs: 709.8829956054688
INFO:root:Train (Epoch 145): Loss/seq after 00700 batchs: 685.7324829101562
INFO:root:Train (Epoch 145): Loss/seq after 00750 batchs: 694.171875
INFO:root:Train (Epoch 145): Loss/seq after 00800 batchs: 695.9736328125
INFO:root:Train (Epoch 145): Loss/seq after 00850 batchs: 674.1618041992188
INFO:root:Train (Epoch 145): Loss/seq after 00900 batchs: 660.9261474609375
INFO:root:Train (Epoch 145): Loss/seq after 00950 batchs: 658.9751586914062
INFO:root:Train (Epoch 145): Loss/seq after 01000 batchs: 650.2803344726562
INFO:root:Train (Epoch 145): Loss/seq after 01050 batchs: 639.2781982421875
INFO:root:Train (Epoch 145): Loss/seq after 01100 batchs: 630.2982177734375
INFO:root:Train (Epoch 145): Loss/seq after 01150 batchs: 615.3966674804688
INFO:root:Train (Epoch 145): Loss/seq after 01200 batchs: 619.4271240234375
INFO:root:Train (Epoch 145): Loss/seq after 01250 batchs: 617.5317993164062
INFO:root:Train (Epoch 145): Loss/seq after 01300 batchs: 605.8850708007812
INFO:root:Train (Epoch 145): Loss/seq after 01350 batchs: 596.8348388671875
INFO:root:Train (Epoch 145): Loss/seq after 01400 batchs: 602.5415649414062
INFO:root:Train (Epoch 145): Loss/seq after 01450 batchs: 603.98779296875
INFO:root:Train (Epoch 145): Loss/seq after 01500 batchs: 609.9921264648438
INFO:root:Train (Epoch 145): Loss/seq after 01550 batchs: 611.8134155273438
INFO:root:Train (Epoch 145): Loss/seq after 01600 batchs: 606.4793090820312
INFO:root:Train (Epoch 145): Loss/seq after 01650 batchs: 603.9094848632812
INFO:root:Train (Epoch 145): Loss/seq after 01700 batchs: 605.6292724609375
INFO:root:Train (Epoch 145): Loss/seq after 01750 batchs: 602.7040405273438
INFO:root:Train (Epoch 145): Loss/seq after 01800 batchs: 599.3057250976562
INFO:root:Train (Epoch 145): Loss/seq after 01850 batchs: 595.0596923828125
INFO:root:Train (Epoch 145): Loss/seq after 01900 batchs: 595.7280883789062
INFO:root:Train (Epoch 145): Loss/seq after 01950 batchs: 594.1635131835938
INFO:root:Train (Epoch 145): Loss/seq after 02000 batchs: 592.5741577148438
INFO:root:Train (Epoch 145): Loss/seq after 02050 batchs: 590.7667846679688
INFO:root:Train (Epoch 145): Loss/seq after 02100 batchs: 587.4613647460938
INFO:root:Train (Epoch 145): Loss/seq after 02150 batchs: 585.0923461914062
INFO:root:Train (Epoch 145): Loss/seq after 02200 batchs: 581.8741455078125
INFO:root:Train (Epoch 145): Loss/seq after 02250 batchs: 580.3043823242188
INFO:root:Train (Epoch 145): Loss/seq after 02300 batchs: 577.3379516601562
INFO:root:Train (Epoch 145): Loss/seq after 02350 batchs: 573.1685791015625
INFO:root:Train (Epoch 145): Loss/seq after 02400 batchs: 574.6705322265625
INFO:root:Train (Epoch 145): Loss/seq after 02450 batchs: 569.7159423828125
INFO:root:Train (Epoch 145): Loss/seq after 02500 batchs: 561.4088134765625
INFO:root:Train (Epoch 145): Loss/seq after 02550 batchs: 555.2205200195312
INFO:root:Train (Epoch 145): Loss/seq after 02600 batchs: 554.2536010742188
INFO:root:Train (Epoch 145): Loss/seq after 02650 batchs: 552.148681640625
INFO:root:Train (Epoch 145): Loss/seq after 02700 batchs: 549.8009643554688
INFO:root:Train (Epoch 145): Loss/seq after 02750 batchs: 547.9434204101562
INFO:root:Train (Epoch 145): Loss/seq after 02800 batchs: 548.2662353515625
INFO:root:Train (Epoch 145): Loss/seq after 02850 batchs: 548.0156860351562
INFO:root:Train (Epoch 145): Loss/seq after 02900 batchs: 549.3529052734375
INFO:root:Train (Epoch 145): Loss/seq after 02950 batchs: 548.2860107421875
INFO:root:Train (Epoch 145): Loss/seq after 03000 batchs: 553.29296875
INFO:root:Train (Epoch 145): Loss/seq after 03050 batchs: 555.1818237304688
INFO:root:Train (Epoch 145): Loss/seq after 03100 batchs: 558.3026123046875
INFO:root:Train (Epoch 145): Loss/seq after 03150 batchs: 562.2694702148438
INFO:root:Train (Epoch 145): Loss/seq after 03200 batchs: 563.4669189453125
INFO:root:Train (Epoch 145): Loss/seq after 03250 batchs: 566.7022705078125
INFO:root:Train (Epoch 145): Loss/seq after 03300 batchs: 565.8880615234375
INFO:root:Train (Epoch 145): Loss/seq after 03350 batchs: 566.3033447265625
INFO:root:Train (Epoch 145): Loss/seq after 03400 batchs: 562.1572265625
INFO:root:Train (Epoch 145): Loss/seq after 03450 batchs: 560.9124145507812
INFO:root:Train (Epoch 145): Loss/seq after 03500 batchs: 561.55810546875
INFO:root:Train (Epoch 145): Loss/seq after 03550 batchs: 558.9330444335938
INFO:root:Train (Epoch 145): Loss/seq after 03600 batchs: 566.9590454101562
INFO:root:Train (Epoch 145): Loss/seq after 03650 batchs: 564.2991943359375
INFO:root:Train (Epoch 145): Loss/seq after 03700 batchs: 566.961181640625
INFO:root:Train (Epoch 145): Loss/seq after 03750 batchs: 571.6390991210938
INFO:root:Train (Epoch 145): Loss/seq after 03800 batchs: 569.204345703125
INFO:root:Train (Epoch 145): Loss/seq after 03850 batchs: 568.0333862304688
INFO:root:Train (Epoch 145): Loss/seq after 03900 batchs: 571.8430786132812
INFO:root:Train (Epoch 145): Loss/seq after 03950 batchs: 575.7380981445312
INFO:root:Train (Epoch 145): Loss/seq after 04000 batchs: 571.673583984375
INFO:root:Train (Epoch 145): Loss/seq after 04050 batchs: 568.1360473632812
INFO:root:Train (Epoch 145): Loss/seq after 04100 batchs: 566.2945556640625
INFO:root:Train (Epoch 145): Loss/seq after 04150 batchs: 566.0233154296875
INFO:root:Train (Epoch 145): Loss/seq after 04200 batchs: 564.37548828125
INFO:root:Train (Epoch 145): Loss/seq after 04250 batchs: 562.5613403320312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 145): Loss/seq after 00000 batches: 503.8107604980469
INFO:root:# Valid (Epoch 145): Loss/seq after 00050 batches: 786.7855834960938
INFO:root:# Valid (Epoch 145): Loss/seq after 00100 batches: 779.7913818359375
INFO:root:# Valid (Epoch 145): Loss/seq after 00150 batches: 582.760009765625
INFO:root:# Valid (Epoch 145): Loss/seq after 00200 batches: 533.1714477539062
INFO:root:Artifacts: Make stick videos for epoch 145
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_145_on_20220414_033906.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_145_index_797_on_20220414_033906.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 146): Loss/seq after 00000 batchs: 1001.3871459960938
INFO:root:Train (Epoch 146): Loss/seq after 00050 batchs: 781.77490234375
INFO:root:Train (Epoch 146): Loss/seq after 00100 batchs: 776.55615234375
INFO:root:Train (Epoch 146): Loss/seq after 00150 batchs: 708.2277221679688
INFO:root:Train (Epoch 146): Loss/seq after 00200 batchs: 771.3051147460938
INFO:root:Train (Epoch 146): Loss/seq after 00250 batchs: 861.6668701171875
INFO:root:Train (Epoch 146): Loss/seq after 00300 batchs: 861.4910888671875
INFO:root:Train (Epoch 146): Loss/seq after 00350 batchs: 807.6087036132812
INFO:root:Train (Epoch 146): Loss/seq after 00400 batchs: 811.63330078125
INFO:root:Train (Epoch 146): Loss/seq after 00450 batchs: 795.8616333007812
INFO:root:Train (Epoch 146): Loss/seq after 00500 batchs: 770.6827392578125
INFO:root:Train (Epoch 146): Loss/seq after 00550 batchs: 746.6529541015625
INFO:root:Train (Epoch 146): Loss/seq after 00600 batchs: 719.9754028320312
INFO:root:Train (Epoch 146): Loss/seq after 00650 batchs: 699.8990478515625
INFO:root:Train (Epoch 146): Loss/seq after 00700 batchs: 676.55078125
INFO:root:Train (Epoch 146): Loss/seq after 00750 batchs: 683.729248046875
INFO:root:Train (Epoch 146): Loss/seq after 00800 batchs: 685.8282470703125
INFO:root:Train (Epoch 146): Loss/seq after 00850 batchs: 664.6117553710938
INFO:root:Train (Epoch 146): Loss/seq after 00900 batchs: 650.6094970703125
INFO:root:Train (Epoch 146): Loss/seq after 00950 batchs: 647.9775390625
INFO:root:Train (Epoch 146): Loss/seq after 01000 batchs: 639.6178588867188
INFO:root:Train (Epoch 146): Loss/seq after 01050 batchs: 628.7106323242188
INFO:root:Train (Epoch 146): Loss/seq after 01100 batchs: 620.1347045898438
INFO:root:Train (Epoch 146): Loss/seq after 01150 batchs: 605.8207397460938
INFO:root:Train (Epoch 146): Loss/seq after 01200 batchs: 610.5106811523438
INFO:root:Train (Epoch 146): Loss/seq after 01250 batchs: 608.9320068359375
INFO:root:Train (Epoch 146): Loss/seq after 01300 batchs: 597.7374267578125
INFO:root:Train (Epoch 146): Loss/seq after 01350 batchs: 588.7731323242188
INFO:root:Train (Epoch 146): Loss/seq after 01400 batchs: 594.2836303710938
INFO:root:Train (Epoch 146): Loss/seq after 01450 batchs: 596.1400756835938
INFO:root:Train (Epoch 146): Loss/seq after 01500 batchs: 602.4533081054688
INFO:root:Train (Epoch 146): Loss/seq after 01550 batchs: 604.3697509765625
INFO:root:Train (Epoch 146): Loss/seq after 01600 batchs: 598.9710693359375
INFO:root:Train (Epoch 146): Loss/seq after 01650 batchs: 596.7877197265625
INFO:root:Train (Epoch 146): Loss/seq after 01700 batchs: 599.1455688476562
INFO:root:Train (Epoch 146): Loss/seq after 01750 batchs: 596.3645629882812
INFO:root:Train (Epoch 146): Loss/seq after 01800 batchs: 593.0820922851562
INFO:root:Train (Epoch 146): Loss/seq after 01850 batchs: 588.9212646484375
INFO:root:Train (Epoch 146): Loss/seq after 01900 batchs: 589.53955078125
INFO:root:Train (Epoch 146): Loss/seq after 01950 batchs: 587.9736328125
INFO:root:Train (Epoch 146): Loss/seq after 02000 batchs: 586.529296875
INFO:root:Train (Epoch 146): Loss/seq after 02050 batchs: 584.88671875
INFO:root:Train (Epoch 146): Loss/seq after 02100 batchs: 581.8543090820312
INFO:root:Train (Epoch 146): Loss/seq after 02150 batchs: 579.6234741210938
INFO:root:Train (Epoch 146): Loss/seq after 02200 batchs: 576.5270385742188
INFO:root:Train (Epoch 146): Loss/seq after 02250 batchs: 574.9541015625
INFO:root:Train (Epoch 146): Loss/seq after 02300 batchs: 571.8781127929688
INFO:root:Train (Epoch 146): Loss/seq after 02350 batchs: 567.41357421875
INFO:root:Train (Epoch 146): Loss/seq after 02400 batchs: 568.9539184570312
INFO:root:Train (Epoch 146): Loss/seq after 02450 batchs: 564.0641479492188
INFO:root:Train (Epoch 146): Loss/seq after 02500 batchs: 555.863525390625
INFO:root:Train (Epoch 146): Loss/seq after 02550 batchs: 549.7880859375
INFO:root:Train (Epoch 146): Loss/seq after 02600 batchs: 548.8219604492188
INFO:root:Train (Epoch 146): Loss/seq after 02650 batchs: 546.6719360351562
INFO:root:Train (Epoch 146): Loss/seq after 02700 batchs: 544.5645141601562
INFO:root:Train (Epoch 146): Loss/seq after 02750 batchs: 542.4896850585938
INFO:root:Train (Epoch 146): Loss/seq after 02800 batchs: 542.7172241210938
INFO:root:Train (Epoch 146): Loss/seq after 02850 batchs: 542.4840698242188
INFO:root:Train (Epoch 146): Loss/seq after 02900 batchs: 543.6116333007812
INFO:root:Train (Epoch 146): Loss/seq after 02950 batchs: 542.6470947265625
INFO:root:Train (Epoch 146): Loss/seq after 03000 batchs: 547.7811279296875
INFO:root:Train (Epoch 146): Loss/seq after 03050 batchs: 549.796630859375
INFO:root:Train (Epoch 146): Loss/seq after 03100 batchs: 553.031005859375
INFO:root:Train (Epoch 146): Loss/seq after 03150 batchs: 556.7606811523438
INFO:root:Train (Epoch 146): Loss/seq after 03200 batchs: 558.3191528320312
INFO:root:Train (Epoch 146): Loss/seq after 03250 batchs: 561.6083984375
INFO:root:Train (Epoch 146): Loss/seq after 03300 batchs: 560.6303100585938
INFO:root:Train (Epoch 146): Loss/seq after 03350 batchs: 560.7675170898438
INFO:root:Train (Epoch 146): Loss/seq after 03400 batchs: 556.623779296875
INFO:root:Train (Epoch 146): Loss/seq after 03450 batchs: 555.26416015625
INFO:root:Train (Epoch 146): Loss/seq after 03500 batchs: 555.7650146484375
INFO:root:Train (Epoch 146): Loss/seq after 03550 batchs: 552.9979248046875
INFO:root:Train (Epoch 146): Loss/seq after 03600 batchs: 560.5183715820312
INFO:root:Train (Epoch 146): Loss/seq after 03650 batchs: 557.8785400390625
INFO:root:Train (Epoch 146): Loss/seq after 03700 batchs: 560.5675659179688
INFO:root:Train (Epoch 146): Loss/seq after 03750 batchs: 565.2755737304688
INFO:root:Train (Epoch 146): Loss/seq after 03800 batchs: 562.9910278320312
INFO:root:Train (Epoch 146): Loss/seq after 03850 batchs: 561.7568359375
INFO:root:Train (Epoch 146): Loss/seq after 03900 batchs: 565.5081176757812
INFO:root:Train (Epoch 146): Loss/seq after 03950 batchs: 569.3788452148438
INFO:root:Train (Epoch 146): Loss/seq after 04000 batchs: 565.4036254882812
INFO:root:Train (Epoch 146): Loss/seq after 04050 batchs: 561.8992309570312
INFO:root:Train (Epoch 146): Loss/seq after 04100 batchs: 560.0956420898438
INFO:root:Train (Epoch 146): Loss/seq after 04150 batchs: 559.7885131835938
INFO:root:Train (Epoch 146): Loss/seq after 04200 batchs: 558.20556640625
INFO:root:Train (Epoch 146): Loss/seq after 04250 batchs: 556.4371337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 146): Loss/seq after 00000 batches: 521.89208984375
INFO:root:# Valid (Epoch 146): Loss/seq after 00050 batches: 779.395263671875
INFO:root:# Valid (Epoch 146): Loss/seq after 00100 batches: 790.1236572265625
INFO:root:# Valid (Epoch 146): Loss/seq after 00150 batches: 592.8599853515625
INFO:root:# Valid (Epoch 146): Loss/seq after 00200 batches: 546.6535034179688
INFO:root:Artifacts: Make stick videos for epoch 146
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_146_on_20220414_034424.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_146_index_339_on_20220414_034424.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 147): Loss/seq after 00000 batchs: 955.585205078125
INFO:root:Train (Epoch 147): Loss/seq after 00050 batchs: 795.2559814453125
INFO:root:Train (Epoch 147): Loss/seq after 00100 batchs: 787.0596923828125
INFO:root:Train (Epoch 147): Loss/seq after 00150 batchs: 717.8829345703125
INFO:root:Train (Epoch 147): Loss/seq after 00200 batchs: 782.211669921875
INFO:root:Train (Epoch 147): Loss/seq after 00250 batchs: 873.497314453125
INFO:root:Train (Epoch 147): Loss/seq after 00300 batchs: 871.99658203125
INFO:root:Train (Epoch 147): Loss/seq after 00350 batchs: 816.7382202148438
INFO:root:Train (Epoch 147): Loss/seq after 00400 batchs: 816.7246704101562
INFO:root:Train (Epoch 147): Loss/seq after 00450 batchs: 799.9556884765625
INFO:root:Train (Epoch 147): Loss/seq after 00500 batchs: 774.3516235351562
INFO:root:Train (Epoch 147): Loss/seq after 00550 batchs: 749.8695068359375
INFO:root:Train (Epoch 147): Loss/seq after 00600 batchs: 722.697998046875
INFO:root:Train (Epoch 147): Loss/seq after 00650 batchs: 702.0635986328125
INFO:root:Train (Epoch 147): Loss/seq after 00700 batchs: 677.6724243164062
INFO:root:Train (Epoch 147): Loss/seq after 00750 batchs: 686.5758056640625
INFO:root:Train (Epoch 147): Loss/seq after 00800 batchs: 688.994384765625
INFO:root:Train (Epoch 147): Loss/seq after 00850 batchs: 667.3016967773438
INFO:root:Train (Epoch 147): Loss/seq after 00900 batchs: 653.4200439453125
INFO:root:Train (Epoch 147): Loss/seq after 00950 batchs: 651.4542846679688
INFO:root:Train (Epoch 147): Loss/seq after 01000 batchs: 643.3926391601562
INFO:root:Train (Epoch 147): Loss/seq after 01050 batchs: 633.0263671875
INFO:root:Train (Epoch 147): Loss/seq after 01100 batchs: 625.4058837890625
INFO:root:Train (Epoch 147): Loss/seq after 01150 batchs: 610.8970947265625
INFO:root:Train (Epoch 147): Loss/seq after 01200 batchs: 615.1810302734375
INFO:root:Train (Epoch 147): Loss/seq after 01250 batchs: 613.7129516601562
INFO:root:Train (Epoch 147): Loss/seq after 01300 batchs: 602.4382934570312
INFO:root:Train (Epoch 147): Loss/seq after 01350 batchs: 593.171875
INFO:root:Train (Epoch 147): Loss/seq after 01400 batchs: 597.96240234375
INFO:root:Train (Epoch 147): Loss/seq after 01450 batchs: 599.4673461914062
INFO:root:Train (Epoch 147): Loss/seq after 01500 batchs: 605.62646484375
INFO:root:Train (Epoch 147): Loss/seq after 01550 batchs: 607.60107421875
INFO:root:Train (Epoch 147): Loss/seq after 01600 batchs: 602.1215209960938
INFO:root:Train (Epoch 147): Loss/seq after 01650 batchs: 599.724365234375
INFO:root:Train (Epoch 147): Loss/seq after 01700 batchs: 601.5904541015625
INFO:root:Train (Epoch 147): Loss/seq after 01750 batchs: 598.8165283203125
INFO:root:Train (Epoch 147): Loss/seq after 01800 batchs: 595.3947143554688
INFO:root:Train (Epoch 147): Loss/seq after 01850 batchs: 591.0450439453125
INFO:root:Train (Epoch 147): Loss/seq after 01900 batchs: 591.6097412109375
INFO:root:Train (Epoch 147): Loss/seq after 01950 batchs: 589.8582153320312
INFO:root:Train (Epoch 147): Loss/seq after 02000 batchs: 588.4513549804688
INFO:root:Train (Epoch 147): Loss/seq after 02050 batchs: 586.6880493164062
INFO:root:Train (Epoch 147): Loss/seq after 02100 batchs: 583.6305541992188
INFO:root:Train (Epoch 147): Loss/seq after 02150 batchs: 581.21728515625
INFO:root:Train (Epoch 147): Loss/seq after 02200 batchs: 577.9598999023438
INFO:root:Train (Epoch 147): Loss/seq after 02250 batchs: 576.1593017578125
INFO:root:Train (Epoch 147): Loss/seq after 02300 batchs: 573.2745971679688
INFO:root:Train (Epoch 147): Loss/seq after 02350 batchs: 568.7251586914062
INFO:root:Train (Epoch 147): Loss/seq after 02400 batchs: 570.2022094726562
INFO:root:Train (Epoch 147): Loss/seq after 02450 batchs: 565.1974487304688
INFO:root:Train (Epoch 147): Loss/seq after 02500 batchs: 556.9076538085938
INFO:root:Train (Epoch 147): Loss/seq after 02550 batchs: 550.8104248046875
INFO:root:Train (Epoch 147): Loss/seq after 02600 batchs: 549.64404296875
INFO:root:Train (Epoch 147): Loss/seq after 02650 batchs: 547.4845581054688
INFO:root:Train (Epoch 147): Loss/seq after 02700 batchs: 545.343505859375
INFO:root:Train (Epoch 147): Loss/seq after 02750 batchs: 543.273681640625
INFO:root:Train (Epoch 147): Loss/seq after 02800 batchs: 543.2554321289062
INFO:root:Train (Epoch 147): Loss/seq after 02850 batchs: 543.0532836914062
INFO:root:Train (Epoch 147): Loss/seq after 02900 batchs: 544.1538696289062
INFO:root:Train (Epoch 147): Loss/seq after 02950 batchs: 543.2136840820312
INFO:root:Train (Epoch 147): Loss/seq after 03000 batchs: 548.3219604492188
INFO:root:Train (Epoch 147): Loss/seq after 03050 batchs: 550.2242431640625
INFO:root:Train (Epoch 147): Loss/seq after 03100 batchs: 553.0531616210938
INFO:root:Train (Epoch 147): Loss/seq after 03150 batchs: 556.6897583007812
INFO:root:Train (Epoch 147): Loss/seq after 03200 batchs: 557.7637329101562
INFO:root:Train (Epoch 147): Loss/seq after 03250 batchs: 560.7626953125
INFO:root:Train (Epoch 147): Loss/seq after 03300 batchs: 559.8455810546875
INFO:root:Train (Epoch 147): Loss/seq after 03350 batchs: 560.035400390625
INFO:root:Train (Epoch 147): Loss/seq after 03400 batchs: 555.97509765625
INFO:root:Train (Epoch 147): Loss/seq after 03450 batchs: 554.6041259765625
INFO:root:Train (Epoch 147): Loss/seq after 03500 batchs: 555.0606079101562
INFO:root:Train (Epoch 147): Loss/seq after 03550 batchs: 552.2020263671875
INFO:root:Train (Epoch 147): Loss/seq after 03600 batchs: 559.6282348632812
INFO:root:Train (Epoch 147): Loss/seq after 03650 batchs: 557.0598754882812
INFO:root:Train (Epoch 147): Loss/seq after 03700 batchs: 559.8319702148438
INFO:root:Train (Epoch 147): Loss/seq after 03750 batchs: 564.5611572265625
INFO:root:Train (Epoch 147): Loss/seq after 03800 batchs: 562.2809448242188
INFO:root:Train (Epoch 147): Loss/seq after 03850 batchs: 561.23193359375
INFO:root:Train (Epoch 147): Loss/seq after 03900 batchs: 564.85205078125
INFO:root:Train (Epoch 147): Loss/seq after 03950 batchs: 568.7281494140625
INFO:root:Train (Epoch 147): Loss/seq after 04000 batchs: 564.71142578125
INFO:root:Train (Epoch 147): Loss/seq after 04050 batchs: 561.2042846679688
INFO:root:Train (Epoch 147): Loss/seq after 04100 batchs: 559.4029541015625
INFO:root:Train (Epoch 147): Loss/seq after 04150 batchs: 559.1904907226562
INFO:root:Train (Epoch 147): Loss/seq after 04200 batchs: 557.56640625
INFO:root:Train (Epoch 147): Loss/seq after 04250 batchs: 555.931396484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 147): Loss/seq after 00000 batches: 520.7410888671875
INFO:root:# Valid (Epoch 147): Loss/seq after 00050 batches: 695.0515747070312
INFO:root:# Valid (Epoch 147): Loss/seq after 00100 batches: 736.9912719726562
INFO:root:# Valid (Epoch 147): Loss/seq after 00150 batches: 554.9624633789062
INFO:root:# Valid (Epoch 147): Loss/seq after 00200 batches: 512.7134399414062
INFO:root:Artifacts: Make stick videos for epoch 147
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_147_on_20220414_034940.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_147_index_1862_on_20220414_034940.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 148): Loss/seq after 00000 batchs: 1052.3172607421875
INFO:root:Train (Epoch 148): Loss/seq after 00050 batchs: 784.3892211914062
INFO:root:Train (Epoch 148): Loss/seq after 00100 batchs: 782.678955078125
INFO:root:Train (Epoch 148): Loss/seq after 00150 batchs: 712.55859375
INFO:root:Train (Epoch 148): Loss/seq after 00200 batchs: 771.8079223632812
INFO:root:Train (Epoch 148): Loss/seq after 00250 batchs: 862.7566528320312
INFO:root:Train (Epoch 148): Loss/seq after 00300 batchs: 861.7969360351562
INFO:root:Train (Epoch 148): Loss/seq after 00350 batchs: 807.4274291992188
INFO:root:Train (Epoch 148): Loss/seq after 00400 batchs: 810.9142456054688
INFO:root:Train (Epoch 148): Loss/seq after 00450 batchs: 794.9390869140625
INFO:root:Train (Epoch 148): Loss/seq after 00500 batchs: 770.8259887695312
INFO:root:Train (Epoch 148): Loss/seq after 00550 batchs: 748.6753540039062
INFO:root:Train (Epoch 148): Loss/seq after 00600 batchs: 722.9495239257812
INFO:root:Train (Epoch 148): Loss/seq after 00650 batchs: 702.1864624023438
INFO:root:Train (Epoch 148): Loss/seq after 00700 batchs: 677.3197021484375
INFO:root:Train (Epoch 148): Loss/seq after 00750 batchs: 684.6389770507812
INFO:root:Train (Epoch 148): Loss/seq after 00800 batchs: 686.8997802734375
INFO:root:Train (Epoch 148): Loss/seq after 00850 batchs: 665.5048217773438
INFO:root:Train (Epoch 148): Loss/seq after 00900 batchs: 651.5667724609375
INFO:root:Train (Epoch 148): Loss/seq after 00950 batchs: 649.5343627929688
INFO:root:Train (Epoch 148): Loss/seq after 01000 batchs: 641.08154296875
INFO:root:Train (Epoch 148): Loss/seq after 01050 batchs: 629.829345703125
INFO:root:Train (Epoch 148): Loss/seq after 01100 batchs: 620.9461059570312
INFO:root:Train (Epoch 148): Loss/seq after 01150 batchs: 606.0806274414062
INFO:root:Train (Epoch 148): Loss/seq after 01200 batchs: 610.4738159179688
INFO:root:Train (Epoch 148): Loss/seq after 01250 batchs: 608.778076171875
INFO:root:Train (Epoch 148): Loss/seq after 01300 batchs: 597.2846069335938
INFO:root:Train (Epoch 148): Loss/seq after 01350 batchs: 588.1886596679688
INFO:root:Train (Epoch 148): Loss/seq after 01400 batchs: 592.8702392578125
INFO:root:Train (Epoch 148): Loss/seq after 01450 batchs: 594.6143798828125
INFO:root:Train (Epoch 148): Loss/seq after 01500 batchs: 600.8007202148438
INFO:root:Train (Epoch 148): Loss/seq after 01550 batchs: 602.1802978515625
INFO:root:Train (Epoch 148): Loss/seq after 01600 batchs: 596.7283935546875
INFO:root:Train (Epoch 148): Loss/seq after 01650 batchs: 594.2703247070312
INFO:root:Train (Epoch 148): Loss/seq after 01700 batchs: 596.3336181640625
INFO:root:Train (Epoch 148): Loss/seq after 01750 batchs: 593.4832153320312
INFO:root:Train (Epoch 148): Loss/seq after 01800 batchs: 590.1828002929688
INFO:root:Train (Epoch 148): Loss/seq after 01850 batchs: 585.994873046875
INFO:root:Train (Epoch 148): Loss/seq after 01900 batchs: 586.703857421875
INFO:root:Train (Epoch 148): Loss/seq after 01950 batchs: 585.2225341796875
INFO:root:Train (Epoch 148): Loss/seq after 02000 batchs: 583.7974853515625
INFO:root:Train (Epoch 148): Loss/seq after 02050 batchs: 582.1350708007812
INFO:root:Train (Epoch 148): Loss/seq after 02100 batchs: 579.0656127929688
INFO:root:Train (Epoch 148): Loss/seq after 02150 batchs: 576.6973876953125
INFO:root:Train (Epoch 148): Loss/seq after 02200 batchs: 573.64697265625
INFO:root:Train (Epoch 148): Loss/seq after 02250 batchs: 572.1336059570312
INFO:root:Train (Epoch 148): Loss/seq after 02300 batchs: 569.2188720703125
INFO:root:Train (Epoch 148): Loss/seq after 02350 batchs: 564.91845703125
INFO:root:Train (Epoch 148): Loss/seq after 02400 batchs: 566.4641723632812
INFO:root:Train (Epoch 148): Loss/seq after 02450 batchs: 561.5646362304688
INFO:root:Train (Epoch 148): Loss/seq after 02500 batchs: 553.3826904296875
INFO:root:Train (Epoch 148): Loss/seq after 02550 batchs: 547.35498046875
INFO:root:Train (Epoch 148): Loss/seq after 02600 batchs: 546.4408569335938
INFO:root:Train (Epoch 148): Loss/seq after 02650 batchs: 544.4415283203125
INFO:root:Train (Epoch 148): Loss/seq after 02700 batchs: 542.374755859375
INFO:root:Train (Epoch 148): Loss/seq after 02750 batchs: 540.2520141601562
INFO:root:Train (Epoch 148): Loss/seq after 02800 batchs: 540.4193725585938
INFO:root:Train (Epoch 148): Loss/seq after 02850 batchs: 540.4395141601562
INFO:root:Train (Epoch 148): Loss/seq after 02900 batchs: 541.6912231445312
INFO:root:Train (Epoch 148): Loss/seq after 02950 batchs: 540.7417602539062
INFO:root:Train (Epoch 148): Loss/seq after 03000 batchs: 545.8594970703125
INFO:root:Train (Epoch 148): Loss/seq after 03050 batchs: 547.6611328125
INFO:root:Train (Epoch 148): Loss/seq after 03100 batchs: 550.4398193359375
INFO:root:Train (Epoch 148): Loss/seq after 03150 batchs: 553.6051635742188
INFO:root:Train (Epoch 148): Loss/seq after 03200 batchs: 554.711181640625
INFO:root:Train (Epoch 148): Loss/seq after 03250 batchs: 558.0571899414062
INFO:root:Train (Epoch 148): Loss/seq after 03300 batchs: 557.6188354492188
INFO:root:Train (Epoch 148): Loss/seq after 03350 batchs: 557.7908935546875
INFO:root:Train (Epoch 148): Loss/seq after 03400 batchs: 553.7232666015625
INFO:root:Train (Epoch 148): Loss/seq after 03450 batchs: 552.4313354492188
INFO:root:Train (Epoch 148): Loss/seq after 03500 batchs: 552.8421020507812
INFO:root:Train (Epoch 148): Loss/seq after 03550 batchs: 549.95703125
INFO:root:Train (Epoch 148): Loss/seq after 03600 batchs: 557.5819091796875
INFO:root:Train (Epoch 148): Loss/seq after 03650 batchs: 555.1056518554688
INFO:root:Train (Epoch 148): Loss/seq after 03700 batchs: 557.74658203125
INFO:root:Train (Epoch 148): Loss/seq after 03750 batchs: 562.354248046875
INFO:root:Train (Epoch 148): Loss/seq after 03800 batchs: 560.0948486328125
INFO:root:Train (Epoch 148): Loss/seq after 03850 batchs: 558.956787109375
INFO:root:Train (Epoch 148): Loss/seq after 03900 batchs: 562.5186157226562
INFO:root:Train (Epoch 148): Loss/seq after 03950 batchs: 566.1602783203125
INFO:root:Train (Epoch 148): Loss/seq after 04000 batchs: 562.1752319335938
INFO:root:Train (Epoch 148): Loss/seq after 04050 batchs: 558.708251953125
INFO:root:Train (Epoch 148): Loss/seq after 04100 batchs: 556.8676147460938
INFO:root:Train (Epoch 148): Loss/seq after 04150 batchs: 556.6497802734375
INFO:root:Train (Epoch 148): Loss/seq after 04200 batchs: 555.0303955078125
INFO:root:Train (Epoch 148): Loss/seq after 04250 batchs: 553.2374877929688
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 148): Loss/seq after 00000 batches: 501.2967529296875
INFO:root:# Valid (Epoch 148): Loss/seq after 00050 batches: 812.1665649414062
INFO:root:# Valid (Epoch 148): Loss/seq after 00100 batches: 790.2984008789062
INFO:root:# Valid (Epoch 148): Loss/seq after 00150 batches: 589.380615234375
INFO:root:# Valid (Epoch 148): Loss/seq after 00200 batches: 538.3635864257812
INFO:root:Artifacts: Make stick videos for epoch 148
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_148_on_20220414_035458.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_148_index_150_on_20220414_035458.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 149): Loss/seq after 00000 batchs: 979.4373168945312
INFO:root:Train (Epoch 149): Loss/seq after 00050 batchs: 781.2578125
INFO:root:Train (Epoch 149): Loss/seq after 00100 batchs: 781.3998413085938
INFO:root:Train (Epoch 149): Loss/seq after 00150 batchs: 706.7470092773438
INFO:root:Train (Epoch 149): Loss/seq after 00200 batchs: 768.9570922851562
INFO:root:Train (Epoch 149): Loss/seq after 00250 batchs: 855.0995483398438
INFO:root:Train (Epoch 149): Loss/seq after 00300 batchs: 855.8771362304688
INFO:root:Train (Epoch 149): Loss/seq after 00350 batchs: 802.412841796875
INFO:root:Train (Epoch 149): Loss/seq after 00400 batchs: 804.6364135742188
INFO:root:Train (Epoch 149): Loss/seq after 00450 batchs: 789.0924682617188
INFO:root:Train (Epoch 149): Loss/seq after 00500 batchs: 764.6348876953125
INFO:root:Train (Epoch 149): Loss/seq after 00550 batchs: 740.5914916992188
INFO:root:Train (Epoch 149): Loss/seq after 00600 batchs: 714.6703491210938
INFO:root:Train (Epoch 149): Loss/seq after 00650 batchs: 693.499755859375
INFO:root:Train (Epoch 149): Loss/seq after 00700 batchs: 668.6261596679688
INFO:root:Train (Epoch 149): Loss/seq after 00750 batchs: 676.332275390625
INFO:root:Train (Epoch 149): Loss/seq after 00800 batchs: 679.6859130859375
INFO:root:Train (Epoch 149): Loss/seq after 00850 batchs: 658.6278686523438
INFO:root:Train (Epoch 149): Loss/seq after 00900 batchs: 644.927978515625
INFO:root:Train (Epoch 149): Loss/seq after 00950 batchs: 643.200439453125
INFO:root:Train (Epoch 149): Loss/seq after 01000 batchs: 634.5170288085938
INFO:root:Train (Epoch 149): Loss/seq after 01050 batchs: 623.4656982421875
INFO:root:Train (Epoch 149): Loss/seq after 01100 batchs: 615.0320434570312
INFO:root:Train (Epoch 149): Loss/seq after 01150 batchs: 600.591552734375
INFO:root:Train (Epoch 149): Loss/seq after 01200 batchs: 605.10888671875
INFO:root:Train (Epoch 149): Loss/seq after 01250 batchs: 603.4703979492188
INFO:root:Train (Epoch 149): Loss/seq after 01300 batchs: 592.1468505859375
INFO:root:Train (Epoch 149): Loss/seq after 01350 batchs: 583.4227905273438
INFO:root:Train (Epoch 149): Loss/seq after 01400 batchs: 588.5668334960938
INFO:root:Train (Epoch 149): Loss/seq after 01450 batchs: 590.1713256835938
INFO:root:Train (Epoch 149): Loss/seq after 01500 batchs: 596.3741455078125
INFO:root:Train (Epoch 149): Loss/seq after 01550 batchs: 597.74658203125
INFO:root:Train (Epoch 149): Loss/seq after 01600 batchs: 592.2183837890625
INFO:root:Train (Epoch 149): Loss/seq after 01650 batchs: 589.9171142578125
INFO:root:Train (Epoch 149): Loss/seq after 01700 batchs: 592.0288696289062
INFO:root:Train (Epoch 149): Loss/seq after 01750 batchs: 589.2294311523438
INFO:root:Train (Epoch 149): Loss/seq after 01800 batchs: 585.9951171875
INFO:root:Train (Epoch 149): Loss/seq after 01850 batchs: 581.8403930664062
INFO:root:Train (Epoch 149): Loss/seq after 01900 batchs: 582.2933959960938
INFO:root:Train (Epoch 149): Loss/seq after 01950 batchs: 580.5907592773438
INFO:root:Train (Epoch 149): Loss/seq after 02000 batchs: 579.1990966796875
INFO:root:Train (Epoch 149): Loss/seq after 02050 batchs: 577.5587768554688
INFO:root:Train (Epoch 149): Loss/seq after 02100 batchs: 574.6941528320312
INFO:root:Train (Epoch 149): Loss/seq after 02150 batchs: 572.5658569335938
INFO:root:Train (Epoch 149): Loss/seq after 02200 batchs: 569.6126098632812
INFO:root:Train (Epoch 149): Loss/seq after 02250 batchs: 567.9533081054688
INFO:root:Train (Epoch 149): Loss/seq after 02300 batchs: 565.2919921875
INFO:root:Train (Epoch 149): Loss/seq after 02350 batchs: 561.0989990234375
INFO:root:Train (Epoch 149): Loss/seq after 02400 batchs: 562.777099609375
INFO:root:Train (Epoch 149): Loss/seq after 02450 batchs: 557.9998168945312
INFO:root:Train (Epoch 149): Loss/seq after 02500 batchs: 549.8909912109375
INFO:root:Train (Epoch 149): Loss/seq after 02550 batchs: 543.9050903320312
INFO:root:Train (Epoch 149): Loss/seq after 02600 batchs: 542.9939575195312
INFO:root:Train (Epoch 149): Loss/seq after 02650 batchs: 540.9275512695312
INFO:root:Train (Epoch 149): Loss/seq after 02700 batchs: 538.6071166992188
INFO:root:Train (Epoch 149): Loss/seq after 02750 batchs: 535.9649047851562
INFO:root:Train (Epoch 149): Loss/seq after 02800 batchs: 536.075439453125
INFO:root:Train (Epoch 149): Loss/seq after 02850 batchs: 535.9616088867188
INFO:root:Train (Epoch 149): Loss/seq after 02900 batchs: 537.1795654296875
INFO:root:Train (Epoch 149): Loss/seq after 02950 batchs: 536.3606567382812
INFO:root:Train (Epoch 149): Loss/seq after 03000 batchs: 541.5250244140625
INFO:root:Train (Epoch 149): Loss/seq after 03050 batchs: 543.3945922851562
INFO:root:Train (Epoch 149): Loss/seq after 03100 batchs: 546.49853515625
INFO:root:Train (Epoch 149): Loss/seq after 03150 batchs: 549.7233276367188
INFO:root:Train (Epoch 149): Loss/seq after 03200 batchs: 550.9221801757812
INFO:root:Train (Epoch 149): Loss/seq after 03250 batchs: 553.6728515625
INFO:root:Train (Epoch 149): Loss/seq after 03300 batchs: 553.2131958007812
INFO:root:Train (Epoch 149): Loss/seq after 03350 batchs: 553.6277465820312
INFO:root:Train (Epoch 149): Loss/seq after 03400 batchs: 549.6311645507812
INFO:root:Train (Epoch 149): Loss/seq after 03450 batchs: 548.2597045898438
INFO:root:Train (Epoch 149): Loss/seq after 03500 batchs: 548.853515625
INFO:root:Train (Epoch 149): Loss/seq after 03550 batchs: 546.0989379882812
INFO:root:Train (Epoch 149): Loss/seq after 03600 batchs: 553.6146850585938
INFO:root:Train (Epoch 149): Loss/seq after 03650 batchs: 551.0621948242188
INFO:root:Train (Epoch 149): Loss/seq after 03700 batchs: 553.8690795898438
INFO:root:Train (Epoch 149): Loss/seq after 03750 batchs: 558.5250854492188
INFO:root:Train (Epoch 149): Loss/seq after 03800 batchs: 556.262451171875
INFO:root:Train (Epoch 149): Loss/seq after 03850 batchs: 555.08544921875
INFO:root:Train (Epoch 149): Loss/seq after 03900 batchs: 558.6959838867188
INFO:root:Train (Epoch 149): Loss/seq after 03950 batchs: 562.6337280273438
INFO:root:Train (Epoch 149): Loss/seq after 04000 batchs: 558.6600952148438
INFO:root:Train (Epoch 149): Loss/seq after 04050 batchs: 555.226318359375
INFO:root:Train (Epoch 149): Loss/seq after 04100 batchs: 553.44677734375
INFO:root:Train (Epoch 149): Loss/seq after 04150 batchs: 553.20703125
INFO:root:Train (Epoch 149): Loss/seq after 04200 batchs: 551.7178344726562
INFO:root:Train (Epoch 149): Loss/seq after 04250 batchs: 549.9100341796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 149): Loss/seq after 00000 batches: 504.3960266113281
INFO:root:# Valid (Epoch 149): Loss/seq after 00050 batches: 763.8606567382812
INFO:root:# Valid (Epoch 149): Loss/seq after 00100 batches: 755.3648071289062
INFO:root:# Valid (Epoch 149): Loss/seq after 00150 batches: 565.7535400390625
INFO:root:# Valid (Epoch 149): Loss/seq after 00200 batches: 518.4666748046875
INFO:root:Artifacts: Make stick videos for epoch 149
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_149_on_20220414_040015.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_149_index_934_on_20220414_040015.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 150): Loss/seq after 00000 batchs: 943.2116088867188
INFO:root:Train (Epoch 150): Loss/seq after 00050 batchs: 766.7339477539062
INFO:root:Train (Epoch 150): Loss/seq after 00100 batchs: 758.789306640625
INFO:root:Train (Epoch 150): Loss/seq after 00150 batchs: 691.3516235351562
INFO:root:Train (Epoch 150): Loss/seq after 00200 batchs: 760.7166137695312
INFO:root:Train (Epoch 150): Loss/seq after 00250 batchs: 846.630126953125
INFO:root:Train (Epoch 150): Loss/seq after 00300 batchs: 847.5718383789062
INFO:root:Train (Epoch 150): Loss/seq after 00350 batchs: 794.86279296875
INFO:root:Train (Epoch 150): Loss/seq after 00400 batchs: 793.5809936523438
INFO:root:Train (Epoch 150): Loss/seq after 00450 batchs: 778.882080078125
INFO:root:Train (Epoch 150): Loss/seq after 00500 batchs: 754.3409423828125
INFO:root:Train (Epoch 150): Loss/seq after 00550 batchs: 731.9710693359375
INFO:root:Train (Epoch 150): Loss/seq after 00600 batchs: 706.1712646484375
INFO:root:Train (Epoch 150): Loss/seq after 00650 batchs: 686.5218505859375
INFO:root:Train (Epoch 150): Loss/seq after 00700 batchs: 661.9619750976562
INFO:root:Train (Epoch 150): Loss/seq after 00750 batchs: 670.0411987304688
INFO:root:Train (Epoch 150): Loss/seq after 00800 batchs: 672.3444213867188
INFO:root:Train (Epoch 150): Loss/seq after 00850 batchs: 651.8856201171875
INFO:root:Train (Epoch 150): Loss/seq after 00900 batchs: 638.6871337890625
INFO:root:Train (Epoch 150): Loss/seq after 00950 batchs: 636.68603515625
INFO:root:Train (Epoch 150): Loss/seq after 01000 batchs: 629.0385131835938
INFO:root:Train (Epoch 150): Loss/seq after 01050 batchs: 618.1044921875
INFO:root:Train (Epoch 150): Loss/seq after 01100 batchs: 609.3961791992188
INFO:root:Train (Epoch 150): Loss/seq after 01150 batchs: 595.1686401367188
INFO:root:Train (Epoch 150): Loss/seq after 01200 batchs: 599.4446411132812
INFO:root:Train (Epoch 150): Loss/seq after 01250 batchs: 598.0061645507812
INFO:root:Train (Epoch 150): Loss/seq after 01300 batchs: 587.39111328125
INFO:root:Train (Epoch 150): Loss/seq after 01350 batchs: 578.3851318359375
INFO:root:Train (Epoch 150): Loss/seq after 01400 batchs: 583.3534545898438
INFO:root:Train (Epoch 150): Loss/seq after 01450 batchs: 585.0513916015625
INFO:root:Train (Epoch 150): Loss/seq after 01500 batchs: 591.477783203125
INFO:root:Train (Epoch 150): Loss/seq after 01550 batchs: 593.0603637695312
INFO:root:Train (Epoch 150): Loss/seq after 01600 batchs: 587.5639038085938
INFO:root:Train (Epoch 150): Loss/seq after 01650 batchs: 585.21875
INFO:root:Train (Epoch 150): Loss/seq after 01700 batchs: 587.6671752929688
INFO:root:Train (Epoch 150): Loss/seq after 01750 batchs: 585.115966796875
INFO:root:Train (Epoch 150): Loss/seq after 01800 batchs: 581.9252319335938
INFO:root:Train (Epoch 150): Loss/seq after 01850 batchs: 577.8993530273438
INFO:root:Train (Epoch 150): Loss/seq after 01900 batchs: 578.4541015625
INFO:root:Train (Epoch 150): Loss/seq after 01950 batchs: 577.0751342773438
INFO:root:Train (Epoch 150): Loss/seq after 02000 batchs: 575.7770385742188
INFO:root:Train (Epoch 150): Loss/seq after 02050 batchs: 574.2564086914062
INFO:root:Train (Epoch 150): Loss/seq after 02100 batchs: 571.2561645507812
INFO:root:Train (Epoch 150): Loss/seq after 02150 batchs: 569.0106811523438
INFO:root:Train (Epoch 150): Loss/seq after 02200 batchs: 566.1336059570312
INFO:root:Train (Epoch 150): Loss/seq after 02250 batchs: 564.4029541015625
INFO:root:Train (Epoch 150): Loss/seq after 02300 batchs: 561.4150390625
INFO:root:Train (Epoch 150): Loss/seq after 02350 batchs: 557.279052734375
INFO:root:Train (Epoch 150): Loss/seq after 02400 batchs: 558.9852294921875
INFO:root:Train (Epoch 150): Loss/seq after 02450 batchs: 554.2900390625
INFO:root:Train (Epoch 150): Loss/seq after 02500 batchs: 546.2429809570312
INFO:root:Train (Epoch 150): Loss/seq after 02550 batchs: 540.29541015625
INFO:root:Train (Epoch 150): Loss/seq after 02600 batchs: 539.388427734375
INFO:root:Train (Epoch 150): Loss/seq after 02650 batchs: 537.4357299804688
INFO:root:Train (Epoch 150): Loss/seq after 02700 batchs: 534.990234375
INFO:root:Train (Epoch 150): Loss/seq after 02750 batchs: 532.2906494140625
INFO:root:Train (Epoch 150): Loss/seq after 02800 batchs: 532.1217651367188
INFO:root:Train (Epoch 150): Loss/seq after 02850 batchs: 531.8969116210938
INFO:root:Train (Epoch 150): Loss/seq after 02900 batchs: 533.0870361328125
INFO:root:Train (Epoch 150): Loss/seq after 02950 batchs: 532.3087768554688
INFO:root:Train (Epoch 150): Loss/seq after 03000 batchs: 537.457763671875
INFO:root:Train (Epoch 150): Loss/seq after 03050 batchs: 539.5770263671875
INFO:root:Train (Epoch 150): Loss/seq after 03100 batchs: 542.7423095703125
INFO:root:Train (Epoch 150): Loss/seq after 03150 batchs: 545.947509765625
INFO:root:Train (Epoch 150): Loss/seq after 03200 batchs: 547.0364379882812
INFO:root:Train (Epoch 150): Loss/seq after 03250 batchs: 550.0206298828125
INFO:root:Train (Epoch 150): Loss/seq after 03300 batchs: 549.3743896484375
INFO:root:Train (Epoch 150): Loss/seq after 03350 batchs: 549.49560546875
INFO:root:Train (Epoch 150): Loss/seq after 03400 batchs: 545.4729614257812
INFO:root:Train (Epoch 150): Loss/seq after 03450 batchs: 544.2667846679688
INFO:root:Train (Epoch 150): Loss/seq after 03500 batchs: 545.0601806640625
INFO:root:Train (Epoch 150): Loss/seq after 03550 batchs: 542.5986938476562
INFO:root:Train (Epoch 150): Loss/seq after 03600 batchs: 550.0723876953125
INFO:root:Train (Epoch 150): Loss/seq after 03650 batchs: 547.5051879882812
INFO:root:Train (Epoch 150): Loss/seq after 03700 batchs: 550.39990234375
INFO:root:Train (Epoch 150): Loss/seq after 03750 batchs: 555.0447998046875
INFO:root:Train (Epoch 150): Loss/seq after 03800 batchs: 552.8673095703125
INFO:root:Train (Epoch 150): Loss/seq after 03850 batchs: 551.6121215820312
INFO:root:Train (Epoch 150): Loss/seq after 03900 batchs: 554.9815673828125
INFO:root:Train (Epoch 150): Loss/seq after 03950 batchs: 558.8638305664062
INFO:root:Train (Epoch 150): Loss/seq after 04000 batchs: 554.8910522460938
INFO:root:Train (Epoch 150): Loss/seq after 04050 batchs: 551.4826049804688
INFO:root:Train (Epoch 150): Loss/seq after 04100 batchs: 549.7703857421875
INFO:root:Train (Epoch 150): Loss/seq after 04150 batchs: 549.5843505859375
INFO:root:Train (Epoch 150): Loss/seq after 04200 batchs: 548.110595703125
INFO:root:Train (Epoch 150): Loss/seq after 04250 batchs: 546.3687133789062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 150): Loss/seq after 00000 batches: 484.533203125
INFO:root:# Valid (Epoch 150): Loss/seq after 00050 batches: 730.6486206054688
INFO:root:# Valid (Epoch 150): Loss/seq after 00100 batches: 736.6395263671875
INFO:root:# Valid (Epoch 150): Loss/seq after 00150 batches: 553.605712890625
INFO:root:# Valid (Epoch 150): Loss/seq after 00200 batches: 510.32574462890625
INFO:root:Artifacts: Make stick videos for epoch 150
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_150_on_20220414_040532.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_150_index_1728_on_20220414_040532.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 151): Loss/seq after 00000 batchs: 978.7306518554688
INFO:root:Train (Epoch 151): Loss/seq after 00050 batchs: 765.7128295898438
INFO:root:Train (Epoch 151): Loss/seq after 00100 batchs: 773.0298461914062
INFO:root:Train (Epoch 151): Loss/seq after 00150 batchs: 706.80078125
INFO:root:Train (Epoch 151): Loss/seq after 00200 batchs: 769.9678955078125
INFO:root:Train (Epoch 151): Loss/seq after 00250 batchs: 854.4757080078125
INFO:root:Train (Epoch 151): Loss/seq after 00300 batchs: 855.3258666992188
INFO:root:Train (Epoch 151): Loss/seq after 00350 batchs: 802.8528442382812
INFO:root:Train (Epoch 151): Loss/seq after 00400 batchs: 804.2031860351562
INFO:root:Train (Epoch 151): Loss/seq after 00450 batchs: 788.131103515625
INFO:root:Train (Epoch 151): Loss/seq after 00500 batchs: 766.5772094726562
INFO:root:Train (Epoch 151): Loss/seq after 00550 batchs: 743.2576293945312
INFO:root:Train (Epoch 151): Loss/seq after 00600 batchs: 717.503173828125
INFO:root:Train (Epoch 151): Loss/seq after 00650 batchs: 696.1132202148438
INFO:root:Train (Epoch 151): Loss/seq after 00700 batchs: 670.3919067382812
INFO:root:Train (Epoch 151): Loss/seq after 00750 batchs: 676.2200317382812
INFO:root:Train (Epoch 151): Loss/seq after 00800 batchs: 679.0242309570312
INFO:root:Train (Epoch 151): Loss/seq after 00850 batchs: 658.36962890625
INFO:root:Train (Epoch 151): Loss/seq after 00900 batchs: 644.911865234375
INFO:root:Train (Epoch 151): Loss/seq after 00950 batchs: 641.894775390625
INFO:root:Train (Epoch 151): Loss/seq after 01000 batchs: 633.6380615234375
INFO:root:Train (Epoch 151): Loss/seq after 01050 batchs: 623.0991821289062
INFO:root:Train (Epoch 151): Loss/seq after 01100 batchs: 615.1466674804688
INFO:root:Train (Epoch 151): Loss/seq after 01150 batchs: 600.9857177734375
INFO:root:Train (Epoch 151): Loss/seq after 01200 batchs: 605.3920288085938
INFO:root:Train (Epoch 151): Loss/seq after 01250 batchs: 603.4418334960938
INFO:root:Train (Epoch 151): Loss/seq after 01300 batchs: 591.834716796875
INFO:root:Train (Epoch 151): Loss/seq after 01350 batchs: 582.9443359375
INFO:root:Train (Epoch 151): Loss/seq after 01400 batchs: 587.7903442382812
INFO:root:Train (Epoch 151): Loss/seq after 01450 batchs: 589.181884765625
INFO:root:Train (Epoch 151): Loss/seq after 01500 batchs: 595.391845703125
INFO:root:Train (Epoch 151): Loss/seq after 01550 batchs: 596.8463134765625
INFO:root:Train (Epoch 151): Loss/seq after 01600 batchs: 591.3978881835938
INFO:root:Train (Epoch 151): Loss/seq after 01650 batchs: 589.0546264648438
INFO:root:Train (Epoch 151): Loss/seq after 01700 batchs: 591.36865234375
INFO:root:Train (Epoch 151): Loss/seq after 01750 batchs: 588.457763671875
INFO:root:Train (Epoch 151): Loss/seq after 01800 batchs: 585.2147827148438
INFO:root:Train (Epoch 151): Loss/seq after 01850 batchs: 580.9765625
INFO:root:Train (Epoch 151): Loss/seq after 01900 batchs: 581.5946044921875
INFO:root:Train (Epoch 151): Loss/seq after 01950 batchs: 580.0872802734375
INFO:root:Train (Epoch 151): Loss/seq after 02000 batchs: 578.756591796875
INFO:root:Train (Epoch 151): Loss/seq after 02050 batchs: 577.18408203125
INFO:root:Train (Epoch 151): Loss/seq after 02100 batchs: 574.1876831054688
INFO:root:Train (Epoch 151): Loss/seq after 02150 batchs: 571.875
INFO:root:Train (Epoch 151): Loss/seq after 02200 batchs: 568.7716674804688
INFO:root:Train (Epoch 151): Loss/seq after 02250 batchs: 566.9390869140625
INFO:root:Train (Epoch 151): Loss/seq after 02300 batchs: 563.85986328125
INFO:root:Train (Epoch 151): Loss/seq after 02350 batchs: 559.3921508789062
INFO:root:Train (Epoch 151): Loss/seq after 02400 batchs: 561.0025024414062
INFO:root:Train (Epoch 151): Loss/seq after 02450 batchs: 556.1497192382812
INFO:root:Train (Epoch 151): Loss/seq after 02500 batchs: 548.0386352539062
INFO:root:Train (Epoch 151): Loss/seq after 02550 batchs: 542.0761108398438
INFO:root:Train (Epoch 151): Loss/seq after 02600 batchs: 541.05419921875
INFO:root:Train (Epoch 151): Loss/seq after 02650 batchs: 538.876220703125
INFO:root:Train (Epoch 151): Loss/seq after 02700 batchs: 536.563720703125
INFO:root:Train (Epoch 151): Loss/seq after 02750 batchs: 533.8842163085938
INFO:root:Train (Epoch 151): Loss/seq after 02800 batchs: 533.5046997070312
INFO:root:Train (Epoch 151): Loss/seq after 02850 batchs: 533.2010498046875
INFO:root:Train (Epoch 151): Loss/seq after 02900 batchs: 534.2785034179688
INFO:root:Train (Epoch 151): Loss/seq after 02950 batchs: 533.3014526367188
INFO:root:Train (Epoch 151): Loss/seq after 03000 batchs: 538.4932250976562
INFO:root:Train (Epoch 151): Loss/seq after 03050 batchs: 540.50439453125
INFO:root:Train (Epoch 151): Loss/seq after 03100 batchs: 543.5415649414062
INFO:root:Train (Epoch 151): Loss/seq after 03150 batchs: 546.49951171875
INFO:root:Train (Epoch 151): Loss/seq after 03200 batchs: 547.5088500976562
INFO:root:Train (Epoch 151): Loss/seq after 03250 batchs: 550.5708618164062
INFO:root:Train (Epoch 151): Loss/seq after 03300 batchs: 549.7876586914062
INFO:root:Train (Epoch 151): Loss/seq after 03350 batchs: 549.737548828125
INFO:root:Train (Epoch 151): Loss/seq after 03400 batchs: 545.7448120117188
INFO:root:Train (Epoch 151): Loss/seq after 03450 batchs: 544.4340209960938
INFO:root:Train (Epoch 151): Loss/seq after 03500 batchs: 545.095703125
INFO:root:Train (Epoch 151): Loss/seq after 03550 batchs: 542.3406372070312
INFO:root:Train (Epoch 151): Loss/seq after 03600 batchs: 549.6743774414062
INFO:root:Train (Epoch 151): Loss/seq after 03650 batchs: 547.015869140625
INFO:root:Train (Epoch 151): Loss/seq after 03700 batchs: 549.8173828125
INFO:root:Train (Epoch 151): Loss/seq after 03750 batchs: 554.4423217773438
INFO:root:Train (Epoch 151): Loss/seq after 03800 batchs: 552.2134399414062
INFO:root:Train (Epoch 151): Loss/seq after 03850 batchs: 551.0326538085938
INFO:root:Train (Epoch 151): Loss/seq after 03900 batchs: 554.5663452148438
INFO:root:Train (Epoch 151): Loss/seq after 03950 batchs: 558.2168579101562
INFO:root:Train (Epoch 151): Loss/seq after 04000 batchs: 554.2872314453125
INFO:root:Train (Epoch 151): Loss/seq after 04050 batchs: 550.8589477539062
INFO:root:Train (Epoch 151): Loss/seq after 04100 batchs: 549.1146240234375
INFO:root:Train (Epoch 151): Loss/seq after 04150 batchs: 548.8945922851562
INFO:root:Train (Epoch 151): Loss/seq after 04200 batchs: 547.4244384765625
INFO:root:Train (Epoch 151): Loss/seq after 04250 batchs: 545.64892578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 151): Loss/seq after 00000 batches: 536.1954956054688
INFO:root:# Valid (Epoch 151): Loss/seq after 00050 batches: 786.9006958007812
INFO:root:# Valid (Epoch 151): Loss/seq after 00100 batches: 753.529541015625
INFO:root:# Valid (Epoch 151): Loss/seq after 00150 batches: 566.260498046875
INFO:root:# Valid (Epoch 151): Loss/seq after 00200 batches: 519.4694213867188
INFO:root:Artifacts: Make stick videos for epoch 151
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_151_on_20220414_041052.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_151_index_440_on_20220414_041052.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 152): Loss/seq after 00000 batchs: 925.6984252929688
INFO:root:Train (Epoch 152): Loss/seq after 00050 batchs: 759.8716430664062
INFO:root:Train (Epoch 152): Loss/seq after 00100 batchs: 757.9817504882812
INFO:root:Train (Epoch 152): Loss/seq after 00150 batchs: 689.86181640625
INFO:root:Train (Epoch 152): Loss/seq after 00200 batchs: 757.25634765625
INFO:root:Train (Epoch 152): Loss/seq after 00250 batchs: 839.0779418945312
INFO:root:Train (Epoch 152): Loss/seq after 00300 batchs: 840.0086669921875
INFO:root:Train (Epoch 152): Loss/seq after 00350 batchs: 788.334228515625
INFO:root:Train (Epoch 152): Loss/seq after 00400 batchs: 788.5604858398438
INFO:root:Train (Epoch 152): Loss/seq after 00450 batchs: 774.7703247070312
INFO:root:Train (Epoch 152): Loss/seq after 00500 batchs: 752.9627685546875
INFO:root:Train (Epoch 152): Loss/seq after 00550 batchs: 731.2583618164062
INFO:root:Train (Epoch 152): Loss/seq after 00600 batchs: 705.9178466796875
INFO:root:Train (Epoch 152): Loss/seq after 00650 batchs: 684.2621459960938
INFO:root:Train (Epoch 152): Loss/seq after 00700 batchs: 660.02685546875
INFO:root:Train (Epoch 152): Loss/seq after 00750 batchs: 667.5772705078125
INFO:root:Train (Epoch 152): Loss/seq after 00800 batchs: 670.8595581054688
INFO:root:Train (Epoch 152): Loss/seq after 00850 batchs: 650.7191162109375
INFO:root:Train (Epoch 152): Loss/seq after 00900 batchs: 637.7263793945312
INFO:root:Train (Epoch 152): Loss/seq after 00950 batchs: 635.9615478515625
INFO:root:Train (Epoch 152): Loss/seq after 01000 batchs: 626.8867797851562
INFO:root:Train (Epoch 152): Loss/seq after 01050 batchs: 616.3506469726562
INFO:root:Train (Epoch 152): Loss/seq after 01100 batchs: 608.0089721679688
INFO:root:Train (Epoch 152): Loss/seq after 01150 batchs: 593.7066650390625
INFO:root:Train (Epoch 152): Loss/seq after 01200 batchs: 598.2335205078125
INFO:root:Train (Epoch 152): Loss/seq after 01250 batchs: 596.3667602539062
INFO:root:Train (Epoch 152): Loss/seq after 01300 batchs: 585.1890258789062
INFO:root:Train (Epoch 152): Loss/seq after 01350 batchs: 576.0362548828125
INFO:root:Train (Epoch 152): Loss/seq after 01400 batchs: 580.842529296875
INFO:root:Train (Epoch 152): Loss/seq after 01450 batchs: 582.6436767578125
INFO:root:Train (Epoch 152): Loss/seq after 01500 batchs: 588.99267578125
INFO:root:Train (Epoch 152): Loss/seq after 01550 batchs: 590.866943359375
INFO:root:Train (Epoch 152): Loss/seq after 01600 batchs: 585.5584106445312
INFO:root:Train (Epoch 152): Loss/seq after 01650 batchs: 583.2943725585938
INFO:root:Train (Epoch 152): Loss/seq after 01700 batchs: 585.4437866210938
INFO:root:Train (Epoch 152): Loss/seq after 01750 batchs: 582.7305908203125
INFO:root:Train (Epoch 152): Loss/seq after 01800 batchs: 579.4728393554688
INFO:root:Train (Epoch 152): Loss/seq after 01850 batchs: 575.3900756835938
INFO:root:Train (Epoch 152): Loss/seq after 01900 batchs: 575.9967041015625
INFO:root:Train (Epoch 152): Loss/seq after 01950 batchs: 574.6422729492188
INFO:root:Train (Epoch 152): Loss/seq after 02000 batchs: 573.4511108398438
INFO:root:Train (Epoch 152): Loss/seq after 02050 batchs: 571.8182983398438
INFO:root:Train (Epoch 152): Loss/seq after 02100 batchs: 568.7626953125
INFO:root:Train (Epoch 152): Loss/seq after 02150 batchs: 566.5162963867188
INFO:root:Train (Epoch 152): Loss/seq after 02200 batchs: 563.411865234375
INFO:root:Train (Epoch 152): Loss/seq after 02250 batchs: 561.7593994140625
INFO:root:Train (Epoch 152): Loss/seq after 02300 batchs: 558.753173828125
INFO:root:Train (Epoch 152): Loss/seq after 02350 batchs: 554.6259765625
INFO:root:Train (Epoch 152): Loss/seq after 02400 batchs: 556.3601684570312
INFO:root:Train (Epoch 152): Loss/seq after 02450 batchs: 551.6778564453125
INFO:root:Train (Epoch 152): Loss/seq after 02500 batchs: 543.669921875
INFO:root:Train (Epoch 152): Loss/seq after 02550 batchs: 537.6817626953125
INFO:root:Train (Epoch 152): Loss/seq after 02600 batchs: 536.593994140625
INFO:root:Train (Epoch 152): Loss/seq after 02650 batchs: 534.360595703125
INFO:root:Train (Epoch 152): Loss/seq after 02700 batchs: 532.0411376953125
INFO:root:Train (Epoch 152): Loss/seq after 02750 batchs: 529.233154296875
INFO:root:Train (Epoch 152): Loss/seq after 02800 batchs: 528.8245849609375
INFO:root:Train (Epoch 152): Loss/seq after 02850 batchs: 528.7913818359375
INFO:root:Train (Epoch 152): Loss/seq after 02900 batchs: 529.8635864257812
INFO:root:Train (Epoch 152): Loss/seq after 02950 batchs: 529.0242309570312
INFO:root:Train (Epoch 152): Loss/seq after 03000 batchs: 534.2633666992188
INFO:root:Train (Epoch 152): Loss/seq after 03050 batchs: 536.0984497070312
INFO:root:Train (Epoch 152): Loss/seq after 03100 batchs: 538.6378173828125
INFO:root:Train (Epoch 152): Loss/seq after 03150 batchs: 541.84326171875
INFO:root:Train (Epoch 152): Loss/seq after 03200 batchs: 542.8269653320312
INFO:root:Train (Epoch 152): Loss/seq after 03250 batchs: 545.5975952148438
INFO:root:Train (Epoch 152): Loss/seq after 03300 batchs: 544.6165771484375
INFO:root:Train (Epoch 152): Loss/seq after 03350 batchs: 544.3699340820312
INFO:root:Train (Epoch 152): Loss/seq after 03400 batchs: 540.5424194335938
INFO:root:Train (Epoch 152): Loss/seq after 03450 batchs: 539.4337158203125
INFO:root:Train (Epoch 152): Loss/seq after 03500 batchs: 540.139892578125
INFO:root:Train (Epoch 152): Loss/seq after 03550 batchs: 537.434326171875
INFO:root:Train (Epoch 152): Loss/seq after 03600 batchs: 545.0004272460938
INFO:root:Train (Epoch 152): Loss/seq after 03650 batchs: 542.556640625
INFO:root:Train (Epoch 152): Loss/seq after 03700 batchs: 545.41162109375
INFO:root:Train (Epoch 152): Loss/seq after 03750 batchs: 550.0743408203125
INFO:root:Train (Epoch 152): Loss/seq after 03800 batchs: 547.8805541992188
INFO:root:Train (Epoch 152): Loss/seq after 03850 batchs: 546.8988037109375
INFO:root:Train (Epoch 152): Loss/seq after 03900 batchs: 550.2108154296875
INFO:root:Train (Epoch 152): Loss/seq after 03950 batchs: 553.8588256835938
INFO:root:Train (Epoch 152): Loss/seq after 04000 batchs: 549.9668579101562
INFO:root:Train (Epoch 152): Loss/seq after 04050 batchs: 546.6322631835938
INFO:root:Train (Epoch 152): Loss/seq after 04100 batchs: 544.9797973632812
INFO:root:Train (Epoch 152): Loss/seq after 04150 batchs: 544.8161010742188
INFO:root:Train (Epoch 152): Loss/seq after 04200 batchs: 543.3120727539062
INFO:root:Train (Epoch 152): Loss/seq after 04250 batchs: 541.6930541992188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 152): Loss/seq after 00000 batches: 514.244384765625
INFO:root:# Valid (Epoch 152): Loss/seq after 00050 batches: 689.162841796875
INFO:root:# Valid (Epoch 152): Loss/seq after 00100 batches: 710.0921630859375
INFO:root:# Valid (Epoch 152): Loss/seq after 00150 batches: 537.6795043945312
INFO:root:# Valid (Epoch 152): Loss/seq after 00200 batches: 497.6101379394531
INFO:root:Artifacts: Make stick videos for epoch 152
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_152_on_20220414_041609.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_152_index_1870_on_20220414_041609.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 153): Loss/seq after 00000 batchs: 870.58349609375
INFO:root:Train (Epoch 153): Loss/seq after 00050 batchs: 758.8402709960938
INFO:root:Train (Epoch 153): Loss/seq after 00100 batchs: 745.6968994140625
INFO:root:Train (Epoch 153): Loss/seq after 00150 batchs: 679.9972534179688
INFO:root:Train (Epoch 153): Loss/seq after 00200 batchs: 750.3984375
INFO:root:Train (Epoch 153): Loss/seq after 00250 batchs: 832.6573486328125
INFO:root:Train (Epoch 153): Loss/seq after 00300 batchs: 835.2413940429688
INFO:root:Train (Epoch 153): Loss/seq after 00350 batchs: 784.1378173828125
INFO:root:Train (Epoch 153): Loss/seq after 00400 batchs: 783.3892211914062
INFO:root:Train (Epoch 153): Loss/seq after 00450 batchs: 769.6875610351562
INFO:root:Train (Epoch 153): Loss/seq after 00500 batchs: 747.0226440429688
INFO:root:Train (Epoch 153): Loss/seq after 00550 batchs: 725.5851440429688
INFO:root:Train (Epoch 153): Loss/seq after 00600 batchs: 700.7586059570312
INFO:root:Train (Epoch 153): Loss/seq after 00650 batchs: 679.8541259765625
INFO:root:Train (Epoch 153): Loss/seq after 00700 batchs: 655.0921020507812
INFO:root:Train (Epoch 153): Loss/seq after 00750 batchs: 661.956298828125
INFO:root:Train (Epoch 153): Loss/seq after 00800 batchs: 665.310302734375
INFO:root:Train (Epoch 153): Loss/seq after 00850 batchs: 645.1915893554688
INFO:root:Train (Epoch 153): Loss/seq after 00900 batchs: 632.5691528320312
INFO:root:Train (Epoch 153): Loss/seq after 00950 batchs: 628.8159790039062
INFO:root:Train (Epoch 153): Loss/seq after 01000 batchs: 620.20556640625
INFO:root:Train (Epoch 153): Loss/seq after 01050 batchs: 609.1972045898438
INFO:root:Train (Epoch 153): Loss/seq after 01100 batchs: 601.453125
INFO:root:Train (Epoch 153): Loss/seq after 01150 batchs: 587.201904296875
INFO:root:Train (Epoch 153): Loss/seq after 01200 batchs: 591.615478515625
INFO:root:Train (Epoch 153): Loss/seq after 01250 batchs: 590.02685546875
INFO:root:Train (Epoch 153): Loss/seq after 01300 batchs: 579.2832641601562
INFO:root:Train (Epoch 153): Loss/seq after 01350 batchs: 570.3545532226562
INFO:root:Train (Epoch 153): Loss/seq after 01400 batchs: 574.4752197265625
INFO:root:Train (Epoch 153): Loss/seq after 01450 batchs: 576.1461181640625
INFO:root:Train (Epoch 153): Loss/seq after 01500 batchs: 582.4780883789062
INFO:root:Train (Epoch 153): Loss/seq after 01550 batchs: 584.1282958984375
INFO:root:Train (Epoch 153): Loss/seq after 01600 batchs: 578.9658813476562
INFO:root:Train (Epoch 153): Loss/seq after 01650 batchs: 577.28369140625
INFO:root:Train (Epoch 153): Loss/seq after 01700 batchs: 580.2188720703125
INFO:root:Train (Epoch 153): Loss/seq after 01750 batchs: 577.833984375
INFO:root:Train (Epoch 153): Loss/seq after 01800 batchs: 574.7606811523438
INFO:root:Train (Epoch 153): Loss/seq after 01850 batchs: 570.7760620117188
INFO:root:Train (Epoch 153): Loss/seq after 01900 batchs: 571.34326171875
INFO:root:Train (Epoch 153): Loss/seq after 01950 batchs: 570.2073364257812
INFO:root:Train (Epoch 153): Loss/seq after 02000 batchs: 569.0369873046875
INFO:root:Train (Epoch 153): Loss/seq after 02050 batchs: 567.528564453125
INFO:root:Train (Epoch 153): Loss/seq after 02100 batchs: 564.608154296875
INFO:root:Train (Epoch 153): Loss/seq after 02150 batchs: 562.6060791015625
INFO:root:Train (Epoch 153): Loss/seq after 02200 batchs: 559.594970703125
INFO:root:Train (Epoch 153): Loss/seq after 02250 batchs: 557.8374633789062
INFO:root:Train (Epoch 153): Loss/seq after 02300 batchs: 554.8092651367188
INFO:root:Train (Epoch 153): Loss/seq after 02350 batchs: 550.5713500976562
INFO:root:Train (Epoch 153): Loss/seq after 02400 batchs: 552.3596801757812
INFO:root:Train (Epoch 153): Loss/seq after 02450 batchs: 547.7512817382812
INFO:root:Train (Epoch 153): Loss/seq after 02500 batchs: 539.8216552734375
INFO:root:Train (Epoch 153): Loss/seq after 02550 batchs: 533.96923828125
INFO:root:Train (Epoch 153): Loss/seq after 02600 batchs: 532.8969116210938
INFO:root:Train (Epoch 153): Loss/seq after 02650 batchs: 530.8616333007812
INFO:root:Train (Epoch 153): Loss/seq after 02700 batchs: 528.7363891601562
INFO:root:Train (Epoch 153): Loss/seq after 02750 batchs: 525.9685668945312
INFO:root:Train (Epoch 153): Loss/seq after 02800 batchs: 525.7069091796875
INFO:root:Train (Epoch 153): Loss/seq after 02850 batchs: 525.6404418945312
INFO:root:Train (Epoch 153): Loss/seq after 02900 batchs: 527.172607421875
INFO:root:Train (Epoch 153): Loss/seq after 02950 batchs: 526.440673828125
INFO:root:Train (Epoch 153): Loss/seq after 03000 batchs: 531.6544799804688
INFO:root:Train (Epoch 153): Loss/seq after 03050 batchs: 533.6651611328125
INFO:root:Train (Epoch 153): Loss/seq after 03100 batchs: 536.2739868164062
INFO:root:Train (Epoch 153): Loss/seq after 03150 batchs: 538.7092895507812
INFO:root:Train (Epoch 153): Loss/seq after 03200 batchs: 539.4723510742188
INFO:root:Train (Epoch 153): Loss/seq after 03250 batchs: 542.3897094726562
INFO:root:Train (Epoch 153): Loss/seq after 03300 batchs: 541.4273071289062
INFO:root:Train (Epoch 153): Loss/seq after 03350 batchs: 541.5463256835938
INFO:root:Train (Epoch 153): Loss/seq after 03400 batchs: 537.6590576171875
INFO:root:Train (Epoch 153): Loss/seq after 03450 batchs: 536.406005859375
INFO:root:Train (Epoch 153): Loss/seq after 03500 batchs: 537.0573120117188
INFO:root:Train (Epoch 153): Loss/seq after 03550 batchs: 534.4666137695312
INFO:root:Train (Epoch 153): Loss/seq after 03600 batchs: 542.0155639648438
INFO:root:Train (Epoch 153): Loss/seq after 03650 batchs: 539.5980224609375
INFO:root:Train (Epoch 153): Loss/seq after 03700 batchs: 542.2473754882812
INFO:root:Train (Epoch 153): Loss/seq after 03750 batchs: 546.8274536132812
INFO:root:Train (Epoch 153): Loss/seq after 03800 batchs: 544.6571044921875
INFO:root:Train (Epoch 153): Loss/seq after 03850 batchs: 543.5260620117188
INFO:root:Train (Epoch 153): Loss/seq after 03900 batchs: 546.730224609375
INFO:root:Train (Epoch 153): Loss/seq after 03950 batchs: 550.3408813476562
INFO:root:Train (Epoch 153): Loss/seq after 04000 batchs: 546.5164184570312
INFO:root:Train (Epoch 153): Loss/seq after 04050 batchs: 543.2022705078125
INFO:root:Train (Epoch 153): Loss/seq after 04100 batchs: 541.492919921875
INFO:root:Train (Epoch 153): Loss/seq after 04150 batchs: 541.3497314453125
INFO:root:Train (Epoch 153): Loss/seq after 04200 batchs: 539.88037109375
INFO:root:Train (Epoch 153): Loss/seq after 04250 batchs: 538.1795654296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 153): Loss/seq after 00000 batches: 529.6792602539062
INFO:root:# Valid (Epoch 153): Loss/seq after 00050 batches: 777.2275390625
INFO:root:# Valid (Epoch 153): Loss/seq after 00100 batches: 758.48779296875
INFO:root:# Valid (Epoch 153): Loss/seq after 00150 batches: 569.9882202148438
INFO:root:# Valid (Epoch 153): Loss/seq after 00200 batches: 522.8762817382812
INFO:root:Artifacts: Make stick videos for epoch 153
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_153_on_20220414_042127.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_153_index_403_on_20220414_042127.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 154): Loss/seq after 00000 batchs: 909.9685668945312
INFO:root:Train (Epoch 154): Loss/seq after 00050 batchs: 751.1964111328125
INFO:root:Train (Epoch 154): Loss/seq after 00100 batchs: 746.2005004882812
INFO:root:Train (Epoch 154): Loss/seq after 00150 batchs: 681.2369384765625
INFO:root:Train (Epoch 154): Loss/seq after 00200 batchs: 738.2467651367188
INFO:root:Train (Epoch 154): Loss/seq after 00250 batchs: 820.0350341796875
INFO:root:Train (Epoch 154): Loss/seq after 00300 batchs: 823.8397216796875
INFO:root:Train (Epoch 154): Loss/seq after 00350 batchs: 774.7951049804688
INFO:root:Train (Epoch 154): Loss/seq after 00400 batchs: 776.9216918945312
INFO:root:Train (Epoch 154): Loss/seq after 00450 batchs: 763.9402465820312
INFO:root:Train (Epoch 154): Loss/seq after 00500 batchs: 741.066162109375
INFO:root:Train (Epoch 154): Loss/seq after 00550 batchs: 719.09912109375
INFO:root:Train (Epoch 154): Loss/seq after 00600 batchs: 696.2354736328125
INFO:root:Train (Epoch 154): Loss/seq after 00650 batchs: 676.3951416015625
INFO:root:Train (Epoch 154): Loss/seq after 00700 batchs: 651.9873046875
INFO:root:Train (Epoch 154): Loss/seq after 00750 batchs: 657.9014282226562
INFO:root:Train (Epoch 154): Loss/seq after 00800 batchs: 662.4445190429688
INFO:root:Train (Epoch 154): Loss/seq after 00850 batchs: 642.4561157226562
INFO:root:Train (Epoch 154): Loss/seq after 00900 batchs: 629.1708984375
INFO:root:Train (Epoch 154): Loss/seq after 00950 batchs: 626.453369140625
INFO:root:Train (Epoch 154): Loss/seq after 01000 batchs: 617.8668212890625
INFO:root:Train (Epoch 154): Loss/seq after 01050 batchs: 607.3714599609375
INFO:root:Train (Epoch 154): Loss/seq after 01100 batchs: 599.34521484375
INFO:root:Train (Epoch 154): Loss/seq after 01150 batchs: 585.3773803710938
INFO:root:Train (Epoch 154): Loss/seq after 01200 batchs: 590.0120849609375
INFO:root:Train (Epoch 154): Loss/seq after 01250 batchs: 588.6116943359375
INFO:root:Train (Epoch 154): Loss/seq after 01300 batchs: 577.5379638671875
INFO:root:Train (Epoch 154): Loss/seq after 01350 batchs: 568.4628295898438
INFO:root:Train (Epoch 154): Loss/seq after 01400 batchs: 572.5882568359375
INFO:root:Train (Epoch 154): Loss/seq after 01450 batchs: 574.3803100585938
INFO:root:Train (Epoch 154): Loss/seq after 01500 batchs: 580.95458984375
INFO:root:Train (Epoch 154): Loss/seq after 01550 batchs: 583.0457763671875
INFO:root:Train (Epoch 154): Loss/seq after 01600 batchs: 577.8389282226562
INFO:root:Train (Epoch 154): Loss/seq after 01650 batchs: 575.7155151367188
INFO:root:Train (Epoch 154): Loss/seq after 01700 batchs: 578.0394287109375
INFO:root:Train (Epoch 154): Loss/seq after 01750 batchs: 575.5264282226562
INFO:root:Train (Epoch 154): Loss/seq after 01800 batchs: 572.3819580078125
INFO:root:Train (Epoch 154): Loss/seq after 01850 batchs: 568.3886108398438
INFO:root:Train (Epoch 154): Loss/seq after 01900 batchs: 568.921142578125
INFO:root:Train (Epoch 154): Loss/seq after 01950 batchs: 567.5411987304688
INFO:root:Train (Epoch 154): Loss/seq after 02000 batchs: 566.4486694335938
INFO:root:Train (Epoch 154): Loss/seq after 02050 batchs: 565.0859375
INFO:root:Train (Epoch 154): Loss/seq after 02100 batchs: 562.1980590820312
INFO:root:Train (Epoch 154): Loss/seq after 02150 batchs: 560.0541381835938
INFO:root:Train (Epoch 154): Loss/seq after 02200 batchs: 557.1058959960938
INFO:root:Train (Epoch 154): Loss/seq after 02250 batchs: 555.2428588867188
INFO:root:Train (Epoch 154): Loss/seq after 02300 batchs: 552.0073852539062
INFO:root:Train (Epoch 154): Loss/seq after 02350 batchs: 547.8681640625
INFO:root:Train (Epoch 154): Loss/seq after 02400 batchs: 549.6188354492188
INFO:root:Train (Epoch 154): Loss/seq after 02450 batchs: 544.9439086914062
INFO:root:Train (Epoch 154): Loss/seq after 02500 batchs: 537.0593872070312
INFO:root:Train (Epoch 154): Loss/seq after 02550 batchs: 531.1946411132812
INFO:root:Train (Epoch 154): Loss/seq after 02600 batchs: 530.0900268554688
INFO:root:Train (Epoch 154): Loss/seq after 02650 batchs: 527.8967895507812
INFO:root:Train (Epoch 154): Loss/seq after 02700 batchs: 525.6485595703125
INFO:root:Train (Epoch 154): Loss/seq after 02750 batchs: 522.820556640625
INFO:root:Train (Epoch 154): Loss/seq after 02800 batchs: 522.8259887695312
INFO:root:Train (Epoch 154): Loss/seq after 02850 batchs: 522.8574829101562
INFO:root:Train (Epoch 154): Loss/seq after 02900 batchs: 523.9862670898438
INFO:root:Train (Epoch 154): Loss/seq after 02950 batchs: 523.25048828125
INFO:root:Train (Epoch 154): Loss/seq after 03000 batchs: 528.4990844726562
INFO:root:Train (Epoch 154): Loss/seq after 03050 batchs: 530.4310913085938
INFO:root:Train (Epoch 154): Loss/seq after 03100 batchs: 532.9097900390625
INFO:root:Train (Epoch 154): Loss/seq after 03150 batchs: 535.674072265625
INFO:root:Train (Epoch 154): Loss/seq after 03200 batchs: 536.5371704101562
INFO:root:Train (Epoch 154): Loss/seq after 03250 batchs: 539.3721313476562
INFO:root:Train (Epoch 154): Loss/seq after 03300 batchs: 538.4298095703125
INFO:root:Train (Epoch 154): Loss/seq after 03350 batchs: 538.6422729492188
INFO:root:Train (Epoch 154): Loss/seq after 03400 batchs: 534.7721557617188
INFO:root:Train (Epoch 154): Loss/seq after 03450 batchs: 533.4959716796875
INFO:root:Train (Epoch 154): Loss/seq after 03500 batchs: 534.2011108398438
INFO:root:Train (Epoch 154): Loss/seq after 03550 batchs: 531.5714111328125
INFO:root:Train (Epoch 154): Loss/seq after 03600 batchs: 539.04345703125
INFO:root:Train (Epoch 154): Loss/seq after 03650 batchs: 536.8577880859375
INFO:root:Train (Epoch 154): Loss/seq after 03700 batchs: 539.7262573242188
INFO:root:Train (Epoch 154): Loss/seq after 03750 batchs: 544.2841186523438
INFO:root:Train (Epoch 154): Loss/seq after 03800 batchs: 542.15625
INFO:root:Train (Epoch 154): Loss/seq after 03850 batchs: 541.12060546875
INFO:root:Train (Epoch 154): Loss/seq after 03900 batchs: 544.359375
INFO:root:Train (Epoch 154): Loss/seq after 03950 batchs: 547.9261474609375
INFO:root:Train (Epoch 154): Loss/seq after 04000 batchs: 544.123046875
INFO:root:Train (Epoch 154): Loss/seq after 04050 batchs: 540.819580078125
INFO:root:Train (Epoch 154): Loss/seq after 04100 batchs: 539.16748046875
INFO:root:Train (Epoch 154): Loss/seq after 04150 batchs: 539.068603515625
INFO:root:Train (Epoch 154): Loss/seq after 04200 batchs: 537.5284423828125
INFO:root:Train (Epoch 154): Loss/seq after 04250 batchs: 535.7724609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 154): Loss/seq after 00000 batches: 496.7660827636719
INFO:root:# Valid (Epoch 154): Loss/seq after 00050 batches: 729.9021606445312
INFO:root:# Valid (Epoch 154): Loss/seq after 00100 batches: 711.688232421875
INFO:root:# Valid (Epoch 154): Loss/seq after 00150 batches: 537.1597900390625
INFO:root:# Valid (Epoch 154): Loss/seq after 00200 batches: 497.62591552734375
INFO:root:Artifacts: Make stick videos for epoch 154
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_154_on_20220414_042645.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_154_index_633_on_20220414_042645.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 155): Loss/seq after 00000 batchs: 1044.6041259765625
INFO:root:Train (Epoch 155): Loss/seq after 00050 batchs: 758.5887451171875
INFO:root:Train (Epoch 155): Loss/seq after 00100 batchs: 741.9785766601562
INFO:root:Train (Epoch 155): Loss/seq after 00150 batchs: 675.5870361328125
INFO:root:Train (Epoch 155): Loss/seq after 00200 batchs: 740.9113159179688
INFO:root:Train (Epoch 155): Loss/seq after 00250 batchs: 818.2866821289062
INFO:root:Train (Epoch 155): Loss/seq after 00300 batchs: 822.2301635742188
INFO:root:Train (Epoch 155): Loss/seq after 00350 batchs: 773.2869262695312
INFO:root:Train (Epoch 155): Loss/seq after 00400 batchs: 773.5001220703125
INFO:root:Train (Epoch 155): Loss/seq after 00450 batchs: 760.9469604492188
INFO:root:Train (Epoch 155): Loss/seq after 00500 batchs: 736.983154296875
INFO:root:Train (Epoch 155): Loss/seq after 00550 batchs: 715.1358642578125
INFO:root:Train (Epoch 155): Loss/seq after 00600 batchs: 690.8757934570312
INFO:root:Train (Epoch 155): Loss/seq after 00650 batchs: 670.33740234375
INFO:root:Train (Epoch 155): Loss/seq after 00700 batchs: 646.8356323242188
INFO:root:Train (Epoch 155): Loss/seq after 00750 batchs: 654.28759765625
INFO:root:Train (Epoch 155): Loss/seq after 00800 batchs: 658.7571411132812
INFO:root:Train (Epoch 155): Loss/seq after 00850 batchs: 638.8455810546875
INFO:root:Train (Epoch 155): Loss/seq after 00900 batchs: 626.497314453125
INFO:root:Train (Epoch 155): Loss/seq after 00950 batchs: 623.6334838867188
INFO:root:Train (Epoch 155): Loss/seq after 01000 batchs: 615.7064819335938
INFO:root:Train (Epoch 155): Loss/seq after 01050 batchs: 605.02587890625
INFO:root:Train (Epoch 155): Loss/seq after 01100 batchs: 597.0157470703125
INFO:root:Train (Epoch 155): Loss/seq after 01150 batchs: 583.1480712890625
INFO:root:Train (Epoch 155): Loss/seq after 01200 batchs: 588.098388671875
INFO:root:Train (Epoch 155): Loss/seq after 01250 batchs: 586.6812744140625
INFO:root:Train (Epoch 155): Loss/seq after 01300 batchs: 575.603759765625
INFO:root:Train (Epoch 155): Loss/seq after 01350 batchs: 566.76953125
INFO:root:Train (Epoch 155): Loss/seq after 01400 batchs: 571.343505859375
INFO:root:Train (Epoch 155): Loss/seq after 01450 batchs: 573.0740966796875
INFO:root:Train (Epoch 155): Loss/seq after 01500 batchs: 579.5604248046875
INFO:root:Train (Epoch 155): Loss/seq after 01550 batchs: 581.1194458007812
INFO:root:Train (Epoch 155): Loss/seq after 01600 batchs: 575.9691772460938
INFO:root:Train (Epoch 155): Loss/seq after 01650 batchs: 573.90966796875
INFO:root:Train (Epoch 155): Loss/seq after 01700 batchs: 576.6876831054688
INFO:root:Train (Epoch 155): Loss/seq after 01750 batchs: 574.2562255859375
INFO:root:Train (Epoch 155): Loss/seq after 01800 batchs: 571.1458740234375
INFO:root:Train (Epoch 155): Loss/seq after 01850 batchs: 567.1461791992188
INFO:root:Train (Epoch 155): Loss/seq after 01900 batchs: 567.67333984375
INFO:root:Train (Epoch 155): Loss/seq after 01950 batchs: 566.2703857421875
INFO:root:Train (Epoch 155): Loss/seq after 02000 batchs: 565.3142700195312
INFO:root:Train (Epoch 155): Loss/seq after 02050 batchs: 564.1009521484375
INFO:root:Train (Epoch 155): Loss/seq after 02100 batchs: 561.3119506835938
INFO:root:Train (Epoch 155): Loss/seq after 02150 batchs: 559.1965942382812
INFO:root:Train (Epoch 155): Loss/seq after 02200 batchs: 556.2660522460938
INFO:root:Train (Epoch 155): Loss/seq after 02250 batchs: 554.6771240234375
INFO:root:Train (Epoch 155): Loss/seq after 02300 batchs: 551.857421875
INFO:root:Train (Epoch 155): Loss/seq after 02350 batchs: 547.6021118164062
INFO:root:Train (Epoch 155): Loss/seq after 02400 batchs: 549.2567138671875
INFO:root:Train (Epoch 155): Loss/seq after 02450 batchs: 544.6728515625
INFO:root:Train (Epoch 155): Loss/seq after 02500 batchs: 536.7896728515625
INFO:root:Train (Epoch 155): Loss/seq after 02550 batchs: 531.0165405273438
INFO:root:Train (Epoch 155): Loss/seq after 02600 batchs: 529.9995727539062
INFO:root:Train (Epoch 155): Loss/seq after 02650 batchs: 527.7933959960938
INFO:root:Train (Epoch 155): Loss/seq after 02700 batchs: 525.3492431640625
INFO:root:Train (Epoch 155): Loss/seq after 02750 batchs: 522.3727416992188
INFO:root:Train (Epoch 155): Loss/seq after 02800 batchs: 522.0590209960938
INFO:root:Train (Epoch 155): Loss/seq after 02850 batchs: 521.7586059570312
INFO:root:Train (Epoch 155): Loss/seq after 02900 batchs: 523.109619140625
INFO:root:Train (Epoch 155): Loss/seq after 02950 batchs: 522.4222412109375
INFO:root:Train (Epoch 155): Loss/seq after 03000 batchs: 527.7069702148438
INFO:root:Train (Epoch 155): Loss/seq after 03050 batchs: 529.5518188476562
INFO:root:Train (Epoch 155): Loss/seq after 03100 batchs: 532.2692260742188
INFO:root:Train (Epoch 155): Loss/seq after 03150 batchs: 534.8010864257812
INFO:root:Train (Epoch 155): Loss/seq after 03200 batchs: 535.5950317382812
INFO:root:Train (Epoch 155): Loss/seq after 03250 batchs: 538.3236694335938
INFO:root:Train (Epoch 155): Loss/seq after 03300 batchs: 537.4359130859375
INFO:root:Train (Epoch 155): Loss/seq after 03350 batchs: 537.1019897460938
INFO:root:Train (Epoch 155): Loss/seq after 03400 batchs: 533.2994384765625
INFO:root:Train (Epoch 155): Loss/seq after 03450 batchs: 532.1204833984375
INFO:root:Train (Epoch 155): Loss/seq after 03500 batchs: 532.9176635742188
INFO:root:Train (Epoch 155): Loss/seq after 03550 batchs: 530.3173217773438
INFO:root:Train (Epoch 155): Loss/seq after 03600 batchs: 537.83740234375
INFO:root:Train (Epoch 155): Loss/seq after 03650 batchs: 535.4845581054688
INFO:root:Train (Epoch 155): Loss/seq after 03700 batchs: 538.2044677734375
INFO:root:Train (Epoch 155): Loss/seq after 03750 batchs: 542.7227172851562
INFO:root:Train (Epoch 155): Loss/seq after 03800 batchs: 540.5767822265625
INFO:root:Train (Epoch 155): Loss/seq after 03850 batchs: 539.4845581054688
INFO:root:Train (Epoch 155): Loss/seq after 03900 batchs: 542.9218139648438
INFO:root:Train (Epoch 155): Loss/seq after 03950 batchs: 546.4472045898438
INFO:root:Train (Epoch 155): Loss/seq after 04000 batchs: 542.6072387695312
INFO:root:Train (Epoch 155): Loss/seq after 04050 batchs: 539.2999267578125
INFO:root:Train (Epoch 155): Loss/seq after 04100 batchs: 537.6485595703125
INFO:root:Train (Epoch 155): Loss/seq after 04150 batchs: 537.4574584960938
INFO:root:Train (Epoch 155): Loss/seq after 04200 batchs: 535.9793090820312
INFO:root:Train (Epoch 155): Loss/seq after 04250 batchs: 534.283447265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 155): Loss/seq after 00000 batches: 499.92242431640625
INFO:root:# Valid (Epoch 155): Loss/seq after 00050 batches: 759.22021484375
INFO:root:# Valid (Epoch 155): Loss/seq after 00100 batches: 719.3675537109375
INFO:root:# Valid (Epoch 155): Loss/seq after 00150 batches: 541.87060546875
INFO:root:# Valid (Epoch 155): Loss/seq after 00200 batches: 499.88153076171875
INFO:root:Artifacts: Make stick videos for epoch 155
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_155_on_20220414_043203.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_155_index_1454_on_20220414_043203.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 156): Loss/seq after 00000 batchs: 962.3658447265625
INFO:root:Train (Epoch 156): Loss/seq after 00050 batchs: 750.7376098632812
INFO:root:Train (Epoch 156): Loss/seq after 00100 batchs: 740.5665283203125
INFO:root:Train (Epoch 156): Loss/seq after 00150 batchs: 674.8570556640625
INFO:root:Train (Epoch 156): Loss/seq after 00200 batchs: 736.4349365234375
INFO:root:Train (Epoch 156): Loss/seq after 00250 batchs: 818.8345336914062
INFO:root:Train (Epoch 156): Loss/seq after 00300 batchs: 823.6135864257812
INFO:root:Train (Epoch 156): Loss/seq after 00350 batchs: 773.9745483398438
INFO:root:Train (Epoch 156): Loss/seq after 00400 batchs: 773.5997924804688
INFO:root:Train (Epoch 156): Loss/seq after 00450 batchs: 760.6102294921875
INFO:root:Train (Epoch 156): Loss/seq after 00500 batchs: 736.833740234375
INFO:root:Train (Epoch 156): Loss/seq after 00550 batchs: 714.7633666992188
INFO:root:Train (Epoch 156): Loss/seq after 00600 batchs: 690.5716552734375
INFO:root:Train (Epoch 156): Loss/seq after 00650 batchs: 668.193359375
INFO:root:Train (Epoch 156): Loss/seq after 00700 batchs: 642.8319091796875
INFO:root:Train (Epoch 156): Loss/seq after 00750 batchs: 648.9629516601562
INFO:root:Train (Epoch 156): Loss/seq after 00800 batchs: 652.3560791015625
INFO:root:Train (Epoch 156): Loss/seq after 00850 batchs: 632.8692016601562
INFO:root:Train (Epoch 156): Loss/seq after 00900 batchs: 620.8512573242188
INFO:root:Train (Epoch 156): Loss/seq after 00950 batchs: 617.6315307617188
INFO:root:Train (Epoch 156): Loss/seq after 01000 batchs: 609.5106811523438
INFO:root:Train (Epoch 156): Loss/seq after 01050 batchs: 599.1805419921875
INFO:root:Train (Epoch 156): Loss/seq after 01100 batchs: 591.1143188476562
INFO:root:Train (Epoch 156): Loss/seq after 01150 batchs: 577.5054931640625
INFO:root:Train (Epoch 156): Loss/seq after 01200 batchs: 582.5902709960938
INFO:root:Train (Epoch 156): Loss/seq after 01250 batchs: 581.1574096679688
INFO:root:Train (Epoch 156): Loss/seq after 01300 batchs: 570.1298217773438
INFO:root:Train (Epoch 156): Loss/seq after 01350 batchs: 561.7144775390625
INFO:root:Train (Epoch 156): Loss/seq after 01400 batchs: 565.8839721679688
INFO:root:Train (Epoch 156): Loss/seq after 01450 batchs: 567.7122802734375
INFO:root:Train (Epoch 156): Loss/seq after 01500 batchs: 574.392578125
INFO:root:Train (Epoch 156): Loss/seq after 01550 batchs: 576.0093994140625
INFO:root:Train (Epoch 156): Loss/seq after 01600 batchs: 570.9893798828125
INFO:root:Train (Epoch 156): Loss/seq after 01650 batchs: 568.9768676757812
INFO:root:Train (Epoch 156): Loss/seq after 01700 batchs: 571.5568237304688
INFO:root:Train (Epoch 156): Loss/seq after 01750 batchs: 569.0497436523438
INFO:root:Train (Epoch 156): Loss/seq after 01800 batchs: 566.0357666015625
INFO:root:Train (Epoch 156): Loss/seq after 01850 batchs: 562.1826782226562
INFO:root:Train (Epoch 156): Loss/seq after 01900 batchs: 562.7902221679688
INFO:root:Train (Epoch 156): Loss/seq after 01950 batchs: 561.5765380859375
INFO:root:Train (Epoch 156): Loss/seq after 02000 batchs: 560.6311645507812
INFO:root:Train (Epoch 156): Loss/seq after 02050 batchs: 559.3535766601562
INFO:root:Train (Epoch 156): Loss/seq after 02100 batchs: 556.5345458984375
INFO:root:Train (Epoch 156): Loss/seq after 02150 batchs: 554.5233764648438
INFO:root:Train (Epoch 156): Loss/seq after 02200 batchs: 551.6031494140625
INFO:root:Train (Epoch 156): Loss/seq after 02250 batchs: 550.1995239257812
INFO:root:Train (Epoch 156): Loss/seq after 02300 batchs: 547.1590576171875
INFO:root:Train (Epoch 156): Loss/seq after 02350 batchs: 543.6246337890625
INFO:root:Train (Epoch 156): Loss/seq after 02400 batchs: 545.6647338867188
INFO:root:Train (Epoch 156): Loss/seq after 02450 batchs: 541.1930541992188
INFO:root:Train (Epoch 156): Loss/seq after 02500 batchs: 533.37744140625
INFO:root:Train (Epoch 156): Loss/seq after 02550 batchs: 527.5836181640625
INFO:root:Train (Epoch 156): Loss/seq after 02600 batchs: 526.701904296875
INFO:root:Train (Epoch 156): Loss/seq after 02650 batchs: 524.573486328125
INFO:root:Train (Epoch 156): Loss/seq after 02700 batchs: 522.2850341796875
INFO:root:Train (Epoch 156): Loss/seq after 02750 batchs: 519.16357421875
INFO:root:Train (Epoch 156): Loss/seq after 02800 batchs: 518.7620849609375
INFO:root:Train (Epoch 156): Loss/seq after 02850 batchs: 518.5125732421875
INFO:root:Train (Epoch 156): Loss/seq after 02900 batchs: 519.583984375
INFO:root:Train (Epoch 156): Loss/seq after 02950 batchs: 518.90576171875
INFO:root:Train (Epoch 156): Loss/seq after 03000 batchs: 524.2291259765625
INFO:root:Train (Epoch 156): Loss/seq after 03050 batchs: 526.2289428710938
INFO:root:Train (Epoch 156): Loss/seq after 03100 batchs: 528.830810546875
INFO:root:Train (Epoch 156): Loss/seq after 03150 batchs: 531.3245239257812
INFO:root:Train (Epoch 156): Loss/seq after 03200 batchs: 532.37841796875
INFO:root:Train (Epoch 156): Loss/seq after 03250 batchs: 535.158447265625
INFO:root:Train (Epoch 156): Loss/seq after 03300 batchs: 534.7608642578125
INFO:root:Train (Epoch 156): Loss/seq after 03350 batchs: 534.68115234375
INFO:root:Train (Epoch 156): Loss/seq after 03400 batchs: 531.061767578125
INFO:root:Train (Epoch 156): Loss/seq after 03450 batchs: 530.1130981445312
INFO:root:Train (Epoch 156): Loss/seq after 03500 batchs: 530.8181762695312
INFO:root:Train (Epoch 156): Loss/seq after 03550 batchs: 528.2723999023438
INFO:root:Train (Epoch 156): Loss/seq after 03600 batchs: 535.6809692382812
INFO:root:Train (Epoch 156): Loss/seq after 03650 batchs: 533.4561157226562
INFO:root:Train (Epoch 156): Loss/seq after 03700 batchs: 536.0894775390625
INFO:root:Train (Epoch 156): Loss/seq after 03750 batchs: 540.614501953125
INFO:root:Train (Epoch 156): Loss/seq after 03800 batchs: 538.54150390625
INFO:root:Train (Epoch 156): Loss/seq after 03850 batchs: 537.4996948242188
INFO:root:Train (Epoch 156): Loss/seq after 03900 batchs: 540.6304321289062
INFO:root:Train (Epoch 156): Loss/seq after 03950 batchs: 544.2606811523438
INFO:root:Train (Epoch 156): Loss/seq after 04000 batchs: 540.4763793945312
INFO:root:Train (Epoch 156): Loss/seq after 04050 batchs: 537.1668090820312
INFO:root:Train (Epoch 156): Loss/seq after 04100 batchs: 535.5332641601562
INFO:root:Train (Epoch 156): Loss/seq after 04150 batchs: 535.3482666015625
INFO:root:Train (Epoch 156): Loss/seq after 04200 batchs: 533.88134765625
INFO:root:Train (Epoch 156): Loss/seq after 04250 batchs: 532.2411499023438
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 156): Loss/seq after 00000 batches: 489.6522521972656
INFO:root:# Valid (Epoch 156): Loss/seq after 00050 batches: 694.2333984375
INFO:root:# Valid (Epoch 156): Loss/seq after 00100 batches: 700.3944702148438
INFO:root:# Valid (Epoch 156): Loss/seq after 00150 batches: 531.4064331054688
INFO:root:# Valid (Epoch 156): Loss/seq after 00200 batches: 492.4787902832031
INFO:root:Artifacts: Make stick videos for epoch 156
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_156_on_20220414_043721.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_156_index_1882_on_20220414_043721.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 157): Loss/seq after 00000 batchs: 957.9797973632812
INFO:root:Train (Epoch 157): Loss/seq after 00050 batchs: 762.0262451171875
INFO:root:Train (Epoch 157): Loss/seq after 00100 batchs: 751.1250610351562
INFO:root:Train (Epoch 157): Loss/seq after 00150 batchs: 681.6644897460938
INFO:root:Train (Epoch 157): Loss/seq after 00200 batchs: 743.6487426757812
INFO:root:Train (Epoch 157): Loss/seq after 00250 batchs: 818.7904663085938
INFO:root:Train (Epoch 157): Loss/seq after 00300 batchs: 821.3569946289062
INFO:root:Train (Epoch 157): Loss/seq after 00350 batchs: 772.311767578125
INFO:root:Train (Epoch 157): Loss/seq after 00400 batchs: 768.5346069335938
INFO:root:Train (Epoch 157): Loss/seq after 00450 batchs: 756.85986328125
INFO:root:Train (Epoch 157): Loss/seq after 00500 batchs: 735.6930541992188
INFO:root:Train (Epoch 157): Loss/seq after 00550 batchs: 714.3394775390625
INFO:root:Train (Epoch 157): Loss/seq after 00600 batchs: 689.9581909179688
INFO:root:Train (Epoch 157): Loss/seq after 00650 batchs: 667.6992797851562
INFO:root:Train (Epoch 157): Loss/seq after 00700 batchs: 642.905029296875
INFO:root:Train (Epoch 157): Loss/seq after 00750 batchs: 649.6887817382812
INFO:root:Train (Epoch 157): Loss/seq after 00800 batchs: 652.7337036132812
INFO:root:Train (Epoch 157): Loss/seq after 00850 batchs: 633.4066162109375
INFO:root:Train (Epoch 157): Loss/seq after 00900 batchs: 621.0139770507812
INFO:root:Train (Epoch 157): Loss/seq after 00950 batchs: 617.5184326171875
INFO:root:Train (Epoch 157): Loss/seq after 01000 batchs: 608.454833984375
INFO:root:Train (Epoch 157): Loss/seq after 01050 batchs: 597.7922973632812
INFO:root:Train (Epoch 157): Loss/seq after 01100 batchs: 589.7811279296875
INFO:root:Train (Epoch 157): Loss/seq after 01150 batchs: 576.0474853515625
INFO:root:Train (Epoch 157): Loss/seq after 01200 batchs: 581.0303955078125
INFO:root:Train (Epoch 157): Loss/seq after 01250 batchs: 579.57421875
INFO:root:Train (Epoch 157): Loss/seq after 01300 batchs: 568.6956787109375
INFO:root:Train (Epoch 157): Loss/seq after 01350 batchs: 559.8659057617188
INFO:root:Train (Epoch 157): Loss/seq after 01400 batchs: 563.613525390625
INFO:root:Train (Epoch 157): Loss/seq after 01450 batchs: 565.48046875
INFO:root:Train (Epoch 157): Loss/seq after 01500 batchs: 572.1762084960938
INFO:root:Train (Epoch 157): Loss/seq after 01550 batchs: 573.9564819335938
INFO:root:Train (Epoch 157): Loss/seq after 01600 batchs: 569.03955078125
INFO:root:Train (Epoch 157): Loss/seq after 01650 batchs: 566.9166259765625
INFO:root:Train (Epoch 157): Loss/seq after 01700 batchs: 569.2818603515625
INFO:root:Train (Epoch 157): Loss/seq after 01750 batchs: 566.8030395507812
INFO:root:Train (Epoch 157): Loss/seq after 01800 batchs: 563.7525024414062
INFO:root:Train (Epoch 157): Loss/seq after 01850 batchs: 559.9329833984375
INFO:root:Train (Epoch 157): Loss/seq after 01900 batchs: 560.2386474609375
INFO:root:Train (Epoch 157): Loss/seq after 01950 batchs: 559.0166015625
INFO:root:Train (Epoch 157): Loss/seq after 02000 batchs: 558.059326171875
INFO:root:Train (Epoch 157): Loss/seq after 02050 batchs: 556.7439575195312
INFO:root:Train (Epoch 157): Loss/seq after 02100 batchs: 553.9885864257812
INFO:root:Train (Epoch 157): Loss/seq after 02150 batchs: 552.0321044921875
INFO:root:Train (Epoch 157): Loss/seq after 02200 batchs: 549.178466796875
INFO:root:Train (Epoch 157): Loss/seq after 02250 batchs: 547.4590454101562
INFO:root:Train (Epoch 157): Loss/seq after 02300 batchs: 544.3511352539062
INFO:root:Train (Epoch 157): Loss/seq after 02350 batchs: 540.1492309570312
INFO:root:Train (Epoch 157): Loss/seq after 02400 batchs: 542.1807861328125
INFO:root:Train (Epoch 157): Loss/seq after 02450 batchs: 537.6356201171875
INFO:root:Train (Epoch 157): Loss/seq after 02500 batchs: 529.8643798828125
INFO:root:Train (Epoch 157): Loss/seq after 02550 batchs: 524.07666015625
INFO:root:Train (Epoch 157): Loss/seq after 02600 batchs: 523.0709228515625
INFO:root:Train (Epoch 157): Loss/seq after 02650 batchs: 520.8966674804688
INFO:root:Train (Epoch 157): Loss/seq after 02700 batchs: 518.6388549804688
INFO:root:Train (Epoch 157): Loss/seq after 02750 batchs: 515.654541015625
INFO:root:Train (Epoch 157): Loss/seq after 02800 batchs: 515.5117797851562
INFO:root:Train (Epoch 157): Loss/seq after 02850 batchs: 515.27001953125
INFO:root:Train (Epoch 157): Loss/seq after 02900 batchs: 516.5195922851562
INFO:root:Train (Epoch 157): Loss/seq after 02950 batchs: 515.8406372070312
INFO:root:Train (Epoch 157): Loss/seq after 03000 batchs: 521.0902099609375
INFO:root:Train (Epoch 157): Loss/seq after 03050 batchs: 523.03466796875
INFO:root:Train (Epoch 157): Loss/seq after 03100 batchs: 525.4984741210938
INFO:root:Train (Epoch 157): Loss/seq after 03150 batchs: 527.7870483398438
INFO:root:Train (Epoch 157): Loss/seq after 03200 batchs: 528.41455078125
INFO:root:Train (Epoch 157): Loss/seq after 03250 batchs: 530.7544555664062
INFO:root:Train (Epoch 157): Loss/seq after 03300 batchs: 529.8456420898438
INFO:root:Train (Epoch 157): Loss/seq after 03350 batchs: 529.8306884765625
INFO:root:Train (Epoch 157): Loss/seq after 03400 batchs: 526.0025024414062
INFO:root:Train (Epoch 157): Loss/seq after 03450 batchs: 524.8793334960938
INFO:root:Train (Epoch 157): Loss/seq after 03500 batchs: 525.5973510742188
INFO:root:Train (Epoch 157): Loss/seq after 03550 batchs: 523.1347045898438
INFO:root:Train (Epoch 157): Loss/seq after 03600 batchs: 530.7716064453125
INFO:root:Train (Epoch 157): Loss/seq after 03650 batchs: 528.4401245117188
INFO:root:Train (Epoch 157): Loss/seq after 03700 batchs: 531.1843872070312
INFO:root:Train (Epoch 157): Loss/seq after 03750 batchs: 535.802734375
INFO:root:Train (Epoch 157): Loss/seq after 03800 batchs: 533.7637939453125
INFO:root:Train (Epoch 157): Loss/seq after 03850 batchs: 532.6484375
INFO:root:Train (Epoch 157): Loss/seq after 03900 batchs: 535.6766967773438
INFO:root:Train (Epoch 157): Loss/seq after 03950 batchs: 539.1383666992188
INFO:root:Train (Epoch 157): Loss/seq after 04000 batchs: 535.40966796875
INFO:root:Train (Epoch 157): Loss/seq after 04050 batchs: 532.18505859375
INFO:root:Train (Epoch 157): Loss/seq after 04100 batchs: 530.6275024414062
INFO:root:Train (Epoch 157): Loss/seq after 04150 batchs: 530.57470703125
INFO:root:Train (Epoch 157): Loss/seq after 04200 batchs: 529.2101440429688
INFO:root:Train (Epoch 157): Loss/seq after 04250 batchs: 527.609619140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 157): Loss/seq after 00000 batches: 509.58880615234375
INFO:root:# Valid (Epoch 157): Loss/seq after 00050 batches: 730.678466796875
INFO:root:# Valid (Epoch 157): Loss/seq after 00100 batches: 738.5355224609375
INFO:root:# Valid (Epoch 157): Loss/seq after 00150 batches: 554.31298828125
INFO:root:# Valid (Epoch 157): Loss/seq after 00200 batches: 508.65545654296875
INFO:root:Artifacts: Make stick videos for epoch 157
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_157_on_20220414_044239.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_157_index_1294_on_20220414_044239.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 158): Loss/seq after 00000 batchs: 912.1785278320312
INFO:root:Train (Epoch 158): Loss/seq after 00050 batchs: 750.6859130859375
INFO:root:Train (Epoch 158): Loss/seq after 00100 batchs: 748.37841796875
INFO:root:Train (Epoch 158): Loss/seq after 00150 batchs: 680.3657836914062
INFO:root:Train (Epoch 158): Loss/seq after 00200 batchs: 738.9609375
INFO:root:Train (Epoch 158): Loss/seq after 00250 batchs: 815.074462890625
INFO:root:Train (Epoch 158): Loss/seq after 00300 batchs: 819.7755126953125
INFO:root:Train (Epoch 158): Loss/seq after 00350 batchs: 770.9613647460938
INFO:root:Train (Epoch 158): Loss/seq after 00400 batchs: 768.111572265625
INFO:root:Train (Epoch 158): Loss/seq after 00450 batchs: 756.0181274414062
INFO:root:Train (Epoch 158): Loss/seq after 00500 batchs: 731.9080200195312
INFO:root:Train (Epoch 158): Loss/seq after 00550 batchs: 711.0690307617188
INFO:root:Train (Epoch 158): Loss/seq after 00600 batchs: 686.5825805664062
INFO:root:Train (Epoch 158): Loss/seq after 00650 batchs: 665.152587890625
INFO:root:Train (Epoch 158): Loss/seq after 00700 batchs: 640.7435913085938
INFO:root:Train (Epoch 158): Loss/seq after 00750 batchs: 646.0360717773438
INFO:root:Train (Epoch 158): Loss/seq after 00800 batchs: 649.6629638671875
INFO:root:Train (Epoch 158): Loss/seq after 00850 batchs: 629.8973388671875
INFO:root:Train (Epoch 158): Loss/seq after 00900 batchs: 617.6378784179688
INFO:root:Train (Epoch 158): Loss/seq after 00950 batchs: 614.66162109375
INFO:root:Train (Epoch 158): Loss/seq after 01000 batchs: 605.9097900390625
INFO:root:Train (Epoch 158): Loss/seq after 01050 batchs: 595.763671875
INFO:root:Train (Epoch 158): Loss/seq after 01100 batchs: 588.1651611328125
INFO:root:Train (Epoch 158): Loss/seq after 01150 batchs: 574.4732666015625
INFO:root:Train (Epoch 158): Loss/seq after 01200 batchs: 579.6198120117188
INFO:root:Train (Epoch 158): Loss/seq after 01250 batchs: 578.4559326171875
INFO:root:Train (Epoch 158): Loss/seq after 01300 batchs: 567.445068359375
INFO:root:Train (Epoch 158): Loss/seq after 01350 batchs: 558.5484008789062
INFO:root:Train (Epoch 158): Loss/seq after 01400 batchs: 562.1229248046875
INFO:root:Train (Epoch 158): Loss/seq after 01450 batchs: 564.2239990234375
INFO:root:Train (Epoch 158): Loss/seq after 01500 batchs: 570.8906860351562
INFO:root:Train (Epoch 158): Loss/seq after 01550 batchs: 572.9954833984375
INFO:root:Train (Epoch 158): Loss/seq after 01600 batchs: 568.003662109375
INFO:root:Train (Epoch 158): Loss/seq after 01650 batchs: 565.9441528320312
INFO:root:Train (Epoch 158): Loss/seq after 01700 batchs: 568.5082397460938
INFO:root:Train (Epoch 158): Loss/seq after 01750 batchs: 566.0238037109375
INFO:root:Train (Epoch 158): Loss/seq after 01800 batchs: 563.0263671875
INFO:root:Train (Epoch 158): Loss/seq after 01850 batchs: 559.1624755859375
INFO:root:Train (Epoch 158): Loss/seq after 01900 batchs: 559.7991333007812
INFO:root:Train (Epoch 158): Loss/seq after 01950 batchs: 558.6568603515625
INFO:root:Train (Epoch 158): Loss/seq after 02000 batchs: 557.71533203125
INFO:root:Train (Epoch 158): Loss/seq after 02050 batchs: 556.3682861328125
INFO:root:Train (Epoch 158): Loss/seq after 02100 batchs: 553.57080078125
INFO:root:Train (Epoch 158): Loss/seq after 02150 batchs: 551.4940795898438
INFO:root:Train (Epoch 158): Loss/seq after 02200 batchs: 548.6321411132812
INFO:root:Train (Epoch 158): Loss/seq after 02250 batchs: 546.7273559570312
INFO:root:Train (Epoch 158): Loss/seq after 02300 batchs: 543.533447265625
INFO:root:Train (Epoch 158): Loss/seq after 02350 batchs: 539.438232421875
INFO:root:Train (Epoch 158): Loss/seq after 02400 batchs: 541.2352905273438
INFO:root:Train (Epoch 158): Loss/seq after 02450 batchs: 536.6864013671875
INFO:root:Train (Epoch 158): Loss/seq after 02500 batchs: 528.9365234375
INFO:root:Train (Epoch 158): Loss/seq after 02550 batchs: 523.2247924804688
INFO:root:Train (Epoch 158): Loss/seq after 02600 batchs: 522.2843017578125
INFO:root:Train (Epoch 158): Loss/seq after 02650 batchs: 520.0061645507812
INFO:root:Train (Epoch 158): Loss/seq after 02700 batchs: 517.5828247070312
INFO:root:Train (Epoch 158): Loss/seq after 02750 batchs: 513.9859619140625
INFO:root:Train (Epoch 158): Loss/seq after 02800 batchs: 513.1067504882812
INFO:root:Train (Epoch 158): Loss/seq after 02850 batchs: 512.865234375
INFO:root:Train (Epoch 158): Loss/seq after 02900 batchs: 514.1878051757812
INFO:root:Train (Epoch 158): Loss/seq after 02950 batchs: 513.5592041015625
INFO:root:Train (Epoch 158): Loss/seq after 03000 batchs: 518.9089965820312
INFO:root:Train (Epoch 158): Loss/seq after 03050 batchs: 520.70556640625
INFO:root:Train (Epoch 158): Loss/seq after 03100 batchs: 522.8687744140625
INFO:root:Train (Epoch 158): Loss/seq after 03150 batchs: 525.2174682617188
INFO:root:Train (Epoch 158): Loss/seq after 03200 batchs: 525.7702026367188
INFO:root:Train (Epoch 158): Loss/seq after 03250 batchs: 528.2288208007812
INFO:root:Train (Epoch 158): Loss/seq after 03300 batchs: 527.4486083984375
INFO:root:Train (Epoch 158): Loss/seq after 03350 batchs: 527.3492431640625
INFO:root:Train (Epoch 158): Loss/seq after 03400 batchs: 523.7050170898438
INFO:root:Train (Epoch 158): Loss/seq after 03450 batchs: 522.58837890625
INFO:root:Train (Epoch 158): Loss/seq after 03500 batchs: 523.4498901367188
INFO:root:Train (Epoch 158): Loss/seq after 03550 batchs: 520.8189697265625
INFO:root:Train (Epoch 158): Loss/seq after 03600 batchs: 528.3128662109375
INFO:root:Train (Epoch 158): Loss/seq after 03650 batchs: 525.8536376953125
INFO:root:Train (Epoch 158): Loss/seq after 03700 batchs: 528.6207275390625
INFO:root:Train (Epoch 158): Loss/seq after 03750 batchs: 533.2456665039062
INFO:root:Train (Epoch 158): Loss/seq after 03800 batchs: 531.2564697265625
INFO:root:Train (Epoch 158): Loss/seq after 03850 batchs: 530.0810546875
INFO:root:Train (Epoch 158): Loss/seq after 03900 batchs: 533.2564086914062
INFO:root:Train (Epoch 158): Loss/seq after 03950 batchs: 536.6443481445312
INFO:root:Train (Epoch 158): Loss/seq after 04000 batchs: 532.9100341796875
INFO:root:Train (Epoch 158): Loss/seq after 04050 batchs: 529.7140502929688
INFO:root:Train (Epoch 158): Loss/seq after 04100 batchs: 528.1038208007812
INFO:root:Train (Epoch 158): Loss/seq after 04150 batchs: 528.01708984375
INFO:root:Train (Epoch 158): Loss/seq after 04200 batchs: 526.579345703125
INFO:root:Train (Epoch 158): Loss/seq after 04250 batchs: 524.9204711914062
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 158): Loss/seq after 00000 batches: 506.7221984863281
INFO:root:# Valid (Epoch 158): Loss/seq after 00050 batches: 722.1026000976562
INFO:root:# Valid (Epoch 158): Loss/seq after 00100 batches: 718.0818481445312
INFO:root:# Valid (Epoch 158): Loss/seq after 00150 batches: 540.7703247070312
INFO:root:# Valid (Epoch 158): Loss/seq after 00200 batches: 496.9160461425781
INFO:root:Artifacts: Make stick videos for epoch 158
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_158_on_20220414_044758.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_158_index_1625_on_20220414_044758.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 159): Loss/seq after 00000 batchs: 899.2449951171875
INFO:root:Train (Epoch 159): Loss/seq after 00050 batchs: 748.09326171875
INFO:root:Train (Epoch 159): Loss/seq after 00100 batchs: 748.1007690429688
INFO:root:Train (Epoch 159): Loss/seq after 00150 batchs: 684.8732299804688
INFO:root:Train (Epoch 159): Loss/seq after 00200 batchs: 741.3291015625
INFO:root:Train (Epoch 159): Loss/seq after 00250 batchs: 813.8757934570312
INFO:root:Train (Epoch 159): Loss/seq after 00300 batchs: 817.8047485351562
INFO:root:Train (Epoch 159): Loss/seq after 00350 batchs: 769.318115234375
INFO:root:Train (Epoch 159): Loss/seq after 00400 batchs: 764.0325927734375
INFO:root:Train (Epoch 159): Loss/seq after 00450 batchs: 752.4463500976562
INFO:root:Train (Epoch 159): Loss/seq after 00500 batchs: 727.4371337890625
INFO:root:Train (Epoch 159): Loss/seq after 00550 batchs: 706.3457641601562
INFO:root:Train (Epoch 159): Loss/seq after 00600 batchs: 682.5437622070312
INFO:root:Train (Epoch 159): Loss/seq after 00650 batchs: 660.00439453125
INFO:root:Train (Epoch 159): Loss/seq after 00700 batchs: 634.5445556640625
INFO:root:Train (Epoch 159): Loss/seq after 00750 batchs: 639.8713989257812
INFO:root:Train (Epoch 159): Loss/seq after 00800 batchs: 646.412109375
INFO:root:Train (Epoch 159): Loss/seq after 00850 batchs: 626.773193359375
INFO:root:Train (Epoch 159): Loss/seq after 00900 batchs: 614.7929077148438
INFO:root:Train (Epoch 159): Loss/seq after 00950 batchs: 612.6517944335938
INFO:root:Train (Epoch 159): Loss/seq after 01000 batchs: 604.5803833007812
INFO:root:Train (Epoch 159): Loss/seq after 01050 batchs: 595.381591796875
INFO:root:Train (Epoch 159): Loss/seq after 01100 batchs: 588.1207885742188
INFO:root:Train (Epoch 159): Loss/seq after 01150 batchs: 574.7415771484375
INFO:root:Train (Epoch 159): Loss/seq after 01200 batchs: 580.1318969726562
INFO:root:Train (Epoch 159): Loss/seq after 01250 batchs: 578.766845703125
INFO:root:Train (Epoch 159): Loss/seq after 01300 batchs: 567.8728637695312
INFO:root:Train (Epoch 159): Loss/seq after 01350 batchs: 559.1708374023438
INFO:root:Train (Epoch 159): Loss/seq after 01400 batchs: 562.6851806640625
INFO:root:Train (Epoch 159): Loss/seq after 01450 batchs: 564.9635009765625
INFO:root:Train (Epoch 159): Loss/seq after 01500 batchs: 571.7053833007812
INFO:root:Train (Epoch 159): Loss/seq after 01550 batchs: 573.55419921875
INFO:root:Train (Epoch 159): Loss/seq after 01600 batchs: 568.7760620117188
INFO:root:Train (Epoch 159): Loss/seq after 01650 batchs: 566.6040649414062
INFO:root:Train (Epoch 159): Loss/seq after 01700 batchs: 569.2305297851562
INFO:root:Train (Epoch 159): Loss/seq after 01750 batchs: 566.6856079101562
INFO:root:Train (Epoch 159): Loss/seq after 01800 batchs: 563.5809936523438
INFO:root:Train (Epoch 159): Loss/seq after 01850 batchs: 559.7948608398438
INFO:root:Train (Epoch 159): Loss/seq after 01900 batchs: 560.2343139648438
INFO:root:Train (Epoch 159): Loss/seq after 01950 batchs: 559.0484008789062
INFO:root:Train (Epoch 159): Loss/seq after 02000 batchs: 558.0855712890625
INFO:root:Train (Epoch 159): Loss/seq after 02050 batchs: 556.7068481445312
INFO:root:Train (Epoch 159): Loss/seq after 02100 batchs: 553.9076538085938
INFO:root:Train (Epoch 159): Loss/seq after 02150 batchs: 551.8878173828125
INFO:root:Train (Epoch 159): Loss/seq after 02200 batchs: 548.9312133789062
INFO:root:Train (Epoch 159): Loss/seq after 02250 batchs: 547.2348022460938
INFO:root:Train (Epoch 159): Loss/seq after 02300 batchs: 544.0377197265625
INFO:root:Train (Epoch 159): Loss/seq after 02350 batchs: 539.9484252929688
INFO:root:Train (Epoch 159): Loss/seq after 02400 batchs: 541.707275390625
INFO:root:Train (Epoch 159): Loss/seq after 02450 batchs: 537.1389770507812
INFO:root:Train (Epoch 159): Loss/seq after 02500 batchs: 529.352294921875
INFO:root:Train (Epoch 159): Loss/seq after 02550 batchs: 523.6047973632812
INFO:root:Train (Epoch 159): Loss/seq after 02600 batchs: 522.61376953125
INFO:root:Train (Epoch 159): Loss/seq after 02650 batchs: 520.3131103515625
INFO:root:Train (Epoch 159): Loss/seq after 02700 batchs: 517.8782348632812
INFO:root:Train (Epoch 159): Loss/seq after 02750 batchs: 514.6369018554688
INFO:root:Train (Epoch 159): Loss/seq after 02800 batchs: 514.1357421875
INFO:root:Train (Epoch 159): Loss/seq after 02850 batchs: 513.7196044921875
INFO:root:Train (Epoch 159): Loss/seq after 02900 batchs: 514.9701538085938
INFO:root:Train (Epoch 159): Loss/seq after 02950 batchs: 514.4017333984375
INFO:root:Train (Epoch 159): Loss/seq after 03000 batchs: 519.773193359375
INFO:root:Train (Epoch 159): Loss/seq after 03050 batchs: 521.9148559570312
INFO:root:Train (Epoch 159): Loss/seq after 03100 batchs: 524.1954956054688
INFO:root:Train (Epoch 159): Loss/seq after 03150 batchs: 526.0863647460938
INFO:root:Train (Epoch 159): Loss/seq after 03200 batchs: 526.7734985351562
INFO:root:Train (Epoch 159): Loss/seq after 03250 batchs: 529.1014404296875
INFO:root:Train (Epoch 159): Loss/seq after 03300 batchs: 528.2520751953125
INFO:root:Train (Epoch 159): Loss/seq after 03350 batchs: 528.160888671875
INFO:root:Train (Epoch 159): Loss/seq after 03400 batchs: 524.4055786132812
INFO:root:Train (Epoch 159): Loss/seq after 03450 batchs: 523.1893310546875
INFO:root:Train (Epoch 159): Loss/seq after 03500 batchs: 523.9577026367188
INFO:root:Train (Epoch 159): Loss/seq after 03550 batchs: 521.5352172851562
INFO:root:Train (Epoch 159): Loss/seq after 03600 batchs: 528.9474487304688
INFO:root:Train (Epoch 159): Loss/seq after 03650 batchs: 526.714599609375
INFO:root:Train (Epoch 159): Loss/seq after 03700 batchs: 529.3743896484375
INFO:root:Train (Epoch 159): Loss/seq after 03750 batchs: 533.9832763671875
INFO:root:Train (Epoch 159): Loss/seq after 03800 batchs: 531.9771728515625
INFO:root:Train (Epoch 159): Loss/seq after 03850 batchs: 530.8350219726562
INFO:root:Train (Epoch 159): Loss/seq after 03900 batchs: 533.9783935546875
INFO:root:Train (Epoch 159): Loss/seq after 03950 batchs: 537.4854736328125
INFO:root:Train (Epoch 159): Loss/seq after 04000 batchs: 533.751220703125
INFO:root:Train (Epoch 159): Loss/seq after 04050 batchs: 530.5410766601562
INFO:root:Train (Epoch 159): Loss/seq after 04100 batchs: 528.95654296875
INFO:root:Train (Epoch 159): Loss/seq after 04150 batchs: 528.834228515625
INFO:root:Train (Epoch 159): Loss/seq after 04200 batchs: 527.3172607421875
INFO:root:Train (Epoch 159): Loss/seq after 04250 batchs: 525.6384887695312
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 159): Loss/seq after 00000 batches: 505.4079284667969
INFO:root:# Valid (Epoch 159): Loss/seq after 00050 batches: 736.0671997070312
INFO:root:# Valid (Epoch 159): Loss/seq after 00100 batches: 726.39013671875
INFO:root:# Valid (Epoch 159): Loss/seq after 00150 batches: 549.791259765625
INFO:root:# Valid (Epoch 159): Loss/seq after 00200 batches: 511.4316101074219
INFO:root:Artifacts: Make stick videos for epoch 159
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_159_on_20220414_045318.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_159_index_869_on_20220414_045318.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 160): Loss/seq after 00000 batchs: 870.5800170898438
INFO:root:Train (Epoch 160): Loss/seq after 00050 batchs: 733.31640625
INFO:root:Train (Epoch 160): Loss/seq after 00100 batchs: 727.4031372070312
INFO:root:Train (Epoch 160): Loss/seq after 00150 batchs: 663.4730834960938
INFO:root:Train (Epoch 160): Loss/seq after 00200 batchs: 727.41259765625
INFO:root:Train (Epoch 160): Loss/seq after 00250 batchs: 801.4867553710938
INFO:root:Train (Epoch 160): Loss/seq after 00300 batchs: 807.2882080078125
INFO:root:Train (Epoch 160): Loss/seq after 00350 batchs: 759.3857421875
INFO:root:Train (Epoch 160): Loss/seq after 00400 batchs: 757.2117919921875
INFO:root:Train (Epoch 160): Loss/seq after 00450 batchs: 746.27001953125
INFO:root:Train (Epoch 160): Loss/seq after 00500 batchs: 723.4673461914062
INFO:root:Train (Epoch 160): Loss/seq after 00550 batchs: 702.5040283203125
INFO:root:Train (Epoch 160): Loss/seq after 00600 batchs: 678.7423095703125
INFO:root:Train (Epoch 160): Loss/seq after 00650 batchs: 656.8961181640625
INFO:root:Train (Epoch 160): Loss/seq after 00700 batchs: 632.298828125
INFO:root:Train (Epoch 160): Loss/seq after 00750 batchs: 637.8626098632812
INFO:root:Train (Epoch 160): Loss/seq after 00800 batchs: 642.3405151367188
INFO:root:Train (Epoch 160): Loss/seq after 00850 batchs: 623.3947143554688
INFO:root:Train (Epoch 160): Loss/seq after 00900 batchs: 610.9011840820312
INFO:root:Train (Epoch 160): Loss/seq after 00950 batchs: 607.6572265625
INFO:root:Train (Epoch 160): Loss/seq after 01000 batchs: 599.236083984375
INFO:root:Train (Epoch 160): Loss/seq after 01050 batchs: 590.051025390625
INFO:root:Train (Epoch 160): Loss/seq after 01100 batchs: 582.2144165039062
INFO:root:Train (Epoch 160): Loss/seq after 01150 batchs: 568.7538452148438
INFO:root:Train (Epoch 160): Loss/seq after 01200 batchs: 574.14990234375
INFO:root:Train (Epoch 160): Loss/seq after 01250 batchs: 572.916015625
INFO:root:Train (Epoch 160): Loss/seq after 01300 batchs: 561.807861328125
INFO:root:Train (Epoch 160): Loss/seq after 01350 batchs: 553.000244140625
INFO:root:Train (Epoch 160): Loss/seq after 01400 batchs: 556.4649047851562
INFO:root:Train (Epoch 160): Loss/seq after 01450 batchs: 558.7798461914062
INFO:root:Train (Epoch 160): Loss/seq after 01500 batchs: 565.5390625
INFO:root:Train (Epoch 160): Loss/seq after 01550 batchs: 567.3449096679688
INFO:root:Train (Epoch 160): Loss/seq after 01600 batchs: 562.4132690429688
INFO:root:Train (Epoch 160): Loss/seq after 01650 batchs: 560.5560302734375
INFO:root:Train (Epoch 160): Loss/seq after 01700 batchs: 563.6788330078125
INFO:root:Train (Epoch 160): Loss/seq after 01750 batchs: 561.2810668945312
INFO:root:Train (Epoch 160): Loss/seq after 01800 batchs: 558.3038940429688
INFO:root:Train (Epoch 160): Loss/seq after 01850 batchs: 554.439697265625
INFO:root:Train (Epoch 160): Loss/seq after 01900 batchs: 555.07080078125
INFO:root:Train (Epoch 160): Loss/seq after 01950 batchs: 553.8007202148438
INFO:root:Train (Epoch 160): Loss/seq after 02000 batchs: 552.9228515625
INFO:root:Train (Epoch 160): Loss/seq after 02050 batchs: 551.6902465820312
INFO:root:Train (Epoch 160): Loss/seq after 02100 batchs: 549.0332641601562
INFO:root:Train (Epoch 160): Loss/seq after 02150 batchs: 547.0728759765625
INFO:root:Train (Epoch 160): Loss/seq after 02200 batchs: 544.2868041992188
INFO:root:Train (Epoch 160): Loss/seq after 02250 batchs: 542.6423950195312
INFO:root:Train (Epoch 160): Loss/seq after 02300 batchs: 539.415283203125
INFO:root:Train (Epoch 160): Loss/seq after 02350 batchs: 535.30712890625
INFO:root:Train (Epoch 160): Loss/seq after 02400 batchs: 537.0519409179688
INFO:root:Train (Epoch 160): Loss/seq after 02450 batchs: 532.5057373046875
INFO:root:Train (Epoch 160): Loss/seq after 02500 batchs: 524.7894287109375
INFO:root:Train (Epoch 160): Loss/seq after 02550 batchs: 519.0631103515625
INFO:root:Train (Epoch 160): Loss/seq after 02600 batchs: 518.0368041992188
INFO:root:Train (Epoch 160): Loss/seq after 02650 batchs: 515.77197265625
INFO:root:Train (Epoch 160): Loss/seq after 02700 batchs: 513.5311889648438
INFO:root:Train (Epoch 160): Loss/seq after 02750 batchs: 510.1635437011719
INFO:root:Train (Epoch 160): Loss/seq after 02800 batchs: 509.9173889160156
INFO:root:Train (Epoch 160): Loss/seq after 02850 batchs: 509.72039794921875
INFO:root:Train (Epoch 160): Loss/seq after 02900 batchs: 511.09478759765625
INFO:root:Train (Epoch 160): Loss/seq after 02950 batchs: 510.52032470703125
INFO:root:Train (Epoch 160): Loss/seq after 03000 batchs: 515.8714599609375
INFO:root:Train (Epoch 160): Loss/seq after 03050 batchs: 518.1591186523438
INFO:root:Train (Epoch 160): Loss/seq after 03100 batchs: 520.6201782226562
INFO:root:Train (Epoch 160): Loss/seq after 03150 batchs: 522.6079711914062
INFO:root:Train (Epoch 160): Loss/seq after 03200 batchs: 522.942626953125
INFO:root:Train (Epoch 160): Loss/seq after 03250 batchs: 525.5508422851562
INFO:root:Train (Epoch 160): Loss/seq after 03300 batchs: 524.9202270507812
INFO:root:Train (Epoch 160): Loss/seq after 03350 batchs: 525.044921875
INFO:root:Train (Epoch 160): Loss/seq after 03400 batchs: 521.2664184570312
INFO:root:Train (Epoch 160): Loss/seq after 03450 batchs: 520.1333618164062
INFO:root:Train (Epoch 160): Loss/seq after 03500 batchs: 521.0667724609375
INFO:root:Train (Epoch 160): Loss/seq after 03550 batchs: 518.6324462890625
INFO:root:Train (Epoch 160): Loss/seq after 03600 batchs: 526.1902465820312
INFO:root:Train (Epoch 160): Loss/seq after 03650 batchs: 523.87744140625
INFO:root:Train (Epoch 160): Loss/seq after 03700 batchs: 526.6372680664062
INFO:root:Train (Epoch 160): Loss/seq after 03750 batchs: 531.2216186523438
INFO:root:Train (Epoch 160): Loss/seq after 03800 batchs: 529.2425537109375
INFO:root:Train (Epoch 160): Loss/seq after 03850 batchs: 528.1181640625
INFO:root:Train (Epoch 160): Loss/seq after 03900 batchs: 531.2950439453125
INFO:root:Train (Epoch 160): Loss/seq after 03950 batchs: 534.5743408203125
INFO:root:Train (Epoch 160): Loss/seq after 04000 batchs: 530.8618774414062
INFO:root:Train (Epoch 160): Loss/seq after 04050 batchs: 527.649169921875
INFO:root:Train (Epoch 160): Loss/seq after 04100 batchs: 526.1383666992188
INFO:root:Train (Epoch 160): Loss/seq after 04150 batchs: 526.0081176757812
INFO:root:Train (Epoch 160): Loss/seq after 04200 batchs: 524.6573486328125
INFO:root:Train (Epoch 160): Loss/seq after 04250 batchs: 522.9295654296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 160): Loss/seq after 00000 batches: 513.4763793945312
INFO:root:# Valid (Epoch 160): Loss/seq after 00050 batches: 688.286376953125
INFO:root:# Valid (Epoch 160): Loss/seq after 00100 batches: 703.235595703125
INFO:root:# Valid (Epoch 160): Loss/seq after 00150 batches: 529.5245971679688
INFO:root:# Valid (Epoch 160): Loss/seq after 00200 batches: 488.40203857421875
INFO:root:Artifacts: Make stick videos for epoch 160
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_160_on_20220414_045835.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_160_index_620_on_20220414_045835.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 161): Loss/seq after 00000 batchs: 856.839599609375
INFO:root:Train (Epoch 161): Loss/seq after 00050 batchs: 741.2618408203125
INFO:root:Train (Epoch 161): Loss/seq after 00100 batchs: 733.1993408203125
INFO:root:Train (Epoch 161): Loss/seq after 00150 batchs: 667.2362670898438
INFO:root:Train (Epoch 161): Loss/seq after 00200 batchs: 726.8726806640625
INFO:root:Train (Epoch 161): Loss/seq after 00250 batchs: 795.7075805664062
INFO:root:Train (Epoch 161): Loss/seq after 00300 batchs: 801.7823486328125
INFO:root:Train (Epoch 161): Loss/seq after 00350 batchs: 754.795654296875
INFO:root:Train (Epoch 161): Loss/seq after 00400 batchs: 752.7202758789062
INFO:root:Train (Epoch 161): Loss/seq after 00450 batchs: 742.0769653320312
INFO:root:Train (Epoch 161): Loss/seq after 00500 batchs: 719.0447387695312
INFO:root:Train (Epoch 161): Loss/seq after 00550 batchs: 699.5015869140625
INFO:root:Train (Epoch 161): Loss/seq after 00600 batchs: 675.0606079101562
INFO:root:Train (Epoch 161): Loss/seq after 00650 batchs: 652.345947265625
INFO:root:Train (Epoch 161): Loss/seq after 00700 batchs: 627.2396240234375
INFO:root:Train (Epoch 161): Loss/seq after 00750 batchs: 632.77392578125
INFO:root:Train (Epoch 161): Loss/seq after 00800 batchs: 639.4637451171875
INFO:root:Train (Epoch 161): Loss/seq after 00850 batchs: 620.3399658203125
INFO:root:Train (Epoch 161): Loss/seq after 00900 batchs: 608.1996459960938
INFO:root:Train (Epoch 161): Loss/seq after 00950 batchs: 604.6915283203125
INFO:root:Train (Epoch 161): Loss/seq after 01000 batchs: 596.271484375
INFO:root:Train (Epoch 161): Loss/seq after 01050 batchs: 585.592529296875
INFO:root:Train (Epoch 161): Loss/seq after 01100 batchs: 578.1424560546875
INFO:root:Train (Epoch 161): Loss/seq after 01150 batchs: 565.07421875
INFO:root:Train (Epoch 161): Loss/seq after 01200 batchs: 570.4976196289062
INFO:root:Train (Epoch 161): Loss/seq after 01250 batchs: 569.2432250976562
INFO:root:Train (Epoch 161): Loss/seq after 01300 batchs: 558.50146484375
INFO:root:Train (Epoch 161): Loss/seq after 01350 batchs: 549.9041748046875
INFO:root:Train (Epoch 161): Loss/seq after 01400 batchs: 553.3152465820312
INFO:root:Train (Epoch 161): Loss/seq after 01450 batchs: 555.622314453125
INFO:root:Train (Epoch 161): Loss/seq after 01500 batchs: 562.6915283203125
INFO:root:Train (Epoch 161): Loss/seq after 01550 batchs: 564.7801513671875
INFO:root:Train (Epoch 161): Loss/seq after 01600 batchs: 559.9461669921875
INFO:root:Train (Epoch 161): Loss/seq after 01650 batchs: 557.921875
INFO:root:Train (Epoch 161): Loss/seq after 01700 batchs: 560.4337158203125
INFO:root:Train (Epoch 161): Loss/seq after 01750 batchs: 558.194091796875
INFO:root:Train (Epoch 161): Loss/seq after 01800 batchs: 555.2135620117188
INFO:root:Train (Epoch 161): Loss/seq after 01850 batchs: 551.4485473632812
INFO:root:Train (Epoch 161): Loss/seq after 01900 batchs: 551.6851806640625
INFO:root:Train (Epoch 161): Loss/seq after 01950 batchs: 550.9579467773438
INFO:root:Train (Epoch 161): Loss/seq after 02000 batchs: 550.1524047851562
INFO:root:Train (Epoch 161): Loss/seq after 02050 batchs: 548.9599609375
INFO:root:Train (Epoch 161): Loss/seq after 02100 batchs: 546.3758544921875
INFO:root:Train (Epoch 161): Loss/seq after 02150 batchs: 544.4405517578125
INFO:root:Train (Epoch 161): Loss/seq after 02200 batchs: 541.6829833984375
INFO:root:Train (Epoch 161): Loss/seq after 02250 batchs: 539.8438720703125
INFO:root:Train (Epoch 161): Loss/seq after 02300 batchs: 536.7376708984375
INFO:root:Train (Epoch 161): Loss/seq after 02350 batchs: 532.7445068359375
INFO:root:Train (Epoch 161): Loss/seq after 02400 batchs: 534.637939453125
INFO:root:Train (Epoch 161): Loss/seq after 02450 batchs: 530.1539916992188
INFO:root:Train (Epoch 161): Loss/seq after 02500 batchs: 522.4711303710938
INFO:root:Train (Epoch 161): Loss/seq after 02550 batchs: 516.79296875
INFO:root:Train (Epoch 161): Loss/seq after 02600 batchs: 515.8102416992188
INFO:root:Train (Epoch 161): Loss/seq after 02650 batchs: 513.4842529296875
INFO:root:Train (Epoch 161): Loss/seq after 02700 batchs: 511.1425476074219
INFO:root:Train (Epoch 161): Loss/seq after 02750 batchs: 507.8597106933594
INFO:root:Train (Epoch 161): Loss/seq after 02800 batchs: 507.1307067871094
INFO:root:Train (Epoch 161): Loss/seq after 02850 batchs: 506.7257080078125
INFO:root:Train (Epoch 161): Loss/seq after 02900 batchs: 507.8680725097656
INFO:root:Train (Epoch 161): Loss/seq after 02950 batchs: 507.30767822265625
INFO:root:Train (Epoch 161): Loss/seq after 03000 batchs: 512.700927734375
INFO:root:Train (Epoch 161): Loss/seq after 03050 batchs: 514.5845947265625
INFO:root:Train (Epoch 161): Loss/seq after 03100 batchs: 517.3264770507812
INFO:root:Train (Epoch 161): Loss/seq after 03150 batchs: 519.2483520507812
INFO:root:Train (Epoch 161): Loss/seq after 03200 batchs: 520.2528686523438
INFO:root:Train (Epoch 161): Loss/seq after 03250 batchs: 522.8881225585938
INFO:root:Train (Epoch 161): Loss/seq after 03300 batchs: 522.2792358398438
INFO:root:Train (Epoch 161): Loss/seq after 03350 batchs: 522.2012329101562
INFO:root:Train (Epoch 161): Loss/seq after 03400 batchs: 518.6264038085938
INFO:root:Train (Epoch 161): Loss/seq after 03450 batchs: 517.552001953125
INFO:root:Train (Epoch 161): Loss/seq after 03500 batchs: 518.2118530273438
INFO:root:Train (Epoch 161): Loss/seq after 03550 batchs: 515.6927490234375
INFO:root:Train (Epoch 161): Loss/seq after 03600 batchs: 523.2999267578125
INFO:root:Train (Epoch 161): Loss/seq after 03650 batchs: 520.94482421875
INFO:root:Train (Epoch 161): Loss/seq after 03700 batchs: 523.7512817382812
INFO:root:Train (Epoch 161): Loss/seq after 03750 batchs: 528.3475341796875
INFO:root:Train (Epoch 161): Loss/seq after 03800 batchs: 526.3472290039062
INFO:root:Train (Epoch 161): Loss/seq after 03850 batchs: 525.2877197265625
INFO:root:Train (Epoch 161): Loss/seq after 03900 batchs: 528.252197265625
INFO:root:Train (Epoch 161): Loss/seq after 03950 batchs: 531.5195922851562
INFO:root:Train (Epoch 161): Loss/seq after 04000 batchs: 527.8101806640625
INFO:root:Train (Epoch 161): Loss/seq after 04050 batchs: 524.6526489257812
INFO:root:Train (Epoch 161): Loss/seq after 04100 batchs: 523.1305541992188
INFO:root:Train (Epoch 161): Loss/seq after 04150 batchs: 523.0762329101562
INFO:root:Train (Epoch 161): Loss/seq after 04200 batchs: 521.58154296875
INFO:root:Train (Epoch 161): Loss/seq after 04250 batchs: 519.8955078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 161): Loss/seq after 00000 batches: 461.3687744140625
INFO:root:# Valid (Epoch 161): Loss/seq after 00050 batches: 719.6669311523438
INFO:root:# Valid (Epoch 161): Loss/seq after 00100 batches: 699.8119506835938
INFO:root:# Valid (Epoch 161): Loss/seq after 00150 batches: 528.1026000976562
INFO:root:# Valid (Epoch 161): Loss/seq after 00200 batches: 488.2904357910156
INFO:root:Artifacts: Make stick videos for epoch 161
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_161_on_20220414_050353.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_161_index_1578_on_20220414_050353.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 162): Loss/seq after 00000 batchs: 899.3651733398438
INFO:root:Train (Epoch 162): Loss/seq after 00050 batchs: 725.2640380859375
INFO:root:Train (Epoch 162): Loss/seq after 00100 batchs: 729.5652465820312
INFO:root:Train (Epoch 162): Loss/seq after 00150 batchs: 664.6842041015625
INFO:root:Train (Epoch 162): Loss/seq after 00200 batchs: 724.5111083984375
INFO:root:Train (Epoch 162): Loss/seq after 00250 batchs: 795.9177856445312
INFO:root:Train (Epoch 162): Loss/seq after 00300 batchs: 799.751220703125
INFO:root:Train (Epoch 162): Loss/seq after 00350 batchs: 753.9796752929688
INFO:root:Train (Epoch 162): Loss/seq after 00400 batchs: 751.2719116210938
INFO:root:Train (Epoch 162): Loss/seq after 00450 batchs: 741.529296875
INFO:root:Train (Epoch 162): Loss/seq after 00500 batchs: 719.4291381835938
INFO:root:Train (Epoch 162): Loss/seq after 00550 batchs: 699.4725341796875
INFO:root:Train (Epoch 162): Loss/seq after 00600 batchs: 675.4214477539062
INFO:root:Train (Epoch 162): Loss/seq after 00650 batchs: 652.632568359375
INFO:root:Train (Epoch 162): Loss/seq after 00700 batchs: 627.6702880859375
INFO:root:Train (Epoch 162): Loss/seq after 00750 batchs: 633.7015380859375
INFO:root:Train (Epoch 162): Loss/seq after 00800 batchs: 637.2210083007812
INFO:root:Train (Epoch 162): Loss/seq after 00850 batchs: 618.2399291992188
INFO:root:Train (Epoch 162): Loss/seq after 00900 batchs: 606.19921875
INFO:root:Train (Epoch 162): Loss/seq after 00950 batchs: 602.6387939453125
INFO:root:Train (Epoch 162): Loss/seq after 01000 batchs: 594.0224609375
INFO:root:Train (Epoch 162): Loss/seq after 01050 batchs: 583.5800170898438
INFO:root:Train (Epoch 162): Loss/seq after 01100 batchs: 575.5562133789062
INFO:root:Train (Epoch 162): Loss/seq after 01150 batchs: 562.4024658203125
INFO:root:Train (Epoch 162): Loss/seq after 01200 batchs: 567.7959594726562
INFO:root:Train (Epoch 162): Loss/seq after 01250 batchs: 566.7305908203125
INFO:root:Train (Epoch 162): Loss/seq after 01300 batchs: 555.79296875
INFO:root:Train (Epoch 162): Loss/seq after 01350 batchs: 546.8800048828125
INFO:root:Train (Epoch 162): Loss/seq after 01400 batchs: 549.625244140625
INFO:root:Train (Epoch 162): Loss/seq after 01450 batchs: 551.9820556640625
INFO:root:Train (Epoch 162): Loss/seq after 01500 batchs: 558.9205932617188
INFO:root:Train (Epoch 162): Loss/seq after 01550 batchs: 560.7792358398438
INFO:root:Train (Epoch 162): Loss/seq after 01600 batchs: 555.9625244140625
INFO:root:Train (Epoch 162): Loss/seq after 01650 batchs: 553.9668579101562
INFO:root:Train (Epoch 162): Loss/seq after 01700 batchs: 556.6815185546875
INFO:root:Train (Epoch 162): Loss/seq after 01750 batchs: 554.460693359375
INFO:root:Train (Epoch 162): Loss/seq after 01800 batchs: 551.5341186523438
INFO:root:Train (Epoch 162): Loss/seq after 01850 batchs: 547.9261474609375
INFO:root:Train (Epoch 162): Loss/seq after 01900 batchs: 548.1829833984375
INFO:root:Train (Epoch 162): Loss/seq after 01950 batchs: 547.040771484375
INFO:root:Train (Epoch 162): Loss/seq after 02000 batchs: 546.3764038085938
INFO:root:Train (Epoch 162): Loss/seq after 02050 batchs: 545.3502197265625
INFO:root:Train (Epoch 162): Loss/seq after 02100 batchs: 542.7887573242188
INFO:root:Train (Epoch 162): Loss/seq after 02150 batchs: 541.1115112304688
INFO:root:Train (Epoch 162): Loss/seq after 02200 batchs: 538.6263427734375
INFO:root:Train (Epoch 162): Loss/seq after 02250 batchs: 536.8495483398438
INFO:root:Train (Epoch 162): Loss/seq after 02300 batchs: 533.5540771484375
INFO:root:Train (Epoch 162): Loss/seq after 02350 batchs: 529.5309448242188
INFO:root:Train (Epoch 162): Loss/seq after 02400 batchs: 531.2689819335938
INFO:root:Train (Epoch 162): Loss/seq after 02450 batchs: 526.8565063476562
INFO:root:Train (Epoch 162): Loss/seq after 02500 batchs: 519.2261352539062
INFO:root:Train (Epoch 162): Loss/seq after 02550 batchs: 513.6839599609375
INFO:root:Train (Epoch 162): Loss/seq after 02600 batchs: 512.60302734375
INFO:root:Train (Epoch 162): Loss/seq after 02650 batchs: 510.3608093261719
INFO:root:Train (Epoch 162): Loss/seq after 02700 batchs: 507.9909362792969
INFO:root:Train (Epoch 162): Loss/seq after 02750 batchs: 504.5496826171875
INFO:root:Train (Epoch 162): Loss/seq after 02800 batchs: 503.6365051269531
INFO:root:Train (Epoch 162): Loss/seq after 02850 batchs: 503.31353759765625
INFO:root:Train (Epoch 162): Loss/seq after 02900 batchs: 504.42889404296875
INFO:root:Train (Epoch 162): Loss/seq after 02950 batchs: 503.8468322753906
INFO:root:Train (Epoch 162): Loss/seq after 03000 batchs: 509.2483215332031
INFO:root:Train (Epoch 162): Loss/seq after 03050 batchs: 511.22076416015625
INFO:root:Train (Epoch 162): Loss/seq after 03100 batchs: 513.4172973632812
INFO:root:Train (Epoch 162): Loss/seq after 03150 batchs: 515.644287109375
INFO:root:Train (Epoch 162): Loss/seq after 03200 batchs: 516.1101684570312
INFO:root:Train (Epoch 162): Loss/seq after 03250 batchs: 518.6089477539062
INFO:root:Train (Epoch 162): Loss/seq after 03300 batchs: 518.1761474609375
INFO:root:Train (Epoch 162): Loss/seq after 03350 batchs: 518.1375732421875
INFO:root:Train (Epoch 162): Loss/seq after 03400 batchs: 514.5394897460938
INFO:root:Train (Epoch 162): Loss/seq after 03450 batchs: 513.52978515625
INFO:root:Train (Epoch 162): Loss/seq after 03500 batchs: 514.345947265625
INFO:root:Train (Epoch 162): Loss/seq after 03550 batchs: 512.009521484375
INFO:root:Train (Epoch 162): Loss/seq after 03600 batchs: 519.4437255859375
INFO:root:Train (Epoch 162): Loss/seq after 03650 batchs: 517.1143798828125
INFO:root:Train (Epoch 162): Loss/seq after 03700 batchs: 519.8801879882812
INFO:root:Train (Epoch 162): Loss/seq after 03750 batchs: 524.5634765625
INFO:root:Train (Epoch 162): Loss/seq after 03800 batchs: 522.6607666015625
INFO:root:Train (Epoch 162): Loss/seq after 03850 batchs: 521.6981811523438
INFO:root:Train (Epoch 162): Loss/seq after 03900 batchs: 524.7821655273438
INFO:root:Train (Epoch 162): Loss/seq after 03950 batchs: 528.1239013671875
INFO:root:Train (Epoch 162): Loss/seq after 04000 batchs: 524.4448852539062
INFO:root:Train (Epoch 162): Loss/seq after 04050 batchs: 521.2828369140625
INFO:root:Train (Epoch 162): Loss/seq after 04100 batchs: 519.8567504882812
INFO:root:Train (Epoch 162): Loss/seq after 04150 batchs: 519.77783203125
INFO:root:Train (Epoch 162): Loss/seq after 04200 batchs: 518.5012817382812
INFO:root:Train (Epoch 162): Loss/seq after 04250 batchs: 516.8463745117188
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 162): Loss/seq after 00000 batches: 494.37591552734375
INFO:root:# Valid (Epoch 162): Loss/seq after 00050 batches: 692.8648071289062
INFO:root:# Valid (Epoch 162): Loss/seq after 00100 batches: 696.646484375
INFO:root:# Valid (Epoch 162): Loss/seq after 00150 batches: 525.2649536132812
INFO:root:# Valid (Epoch 162): Loss/seq after 00200 batches: 484.4830017089844
INFO:root:Artifacts: Make stick videos for epoch 162
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_162_on_20220414_050910.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_162_index_548_on_20220414_050910.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 163): Loss/seq after 00000 batchs: 857.194091796875
INFO:root:Train (Epoch 163): Loss/seq after 00050 batchs: 731.7862548828125
INFO:root:Train (Epoch 163): Loss/seq after 00100 batchs: 715.6715698242188
INFO:root:Train (Epoch 163): Loss/seq after 00150 batchs: 653.2039184570312
INFO:root:Train (Epoch 163): Loss/seq after 00200 batchs: 714.7222290039062
INFO:root:Train (Epoch 163): Loss/seq after 00250 batchs: 790.5891723632812
INFO:root:Train (Epoch 163): Loss/seq after 00300 batchs: 795.867431640625
INFO:root:Train (Epoch 163): Loss/seq after 00350 batchs: 749.3037719726562
INFO:root:Train (Epoch 163): Loss/seq after 00400 batchs: 745.1395874023438
INFO:root:Train (Epoch 163): Loss/seq after 00450 batchs: 735.5302124023438
INFO:root:Train (Epoch 163): Loss/seq after 00500 batchs: 712.40673828125
INFO:root:Train (Epoch 163): Loss/seq after 00550 batchs: 692.8174438476562
INFO:root:Train (Epoch 163): Loss/seq after 00600 batchs: 668.723876953125
INFO:root:Train (Epoch 163): Loss/seq after 00650 batchs: 646.683349609375
INFO:root:Train (Epoch 163): Loss/seq after 00700 batchs: 621.5260009765625
INFO:root:Train (Epoch 163): Loss/seq after 00750 batchs: 625.4548950195312
INFO:root:Train (Epoch 163): Loss/seq after 00800 batchs: 629.9815063476562
INFO:root:Train (Epoch 163): Loss/seq after 00850 batchs: 611.2765502929688
INFO:root:Train (Epoch 163): Loss/seq after 00900 batchs: 600.069091796875
INFO:root:Train (Epoch 163): Loss/seq after 00950 batchs: 597.3020629882812
INFO:root:Train (Epoch 163): Loss/seq after 01000 batchs: 588.8300170898438
INFO:root:Train (Epoch 163): Loss/seq after 01050 batchs: 578.572265625
INFO:root:Train (Epoch 163): Loss/seq after 01100 batchs: 571.2700805664062
INFO:root:Train (Epoch 163): Loss/seq after 01150 batchs: 557.970947265625
INFO:root:Train (Epoch 163): Loss/seq after 01200 batchs: 563.2919311523438
INFO:root:Train (Epoch 163): Loss/seq after 01250 batchs: 562.1593627929688
INFO:root:Train (Epoch 163): Loss/seq after 01300 batchs: 551.4346313476562
INFO:root:Train (Epoch 163): Loss/seq after 01350 batchs: 542.8301391601562
INFO:root:Train (Epoch 163): Loss/seq after 01400 batchs: 546.1591186523438
INFO:root:Train (Epoch 163): Loss/seq after 01450 batchs: 548.3350830078125
INFO:root:Train (Epoch 163): Loss/seq after 01500 batchs: 555.2206420898438
INFO:root:Train (Epoch 163): Loss/seq after 01550 batchs: 557.2097778320312
INFO:root:Train (Epoch 163): Loss/seq after 01600 batchs: 552.4413452148438
INFO:root:Train (Epoch 163): Loss/seq after 01650 batchs: 550.5972290039062
INFO:root:Train (Epoch 163): Loss/seq after 01700 batchs: 553.5203247070312
INFO:root:Train (Epoch 163): Loss/seq after 01750 batchs: 551.3030395507812
INFO:root:Train (Epoch 163): Loss/seq after 01800 batchs: 548.455078125
INFO:root:Train (Epoch 163): Loss/seq after 01850 batchs: 544.8643188476562
INFO:root:Train (Epoch 163): Loss/seq after 01900 batchs: 544.9677124023438
INFO:root:Train (Epoch 163): Loss/seq after 01950 batchs: 544.0317993164062
INFO:root:Train (Epoch 163): Loss/seq after 02000 batchs: 543.4161376953125
INFO:root:Train (Epoch 163): Loss/seq after 02050 batchs: 542.329345703125
INFO:root:Train (Epoch 163): Loss/seq after 02100 batchs: 539.8887939453125
INFO:root:Train (Epoch 163): Loss/seq after 02150 batchs: 538.103759765625
INFO:root:Train (Epoch 163): Loss/seq after 02200 batchs: 535.499755859375
INFO:root:Train (Epoch 163): Loss/seq after 02250 batchs: 533.6376953125
INFO:root:Train (Epoch 163): Loss/seq after 02300 batchs: 530.5664672851562
INFO:root:Train (Epoch 163): Loss/seq after 02350 batchs: 526.6941528320312
INFO:root:Train (Epoch 163): Loss/seq after 02400 batchs: 528.5363159179688
INFO:root:Train (Epoch 163): Loss/seq after 02450 batchs: 524.116455078125
INFO:root:Train (Epoch 163): Loss/seq after 02500 batchs: 516.5042724609375
INFO:root:Train (Epoch 163): Loss/seq after 02550 batchs: 510.9767761230469
INFO:root:Train (Epoch 163): Loss/seq after 02600 batchs: 510.0445556640625
INFO:root:Train (Epoch 163): Loss/seq after 02650 batchs: 507.8894348144531
INFO:root:Train (Epoch 163): Loss/seq after 02700 batchs: 505.6582336425781
INFO:root:Train (Epoch 163): Loss/seq after 02750 batchs: 502.2070007324219
INFO:root:Train (Epoch 163): Loss/seq after 02800 batchs: 501.74664306640625
INFO:root:Train (Epoch 163): Loss/seq after 02850 batchs: 501.4671630859375
INFO:root:Train (Epoch 163): Loss/seq after 02900 batchs: 502.78045654296875
INFO:root:Train (Epoch 163): Loss/seq after 02950 batchs: 502.29217529296875
INFO:root:Train (Epoch 163): Loss/seq after 03000 batchs: 507.78143310546875
INFO:root:Train (Epoch 163): Loss/seq after 03050 batchs: 509.8410949707031
INFO:root:Train (Epoch 163): Loss/seq after 03100 batchs: 512.0052490234375
INFO:root:Train (Epoch 163): Loss/seq after 03150 batchs: 514.0069580078125
INFO:root:Train (Epoch 163): Loss/seq after 03200 batchs: 514.2778930664062
INFO:root:Train (Epoch 163): Loss/seq after 03250 batchs: 516.9536743164062
INFO:root:Train (Epoch 163): Loss/seq after 03300 batchs: 516.1814575195312
INFO:root:Train (Epoch 163): Loss/seq after 03350 batchs: 516.121826171875
INFO:root:Train (Epoch 163): Loss/seq after 03400 batchs: 512.6883544921875
INFO:root:Train (Epoch 163): Loss/seq after 03450 batchs: 511.7156066894531
INFO:root:Train (Epoch 163): Loss/seq after 03500 batchs: 512.5912475585938
INFO:root:Train (Epoch 163): Loss/seq after 03550 batchs: 510.1393127441406
INFO:root:Train (Epoch 163): Loss/seq after 03600 batchs: 517.6376342773438
INFO:root:Train (Epoch 163): Loss/seq after 03650 batchs: 515.3632202148438
INFO:root:Train (Epoch 163): Loss/seq after 03700 batchs: 518.13134765625
INFO:root:Train (Epoch 163): Loss/seq after 03750 batchs: 522.6929321289062
INFO:root:Train (Epoch 163): Loss/seq after 03800 batchs: 520.8025512695312
INFO:root:Train (Epoch 163): Loss/seq after 03850 batchs: 519.81005859375
INFO:root:Train (Epoch 163): Loss/seq after 03900 batchs: 522.9777221679688
INFO:root:Train (Epoch 163): Loss/seq after 03950 batchs: 526.2738647460938
INFO:root:Train (Epoch 163): Loss/seq after 04000 batchs: 522.6144409179688
INFO:root:Train (Epoch 163): Loss/seq after 04050 batchs: 519.4830932617188
INFO:root:Train (Epoch 163): Loss/seq after 04100 batchs: 518.0311279296875
INFO:root:Train (Epoch 163): Loss/seq after 04150 batchs: 517.9345703125
INFO:root:Train (Epoch 163): Loss/seq after 04200 batchs: 516.4676513671875
INFO:root:Train (Epoch 163): Loss/seq after 04250 batchs: 514.746337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 163): Loss/seq after 00000 batches: 496.0256042480469
INFO:root:# Valid (Epoch 163): Loss/seq after 00050 batches: 709.8490600585938
INFO:root:# Valid (Epoch 163): Loss/seq after 00100 batches: 701.5712890625
INFO:root:# Valid (Epoch 163): Loss/seq after 00150 batches: 529.3501586914062
INFO:root:# Valid (Epoch 163): Loss/seq after 00200 batches: 487.6267395019531
INFO:root:Artifacts: Make stick videos for epoch 163
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_163_on_20220414_051427.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_163_index_1052_on_20220414_051427.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 164): Loss/seq after 00000 batchs: 919.9041137695312
INFO:root:Train (Epoch 164): Loss/seq after 00050 batchs: 722.69970703125
INFO:root:Train (Epoch 164): Loss/seq after 00100 batchs: 716.61669921875
INFO:root:Train (Epoch 164): Loss/seq after 00150 batchs: 650.80078125
INFO:root:Train (Epoch 164): Loss/seq after 00200 batchs: 711.7762451171875
INFO:root:Train (Epoch 164): Loss/seq after 00250 batchs: 781.1409301757812
INFO:root:Train (Epoch 164): Loss/seq after 00300 batchs: 789.3451538085938
INFO:root:Train (Epoch 164): Loss/seq after 00350 batchs: 743.95751953125
INFO:root:Train (Epoch 164): Loss/seq after 00400 batchs: 740.0897827148438
INFO:root:Train (Epoch 164): Loss/seq after 00450 batchs: 730.8215942382812
INFO:root:Train (Epoch 164): Loss/seq after 00500 batchs: 708.9364013671875
INFO:root:Train (Epoch 164): Loss/seq after 00550 batchs: 690.7445068359375
INFO:root:Train (Epoch 164): Loss/seq after 00600 batchs: 667.75927734375
INFO:root:Train (Epoch 164): Loss/seq after 00650 batchs: 644.954833984375
INFO:root:Train (Epoch 164): Loss/seq after 00700 batchs: 619.736572265625
INFO:root:Train (Epoch 164): Loss/seq after 00750 batchs: 625.8934326171875
INFO:root:Train (Epoch 164): Loss/seq after 00800 batchs: 630.9368896484375
INFO:root:Train (Epoch 164): Loss/seq after 00850 batchs: 611.9703979492188
INFO:root:Train (Epoch 164): Loss/seq after 00900 batchs: 600.0444946289062
INFO:root:Train (Epoch 164): Loss/seq after 00950 batchs: 596.6807861328125
INFO:root:Train (Epoch 164): Loss/seq after 01000 batchs: 587.8744506835938
INFO:root:Train (Epoch 164): Loss/seq after 01050 batchs: 577.792236328125
INFO:root:Train (Epoch 164): Loss/seq after 01100 batchs: 569.9039306640625
INFO:root:Train (Epoch 164): Loss/seq after 01150 batchs: 556.7286987304688
INFO:root:Train (Epoch 164): Loss/seq after 01200 batchs: 562.5023803710938
INFO:root:Train (Epoch 164): Loss/seq after 01250 batchs: 561.4749145507812
INFO:root:Train (Epoch 164): Loss/seq after 01300 batchs: 550.7782592773438
INFO:root:Train (Epoch 164): Loss/seq after 01350 batchs: 542.4152221679688
INFO:root:Train (Epoch 164): Loss/seq after 01400 batchs: 545.30419921875
INFO:root:Train (Epoch 164): Loss/seq after 01450 batchs: 547.5379638671875
INFO:root:Train (Epoch 164): Loss/seq after 01500 batchs: 554.5880126953125
INFO:root:Train (Epoch 164): Loss/seq after 01550 batchs: 556.31640625
INFO:root:Train (Epoch 164): Loss/seq after 01600 batchs: 551.5812377929688
INFO:root:Train (Epoch 164): Loss/seq after 01650 batchs: 549.5709838867188
INFO:root:Train (Epoch 164): Loss/seq after 01700 batchs: 552.465087890625
INFO:root:Train (Epoch 164): Loss/seq after 01750 batchs: 550.1874389648438
INFO:root:Train (Epoch 164): Loss/seq after 01800 batchs: 547.3757934570312
INFO:root:Train (Epoch 164): Loss/seq after 01850 batchs: 543.890869140625
INFO:root:Train (Epoch 164): Loss/seq after 01900 batchs: 544.0852661132812
INFO:root:Train (Epoch 164): Loss/seq after 01950 batchs: 543.0848999023438
INFO:root:Train (Epoch 164): Loss/seq after 02000 batchs: 542.449951171875
INFO:root:Train (Epoch 164): Loss/seq after 02050 batchs: 541.4220581054688
INFO:root:Train (Epoch 164): Loss/seq after 02100 batchs: 538.8524169921875
INFO:root:Train (Epoch 164): Loss/seq after 02150 batchs: 537.0062866210938
INFO:root:Train (Epoch 164): Loss/seq after 02200 batchs: 534.3209838867188
INFO:root:Train (Epoch 164): Loss/seq after 02250 batchs: 532.4173583984375
INFO:root:Train (Epoch 164): Loss/seq after 02300 batchs: 529.1817626953125
INFO:root:Train (Epoch 164): Loss/seq after 02350 batchs: 525.3535766601562
INFO:root:Train (Epoch 164): Loss/seq after 02400 batchs: 527.2427368164062
INFO:root:Train (Epoch 164): Loss/seq after 02450 batchs: 522.9067993164062
INFO:root:Train (Epoch 164): Loss/seq after 02500 batchs: 515.3246459960938
INFO:root:Train (Epoch 164): Loss/seq after 02550 batchs: 509.70892333984375
INFO:root:Train (Epoch 164): Loss/seq after 02600 batchs: 508.6899108886719
INFO:root:Train (Epoch 164): Loss/seq after 02650 batchs: 506.4043273925781
INFO:root:Train (Epoch 164): Loss/seq after 02700 batchs: 503.9831848144531
INFO:root:Train (Epoch 164): Loss/seq after 02750 batchs: 500.5133361816406
INFO:root:Train (Epoch 164): Loss/seq after 02800 batchs: 499.7432556152344
INFO:root:Train (Epoch 164): Loss/seq after 02850 batchs: 499.339111328125
INFO:root:Train (Epoch 164): Loss/seq after 02900 batchs: 500.4967041015625
INFO:root:Train (Epoch 164): Loss/seq after 02950 batchs: 500.05078125
INFO:root:Train (Epoch 164): Loss/seq after 03000 batchs: 505.5074157714844
INFO:root:Train (Epoch 164): Loss/seq after 03050 batchs: 507.49920654296875
INFO:root:Train (Epoch 164): Loss/seq after 03100 batchs: 509.4106140136719
INFO:root:Train (Epoch 164): Loss/seq after 03150 batchs: 511.46112060546875
INFO:root:Train (Epoch 164): Loss/seq after 03200 batchs: 511.85247802734375
INFO:root:Train (Epoch 164): Loss/seq after 03250 batchs: 514.4093017578125
INFO:root:Train (Epoch 164): Loss/seq after 03300 batchs: 513.47119140625
INFO:root:Train (Epoch 164): Loss/seq after 03350 batchs: 513.0294189453125
INFO:root:Train (Epoch 164): Loss/seq after 03400 batchs: 509.41998291015625
INFO:root:Train (Epoch 164): Loss/seq after 03450 batchs: 508.3446960449219
INFO:root:Train (Epoch 164): Loss/seq after 03500 batchs: 509.0809020996094
INFO:root:Train (Epoch 164): Loss/seq after 03550 batchs: 506.6165466308594
INFO:root:Train (Epoch 164): Loss/seq after 03600 batchs: 514.068359375
INFO:root:Train (Epoch 164): Loss/seq after 03650 batchs: 512.01171875
INFO:root:Train (Epoch 164): Loss/seq after 03700 batchs: 514.9924926757812
INFO:root:Train (Epoch 164): Loss/seq after 03750 batchs: 519.6060791015625
INFO:root:Train (Epoch 164): Loss/seq after 03800 batchs: 517.75732421875
INFO:root:Train (Epoch 164): Loss/seq after 03850 batchs: 516.689453125
INFO:root:Train (Epoch 164): Loss/seq after 03900 batchs: 519.5656127929688
INFO:root:Train (Epoch 164): Loss/seq after 03950 batchs: 522.7783203125
INFO:root:Train (Epoch 164): Loss/seq after 04000 batchs: 519.1674194335938
INFO:root:Train (Epoch 164): Loss/seq after 04050 batchs: 516.0410766601562
INFO:root:Train (Epoch 164): Loss/seq after 04100 batchs: 514.6513061523438
INFO:root:Train (Epoch 164): Loss/seq after 04150 batchs: 514.5708618164062
INFO:root:Train (Epoch 164): Loss/seq after 04200 batchs: 513.12939453125
INFO:root:Train (Epoch 164): Loss/seq after 04250 batchs: 511.5626220703125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 164): Loss/seq after 00000 batches: 467.32452392578125
INFO:root:# Valid (Epoch 164): Loss/seq after 00050 batches: 660.5628051757812
INFO:root:# Valid (Epoch 164): Loss/seq after 00100 batches: 678.8753662109375
INFO:root:# Valid (Epoch 164): Loss/seq after 00150 batches: 516.16162109375
INFO:root:# Valid (Epoch 164): Loss/seq after 00200 batches: 480.5643615722656
INFO:root:Artifacts: Make stick videos for epoch 164
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_164_on_20220414_051945.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_164_index_51_on_20220414_051945.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 165): Loss/seq after 00000 batchs: 951.5263671875
INFO:root:Train (Epoch 165): Loss/seq after 00050 batchs: 735.0794067382812
INFO:root:Train (Epoch 165): Loss/seq after 00100 batchs: 724.2601318359375
INFO:root:Train (Epoch 165): Loss/seq after 00150 batchs: 656.9957275390625
INFO:root:Train (Epoch 165): Loss/seq after 00200 batchs: 713.0836181640625
INFO:root:Train (Epoch 165): Loss/seq after 00250 batchs: 781.4188232421875
INFO:root:Train (Epoch 165): Loss/seq after 00300 batchs: 788.2857666015625
INFO:root:Train (Epoch 165): Loss/seq after 00350 batchs: 742.938232421875
INFO:root:Train (Epoch 165): Loss/seq after 00400 batchs: 741.093994140625
INFO:root:Train (Epoch 165): Loss/seq after 00450 batchs: 732.3780517578125
INFO:root:Train (Epoch 165): Loss/seq after 00500 batchs: 708.65283203125
INFO:root:Train (Epoch 165): Loss/seq after 00550 batchs: 689.0722045898438
INFO:root:Train (Epoch 165): Loss/seq after 00600 batchs: 665.0286865234375
INFO:root:Train (Epoch 165): Loss/seq after 00650 batchs: 642.66259765625
INFO:root:Train (Epoch 165): Loss/seq after 00700 batchs: 617.7984619140625
INFO:root:Train (Epoch 165): Loss/seq after 00750 batchs: 623.0816040039062
INFO:root:Train (Epoch 165): Loss/seq after 00800 batchs: 627.4912109375
INFO:root:Train (Epoch 165): Loss/seq after 00850 batchs: 608.29248046875
INFO:root:Train (Epoch 165): Loss/seq after 00900 batchs: 596.2243041992188
INFO:root:Train (Epoch 165): Loss/seq after 00950 batchs: 592.5641479492188
INFO:root:Train (Epoch 165): Loss/seq after 01000 batchs: 584.0503540039062
INFO:root:Train (Epoch 165): Loss/seq after 01050 batchs: 574.0921020507812
INFO:root:Train (Epoch 165): Loss/seq after 01100 batchs: 567.0316772460938
INFO:root:Train (Epoch 165): Loss/seq after 01150 batchs: 554.0294799804688
INFO:root:Train (Epoch 165): Loss/seq after 01200 batchs: 559.2752075195312
INFO:root:Train (Epoch 165): Loss/seq after 01250 batchs: 558.3927612304688
INFO:root:Train (Epoch 165): Loss/seq after 01300 batchs: 547.8133544921875
INFO:root:Train (Epoch 165): Loss/seq after 01350 batchs: 539.3927612304688
INFO:root:Train (Epoch 165): Loss/seq after 01400 batchs: 541.8027954101562
INFO:root:Train (Epoch 165): Loss/seq after 01450 batchs: 544.0182495117188
INFO:root:Train (Epoch 165): Loss/seq after 01500 batchs: 551.0866088867188
INFO:root:Train (Epoch 165): Loss/seq after 01550 batchs: 553.1854248046875
INFO:root:Train (Epoch 165): Loss/seq after 01600 batchs: 548.4395751953125
INFO:root:Train (Epoch 165): Loss/seq after 01650 batchs: 546.5059814453125
INFO:root:Train (Epoch 165): Loss/seq after 01700 batchs: 549.4989624023438
INFO:root:Train (Epoch 165): Loss/seq after 01750 batchs: 547.151611328125
INFO:root:Train (Epoch 165): Loss/seq after 01800 batchs: 544.2461547851562
INFO:root:Train (Epoch 165): Loss/seq after 01850 batchs: 540.7057495117188
INFO:root:Train (Epoch 165): Loss/seq after 01900 batchs: 540.935791015625
INFO:root:Train (Epoch 165): Loss/seq after 01950 batchs: 540.0020141601562
INFO:root:Train (Epoch 165): Loss/seq after 02000 batchs: 539.454345703125
INFO:root:Train (Epoch 165): Loss/seq after 02050 batchs: 538.4736938476562
INFO:root:Train (Epoch 165): Loss/seq after 02100 batchs: 535.9712524414062
INFO:root:Train (Epoch 165): Loss/seq after 02150 batchs: 534.0560913085938
INFO:root:Train (Epoch 165): Loss/seq after 02200 batchs: 531.4576416015625
INFO:root:Train (Epoch 165): Loss/seq after 02250 batchs: 529.672607421875
INFO:root:Train (Epoch 165): Loss/seq after 02300 batchs: 526.4401245117188
INFO:root:Train (Epoch 165): Loss/seq after 02350 batchs: 522.5520629882812
INFO:root:Train (Epoch 165): Loss/seq after 02400 batchs: 524.442138671875
INFO:root:Train (Epoch 165): Loss/seq after 02450 batchs: 520.1348876953125
INFO:root:Train (Epoch 165): Loss/seq after 02500 batchs: 512.60498046875
INFO:root:Train (Epoch 165): Loss/seq after 02550 batchs: 507.0492858886719
INFO:root:Train (Epoch 165): Loss/seq after 02600 batchs: 505.9908142089844
INFO:root:Train (Epoch 165): Loss/seq after 02650 batchs: 503.7259826660156
INFO:root:Train (Epoch 165): Loss/seq after 02700 batchs: 501.33563232421875
INFO:root:Train (Epoch 165): Loss/seq after 02750 batchs: 497.97052001953125
INFO:root:Train (Epoch 165): Loss/seq after 02800 batchs: 496.669677734375
INFO:root:Train (Epoch 165): Loss/seq after 02850 batchs: 496.3390197753906
INFO:root:Train (Epoch 165): Loss/seq after 02900 batchs: 497.4319763183594
INFO:root:Train (Epoch 165): Loss/seq after 02950 batchs: 497.0621337890625
INFO:root:Train (Epoch 165): Loss/seq after 03000 batchs: 502.5954895019531
INFO:root:Train (Epoch 165): Loss/seq after 03050 batchs: 504.474853515625
INFO:root:Train (Epoch 165): Loss/seq after 03100 batchs: 506.7021789550781
INFO:root:Train (Epoch 165): Loss/seq after 03150 batchs: 508.36505126953125
INFO:root:Train (Epoch 165): Loss/seq after 03200 batchs: 508.7713623046875
INFO:root:Train (Epoch 165): Loss/seq after 03250 batchs: 511.13641357421875
INFO:root:Train (Epoch 165): Loss/seq after 03300 batchs: 510.4470520019531
INFO:root:Train (Epoch 165): Loss/seq after 03350 batchs: 510.6728515625
INFO:root:Train (Epoch 165): Loss/seq after 03400 batchs: 506.95928955078125
INFO:root:Train (Epoch 165): Loss/seq after 03450 batchs: 505.8550720214844
INFO:root:Train (Epoch 165): Loss/seq after 03500 batchs: 506.7297058105469
INFO:root:Train (Epoch 165): Loss/seq after 03550 batchs: 504.2797546386719
INFO:root:Train (Epoch 165): Loss/seq after 03600 batchs: 511.7414855957031
INFO:root:Train (Epoch 165): Loss/seq after 03650 batchs: 509.6009826660156
INFO:root:Train (Epoch 165): Loss/seq after 03700 batchs: 512.4578857421875
INFO:root:Train (Epoch 165): Loss/seq after 03750 batchs: 517.118896484375
INFO:root:Train (Epoch 165): Loss/seq after 03800 batchs: 515.2725219726562
INFO:root:Train (Epoch 165): Loss/seq after 03850 batchs: 514.2323608398438
INFO:root:Train (Epoch 165): Loss/seq after 03900 batchs: 517.09716796875
INFO:root:Train (Epoch 165): Loss/seq after 03950 batchs: 520.2394409179688
INFO:root:Train (Epoch 165): Loss/seq after 04000 batchs: 516.6647338867188
INFO:root:Train (Epoch 165): Loss/seq after 04050 batchs: 513.5692749023438
INFO:root:Train (Epoch 165): Loss/seq after 04100 batchs: 512.1317749023438
INFO:root:Train (Epoch 165): Loss/seq after 04150 batchs: 512.10302734375
INFO:root:Train (Epoch 165): Loss/seq after 04200 batchs: 510.6858825683594
INFO:root:Train (Epoch 165): Loss/seq after 04250 batchs: 509.1848449707031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 165): Loss/seq after 00000 batches: 477.4331359863281
INFO:root:# Valid (Epoch 165): Loss/seq after 00050 batches: 668.2191772460938
INFO:root:# Valid (Epoch 165): Loss/seq after 00100 batches: 666.6038818359375
INFO:root:# Valid (Epoch 165): Loss/seq after 00150 batches: 506.2379455566406
INFO:root:# Valid (Epoch 165): Loss/seq after 00200 batches: 471.37847900390625
INFO:root:Artifacts: Make stick videos for epoch 165
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_165_on_20220414_052503.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_165_index_1125_on_20220414_052503.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 166): Loss/seq after 00000 batchs: 958.6030883789062
INFO:root:Train (Epoch 166): Loss/seq after 00050 batchs: 725.927978515625
INFO:root:Train (Epoch 166): Loss/seq after 00100 batchs: 715.7989501953125
INFO:root:Train (Epoch 166): Loss/seq after 00150 batchs: 653.2354125976562
INFO:root:Train (Epoch 166): Loss/seq after 00200 batchs: 708.5128173828125
INFO:root:Train (Epoch 166): Loss/seq after 00250 batchs: 773.7484741210938
INFO:root:Train (Epoch 166): Loss/seq after 00300 batchs: 780.4681396484375
INFO:root:Train (Epoch 166): Loss/seq after 00350 batchs: 736.4000854492188
INFO:root:Train (Epoch 166): Loss/seq after 00400 batchs: 731.2260131835938
INFO:root:Train (Epoch 166): Loss/seq after 00450 batchs: 723.48193359375
INFO:root:Train (Epoch 166): Loss/seq after 00500 batchs: 700.8878784179688
INFO:root:Train (Epoch 166): Loss/seq after 00550 batchs: 682.3939208984375
INFO:root:Train (Epoch 166): Loss/seq after 00600 batchs: 659.05517578125
INFO:root:Train (Epoch 166): Loss/seq after 00650 batchs: 636.5358276367188
INFO:root:Train (Epoch 166): Loss/seq after 00700 batchs: 612.2747192382812
INFO:root:Train (Epoch 166): Loss/seq after 00750 batchs: 617.8695068359375
INFO:root:Train (Epoch 166): Loss/seq after 00800 batchs: 622.03125
INFO:root:Train (Epoch 166): Loss/seq after 00850 batchs: 603.47509765625
INFO:root:Train (Epoch 166): Loss/seq after 00900 batchs: 591.2427978515625
INFO:root:Train (Epoch 166): Loss/seq after 00950 batchs: 589.766357421875
INFO:root:Train (Epoch 166): Loss/seq after 01000 batchs: 581.3648071289062
INFO:root:Train (Epoch 166): Loss/seq after 01050 batchs: 571.09130859375
INFO:root:Train (Epoch 166): Loss/seq after 01100 batchs: 563.97705078125
INFO:root:Train (Epoch 166): Loss/seq after 01150 batchs: 550.94970703125
INFO:root:Train (Epoch 166): Loss/seq after 01200 batchs: 556.3059692382812
INFO:root:Train (Epoch 166): Loss/seq after 01250 batchs: 555.5582885742188
INFO:root:Train (Epoch 166): Loss/seq after 01300 batchs: 544.9691162109375
INFO:root:Train (Epoch 166): Loss/seq after 01350 batchs: 536.3736572265625
INFO:root:Train (Epoch 166): Loss/seq after 01400 batchs: 539.5241088867188
INFO:root:Train (Epoch 166): Loss/seq after 01450 batchs: 541.983642578125
INFO:root:Train (Epoch 166): Loss/seq after 01500 batchs: 549.1830444335938
INFO:root:Train (Epoch 166): Loss/seq after 01550 batchs: 551.562255859375
INFO:root:Train (Epoch 166): Loss/seq after 01600 batchs: 546.9535522460938
INFO:root:Train (Epoch 166): Loss/seq after 01650 batchs: 545.1788330078125
INFO:root:Train (Epoch 166): Loss/seq after 01700 batchs: 548.4667358398438
INFO:root:Train (Epoch 166): Loss/seq after 01750 batchs: 546.3012084960938
INFO:root:Train (Epoch 166): Loss/seq after 01800 batchs: 543.4341430664062
INFO:root:Train (Epoch 166): Loss/seq after 01850 batchs: 539.94091796875
INFO:root:Train (Epoch 166): Loss/seq after 01900 batchs: 540.4797973632812
INFO:root:Train (Epoch 166): Loss/seq after 01950 batchs: 539.4744873046875
INFO:root:Train (Epoch 166): Loss/seq after 02000 batchs: 538.8272094726562
INFO:root:Train (Epoch 166): Loss/seq after 02050 batchs: 537.7881469726562
INFO:root:Train (Epoch 166): Loss/seq after 02100 batchs: 535.3008422851562
INFO:root:Train (Epoch 166): Loss/seq after 02150 batchs: 533.5096435546875
INFO:root:Train (Epoch 166): Loss/seq after 02200 batchs: 530.9071044921875
INFO:root:Train (Epoch 166): Loss/seq after 02250 batchs: 529.0283203125
INFO:root:Train (Epoch 166): Loss/seq after 02300 batchs: 525.8069458007812
INFO:root:Train (Epoch 166): Loss/seq after 02350 batchs: 522.177490234375
INFO:root:Train (Epoch 166): Loss/seq after 02400 batchs: 523.7921752929688
INFO:root:Train (Epoch 166): Loss/seq after 02450 batchs: 519.4942626953125
INFO:root:Train (Epoch 166): Loss/seq after 02500 batchs: 511.95672607421875
INFO:root:Train (Epoch 166): Loss/seq after 02550 batchs: 506.45941162109375
INFO:root:Train (Epoch 166): Loss/seq after 02600 batchs: 505.5655822753906
INFO:root:Train (Epoch 166): Loss/seq after 02650 batchs: 503.1607360839844
INFO:root:Train (Epoch 166): Loss/seq after 02700 batchs: 500.82989501953125
INFO:root:Train (Epoch 166): Loss/seq after 02750 batchs: 497.286865234375
INFO:root:Train (Epoch 166): Loss/seq after 02800 batchs: 495.8503112792969
INFO:root:Train (Epoch 166): Loss/seq after 02850 batchs: 495.4163513183594
INFO:root:Train (Epoch 166): Loss/seq after 02900 batchs: 496.511474609375
INFO:root:Train (Epoch 166): Loss/seq after 02950 batchs: 496.1054992675781
INFO:root:Train (Epoch 166): Loss/seq after 03000 batchs: 501.66204833984375
INFO:root:Train (Epoch 166): Loss/seq after 03050 batchs: 503.5964660644531
INFO:root:Train (Epoch 166): Loss/seq after 03100 batchs: 505.92877197265625
INFO:root:Train (Epoch 166): Loss/seq after 03150 batchs: 507.90216064453125
INFO:root:Train (Epoch 166): Loss/seq after 03200 batchs: 508.2248229980469
INFO:root:Train (Epoch 166): Loss/seq after 03250 batchs: 510.646484375
INFO:root:Train (Epoch 166): Loss/seq after 03300 batchs: 509.84600830078125
INFO:root:Train (Epoch 166): Loss/seq after 03350 batchs: 509.87310791015625
INFO:root:Train (Epoch 166): Loss/seq after 03400 batchs: 506.2590026855469
INFO:root:Train (Epoch 166): Loss/seq after 03450 batchs: 505.2021484375
INFO:root:Train (Epoch 166): Loss/seq after 03500 batchs: 506.0301208496094
INFO:root:Train (Epoch 166): Loss/seq after 03550 batchs: 503.5253601074219
INFO:root:Train (Epoch 166): Loss/seq after 03600 batchs: 510.80364990234375
INFO:root:Train (Epoch 166): Loss/seq after 03650 batchs: 508.6242980957031
INFO:root:Train (Epoch 166): Loss/seq after 03700 batchs: 511.2642517089844
INFO:root:Train (Epoch 166): Loss/seq after 03750 batchs: 515.722900390625
INFO:root:Train (Epoch 166): Loss/seq after 03800 batchs: 513.8626098632812
INFO:root:Train (Epoch 166): Loss/seq after 03850 batchs: 512.7970581054688
INFO:root:Train (Epoch 166): Loss/seq after 03900 batchs: 515.6209106445312
INFO:root:Train (Epoch 166): Loss/seq after 03950 batchs: 518.7767944335938
INFO:root:Train (Epoch 166): Loss/seq after 04000 batchs: 515.1971435546875
INFO:root:Train (Epoch 166): Loss/seq after 04050 batchs: 512.102294921875
INFO:root:Train (Epoch 166): Loss/seq after 04100 batchs: 510.6798400878906
INFO:root:Train (Epoch 166): Loss/seq after 04150 batchs: 510.6350402832031
INFO:root:Train (Epoch 166): Loss/seq after 04200 batchs: 509.2337341308594
INFO:root:Train (Epoch 166): Loss/seq after 04250 batchs: 507.5395202636719
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 166): Loss/seq after 00000 batches: 501.5123291015625
INFO:root:# Valid (Epoch 166): Loss/seq after 00050 batches: 694.4678344726562
INFO:root:# Valid (Epoch 166): Loss/seq after 00100 batches: 684.30810546875
INFO:root:# Valid (Epoch 166): Loss/seq after 00150 batches: 516.372802734375
INFO:root:# Valid (Epoch 166): Loss/seq after 00200 batches: 479.1774597167969
INFO:root:Artifacts: Make stick videos for epoch 166
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_166_on_20220414_053020.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_166_index_805_on_20220414_053020.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 167): Loss/seq after 00000 batchs: 815.1142578125
INFO:root:Train (Epoch 167): Loss/seq after 00050 batchs: 714.421875
INFO:root:Train (Epoch 167): Loss/seq after 00100 batchs: 707.2789916992188
INFO:root:Train (Epoch 167): Loss/seq after 00150 batchs: 644.7865600585938
INFO:root:Train (Epoch 167): Loss/seq after 00200 batchs: 700.3917236328125
INFO:root:Train (Epoch 167): Loss/seq after 00250 batchs: 764.3292846679688
INFO:root:Train (Epoch 167): Loss/seq after 00300 batchs: 773.8417358398438
INFO:root:Train (Epoch 167): Loss/seq after 00350 batchs: 730.21044921875
INFO:root:Train (Epoch 167): Loss/seq after 00400 batchs: 726.8491821289062
INFO:root:Train (Epoch 167): Loss/seq after 00450 batchs: 719.0318603515625
INFO:root:Train (Epoch 167): Loss/seq after 00500 batchs: 694.859375
INFO:root:Train (Epoch 167): Loss/seq after 00550 batchs: 676.3392333984375
INFO:root:Train (Epoch 167): Loss/seq after 00600 batchs: 653.5429077148438
INFO:root:Train (Epoch 167): Loss/seq after 00650 batchs: 630.6085205078125
INFO:root:Train (Epoch 167): Loss/seq after 00700 batchs: 606.6203002929688
INFO:root:Train (Epoch 167): Loss/seq after 00750 batchs: 611.0958862304688
INFO:root:Train (Epoch 167): Loss/seq after 00800 batchs: 616.353271484375
INFO:root:Train (Epoch 167): Loss/seq after 00850 batchs: 597.8981323242188
INFO:root:Train (Epoch 167): Loss/seq after 00900 batchs: 586.6823120117188
INFO:root:Train (Epoch 167): Loss/seq after 00950 batchs: 583.8359985351562
INFO:root:Train (Epoch 167): Loss/seq after 01000 batchs: 574.98046875
INFO:root:Train (Epoch 167): Loss/seq after 01050 batchs: 564.8818359375
INFO:root:Train (Epoch 167): Loss/seq after 01100 batchs: 557.8154907226562
INFO:root:Train (Epoch 167): Loss/seq after 01150 batchs: 544.9676513671875
INFO:root:Train (Epoch 167): Loss/seq after 01200 batchs: 550.2176513671875
INFO:root:Train (Epoch 167): Loss/seq after 01250 batchs: 549.1787109375
INFO:root:Train (Epoch 167): Loss/seq after 01300 batchs: 538.7651977539062
INFO:root:Train (Epoch 167): Loss/seq after 01350 batchs: 530.69384765625
INFO:root:Train (Epoch 167): Loss/seq after 01400 batchs: 533.5563354492188
INFO:root:Train (Epoch 167): Loss/seq after 01450 batchs: 536.0663452148438
INFO:root:Train (Epoch 167): Loss/seq after 01500 batchs: 543.2714233398438
INFO:root:Train (Epoch 167): Loss/seq after 01550 batchs: 545.1015014648438
INFO:root:Train (Epoch 167): Loss/seq after 01600 batchs: 540.5125732421875
INFO:root:Train (Epoch 167): Loss/seq after 01650 batchs: 538.9046020507812
INFO:root:Train (Epoch 167): Loss/seq after 01700 batchs: 542.2359619140625
INFO:root:Train (Epoch 167): Loss/seq after 01750 batchs: 540.08349609375
INFO:root:Train (Epoch 167): Loss/seq after 01800 batchs: 537.22607421875
INFO:root:Train (Epoch 167): Loss/seq after 01850 batchs: 533.8280639648438
INFO:root:Train (Epoch 167): Loss/seq after 01900 batchs: 533.97021484375
INFO:root:Train (Epoch 167): Loss/seq after 01950 batchs: 533.3341064453125
INFO:root:Train (Epoch 167): Loss/seq after 02000 batchs: 533.13525390625
INFO:root:Train (Epoch 167): Loss/seq after 02050 batchs: 532.373046875
INFO:root:Train (Epoch 167): Loss/seq after 02100 batchs: 530.0527954101562
INFO:root:Train (Epoch 167): Loss/seq after 02150 batchs: 528.3191528320312
INFO:root:Train (Epoch 167): Loss/seq after 02200 batchs: 525.7941284179688
INFO:root:Train (Epoch 167): Loss/seq after 02250 batchs: 524.39013671875
INFO:root:Train (Epoch 167): Loss/seq after 02300 batchs: 521.6046142578125
INFO:root:Train (Epoch 167): Loss/seq after 02350 batchs: 517.8291015625
INFO:root:Train (Epoch 167): Loss/seq after 02400 batchs: 519.522216796875
INFO:root:Train (Epoch 167): Loss/seq after 02450 batchs: 515.2866821289062
INFO:root:Train (Epoch 167): Loss/seq after 02500 batchs: 507.84185791015625
INFO:root:Train (Epoch 167): Loss/seq after 02550 batchs: 502.33465576171875
INFO:root:Train (Epoch 167): Loss/seq after 02600 batchs: 501.2243347167969
INFO:root:Train (Epoch 167): Loss/seq after 02650 batchs: 498.7687683105469
INFO:root:Train (Epoch 167): Loss/seq after 02700 batchs: 496.35955810546875
INFO:root:Train (Epoch 167): Loss/seq after 02750 batchs: 492.62255859375
INFO:root:Train (Epoch 167): Loss/seq after 02800 batchs: 491.29766845703125
INFO:root:Train (Epoch 167): Loss/seq after 02850 batchs: 490.9603576660156
INFO:root:Train (Epoch 167): Loss/seq after 02900 batchs: 491.9898681640625
INFO:root:Train (Epoch 167): Loss/seq after 02950 batchs: 491.6136779785156
INFO:root:Train (Epoch 167): Loss/seq after 03000 batchs: 497.1430358886719
INFO:root:Train (Epoch 167): Loss/seq after 03050 batchs: 499.1466979980469
INFO:root:Train (Epoch 167): Loss/seq after 03100 batchs: 501.1145324707031
INFO:root:Train (Epoch 167): Loss/seq after 03150 batchs: 502.5196533203125
INFO:root:Train (Epoch 167): Loss/seq after 03200 batchs: 502.794921875
INFO:root:Train (Epoch 167): Loss/seq after 03250 batchs: 504.89056396484375
INFO:root:Train (Epoch 167): Loss/seq after 03300 batchs: 504.1744384765625
INFO:root:Train (Epoch 167): Loss/seq after 03350 batchs: 503.776611328125
INFO:root:Train (Epoch 167): Loss/seq after 03400 batchs: 500.0693664550781
INFO:root:Train (Epoch 167): Loss/seq after 03450 batchs: 499.0806884765625
INFO:root:Train (Epoch 167): Loss/seq after 03500 batchs: 499.79510498046875
INFO:root:Train (Epoch 167): Loss/seq after 03550 batchs: 497.37054443359375
INFO:root:Train (Epoch 167): Loss/seq after 03600 batchs: 504.7392272949219
INFO:root:Train (Epoch 167): Loss/seq after 03650 batchs: 502.8040466308594
INFO:root:Train (Epoch 167): Loss/seq after 03700 batchs: 505.8102722167969
INFO:root:Train (Epoch 167): Loss/seq after 03750 batchs: 510.35833740234375
INFO:root:Train (Epoch 167): Loss/seq after 03800 batchs: 508.6258544921875
INFO:root:Train (Epoch 167): Loss/seq after 03850 batchs: 507.63555908203125
INFO:root:Train (Epoch 167): Loss/seq after 03900 batchs: 510.5398254394531
INFO:root:Train (Epoch 167): Loss/seq after 03950 batchs: 513.8689575195312
INFO:root:Train (Epoch 167): Loss/seq after 04000 batchs: 510.3637390136719
INFO:root:Train (Epoch 167): Loss/seq after 04050 batchs: 507.3131408691406
INFO:root:Train (Epoch 167): Loss/seq after 04100 batchs: 505.93310546875
INFO:root:Train (Epoch 167): Loss/seq after 04150 batchs: 505.9471130371094
INFO:root:Train (Epoch 167): Loss/seq after 04200 batchs: 504.60845947265625
INFO:root:Train (Epoch 167): Loss/seq after 04250 batchs: 503.0038146972656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 167): Loss/seq after 00000 batches: 480.2134704589844
INFO:root:# Valid (Epoch 167): Loss/seq after 00050 batches: 657.7476196289062
INFO:root:# Valid (Epoch 167): Loss/seq after 00100 batches: 672.5385131835938
INFO:root:# Valid (Epoch 167): Loss/seq after 00150 batches: 509.41033935546875
INFO:root:# Valid (Epoch 167): Loss/seq after 00200 batches: 474.9803161621094
INFO:root:Artifacts: Make stick videos for epoch 167
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_167_on_20220414_053538.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_167_index_1146_on_20220414_053538.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 168): Loss/seq after 00000 batchs: 883.0587768554688
INFO:root:Train (Epoch 168): Loss/seq after 00050 batchs: 729.0089111328125
INFO:root:Train (Epoch 168): Loss/seq after 00100 batchs: 708.2109985351562
INFO:root:Train (Epoch 168): Loss/seq after 00150 batchs: 647.1719360351562
INFO:root:Train (Epoch 168): Loss/seq after 00200 batchs: 700.1884765625
INFO:root:Train (Epoch 168): Loss/seq after 00250 batchs: 776.936279296875
INFO:root:Train (Epoch 168): Loss/seq after 00300 batchs: 782.833740234375
INFO:root:Train (Epoch 168): Loss/seq after 00350 batchs: 737.5651245117188
INFO:root:Train (Epoch 168): Loss/seq after 00400 batchs: 732.1060180664062
INFO:root:Train (Epoch 168): Loss/seq after 00450 batchs: 723.66357421875
INFO:root:Train (Epoch 168): Loss/seq after 00500 batchs: 699.7852783203125
INFO:root:Train (Epoch 168): Loss/seq after 00550 batchs: 681.0435180664062
INFO:root:Train (Epoch 168): Loss/seq after 00600 batchs: 658.0201416015625
INFO:root:Train (Epoch 168): Loss/seq after 00650 batchs: 635.1107177734375
INFO:root:Train (Epoch 168): Loss/seq after 00700 batchs: 611.058837890625
INFO:root:Train (Epoch 168): Loss/seq after 00750 batchs: 614.9488525390625
INFO:root:Train (Epoch 168): Loss/seq after 00800 batchs: 620.6814575195312
INFO:root:Train (Epoch 168): Loss/seq after 00850 batchs: 602.2606201171875
INFO:root:Train (Epoch 168): Loss/seq after 00900 batchs: 591.5012817382812
INFO:root:Train (Epoch 168): Loss/seq after 00950 batchs: 588.4996948242188
INFO:root:Train (Epoch 168): Loss/seq after 01000 batchs: 579.9170532226562
INFO:root:Train (Epoch 168): Loss/seq after 01050 batchs: 569.8868408203125
INFO:root:Train (Epoch 168): Loss/seq after 01100 batchs: 563.0274658203125
INFO:root:Train (Epoch 168): Loss/seq after 01150 batchs: 549.9359741210938
INFO:root:Train (Epoch 168): Loss/seq after 01200 batchs: 554.7907104492188
INFO:root:Train (Epoch 168): Loss/seq after 01250 batchs: 554.1400146484375
INFO:root:Train (Epoch 168): Loss/seq after 01300 batchs: 543.602783203125
INFO:root:Train (Epoch 168): Loss/seq after 01350 batchs: 535.2322998046875
INFO:root:Train (Epoch 168): Loss/seq after 01400 batchs: 537.9943237304688
INFO:root:Train (Epoch 168): Loss/seq after 01450 batchs: 540.1589965820312
INFO:root:Train (Epoch 168): Loss/seq after 01500 batchs: 547.1950073242188
INFO:root:Train (Epoch 168): Loss/seq after 01550 batchs: 548.7618408203125
INFO:root:Train (Epoch 168): Loss/seq after 01600 batchs: 544.1898803710938
INFO:root:Train (Epoch 168): Loss/seq after 01650 batchs: 542.190185546875
INFO:root:Train (Epoch 168): Loss/seq after 01700 batchs: 545.1572265625
INFO:root:Train (Epoch 168): Loss/seq after 01750 batchs: 543.1002197265625
INFO:root:Train (Epoch 168): Loss/seq after 01800 batchs: 540.0718994140625
INFO:root:Train (Epoch 168): Loss/seq after 01850 batchs: 536.6463012695312
INFO:root:Train (Epoch 168): Loss/seq after 01900 batchs: 536.6785888671875
INFO:root:Train (Epoch 168): Loss/seq after 01950 batchs: 535.5032348632812
INFO:root:Train (Epoch 168): Loss/seq after 02000 batchs: 534.9780883789062
INFO:root:Train (Epoch 168): Loss/seq after 02050 batchs: 533.9635009765625
INFO:root:Train (Epoch 168): Loss/seq after 02100 batchs: 531.4690551757812
INFO:root:Train (Epoch 168): Loss/seq after 02150 batchs: 529.6445922851562
INFO:root:Train (Epoch 168): Loss/seq after 02200 batchs: 527.067626953125
INFO:root:Train (Epoch 168): Loss/seq after 02250 batchs: 525.219970703125
INFO:root:Train (Epoch 168): Loss/seq after 02300 batchs: 521.9893188476562
INFO:root:Train (Epoch 168): Loss/seq after 02350 batchs: 518.1641235351562
INFO:root:Train (Epoch 168): Loss/seq after 02400 batchs: 519.7654418945312
INFO:root:Train (Epoch 168): Loss/seq after 02450 batchs: 515.5595703125
INFO:root:Train (Epoch 168): Loss/seq after 02500 batchs: 508.085205078125
INFO:root:Train (Epoch 168): Loss/seq after 02550 batchs: 502.47039794921875
INFO:root:Train (Epoch 168): Loss/seq after 02600 batchs: 501.24908447265625
INFO:root:Train (Epoch 168): Loss/seq after 02650 batchs: 498.6712646484375
INFO:root:Train (Epoch 168): Loss/seq after 02700 batchs: 496.3486328125
INFO:root:Train (Epoch 168): Loss/seq after 02750 batchs: 492.7554626464844
INFO:root:Train (Epoch 168): Loss/seq after 02800 batchs: 491.3848571777344
INFO:root:Train (Epoch 168): Loss/seq after 02850 batchs: 490.8932800292969
INFO:root:Train (Epoch 168): Loss/seq after 02900 batchs: 491.9433288574219
INFO:root:Train (Epoch 168): Loss/seq after 02950 batchs: 491.46246337890625
INFO:root:Train (Epoch 168): Loss/seq after 03000 batchs: 496.95599365234375
INFO:root:Train (Epoch 168): Loss/seq after 03050 batchs: 498.8131103515625
INFO:root:Train (Epoch 168): Loss/seq after 03100 batchs: 501.06231689453125
INFO:root:Train (Epoch 168): Loss/seq after 03150 batchs: 502.46014404296875
INFO:root:Train (Epoch 168): Loss/seq after 03200 batchs: 502.6625061035156
INFO:root:Train (Epoch 168): Loss/seq after 03250 batchs: 504.9646301269531
INFO:root:Train (Epoch 168): Loss/seq after 03300 batchs: 504.4781188964844
INFO:root:Train (Epoch 168): Loss/seq after 03350 batchs: 503.8209228515625
INFO:root:Train (Epoch 168): Loss/seq after 03400 batchs: 500.09210205078125
INFO:root:Train (Epoch 168): Loss/seq after 03450 batchs: 499.2471008300781
INFO:root:Train (Epoch 168): Loss/seq after 03500 batchs: 500.1493225097656
INFO:root:Train (Epoch 168): Loss/seq after 03550 batchs: 497.7633361816406
INFO:root:Train (Epoch 168): Loss/seq after 03600 batchs: 505.107421875
INFO:root:Train (Epoch 168): Loss/seq after 03650 batchs: 502.9059753417969
INFO:root:Train (Epoch 168): Loss/seq after 03700 batchs: 505.7511291503906
INFO:root:Train (Epoch 168): Loss/seq after 03750 batchs: 510.2642517089844
INFO:root:Train (Epoch 168): Loss/seq after 03800 batchs: 508.4692077636719
INFO:root:Train (Epoch 168): Loss/seq after 03850 batchs: 507.3077087402344
INFO:root:Train (Epoch 168): Loss/seq after 03900 batchs: 510.0582275390625
INFO:root:Train (Epoch 168): Loss/seq after 03950 batchs: 513.2760009765625
INFO:root:Train (Epoch 168): Loss/seq after 04000 batchs: 509.7416687011719
INFO:root:Train (Epoch 168): Loss/seq after 04050 batchs: 506.6739807128906
INFO:root:Train (Epoch 168): Loss/seq after 04100 batchs: 505.3150329589844
INFO:root:Train (Epoch 168): Loss/seq after 04150 batchs: 505.25994873046875
INFO:root:Train (Epoch 168): Loss/seq after 04200 batchs: 503.9813537597656
INFO:root:Train (Epoch 168): Loss/seq after 04250 batchs: 502.4410705566406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 168): Loss/seq after 00000 batches: 491.1307373046875
INFO:root:# Valid (Epoch 168): Loss/seq after 00050 batches: 651.5588989257812
INFO:root:# Valid (Epoch 168): Loss/seq after 00100 batches: 658.4068603515625
INFO:root:# Valid (Epoch 168): Loss/seq after 00150 batches: 498.9941101074219
INFO:root:# Valid (Epoch 168): Loss/seq after 00200 batches: 462.40643310546875
INFO:root:Artifacts: Make stick videos for epoch 168
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_168_on_20220414_054055.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_168_index_418_on_20220414_054055.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 169): Loss/seq after 00000 batchs: 851.6251831054688
INFO:root:Train (Epoch 169): Loss/seq after 00050 batchs: 710.2651977539062
INFO:root:Train (Epoch 169): Loss/seq after 00100 batchs: 700.1028442382812
INFO:root:Train (Epoch 169): Loss/seq after 00150 batchs: 640.526123046875
INFO:root:Train (Epoch 169): Loss/seq after 00200 batchs: 698.9205322265625
INFO:root:Train (Epoch 169): Loss/seq after 00250 batchs: 761.8121337890625
INFO:root:Train (Epoch 169): Loss/seq after 00300 batchs: 769.2202758789062
INFO:root:Train (Epoch 169): Loss/seq after 00350 batchs: 725.8331298828125
INFO:root:Train (Epoch 169): Loss/seq after 00400 batchs: 719.6466064453125
INFO:root:Train (Epoch 169): Loss/seq after 00450 batchs: 712.9566650390625
INFO:root:Train (Epoch 169): Loss/seq after 00500 batchs: 690.7559814453125
INFO:root:Train (Epoch 169): Loss/seq after 00550 batchs: 672.261962890625
INFO:root:Train (Epoch 169): Loss/seq after 00600 batchs: 650.2340087890625
INFO:root:Train (Epoch 169): Loss/seq after 00650 batchs: 628.097900390625
INFO:root:Train (Epoch 169): Loss/seq after 00700 batchs: 603.7308349609375
INFO:root:Train (Epoch 169): Loss/seq after 00750 batchs: 608.0244140625
INFO:root:Train (Epoch 169): Loss/seq after 00800 batchs: 612.554443359375
INFO:root:Train (Epoch 169): Loss/seq after 00850 batchs: 594.0536499023438
INFO:root:Train (Epoch 169): Loss/seq after 00900 batchs: 583.02099609375
INFO:root:Train (Epoch 169): Loss/seq after 00950 batchs: 579.718994140625
INFO:root:Train (Epoch 169): Loss/seq after 01000 batchs: 571.8508911132812
INFO:root:Train (Epoch 169): Loss/seq after 01050 batchs: 561.6640014648438
INFO:root:Train (Epoch 169): Loss/seq after 01100 batchs: 554.3308715820312
INFO:root:Train (Epoch 169): Loss/seq after 01150 batchs: 541.4288940429688
INFO:root:Train (Epoch 169): Loss/seq after 01200 batchs: 546.8553466796875
INFO:root:Train (Epoch 169): Loss/seq after 01250 batchs: 545.8883666992188
INFO:root:Train (Epoch 169): Loss/seq after 01300 batchs: 535.5340576171875
INFO:root:Train (Epoch 169): Loss/seq after 01350 batchs: 527.1011352539062
INFO:root:Train (Epoch 169): Loss/seq after 01400 batchs: 529.1616821289062
INFO:root:Train (Epoch 169): Loss/seq after 01450 batchs: 531.2920532226562
INFO:root:Train (Epoch 169): Loss/seq after 01500 batchs: 538.5037841796875
INFO:root:Train (Epoch 169): Loss/seq after 01550 batchs: 540.349365234375
INFO:root:Train (Epoch 169): Loss/seq after 01600 batchs: 535.92236328125
INFO:root:Train (Epoch 169): Loss/seq after 01650 batchs: 534.40234375
INFO:root:Train (Epoch 169): Loss/seq after 01700 batchs: 537.6105346679688
INFO:root:Train (Epoch 169): Loss/seq after 01750 batchs: 535.5104370117188
INFO:root:Train (Epoch 169): Loss/seq after 01800 batchs: 532.6505126953125
INFO:root:Train (Epoch 169): Loss/seq after 01850 batchs: 529.3306884765625
INFO:root:Train (Epoch 169): Loss/seq after 01900 batchs: 529.4224243164062
INFO:root:Train (Epoch 169): Loss/seq after 01950 batchs: 528.1576538085938
INFO:root:Train (Epoch 169): Loss/seq after 02000 batchs: 527.6142578125
INFO:root:Train (Epoch 169): Loss/seq after 02050 batchs: 526.7866821289062
INFO:root:Train (Epoch 169): Loss/seq after 02100 batchs: 524.497802734375
INFO:root:Train (Epoch 169): Loss/seq after 02150 batchs: 522.819091796875
INFO:root:Train (Epoch 169): Loss/seq after 02200 batchs: 520.3606567382812
INFO:root:Train (Epoch 169): Loss/seq after 02250 batchs: 518.9086303710938
INFO:root:Train (Epoch 169): Loss/seq after 02300 batchs: 516.0100708007812
INFO:root:Train (Epoch 169): Loss/seq after 02350 batchs: 512.44091796875
INFO:root:Train (Epoch 169): Loss/seq after 02400 batchs: 514.1239624023438
INFO:root:Train (Epoch 169): Loss/seq after 02450 batchs: 509.9907531738281
INFO:root:Train (Epoch 169): Loss/seq after 02500 batchs: 502.6085205078125
INFO:root:Train (Epoch 169): Loss/seq after 02550 batchs: 496.9531555175781
INFO:root:Train (Epoch 169): Loss/seq after 02600 batchs: 495.8734130859375
INFO:root:Train (Epoch 169): Loss/seq after 02650 batchs: 493.3966064453125
INFO:root:Train (Epoch 169): Loss/seq after 02700 batchs: 491.0719299316406
INFO:root:Train (Epoch 169): Loss/seq after 02750 batchs: 487.55035400390625
INFO:root:Train (Epoch 169): Loss/seq after 02800 batchs: 486.3784484863281
INFO:root:Train (Epoch 169): Loss/seq after 02850 batchs: 486.1904296875
INFO:root:Train (Epoch 169): Loss/seq after 02900 batchs: 487.38177490234375
INFO:root:Train (Epoch 169): Loss/seq after 02950 batchs: 487.0412902832031
INFO:root:Train (Epoch 169): Loss/seq after 03000 batchs: 492.6279296875
INFO:root:Train (Epoch 169): Loss/seq after 03050 batchs: 494.64801025390625
INFO:root:Train (Epoch 169): Loss/seq after 03100 batchs: 496.78094482421875
INFO:root:Train (Epoch 169): Loss/seq after 03150 batchs: 497.95074462890625
INFO:root:Train (Epoch 169): Loss/seq after 03200 batchs: 498.16241455078125
INFO:root:Train (Epoch 169): Loss/seq after 03250 batchs: 500.53045654296875
INFO:root:Train (Epoch 169): Loss/seq after 03300 batchs: 499.7678527832031
INFO:root:Train (Epoch 169): Loss/seq after 03350 batchs: 499.2864685058594
INFO:root:Train (Epoch 169): Loss/seq after 03400 batchs: 495.7898864746094
INFO:root:Train (Epoch 169): Loss/seq after 03450 batchs: 494.9019470214844
INFO:root:Train (Epoch 169): Loss/seq after 03500 batchs: 495.7070007324219
INFO:root:Train (Epoch 169): Loss/seq after 03550 batchs: 493.44586181640625
INFO:root:Train (Epoch 169): Loss/seq after 03600 batchs: 500.87762451171875
INFO:root:Train (Epoch 169): Loss/seq after 03650 batchs: 498.8355407714844
INFO:root:Train (Epoch 169): Loss/seq after 03700 batchs: 501.5820617675781
INFO:root:Train (Epoch 169): Loss/seq after 03750 batchs: 506.0939025878906
INFO:root:Train (Epoch 169): Loss/seq after 03800 batchs: 504.38372802734375
INFO:root:Train (Epoch 169): Loss/seq after 03850 batchs: 503.47039794921875
INFO:root:Train (Epoch 169): Loss/seq after 03900 batchs: 506.4288024902344
INFO:root:Train (Epoch 169): Loss/seq after 03950 batchs: 509.6771545410156
INFO:root:Train (Epoch 169): Loss/seq after 04000 batchs: 506.1942138671875
INFO:root:Train (Epoch 169): Loss/seq after 04050 batchs: 503.156494140625
INFO:root:Train (Epoch 169): Loss/seq after 04100 batchs: 501.8413391113281
INFO:root:Train (Epoch 169): Loss/seq after 04150 batchs: 501.8420104980469
INFO:root:Train (Epoch 169): Loss/seq after 04200 batchs: 500.5401611328125
INFO:root:Train (Epoch 169): Loss/seq after 04250 batchs: 498.98065185546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 169): Loss/seq after 00000 batches: 431.5638732910156
INFO:root:# Valid (Epoch 169): Loss/seq after 00050 batches: 645.0684814453125
INFO:root:# Valid (Epoch 169): Loss/seq after 00100 batches: 661.6903686523438
INFO:root:# Valid (Epoch 169): Loss/seq after 00150 batches: 501.9295959472656
INFO:root:# Valid (Epoch 169): Loss/seq after 00200 batches: 468.1099853515625
INFO:root:Artifacts: Make stick videos for epoch 169
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_169_on_20220414_054613.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_169_index_390_on_20220414_054613.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 170): Loss/seq after 00000 batchs: 743.5632934570312
INFO:root:Train (Epoch 170): Loss/seq after 00050 batchs: 707.5804443359375
INFO:root:Train (Epoch 170): Loss/seq after 00100 batchs: 688.6444702148438
INFO:root:Train (Epoch 170): Loss/seq after 00150 batchs: 628.9277954101562
INFO:root:Train (Epoch 170): Loss/seq after 00200 batchs: 685.1875610351562
INFO:root:Train (Epoch 170): Loss/seq after 00250 batchs: 757.2886962890625
INFO:root:Train (Epoch 170): Loss/seq after 00300 batchs: 765.7254028320312
INFO:root:Train (Epoch 170): Loss/seq after 00350 batchs: 722.668701171875
INFO:root:Train (Epoch 170): Loss/seq after 00400 batchs: 717.3116455078125
INFO:root:Train (Epoch 170): Loss/seq after 00450 batchs: 710.5543823242188
INFO:root:Train (Epoch 170): Loss/seq after 00500 batchs: 688.8106689453125
INFO:root:Train (Epoch 170): Loss/seq after 00550 batchs: 670.4000854492188
INFO:root:Train (Epoch 170): Loss/seq after 00600 batchs: 648.0669555664062
INFO:root:Train (Epoch 170): Loss/seq after 00650 batchs: 625.6632690429688
INFO:root:Train (Epoch 170): Loss/seq after 00700 batchs: 601.1318359375
INFO:root:Train (Epoch 170): Loss/seq after 00750 batchs: 605.508056640625
INFO:root:Train (Epoch 170): Loss/seq after 00800 batchs: 609.9496459960938
INFO:root:Train (Epoch 170): Loss/seq after 00850 batchs: 591.5145874023438
INFO:root:Train (Epoch 170): Loss/seq after 00900 batchs: 580.01708984375
INFO:root:Train (Epoch 170): Loss/seq after 00950 batchs: 576.8998413085938
INFO:root:Train (Epoch 170): Loss/seq after 01000 batchs: 568.324462890625
INFO:root:Train (Epoch 170): Loss/seq after 01050 batchs: 558.2626953125
INFO:root:Train (Epoch 170): Loss/seq after 01100 batchs: 551.5894165039062
INFO:root:Train (Epoch 170): Loss/seq after 01150 batchs: 538.819091796875
INFO:root:Train (Epoch 170): Loss/seq after 01200 batchs: 543.943603515625
INFO:root:Train (Epoch 170): Loss/seq after 01250 batchs: 542.919189453125
INFO:root:Train (Epoch 170): Loss/seq after 01300 batchs: 532.6964721679688
INFO:root:Train (Epoch 170): Loss/seq after 01350 batchs: 523.9830322265625
INFO:root:Train (Epoch 170): Loss/seq after 01400 batchs: 526.773681640625
INFO:root:Train (Epoch 170): Loss/seq after 01450 batchs: 529.1132202148438
INFO:root:Train (Epoch 170): Loss/seq after 01500 batchs: 536.5442504882812
INFO:root:Train (Epoch 170): Loss/seq after 01550 batchs: 538.1273803710938
INFO:root:Train (Epoch 170): Loss/seq after 01600 batchs: 533.6849365234375
INFO:root:Train (Epoch 170): Loss/seq after 01650 batchs: 531.9697265625
INFO:root:Train (Epoch 170): Loss/seq after 01700 batchs: 535.1485595703125
INFO:root:Train (Epoch 170): Loss/seq after 01750 batchs: 532.9979248046875
INFO:root:Train (Epoch 170): Loss/seq after 01800 batchs: 530.2363891601562
INFO:root:Train (Epoch 170): Loss/seq after 01850 batchs: 526.952392578125
INFO:root:Train (Epoch 170): Loss/seq after 01900 batchs: 526.8397827148438
INFO:root:Train (Epoch 170): Loss/seq after 01950 batchs: 525.2427978515625
INFO:root:Train (Epoch 170): Loss/seq after 02000 batchs: 524.9365844726562
INFO:root:Train (Epoch 170): Loss/seq after 02050 batchs: 524.163330078125
INFO:root:Train (Epoch 170): Loss/seq after 02100 batchs: 521.9451293945312
INFO:root:Train (Epoch 170): Loss/seq after 02150 batchs: 520.2557373046875
INFO:root:Train (Epoch 170): Loss/seq after 02200 batchs: 517.9584350585938
INFO:root:Train (Epoch 170): Loss/seq after 02250 batchs: 516.2325439453125
INFO:root:Train (Epoch 170): Loss/seq after 02300 batchs: 512.9851684570312
INFO:root:Train (Epoch 170): Loss/seq after 02350 batchs: 509.44873046875
INFO:root:Train (Epoch 170): Loss/seq after 02400 batchs: 511.1045837402344
INFO:root:Train (Epoch 170): Loss/seq after 02450 batchs: 507.0445556640625
INFO:root:Train (Epoch 170): Loss/seq after 02500 batchs: 499.7002258300781
INFO:root:Train (Epoch 170): Loss/seq after 02550 batchs: 494.1190490722656
INFO:root:Train (Epoch 170): Loss/seq after 02600 batchs: 493.06671142578125
INFO:root:Train (Epoch 170): Loss/seq after 02650 batchs: 490.65234375
INFO:root:Train (Epoch 170): Loss/seq after 02700 batchs: 488.4626159667969
INFO:root:Train (Epoch 170): Loss/seq after 02750 batchs: 484.861572265625
INFO:root:Train (Epoch 170): Loss/seq after 02800 batchs: 483.3363037109375
INFO:root:Train (Epoch 170): Loss/seq after 02850 batchs: 483.0023193359375
INFO:root:Train (Epoch 170): Loss/seq after 02900 batchs: 484.312255859375
INFO:root:Train (Epoch 170): Loss/seq after 02950 batchs: 483.9794921875
INFO:root:Train (Epoch 170): Loss/seq after 03000 batchs: 489.533203125
INFO:root:Train (Epoch 170): Loss/seq after 03050 batchs: 491.4510498046875
INFO:root:Train (Epoch 170): Loss/seq after 03100 batchs: 493.5874938964844
INFO:root:Train (Epoch 170): Loss/seq after 03150 batchs: 495.2313537597656
INFO:root:Train (Epoch 170): Loss/seq after 03200 batchs: 495.4156188964844
INFO:root:Train (Epoch 170): Loss/seq after 03250 batchs: 497.7664489746094
INFO:root:Train (Epoch 170): Loss/seq after 03300 batchs: 497.10040283203125
INFO:root:Train (Epoch 170): Loss/seq after 03350 batchs: 496.7444763183594
INFO:root:Train (Epoch 170): Loss/seq after 03400 batchs: 493.1351013183594
INFO:root:Train (Epoch 170): Loss/seq after 03450 batchs: 492.1251220703125
INFO:root:Train (Epoch 170): Loss/seq after 03500 batchs: 492.7978820800781
INFO:root:Train (Epoch 170): Loss/seq after 03550 batchs: 490.35772705078125
INFO:root:Train (Epoch 170): Loss/seq after 03600 batchs: 497.49395751953125
INFO:root:Train (Epoch 170): Loss/seq after 03650 batchs: 495.3854064941406
INFO:root:Train (Epoch 170): Loss/seq after 03700 batchs: 498.190673828125
INFO:root:Train (Epoch 170): Loss/seq after 03750 batchs: 502.6949462890625
INFO:root:Train (Epoch 170): Loss/seq after 03800 batchs: 500.9730224609375
INFO:root:Train (Epoch 170): Loss/seq after 03850 batchs: 499.9539489746094
INFO:root:Train (Epoch 170): Loss/seq after 03900 batchs: 502.73236083984375
INFO:root:Train (Epoch 170): Loss/seq after 03950 batchs: 505.91326904296875
INFO:root:Train (Epoch 170): Loss/seq after 04000 batchs: 502.4801330566406
INFO:root:Train (Epoch 170): Loss/seq after 04050 batchs: 499.48663330078125
INFO:root:Train (Epoch 170): Loss/seq after 04100 batchs: 498.1727600097656
INFO:root:Train (Epoch 170): Loss/seq after 04150 batchs: 498.1720275878906
INFO:root:Train (Epoch 170): Loss/seq after 04200 batchs: 496.8152770996094
INFO:root:Train (Epoch 170): Loss/seq after 04250 batchs: 495.2330627441406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 170): Loss/seq after 00000 batches: 464.8627014160156
INFO:root:# Valid (Epoch 170): Loss/seq after 00050 batches: 637.2943115234375
INFO:root:# Valid (Epoch 170): Loss/seq after 00100 batches: 645.0703125
INFO:root:# Valid (Epoch 170): Loss/seq after 00150 batches: 488.9224548339844
INFO:root:# Valid (Epoch 170): Loss/seq after 00200 batches: 455.4956359863281
INFO:root:Artifacts: Make stick videos for epoch 170
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_170_on_20220414_055130.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_170_index_345_on_20220414_055130.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 171): Loss/seq after 00000 batchs: 787.107177734375
INFO:root:Train (Epoch 171): Loss/seq after 00050 batchs: 709.2952880859375
INFO:root:Train (Epoch 171): Loss/seq after 00100 batchs: 695.884765625
INFO:root:Train (Epoch 171): Loss/seq after 00150 batchs: 644.2316284179688
INFO:root:Train (Epoch 171): Loss/seq after 00200 batchs: 698.9502563476562
INFO:root:Train (Epoch 171): Loss/seq after 00250 batchs: 758.9425048828125
INFO:root:Train (Epoch 171): Loss/seq after 00300 batchs: 766.910400390625
INFO:root:Train (Epoch 171): Loss/seq after 00350 batchs: 722.9268188476562
INFO:root:Train (Epoch 171): Loss/seq after 00400 batchs: 717.6666259765625
INFO:root:Train (Epoch 171): Loss/seq after 00450 batchs: 710.7537231445312
INFO:root:Train (Epoch 171): Loss/seq after 00500 batchs: 688.7081909179688
INFO:root:Train (Epoch 171): Loss/seq after 00550 batchs: 670.994140625
INFO:root:Train (Epoch 171): Loss/seq after 00600 batchs: 647.9315795898438
INFO:root:Train (Epoch 171): Loss/seq after 00650 batchs: 625.5094604492188
INFO:root:Train (Epoch 171): Loss/seq after 00700 batchs: 600.7018432617188
INFO:root:Train (Epoch 171): Loss/seq after 00750 batchs: 603.5747680664062
INFO:root:Train (Epoch 171): Loss/seq after 00800 batchs: 608.4697875976562
INFO:root:Train (Epoch 171): Loss/seq after 00850 batchs: 589.9497680664062
INFO:root:Train (Epoch 171): Loss/seq after 00900 batchs: 579.4282836914062
INFO:root:Train (Epoch 171): Loss/seq after 00950 batchs: 576.1731567382812
INFO:root:Train (Epoch 171): Loss/seq after 01000 batchs: 566.763427734375
INFO:root:Train (Epoch 171): Loss/seq after 01050 batchs: 556.6636962890625
INFO:root:Train (Epoch 171): Loss/seq after 01100 batchs: 549.1953735351562
INFO:root:Train (Epoch 171): Loss/seq after 01150 batchs: 536.0706787109375
INFO:root:Train (Epoch 171): Loss/seq after 01200 batchs: 541.5205688476562
INFO:root:Train (Epoch 171): Loss/seq after 01250 batchs: 541.2030639648438
INFO:root:Train (Epoch 171): Loss/seq after 01300 batchs: 530.798828125
INFO:root:Train (Epoch 171): Loss/seq after 01350 batchs: 522.5010375976562
INFO:root:Train (Epoch 171): Loss/seq after 01400 batchs: 524.8004760742188
INFO:root:Train (Epoch 171): Loss/seq after 01450 batchs: 527.1356811523438
INFO:root:Train (Epoch 171): Loss/seq after 01500 batchs: 534.5881958007812
INFO:root:Train (Epoch 171): Loss/seq after 01550 batchs: 536.1117553710938
INFO:root:Train (Epoch 171): Loss/seq after 01600 batchs: 531.6688232421875
INFO:root:Train (Epoch 171): Loss/seq after 01650 batchs: 530.1433715820312
INFO:root:Train (Epoch 171): Loss/seq after 01700 batchs: 533.57666015625
INFO:root:Train (Epoch 171): Loss/seq after 01750 batchs: 531.4860229492188
INFO:root:Train (Epoch 171): Loss/seq after 01800 batchs: 528.7506713867188
INFO:root:Train (Epoch 171): Loss/seq after 01850 batchs: 525.4427490234375
INFO:root:Train (Epoch 171): Loss/seq after 01900 batchs: 524.899169921875
INFO:root:Train (Epoch 171): Loss/seq after 01950 batchs: 524.4130859375
INFO:root:Train (Epoch 171): Loss/seq after 02000 batchs: 524.1773071289062
INFO:root:Train (Epoch 171): Loss/seq after 02050 batchs: 523.3570556640625
INFO:root:Train (Epoch 171): Loss/seq after 02100 batchs: 521.0087890625
INFO:root:Train (Epoch 171): Loss/seq after 02150 batchs: 519.4542236328125
INFO:root:Train (Epoch 171): Loss/seq after 02200 batchs: 516.9727783203125
INFO:root:Train (Epoch 171): Loss/seq after 02250 batchs: 515.2648315429688
INFO:root:Train (Epoch 171): Loss/seq after 02300 batchs: 512.1052856445312
INFO:root:Train (Epoch 171): Loss/seq after 02350 batchs: 508.42620849609375
INFO:root:Train (Epoch 171): Loss/seq after 02400 batchs: 509.87750244140625
INFO:root:Train (Epoch 171): Loss/seq after 02450 batchs: 505.729248046875
INFO:root:Train (Epoch 171): Loss/seq after 02500 batchs: 498.4139709472656
INFO:root:Train (Epoch 171): Loss/seq after 02550 batchs: 492.8478088378906
INFO:root:Train (Epoch 171): Loss/seq after 02600 batchs: 491.6965637207031
INFO:root:Train (Epoch 171): Loss/seq after 02650 batchs: 489.1378173828125
INFO:root:Train (Epoch 171): Loss/seq after 02700 batchs: 486.8240051269531
INFO:root:Train (Epoch 171): Loss/seq after 02750 batchs: 482.96295166015625
INFO:root:Train (Epoch 171): Loss/seq after 02800 batchs: 481.49432373046875
INFO:root:Train (Epoch 171): Loss/seq after 02850 batchs: 481.22479248046875
INFO:root:Train (Epoch 171): Loss/seq after 02900 batchs: 482.3568420410156
INFO:root:Train (Epoch 171): Loss/seq after 02950 batchs: 482.08709716796875
INFO:root:Train (Epoch 171): Loss/seq after 03000 batchs: 487.7538757324219
INFO:root:Train (Epoch 171): Loss/seq after 03050 batchs: 489.7999267578125
INFO:root:Train (Epoch 171): Loss/seq after 03100 batchs: 491.6978759765625
INFO:root:Train (Epoch 171): Loss/seq after 03150 batchs: 492.6640319824219
INFO:root:Train (Epoch 171): Loss/seq after 03200 batchs: 492.9991149902344
INFO:root:Train (Epoch 171): Loss/seq after 03250 batchs: 494.9735107421875
INFO:root:Train (Epoch 171): Loss/seq after 03300 batchs: 494.1556091308594
INFO:root:Train (Epoch 171): Loss/seq after 03350 batchs: 493.5939636230469
INFO:root:Train (Epoch 171): Loss/seq after 03400 batchs: 489.9010925292969
INFO:root:Train (Epoch 171): Loss/seq after 03450 batchs: 488.8477478027344
INFO:root:Train (Epoch 171): Loss/seq after 03500 batchs: 489.70477294921875
INFO:root:Train (Epoch 171): Loss/seq after 03550 batchs: 487.1795654296875
INFO:root:Train (Epoch 171): Loss/seq after 03600 batchs: 494.5752868652344
INFO:root:Train (Epoch 171): Loss/seq after 03650 batchs: 492.474365234375
INFO:root:Train (Epoch 171): Loss/seq after 03700 batchs: 495.50177001953125
INFO:root:Train (Epoch 171): Loss/seq after 03750 batchs: 499.9682312011719
INFO:root:Train (Epoch 171): Loss/seq after 03800 batchs: 498.25555419921875
INFO:root:Train (Epoch 171): Loss/seq after 03850 batchs: 497.2577209472656
INFO:root:Train (Epoch 171): Loss/seq after 03900 batchs: 500.0244140625
INFO:root:Train (Epoch 171): Loss/seq after 03950 batchs: 503.16156005859375
INFO:root:Train (Epoch 171): Loss/seq after 04000 batchs: 499.745361328125
INFO:root:Train (Epoch 171): Loss/seq after 04050 batchs: 496.75433349609375
INFO:root:Train (Epoch 171): Loss/seq after 04100 batchs: 495.4412536621094
INFO:root:Train (Epoch 171): Loss/seq after 04150 batchs: 495.45806884765625
INFO:root:Train (Epoch 171): Loss/seq after 04200 batchs: 494.08697509765625
INFO:root:Train (Epoch 171): Loss/seq after 04250 batchs: 492.53289794921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 171): Loss/seq after 00000 batches: 433.4136047363281
INFO:root:# Valid (Epoch 171): Loss/seq after 00050 batches: 680.7193603515625
INFO:root:# Valid (Epoch 171): Loss/seq after 00100 batches: 689.427978515625
INFO:root:# Valid (Epoch 171): Loss/seq after 00150 batches: 519.0174560546875
INFO:root:# Valid (Epoch 171): Loss/seq after 00200 batches: 478.63934326171875
INFO:root:Artifacts: Make stick videos for epoch 171
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_171_on_20220414_055649.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_171_index_1715_on_20220414_055649.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 172): Loss/seq after 00000 batchs: 844.9581909179688
INFO:root:Train (Epoch 172): Loss/seq after 00050 batchs: 695.8001098632812
INFO:root:Train (Epoch 172): Loss/seq after 00100 batchs: 680.6383666992188
INFO:root:Train (Epoch 172): Loss/seq after 00150 batchs: 625.7042846679688
INFO:root:Train (Epoch 172): Loss/seq after 00200 batchs: 678.49560546875
INFO:root:Train (Epoch 172): Loss/seq after 00250 batchs: 745.5623168945312
INFO:root:Train (Epoch 172): Loss/seq after 00300 batchs: 754.902099609375
INFO:root:Train (Epoch 172): Loss/seq after 00350 batchs: 713.11865234375
INFO:root:Train (Epoch 172): Loss/seq after 00400 batchs: 706.9644165039062
INFO:root:Train (Epoch 172): Loss/seq after 00450 batchs: 701.3786010742188
INFO:root:Train (Epoch 172): Loss/seq after 00500 batchs: 677.508056640625
INFO:root:Train (Epoch 172): Loss/seq after 00550 batchs: 659.67333984375
INFO:root:Train (Epoch 172): Loss/seq after 00600 batchs: 637.5407104492188
INFO:root:Train (Epoch 172): Loss/seq after 00650 batchs: 614.8302001953125
INFO:root:Train (Epoch 172): Loss/seq after 00700 batchs: 590.8782348632812
INFO:root:Train (Epoch 172): Loss/seq after 00750 batchs: 594.2899780273438
INFO:root:Train (Epoch 172): Loss/seq after 00800 batchs: 599.48779296875
INFO:root:Train (Epoch 172): Loss/seq after 00850 batchs: 581.3953857421875
INFO:root:Train (Epoch 172): Loss/seq after 00900 batchs: 570.7220458984375
INFO:root:Train (Epoch 172): Loss/seq after 00950 batchs: 567.2235107421875
INFO:root:Train (Epoch 172): Loss/seq after 01000 batchs: 559.0691528320312
INFO:root:Train (Epoch 172): Loss/seq after 01050 batchs: 550.8553466796875
INFO:root:Train (Epoch 172): Loss/seq after 01100 batchs: 543.7911987304688
INFO:root:Train (Epoch 172): Loss/seq after 01150 batchs: 530.7966918945312
INFO:root:Train (Epoch 172): Loss/seq after 01200 batchs: 536.2523803710938
INFO:root:Train (Epoch 172): Loss/seq after 01250 batchs: 536.1892700195312
INFO:root:Train (Epoch 172): Loss/seq after 01300 batchs: 526.046630859375
INFO:root:Train (Epoch 172): Loss/seq after 01350 batchs: 517.962158203125
INFO:root:Train (Epoch 172): Loss/seq after 01400 batchs: 519.9547729492188
INFO:root:Train (Epoch 172): Loss/seq after 01450 batchs: 522.5843505859375
INFO:root:Train (Epoch 172): Loss/seq after 01500 batchs: 530.0208740234375
INFO:root:Train (Epoch 172): Loss/seq after 01550 batchs: 531.7356567382812
INFO:root:Train (Epoch 172): Loss/seq after 01600 batchs: 527.2835083007812
INFO:root:Train (Epoch 172): Loss/seq after 01650 batchs: 525.6991577148438
INFO:root:Train (Epoch 172): Loss/seq after 01700 batchs: 529.074462890625
INFO:root:Train (Epoch 172): Loss/seq after 01750 batchs: 526.8275146484375
INFO:root:Train (Epoch 172): Loss/seq after 01800 batchs: 524.1722412109375
INFO:root:Train (Epoch 172): Loss/seq after 01850 batchs: 521.064453125
INFO:root:Train (Epoch 172): Loss/seq after 01900 batchs: 520.9483032226562
INFO:root:Train (Epoch 172): Loss/seq after 01950 batchs: 519.7420654296875
INFO:root:Train (Epoch 172): Loss/seq after 02000 batchs: 519.37451171875
INFO:root:Train (Epoch 172): Loss/seq after 02050 batchs: 518.8150024414062
INFO:root:Train (Epoch 172): Loss/seq after 02100 batchs: 516.79736328125
INFO:root:Train (Epoch 172): Loss/seq after 02150 batchs: 515.2779541015625
INFO:root:Train (Epoch 172): Loss/seq after 02200 batchs: 512.9535522460938
INFO:root:Train (Epoch 172): Loss/seq after 02250 batchs: 511.3124694824219
INFO:root:Train (Epoch 172): Loss/seq after 02300 batchs: 507.9854736328125
INFO:root:Train (Epoch 172): Loss/seq after 02350 batchs: 504.45343017578125
INFO:root:Train (Epoch 172): Loss/seq after 02400 batchs: 505.94873046875
INFO:root:Train (Epoch 172): Loss/seq after 02450 batchs: 501.89892578125
INFO:root:Train (Epoch 172): Loss/seq after 02500 batchs: 494.6558837890625
INFO:root:Train (Epoch 172): Loss/seq after 02550 batchs: 489.1889953613281
INFO:root:Train (Epoch 172): Loss/seq after 02600 batchs: 488.13043212890625
INFO:root:Train (Epoch 172): Loss/seq after 02650 batchs: 485.52886962890625
INFO:root:Train (Epoch 172): Loss/seq after 02700 batchs: 483.2110900878906
INFO:root:Train (Epoch 172): Loss/seq after 02750 batchs: 479.4109191894531
INFO:root:Train (Epoch 172): Loss/seq after 02800 batchs: 477.85125732421875
INFO:root:Train (Epoch 172): Loss/seq after 02850 batchs: 477.6439514160156
INFO:root:Train (Epoch 172): Loss/seq after 02900 batchs: 478.7430114746094
INFO:root:Train (Epoch 172): Loss/seq after 02950 batchs: 478.4124755859375
INFO:root:Train (Epoch 172): Loss/seq after 03000 batchs: 483.9876403808594
INFO:root:Train (Epoch 172): Loss/seq after 03050 batchs: 486.0165710449219
INFO:root:Train (Epoch 172): Loss/seq after 03100 batchs: 488.0213623046875
INFO:root:Train (Epoch 172): Loss/seq after 03150 batchs: 489.8423767089844
INFO:root:Train (Epoch 172): Loss/seq after 03200 batchs: 490.13226318359375
INFO:root:Train (Epoch 172): Loss/seq after 03250 batchs: 492.443359375
INFO:root:Train (Epoch 172): Loss/seq after 03300 batchs: 491.9333190917969
INFO:root:Train (Epoch 172): Loss/seq after 03350 batchs: 491.6683654785156
INFO:root:Train (Epoch 172): Loss/seq after 03400 batchs: 488.06890869140625
INFO:root:Train (Epoch 172): Loss/seq after 03450 batchs: 487.07489013671875
INFO:root:Train (Epoch 172): Loss/seq after 03500 batchs: 488.1461486816406
INFO:root:Train (Epoch 172): Loss/seq after 03550 batchs: 486.03302001953125
INFO:root:Train (Epoch 172): Loss/seq after 03600 batchs: 493.4169616699219
INFO:root:Train (Epoch 172): Loss/seq after 03650 batchs: 491.5704345703125
INFO:root:Train (Epoch 172): Loss/seq after 03700 batchs: 494.9939880371094
INFO:root:Train (Epoch 172): Loss/seq after 03750 batchs: 499.57000732421875
INFO:root:Train (Epoch 172): Loss/seq after 03800 batchs: 497.8559875488281
INFO:root:Train (Epoch 172): Loss/seq after 03850 batchs: 496.8276062011719
INFO:root:Train (Epoch 172): Loss/seq after 03900 batchs: 499.76593017578125
INFO:root:Train (Epoch 172): Loss/seq after 03950 batchs: 503.02899169921875
INFO:root:Train (Epoch 172): Loss/seq after 04000 batchs: 499.5882263183594
INFO:root:Train (Epoch 172): Loss/seq after 04050 batchs: 496.639404296875
INFO:root:Train (Epoch 172): Loss/seq after 04100 batchs: 495.3669738769531
INFO:root:Train (Epoch 172): Loss/seq after 04150 batchs: 495.4186096191406
INFO:root:Train (Epoch 172): Loss/seq after 04200 batchs: 494.1498107910156
INFO:root:Train (Epoch 172): Loss/seq after 04250 batchs: 492.5587463378906
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 172): Loss/seq after 00000 batches: 443.3777770996094
INFO:root:# Valid (Epoch 172): Loss/seq after 00050 batches: 629.7402954101562
INFO:root:# Valid (Epoch 172): Loss/seq after 00100 batches: 636.5985107421875
INFO:root:# Valid (Epoch 172): Loss/seq after 00150 batches: 484.2528076171875
INFO:root:# Valid (Epoch 172): Loss/seq after 00200 batches: 453.0242004394531
INFO:root:Artifacts: Make stick videos for epoch 172
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_172_on_20220414_060206.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_172_index_1451_on_20220414_060206.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 173): Loss/seq after 00000 batchs: 819.5913696289062
INFO:root:Train (Epoch 173): Loss/seq after 00050 batchs: 696.8096313476562
INFO:root:Train (Epoch 173): Loss/seq after 00100 batchs: 686.6098022460938
INFO:root:Train (Epoch 173): Loss/seq after 00150 batchs: 629.62548828125
INFO:root:Train (Epoch 173): Loss/seq after 00200 batchs: 688.546630859375
INFO:root:Train (Epoch 173): Loss/seq after 00250 batchs: 757.7006225585938
INFO:root:Train (Epoch 173): Loss/seq after 00300 batchs: 765.1980590820312
INFO:root:Train (Epoch 173): Loss/seq after 00350 batchs: 722.207275390625
INFO:root:Train (Epoch 173): Loss/seq after 00400 batchs: 715.6741333007812
INFO:root:Train (Epoch 173): Loss/seq after 00450 batchs: 708.5421142578125
INFO:root:Train (Epoch 173): Loss/seq after 00500 batchs: 687.1912841796875
INFO:root:Train (Epoch 173): Loss/seq after 00550 batchs: 669.5231323242188
INFO:root:Train (Epoch 173): Loss/seq after 00600 batchs: 646.642578125
INFO:root:Train (Epoch 173): Loss/seq after 00650 batchs: 623.8394165039062
INFO:root:Train (Epoch 173): Loss/seq after 00700 batchs: 599.0899658203125
INFO:root:Train (Epoch 173): Loss/seq after 00750 batchs: 602.7095947265625
INFO:root:Train (Epoch 173): Loss/seq after 00800 batchs: 608.3626098632812
INFO:root:Train (Epoch 173): Loss/seq after 00850 batchs: 589.8638305664062
INFO:root:Train (Epoch 173): Loss/seq after 00900 batchs: 578.3682861328125
INFO:root:Train (Epoch 173): Loss/seq after 00950 batchs: 574.6578979492188
INFO:root:Train (Epoch 173): Loss/seq after 01000 batchs: 565.9188842773438
INFO:root:Train (Epoch 173): Loss/seq after 01050 batchs: 555.538330078125
INFO:root:Train (Epoch 173): Loss/seq after 01100 batchs: 548.3505859375
INFO:root:Train (Epoch 173): Loss/seq after 01150 batchs: 535.0675048828125
INFO:root:Train (Epoch 173): Loss/seq after 01200 batchs: 540.2066040039062
INFO:root:Train (Epoch 173): Loss/seq after 01250 batchs: 539.4951171875
INFO:root:Train (Epoch 173): Loss/seq after 01300 batchs: 529.4454345703125
INFO:root:Train (Epoch 173): Loss/seq after 01350 batchs: 521.12744140625
INFO:root:Train (Epoch 173): Loss/seq after 01400 batchs: 523.3222045898438
INFO:root:Train (Epoch 173): Loss/seq after 01450 batchs: 525.5635375976562
INFO:root:Train (Epoch 173): Loss/seq after 01500 batchs: 532.9052734375
INFO:root:Train (Epoch 173): Loss/seq after 01550 batchs: 534.8436889648438
INFO:root:Train (Epoch 173): Loss/seq after 01600 batchs: 530.2401733398438
INFO:root:Train (Epoch 173): Loss/seq after 01650 batchs: 528.5437622070312
INFO:root:Train (Epoch 173): Loss/seq after 01700 batchs: 531.789306640625
INFO:root:Train (Epoch 173): Loss/seq after 01750 batchs: 529.6005859375
INFO:root:Train (Epoch 173): Loss/seq after 01800 batchs: 526.8928833007812
INFO:root:Train (Epoch 173): Loss/seq after 01850 batchs: 523.5885620117188
INFO:root:Train (Epoch 173): Loss/seq after 01900 batchs: 523.2432250976562
INFO:root:Train (Epoch 173): Loss/seq after 01950 batchs: 521.777587890625
INFO:root:Train (Epoch 173): Loss/seq after 02000 batchs: 521.4325561523438
INFO:root:Train (Epoch 173): Loss/seq after 02050 batchs: 520.737060546875
INFO:root:Train (Epoch 173): Loss/seq after 02100 batchs: 518.4667358398438
INFO:root:Train (Epoch 173): Loss/seq after 02150 batchs: 516.7750244140625
INFO:root:Train (Epoch 173): Loss/seq after 02200 batchs: 514.4260864257812
INFO:root:Train (Epoch 173): Loss/seq after 02250 batchs: 512.5725708007812
INFO:root:Train (Epoch 173): Loss/seq after 02300 batchs: 509.4270324707031
INFO:root:Train (Epoch 173): Loss/seq after 02350 batchs: 505.8796691894531
INFO:root:Train (Epoch 173): Loss/seq after 02400 batchs: 507.4584655761719
INFO:root:Train (Epoch 173): Loss/seq after 02450 batchs: 503.3879089355469
INFO:root:Train (Epoch 173): Loss/seq after 02500 batchs: 496.0810546875
INFO:root:Train (Epoch 173): Loss/seq after 02550 batchs: 490.4211120605469
INFO:root:Train (Epoch 173): Loss/seq after 02600 batchs: 489.03857421875
INFO:root:Train (Epoch 173): Loss/seq after 02650 batchs: 486.3978271484375
INFO:root:Train (Epoch 173): Loss/seq after 02700 batchs: 483.93780517578125
INFO:root:Train (Epoch 173): Loss/seq after 02750 batchs: 479.9425048828125
INFO:root:Train (Epoch 173): Loss/seq after 02800 batchs: 478.67596435546875
INFO:root:Train (Epoch 173): Loss/seq after 02850 batchs: 478.292236328125
INFO:root:Train (Epoch 173): Loss/seq after 02900 batchs: 479.3640441894531
INFO:root:Train (Epoch 173): Loss/seq after 02950 batchs: 479.11639404296875
INFO:root:Train (Epoch 173): Loss/seq after 03000 batchs: 484.65740966796875
INFO:root:Train (Epoch 173): Loss/seq after 03050 batchs: 486.7142639160156
INFO:root:Train (Epoch 173): Loss/seq after 03100 batchs: 488.8741455078125
INFO:root:Train (Epoch 173): Loss/seq after 03150 batchs: 490.214111328125
INFO:root:Train (Epoch 173): Loss/seq after 03200 batchs: 490.41552734375
INFO:root:Train (Epoch 173): Loss/seq after 03250 batchs: 492.4498291015625
INFO:root:Train (Epoch 173): Loss/seq after 03300 batchs: 491.8139343261719
INFO:root:Train (Epoch 173): Loss/seq after 03350 batchs: 491.16595458984375
INFO:root:Train (Epoch 173): Loss/seq after 03400 batchs: 487.4882507324219
INFO:root:Train (Epoch 173): Loss/seq after 03450 batchs: 486.5466613769531
INFO:root:Train (Epoch 173): Loss/seq after 03500 batchs: 487.51617431640625
INFO:root:Train (Epoch 173): Loss/seq after 03550 batchs: 485.26715087890625
INFO:root:Train (Epoch 173): Loss/seq after 03600 batchs: 492.58856201171875
INFO:root:Train (Epoch 173): Loss/seq after 03650 batchs: 490.5052795410156
INFO:root:Train (Epoch 173): Loss/seq after 03700 batchs: 493.50872802734375
INFO:root:Train (Epoch 173): Loss/seq after 03750 batchs: 497.9976501464844
INFO:root:Train (Epoch 173): Loss/seq after 03800 batchs: 496.3149719238281
INFO:root:Train (Epoch 173): Loss/seq after 03850 batchs: 495.2347412109375
INFO:root:Train (Epoch 173): Loss/seq after 03900 batchs: 498.0057373046875
INFO:root:Train (Epoch 173): Loss/seq after 03950 batchs: 501.2160949707031
INFO:root:Train (Epoch 173): Loss/seq after 04000 batchs: 497.7801818847656
INFO:root:Train (Epoch 173): Loss/seq after 04050 batchs: 494.8247985839844
INFO:root:Train (Epoch 173): Loss/seq after 04100 batchs: 493.61590576171875
INFO:root:Train (Epoch 173): Loss/seq after 04150 batchs: 493.6197204589844
INFO:root:Train (Epoch 173): Loss/seq after 04200 batchs: 492.3518981933594
INFO:root:Train (Epoch 173): Loss/seq after 04250 batchs: 490.88507080078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 173): Loss/seq after 00000 batches: 472.17041015625
INFO:root:# Valid (Epoch 173): Loss/seq after 00050 batches: 623.4583129882812
INFO:root:# Valid (Epoch 173): Loss/seq after 00100 batches: 635.3675537109375
INFO:root:# Valid (Epoch 173): Loss/seq after 00150 batches: 482.82708740234375
INFO:root:# Valid (Epoch 173): Loss/seq after 00200 batches: 450.2160339355469
INFO:root:Artifacts: Make stick videos for epoch 173
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_173_on_20220414_060723.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_173_index_1849_on_20220414_060723.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 174): Loss/seq after 00000 batchs: 847.3250732421875
INFO:root:Train (Epoch 174): Loss/seq after 00050 batchs: 688.2882690429688
INFO:root:Train (Epoch 174): Loss/seq after 00100 batchs: 678.08544921875
INFO:root:Train (Epoch 174): Loss/seq after 00150 batchs: 625.051513671875
INFO:root:Train (Epoch 174): Loss/seq after 00200 batchs: 677.1896362304688
INFO:root:Train (Epoch 174): Loss/seq after 00250 batchs: 742.1405639648438
INFO:root:Train (Epoch 174): Loss/seq after 00300 batchs: 749.6639404296875
INFO:root:Train (Epoch 174): Loss/seq after 00350 batchs: 707.2568359375
INFO:root:Train (Epoch 174): Loss/seq after 00400 batchs: 701.5201416015625
INFO:root:Train (Epoch 174): Loss/seq after 00450 batchs: 696.6740112304688
INFO:root:Train (Epoch 174): Loss/seq after 00500 batchs: 674.6952514648438
INFO:root:Train (Epoch 174): Loss/seq after 00550 batchs: 657.4583129882812
INFO:root:Train (Epoch 174): Loss/seq after 00600 batchs: 635.0408935546875
INFO:root:Train (Epoch 174): Loss/seq after 00650 batchs: 612.7977905273438
INFO:root:Train (Epoch 174): Loss/seq after 00700 batchs: 587.9583740234375
INFO:root:Train (Epoch 174): Loss/seq after 00750 batchs: 591.1218872070312
INFO:root:Train (Epoch 174): Loss/seq after 00800 batchs: 597.406494140625
INFO:root:Train (Epoch 174): Loss/seq after 00850 batchs: 579.3821411132812
INFO:root:Train (Epoch 174): Loss/seq after 00900 batchs: 568.21484375
INFO:root:Train (Epoch 174): Loss/seq after 00950 batchs: 566.4912719726562
INFO:root:Train (Epoch 174): Loss/seq after 01000 batchs: 557.90673828125
INFO:root:Train (Epoch 174): Loss/seq after 01050 batchs: 548.7320556640625
INFO:root:Train (Epoch 174): Loss/seq after 01100 batchs: 541.6038208007812
INFO:root:Train (Epoch 174): Loss/seq after 01150 batchs: 528.67431640625
INFO:root:Train (Epoch 174): Loss/seq after 01200 batchs: 534.2037963867188
INFO:root:Train (Epoch 174): Loss/seq after 01250 batchs: 533.8185424804688
INFO:root:Train (Epoch 174): Loss/seq after 01300 batchs: 523.7022705078125
INFO:root:Train (Epoch 174): Loss/seq after 01350 batchs: 515.5204467773438
INFO:root:Train (Epoch 174): Loss/seq after 01400 batchs: 517.7532348632812
INFO:root:Train (Epoch 174): Loss/seq after 01450 batchs: 520.0845336914062
INFO:root:Train (Epoch 174): Loss/seq after 01500 batchs: 527.4373168945312
INFO:root:Train (Epoch 174): Loss/seq after 01550 batchs: 529.5910034179688
INFO:root:Train (Epoch 174): Loss/seq after 01600 batchs: 525.2169799804688
INFO:root:Train (Epoch 174): Loss/seq after 01650 batchs: 523.3854370117188
INFO:root:Train (Epoch 174): Loss/seq after 01700 batchs: 526.4830322265625
INFO:root:Train (Epoch 174): Loss/seq after 01750 batchs: 524.33447265625
INFO:root:Train (Epoch 174): Loss/seq after 01800 batchs: 521.6141967773438
INFO:root:Train (Epoch 174): Loss/seq after 01850 batchs: 518.3701782226562
INFO:root:Train (Epoch 174): Loss/seq after 01900 batchs: 517.96826171875
INFO:root:Train (Epoch 174): Loss/seq after 01950 batchs: 516.553955078125
INFO:root:Train (Epoch 174): Loss/seq after 02000 batchs: 516.1884765625
INFO:root:Train (Epoch 174): Loss/seq after 02050 batchs: 515.4136352539062
INFO:root:Train (Epoch 174): Loss/seq after 02100 batchs: 513.3583374023438
INFO:root:Train (Epoch 174): Loss/seq after 02150 batchs: 511.7385559082031
INFO:root:Train (Epoch 174): Loss/seq after 02200 batchs: 509.51702880859375
INFO:root:Train (Epoch 174): Loss/seq after 02250 batchs: 507.656005859375
INFO:root:Train (Epoch 174): Loss/seq after 02300 batchs: 504.3443603515625
INFO:root:Train (Epoch 174): Loss/seq after 02350 batchs: 500.87530517578125
INFO:root:Train (Epoch 174): Loss/seq after 02400 batchs: 502.31878662109375
INFO:root:Train (Epoch 174): Loss/seq after 02450 batchs: 498.2678527832031
INFO:root:Train (Epoch 174): Loss/seq after 02500 batchs: 491.04931640625
INFO:root:Train (Epoch 174): Loss/seq after 02550 batchs: 485.5175476074219
INFO:root:Train (Epoch 174): Loss/seq after 02600 batchs: 484.0566101074219
INFO:root:Train (Epoch 174): Loss/seq after 02650 batchs: 481.336669921875
INFO:root:Train (Epoch 174): Loss/seq after 02700 batchs: 478.9231872558594
INFO:root:Train (Epoch 174): Loss/seq after 02750 batchs: 475.1075744628906
INFO:root:Train (Epoch 174): Loss/seq after 02800 batchs: 473.9412536621094
INFO:root:Train (Epoch 174): Loss/seq after 02850 batchs: 473.5766906738281
INFO:root:Train (Epoch 174): Loss/seq after 02900 batchs: 474.666015625
INFO:root:Train (Epoch 174): Loss/seq after 02950 batchs: 474.3505859375
INFO:root:Train (Epoch 174): Loss/seq after 03000 batchs: 480.0467224121094
INFO:root:Train (Epoch 174): Loss/seq after 03050 batchs: 482.0176696777344
INFO:root:Train (Epoch 174): Loss/seq after 03100 batchs: 484.5367431640625
INFO:root:Train (Epoch 174): Loss/seq after 03150 batchs: 486.0478515625
INFO:root:Train (Epoch 174): Loss/seq after 03200 batchs: 486.4625244140625
INFO:root:Train (Epoch 174): Loss/seq after 03250 batchs: 488.1111755371094
INFO:root:Train (Epoch 174): Loss/seq after 03300 batchs: 487.3371887207031
INFO:root:Train (Epoch 174): Loss/seq after 03350 batchs: 486.7718811035156
INFO:root:Train (Epoch 174): Loss/seq after 03400 batchs: 483.142333984375
INFO:root:Train (Epoch 174): Loss/seq after 03450 batchs: 482.2640075683594
INFO:root:Train (Epoch 174): Loss/seq after 03500 batchs: 483.0543518066406
INFO:root:Train (Epoch 174): Loss/seq after 03550 batchs: 480.9501953125
INFO:root:Train (Epoch 174): Loss/seq after 03600 batchs: 488.2323303222656
INFO:root:Train (Epoch 174): Loss/seq after 03650 batchs: 486.14398193359375
INFO:root:Train (Epoch 174): Loss/seq after 03700 batchs: 489.0123291015625
INFO:root:Train (Epoch 174): Loss/seq after 03750 batchs: 493.4468994140625
INFO:root:Train (Epoch 174): Loss/seq after 03800 batchs: 491.82769775390625
INFO:root:Train (Epoch 174): Loss/seq after 03850 batchs: 490.8206481933594
INFO:root:Train (Epoch 174): Loss/seq after 03900 batchs: 493.6961975097656
INFO:root:Train (Epoch 174): Loss/seq after 03950 batchs: 496.99359130859375
INFO:root:Train (Epoch 174): Loss/seq after 04000 batchs: 493.5934143066406
INFO:root:Train (Epoch 174): Loss/seq after 04050 batchs: 490.6405944824219
INFO:root:Train (Epoch 174): Loss/seq after 04100 batchs: 489.4199523925781
INFO:root:Train (Epoch 174): Loss/seq after 04150 batchs: 489.4079895019531
INFO:root:Train (Epoch 174): Loss/seq after 04200 batchs: 488.07666015625
INFO:root:Train (Epoch 174): Loss/seq after 04250 batchs: 486.49798583984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 174): Loss/seq after 00000 batches: 456.86138916015625
INFO:root:# Valid (Epoch 174): Loss/seq after 00050 batches: 663.79443359375
INFO:root:# Valid (Epoch 174): Loss/seq after 00100 batches: 656.7592163085938
INFO:root:# Valid (Epoch 174): Loss/seq after 00150 batches: 496.3736572265625
INFO:root:# Valid (Epoch 174): Loss/seq after 00200 batches: 460.4876708984375
INFO:root:Artifacts: Make stick videos for epoch 174
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_174_on_20220414_061240.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_174_index_766_on_20220414_061240.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 175): Loss/seq after 00000 batchs: 919.9711303710938
INFO:root:Train (Epoch 175): Loss/seq after 00050 batchs: 707.3197021484375
INFO:root:Train (Epoch 175): Loss/seq after 00100 batchs: 682.6951293945312
INFO:root:Train (Epoch 175): Loss/seq after 00150 batchs: 624.7069702148438
INFO:root:Train (Epoch 175): Loss/seq after 00200 batchs: 678.0237426757812
INFO:root:Train (Epoch 175): Loss/seq after 00250 batchs: 742.24609375
INFO:root:Train (Epoch 175): Loss/seq after 00300 batchs: 749.1129150390625
INFO:root:Train (Epoch 175): Loss/seq after 00350 batchs: 706.5502319335938
INFO:root:Train (Epoch 175): Loss/seq after 00400 batchs: 701.1906127929688
INFO:root:Train (Epoch 175): Loss/seq after 00450 batchs: 696.1464233398438
INFO:root:Train (Epoch 175): Loss/seq after 00500 batchs: 674.931640625
INFO:root:Train (Epoch 175): Loss/seq after 00550 batchs: 657.5681762695312
INFO:root:Train (Epoch 175): Loss/seq after 00600 batchs: 635.0704956054688
INFO:root:Train (Epoch 175): Loss/seq after 00650 batchs: 613.1361694335938
INFO:root:Train (Epoch 175): Loss/seq after 00700 batchs: 587.7412719726562
INFO:root:Train (Epoch 175): Loss/seq after 00750 batchs: 590.2568969726562
INFO:root:Train (Epoch 175): Loss/seq after 00800 batchs: 596.1383056640625
INFO:root:Train (Epoch 175): Loss/seq after 00850 batchs: 577.6769409179688
INFO:root:Train (Epoch 175): Loss/seq after 00900 batchs: 566.6158447265625
INFO:root:Train (Epoch 175): Loss/seq after 00950 batchs: 562.9585571289062
INFO:root:Train (Epoch 175): Loss/seq after 01000 batchs: 554.003662109375
INFO:root:Train (Epoch 175): Loss/seq after 01050 batchs: 544.3775634765625
INFO:root:Train (Epoch 175): Loss/seq after 01100 batchs: 537.2152099609375
INFO:root:Train (Epoch 175): Loss/seq after 01150 batchs: 524.3319702148438
INFO:root:Train (Epoch 175): Loss/seq after 01200 batchs: 529.5256958007812
INFO:root:Train (Epoch 175): Loss/seq after 01250 batchs: 529.1444091796875
INFO:root:Train (Epoch 175): Loss/seq after 01300 batchs: 519.155517578125
INFO:root:Train (Epoch 175): Loss/seq after 01350 batchs: 511.2198791503906
INFO:root:Train (Epoch 175): Loss/seq after 01400 batchs: 513.458740234375
INFO:root:Train (Epoch 175): Loss/seq after 01450 batchs: 515.99755859375
INFO:root:Train (Epoch 175): Loss/seq after 01500 batchs: 523.6749267578125
INFO:root:Train (Epoch 175): Loss/seq after 01550 batchs: 525.3181762695312
INFO:root:Train (Epoch 175): Loss/seq after 01600 batchs: 521.012451171875
INFO:root:Train (Epoch 175): Loss/seq after 01650 batchs: 519.507568359375
INFO:root:Train (Epoch 175): Loss/seq after 01700 batchs: 522.764404296875
INFO:root:Train (Epoch 175): Loss/seq after 01750 batchs: 520.5641479492188
INFO:root:Train (Epoch 175): Loss/seq after 01800 batchs: 517.8512573242188
INFO:root:Train (Epoch 175): Loss/seq after 01850 batchs: 514.653076171875
INFO:root:Train (Epoch 175): Loss/seq after 01900 batchs: 514.2792358398438
INFO:root:Train (Epoch 175): Loss/seq after 01950 batchs: 513.32177734375
INFO:root:Train (Epoch 175): Loss/seq after 02000 batchs: 513.2066650390625
INFO:root:Train (Epoch 175): Loss/seq after 02050 batchs: 512.5125122070312
INFO:root:Train (Epoch 175): Loss/seq after 02100 batchs: 510.5136413574219
INFO:root:Train (Epoch 175): Loss/seq after 02150 batchs: 508.9329528808594
INFO:root:Train (Epoch 175): Loss/seq after 02200 batchs: 506.626708984375
INFO:root:Train (Epoch 175): Loss/seq after 02250 batchs: 505.0990905761719
INFO:root:Train (Epoch 175): Loss/seq after 02300 batchs: 501.8652038574219
INFO:root:Train (Epoch 175): Loss/seq after 02350 batchs: 498.3226623535156
INFO:root:Train (Epoch 175): Loss/seq after 02400 batchs: 499.7969665527344
INFO:root:Train (Epoch 175): Loss/seq after 02450 batchs: 495.80926513671875
INFO:root:Train (Epoch 175): Loss/seq after 02500 batchs: 488.6516418457031
INFO:root:Train (Epoch 175): Loss/seq after 02550 batchs: 483.1817932128906
INFO:root:Train (Epoch 175): Loss/seq after 02600 batchs: 481.95257568359375
INFO:root:Train (Epoch 175): Loss/seq after 02650 batchs: 479.2823486328125
INFO:root:Train (Epoch 175): Loss/seq after 02700 batchs: 477.1054382324219
INFO:root:Train (Epoch 175): Loss/seq after 02750 batchs: 473.2922668457031
INFO:root:Train (Epoch 175): Loss/seq after 02800 batchs: 471.5719909667969
INFO:root:Train (Epoch 175): Loss/seq after 02850 batchs: 471.3162536621094
INFO:root:Train (Epoch 175): Loss/seq after 02900 batchs: 472.37664794921875
INFO:root:Train (Epoch 175): Loss/seq after 02950 batchs: 472.11285400390625
INFO:root:Train (Epoch 175): Loss/seq after 03000 batchs: 477.6882019042969
INFO:root:Train (Epoch 175): Loss/seq after 03050 batchs: 479.75689697265625
INFO:root:Train (Epoch 175): Loss/seq after 03100 batchs: 481.7576904296875
INFO:root:Train (Epoch 175): Loss/seq after 03150 batchs: 482.5835266113281
INFO:root:Train (Epoch 175): Loss/seq after 03200 batchs: 482.8302307128906
INFO:root:Train (Epoch 175): Loss/seq after 03250 batchs: 484.47265625
INFO:root:Train (Epoch 175): Loss/seq after 03300 batchs: 483.88604736328125
INFO:root:Train (Epoch 175): Loss/seq after 03350 batchs: 483.202880859375
INFO:root:Train (Epoch 175): Loss/seq after 03400 batchs: 479.6341857910156
INFO:root:Train (Epoch 175): Loss/seq after 03450 batchs: 478.7265930175781
INFO:root:Train (Epoch 175): Loss/seq after 03500 batchs: 479.5895080566406
INFO:root:Train (Epoch 175): Loss/seq after 03550 batchs: 477.37982177734375
INFO:root:Train (Epoch 175): Loss/seq after 03600 batchs: 484.56378173828125
INFO:root:Train (Epoch 175): Loss/seq after 03650 batchs: 482.5431213378906
INFO:root:Train (Epoch 175): Loss/seq after 03700 batchs: 485.3109436035156
INFO:root:Train (Epoch 175): Loss/seq after 03750 batchs: 489.7983093261719
INFO:root:Train (Epoch 175): Loss/seq after 03800 batchs: 488.2225646972656
INFO:root:Train (Epoch 175): Loss/seq after 03850 batchs: 487.2933044433594
INFO:root:Train (Epoch 175): Loss/seq after 03900 batchs: 489.95257568359375
INFO:root:Train (Epoch 175): Loss/seq after 03950 batchs: 493.31243896484375
INFO:root:Train (Epoch 175): Loss/seq after 04000 batchs: 489.9448547363281
INFO:root:Train (Epoch 175): Loss/seq after 04050 batchs: 486.9908752441406
INFO:root:Train (Epoch 175): Loss/seq after 04100 batchs: 485.79656982421875
INFO:root:Train (Epoch 175): Loss/seq after 04150 batchs: 485.7884521484375
INFO:root:Train (Epoch 175): Loss/seq after 04200 batchs: 484.4658508300781
INFO:root:Train (Epoch 175): Loss/seq after 04250 batchs: 482.9720458984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 175): Loss/seq after 00000 batches: 493.4814453125
INFO:root:# Valid (Epoch 175): Loss/seq after 00050 batches: 637.375
INFO:root:# Valid (Epoch 175): Loss/seq after 00100 batches: 639.5579223632812
INFO:root:# Valid (Epoch 175): Loss/seq after 00150 batches: 486.75738525390625
INFO:root:# Valid (Epoch 175): Loss/seq after 00200 batches: 455.9593811035156
INFO:root:Artifacts: Make stick videos for epoch 175
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_175_on_20220414_061758.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_175_index_1181_on_20220414_061758.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 176): Loss/seq after 00000 batchs: 797.5780639648438
INFO:root:Train (Epoch 176): Loss/seq after 00050 batchs: 682.4151000976562
INFO:root:Train (Epoch 176): Loss/seq after 00100 batchs: 665.5546264648438
INFO:root:Train (Epoch 176): Loss/seq after 00150 batchs: 609.9671630859375
INFO:root:Train (Epoch 176): Loss/seq after 00200 batchs: 660.1929931640625
INFO:root:Train (Epoch 176): Loss/seq after 00250 batchs: 725.95654296875
INFO:root:Train (Epoch 176): Loss/seq after 00300 batchs: 735.7139282226562
INFO:root:Train (Epoch 176): Loss/seq after 00350 batchs: 695.2303466796875
INFO:root:Train (Epoch 176): Loss/seq after 00400 batchs: 688.7393188476562
INFO:root:Train (Epoch 176): Loss/seq after 00450 batchs: 685.1217651367188
INFO:root:Train (Epoch 176): Loss/seq after 00500 batchs: 662.4068603515625
INFO:root:Train (Epoch 176): Loss/seq after 00550 batchs: 645.4146728515625
INFO:root:Train (Epoch 176): Loss/seq after 00600 batchs: 624.5955200195312
INFO:root:Train (Epoch 176): Loss/seq after 00650 batchs: 603.05615234375
INFO:root:Train (Epoch 176): Loss/seq after 00700 batchs: 579.7515258789062
INFO:root:Train (Epoch 176): Loss/seq after 00750 batchs: 582.216064453125
INFO:root:Train (Epoch 176): Loss/seq after 00800 batchs: 587.5802612304688
INFO:root:Train (Epoch 176): Loss/seq after 00850 batchs: 569.387451171875
INFO:root:Train (Epoch 176): Loss/seq after 00900 batchs: 558.1959228515625
INFO:root:Train (Epoch 176): Loss/seq after 00950 batchs: 554.8897094726562
INFO:root:Train (Epoch 176): Loss/seq after 01000 batchs: 546.8854370117188
INFO:root:Train (Epoch 176): Loss/seq after 01050 batchs: 537.3053588867188
INFO:root:Train (Epoch 176): Loss/seq after 01100 batchs: 530.3392333984375
INFO:root:Train (Epoch 176): Loss/seq after 01150 batchs: 517.504638671875
INFO:root:Train (Epoch 176): Loss/seq after 01200 batchs: 523.4337158203125
INFO:root:Train (Epoch 176): Loss/seq after 01250 batchs: 523.147705078125
INFO:root:Train (Epoch 176): Loss/seq after 01300 batchs: 513.4520263671875
INFO:root:Train (Epoch 176): Loss/seq after 01350 batchs: 505.4014892578125
INFO:root:Train (Epoch 176): Loss/seq after 01400 batchs: 507.9518127441406
INFO:root:Train (Epoch 176): Loss/seq after 01450 batchs: 510.4674377441406
INFO:root:Train (Epoch 176): Loss/seq after 01500 batchs: 518.1251220703125
INFO:root:Train (Epoch 176): Loss/seq after 01550 batchs: 519.6324462890625
INFO:root:Train (Epoch 176): Loss/seq after 01600 batchs: 515.5054931640625
INFO:root:Train (Epoch 176): Loss/seq after 01650 batchs: 514.2147216796875
INFO:root:Train (Epoch 176): Loss/seq after 01700 batchs: 517.5980834960938
INFO:root:Train (Epoch 176): Loss/seq after 01750 batchs: 515.4942626953125
INFO:root:Train (Epoch 176): Loss/seq after 01800 batchs: 512.9244384765625
INFO:root:Train (Epoch 176): Loss/seq after 01850 batchs: 509.8746032714844
INFO:root:Train (Epoch 176): Loss/seq after 01900 batchs: 509.43359375
INFO:root:Train (Epoch 176): Loss/seq after 01950 batchs: 508.1754455566406
INFO:root:Train (Epoch 176): Loss/seq after 02000 batchs: 508.0431213378906
INFO:root:Train (Epoch 176): Loss/seq after 02050 batchs: 507.45458984375
INFO:root:Train (Epoch 176): Loss/seq after 02100 batchs: 505.3287353515625
INFO:root:Train (Epoch 176): Loss/seq after 02150 batchs: 503.8096923828125
INFO:root:Train (Epoch 176): Loss/seq after 02200 batchs: 501.7027587890625
INFO:root:Train (Epoch 176): Loss/seq after 02250 batchs: 500.0570983886719
INFO:root:Train (Epoch 176): Loss/seq after 02300 batchs: 496.7832336425781
INFO:root:Train (Epoch 176): Loss/seq after 02350 batchs: 493.28472900390625
INFO:root:Train (Epoch 176): Loss/seq after 02400 batchs: 494.5725402832031
INFO:root:Train (Epoch 176): Loss/seq after 02450 batchs: 490.7046203613281
INFO:root:Train (Epoch 176): Loss/seq after 02500 batchs: 483.5802307128906
INFO:root:Train (Epoch 176): Loss/seq after 02550 batchs: 478.1039733886719
INFO:root:Train (Epoch 176): Loss/seq after 02600 batchs: 476.94683837890625
INFO:root:Train (Epoch 176): Loss/seq after 02650 batchs: 474.2316589355469
INFO:root:Train (Epoch 176): Loss/seq after 02700 batchs: 472.0505065917969
INFO:root:Train (Epoch 176): Loss/seq after 02750 batchs: 468.30303955078125
INFO:root:Train (Epoch 176): Loss/seq after 02800 batchs: 466.7715148925781
INFO:root:Train (Epoch 176): Loss/seq after 02850 batchs: 466.4023132324219
INFO:root:Train (Epoch 176): Loss/seq after 02900 batchs: 467.4969787597656
INFO:root:Train (Epoch 176): Loss/seq after 02950 batchs: 467.2907409667969
INFO:root:Train (Epoch 176): Loss/seq after 03000 batchs: 472.9846496582031
INFO:root:Train (Epoch 176): Loss/seq after 03050 batchs: 475.05401611328125
INFO:root:Train (Epoch 176): Loss/seq after 03100 batchs: 477.1314392089844
INFO:root:Train (Epoch 176): Loss/seq after 03150 batchs: 477.9758605957031
INFO:root:Train (Epoch 176): Loss/seq after 03200 batchs: 478.058349609375
INFO:root:Train (Epoch 176): Loss/seq after 03250 batchs: 479.98297119140625
INFO:root:Train (Epoch 176): Loss/seq after 03300 batchs: 479.2608947753906
INFO:root:Train (Epoch 176): Loss/seq after 03350 batchs: 479.05255126953125
INFO:root:Train (Epoch 176): Loss/seq after 03400 batchs: 475.6759033203125
INFO:root:Train (Epoch 176): Loss/seq after 03450 batchs: 474.6958312988281
INFO:root:Train (Epoch 176): Loss/seq after 03500 batchs: 475.3468322753906
INFO:root:Train (Epoch 176): Loss/seq after 03550 batchs: 473.1783447265625
INFO:root:Train (Epoch 176): Loss/seq after 03600 batchs: 480.7286376953125
INFO:root:Train (Epoch 176): Loss/seq after 03650 batchs: 478.8127746582031
INFO:root:Train (Epoch 176): Loss/seq after 03700 batchs: 481.646728515625
INFO:root:Train (Epoch 176): Loss/seq after 03750 batchs: 486.2503967285156
INFO:root:Train (Epoch 176): Loss/seq after 03800 batchs: 484.6718444824219
INFO:root:Train (Epoch 176): Loss/seq after 03850 batchs: 483.6759948730469
INFO:root:Train (Epoch 176): Loss/seq after 03900 batchs: 486.3702087402344
INFO:root:Train (Epoch 176): Loss/seq after 03950 batchs: 489.5826110839844
INFO:root:Train (Epoch 176): Loss/seq after 04000 batchs: 486.2597961425781
INFO:root:Train (Epoch 176): Loss/seq after 04050 batchs: 483.3316345214844
INFO:root:Train (Epoch 176): Loss/seq after 04100 batchs: 482.199462890625
INFO:root:Train (Epoch 176): Loss/seq after 04150 batchs: 482.3089294433594
INFO:root:Train (Epoch 176): Loss/seq after 04200 batchs: 481.12982177734375
INFO:root:Train (Epoch 176): Loss/seq after 04250 batchs: 479.64599609375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 176): Loss/seq after 00000 batches: 462.80389404296875
INFO:root:# Valid (Epoch 176): Loss/seq after 00050 batches: 647.5427856445312
INFO:root:# Valid (Epoch 176): Loss/seq after 00100 batches: 640.0401000976562
INFO:root:# Valid (Epoch 176): Loss/seq after 00150 batches: 488.0946350097656
INFO:root:# Valid (Epoch 176): Loss/seq after 00200 batches: 456.0628356933594
INFO:root:Artifacts: Make stick videos for epoch 176
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_176_on_20220414_062315.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_176_index_1060_on_20220414_062315.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 177): Loss/seq after 00000 batchs: 904.9796142578125
INFO:root:Train (Epoch 177): Loss/seq after 00050 batchs: 701.9703979492188
INFO:root:Train (Epoch 177): Loss/seq after 00100 batchs: 673.84619140625
INFO:root:Train (Epoch 177): Loss/seq after 00150 batchs: 615.3002319335938
INFO:root:Train (Epoch 177): Loss/seq after 00200 batchs: 668.8539428710938
INFO:root:Train (Epoch 177): Loss/seq after 00250 batchs: 729.97021484375
INFO:root:Train (Epoch 177): Loss/seq after 00300 batchs: 737.4797973632812
INFO:root:Train (Epoch 177): Loss/seq after 00350 batchs: 696.2655639648438
INFO:root:Train (Epoch 177): Loss/seq after 00400 batchs: 690.4056396484375
INFO:root:Train (Epoch 177): Loss/seq after 00450 batchs: 686.4534912109375
INFO:root:Train (Epoch 177): Loss/seq after 00500 batchs: 666.4807739257812
INFO:root:Train (Epoch 177): Loss/seq after 00550 batchs: 649.5136108398438
INFO:root:Train (Epoch 177): Loss/seq after 00600 batchs: 627.8893432617188
INFO:root:Train (Epoch 177): Loss/seq after 00650 batchs: 605.4153442382812
INFO:root:Train (Epoch 177): Loss/seq after 00700 batchs: 582.2911376953125
INFO:root:Train (Epoch 177): Loss/seq after 00750 batchs: 583.43798828125
INFO:root:Train (Epoch 177): Loss/seq after 00800 batchs: 588.5038452148438
INFO:root:Train (Epoch 177): Loss/seq after 00850 batchs: 570.515625
INFO:root:Train (Epoch 177): Loss/seq after 00900 batchs: 559.6392822265625
INFO:root:Train (Epoch 177): Loss/seq after 00950 batchs: 556.3336791992188
INFO:root:Train (Epoch 177): Loss/seq after 01000 batchs: 547.9201049804688
INFO:root:Train (Epoch 177): Loss/seq after 01050 batchs: 538.028076171875
INFO:root:Train (Epoch 177): Loss/seq after 01100 batchs: 530.9503173828125
INFO:root:Train (Epoch 177): Loss/seq after 01150 batchs: 518.1777954101562
INFO:root:Train (Epoch 177): Loss/seq after 01200 batchs: 523.8148803710938
INFO:root:Train (Epoch 177): Loss/seq after 01250 batchs: 523.465087890625
INFO:root:Train (Epoch 177): Loss/seq after 01300 batchs: 513.3900146484375
INFO:root:Train (Epoch 177): Loss/seq after 01350 batchs: 505.54522705078125
INFO:root:Train (Epoch 177): Loss/seq after 01400 batchs: 507.8322448730469
INFO:root:Train (Epoch 177): Loss/seq after 01450 batchs: 510.31451416015625
INFO:root:Train (Epoch 177): Loss/seq after 01500 batchs: 517.8694458007812
INFO:root:Train (Epoch 177): Loss/seq after 01550 batchs: 519.2081298828125
INFO:root:Train (Epoch 177): Loss/seq after 01600 batchs: 515.05908203125
INFO:root:Train (Epoch 177): Loss/seq after 01650 batchs: 513.466064453125
INFO:root:Train (Epoch 177): Loss/seq after 01700 batchs: 516.6528930664062
INFO:root:Train (Epoch 177): Loss/seq after 01750 batchs: 514.591552734375
INFO:root:Train (Epoch 177): Loss/seq after 01800 batchs: 511.997802734375
INFO:root:Train (Epoch 177): Loss/seq after 01850 batchs: 508.979736328125
INFO:root:Train (Epoch 177): Loss/seq after 01900 batchs: 508.44757080078125
INFO:root:Train (Epoch 177): Loss/seq after 01950 batchs: 507.0116882324219
INFO:root:Train (Epoch 177): Loss/seq after 02000 batchs: 506.8770446777344
INFO:root:Train (Epoch 177): Loss/seq after 02050 batchs: 506.3204345703125
INFO:root:Train (Epoch 177): Loss/seq after 02100 batchs: 504.3466491699219
INFO:root:Train (Epoch 177): Loss/seq after 02150 batchs: 502.7718505859375
INFO:root:Train (Epoch 177): Loss/seq after 02200 batchs: 500.6677551269531
INFO:root:Train (Epoch 177): Loss/seq after 02250 batchs: 499.0842590332031
INFO:root:Train (Epoch 177): Loss/seq after 02300 batchs: 495.9212646484375
INFO:root:Train (Epoch 177): Loss/seq after 02350 batchs: 492.5411071777344
INFO:root:Train (Epoch 177): Loss/seq after 02400 batchs: 493.8217468261719
INFO:root:Train (Epoch 177): Loss/seq after 02450 batchs: 489.9676208496094
INFO:root:Train (Epoch 177): Loss/seq after 02500 batchs: 482.8888854980469
INFO:root:Train (Epoch 177): Loss/seq after 02550 batchs: 477.3842468261719
INFO:root:Train (Epoch 177): Loss/seq after 02600 batchs: 476.1576232910156
INFO:root:Train (Epoch 177): Loss/seq after 02650 batchs: 473.4152526855469
INFO:root:Train (Epoch 177): Loss/seq after 02700 batchs: 471.0796203613281
INFO:root:Train (Epoch 177): Loss/seq after 02750 batchs: 467.1865539550781
INFO:root:Train (Epoch 177): Loss/seq after 02800 batchs: 465.3928527832031
INFO:root:Train (Epoch 177): Loss/seq after 02850 batchs: 464.9848327636719
INFO:root:Train (Epoch 177): Loss/seq after 02900 batchs: 465.9534606933594
INFO:root:Train (Epoch 177): Loss/seq after 02950 batchs: 465.7933044433594
INFO:root:Train (Epoch 177): Loss/seq after 03000 batchs: 471.47369384765625
INFO:root:Train (Epoch 177): Loss/seq after 03050 batchs: 473.4512939453125
INFO:root:Train (Epoch 177): Loss/seq after 03100 batchs: 475.5165100097656
INFO:root:Train (Epoch 177): Loss/seq after 03150 batchs: 476.1435241699219
INFO:root:Train (Epoch 177): Loss/seq after 03200 batchs: 476.2518005371094
INFO:root:Train (Epoch 177): Loss/seq after 03250 batchs: 478.3894958496094
INFO:root:Train (Epoch 177): Loss/seq after 03300 batchs: 477.86688232421875
INFO:root:Train (Epoch 177): Loss/seq after 03350 batchs: 477.5067443847656
INFO:root:Train (Epoch 177): Loss/seq after 03400 batchs: 473.9422607421875
INFO:root:Train (Epoch 177): Loss/seq after 03450 batchs: 472.9474182128906
INFO:root:Train (Epoch 177): Loss/seq after 03500 batchs: 473.822265625
INFO:root:Train (Epoch 177): Loss/seq after 03550 batchs: 471.50958251953125
INFO:root:Train (Epoch 177): Loss/seq after 03600 batchs: 478.9048767089844
INFO:root:Train (Epoch 177): Loss/seq after 03650 batchs: 476.8998718261719
INFO:root:Train (Epoch 177): Loss/seq after 03700 batchs: 479.62384033203125
INFO:root:Train (Epoch 177): Loss/seq after 03750 batchs: 484.1546936035156
INFO:root:Train (Epoch 177): Loss/seq after 03800 batchs: 482.62860107421875
INFO:root:Train (Epoch 177): Loss/seq after 03850 batchs: 481.8548889160156
INFO:root:Train (Epoch 177): Loss/seq after 03900 batchs: 484.57666015625
INFO:root:Train (Epoch 177): Loss/seq after 03950 batchs: 487.7835998535156
INFO:root:Train (Epoch 177): Loss/seq after 04000 batchs: 484.5055236816406
INFO:root:Train (Epoch 177): Loss/seq after 04050 batchs: 481.5905456542969
INFO:root:Train (Epoch 177): Loss/seq after 04100 batchs: 480.48828125
INFO:root:Train (Epoch 177): Loss/seq after 04150 batchs: 480.5659484863281
INFO:root:Train (Epoch 177): Loss/seq after 04200 batchs: 479.2880859375
INFO:root:Train (Epoch 177): Loss/seq after 04250 batchs: 477.8215637207031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 177): Loss/seq after 00000 batches: 428.15570068359375
INFO:root:# Valid (Epoch 177): Loss/seq after 00050 batches: 616.1029663085938
INFO:root:# Valid (Epoch 177): Loss/seq after 00100 batches: 619.7796630859375
INFO:root:# Valid (Epoch 177): Loss/seq after 00150 batches: 470.443603515625
INFO:root:# Valid (Epoch 177): Loss/seq after 00200 batches: 439.80853271484375
INFO:root:Artifacts: Make stick videos for epoch 177
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_177_on_20220414_062832.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_177_index_1530_on_20220414_062832.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 178): Loss/seq after 00000 batchs: 858.5916137695312
INFO:root:Train (Epoch 178): Loss/seq after 00050 batchs: 684.053466796875
INFO:root:Train (Epoch 178): Loss/seq after 00100 batchs: 662.1320190429688
INFO:root:Train (Epoch 178): Loss/seq after 00150 batchs: 608.8919067382812
INFO:root:Train (Epoch 178): Loss/seq after 00200 batchs: 660.388427734375
INFO:root:Train (Epoch 178): Loss/seq after 00250 batchs: 723.9579467773438
INFO:root:Train (Epoch 178): Loss/seq after 00300 batchs: 732.9093017578125
INFO:root:Train (Epoch 178): Loss/seq after 00350 batchs: 692.1754760742188
INFO:root:Train (Epoch 178): Loss/seq after 00400 batchs: 687.2697143554688
INFO:root:Train (Epoch 178): Loss/seq after 00450 batchs: 683.255615234375
INFO:root:Train (Epoch 178): Loss/seq after 00500 batchs: 664.45654296875
INFO:root:Train (Epoch 178): Loss/seq after 00550 batchs: 648.28466796875
INFO:root:Train (Epoch 178): Loss/seq after 00600 batchs: 625.9197387695312
INFO:root:Train (Epoch 178): Loss/seq after 00650 batchs: 604.3572998046875
INFO:root:Train (Epoch 178): Loss/seq after 00700 batchs: 579.7343139648438
INFO:root:Train (Epoch 178): Loss/seq after 00750 batchs: 582.1024780273438
INFO:root:Train (Epoch 178): Loss/seq after 00800 batchs: 588.2449340820312
INFO:root:Train (Epoch 178): Loss/seq after 00850 batchs: 570.2525024414062
INFO:root:Train (Epoch 178): Loss/seq after 00900 batchs: 560.151611328125
INFO:root:Train (Epoch 178): Loss/seq after 00950 batchs: 557.0786743164062
INFO:root:Train (Epoch 178): Loss/seq after 01000 batchs: 548.2244262695312
INFO:root:Train (Epoch 178): Loss/seq after 01050 batchs: 538.194580078125
INFO:root:Train (Epoch 178): Loss/seq after 01100 batchs: 530.96923828125
INFO:root:Train (Epoch 178): Loss/seq after 01150 batchs: 518.0951538085938
INFO:root:Train (Epoch 178): Loss/seq after 01200 batchs: 523.2638549804688
INFO:root:Train (Epoch 178): Loss/seq after 01250 batchs: 523.1781616210938
INFO:root:Train (Epoch 178): Loss/seq after 01300 batchs: 513.194580078125
INFO:root:Train (Epoch 178): Loss/seq after 01350 batchs: 505.40399169921875
INFO:root:Train (Epoch 178): Loss/seq after 01400 batchs: 507.17266845703125
INFO:root:Train (Epoch 178): Loss/seq after 01450 batchs: 509.6133728027344
INFO:root:Train (Epoch 178): Loss/seq after 01500 batchs: 516.9874267578125
INFO:root:Train (Epoch 178): Loss/seq after 01550 batchs: 518.7169799804688
INFO:root:Train (Epoch 178): Loss/seq after 01600 batchs: 514.6022338867188
INFO:root:Train (Epoch 178): Loss/seq after 01650 batchs: 512.9340209960938
INFO:root:Train (Epoch 178): Loss/seq after 01700 batchs: 516.4400634765625
INFO:root:Train (Epoch 178): Loss/seq after 01750 batchs: 514.13037109375
INFO:root:Train (Epoch 178): Loss/seq after 01800 batchs: 511.3518981933594
INFO:root:Train (Epoch 178): Loss/seq after 01850 batchs: 508.29852294921875
INFO:root:Train (Epoch 178): Loss/seq after 01900 batchs: 507.90032958984375
INFO:root:Train (Epoch 178): Loss/seq after 01950 batchs: 507.0417175292969
INFO:root:Train (Epoch 178): Loss/seq after 02000 batchs: 507.00701904296875
INFO:root:Train (Epoch 178): Loss/seq after 02050 batchs: 506.3836975097656
INFO:root:Train (Epoch 178): Loss/seq after 02100 batchs: 504.31695556640625
INFO:root:Train (Epoch 178): Loss/seq after 02150 batchs: 502.88323974609375
INFO:root:Train (Epoch 178): Loss/seq after 02200 batchs: 500.70428466796875
INFO:root:Train (Epoch 178): Loss/seq after 02250 batchs: 499.0423889160156
INFO:root:Train (Epoch 178): Loss/seq after 02300 batchs: 495.767822265625
INFO:root:Train (Epoch 178): Loss/seq after 02350 batchs: 492.45245361328125
INFO:root:Train (Epoch 178): Loss/seq after 02400 batchs: 493.78472900390625
INFO:root:Train (Epoch 178): Loss/seq after 02450 batchs: 489.894287109375
INFO:root:Train (Epoch 178): Loss/seq after 02500 batchs: 482.7867431640625
INFO:root:Train (Epoch 178): Loss/seq after 02550 batchs: 477.1866455078125
INFO:root:Train (Epoch 178): Loss/seq after 02600 batchs: 476.1191711425781
INFO:root:Train (Epoch 178): Loss/seq after 02650 batchs: 473.35302734375
INFO:root:Train (Epoch 178): Loss/seq after 02700 batchs: 471.01153564453125
INFO:root:Train (Epoch 178): Loss/seq after 02750 batchs: 467.1507263183594
INFO:root:Train (Epoch 178): Loss/seq after 02800 batchs: 465.41339111328125
INFO:root:Train (Epoch 178): Loss/seq after 02850 batchs: 465.0602111816406
INFO:root:Train (Epoch 178): Loss/seq after 02900 batchs: 466.0294494628906
INFO:root:Train (Epoch 178): Loss/seq after 02950 batchs: 465.876220703125
INFO:root:Train (Epoch 178): Loss/seq after 03000 batchs: 471.6047668457031
INFO:root:Train (Epoch 178): Loss/seq after 03050 batchs: 473.8196716308594
INFO:root:Train (Epoch 178): Loss/seq after 03100 batchs: 475.98931884765625
INFO:root:Train (Epoch 178): Loss/seq after 03150 batchs: 476.8806457519531
INFO:root:Train (Epoch 178): Loss/seq after 03200 batchs: 477.1967468261719
INFO:root:Train (Epoch 178): Loss/seq after 03250 batchs: 479.25152587890625
INFO:root:Train (Epoch 178): Loss/seq after 03300 batchs: 478.31719970703125
INFO:root:Train (Epoch 178): Loss/seq after 03350 batchs: 477.7304992675781
INFO:root:Train (Epoch 178): Loss/seq after 03400 batchs: 474.19573974609375
INFO:root:Train (Epoch 178): Loss/seq after 03450 batchs: 473.21923828125
INFO:root:Train (Epoch 178): Loss/seq after 03500 batchs: 473.7653503417969
INFO:root:Train (Epoch 178): Loss/seq after 03550 batchs: 471.4266357421875
INFO:root:Train (Epoch 178): Loss/seq after 03600 batchs: 478.50714111328125
INFO:root:Train (Epoch 178): Loss/seq after 03650 batchs: 476.45037841796875
INFO:root:Train (Epoch 178): Loss/seq after 03700 batchs: 479.0009765625
INFO:root:Train (Epoch 178): Loss/seq after 03750 batchs: 483.49078369140625
INFO:root:Train (Epoch 178): Loss/seq after 03800 batchs: 481.97467041015625
INFO:root:Train (Epoch 178): Loss/seq after 03850 batchs: 481.08038330078125
INFO:root:Train (Epoch 178): Loss/seq after 03900 batchs: 483.83026123046875
INFO:root:Train (Epoch 178): Loss/seq after 03950 batchs: 486.9276428222656
INFO:root:Train (Epoch 178): Loss/seq after 04000 batchs: 483.595947265625
INFO:root:Train (Epoch 178): Loss/seq after 04050 batchs: 480.684814453125
INFO:root:Train (Epoch 178): Loss/seq after 04100 batchs: 479.5958251953125
INFO:root:Train (Epoch 178): Loss/seq after 04150 batchs: 479.6684875488281
INFO:root:Train (Epoch 178): Loss/seq after 04200 batchs: 478.3948059082031
INFO:root:Train (Epoch 178): Loss/seq after 04250 batchs: 476.9977111816406
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 178): Loss/seq after 00000 batches: 451.9027099609375
INFO:root:# Valid (Epoch 178): Loss/seq after 00050 batches: 611.3169555664062
INFO:root:# Valid (Epoch 178): Loss/seq after 00100 batches: 619.4651489257812
INFO:root:# Valid (Epoch 178): Loss/seq after 00150 batches: 472.6789245605469
INFO:root:# Valid (Epoch 178): Loss/seq after 00200 batches: 443.9172058105469
INFO:root:Artifacts: Make stick videos for epoch 178
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_178_on_20220414_063349.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_178_index_1519_on_20220414_063349.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 179): Loss/seq after 00000 batchs: 953.7612915039062
INFO:root:Train (Epoch 179): Loss/seq after 00050 batchs: 681.633544921875
INFO:root:Train (Epoch 179): Loss/seq after 00100 batchs: 661.8331909179688
INFO:root:Train (Epoch 179): Loss/seq after 00150 batchs: 609.1058349609375
INFO:root:Train (Epoch 179): Loss/seq after 00200 batchs: 662.1041259765625
INFO:root:Train (Epoch 179): Loss/seq after 00250 batchs: 721.2766723632812
INFO:root:Train (Epoch 179): Loss/seq after 00300 batchs: 730.7355346679688
INFO:root:Train (Epoch 179): Loss/seq after 00350 batchs: 689.80029296875
INFO:root:Train (Epoch 179): Loss/seq after 00400 batchs: 682.8858642578125
INFO:root:Train (Epoch 179): Loss/seq after 00450 batchs: 679.4446411132812
INFO:root:Train (Epoch 179): Loss/seq after 00500 batchs: 657.4623413085938
INFO:root:Train (Epoch 179): Loss/seq after 00550 batchs: 640.6077880859375
INFO:root:Train (Epoch 179): Loss/seq after 00600 batchs: 619.406005859375
INFO:root:Train (Epoch 179): Loss/seq after 00650 batchs: 597.0210571289062
INFO:root:Train (Epoch 179): Loss/seq after 00700 batchs: 573.4278564453125
INFO:root:Train (Epoch 179): Loss/seq after 00750 batchs: 575.68115234375
INFO:root:Train (Epoch 179): Loss/seq after 00800 batchs: 581.4412841796875
INFO:root:Train (Epoch 179): Loss/seq after 00850 batchs: 563.7945556640625
INFO:root:Train (Epoch 179): Loss/seq after 00900 batchs: 552.7443237304688
INFO:root:Train (Epoch 179): Loss/seq after 00950 batchs: 550.2713012695312
INFO:root:Train (Epoch 179): Loss/seq after 01000 batchs: 541.6127319335938
INFO:root:Train (Epoch 179): Loss/seq after 01050 batchs: 532.4695434570312
INFO:root:Train (Epoch 179): Loss/seq after 01100 batchs: 525.1995849609375
INFO:root:Train (Epoch 179): Loss/seq after 01150 batchs: 512.473876953125
INFO:root:Train (Epoch 179): Loss/seq after 01200 batchs: 518.2966918945312
INFO:root:Train (Epoch 179): Loss/seq after 01250 batchs: 518.0750122070312
INFO:root:Train (Epoch 179): Loss/seq after 01300 batchs: 508.1518859863281
INFO:root:Train (Epoch 179): Loss/seq after 01350 batchs: 500.24822998046875
INFO:root:Train (Epoch 179): Loss/seq after 01400 batchs: 502.08258056640625
INFO:root:Train (Epoch 179): Loss/seq after 01450 batchs: 504.5955810546875
INFO:root:Train (Epoch 179): Loss/seq after 01500 batchs: 512.2504272460938
INFO:root:Train (Epoch 179): Loss/seq after 01550 batchs: 513.8433837890625
INFO:root:Train (Epoch 179): Loss/seq after 01600 batchs: 509.9344787597656
INFO:root:Train (Epoch 179): Loss/seq after 01650 batchs: 508.3185729980469
INFO:root:Train (Epoch 179): Loss/seq after 01700 batchs: 511.6807861328125
INFO:root:Train (Epoch 179): Loss/seq after 01750 batchs: 509.6340637207031
INFO:root:Train (Epoch 179): Loss/seq after 01800 batchs: 507.198486328125
INFO:root:Train (Epoch 179): Loss/seq after 01850 batchs: 504.34283447265625
INFO:root:Train (Epoch 179): Loss/seq after 01900 batchs: 503.9872131347656
INFO:root:Train (Epoch 179): Loss/seq after 01950 batchs: 502.6764831542969
INFO:root:Train (Epoch 179): Loss/seq after 02000 batchs: 502.6475524902344
INFO:root:Train (Epoch 179): Loss/seq after 02050 batchs: 502.0592041015625
INFO:root:Train (Epoch 179): Loss/seq after 02100 batchs: 499.9831848144531
INFO:root:Train (Epoch 179): Loss/seq after 02150 batchs: 498.463623046875
INFO:root:Train (Epoch 179): Loss/seq after 02200 batchs: 496.3526306152344
INFO:root:Train (Epoch 179): Loss/seq after 02250 batchs: 494.8164367675781
INFO:root:Train (Epoch 179): Loss/seq after 02300 batchs: 491.64678955078125
INFO:root:Train (Epoch 179): Loss/seq after 02350 batchs: 488.3653869628906
INFO:root:Train (Epoch 179): Loss/seq after 02400 batchs: 489.75543212890625
INFO:root:Train (Epoch 179): Loss/seq after 02450 batchs: 485.892333984375
INFO:root:Train (Epoch 179): Loss/seq after 02500 batchs: 478.837158203125
INFO:root:Train (Epoch 179): Loss/seq after 02550 batchs: 473.3013000488281
INFO:root:Train (Epoch 179): Loss/seq after 02600 batchs: 471.99249267578125
INFO:root:Train (Epoch 179): Loss/seq after 02650 batchs: 468.9839172363281
INFO:root:Train (Epoch 179): Loss/seq after 02700 batchs: 466.66473388671875
INFO:root:Train (Epoch 179): Loss/seq after 02750 batchs: 462.7284851074219
INFO:root:Train (Epoch 179): Loss/seq after 02800 batchs: 461.01812744140625
INFO:root:Train (Epoch 179): Loss/seq after 02850 batchs: 460.7955627441406
INFO:root:Train (Epoch 179): Loss/seq after 02900 batchs: 461.7998352050781
INFO:root:Train (Epoch 179): Loss/seq after 02950 batchs: 461.64532470703125
INFO:root:Train (Epoch 179): Loss/seq after 03000 batchs: 467.314453125
INFO:root:Train (Epoch 179): Loss/seq after 03050 batchs: 469.4783935546875
INFO:root:Train (Epoch 179): Loss/seq after 03100 batchs: 471.3955383300781
INFO:root:Train (Epoch 179): Loss/seq after 03150 batchs: 472.8439636230469
INFO:root:Train (Epoch 179): Loss/seq after 03200 batchs: 473.323486328125
INFO:root:Train (Epoch 179): Loss/seq after 03250 batchs: 475.3730773925781
INFO:root:Train (Epoch 179): Loss/seq after 03300 batchs: 474.8002014160156
INFO:root:Train (Epoch 179): Loss/seq after 03350 batchs: 474.04437255859375
INFO:root:Train (Epoch 179): Loss/seq after 03400 batchs: 470.4850158691406
INFO:root:Train (Epoch 179): Loss/seq after 03450 batchs: 469.69696044921875
INFO:root:Train (Epoch 179): Loss/seq after 03500 batchs: 471.10101318359375
INFO:root:Train (Epoch 179): Loss/seq after 03550 batchs: 469.17120361328125
INFO:root:Train (Epoch 179): Loss/seq after 03600 batchs: 476.4513854980469
INFO:root:Train (Epoch 179): Loss/seq after 03650 batchs: 474.6275634765625
INFO:root:Train (Epoch 179): Loss/seq after 03700 batchs: 477.5816650390625
INFO:root:Train (Epoch 179): Loss/seq after 03750 batchs: 482.1418151855469
INFO:root:Train (Epoch 179): Loss/seq after 03800 batchs: 480.66168212890625
INFO:root:Train (Epoch 179): Loss/seq after 03850 batchs: 479.7742614746094
INFO:root:Train (Epoch 179): Loss/seq after 03900 batchs: 482.67572021484375
INFO:root:Train (Epoch 179): Loss/seq after 03950 batchs: 486.0874328613281
INFO:root:Train (Epoch 179): Loss/seq after 04000 batchs: 482.8319091796875
INFO:root:Train (Epoch 179): Loss/seq after 04050 batchs: 479.8712463378906
INFO:root:Train (Epoch 179): Loss/seq after 04100 batchs: 478.8241271972656
INFO:root:Train (Epoch 179): Loss/seq after 04150 batchs: 478.8731689453125
INFO:root:Train (Epoch 179): Loss/seq after 04200 batchs: 477.6341857910156
INFO:root:Train (Epoch 179): Loss/seq after 04250 batchs: 476.20233154296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 179): Loss/seq after 00000 batches: 434.5010986328125
INFO:root:# Valid (Epoch 179): Loss/seq after 00050 batches: 613.1156616210938
INFO:root:# Valid (Epoch 179): Loss/seq after 00100 batches: 622.6113891601562
INFO:root:# Valid (Epoch 179): Loss/seq after 00150 batches: 475.1478271484375
INFO:root:# Valid (Epoch 179): Loss/seq after 00200 batches: 446.7727355957031
INFO:root:Artifacts: Make stick videos for epoch 179
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_179_on_20220414_063907.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_179_index_456_on_20220414_063907.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 180): Loss/seq after 00000 batchs: 876.5321655273438
INFO:root:Train (Epoch 180): Loss/seq after 00050 batchs: 683.4090576171875
INFO:root:Train (Epoch 180): Loss/seq after 00100 batchs: 651.6427001953125
INFO:root:Train (Epoch 180): Loss/seq after 00150 batchs: 601.9222412109375
INFO:root:Train (Epoch 180): Loss/seq after 00200 batchs: 660.48779296875
INFO:root:Train (Epoch 180): Loss/seq after 00250 batchs: 721.6491088867188
INFO:root:Train (Epoch 180): Loss/seq after 00300 batchs: 731.1878051757812
INFO:root:Train (Epoch 180): Loss/seq after 00350 batchs: 690.9821166992188
INFO:root:Train (Epoch 180): Loss/seq after 00400 batchs: 681.9560546875
INFO:root:Train (Epoch 180): Loss/seq after 00450 batchs: 678.6661376953125
INFO:root:Train (Epoch 180): Loss/seq after 00500 batchs: 656.21044921875
INFO:root:Train (Epoch 180): Loss/seq after 00550 batchs: 639.521240234375
INFO:root:Train (Epoch 180): Loss/seq after 00600 batchs: 618.3427734375
INFO:root:Train (Epoch 180): Loss/seq after 00650 batchs: 595.966796875
INFO:root:Train (Epoch 180): Loss/seq after 00700 batchs: 572.3389282226562
INFO:root:Train (Epoch 180): Loss/seq after 00750 batchs: 574.6564331054688
INFO:root:Train (Epoch 180): Loss/seq after 00800 batchs: 580.1822509765625
INFO:root:Train (Epoch 180): Loss/seq after 00850 batchs: 562.1727905273438
INFO:root:Train (Epoch 180): Loss/seq after 00900 batchs: 551.2943115234375
INFO:root:Train (Epoch 180): Loss/seq after 00950 batchs: 548.7113037109375
INFO:root:Train (Epoch 180): Loss/seq after 01000 batchs: 540.3580322265625
INFO:root:Train (Epoch 180): Loss/seq after 01050 batchs: 530.9097900390625
INFO:root:Train (Epoch 180): Loss/seq after 01100 batchs: 523.6813354492188
INFO:root:Train (Epoch 180): Loss/seq after 01150 batchs: 510.9128112792969
INFO:root:Train (Epoch 180): Loss/seq after 01200 batchs: 516.7274169921875
INFO:root:Train (Epoch 180): Loss/seq after 01250 batchs: 516.5204467773438
INFO:root:Train (Epoch 180): Loss/seq after 01300 batchs: 506.63812255859375
INFO:root:Train (Epoch 180): Loss/seq after 01350 batchs: 499.0919494628906
INFO:root:Train (Epoch 180): Loss/seq after 01400 batchs: 501.2861328125
INFO:root:Train (Epoch 180): Loss/seq after 01450 batchs: 503.8422546386719
INFO:root:Train (Epoch 180): Loss/seq after 01500 batchs: 511.4078674316406
INFO:root:Train (Epoch 180): Loss/seq after 01550 batchs: 512.654296875
INFO:root:Train (Epoch 180): Loss/seq after 01600 batchs: 508.46929931640625
INFO:root:Train (Epoch 180): Loss/seq after 01650 batchs: 506.9742736816406
INFO:root:Train (Epoch 180): Loss/seq after 01700 batchs: 510.562255859375
INFO:root:Train (Epoch 180): Loss/seq after 01750 batchs: 508.3424377441406
INFO:root:Train (Epoch 180): Loss/seq after 01800 batchs: 505.74737548828125
INFO:root:Train (Epoch 180): Loss/seq after 01850 batchs: 502.8314514160156
INFO:root:Train (Epoch 180): Loss/seq after 01900 batchs: 502.1349792480469
INFO:root:Train (Epoch 180): Loss/seq after 01950 batchs: 500.70068359375
INFO:root:Train (Epoch 180): Loss/seq after 02000 batchs: 500.7562255859375
INFO:root:Train (Epoch 180): Loss/seq after 02050 batchs: 500.2276916503906
INFO:root:Train (Epoch 180): Loss/seq after 02100 batchs: 498.2212219238281
INFO:root:Train (Epoch 180): Loss/seq after 02150 batchs: 496.78656005859375
INFO:root:Train (Epoch 180): Loss/seq after 02200 batchs: 494.6679992675781
INFO:root:Train (Epoch 180): Loss/seq after 02250 batchs: 493.45257568359375
INFO:root:Train (Epoch 180): Loss/seq after 02300 batchs: 490.5731506347656
INFO:root:Train (Epoch 180): Loss/seq after 02350 batchs: 487.3552551269531
INFO:root:Train (Epoch 180): Loss/seq after 02400 batchs: 488.8025817871094
INFO:root:Train (Epoch 180): Loss/seq after 02450 batchs: 484.9566345214844
INFO:root:Train (Epoch 180): Loss/seq after 02500 batchs: 477.8953552246094
INFO:root:Train (Epoch 180): Loss/seq after 02550 batchs: 472.23931884765625
INFO:root:Train (Epoch 180): Loss/seq after 02600 batchs: 470.91290283203125
INFO:root:Train (Epoch 180): Loss/seq after 02650 batchs: 467.93017578125
INFO:root:Train (Epoch 180): Loss/seq after 02700 batchs: 465.67236328125
INFO:root:Train (Epoch 180): Loss/seq after 02750 batchs: 461.64300537109375
INFO:root:Train (Epoch 180): Loss/seq after 02800 batchs: 459.7611083984375
INFO:root:Train (Epoch 180): Loss/seq after 02850 batchs: 459.4872131347656
INFO:root:Train (Epoch 180): Loss/seq after 02900 batchs: 460.4808044433594
INFO:root:Train (Epoch 180): Loss/seq after 02950 batchs: 460.26593017578125
INFO:root:Train (Epoch 180): Loss/seq after 03000 batchs: 466.0489196777344
INFO:root:Train (Epoch 180): Loss/seq after 03050 batchs: 468.1870422363281
INFO:root:Train (Epoch 180): Loss/seq after 03100 batchs: 470.20880126953125
INFO:root:Train (Epoch 180): Loss/seq after 03150 batchs: 471.0141296386719
INFO:root:Train (Epoch 180): Loss/seq after 03200 batchs: 471.213623046875
INFO:root:Train (Epoch 180): Loss/seq after 03250 batchs: 473.0846862792969
INFO:root:Train (Epoch 180): Loss/seq after 03300 batchs: 472.313720703125
INFO:root:Train (Epoch 180): Loss/seq after 03350 batchs: 471.4324951171875
INFO:root:Train (Epoch 180): Loss/seq after 03400 batchs: 467.9324951171875
INFO:root:Train (Epoch 180): Loss/seq after 03450 batchs: 466.9952697753906
INFO:root:Train (Epoch 180): Loss/seq after 03500 batchs: 467.8786315917969
INFO:root:Train (Epoch 180): Loss/seq after 03550 batchs: 465.6292419433594
INFO:root:Train (Epoch 180): Loss/seq after 03600 batchs: 472.9558410644531
INFO:root:Train (Epoch 180): Loss/seq after 03650 batchs: 470.98187255859375
INFO:root:Train (Epoch 180): Loss/seq after 03700 batchs: 473.7259521484375
INFO:root:Train (Epoch 180): Loss/seq after 03750 batchs: 478.23846435546875
INFO:root:Train (Epoch 180): Loss/seq after 03800 batchs: 476.7947692871094
INFO:root:Train (Epoch 180): Loss/seq after 03850 batchs: 475.83154296875
INFO:root:Train (Epoch 180): Loss/seq after 03900 batchs: 478.3564758300781
INFO:root:Train (Epoch 180): Loss/seq after 03950 batchs: 481.45880126953125
INFO:root:Train (Epoch 180): Loss/seq after 04000 batchs: 478.17803955078125
INFO:root:Train (Epoch 180): Loss/seq after 04050 batchs: 475.2900390625
INFO:root:Train (Epoch 180): Loss/seq after 04100 batchs: 474.22906494140625
INFO:root:Train (Epoch 180): Loss/seq after 04150 batchs: 474.25958251953125
INFO:root:Train (Epoch 180): Loss/seq after 04200 batchs: 472.9919128417969
INFO:root:Train (Epoch 180): Loss/seq after 04250 batchs: 471.55181884765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 180): Loss/seq after 00000 batches: 464.8094787597656
INFO:root:# Valid (Epoch 180): Loss/seq after 00050 batches: 615.8317260742188
INFO:root:# Valid (Epoch 180): Loss/seq after 00100 batches: 612.7902221679688
INFO:root:# Valid (Epoch 180): Loss/seq after 00150 batches: 467.1177673339844
INFO:root:# Valid (Epoch 180): Loss/seq after 00200 batches: 438.99249267578125
INFO:root:Artifacts: Make stick videos for epoch 180
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_180_on_20220414_064424.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_180_index_1358_on_20220414_064424.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 181): Loss/seq after 00000 batchs: 796.8326416015625
INFO:root:Train (Epoch 181): Loss/seq after 00050 batchs: 675.9134521484375
INFO:root:Train (Epoch 181): Loss/seq after 00100 batchs: 655.26953125
INFO:root:Train (Epoch 181): Loss/seq after 00150 batchs: 604.5946044921875
INFO:root:Train (Epoch 181): Loss/seq after 00200 batchs: 658.4724731445312
INFO:root:Train (Epoch 181): Loss/seq after 00250 batchs: 725.8157348632812
INFO:root:Train (Epoch 181): Loss/seq after 00300 batchs: 735.5989379882812
INFO:root:Train (Epoch 181): Loss/seq after 00350 batchs: 694.1036987304688
INFO:root:Train (Epoch 181): Loss/seq after 00400 batchs: 687.1671752929688
INFO:root:Train (Epoch 181): Loss/seq after 00450 batchs: 682.9617919921875
INFO:root:Train (Epoch 181): Loss/seq after 00500 batchs: 661.55078125
INFO:root:Train (Epoch 181): Loss/seq after 00550 batchs: 645.3550415039062
INFO:root:Train (Epoch 181): Loss/seq after 00600 batchs: 623.221923828125
INFO:root:Train (Epoch 181): Loss/seq after 00650 batchs: 600.1307983398438
INFO:root:Train (Epoch 181): Loss/seq after 00700 batchs: 576.0039672851562
INFO:root:Train (Epoch 181): Loss/seq after 00750 batchs: 578.077880859375
INFO:root:Train (Epoch 181): Loss/seq after 00800 batchs: 583.7565307617188
INFO:root:Train (Epoch 181): Loss/seq after 00850 batchs: 565.5044555664062
INFO:root:Train (Epoch 181): Loss/seq after 00900 batchs: 554.1353149414062
INFO:root:Train (Epoch 181): Loss/seq after 00950 batchs: 550.9645385742188
INFO:root:Train (Epoch 181): Loss/seq after 01000 batchs: 542.6505737304688
INFO:root:Train (Epoch 181): Loss/seq after 01050 batchs: 532.707763671875
INFO:root:Train (Epoch 181): Loss/seq after 01100 batchs: 525.4476928710938
INFO:root:Train (Epoch 181): Loss/seq after 01150 batchs: 512.3564453125
INFO:root:Train (Epoch 181): Loss/seq after 01200 batchs: 517.3814086914062
INFO:root:Train (Epoch 181): Loss/seq after 01250 batchs: 517.125
INFO:root:Train (Epoch 181): Loss/seq after 01300 batchs: 507.53082275390625
INFO:root:Train (Epoch 181): Loss/seq after 01350 batchs: 499.5363464355469
INFO:root:Train (Epoch 181): Loss/seq after 01400 batchs: 501.33367919921875
INFO:root:Train (Epoch 181): Loss/seq after 01450 batchs: 503.66552734375
INFO:root:Train (Epoch 181): Loss/seq after 01500 batchs: 511.1955871582031
INFO:root:Train (Epoch 181): Loss/seq after 01550 batchs: 512.1901245117188
INFO:root:Train (Epoch 181): Loss/seq after 01600 batchs: 507.980712890625
INFO:root:Train (Epoch 181): Loss/seq after 01650 batchs: 506.2088317871094
INFO:root:Train (Epoch 181): Loss/seq after 01700 batchs: 509.5651550292969
INFO:root:Train (Epoch 181): Loss/seq after 01750 batchs: 507.40869140625
INFO:root:Train (Epoch 181): Loss/seq after 01800 batchs: 504.6800842285156
INFO:root:Train (Epoch 181): Loss/seq after 01850 batchs: 501.7241516113281
INFO:root:Train (Epoch 181): Loss/seq after 01900 batchs: 501.03143310546875
INFO:root:Train (Epoch 181): Loss/seq after 01950 batchs: 499.6592712402344
INFO:root:Train (Epoch 181): Loss/seq after 02000 batchs: 499.67864990234375
INFO:root:Train (Epoch 181): Loss/seq after 02050 batchs: 499.232666015625
INFO:root:Train (Epoch 181): Loss/seq after 02100 batchs: 497.34088134765625
INFO:root:Train (Epoch 181): Loss/seq after 02150 batchs: 495.8159484863281
INFO:root:Train (Epoch 181): Loss/seq after 02200 batchs: 493.6988220214844
INFO:root:Train (Epoch 181): Loss/seq after 02250 batchs: 492.0419921875
INFO:root:Train (Epoch 181): Loss/seq after 02300 batchs: 488.72613525390625
INFO:root:Train (Epoch 181): Loss/seq after 02350 batchs: 485.5521545410156
INFO:root:Train (Epoch 181): Loss/seq after 02400 batchs: 486.77728271484375
INFO:root:Train (Epoch 181): Loss/seq after 02450 batchs: 483.0233154296875
INFO:root:Train (Epoch 181): Loss/seq after 02500 batchs: 475.996337890625
INFO:root:Train (Epoch 181): Loss/seq after 02550 batchs: 470.3151550292969
INFO:root:Train (Epoch 181): Loss/seq after 02600 batchs: 468.98931884765625
INFO:root:Train (Epoch 181): Loss/seq after 02650 batchs: 466.10113525390625
INFO:root:Train (Epoch 181): Loss/seq after 02700 batchs: 463.81439208984375
INFO:root:Train (Epoch 181): Loss/seq after 02750 batchs: 459.871826171875
INFO:root:Train (Epoch 181): Loss/seq after 02800 batchs: 458.20635986328125
INFO:root:Train (Epoch 181): Loss/seq after 02850 batchs: 457.8662414550781
INFO:root:Train (Epoch 181): Loss/seq after 02900 batchs: 458.6707458496094
INFO:root:Train (Epoch 181): Loss/seq after 02950 batchs: 458.5105895996094
INFO:root:Train (Epoch 181): Loss/seq after 03000 batchs: 464.20233154296875
INFO:root:Train (Epoch 181): Loss/seq after 03050 batchs: 466.3543701171875
INFO:root:Train (Epoch 181): Loss/seq after 03100 batchs: 468.261474609375
INFO:root:Train (Epoch 181): Loss/seq after 03150 batchs: 468.86663818359375
INFO:root:Train (Epoch 181): Loss/seq after 03200 batchs: 468.9295959472656
INFO:root:Train (Epoch 181): Loss/seq after 03250 batchs: 470.74603271484375
INFO:root:Train (Epoch 181): Loss/seq after 03300 batchs: 469.8988037109375
INFO:root:Train (Epoch 181): Loss/seq after 03350 batchs: 469.01416015625
INFO:root:Train (Epoch 181): Loss/seq after 03400 batchs: 465.6136779785156
INFO:root:Train (Epoch 181): Loss/seq after 03450 batchs: 464.74969482421875
INFO:root:Train (Epoch 181): Loss/seq after 03500 batchs: 465.44805908203125
INFO:root:Train (Epoch 181): Loss/seq after 03550 batchs: 463.2089538574219
INFO:root:Train (Epoch 181): Loss/seq after 03600 batchs: 470.3365173339844
INFO:root:Train (Epoch 181): Loss/seq after 03650 batchs: 468.3571472167969
INFO:root:Train (Epoch 181): Loss/seq after 03700 batchs: 471.0135192871094
INFO:root:Train (Epoch 181): Loss/seq after 03750 batchs: 475.39508056640625
INFO:root:Train (Epoch 181): Loss/seq after 03800 batchs: 473.9723205566406
INFO:root:Train (Epoch 181): Loss/seq after 03850 batchs: 473.1009216308594
INFO:root:Train (Epoch 181): Loss/seq after 03900 batchs: 475.6097717285156
INFO:root:Train (Epoch 181): Loss/seq after 03950 batchs: 478.7195129394531
INFO:root:Train (Epoch 181): Loss/seq after 04000 batchs: 475.5272521972656
INFO:root:Train (Epoch 181): Loss/seq after 04050 batchs: 472.67303466796875
INFO:root:Train (Epoch 181): Loss/seq after 04100 batchs: 471.67547607421875
INFO:root:Train (Epoch 181): Loss/seq after 04150 batchs: 471.6590576171875
INFO:root:Train (Epoch 181): Loss/seq after 04200 batchs: 470.45416259765625
INFO:root:Train (Epoch 181): Loss/seq after 04250 batchs: 469.05230712890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 181): Loss/seq after 00000 batches: 459.9505310058594
INFO:root:# Valid (Epoch 181): Loss/seq after 00050 batches: 597.1953735351562
INFO:root:# Valid (Epoch 181): Loss/seq after 00100 batches: 603.359619140625
INFO:root:# Valid (Epoch 181): Loss/seq after 00150 batches: 459.65655517578125
INFO:root:# Valid (Epoch 181): Loss/seq after 00200 batches: 432.36962890625
INFO:root:Artifacts: Make stick videos for epoch 181
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_181_on_20220414_064941.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_181_index_110_on_20220414_064941.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 182): Loss/seq after 00000 batchs: 805.48095703125
INFO:root:Train (Epoch 182): Loss/seq after 00050 batchs: 668.3290405273438
INFO:root:Train (Epoch 182): Loss/seq after 00100 batchs: 649.8787231445312
INFO:root:Train (Epoch 182): Loss/seq after 00150 batchs: 604.53173828125
INFO:root:Train (Epoch 182): Loss/seq after 00200 batchs: 657.39697265625
INFO:root:Train (Epoch 182): Loss/seq after 00250 batchs: 722.1661987304688
INFO:root:Train (Epoch 182): Loss/seq after 00300 batchs: 730.9580688476562
INFO:root:Train (Epoch 182): Loss/seq after 00350 batchs: 689.5801391601562
INFO:root:Train (Epoch 182): Loss/seq after 00400 batchs: 681.6324462890625
INFO:root:Train (Epoch 182): Loss/seq after 00450 batchs: 678.388427734375
INFO:root:Train (Epoch 182): Loss/seq after 00500 batchs: 657.6353149414062
INFO:root:Train (Epoch 182): Loss/seq after 00550 batchs: 640.5116577148438
INFO:root:Train (Epoch 182): Loss/seq after 00600 batchs: 619.1901245117188
INFO:root:Train (Epoch 182): Loss/seq after 00650 batchs: 596.7967529296875
INFO:root:Train (Epoch 182): Loss/seq after 00700 batchs: 572.6129760742188
INFO:root:Train (Epoch 182): Loss/seq after 00750 batchs: 574.1944580078125
INFO:root:Train (Epoch 182): Loss/seq after 00800 batchs: 578.6590576171875
INFO:root:Train (Epoch 182): Loss/seq after 00850 batchs: 561.02783203125
INFO:root:Train (Epoch 182): Loss/seq after 00900 batchs: 550.3043823242188
INFO:root:Train (Epoch 182): Loss/seq after 00950 batchs: 547.0415649414062
INFO:root:Train (Epoch 182): Loss/seq after 01000 batchs: 538.6868286132812
INFO:root:Train (Epoch 182): Loss/seq after 01050 batchs: 528.7659912109375
INFO:root:Train (Epoch 182): Loss/seq after 01100 batchs: 521.5653076171875
INFO:root:Train (Epoch 182): Loss/seq after 01150 batchs: 508.5968933105469
INFO:root:Train (Epoch 182): Loss/seq after 01200 batchs: 513.733154296875
INFO:root:Train (Epoch 182): Loss/seq after 01250 batchs: 513.679931640625
INFO:root:Train (Epoch 182): Loss/seq after 01300 batchs: 504.02325439453125
INFO:root:Train (Epoch 182): Loss/seq after 01350 batchs: 496.5842590332031
INFO:root:Train (Epoch 182): Loss/seq after 01400 batchs: 498.23406982421875
INFO:root:Train (Epoch 182): Loss/seq after 01450 batchs: 500.65338134765625
INFO:root:Train (Epoch 182): Loss/seq after 01500 batchs: 508.33392333984375
INFO:root:Train (Epoch 182): Loss/seq after 01550 batchs: 510.0827941894531
INFO:root:Train (Epoch 182): Loss/seq after 01600 batchs: 505.8504943847656
INFO:root:Train (Epoch 182): Loss/seq after 01650 batchs: 504.34625244140625
INFO:root:Train (Epoch 182): Loss/seq after 01700 batchs: 507.9781494140625
INFO:root:Train (Epoch 182): Loss/seq after 01750 batchs: 505.798828125
INFO:root:Train (Epoch 182): Loss/seq after 01800 batchs: 503.0625
INFO:root:Train (Epoch 182): Loss/seq after 01850 batchs: 500.08441162109375
INFO:root:Train (Epoch 182): Loss/seq after 01900 batchs: 499.4500732421875
INFO:root:Train (Epoch 182): Loss/seq after 01950 batchs: 498.2042236328125
INFO:root:Train (Epoch 182): Loss/seq after 02000 batchs: 498.2229309082031
INFO:root:Train (Epoch 182): Loss/seq after 02050 batchs: 497.4961242675781
INFO:root:Train (Epoch 182): Loss/seq after 02100 batchs: 495.5937194824219
INFO:root:Train (Epoch 182): Loss/seq after 02150 batchs: 493.96697998046875
INFO:root:Train (Epoch 182): Loss/seq after 02200 batchs: 491.7732849121094
INFO:root:Train (Epoch 182): Loss/seq after 02250 batchs: 490.1930847167969
INFO:root:Train (Epoch 182): Loss/seq after 02300 batchs: 486.98760986328125
INFO:root:Train (Epoch 182): Loss/seq after 02350 batchs: 483.6503601074219
INFO:root:Train (Epoch 182): Loss/seq after 02400 batchs: 485.01837158203125
INFO:root:Train (Epoch 182): Loss/seq after 02450 batchs: 481.1844482421875
INFO:root:Train (Epoch 182): Loss/seq after 02500 batchs: 474.1634826660156
INFO:root:Train (Epoch 182): Loss/seq after 02550 batchs: 468.52410888671875
INFO:root:Train (Epoch 182): Loss/seq after 02600 batchs: 467.0146179199219
INFO:root:Train (Epoch 182): Loss/seq after 02650 batchs: 463.8839111328125
INFO:root:Train (Epoch 182): Loss/seq after 02700 batchs: 461.4247741699219
INFO:root:Train (Epoch 182): Loss/seq after 02750 batchs: 457.3816833496094
INFO:root:Train (Epoch 182): Loss/seq after 02800 batchs: 455.827392578125
INFO:root:Train (Epoch 182): Loss/seq after 02850 batchs: 455.51776123046875
INFO:root:Train (Epoch 182): Loss/seq after 02900 batchs: 456.65838623046875
INFO:root:Train (Epoch 182): Loss/seq after 02950 batchs: 456.55615234375
INFO:root:Train (Epoch 182): Loss/seq after 03000 batchs: 462.26947021484375
INFO:root:Train (Epoch 182): Loss/seq after 03050 batchs: 464.4921875
INFO:root:Train (Epoch 182): Loss/seq after 03100 batchs: 466.4465637207031
INFO:root:Train (Epoch 182): Loss/seq after 03150 batchs: 467.2288818359375
INFO:root:Train (Epoch 182): Loss/seq after 03200 batchs: 467.4283447265625
INFO:root:Train (Epoch 182): Loss/seq after 03250 batchs: 469.14874267578125
INFO:root:Train (Epoch 182): Loss/seq after 03300 batchs: 468.57623291015625
INFO:root:Train (Epoch 182): Loss/seq after 03350 batchs: 467.81365966796875
INFO:root:Train (Epoch 182): Loss/seq after 03400 batchs: 464.35015869140625
INFO:root:Train (Epoch 182): Loss/seq after 03450 batchs: 463.3603210449219
INFO:root:Train (Epoch 182): Loss/seq after 03500 batchs: 464.2076110839844
INFO:root:Train (Epoch 182): Loss/seq after 03550 batchs: 461.8933410644531
INFO:root:Train (Epoch 182): Loss/seq after 03600 batchs: 469.0718078613281
INFO:root:Train (Epoch 182): Loss/seq after 03650 batchs: 467.1311950683594
INFO:root:Train (Epoch 182): Loss/seq after 03700 batchs: 469.8253479003906
INFO:root:Train (Epoch 182): Loss/seq after 03750 batchs: 474.3037109375
INFO:root:Train (Epoch 182): Loss/seq after 03800 batchs: 472.8509826660156
INFO:root:Train (Epoch 182): Loss/seq after 03850 batchs: 471.847412109375
INFO:root:Train (Epoch 182): Loss/seq after 03900 batchs: 474.4984436035156
INFO:root:Train (Epoch 182): Loss/seq after 03950 batchs: 477.5221252441406
INFO:root:Train (Epoch 182): Loss/seq after 04000 batchs: 474.29107666015625
INFO:root:Train (Epoch 182): Loss/seq after 04050 batchs: 471.4552307128906
INFO:root:Train (Epoch 182): Loss/seq after 04100 batchs: 470.4198913574219
INFO:root:Train (Epoch 182): Loss/seq after 04150 batchs: 470.4797058105469
INFO:root:Train (Epoch 182): Loss/seq after 04200 batchs: 469.26617431640625
INFO:root:Train (Epoch 182): Loss/seq after 04250 batchs: 467.8514099121094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 182): Loss/seq after 00000 batches: 457.21527099609375
INFO:root:# Valid (Epoch 182): Loss/seq after 00050 batches: 617.760986328125
INFO:root:# Valid (Epoch 182): Loss/seq after 00100 batches: 608.4718627929688
INFO:root:# Valid (Epoch 182): Loss/seq after 00150 batches: 462.618896484375
INFO:root:# Valid (Epoch 182): Loss/seq after 00200 batches: 435.9544372558594
INFO:root:Artifacts: Make stick videos for epoch 182
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_182_on_20220414_065457.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_182_index_1114_on_20220414_065457.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 183): Loss/seq after 00000 batchs: 798.6868286132812
INFO:root:Train (Epoch 183): Loss/seq after 00050 batchs: 676.8379516601562
INFO:root:Train (Epoch 183): Loss/seq after 00100 batchs: 663.9296264648438
INFO:root:Train (Epoch 183): Loss/seq after 00150 batchs: 611.4974365234375
INFO:root:Train (Epoch 183): Loss/seq after 00200 batchs: 663.0563354492188
INFO:root:Train (Epoch 183): Loss/seq after 00250 batchs: 723.5281982421875
INFO:root:Train (Epoch 183): Loss/seq after 00300 batchs: 731.24560546875
INFO:root:Train (Epoch 183): Loss/seq after 00350 batchs: 689.2130737304688
INFO:root:Train (Epoch 183): Loss/seq after 00400 batchs: 683.1565551757812
INFO:root:Train (Epoch 183): Loss/seq after 00450 batchs: 679.2781372070312
INFO:root:Train (Epoch 183): Loss/seq after 00500 batchs: 656.7979125976562
INFO:root:Train (Epoch 183): Loss/seq after 00550 batchs: 640.6070556640625
INFO:root:Train (Epoch 183): Loss/seq after 00600 batchs: 618.9924926757812
INFO:root:Train (Epoch 183): Loss/seq after 00650 batchs: 596.3926391601562
INFO:root:Train (Epoch 183): Loss/seq after 00700 batchs: 571.9259033203125
INFO:root:Train (Epoch 183): Loss/seq after 00750 batchs: 573.7099609375
INFO:root:Train (Epoch 183): Loss/seq after 00800 batchs: 579.14208984375
INFO:root:Train (Epoch 183): Loss/seq after 00850 batchs: 561.3189086914062
INFO:root:Train (Epoch 183): Loss/seq after 00900 batchs: 549.8059692382812
INFO:root:Train (Epoch 183): Loss/seq after 00950 batchs: 546.8358764648438
INFO:root:Train (Epoch 183): Loss/seq after 01000 batchs: 538.3192138671875
INFO:root:Train (Epoch 183): Loss/seq after 01050 batchs: 529.3641967773438
INFO:root:Train (Epoch 183): Loss/seq after 01100 batchs: 522.0910034179688
INFO:root:Train (Epoch 183): Loss/seq after 01150 batchs: 509.16510009765625
INFO:root:Train (Epoch 183): Loss/seq after 01200 batchs: 514.8780517578125
INFO:root:Train (Epoch 183): Loss/seq after 01250 batchs: 514.9202880859375
INFO:root:Train (Epoch 183): Loss/seq after 01300 batchs: 505.2958679199219
INFO:root:Train (Epoch 183): Loss/seq after 01350 batchs: 497.7843017578125
INFO:root:Train (Epoch 183): Loss/seq after 01400 batchs: 499.2565002441406
INFO:root:Train (Epoch 183): Loss/seq after 01450 batchs: 501.9142761230469
INFO:root:Train (Epoch 183): Loss/seq after 01500 batchs: 509.1619567871094
INFO:root:Train (Epoch 183): Loss/seq after 01550 batchs: 510.4648742675781
INFO:root:Train (Epoch 183): Loss/seq after 01600 batchs: 506.38861083984375
INFO:root:Train (Epoch 183): Loss/seq after 01650 batchs: 504.72344970703125
INFO:root:Train (Epoch 183): Loss/seq after 01700 batchs: 508.06884765625
INFO:root:Train (Epoch 183): Loss/seq after 01750 batchs: 505.8674621582031
INFO:root:Train (Epoch 183): Loss/seq after 01800 batchs: 503.35919189453125
INFO:root:Train (Epoch 183): Loss/seq after 01850 batchs: 500.3404235839844
INFO:root:Train (Epoch 183): Loss/seq after 01900 batchs: 499.5620422363281
INFO:root:Train (Epoch 183): Loss/seq after 01950 batchs: 497.9469909667969
INFO:root:Train (Epoch 183): Loss/seq after 02000 batchs: 497.9442138671875
INFO:root:Train (Epoch 183): Loss/seq after 02050 batchs: 497.34674072265625
INFO:root:Train (Epoch 183): Loss/seq after 02100 batchs: 495.4020690917969
INFO:root:Train (Epoch 183): Loss/seq after 02150 batchs: 493.8509521484375
INFO:root:Train (Epoch 183): Loss/seq after 02200 batchs: 491.7845153808594
INFO:root:Train (Epoch 183): Loss/seq after 02250 batchs: 490.0829162597656
INFO:root:Train (Epoch 183): Loss/seq after 02300 batchs: 486.67327880859375
INFO:root:Train (Epoch 183): Loss/seq after 02350 batchs: 483.3670349121094
INFO:root:Train (Epoch 183): Loss/seq after 02400 batchs: 484.35089111328125
INFO:root:Train (Epoch 183): Loss/seq after 02450 batchs: 480.4800109863281
INFO:root:Train (Epoch 183): Loss/seq after 02500 batchs: 473.4478759765625
INFO:root:Train (Epoch 183): Loss/seq after 02550 batchs: 467.81005859375
INFO:root:Train (Epoch 183): Loss/seq after 02600 batchs: 466.4550476074219
INFO:root:Train (Epoch 183): Loss/seq after 02650 batchs: 463.494873046875
INFO:root:Train (Epoch 183): Loss/seq after 02700 batchs: 461.3368835449219
INFO:root:Train (Epoch 183): Loss/seq after 02750 batchs: 457.3684387207031
INFO:root:Train (Epoch 183): Loss/seq after 02800 batchs: 455.7673645019531
INFO:root:Train (Epoch 183): Loss/seq after 02850 batchs: 455.4574279785156
INFO:root:Train (Epoch 183): Loss/seq after 02900 batchs: 456.42889404296875
INFO:root:Train (Epoch 183): Loss/seq after 02950 batchs: 456.208740234375
INFO:root:Train (Epoch 183): Loss/seq after 03000 batchs: 461.8155212402344
INFO:root:Train (Epoch 183): Loss/seq after 03050 batchs: 463.90057373046875
INFO:root:Train (Epoch 183): Loss/seq after 03100 batchs: 466.08636474609375
INFO:root:Train (Epoch 183): Loss/seq after 03150 batchs: 466.9432067871094
INFO:root:Train (Epoch 183): Loss/seq after 03200 batchs: 467.4547119140625
INFO:root:Train (Epoch 183): Loss/seq after 03250 batchs: 469.36676025390625
INFO:root:Train (Epoch 183): Loss/seq after 03300 batchs: 468.8543701171875
INFO:root:Train (Epoch 183): Loss/seq after 03350 batchs: 468.0727844238281
INFO:root:Train (Epoch 183): Loss/seq after 03400 batchs: 464.536376953125
INFO:root:Train (Epoch 183): Loss/seq after 03450 batchs: 463.57122802734375
INFO:root:Train (Epoch 183): Loss/seq after 03500 batchs: 464.3934631347656
INFO:root:Train (Epoch 183): Loss/seq after 03550 batchs: 462.05682373046875
INFO:root:Train (Epoch 183): Loss/seq after 03600 batchs: 469.15936279296875
INFO:root:Train (Epoch 183): Loss/seq after 03650 batchs: 467.1759033203125
INFO:root:Train (Epoch 183): Loss/seq after 03700 batchs: 469.7398681640625
INFO:root:Train (Epoch 183): Loss/seq after 03750 batchs: 474.1150207519531
INFO:root:Train (Epoch 183): Loss/seq after 03800 batchs: 472.66253662109375
INFO:root:Train (Epoch 183): Loss/seq after 03850 batchs: 471.63482666015625
INFO:root:Train (Epoch 183): Loss/seq after 03900 batchs: 474.1960144042969
INFO:root:Train (Epoch 183): Loss/seq after 03950 batchs: 477.2952880859375
INFO:root:Train (Epoch 183): Loss/seq after 04000 batchs: 474.0823974609375
INFO:root:Train (Epoch 183): Loss/seq after 04050 batchs: 471.2395935058594
INFO:root:Train (Epoch 183): Loss/seq after 04100 batchs: 470.2522277832031
INFO:root:Train (Epoch 183): Loss/seq after 04150 batchs: 470.275390625
INFO:root:Train (Epoch 183): Loss/seq after 04200 batchs: 468.9563293457031
INFO:root:Train (Epoch 183): Loss/seq after 04250 batchs: 467.58746337890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 183): Loss/seq after 00000 batches: 436.7431640625
INFO:root:# Valid (Epoch 183): Loss/seq after 00050 batches: 602.0444946289062
INFO:root:# Valid (Epoch 183): Loss/seq after 00100 batches: 602.9575805664062
INFO:root:# Valid (Epoch 183): Loss/seq after 00150 batches: 458.6921081542969
INFO:root:# Valid (Epoch 183): Loss/seq after 00200 batches: 431.43084716796875
INFO:root:Artifacts: Make stick videos for epoch 183
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_183_on_20220414_070016.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_183_index_1285_on_20220414_070016.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 184): Loss/seq after 00000 batchs: 821.8456420898438
INFO:root:Train (Epoch 184): Loss/seq after 00050 batchs: 666.6373291015625
INFO:root:Train (Epoch 184): Loss/seq after 00100 batchs: 654.3255004882812
INFO:root:Train (Epoch 184): Loss/seq after 00150 batchs: 603.7880249023438
INFO:root:Train (Epoch 184): Loss/seq after 00200 batchs: 654.6427612304688
INFO:root:Train (Epoch 184): Loss/seq after 00250 batchs: 716.7144165039062
INFO:root:Train (Epoch 184): Loss/seq after 00300 batchs: 725.3924560546875
INFO:root:Train (Epoch 184): Loss/seq after 00350 batchs: 683.7239379882812
INFO:root:Train (Epoch 184): Loss/seq after 00400 batchs: 673.1393432617188
INFO:root:Train (Epoch 184): Loss/seq after 00450 batchs: 670.496826171875
INFO:root:Train (Epoch 184): Loss/seq after 00500 batchs: 648.0127563476562
INFO:root:Train (Epoch 184): Loss/seq after 00550 batchs: 631.186767578125
INFO:root:Train (Epoch 184): Loss/seq after 00600 batchs: 610.3324584960938
INFO:root:Train (Epoch 184): Loss/seq after 00650 batchs: 588.2335205078125
INFO:root:Train (Epoch 184): Loss/seq after 00700 batchs: 564.8501586914062
INFO:root:Train (Epoch 184): Loss/seq after 00750 batchs: 565.3372192382812
INFO:root:Train (Epoch 184): Loss/seq after 00800 batchs: 571.076904296875
INFO:root:Train (Epoch 184): Loss/seq after 00850 batchs: 553.2859497070312
INFO:root:Train (Epoch 184): Loss/seq after 00900 batchs: 543.1951293945312
INFO:root:Train (Epoch 184): Loss/seq after 00950 batchs: 540.138916015625
INFO:root:Train (Epoch 184): Loss/seq after 01000 batchs: 531.7020263671875
INFO:root:Train (Epoch 184): Loss/seq after 01050 batchs: 522.6151733398438
INFO:root:Train (Epoch 184): Loss/seq after 01100 batchs: 515.87158203125
INFO:root:Train (Epoch 184): Loss/seq after 01150 batchs: 502.9034729003906
INFO:root:Train (Epoch 184): Loss/seq after 01200 batchs: 508.7179870605469
INFO:root:Train (Epoch 184): Loss/seq after 01250 batchs: 509.20697021484375
INFO:root:Train (Epoch 184): Loss/seq after 01300 batchs: 499.6809997558594
INFO:root:Train (Epoch 184): Loss/seq after 01350 batchs: 491.7213134765625
INFO:root:Train (Epoch 184): Loss/seq after 01400 batchs: 493.3755187988281
INFO:root:Train (Epoch 184): Loss/seq after 01450 batchs: 496.06500244140625
INFO:root:Train (Epoch 184): Loss/seq after 01500 batchs: 503.6787414550781
INFO:root:Train (Epoch 184): Loss/seq after 01550 batchs: 505.402099609375
INFO:root:Train (Epoch 184): Loss/seq after 01600 batchs: 501.3326721191406
INFO:root:Train (Epoch 184): Loss/seq after 01650 batchs: 499.80194091796875
INFO:root:Train (Epoch 184): Loss/seq after 01700 batchs: 503.57427978515625
INFO:root:Train (Epoch 184): Loss/seq after 01750 batchs: 501.5770568847656
INFO:root:Train (Epoch 184): Loss/seq after 01800 batchs: 498.9782409667969
INFO:root:Train (Epoch 184): Loss/seq after 01850 batchs: 496.1189880371094
INFO:root:Train (Epoch 184): Loss/seq after 01900 batchs: 495.4113464355469
INFO:root:Train (Epoch 184): Loss/seq after 01950 batchs: 493.87579345703125
INFO:root:Train (Epoch 184): Loss/seq after 02000 batchs: 493.88873291015625
INFO:root:Train (Epoch 184): Loss/seq after 02050 batchs: 493.4143371582031
INFO:root:Train (Epoch 184): Loss/seq after 02100 batchs: 491.4547119140625
INFO:root:Train (Epoch 184): Loss/seq after 02150 batchs: 490.0789794921875
INFO:root:Train (Epoch 184): Loss/seq after 02200 batchs: 488.0777587890625
INFO:root:Train (Epoch 184): Loss/seq after 02250 batchs: 486.5910339355469
INFO:root:Train (Epoch 184): Loss/seq after 02300 batchs: 483.37188720703125
INFO:root:Train (Epoch 184): Loss/seq after 02350 batchs: 480.1681213378906
INFO:root:Train (Epoch 184): Loss/seq after 02400 batchs: 481.51251220703125
INFO:root:Train (Epoch 184): Loss/seq after 02450 batchs: 477.7232360839844
INFO:root:Train (Epoch 184): Loss/seq after 02500 batchs: 470.76568603515625
INFO:root:Train (Epoch 184): Loss/seq after 02550 batchs: 465.2302551269531
INFO:root:Train (Epoch 184): Loss/seq after 02600 batchs: 463.8409118652344
INFO:root:Train (Epoch 184): Loss/seq after 02650 batchs: 460.74462890625
INFO:root:Train (Epoch 184): Loss/seq after 02700 batchs: 458.3818664550781
INFO:root:Train (Epoch 184): Loss/seq after 02750 batchs: 454.2928771972656
INFO:root:Train (Epoch 184): Loss/seq after 02800 batchs: 452.1980895996094
INFO:root:Train (Epoch 184): Loss/seq after 02850 batchs: 451.7696838378906
INFO:root:Train (Epoch 184): Loss/seq after 02900 batchs: 452.6153259277344
INFO:root:Train (Epoch 184): Loss/seq after 02950 batchs: 452.4507751464844
INFO:root:Train (Epoch 184): Loss/seq after 03000 batchs: 458.2206115722656
INFO:root:Train (Epoch 184): Loss/seq after 03050 batchs: 460.37652587890625
INFO:root:Train (Epoch 184): Loss/seq after 03100 batchs: 462.0938720703125
INFO:root:Train (Epoch 184): Loss/seq after 03150 batchs: 462.591796875
INFO:root:Train (Epoch 184): Loss/seq after 03200 batchs: 462.75872802734375
INFO:root:Train (Epoch 184): Loss/seq after 03250 batchs: 464.29302978515625
INFO:root:Train (Epoch 184): Loss/seq after 03300 batchs: 463.3955383300781
INFO:root:Train (Epoch 184): Loss/seq after 03350 batchs: 462.4769592285156
INFO:root:Train (Epoch 184): Loss/seq after 03400 batchs: 459.0101013183594
INFO:root:Train (Epoch 184): Loss/seq after 03450 batchs: 458.18865966796875
INFO:root:Train (Epoch 184): Loss/seq after 03500 batchs: 458.8172302246094
INFO:root:Train (Epoch 184): Loss/seq after 03550 batchs: 456.5771179199219
INFO:root:Train (Epoch 184): Loss/seq after 03600 batchs: 463.65582275390625
INFO:root:Train (Epoch 184): Loss/seq after 03650 batchs: 461.7383117675781
INFO:root:Train (Epoch 184): Loss/seq after 03700 batchs: 464.3231506347656
INFO:root:Train (Epoch 184): Loss/seq after 03750 batchs: 468.7897644042969
INFO:root:Train (Epoch 184): Loss/seq after 03800 batchs: 467.3532409667969
INFO:root:Train (Epoch 184): Loss/seq after 03850 batchs: 466.4436950683594
INFO:root:Train (Epoch 184): Loss/seq after 03900 batchs: 468.9827575683594
INFO:root:Train (Epoch 184): Loss/seq after 03950 batchs: 471.9896545410156
INFO:root:Train (Epoch 184): Loss/seq after 04000 batchs: 468.8433532714844
INFO:root:Train (Epoch 184): Loss/seq after 04050 batchs: 466.05322265625
INFO:root:Train (Epoch 184): Loss/seq after 04100 batchs: 465.0778503417969
INFO:root:Train (Epoch 184): Loss/seq after 04150 batchs: 465.14166259765625
INFO:root:Train (Epoch 184): Loss/seq after 04200 batchs: 463.87310791015625
INFO:root:Train (Epoch 184): Loss/seq after 04250 batchs: 462.4907531738281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 184): Loss/seq after 00000 batches: 385.98040771484375
INFO:root:# Valid (Epoch 184): Loss/seq after 00050 batches: 582.27197265625
INFO:root:# Valid (Epoch 184): Loss/seq after 00100 batches: 590.3150634765625
INFO:root:# Valid (Epoch 184): Loss/seq after 00150 batches: 451.1662292480469
INFO:root:# Valid (Epoch 184): Loss/seq after 00200 batches: 424.3855285644531
INFO:root:Artifacts: Make stick videos for epoch 184
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_184_on_20220414_070534.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_184_index_94_on_20220414_070534.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 185): Loss/seq after 00000 batchs: 844.6721801757812
INFO:root:Train (Epoch 185): Loss/seq after 00050 batchs: 675.560302734375
INFO:root:Train (Epoch 185): Loss/seq after 00100 batchs: 651.2401733398438
INFO:root:Train (Epoch 185): Loss/seq after 00150 batchs: 598.144287109375
INFO:root:Train (Epoch 185): Loss/seq after 00200 batchs: 645.3743286132812
INFO:root:Train (Epoch 185): Loss/seq after 00250 batchs: 706.0260620117188
INFO:root:Train (Epoch 185): Loss/seq after 00300 batchs: 716.4843139648438
INFO:root:Train (Epoch 185): Loss/seq after 00350 batchs: 676.5800170898438
INFO:root:Train (Epoch 185): Loss/seq after 00400 batchs: 669.7201538085938
INFO:root:Train (Epoch 185): Loss/seq after 00450 batchs: 667.158447265625
INFO:root:Train (Epoch 185): Loss/seq after 00500 batchs: 645.6517333984375
INFO:root:Train (Epoch 185): Loss/seq after 00550 batchs: 629.4164428710938
INFO:root:Train (Epoch 185): Loss/seq after 00600 batchs: 608.4884033203125
INFO:root:Train (Epoch 185): Loss/seq after 00650 batchs: 585.9415893554688
INFO:root:Train (Epoch 185): Loss/seq after 00700 batchs: 561.9402465820312
INFO:root:Train (Epoch 185): Loss/seq after 00750 batchs: 562.595947265625
INFO:root:Train (Epoch 185): Loss/seq after 00800 batchs: 568.1427612304688
INFO:root:Train (Epoch 185): Loss/seq after 00850 batchs: 550.602294921875
INFO:root:Train (Epoch 185): Loss/seq after 00900 batchs: 539.9803466796875
INFO:root:Train (Epoch 185): Loss/seq after 00950 batchs: 537.68994140625
INFO:root:Train (Epoch 185): Loss/seq after 01000 batchs: 529.1295166015625
INFO:root:Train (Epoch 185): Loss/seq after 01050 batchs: 520.9691772460938
INFO:root:Train (Epoch 185): Loss/seq after 01100 batchs: 513.5949096679688
INFO:root:Train (Epoch 185): Loss/seq after 01150 batchs: 500.53350830078125
INFO:root:Train (Epoch 185): Loss/seq after 01200 batchs: 506.3770751953125
INFO:root:Train (Epoch 185): Loss/seq after 01250 batchs: 506.45843505859375
INFO:root:Train (Epoch 185): Loss/seq after 01300 batchs: 496.81402587890625
INFO:root:Train (Epoch 185): Loss/seq after 01350 batchs: 488.98272705078125
INFO:root:Train (Epoch 185): Loss/seq after 01400 batchs: 491.00543212890625
INFO:root:Train (Epoch 185): Loss/seq after 01450 batchs: 493.4664001464844
INFO:root:Train (Epoch 185): Loss/seq after 01500 batchs: 500.7928466796875
INFO:root:Train (Epoch 185): Loss/seq after 01550 batchs: 502.0520935058594
INFO:root:Train (Epoch 185): Loss/seq after 01600 batchs: 498.16339111328125
INFO:root:Train (Epoch 185): Loss/seq after 01650 batchs: 496.65594482421875
INFO:root:Train (Epoch 185): Loss/seq after 01700 batchs: 500.28851318359375
INFO:root:Train (Epoch 185): Loss/seq after 01750 batchs: 497.9742736816406
INFO:root:Train (Epoch 185): Loss/seq after 01800 batchs: 495.4983215332031
INFO:root:Train (Epoch 185): Loss/seq after 01850 batchs: 492.7340087890625
INFO:root:Train (Epoch 185): Loss/seq after 01900 batchs: 491.94134521484375
INFO:root:Train (Epoch 185): Loss/seq after 01950 batchs: 490.6293029785156
INFO:root:Train (Epoch 185): Loss/seq after 02000 batchs: 490.7103271484375
INFO:root:Train (Epoch 185): Loss/seq after 02050 batchs: 490.2257385253906
INFO:root:Train (Epoch 185): Loss/seq after 02100 batchs: 488.4201965332031
INFO:root:Train (Epoch 185): Loss/seq after 02150 batchs: 487.0141296386719
INFO:root:Train (Epoch 185): Loss/seq after 02200 batchs: 485.028564453125
INFO:root:Train (Epoch 185): Loss/seq after 02250 batchs: 483.4604187011719
INFO:root:Train (Epoch 185): Loss/seq after 02300 batchs: 480.1090087890625
INFO:root:Train (Epoch 185): Loss/seq after 02350 batchs: 476.958740234375
INFO:root:Train (Epoch 185): Loss/seq after 02400 batchs: 478.2989501953125
INFO:root:Train (Epoch 185): Loss/seq after 02450 batchs: 474.5695495605469
INFO:root:Train (Epoch 185): Loss/seq after 02500 batchs: 467.6428527832031
INFO:root:Train (Epoch 185): Loss/seq after 02550 batchs: 462.02325439453125
INFO:root:Train (Epoch 185): Loss/seq after 02600 batchs: 460.5904846191406
INFO:root:Train (Epoch 185): Loss/seq after 02650 batchs: 457.4896240234375
INFO:root:Train (Epoch 185): Loss/seq after 02700 batchs: 455.30804443359375
INFO:root:Train (Epoch 185): Loss/seq after 02750 batchs: 451.2066650390625
INFO:root:Train (Epoch 185): Loss/seq after 02800 batchs: 448.9222106933594
INFO:root:Train (Epoch 185): Loss/seq after 02850 batchs: 448.5716857910156
INFO:root:Train (Epoch 185): Loss/seq after 02900 batchs: 449.64263916015625
INFO:root:Train (Epoch 185): Loss/seq after 02950 batchs: 449.4935607910156
INFO:root:Train (Epoch 185): Loss/seq after 03000 batchs: 455.1640319824219
INFO:root:Train (Epoch 185): Loss/seq after 03050 batchs: 457.2381896972656
INFO:root:Train (Epoch 185): Loss/seq after 03100 batchs: 459.00067138671875
INFO:root:Train (Epoch 185): Loss/seq after 03150 batchs: 459.4745178222656
INFO:root:Train (Epoch 185): Loss/seq after 03200 batchs: 459.4128112792969
INFO:root:Train (Epoch 185): Loss/seq after 03250 batchs: 461.1468811035156
INFO:root:Train (Epoch 185): Loss/seq after 03300 batchs: 460.3106689453125
INFO:root:Train (Epoch 185): Loss/seq after 03350 batchs: 459.4831848144531
INFO:root:Train (Epoch 185): Loss/seq after 03400 batchs: 456.03729248046875
INFO:root:Train (Epoch 185): Loss/seq after 03450 batchs: 455.2193908691406
INFO:root:Train (Epoch 185): Loss/seq after 03500 batchs: 456.0416564941406
INFO:root:Train (Epoch 185): Loss/seq after 03550 batchs: 453.90093994140625
INFO:root:Train (Epoch 185): Loss/seq after 03600 batchs: 461.0133972167969
INFO:root:Train (Epoch 185): Loss/seq after 03650 batchs: 459.163818359375
INFO:root:Train (Epoch 185): Loss/seq after 03700 batchs: 461.6054992675781
INFO:root:Train (Epoch 185): Loss/seq after 03750 batchs: 466.0896301269531
INFO:root:Train (Epoch 185): Loss/seq after 03800 batchs: 464.7347717285156
INFO:root:Train (Epoch 185): Loss/seq after 03850 batchs: 463.79974365234375
INFO:root:Train (Epoch 185): Loss/seq after 03900 batchs: 466.3546447753906
INFO:root:Train (Epoch 185): Loss/seq after 03950 batchs: 469.3963928222656
INFO:root:Train (Epoch 185): Loss/seq after 04000 batchs: 466.26873779296875
INFO:root:Train (Epoch 185): Loss/seq after 04050 batchs: 463.4940490722656
INFO:root:Train (Epoch 185): Loss/seq after 04100 batchs: 462.50506591796875
INFO:root:Train (Epoch 185): Loss/seq after 04150 batchs: 462.6581115722656
INFO:root:Train (Epoch 185): Loss/seq after 04200 batchs: 461.4202880859375
INFO:root:Train (Epoch 185): Loss/seq after 04250 batchs: 460.0286560058594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 185): Loss/seq after 00000 batches: 373.849609375
INFO:root:# Valid (Epoch 185): Loss/seq after 00050 batches: 591.8264770507812
INFO:root:# Valid (Epoch 185): Loss/seq after 00100 batches: 607.6384887695312
INFO:root:# Valid (Epoch 185): Loss/seq after 00150 batches: 462.99969482421875
INFO:root:# Valid (Epoch 185): Loss/seq after 00200 batches: 435.0685119628906
INFO:root:Artifacts: Make stick videos for epoch 185
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_185_on_20220414_071052.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_185_index_1480_on_20220414_071052.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 186): Loss/seq after 00000 batchs: 823.017578125
INFO:root:Train (Epoch 186): Loss/seq after 00050 batchs: 651.4606323242188
INFO:root:Train (Epoch 186): Loss/seq after 00100 batchs: 632.2939453125
INFO:root:Train (Epoch 186): Loss/seq after 00150 batchs: 584.5326538085938
INFO:root:Train (Epoch 186): Loss/seq after 00200 batchs: 635.434814453125
INFO:root:Train (Epoch 186): Loss/seq after 00250 batchs: 701.10107421875
INFO:root:Train (Epoch 186): Loss/seq after 00300 batchs: 710.9285278320312
INFO:root:Train (Epoch 186): Loss/seq after 00350 batchs: 670.5028076171875
INFO:root:Train (Epoch 186): Loss/seq after 00400 batchs: 663.6705322265625
INFO:root:Train (Epoch 186): Loss/seq after 00450 batchs: 661.8964233398438
INFO:root:Train (Epoch 186): Loss/seq after 00500 batchs: 641.9271240234375
INFO:root:Train (Epoch 186): Loss/seq after 00550 batchs: 627.0565185546875
INFO:root:Train (Epoch 186): Loss/seq after 00600 batchs: 605.9773559570312
INFO:root:Train (Epoch 186): Loss/seq after 00650 batchs: 585.2171020507812
INFO:root:Train (Epoch 186): Loss/seq after 00700 batchs: 562.0248413085938
INFO:root:Train (Epoch 186): Loss/seq after 00750 batchs: 563.3084716796875
INFO:root:Train (Epoch 186): Loss/seq after 00800 batchs: 568.3096923828125
INFO:root:Train (Epoch 186): Loss/seq after 00850 batchs: 550.8522338867188
INFO:root:Train (Epoch 186): Loss/seq after 00900 batchs: 540.2579345703125
INFO:root:Train (Epoch 186): Loss/seq after 00950 batchs: 537.4855346679688
INFO:root:Train (Epoch 186): Loss/seq after 01000 batchs: 529.2011108398438
INFO:root:Train (Epoch 186): Loss/seq after 01050 batchs: 519.6593017578125
INFO:root:Train (Epoch 186): Loss/seq after 01100 batchs: 512.0591430664062
INFO:root:Train (Epoch 186): Loss/seq after 01150 batchs: 499.5093078613281
INFO:root:Train (Epoch 186): Loss/seq after 01200 batchs: 504.7115783691406
INFO:root:Train (Epoch 186): Loss/seq after 01250 batchs: 504.7782897949219
INFO:root:Train (Epoch 186): Loss/seq after 01300 batchs: 495.356689453125
INFO:root:Train (Epoch 186): Loss/seq after 01350 batchs: 487.4848937988281
INFO:root:Train (Epoch 186): Loss/seq after 01400 batchs: 489.12481689453125
INFO:root:Train (Epoch 186): Loss/seq after 01450 batchs: 491.65557861328125
INFO:root:Train (Epoch 186): Loss/seq after 01500 batchs: 499.3034362792969
INFO:root:Train (Epoch 186): Loss/seq after 01550 batchs: 500.5234680175781
INFO:root:Train (Epoch 186): Loss/seq after 01600 batchs: 496.3370361328125
INFO:root:Train (Epoch 186): Loss/seq after 01650 batchs: 494.86297607421875
INFO:root:Train (Epoch 186): Loss/seq after 01700 batchs: 498.4488525390625
INFO:root:Train (Epoch 186): Loss/seq after 01750 batchs: 496.2118225097656
INFO:root:Train (Epoch 186): Loss/seq after 01800 batchs: 493.72076416015625
INFO:root:Train (Epoch 186): Loss/seq after 01850 batchs: 490.93841552734375
INFO:root:Train (Epoch 186): Loss/seq after 01900 batchs: 490.3929748535156
INFO:root:Train (Epoch 186): Loss/seq after 01950 batchs: 488.9693908691406
INFO:root:Train (Epoch 186): Loss/seq after 02000 batchs: 489.166259765625
INFO:root:Train (Epoch 186): Loss/seq after 02050 batchs: 488.70635986328125
INFO:root:Train (Epoch 186): Loss/seq after 02100 batchs: 486.8713073730469
INFO:root:Train (Epoch 186): Loss/seq after 02150 batchs: 485.5270690917969
INFO:root:Train (Epoch 186): Loss/seq after 02200 batchs: 483.5600280761719
INFO:root:Train (Epoch 186): Loss/seq after 02250 batchs: 481.9873352050781
INFO:root:Train (Epoch 186): Loss/seq after 02300 batchs: 478.6580810546875
INFO:root:Train (Epoch 186): Loss/seq after 02350 batchs: 475.4234313964844
INFO:root:Train (Epoch 186): Loss/seq after 02400 batchs: 476.7300109863281
INFO:root:Train (Epoch 186): Loss/seq after 02450 batchs: 473.0513610839844
INFO:root:Train (Epoch 186): Loss/seq after 02500 batchs: 466.1497497558594
INFO:root:Train (Epoch 186): Loss/seq after 02550 batchs: 460.4516296386719
INFO:root:Train (Epoch 186): Loss/seq after 02600 batchs: 458.9733581542969
INFO:root:Train (Epoch 186): Loss/seq after 02650 batchs: 455.9339294433594
INFO:root:Train (Epoch 186): Loss/seq after 02700 batchs: 453.7585754394531
INFO:root:Train (Epoch 186): Loss/seq after 02750 batchs: 449.62750244140625
INFO:root:Train (Epoch 186): Loss/seq after 02800 batchs: 447.4156188964844
INFO:root:Train (Epoch 186): Loss/seq after 02850 batchs: 447.1421813964844
INFO:root:Train (Epoch 186): Loss/seq after 02900 batchs: 447.95947265625
INFO:root:Train (Epoch 186): Loss/seq after 02950 batchs: 447.8450927734375
INFO:root:Train (Epoch 186): Loss/seq after 03000 batchs: 453.4625549316406
INFO:root:Train (Epoch 186): Loss/seq after 03050 batchs: 455.4183349609375
INFO:root:Train (Epoch 186): Loss/seq after 03100 batchs: 457.04412841796875
INFO:root:Train (Epoch 186): Loss/seq after 03150 batchs: 457.2254943847656
INFO:root:Train (Epoch 186): Loss/seq after 03200 batchs: 457.1489562988281
INFO:root:Train (Epoch 186): Loss/seq after 03250 batchs: 458.67572021484375
INFO:root:Train (Epoch 186): Loss/seq after 03300 batchs: 457.7690734863281
INFO:root:Train (Epoch 186): Loss/seq after 03350 batchs: 456.5801086425781
INFO:root:Train (Epoch 186): Loss/seq after 03400 batchs: 453.17791748046875
INFO:root:Train (Epoch 186): Loss/seq after 03450 batchs: 452.2790222167969
INFO:root:Train (Epoch 186): Loss/seq after 03500 batchs: 452.9561767578125
INFO:root:Train (Epoch 186): Loss/seq after 03550 batchs: 450.7226257324219
INFO:root:Train (Epoch 186): Loss/seq after 03600 batchs: 457.79541015625
INFO:root:Train (Epoch 186): Loss/seq after 03650 batchs: 456.0257568359375
INFO:root:Train (Epoch 186): Loss/seq after 03700 batchs: 458.3923034667969
INFO:root:Train (Epoch 186): Loss/seq after 03750 batchs: 462.8105773925781
INFO:root:Train (Epoch 186): Loss/seq after 03800 batchs: 461.44354248046875
INFO:root:Train (Epoch 186): Loss/seq after 03850 batchs: 460.52252197265625
INFO:root:Train (Epoch 186): Loss/seq after 03900 batchs: 462.99053955078125
INFO:root:Train (Epoch 186): Loss/seq after 03950 batchs: 465.9859313964844
INFO:root:Train (Epoch 186): Loss/seq after 04000 batchs: 462.9051513671875
INFO:root:Train (Epoch 186): Loss/seq after 04050 batchs: 460.1299133300781
INFO:root:Train (Epoch 186): Loss/seq after 04100 batchs: 459.1441345214844
INFO:root:Train (Epoch 186): Loss/seq after 04150 batchs: 459.24627685546875
INFO:root:Train (Epoch 186): Loss/seq after 04200 batchs: 458.07391357421875
INFO:root:Train (Epoch 186): Loss/seq after 04250 batchs: 456.7251281738281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 186): Loss/seq after 00000 batches: 422.3364562988281
INFO:root:# Valid (Epoch 186): Loss/seq after 00050 batches: 583.9710083007812
INFO:root:# Valid (Epoch 186): Loss/seq after 00100 batches: 577.18505859375
INFO:root:# Valid (Epoch 186): Loss/seq after 00150 batches: 441.1804504394531
INFO:root:# Valid (Epoch 186): Loss/seq after 00200 batches: 418.2115173339844
INFO:root:Artifacts: Make stick videos for epoch 186
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_186_on_20220414_071611.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_186_index_1076_on_20220414_071611.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 187): Loss/seq after 00000 batchs: 749.8817138671875
INFO:root:Train (Epoch 187): Loss/seq after 00050 batchs: 648.6576538085938
INFO:root:Train (Epoch 187): Loss/seq after 00100 batchs: 621.2996215820312
INFO:root:Train (Epoch 187): Loss/seq after 00150 batchs: 579.4227294921875
INFO:root:Train (Epoch 187): Loss/seq after 00200 batchs: 632.78564453125
INFO:root:Train (Epoch 187): Loss/seq after 00250 batchs: 700.453125
INFO:root:Train (Epoch 187): Loss/seq after 00300 batchs: 710.807373046875
INFO:root:Train (Epoch 187): Loss/seq after 00350 batchs: 671.6329345703125
INFO:root:Train (Epoch 187): Loss/seq after 00400 batchs: 664.5703735351562
INFO:root:Train (Epoch 187): Loss/seq after 00450 batchs: 662.3551025390625
INFO:root:Train (Epoch 187): Loss/seq after 00500 batchs: 640.0526733398438
INFO:root:Train (Epoch 187): Loss/seq after 00550 batchs: 624.3619384765625
INFO:root:Train (Epoch 187): Loss/seq after 00600 batchs: 604.5894165039062
INFO:root:Train (Epoch 187): Loss/seq after 00650 batchs: 582.75537109375
INFO:root:Train (Epoch 187): Loss/seq after 00700 batchs: 559.7772827148438
INFO:root:Train (Epoch 187): Loss/seq after 00750 batchs: 560.0084838867188
INFO:root:Train (Epoch 187): Loss/seq after 00800 batchs: 564.94091796875
INFO:root:Train (Epoch 187): Loss/seq after 00850 batchs: 547.228515625
INFO:root:Train (Epoch 187): Loss/seq after 00900 batchs: 537.056640625
INFO:root:Train (Epoch 187): Loss/seq after 00950 batchs: 534.400146484375
INFO:root:Train (Epoch 187): Loss/seq after 01000 batchs: 526.0613403320312
INFO:root:Train (Epoch 187): Loss/seq after 01050 batchs: 516.5247192382812
INFO:root:Train (Epoch 187): Loss/seq after 01100 batchs: 508.974365234375
INFO:root:Train (Epoch 187): Loss/seq after 01150 batchs: 495.98822021484375
INFO:root:Train (Epoch 187): Loss/seq after 01200 batchs: 501.0464172363281
INFO:root:Train (Epoch 187): Loss/seq after 01250 batchs: 501.06903076171875
INFO:root:Train (Epoch 187): Loss/seq after 01300 batchs: 491.21337890625
INFO:root:Train (Epoch 187): Loss/seq after 01350 batchs: 483.7490539550781
INFO:root:Train (Epoch 187): Loss/seq after 01400 batchs: 485.0361633300781
INFO:root:Train (Epoch 187): Loss/seq after 01450 batchs: 487.70684814453125
INFO:root:Train (Epoch 187): Loss/seq after 01500 batchs: 495.1898498535156
INFO:root:Train (Epoch 187): Loss/seq after 01550 batchs: 496.7423400878906
INFO:root:Train (Epoch 187): Loss/seq after 01600 batchs: 493.0173034667969
INFO:root:Train (Epoch 187): Loss/seq after 01650 batchs: 491.5178527832031
INFO:root:Train (Epoch 187): Loss/seq after 01700 batchs: 495.0567932128906
INFO:root:Train (Epoch 187): Loss/seq after 01750 batchs: 493.0021057128906
INFO:root:Train (Epoch 187): Loss/seq after 01800 batchs: 490.4725646972656
INFO:root:Train (Epoch 187): Loss/seq after 01850 batchs: 487.6687316894531
INFO:root:Train (Epoch 187): Loss/seq after 01900 batchs: 487.025146484375
INFO:root:Train (Epoch 187): Loss/seq after 01950 batchs: 485.6378173828125
INFO:root:Train (Epoch 187): Loss/seq after 02000 batchs: 485.8699951171875
INFO:root:Train (Epoch 187): Loss/seq after 02050 batchs: 485.4959716796875
INFO:root:Train (Epoch 187): Loss/seq after 02100 batchs: 483.7118225097656
INFO:root:Train (Epoch 187): Loss/seq after 02150 batchs: 482.3907165527344
INFO:root:Train (Epoch 187): Loss/seq after 02200 batchs: 480.4929504394531
INFO:root:Train (Epoch 187): Loss/seq after 02250 batchs: 478.86712646484375
INFO:root:Train (Epoch 187): Loss/seq after 02300 batchs: 475.4622497558594
INFO:root:Train (Epoch 187): Loss/seq after 02350 batchs: 472.3942565917969
INFO:root:Train (Epoch 187): Loss/seq after 02400 batchs: 473.7525939941406
INFO:root:Train (Epoch 187): Loss/seq after 02450 batchs: 470.09210205078125
INFO:root:Train (Epoch 187): Loss/seq after 02500 batchs: 463.2451171875
INFO:root:Train (Epoch 187): Loss/seq after 02550 batchs: 457.5580139160156
INFO:root:Train (Epoch 187): Loss/seq after 02600 batchs: 456.23480224609375
INFO:root:Train (Epoch 187): Loss/seq after 02650 batchs: 453.10858154296875
INFO:root:Train (Epoch 187): Loss/seq after 02700 batchs: 450.8772277832031
INFO:root:Train (Epoch 187): Loss/seq after 02750 batchs: 446.8347473144531
INFO:root:Train (Epoch 187): Loss/seq after 02800 batchs: 444.6017150878906
INFO:root:Train (Epoch 187): Loss/seq after 02850 batchs: 444.3204345703125
INFO:root:Train (Epoch 187): Loss/seq after 02900 batchs: 445.3222961425781
INFO:root:Train (Epoch 187): Loss/seq after 02950 batchs: 445.1414489746094
INFO:root:Train (Epoch 187): Loss/seq after 03000 batchs: 450.8756408691406
INFO:root:Train (Epoch 187): Loss/seq after 03050 batchs: 452.9060974121094
INFO:root:Train (Epoch 187): Loss/seq after 03100 batchs: 454.547119140625
INFO:root:Train (Epoch 187): Loss/seq after 03150 batchs: 455.0757141113281
INFO:root:Train (Epoch 187): Loss/seq after 03200 batchs: 454.99713134765625
INFO:root:Train (Epoch 187): Loss/seq after 03250 batchs: 456.4386291503906
INFO:root:Train (Epoch 187): Loss/seq after 03300 batchs: 455.85430908203125
INFO:root:Train (Epoch 187): Loss/seq after 03350 batchs: 454.8603515625
INFO:root:Train (Epoch 187): Loss/seq after 03400 batchs: 451.536376953125
INFO:root:Train (Epoch 187): Loss/seq after 03450 batchs: 450.691162109375
INFO:root:Train (Epoch 187): Loss/seq after 03500 batchs: 451.6169738769531
INFO:root:Train (Epoch 187): Loss/seq after 03550 batchs: 449.5342102050781
INFO:root:Train (Epoch 187): Loss/seq after 03600 batchs: 456.6102600097656
INFO:root:Train (Epoch 187): Loss/seq after 03650 batchs: 454.6655578613281
INFO:root:Train (Epoch 187): Loss/seq after 03700 batchs: 457.1470947265625
INFO:root:Train (Epoch 187): Loss/seq after 03750 batchs: 461.5758361816406
INFO:root:Train (Epoch 187): Loss/seq after 03800 batchs: 460.22119140625
INFO:root:Train (Epoch 187): Loss/seq after 03850 batchs: 459.3144226074219
INFO:root:Train (Epoch 187): Loss/seq after 03900 batchs: 461.78680419921875
INFO:root:Train (Epoch 187): Loss/seq after 03950 batchs: 464.8625183105469
INFO:root:Train (Epoch 187): Loss/seq after 04000 batchs: 461.768310546875
INFO:root:Train (Epoch 187): Loss/seq after 04050 batchs: 458.9979553222656
INFO:root:Train (Epoch 187): Loss/seq after 04100 batchs: 457.994384765625
INFO:root:Train (Epoch 187): Loss/seq after 04150 batchs: 458.0658264160156
INFO:root:Train (Epoch 187): Loss/seq after 04200 batchs: 456.7679748535156
INFO:root:Train (Epoch 187): Loss/seq after 04250 batchs: 455.3426818847656
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 187): Loss/seq after 00000 batches: 438.9730224609375
INFO:root:# Valid (Epoch 187): Loss/seq after 00050 batches: 575.426513671875
INFO:root:# Valid (Epoch 187): Loss/seq after 00100 batches: 572.4804077148438
INFO:root:# Valid (Epoch 187): Loss/seq after 00150 batches: 436.7348937988281
INFO:root:# Valid (Epoch 187): Loss/seq after 00200 batches: 413.3332824707031
INFO:root:Artifacts: Make stick videos for epoch 187
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_187_on_20220414_072129.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_187_index_847_on_20220414_072129.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 188): Loss/seq after 00000 batchs: 752.7817993164062
INFO:root:Train (Epoch 188): Loss/seq after 00050 batchs: 653.63720703125
INFO:root:Train (Epoch 188): Loss/seq after 00100 batchs: 626.390625
INFO:root:Train (Epoch 188): Loss/seq after 00150 batchs: 586.9844970703125
INFO:root:Train (Epoch 188): Loss/seq after 00200 batchs: 632.7645874023438
INFO:root:Train (Epoch 188): Loss/seq after 00250 batchs: 691.9423217773438
INFO:root:Train (Epoch 188): Loss/seq after 00300 batchs: 702.9614868164062
INFO:root:Train (Epoch 188): Loss/seq after 00350 batchs: 663.3458251953125
INFO:root:Train (Epoch 188): Loss/seq after 00400 batchs: 653.7788696289062
INFO:root:Train (Epoch 188): Loss/seq after 00450 batchs: 653.1021728515625
INFO:root:Train (Epoch 188): Loss/seq after 00500 batchs: 633.0213012695312
INFO:root:Train (Epoch 188): Loss/seq after 00550 batchs: 617.6770629882812
INFO:root:Train (Epoch 188): Loss/seq after 00600 batchs: 597.6498413085938
INFO:root:Train (Epoch 188): Loss/seq after 00650 batchs: 575.7094116210938
INFO:root:Train (Epoch 188): Loss/seq after 00700 batchs: 552.3384399414062
INFO:root:Train (Epoch 188): Loss/seq after 00750 batchs: 552.6958618164062
INFO:root:Train (Epoch 188): Loss/seq after 00800 batchs: 558.8538818359375
INFO:root:Train (Epoch 188): Loss/seq after 00850 batchs: 541.6723022460938
INFO:root:Train (Epoch 188): Loss/seq after 00900 batchs: 531.5101928710938
INFO:root:Train (Epoch 188): Loss/seq after 00950 batchs: 528.734619140625
INFO:root:Train (Epoch 188): Loss/seq after 01000 batchs: 520.0572509765625
INFO:root:Train (Epoch 188): Loss/seq after 01050 batchs: 510.9632873535156
INFO:root:Train (Epoch 188): Loss/seq after 01100 batchs: 503.8049621582031
INFO:root:Train (Epoch 188): Loss/seq after 01150 batchs: 491.0830993652344
INFO:root:Train (Epoch 188): Loss/seq after 01200 batchs: 496.90771484375
INFO:root:Train (Epoch 188): Loss/seq after 01250 batchs: 497.08612060546875
INFO:root:Train (Epoch 188): Loss/seq after 01300 batchs: 487.2295227050781
INFO:root:Train (Epoch 188): Loss/seq after 01350 batchs: 479.6507873535156
INFO:root:Train (Epoch 188): Loss/seq after 01400 batchs: 481.08587646484375
INFO:root:Train (Epoch 188): Loss/seq after 01450 batchs: 483.79547119140625
INFO:root:Train (Epoch 188): Loss/seq after 01500 batchs: 491.2690124511719
INFO:root:Train (Epoch 188): Loss/seq after 01550 batchs: 492.7650146484375
INFO:root:Train (Epoch 188): Loss/seq after 01600 batchs: 488.95745849609375
INFO:root:Train (Epoch 188): Loss/seq after 01650 batchs: 487.657958984375
INFO:root:Train (Epoch 188): Loss/seq after 01700 batchs: 491.4731140136719
INFO:root:Train (Epoch 188): Loss/seq after 01750 batchs: 489.49591064453125
INFO:root:Train (Epoch 188): Loss/seq after 01800 batchs: 486.8895263671875
INFO:root:Train (Epoch 188): Loss/seq after 01850 batchs: 484.1722106933594
INFO:root:Train (Epoch 188): Loss/seq after 01900 batchs: 483.3086242675781
INFO:root:Train (Epoch 188): Loss/seq after 01950 batchs: 482.049072265625
INFO:root:Train (Epoch 188): Loss/seq after 02000 batchs: 482.2054443359375
INFO:root:Train (Epoch 188): Loss/seq after 02050 batchs: 481.9335632324219
INFO:root:Train (Epoch 188): Loss/seq after 02100 batchs: 480.16552734375
INFO:root:Train (Epoch 188): Loss/seq after 02150 batchs: 478.8365173339844
INFO:root:Train (Epoch 188): Loss/seq after 02200 batchs: 476.96490478515625
INFO:root:Train (Epoch 188): Loss/seq after 02250 batchs: 475.3525085449219
INFO:root:Train (Epoch 188): Loss/seq after 02300 batchs: 472.1919250488281
INFO:root:Train (Epoch 188): Loss/seq after 02350 batchs: 469.126708984375
INFO:root:Train (Epoch 188): Loss/seq after 02400 batchs: 470.3356018066406
INFO:root:Train (Epoch 188): Loss/seq after 02450 batchs: 466.65228271484375
INFO:root:Train (Epoch 188): Loss/seq after 02500 batchs: 459.8500061035156
INFO:root:Train (Epoch 188): Loss/seq after 02550 batchs: 454.2575378417969
INFO:root:Train (Epoch 188): Loss/seq after 02600 batchs: 452.740234375
INFO:root:Train (Epoch 188): Loss/seq after 02650 batchs: 449.7761535644531
INFO:root:Train (Epoch 188): Loss/seq after 02700 batchs: 447.5804443359375
INFO:root:Train (Epoch 188): Loss/seq after 02750 batchs: 443.40435791015625
INFO:root:Train (Epoch 188): Loss/seq after 02800 batchs: 441.3820495605469
INFO:root:Train (Epoch 188): Loss/seq after 02850 batchs: 441.1029968261719
INFO:root:Train (Epoch 188): Loss/seq after 02900 batchs: 442.1912841796875
INFO:root:Train (Epoch 188): Loss/seq after 02950 batchs: 442.0765075683594
INFO:root:Train (Epoch 188): Loss/seq after 03000 batchs: 447.7238464355469
INFO:root:Train (Epoch 188): Loss/seq after 03050 batchs: 449.8737487792969
INFO:root:Train (Epoch 188): Loss/seq after 03100 batchs: 451.67828369140625
INFO:root:Train (Epoch 188): Loss/seq after 03150 batchs: 452.41619873046875
INFO:root:Train (Epoch 188): Loss/seq after 03200 batchs: 452.5970153808594
INFO:root:Train (Epoch 188): Loss/seq after 03250 batchs: 454.423828125
INFO:root:Train (Epoch 188): Loss/seq after 03300 batchs: 453.8836975097656
INFO:root:Train (Epoch 188): Loss/seq after 03350 batchs: 452.9375305175781
INFO:root:Train (Epoch 188): Loss/seq after 03400 batchs: 449.5934753417969
INFO:root:Train (Epoch 188): Loss/seq after 03450 batchs: 448.7281188964844
INFO:root:Train (Epoch 188): Loss/seq after 03500 batchs: 449.5727233886719
INFO:root:Train (Epoch 188): Loss/seq after 03550 batchs: 447.35772705078125
INFO:root:Train (Epoch 188): Loss/seq after 03600 batchs: 454.4732666015625
INFO:root:Train (Epoch 188): Loss/seq after 03650 batchs: 452.6050109863281
INFO:root:Train (Epoch 188): Loss/seq after 03700 batchs: 455.13525390625
INFO:root:Train (Epoch 188): Loss/seq after 03750 batchs: 459.6247253417969
INFO:root:Train (Epoch 188): Loss/seq after 03800 batchs: 458.2876892089844
INFO:root:Train (Epoch 188): Loss/seq after 03850 batchs: 457.4497985839844
INFO:root:Train (Epoch 188): Loss/seq after 03900 batchs: 460.00006103515625
INFO:root:Train (Epoch 188): Loss/seq after 03950 batchs: 463.00323486328125
INFO:root:Train (Epoch 188): Loss/seq after 04000 batchs: 459.90478515625
INFO:root:Train (Epoch 188): Loss/seq after 04050 batchs: 457.1673278808594
INFO:root:Train (Epoch 188): Loss/seq after 04100 batchs: 456.2297668457031
INFO:root:Train (Epoch 188): Loss/seq after 04150 batchs: 456.22528076171875
INFO:root:Train (Epoch 188): Loss/seq after 04200 batchs: 454.9974060058594
INFO:root:Train (Epoch 188): Loss/seq after 04250 batchs: 453.581298828125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 188): Loss/seq after 00000 batches: 413.0899353027344
INFO:root:# Valid (Epoch 188): Loss/seq after 00050 batches: 600.0686645507812
INFO:root:# Valid (Epoch 188): Loss/seq after 00100 batches: 603.0576782226562
INFO:root:# Valid (Epoch 188): Loss/seq after 00150 batches: 459.09747314453125
INFO:root:# Valid (Epoch 188): Loss/seq after 00200 batches: 434.80389404296875
INFO:root:Artifacts: Make stick videos for epoch 188
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_188_on_20220414_072646.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_188_index_678_on_20220414_072646.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 189): Loss/seq after 00000 batchs: 860.3638916015625
INFO:root:Train (Epoch 189): Loss/seq after 00050 batchs: 640.74951171875
INFO:root:Train (Epoch 189): Loss/seq after 00100 batchs: 623.9583129882812
INFO:root:Train (Epoch 189): Loss/seq after 00150 batchs: 578.8463134765625
INFO:root:Train (Epoch 189): Loss/seq after 00200 batchs: 623.4243774414062
INFO:root:Train (Epoch 189): Loss/seq after 00250 batchs: 685.111328125
INFO:root:Train (Epoch 189): Loss/seq after 00300 batchs: 694.4957885742188
INFO:root:Train (Epoch 189): Loss/seq after 00350 batchs: 656.661376953125
INFO:root:Train (Epoch 189): Loss/seq after 00400 batchs: 652.0042724609375
INFO:root:Train (Epoch 189): Loss/seq after 00450 batchs: 651.5147094726562
INFO:root:Train (Epoch 189): Loss/seq after 00500 batchs: 631.6360473632812
INFO:root:Train (Epoch 189): Loss/seq after 00550 batchs: 616.61083984375
INFO:root:Train (Epoch 189): Loss/seq after 00600 batchs: 595.8557739257812
INFO:root:Train (Epoch 189): Loss/seq after 00650 batchs: 573.2444458007812
INFO:root:Train (Epoch 189): Loss/seq after 00700 batchs: 550.5059204101562
INFO:root:Train (Epoch 189): Loss/seq after 00750 batchs: 551.3687744140625
INFO:root:Train (Epoch 189): Loss/seq after 00800 batchs: 555.9378662109375
INFO:root:Train (Epoch 189): Loss/seq after 00850 batchs: 538.5833740234375
INFO:root:Train (Epoch 189): Loss/seq after 00900 batchs: 529.0274047851562
INFO:root:Train (Epoch 189): Loss/seq after 00950 batchs: 526.88916015625
INFO:root:Train (Epoch 189): Loss/seq after 01000 batchs: 518.6803588867188
INFO:root:Train (Epoch 189): Loss/seq after 01050 batchs: 509.34222412109375
INFO:root:Train (Epoch 189): Loss/seq after 01100 batchs: 501.7904357910156
INFO:root:Train (Epoch 189): Loss/seq after 01150 batchs: 488.9806213378906
INFO:root:Train (Epoch 189): Loss/seq after 01200 batchs: 494.4458312988281
INFO:root:Train (Epoch 189): Loss/seq after 01250 batchs: 494.9266052246094
INFO:root:Train (Epoch 189): Loss/seq after 01300 batchs: 485.363037109375
INFO:root:Train (Epoch 189): Loss/seq after 01350 batchs: 477.5823669433594
INFO:root:Train (Epoch 189): Loss/seq after 01400 batchs: 479.06591796875
INFO:root:Train (Epoch 189): Loss/seq after 01450 batchs: 481.8291931152344
INFO:root:Train (Epoch 189): Loss/seq after 01500 batchs: 489.2853088378906
INFO:root:Train (Epoch 189): Loss/seq after 01550 batchs: 490.67559814453125
INFO:root:Train (Epoch 189): Loss/seq after 01600 batchs: 486.848388671875
INFO:root:Train (Epoch 189): Loss/seq after 01650 batchs: 485.1801452636719
INFO:root:Train (Epoch 189): Loss/seq after 01700 batchs: 488.8576354980469
INFO:root:Train (Epoch 189): Loss/seq after 01750 batchs: 486.9169921875
INFO:root:Train (Epoch 189): Loss/seq after 01800 batchs: 484.39306640625
INFO:root:Train (Epoch 189): Loss/seq after 01850 batchs: 481.7726135253906
INFO:root:Train (Epoch 189): Loss/seq after 01900 batchs: 480.902099609375
INFO:root:Train (Epoch 189): Loss/seq after 01950 batchs: 479.5552673339844
INFO:root:Train (Epoch 189): Loss/seq after 02000 batchs: 479.8314208984375
INFO:root:Train (Epoch 189): Loss/seq after 02050 batchs: 479.4883728027344
INFO:root:Train (Epoch 189): Loss/seq after 02100 batchs: 477.9331970214844
INFO:root:Train (Epoch 189): Loss/seq after 02150 batchs: 476.4259948730469
INFO:root:Train (Epoch 189): Loss/seq after 02200 batchs: 474.53948974609375
INFO:root:Train (Epoch 189): Loss/seq after 02250 batchs: 472.9754638671875
INFO:root:Train (Epoch 189): Loss/seq after 02300 batchs: 469.7170715332031
INFO:root:Train (Epoch 189): Loss/seq after 02350 batchs: 466.6529235839844
INFO:root:Train (Epoch 189): Loss/seq after 02400 batchs: 467.99609375
INFO:root:Train (Epoch 189): Loss/seq after 02450 batchs: 464.468017578125
INFO:root:Train (Epoch 189): Loss/seq after 02500 batchs: 457.7109069824219
INFO:root:Train (Epoch 189): Loss/seq after 02550 batchs: 451.9937744140625
INFO:root:Train (Epoch 189): Loss/seq after 02600 batchs: 450.5281066894531
INFO:root:Train (Epoch 189): Loss/seq after 02650 batchs: 447.3839111328125
INFO:root:Train (Epoch 189): Loss/seq after 02700 batchs: 445.11798095703125
INFO:root:Train (Epoch 189): Loss/seq after 02750 batchs: 441.1705322265625
INFO:root:Train (Epoch 189): Loss/seq after 02800 batchs: 438.9851379394531
INFO:root:Train (Epoch 189): Loss/seq after 02850 batchs: 438.76434326171875
INFO:root:Train (Epoch 189): Loss/seq after 02900 batchs: 439.84429931640625
INFO:root:Train (Epoch 189): Loss/seq after 02950 batchs: 439.81134033203125
INFO:root:Train (Epoch 189): Loss/seq after 03000 batchs: 445.51837158203125
INFO:root:Train (Epoch 189): Loss/seq after 03050 batchs: 447.5787658691406
INFO:root:Train (Epoch 189): Loss/seq after 03100 batchs: 449.50384521484375
INFO:root:Train (Epoch 189): Loss/seq after 03150 batchs: 449.90301513671875
INFO:root:Train (Epoch 189): Loss/seq after 03200 batchs: 450.07373046875
INFO:root:Train (Epoch 189): Loss/seq after 03250 batchs: 451.91571044921875
INFO:root:Train (Epoch 189): Loss/seq after 03300 batchs: 451.5484313964844
INFO:root:Train (Epoch 189): Loss/seq after 03350 batchs: 450.6745910644531
INFO:root:Train (Epoch 189): Loss/seq after 03400 batchs: 447.36041259765625
INFO:root:Train (Epoch 189): Loss/seq after 03450 batchs: 446.4018859863281
INFO:root:Train (Epoch 189): Loss/seq after 03500 batchs: 447.3531188964844
INFO:root:Train (Epoch 189): Loss/seq after 03550 batchs: 445.11456298828125
INFO:root:Train (Epoch 189): Loss/seq after 03600 batchs: 452.1338806152344
INFO:root:Train (Epoch 189): Loss/seq after 03650 batchs: 450.25225830078125
INFO:root:Train (Epoch 189): Loss/seq after 03700 batchs: 452.7966003417969
INFO:root:Train (Epoch 189): Loss/seq after 03750 batchs: 457.23016357421875
INFO:root:Train (Epoch 189): Loss/seq after 03800 batchs: 455.92327880859375
INFO:root:Train (Epoch 189): Loss/seq after 03850 batchs: 455.00274658203125
INFO:root:Train (Epoch 189): Loss/seq after 03900 batchs: 457.4896545410156
INFO:root:Train (Epoch 189): Loss/seq after 03950 batchs: 460.4769287109375
INFO:root:Train (Epoch 189): Loss/seq after 04000 batchs: 457.4049377441406
INFO:root:Train (Epoch 189): Loss/seq after 04050 batchs: 454.7220764160156
INFO:root:Train (Epoch 189): Loss/seq after 04100 batchs: 453.77435302734375
INFO:root:Train (Epoch 189): Loss/seq after 04150 batchs: 453.8229064941406
INFO:root:Train (Epoch 189): Loss/seq after 04200 batchs: 452.6031494140625
INFO:root:Train (Epoch 189): Loss/seq after 04250 batchs: 451.1671142578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 189): Loss/seq after 00000 batches: 386.8764343261719
INFO:root:# Valid (Epoch 189): Loss/seq after 00050 batches: 571.1561279296875
INFO:root:# Valid (Epoch 189): Loss/seq after 00100 batches: 578.14453125
INFO:root:# Valid (Epoch 189): Loss/seq after 00150 batches: 442.40277099609375
INFO:root:# Valid (Epoch 189): Loss/seq after 00200 batches: 420.0696716308594
INFO:root:Artifacts: Make stick videos for epoch 189
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_189_on_20220414_073205.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_189_index_764_on_20220414_073205.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 190): Loss/seq after 00000 batchs: 771.4859619140625
INFO:root:Train (Epoch 190): Loss/seq after 00050 batchs: 626.239013671875
INFO:root:Train (Epoch 190): Loss/seq after 00100 batchs: 613.4470825195312
INFO:root:Train (Epoch 190): Loss/seq after 00150 batchs: 569.57373046875
INFO:root:Train (Epoch 190): Loss/seq after 00200 batchs: 621.1846313476562
INFO:root:Train (Epoch 190): Loss/seq after 00250 batchs: 677.6859130859375
INFO:root:Train (Epoch 190): Loss/seq after 00300 batchs: 688.0684814453125
INFO:root:Train (Epoch 190): Loss/seq after 00350 batchs: 651.4118041992188
INFO:root:Train (Epoch 190): Loss/seq after 00400 batchs: 642.8445434570312
INFO:root:Train (Epoch 190): Loss/seq after 00450 batchs: 642.5621337890625
INFO:root:Train (Epoch 190): Loss/seq after 00500 batchs: 622.354736328125
INFO:root:Train (Epoch 190): Loss/seq after 00550 batchs: 607.33740234375
INFO:root:Train (Epoch 190): Loss/seq after 00600 batchs: 587.1932373046875
INFO:root:Train (Epoch 190): Loss/seq after 00650 batchs: 565.1895751953125
INFO:root:Train (Epoch 190): Loss/seq after 00700 batchs: 542.5603637695312
INFO:root:Train (Epoch 190): Loss/seq after 00750 batchs: 542.5660400390625
INFO:root:Train (Epoch 190): Loss/seq after 00800 batchs: 548.4883422851562
INFO:root:Train (Epoch 190): Loss/seq after 00850 batchs: 531.6394653320312
INFO:root:Train (Epoch 190): Loss/seq after 00900 batchs: 521.9443969726562
INFO:root:Train (Epoch 190): Loss/seq after 00950 batchs: 518.2783813476562
INFO:root:Train (Epoch 190): Loss/seq after 01000 batchs: 510.2730712890625
INFO:root:Train (Epoch 190): Loss/seq after 01050 batchs: 501.1171875
INFO:root:Train (Epoch 190): Loss/seq after 01100 batchs: 493.6516418457031
INFO:root:Train (Epoch 190): Loss/seq after 01150 batchs: 481.1080627441406
INFO:root:Train (Epoch 190): Loss/seq after 01200 batchs: 486.54937744140625
INFO:root:Train (Epoch 190): Loss/seq after 01250 batchs: 487.1716003417969
INFO:root:Train (Epoch 190): Loss/seq after 01300 batchs: 477.9938049316406
INFO:root:Train (Epoch 190): Loss/seq after 01350 batchs: 470.82147216796875
INFO:root:Train (Epoch 190): Loss/seq after 01400 batchs: 472.4874267578125
INFO:root:Train (Epoch 190): Loss/seq after 01450 batchs: 475.2935485839844
INFO:root:Train (Epoch 190): Loss/seq after 01500 batchs: 483.0341491699219
INFO:root:Train (Epoch 190): Loss/seq after 01550 batchs: 484.7544250488281
INFO:root:Train (Epoch 190): Loss/seq after 01600 batchs: 480.9717712402344
INFO:root:Train (Epoch 190): Loss/seq after 01650 batchs: 479.4684753417969
INFO:root:Train (Epoch 190): Loss/seq after 01700 batchs: 483.5032653808594
INFO:root:Train (Epoch 190): Loss/seq after 01750 batchs: 481.5356750488281
INFO:root:Train (Epoch 190): Loss/seq after 01800 batchs: 479.1944274902344
INFO:root:Train (Epoch 190): Loss/seq after 01850 batchs: 476.64508056640625
INFO:root:Train (Epoch 190): Loss/seq after 01900 batchs: 475.94268798828125
wandb: Network error (ReadTimeout), entering retry loop.
INFO:root:Train (Epoch 190): Loss/seq after 01950 batchs: 474.8262023925781
INFO:root:Train (Epoch 190): Loss/seq after 02000 batchs: 475.2217102050781
INFO:root:Train (Epoch 190): Loss/seq after 02050 batchs: 474.8699645996094
INFO:root:Train (Epoch 190): Loss/seq after 02100 batchs: 473.3520812988281
INFO:root:Train (Epoch 190): Loss/seq after 02150 batchs: 472.06005859375
INFO:root:Train (Epoch 190): Loss/seq after 02200 batchs: 470.16424560546875
INFO:root:Train (Epoch 190): Loss/seq after 02250 batchs: 468.8545837402344
INFO:root:Train (Epoch 190): Loss/seq after 02300 batchs: 465.47113037109375
INFO:root:Train (Epoch 190): Loss/seq after 02350 batchs: 462.4823303222656
INFO:root:Train (Epoch 190): Loss/seq after 02400 batchs: 463.8256530761719
INFO:root:Train (Epoch 190): Loss/seq after 02450 batchs: 460.3077392578125
INFO:root:Train (Epoch 190): Loss/seq after 02500 batchs: 453.6298522949219
INFO:root:Train (Epoch 190): Loss/seq after 02550 batchs: 447.9099426269531
INFO:root:Train (Epoch 190): Loss/seq after 02600 batchs: 446.54559326171875
INFO:root:Train (Epoch 190): Loss/seq after 02650 batchs: 443.4378967285156
INFO:root:Train (Epoch 190): Loss/seq after 02700 batchs: 441.42218017578125
INFO:root:Train (Epoch 190): Loss/seq after 02750 batchs: 437.5086364746094
INFO:root:Train (Epoch 190): Loss/seq after 02800 batchs: 435.56591796875
INFO:root:Train (Epoch 190): Loss/seq after 02850 batchs: 435.3490905761719
INFO:root:Train (Epoch 190): Loss/seq after 02900 batchs: 436.3602600097656
INFO:root:Train (Epoch 190): Loss/seq after 02950 batchs: 436.2342834472656
INFO:root:Train (Epoch 190): Loss/seq after 03000 batchs: 441.96343994140625
INFO:root:Train (Epoch 190): Loss/seq after 03050 batchs: 444.4254455566406
INFO:root:Train (Epoch 190): Loss/seq after 03100 batchs: 446.1839904785156
INFO:root:Train (Epoch 190): Loss/seq after 03150 batchs: 446.7994689941406
INFO:root:Train (Epoch 190): Loss/seq after 03200 batchs: 447.0372314453125
INFO:root:Train (Epoch 190): Loss/seq after 03250 batchs: 448.6579284667969
INFO:root:Train (Epoch 190): Loss/seq after 03300 batchs: 448.3619384765625
INFO:root:Train (Epoch 190): Loss/seq after 03350 batchs: 447.41748046875
INFO:root:Train (Epoch 190): Loss/seq after 03400 batchs: 444.1156311035156
INFO:root:Train (Epoch 190): Loss/seq after 03450 batchs: 443.1896667480469
INFO:root:Train (Epoch 190): Loss/seq after 03500 batchs: 444.0381774902344
INFO:root:Train (Epoch 190): Loss/seq after 03550 batchs: 441.9737548828125
INFO:root:Train (Epoch 190): Loss/seq after 03600 batchs: 448.8874206542969
INFO:root:Train (Epoch 190): Loss/seq after 03650 batchs: 447.1225891113281
INFO:root:Train (Epoch 190): Loss/seq after 03700 batchs: 449.6969299316406
INFO:root:Train (Epoch 190): Loss/seq after 03750 batchs: 454.1401062011719
INFO:root:Train (Epoch 190): Loss/seq after 03800 batchs: 452.9031982421875
INFO:root:Train (Epoch 190): Loss/seq after 03850 batchs: 451.9847412109375
INFO:root:Train (Epoch 190): Loss/seq after 03900 batchs: 454.45452880859375
INFO:root:Train (Epoch 190): Loss/seq after 03950 batchs: 457.23529052734375
INFO:root:Train (Epoch 190): Loss/seq after 04000 batchs: 454.21246337890625
INFO:root:Train (Epoch 190): Loss/seq after 04050 batchs: 451.4771423339844
INFO:root:Train (Epoch 190): Loss/seq after 04100 batchs: 450.6141357421875
INFO:root:Train (Epoch 190): Loss/seq after 04150 batchs: 450.6907958984375
INFO:root:Train (Epoch 190): Loss/seq after 04200 batchs: 449.5767822265625
INFO:root:Train (Epoch 190): Loss/seq after 04250 batchs: 448.2473449707031
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 190): Loss/seq after 00000 batches: 389.9611511230469
INFO:root:# Valid (Epoch 190): Loss/seq after 00050 batches: 572.7564086914062
INFO:root:# Valid (Epoch 190): Loss/seq after 00100 batches: 576.0457153320312
INFO:root:# Valid (Epoch 190): Loss/seq after 00150 batches: 439.77679443359375
INFO:root:# Valid (Epoch 190): Loss/seq after 00200 batches: 414.61773681640625
INFO:root:Artifacts: Make stick videos for epoch 190
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_190_on_20220414_073723.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_190_index_1212_on_20220414_073723.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 191): Loss/seq after 00000 batchs: 933.1588134765625
INFO:root:Train (Epoch 191): Loss/seq after 00050 batchs: 642.7598876953125
INFO:root:Train (Epoch 191): Loss/seq after 00100 batchs: 615.8545532226562
INFO:root:Train (Epoch 191): Loss/seq after 00150 batchs: 572.3426513671875
INFO:root:Train (Epoch 191): Loss/seq after 00200 batchs: 617.9554443359375
INFO:root:Train (Epoch 191): Loss/seq after 00250 batchs: 681.1444702148438
INFO:root:Train (Epoch 191): Loss/seq after 00300 batchs: 690.7781982421875
INFO:root:Train (Epoch 191): Loss/seq after 00350 batchs: 652.5364379882812
INFO:root:Train (Epoch 191): Loss/seq after 00400 batchs: 648.498046875
INFO:root:Train (Epoch 191): Loss/seq after 00450 batchs: 648.3441162109375
INFO:root:Train (Epoch 191): Loss/seq after 00500 batchs: 627.8335571289062
INFO:root:Train (Epoch 191): Loss/seq after 00550 batchs: 612.8843383789062
INFO:root:Train (Epoch 191): Loss/seq after 00600 batchs: 592.3431396484375
INFO:root:Train (Epoch 191): Loss/seq after 00650 batchs: 570.6198120117188
INFO:root:Train (Epoch 191): Loss/seq after 00700 batchs: 546.8671875
INFO:root:Train (Epoch 191): Loss/seq after 00750 batchs: 546.8123168945312
INFO:root:Train (Epoch 191): Loss/seq after 00800 batchs: 551.7379150390625
INFO:root:Train (Epoch 191): Loss/seq after 00850 batchs: 534.3236083984375
INFO:root:Train (Epoch 191): Loss/seq after 00900 batchs: 524.2833251953125
INFO:root:Train (Epoch 191): Loss/seq after 00950 batchs: 521.1218872070312
INFO:root:Train (Epoch 191): Loss/seq after 01000 batchs: 512.22119140625
INFO:root:Train (Epoch 191): Loss/seq after 01050 batchs: 502.958251953125
INFO:root:Train (Epoch 191): Loss/seq after 01100 batchs: 495.49755859375
INFO:root:Train (Epoch 191): Loss/seq after 01150 batchs: 482.7731018066406
INFO:root:Train (Epoch 191): Loss/seq after 01200 batchs: 487.99493408203125
INFO:root:Train (Epoch 191): Loss/seq after 01250 batchs: 488.3820495605469
INFO:root:Train (Epoch 191): Loss/seq after 01300 batchs: 478.60986328125
INFO:root:Train (Epoch 191): Loss/seq after 01350 batchs: 471.6064758300781
INFO:root:Train (Epoch 191): Loss/seq after 01400 batchs: 473.5581970214844
INFO:root:Train (Epoch 191): Loss/seq after 01450 batchs: 476.31878662109375
INFO:root:Train (Epoch 191): Loss/seq after 01500 batchs: 484.0158386230469
INFO:root:Train (Epoch 191): Loss/seq after 01550 batchs: 485.24566650390625
INFO:root:Train (Epoch 191): Loss/seq after 01600 batchs: 481.33013916015625
INFO:root:Train (Epoch 191): Loss/seq after 01650 batchs: 479.825439453125
INFO:root:Train (Epoch 191): Loss/seq after 01700 batchs: 483.60577392578125
INFO:root:Train (Epoch 191): Loss/seq after 01750 batchs: 481.6635437011719
INFO:root:Train (Epoch 191): Loss/seq after 01800 batchs: 479.11260986328125
INFO:root:Train (Epoch 191): Loss/seq after 01850 batchs: 476.46392822265625
INFO:root:Train (Epoch 191): Loss/seq after 01900 batchs: 475.78741455078125
INFO:root:Train (Epoch 191): Loss/seq after 01950 batchs: 474.5362548828125
INFO:root:Train (Epoch 191): Loss/seq after 02000 batchs: 474.80963134765625
INFO:root:Train (Epoch 191): Loss/seq after 02050 batchs: 474.44781494140625
INFO:root:Train (Epoch 191): Loss/seq after 02100 batchs: 472.8574523925781
INFO:root:Train (Epoch 191): Loss/seq after 02150 batchs: 471.4348449707031
INFO:root:Train (Epoch 191): Loss/seq after 02200 batchs: 469.56109619140625
INFO:root:Train (Epoch 191): Loss/seq after 02250 batchs: 468.31280517578125
INFO:root:Train (Epoch 191): Loss/seq after 02300 batchs: 465.1235656738281
INFO:root:Train (Epoch 191): Loss/seq after 02350 batchs: 462.27130126953125
INFO:root:Train (Epoch 191): Loss/seq after 02400 batchs: 463.6058349609375
INFO:root:Train (Epoch 191): Loss/seq after 02450 batchs: 460.03509521484375
INFO:root:Train (Epoch 191): Loss/seq after 02500 batchs: 453.338623046875
INFO:root:Train (Epoch 191): Loss/seq after 02550 batchs: 447.6800842285156
INFO:root:Train (Epoch 191): Loss/seq after 02600 batchs: 446.0390319824219
INFO:root:Train (Epoch 191): Loss/seq after 02650 batchs: 443.010986328125
INFO:root:Train (Epoch 191): Loss/seq after 02700 batchs: 440.6058044433594
INFO:root:Train (Epoch 191): Loss/seq after 02750 batchs: 436.70709228515625
INFO:root:Train (Epoch 191): Loss/seq after 02800 batchs: 434.7237548828125
INFO:root:Train (Epoch 191): Loss/seq after 02850 batchs: 434.31121826171875
INFO:root:Train (Epoch 191): Loss/seq after 02900 batchs: 435.2746276855469
INFO:root:Train (Epoch 191): Loss/seq after 02950 batchs: 435.2110595703125
INFO:root:Train (Epoch 191): Loss/seq after 03000 batchs: 440.7703552246094
INFO:root:Train (Epoch 191): Loss/seq after 03050 batchs: 442.87347412109375
INFO:root:Train (Epoch 191): Loss/seq after 03100 batchs: 445.0246276855469
INFO:root:Train (Epoch 191): Loss/seq after 03150 batchs: 446.0152587890625
INFO:root:Train (Epoch 191): Loss/seq after 03200 batchs: 446.1591796875
INFO:root:Train (Epoch 191): Loss/seq after 03250 batchs: 447.41583251953125
INFO:root:Train (Epoch 191): Loss/seq after 03300 batchs: 446.8553161621094
INFO:root:Train (Epoch 191): Loss/seq after 03350 batchs: 445.7562255859375
INFO:root:Train (Epoch 191): Loss/seq after 03400 batchs: 442.467041015625
INFO:root:Train (Epoch 191): Loss/seq after 03450 batchs: 441.64654541015625
INFO:root:Train (Epoch 191): Loss/seq after 03500 batchs: 442.4581298828125
INFO:root:Train (Epoch 191): Loss/seq after 03550 batchs: 440.3506164550781
INFO:root:Train (Epoch 191): Loss/seq after 03600 batchs: 447.3477478027344
INFO:root:Train (Epoch 191): Loss/seq after 03650 batchs: 445.6119079589844
INFO:root:Train (Epoch 191): Loss/seq after 03700 batchs: 447.9533386230469
INFO:root:Train (Epoch 191): Loss/seq after 03750 batchs: 452.3444519042969
INFO:root:Train (Epoch 191): Loss/seq after 03800 batchs: 451.0951843261719
INFO:root:Train (Epoch 191): Loss/seq after 03850 batchs: 450.1476745605469
INFO:root:Train (Epoch 191): Loss/seq after 03900 batchs: 452.3983154296875
INFO:root:Train (Epoch 191): Loss/seq after 03950 batchs: 455.38409423828125
INFO:root:Train (Epoch 191): Loss/seq after 04000 batchs: 452.3702392578125
INFO:root:Train (Epoch 191): Loss/seq after 04050 batchs: 449.6700134277344
INFO:root:Train (Epoch 191): Loss/seq after 04100 batchs: 448.7637634277344
INFO:root:Train (Epoch 191): Loss/seq after 04150 batchs: 448.8280029296875
INFO:root:Train (Epoch 191): Loss/seq after 04200 batchs: 447.5243225097656
INFO:root:Train (Epoch 191): Loss/seq after 04250 batchs: 446.16705322265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 191): Loss/seq after 00000 batches: 399.59747314453125
INFO:root:# Valid (Epoch 191): Loss/seq after 00050 batches: 586.4596557617188
INFO:root:# Valid (Epoch 191): Loss/seq after 00100 batches: 595.26904296875
INFO:root:# Valid (Epoch 191): Loss/seq after 00150 batches: 452.959228515625
INFO:root:# Valid (Epoch 191): Loss/seq after 00200 batches: 425.36236572265625
INFO:root:Artifacts: Make stick videos for epoch 191
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_191_on_20220414_074241.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_191_index_1168_on_20220414_074241.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 192): Loss/seq after 00000 batchs: 780.3251342773438
INFO:root:Train (Epoch 192): Loss/seq after 00050 batchs: 638.760986328125
INFO:root:Train (Epoch 192): Loss/seq after 00100 batchs: 605.6066284179688
INFO:root:Train (Epoch 192): Loss/seq after 00150 batchs: 560.1940307617188
INFO:root:Train (Epoch 192): Loss/seq after 00200 batchs: 610.3427124023438
INFO:root:Train (Epoch 192): Loss/seq after 00250 batchs: 668.9771118164062
INFO:root:Train (Epoch 192): Loss/seq after 00300 batchs: 682.170654296875
INFO:root:Train (Epoch 192): Loss/seq after 00350 batchs: 644.5012817382812
INFO:root:Train (Epoch 192): Loss/seq after 00400 batchs: 635.907958984375
INFO:root:Train (Epoch 192): Loss/seq after 00450 batchs: 636.389404296875
INFO:root:Train (Epoch 192): Loss/seq after 00500 batchs: 617.736572265625
INFO:root:Train (Epoch 192): Loss/seq after 00550 batchs: 602.8258666992188
INFO:root:Train (Epoch 192): Loss/seq after 00600 batchs: 583.1292114257812
INFO:root:Train (Epoch 192): Loss/seq after 00650 batchs: 561.4151000976562
INFO:root:Train (Epoch 192): Loss/seq after 00700 batchs: 538.206787109375
INFO:root:Train (Epoch 192): Loss/seq after 00750 batchs: 537.8985595703125
INFO:root:Train (Epoch 192): Loss/seq after 00800 batchs: 543.0850219726562
INFO:root:Train (Epoch 192): Loss/seq after 00850 batchs: 526.482177734375
INFO:root:Train (Epoch 192): Loss/seq after 00900 batchs: 517.35791015625
INFO:root:Train (Epoch 192): Loss/seq after 00950 batchs: 514.81005859375
INFO:root:Train (Epoch 192): Loss/seq after 01000 batchs: 506.3221740722656
INFO:root:Train (Epoch 192): Loss/seq after 01050 batchs: 497.7210388183594
INFO:root:Train (Epoch 192): Loss/seq after 01100 batchs: 491.02520751953125
INFO:root:Train (Epoch 192): Loss/seq after 01150 batchs: 478.4786071777344
INFO:root:Train (Epoch 192): Loss/seq after 01200 batchs: 484.4647216796875
INFO:root:Train (Epoch 192): Loss/seq after 01250 batchs: 484.8338317871094
INFO:root:Train (Epoch 192): Loss/seq after 01300 batchs: 475.3557434082031
INFO:root:Train (Epoch 192): Loss/seq after 01350 batchs: 468.4323425292969
INFO:root:Train (Epoch 192): Loss/seq after 01400 batchs: 470.3023986816406
INFO:root:Train (Epoch 192): Loss/seq after 01450 batchs: 473.2196350097656
INFO:root:Train (Epoch 192): Loss/seq after 01500 batchs: 480.7779235839844
INFO:root:Train (Epoch 192): Loss/seq after 01550 batchs: 482.39556884765625
INFO:root:Train (Epoch 192): Loss/seq after 01600 batchs: 478.4539794921875
INFO:root:Train (Epoch 192): Loss/seq after 01650 batchs: 476.90185546875
INFO:root:Train (Epoch 192): Loss/seq after 01700 batchs: 480.625244140625
INFO:root:Train (Epoch 192): Loss/seq after 01750 batchs: 478.52886962890625
INFO:root:Train (Epoch 192): Loss/seq after 01800 batchs: 476.41650390625
INFO:root:Train (Epoch 192): Loss/seq after 01850 batchs: 473.8009033203125
INFO:root:Train (Epoch 192): Loss/seq after 01900 batchs: 472.7126159667969
INFO:root:Train (Epoch 192): Loss/seq after 01950 batchs: 471.2655029296875
INFO:root:Train (Epoch 192): Loss/seq after 02000 batchs: 471.7917785644531
INFO:root:Train (Epoch 192): Loss/seq after 02050 batchs: 471.5708312988281
INFO:root:Train (Epoch 192): Loss/seq after 02100 batchs: 469.9866027832031
INFO:root:Train (Epoch 192): Loss/seq after 02150 batchs: 468.7070617675781
INFO:root:Train (Epoch 192): Loss/seq after 02200 batchs: 467.0279846191406
INFO:root:Train (Epoch 192): Loss/seq after 02250 batchs: 465.897216796875
INFO:root:Train (Epoch 192): Loss/seq after 02300 batchs: 462.696044921875
INFO:root:Train (Epoch 192): Loss/seq after 02350 batchs: 459.8592529296875
INFO:root:Train (Epoch 192): Loss/seq after 02400 batchs: 461.1273498535156
INFO:root:Train (Epoch 192): Loss/seq after 02450 batchs: 457.6129455566406
INFO:root:Train (Epoch 192): Loss/seq after 02500 batchs: 450.9780578613281
INFO:root:Train (Epoch 192): Loss/seq after 02550 batchs: 445.42437744140625
INFO:root:Train (Epoch 192): Loss/seq after 02600 batchs: 443.9119567871094
INFO:root:Train (Epoch 192): Loss/seq after 02650 batchs: 440.7179260253906
INFO:root:Train (Epoch 192): Loss/seq after 02700 batchs: 438.3158874511719
INFO:root:Train (Epoch 192): Loss/seq after 02750 batchs: 434.4468688964844
INFO:root:Train (Epoch 192): Loss/seq after 02800 batchs: 432.53936767578125
INFO:root:Train (Epoch 192): Loss/seq after 02850 batchs: 432.2754211425781
INFO:root:Train (Epoch 192): Loss/seq after 02900 batchs: 433.3544006347656
INFO:root:Train (Epoch 192): Loss/seq after 02950 batchs: 433.24822998046875
INFO:root:Train (Epoch 192): Loss/seq after 03000 batchs: 438.764892578125
INFO:root:Train (Epoch 192): Loss/seq after 03050 batchs: 440.8350830078125
INFO:root:Train (Epoch 192): Loss/seq after 03100 batchs: 442.7745056152344
INFO:root:Train (Epoch 192): Loss/seq after 03150 batchs: 443.39483642578125
INFO:root:Train (Epoch 192): Loss/seq after 03200 batchs: 443.4991149902344
INFO:root:Train (Epoch 192): Loss/seq after 03250 batchs: 444.8774108886719
INFO:root:Train (Epoch 192): Loss/seq after 03300 batchs: 444.2933654785156
INFO:root:Train (Epoch 192): Loss/seq after 03350 batchs: 443.3172607421875
INFO:root:Train (Epoch 192): Loss/seq after 03400 batchs: 440.0983581542969
INFO:root:Train (Epoch 192): Loss/seq after 03450 batchs: 439.170166015625
INFO:root:Train (Epoch 192): Loss/seq after 03500 batchs: 440.0301208496094
INFO:root:Train (Epoch 192): Loss/seq after 03550 batchs: 437.9233093261719
INFO:root:Train (Epoch 192): Loss/seq after 03600 batchs: 444.8037414550781
INFO:root:Train (Epoch 192): Loss/seq after 03650 batchs: 442.9872131347656
INFO:root:Train (Epoch 192): Loss/seq after 03700 batchs: 445.4555358886719
INFO:root:Train (Epoch 192): Loss/seq after 03750 batchs: 449.80987548828125
INFO:root:Train (Epoch 192): Loss/seq after 03800 batchs: 448.604248046875
INFO:root:Train (Epoch 192): Loss/seq after 03850 batchs: 447.7475891113281
INFO:root:Train (Epoch 192): Loss/seq after 03900 batchs: 450.1671142578125
INFO:root:Train (Epoch 192): Loss/seq after 03950 batchs: 453.07147216796875
INFO:root:Train (Epoch 192): Loss/seq after 04000 batchs: 450.08807373046875
INFO:root:Train (Epoch 192): Loss/seq after 04050 batchs: 447.38299560546875
INFO:root:Train (Epoch 192): Loss/seq after 04100 batchs: 446.5091552734375
INFO:root:Train (Epoch 192): Loss/seq after 04150 batchs: 446.5149230957031
INFO:root:Train (Epoch 192): Loss/seq after 04200 batchs: 445.26318359375
INFO:root:Train (Epoch 192): Loss/seq after 04250 batchs: 443.9061279296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 192): Loss/seq after 00000 batches: 370.081787109375
INFO:root:# Valid (Epoch 192): Loss/seq after 00050 batches: 605.8616333007812
INFO:root:# Valid (Epoch 192): Loss/seq after 00100 batches: 600.9906005859375
INFO:root:# Valid (Epoch 192): Loss/seq after 00150 batches: 455.427978515625
INFO:root:# Valid (Epoch 192): Loss/seq after 00200 batches: 427.3970642089844
INFO:root:Artifacts: Make stick videos for epoch 192
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_192_on_20220414_074800.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_192_index_627_on_20220414_074800.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 193): Loss/seq after 00000 batchs: 709.4796752929688
INFO:root:Train (Epoch 193): Loss/seq after 00050 batchs: 635.6654663085938
INFO:root:Train (Epoch 193): Loss/seq after 00100 batchs: 605.9862060546875
INFO:root:Train (Epoch 193): Loss/seq after 00150 batchs: 564.2916259765625
INFO:root:Train (Epoch 193): Loss/seq after 00200 batchs: 613.1334838867188
INFO:root:Train (Epoch 193): Loss/seq after 00250 batchs: 678.2146606445312
INFO:root:Train (Epoch 193): Loss/seq after 00300 batchs: 688.7340087890625
INFO:root:Train (Epoch 193): Loss/seq after 00350 batchs: 649.8339233398438
INFO:root:Train (Epoch 193): Loss/seq after 00400 batchs: 643.315673828125
INFO:root:Train (Epoch 193): Loss/seq after 00450 batchs: 642.7803955078125
INFO:root:Train (Epoch 193): Loss/seq after 00500 batchs: 621.9528198242188
INFO:root:Train (Epoch 193): Loss/seq after 00550 batchs: 606.4369506835938
INFO:root:Train (Epoch 193): Loss/seq after 00600 batchs: 587.3740844726562
INFO:root:Train (Epoch 193): Loss/seq after 00650 batchs: 565.175048828125
INFO:root:Train (Epoch 193): Loss/seq after 00700 batchs: 542.18505859375
INFO:root:Train (Epoch 193): Loss/seq after 00750 batchs: 541.7361450195312
INFO:root:Train (Epoch 193): Loss/seq after 00800 batchs: 545.8125
INFO:root:Train (Epoch 193): Loss/seq after 00850 batchs: 528.82666015625
INFO:root:Train (Epoch 193): Loss/seq after 00900 batchs: 518.9295654296875
INFO:root:Train (Epoch 193): Loss/seq after 00950 batchs: 515.9620971679688
INFO:root:Train (Epoch 193): Loss/seq after 01000 batchs: 507.09039306640625
INFO:root:Train (Epoch 193): Loss/seq after 01050 batchs: 497.89599609375
INFO:root:Train (Epoch 193): Loss/seq after 01100 batchs: 490.07489013671875
INFO:root:Train (Epoch 193): Loss/seq after 01150 batchs: 477.6518859863281
INFO:root:Train (Epoch 193): Loss/seq after 01200 batchs: 482.9217834472656
INFO:root:Train (Epoch 193): Loss/seq after 01250 batchs: 483.44293212890625
INFO:root:Train (Epoch 193): Loss/seq after 01300 batchs: 473.8638610839844
INFO:root:Train (Epoch 193): Loss/seq after 01350 batchs: 466.490234375
INFO:root:Train (Epoch 193): Loss/seq after 01400 batchs: 467.8969421386719
INFO:root:Train (Epoch 193): Loss/seq after 01450 batchs: 470.8313903808594
INFO:root:Train (Epoch 193): Loss/seq after 01500 batchs: 478.3853454589844
INFO:root:Train (Epoch 193): Loss/seq after 01550 batchs: 479.7515563964844
INFO:root:Train (Epoch 193): Loss/seq after 01600 batchs: 476.1204528808594
INFO:root:Train (Epoch 193): Loss/seq after 01650 batchs: 474.5566101074219
INFO:root:Train (Epoch 193): Loss/seq after 01700 batchs: 478.2999267578125
INFO:root:Train (Epoch 193): Loss/seq after 01750 batchs: 476.3674621582031
INFO:root:Train (Epoch 193): Loss/seq after 01800 batchs: 473.9451904296875
INFO:root:Train (Epoch 193): Loss/seq after 01850 batchs: 471.3343811035156
INFO:root:Train (Epoch 193): Loss/seq after 01900 batchs: 470.3647766113281
INFO:root:Train (Epoch 193): Loss/seq after 01950 batchs: 468.85357666015625
INFO:root:Train (Epoch 193): Loss/seq after 02000 batchs: 469.2944641113281
INFO:root:Train (Epoch 193): Loss/seq after 02050 batchs: 469.1761474609375
INFO:root:Train (Epoch 193): Loss/seq after 02100 batchs: 467.5879821777344
INFO:root:Train (Epoch 193): Loss/seq after 02150 batchs: 466.1793212890625
INFO:root:Train (Epoch 193): Loss/seq after 02200 batchs: 464.40594482421875
INFO:root:Train (Epoch 193): Loss/seq after 02250 batchs: 463.09942626953125
INFO:root:Train (Epoch 193): Loss/seq after 02300 batchs: 459.83880615234375
INFO:root:Train (Epoch 193): Loss/seq after 02350 batchs: 456.8339538574219
INFO:root:Train (Epoch 193): Loss/seq after 02400 batchs: 457.9277038574219
INFO:root:Train (Epoch 193): Loss/seq after 02450 batchs: 454.4801025390625
INFO:root:Train (Epoch 193): Loss/seq after 02500 batchs: 447.8680114746094
INFO:root:Train (Epoch 193): Loss/seq after 02550 batchs: 442.29168701171875
INFO:root:Train (Epoch 193): Loss/seq after 02600 batchs: 440.71514892578125
INFO:root:Train (Epoch 193): Loss/seq after 02650 batchs: 437.56982421875
INFO:root:Train (Epoch 193): Loss/seq after 02700 batchs: 435.2495422363281
INFO:root:Train (Epoch 193): Loss/seq after 02750 batchs: 431.3317565917969
INFO:root:Train (Epoch 193): Loss/seq after 02800 batchs: 429.2940979003906
INFO:root:Train (Epoch 193): Loss/seq after 02850 batchs: 429.080078125
INFO:root:Train (Epoch 193): Loss/seq after 02900 batchs: 430.1291198730469
INFO:root:Train (Epoch 193): Loss/seq after 02950 batchs: 430.0729064941406
INFO:root:Train (Epoch 193): Loss/seq after 03000 batchs: 435.7017517089844
INFO:root:Train (Epoch 193): Loss/seq after 03050 batchs: 437.65106201171875
INFO:root:Train (Epoch 193): Loss/seq after 03100 batchs: 439.2275085449219
INFO:root:Train (Epoch 193): Loss/seq after 03150 batchs: 439.5642395019531
INFO:root:Train (Epoch 193): Loss/seq after 03200 batchs: 439.5386962890625
INFO:root:Train (Epoch 193): Loss/seq after 03250 batchs: 440.9757995605469
INFO:root:Train (Epoch 193): Loss/seq after 03300 batchs: 440.5301818847656
INFO:root:Train (Epoch 193): Loss/seq after 03350 batchs: 439.6200256347656
INFO:root:Train (Epoch 193): Loss/seq after 03400 batchs: 436.4537353515625
INFO:root:Train (Epoch 193): Loss/seq after 03450 batchs: 435.62548828125
INFO:root:Train (Epoch 193): Loss/seq after 03500 batchs: 436.48504638671875
INFO:root:Train (Epoch 193): Loss/seq after 03550 batchs: 434.3508605957031
INFO:root:Train (Epoch 193): Loss/seq after 03600 batchs: 441.2269592285156
INFO:root:Train (Epoch 193): Loss/seq after 03650 batchs: 439.4181213378906
INFO:root:Train (Epoch 193): Loss/seq after 03700 batchs: 441.8336486816406
INFO:root:Train (Epoch 193): Loss/seq after 03750 batchs: 446.20989990234375
INFO:root:Train (Epoch 193): Loss/seq after 03800 batchs: 445.0412292480469
INFO:root:Train (Epoch 193): Loss/seq after 03850 batchs: 444.2244873046875
INFO:root:Train (Epoch 193): Loss/seq after 03900 batchs: 446.63201904296875
INFO:root:Train (Epoch 193): Loss/seq after 03950 batchs: 449.5247802734375
INFO:root:Train (Epoch 193): Loss/seq after 04000 batchs: 446.5906066894531
INFO:root:Train (Epoch 193): Loss/seq after 04050 batchs: 443.9376220703125
INFO:root:Train (Epoch 193): Loss/seq after 04100 batchs: 443.0975341796875
INFO:root:Train (Epoch 193): Loss/seq after 04150 batchs: 443.18951416015625
INFO:root:Train (Epoch 193): Loss/seq after 04200 batchs: 441.9722900390625
INFO:root:Train (Epoch 193): Loss/seq after 04250 batchs: 440.6274719238281
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 193): Loss/seq after 00000 batches: 357.64691162109375
INFO:root:# Valid (Epoch 193): Loss/seq after 00050 batches: 595.4142456054688
INFO:root:# Valid (Epoch 193): Loss/seq after 00100 batches: 592.2823486328125
INFO:root:# Valid (Epoch 193): Loss/seq after 00150 batches: 448.1385498046875
INFO:root:# Valid (Epoch 193): Loss/seq after 00200 batches: 420.5205993652344
INFO:root:Artifacts: Make stick videos for epoch 193
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_193_on_20220414_075318.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_193_index_1584_on_20220414_075318.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 194): Loss/seq after 00000 batchs: 755.4202880859375
INFO:root:Train (Epoch 194): Loss/seq after 00050 batchs: 629.371826171875
INFO:root:Train (Epoch 194): Loss/seq after 00100 batchs: 610.1364135742188
INFO:root:Train (Epoch 194): Loss/seq after 00150 batchs: 566.7017211914062
INFO:root:Train (Epoch 194): Loss/seq after 00200 batchs: 614.9537963867188
INFO:root:Train (Epoch 194): Loss/seq after 00250 batchs: 672.4225463867188
INFO:root:Train (Epoch 194): Loss/seq after 00300 batchs: 683.581298828125
INFO:root:Train (Epoch 194): Loss/seq after 00350 batchs: 645.3192138671875
INFO:root:Train (Epoch 194): Loss/seq after 00400 batchs: 639.7416381835938
INFO:root:Train (Epoch 194): Loss/seq after 00450 batchs: 639.67626953125
INFO:root:Train (Epoch 194): Loss/seq after 00500 batchs: 620.9215087890625
INFO:root:Train (Epoch 194): Loss/seq after 00550 batchs: 606.5404663085938
INFO:root:Train (Epoch 194): Loss/seq after 00600 batchs: 587.0537109375
INFO:root:Train (Epoch 194): Loss/seq after 00650 batchs: 565.4855346679688
INFO:root:Train (Epoch 194): Loss/seq after 00700 batchs: 541.8323364257812
INFO:root:Train (Epoch 194): Loss/seq after 00750 batchs: 541.5659790039062
INFO:root:Train (Epoch 194): Loss/seq after 00800 batchs: 546.105712890625
INFO:root:Train (Epoch 194): Loss/seq after 00850 batchs: 529.3351440429688
INFO:root:Train (Epoch 194): Loss/seq after 00900 batchs: 519.3623046875
INFO:root:Train (Epoch 194): Loss/seq after 00950 batchs: 516.6153564453125
INFO:root:Train (Epoch 194): Loss/seq after 01000 batchs: 508.2127380371094
INFO:root:Train (Epoch 194): Loss/seq after 01050 batchs: 499.0954895019531
INFO:root:Train (Epoch 194): Loss/seq after 01100 batchs: 491.6258544921875
INFO:root:Train (Epoch 194): Loss/seq after 01150 batchs: 478.91497802734375
INFO:root:Train (Epoch 194): Loss/seq after 01200 batchs: 484.1354675292969
INFO:root:Train (Epoch 194): Loss/seq after 01250 batchs: 484.90093994140625
INFO:root:Train (Epoch 194): Loss/seq after 01300 batchs: 475.4947204589844
INFO:root:Train (Epoch 194): Loss/seq after 01350 batchs: 468.0870361328125
INFO:root:Train (Epoch 194): Loss/seq after 01400 batchs: 469.6883544921875
INFO:root:Train (Epoch 194): Loss/seq after 01450 batchs: 472.5002136230469
INFO:root:Train (Epoch 194): Loss/seq after 01500 batchs: 479.73736572265625
INFO:root:Train (Epoch 194): Loss/seq after 01550 batchs: 481.1338806152344
INFO:root:Train (Epoch 194): Loss/seq after 01600 batchs: 477.3664245605469
INFO:root:Train (Epoch 194): Loss/seq after 01650 batchs: 475.62286376953125
INFO:root:Train (Epoch 194): Loss/seq after 01700 batchs: 479.38348388671875
INFO:root:Train (Epoch 194): Loss/seq after 01750 batchs: 477.6997985839844
INFO:root:Train (Epoch 194): Loss/seq after 01800 batchs: 475.58184814453125
INFO:root:Train (Epoch 194): Loss/seq after 01850 batchs: 472.9136962890625
INFO:root:Train (Epoch 194): Loss/seq after 01900 batchs: 472.1759338378906
INFO:root:Train (Epoch 194): Loss/seq after 01950 batchs: 470.9386291503906
INFO:root:Train (Epoch 194): Loss/seq after 02000 batchs: 471.2615661621094
INFO:root:Train (Epoch 194): Loss/seq after 02050 batchs: 471.0425720214844
INFO:root:Train (Epoch 194): Loss/seq after 02100 batchs: 469.4017639160156
INFO:root:Train (Epoch 194): Loss/seq after 02150 batchs: 467.97509765625
INFO:root:Train (Epoch 194): Loss/seq after 02200 batchs: 466.0475769042969
INFO:root:Train (Epoch 194): Loss/seq after 02250 batchs: 464.4591369628906
INFO:root:Train (Epoch 194): Loss/seq after 02300 batchs: 460.86602783203125
INFO:root:Train (Epoch 194): Loss/seq after 02350 batchs: 457.87530517578125
INFO:root:Train (Epoch 194): Loss/seq after 02400 batchs: 458.9344177246094
INFO:root:Train (Epoch 194): Loss/seq after 02450 batchs: 455.41925048828125
INFO:root:Train (Epoch 194): Loss/seq after 02500 batchs: 448.80987548828125
INFO:root:Train (Epoch 194): Loss/seq after 02550 batchs: 443.15576171875
INFO:root:Train (Epoch 194): Loss/seq after 02600 batchs: 441.3552551269531
INFO:root:Train (Epoch 194): Loss/seq after 02650 batchs: 437.9810791015625
INFO:root:Train (Epoch 194): Loss/seq after 02700 batchs: 435.6440734863281
INFO:root:Train (Epoch 194): Loss/seq after 02750 batchs: 431.6261901855469
INFO:root:Train (Epoch 194): Loss/seq after 02800 batchs: 429.3043212890625
INFO:root:Train (Epoch 194): Loss/seq after 02850 batchs: 428.97662353515625
INFO:root:Train (Epoch 194): Loss/seq after 02900 batchs: 429.9270324707031
INFO:root:Train (Epoch 194): Loss/seq after 02950 batchs: 429.85687255859375
INFO:root:Train (Epoch 194): Loss/seq after 03000 batchs: 435.3896484375
INFO:root:Train (Epoch 194): Loss/seq after 03050 batchs: 437.5099792480469
INFO:root:Train (Epoch 194): Loss/seq after 03100 batchs: 439.43218994140625
INFO:root:Train (Epoch 194): Loss/seq after 03150 batchs: 439.65423583984375
INFO:root:Train (Epoch 194): Loss/seq after 03200 batchs: 439.6080627441406
INFO:root:Train (Epoch 194): Loss/seq after 03250 batchs: 441.2056884765625
INFO:root:Train (Epoch 194): Loss/seq after 03300 batchs: 440.6138916015625
INFO:root:Train (Epoch 194): Loss/seq after 03350 batchs: 439.73089599609375
INFO:root:Train (Epoch 194): Loss/seq after 03400 batchs: 436.5755920410156
INFO:root:Train (Epoch 194): Loss/seq after 03450 batchs: 435.7388000488281
INFO:root:Train (Epoch 194): Loss/seq after 03500 batchs: 436.4348449707031
INFO:root:Train (Epoch 194): Loss/seq after 03550 batchs: 434.35504150390625
INFO:root:Train (Epoch 194): Loss/seq after 03600 batchs: 441.15545654296875
INFO:root:Train (Epoch 194): Loss/seq after 03650 batchs: 439.2959899902344
INFO:root:Train (Epoch 194): Loss/seq after 03700 batchs: 441.64324951171875
INFO:root:Train (Epoch 194): Loss/seq after 03750 batchs: 446.00482177734375
INFO:root:Train (Epoch 194): Loss/seq after 03800 batchs: 444.7795104980469
INFO:root:Train (Epoch 194): Loss/seq after 03850 batchs: 443.8918151855469
INFO:root:Train (Epoch 194): Loss/seq after 03900 batchs: 446.41827392578125
INFO:root:Train (Epoch 194): Loss/seq after 03950 batchs: 449.32122802734375
INFO:root:Train (Epoch 194): Loss/seq after 04000 batchs: 446.3672180175781
INFO:root:Train (Epoch 194): Loss/seq after 04050 batchs: 443.68072509765625
INFO:root:Train (Epoch 194): Loss/seq after 04100 batchs: 442.7664794921875
INFO:root:Train (Epoch 194): Loss/seq after 04150 batchs: 442.7677917480469
INFO:root:Train (Epoch 194): Loss/seq after 04200 batchs: 441.5580139160156
INFO:root:Train (Epoch 194): Loss/seq after 04250 batchs: 440.169189453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 194): Loss/seq after 00000 batches: 391.4508361816406
INFO:root:# Valid (Epoch 194): Loss/seq after 00050 batches: 572.7835083007812
INFO:root:# Valid (Epoch 194): Loss/seq after 00100 batches: 589.858154296875
INFO:root:# Valid (Epoch 194): Loss/seq after 00150 batches: 449.8443603515625
INFO:root:# Valid (Epoch 194): Loss/seq after 00200 batches: 422.6052551269531
INFO:root:Artifacts: Make stick videos for epoch 194
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_194_on_20220414_075835.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_194_index_1214_on_20220414_075835.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 195): Loss/seq after 00000 batchs: 930.1856079101562
INFO:root:Train (Epoch 195): Loss/seq after 00050 batchs: 629.3775634765625
INFO:root:Train (Epoch 195): Loss/seq after 00100 batchs: 601.922119140625
INFO:root:Train (Epoch 195): Loss/seq after 00150 batchs: 560.7936401367188
INFO:root:Train (Epoch 195): Loss/seq after 00200 batchs: 610.1752319335938
INFO:root:Train (Epoch 195): Loss/seq after 00250 batchs: 664.3593139648438
INFO:root:Train (Epoch 195): Loss/seq after 00300 batchs: 675.3233032226562
INFO:root:Train (Epoch 195): Loss/seq after 00350 batchs: 638.4417724609375
INFO:root:Train (Epoch 195): Loss/seq after 00400 batchs: 626.158203125
INFO:root:Train (Epoch 195): Loss/seq after 00450 batchs: 627.2940063476562
INFO:root:Train (Epoch 195): Loss/seq after 00500 batchs: 605.9766235351562
INFO:root:Train (Epoch 195): Loss/seq after 00550 batchs: 592.5789794921875
INFO:root:Train (Epoch 195): Loss/seq after 00600 batchs: 573.3632202148438
INFO:root:Train (Epoch 195): Loss/seq after 00650 batchs: 552.589111328125
INFO:root:Train (Epoch 195): Loss/seq after 00700 batchs: 529.788818359375
INFO:root:Train (Epoch 195): Loss/seq after 00750 batchs: 529.7495727539062
INFO:root:Train (Epoch 195): Loss/seq after 00800 batchs: 534.6273193359375
INFO:root:Train (Epoch 195): Loss/seq after 00850 batchs: 518.39453125
INFO:root:Train (Epoch 195): Loss/seq after 00900 batchs: 508.353759765625
INFO:root:Train (Epoch 195): Loss/seq after 00950 batchs: 505.39935302734375
INFO:root:Train (Epoch 195): Loss/seq after 01000 batchs: 497.0713806152344
INFO:root:Train (Epoch 195): Loss/seq after 01050 batchs: 488.11688232421875
INFO:root:Train (Epoch 195): Loss/seq after 01100 batchs: 480.6619567871094
INFO:root:Train (Epoch 195): Loss/seq after 01150 batchs: 468.466796875
INFO:root:Train (Epoch 195): Loss/seq after 01200 batchs: 473.65606689453125
INFO:root:Train (Epoch 195): Loss/seq after 01250 batchs: 474.52947998046875
INFO:root:Train (Epoch 195): Loss/seq after 01300 batchs: 465.36578369140625
INFO:root:Train (Epoch 195): Loss/seq after 01350 batchs: 458.0320739746094
INFO:root:Train (Epoch 195): Loss/seq after 01400 batchs: 459.775146484375
INFO:root:Train (Epoch 195): Loss/seq after 01450 batchs: 462.8460998535156
INFO:root:Train (Epoch 195): Loss/seq after 01500 batchs: 470.1781921386719
INFO:root:Train (Epoch 195): Loss/seq after 01550 batchs: 471.7515869140625
INFO:root:Train (Epoch 195): Loss/seq after 01600 batchs: 468.1445007324219
INFO:root:Train (Epoch 195): Loss/seq after 01650 batchs: 466.6370544433594
INFO:root:Train (Epoch 195): Loss/seq after 01700 batchs: 470.7419128417969
INFO:root:Train (Epoch 195): Loss/seq after 01750 batchs: 468.8658752441406
INFO:root:Train (Epoch 195): Loss/seq after 01800 batchs: 466.7210388183594
INFO:root:Train (Epoch 195): Loss/seq after 01850 batchs: 464.3387145996094
INFO:root:Train (Epoch 195): Loss/seq after 01900 batchs: 463.72076416015625
INFO:root:Train (Epoch 195): Loss/seq after 01950 batchs: 462.5816345214844
INFO:root:Train (Epoch 195): Loss/seq after 02000 batchs: 463.2037048339844
INFO:root:Train (Epoch 195): Loss/seq after 02050 batchs: 463.00640869140625
INFO:root:Train (Epoch 195): Loss/seq after 02100 batchs: 461.5860595703125
INFO:root:Train (Epoch 195): Loss/seq after 02150 batchs: 460.3962707519531
INFO:root:Train (Epoch 195): Loss/seq after 02200 batchs: 458.60198974609375
INFO:root:Train (Epoch 195): Loss/seq after 02250 batchs: 457.5107421875
INFO:root:Train (Epoch 195): Loss/seq after 02300 batchs: 454.1942443847656
INFO:root:Train (Epoch 195): Loss/seq after 02350 batchs: 451.2704162597656
INFO:root:Train (Epoch 195): Loss/seq after 02400 batchs: 452.2615051269531
INFO:root:Train (Epoch 195): Loss/seq after 02450 batchs: 448.86541748046875
INFO:root:Train (Epoch 195): Loss/seq after 02500 batchs: 442.3797607421875
INFO:root:Train (Epoch 195): Loss/seq after 02550 batchs: 436.8152160644531
INFO:root:Train (Epoch 195): Loss/seq after 02600 batchs: 435.34515380859375
INFO:root:Train (Epoch 195): Loss/seq after 02650 batchs: 432.2608947753906
INFO:root:Train (Epoch 195): Loss/seq after 02700 batchs: 429.992431640625
INFO:root:Train (Epoch 195): Loss/seq after 02750 batchs: 426.1250305175781
INFO:root:Train (Epoch 195): Loss/seq after 02800 batchs: 423.8846740722656
INFO:root:Train (Epoch 195): Loss/seq after 02850 batchs: 423.7091369628906
INFO:root:Train (Epoch 195): Loss/seq after 02900 batchs: 424.72894287109375
INFO:root:Train (Epoch 195): Loss/seq after 02950 batchs: 424.7611083984375
INFO:root:Train (Epoch 195): Loss/seq after 03000 batchs: 430.27264404296875
INFO:root:Train (Epoch 195): Loss/seq after 03050 batchs: 432.5322570800781
INFO:root:Train (Epoch 195): Loss/seq after 03100 batchs: 434.05828857421875
INFO:root:Train (Epoch 195): Loss/seq after 03150 batchs: 434.4024658203125
INFO:root:Train (Epoch 195): Loss/seq after 03200 batchs: 434.3330993652344
INFO:root:Train (Epoch 195): Loss/seq after 03250 batchs: 435.7303466796875
INFO:root:Train (Epoch 195): Loss/seq after 03300 batchs: 435.4180603027344
INFO:root:Train (Epoch 195): Loss/seq after 03350 batchs: 434.39013671875
INFO:root:Train (Epoch 195): Loss/seq after 03400 batchs: 431.234130859375
INFO:root:Train (Epoch 195): Loss/seq after 03450 batchs: 430.4216003417969
INFO:root:Train (Epoch 195): Loss/seq after 03500 batchs: 431.41552734375
INFO:root:Train (Epoch 195): Loss/seq after 03550 batchs: 429.4070129394531
INFO:root:Train (Epoch 195): Loss/seq after 03600 batchs: 436.3388977050781
INFO:root:Train (Epoch 195): Loss/seq after 03650 batchs: 434.5205078125
INFO:root:Train (Epoch 195): Loss/seq after 03700 batchs: 436.8515319824219
INFO:root:Train (Epoch 195): Loss/seq after 03750 batchs: 441.2393798828125
INFO:root:Train (Epoch 195): Loss/seq after 03800 batchs: 440.11846923828125
INFO:root:Train (Epoch 195): Loss/seq after 03850 batchs: 439.196533203125
INFO:root:Train (Epoch 195): Loss/seq after 03900 batchs: 441.4432373046875
INFO:root:Train (Epoch 195): Loss/seq after 03950 batchs: 444.5539245605469
INFO:root:Train (Epoch 195): Loss/seq after 04000 batchs: 441.6500244140625
INFO:root:Train (Epoch 195): Loss/seq after 04050 batchs: 439.0415344238281
INFO:root:Train (Epoch 195): Loss/seq after 04100 batchs: 438.2509460449219
INFO:root:Train (Epoch 195): Loss/seq after 04150 batchs: 438.3752746582031
INFO:root:Train (Epoch 195): Loss/seq after 04200 batchs: 437.273193359375
INFO:root:Train (Epoch 195): Loss/seq after 04250 batchs: 435.9464111328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 195): Loss/seq after 00000 batches: 357.76409912109375
INFO:root:# Valid (Epoch 195): Loss/seq after 00050 batches: 560.2420654296875
INFO:root:# Valid (Epoch 195): Loss/seq after 00100 batches: 573.4149169921875
INFO:root:# Valid (Epoch 195): Loss/seq after 00150 batches: 436.9896545410156
INFO:root:# Valid (Epoch 195): Loss/seq after 00200 batches: 412.6141357421875
INFO:root:Artifacts: Make stick videos for epoch 195
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_195_on_20220414_080353.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_195_index_1039_on_20220414_080353.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 196): Loss/seq after 00000 batchs: 753.6290283203125
INFO:root:Train (Epoch 196): Loss/seq after 00050 batchs: 614.5154418945312
INFO:root:Train (Epoch 196): Loss/seq after 00100 batchs: 593.083984375
INFO:root:Train (Epoch 196): Loss/seq after 00150 batchs: 550.3064575195312
INFO:root:Train (Epoch 196): Loss/seq after 00200 batchs: 597.0988159179688
INFO:root:Train (Epoch 196): Loss/seq after 00250 batchs: 654.8311157226562
INFO:root:Train (Epoch 196): Loss/seq after 00300 batchs: 667.5617065429688
INFO:root:Train (Epoch 196): Loss/seq after 00350 batchs: 631.4303588867188
INFO:root:Train (Epoch 196): Loss/seq after 00400 batchs: 621.1410522460938
INFO:root:Train (Epoch 196): Loss/seq after 00450 batchs: 622.8018798828125
INFO:root:Train (Epoch 196): Loss/seq after 00500 batchs: 602.8439331054688
INFO:root:Train (Epoch 196): Loss/seq after 00550 batchs: 588.9893188476562
INFO:root:Train (Epoch 196): Loss/seq after 00600 batchs: 570.220703125
INFO:root:Train (Epoch 196): Loss/seq after 00650 batchs: 548.55517578125
INFO:root:Train (Epoch 196): Loss/seq after 00700 batchs: 527.1707763671875
INFO:root:Train (Epoch 196): Loss/seq after 00750 batchs: 526.2391357421875
INFO:root:Train (Epoch 196): Loss/seq after 00800 batchs: 531.0090942382812
INFO:root:Train (Epoch 196): Loss/seq after 00850 batchs: 514.5975341796875
INFO:root:Train (Epoch 196): Loss/seq after 00900 batchs: 505.30279541015625
INFO:root:Train (Epoch 196): Loss/seq after 00950 batchs: 501.90924072265625
INFO:root:Train (Epoch 196): Loss/seq after 01000 batchs: 493.7449035644531
INFO:root:Train (Epoch 196): Loss/seq after 01050 batchs: 485.32196044921875
INFO:root:Train (Epoch 196): Loss/seq after 01100 batchs: 477.5434265136719
INFO:root:Train (Epoch 196): Loss/seq after 01150 batchs: 464.9820861816406
INFO:root:Train (Epoch 196): Loss/seq after 01200 batchs: 470.9564514160156
INFO:root:Train (Epoch 196): Loss/seq after 01250 batchs: 471.64013671875
INFO:root:Train (Epoch 196): Loss/seq after 01300 batchs: 462.4407653808594
INFO:root:Train (Epoch 196): Loss/seq after 01350 batchs: 455.2125244140625
INFO:root:Train (Epoch 196): Loss/seq after 01400 batchs: 457.0301513671875
INFO:root:Train (Epoch 196): Loss/seq after 01450 batchs: 459.9736633300781
INFO:root:Train (Epoch 196): Loss/seq after 01500 batchs: 467.54095458984375
INFO:root:Train (Epoch 196): Loss/seq after 01550 batchs: 468.80224609375
INFO:root:Train (Epoch 196): Loss/seq after 01600 batchs: 465.08660888671875
INFO:root:Train (Epoch 196): Loss/seq after 01650 batchs: 463.6676940917969
INFO:root:Train (Epoch 196): Loss/seq after 01700 batchs: 467.8231506347656
INFO:root:Train (Epoch 196): Loss/seq after 01750 batchs: 466.1011047363281
INFO:root:Train (Epoch 196): Loss/seq after 01800 batchs: 464.1845703125
INFO:root:Train (Epoch 196): Loss/seq after 01850 batchs: 461.8871765136719
INFO:root:Train (Epoch 196): Loss/seq after 01900 batchs: 461.3036193847656
INFO:root:Train (Epoch 196): Loss/seq after 01950 batchs: 460.2867431640625
INFO:root:Train (Epoch 196): Loss/seq after 02000 batchs: 461.0203552246094
INFO:root:Train (Epoch 196): Loss/seq after 02050 batchs: 460.7376403808594
INFO:root:Train (Epoch 196): Loss/seq after 02100 batchs: 459.39801025390625
INFO:root:Train (Epoch 196): Loss/seq after 02150 batchs: 458.1945495605469
INFO:root:Train (Epoch 196): Loss/seq after 02200 batchs: 456.5558166503906
INFO:root:Train (Epoch 196): Loss/seq after 02250 batchs: 455.31890869140625
INFO:root:Train (Epoch 196): Loss/seq after 02300 batchs: 452.11602783203125
INFO:root:Train (Epoch 196): Loss/seq after 02350 batchs: 449.3294982910156
INFO:root:Train (Epoch 196): Loss/seq after 02400 batchs: 450.4974670410156
INFO:root:Train (Epoch 196): Loss/seq after 02450 batchs: 447.0839538574219
INFO:root:Train (Epoch 196): Loss/seq after 02500 batchs: 440.6317443847656
INFO:root:Train (Epoch 196): Loss/seq after 02550 batchs: 435.0487365722656
INFO:root:Train (Epoch 196): Loss/seq after 02600 batchs: 433.56671142578125
INFO:root:Train (Epoch 196): Loss/seq after 02650 batchs: 430.4082946777344
INFO:root:Train (Epoch 196): Loss/seq after 02700 batchs: 428.1848449707031
INFO:root:Train (Epoch 196): Loss/seq after 02750 batchs: 424.1365051269531
INFO:root:Train (Epoch 196): Loss/seq after 02800 batchs: 421.9398498535156
INFO:root:Train (Epoch 196): Loss/seq after 02850 batchs: 421.698486328125
INFO:root:Train (Epoch 196): Loss/seq after 02900 batchs: 422.7144470214844
INFO:root:Train (Epoch 196): Loss/seq after 02950 batchs: 422.6592712402344
INFO:root:Train (Epoch 196): Loss/seq after 03000 batchs: 428.0545349121094
INFO:root:Train (Epoch 196): Loss/seq after 03050 batchs: 430.02911376953125
INFO:root:Train (Epoch 196): Loss/seq after 03100 batchs: 431.8047180175781
INFO:root:Train (Epoch 196): Loss/seq after 03150 batchs: 431.81231689453125
INFO:root:Train (Epoch 196): Loss/seq after 03200 batchs: 431.9490966796875
INFO:root:Train (Epoch 196): Loss/seq after 03250 batchs: 433.3218688964844
INFO:root:Train (Epoch 196): Loss/seq after 03300 batchs: 432.8974609375
INFO:root:Train (Epoch 196): Loss/seq after 03350 batchs: 431.935302734375
INFO:root:Train (Epoch 196): Loss/seq after 03400 batchs: 428.7839660644531
INFO:root:Train (Epoch 196): Loss/seq after 03450 batchs: 428.0634765625
INFO:root:Train (Epoch 196): Loss/seq after 03500 batchs: 428.9037170410156
INFO:root:Train (Epoch 196): Loss/seq after 03550 batchs: 426.802490234375
INFO:root:Train (Epoch 196): Loss/seq after 03600 batchs: 433.6309814453125
INFO:root:Train (Epoch 196): Loss/seq after 03650 batchs: 431.9793701171875
INFO:root:Train (Epoch 196): Loss/seq after 03700 batchs: 434.57916259765625
INFO:root:Train (Epoch 196): Loss/seq after 03750 batchs: 438.96136474609375
INFO:root:Train (Epoch 196): Loss/seq after 03800 batchs: 437.8780822753906
INFO:root:Train (Epoch 196): Loss/seq after 03850 batchs: 437.1252136230469
INFO:root:Train (Epoch 196): Loss/seq after 03900 batchs: 439.3575744628906
INFO:root:Train (Epoch 196): Loss/seq after 03950 batchs: 442.294677734375
INFO:root:Train (Epoch 196): Loss/seq after 04000 batchs: 439.4202880859375
INFO:root:Train (Epoch 196): Loss/seq after 04050 batchs: 436.83831787109375
INFO:root:Train (Epoch 196): Loss/seq after 04100 batchs: 436.0119323730469
INFO:root:Train (Epoch 196): Loss/seq after 04150 batchs: 436.0967712402344
INFO:root:Train (Epoch 196): Loss/seq after 04200 batchs: 434.87713623046875
INFO:root:Train (Epoch 196): Loss/seq after 04250 batchs: 433.5555114746094
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 196): Loss/seq after 00000 batches: 404.77783203125
INFO:root:# Valid (Epoch 196): Loss/seq after 00050 batches: 561.346923828125
INFO:root:# Valid (Epoch 196): Loss/seq after 00100 batches: 562.737060546875
INFO:root:# Valid (Epoch 196): Loss/seq after 00150 batches: 430.7028503417969
INFO:root:# Valid (Epoch 196): Loss/seq after 00200 batches: 408.3738098144531
INFO:root:Artifacts: Make stick videos for epoch 196
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_196_on_20220414_080910.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_196_index_1657_on_20220414_080910.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 197): Loss/seq after 00000 batchs: 785.5621337890625
INFO:root:Train (Epoch 197): Loss/seq after 00050 batchs: 614.307373046875
INFO:root:Train (Epoch 197): Loss/seq after 00100 batchs: 593.2064208984375
INFO:root:Train (Epoch 197): Loss/seq after 00150 batchs: 552.1776733398438
INFO:root:Train (Epoch 197): Loss/seq after 00200 batchs: 602.7271118164062
INFO:root:Train (Epoch 197): Loss/seq after 00250 batchs: 658.8665161132812
INFO:root:Train (Epoch 197): Loss/seq after 00300 batchs: 672.8841552734375
INFO:root:Train (Epoch 197): Loss/seq after 00350 batchs: 635.3191528320312
INFO:root:Train (Epoch 197): Loss/seq after 00400 batchs: 626.2211303710938
INFO:root:Train (Epoch 197): Loss/seq after 00450 batchs: 627.4402465820312
INFO:root:Train (Epoch 197): Loss/seq after 00500 batchs: 607.578857421875
INFO:root:Train (Epoch 197): Loss/seq after 00550 batchs: 592.947021484375
INFO:root:Train (Epoch 197): Loss/seq after 00600 batchs: 573.222900390625
INFO:root:Train (Epoch 197): Loss/seq after 00650 batchs: 551.7804565429688
INFO:root:Train (Epoch 197): Loss/seq after 00700 batchs: 529.10595703125
INFO:root:Train (Epoch 197): Loss/seq after 00750 batchs: 528.130615234375
INFO:root:Train (Epoch 197): Loss/seq after 00800 batchs: 532.9413452148438
INFO:root:Train (Epoch 197): Loss/seq after 00850 batchs: 516.1448364257812
INFO:root:Train (Epoch 197): Loss/seq after 00900 batchs: 506.6949462890625
INFO:root:Train (Epoch 197): Loss/seq after 00950 batchs: 503.8680114746094
INFO:root:Train (Epoch 197): Loss/seq after 01000 batchs: 495.05474853515625
INFO:root:Train (Epoch 197): Loss/seq after 01050 batchs: 485.9552001953125
INFO:root:Train (Epoch 197): Loss/seq after 01100 batchs: 478.3101806640625
INFO:root:Train (Epoch 197): Loss/seq after 01150 batchs: 465.8076171875
INFO:root:Train (Epoch 197): Loss/seq after 01200 batchs: 470.89727783203125
INFO:root:Train (Epoch 197): Loss/seq after 01250 batchs: 471.643798828125
INFO:root:Train (Epoch 197): Loss/seq after 01300 batchs: 462.4289855957031
INFO:root:Train (Epoch 197): Loss/seq after 01350 batchs: 455.1993408203125
INFO:root:Train (Epoch 197): Loss/seq after 01400 batchs: 456.4833984375
INFO:root:Train (Epoch 197): Loss/seq after 01450 batchs: 459.0823059082031
INFO:root:Train (Epoch 197): Loss/seq after 01500 batchs: 466.6729736328125
INFO:root:Train (Epoch 197): Loss/seq after 01550 batchs: 467.8512878417969
INFO:root:Train (Epoch 197): Loss/seq after 01600 batchs: 464.080322265625
INFO:root:Train (Epoch 197): Loss/seq after 01650 batchs: 462.64599609375
INFO:root:Train (Epoch 197): Loss/seq after 01700 batchs: 466.68878173828125
INFO:root:Train (Epoch 197): Loss/seq after 01750 batchs: 464.7665100097656
INFO:root:Train (Epoch 197): Loss/seq after 01800 batchs: 462.7626647949219
INFO:root:Train (Epoch 197): Loss/seq after 01850 batchs: 460.4599304199219
INFO:root:Train (Epoch 197): Loss/seq after 01900 batchs: 460.08599853515625
INFO:root:Train (Epoch 197): Loss/seq after 01950 batchs: 459.3905029296875
INFO:root:Train (Epoch 197): Loss/seq after 02000 batchs: 459.94586181640625
INFO:root:Train (Epoch 197): Loss/seq after 02050 batchs: 459.8082580566406
INFO:root:Train (Epoch 197): Loss/seq after 02100 batchs: 458.3714599609375
INFO:root:Train (Epoch 197): Loss/seq after 02150 batchs: 457.1884765625
INFO:root:Train (Epoch 197): Loss/seq after 02200 batchs: 455.4578857421875
INFO:root:Train (Epoch 197): Loss/seq after 02250 batchs: 454.2819519042969
INFO:root:Train (Epoch 197): Loss/seq after 02300 batchs: 450.8965148925781
INFO:root:Train (Epoch 197): Loss/seq after 02350 batchs: 448.0272216796875
INFO:root:Train (Epoch 197): Loss/seq after 02400 batchs: 449.0992736816406
INFO:root:Train (Epoch 197): Loss/seq after 02450 batchs: 445.73345947265625
INFO:root:Train (Epoch 197): Loss/seq after 02500 batchs: 439.271484375
INFO:root:Train (Epoch 197): Loss/seq after 02550 batchs: 433.6796875
INFO:root:Train (Epoch 197): Loss/seq after 02600 batchs: 432.13946533203125
INFO:root:Train (Epoch 197): Loss/seq after 02650 batchs: 428.9427185058594
INFO:root:Train (Epoch 197): Loss/seq after 02700 batchs: 426.7572326660156
INFO:root:Train (Epoch 197): Loss/seq after 02750 batchs: 422.77386474609375
INFO:root:Train (Epoch 197): Loss/seq after 02800 batchs: 420.3524475097656
INFO:root:Train (Epoch 197): Loss/seq after 02850 batchs: 420.0774841308594
INFO:root:Train (Epoch 197): Loss/seq after 02900 batchs: 421.0447082519531
INFO:root:Train (Epoch 197): Loss/seq after 02950 batchs: 421.02496337890625
INFO:root:Train (Epoch 197): Loss/seq after 03000 batchs: 426.5339660644531
INFO:root:Train (Epoch 197): Loss/seq after 03050 batchs: 428.6080627441406
INFO:root:Train (Epoch 197): Loss/seq after 03100 batchs: 430.5860900878906
INFO:root:Train (Epoch 197): Loss/seq after 03150 batchs: 430.91015625
INFO:root:Train (Epoch 197): Loss/seq after 03200 batchs: 430.9468994140625
INFO:root:Train (Epoch 197): Loss/seq after 03250 batchs: 432.2491760253906
INFO:root:Train (Epoch 197): Loss/seq after 03300 batchs: 431.64141845703125
INFO:root:Train (Epoch 197): Loss/seq after 03350 batchs: 430.680908203125
INFO:root:Train (Epoch 197): Loss/seq after 03400 batchs: 427.5312805175781
INFO:root:Train (Epoch 197): Loss/seq after 03450 batchs: 426.8397521972656
INFO:root:Train (Epoch 197): Loss/seq after 03500 batchs: 427.85003662109375
INFO:root:Train (Epoch 197): Loss/seq after 03550 batchs: 425.8683166503906
INFO:root:Train (Epoch 197): Loss/seq after 03600 batchs: 432.8531799316406
INFO:root:Train (Epoch 197): Loss/seq after 03650 batchs: 431.1717224121094
INFO:root:Train (Epoch 197): Loss/seq after 03700 batchs: 433.47723388671875
INFO:root:Train (Epoch 197): Loss/seq after 03750 batchs: 437.8607177734375
INFO:root:Train (Epoch 197): Loss/seq after 03800 batchs: 436.7768859863281
INFO:root:Train (Epoch 197): Loss/seq after 03850 batchs: 435.8713073730469
INFO:root:Train (Epoch 197): Loss/seq after 03900 batchs: 438.1887512207031
INFO:root:Train (Epoch 197): Loss/seq after 03950 batchs: 441.0674133300781
INFO:root:Train (Epoch 197): Loss/seq after 04000 batchs: 438.17681884765625
INFO:root:Train (Epoch 197): Loss/seq after 04050 batchs: 435.5542907714844
INFO:root:Train (Epoch 197): Loss/seq after 04100 batchs: 434.7383728027344
INFO:root:Train (Epoch 197): Loss/seq after 04150 batchs: 434.8363952636719
INFO:root:Train (Epoch 197): Loss/seq after 04200 batchs: 433.6576232910156
INFO:root:Train (Epoch 197): Loss/seq after 04250 batchs: 432.3347473144531
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 197): Loss/seq after 00000 batches: 357.15087890625
INFO:root:# Valid (Epoch 197): Loss/seq after 00050 batches: 571.9500732421875
INFO:root:# Valid (Epoch 197): Loss/seq after 00100 batches: 562.6117553710938
INFO:root:# Valid (Epoch 197): Loss/seq after 00150 batches: 429.1043701171875
INFO:root:# Valid (Epoch 197): Loss/seq after 00200 batches: 405.7961730957031
INFO:root:Artifacts: Make stick videos for epoch 197
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_197_on_20220414_081429.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_197_index_1555_on_20220414_081429.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 198): Loss/seq after 00000 batchs: 867.6022338867188
INFO:root:Train (Epoch 198): Loss/seq after 00050 batchs: 618.5082397460938
INFO:root:Train (Epoch 198): Loss/seq after 00100 batchs: 584.8960571289062
INFO:root:Train (Epoch 198): Loss/seq after 00150 batchs: 545.4879760742188
INFO:root:Train (Epoch 198): Loss/seq after 00200 batchs: 596.9937133789062
INFO:root:Train (Epoch 198): Loss/seq after 00250 batchs: 659.3142700195312
INFO:root:Train (Epoch 198): Loss/seq after 00300 batchs: 672.0782470703125
INFO:root:Train (Epoch 198): Loss/seq after 00350 batchs: 634.3792114257812
INFO:root:Train (Epoch 198): Loss/seq after 00400 batchs: 623.8782348632812
INFO:root:Train (Epoch 198): Loss/seq after 00450 batchs: 624.928955078125
INFO:root:Train (Epoch 198): Loss/seq after 00500 batchs: 603.4383544921875
INFO:root:Train (Epoch 198): Loss/seq after 00550 batchs: 588.820068359375
INFO:root:Train (Epoch 198): Loss/seq after 00600 batchs: 569.4916381835938
INFO:root:Train (Epoch 198): Loss/seq after 00650 batchs: 547.6608276367188
INFO:root:Train (Epoch 198): Loss/seq after 00700 batchs: 525.16796875
INFO:root:Train (Epoch 198): Loss/seq after 00750 batchs: 524.5858154296875
INFO:root:Train (Epoch 198): Loss/seq after 00800 batchs: 529.0955810546875
INFO:root:Train (Epoch 198): Loss/seq after 00850 batchs: 512.4292602539062
INFO:root:Train (Epoch 198): Loss/seq after 00900 batchs: 503.3558044433594
INFO:root:Train (Epoch 198): Loss/seq after 00950 batchs: 499.9291687011719
INFO:root:Train (Epoch 198): Loss/seq after 01000 batchs: 491.6749267578125
INFO:root:Train (Epoch 198): Loss/seq after 01050 batchs: 482.8182067871094
INFO:root:Train (Epoch 198): Loss/seq after 01100 batchs: 475.1833190917969
INFO:root:Train (Epoch 198): Loss/seq after 01150 batchs: 462.9557189941406
INFO:root:Train (Epoch 198): Loss/seq after 01200 batchs: 468.1241149902344
INFO:root:Train (Epoch 198): Loss/seq after 01250 batchs: 469.0455017089844
INFO:root:Train (Epoch 198): Loss/seq after 01300 batchs: 459.8642883300781
INFO:root:Train (Epoch 198): Loss/seq after 01350 batchs: 452.6981201171875
INFO:root:Train (Epoch 198): Loss/seq after 01400 batchs: 454.1023864746094
INFO:root:Train (Epoch 198): Loss/seq after 01450 batchs: 457.2281188964844
INFO:root:Train (Epoch 198): Loss/seq after 01500 batchs: 464.51849365234375
INFO:root:Train (Epoch 198): Loss/seq after 01550 batchs: 466.1810302734375
INFO:root:Train (Epoch 198): Loss/seq after 01600 batchs: 462.7096862792969
INFO:root:Train (Epoch 198): Loss/seq after 01650 batchs: 460.98101806640625
INFO:root:Train (Epoch 198): Loss/seq after 01700 batchs: 464.8777770996094
INFO:root:Train (Epoch 198): Loss/seq after 01750 batchs: 462.9672546386719
INFO:root:Train (Epoch 198): Loss/seq after 01800 batchs: 460.83404541015625
INFO:root:Train (Epoch 198): Loss/seq after 01850 batchs: 458.4807434082031
INFO:root:Train (Epoch 198): Loss/seq after 01900 batchs: 457.95159912109375
INFO:root:Train (Epoch 198): Loss/seq after 01950 batchs: 456.7818298339844
INFO:root:Train (Epoch 198): Loss/seq after 02000 batchs: 457.2966613769531
INFO:root:Train (Epoch 198): Loss/seq after 02050 batchs: 457.27484130859375
INFO:root:Train (Epoch 198): Loss/seq after 02100 batchs: 455.855224609375
INFO:root:Train (Epoch 198): Loss/seq after 02150 batchs: 454.5674743652344
INFO:root:Train (Epoch 198): Loss/seq after 02200 batchs: 452.85968017578125
INFO:root:Train (Epoch 198): Loss/seq after 02250 batchs: 451.3146667480469
INFO:root:Train (Epoch 198): Loss/seq after 02300 batchs: 447.9300231933594
INFO:root:Train (Epoch 198): Loss/seq after 02350 batchs: 445.0733337402344
INFO:root:Train (Epoch 198): Loss/seq after 02400 batchs: 446.183349609375
INFO:root:Train (Epoch 198): Loss/seq after 02450 batchs: 442.7848815917969
INFO:root:Train (Epoch 198): Loss/seq after 02500 batchs: 436.3799133300781
INFO:root:Train (Epoch 198): Loss/seq after 02550 batchs: 430.78546142578125
INFO:root:Train (Epoch 198): Loss/seq after 02600 batchs: 429.1935729980469
INFO:root:Train (Epoch 198): Loss/seq after 02650 batchs: 426.0292663574219
INFO:root:Train (Epoch 198): Loss/seq after 02700 batchs: 423.8206481933594
INFO:root:Train (Epoch 198): Loss/seq after 02750 batchs: 419.849609375
INFO:root:Train (Epoch 198): Loss/seq after 02800 batchs: 417.4808044433594
INFO:root:Train (Epoch 198): Loss/seq after 02850 batchs: 417.0830383300781
INFO:root:Train (Epoch 198): Loss/seq after 02900 batchs: 417.9430236816406
INFO:root:Train (Epoch 198): Loss/seq after 02950 batchs: 417.9549255371094
INFO:root:Train (Epoch 198): Loss/seq after 03000 batchs: 423.4127502441406
INFO:root:Train (Epoch 198): Loss/seq after 03050 batchs: 425.48504638671875
INFO:root:Train (Epoch 198): Loss/seq after 03100 batchs: 427.0987548828125
INFO:root:Train (Epoch 198): Loss/seq after 03150 batchs: 427.65460205078125
INFO:root:Train (Epoch 198): Loss/seq after 03200 batchs: 427.79595947265625
INFO:root:Train (Epoch 198): Loss/seq after 03250 batchs: 429.19378662109375
INFO:root:Train (Epoch 198): Loss/seq after 03300 batchs: 428.7853698730469
INFO:root:Train (Epoch 198): Loss/seq after 03350 batchs: 427.75677490234375
INFO:root:Train (Epoch 198): Loss/seq after 03400 batchs: 424.6940002441406
INFO:root:Train (Epoch 198): Loss/seq after 03450 batchs: 423.93194580078125
INFO:root:Train (Epoch 198): Loss/seq after 03500 batchs: 425.1015625
INFO:root:Train (Epoch 198): Loss/seq after 03550 batchs: 423.1563415527344
INFO:root:Train (Epoch 198): Loss/seq after 03600 batchs: 429.98291015625
INFO:root:Train (Epoch 198): Loss/seq after 03650 batchs: 428.20697021484375
INFO:root:Train (Epoch 198): Loss/seq after 03700 batchs: 430.867919921875
INFO:root:Train (Epoch 198): Loss/seq after 03750 batchs: 435.262451171875
INFO:root:Train (Epoch 198): Loss/seq after 03800 batchs: 434.1797790527344
INFO:root:Train (Epoch 198): Loss/seq after 03850 batchs: 433.300048828125
INFO:root:Train (Epoch 198): Loss/seq after 03900 batchs: 435.856689453125
INFO:root:Train (Epoch 198): Loss/seq after 03950 batchs: 438.5614013671875
INFO:root:Train (Epoch 198): Loss/seq after 04000 batchs: 435.7054748535156
INFO:root:Train (Epoch 198): Loss/seq after 04050 batchs: 433.1015930175781
INFO:root:Train (Epoch 198): Loss/seq after 04100 batchs: 432.3205261230469
INFO:root:Train (Epoch 198): Loss/seq after 04150 batchs: 432.40545654296875
INFO:root:Train (Epoch 198): Loss/seq after 04200 batchs: 431.3294677734375
INFO:root:Train (Epoch 198): Loss/seq after 04250 batchs: 430.0667419433594
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 198): Loss/seq after 00000 batches: 356.2834777832031
INFO:root:# Valid (Epoch 198): Loss/seq after 00050 batches: 570.2427978515625
INFO:root:# Valid (Epoch 198): Loss/seq after 00100 batches: 562.3392333984375
INFO:root:# Valid (Epoch 198): Loss/seq after 00150 batches: 428.7704772949219
INFO:root:# Valid (Epoch 198): Loss/seq after 00200 batches: 404.2899169921875
INFO:root:Artifacts: Make stick videos for epoch 198
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_198_on_20220414_081946.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_198_index_998_on_20220414_081946.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 199): Loss/seq after 00000 batchs: 914.720458984375
INFO:root:Train (Epoch 199): Loss/seq after 00050 batchs: 622.044189453125
INFO:root:Train (Epoch 199): Loss/seq after 00100 batchs: 595.65869140625
INFO:root:Train (Epoch 199): Loss/seq after 00150 batchs: 553.083251953125
INFO:root:Train (Epoch 199): Loss/seq after 00200 batchs: 597.4143676757812
INFO:root:Train (Epoch 199): Loss/seq after 00250 batchs: 653.8275146484375
INFO:root:Train (Epoch 199): Loss/seq after 00300 batchs: 666.848388671875
INFO:root:Train (Epoch 199): Loss/seq after 00350 batchs: 629.8914184570312
INFO:root:Train (Epoch 199): Loss/seq after 00400 batchs: 619.5248413085938
INFO:root:Train (Epoch 199): Loss/seq after 00450 batchs: 621.2125854492188
INFO:root:Train (Epoch 199): Loss/seq after 00500 batchs: 601.0062866210938
INFO:root:Train (Epoch 199): Loss/seq after 00550 batchs: 586.8988647460938
INFO:root:Train (Epoch 199): Loss/seq after 00600 batchs: 567.8621215820312
INFO:root:Train (Epoch 199): Loss/seq after 00650 batchs: 545.9268798828125
INFO:root:Train (Epoch 199): Loss/seq after 00700 batchs: 522.6827392578125
INFO:root:Train (Epoch 199): Loss/seq after 00750 batchs: 521.5065307617188
INFO:root:Train (Epoch 199): Loss/seq after 00800 batchs: 526.83154296875
INFO:root:Train (Epoch 199): Loss/seq after 00850 batchs: 510.8863525390625
INFO:root:Train (Epoch 199): Loss/seq after 00900 batchs: 501.36376953125
INFO:root:Train (Epoch 199): Loss/seq after 00950 batchs: 499.7618103027344
INFO:root:Train (Epoch 199): Loss/seq after 01000 batchs: 491.490478515625
INFO:root:Train (Epoch 199): Loss/seq after 01050 batchs: 482.865966796875
INFO:root:Train (Epoch 199): Loss/seq after 01100 batchs: 475.2150573730469
INFO:root:Train (Epoch 199): Loss/seq after 01150 batchs: 463.1629638671875
INFO:root:Train (Epoch 199): Loss/seq after 01200 batchs: 467.9808349609375
INFO:root:Train (Epoch 199): Loss/seq after 01250 batchs: 468.4306640625
INFO:root:Train (Epoch 199): Loss/seq after 01300 batchs: 459.4199523925781
INFO:root:Train (Epoch 199): Loss/seq after 01350 batchs: 452.326171875
INFO:root:Train (Epoch 199): Loss/seq after 01400 batchs: 453.92144775390625
INFO:root:Train (Epoch 199): Loss/seq after 01450 batchs: 456.90216064453125
INFO:root:Train (Epoch 199): Loss/seq after 01500 batchs: 464.3462829589844
INFO:root:Train (Epoch 199): Loss/seq after 01550 batchs: 465.77178955078125
INFO:root:Train (Epoch 199): Loss/seq after 01600 batchs: 462.15399169921875
INFO:root:Train (Epoch 199): Loss/seq after 01650 batchs: 460.6119079589844
INFO:root:Train (Epoch 199): Loss/seq after 01700 batchs: 464.7987060546875
INFO:root:Train (Epoch 199): Loss/seq after 01750 batchs: 463.0789794921875
INFO:root:Train (Epoch 199): Loss/seq after 01800 batchs: 460.9932556152344
INFO:root:Train (Epoch 199): Loss/seq after 01850 batchs: 458.5826721191406
INFO:root:Train (Epoch 199): Loss/seq after 01900 batchs: 457.84283447265625
INFO:root:Train (Epoch 199): Loss/seq after 01950 batchs: 456.5926208496094
INFO:root:Train (Epoch 199): Loss/seq after 02000 batchs: 457.07208251953125
INFO:root:Train (Epoch 199): Loss/seq after 02050 batchs: 457.00567626953125
INFO:root:Train (Epoch 199): Loss/seq after 02100 batchs: 455.68707275390625
INFO:root:Train (Epoch 199): Loss/seq after 02150 batchs: 454.49237060546875
INFO:root:Train (Epoch 199): Loss/seq after 02200 batchs: 452.8211975097656
INFO:root:Train (Epoch 199): Loss/seq after 02250 batchs: 451.4219665527344
INFO:root:Train (Epoch 199): Loss/seq after 02300 batchs: 447.9526062011719
INFO:root:Train (Epoch 199): Loss/seq after 02350 batchs: 445.20916748046875
INFO:root:Train (Epoch 199): Loss/seq after 02400 batchs: 446.2402038574219
INFO:root:Train (Epoch 199): Loss/seq after 02450 batchs: 442.86846923828125
INFO:root:Train (Epoch 199): Loss/seq after 02500 batchs: 436.41644287109375
INFO:root:Train (Epoch 199): Loss/seq after 02550 batchs: 430.8059387207031
INFO:root:Train (Epoch 199): Loss/seq after 02600 batchs: 429.1924743652344
INFO:root:Train (Epoch 199): Loss/seq after 02650 batchs: 425.8948059082031
INFO:root:Train (Epoch 199): Loss/seq after 02700 batchs: 423.64788818359375
INFO:root:Train (Epoch 199): Loss/seq after 02750 batchs: 419.6902160644531
INFO:root:Train (Epoch 199): Loss/seq after 02800 batchs: 417.4047546386719
INFO:root:Train (Epoch 199): Loss/seq after 02850 batchs: 417.3097229003906
INFO:root:Train (Epoch 199): Loss/seq after 02900 batchs: 418.0826416015625
INFO:root:Train (Epoch 199): Loss/seq after 02950 batchs: 418.0841369628906
INFO:root:Train (Epoch 199): Loss/seq after 03000 batchs: 423.5979919433594
INFO:root:Train (Epoch 199): Loss/seq after 03050 batchs: 425.7427673339844
INFO:root:Train (Epoch 199): Loss/seq after 03100 batchs: 427.4516906738281
INFO:root:Train (Epoch 199): Loss/seq after 03150 batchs: 427.6094055175781
INFO:root:Train (Epoch 199): Loss/seq after 03200 batchs: 427.8067932128906
INFO:root:Train (Epoch 199): Loss/seq after 03250 batchs: 428.9817199707031
INFO:root:Train (Epoch 199): Loss/seq after 03300 batchs: 428.77215576171875
INFO:root:Train (Epoch 199): Loss/seq after 03350 batchs: 427.7535705566406
INFO:root:Train (Epoch 199): Loss/seq after 03400 batchs: 424.706787109375
INFO:root:Train (Epoch 199): Loss/seq after 03450 batchs: 423.7469177246094
INFO:root:Train (Epoch 199): Loss/seq after 03500 batchs: 425.41302490234375
INFO:root:Train (Epoch 199): Loss/seq after 03550 batchs: 423.5020446777344
INFO:root:Train (Epoch 199): Loss/seq after 03600 batchs: 430.2222595214844
INFO:root:Train (Epoch 199): Loss/seq after 03650 batchs: 428.5496520996094
INFO:root:Train (Epoch 199): Loss/seq after 03700 batchs: 431.04180908203125
INFO:root:Train (Epoch 199): Loss/seq after 03750 batchs: 435.2892150878906
INFO:root:Train (Epoch 199): Loss/seq after 03800 batchs: 434.1950988769531
INFO:root:Train (Epoch 199): Loss/seq after 03850 batchs: 433.281005859375
INFO:root:Train (Epoch 199): Loss/seq after 03900 batchs: 435.7611999511719
INFO:root:Train (Epoch 199): Loss/seq after 03950 batchs: 438.6184997558594
INFO:root:Train (Epoch 199): Loss/seq after 04000 batchs: 435.74420166015625
INFO:root:Train (Epoch 199): Loss/seq after 04050 batchs: 433.1273498535156
INFO:root:Train (Epoch 199): Loss/seq after 04100 batchs: 432.2958679199219
INFO:root:Train (Epoch 199): Loss/seq after 04150 batchs: 432.3360595703125
INFO:root:Train (Epoch 199): Loss/seq after 04200 batchs: 431.1394958496094
INFO:root:Train (Epoch 199): Loss/seq after 04250 batchs: 429.764892578125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 199): Loss/seq after 00000 batches: 385.69757080078125
INFO:root:# Valid (Epoch 199): Loss/seq after 00050 batches: 557.54931640625
INFO:root:# Valid (Epoch 199): Loss/seq after 00100 batches: 567.7380981445312
INFO:root:# Valid (Epoch 199): Loss/seq after 00150 batches: 431.2028503417969
INFO:root:# Valid (Epoch 199): Loss/seq after 00200 batches: 407.8738098144531
INFO:root:Artifacts: Make stick videos for epoch 199
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_199_on_20220414_082504.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_199_index_117_on_20220414_082504.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Done training.

wandb: Waiting for W&B process to finish, PID 185727... (success).
wandb: - 424.60MB of 424.60MB uploaded (0.00MB deduped)wandb: \ 424.60MB of 424.60MB uploaded (0.00MB deduped)wandb: | 424.60MB of 424.67MB uploaded (0.00MB deduped)wandb: / 424.60MB of 426.13MB uploaded (0.00MB deduped)wandb: - 425.55MB of 426.13MB uploaded (0.00MB deduped)wandb: \ 426.13MB of 426.13MB uploaded (0.00MB deduped)wandb: | 426.13MB of 426.13MB uploaded (0.00MB deduped)wandb: / 426.13MB of 426.13MB uploaded (0.00MB deduped)wandb: - 426.13MB of 426.13MB uploaded (0.00MB deduped)wandb: \ 426.13MB of 426.13MB uploaded (0.00MB deduped)wandb: | 426.13MB of 426.13MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:        epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:         loss ██▇▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▅▅▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:   valid_loss █▅▄▅▅▇▅▅▇▅▄▄▅▃▄▄▅▃▃▄▃▂▂▄▂▂▂▃▂▂▃▃▁▁▂▁▁▁▂▂
wandb: 
wandb: Run summary:
wandb:        epoch 199
wandb:         loss 429.76489
wandb:   valid_loss 407.87381
wandb: 
wandb: Synced 6 W&B file(s), 0 media file(s), 400 artifact file(s) and 0 other file(s)
wandb: Synced smart-sweep-4: https://wandb.ai/mathildepapillon/move-move/runs/d5k0u3jz
wandb: Find logs at: ./wandb/run-20220413_144429-d5k0u3jz/logs/debug.log
wandb: 

2022-04-14 08:25:30,551 - wandb.wandb_agent - INFO - Cleaning up finished run: d5k0u3jz
2022-04-14 08:25:31,362 - wandb.wandb_agent - INFO - Agent received command: run
2022-04-14 08:25:31,362 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 8
	learning_rate: 1e-05
2022-04-14 08:25:31,397 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python main.py --batch_size=8 --learning_rate=1e-05
INFO:root:Using device cuda
2022-04-14 08:25:36,410 - wandb.wandb_agent - INFO - Running runs: ['pdkml1l2']
wandb: Currently logged in as: mathildepapillon (use `wandb login --relogin` to force relogin)
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
TORCH
1.10.0+cu102
wandb: wandb version 0.12.14 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run ancient-sweep-5
wandb: ⭐️ View project at https://wandb.ai/mathildepapillon/move-move
wandb: 🧹 View sweep at https://wandb.ai/mathildepapillon/move-move/sweeps/tld50t54
wandb: 🚀 View run at https://wandb.ai/mathildepapillon/move-move/runs/pdkml1l2
wandb: Run data is saved locally in /home/papillon/move/move/wandb/run-20220414_082536-pdkml1l2
wandb: Run `wandb offline` to turn off syncing.
INFO:root:Config: {config}
INFO:root:Run server specific commands
INFO:root:Initialize model
INFO:root:Loading raw datasets:
INFO:root:- data/mariel_betternot_and_retrograde.npy of shape (9925, 53, 3)
INFO:root:- data/mariel_beyond.npy of shape (5803, 53, 3)
INFO:root:- data/mariel_chunli.npy of shape (3866, 53, 3)
INFO:root:- data/mariel_honey.npy of shape (5309, 53, 3)
INFO:root:- data/mariel_knownbetter.npy of shape (6649, 53, 3)
INFO:root:- data/mariel_penelope.npy of shape (6757, 53, 3)
INFO:root:Preprocessing: Load seq_data of shape (38181, 128, 159)
INFO:root:>> Train ds has shape (34363, 128, 159)
INFO:root:>> Valid ds has shape (1909, 128, 159)
INFO:root:>> Test ds has shape (1909, 128, 159)
INFO:root:Preprocessing: Convert into torch dataloader
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 0): Loss/seq after 00000 batchs: 3744.893798828125
INFO:root:Train (Epoch 0): Loss/seq after 00050 batchs: 7249.55517578125
INFO:root:Train (Epoch 0): Loss/seq after 00100 batchs: 6299.17822265625
INFO:root:Train (Epoch 0): Loss/seq after 00150 batchs: 6423.63037109375
INFO:root:Train (Epoch 0): Loss/seq after 00200 batchs: 5493.400390625
INFO:root:Train (Epoch 0): Loss/seq after 00250 batchs: 5006.005859375
INFO:root:Train (Epoch 0): Loss/seq after 00300 batchs: 4463.0439453125
INFO:root:Train (Epoch 0): Loss/seq after 00350 batchs: 3998.55126953125
INFO:root:Train (Epoch 0): Loss/seq after 00400 batchs: 3979.355712890625
INFO:root:Train (Epoch 0): Loss/seq after 00450 batchs: 3703.282470703125
INFO:root:Train (Epoch 0): Loss/seq after 00500 batchs: 3605.798095703125
INFO:root:Train (Epoch 0): Loss/seq after 00550 batchs: 3403.669677734375
INFO:root:Train (Epoch 0): Loss/seq after 00600 batchs: 3248.106689453125
INFO:root:Train (Epoch 0): Loss/seq after 00650 batchs: 3223.540283203125
INFO:root:Train (Epoch 0): Loss/seq after 00700 batchs: 3200.26123046875
INFO:root:Train (Epoch 0): Loss/seq after 00750 batchs: 3144.102783203125
INFO:root:Train (Epoch 0): Loss/seq after 00800 batchs: 3087.140625
INFO:root:Train (Epoch 0): Loss/seq after 00850 batchs: 2973.742919921875
INFO:root:Train (Epoch 0): Loss/seq after 00900 batchs: 2921.130615234375
INFO:root:Train (Epoch 0): Loss/seq after 00950 batchs: 2984.493408203125
INFO:root:Train (Epoch 0): Loss/seq after 01000 batchs: 2946.91259765625
INFO:root:Train (Epoch 0): Loss/seq after 01050 batchs: 2887.576171875
INFO:root:Train (Epoch 0): Loss/seq after 01100 batchs: 2847.759033203125
INFO:root:Train (Epoch 0): Loss/seq after 01150 batchs: 2775.9619140625
INFO:root:Train (Epoch 0): Loss/seq after 01200 batchs: 2716.048583984375
INFO:root:Train (Epoch 0): Loss/seq after 01250 batchs: 2670.693603515625
INFO:root:Train (Epoch 0): Loss/seq after 01300 batchs: 2646.251953125
INFO:root:Train (Epoch 0): Loss/seq after 01350 batchs: 2611.1455078125
INFO:root:Train (Epoch 0): Loss/seq after 01400 batchs: 2633.416015625
INFO:root:Train (Epoch 0): Loss/seq after 01450 batchs: 2595.035400390625
INFO:root:Train (Epoch 0): Loss/seq after 01500 batchs: 2550.29541015625
INFO:root:Train (Epoch 0): Loss/seq after 01550 batchs: 2532.054931640625
INFO:root:Train (Epoch 0): Loss/seq after 01600 batchs: 2483.8681640625
INFO:root:Train (Epoch 0): Loss/seq after 01650 batchs: 2453.967041015625
INFO:root:Train (Epoch 0): Loss/seq after 01700 batchs: 2416.7607421875
INFO:root:Train (Epoch 0): Loss/seq after 01750 batchs: 2378.752685546875
INFO:root:Train (Epoch 0): Loss/seq after 01800 batchs: 2339.922119140625
INFO:root:Train (Epoch 0): Loss/seq after 01850 batchs: 2302.139404296875
INFO:root:Train (Epoch 0): Loss/seq after 01900 batchs: 2278.6181640625
INFO:root:Train (Epoch 0): Loss/seq after 01950 batchs: 2251.5224609375
INFO:root:Train (Epoch 0): Loss/seq after 02000 batchs: 2221.543212890625
INFO:root:Train (Epoch 0): Loss/seq after 02050 batchs: 2193.416015625
INFO:root:Train (Epoch 0): Loss/seq after 02100 batchs: 2163.307373046875
INFO:root:Train (Epoch 0): Loss/seq after 02150 batchs: 2135.076416015625
INFO:root:Train (Epoch 0): Loss/seq after 02200 batchs: 2106.27685546875
INFO:root:Train (Epoch 0): Loss/seq after 02250 batchs: 2101.462646484375
INFO:root:Train (Epoch 0): Loss/seq after 02300 batchs: 2096.311279296875
INFO:root:Train (Epoch 0): Loss/seq after 02350 batchs: 2073.7509765625
INFO:root:Train (Epoch 0): Loss/seq after 02400 batchs: 2055.83544921875
INFO:root:Train (Epoch 0): Loss/seq after 02450 batchs: 2030.1943359375
INFO:root:Train (Epoch 0): Loss/seq after 02500 batchs: 1999.0526123046875
INFO:root:Train (Epoch 0): Loss/seq after 02550 batchs: 1979.593505859375
INFO:root:Train (Epoch 0): Loss/seq after 02600 batchs: 1968.5751953125
INFO:root:Train (Epoch 0): Loss/seq after 02650 batchs: 1953.7276611328125
INFO:root:Train (Epoch 0): Loss/seq after 02700 batchs: 1943.0902099609375
INFO:root:Train (Epoch 0): Loss/seq after 02750 batchs: 1965.858154296875
INFO:root:Train (Epoch 0): Loss/seq after 02800 batchs: 1969.652587890625
INFO:root:Train (Epoch 0): Loss/seq after 02850 batchs: 1962.6634521484375
INFO:root:Train (Epoch 0): Loss/seq after 02900 batchs: 1953.083740234375
INFO:root:Train (Epoch 0): Loss/seq after 02950 batchs: 1936.7996826171875
INFO:root:Train (Epoch 0): Loss/seq after 03000 batchs: 1924.4901123046875
INFO:root:Train (Epoch 0): Loss/seq after 03050 batchs: 1917.1834716796875
INFO:root:Train (Epoch 0): Loss/seq after 03100 batchs: 1932.592529296875
INFO:root:Train (Epoch 0): Loss/seq after 03150 batchs: 1947.041259765625
INFO:root:Train (Epoch 0): Loss/seq after 03200 batchs: 1953.381591796875
INFO:root:Train (Epoch 0): Loss/seq after 03250 batchs: 1957.9989013671875
INFO:root:Train (Epoch 0): Loss/seq after 03300 batchs: 1952.273193359375
INFO:root:Train (Epoch 0): Loss/seq after 03350 batchs: 1946.680908203125
INFO:root:Train (Epoch 0): Loss/seq after 03400 batchs: 1929.1907958984375
INFO:root:Train (Epoch 0): Loss/seq after 03450 batchs: 1916.98388671875
INFO:root:Train (Epoch 0): Loss/seq after 03500 batchs: 1914.5447998046875
INFO:root:Train (Epoch 0): Loss/seq after 03550 batchs: 1904.040771484375
INFO:root:Train (Epoch 0): Loss/seq after 03600 batchs: 1903.7640380859375
INFO:root:Train (Epoch 0): Loss/seq after 03650 batchs: 1893.1622314453125
INFO:root:Train (Epoch 0): Loss/seq after 03700 batchs: 1885.5888671875
INFO:root:Train (Epoch 0): Loss/seq after 03750 batchs: 1877.9720458984375
INFO:root:Train (Epoch 0): Loss/seq after 03800 batchs: 1863.820068359375
INFO:root:Train (Epoch 0): Loss/seq after 03850 batchs: 1852.66552734375
INFO:root:Train (Epoch 0): Loss/seq after 03900 batchs: 1861.62890625
INFO:root:Train (Epoch 0): Loss/seq after 03950 batchs: 1865.39697265625
INFO:root:Train (Epoch 0): Loss/seq after 04000 batchs: 1850.9364013671875
INFO:root:Train (Epoch 0): Loss/seq after 04050 batchs: 1836.306396484375
INFO:root:Train (Epoch 0): Loss/seq after 04100 batchs: 1827.255615234375
INFO:root:Train (Epoch 0): Loss/seq after 04150 batchs: 1815.98974609375
INFO:root:Train (Epoch 0): Loss/seq after 04200 batchs: 1806.51708984375
INFO:root:Train (Epoch 0): Loss/seq after 04250 batchs: 1796.5145263671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 0): Loss/seq after 00000 batches: 1096.4033203125
INFO:root:# Valid (Epoch 0): Loss/seq after 00050 batches: 1243.5386962890625
INFO:root:# Valid (Epoch 0): Loss/seq after 00100 batches: 1622.66552734375
INFO:root:# Valid (Epoch 0): Loss/seq after 00150 batches: 1337.5545654296875
INFO:root:# Valid (Epoch 0): Loss/seq after 00200 batches: 1207.0072021484375
INFO:root:Artifacts: Make stick videos for epoch 0
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_0_on_20220414_083059.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_0_index_1528_on_20220414_083059.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 1): Loss/seq after 00000 batchs: 2487.791015625
INFO:root:Train (Epoch 1): Loss/seq after 00050 batchs: 2047.1695556640625
INFO:root:Train (Epoch 1): Loss/seq after 00100 batchs: 2000.71533203125
INFO:root:Train (Epoch 1): Loss/seq after 00150 batchs: 1760.979248046875
INFO:root:Train (Epoch 1): Loss/seq after 00200 batchs: 1865.62353515625
INFO:root:Train (Epoch 1): Loss/seq after 00250 batchs: 2026.2230224609375
INFO:root:Train (Epoch 1): Loss/seq after 00300 batchs: 1931.4420166015625
INFO:root:Train (Epoch 1): Loss/seq after 00350 batchs: 1802.708984375
INFO:root:Train (Epoch 1): Loss/seq after 00400 batchs: 1866.5621337890625
INFO:root:Train (Epoch 1): Loss/seq after 00450 batchs: 1768.676513671875
INFO:root:Train (Epoch 1): Loss/seq after 00500 batchs: 1803.02783203125
INFO:root:Train (Epoch 1): Loss/seq after 00550 batchs: 1724.5184326171875
INFO:root:Train (Epoch 1): Loss/seq after 00600 batchs: 1702.3035888671875
INFO:root:Train (Epoch 1): Loss/seq after 00650 batchs: 1755.434326171875
INFO:root:Train (Epoch 1): Loss/seq after 00700 batchs: 1827.949462890625
INFO:root:Train (Epoch 1): Loss/seq after 00750 batchs: 1860.071044921875
INFO:root:Train (Epoch 1): Loss/seq after 00800 batchs: 1837.467529296875
INFO:root:Train (Epoch 1): Loss/seq after 00850 batchs: 1790.0126953125
INFO:root:Train (Epoch 1): Loss/seq after 00900 batchs: 1798.9425048828125
INFO:root:Train (Epoch 1): Loss/seq after 00950 batchs: 1899.91259765625
INFO:root:Train (Epoch 1): Loss/seq after 01000 batchs: 1903.180908203125
INFO:root:Train (Epoch 1): Loss/seq after 01050 batchs: 1891.37109375
INFO:root:Train (Epoch 1): Loss/seq after 01100 batchs: 1877.3890380859375
INFO:root:Train (Epoch 1): Loss/seq after 01150 batchs: 1843.7100830078125
INFO:root:Train (Epoch 1): Loss/seq after 01200 batchs: 1819.744140625
INFO:root:Train (Epoch 1): Loss/seq after 01250 batchs: 1807.130859375
INFO:root:Train (Epoch 1): Loss/seq after 01300 batchs: 1811.2203369140625
INFO:root:Train (Epoch 1): Loss/seq after 01350 batchs: 1804.24267578125
INFO:root:Train (Epoch 1): Loss/seq after 01400 batchs: 1854.0665283203125
INFO:root:Train (Epoch 1): Loss/seq after 01450 batchs: 1835.65283203125
INFO:root:Train (Epoch 1): Loss/seq after 01500 batchs: 1813.4710693359375
INFO:root:Train (Epoch 1): Loss/seq after 01550 batchs: 1812.757080078125
INFO:root:Train (Epoch 1): Loss/seq after 01600 batchs: 1784.451416015625
INFO:root:Train (Epoch 1): Loss/seq after 01650 batchs: 1772.0255126953125
INFO:root:Train (Epoch 1): Loss/seq after 01700 batchs: 1752.55419921875
INFO:root:Train (Epoch 1): Loss/seq after 01750 batchs: 1730.886474609375
INFO:root:Train (Epoch 1): Loss/seq after 01800 batchs: 1707.7578125
INFO:root:Train (Epoch 1): Loss/seq after 01850 batchs: 1684.733154296875
INFO:root:Train (Epoch 1): Loss/seq after 01900 batchs: 1675.20556640625
INFO:root:Train (Epoch 1): Loss/seq after 01950 batchs: 1661.815673828125
INFO:root:Train (Epoch 1): Loss/seq after 02000 batchs: 1644.5323486328125
INFO:root:Train (Epoch 1): Loss/seq after 02050 batchs: 1628.895263671875
INFO:root:Train (Epoch 1): Loss/seq after 02100 batchs: 1610.395751953125
INFO:root:Train (Epoch 1): Loss/seq after 02150 batchs: 1593.4390869140625
INFO:root:Train (Epoch 1): Loss/seq after 02200 batchs: 1575.4727783203125
INFO:root:Train (Epoch 1): Loss/seq after 02250 batchs: 1581.8209228515625
INFO:root:Train (Epoch 1): Loss/seq after 02300 batchs: 1583.3763427734375
INFO:root:Train (Epoch 1): Loss/seq after 02350 batchs: 1569.6650390625
INFO:root:Train (Epoch 1): Loss/seq after 02400 batchs: 1560.84521484375
INFO:root:Train (Epoch 1): Loss/seq after 02450 batchs: 1543.931396484375
INFO:root:Train (Epoch 1): Loss/seq after 02500 batchs: 1521.3038330078125
INFO:root:Train (Epoch 1): Loss/seq after 02550 batchs: 1509.615966796875
INFO:root:Train (Epoch 1): Loss/seq after 02600 batchs: 1505.5810546875
INFO:root:Train (Epoch 1): Loss/seq after 02650 batchs: 1498.287109375
INFO:root:Train (Epoch 1): Loss/seq after 02700 batchs: 1493.637451171875
INFO:root:Train (Epoch 1): Loss/seq after 02750 batchs: 1524.635498046875
INFO:root:Train (Epoch 1): Loss/seq after 02800 batchs: 1532.5711669921875
INFO:root:Train (Epoch 1): Loss/seq after 02850 batchs: 1529.1580810546875
INFO:root:Train (Epoch 1): Loss/seq after 02900 batchs: 1524.3551025390625
INFO:root:Train (Epoch 1): Loss/seq after 02950 batchs: 1513.8536376953125
INFO:root:Train (Epoch 1): Loss/seq after 03000 batchs: 1507.6002197265625
INFO:root:Train (Epoch 1): Loss/seq after 03050 batchs: 1506.192626953125
INFO:root:Train (Epoch 1): Loss/seq after 03100 batchs: 1523.669921875
INFO:root:Train (Epoch 1): Loss/seq after 03150 batchs: 1546.7667236328125
INFO:root:Train (Epoch 1): Loss/seq after 03200 batchs: 1558.482177734375
INFO:root:Train (Epoch 1): Loss/seq after 03250 batchs: 1568.715576171875
INFO:root:Train (Epoch 1): Loss/seq after 03300 batchs: 1570.2559814453125
INFO:root:Train (Epoch 1): Loss/seq after 03350 batchs: 1567.808349609375
INFO:root:Train (Epoch 1): Loss/seq after 03400 batchs: 1554.896240234375
INFO:root:Train (Epoch 1): Loss/seq after 03450 batchs: 1546.2020263671875
INFO:root:Train (Epoch 1): Loss/seq after 03500 batchs: 1543.8480224609375
INFO:root:Train (Epoch 1): Loss/seq after 03550 batchs: 1536.252197265625
INFO:root:Train (Epoch 1): Loss/seq after 03600 batchs: 1539.3486328125
INFO:root:Train (Epoch 1): Loss/seq after 03650 batchs: 1532.9212646484375
INFO:root:Train (Epoch 1): Loss/seq after 03700 batchs: 1529.6968994140625
INFO:root:Train (Epoch 1): Loss/seq after 03750 batchs: 1526.1600341796875
INFO:root:Train (Epoch 1): Loss/seq after 03800 batchs: 1516.03662109375
INFO:root:Train (Epoch 1): Loss/seq after 03850 batchs: 1508.69287109375
INFO:root:Train (Epoch 1): Loss/seq after 03900 batchs: 1519.5892333984375
INFO:root:Train (Epoch 1): Loss/seq after 03950 batchs: 1526.1368408203125
INFO:root:Train (Epoch 1): Loss/seq after 04000 batchs: 1513.9915771484375
INFO:root:Train (Epoch 1): Loss/seq after 04050 batchs: 1502.8353271484375
INFO:root:Train (Epoch 1): Loss/seq after 04100 batchs: 1497.0579833984375
INFO:root:Train (Epoch 1): Loss/seq after 04150 batchs: 1489.2431640625
INFO:root:Train (Epoch 1): Loss/seq after 04200 batchs: 1482.810302734375
INFO:root:Train (Epoch 1): Loss/seq after 04250 batchs: 1476.132080078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 1): Loss/seq after 00000 batches: 1079.70458984375
INFO:root:# Valid (Epoch 1): Loss/seq after 00050 batches: 1197.03271484375
INFO:root:# Valid (Epoch 1): Loss/seq after 00100 batches: 1564.630859375
INFO:root:# Valid (Epoch 1): Loss/seq after 00150 batches: 1288.025390625
INFO:root:# Valid (Epoch 1): Loss/seq after 00200 batches: 1161.6275634765625
INFO:root:Artifacts: Make stick videos for epoch 1
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_1_on_20220414_083623.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_1_index_1647_on_20220414_083623.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 2): Loss/seq after 00000 batchs: 2525.72705078125
INFO:root:Train (Epoch 2): Loss/seq after 00050 batchs: 1923.3433837890625
INFO:root:Train (Epoch 2): Loss/seq after 00100 batchs: 1831.3712158203125
INFO:root:Train (Epoch 2): Loss/seq after 00150 batchs: 1643.2032470703125
INFO:root:Train (Epoch 2): Loss/seq after 00200 batchs: 1783.630859375
INFO:root:Train (Epoch 2): Loss/seq after 00250 batchs: 1898.5897216796875
INFO:root:Train (Epoch 2): Loss/seq after 00300 batchs: 1792.661865234375
INFO:root:Train (Epoch 2): Loss/seq after 00350 batchs: 1672.249267578125
INFO:root:Train (Epoch 2): Loss/seq after 00400 batchs: 1745.48291015625
INFO:root:Train (Epoch 2): Loss/seq after 00450 batchs: 1656.0399169921875
INFO:root:Train (Epoch 2): Loss/seq after 00500 batchs: 1693.6370849609375
INFO:root:Train (Epoch 2): Loss/seq after 00550 batchs: 1620.1651611328125
INFO:root:Train (Epoch 2): Loss/seq after 00600 batchs: 1584.8958740234375
INFO:root:Train (Epoch 2): Loss/seq after 00650 batchs: 1646.5281982421875
INFO:root:Train (Epoch 2): Loss/seq after 00700 batchs: 1726.4886474609375
INFO:root:Train (Epoch 2): Loss/seq after 00750 batchs: 1762.228271484375
INFO:root:Train (Epoch 2): Loss/seq after 00800 batchs: 1740.630126953125
INFO:root:Train (Epoch 2): Loss/seq after 00850 batchs: 1697.508544921875
INFO:root:Train (Epoch 2): Loss/seq after 00900 batchs: 1711.346435546875
INFO:root:Train (Epoch 2): Loss/seq after 00950 batchs: 1824.3248291015625
INFO:root:Train (Epoch 2): Loss/seq after 01000 batchs: 1823.5546875
INFO:root:Train (Epoch 2): Loss/seq after 01050 batchs: 1799.0244140625
INFO:root:Train (Epoch 2): Loss/seq after 01100 batchs: 1784.0169677734375
INFO:root:Train (Epoch 2): Loss/seq after 01150 batchs: 1754.7677001953125
INFO:root:Train (Epoch 2): Loss/seq after 01200 batchs: 1733.4195556640625
INFO:root:Train (Epoch 2): Loss/seq after 01250 batchs: 1724.921875
INFO:root:Train (Epoch 2): Loss/seq after 01300 batchs: 1731.517822265625
INFO:root:Train (Epoch 2): Loss/seq after 01350 batchs: 1726.904052734375
INFO:root:Train (Epoch 2): Loss/seq after 01400 batchs: 1777.708984375
INFO:root:Train (Epoch 2): Loss/seq after 01450 batchs: 1761.915771484375
INFO:root:Train (Epoch 2): Loss/seq after 01500 batchs: 1740.1016845703125
INFO:root:Train (Epoch 2): Loss/seq after 01550 batchs: 1742.4671630859375
INFO:root:Train (Epoch 2): Loss/seq after 01600 batchs: 1715.5159912109375
INFO:root:Train (Epoch 2): Loss/seq after 01650 batchs: 1705.17529296875
INFO:root:Train (Epoch 2): Loss/seq after 01700 batchs: 1687.2432861328125
INFO:root:Train (Epoch 2): Loss/seq after 01750 batchs: 1666.632568359375
INFO:root:Train (Epoch 2): Loss/seq after 01800 batchs: 1644.446044921875
INFO:root:Train (Epoch 2): Loss/seq after 01850 batchs: 1622.29638671875
INFO:root:Train (Epoch 2): Loss/seq after 01900 batchs: 1613.60546875
INFO:root:Train (Epoch 2): Loss/seq after 01950 batchs: 1601.1700439453125
INFO:root:Train (Epoch 2): Loss/seq after 02000 batchs: 1584.6441650390625
INFO:root:Train (Epoch 2): Loss/seq after 02050 batchs: 1569.87939453125
INFO:root:Train (Epoch 2): Loss/seq after 02100 batchs: 1552.1171875
INFO:root:Train (Epoch 2): Loss/seq after 02150 batchs: 1535.954345703125
INFO:root:Train (Epoch 2): Loss/seq after 02200 batchs: 1518.7481689453125
INFO:root:Train (Epoch 2): Loss/seq after 02250 batchs: 1526.048828125
INFO:root:Train (Epoch 2): Loss/seq after 02300 batchs: 1529.791015625
INFO:root:Train (Epoch 2): Loss/seq after 02350 batchs: 1517.3070068359375
INFO:root:Train (Epoch 2): Loss/seq after 02400 batchs: 1509.1549072265625
INFO:root:Train (Epoch 2): Loss/seq after 02450 batchs: 1492.949951171875
INFO:root:Train (Epoch 2): Loss/seq after 02500 batchs: 1470.8792724609375
INFO:root:Train (Epoch 2): Loss/seq after 02550 batchs: 1460.672607421875
INFO:root:Train (Epoch 2): Loss/seq after 02600 batchs: 1457.5933837890625
INFO:root:Train (Epoch 2): Loss/seq after 02650 batchs: 1450.9107666015625
INFO:root:Train (Epoch 2): Loss/seq after 02700 batchs: 1448.2718505859375
INFO:root:Train (Epoch 2): Loss/seq after 02750 batchs: 1480.5111083984375
INFO:root:Train (Epoch 2): Loss/seq after 02800 batchs: 1489.6871337890625
INFO:root:Train (Epoch 2): Loss/seq after 02850 batchs: 1487.460693359375
INFO:root:Train (Epoch 2): Loss/seq after 02900 batchs: 1485.0963134765625
INFO:root:Train (Epoch 2): Loss/seq after 02950 batchs: 1475.7501220703125
INFO:root:Train (Epoch 2): Loss/seq after 03000 batchs: 1469.9013671875
INFO:root:Train (Epoch 2): Loss/seq after 03050 batchs: 1468.7352294921875
INFO:root:Train (Epoch 2): Loss/seq after 03100 batchs: 1487.8453369140625
INFO:root:Train (Epoch 2): Loss/seq after 03150 batchs: 1509.4727783203125
INFO:root:Train (Epoch 2): Loss/seq after 03200 batchs: 1521.509521484375
INFO:root:Train (Epoch 2): Loss/seq after 03250 batchs: 1532.2774658203125
INFO:root:Train (Epoch 2): Loss/seq after 03300 batchs: 1532.2430419921875
INFO:root:Train (Epoch 2): Loss/seq after 03350 batchs: 1530.434814453125
INFO:root:Train (Epoch 2): Loss/seq after 03400 batchs: 1517.8316650390625
INFO:root:Train (Epoch 2): Loss/seq after 03450 batchs: 1510.4700927734375
INFO:root:Train (Epoch 2): Loss/seq after 03500 batchs: 1512.2484130859375
INFO:root:Train (Epoch 2): Loss/seq after 03550 batchs: 1506.056396484375
INFO:root:Train (Epoch 2): Loss/seq after 03600 batchs: 1510.117431640625
INFO:root:Train (Epoch 2): Loss/seq after 03650 batchs: 1504.0654296875
INFO:root:Train (Epoch 2): Loss/seq after 03700 batchs: 1500.946044921875
INFO:root:Train (Epoch 2): Loss/seq after 03750 batchs: 1497.641845703125
INFO:root:Train (Epoch 2): Loss/seq after 03800 batchs: 1487.68505859375
INFO:root:Train (Epoch 2): Loss/seq after 03850 batchs: 1480.5662841796875
INFO:root:Train (Epoch 2): Loss/seq after 03900 batchs: 1489.870849609375
INFO:root:Train (Epoch 2): Loss/seq after 03950 batchs: 1497.4874267578125
INFO:root:Train (Epoch 2): Loss/seq after 04000 batchs: 1485.7889404296875
INFO:root:Train (Epoch 2): Loss/seq after 04050 batchs: 1474.766845703125
INFO:root:Train (Epoch 2): Loss/seq after 04100 batchs: 1469.2386474609375
INFO:root:Train (Epoch 2): Loss/seq after 04150 batchs: 1461.495849609375
INFO:root:Train (Epoch 2): Loss/seq after 04200 batchs: 1455.3060302734375
INFO:root:Train (Epoch 2): Loss/seq after 04250 batchs: 1448.74072265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 2): Loss/seq after 00000 batches: 1041.6934814453125
INFO:root:# Valid (Epoch 2): Loss/seq after 00050 batches: 1179.491943359375
INFO:root:# Valid (Epoch 2): Loss/seq after 00100 batches: 1539.2900390625
INFO:root:# Valid (Epoch 2): Loss/seq after 00150 batches: 1264.8570556640625
INFO:root:# Valid (Epoch 2): Loss/seq after 00200 batches: 1138.30859375
INFO:root:Artifacts: Make stick videos for epoch 2
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_2_on_20220414_084148.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_2_index_1441_on_20220414_084148.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 3): Loss/seq after 00000 batchs: 2529.702880859375
INFO:root:Train (Epoch 3): Loss/seq after 00050 batchs: 1930.383056640625
INFO:root:Train (Epoch 3): Loss/seq after 00100 batchs: 1875.172119140625
INFO:root:Train (Epoch 3): Loss/seq after 00150 batchs: 1657.242431640625
INFO:root:Train (Epoch 3): Loss/seq after 00200 batchs: 1782.6614990234375
INFO:root:Train (Epoch 3): Loss/seq after 00250 batchs: 1896.359375
INFO:root:Train (Epoch 3): Loss/seq after 00300 batchs: 1777.894287109375
INFO:root:Train (Epoch 3): Loss/seq after 00350 batchs: 1656.5614013671875
INFO:root:Train (Epoch 3): Loss/seq after 00400 batchs: 1727.1068115234375
INFO:root:Train (Epoch 3): Loss/seq after 00450 batchs: 1636.4354248046875
INFO:root:Train (Epoch 3): Loss/seq after 00500 batchs: 1682.1253662109375
INFO:root:Train (Epoch 3): Loss/seq after 00550 batchs: 1610.521240234375
INFO:root:Train (Epoch 3): Loss/seq after 00600 batchs: 1579.49560546875
INFO:root:Train (Epoch 3): Loss/seq after 00650 batchs: 1639.1749267578125
INFO:root:Train (Epoch 3): Loss/seq after 00700 batchs: 1719.132568359375
INFO:root:Train (Epoch 3): Loss/seq after 00750 batchs: 1756.2169189453125
INFO:root:Train (Epoch 3): Loss/seq after 00800 batchs: 1735.7679443359375
INFO:root:Train (Epoch 3): Loss/seq after 00850 batchs: 1691.7313232421875
INFO:root:Train (Epoch 3): Loss/seq after 00900 batchs: 1701.9708251953125
INFO:root:Train (Epoch 3): Loss/seq after 00950 batchs: 1801.9417724609375
INFO:root:Train (Epoch 3): Loss/seq after 01000 batchs: 1804.2218017578125
INFO:root:Train (Epoch 3): Loss/seq after 01050 batchs: 1782.5189208984375
INFO:root:Train (Epoch 3): Loss/seq after 01100 batchs: 1776.7974853515625
INFO:root:Train (Epoch 3): Loss/seq after 01150 batchs: 1744.4764404296875
INFO:root:Train (Epoch 3): Loss/seq after 01200 batchs: 1721.342041015625
INFO:root:Train (Epoch 3): Loss/seq after 01250 batchs: 1708.8175048828125
INFO:root:Train (Epoch 3): Loss/seq after 01300 batchs: 1716.047607421875
INFO:root:Train (Epoch 3): Loss/seq after 01350 batchs: 1711.5452880859375
INFO:root:Train (Epoch 3): Loss/seq after 01400 batchs: 1762.3277587890625
INFO:root:Train (Epoch 3): Loss/seq after 01450 batchs: 1744.26806640625
INFO:root:Train (Epoch 3): Loss/seq after 01500 batchs: 1723.08154296875
INFO:root:Train (Epoch 3): Loss/seq after 01550 batchs: 1723.798095703125
INFO:root:Train (Epoch 3): Loss/seq after 01600 batchs: 1696.093017578125
INFO:root:Train (Epoch 3): Loss/seq after 01650 batchs: 1686.2431640625
INFO:root:Train (Epoch 3): Loss/seq after 01700 batchs: 1668.4488525390625
INFO:root:Train (Epoch 3): Loss/seq after 01750 batchs: 1647.95849609375
INFO:root:Train (Epoch 3): Loss/seq after 01800 batchs: 1625.9979248046875
INFO:root:Train (Epoch 3): Loss/seq after 01850 batchs: 1603.96533203125
INFO:root:Train (Epoch 3): Loss/seq after 01900 batchs: 1595.394775390625
INFO:root:Train (Epoch 3): Loss/seq after 01950 batchs: 1583.1795654296875
INFO:root:Train (Epoch 3): Loss/seq after 02000 batchs: 1566.74462890625
INFO:root:Train (Epoch 3): Loss/seq after 02050 batchs: 1552.15771484375
INFO:root:Train (Epoch 3): Loss/seq after 02100 batchs: 1534.53271484375
INFO:root:Train (Epoch 3): Loss/seq after 02150 batchs: 1518.5224609375
INFO:root:Train (Epoch 3): Loss/seq after 02200 batchs: 1501.463134765625
INFO:root:Train (Epoch 3): Loss/seq after 02250 batchs: 1508.2237548828125
INFO:root:Train (Epoch 3): Loss/seq after 02300 batchs: 1510.663818359375
INFO:root:Train (Epoch 3): Loss/seq after 02350 batchs: 1497.819091796875
INFO:root:Train (Epoch 3): Loss/seq after 02400 batchs: 1489.8348388671875
INFO:root:Train (Epoch 3): Loss/seq after 02450 batchs: 1473.7955322265625
INFO:root:Train (Epoch 3): Loss/seq after 02500 batchs: 1451.914794921875
INFO:root:Train (Epoch 3): Loss/seq after 02550 batchs: 1441.9639892578125
INFO:root:Train (Epoch 3): Loss/seq after 02600 batchs: 1438.918212890625
INFO:root:Train (Epoch 3): Loss/seq after 02650 batchs: 1432.3741455078125
INFO:root:Train (Epoch 3): Loss/seq after 02700 batchs: 1430.062744140625
INFO:root:Train (Epoch 3): Loss/seq after 02750 batchs: 1460.5252685546875
INFO:root:Train (Epoch 3): Loss/seq after 02800 batchs: 1471.413818359375
INFO:root:Train (Epoch 3): Loss/seq after 02850 batchs: 1468.6964111328125
INFO:root:Train (Epoch 3): Loss/seq after 02900 batchs: 1467.841552734375
INFO:root:Train (Epoch 3): Loss/seq after 02950 batchs: 1458.481201171875
INFO:root:Train (Epoch 3): Loss/seq after 03000 batchs: 1452.8748779296875
INFO:root:Train (Epoch 3): Loss/seq after 03050 batchs: 1451.8275146484375
INFO:root:Train (Epoch 3): Loss/seq after 03100 batchs: 1470.2911376953125
INFO:root:Train (Epoch 3): Loss/seq after 03150 batchs: 1491.9375
INFO:root:Train (Epoch 3): Loss/seq after 03200 batchs: 1504.0126953125
INFO:root:Train (Epoch 3): Loss/seq after 03250 batchs: 1514.9251708984375
INFO:root:Train (Epoch 3): Loss/seq after 03300 batchs: 1515.2332763671875
INFO:root:Train (Epoch 3): Loss/seq after 03350 batchs: 1514.2012939453125
INFO:root:Train (Epoch 3): Loss/seq after 03400 batchs: 1501.8040771484375
INFO:root:Train (Epoch 3): Loss/seq after 03450 batchs: 1494.7918701171875
INFO:root:Train (Epoch 3): Loss/seq after 03500 batchs: 1496.95703125
INFO:root:Train (Epoch 3): Loss/seq after 03550 batchs: 1490.558837890625
INFO:root:Train (Epoch 3): Loss/seq after 03600 batchs: 1494.5892333984375
INFO:root:Train (Epoch 3): Loss/seq after 03650 batchs: 1488.7193603515625
INFO:root:Train (Epoch 3): Loss/seq after 03700 batchs: 1485.6806640625
INFO:root:Train (Epoch 3): Loss/seq after 03750 batchs: 1482.46728515625
INFO:root:Train (Epoch 3): Loss/seq after 03800 batchs: 1472.61865234375
INFO:root:Train (Epoch 3): Loss/seq after 03850 batchs: 1465.5928955078125
INFO:root:Train (Epoch 3): Loss/seq after 03900 batchs: 1476.3197021484375
INFO:root:Train (Epoch 3): Loss/seq after 03950 batchs: 1483.4847412109375
INFO:root:Train (Epoch 3): Loss/seq after 04000 batchs: 1471.962158203125
INFO:root:Train (Epoch 3): Loss/seq after 04050 batchs: 1461.0213623046875
INFO:root:Train (Epoch 3): Loss/seq after 04100 batchs: 1455.5576171875
INFO:root:Train (Epoch 3): Loss/seq after 04150 batchs: 1447.8641357421875
INFO:root:Train (Epoch 3): Loss/seq after 04200 batchs: 1441.627685546875
INFO:root:Train (Epoch 3): Loss/seq after 04250 batchs: 1435.1175537109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 3): Loss/seq after 00000 batches: 1037.62158203125
INFO:root:# Valid (Epoch 3): Loss/seq after 00050 batches: 1170.1524658203125
INFO:root:# Valid (Epoch 3): Loss/seq after 00100 batches: 1532.787353515625
INFO:root:# Valid (Epoch 3): Loss/seq after 00150 batches: 1256.334228515625
INFO:root:# Valid (Epoch 3): Loss/seq after 00200 batches: 1128.9794921875
INFO:root:Artifacts: Make stick videos for epoch 3
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_3_on_20220414_084714.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_3_index_1797_on_20220414_084714.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 4): Loss/seq after 00000 batchs: 2453.157470703125
INFO:root:Train (Epoch 4): Loss/seq after 00050 batchs: 1932.7227783203125
INFO:root:Train (Epoch 4): Loss/seq after 00100 batchs: 1906.9178466796875
INFO:root:Train (Epoch 4): Loss/seq after 00150 batchs: 1680.9744873046875
INFO:root:Train (Epoch 4): Loss/seq after 00200 batchs: 1787.4757080078125
INFO:root:Train (Epoch 4): Loss/seq after 00250 batchs: 1922.1328125
INFO:root:Train (Epoch 4): Loss/seq after 00300 batchs: 1800.466552734375
INFO:root:Train (Epoch 4): Loss/seq after 00350 batchs: 1675.01123046875
INFO:root:Train (Epoch 4): Loss/seq after 00400 batchs: 1748.8939208984375
INFO:root:Train (Epoch 4): Loss/seq after 00450 batchs: 1655.54150390625
INFO:root:Train (Epoch 4): Loss/seq after 00500 batchs: 1699.802490234375
INFO:root:Train (Epoch 4): Loss/seq after 00550 batchs: 1626.09375
INFO:root:Train (Epoch 4): Loss/seq after 00600 batchs: 1586.1490478515625
INFO:root:Train (Epoch 4): Loss/seq after 00650 batchs: 1646.4759521484375
INFO:root:Train (Epoch 4): Loss/seq after 00700 batchs: 1726.7255859375
INFO:root:Train (Epoch 4): Loss/seq after 00750 batchs: 1764.1500244140625
INFO:root:Train (Epoch 4): Loss/seq after 00800 batchs: 1741.4754638671875
INFO:root:Train (Epoch 4): Loss/seq after 00850 batchs: 1696.690673828125
INFO:root:Train (Epoch 4): Loss/seq after 00900 batchs: 1705.8404541015625
INFO:root:Train (Epoch 4): Loss/seq after 00950 batchs: 1815.400146484375
INFO:root:Train (Epoch 4): Loss/seq after 01000 batchs: 1817.61279296875
INFO:root:Train (Epoch 4): Loss/seq after 01050 batchs: 1803.6500244140625
INFO:root:Train (Epoch 4): Loss/seq after 01100 batchs: 1792.7489013671875
INFO:root:Train (Epoch 4): Loss/seq after 01150 batchs: 1760.7138671875
INFO:root:Train (Epoch 4): Loss/seq after 01200 batchs: 1737.672607421875
INFO:root:Train (Epoch 4): Loss/seq after 01250 batchs: 1724.58935546875
INFO:root:Train (Epoch 4): Loss/seq after 01300 batchs: 1730.39794921875
INFO:root:Train (Epoch 4): Loss/seq after 01350 batchs: 1725.512939453125
INFO:root:Train (Epoch 4): Loss/seq after 01400 batchs: 1774.0150146484375
INFO:root:Train (Epoch 4): Loss/seq after 01450 batchs: 1754.05859375
INFO:root:Train (Epoch 4): Loss/seq after 01500 batchs: 1732.067626953125
INFO:root:Train (Epoch 4): Loss/seq after 01550 batchs: 1729.8505859375
INFO:root:Train (Epoch 4): Loss/seq after 01600 batchs: 1701.726318359375
INFO:root:Train (Epoch 4): Loss/seq after 01650 batchs: 1691.21240234375
INFO:root:Train (Epoch 4): Loss/seq after 01700 batchs: 1673.069580078125
INFO:root:Train (Epoch 4): Loss/seq after 01750 batchs: 1652.213623046875
INFO:root:Train (Epoch 4): Loss/seq after 01800 batchs: 1629.95703125
INFO:root:Train (Epoch 4): Loss/seq after 01850 batchs: 1607.6529541015625
INFO:root:Train (Epoch 4): Loss/seq after 01900 batchs: 1598.76708984375
INFO:root:Train (Epoch 4): Loss/seq after 01950 batchs: 1586.3311767578125
INFO:root:Train (Epoch 4): Loss/seq after 02000 batchs: 1569.6563720703125
INFO:root:Train (Epoch 4): Loss/seq after 02050 batchs: 1554.838134765625
INFO:root:Train (Epoch 4): Loss/seq after 02100 batchs: 1536.9991455078125
INFO:root:Train (Epoch 4): Loss/seq after 02150 batchs: 1520.7847900390625
INFO:root:Train (Epoch 4): Loss/seq after 02200 batchs: 1503.5433349609375
INFO:root:Train (Epoch 4): Loss/seq after 02250 batchs: 1508.6109619140625
INFO:root:Train (Epoch 4): Loss/seq after 02300 batchs: 1512.6790771484375
INFO:root:Train (Epoch 4): Loss/seq after 02350 batchs: 1499.576171875
INFO:root:Train (Epoch 4): Loss/seq after 02400 batchs: 1491.3077392578125
INFO:root:Train (Epoch 4): Loss/seq after 02450 batchs: 1475.05029296875
INFO:root:Train (Epoch 4): Loss/seq after 02500 batchs: 1453.06201171875
INFO:root:Train (Epoch 4): Loss/seq after 02550 batchs: 1442.9957275390625
INFO:root:Train (Epoch 4): Loss/seq after 02600 batchs: 1439.8489990234375
INFO:root:Train (Epoch 4): Loss/seq after 02650 batchs: 1433.1627197265625
INFO:root:Train (Epoch 4): Loss/seq after 02700 batchs: 1431.1422119140625
INFO:root:Train (Epoch 4): Loss/seq after 02750 batchs: 1462.326416015625
INFO:root:Train (Epoch 4): Loss/seq after 02800 batchs: 1472.0889892578125
INFO:root:Train (Epoch 4): Loss/seq after 02850 batchs: 1469.2022705078125
INFO:root:Train (Epoch 4): Loss/seq after 02900 batchs: 1468.46337890625
INFO:root:Train (Epoch 4): Loss/seq after 02950 batchs: 1459.143310546875
INFO:root:Train (Epoch 4): Loss/seq after 03000 batchs: 1453.4979248046875
INFO:root:Train (Epoch 4): Loss/seq after 03050 batchs: 1452.39111328125
INFO:root:Train (Epoch 4): Loss/seq after 03100 batchs: 1471.4146728515625
INFO:root:Train (Epoch 4): Loss/seq after 03150 batchs: 1492.3104248046875
INFO:root:Train (Epoch 4): Loss/seq after 03200 batchs: 1504.301025390625
INFO:root:Train (Epoch 4): Loss/seq after 03250 batchs: 1515.2861328125
INFO:root:Train (Epoch 4): Loss/seq after 03300 batchs: 1514.4443359375
INFO:root:Train (Epoch 4): Loss/seq after 03350 batchs: 1512.860107421875
INFO:root:Train (Epoch 4): Loss/seq after 03400 batchs: 1500.370361328125
INFO:root:Train (Epoch 4): Loss/seq after 03450 batchs: 1492.005859375
INFO:root:Train (Epoch 4): Loss/seq after 03500 batchs: 1490.84716796875
INFO:root:Train (Epoch 4): Loss/seq after 03550 batchs: 1483.7928466796875
INFO:root:Train (Epoch 4): Loss/seq after 03600 batchs: 1486.943115234375
INFO:root:Train (Epoch 4): Loss/seq after 03650 batchs: 1481.0025634765625
INFO:root:Train (Epoch 4): Loss/seq after 03700 batchs: 1478.0147705078125
INFO:root:Train (Epoch 4): Loss/seq after 03750 batchs: 1474.7969970703125
INFO:root:Train (Epoch 4): Loss/seq after 03800 batchs: 1465.0260009765625
INFO:root:Train (Epoch 4): Loss/seq after 03850 batchs: 1458.0030517578125
INFO:root:Train (Epoch 4): Loss/seq after 03900 batchs: 1466.5206298828125
INFO:root:Train (Epoch 4): Loss/seq after 03950 batchs: 1473.784912109375
INFO:root:Train (Epoch 4): Loss/seq after 04000 batchs: 1461.92333984375
INFO:root:Train (Epoch 4): Loss/seq after 04050 batchs: 1451.0196533203125
INFO:root:Train (Epoch 4): Loss/seq after 04100 batchs: 1445.4781494140625
INFO:root:Train (Epoch 4): Loss/seq after 04150 batchs: 1437.854736328125
INFO:root:Train (Epoch 4): Loss/seq after 04200 batchs: 1431.6290283203125
INFO:root:Train (Epoch 4): Loss/seq after 04250 batchs: 1425.2171630859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 4): Loss/seq after 00000 batches: 1033.1339111328125
INFO:root:# Valid (Epoch 4): Loss/seq after 00050 batches: 1165.0201416015625
INFO:root:# Valid (Epoch 4): Loss/seq after 00100 batches: 1537.4368896484375
INFO:root:# Valid (Epoch 4): Loss/seq after 00150 batches: 1257.8232421875
INFO:root:# Valid (Epoch 4): Loss/seq after 00200 batches: 1128.87841796875
INFO:root:Artifacts: Make stick videos for epoch 4
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_4_on_20220414_085240.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_4_index_1544_on_20220414_085240.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 5): Loss/seq after 00000 batchs: 2432.696044921875
INFO:root:Train (Epoch 5): Loss/seq after 00050 batchs: 1884.4276123046875
INFO:root:Train (Epoch 5): Loss/seq after 00100 batchs: 1835.720947265625
INFO:root:Train (Epoch 5): Loss/seq after 00150 batchs: 1634.9964599609375
INFO:root:Train (Epoch 5): Loss/seq after 00200 batchs: 1742.126220703125
INFO:root:Train (Epoch 5): Loss/seq after 00250 batchs: 1922.5401611328125
INFO:root:Train (Epoch 5): Loss/seq after 00300 batchs: 1806.413330078125
INFO:root:Train (Epoch 5): Loss/seq after 00350 batchs: 1679.65185546875
INFO:root:Train (Epoch 5): Loss/seq after 00400 batchs: 1786.0728759765625
INFO:root:Train (Epoch 5): Loss/seq after 00450 batchs: 1693.2021484375
INFO:root:Train (Epoch 5): Loss/seq after 00500 batchs: 1728.1405029296875
INFO:root:Train (Epoch 5): Loss/seq after 00550 batchs: 1655.8917236328125
INFO:root:Train (Epoch 5): Loss/seq after 00600 batchs: 1614.6322021484375
INFO:root:Train (Epoch 5): Loss/seq after 00650 batchs: 1669.363037109375
INFO:root:Train (Epoch 5): Loss/seq after 00700 batchs: 1746.8641357421875
INFO:root:Train (Epoch 5): Loss/seq after 00750 batchs: 1781.2891845703125
INFO:root:Train (Epoch 5): Loss/seq after 00800 batchs: 1757.7147216796875
INFO:root:Train (Epoch 5): Loss/seq after 00850 batchs: 1711.6097412109375
INFO:root:Train (Epoch 5): Loss/seq after 00900 batchs: 1710.4681396484375
INFO:root:Train (Epoch 5): Loss/seq after 00950 batchs: 1806.7066650390625
INFO:root:Train (Epoch 5): Loss/seq after 01000 batchs: 1805.9881591796875
INFO:root:Train (Epoch 5): Loss/seq after 01050 batchs: 1781.317626953125
INFO:root:Train (Epoch 5): Loss/seq after 01100 batchs: 1769.4771728515625
INFO:root:Train (Epoch 5): Loss/seq after 01150 batchs: 1737.166748046875
INFO:root:Train (Epoch 5): Loss/seq after 01200 batchs: 1714.6248779296875
INFO:root:Train (Epoch 5): Loss/seq after 01250 batchs: 1700.8365478515625
INFO:root:Train (Epoch 5): Loss/seq after 01300 batchs: 1708.0635986328125
INFO:root:Train (Epoch 5): Loss/seq after 01350 batchs: 1703.81298828125
INFO:root:Train (Epoch 5): Loss/seq after 01400 batchs: 1752.603271484375
INFO:root:Train (Epoch 5): Loss/seq after 01450 batchs: 1731.6571044921875
INFO:root:Train (Epoch 5): Loss/seq after 01500 batchs: 1709.9632568359375
INFO:root:Train (Epoch 5): Loss/seq after 01550 batchs: 1704.774658203125
INFO:root:Train (Epoch 5): Loss/seq after 01600 batchs: 1678.183349609375
INFO:root:Train (Epoch 5): Loss/seq after 01650 batchs: 1665.5933837890625
INFO:root:Train (Epoch 5): Loss/seq after 01700 batchs: 1647.96337890625
INFO:root:Train (Epoch 5): Loss/seq after 01750 batchs: 1627.4647216796875
INFO:root:Train (Epoch 5): Loss/seq after 01800 batchs: 1605.5718994140625
INFO:root:Train (Epoch 5): Loss/seq after 01850 batchs: 1583.7772216796875
INFO:root:Train (Epoch 5): Loss/seq after 01900 batchs: 1575.412841796875
INFO:root:Train (Epoch 5): Loss/seq after 01950 batchs: 1563.5196533203125
INFO:root:Train (Epoch 5): Loss/seq after 02000 batchs: 1547.2955322265625
INFO:root:Train (Epoch 5): Loss/seq after 02050 batchs: 1532.90380859375
INFO:root:Train (Epoch 5): Loss/seq after 02100 batchs: 1515.487548828125
INFO:root:Train (Epoch 5): Loss/seq after 02150 batchs: 1499.746337890625
INFO:root:Train (Epoch 5): Loss/seq after 02200 batchs: 1482.909912109375
INFO:root:Train (Epoch 5): Loss/seq after 02250 batchs: 1485.543701171875
INFO:root:Train (Epoch 5): Loss/seq after 02300 batchs: 1489.374755859375
INFO:root:Train (Epoch 5): Loss/seq after 02350 batchs: 1476.778564453125
INFO:root:Train (Epoch 5): Loss/seq after 02400 batchs: 1468.92724609375
INFO:root:Train (Epoch 5): Loss/seq after 02450 batchs: 1453.0660400390625
INFO:root:Train (Epoch 5): Loss/seq after 02500 batchs: 1431.4830322265625
INFO:root:Train (Epoch 5): Loss/seq after 02550 batchs: 1421.87939453125
INFO:root:Train (Epoch 5): Loss/seq after 02600 batchs: 1419.40283203125
INFO:root:Train (Epoch 5): Loss/seq after 02650 batchs: 1413.054443359375
INFO:root:Train (Epoch 5): Loss/seq after 02700 batchs: 1411.0079345703125
INFO:root:Train (Epoch 5): Loss/seq after 02750 batchs: 1441.609619140625
INFO:root:Train (Epoch 5): Loss/seq after 02800 batchs: 1452.55322265625
INFO:root:Train (Epoch 5): Loss/seq after 02850 batchs: 1449.700439453125
INFO:root:Train (Epoch 5): Loss/seq after 02900 batchs: 1451.3302001953125
INFO:root:Train (Epoch 5): Loss/seq after 02950 batchs: 1442.37060546875
INFO:root:Train (Epoch 5): Loss/seq after 03000 batchs: 1437.0235595703125
INFO:root:Train (Epoch 5): Loss/seq after 03050 batchs: 1436.164794921875
INFO:root:Train (Epoch 5): Loss/seq after 03100 batchs: 1454.095703125
INFO:root:Train (Epoch 5): Loss/seq after 03150 batchs: 1475.7987060546875
INFO:root:Train (Epoch 5): Loss/seq after 03200 batchs: 1487.869384765625
INFO:root:Train (Epoch 5): Loss/seq after 03250 batchs: 1498.9002685546875
INFO:root:Train (Epoch 5): Loss/seq after 03300 batchs: 1496.8421630859375
INFO:root:Train (Epoch 5): Loss/seq after 03350 batchs: 1495.6650390625
INFO:root:Train (Epoch 5): Loss/seq after 03400 batchs: 1483.4027099609375
INFO:root:Train (Epoch 5): Loss/seq after 03450 batchs: 1474.3197021484375
INFO:root:Train (Epoch 5): Loss/seq after 03500 batchs: 1473.6612548828125
INFO:root:Train (Epoch 5): Loss/seq after 03550 batchs: 1466.7822265625
INFO:root:Train (Epoch 5): Loss/seq after 03600 batchs: 1470.4285888671875
INFO:root:Train (Epoch 5): Loss/seq after 03650 batchs: 1464.1607666015625
INFO:root:Train (Epoch 5): Loss/seq after 03700 batchs: 1461.82470703125
INFO:root:Train (Epoch 5): Loss/seq after 03750 batchs: 1458.7601318359375
INFO:root:Train (Epoch 5): Loss/seq after 03800 batchs: 1449.15771484375
INFO:root:Train (Epoch 5): Loss/seq after 03850 batchs: 1442.28564453125
INFO:root:Train (Epoch 5): Loss/seq after 03900 batchs: 1449.9549560546875
INFO:root:Train (Epoch 5): Loss/seq after 03950 batchs: 1458.1722412109375
INFO:root:Train (Epoch 5): Loss/seq after 04000 batchs: 1446.5242919921875
INFO:root:Train (Epoch 5): Loss/seq after 04050 batchs: 1435.78759765625
INFO:root:Train (Epoch 5): Loss/seq after 04100 batchs: 1430.2396240234375
INFO:root:Train (Epoch 5): Loss/seq after 04150 batchs: 1422.7703857421875
INFO:root:Train (Epoch 5): Loss/seq after 04200 batchs: 1416.56103515625
INFO:root:Train (Epoch 5): Loss/seq after 04250 batchs: 1410.237060546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 5): Loss/seq after 00000 batches: 996.2146606445312
INFO:root:# Valid (Epoch 5): Loss/seq after 00050 batches: 1143.9935302734375
INFO:root:# Valid (Epoch 5): Loss/seq after 00100 batches: 1490.52197265625
INFO:root:# Valid (Epoch 5): Loss/seq after 00150 batches: 1232.384765625
INFO:root:# Valid (Epoch 5): Loss/seq after 00200 batches: 1113.387451171875
INFO:root:Artifacts: Make stick videos for epoch 5
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_5_on_20220414_085807.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_5_index_429_on_20220414_085807.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 6): Loss/seq after 00000 batchs: 2413.5234375
INFO:root:Train (Epoch 6): Loss/seq after 00050 batchs: 1852.958984375
INFO:root:Train (Epoch 6): Loss/seq after 00100 batchs: 1844.8006591796875
INFO:root:Train (Epoch 6): Loss/seq after 00150 batchs: 1629.116455078125
INFO:root:Train (Epoch 6): Loss/seq after 00200 batchs: 1749.3621826171875
INFO:root:Train (Epoch 6): Loss/seq after 00250 batchs: 1970.6341552734375
INFO:root:Train (Epoch 6): Loss/seq after 00300 batchs: 1858.6685791015625
INFO:root:Train (Epoch 6): Loss/seq after 00350 batchs: 1724.1475830078125
INFO:root:Train (Epoch 6): Loss/seq after 00400 batchs: 1782.6600341796875
INFO:root:Train (Epoch 6): Loss/seq after 00450 batchs: 1685.4351806640625
INFO:root:Train (Epoch 6): Loss/seq after 00500 batchs: 1732.4312744140625
INFO:root:Train (Epoch 6): Loss/seq after 00550 batchs: 1655.9228515625
INFO:root:Train (Epoch 6): Loss/seq after 00600 batchs: 1621.628662109375
INFO:root:Train (Epoch 6): Loss/seq after 00650 batchs: 1674.580810546875
INFO:root:Train (Epoch 6): Loss/seq after 00700 batchs: 1750.199951171875
INFO:root:Train (Epoch 6): Loss/seq after 00750 batchs: 1778.403076171875
INFO:root:Train (Epoch 6): Loss/seq after 00800 batchs: 1761.8414306640625
INFO:root:Train (Epoch 6): Loss/seq after 00850 batchs: 1715.2998046875
INFO:root:Train (Epoch 6): Loss/seq after 00900 batchs: 1725.8092041015625
INFO:root:Train (Epoch 6): Loss/seq after 00950 batchs: 1818.198974609375
INFO:root:Train (Epoch 6): Loss/seq after 01000 batchs: 1817.649658203125
INFO:root:Train (Epoch 6): Loss/seq after 01050 batchs: 1792.682373046875
INFO:root:Train (Epoch 6): Loss/seq after 01100 batchs: 1774.5059814453125
INFO:root:Train (Epoch 6): Loss/seq after 01150 batchs: 1741.910400390625
INFO:root:Train (Epoch 6): Loss/seq after 01200 batchs: 1718.065185546875
INFO:root:Train (Epoch 6): Loss/seq after 01250 batchs: 1702.7298583984375
INFO:root:Train (Epoch 6): Loss/seq after 01300 batchs: 1709.998046875
INFO:root:Train (Epoch 6): Loss/seq after 01350 batchs: 1705.933837890625
INFO:root:Train (Epoch 6): Loss/seq after 01400 batchs: 1755.40234375
INFO:root:Train (Epoch 6): Loss/seq after 01450 batchs: 1735.3304443359375
INFO:root:Train (Epoch 6): Loss/seq after 01500 batchs: 1713.3231201171875
INFO:root:Train (Epoch 6): Loss/seq after 01550 batchs: 1709.1439208984375
INFO:root:Train (Epoch 6): Loss/seq after 01600 batchs: 1682.8116455078125
INFO:root:Train (Epoch 6): Loss/seq after 01650 batchs: 1669.7618408203125
INFO:root:Train (Epoch 6): Loss/seq after 01700 batchs: 1652.0826416015625
INFO:root:Train (Epoch 6): Loss/seq after 01750 batchs: 1631.314208984375
INFO:root:Train (Epoch 6): Loss/seq after 01800 batchs: 1609.217041015625
INFO:root:Train (Epoch 6): Loss/seq after 01850 batchs: 1587.224609375
INFO:root:Train (Epoch 6): Loss/seq after 01900 batchs: 1579.199462890625
INFO:root:Train (Epoch 6): Loss/seq after 01950 batchs: 1567.2685546875
INFO:root:Train (Epoch 6): Loss/seq after 02000 batchs: 1550.87353515625
INFO:root:Train (Epoch 6): Loss/seq after 02050 batchs: 1536.3970947265625
INFO:root:Train (Epoch 6): Loss/seq after 02100 batchs: 1518.8299560546875
INFO:root:Train (Epoch 6): Loss/seq after 02150 batchs: 1502.9105224609375
INFO:root:Train (Epoch 6): Loss/seq after 02200 batchs: 1485.9449462890625
INFO:root:Train (Epoch 6): Loss/seq after 02250 batchs: 1489.859619140625
INFO:root:Train (Epoch 6): Loss/seq after 02300 batchs: 1491.6749267578125
INFO:root:Train (Epoch 6): Loss/seq after 02350 batchs: 1478.4852294921875
INFO:root:Train (Epoch 6): Loss/seq after 02400 batchs: 1470.475341796875
INFO:root:Train (Epoch 6): Loss/seq after 02450 batchs: 1454.2490234375
INFO:root:Train (Epoch 6): Loss/seq after 02500 batchs: 1432.5845947265625
INFO:root:Train (Epoch 6): Loss/seq after 02550 batchs: 1419.5262451171875
INFO:root:Train (Epoch 6): Loss/seq after 02600 batchs: 1415.087646484375
INFO:root:Train (Epoch 6): Loss/seq after 02650 batchs: 1406.7493896484375
INFO:root:Train (Epoch 6): Loss/seq after 02700 batchs: 1400.8028564453125
INFO:root:Train (Epoch 6): Loss/seq after 02750 batchs: 1430.2923583984375
INFO:root:Train (Epoch 6): Loss/seq after 02800 batchs: 1438.4190673828125
INFO:root:Train (Epoch 6): Loss/seq after 02850 batchs: 1433.9522705078125
INFO:root:Train (Epoch 6): Loss/seq after 02900 batchs: 1430.9569091796875
INFO:root:Train (Epoch 6): Loss/seq after 02950 batchs: 1420.6876220703125
INFO:root:Train (Epoch 6): Loss/seq after 03000 batchs: 1415.23193359375
INFO:root:Train (Epoch 6): Loss/seq after 03050 batchs: 1414.71484375
INFO:root:Train (Epoch 6): Loss/seq after 03100 batchs: 1432.4356689453125
INFO:root:Train (Epoch 6): Loss/seq after 03150 batchs: 1451.4847412109375
INFO:root:Train (Epoch 6): Loss/seq after 03200 batchs: 1463.4581298828125
INFO:root:Train (Epoch 6): Loss/seq after 03250 batchs: 1474.93896484375
INFO:root:Train (Epoch 6): Loss/seq after 03300 batchs: 1473.0438232421875
INFO:root:Train (Epoch 6): Loss/seq after 03350 batchs: 1470.6781005859375
INFO:root:Train (Epoch 6): Loss/seq after 03400 batchs: 1458.7308349609375
INFO:root:Train (Epoch 6): Loss/seq after 03450 batchs: 1450.330810546875
INFO:root:Train (Epoch 6): Loss/seq after 03500 batchs: 1448.6649169921875
INFO:root:Train (Epoch 6): Loss/seq after 03550 batchs: 1441.7794189453125
INFO:root:Train (Epoch 6): Loss/seq after 03600 batchs: 1445.212646484375
INFO:root:Train (Epoch 6): Loss/seq after 03650 batchs: 1439.033447265625
INFO:root:Train (Epoch 6): Loss/seq after 03700 batchs: 1436.3521728515625
INFO:root:Train (Epoch 6): Loss/seq after 03750 batchs: 1433.7174072265625
INFO:root:Train (Epoch 6): Loss/seq after 03800 batchs: 1424.4423828125
INFO:root:Train (Epoch 6): Loss/seq after 03850 batchs: 1417.882568359375
INFO:root:Train (Epoch 6): Loss/seq after 03900 batchs: 1424.289306640625
INFO:root:Train (Epoch 6): Loss/seq after 03950 batchs: 1431.8115234375
INFO:root:Train (Epoch 6): Loss/seq after 04000 batchs: 1420.3984375
INFO:root:Train (Epoch 6): Loss/seq after 04050 batchs: 1409.9517822265625
INFO:root:Train (Epoch 6): Loss/seq after 04100 batchs: 1404.828857421875
INFO:root:Train (Epoch 6): Loss/seq after 04150 batchs: 1397.648681640625
INFO:root:Train (Epoch 6): Loss/seq after 04200 batchs: 1391.5106201171875
INFO:root:Train (Epoch 6): Loss/seq after 04250 batchs: 1385.3492431640625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 6): Loss/seq after 00000 batches: 997.9044189453125
INFO:root:# Valid (Epoch 6): Loss/seq after 00050 batches: 1143.9981689453125
INFO:root:# Valid (Epoch 6): Loss/seq after 00100 batches: 1482.5201416015625
INFO:root:# Valid (Epoch 6): Loss/seq after 00150 batches: 1224.482666015625
INFO:root:# Valid (Epoch 6): Loss/seq after 00200 batches: 1106.48876953125
INFO:root:Artifacts: Make stick videos for epoch 6
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_6_on_20220414_090334.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_6_index_615_on_20220414_090334.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 7): Loss/seq after 00000 batchs: 2433.98193359375
INFO:root:Train (Epoch 7): Loss/seq after 00050 batchs: 1816.6705322265625
INFO:root:Train (Epoch 7): Loss/seq after 00100 batchs: 1843.8890380859375
INFO:root:Train (Epoch 7): Loss/seq after 00150 batchs: 1641.36572265625
INFO:root:Train (Epoch 7): Loss/seq after 00200 batchs: 1748.0784912109375
INFO:root:Train (Epoch 7): Loss/seq after 00250 batchs: 1837.6875
INFO:root:Train (Epoch 7): Loss/seq after 00300 batchs: 1722.39599609375
INFO:root:Train (Epoch 7): Loss/seq after 00350 batchs: 1604.1527099609375
INFO:root:Train (Epoch 7): Loss/seq after 00400 batchs: 1661.3935546875
INFO:root:Train (Epoch 7): Loss/seq after 00450 batchs: 1574.9781494140625
INFO:root:Train (Epoch 7): Loss/seq after 00500 batchs: 1618.740478515625
INFO:root:Train (Epoch 7): Loss/seq after 00550 batchs: 1551.4443359375
INFO:root:Train (Epoch 7): Loss/seq after 00600 batchs: 1515.93701171875
INFO:root:Train (Epoch 7): Loss/seq after 00650 batchs: 1573.187255859375
INFO:root:Train (Epoch 7): Loss/seq after 00700 batchs: 1653.9534912109375
INFO:root:Train (Epoch 7): Loss/seq after 00750 batchs: 1686.3499755859375
INFO:root:Train (Epoch 7): Loss/seq after 00800 batchs: 1667.936767578125
INFO:root:Train (Epoch 7): Loss/seq after 00850 batchs: 1627.466064453125
INFO:root:Train (Epoch 7): Loss/seq after 00900 batchs: 1628.3289794921875
INFO:root:Train (Epoch 7): Loss/seq after 00950 batchs: 1722.5400390625
INFO:root:Train (Epoch 7): Loss/seq after 01000 batchs: 1720.5643310546875
INFO:root:Train (Epoch 7): Loss/seq after 01050 batchs: 1695.7708740234375
INFO:root:Train (Epoch 7): Loss/seq after 01100 batchs: 1684.3140869140625
INFO:root:Train (Epoch 7): Loss/seq after 01150 batchs: 1655.354248046875
INFO:root:Train (Epoch 7): Loss/seq after 01200 batchs: 1635.1781005859375
INFO:root:Train (Epoch 7): Loss/seq after 01250 batchs: 1626.75244140625
INFO:root:Train (Epoch 7): Loss/seq after 01300 batchs: 1636.8779296875
INFO:root:Train (Epoch 7): Loss/seq after 01350 batchs: 1635.1094970703125
INFO:root:Train (Epoch 7): Loss/seq after 01400 batchs: 1685.8170166015625
INFO:root:Train (Epoch 7): Loss/seq after 01450 batchs: 1667.46826171875
INFO:root:Train (Epoch 7): Loss/seq after 01500 batchs: 1648.1103515625
INFO:root:Train (Epoch 7): Loss/seq after 01550 batchs: 1643.8028564453125
INFO:root:Train (Epoch 7): Loss/seq after 01600 batchs: 1618.02197265625
INFO:root:Train (Epoch 7): Loss/seq after 01650 batchs: 1605.5782470703125
INFO:root:Train (Epoch 7): Loss/seq after 01700 batchs: 1589.71435546875
INFO:root:Train (Epoch 7): Loss/seq after 01750 batchs: 1570.6715087890625
INFO:root:Train (Epoch 7): Loss/seq after 01800 batchs: 1550.1778564453125
INFO:root:Train (Epoch 7): Loss/seq after 01850 batchs: 1529.7803955078125
INFO:root:Train (Epoch 7): Loss/seq after 01900 batchs: 1522.5987548828125
INFO:root:Train (Epoch 7): Loss/seq after 01950 batchs: 1511.9940185546875
INFO:root:Train (Epoch 7): Loss/seq after 02000 batchs: 1496.8946533203125
INFO:root:Train (Epoch 7): Loss/seq after 02050 batchs: 1483.6026611328125
INFO:root:Train (Epoch 7): Loss/seq after 02100 batchs: 1467.2713623046875
INFO:root:Train (Epoch 7): Loss/seq after 02150 batchs: 1452.4888916015625
INFO:root:Train (Epoch 7): Loss/seq after 02200 batchs: 1436.5560302734375
INFO:root:Train (Epoch 7): Loss/seq after 02250 batchs: 1439.7164306640625
INFO:root:Train (Epoch 7): Loss/seq after 02300 batchs: 1441.751220703125
INFO:root:Train (Epoch 7): Loss/seq after 02350 batchs: 1430.4371337890625
INFO:root:Train (Epoch 7): Loss/seq after 02400 batchs: 1423.461181640625
INFO:root:Train (Epoch 7): Loss/seq after 02450 batchs: 1408.4837646484375
INFO:root:Train (Epoch 7): Loss/seq after 02500 batchs: 1387.74267578125
INFO:root:Train (Epoch 7): Loss/seq after 02550 batchs: 1377.9224853515625
INFO:root:Train (Epoch 7): Loss/seq after 02600 batchs: 1375.6654052734375
INFO:root:Train (Epoch 7): Loss/seq after 02650 batchs: 1370.0909423828125
INFO:root:Train (Epoch 7): Loss/seq after 02700 batchs: 1367.320068359375
INFO:root:Train (Epoch 7): Loss/seq after 02750 batchs: 1397.5235595703125
INFO:root:Train (Epoch 7): Loss/seq after 02800 batchs: 1406.0718994140625
INFO:root:Train (Epoch 7): Loss/seq after 02850 batchs: 1401.9056396484375
INFO:root:Train (Epoch 7): Loss/seq after 02900 batchs: 1398.739013671875
INFO:root:Train (Epoch 7): Loss/seq after 02950 batchs: 1389.111572265625
INFO:root:Train (Epoch 7): Loss/seq after 03000 batchs: 1384.178955078125
INFO:root:Train (Epoch 7): Loss/seq after 03050 batchs: 1384.131103515625
INFO:root:Train (Epoch 7): Loss/seq after 03100 batchs: 1401.316162109375
INFO:root:Train (Epoch 7): Loss/seq after 03150 batchs: 1420.510986328125
INFO:root:Train (Epoch 7): Loss/seq after 03200 batchs: 1432.9053955078125
INFO:root:Train (Epoch 7): Loss/seq after 03250 batchs: 1444.716064453125
INFO:root:Train (Epoch 7): Loss/seq after 03300 batchs: 1442.276611328125
INFO:root:Train (Epoch 7): Loss/seq after 03350 batchs: 1440.0791015625
INFO:root:Train (Epoch 7): Loss/seq after 03400 batchs: 1428.6220703125
INFO:root:Train (Epoch 7): Loss/seq after 03450 batchs: 1420.3369140625
INFO:root:Train (Epoch 7): Loss/seq after 03500 batchs: 1418.7763671875
INFO:root:Train (Epoch 7): Loss/seq after 03550 batchs: 1411.728271484375
INFO:root:Train (Epoch 7): Loss/seq after 03600 batchs: 1415.3428955078125
INFO:root:Train (Epoch 7): Loss/seq after 03650 batchs: 1409.1429443359375
INFO:root:Train (Epoch 7): Loss/seq after 03700 batchs: 1406.66796875
INFO:root:Train (Epoch 7): Loss/seq after 03750 batchs: 1404.25634765625
INFO:root:Train (Epoch 7): Loss/seq after 03800 batchs: 1395.1705322265625
INFO:root:Train (Epoch 7): Loss/seq after 03850 batchs: 1388.6573486328125
INFO:root:Train (Epoch 7): Loss/seq after 03900 batchs: 1395.359619140625
INFO:root:Train (Epoch 7): Loss/seq after 03950 batchs: 1404.989013671875
INFO:root:Train (Epoch 7): Loss/seq after 04000 batchs: 1393.8916015625
INFO:root:Train (Epoch 7): Loss/seq after 04050 batchs: 1383.7713623046875
INFO:root:Train (Epoch 7): Loss/seq after 04100 batchs: 1378.4114990234375
INFO:root:Train (Epoch 7): Loss/seq after 04150 batchs: 1371.582275390625
INFO:root:Train (Epoch 7): Loss/seq after 04200 batchs: 1365.98583984375
INFO:root:Train (Epoch 7): Loss/seq after 04250 batchs: 1360.364501953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 7): Loss/seq after 00000 batches: 972.8630981445312
INFO:root:# Valid (Epoch 7): Loss/seq after 00050 batches: 1129.916259765625
INFO:root:# Valid (Epoch 7): Loss/seq after 00100 batches: 1493.8963623046875
INFO:root:# Valid (Epoch 7): Loss/seq after 00150 batches: 1241.939697265625
INFO:root:# Valid (Epoch 7): Loss/seq after 00200 batches: 1124.124755859375
INFO:root:Artifacts: Make stick videos for epoch 7
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_7_on_20220414_090900.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_7_index_477_on_20220414_090900.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 8): Loss/seq after 00000 batchs: 2654.3916015625
INFO:root:Train (Epoch 8): Loss/seq after 00050 batchs: 1924.385498046875
INFO:root:Train (Epoch 8): Loss/seq after 00100 batchs: 1838.486083984375
INFO:root:Train (Epoch 8): Loss/seq after 00150 batchs: 1615.3857421875
INFO:root:Train (Epoch 8): Loss/seq after 00200 batchs: 1724.346923828125
INFO:root:Train (Epoch 8): Loss/seq after 00250 batchs: 1824.458740234375
INFO:root:Train (Epoch 8): Loss/seq after 00300 batchs: 1706.9683837890625
INFO:root:Train (Epoch 8): Loss/seq after 00350 batchs: 1589.69091796875
INFO:root:Train (Epoch 8): Loss/seq after 00400 batchs: 1648.85888671875
INFO:root:Train (Epoch 8): Loss/seq after 00450 batchs: 1563.6610107421875
INFO:root:Train (Epoch 8): Loss/seq after 00500 batchs: 1596.1407470703125
INFO:root:Train (Epoch 8): Loss/seq after 00550 batchs: 1525.4891357421875
INFO:root:Train (Epoch 8): Loss/seq after 00600 batchs: 1487.397705078125
INFO:root:Train (Epoch 8): Loss/seq after 00650 batchs: 1552.9136962890625
INFO:root:Train (Epoch 8): Loss/seq after 00700 batchs: 1636.5018310546875
INFO:root:Train (Epoch 8): Loss/seq after 00750 batchs: 1672.9735107421875
INFO:root:Train (Epoch 8): Loss/seq after 00800 batchs: 1654.2574462890625
INFO:root:Train (Epoch 8): Loss/seq after 00850 batchs: 1615.154296875
INFO:root:Train (Epoch 8): Loss/seq after 00900 batchs: 1617.3778076171875
INFO:root:Train (Epoch 8): Loss/seq after 00950 batchs: 1711.5325927734375
INFO:root:Train (Epoch 8): Loss/seq after 01000 batchs: 1710.3004150390625
INFO:root:Train (Epoch 8): Loss/seq after 01050 batchs: 1686.0919189453125
INFO:root:Train (Epoch 8): Loss/seq after 01100 batchs: 1672.6370849609375
INFO:root:Train (Epoch 8): Loss/seq after 01150 batchs: 1643.1822509765625
INFO:root:Train (Epoch 8): Loss/seq after 01200 batchs: 1625.06640625
INFO:root:Train (Epoch 8): Loss/seq after 01250 batchs: 1615.9378662109375
INFO:root:Train (Epoch 8): Loss/seq after 01300 batchs: 1626.299560546875
INFO:root:Train (Epoch 8): Loss/seq after 01350 batchs: 1624.60302734375
INFO:root:Train (Epoch 8): Loss/seq after 01400 batchs: 1675.130615234375
INFO:root:Train (Epoch 8): Loss/seq after 01450 batchs: 1656.3819580078125
INFO:root:Train (Epoch 8): Loss/seq after 01500 batchs: 1637.1094970703125
INFO:root:Train (Epoch 8): Loss/seq after 01550 batchs: 1635.72705078125
INFO:root:Train (Epoch 8): Loss/seq after 01600 batchs: 1610.893310546875
INFO:root:Train (Epoch 8): Loss/seq after 01650 batchs: 1599.14697265625
INFO:root:Train (Epoch 8): Loss/seq after 01700 batchs: 1583.22412109375
INFO:root:Train (Epoch 8): Loss/seq after 01750 batchs: 1564.3525390625
INFO:root:Train (Epoch 8): Loss/seq after 01800 batchs: 1544.046630859375
INFO:root:Train (Epoch 8): Loss/seq after 01850 batchs: 1523.7989501953125
INFO:root:Train (Epoch 8): Loss/seq after 01900 batchs: 1516.7635498046875
INFO:root:Train (Epoch 8): Loss/seq after 01950 batchs: 1506.2119140625
INFO:root:Train (Epoch 8): Loss/seq after 02000 batchs: 1491.1083984375
INFO:root:Train (Epoch 8): Loss/seq after 02050 batchs: 1478.19384765625
INFO:root:Train (Epoch 8): Loss/seq after 02100 batchs: 1461.9559326171875
INFO:root:Train (Epoch 8): Loss/seq after 02150 batchs: 1447.3900146484375
INFO:root:Train (Epoch 8): Loss/seq after 02200 batchs: 1431.641357421875
INFO:root:Train (Epoch 8): Loss/seq after 02250 batchs: 1433.654052734375
INFO:root:Train (Epoch 8): Loss/seq after 02300 batchs: 1436.7818603515625
INFO:root:Train (Epoch 8): Loss/seq after 02350 batchs: 1424.44384765625
INFO:root:Train (Epoch 8): Loss/seq after 02400 batchs: 1417.2904052734375
INFO:root:Train (Epoch 8): Loss/seq after 02450 batchs: 1402.053955078125
INFO:root:Train (Epoch 8): Loss/seq after 02500 batchs: 1381.51171875
INFO:root:Train (Epoch 8): Loss/seq after 02550 batchs: 1369.9931640625
INFO:root:Train (Epoch 8): Loss/seq after 02600 batchs: 1367.313720703125
INFO:root:Train (Epoch 8): Loss/seq after 02650 batchs: 1361.427001953125
INFO:root:Train (Epoch 8): Loss/seq after 02700 batchs: 1358.8759765625
INFO:root:Train (Epoch 8): Loss/seq after 02750 batchs: 1389.2052001953125
INFO:root:Train (Epoch 8): Loss/seq after 02800 batchs: 1397.549072265625
INFO:root:Train (Epoch 8): Loss/seq after 02850 batchs: 1393.197265625
INFO:root:Train (Epoch 8): Loss/seq after 02900 batchs: 1389.60888671875
INFO:root:Train (Epoch 8): Loss/seq after 02950 batchs: 1379.9459228515625
INFO:root:Train (Epoch 8): Loss/seq after 03000 batchs: 1375.1334228515625
INFO:root:Train (Epoch 8): Loss/seq after 03050 batchs: 1375.22900390625
INFO:root:Train (Epoch 8): Loss/seq after 03100 batchs: 1391.6669921875
INFO:root:Train (Epoch 8): Loss/seq after 03150 batchs: 1411.0570068359375
INFO:root:Train (Epoch 8): Loss/seq after 03200 batchs: 1424.1920166015625
INFO:root:Train (Epoch 8): Loss/seq after 03250 batchs: 1436.493408203125
INFO:root:Train (Epoch 8): Loss/seq after 03300 batchs: 1434.510498046875
INFO:root:Train (Epoch 8): Loss/seq after 03350 batchs: 1432.4815673828125
INFO:root:Train (Epoch 8): Loss/seq after 03400 batchs: 1420.9537353515625
INFO:root:Train (Epoch 8): Loss/seq after 03450 batchs: 1412.3525390625
INFO:root:Train (Epoch 8): Loss/seq after 03500 batchs: 1410.8409423828125
INFO:root:Train (Epoch 8): Loss/seq after 03550 batchs: 1403.9580078125
INFO:root:Train (Epoch 8): Loss/seq after 03600 batchs: 1407.71533203125
INFO:root:Train (Epoch 8): Loss/seq after 03650 batchs: 1401.8643798828125
INFO:root:Train (Epoch 8): Loss/seq after 03700 batchs: 1399.557861328125
INFO:root:Train (Epoch 8): Loss/seq after 03750 batchs: 1397.3475341796875
INFO:root:Train (Epoch 8): Loss/seq after 03800 batchs: 1388.3377685546875
INFO:root:Train (Epoch 8): Loss/seq after 03850 batchs: 1381.8695068359375
INFO:root:Train (Epoch 8): Loss/seq after 03900 batchs: 1388.7181396484375
INFO:root:Train (Epoch 8): Loss/seq after 03950 batchs: 1397.574951171875
INFO:root:Train (Epoch 8): Loss/seq after 04000 batchs: 1386.5604248046875
INFO:root:Train (Epoch 8): Loss/seq after 04050 batchs: 1376.5150146484375
INFO:root:Train (Epoch 8): Loss/seq after 04100 batchs: 1371.1383056640625
INFO:root:Train (Epoch 8): Loss/seq after 04150 batchs: 1364.3873291015625
INFO:root:Train (Epoch 8): Loss/seq after 04200 batchs: 1358.0596923828125
INFO:root:Train (Epoch 8): Loss/seq after 04250 batchs: 1351.975830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 8): Loss/seq after 00000 batches: 952.1968994140625
INFO:root:# Valid (Epoch 8): Loss/seq after 00050 batches: 1124.562744140625
INFO:root:# Valid (Epoch 8): Loss/seq after 00100 batches: 1461.5120849609375
INFO:root:# Valid (Epoch 8): Loss/seq after 00150 batches: 1223.5948486328125
INFO:root:# Valid (Epoch 8): Loss/seq after 00200 batches: 1113.8270263671875
INFO:root:Artifacts: Make stick videos for epoch 8
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_8_on_20220414_091426.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_8_index_1846_on_20220414_091426.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 9): Loss/seq after 00000 batchs: 2641.463623046875
INFO:root:Train (Epoch 9): Loss/seq after 00050 batchs: 1813.099365234375
INFO:root:Train (Epoch 9): Loss/seq after 00100 batchs: 1807.34423828125
INFO:root:Train (Epoch 9): Loss/seq after 00150 batchs: 1597.9140625
INFO:root:Train (Epoch 9): Loss/seq after 00200 batchs: 1706.7686767578125
INFO:root:Train (Epoch 9): Loss/seq after 00250 batchs: 1809.1007080078125
INFO:root:Train (Epoch 9): Loss/seq after 00300 batchs: 1695.297607421875
INFO:root:Train (Epoch 9): Loss/seq after 00350 batchs: 1579.8238525390625
INFO:root:Train (Epoch 9): Loss/seq after 00400 batchs: 1640.4869384765625
INFO:root:Train (Epoch 9): Loss/seq after 00450 batchs: 1556.1142578125
INFO:root:Train (Epoch 9): Loss/seq after 00500 batchs: 1587.8148193359375
INFO:root:Train (Epoch 9): Loss/seq after 00550 batchs: 1518.9127197265625
INFO:root:Train (Epoch 9): Loss/seq after 00600 batchs: 1482.7890625
INFO:root:Train (Epoch 9): Loss/seq after 00650 batchs: 1543.7374267578125
INFO:root:Train (Epoch 9): Loss/seq after 00700 batchs: 1626.771484375
INFO:root:Train (Epoch 9): Loss/seq after 00750 batchs: 1660.892578125
INFO:root:Train (Epoch 9): Loss/seq after 00800 batchs: 1643.6324462890625
INFO:root:Train (Epoch 9): Loss/seq after 00850 batchs: 1604.9154052734375
INFO:root:Train (Epoch 9): Loss/seq after 00900 batchs: 1607.41357421875
INFO:root:Train (Epoch 9): Loss/seq after 00950 batchs: 1702.6046142578125
INFO:root:Train (Epoch 9): Loss/seq after 01000 batchs: 1701.0269775390625
INFO:root:Train (Epoch 9): Loss/seq after 01050 batchs: 1675.2255859375
INFO:root:Train (Epoch 9): Loss/seq after 01100 batchs: 1658.1407470703125
INFO:root:Train (Epoch 9): Loss/seq after 01150 batchs: 1629.7125244140625
INFO:root:Train (Epoch 9): Loss/seq after 01200 batchs: 1609.403564453125
INFO:root:Train (Epoch 9): Loss/seq after 01250 batchs: 1598.63720703125
INFO:root:Train (Epoch 9): Loss/seq after 01300 batchs: 1609.083984375
INFO:root:Train (Epoch 9): Loss/seq after 01350 batchs: 1608.0281982421875
INFO:root:Train (Epoch 9): Loss/seq after 01400 batchs: 1659.181396484375
INFO:root:Train (Epoch 9): Loss/seq after 01450 batchs: 1639.543701171875
INFO:root:Train (Epoch 9): Loss/seq after 01500 batchs: 1621.2161865234375
INFO:root:Train (Epoch 9): Loss/seq after 01550 batchs: 1617.6868896484375
INFO:root:Train (Epoch 9): Loss/seq after 01600 batchs: 1592.8265380859375
INFO:root:Train (Epoch 9): Loss/seq after 01650 batchs: 1581.2314453125
INFO:root:Train (Epoch 9): Loss/seq after 01700 batchs: 1565.9161376953125
INFO:root:Train (Epoch 9): Loss/seq after 01750 batchs: 1547.2454833984375
INFO:root:Train (Epoch 9): Loss/seq after 01800 batchs: 1527.1761474609375
INFO:root:Train (Epoch 9): Loss/seq after 01850 batchs: 1507.4693603515625
INFO:root:Train (Epoch 9): Loss/seq after 01900 batchs: 1500.7906494140625
INFO:root:Train (Epoch 9): Loss/seq after 01950 batchs: 1490.73095703125
INFO:root:Train (Epoch 9): Loss/seq after 02000 batchs: 1475.8870849609375
INFO:root:Train (Epoch 9): Loss/seq after 02050 batchs: 1463.083251953125
INFO:root:Train (Epoch 9): Loss/seq after 02100 batchs: 1447.2056884765625
INFO:root:Train (Epoch 9): Loss/seq after 02150 batchs: 1433.10693359375
INFO:root:Train (Epoch 9): Loss/seq after 02200 batchs: 1417.676025390625
INFO:root:Train (Epoch 9): Loss/seq after 02250 batchs: 1420.752197265625
INFO:root:Train (Epoch 9): Loss/seq after 02300 batchs: 1422.9229736328125
INFO:root:Train (Epoch 9): Loss/seq after 02350 batchs: 1412.084716796875
INFO:root:Train (Epoch 9): Loss/seq after 02400 batchs: 1404.9906005859375
INFO:root:Train (Epoch 9): Loss/seq after 02450 batchs: 1389.8104248046875
INFO:root:Train (Epoch 9): Loss/seq after 02500 batchs: 1369.47998046875
INFO:root:Train (Epoch 9): Loss/seq after 02550 batchs: 1356.0953369140625
INFO:root:Train (Epoch 9): Loss/seq after 02600 batchs: 1353.2108154296875
INFO:root:Train (Epoch 9): Loss/seq after 02650 batchs: 1346.4462890625
INFO:root:Train (Epoch 9): Loss/seq after 02700 batchs: 1342.0252685546875
INFO:root:Train (Epoch 9): Loss/seq after 02750 batchs: 1372.2977294921875
INFO:root:Train (Epoch 9): Loss/seq after 02800 batchs: 1380.7225341796875
INFO:root:Train (Epoch 9): Loss/seq after 02850 batchs: 1376.510498046875
INFO:root:Train (Epoch 9): Loss/seq after 02900 batchs: 1372.997802734375
INFO:root:Train (Epoch 9): Loss/seq after 02950 batchs: 1363.5
INFO:root:Train (Epoch 9): Loss/seq after 03000 batchs: 1358.928466796875
INFO:root:Train (Epoch 9): Loss/seq after 03050 batchs: 1359.2818603515625
INFO:root:Train (Epoch 9): Loss/seq after 03100 batchs: 1377.2454833984375
INFO:root:Train (Epoch 9): Loss/seq after 03150 batchs: 1396.150146484375
INFO:root:Train (Epoch 9): Loss/seq after 03200 batchs: 1408.972412109375
INFO:root:Train (Epoch 9): Loss/seq after 03250 batchs: 1421.3819580078125
INFO:root:Train (Epoch 9): Loss/seq after 03300 batchs: 1418.8509521484375
INFO:root:Train (Epoch 9): Loss/seq after 03350 batchs: 1416.8233642578125
INFO:root:Train (Epoch 9): Loss/seq after 03400 batchs: 1405.6595458984375
INFO:root:Train (Epoch 9): Loss/seq after 03450 batchs: 1397.201416015625
INFO:root:Train (Epoch 9): Loss/seq after 03500 batchs: 1395.6834716796875
INFO:root:Train (Epoch 9): Loss/seq after 03550 batchs: 1389.1688232421875
INFO:root:Train (Epoch 9): Loss/seq after 03600 batchs: 1393.1241455078125
INFO:root:Train (Epoch 9): Loss/seq after 03650 batchs: 1387.54150390625
INFO:root:Train (Epoch 9): Loss/seq after 03700 batchs: 1385.3504638671875
INFO:root:Train (Epoch 9): Loss/seq after 03750 batchs: 1383.1005859375
INFO:root:Train (Epoch 9): Loss/seq after 03800 batchs: 1374.222412109375
INFO:root:Train (Epoch 9): Loss/seq after 03850 batchs: 1367.91845703125
INFO:root:Train (Epoch 9): Loss/seq after 03900 batchs: 1374.67333984375
INFO:root:Train (Epoch 9): Loss/seq after 03950 batchs: 1383.2073974609375
INFO:root:Train (Epoch 9): Loss/seq after 04000 batchs: 1372.346923828125
INFO:root:Train (Epoch 9): Loss/seq after 04050 batchs: 1362.4810791015625
INFO:root:Train (Epoch 9): Loss/seq after 04100 batchs: 1357.2796630859375
INFO:root:Train (Epoch 9): Loss/seq after 04150 batchs: 1350.700439453125
INFO:root:Train (Epoch 9): Loss/seq after 04200 batchs: 1344.99853515625
INFO:root:Train (Epoch 9): Loss/seq after 04250 batchs: 1339.388671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 9): Loss/seq after 00000 batches: 952.1002197265625
INFO:root:# Valid (Epoch 9): Loss/seq after 00050 batches: 1121.322265625
INFO:root:# Valid (Epoch 9): Loss/seq after 00100 batches: 1490.554443359375
INFO:root:# Valid (Epoch 9): Loss/seq after 00150 batches: 1247.8878173828125
INFO:root:# Valid (Epoch 9): Loss/seq after 00200 batches: 1133.00537109375
INFO:root:Artifacts: Make stick videos for epoch 9
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_9_on_20220414_091954.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_9_index_110_on_20220414_091954.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 10): Loss/seq after 00000 batchs: 2460.167236328125
INFO:root:Train (Epoch 10): Loss/seq after 00050 batchs: 1821.619384765625
INFO:root:Train (Epoch 10): Loss/seq after 00100 batchs: 1796.4232177734375
INFO:root:Train (Epoch 10): Loss/seq after 00150 batchs: 1578.15087890625
INFO:root:Train (Epoch 10): Loss/seq after 00200 batchs: 1695.84228515625
INFO:root:Train (Epoch 10): Loss/seq after 00250 batchs: 1798.1500244140625
INFO:root:Train (Epoch 10): Loss/seq after 00300 batchs: 1684.8951416015625
INFO:root:Train (Epoch 10): Loss/seq after 00350 batchs: 1570.5938720703125
INFO:root:Train (Epoch 10): Loss/seq after 00400 batchs: 1633.2801513671875
INFO:root:Train (Epoch 10): Loss/seq after 00450 batchs: 1549.644775390625
INFO:root:Train (Epoch 10): Loss/seq after 00500 batchs: 1579.0980224609375
INFO:root:Train (Epoch 10): Loss/seq after 00550 batchs: 1512.568115234375
INFO:root:Train (Epoch 10): Loss/seq after 00600 batchs: 1478.0499267578125
INFO:root:Train (Epoch 10): Loss/seq after 00650 batchs: 1539.953369140625
INFO:root:Train (Epoch 10): Loss/seq after 00700 batchs: 1622.485107421875
INFO:root:Train (Epoch 10): Loss/seq after 00750 batchs: 1656.4173583984375
INFO:root:Train (Epoch 10): Loss/seq after 00800 batchs: 1640.200927734375
INFO:root:Train (Epoch 10): Loss/seq after 00850 batchs: 1601.29052734375
INFO:root:Train (Epoch 10): Loss/seq after 00900 batchs: 1604.14599609375
INFO:root:Train (Epoch 10): Loss/seq after 00950 batchs: 1697.3748779296875
INFO:root:Train (Epoch 10): Loss/seq after 01000 batchs: 1695.8675537109375
INFO:root:Train (Epoch 10): Loss/seq after 01050 batchs: 1671.7509765625
INFO:root:Train (Epoch 10): Loss/seq after 01100 batchs: 1654.682373046875
INFO:root:Train (Epoch 10): Loss/seq after 01150 batchs: 1625.7554931640625
INFO:root:Train (Epoch 10): Loss/seq after 01200 batchs: 1606.7227783203125
INFO:root:Train (Epoch 10): Loss/seq after 01250 batchs: 1595.398193359375
INFO:root:Train (Epoch 10): Loss/seq after 01300 batchs: 1605.6407470703125
INFO:root:Train (Epoch 10): Loss/seq after 01350 batchs: 1604.5474853515625
INFO:root:Train (Epoch 10): Loss/seq after 01400 batchs: 1655.20556640625
INFO:root:Train (Epoch 10): Loss/seq after 01450 batchs: 1635.8287353515625
INFO:root:Train (Epoch 10): Loss/seq after 01500 batchs: 1617.2598876953125
INFO:root:Train (Epoch 10): Loss/seq after 01550 batchs: 1614.6962890625
INFO:root:Train (Epoch 10): Loss/seq after 01600 batchs: 1589.5472412109375
INFO:root:Train (Epoch 10): Loss/seq after 01650 batchs: 1577.4295654296875
INFO:root:Train (Epoch 10): Loss/seq after 01700 batchs: 1561.369384765625
INFO:root:Train (Epoch 10): Loss/seq after 01750 batchs: 1543.085205078125
INFO:root:Train (Epoch 10): Loss/seq after 01800 batchs: 1523.416015625
INFO:root:Train (Epoch 10): Loss/seq after 01850 batchs: 1503.70556640625
INFO:root:Train (Epoch 10): Loss/seq after 01900 batchs: 1497.2606201171875
INFO:root:Train (Epoch 10): Loss/seq after 01950 batchs: 1487.2308349609375
INFO:root:Train (Epoch 10): Loss/seq after 02000 batchs: 1472.78955078125
INFO:root:Train (Epoch 10): Loss/seq after 02050 batchs: 1460.1541748046875
INFO:root:Train (Epoch 10): Loss/seq after 02100 batchs: 1444.3424072265625
INFO:root:Train (Epoch 10): Loss/seq after 02150 batchs: 1430.105712890625
INFO:root:Train (Epoch 10): Loss/seq after 02200 batchs: 1414.6444091796875
INFO:root:Train (Epoch 10): Loss/seq after 02250 batchs: 1416.0716552734375
INFO:root:Train (Epoch 10): Loss/seq after 02300 batchs: 1419.316162109375
INFO:root:Train (Epoch 10): Loss/seq after 02350 batchs: 1407.4593505859375
INFO:root:Train (Epoch 10): Loss/seq after 02400 batchs: 1401.0965576171875
INFO:root:Train (Epoch 10): Loss/seq after 02450 batchs: 1386.683837890625
INFO:root:Train (Epoch 10): Loss/seq after 02500 batchs: 1366.4005126953125
INFO:root:Train (Epoch 10): Loss/seq after 02550 batchs: 1358.4981689453125
INFO:root:Train (Epoch 10): Loss/seq after 02600 batchs: 1357.426513671875
INFO:root:Train (Epoch 10): Loss/seq after 02650 batchs: 1352.142333984375
INFO:root:Train (Epoch 10): Loss/seq after 02700 batchs: 1351.647705078125
INFO:root:Train (Epoch 10): Loss/seq after 02750 batchs: 1383.2303466796875
INFO:root:Train (Epoch 10): Loss/seq after 02800 batchs: 1392.322021484375
INFO:root:Train (Epoch 10): Loss/seq after 02850 batchs: 1389.999267578125
INFO:root:Train (Epoch 10): Loss/seq after 02900 batchs: 1387.143798828125
INFO:root:Train (Epoch 10): Loss/seq after 02950 batchs: 1378.0345458984375
INFO:root:Train (Epoch 10): Loss/seq after 03000 batchs: 1373.3614501953125
INFO:root:Train (Epoch 10): Loss/seq after 03050 batchs: 1373.45458984375
INFO:root:Train (Epoch 10): Loss/seq after 03100 batchs: 1389.205322265625
INFO:root:Train (Epoch 10): Loss/seq after 03150 batchs: 1408.0333251953125
INFO:root:Train (Epoch 10): Loss/seq after 03200 batchs: 1420.5531005859375
INFO:root:Train (Epoch 10): Loss/seq after 03250 batchs: 1432.2945556640625
INFO:root:Train (Epoch 10): Loss/seq after 03300 batchs: 1429.4788818359375
INFO:root:Train (Epoch 10): Loss/seq after 03350 batchs: 1427.6746826171875
INFO:root:Train (Epoch 10): Loss/seq after 03400 batchs: 1416.25830078125
INFO:root:Train (Epoch 10): Loss/seq after 03450 batchs: 1407.6866455078125
INFO:root:Train (Epoch 10): Loss/seq after 03500 batchs: 1406.08251953125
INFO:root:Train (Epoch 10): Loss/seq after 03550 batchs: 1399.3818359375
INFO:root:Train (Epoch 10): Loss/seq after 03600 batchs: 1403.157470703125
INFO:root:Train (Epoch 10): Loss/seq after 03650 batchs: 1397.080810546875
INFO:root:Train (Epoch 10): Loss/seq after 03700 batchs: 1394.6578369140625
INFO:root:Train (Epoch 10): Loss/seq after 03750 batchs: 1392.3028564453125
INFO:root:Train (Epoch 10): Loss/seq after 03800 batchs: 1383.3123779296875
INFO:root:Train (Epoch 10): Loss/seq after 03850 batchs: 1376.9188232421875
INFO:root:Train (Epoch 10): Loss/seq after 03900 batchs: 1383.5374755859375
INFO:root:Train (Epoch 10): Loss/seq after 03950 batchs: 1391.3673095703125
INFO:root:Train (Epoch 10): Loss/seq after 04000 batchs: 1380.3873291015625
INFO:root:Train (Epoch 10): Loss/seq after 04050 batchs: 1370.4183349609375
INFO:root:Train (Epoch 10): Loss/seq after 04100 batchs: 1364.8369140625
INFO:root:Train (Epoch 10): Loss/seq after 04150 batchs: 1357.798828125
INFO:root:Train (Epoch 10): Loss/seq after 04200 batchs: 1351.5533447265625
INFO:root:Train (Epoch 10): Loss/seq after 04250 batchs: 1345.7911376953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 10): Loss/seq after 00000 batches: 925.62841796875
INFO:root:# Valid (Epoch 10): Loss/seq after 00050 batches: 1112.0244140625
INFO:root:# Valid (Epoch 10): Loss/seq after 00100 batches: 1432.853271484375
INFO:root:# Valid (Epoch 10): Loss/seq after 00150 batches: 1196.8336181640625
INFO:root:# Valid (Epoch 10): Loss/seq after 00200 batches: 1087.039794921875
INFO:root:Artifacts: Make stick videos for epoch 10
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_10_on_20220414_092521.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_10_index_454_on_20220414_092521.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 11): Loss/seq after 00000 batchs: 2537.489990234375
INFO:root:Train (Epoch 11): Loss/seq after 00050 batchs: 1765.551513671875
INFO:root:Train (Epoch 11): Loss/seq after 00100 batchs: 1745.6309814453125
INFO:root:Train (Epoch 11): Loss/seq after 00150 batchs: 1546.35986328125
INFO:root:Train (Epoch 11): Loss/seq after 00200 batchs: 1666.175537109375
INFO:root:Train (Epoch 11): Loss/seq after 00250 batchs: 1776.1131591796875
INFO:root:Train (Epoch 11): Loss/seq after 00300 batchs: 1666.791015625
INFO:root:Train (Epoch 11): Loss/seq after 00350 batchs: 1555.2188720703125
INFO:root:Train (Epoch 11): Loss/seq after 00400 batchs: 1616.576171875
INFO:root:Train (Epoch 11): Loss/seq after 00450 batchs: 1534.755615234375
INFO:root:Train (Epoch 11): Loss/seq after 00500 batchs: 1569.1162109375
INFO:root:Train (Epoch 11): Loss/seq after 00550 batchs: 1507.6986083984375
INFO:root:Train (Epoch 11): Loss/seq after 00600 batchs: 1477.7154541015625
INFO:root:Train (Epoch 11): Loss/seq after 00650 batchs: 1539.848876953125
INFO:root:Train (Epoch 11): Loss/seq after 00700 batchs: 1621.9290771484375
INFO:root:Train (Epoch 11): Loss/seq after 00750 batchs: 1655.3009033203125
INFO:root:Train (Epoch 11): Loss/seq after 00800 batchs: 1639.38671875
INFO:root:Train (Epoch 11): Loss/seq after 00850 batchs: 1600.821533203125
INFO:root:Train (Epoch 11): Loss/seq after 00900 batchs: 1600.3099365234375
INFO:root:Train (Epoch 11): Loss/seq after 00950 batchs: 1692.5599365234375
INFO:root:Train (Epoch 11): Loss/seq after 01000 batchs: 1690.68994140625
INFO:root:Train (Epoch 11): Loss/seq after 01050 batchs: 1666.1575927734375
INFO:root:Train (Epoch 11): Loss/seq after 01100 batchs: 1649.2547607421875
INFO:root:Train (Epoch 11): Loss/seq after 01150 batchs: 1621.28076171875
INFO:root:Train (Epoch 11): Loss/seq after 01200 batchs: 1599.8231201171875
INFO:root:Train (Epoch 11): Loss/seq after 01250 batchs: 1588.7186279296875
INFO:root:Train (Epoch 11): Loss/seq after 01300 batchs: 1599.676513671875
INFO:root:Train (Epoch 11): Loss/seq after 01350 batchs: 1598.62353515625
INFO:root:Train (Epoch 11): Loss/seq after 01400 batchs: 1648.36279296875
INFO:root:Train (Epoch 11): Loss/seq after 01450 batchs: 1629.052490234375
INFO:root:Train (Epoch 11): Loss/seq after 01500 batchs: 1610.406494140625
INFO:root:Train (Epoch 11): Loss/seq after 01550 batchs: 1606.7467041015625
INFO:root:Train (Epoch 11): Loss/seq after 01600 batchs: 1581.754638671875
INFO:root:Train (Epoch 11): Loss/seq after 01650 batchs: 1569.43310546875
INFO:root:Train (Epoch 11): Loss/seq after 01700 batchs: 1554.118408203125
INFO:root:Train (Epoch 11): Loss/seq after 01750 batchs: 1535.87353515625
INFO:root:Train (Epoch 11): Loss/seq after 01800 batchs: 1516.4581298828125
INFO:root:Train (Epoch 11): Loss/seq after 01850 batchs: 1496.9642333984375
INFO:root:Train (Epoch 11): Loss/seq after 01900 batchs: 1490.571044921875
INFO:root:Train (Epoch 11): Loss/seq after 01950 batchs: 1480.64013671875
INFO:root:Train (Epoch 11): Loss/seq after 02000 batchs: 1466.1895751953125
INFO:root:Train (Epoch 11): Loss/seq after 02050 batchs: 1453.6448974609375
INFO:root:Train (Epoch 11): Loss/seq after 02100 batchs: 1437.974365234375
INFO:root:Train (Epoch 11): Loss/seq after 02150 batchs: 1423.974365234375
INFO:root:Train (Epoch 11): Loss/seq after 02200 batchs: 1408.7216796875
INFO:root:Train (Epoch 11): Loss/seq after 02250 batchs: 1410.0455322265625
INFO:root:Train (Epoch 11): Loss/seq after 02300 batchs: 1411.646240234375
INFO:root:Train (Epoch 11): Loss/seq after 02350 batchs: 1399.6470947265625
INFO:root:Train (Epoch 11): Loss/seq after 02400 batchs: 1393.13427734375
INFO:root:Train (Epoch 11): Loss/seq after 02450 batchs: 1378.3646240234375
INFO:root:Train (Epoch 11): Loss/seq after 02500 batchs: 1358.3050537109375
INFO:root:Train (Epoch 11): Loss/seq after 02550 batchs: 1345.7767333984375
INFO:root:Train (Epoch 11): Loss/seq after 02600 batchs: 1344.099853515625
INFO:root:Train (Epoch 11): Loss/seq after 02650 batchs: 1338.7418212890625
INFO:root:Train (Epoch 11): Loss/seq after 02700 batchs: 1335.6527099609375
INFO:root:Train (Epoch 11): Loss/seq after 02750 batchs: 1366.1519775390625
INFO:root:Train (Epoch 11): Loss/seq after 02800 batchs: 1374.6507568359375
INFO:root:Train (Epoch 11): Loss/seq after 02850 batchs: 1370.7178955078125
INFO:root:Train (Epoch 11): Loss/seq after 02900 batchs: 1367.626220703125
INFO:root:Train (Epoch 11): Loss/seq after 02950 batchs: 1358.3223876953125
INFO:root:Train (Epoch 11): Loss/seq after 03000 batchs: 1353.830322265625
INFO:root:Train (Epoch 11): Loss/seq after 03050 batchs: 1354.248291015625
INFO:root:Train (Epoch 11): Loss/seq after 03100 batchs: 1370.0037841796875
INFO:root:Train (Epoch 11): Loss/seq after 03150 batchs: 1388.359130859375
INFO:root:Train (Epoch 11): Loss/seq after 03200 batchs: 1401.214111328125
INFO:root:Train (Epoch 11): Loss/seq after 03250 batchs: 1413.3245849609375
INFO:root:Train (Epoch 11): Loss/seq after 03300 batchs: 1410.5673828125
INFO:root:Train (Epoch 11): Loss/seq after 03350 batchs: 1408.874755859375
INFO:root:Train (Epoch 11): Loss/seq after 03400 batchs: 1397.719970703125
INFO:root:Train (Epoch 11): Loss/seq after 03450 batchs: 1389.16650390625
INFO:root:Train (Epoch 11): Loss/seq after 03500 batchs: 1388.052734375
INFO:root:Train (Epoch 11): Loss/seq after 03550 batchs: 1381.5943603515625
INFO:root:Train (Epoch 11): Loss/seq after 03600 batchs: 1385.590576171875
INFO:root:Train (Epoch 11): Loss/seq after 03650 batchs: 1380.0804443359375
INFO:root:Train (Epoch 11): Loss/seq after 03700 batchs: 1378.1629638671875
INFO:root:Train (Epoch 11): Loss/seq after 03750 batchs: 1376.0230712890625
INFO:root:Train (Epoch 11): Loss/seq after 03800 batchs: 1367.32470703125
INFO:root:Train (Epoch 11): Loss/seq after 03850 batchs: 1361.2166748046875
INFO:root:Train (Epoch 11): Loss/seq after 03900 batchs: 1367.762939453125
INFO:root:Train (Epoch 11): Loss/seq after 03950 batchs: 1375.6856689453125
INFO:root:Train (Epoch 11): Loss/seq after 04000 batchs: 1364.8875732421875
INFO:root:Train (Epoch 11): Loss/seq after 04050 batchs: 1355.0968017578125
INFO:root:Train (Epoch 11): Loss/seq after 04100 batchs: 1349.759765625
INFO:root:Train (Epoch 11): Loss/seq after 04150 batchs: 1342.84814453125
INFO:root:Train (Epoch 11): Loss/seq after 04200 batchs: 1336.97802734375
INFO:root:Train (Epoch 11): Loss/seq after 04250 batchs: 1331.4365234375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 11): Loss/seq after 00000 batches: 929.0455322265625
INFO:root:# Valid (Epoch 11): Loss/seq after 00050 batches: 1114.2197265625
INFO:root:# Valid (Epoch 11): Loss/seq after 00100 batches: 1446.163330078125
INFO:root:# Valid (Epoch 11): Loss/seq after 00150 batches: 1209.810546875
INFO:root:# Valid (Epoch 11): Loss/seq after 00200 batches: 1099.5997314453125
INFO:root:Artifacts: Make stick videos for epoch 11
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_11_on_20220414_093048.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_11_index_130_on_20220414_093048.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 12): Loss/seq after 00000 batchs: 2637.64306640625
INFO:root:Train (Epoch 12): Loss/seq after 00050 batchs: 1769.6634521484375
INFO:root:Train (Epoch 12): Loss/seq after 00100 batchs: 1743.3587646484375
INFO:root:Train (Epoch 12): Loss/seq after 00150 batchs: 1543.9337158203125
INFO:root:Train (Epoch 12): Loss/seq after 00200 batchs: 1665.7735595703125
INFO:root:Train (Epoch 12): Loss/seq after 00250 batchs: 1780.5537109375
INFO:root:Train (Epoch 12): Loss/seq after 00300 batchs: 1669.6964111328125
INFO:root:Train (Epoch 12): Loss/seq after 00350 batchs: 1558.02099609375
INFO:root:Train (Epoch 12): Loss/seq after 00400 batchs: 1619.9520263671875
INFO:root:Train (Epoch 12): Loss/seq after 00450 batchs: 1537.6845703125
INFO:root:Train (Epoch 12): Loss/seq after 00500 batchs: 1568.4072265625
INFO:root:Train (Epoch 12): Loss/seq after 00550 batchs: 1502.368896484375
INFO:root:Train (Epoch 12): Loss/seq after 00600 batchs: 1467.883544921875
INFO:root:Train (Epoch 12): Loss/seq after 00650 batchs: 1527.54052734375
INFO:root:Train (Epoch 12): Loss/seq after 00700 batchs: 1607.939453125
INFO:root:Train (Epoch 12): Loss/seq after 00750 batchs: 1641.4039306640625
INFO:root:Train (Epoch 12): Loss/seq after 00800 batchs: 1625.4659423828125
INFO:root:Train (Epoch 12): Loss/seq after 00850 batchs: 1587.9625244140625
INFO:root:Train (Epoch 12): Loss/seq after 00900 batchs: 1586.91357421875
INFO:root:Train (Epoch 12): Loss/seq after 00950 batchs: 1678.6649169921875
INFO:root:Train (Epoch 12): Loss/seq after 01000 batchs: 1675.5850830078125
INFO:root:Train (Epoch 12): Loss/seq after 01050 batchs: 1650.9820556640625
INFO:root:Train (Epoch 12): Loss/seq after 01100 batchs: 1634.816162109375
INFO:root:Train (Epoch 12): Loss/seq after 01150 batchs: 1607.3507080078125
INFO:root:Train (Epoch 12): Loss/seq after 01200 batchs: 1586.8150634765625
INFO:root:Train (Epoch 12): Loss/seq after 01250 batchs: 1575.8023681640625
INFO:root:Train (Epoch 12): Loss/seq after 01300 batchs: 1586.8548583984375
INFO:root:Train (Epoch 12): Loss/seq after 01350 batchs: 1586.1822509765625
INFO:root:Train (Epoch 12): Loss/seq after 01400 batchs: 1634.403564453125
INFO:root:Train (Epoch 12): Loss/seq after 01450 batchs: 1615.03173828125
INFO:root:Train (Epoch 12): Loss/seq after 01500 batchs: 1596.7904052734375
INFO:root:Train (Epoch 12): Loss/seq after 01550 batchs: 1594.1571044921875
INFO:root:Train (Epoch 12): Loss/seq after 01600 batchs: 1569.6978759765625
INFO:root:Train (Epoch 12): Loss/seq after 01650 batchs: 1558.2421875
INFO:root:Train (Epoch 12): Loss/seq after 01700 batchs: 1543.6156005859375
INFO:root:Train (Epoch 12): Loss/seq after 01750 batchs: 1525.5198974609375
INFO:root:Train (Epoch 12): Loss/seq after 01800 batchs: 1506.4278564453125
INFO:root:Train (Epoch 12): Loss/seq after 01850 batchs: 1487.1768798828125
INFO:root:Train (Epoch 12): Loss/seq after 01900 batchs: 1480.98095703125
INFO:root:Train (Epoch 12): Loss/seq after 01950 batchs: 1471.2677001953125
INFO:root:Train (Epoch 12): Loss/seq after 02000 batchs: 1456.9935302734375
INFO:root:Train (Epoch 12): Loss/seq after 02050 batchs: 1444.6754150390625
INFO:root:Train (Epoch 12): Loss/seq after 02100 batchs: 1429.2142333984375
INFO:root:Train (Epoch 12): Loss/seq after 02150 batchs: 1415.2725830078125
INFO:root:Train (Epoch 12): Loss/seq after 02200 batchs: 1400.2191162109375
INFO:root:Train (Epoch 12): Loss/seq after 02250 batchs: 1401.8480224609375
INFO:root:Train (Epoch 12): Loss/seq after 02300 batchs: 1404.060546875
INFO:root:Train (Epoch 12): Loss/seq after 02350 batchs: 1392.197021484375
INFO:root:Train (Epoch 12): Loss/seq after 02400 batchs: 1385.890625
INFO:root:Train (Epoch 12): Loss/seq after 02450 batchs: 1371.3233642578125
INFO:root:Train (Epoch 12): Loss/seq after 02500 batchs: 1351.439697265625
INFO:root:Train (Epoch 12): Loss/seq after 02550 batchs: 1339.9368896484375
INFO:root:Train (Epoch 12): Loss/seq after 02600 batchs: 1338.159423828125
INFO:root:Train (Epoch 12): Loss/seq after 02650 batchs: 1332.7589111328125
INFO:root:Train (Epoch 12): Loss/seq after 02700 batchs: 1330.350830078125
INFO:root:Train (Epoch 12): Loss/seq after 02750 batchs: 1360.51953125
INFO:root:Train (Epoch 12): Loss/seq after 02800 batchs: 1369.2305908203125
INFO:root:Train (Epoch 12): Loss/seq after 02850 batchs: 1365.4534912109375
INFO:root:Train (Epoch 12): Loss/seq after 02900 batchs: 1361.99462890625
INFO:root:Train (Epoch 12): Loss/seq after 02950 batchs: 1352.7347412109375
INFO:root:Train (Epoch 12): Loss/seq after 03000 batchs: 1348.3465576171875
INFO:root:Train (Epoch 12): Loss/seq after 03050 batchs: 1348.8472900390625
INFO:root:Train (Epoch 12): Loss/seq after 03100 batchs: 1365.034423828125
INFO:root:Train (Epoch 12): Loss/seq after 03150 batchs: 1382.3717041015625
INFO:root:Train (Epoch 12): Loss/seq after 03200 batchs: 1393.483642578125
INFO:root:Train (Epoch 12): Loss/seq after 03250 batchs: 1404.385498046875
INFO:root:Train (Epoch 12): Loss/seq after 03300 batchs: 1402.5125732421875
INFO:root:Train (Epoch 12): Loss/seq after 03350 batchs: 1401.1700439453125
INFO:root:Train (Epoch 12): Loss/seq after 03400 batchs: 1390.287841796875
INFO:root:Train (Epoch 12): Loss/seq after 03450 batchs: 1382.5374755859375
INFO:root:Train (Epoch 12): Loss/seq after 03500 batchs: 1380.952392578125
INFO:root:Train (Epoch 12): Loss/seq after 03550 batchs: 1374.2679443359375
INFO:root:Train (Epoch 12): Loss/seq after 03600 batchs: 1378.2486572265625
INFO:root:Train (Epoch 12): Loss/seq after 03650 batchs: 1372.6591796875
INFO:root:Train (Epoch 12): Loss/seq after 03700 batchs: 1370.7027587890625
INFO:root:Train (Epoch 12): Loss/seq after 03750 batchs: 1368.68994140625
INFO:root:Train (Epoch 12): Loss/seq after 03800 batchs: 1359.982177734375
INFO:root:Train (Epoch 12): Loss/seq after 03850 batchs: 1353.868896484375
INFO:root:Train (Epoch 12): Loss/seq after 03900 batchs: 1360.107666015625
INFO:root:Train (Epoch 12): Loss/seq after 03950 batchs: 1367.0018310546875
INFO:root:Train (Epoch 12): Loss/seq after 04000 batchs: 1356.3345947265625
INFO:root:Train (Epoch 12): Loss/seq after 04050 batchs: 1346.6875
INFO:root:Train (Epoch 12): Loss/seq after 04100 batchs: 1340.9378662109375
INFO:root:Train (Epoch 12): Loss/seq after 04150 batchs: 1333.81884765625
INFO:root:Train (Epoch 12): Loss/seq after 04200 batchs: 1327.5892333984375
INFO:root:Train (Epoch 12): Loss/seq after 04250 batchs: 1322.0408935546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 12): Loss/seq after 00000 batches: 916.3858032226562
INFO:root:# Valid (Epoch 12): Loss/seq after 00050 batches: 1111.0908203125
INFO:root:# Valid (Epoch 12): Loss/seq after 00100 batches: 1444.3961181640625
INFO:root:# Valid (Epoch 12): Loss/seq after 00150 batches: 1215.322021484375
INFO:root:# Valid (Epoch 12): Loss/seq after 00200 batches: 1106.886962890625
INFO:root:Artifacts: Make stick videos for epoch 12
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_12_on_20220414_093616.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_12_index_434_on_20220414_093616.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 13): Loss/seq after 00000 batchs: 2711.322265625
INFO:root:Train (Epoch 13): Loss/seq after 00050 batchs: 1811.9912109375
INFO:root:Train (Epoch 13): Loss/seq after 00100 batchs: 1746.26220703125
INFO:root:Train (Epoch 13): Loss/seq after 00150 batchs: 1539.2122802734375
INFO:root:Train (Epoch 13): Loss/seq after 00200 batchs: 1658.23779296875
INFO:root:Train (Epoch 13): Loss/seq after 00250 batchs: 1774.4327392578125
INFO:root:Train (Epoch 13): Loss/seq after 00300 batchs: 1664.0234375
INFO:root:Train (Epoch 13): Loss/seq after 00350 batchs: 1552.087646484375
INFO:root:Train (Epoch 13): Loss/seq after 00400 batchs: 1613.57421875
INFO:root:Train (Epoch 13): Loss/seq after 00450 batchs: 1532.2242431640625
INFO:root:Train (Epoch 13): Loss/seq after 00500 batchs: 1564.9708251953125
INFO:root:Train (Epoch 13): Loss/seq after 00550 batchs: 1498.6568603515625
INFO:root:Train (Epoch 13): Loss/seq after 00600 batchs: 1462.169677734375
INFO:root:Train (Epoch 13): Loss/seq after 00650 batchs: 1502.8958740234375
INFO:root:Train (Epoch 13): Loss/seq after 00700 batchs: 1568.91357421875
INFO:root:Train (Epoch 13): Loss/seq after 00750 batchs: 1606.4822998046875
INFO:root:Train (Epoch 13): Loss/seq after 00800 batchs: 1591.694580078125
INFO:root:Train (Epoch 13): Loss/seq after 00850 batchs: 1556.9697265625
INFO:root:Train (Epoch 13): Loss/seq after 00900 batchs: 1558.1761474609375
INFO:root:Train (Epoch 13): Loss/seq after 00950 batchs: 1640.9227294921875
INFO:root:Train (Epoch 13): Loss/seq after 01000 batchs: 1639.0701904296875
INFO:root:Train (Epoch 13): Loss/seq after 01050 batchs: 1616.2615966796875
INFO:root:Train (Epoch 13): Loss/seq after 01100 batchs: 1602.7691650390625
INFO:root:Train (Epoch 13): Loss/seq after 01150 batchs: 1577.1044921875
INFO:root:Train (Epoch 13): Loss/seq after 01200 batchs: 1559.1458740234375
INFO:root:Train (Epoch 13): Loss/seq after 01250 batchs: 1548.6953125
INFO:root:Train (Epoch 13): Loss/seq after 01300 batchs: 1557.459716796875
INFO:root:Train (Epoch 13): Loss/seq after 01350 batchs: 1555.7099609375
INFO:root:Train (Epoch 13): Loss/seq after 01400 batchs: 1594.1591796875
INFO:root:Train (Epoch 13): Loss/seq after 01450 batchs: 1575.9134521484375
INFO:root:Train (Epoch 13): Loss/seq after 01500 batchs: 1558.7330322265625
INFO:root:Train (Epoch 13): Loss/seq after 01550 batchs: 1557.319091796875
INFO:root:Train (Epoch 13): Loss/seq after 01600 batchs: 1533.90234375
INFO:root:Train (Epoch 13): Loss/seq after 01650 batchs: 1523.251953125
INFO:root:Train (Epoch 13): Loss/seq after 01700 batchs: 1509.232177734375
INFO:root:Train (Epoch 13): Loss/seq after 01750 batchs: 1491.996337890625
INFO:root:Train (Epoch 13): Loss/seq after 01800 batchs: 1473.0267333984375
INFO:root:Train (Epoch 13): Loss/seq after 01850 batchs: 1454.793212890625
INFO:root:Train (Epoch 13): Loss/seq after 01900 batchs: 1449.4620361328125
INFO:root:Train (Epoch 13): Loss/seq after 01950 batchs: 1440.721923828125
INFO:root:Train (Epoch 13): Loss/seq after 02000 batchs: 1427.179443359375
INFO:root:Train (Epoch 13): Loss/seq after 02050 batchs: 1415.5283203125
INFO:root:Train (Epoch 13): Loss/seq after 02100 batchs: 1400.7529296875
INFO:root:Train (Epoch 13): Loss/seq after 02150 batchs: 1387.3629150390625
INFO:root:Train (Epoch 13): Loss/seq after 02200 batchs: 1372.9066162109375
INFO:root:Train (Epoch 13): Loss/seq after 02250 batchs: 1376.18408203125
INFO:root:Train (Epoch 13): Loss/seq after 02300 batchs: 1378.67529296875
INFO:root:Train (Epoch 13): Loss/seq after 02350 batchs: 1367.349365234375
INFO:root:Train (Epoch 13): Loss/seq after 02400 batchs: 1361.5323486328125
INFO:root:Train (Epoch 13): Loss/seq after 02450 batchs: 1347.6087646484375
INFO:root:Train (Epoch 13): Loss/seq after 02500 batchs: 1328.233642578125
INFO:root:Train (Epoch 13): Loss/seq after 02550 batchs: 1317.4136962890625
INFO:root:Train (Epoch 13): Loss/seq after 02600 batchs: 1316.0218505859375
INFO:root:Train (Epoch 13): Loss/seq after 02650 batchs: 1310.740234375
INFO:root:Train (Epoch 13): Loss/seq after 02700 batchs: 1308.7861328125
INFO:root:Train (Epoch 13): Loss/seq after 02750 batchs: 1339.6944580078125
INFO:root:Train (Epoch 13): Loss/seq after 02800 batchs: 1348.73779296875
INFO:root:Train (Epoch 13): Loss/seq after 02850 batchs: 1345.0638427734375
INFO:root:Train (Epoch 13): Loss/seq after 02900 batchs: 1342.024658203125
INFO:root:Train (Epoch 13): Loss/seq after 02950 batchs: 1332.8272705078125
INFO:root:Train (Epoch 13): Loss/seq after 03000 batchs: 1328.76708984375
INFO:root:Train (Epoch 13): Loss/seq after 03050 batchs: 1329.5518798828125
INFO:root:Train (Epoch 13): Loss/seq after 03100 batchs: 1344.1072998046875
INFO:root:Train (Epoch 13): Loss/seq after 03150 batchs: 1361.6676025390625
INFO:root:Train (Epoch 13): Loss/seq after 03200 batchs: 1371.0645751953125
INFO:root:Train (Epoch 13): Loss/seq after 03250 batchs: 1378.606689453125
INFO:root:Train (Epoch 13): Loss/seq after 03300 batchs: 1376.922607421875
INFO:root:Train (Epoch 13): Loss/seq after 03350 batchs: 1376.3759765625
INFO:root:Train (Epoch 13): Loss/seq after 03400 batchs: 1365.6798095703125
INFO:root:Train (Epoch 13): Loss/seq after 03450 batchs: 1357.50830078125
INFO:root:Train (Epoch 13): Loss/seq after 03500 batchs: 1356.9637451171875
INFO:root:Train (Epoch 13): Loss/seq after 03550 batchs: 1351.425537109375
INFO:root:Train (Epoch 13): Loss/seq after 03600 batchs: 1355.919189453125
INFO:root:Train (Epoch 13): Loss/seq after 03650 batchs: 1350.78564453125
INFO:root:Train (Epoch 13): Loss/seq after 03700 batchs: 1349.0093994140625
INFO:root:Train (Epoch 13): Loss/seq after 03750 batchs: 1347.225830078125
INFO:root:Train (Epoch 13): Loss/seq after 03800 batchs: 1338.749267578125
INFO:root:Train (Epoch 13): Loss/seq after 03850 batchs: 1332.8128662109375
INFO:root:Train (Epoch 13): Loss/seq after 03900 batchs: 1338.312255859375
INFO:root:Train (Epoch 13): Loss/seq after 03950 batchs: 1344.7322998046875
INFO:root:Train (Epoch 13): Loss/seq after 04000 batchs: 1334.3157958984375
INFO:root:Train (Epoch 13): Loss/seq after 04050 batchs: 1324.91162109375
INFO:root:Train (Epoch 13): Loss/seq after 04100 batchs: 1319.3116455078125
INFO:root:Train (Epoch 13): Loss/seq after 04150 batchs: 1312.3443603515625
INFO:root:Train (Epoch 13): Loss/seq after 04200 batchs: 1306.3951416015625
INFO:root:Train (Epoch 13): Loss/seq after 04250 batchs: 1301.00537109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 13): Loss/seq after 00000 batches: 918.2811279296875
INFO:root:# Valid (Epoch 13): Loss/seq after 00050 batches: 1109.466796875
INFO:root:# Valid (Epoch 13): Loss/seq after 00100 batches: 1423.62548828125
INFO:root:# Valid (Epoch 13): Loss/seq after 00150 batches: 1166.5869140625
INFO:root:# Valid (Epoch 13): Loss/seq after 00200 batches: 1055.1907958984375
INFO:root:Artifacts: Make stick videos for epoch 13
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_13_on_20220414_094142.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_13_index_750_on_20220414_094142.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 14): Loss/seq after 00000 batchs: 2167.5107421875
INFO:root:Train (Epoch 14): Loss/seq after 00050 batchs: 1756.611083984375
INFO:root:Train (Epoch 14): Loss/seq after 00100 batchs: 1717.3084716796875
INFO:root:Train (Epoch 14): Loss/seq after 00150 batchs: 1526.537841796875
INFO:root:Train (Epoch 14): Loss/seq after 00200 batchs: 1650.371826171875
INFO:root:Train (Epoch 14): Loss/seq after 00250 batchs: 1760.622802734375
INFO:root:Train (Epoch 14): Loss/seq after 00300 batchs: 1652.6929931640625
INFO:root:Train (Epoch 14): Loss/seq after 00350 batchs: 1543.3155517578125
INFO:root:Train (Epoch 14): Loss/seq after 00400 batchs: 1593.0633544921875
INFO:root:Train (Epoch 14): Loss/seq after 00450 batchs: 1513.7296142578125
INFO:root:Train (Epoch 14): Loss/seq after 00500 batchs: 1544.4576416015625
INFO:root:Train (Epoch 14): Loss/seq after 00550 batchs: 1480.4593505859375
INFO:root:Train (Epoch 14): Loss/seq after 00600 batchs: 1444.408935546875
INFO:root:Train (Epoch 14): Loss/seq after 00650 batchs: 1485.6954345703125
INFO:root:Train (Epoch 14): Loss/seq after 00700 batchs: 1530.5421142578125
INFO:root:Train (Epoch 14): Loss/seq after 00750 batchs: 1569.26806640625
INFO:root:Train (Epoch 14): Loss/seq after 00800 batchs: 1556.8607177734375
INFO:root:Train (Epoch 14): Loss/seq after 00850 batchs: 1523.738037109375
INFO:root:Train (Epoch 14): Loss/seq after 00900 batchs: 1526.3201904296875
INFO:root:Train (Epoch 14): Loss/seq after 00950 batchs: 1597.29541015625
INFO:root:Train (Epoch 14): Loss/seq after 01000 batchs: 1593.4915771484375
INFO:root:Train (Epoch 14): Loss/seq after 01050 batchs: 1571.84814453125
INFO:root:Train (Epoch 14): Loss/seq after 01100 batchs: 1559.51513671875
INFO:root:Train (Epoch 14): Loss/seq after 01150 batchs: 1535.4232177734375
INFO:root:Train (Epoch 14): Loss/seq after 01200 batchs: 1517.9652099609375
INFO:root:Train (Epoch 14): Loss/seq after 01250 batchs: 1508.322265625
INFO:root:Train (Epoch 14): Loss/seq after 01300 batchs: 1517.6671142578125
INFO:root:Train (Epoch 14): Loss/seq after 01350 batchs: 1517.7578125
INFO:root:Train (Epoch 14): Loss/seq after 01400 batchs: 1554.8656005859375
INFO:root:Train (Epoch 14): Loss/seq after 01450 batchs: 1538.0811767578125
INFO:root:Train (Epoch 14): Loss/seq after 01500 batchs: 1522.3074951171875
INFO:root:Train (Epoch 14): Loss/seq after 01550 batchs: 1523.249267578125
INFO:root:Train (Epoch 14): Loss/seq after 01600 batchs: 1501.5614013671875
INFO:root:Train (Epoch 14): Loss/seq after 01650 batchs: 1492.03125
INFO:root:Train (Epoch 14): Loss/seq after 01700 batchs: 1478.921142578125
INFO:root:Train (Epoch 14): Loss/seq after 01750 batchs: 1462.3428955078125
INFO:root:Train (Epoch 14): Loss/seq after 01800 batchs: 1444.2335205078125
INFO:root:Train (Epoch 14): Loss/seq after 01850 batchs: 1426.7716064453125
INFO:root:Train (Epoch 14): Loss/seq after 01900 batchs: 1421.955810546875
INFO:root:Train (Epoch 14): Loss/seq after 01950 batchs: 1413.8548583984375
INFO:root:Train (Epoch 14): Loss/seq after 02000 batchs: 1400.8931884765625
INFO:root:Train (Epoch 14): Loss/seq after 02050 batchs: 1389.7744140625
INFO:root:Train (Epoch 14): Loss/seq after 02100 batchs: 1375.5230712890625
INFO:root:Train (Epoch 14): Loss/seq after 02150 batchs: 1362.5458984375
INFO:root:Train (Epoch 14): Loss/seq after 02200 batchs: 1348.630859375
INFO:root:Train (Epoch 14): Loss/seq after 02250 batchs: 1352.639892578125
INFO:root:Train (Epoch 14): Loss/seq after 02300 batchs: 1356.153076171875
INFO:root:Train (Epoch 14): Loss/seq after 02350 batchs: 1344.871337890625
INFO:root:Train (Epoch 14): Loss/seq after 02400 batchs: 1339.044677734375
INFO:root:Train (Epoch 14): Loss/seq after 02450 batchs: 1324.9376220703125
INFO:root:Train (Epoch 14): Loss/seq after 02500 batchs: 1305.8079833984375
INFO:root:Train (Epoch 14): Loss/seq after 02550 batchs: 1293.510986328125
INFO:root:Train (Epoch 14): Loss/seq after 02600 batchs: 1290.587646484375
INFO:root:Train (Epoch 14): Loss/seq after 02650 batchs: 1284.662353515625
INFO:root:Train (Epoch 14): Loss/seq after 02700 batchs: 1282.25341796875
INFO:root:Train (Epoch 14): Loss/seq after 02750 batchs: 1313.012939453125
INFO:root:Train (Epoch 14): Loss/seq after 02800 batchs: 1321.842041015625
INFO:root:Train (Epoch 14): Loss/seq after 02850 batchs: 1318.6104736328125
INFO:root:Train (Epoch 14): Loss/seq after 02900 batchs: 1315.93994140625
INFO:root:Train (Epoch 14): Loss/seq after 02950 batchs: 1307.262451171875
INFO:root:Train (Epoch 14): Loss/seq after 03000 batchs: 1303.613037109375
INFO:root:Train (Epoch 14): Loss/seq after 03050 batchs: 1304.7491455078125
INFO:root:Train (Epoch 14): Loss/seq after 03100 batchs: 1319.8006591796875
INFO:root:Train (Epoch 14): Loss/seq after 03150 batchs: 1337.2900390625
INFO:root:Train (Epoch 14): Loss/seq after 03200 batchs: 1345.4981689453125
INFO:root:Train (Epoch 14): Loss/seq after 03250 batchs: 1352.3433837890625
INFO:root:Train (Epoch 14): Loss/seq after 03300 batchs: 1352.3323974609375
INFO:root:Train (Epoch 14): Loss/seq after 03350 batchs: 1351.8106689453125
INFO:root:Train (Epoch 14): Loss/seq after 03400 batchs: 1341.4404296875
INFO:root:Train (Epoch 14): Loss/seq after 03450 batchs: 1333.232421875
INFO:root:Train (Epoch 14): Loss/seq after 03500 batchs: 1332.491943359375
INFO:root:Train (Epoch 14): Loss/seq after 03550 batchs: 1326.903564453125
INFO:root:Train (Epoch 14): Loss/seq after 03600 batchs: 1331.467529296875
INFO:root:Train (Epoch 14): Loss/seq after 03650 batchs: 1326.1220703125
INFO:root:Train (Epoch 14): Loss/seq after 03700 batchs: 1324.5615234375
INFO:root:Train (Epoch 14): Loss/seq after 03750 batchs: 1323.1322021484375
INFO:root:Train (Epoch 14): Loss/seq after 03800 batchs: 1314.9459228515625
INFO:root:Train (Epoch 14): Loss/seq after 03850 batchs: 1309.293701171875
INFO:root:Train (Epoch 14): Loss/seq after 03900 batchs: 1315.3951416015625
INFO:root:Train (Epoch 14): Loss/seq after 03950 batchs: 1321.9613037109375
INFO:root:Train (Epoch 14): Loss/seq after 04000 batchs: 1311.781982421875
INFO:root:Train (Epoch 14): Loss/seq after 04050 batchs: 1302.6375732421875
INFO:root:Train (Epoch 14): Loss/seq after 04100 batchs: 1297.0220947265625
INFO:root:Train (Epoch 14): Loss/seq after 04150 batchs: 1290.2916259765625
INFO:root:Train (Epoch 14): Loss/seq after 04200 batchs: 1284.4931640625
INFO:root:Train (Epoch 14): Loss/seq after 04250 batchs: 1279.181884765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 14): Loss/seq after 00000 batches: 912.7546997070312
INFO:root:# Valid (Epoch 14): Loss/seq after 00050 batches: 1107.7786865234375
INFO:root:# Valid (Epoch 14): Loss/seq after 00100 batches: 1419.200927734375
INFO:root:# Valid (Epoch 14): Loss/seq after 00150 batches: 1156.3206787109375
INFO:root:# Valid (Epoch 14): Loss/seq after 00200 batches: 1043.0684814453125
INFO:root:Artifacts: Make stick videos for epoch 14
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_14_on_20220414_094709.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_14_index_1297_on_20220414_094709.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 15): Loss/seq after 00000 batchs: 2240.39990234375
INFO:root:Train (Epoch 15): Loss/seq after 00050 batchs: 1727.5701904296875
INFO:root:Train (Epoch 15): Loss/seq after 00100 batchs: 1689.635498046875
INFO:root:Train (Epoch 15): Loss/seq after 00150 batchs: 1499.3055419921875
INFO:root:Train (Epoch 15): Loss/seq after 00200 batchs: 1616.2108154296875
INFO:root:Train (Epoch 15): Loss/seq after 00250 batchs: 1733.0323486328125
INFO:root:Train (Epoch 15): Loss/seq after 00300 batchs: 1629.6151123046875
INFO:root:Train (Epoch 15): Loss/seq after 00350 batchs: 1522.633056640625
INFO:root:Train (Epoch 15): Loss/seq after 00400 batchs: 1576.8048095703125
INFO:root:Train (Epoch 15): Loss/seq after 00450 batchs: 1499.4263916015625
INFO:root:Train (Epoch 15): Loss/seq after 00500 batchs: 1530.3511962890625
INFO:root:Train (Epoch 15): Loss/seq after 00550 batchs: 1466.0050048828125
INFO:root:Train (Epoch 15): Loss/seq after 00600 batchs: 1431.254150390625
INFO:root:Train (Epoch 15): Loss/seq after 00650 batchs: 1470.74072265625
INFO:root:Train (Epoch 15): Loss/seq after 00700 batchs: 1503.1419677734375
INFO:root:Train (Epoch 15): Loss/seq after 00750 batchs: 1541.58984375
INFO:root:Train (Epoch 15): Loss/seq after 00800 batchs: 1530.42236328125
INFO:root:Train (Epoch 15): Loss/seq after 00850 batchs: 1498.70166015625
INFO:root:Train (Epoch 15): Loss/seq after 00900 batchs: 1502.644287109375
INFO:root:Train (Epoch 15): Loss/seq after 00950 batchs: 1573.0155029296875
INFO:root:Train (Epoch 15): Loss/seq after 01000 batchs: 1571.7769775390625
INFO:root:Train (Epoch 15): Loss/seq after 01050 batchs: 1550.8770751953125
INFO:root:Train (Epoch 15): Loss/seq after 01100 batchs: 1543.5318603515625
INFO:root:Train (Epoch 15): Loss/seq after 01150 batchs: 1519.277587890625
INFO:root:Train (Epoch 15): Loss/seq after 01200 batchs: 1501.8370361328125
INFO:root:Train (Epoch 15): Loss/seq after 01250 batchs: 1491.7091064453125
INFO:root:Train (Epoch 15): Loss/seq after 01300 batchs: 1495.5150146484375
INFO:root:Train (Epoch 15): Loss/seq after 01350 batchs: 1496.550048828125
INFO:root:Train (Epoch 15): Loss/seq after 01400 batchs: 1533.8714599609375
INFO:root:Train (Epoch 15): Loss/seq after 01450 batchs: 1517.851318359375
INFO:root:Train (Epoch 15): Loss/seq after 01500 batchs: 1502.4788818359375
INFO:root:Train (Epoch 15): Loss/seq after 01550 batchs: 1502.32861328125
INFO:root:Train (Epoch 15): Loss/seq after 01600 batchs: 1481.6546630859375
INFO:root:Train (Epoch 15): Loss/seq after 01650 batchs: 1472.537841796875
INFO:root:Train (Epoch 15): Loss/seq after 01700 batchs: 1460.26806640625
INFO:root:Train (Epoch 15): Loss/seq after 01750 batchs: 1444.225341796875
INFO:root:Train (Epoch 15): Loss/seq after 01800 batchs: 1426.5228271484375
INFO:root:Train (Epoch 15): Loss/seq after 01850 batchs: 1409.5743408203125
INFO:root:Train (Epoch 15): Loss/seq after 01900 batchs: 1405.236572265625
INFO:root:Train (Epoch 15): Loss/seq after 01950 batchs: 1397.466064453125
INFO:root:Train (Epoch 15): Loss/seq after 02000 batchs: 1384.9375
INFO:root:Train (Epoch 15): Loss/seq after 02050 batchs: 1374.201416015625
INFO:root:Train (Epoch 15): Loss/seq after 02100 batchs: 1360.318603515625
INFO:root:Train (Epoch 15): Loss/seq after 02150 batchs: 1347.62109375
INFO:root:Train (Epoch 15): Loss/seq after 02200 batchs: 1334.0421142578125
INFO:root:Train (Epoch 15): Loss/seq after 02250 batchs: 1338.2398681640625
INFO:root:Train (Epoch 15): Loss/seq after 02300 batchs: 1342.75341796875
INFO:root:Train (Epoch 15): Loss/seq after 02350 batchs: 1331.8514404296875
INFO:root:Train (Epoch 15): Loss/seq after 02400 batchs: 1326.3199462890625
INFO:root:Train (Epoch 15): Loss/seq after 02450 batchs: 1312.0
INFO:root:Train (Epoch 15): Loss/seq after 02500 batchs: 1293.0736083984375
INFO:root:Train (Epoch 15): Loss/seq after 02550 batchs: 1280.9150390625
INFO:root:Train (Epoch 15): Loss/seq after 02600 batchs: 1277.6253662109375
INFO:root:Train (Epoch 15): Loss/seq after 02650 batchs: 1272.0174560546875
INFO:root:Train (Epoch 15): Loss/seq after 02700 batchs: 1269.6417236328125
INFO:root:Train (Epoch 15): Loss/seq after 02750 batchs: 1301.2694091796875
INFO:root:Train (Epoch 15): Loss/seq after 02800 batchs: 1311.0496826171875
INFO:root:Train (Epoch 15): Loss/seq after 02850 batchs: 1307.6075439453125
INFO:root:Train (Epoch 15): Loss/seq after 02900 batchs: 1305.2379150390625
INFO:root:Train (Epoch 15): Loss/seq after 02950 batchs: 1296.1676025390625
INFO:root:Train (Epoch 15): Loss/seq after 03000 batchs: 1292.693359375
INFO:root:Train (Epoch 15): Loss/seq after 03050 batchs: 1293.9423828125
INFO:root:Train (Epoch 15): Loss/seq after 03100 batchs: 1308.140625
INFO:root:Train (Epoch 15): Loss/seq after 03150 batchs: 1325.119140625
INFO:root:Train (Epoch 15): Loss/seq after 03200 batchs: 1332.768798828125
INFO:root:Train (Epoch 15): Loss/seq after 03250 batchs: 1339.61962890625
INFO:root:Train (Epoch 15): Loss/seq after 03300 batchs: 1339.380859375
INFO:root:Train (Epoch 15): Loss/seq after 03350 batchs: 1338.9066162109375
INFO:root:Train (Epoch 15): Loss/seq after 03400 batchs: 1328.8350830078125
INFO:root:Train (Epoch 15): Loss/seq after 03450 batchs: 1320.6949462890625
INFO:root:Train (Epoch 15): Loss/seq after 03500 batchs: 1320.2662353515625
INFO:root:Train (Epoch 15): Loss/seq after 03550 batchs: 1314.5450439453125
INFO:root:Train (Epoch 15): Loss/seq after 03600 batchs: 1319.227783203125
INFO:root:Train (Epoch 15): Loss/seq after 03650 batchs: 1314.063720703125
INFO:root:Train (Epoch 15): Loss/seq after 03700 batchs: 1312.8951416015625
INFO:root:Train (Epoch 15): Loss/seq after 03750 batchs: 1311.6669921875
INFO:root:Train (Epoch 15): Loss/seq after 03800 batchs: 1303.61572265625
INFO:root:Train (Epoch 15): Loss/seq after 03850 batchs: 1298.1099853515625
INFO:root:Train (Epoch 15): Loss/seq after 03900 batchs: 1304.36767578125
INFO:root:Train (Epoch 15): Loss/seq after 03950 batchs: 1311.15576171875
INFO:root:Train (Epoch 15): Loss/seq after 04000 batchs: 1301.1279296875
INFO:root:Train (Epoch 15): Loss/seq after 04050 batchs: 1292.11767578125
INFO:root:Train (Epoch 15): Loss/seq after 04100 batchs: 1286.346923828125
INFO:root:Train (Epoch 15): Loss/seq after 04150 batchs: 1279.7720947265625
INFO:root:Train (Epoch 15): Loss/seq after 04200 batchs: 1274.1949462890625
INFO:root:Train (Epoch 15): Loss/seq after 04250 batchs: 1269.2347412109375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 15): Loss/seq after 00000 batches: 920.1398315429688
INFO:root:# Valid (Epoch 15): Loss/seq after 00050 batches: 1113.3717041015625
INFO:root:# Valid (Epoch 15): Loss/seq after 00100 batches: 1422.4105224609375
INFO:root:# Valid (Epoch 15): Loss/seq after 00150 batches: 1144.48193359375
INFO:root:# Valid (Epoch 15): Loss/seq after 00200 batches: 1030.158447265625
INFO:root:Artifacts: Make stick videos for epoch 15
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_15_on_20220414_095235.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_15_index_876_on_20220414_095235.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 16): Loss/seq after 00000 batchs: 1890.169677734375
INFO:root:Train (Epoch 16): Loss/seq after 00050 batchs: 1714.4422607421875
INFO:root:Train (Epoch 16): Loss/seq after 00100 batchs: 1682.3646240234375
INFO:root:Train (Epoch 16): Loss/seq after 00150 batchs: 1494.873291015625
INFO:root:Train (Epoch 16): Loss/seq after 00200 batchs: 1615.4915771484375
INFO:root:Train (Epoch 16): Loss/seq after 00250 batchs: 1750.181640625
INFO:root:Train (Epoch 16): Loss/seq after 00300 batchs: 1643.365478515625
INFO:root:Train (Epoch 16): Loss/seq after 00350 batchs: 1534.671875
INFO:root:Train (Epoch 16): Loss/seq after 00400 batchs: 1592.85009765625
INFO:root:Train (Epoch 16): Loss/seq after 00450 batchs: 1513.5576171875
INFO:root:Train (Epoch 16): Loss/seq after 00500 batchs: 1543.96826171875
INFO:root:Train (Epoch 16): Loss/seq after 00550 batchs: 1478.4437255859375
INFO:root:Train (Epoch 16): Loss/seq after 00600 batchs: 1441.5126953125
INFO:root:Train (Epoch 16): Loss/seq after 00650 batchs: 1476.748291015625
INFO:root:Train (Epoch 16): Loss/seq after 00700 batchs: 1515.4244384765625
INFO:root:Train (Epoch 16): Loss/seq after 00750 batchs: 1549.8372802734375
INFO:root:Train (Epoch 16): Loss/seq after 00800 batchs: 1538.387451171875
INFO:root:Train (Epoch 16): Loss/seq after 00850 batchs: 1505.5692138671875
INFO:root:Train (Epoch 16): Loss/seq after 00900 batchs: 1509.4068603515625
INFO:root:Train (Epoch 16): Loss/seq after 00950 batchs: 1576.39208984375
INFO:root:Train (Epoch 16): Loss/seq after 01000 batchs: 1575.0927734375
INFO:root:Train (Epoch 16): Loss/seq after 01050 batchs: 1553.4498291015625
INFO:root:Train (Epoch 16): Loss/seq after 01100 batchs: 1542.884521484375
INFO:root:Train (Epoch 16): Loss/seq after 01150 batchs: 1519.29931640625
INFO:root:Train (Epoch 16): Loss/seq after 01200 batchs: 1502.148681640625
INFO:root:Train (Epoch 16): Loss/seq after 01250 batchs: 1494.17041015625
INFO:root:Train (Epoch 16): Loss/seq after 01300 batchs: 1507.3040771484375
INFO:root:Train (Epoch 16): Loss/seq after 01350 batchs: 1512.6181640625
INFO:root:Train (Epoch 16): Loss/seq after 01400 batchs: 1546.7269287109375
INFO:root:Train (Epoch 16): Loss/seq after 01450 batchs: 1530.1737060546875
INFO:root:Train (Epoch 16): Loss/seq after 01500 batchs: 1514.607666015625
INFO:root:Train (Epoch 16): Loss/seq after 01550 batchs: 1515.07470703125
INFO:root:Train (Epoch 16): Loss/seq after 01600 batchs: 1492.927490234375
INFO:root:Train (Epoch 16): Loss/seq after 01650 batchs: 1483.2615966796875
INFO:root:Train (Epoch 16): Loss/seq after 01700 batchs: 1469.834228515625
INFO:root:Train (Epoch 16): Loss/seq after 01750 batchs: 1453.5628662109375
INFO:root:Train (Epoch 16): Loss/seq after 01800 batchs: 1435.87841796875
INFO:root:Train (Epoch 16): Loss/seq after 01850 batchs: 1418.6671142578125
INFO:root:Train (Epoch 16): Loss/seq after 01900 batchs: 1414.07470703125
INFO:root:Train (Epoch 16): Loss/seq after 01950 batchs: 1406.146728515625
INFO:root:Train (Epoch 16): Loss/seq after 02000 batchs: 1393.42236328125
INFO:root:Train (Epoch 16): Loss/seq after 02050 batchs: 1382.5986328125
INFO:root:Train (Epoch 16): Loss/seq after 02100 batchs: 1368.544921875
INFO:root:Train (Epoch 16): Loss/seq after 02150 batchs: 1355.6343994140625
INFO:root:Train (Epoch 16): Loss/seq after 02200 batchs: 1341.8623046875
INFO:root:Train (Epoch 16): Loss/seq after 02250 batchs: 1345.0457763671875
INFO:root:Train (Epoch 16): Loss/seq after 02300 batchs: 1349.2830810546875
INFO:root:Train (Epoch 16): Loss/seq after 02350 batchs: 1338.8179931640625
INFO:root:Train (Epoch 16): Loss/seq after 02400 batchs: 1333.386474609375
INFO:root:Train (Epoch 16): Loss/seq after 02450 batchs: 1319.7340087890625
INFO:root:Train (Epoch 16): Loss/seq after 02500 batchs: 1300.7213134765625
INFO:root:Train (Epoch 16): Loss/seq after 02550 batchs: 1290.4224853515625
INFO:root:Train (Epoch 16): Loss/seq after 02600 batchs: 1290.32421875
INFO:root:Train (Epoch 16): Loss/seq after 02650 batchs: 1286.2071533203125
INFO:root:Train (Epoch 16): Loss/seq after 02700 batchs: 1283.5535888671875
INFO:root:Train (Epoch 16): Loss/seq after 02750 batchs: 1315.5872802734375
INFO:root:Train (Epoch 16): Loss/seq after 02800 batchs: 1323.936767578125
INFO:root:Train (Epoch 16): Loss/seq after 02850 batchs: 1320.3155517578125
INFO:root:Train (Epoch 16): Loss/seq after 02900 batchs: 1317.5137939453125
INFO:root:Train (Epoch 16): Loss/seq after 02950 batchs: 1308.6185302734375
INFO:root:Train (Epoch 16): Loss/seq after 03000 batchs: 1304.9512939453125
INFO:root:Train (Epoch 16): Loss/seq after 03050 batchs: 1306.0369873046875
INFO:root:Train (Epoch 16): Loss/seq after 03100 batchs: 1319.97607421875
INFO:root:Train (Epoch 16): Loss/seq after 03150 batchs: 1335.0047607421875
INFO:root:Train (Epoch 16): Loss/seq after 03200 batchs: 1343.4500732421875
INFO:root:Train (Epoch 16): Loss/seq after 03250 batchs: 1349.7900390625
INFO:root:Train (Epoch 16): Loss/seq after 03300 batchs: 1348.1868896484375
INFO:root:Train (Epoch 16): Loss/seq after 03350 batchs: 1347.6441650390625
INFO:root:Train (Epoch 16): Loss/seq after 03400 batchs: 1337.448974609375
INFO:root:Train (Epoch 16): Loss/seq after 03450 batchs: 1329.4622802734375
INFO:root:Train (Epoch 16): Loss/seq after 03500 batchs: 1328.497802734375
INFO:root:Train (Epoch 16): Loss/seq after 03550 batchs: 1322.438232421875
INFO:root:Train (Epoch 16): Loss/seq after 03600 batchs: 1327.098876953125
INFO:root:Train (Epoch 16): Loss/seq after 03650 batchs: 1321.91259765625
INFO:root:Train (Epoch 16): Loss/seq after 03700 batchs: 1320.7357177734375
INFO:root:Train (Epoch 16): Loss/seq after 03750 batchs: 1319.362060546875
INFO:root:Train (Epoch 16): Loss/seq after 03800 batchs: 1311.22607421875
INFO:root:Train (Epoch 16): Loss/seq after 03850 batchs: 1305.6142578125
INFO:root:Train (Epoch 16): Loss/seq after 03900 batchs: 1310.799072265625
INFO:root:Train (Epoch 16): Loss/seq after 03950 batchs: 1316.0023193359375
INFO:root:Train (Epoch 16): Loss/seq after 04000 batchs: 1305.9249267578125
INFO:root:Train (Epoch 16): Loss/seq after 04050 batchs: 1296.8626708984375
INFO:root:Train (Epoch 16): Loss/seq after 04100 batchs: 1291.3558349609375
INFO:root:Train (Epoch 16): Loss/seq after 04150 batchs: 1284.7601318359375
INFO:root:Train (Epoch 16): Loss/seq after 04200 batchs: 1279.20849609375
INFO:root:Train (Epoch 16): Loss/seq after 04250 batchs: 1274.0372314453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 16): Loss/seq after 00000 batches: 889.4205932617188
INFO:root:# Valid (Epoch 16): Loss/seq after 00050 batches: 1106.644775390625
INFO:root:# Valid (Epoch 16): Loss/seq after 00100 batches: 1419.2178955078125
INFO:root:# Valid (Epoch 16): Loss/seq after 00150 batches: 1169.0206298828125
INFO:root:# Valid (Epoch 16): Loss/seq after 00200 batches: 1061.483642578125
INFO:root:Artifacts: Make stick videos for epoch 16
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_16_on_20220414_095801.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_16_index_46_on_20220414_095801.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 17): Loss/seq after 00000 batchs: 1886.13525390625
INFO:root:Train (Epoch 17): Loss/seq after 00050 batchs: 1757.680419921875
INFO:root:Train (Epoch 17): Loss/seq after 00100 batchs: 1716.619140625
INFO:root:Train (Epoch 17): Loss/seq after 00150 batchs: 1515.9935302734375
INFO:root:Train (Epoch 17): Loss/seq after 00200 batchs: 1636.0745849609375
INFO:root:Train (Epoch 17): Loss/seq after 00250 batchs: 1746.643310546875
INFO:root:Train (Epoch 17): Loss/seq after 00300 batchs: 1640.5404052734375
INFO:root:Train (Epoch 17): Loss/seq after 00350 batchs: 1531.274169921875
INFO:root:Train (Epoch 17): Loss/seq after 00400 batchs: 1582.0123291015625
INFO:root:Train (Epoch 17): Loss/seq after 00450 batchs: 1503.8638916015625
INFO:root:Train (Epoch 17): Loss/seq after 00500 batchs: 1535.009521484375
INFO:root:Train (Epoch 17): Loss/seq after 00550 batchs: 1469.9129638671875
INFO:root:Train (Epoch 17): Loss/seq after 00600 batchs: 1435.0723876953125
INFO:root:Train (Epoch 17): Loss/seq after 00650 batchs: 1464.1529541015625
INFO:root:Train (Epoch 17): Loss/seq after 00700 batchs: 1503.105224609375
INFO:root:Train (Epoch 17): Loss/seq after 00750 batchs: 1538.8681640625
INFO:root:Train (Epoch 17): Loss/seq after 00800 batchs: 1528.038330078125
INFO:root:Train (Epoch 17): Loss/seq after 00850 batchs: 1495.1463623046875
INFO:root:Train (Epoch 17): Loss/seq after 00900 batchs: 1499.422119140625
INFO:root:Train (Epoch 17): Loss/seq after 00950 batchs: 1567.5767822265625
INFO:root:Train (Epoch 17): Loss/seq after 01000 batchs: 1565.4146728515625
INFO:root:Train (Epoch 17): Loss/seq after 01050 batchs: 1543.39697265625
INFO:root:Train (Epoch 17): Loss/seq after 01100 batchs: 1532.8077392578125
INFO:root:Train (Epoch 17): Loss/seq after 01150 batchs: 1508.759521484375
INFO:root:Train (Epoch 17): Loss/seq after 01200 batchs: 1491.44921875
INFO:root:Train (Epoch 17): Loss/seq after 01250 batchs: 1482.4830322265625
INFO:root:Train (Epoch 17): Loss/seq after 01300 batchs: 1490.76904296875
INFO:root:Train (Epoch 17): Loss/seq after 01350 batchs: 1490.9149169921875
INFO:root:Train (Epoch 17): Loss/seq after 01400 batchs: 1528.1109619140625
INFO:root:Train (Epoch 17): Loss/seq after 01450 batchs: 1511.9869384765625
INFO:root:Train (Epoch 17): Loss/seq after 01500 batchs: 1496.7884521484375
INFO:root:Train (Epoch 17): Loss/seq after 01550 batchs: 1497.0504150390625
INFO:root:Train (Epoch 17): Loss/seq after 01600 batchs: 1475.5859375
INFO:root:Train (Epoch 17): Loss/seq after 01650 batchs: 1467.2108154296875
INFO:root:Train (Epoch 17): Loss/seq after 01700 batchs: 1454.4820556640625
INFO:root:Train (Epoch 17): Loss/seq after 01750 batchs: 1438.5865478515625
INFO:root:Train (Epoch 17): Loss/seq after 01800 batchs: 1420.976806640625
INFO:root:Train (Epoch 17): Loss/seq after 01850 batchs: 1404.013427734375
INFO:root:Train (Epoch 17): Loss/seq after 01900 batchs: 1399.803955078125
INFO:root:Train (Epoch 17): Loss/seq after 01950 batchs: 1392.2889404296875
INFO:root:Train (Epoch 17): Loss/seq after 02000 batchs: 1379.8388671875
INFO:root:Train (Epoch 17): Loss/seq after 02050 batchs: 1369.191650390625
INFO:root:Train (Epoch 17): Loss/seq after 02100 batchs: 1355.349609375
INFO:root:Train (Epoch 17): Loss/seq after 02150 batchs: 1342.636962890625
INFO:root:Train (Epoch 17): Loss/seq after 02200 batchs: 1329.131103515625
INFO:root:Train (Epoch 17): Loss/seq after 02250 batchs: 1332.062255859375
INFO:root:Train (Epoch 17): Loss/seq after 02300 batchs: 1336.68310546875
INFO:root:Train (Epoch 17): Loss/seq after 02350 batchs: 1325.7156982421875
INFO:root:Train (Epoch 17): Loss/seq after 02400 batchs: 1320.116943359375
INFO:root:Train (Epoch 17): Loss/seq after 02450 batchs: 1305.79638671875
INFO:root:Train (Epoch 17): Loss/seq after 02500 batchs: 1286.9615478515625
INFO:root:Train (Epoch 17): Loss/seq after 02550 batchs: 1274.86669921875
INFO:root:Train (Epoch 17): Loss/seq after 02600 batchs: 1271.015625
INFO:root:Train (Epoch 17): Loss/seq after 02650 batchs: 1265.1055908203125
INFO:root:Train (Epoch 17): Loss/seq after 02700 batchs: 1260.50048828125
INFO:root:Train (Epoch 17): Loss/seq after 02750 batchs: 1291.6649169921875
INFO:root:Train (Epoch 17): Loss/seq after 02800 batchs: 1299.58984375
INFO:root:Train (Epoch 17): Loss/seq after 02850 batchs: 1295.650634765625
INFO:root:Train (Epoch 17): Loss/seq after 02900 batchs: 1293.3720703125
INFO:root:Train (Epoch 17): Loss/seq after 02950 batchs: 1284.22021484375
INFO:root:Train (Epoch 17): Loss/seq after 03000 batchs: 1280.9207763671875
INFO:root:Train (Epoch 17): Loss/seq after 03050 batchs: 1282.3626708984375
INFO:root:Train (Epoch 17): Loss/seq after 03100 batchs: 1296.091796875
INFO:root:Train (Epoch 17): Loss/seq after 03150 batchs: 1310.749755859375
INFO:root:Train (Epoch 17): Loss/seq after 03200 batchs: 1319.025146484375
INFO:root:Train (Epoch 17): Loss/seq after 03250 batchs: 1325.97998046875
INFO:root:Train (Epoch 17): Loss/seq after 03300 batchs: 1325.9288330078125
INFO:root:Train (Epoch 17): Loss/seq after 03350 batchs: 1325.4718017578125
INFO:root:Train (Epoch 17): Loss/seq after 03400 batchs: 1315.5245361328125
INFO:root:Train (Epoch 17): Loss/seq after 03450 batchs: 1307.425537109375
INFO:root:Train (Epoch 17): Loss/seq after 03500 batchs: 1306.7322998046875
INFO:root:Train (Epoch 17): Loss/seq after 03550 batchs: 1300.8397216796875
INFO:root:Train (Epoch 17): Loss/seq after 03600 batchs: 1305.71044921875
INFO:root:Train (Epoch 17): Loss/seq after 03650 batchs: 1300.6881103515625
INFO:root:Train (Epoch 17): Loss/seq after 03700 batchs: 1299.6993408203125
INFO:root:Train (Epoch 17): Loss/seq after 03750 batchs: 1298.6192626953125
INFO:root:Train (Epoch 17): Loss/seq after 03800 batchs: 1290.7265625
INFO:root:Train (Epoch 17): Loss/seq after 03850 batchs: 1285.348876953125
INFO:root:Train (Epoch 17): Loss/seq after 03900 batchs: 1291.69287109375
INFO:root:Train (Epoch 17): Loss/seq after 03950 batchs: 1297.8817138671875
INFO:root:Train (Epoch 17): Loss/seq after 04000 batchs: 1287.9671630859375
INFO:root:Train (Epoch 17): Loss/seq after 04050 batchs: 1279.11181640625
INFO:root:Train (Epoch 17): Loss/seq after 04100 batchs: 1273.432373046875
INFO:root:Train (Epoch 17): Loss/seq after 04150 batchs: 1267.0362548828125
INFO:root:Train (Epoch 17): Loss/seq after 04200 batchs: 1261.5633544921875
INFO:root:Train (Epoch 17): Loss/seq after 04250 batchs: 1256.572021484375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 17): Loss/seq after 00000 batches: 901.4735717773438
INFO:root:# Valid (Epoch 17): Loss/seq after 00050 batches: 1106.1348876953125
INFO:root:# Valid (Epoch 17): Loss/seq after 00100 batches: 1416.2647705078125
INFO:root:# Valid (Epoch 17): Loss/seq after 00150 batches: 1155.7467041015625
INFO:root:# Valid (Epoch 17): Loss/seq after 00200 batches: 1045.4205322265625
INFO:root:Artifacts: Make stick videos for epoch 17
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_17_on_20220414_100327.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_17_index_903_on_20220414_100327.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 18): Loss/seq after 00000 batchs: 2221.650390625
INFO:root:Train (Epoch 18): Loss/seq after 00050 batchs: 1718.4398193359375
INFO:root:Train (Epoch 18): Loss/seq after 00100 batchs: 1688.8902587890625
INFO:root:Train (Epoch 18): Loss/seq after 00150 batchs: 1499.7869873046875
INFO:root:Train (Epoch 18): Loss/seq after 00200 batchs: 1626.602783203125
INFO:root:Train (Epoch 18): Loss/seq after 00250 batchs: 1736.8468017578125
INFO:root:Train (Epoch 18): Loss/seq after 00300 batchs: 1632.731689453125
INFO:root:Train (Epoch 18): Loss/seq after 00350 batchs: 1524.9735107421875
INFO:root:Train (Epoch 18): Loss/seq after 00400 batchs: 1580.1214599609375
INFO:root:Train (Epoch 18): Loss/seq after 00450 batchs: 1502.0877685546875
INFO:root:Train (Epoch 18): Loss/seq after 00500 batchs: 1532.408447265625
INFO:root:Train (Epoch 18): Loss/seq after 00550 batchs: 1468.2142333984375
INFO:root:Train (Epoch 18): Loss/seq after 00600 batchs: 1432.2535400390625
INFO:root:Train (Epoch 18): Loss/seq after 00650 batchs: 1468.6204833984375
INFO:root:Train (Epoch 18): Loss/seq after 00700 batchs: 1499.6070556640625
INFO:root:Train (Epoch 18): Loss/seq after 00750 batchs: 1535.408447265625
INFO:root:Train (Epoch 18): Loss/seq after 00800 batchs: 1524.0670166015625
INFO:root:Train (Epoch 18): Loss/seq after 00850 batchs: 1489.412841796875
INFO:root:Train (Epoch 18): Loss/seq after 00900 batchs: 1492.450439453125
INFO:root:Train (Epoch 18): Loss/seq after 00950 batchs: 1553.6904296875
INFO:root:Train (Epoch 18): Loss/seq after 01000 batchs: 1549.6126708984375
INFO:root:Train (Epoch 18): Loss/seq after 01050 batchs: 1528.6295166015625
INFO:root:Train (Epoch 18): Loss/seq after 01100 batchs: 1517.6246337890625
INFO:root:Train (Epoch 18): Loss/seq after 01150 batchs: 1494.103759765625
INFO:root:Train (Epoch 18): Loss/seq after 01200 batchs: 1477.572021484375
INFO:root:Train (Epoch 18): Loss/seq after 01250 batchs: 1469.876220703125
INFO:root:Train (Epoch 18): Loss/seq after 01300 batchs: 1478.917724609375
INFO:root:Train (Epoch 18): Loss/seq after 01350 batchs: 1482.373779296875
INFO:root:Train (Epoch 18): Loss/seq after 01400 batchs: 1517.923095703125
INFO:root:Train (Epoch 18): Loss/seq after 01450 batchs: 1503.6788330078125
INFO:root:Train (Epoch 18): Loss/seq after 01500 batchs: 1489.2774658203125
INFO:root:Train (Epoch 18): Loss/seq after 01550 batchs: 1489.653564453125
INFO:root:Train (Epoch 18): Loss/seq after 01600 batchs: 1468.441650390625
INFO:root:Train (Epoch 18): Loss/seq after 01650 batchs: 1459.982421875
INFO:root:Train (Epoch 18): Loss/seq after 01700 batchs: 1448.310791015625
INFO:root:Train (Epoch 18): Loss/seq after 01750 batchs: 1432.658447265625
INFO:root:Train (Epoch 18): Loss/seq after 01800 batchs: 1415.2935791015625
INFO:root:Train (Epoch 18): Loss/seq after 01850 batchs: 1398.4832763671875
INFO:root:Train (Epoch 18): Loss/seq after 01900 batchs: 1394.4388427734375
INFO:root:Train (Epoch 18): Loss/seq after 01950 batchs: 1386.877197265625
INFO:root:Train (Epoch 18): Loss/seq after 02000 batchs: 1374.5604248046875
INFO:root:Train (Epoch 18): Loss/seq after 02050 batchs: 1364.0147705078125
INFO:root:Train (Epoch 18): Loss/seq after 02100 batchs: 1350.291259765625
INFO:root:Train (Epoch 18): Loss/seq after 02150 batchs: 1337.55029296875
INFO:root:Train (Epoch 18): Loss/seq after 02200 batchs: 1324.1512451171875
INFO:root:Train (Epoch 18): Loss/seq after 02250 batchs: 1327.25341796875
INFO:root:Train (Epoch 18): Loss/seq after 02300 batchs: 1332.1949462890625
INFO:root:Train (Epoch 18): Loss/seq after 02350 batchs: 1321.3773193359375
INFO:root:Train (Epoch 18): Loss/seq after 02400 batchs: 1316.0008544921875
INFO:root:Train (Epoch 18): Loss/seq after 02450 batchs: 1302.057373046875
INFO:root:Train (Epoch 18): Loss/seq after 02500 batchs: 1283.3018798828125
INFO:root:Train (Epoch 18): Loss/seq after 02550 batchs: 1271.145751953125
INFO:root:Train (Epoch 18): Loss/seq after 02600 batchs: 1267.9832763671875
INFO:root:Train (Epoch 18): Loss/seq after 02650 batchs: 1262.603271484375
INFO:root:Train (Epoch 18): Loss/seq after 02700 batchs: 1258.6163330078125
INFO:root:Train (Epoch 18): Loss/seq after 02750 batchs: 1290.3857421875
INFO:root:Train (Epoch 18): Loss/seq after 02800 batchs: 1300.084228515625
INFO:root:Train (Epoch 18): Loss/seq after 02850 batchs: 1297.361328125
INFO:root:Train (Epoch 18): Loss/seq after 02900 batchs: 1294.9468994140625
INFO:root:Train (Epoch 18): Loss/seq after 02950 batchs: 1286.137451171875
INFO:root:Train (Epoch 18): Loss/seq after 03000 batchs: 1282.831298828125
INFO:root:Train (Epoch 18): Loss/seq after 03050 batchs: 1284.251953125
INFO:root:Train (Epoch 18): Loss/seq after 03100 batchs: 1298.80517578125
INFO:root:Train (Epoch 18): Loss/seq after 03150 batchs: 1312.6103515625
INFO:root:Train (Epoch 18): Loss/seq after 03200 batchs: 1321.8759765625
INFO:root:Train (Epoch 18): Loss/seq after 03250 batchs: 1328.2862548828125
INFO:root:Train (Epoch 18): Loss/seq after 03300 batchs: 1327.058349609375
INFO:root:Train (Epoch 18): Loss/seq after 03350 batchs: 1326.4378662109375
INFO:root:Train (Epoch 18): Loss/seq after 03400 batchs: 1316.492919921875
INFO:root:Train (Epoch 18): Loss/seq after 03450 batchs: 1308.7301025390625
INFO:root:Train (Epoch 18): Loss/seq after 03500 batchs: 1308.128662109375
INFO:root:Train (Epoch 18): Loss/seq after 03550 batchs: 1302.400146484375
INFO:root:Train (Epoch 18): Loss/seq after 03600 batchs: 1307.3248291015625
INFO:root:Train (Epoch 18): Loss/seq after 03650 batchs: 1302.318359375
INFO:root:Train (Epoch 18): Loss/seq after 03700 batchs: 1301.6363525390625
INFO:root:Train (Epoch 18): Loss/seq after 03750 batchs: 1300.555908203125
INFO:root:Train (Epoch 18): Loss/seq after 03800 batchs: 1292.65185546875
INFO:root:Train (Epoch 18): Loss/seq after 03850 batchs: 1287.229736328125
INFO:root:Train (Epoch 18): Loss/seq after 03900 batchs: 1292.8363037109375
INFO:root:Train (Epoch 18): Loss/seq after 03950 batchs: 1299.689453125
INFO:root:Train (Epoch 18): Loss/seq after 04000 batchs: 1289.781005859375
INFO:root:Train (Epoch 18): Loss/seq after 04050 batchs: 1280.9158935546875
INFO:root:Train (Epoch 18): Loss/seq after 04100 batchs: 1275.7679443359375
INFO:root:Train (Epoch 18): Loss/seq after 04150 batchs: 1269.59619140625
INFO:root:Train (Epoch 18): Loss/seq after 04200 batchs: 1264.48583984375
INFO:root:Train (Epoch 18): Loss/seq after 04250 batchs: 1259.4630126953125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 18): Loss/seq after 00000 batches: 914.8074951171875
INFO:root:# Valid (Epoch 18): Loss/seq after 00050 batches: 1110.343017578125
INFO:root:# Valid (Epoch 18): Loss/seq after 00100 batches: 1419.6981201171875
INFO:root:# Valid (Epoch 18): Loss/seq after 00150 batches: 1153.334228515625
INFO:root:# Valid (Epoch 18): Loss/seq after 00200 batches: 1045.16064453125
INFO:root:Artifacts: Make stick videos for epoch 18
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_18_on_20220414_100852.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_18_index_27_on_20220414_100852.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 19): Loss/seq after 00000 batchs: 2043.137939453125
INFO:root:Train (Epoch 19): Loss/seq after 00050 batchs: 1703.060546875
INFO:root:Train (Epoch 19): Loss/seq after 00100 batchs: 1685.047119140625
INFO:root:Train (Epoch 19): Loss/seq after 00150 batchs: 1497.8095703125
INFO:root:Train (Epoch 19): Loss/seq after 00200 batchs: 1634.2666015625
INFO:root:Train (Epoch 19): Loss/seq after 00250 batchs: 1753.6558837890625
INFO:root:Train (Epoch 19): Loss/seq after 00300 batchs: 1646.5028076171875
INFO:root:Train (Epoch 19): Loss/seq after 00350 batchs: 1537.22607421875
INFO:root:Train (Epoch 19): Loss/seq after 00400 batchs: 1598.014404296875
INFO:root:Train (Epoch 19): Loss/seq after 00450 batchs: 1518.356689453125
INFO:root:Train (Epoch 19): Loss/seq after 00500 batchs: 1550.0382080078125
INFO:root:Train (Epoch 19): Loss/seq after 00550 batchs: 1485.1070556640625
INFO:root:Train (Epoch 19): Loss/seq after 00600 batchs: 1449.547607421875
INFO:root:Train (Epoch 19): Loss/seq after 00650 batchs: 1493.4176025390625
INFO:root:Train (Epoch 19): Loss/seq after 00700 batchs: 1514.3671875
INFO:root:Train (Epoch 19): Loss/seq after 00750 batchs: 1551.500732421875
INFO:root:Train (Epoch 19): Loss/seq after 00800 batchs: 1539.7738037109375
INFO:root:Train (Epoch 19): Loss/seq after 00850 batchs: 1506.4764404296875
INFO:root:Train (Epoch 19): Loss/seq after 00900 batchs: 1509.2840576171875
INFO:root:Train (Epoch 19): Loss/seq after 00950 batchs: 1590.0244140625
INFO:root:Train (Epoch 19): Loss/seq after 01000 batchs: 1586.8226318359375
INFO:root:Train (Epoch 19): Loss/seq after 01050 batchs: 1564.5552978515625
INFO:root:Train (Epoch 19): Loss/seq after 01100 batchs: 1550.770263671875
INFO:root:Train (Epoch 19): Loss/seq after 01150 batchs: 1525.7625732421875
INFO:root:Train (Epoch 19): Loss/seq after 01200 batchs: 1508.1519775390625
INFO:root:Train (Epoch 19): Loss/seq after 01250 batchs: 1499.1998291015625
INFO:root:Train (Epoch 19): Loss/seq after 01300 batchs: 1506.773193359375
INFO:root:Train (Epoch 19): Loss/seq after 01350 batchs: 1507.7166748046875
INFO:root:Train (Epoch 19): Loss/seq after 01400 batchs: 1542.971435546875
INFO:root:Train (Epoch 19): Loss/seq after 01450 batchs: 1526.1163330078125
INFO:root:Train (Epoch 19): Loss/seq after 01500 batchs: 1510.452880859375
INFO:root:Train (Epoch 19): Loss/seq after 01550 batchs: 1510.285888671875
INFO:root:Train (Epoch 19): Loss/seq after 01600 batchs: 1488.2725830078125
INFO:root:Train (Epoch 19): Loss/seq after 01650 batchs: 1478.450927734375
INFO:root:Train (Epoch 19): Loss/seq after 01700 batchs: 1465.2342529296875
INFO:root:Train (Epoch 19): Loss/seq after 01750 batchs: 1449.056884765625
INFO:root:Train (Epoch 19): Loss/seq after 01800 batchs: 1431.158447265625
INFO:root:Train (Epoch 19): Loss/seq after 01850 batchs: 1413.8792724609375
INFO:root:Train (Epoch 19): Loss/seq after 01900 batchs: 1409.39599609375
INFO:root:Train (Epoch 19): Loss/seq after 01950 batchs: 1401.487548828125
INFO:root:Train (Epoch 19): Loss/seq after 02000 batchs: 1388.816650390625
INFO:root:Train (Epoch 19): Loss/seq after 02050 batchs: 1377.9495849609375
INFO:root:Train (Epoch 19): Loss/seq after 02100 batchs: 1363.9454345703125
INFO:root:Train (Epoch 19): Loss/seq after 02150 batchs: 1351.052001953125
INFO:root:Train (Epoch 19): Loss/seq after 02200 batchs: 1337.3876953125
INFO:root:Train (Epoch 19): Loss/seq after 02250 batchs: 1340.4205322265625
INFO:root:Train (Epoch 19): Loss/seq after 02300 batchs: 1344.290771484375
INFO:root:Train (Epoch 19): Loss/seq after 02350 batchs: 1333.7230224609375
INFO:root:Train (Epoch 19): Loss/seq after 02400 batchs: 1328.1866455078125
INFO:root:Train (Epoch 19): Loss/seq after 02450 batchs: 1313.8426513671875
INFO:root:Train (Epoch 19): Loss/seq after 02500 batchs: 1294.915283203125
INFO:root:Train (Epoch 19): Loss/seq after 02550 batchs: 1282.5379638671875
INFO:root:Train (Epoch 19): Loss/seq after 02600 batchs: 1278.6571044921875
INFO:root:Train (Epoch 19): Loss/seq after 02650 batchs: 1272.7073974609375
INFO:root:Train (Epoch 19): Loss/seq after 02700 batchs: 1268.549072265625
INFO:root:Train (Epoch 19): Loss/seq after 02750 batchs: 1300.0096435546875
INFO:root:Train (Epoch 19): Loss/seq after 02800 batchs: 1308.4581298828125
INFO:root:Train (Epoch 19): Loss/seq after 02850 batchs: 1304.3900146484375
INFO:root:Train (Epoch 19): Loss/seq after 02900 batchs: 1301.7344970703125
INFO:root:Train (Epoch 19): Loss/seq after 02950 batchs: 1292.435302734375
INFO:root:Train (Epoch 19): Loss/seq after 03000 batchs: 1289.013916015625
INFO:root:Train (Epoch 19): Loss/seq after 03050 batchs: 1290.29638671875
INFO:root:Train (Epoch 19): Loss/seq after 03100 batchs: 1305.510009765625
INFO:root:Train (Epoch 19): Loss/seq after 03150 batchs: 1322.3599853515625
INFO:root:Train (Epoch 19): Loss/seq after 03200 batchs: 1330.253662109375
INFO:root:Train (Epoch 19): Loss/seq after 03250 batchs: 1337.0596923828125
INFO:root:Train (Epoch 19): Loss/seq after 03300 batchs: 1336.3541259765625
INFO:root:Train (Epoch 19): Loss/seq after 03350 batchs: 1335.9722900390625
INFO:root:Train (Epoch 19): Loss/seq after 03400 batchs: 1325.885009765625
INFO:root:Train (Epoch 19): Loss/seq after 03450 batchs: 1317.7900390625
INFO:root:Train (Epoch 19): Loss/seq after 03500 batchs: 1316.900634765625
INFO:root:Train (Epoch 19): Loss/seq after 03550 batchs: 1311.2152099609375
INFO:root:Train (Epoch 19): Loss/seq after 03600 batchs: 1316.0029296875
INFO:root:Train (Epoch 19): Loss/seq after 03650 batchs: 1310.7744140625
INFO:root:Train (Epoch 19): Loss/seq after 03700 batchs: 1309.4110107421875
INFO:root:Train (Epoch 19): Loss/seq after 03750 batchs: 1308.1610107421875
INFO:root:Train (Epoch 19): Loss/seq after 03800 batchs: 1300.124267578125
INFO:root:Train (Epoch 19): Loss/seq after 03850 batchs: 1294.5865478515625
INFO:root:Train (Epoch 19): Loss/seq after 03900 batchs: 1300.4168701171875
INFO:root:Train (Epoch 19): Loss/seq after 03950 batchs: 1307.425048828125
INFO:root:Train (Epoch 19): Loss/seq after 04000 batchs: 1297.391845703125
INFO:root:Train (Epoch 19): Loss/seq after 04050 batchs: 1288.419189453125
INFO:root:Train (Epoch 19): Loss/seq after 04100 batchs: 1282.3421630859375
INFO:root:Train (Epoch 19): Loss/seq after 04150 batchs: 1275.7125244140625
INFO:root:Train (Epoch 19): Loss/seq after 04200 batchs: 1270.0220947265625
INFO:root:Train (Epoch 19): Loss/seq after 04250 batchs: 1264.9637451171875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 19): Loss/seq after 00000 batches: 883.86328125
INFO:root:# Valid (Epoch 19): Loss/seq after 00050 batches: 1106.7562255859375
INFO:root:# Valid (Epoch 19): Loss/seq after 00100 batches: 1419.3992919921875
INFO:root:# Valid (Epoch 19): Loss/seq after 00150 batches: 1144.6741943359375
INFO:root:# Valid (Epoch 19): Loss/seq after 00200 batches: 1029.6954345703125
INFO:root:Artifacts: Make stick videos for epoch 19
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_19_on_20220414_101417.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_19_index_1372_on_20220414_101417.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 20): Loss/seq after 00000 batchs: 1896.4765625
INFO:root:Train (Epoch 20): Loss/seq after 00050 batchs: 1722.16796875
INFO:root:Train (Epoch 20): Loss/seq after 00100 batchs: 1679.9842529296875
INFO:root:Train (Epoch 20): Loss/seq after 00150 batchs: 1495.144287109375
INFO:root:Train (Epoch 20): Loss/seq after 00200 batchs: 1621.779296875
INFO:root:Train (Epoch 20): Loss/seq after 00250 batchs: 1738.8956298828125
INFO:root:Train (Epoch 20): Loss/seq after 00300 batchs: 1634.434814453125
INFO:root:Train (Epoch 20): Loss/seq after 00350 batchs: 1525.90771484375
INFO:root:Train (Epoch 20): Loss/seq after 00400 batchs: 1578.643798828125
INFO:root:Train (Epoch 20): Loss/seq after 00450 batchs: 1500.8834228515625
INFO:root:Train (Epoch 20): Loss/seq after 00500 batchs: 1531.789794921875
INFO:root:Train (Epoch 20): Loss/seq after 00550 batchs: 1468.6915283203125
INFO:root:Train (Epoch 20): Loss/seq after 00600 batchs: 1433.3419189453125
INFO:root:Train (Epoch 20): Loss/seq after 00650 batchs: 1465.4462890625
INFO:root:Train (Epoch 20): Loss/seq after 00700 batchs: 1500.3822021484375
INFO:root:Train (Epoch 20): Loss/seq after 00750 batchs: 1534.5838623046875
INFO:root:Train (Epoch 20): Loss/seq after 00800 batchs: 1523.5848388671875
INFO:root:Train (Epoch 20): Loss/seq after 00850 batchs: 1489.30078125
INFO:root:Train (Epoch 20): Loss/seq after 00900 batchs: 1493.4351806640625
INFO:root:Train (Epoch 20): Loss/seq after 00950 batchs: 1551.3519287109375
INFO:root:Train (Epoch 20): Loss/seq after 01000 batchs: 1546.37646484375
INFO:root:Train (Epoch 20): Loss/seq after 01050 batchs: 1525.548095703125
INFO:root:Train (Epoch 20): Loss/seq after 01100 batchs: 1514.417724609375
INFO:root:Train (Epoch 20): Loss/seq after 01150 batchs: 1491.0362548828125
INFO:root:Train (Epoch 20): Loss/seq after 01200 batchs: 1474.558349609375
INFO:root:Train (Epoch 20): Loss/seq after 01250 batchs: 1467.092529296875
INFO:root:Train (Epoch 20): Loss/seq after 01300 batchs: 1474.8394775390625
INFO:root:Train (Epoch 20): Loss/seq after 01350 batchs: 1473.9884033203125
INFO:root:Train (Epoch 20): Loss/seq after 01400 batchs: 1503.0146484375
INFO:root:Train (Epoch 20): Loss/seq after 01450 batchs: 1488.5340576171875
INFO:root:Train (Epoch 20): Loss/seq after 01500 batchs: 1474.168212890625
INFO:root:Train (Epoch 20): Loss/seq after 01550 batchs: 1475.1788330078125
INFO:root:Train (Epoch 20): Loss/seq after 01600 batchs: 1455.06591796875
INFO:root:Train (Epoch 20): Loss/seq after 01650 batchs: 1446.8079833984375
INFO:root:Train (Epoch 20): Loss/seq after 01700 batchs: 1435.2955322265625
INFO:root:Train (Epoch 20): Loss/seq after 01750 batchs: 1420.213623046875
INFO:root:Train (Epoch 20): Loss/seq after 01800 batchs: 1403.857177734375
INFO:root:Train (Epoch 20): Loss/seq after 01850 batchs: 1387.34619140625
INFO:root:Train (Epoch 20): Loss/seq after 01900 batchs: 1383.6536865234375
INFO:root:Train (Epoch 20): Loss/seq after 01950 batchs: 1376.426513671875
INFO:root:Train (Epoch 20): Loss/seq after 02000 batchs: 1364.4061279296875
INFO:root:Train (Epoch 20): Loss/seq after 02050 batchs: 1354.0802001953125
INFO:root:Train (Epoch 20): Loss/seq after 02100 batchs: 1340.6240234375
INFO:root:Train (Epoch 20): Loss/seq after 02150 batchs: 1328.2889404296875
INFO:root:Train (Epoch 20): Loss/seq after 02200 batchs: 1315.124267578125
INFO:root:Train (Epoch 20): Loss/seq after 02250 batchs: 1318.4644775390625
INFO:root:Train (Epoch 20): Loss/seq after 02300 batchs: 1321.8670654296875
INFO:root:Train (Epoch 20): Loss/seq after 02350 batchs: 1311.5869140625
INFO:root:Train (Epoch 20): Loss/seq after 02400 batchs: 1306.680419921875
INFO:root:Train (Epoch 20): Loss/seq after 02450 batchs: 1292.777587890625
INFO:root:Train (Epoch 20): Loss/seq after 02500 batchs: 1274.262451171875
INFO:root:Train (Epoch 20): Loss/seq after 02550 batchs: 1262.220703125
INFO:root:Train (Epoch 20): Loss/seq after 02600 batchs: 1258.7010498046875
INFO:root:Train (Epoch 20): Loss/seq after 02650 batchs: 1253.0697021484375
INFO:root:Train (Epoch 20): Loss/seq after 02700 batchs: 1248.9658203125
INFO:root:Train (Epoch 20): Loss/seq after 02750 batchs: 1280.4456787109375
INFO:root:Train (Epoch 20): Loss/seq after 02800 batchs: 1289.2640380859375
INFO:root:Train (Epoch 20): Loss/seq after 02850 batchs: 1285.5872802734375
INFO:root:Train (Epoch 20): Loss/seq after 02900 batchs: 1283.0269775390625
INFO:root:Train (Epoch 20): Loss/seq after 02950 batchs: 1274.1414794921875
INFO:root:Train (Epoch 20): Loss/seq after 03000 batchs: 1271.007080078125
INFO:root:Train (Epoch 20): Loss/seq after 03050 batchs: 1272.6475830078125
INFO:root:Train (Epoch 20): Loss/seq after 03100 batchs: 1288.1060791015625
INFO:root:Train (Epoch 20): Loss/seq after 03150 batchs: 1306.67333984375
INFO:root:Train (Epoch 20): Loss/seq after 03200 batchs: 1315.8719482421875
INFO:root:Train (Epoch 20): Loss/seq after 03250 batchs: 1323.5455322265625
INFO:root:Train (Epoch 20): Loss/seq after 03300 batchs: 1324.5504150390625
INFO:root:Train (Epoch 20): Loss/seq after 03350 batchs: 1324.046875
INFO:root:Train (Epoch 20): Loss/seq after 03400 batchs: 1314.155517578125
INFO:root:Train (Epoch 20): Loss/seq after 03450 batchs: 1306.4697265625
INFO:root:Train (Epoch 20): Loss/seq after 03500 batchs: 1306.123291015625
INFO:root:Train (Epoch 20): Loss/seq after 03550 batchs: 1300.485595703125
INFO:root:Train (Epoch 20): Loss/seq after 03600 batchs: 1305.3804931640625
INFO:root:Train (Epoch 20): Loss/seq after 03650 batchs: 1300.28173828125
INFO:root:Train (Epoch 20): Loss/seq after 03700 batchs: 1299.177490234375
INFO:root:Train (Epoch 20): Loss/seq after 03750 batchs: 1298.0943603515625
INFO:root:Train (Epoch 20): Loss/seq after 03800 batchs: 1290.19921875
INFO:root:Train (Epoch 20): Loss/seq after 03850 batchs: 1284.81591796875
INFO:root:Train (Epoch 20): Loss/seq after 03900 batchs: 1290.60888671875
INFO:root:Train (Epoch 20): Loss/seq after 03950 batchs: 1296.8106689453125
INFO:root:Train (Epoch 20): Loss/seq after 04000 batchs: 1286.921630859375
INFO:root:Train (Epoch 20): Loss/seq after 04050 batchs: 1278.088134765625
INFO:root:Train (Epoch 20): Loss/seq after 04100 batchs: 1272.2723388671875
INFO:root:Train (Epoch 20): Loss/seq after 04150 batchs: 1265.7578125
INFO:root:Train (Epoch 20): Loss/seq after 04200 batchs: 1260.2203369140625
INFO:root:Train (Epoch 20): Loss/seq after 04250 batchs: 1255.2611083984375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 20): Loss/seq after 00000 batches: 890.6950073242188
INFO:root:# Valid (Epoch 20): Loss/seq after 00050 batches: 1104.764404296875
INFO:root:# Valid (Epoch 20): Loss/seq after 00100 batches: 1425.7069091796875
INFO:root:# Valid (Epoch 20): Loss/seq after 00150 batches: 1147.630615234375
INFO:root:# Valid (Epoch 20): Loss/seq after 00200 batches: 1032.07861328125
INFO:root:Artifacts: Make stick videos for epoch 20
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_20_on_20220414_101941.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_20_index_1189_on_20220414_101941.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 21): Loss/seq after 00000 batchs: 2267.5087890625
INFO:root:Train (Epoch 21): Loss/seq after 00050 batchs: 1710.2532958984375
INFO:root:Train (Epoch 21): Loss/seq after 00100 batchs: 1675.3756103515625
INFO:root:Train (Epoch 21): Loss/seq after 00150 batchs: 1490.998291015625
INFO:root:Train (Epoch 21): Loss/seq after 00200 batchs: 1614.556396484375
INFO:root:Train (Epoch 21): Loss/seq after 00250 batchs: 1735.69677734375
INFO:root:Train (Epoch 21): Loss/seq after 00300 batchs: 1632.0604248046875
INFO:root:Train (Epoch 21): Loss/seq after 00350 batchs: 1523.87744140625
INFO:root:Train (Epoch 21): Loss/seq after 00400 batchs: 1587.8924560546875
INFO:root:Train (Epoch 21): Loss/seq after 00450 batchs: 1509.0885009765625
INFO:root:Train (Epoch 21): Loss/seq after 00500 batchs: 1541.244140625
INFO:root:Train (Epoch 21): Loss/seq after 00550 batchs: 1476.9014892578125
INFO:root:Train (Epoch 21): Loss/seq after 00600 batchs: 1440.3216552734375
INFO:root:Train (Epoch 21): Loss/seq after 00650 batchs: 1471.5604248046875
INFO:root:Train (Epoch 21): Loss/seq after 00700 batchs: 1508.508056640625
INFO:root:Train (Epoch 21): Loss/seq after 00750 batchs: 1541.5023193359375
INFO:root:Train (Epoch 21): Loss/seq after 00800 batchs: 1530.7630615234375
INFO:root:Train (Epoch 21): Loss/seq after 00850 batchs: 1496.59130859375
INFO:root:Train (Epoch 21): Loss/seq after 00900 batchs: 1499.9871826171875
INFO:root:Train (Epoch 21): Loss/seq after 00950 batchs: 1563.6011962890625
INFO:root:Train (Epoch 21): Loss/seq after 01000 batchs: 1557.6220703125
INFO:root:Train (Epoch 21): Loss/seq after 01050 batchs: 1535.7523193359375
INFO:root:Train (Epoch 21): Loss/seq after 01100 batchs: 1523.349853515625
INFO:root:Train (Epoch 21): Loss/seq after 01150 batchs: 1499.4376220703125
INFO:root:Train (Epoch 21): Loss/seq after 01200 batchs: 1482.593505859375
INFO:root:Train (Epoch 21): Loss/seq after 01250 batchs: 1473.4881591796875
INFO:root:Train (Epoch 21): Loss/seq after 01300 batchs: 1480.771728515625
INFO:root:Train (Epoch 21): Loss/seq after 01350 batchs: 1480.1287841796875
INFO:root:Train (Epoch 21): Loss/seq after 01400 batchs: 1520.0374755859375
INFO:root:Train (Epoch 21): Loss/seq after 01450 batchs: 1505.0172119140625
INFO:root:Train (Epoch 21): Loss/seq after 01500 batchs: 1490.2235107421875
INFO:root:Train (Epoch 21): Loss/seq after 01550 batchs: 1490.6051025390625
INFO:root:Train (Epoch 21): Loss/seq after 01600 batchs: 1469.612060546875
INFO:root:Train (Epoch 21): Loss/seq after 01650 batchs: 1461.17138671875
INFO:root:Train (Epoch 21): Loss/seq after 01700 batchs: 1449.3577880859375
INFO:root:Train (Epoch 21): Loss/seq after 01750 batchs: 1433.7320556640625
INFO:root:Train (Epoch 21): Loss/seq after 01800 batchs: 1416.3455810546875
INFO:root:Train (Epoch 21): Loss/seq after 01850 batchs: 1399.567138671875
INFO:root:Train (Epoch 21): Loss/seq after 01900 batchs: 1395.54296875
INFO:root:Train (Epoch 21): Loss/seq after 01950 batchs: 1388.025390625
INFO:root:Train (Epoch 21): Loss/seq after 02000 batchs: 1375.7286376953125
INFO:root:Train (Epoch 21): Loss/seq after 02050 batchs: 1365.18310546875
INFO:root:Train (Epoch 21): Loss/seq after 02100 batchs: 1351.459228515625
INFO:root:Train (Epoch 21): Loss/seq after 02150 batchs: 1338.7191162109375
INFO:root:Train (Epoch 21): Loss/seq after 02200 batchs: 1325.3380126953125
INFO:root:Train (Epoch 21): Loss/seq after 02250 batchs: 1328.822021484375
INFO:root:Train (Epoch 21): Loss/seq after 02300 batchs: 1332.4871826171875
INFO:root:Train (Epoch 21): Loss/seq after 02350 batchs: 1322.572021484375
INFO:root:Train (Epoch 21): Loss/seq after 02400 batchs: 1317.515869140625
INFO:root:Train (Epoch 21): Loss/seq after 02450 batchs: 1303.591796875
INFO:root:Train (Epoch 21): Loss/seq after 02500 batchs: 1284.83154296875
INFO:root:Train (Epoch 21): Loss/seq after 02550 batchs: 1272.8448486328125
INFO:root:Train (Epoch 21): Loss/seq after 02600 batchs: 1269.4105224609375
INFO:root:Train (Epoch 21): Loss/seq after 02650 batchs: 1263.85693359375
INFO:root:Train (Epoch 21): Loss/seq after 02700 batchs: 1260.363037109375
INFO:root:Train (Epoch 21): Loss/seq after 02750 batchs: 1291.7503662109375
INFO:root:Train (Epoch 21): Loss/seq after 02800 batchs: 1299.9854736328125
INFO:root:Train (Epoch 21): Loss/seq after 02850 batchs: 1296.3916015625
INFO:root:Train (Epoch 21): Loss/seq after 02900 batchs: 1294.137939453125
INFO:root:Train (Epoch 21): Loss/seq after 02950 batchs: 1285.1092529296875
INFO:root:Train (Epoch 21): Loss/seq after 03000 batchs: 1281.8203125
INFO:root:Train (Epoch 21): Loss/seq after 03050 batchs: 1283.2138671875
INFO:root:Train (Epoch 21): Loss/seq after 03100 batchs: 1298.1865234375
INFO:root:Train (Epoch 21): Loss/seq after 03150 batchs: 1312.972900390625
INFO:root:Train (Epoch 21): Loss/seq after 03200 batchs: 1322.765869140625
INFO:root:Train (Epoch 21): Loss/seq after 03250 batchs: 1330.662109375
INFO:root:Train (Epoch 21): Loss/seq after 03300 batchs: 1331.215576171875
INFO:root:Train (Epoch 21): Loss/seq after 03350 batchs: 1331.2872314453125
INFO:root:Train (Epoch 21): Loss/seq after 03400 batchs: 1321.3079833984375
INFO:root:Train (Epoch 21): Loss/seq after 03450 batchs: 1313.2042236328125
INFO:root:Train (Epoch 21): Loss/seq after 03500 batchs: 1312.186767578125
INFO:root:Train (Epoch 21): Loss/seq after 03550 batchs: 1306.3135986328125
INFO:root:Train (Epoch 21): Loss/seq after 03600 batchs: 1311.08642578125
INFO:root:Train (Epoch 21): Loss/seq after 03650 batchs: 1305.8565673828125
INFO:root:Train (Epoch 21): Loss/seq after 03700 batchs: 1304.558837890625
INFO:root:Train (Epoch 21): Loss/seq after 03750 batchs: 1303.4007568359375
INFO:root:Train (Epoch 21): Loss/seq after 03800 batchs: 1295.4232177734375
INFO:root:Train (Epoch 21): Loss/seq after 03850 batchs: 1289.9703369140625
INFO:root:Train (Epoch 21): Loss/seq after 03900 batchs: 1296.7247314453125
INFO:root:Train (Epoch 21): Loss/seq after 03950 batchs: 1303.7281494140625
INFO:root:Train (Epoch 21): Loss/seq after 04000 batchs: 1293.7435302734375
INFO:root:Train (Epoch 21): Loss/seq after 04050 batchs: 1284.8280029296875
INFO:root:Train (Epoch 21): Loss/seq after 04100 batchs: 1278.929931640625
INFO:root:Train (Epoch 21): Loss/seq after 04150 batchs: 1272.29541015625
INFO:root:Train (Epoch 21): Loss/seq after 04200 batchs: 1266.5208740234375
INFO:root:Train (Epoch 21): Loss/seq after 04250 batchs: 1261.41064453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 21): Loss/seq after 00000 batches: 879.5418701171875
INFO:root:# Valid (Epoch 21): Loss/seq after 00050 batches: 1102.60546875
INFO:root:# Valid (Epoch 21): Loss/seq after 00100 batches: 1412.309326171875
INFO:root:# Valid (Epoch 21): Loss/seq after 00150 batches: 1137.8533935546875
INFO:root:# Valid (Epoch 21): Loss/seq after 00200 batches: 1025.4935302734375
INFO:root:Artifacts: Make stick videos for epoch 21
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_21_on_20220414_102504.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_21_index_1895_on_20220414_102504.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 22): Loss/seq after 00000 batchs: 2024.240478515625
INFO:root:Train (Epoch 22): Loss/seq after 00050 batchs: 1721.501708984375
INFO:root:Train (Epoch 22): Loss/seq after 00100 batchs: 1702.8914794921875
INFO:root:Train (Epoch 22): Loss/seq after 00150 batchs: 1508.811279296875
INFO:root:Train (Epoch 22): Loss/seq after 00200 batchs: 1623.1658935546875
INFO:root:Train (Epoch 22): Loss/seq after 00250 batchs: 1741.8814697265625
INFO:root:Train (Epoch 22): Loss/seq after 00300 batchs: 1636.599853515625
INFO:root:Train (Epoch 22): Loss/seq after 00350 batchs: 1527.6650390625
INFO:root:Train (Epoch 22): Loss/seq after 00400 batchs: 1584.446533203125
INFO:root:Train (Epoch 22): Loss/seq after 00450 batchs: 1506.0263671875
INFO:root:Train (Epoch 22): Loss/seq after 00500 batchs: 1536.423583984375
INFO:root:Train (Epoch 22): Loss/seq after 00550 batchs: 1471.7705078125
INFO:root:Train (Epoch 22): Loss/seq after 00600 batchs: 1436.024658203125
INFO:root:Train (Epoch 22): Loss/seq after 00650 batchs: 1474.124755859375
INFO:root:Train (Epoch 22): Loss/seq after 00700 batchs: 1509.0849609375
INFO:root:Train (Epoch 22): Loss/seq after 00750 batchs: 1550.153564453125
INFO:root:Train (Epoch 22): Loss/seq after 00800 batchs: 1537.907470703125
INFO:root:Train (Epoch 22): Loss/seq after 00850 batchs: 1501.6239013671875
INFO:root:Train (Epoch 22): Loss/seq after 00900 batchs: 1503.721435546875
INFO:root:Train (Epoch 22): Loss/seq after 00950 batchs: 1560.1160888671875
INFO:root:Train (Epoch 22): Loss/seq after 01000 batchs: 1555.4132080078125
INFO:root:Train (Epoch 22): Loss/seq after 01050 batchs: 1533.2020263671875
INFO:root:Train (Epoch 22): Loss/seq after 01100 batchs: 1521.0791015625
INFO:root:Train (Epoch 22): Loss/seq after 01150 batchs: 1497.1173095703125
INFO:root:Train (Epoch 22): Loss/seq after 01200 batchs: 1480.3138427734375
INFO:root:Train (Epoch 22): Loss/seq after 01250 batchs: 1471.20947265625
INFO:root:Train (Epoch 22): Loss/seq after 01300 batchs: 1476.856201171875
INFO:root:Train (Epoch 22): Loss/seq after 01350 batchs: 1475.2733154296875
INFO:root:Train (Epoch 22): Loss/seq after 01400 batchs: 1501.9034423828125
INFO:root:Train (Epoch 22): Loss/seq after 01450 batchs: 1486.9129638671875
INFO:root:Train (Epoch 22): Loss/seq after 01500 batchs: 1472.62890625
INFO:root:Train (Epoch 22): Loss/seq after 01550 batchs: 1473.5721435546875
INFO:root:Train (Epoch 22): Loss/seq after 01600 batchs: 1452.740234375
INFO:root:Train (Epoch 22): Loss/seq after 01650 batchs: 1444.2509765625
INFO:root:Train (Epoch 22): Loss/seq after 01700 batchs: 1432.1683349609375
INFO:root:Train (Epoch 22): Loss/seq after 01750 batchs: 1416.9320068359375
INFO:root:Train (Epoch 22): Loss/seq after 01800 batchs: 1400.0369873046875
INFO:root:Train (Epoch 22): Loss/seq after 01850 batchs: 1383.7205810546875
INFO:root:Train (Epoch 22): Loss/seq after 01900 batchs: 1380.141357421875
INFO:root:Train (Epoch 22): Loss/seq after 01950 batchs: 1372.9915771484375
INFO:root:Train (Epoch 22): Loss/seq after 02000 batchs: 1361.038818359375
INFO:root:Train (Epoch 22): Loss/seq after 02050 batchs: 1350.8170166015625
INFO:root:Train (Epoch 22): Loss/seq after 02100 batchs: 1337.4095458984375
INFO:root:Train (Epoch 22): Loss/seq after 02150 batchs: 1324.999267578125
INFO:root:Train (Epoch 22): Loss/seq after 02200 batchs: 1311.858642578125
INFO:root:Train (Epoch 22): Loss/seq after 02250 batchs: 1315.4228515625
INFO:root:Train (Epoch 22): Loss/seq after 02300 batchs: 1318.9884033203125
INFO:root:Train (Epoch 22): Loss/seq after 02350 batchs: 1308.44287109375
INFO:root:Train (Epoch 22): Loss/seq after 02400 batchs: 1303.38671875
INFO:root:Train (Epoch 22): Loss/seq after 02450 batchs: 1289.5750732421875
INFO:root:Train (Epoch 22): Loss/seq after 02500 batchs: 1271.0389404296875
INFO:root:Train (Epoch 22): Loss/seq after 02550 batchs: 1259.085205078125
INFO:root:Train (Epoch 22): Loss/seq after 02600 batchs: 1256.1351318359375
INFO:root:Train (Epoch 22): Loss/seq after 02650 batchs: 1250.806396484375
INFO:root:Train (Epoch 22): Loss/seq after 02700 batchs: 1247.5543212890625
INFO:root:Train (Epoch 22): Loss/seq after 02750 batchs: 1279.6915283203125
INFO:root:Train (Epoch 22): Loss/seq after 02800 batchs: 1287.14453125
INFO:root:Train (Epoch 22): Loss/seq after 02850 batchs: 1283.4461669921875
INFO:root:Train (Epoch 22): Loss/seq after 02900 batchs: 1280.942138671875
INFO:root:Train (Epoch 22): Loss/seq after 02950 batchs: 1271.9658203125
INFO:root:Train (Epoch 22): Loss/seq after 03000 batchs: 1268.9178466796875
INFO:root:Train (Epoch 22): Loss/seq after 03050 batchs: 1270.526611328125
INFO:root:Train (Epoch 22): Loss/seq after 03100 batchs: 1285.640625
INFO:root:Train (Epoch 22): Loss/seq after 03150 batchs: 1298.5838623046875
INFO:root:Train (Epoch 22): Loss/seq after 03200 batchs: 1304.5548095703125
INFO:root:Train (Epoch 22): Loss/seq after 03250 batchs: 1308.1602783203125
INFO:root:Train (Epoch 22): Loss/seq after 03300 batchs: 1308.57861328125
INFO:root:Train (Epoch 22): Loss/seq after 03350 batchs: 1308.2569580078125
INFO:root:Train (Epoch 22): Loss/seq after 03400 batchs: 1298.5611572265625
INFO:root:Train (Epoch 22): Loss/seq after 03450 batchs: 1290.9515380859375
INFO:root:Train (Epoch 22): Loss/seq after 03500 batchs: 1290.6129150390625
INFO:root:Train (Epoch 22): Loss/seq after 03550 batchs: 1285.0164794921875
INFO:root:Train (Epoch 22): Loss/seq after 03600 batchs: 1290.1416015625
INFO:root:Train (Epoch 22): Loss/seq after 03650 batchs: 1285.400634765625
INFO:root:Train (Epoch 22): Loss/seq after 03700 batchs: 1284.5081787109375
INFO:root:Train (Epoch 22): Loss/seq after 03750 batchs: 1283.6279296875
INFO:root:Train (Epoch 22): Loss/seq after 03800 batchs: 1275.9393310546875
INFO:root:Train (Epoch 22): Loss/seq after 03850 batchs: 1270.7635498046875
INFO:root:Train (Epoch 22): Loss/seq after 03900 batchs: 1276.8140869140625
INFO:root:Train (Epoch 22): Loss/seq after 03950 batchs: 1282.689453125
INFO:root:Train (Epoch 22): Loss/seq after 04000 batchs: 1272.9771728515625
INFO:root:Train (Epoch 22): Loss/seq after 04050 batchs: 1264.3082275390625
INFO:root:Train (Epoch 22): Loss/seq after 04100 batchs: 1258.47802734375
INFO:root:Train (Epoch 22): Loss/seq after 04150 batchs: 1252.10498046875
INFO:root:Train (Epoch 22): Loss/seq after 04200 batchs: 1246.6507568359375
INFO:root:Train (Epoch 22): Loss/seq after 04250 batchs: 1241.8280029296875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 22): Loss/seq after 00000 batches: 880.5540161132812
INFO:root:# Valid (Epoch 22): Loss/seq after 00050 batches: 1114.0322265625
INFO:root:# Valid (Epoch 22): Loss/seq after 00100 batches: 1421.4173583984375
INFO:root:# Valid (Epoch 22): Loss/seq after 00150 batches: 1145.6959228515625
INFO:root:# Valid (Epoch 22): Loss/seq after 00200 batches: 1033.607666015625
INFO:root:Artifacts: Make stick videos for epoch 22
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_22_on_20220414_103027.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_22_index_1375_on_20220414_103027.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 23): Loss/seq after 00000 batchs: 2047.6983642578125
INFO:root:Train (Epoch 23): Loss/seq after 00050 batchs: 1691.8463134765625
INFO:root:Train (Epoch 23): Loss/seq after 00100 batchs: 1649.7720947265625
INFO:root:Train (Epoch 23): Loss/seq after 00150 batchs: 1474.6007080078125
INFO:root:Train (Epoch 23): Loss/seq after 00200 batchs: 1598.8876953125
INFO:root:Train (Epoch 23): Loss/seq after 00250 batchs: 1733.781494140625
INFO:root:Train (Epoch 23): Loss/seq after 00300 batchs: 1629.4478759765625
INFO:root:Train (Epoch 23): Loss/seq after 00350 batchs: 1521.7286376953125
INFO:root:Train (Epoch 23): Loss/seq after 00400 batchs: 1577.1494140625
INFO:root:Train (Epoch 23): Loss/seq after 00450 batchs: 1499.8587646484375
INFO:root:Train (Epoch 23): Loss/seq after 00500 batchs: 1540.5230712890625
INFO:root:Train (Epoch 23): Loss/seq after 00550 batchs: 1475.927978515625
INFO:root:Train (Epoch 23): Loss/seq after 00600 batchs: 1439.3145751953125
INFO:root:Train (Epoch 23): Loss/seq after 00650 batchs: 1452.429931640625
INFO:root:Train (Epoch 23): Loss/seq after 00700 batchs: 1462.720947265625
INFO:root:Train (Epoch 23): Loss/seq after 00750 batchs: 1501.0284423828125
INFO:root:Train (Epoch 23): Loss/seq after 00800 batchs: 1491.7236328125
INFO:root:Train (Epoch 23): Loss/seq after 00850 batchs: 1458.68017578125
INFO:root:Train (Epoch 23): Loss/seq after 00900 batchs: 1464.046630859375
INFO:root:Train (Epoch 23): Loss/seq after 00950 batchs: 1518.665283203125
INFO:root:Train (Epoch 23): Loss/seq after 01000 batchs: 1516.5325927734375
INFO:root:Train (Epoch 23): Loss/seq after 01050 batchs: 1496.153076171875
INFO:root:Train (Epoch 23): Loss/seq after 01100 batchs: 1487.31494140625
INFO:root:Train (Epoch 23): Loss/seq after 01150 batchs: 1464.8426513671875
INFO:root:Train (Epoch 23): Loss/seq after 01200 batchs: 1449.309326171875
INFO:root:Train (Epoch 23): Loss/seq after 01250 batchs: 1440.60107421875
INFO:root:Train (Epoch 23): Loss/seq after 01300 batchs: 1448.3148193359375
INFO:root:Train (Epoch 23): Loss/seq after 01350 batchs: 1451.7078857421875
INFO:root:Train (Epoch 23): Loss/seq after 01400 batchs: 1486.1649169921875
INFO:root:Train (Epoch 23): Loss/seq after 01450 batchs: 1471.9071044921875
INFO:root:Train (Epoch 23): Loss/seq after 01500 batchs: 1458.1634521484375
INFO:root:Train (Epoch 23): Loss/seq after 01550 batchs: 1459.0152587890625
INFO:root:Train (Epoch 23): Loss/seq after 01600 batchs: 1438.3587646484375
INFO:root:Train (Epoch 23): Loss/seq after 01650 batchs: 1430.3851318359375
INFO:root:Train (Epoch 23): Loss/seq after 01700 batchs: 1418.62109375
INFO:root:Train (Epoch 23): Loss/seq after 01750 batchs: 1403.797119140625
INFO:root:Train (Epoch 23): Loss/seq after 01800 batchs: 1387.052734375
INFO:root:Train (Epoch 23): Loss/seq after 01850 batchs: 1370.8653564453125
INFO:root:Train (Epoch 23): Loss/seq after 01900 batchs: 1367.517333984375
INFO:root:Train (Epoch 23): Loss/seq after 01950 batchs: 1360.666015625
INFO:root:Train (Epoch 23): Loss/seq after 02000 batchs: 1349.0594482421875
INFO:root:Train (Epoch 23): Loss/seq after 02050 batchs: 1339.1177978515625
INFO:root:Train (Epoch 23): Loss/seq after 02100 batchs: 1325.996337890625
INFO:root:Train (Epoch 23): Loss/seq after 02150 batchs: 1313.7933349609375
INFO:root:Train (Epoch 23): Loss/seq after 02200 batchs: 1300.90869140625
INFO:root:Train (Epoch 23): Loss/seq after 02250 batchs: 1304.79296875
INFO:root:Train (Epoch 23): Loss/seq after 02300 batchs: 1310.2900390625
INFO:root:Train (Epoch 23): Loss/seq after 02350 batchs: 1299.91845703125
INFO:root:Train (Epoch 23): Loss/seq after 02400 batchs: 1294.9830322265625
INFO:root:Train (Epoch 23): Loss/seq after 02450 batchs: 1281.298095703125
INFO:root:Train (Epoch 23): Loss/seq after 02500 batchs: 1262.9351806640625
INFO:root:Train (Epoch 23): Loss/seq after 02550 batchs: 1251.1676025390625
INFO:root:Train (Epoch 23): Loss/seq after 02600 batchs: 1247.93505859375
INFO:root:Train (Epoch 23): Loss/seq after 02650 batchs: 1242.51318359375
INFO:root:Train (Epoch 23): Loss/seq after 02700 batchs: 1238.530517578125
INFO:root:Train (Epoch 23): Loss/seq after 02750 batchs: 1270.0133056640625
INFO:root:Train (Epoch 23): Loss/seq after 02800 batchs: 1277.418212890625
INFO:root:Train (Epoch 23): Loss/seq after 02850 batchs: 1273.9150390625
INFO:root:Train (Epoch 23): Loss/seq after 02900 batchs: 1271.815673828125
INFO:root:Train (Epoch 23): Loss/seq after 02950 batchs: 1262.9444580078125
INFO:root:Train (Epoch 23): Loss/seq after 03000 batchs: 1259.990234375
INFO:root:Train (Epoch 23): Loss/seq after 03050 batchs: 1261.76025390625
INFO:root:Train (Epoch 23): Loss/seq after 03100 batchs: 1276.0360107421875
INFO:root:Train (Epoch 23): Loss/seq after 03150 batchs: 1289.967529296875
INFO:root:Train (Epoch 23): Loss/seq after 03200 batchs: 1294.627685546875
INFO:root:Train (Epoch 23): Loss/seq after 03250 batchs: 1298.637451171875
INFO:root:Train (Epoch 23): Loss/seq after 03300 batchs: 1298.716064453125
INFO:root:Train (Epoch 23): Loss/seq after 03350 batchs: 1298.7999267578125
INFO:root:Train (Epoch 23): Loss/seq after 03400 batchs: 1289.2994384765625
INFO:root:Train (Epoch 23): Loss/seq after 03450 batchs: 1281.94921875
INFO:root:Train (Epoch 23): Loss/seq after 03500 batchs: 1281.4334716796875
INFO:root:Train (Epoch 23): Loss/seq after 03550 batchs: 1275.8643798828125
INFO:root:Train (Epoch 23): Loss/seq after 03600 batchs: 1281.13671875
INFO:root:Train (Epoch 23): Loss/seq after 03650 batchs: 1276.31298828125
INFO:root:Train (Epoch 23): Loss/seq after 03700 batchs: 1275.459716796875
INFO:root:Train (Epoch 23): Loss/seq after 03750 batchs: 1274.6932373046875
INFO:root:Train (Epoch 23): Loss/seq after 03800 batchs: 1267.0904541015625
INFO:root:Train (Epoch 23): Loss/seq after 03850 batchs: 1261.98291015625
INFO:root:Train (Epoch 23): Loss/seq after 03900 batchs: 1267.8154296875
INFO:root:Train (Epoch 23): Loss/seq after 03950 batchs: 1272.0633544921875
INFO:root:Train (Epoch 23): Loss/seq after 04000 batchs: 1262.4703369140625
INFO:root:Train (Epoch 23): Loss/seq after 04050 batchs: 1253.9366455078125
INFO:root:Train (Epoch 23): Loss/seq after 04100 batchs: 1248.3292236328125
INFO:root:Train (Epoch 23): Loss/seq after 04150 batchs: 1242.12255859375
INFO:root:Train (Epoch 23): Loss/seq after 04200 batchs: 1236.806640625
INFO:root:Train (Epoch 23): Loss/seq after 04250 batchs: 1232.031982421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 23): Loss/seq after 00000 batches: 882.0452270507812
INFO:root:# Valid (Epoch 23): Loss/seq after 00050 batches: 1106.12451171875
INFO:root:# Valid (Epoch 23): Loss/seq after 00100 batches: 1420.6466064453125
INFO:root:# Valid (Epoch 23): Loss/seq after 00150 batches: 1143.28466796875
INFO:root:# Valid (Epoch 23): Loss/seq after 00200 batches: 1029.50048828125
INFO:root:Artifacts: Make stick videos for epoch 23
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_23_on_20220414_103551.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_23_index_88_on_20220414_103551.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 24): Loss/seq after 00000 batchs: 1808.0009765625
INFO:root:Train (Epoch 24): Loss/seq after 00050 batchs: 1653.42724609375
INFO:root:Train (Epoch 24): Loss/seq after 00100 batchs: 1715.591552734375
INFO:root:Train (Epoch 24): Loss/seq after 00150 batchs: 1519.1309814453125
INFO:root:Train (Epoch 24): Loss/seq after 00200 batchs: 1652.5010986328125
INFO:root:Train (Epoch 24): Loss/seq after 00250 batchs: 1768.685546875
INFO:root:Train (Epoch 24): Loss/seq after 00300 batchs: 1658.3919677734375
INFO:root:Train (Epoch 24): Loss/seq after 00350 batchs: 1545.8675537109375
INFO:root:Train (Epoch 24): Loss/seq after 00400 batchs: 1593.7088623046875
INFO:root:Train (Epoch 24): Loss/seq after 00450 batchs: 1514.1937255859375
INFO:root:Train (Epoch 24): Loss/seq after 00500 batchs: 1542.6807861328125
INFO:root:Train (Epoch 24): Loss/seq after 00550 batchs: 1477.4403076171875
INFO:root:Train (Epoch 24): Loss/seq after 00600 batchs: 1440.6002197265625
INFO:root:Train (Epoch 24): Loss/seq after 00650 batchs: 1458.4468994140625
INFO:root:Train (Epoch 24): Loss/seq after 00700 batchs: 1476.22509765625
INFO:root:Train (Epoch 24): Loss/seq after 00750 batchs: 1516.052490234375
INFO:root:Train (Epoch 24): Loss/seq after 00800 batchs: 1506.5096435546875
INFO:root:Train (Epoch 24): Loss/seq after 00850 batchs: 1472.5198974609375
INFO:root:Train (Epoch 24): Loss/seq after 00900 batchs: 1483.2484130859375
INFO:root:Train (Epoch 24): Loss/seq after 00950 batchs: 1536.6929931640625
INFO:root:Train (Epoch 24): Loss/seq after 01000 batchs: 1527.7628173828125
INFO:root:Train (Epoch 24): Loss/seq after 01050 batchs: 1507.077880859375
INFO:root:Train (Epoch 24): Loss/seq after 01100 batchs: 1498.764404296875
INFO:root:Train (Epoch 24): Loss/seq after 01150 batchs: 1475.9439697265625
INFO:root:Train (Epoch 24): Loss/seq after 01200 batchs: 1459.982177734375
INFO:root:Train (Epoch 24): Loss/seq after 01250 batchs: 1451.680908203125
INFO:root:Train (Epoch 24): Loss/seq after 01300 batchs: 1449.5631103515625
INFO:root:Train (Epoch 24): Loss/seq after 01350 batchs: 1447.6746826171875
INFO:root:Train (Epoch 24): Loss/seq after 01400 batchs: 1472.242431640625
INFO:root:Train (Epoch 24): Loss/seq after 01450 batchs: 1458.58203125
INFO:root:Train (Epoch 24): Loss/seq after 01500 batchs: 1445.031982421875
INFO:root:Train (Epoch 24): Loss/seq after 01550 batchs: 1446.4361572265625
INFO:root:Train (Epoch 24): Loss/seq after 01600 batchs: 1426.187255859375
INFO:root:Train (Epoch 24): Loss/seq after 01650 batchs: 1418.4771728515625
INFO:root:Train (Epoch 24): Loss/seq after 01700 batchs: 1407.0626220703125
INFO:root:Train (Epoch 24): Loss/seq after 01750 batchs: 1392.5093994140625
INFO:root:Train (Epoch 24): Loss/seq after 01800 batchs: 1376.208740234375
INFO:root:Train (Epoch 24): Loss/seq after 01850 batchs: 1360.53857421875
INFO:root:Train (Epoch 24): Loss/seq after 01900 batchs: 1357.4859619140625
INFO:root:Train (Epoch 24): Loss/seq after 01950 batchs: 1350.8961181640625
INFO:root:Train (Epoch 24): Loss/seq after 02000 batchs: 1339.5054931640625
INFO:root:Train (Epoch 24): Loss/seq after 02050 batchs: 1329.7677001953125
INFO:root:Train (Epoch 24): Loss/seq after 02100 batchs: 1316.8665771484375
INFO:root:Train (Epoch 24): Loss/seq after 02150 batchs: 1304.909912109375
INFO:root:Train (Epoch 24): Loss/seq after 02200 batchs: 1292.3282470703125
INFO:root:Train (Epoch 24): Loss/seq after 02250 batchs: 1296.280029296875
INFO:root:Train (Epoch 24): Loss/seq after 02300 batchs: 1303.76025390625
INFO:root:Train (Epoch 24): Loss/seq after 02350 batchs: 1293.460693359375
INFO:root:Train (Epoch 24): Loss/seq after 02400 batchs: 1288.7149658203125
INFO:root:Train (Epoch 24): Loss/seq after 02450 batchs: 1275.4000244140625
INFO:root:Train (Epoch 24): Loss/seq after 02500 batchs: 1257.1517333984375
INFO:root:Train (Epoch 24): Loss/seq after 02550 batchs: 1245.7978515625
INFO:root:Train (Epoch 24): Loss/seq after 02600 batchs: 1244.4400634765625
INFO:root:Train (Epoch 24): Loss/seq after 02650 batchs: 1239.7342529296875
INFO:root:Train (Epoch 24): Loss/seq after 02700 batchs: 1237.431884765625
INFO:root:Train (Epoch 24): Loss/seq after 02750 batchs: 1269.1317138671875
INFO:root:Train (Epoch 24): Loss/seq after 02800 batchs: 1275.646240234375
INFO:root:Train (Epoch 24): Loss/seq after 02850 batchs: 1272.281982421875
INFO:root:Train (Epoch 24): Loss/seq after 02900 batchs: 1270.2186279296875
INFO:root:Train (Epoch 24): Loss/seq after 02950 batchs: 1261.4818115234375
INFO:root:Train (Epoch 24): Loss/seq after 03000 batchs: 1258.5872802734375
INFO:root:Train (Epoch 24): Loss/seq after 03050 batchs: 1260.3697509765625
INFO:root:Train (Epoch 24): Loss/seq after 03100 batchs: 1274.4774169921875
INFO:root:Train (Epoch 24): Loss/seq after 03150 batchs: 1288.8541259765625
INFO:root:Train (Epoch 24): Loss/seq after 03200 batchs: 1294.50927734375
INFO:root:Train (Epoch 24): Loss/seq after 03250 batchs: 1296.95458984375
INFO:root:Train (Epoch 24): Loss/seq after 03300 batchs: 1296.9293212890625
INFO:root:Train (Epoch 24): Loss/seq after 03350 batchs: 1297.51025390625
INFO:root:Train (Epoch 24): Loss/seq after 03400 batchs: 1287.9267578125
INFO:root:Train (Epoch 24): Loss/seq after 03450 batchs: 1280.177978515625
INFO:root:Train (Epoch 24): Loss/seq after 03500 batchs: 1279.8372802734375
INFO:root:Train (Epoch 24): Loss/seq after 03550 batchs: 1274.265625
INFO:root:Train (Epoch 24): Loss/seq after 03600 batchs: 1279.50537109375
INFO:root:Train (Epoch 24): Loss/seq after 03650 batchs: 1274.651611328125
INFO:root:Train (Epoch 24): Loss/seq after 03700 batchs: 1273.7554931640625
INFO:root:Train (Epoch 24): Loss/seq after 03750 batchs: 1272.9776611328125
INFO:root:Train (Epoch 24): Loss/seq after 03800 batchs: 1265.4093017578125
INFO:root:Train (Epoch 24): Loss/seq after 03850 batchs: 1260.3553466796875
INFO:root:Train (Epoch 24): Loss/seq after 03900 batchs: 1266.81787109375
INFO:root:Train (Epoch 24): Loss/seq after 03950 batchs: 1270.9400634765625
INFO:root:Train (Epoch 24): Loss/seq after 04000 batchs: 1261.361083984375
INFO:root:Train (Epoch 24): Loss/seq after 04050 batchs: 1252.835205078125
INFO:root:Train (Epoch 24): Loss/seq after 04100 batchs: 1247.1629638671875
INFO:root:Train (Epoch 24): Loss/seq after 04150 batchs: 1240.901123046875
INFO:root:Train (Epoch 24): Loss/seq after 04200 batchs: 1235.5941162109375
INFO:root:Train (Epoch 24): Loss/seq after 04250 batchs: 1230.902587890625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 24): Loss/seq after 00000 batches: 880.5540771484375
INFO:root:# Valid (Epoch 24): Loss/seq after 00050 batches: 1110.0853271484375
INFO:root:# Valid (Epoch 24): Loss/seq after 00100 batches: 1425.0074462890625
INFO:root:# Valid (Epoch 24): Loss/seq after 00150 batches: 1149.0699462890625
INFO:root:# Valid (Epoch 24): Loss/seq after 00200 batches: 1034.6241455078125
INFO:root:Artifacts: Make stick videos for epoch 24
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_24_on_20220414_104116.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_24_index_1834_on_20220414_104116.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 25): Loss/seq after 00000 batchs: 1916.6942138671875
INFO:root:Train (Epoch 25): Loss/seq after 00050 batchs: 1632.5045166015625
INFO:root:Train (Epoch 25): Loss/seq after 00100 batchs: 1663.7530517578125
INFO:root:Train (Epoch 25): Loss/seq after 00150 batchs: 1482.0025634765625
INFO:root:Train (Epoch 25): Loss/seq after 00200 batchs: 1594.7139892578125
INFO:root:Train (Epoch 25): Loss/seq after 00250 batchs: 1715.8575439453125
INFO:root:Train (Epoch 25): Loss/seq after 00300 batchs: 1614.03759765625
INFO:root:Train (Epoch 25): Loss/seq after 00350 batchs: 1508.0540771484375
INFO:root:Train (Epoch 25): Loss/seq after 00400 batchs: 1554.8809814453125
INFO:root:Train (Epoch 25): Loss/seq after 00450 batchs: 1479.7354736328125
INFO:root:Train (Epoch 25): Loss/seq after 00500 batchs: 1511.5228271484375
INFO:root:Train (Epoch 25): Loss/seq after 00550 batchs: 1449.1771240234375
INFO:root:Train (Epoch 25): Loss/seq after 00600 batchs: 1414.760498046875
INFO:root:Train (Epoch 25): Loss/seq after 00650 batchs: 1428.9412841796875
INFO:root:Train (Epoch 25): Loss/seq after 00700 batchs: 1426.63037109375
INFO:root:Train (Epoch 25): Loss/seq after 00750 batchs: 1459.2735595703125
INFO:root:Train (Epoch 25): Loss/seq after 00800 batchs: 1452.3121337890625
INFO:root:Train (Epoch 25): Loss/seq after 00850 batchs: 1420.864013671875
INFO:root:Train (Epoch 25): Loss/seq after 00900 batchs: 1426.8076171875
INFO:root:Train (Epoch 25): Loss/seq after 00950 batchs: 1470.7991943359375
INFO:root:Train (Epoch 25): Loss/seq after 01000 batchs: 1466.885498046875
INFO:root:Train (Epoch 25): Loss/seq after 01050 batchs: 1449.0115966796875
INFO:root:Train (Epoch 25): Loss/seq after 01100 batchs: 1441.6707763671875
INFO:root:Train (Epoch 25): Loss/seq after 01150 batchs: 1421.1123046875
INFO:root:Train (Epoch 25): Loss/seq after 01200 batchs: 1407.3443603515625
INFO:root:Train (Epoch 25): Loss/seq after 01250 batchs: 1400.081298828125
INFO:root:Train (Epoch 25): Loss/seq after 01300 batchs: 1398.1380615234375
INFO:root:Train (Epoch 25): Loss/seq after 01350 batchs: 1399.3372802734375
INFO:root:Train (Epoch 25): Loss/seq after 01400 batchs: 1424.637451171875
INFO:root:Train (Epoch 25): Loss/seq after 01450 batchs: 1412.93798828125
INFO:root:Train (Epoch 25): Loss/seq after 01500 batchs: 1401.350341796875
INFO:root:Train (Epoch 25): Loss/seq after 01550 batchs: 1404.8250732421875
INFO:root:Train (Epoch 25): Loss/seq after 01600 batchs: 1386.1634521484375
INFO:root:Train (Epoch 25): Loss/seq after 01650 batchs: 1379.5859375
INFO:root:Train (Epoch 25): Loss/seq after 01700 batchs: 1369.1207275390625
INFO:root:Train (Epoch 25): Loss/seq after 01750 batchs: 1355.6925048828125
INFO:root:Train (Epoch 25): Loss/seq after 01800 batchs: 1340.4111328125
INFO:root:Train (Epoch 25): Loss/seq after 01850 batchs: 1325.670166015625
INFO:root:Train (Epoch 25): Loss/seq after 01900 batchs: 1323.534912109375
INFO:root:Train (Epoch 25): Loss/seq after 01950 batchs: 1317.761962890625
INFO:root:Train (Epoch 25): Loss/seq after 02000 batchs: 1307.1572265625
INFO:root:Train (Epoch 25): Loss/seq after 02050 batchs: 1298.1925048828125
INFO:root:Train (Epoch 25): Loss/seq after 02100 batchs: 1286.026123046875
INFO:root:Train (Epoch 25): Loss/seq after 02150 batchs: 1274.7579345703125
INFO:root:Train (Epoch 25): Loss/seq after 02200 batchs: 1262.8125
INFO:root:Train (Epoch 25): Loss/seq after 02250 batchs: 1267.1929931640625
INFO:root:Train (Epoch 25): Loss/seq after 02300 batchs: 1275.7781982421875
INFO:root:Train (Epoch 25): Loss/seq after 02350 batchs: 1266.130615234375
INFO:root:Train (Epoch 25): Loss/seq after 02400 batchs: 1262.117919921875
INFO:root:Train (Epoch 25): Loss/seq after 02450 batchs: 1249.5155029296875
INFO:root:Train (Epoch 25): Loss/seq after 02500 batchs: 1231.8236083984375
INFO:root:Train (Epoch 25): Loss/seq after 02550 batchs: 1220.7022705078125
INFO:root:Train (Epoch 25): Loss/seq after 02600 batchs: 1219.6834716796875
INFO:root:Train (Epoch 25): Loss/seq after 02650 batchs: 1215.1519775390625
INFO:root:Train (Epoch 25): Loss/seq after 02700 batchs: 1213.4764404296875
INFO:root:Train (Epoch 25): Loss/seq after 02750 batchs: 1245.5452880859375
INFO:root:Train (Epoch 25): Loss/seq after 02800 batchs: 1251.930419921875
INFO:root:Train (Epoch 25): Loss/seq after 02850 batchs: 1249.0953369140625
INFO:root:Train (Epoch 25): Loss/seq after 02900 batchs: 1247.779052734375
INFO:root:Train (Epoch 25): Loss/seq after 02950 batchs: 1239.4383544921875
INFO:root:Train (Epoch 25): Loss/seq after 03000 batchs: 1236.9166259765625
INFO:root:Train (Epoch 25): Loss/seq after 03050 batchs: 1239.116943359375
INFO:root:Train (Epoch 25): Loss/seq after 03100 batchs: 1253.19189453125
INFO:root:Train (Epoch 25): Loss/seq after 03150 batchs: 1266.114501953125
INFO:root:Train (Epoch 25): Loss/seq after 03200 batchs: 1272.177734375
INFO:root:Train (Epoch 25): Loss/seq after 03250 batchs: 1274.9073486328125
INFO:root:Train (Epoch 25): Loss/seq after 03300 batchs: 1276.8582763671875
INFO:root:Train (Epoch 25): Loss/seq after 03350 batchs: 1276.916748046875
INFO:root:Train (Epoch 25): Loss/seq after 03400 batchs: 1267.6854248046875
INFO:root:Train (Epoch 25): Loss/seq after 03450 batchs: 1260.3128662109375
INFO:root:Train (Epoch 25): Loss/seq after 03500 batchs: 1260.458740234375
INFO:root:Train (Epoch 25): Loss/seq after 03550 batchs: 1255.1243896484375
INFO:root:Train (Epoch 25): Loss/seq after 03600 batchs: 1260.61865234375
INFO:root:Train (Epoch 25): Loss/seq after 03650 batchs: 1256.031982421875
INFO:root:Train (Epoch 25): Loss/seq after 03700 batchs: 1255.4830322265625
INFO:root:Train (Epoch 25): Loss/seq after 03750 batchs: 1254.9866943359375
INFO:root:Train (Epoch 25): Loss/seq after 03800 batchs: 1247.6300048828125
INFO:root:Train (Epoch 25): Loss/seq after 03850 batchs: 1242.770751953125
INFO:root:Train (Epoch 25): Loss/seq after 03900 batchs: 1248.385009765625
INFO:root:Train (Epoch 25): Loss/seq after 03950 batchs: 1252.68115234375
INFO:root:Train (Epoch 25): Loss/seq after 04000 batchs: 1243.328369140625
INFO:root:Train (Epoch 25): Loss/seq after 04050 batchs: 1235.021728515625
INFO:root:Train (Epoch 25): Loss/seq after 04100 batchs: 1229.6202392578125
INFO:root:Train (Epoch 25): Loss/seq after 04150 batchs: 1223.566650390625
INFO:root:Train (Epoch 25): Loss/seq after 04200 batchs: 1218.4544677734375
INFO:root:Train (Epoch 25): Loss/seq after 04250 batchs: 1213.93603515625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 25): Loss/seq after 00000 batches: 881.3123168945312
INFO:root:# Valid (Epoch 25): Loss/seq after 00050 batches: 1107.0579833984375
INFO:root:# Valid (Epoch 25): Loss/seq after 00100 batches: 1416.6846923828125
INFO:root:# Valid (Epoch 25): Loss/seq after 00150 batches: 1138.9400634765625
INFO:root:# Valid (Epoch 25): Loss/seq after 00200 batches: 1025.1458740234375
INFO:root:Artifacts: Make stick videos for epoch 25
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_25_on_20220414_104640.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_25_index_1318_on_20220414_104640.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 26): Loss/seq after 00000 batchs: 1653.89306640625
INFO:root:Train (Epoch 26): Loss/seq after 00050 batchs: 1624.2225341796875
INFO:root:Train (Epoch 26): Loss/seq after 00100 batchs: 1653.675048828125
INFO:root:Train (Epoch 26): Loss/seq after 00150 batchs: 1476.3017578125
INFO:root:Train (Epoch 26): Loss/seq after 00200 batchs: 1606.2110595703125
INFO:root:Train (Epoch 26): Loss/seq after 00250 batchs: 1736.2215576171875
INFO:root:Train (Epoch 26): Loss/seq after 00300 batchs: 1631.28466796875
INFO:root:Train (Epoch 26): Loss/seq after 00350 batchs: 1523.192626953125
INFO:root:Train (Epoch 26): Loss/seq after 00400 batchs: 1571.755615234375
INFO:root:Train (Epoch 26): Loss/seq after 00450 batchs: 1494.5916748046875
INFO:root:Train (Epoch 26): Loss/seq after 00500 batchs: 1525.3612060546875
INFO:root:Train (Epoch 26): Loss/seq after 00550 batchs: 1461.3497314453125
INFO:root:Train (Epoch 26): Loss/seq after 00600 batchs: 1423.159423828125
INFO:root:Train (Epoch 26): Loss/seq after 00650 batchs: 1437.276123046875
INFO:root:Train (Epoch 26): Loss/seq after 00700 batchs: 1436.7535400390625
INFO:root:Train (Epoch 26): Loss/seq after 00750 batchs: 1470.865478515625
INFO:root:Train (Epoch 26): Loss/seq after 00800 batchs: 1463.6077880859375
INFO:root:Train (Epoch 26): Loss/seq after 00850 batchs: 1432.17041015625
INFO:root:Train (Epoch 26): Loss/seq after 00900 batchs: 1442.1185302734375
INFO:root:Train (Epoch 26): Loss/seq after 00950 batchs: 1488.4837646484375
INFO:root:Train (Epoch 26): Loss/seq after 01000 batchs: 1479.4764404296875
INFO:root:Train (Epoch 26): Loss/seq after 01050 batchs: 1461.307861328125
INFO:root:Train (Epoch 26): Loss/seq after 01100 batchs: 1459.3233642578125
INFO:root:Train (Epoch 26): Loss/seq after 01150 batchs: 1438.008544921875
INFO:root:Train (Epoch 26): Loss/seq after 01200 batchs: 1423.9029541015625
INFO:root:Train (Epoch 26): Loss/seq after 01250 batchs: 1417.3673095703125
INFO:root:Train (Epoch 26): Loss/seq after 01300 batchs: 1418.7952880859375
INFO:root:Train (Epoch 26): Loss/seq after 01350 batchs: 1418.2843017578125
INFO:root:Train (Epoch 26): Loss/seq after 01400 batchs: 1445.023681640625
INFO:root:Train (Epoch 26): Loss/seq after 01450 batchs: 1431.7808837890625
INFO:root:Train (Epoch 26): Loss/seq after 01500 batchs: 1419.14599609375
INFO:root:Train (Epoch 26): Loss/seq after 01550 batchs: 1422.9072265625
INFO:root:Train (Epoch 26): Loss/seq after 01600 batchs: 1403.55517578125
INFO:root:Train (Epoch 26): Loss/seq after 01650 batchs: 1396.476318359375
INFO:root:Train (Epoch 26): Loss/seq after 01700 batchs: 1385.787841796875
INFO:root:Train (Epoch 26): Loss/seq after 01750 batchs: 1371.9388427734375
INFO:root:Train (Epoch 26): Loss/seq after 01800 batchs: 1356.3009033203125
INFO:root:Train (Epoch 26): Loss/seq after 01850 batchs: 1341.0855712890625
INFO:root:Train (Epoch 26): Loss/seq after 01900 batchs: 1338.4873046875
INFO:root:Train (Epoch 26): Loss/seq after 01950 batchs: 1332.337158203125
INFO:root:Train (Epoch 26): Loss/seq after 02000 batchs: 1321.438232421875
INFO:root:Train (Epoch 26): Loss/seq after 02050 batchs: 1312.1309814453125
INFO:root:Train (Epoch 26): Loss/seq after 02100 batchs: 1299.6341552734375
INFO:root:Train (Epoch 26): Loss/seq after 02150 batchs: 1288.0533447265625
INFO:root:Train (Epoch 26): Loss/seq after 02200 batchs: 1275.7694091796875
INFO:root:Train (Epoch 26): Loss/seq after 02250 batchs: 1279.96923828125
INFO:root:Train (Epoch 26): Loss/seq after 02300 batchs: 1287.0516357421875
INFO:root:Train (Epoch 26): Loss/seq after 02350 batchs: 1277.0572509765625
INFO:root:Train (Epoch 26): Loss/seq after 02400 batchs: 1272.5914306640625
INFO:root:Train (Epoch 26): Loss/seq after 02450 batchs: 1259.3048095703125
INFO:root:Train (Epoch 26): Loss/seq after 02500 batchs: 1241.378173828125
INFO:root:Train (Epoch 26): Loss/seq after 02550 batchs: 1229.866455078125
INFO:root:Train (Epoch 26): Loss/seq after 02600 batchs: 1226.871826171875
INFO:root:Train (Epoch 26): Loss/seq after 02650 batchs: 1221.83544921875
INFO:root:Train (Epoch 26): Loss/seq after 02700 batchs: 1218.1092529296875
INFO:root:Train (Epoch 26): Loss/seq after 02750 batchs: 1250.482177734375
INFO:root:Train (Epoch 26): Loss/seq after 02800 batchs: 1256.589599609375
INFO:root:Train (Epoch 26): Loss/seq after 02850 batchs: 1253.238037109375
INFO:root:Train (Epoch 26): Loss/seq after 02900 batchs: 1251.3466796875
INFO:root:Train (Epoch 26): Loss/seq after 02950 batchs: 1242.8284912109375
INFO:root:Train (Epoch 26): Loss/seq after 03000 batchs: 1240.2369384765625
INFO:root:Train (Epoch 26): Loss/seq after 03050 batchs: 1242.355224609375
INFO:root:Train (Epoch 26): Loss/seq after 03100 batchs: 1255.18212890625
INFO:root:Train (Epoch 26): Loss/seq after 03150 batchs: 1266.94873046875
INFO:root:Train (Epoch 26): Loss/seq after 03200 batchs: 1271.9732666015625
INFO:root:Train (Epoch 26): Loss/seq after 03250 batchs: 1274.9586181640625
INFO:root:Train (Epoch 26): Loss/seq after 03300 batchs: 1276.6943359375
INFO:root:Train (Epoch 26): Loss/seq after 03350 batchs: 1276.6011962890625
INFO:root:Train (Epoch 26): Loss/seq after 03400 batchs: 1267.35107421875
INFO:root:Train (Epoch 26): Loss/seq after 03450 batchs: 1259.86083984375
INFO:root:Train (Epoch 26): Loss/seq after 03500 batchs: 1259.8612060546875
INFO:root:Train (Epoch 26): Loss/seq after 03550 batchs: 1254.5579833984375
INFO:root:Train (Epoch 26): Loss/seq after 03600 batchs: 1260.052001953125
INFO:root:Train (Epoch 26): Loss/seq after 03650 batchs: 1255.6395263671875
INFO:root:Train (Epoch 26): Loss/seq after 03700 batchs: 1255.0614013671875
INFO:root:Train (Epoch 26): Loss/seq after 03750 batchs: 1254.552734375
INFO:root:Train (Epoch 26): Loss/seq after 03800 batchs: 1247.21337890625
INFO:root:Train (Epoch 26): Loss/seq after 03850 batchs: 1242.369140625
INFO:root:Train (Epoch 26): Loss/seq after 03900 batchs: 1249.046630859375
INFO:root:Train (Epoch 26): Loss/seq after 03950 batchs: 1253.9078369140625
INFO:root:Train (Epoch 26): Loss/seq after 04000 batchs: 1244.517822265625
INFO:root:Train (Epoch 26): Loss/seq after 04050 batchs: 1236.19287109375
INFO:root:Train (Epoch 26): Loss/seq after 04100 batchs: 1230.6600341796875
INFO:root:Train (Epoch 26): Loss/seq after 04150 batchs: 1224.645263671875
INFO:root:Train (Epoch 26): Loss/seq after 04200 batchs: 1219.5963134765625
INFO:root:Train (Epoch 26): Loss/seq after 04250 batchs: 1215.0301513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 26): Loss/seq after 00000 batches: 881.4862670898438
INFO:root:# Valid (Epoch 26): Loss/seq after 00050 batches: 1108.4666748046875
INFO:root:# Valid (Epoch 26): Loss/seq after 00100 batches: 1417.12353515625
INFO:root:# Valid (Epoch 26): Loss/seq after 00150 batches: 1143.0404052734375
INFO:root:# Valid (Epoch 26): Loss/seq after 00200 batches: 1030.3714599609375
INFO:root:Artifacts: Make stick videos for epoch 26
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_26_on_20220414_105205.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_26_index_1635_on_20220414_105205.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 27): Loss/seq after 00000 batchs: 1815.33349609375
INFO:root:Train (Epoch 27): Loss/seq after 00050 batchs: 1628.265869140625
INFO:root:Train (Epoch 27): Loss/seq after 00100 batchs: 1643.8326416015625
INFO:root:Train (Epoch 27): Loss/seq after 00150 batchs: 1467.95458984375
INFO:root:Train (Epoch 27): Loss/seq after 00200 batchs: 1580.2608642578125
INFO:root:Train (Epoch 27): Loss/seq after 00250 batchs: 1712.7392578125
INFO:root:Train (Epoch 27): Loss/seq after 00300 batchs: 1613.79638671875
INFO:root:Train (Epoch 27): Loss/seq after 00350 batchs: 1508.8326416015625
INFO:root:Train (Epoch 27): Loss/seq after 00400 batchs: 1559.25048828125
INFO:root:Train (Epoch 27): Loss/seq after 00450 batchs: 1483.603759765625
INFO:root:Train (Epoch 27): Loss/seq after 00500 batchs: 1515.912353515625
INFO:root:Train (Epoch 27): Loss/seq after 00550 batchs: 1452.7041015625
INFO:root:Train (Epoch 27): Loss/seq after 00600 batchs: 1416.479248046875
INFO:root:Train (Epoch 27): Loss/seq after 00650 batchs: 1434.8896484375
INFO:root:Train (Epoch 27): Loss/seq after 00700 batchs: 1441.2900390625
INFO:root:Train (Epoch 27): Loss/seq after 00750 batchs: 1477.5009765625
INFO:root:Train (Epoch 27): Loss/seq after 00800 batchs: 1469.8907470703125
INFO:root:Train (Epoch 27): Loss/seq after 00850 batchs: 1438.030517578125
INFO:root:Train (Epoch 27): Loss/seq after 00900 batchs: 1449.2493896484375
INFO:root:Train (Epoch 27): Loss/seq after 00950 batchs: 1501.6680908203125
INFO:root:Train (Epoch 27): Loss/seq after 01000 batchs: 1494.350341796875
INFO:root:Train (Epoch 27): Loss/seq after 01050 batchs: 1474.7049560546875
INFO:root:Train (Epoch 27): Loss/seq after 01100 batchs: 1465.5126953125
INFO:root:Train (Epoch 27): Loss/seq after 01150 batchs: 1443.914306640625
INFO:root:Train (Epoch 27): Loss/seq after 01200 batchs: 1429.293212890625
INFO:root:Train (Epoch 27): Loss/seq after 01250 batchs: 1421.6837158203125
INFO:root:Train (Epoch 27): Loss/seq after 01300 batchs: 1418.3839111328125
INFO:root:Train (Epoch 27): Loss/seq after 01350 batchs: 1418.02978515625
INFO:root:Train (Epoch 27): Loss/seq after 01400 batchs: 1442.2547607421875
INFO:root:Train (Epoch 27): Loss/seq after 01450 batchs: 1429.5941162109375
INFO:root:Train (Epoch 27): Loss/seq after 01500 batchs: 1417.1357421875
INFO:root:Train (Epoch 27): Loss/seq after 01550 batchs: 1419.421142578125
INFO:root:Train (Epoch 27): Loss/seq after 01600 batchs: 1400.14404296875
INFO:root:Train (Epoch 27): Loss/seq after 01650 batchs: 1393.1380615234375
INFO:root:Train (Epoch 27): Loss/seq after 01700 batchs: 1382.383544921875
INFO:root:Train (Epoch 27): Loss/seq after 01750 batchs: 1368.540283203125
INFO:root:Train (Epoch 27): Loss/seq after 01800 batchs: 1352.7958984375
INFO:root:Train (Epoch 27): Loss/seq after 01850 batchs: 1337.5205078125
INFO:root:Train (Epoch 27): Loss/seq after 01900 batchs: 1334.988525390625
INFO:root:Train (Epoch 27): Loss/seq after 01950 batchs: 1328.8802490234375
INFO:root:Train (Epoch 27): Loss/seq after 02000 batchs: 1317.966552734375
INFO:root:Train (Epoch 27): Loss/seq after 02050 batchs: 1308.737060546875
INFO:root:Train (Epoch 27): Loss/seq after 02100 batchs: 1296.294189453125
INFO:root:Train (Epoch 27): Loss/seq after 02150 batchs: 1284.803466796875
INFO:root:Train (Epoch 27): Loss/seq after 02200 batchs: 1272.5552978515625
INFO:root:Train (Epoch 27): Loss/seq after 02250 batchs: 1276.72314453125
INFO:root:Train (Epoch 27): Loss/seq after 02300 batchs: 1284.646240234375
INFO:root:Train (Epoch 27): Loss/seq after 02350 batchs: 1274.716796875
INFO:root:Train (Epoch 27): Loss/seq after 02400 batchs: 1270.2730712890625
INFO:root:Train (Epoch 27): Loss/seq after 02450 batchs: 1257.08935546875
INFO:root:Train (Epoch 27): Loss/seq after 02500 batchs: 1239.1907958984375
INFO:root:Train (Epoch 27): Loss/seq after 02550 batchs: 1227.82568359375
INFO:root:Train (Epoch 27): Loss/seq after 02600 batchs: 1225.7344970703125
INFO:root:Train (Epoch 27): Loss/seq after 02650 batchs: 1221.0333251953125
INFO:root:Train (Epoch 27): Loss/seq after 02700 batchs: 1218.156982421875
INFO:root:Train (Epoch 27): Loss/seq after 02750 batchs: 1250.9847412109375
INFO:root:Train (Epoch 27): Loss/seq after 02800 batchs: 1257.4344482421875
INFO:root:Train (Epoch 27): Loss/seq after 02850 batchs: 1254.1650390625
INFO:root:Train (Epoch 27): Loss/seq after 02900 batchs: 1252.4466552734375
INFO:root:Train (Epoch 27): Loss/seq after 02950 batchs: 1243.9503173828125
INFO:root:Train (Epoch 27): Loss/seq after 03000 batchs: 1241.326416015625
INFO:root:Train (Epoch 27): Loss/seq after 03050 batchs: 1243.4449462890625
INFO:root:Train (Epoch 27): Loss/seq after 03100 batchs: 1258.3870849609375
INFO:root:Train (Epoch 27): Loss/seq after 03150 batchs: 1269.1641845703125
INFO:root:Train (Epoch 27): Loss/seq after 03200 batchs: 1274.4041748046875
INFO:root:Train (Epoch 27): Loss/seq after 03250 batchs: 1276.26171875
INFO:root:Train (Epoch 27): Loss/seq after 03300 batchs: 1276.903076171875
INFO:root:Train (Epoch 27): Loss/seq after 03350 batchs: 1276.9112548828125
INFO:root:Train (Epoch 27): Loss/seq after 03400 batchs: 1267.68603515625
INFO:root:Train (Epoch 27): Loss/seq after 03450 batchs: 1260.2261962890625
INFO:root:Train (Epoch 27): Loss/seq after 03500 batchs: 1260.0562744140625
INFO:root:Train (Epoch 27): Loss/seq after 03550 batchs: 1254.929931640625
INFO:root:Train (Epoch 27): Loss/seq after 03600 batchs: 1260.4677734375
INFO:root:Train (Epoch 27): Loss/seq after 03650 batchs: 1255.865966796875
INFO:root:Train (Epoch 27): Loss/seq after 03700 batchs: 1255.318115234375
INFO:root:Train (Epoch 27): Loss/seq after 03750 batchs: 1254.8369140625
INFO:root:Train (Epoch 27): Loss/seq after 03800 batchs: 1247.4818115234375
INFO:root:Train (Epoch 27): Loss/seq after 03850 batchs: 1242.623046875
INFO:root:Train (Epoch 27): Loss/seq after 03900 batchs: 1247.9803466796875
INFO:root:Train (Epoch 27): Loss/seq after 03950 batchs: 1251.9254150390625
INFO:root:Train (Epoch 27): Loss/seq after 04000 batchs: 1242.5728759765625
INFO:root:Train (Epoch 27): Loss/seq after 04050 batchs: 1234.2725830078125
INFO:root:Train (Epoch 27): Loss/seq after 04100 batchs: 1228.911865234375
INFO:root:Train (Epoch 27): Loss/seq after 04150 batchs: 1222.8526611328125
INFO:root:Train (Epoch 27): Loss/seq after 04200 batchs: 1217.6962890625
INFO:root:Train (Epoch 27): Loss/seq after 04250 batchs: 1213.1778564453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 27): Loss/seq after 00000 batches: 877.8848266601562
INFO:root:# Valid (Epoch 27): Loss/seq after 00050 batches: 1107.17236328125
INFO:root:# Valid (Epoch 27): Loss/seq after 00100 batches: 1418.540771484375
INFO:root:# Valid (Epoch 27): Loss/seq after 00150 batches: 1144.36865234375
INFO:root:# Valid (Epoch 27): Loss/seq after 00200 batches: 1033.3289794921875
INFO:root:Artifacts: Make stick videos for epoch 27
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_27_on_20220414_105731.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_27_index_1113_on_20220414_105731.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 28): Loss/seq after 00000 batchs: 2086.790283203125
INFO:root:Train (Epoch 28): Loss/seq after 00050 batchs: 1603.510498046875
INFO:root:Train (Epoch 28): Loss/seq after 00100 batchs: 1655.240478515625
INFO:root:Train (Epoch 28): Loss/seq after 00150 batchs: 1478.5751953125
INFO:root:Train (Epoch 28): Loss/seq after 00200 batchs: 1603.5184326171875
INFO:root:Train (Epoch 28): Loss/seq after 00250 batchs: 1722.4632568359375
INFO:root:Train (Epoch 28): Loss/seq after 00300 batchs: 1619.7474365234375
INFO:root:Train (Epoch 28): Loss/seq after 00350 batchs: 1513.243896484375
INFO:root:Train (Epoch 28): Loss/seq after 00400 batchs: 1559.789794921875
INFO:root:Train (Epoch 28): Loss/seq after 00450 batchs: 1484.0367431640625
INFO:root:Train (Epoch 28): Loss/seq after 00500 batchs: 1515.6705322265625
INFO:root:Train (Epoch 28): Loss/seq after 00550 batchs: 1452.31494140625
INFO:root:Train (Epoch 28): Loss/seq after 00600 batchs: 1418.1544189453125
INFO:root:Train (Epoch 28): Loss/seq after 00650 batchs: 1422.759033203125
INFO:root:Train (Epoch 28): Loss/seq after 00700 batchs: 1424.0572509765625
INFO:root:Train (Epoch 28): Loss/seq after 00750 batchs: 1459.799072265625
INFO:root:Train (Epoch 28): Loss/seq after 00800 batchs: 1453.9844970703125
INFO:root:Train (Epoch 28): Loss/seq after 00850 batchs: 1423.1734619140625
INFO:root:Train (Epoch 28): Loss/seq after 00900 batchs: 1429.3404541015625
INFO:root:Train (Epoch 28): Loss/seq after 00950 batchs: 1465.990478515625
INFO:root:Train (Epoch 28): Loss/seq after 01000 batchs: 1459.39599609375
INFO:root:Train (Epoch 28): Loss/seq after 01050 batchs: 1441.62744140625
INFO:root:Train (Epoch 28): Loss/seq after 01100 batchs: 1434.853759765625
INFO:root:Train (Epoch 28): Loss/seq after 01150 batchs: 1414.5625
INFO:root:Train (Epoch 28): Loss/seq after 01200 batchs: 1400.9171142578125
INFO:root:Train (Epoch 28): Loss/seq after 01250 batchs: 1394.19580078125
INFO:root:Train (Epoch 28): Loss/seq after 01300 batchs: 1394.612548828125
INFO:root:Train (Epoch 28): Loss/seq after 01350 batchs: 1399.05126953125
INFO:root:Train (Epoch 28): Loss/seq after 01400 batchs: 1432.3392333984375
INFO:root:Train (Epoch 28): Loss/seq after 01450 batchs: 1419.357177734375
INFO:root:Train (Epoch 28): Loss/seq after 01500 batchs: 1407.2525634765625
INFO:root:Train (Epoch 28): Loss/seq after 01550 batchs: 1409.4892578125
INFO:root:Train (Epoch 28): Loss/seq after 01600 batchs: 1390.59619140625
INFO:root:Train (Epoch 28): Loss/seq after 01650 batchs: 1383.676025390625
INFO:root:Train (Epoch 28): Loss/seq after 01700 batchs: 1373.1434326171875
INFO:root:Train (Epoch 28): Loss/seq after 01750 batchs: 1359.5675048828125
INFO:root:Train (Epoch 28): Loss/seq after 01800 batchs: 1344.06591796875
INFO:root:Train (Epoch 28): Loss/seq after 01850 batchs: 1329.1763916015625
INFO:root:Train (Epoch 28): Loss/seq after 01900 batchs: 1326.9132080078125
INFO:root:Train (Epoch 28): Loss/seq after 01950 batchs: 1320.9844970703125
INFO:root:Train (Epoch 28): Loss/seq after 02000 batchs: 1310.265625
INFO:root:Train (Epoch 28): Loss/seq after 02050 batchs: 1301.237060546875
INFO:root:Train (Epoch 28): Loss/seq after 02100 batchs: 1288.9830322265625
INFO:root:Train (Epoch 28): Loss/seq after 02150 batchs: 1277.64892578125
INFO:root:Train (Epoch 28): Loss/seq after 02200 batchs: 1265.5916748046875
INFO:root:Train (Epoch 28): Loss/seq after 02250 batchs: 1270.139404296875
INFO:root:Train (Epoch 28): Loss/seq after 02300 batchs: 1276.0958251953125
INFO:root:Train (Epoch 28): Loss/seq after 02350 batchs: 1266.42626953125
INFO:root:Train (Epoch 28): Loss/seq after 02400 batchs: 1262.133544921875
INFO:root:Train (Epoch 28): Loss/seq after 02450 batchs: 1249.1773681640625
INFO:root:Train (Epoch 28): Loss/seq after 02500 batchs: 1231.4383544921875
INFO:root:Train (Epoch 28): Loss/seq after 02550 batchs: 1220.169677734375
INFO:root:Train (Epoch 28): Loss/seq after 02600 batchs: 1217.5440673828125
INFO:root:Train (Epoch 28): Loss/seq after 02650 batchs: 1212.69873046875
INFO:root:Train (Epoch 28): Loss/seq after 02700 batchs: 1209.4122314453125
INFO:root:Train (Epoch 28): Loss/seq after 02750 batchs: 1241.9739990234375
INFO:root:Train (Epoch 28): Loss/seq after 02800 batchs: 1250.4337158203125
INFO:root:Train (Epoch 28): Loss/seq after 02850 batchs: 1247.317138671875
INFO:root:Train (Epoch 28): Loss/seq after 02900 batchs: 1245.6072998046875
INFO:root:Train (Epoch 28): Loss/seq after 02950 batchs: 1237.24658203125
INFO:root:Train (Epoch 28): Loss/seq after 03000 batchs: 1234.7301025390625
INFO:root:Train (Epoch 28): Loss/seq after 03050 batchs: 1236.9052734375
INFO:root:Train (Epoch 28): Loss/seq after 03100 batchs: 1253.7314453125
INFO:root:Train (Epoch 28): Loss/seq after 03150 batchs: 1264.6298828125
INFO:root:Train (Epoch 28): Loss/seq after 03200 batchs: 1271.3564453125
INFO:root:Train (Epoch 28): Loss/seq after 03250 batchs: 1274.1756591796875
INFO:root:Train (Epoch 28): Loss/seq after 03300 batchs: 1273.31787109375
INFO:root:Train (Epoch 28): Loss/seq after 03350 batchs: 1273.774169921875
INFO:root:Train (Epoch 28): Loss/seq after 03400 batchs: 1264.55810546875
INFO:root:Train (Epoch 28): Loss/seq after 03450 batchs: 1257.3685302734375
INFO:root:Train (Epoch 28): Loss/seq after 03500 batchs: 1257.5179443359375
INFO:root:Train (Epoch 28): Loss/seq after 03550 batchs: 1252.2503662109375
INFO:root:Train (Epoch 28): Loss/seq after 03600 batchs: 1258.07568359375
INFO:root:Train (Epoch 28): Loss/seq after 03650 batchs: 1253.7047119140625
INFO:root:Train (Epoch 28): Loss/seq after 03700 batchs: 1253.124267578125
INFO:root:Train (Epoch 28): Loss/seq after 03750 batchs: 1252.6573486328125
INFO:root:Train (Epoch 28): Loss/seq after 03800 batchs: 1245.3548583984375
INFO:root:Train (Epoch 28): Loss/seq after 03850 batchs: 1240.5509033203125
INFO:root:Train (Epoch 28): Loss/seq after 03900 batchs: 1248.2296142578125
INFO:root:Train (Epoch 28): Loss/seq after 03950 batchs: 1253.22265625
INFO:root:Train (Epoch 28): Loss/seq after 04000 batchs: 1243.8739013671875
INFO:root:Train (Epoch 28): Loss/seq after 04050 batchs: 1235.5655517578125
INFO:root:Train (Epoch 28): Loss/seq after 04100 batchs: 1229.9302978515625
INFO:root:Train (Epoch 28): Loss/seq after 04150 batchs: 1223.886474609375
INFO:root:Train (Epoch 28): Loss/seq after 04200 batchs: 1218.6920166015625
INFO:root:Train (Epoch 28): Loss/seq after 04250 batchs: 1214.110107421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 28): Loss/seq after 00000 batches: 879.9764404296875
INFO:root:# Valid (Epoch 28): Loss/seq after 00050 batches: 1106.3125
INFO:root:# Valid (Epoch 28): Loss/seq after 00100 batches: 1411.84521484375
INFO:root:# Valid (Epoch 28): Loss/seq after 00150 batches: 1136.7822265625
INFO:root:# Valid (Epoch 28): Loss/seq after 00200 batches: 1024.0531005859375
INFO:root:Artifacts: Make stick videos for epoch 28
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_28_on_20220414_110259.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_28_index_1226_on_20220414_110259.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 29): Loss/seq after 00000 batchs: 2079.1123046875
INFO:root:Train (Epoch 29): Loss/seq after 00050 batchs: 1637.748046875
INFO:root:Train (Epoch 29): Loss/seq after 00100 batchs: 1648.15283203125
INFO:root:Train (Epoch 29): Loss/seq after 00150 batchs: 1475.628662109375
INFO:root:Train (Epoch 29): Loss/seq after 00200 batchs: 1600.9580078125
INFO:root:Train (Epoch 29): Loss/seq after 00250 batchs: 1714.735107421875
INFO:root:Train (Epoch 29): Loss/seq after 00300 batchs: 1613.3345947265625
INFO:root:Train (Epoch 29): Loss/seq after 00350 batchs: 1507.9903564453125
INFO:root:Train (Epoch 29): Loss/seq after 00400 batchs: 1555.4459228515625
INFO:root:Train (Epoch 29): Loss/seq after 00450 batchs: 1480.197021484375
INFO:root:Train (Epoch 29): Loss/seq after 00500 batchs: 1516.0296630859375
INFO:root:Train (Epoch 29): Loss/seq after 00550 batchs: 1453.020263671875
INFO:root:Train (Epoch 29): Loss/seq after 00600 batchs: 1418.268310546875
INFO:root:Train (Epoch 29): Loss/seq after 00650 batchs: 1422.499267578125
INFO:root:Train (Epoch 29): Loss/seq after 00700 batchs: 1422.27978515625
INFO:root:Train (Epoch 29): Loss/seq after 00750 batchs: 1459.8787841796875
INFO:root:Train (Epoch 29): Loss/seq after 00800 batchs: 1454.1038818359375
INFO:root:Train (Epoch 29): Loss/seq after 00850 batchs: 1422.8447265625
INFO:root:Train (Epoch 29): Loss/seq after 00900 batchs: 1429.531005859375
INFO:root:Train (Epoch 29): Loss/seq after 00950 batchs: 1474.28857421875
INFO:root:Train (Epoch 29): Loss/seq after 01000 batchs: 1465.5667724609375
INFO:root:Train (Epoch 29): Loss/seq after 01050 batchs: 1447.88818359375
INFO:root:Train (Epoch 29): Loss/seq after 01100 batchs: 1442.4429931640625
INFO:root:Train (Epoch 29): Loss/seq after 01150 batchs: 1421.68310546875
INFO:root:Train (Epoch 29): Loss/seq after 01200 batchs: 1408.0133056640625
INFO:root:Train (Epoch 29): Loss/seq after 01250 batchs: 1401.3468017578125
INFO:root:Train (Epoch 29): Loss/seq after 01300 batchs: 1406.113037109375
INFO:root:Train (Epoch 29): Loss/seq after 01350 batchs: 1408.3057861328125
INFO:root:Train (Epoch 29): Loss/seq after 01400 batchs: 1434.9002685546875
INFO:root:Train (Epoch 29): Loss/seq after 01450 batchs: 1421.7445068359375
INFO:root:Train (Epoch 29): Loss/seq after 01500 batchs: 1409.5028076171875
INFO:root:Train (Epoch 29): Loss/seq after 01550 batchs: 1412.90869140625
INFO:root:Train (Epoch 29): Loss/seq after 01600 batchs: 1393.889404296875
INFO:root:Train (Epoch 29): Loss/seq after 01650 batchs: 1387.0623779296875
INFO:root:Train (Epoch 29): Loss/seq after 01700 batchs: 1376.486572265625
INFO:root:Train (Epoch 29): Loss/seq after 01750 batchs: 1362.8353271484375
INFO:root:Train (Epoch 29): Loss/seq after 01800 batchs: 1347.2674560546875
INFO:root:Train (Epoch 29): Loss/seq after 01850 batchs: 1332.2900390625
INFO:root:Train (Epoch 29): Loss/seq after 01900 batchs: 1329.93017578125
INFO:root:Train (Epoch 29): Loss/seq after 01950 batchs: 1323.970458984375
INFO:root:Train (Epoch 29): Loss/seq after 02000 batchs: 1313.18505859375
INFO:root:Train (Epoch 29): Loss/seq after 02050 batchs: 1304.1490478515625
INFO:root:Train (Epoch 29): Loss/seq after 02100 batchs: 1291.839111328125
INFO:root:Train (Epoch 29): Loss/seq after 02150 batchs: 1280.420166015625
INFO:root:Train (Epoch 29): Loss/seq after 02200 batchs: 1268.354248046875
INFO:root:Train (Epoch 29): Loss/seq after 02250 batchs: 1272.462646484375
INFO:root:Train (Epoch 29): Loss/seq after 02300 batchs: 1279.6917724609375
INFO:root:Train (Epoch 29): Loss/seq after 02350 batchs: 1269.892333984375
INFO:root:Train (Epoch 29): Loss/seq after 02400 batchs: 1265.49072265625
INFO:root:Train (Epoch 29): Loss/seq after 02450 batchs: 1252.3436279296875
INFO:root:Train (Epoch 29): Loss/seq after 02500 batchs: 1234.546630859375
INFO:root:Train (Epoch 29): Loss/seq after 02550 batchs: 1223.4237060546875
INFO:root:Train (Epoch 29): Loss/seq after 02600 batchs: 1220.7392578125
INFO:root:Train (Epoch 29): Loss/seq after 02650 batchs: 1215.9766845703125
INFO:root:Train (Epoch 29): Loss/seq after 02700 batchs: 1213.014404296875
INFO:root:Train (Epoch 29): Loss/seq after 02750 batchs: 1245.132568359375
INFO:root:Train (Epoch 29): Loss/seq after 02800 batchs: 1251.6431884765625
INFO:root:Train (Epoch 29): Loss/seq after 02850 batchs: 1248.459228515625
INFO:root:Train (Epoch 29): Loss/seq after 02900 batchs: 1246.2664794921875
INFO:root:Train (Epoch 29): Loss/seq after 02950 batchs: 1237.8251953125
INFO:root:Train (Epoch 29): Loss/seq after 03000 batchs: 1235.324462890625
INFO:root:Train (Epoch 29): Loss/seq after 03050 batchs: 1237.485107421875
INFO:root:Train (Epoch 29): Loss/seq after 03100 batchs: 1251.9931640625
INFO:root:Train (Epoch 29): Loss/seq after 03150 batchs: 1261.727294921875
INFO:root:Train (Epoch 29): Loss/seq after 03200 batchs: 1269.0257568359375
INFO:root:Train (Epoch 29): Loss/seq after 03250 batchs: 1271.68701171875
INFO:root:Train (Epoch 29): Loss/seq after 03300 batchs: 1272.4942626953125
INFO:root:Train (Epoch 29): Loss/seq after 03350 batchs: 1272.64453125
INFO:root:Train (Epoch 29): Loss/seq after 03400 batchs: 1263.435302734375
INFO:root:Train (Epoch 29): Loss/seq after 03450 batchs: 1256.0125732421875
INFO:root:Train (Epoch 29): Loss/seq after 03500 batchs: 1256.0069580078125
INFO:root:Train (Epoch 29): Loss/seq after 03550 batchs: 1250.7633056640625
INFO:root:Train (Epoch 29): Loss/seq after 03600 batchs: 1256.241455078125
INFO:root:Train (Epoch 29): Loss/seq after 03650 batchs: 1251.7255859375
INFO:root:Train (Epoch 29): Loss/seq after 03700 batchs: 1251.13623046875
INFO:root:Train (Epoch 29): Loss/seq after 03750 batchs: 1250.67529296875
INFO:root:Train (Epoch 29): Loss/seq after 03800 batchs: 1243.3826904296875
INFO:root:Train (Epoch 29): Loss/seq after 03850 batchs: 1238.585205078125
INFO:root:Train (Epoch 29): Loss/seq after 03900 batchs: 1244.2030029296875
INFO:root:Train (Epoch 29): Loss/seq after 03950 batchs: 1248.2452392578125
INFO:root:Train (Epoch 29): Loss/seq after 04000 batchs: 1238.9371337890625
INFO:root:Train (Epoch 29): Loss/seq after 04050 batchs: 1230.682373046875
INFO:root:Train (Epoch 29): Loss/seq after 04100 batchs: 1225.227783203125
INFO:root:Train (Epoch 29): Loss/seq after 04150 batchs: 1219.2403564453125
INFO:root:Train (Epoch 29): Loss/seq after 04200 batchs: 1214.1290283203125
INFO:root:Train (Epoch 29): Loss/seq after 04250 batchs: 1209.634765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 29): Loss/seq after 00000 batches: 880.3485107421875
INFO:root:# Valid (Epoch 29): Loss/seq after 00050 batches: 1104.3994140625
INFO:root:# Valid (Epoch 29): Loss/seq after 00100 batches: 1412.8006591796875
INFO:root:# Valid (Epoch 29): Loss/seq after 00150 batches: 1137.4866943359375
INFO:root:# Valid (Epoch 29): Loss/seq after 00200 batches: 1023.9483642578125
INFO:root:Artifacts: Make stick videos for epoch 29
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_29_on_20220414_110825.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_29_index_1042_on_20220414_110825.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 30): Loss/seq after 00000 batchs: 2171.5703125
INFO:root:Train (Epoch 30): Loss/seq after 00050 batchs: 1655.031005859375
INFO:root:Train (Epoch 30): Loss/seq after 00100 batchs: 1665.9027099609375
INFO:root:Train (Epoch 30): Loss/seq after 00150 batchs: 1484.6361083984375
INFO:root:Train (Epoch 30): Loss/seq after 00200 batchs: 1608.816162109375
INFO:root:Train (Epoch 30): Loss/seq after 00250 batchs: 1722.1898193359375
INFO:root:Train (Epoch 30): Loss/seq after 00300 batchs: 1619.2332763671875
INFO:root:Train (Epoch 30): Loss/seq after 00350 batchs: 1512.3431396484375
INFO:root:Train (Epoch 30): Loss/seq after 00400 batchs: 1556.125732421875
INFO:root:Train (Epoch 30): Loss/seq after 00450 batchs: 1480.7896728515625
INFO:root:Train (Epoch 30): Loss/seq after 00500 batchs: 1515.06591796875
INFO:root:Train (Epoch 30): Loss/seq after 00550 batchs: 1451.7696533203125
INFO:root:Train (Epoch 30): Loss/seq after 00600 batchs: 1415.95849609375
INFO:root:Train (Epoch 30): Loss/seq after 00650 batchs: 1422.8172607421875
INFO:root:Train (Epoch 30): Loss/seq after 00700 batchs: 1423.4129638671875
INFO:root:Train (Epoch 30): Loss/seq after 00750 batchs: 1454.14208984375
INFO:root:Train (Epoch 30): Loss/seq after 00800 batchs: 1448.1669921875
INFO:root:Train (Epoch 30): Loss/seq after 00850 batchs: 1417.667724609375
INFO:root:Train (Epoch 30): Loss/seq after 00900 batchs: 1424.6324462890625
INFO:root:Train (Epoch 30): Loss/seq after 00950 batchs: 1466.9483642578125
INFO:root:Train (Epoch 30): Loss/seq after 01000 batchs: 1458.4481201171875
INFO:root:Train (Epoch 30): Loss/seq after 01050 batchs: 1440.9334716796875
INFO:root:Train (Epoch 30): Loss/seq after 01100 batchs: 1435.114990234375
INFO:root:Train (Epoch 30): Loss/seq after 01150 batchs: 1415.06689453125
INFO:root:Train (Epoch 30): Loss/seq after 01200 batchs: 1401.7037353515625
INFO:root:Train (Epoch 30): Loss/seq after 01250 batchs: 1392.6982421875
INFO:root:Train (Epoch 30): Loss/seq after 01300 batchs: 1391.9227294921875
INFO:root:Train (Epoch 30): Loss/seq after 01350 batchs: 1395.9766845703125
INFO:root:Train (Epoch 30): Loss/seq after 01400 batchs: 1420.9361572265625
INFO:root:Train (Epoch 30): Loss/seq after 01450 batchs: 1408.1092529296875
INFO:root:Train (Epoch 30): Loss/seq after 01500 batchs: 1396.3067626953125
INFO:root:Train (Epoch 30): Loss/seq after 01550 batchs: 1400.9554443359375
INFO:root:Train (Epoch 30): Loss/seq after 01600 batchs: 1382.4107666015625
INFO:root:Train (Epoch 30): Loss/seq after 01650 batchs: 1376.1763916015625
INFO:root:Train (Epoch 30): Loss/seq after 01700 batchs: 1365.9786376953125
INFO:root:Train (Epoch 30): Loss/seq after 01750 batchs: 1352.681640625
INFO:root:Train (Epoch 30): Loss/seq after 01800 batchs: 1337.4862060546875
INFO:root:Train (Epoch 30): Loss/seq after 01850 batchs: 1322.718994140625
INFO:root:Train (Epoch 30): Loss/seq after 01900 batchs: 1320.612548828125
INFO:root:Train (Epoch 30): Loss/seq after 01950 batchs: 1314.8836669921875
INFO:root:Train (Epoch 30): Loss/seq after 02000 batchs: 1304.333984375
INFO:root:Train (Epoch 30): Loss/seq after 02050 batchs: 1295.4212646484375
INFO:root:Train (Epoch 30): Loss/seq after 02100 batchs: 1283.2939453125
INFO:root:Train (Epoch 30): Loss/seq after 02150 batchs: 1272.05126953125
INFO:root:Train (Epoch 30): Loss/seq after 02200 batchs: 1260.108154296875
INFO:root:Train (Epoch 30): Loss/seq after 02250 batchs: 1264.64990234375
INFO:root:Train (Epoch 30): Loss/seq after 02300 batchs: 1271.6268310546875
INFO:root:Train (Epoch 30): Loss/seq after 02350 batchs: 1262.176025390625
INFO:root:Train (Epoch 30): Loss/seq after 02400 batchs: 1257.958740234375
INFO:root:Train (Epoch 30): Loss/seq after 02450 batchs: 1245.11767578125
INFO:root:Train (Epoch 30): Loss/seq after 02500 batchs: 1227.466064453125
INFO:root:Train (Epoch 30): Loss/seq after 02550 batchs: 1216.6134033203125
INFO:root:Train (Epoch 30): Loss/seq after 02600 batchs: 1215.0806884765625
INFO:root:Train (Epoch 30): Loss/seq after 02650 batchs: 1210.807373046875
INFO:root:Train (Epoch 30): Loss/seq after 02700 batchs: 1207.9498291015625
INFO:root:Train (Epoch 30): Loss/seq after 02750 batchs: 1239.4815673828125
INFO:root:Train (Epoch 30): Loss/seq after 02800 batchs: 1246.1611328125
INFO:root:Train (Epoch 30): Loss/seq after 02850 batchs: 1243.26611328125
INFO:root:Train (Epoch 30): Loss/seq after 02900 batchs: 1241.35205078125
INFO:root:Train (Epoch 30): Loss/seq after 02950 batchs: 1233.1243896484375
INFO:root:Train (Epoch 30): Loss/seq after 03000 batchs: 1230.6688232421875
INFO:root:Train (Epoch 30): Loss/seq after 03050 batchs: 1232.9134521484375
INFO:root:Train (Epoch 30): Loss/seq after 03100 batchs: 1246.9002685546875
INFO:root:Train (Epoch 30): Loss/seq after 03150 batchs: 1258.59130859375
INFO:root:Train (Epoch 30): Loss/seq after 03200 batchs: 1263.1292724609375
INFO:root:Train (Epoch 30): Loss/seq after 03250 batchs: 1266.940185546875
INFO:root:Train (Epoch 30): Loss/seq after 03300 batchs: 1267.9569091796875
INFO:root:Train (Epoch 30): Loss/seq after 03350 batchs: 1268.159423828125
INFO:root:Train (Epoch 30): Loss/seq after 03400 batchs: 1259.06396484375
INFO:root:Train (Epoch 30): Loss/seq after 03450 batchs: 1251.8037109375
INFO:root:Train (Epoch 30): Loss/seq after 03500 batchs: 1251.573486328125
INFO:root:Train (Epoch 30): Loss/seq after 03550 batchs: 1246.3363037109375
INFO:root:Train (Epoch 30): Loss/seq after 03600 batchs: 1251.9317626953125
INFO:root:Train (Epoch 30): Loss/seq after 03650 batchs: 1247.48583984375
INFO:root:Train (Epoch 30): Loss/seq after 03700 batchs: 1246.994384765625
INFO:root:Train (Epoch 30): Loss/seq after 03750 batchs: 1246.58056640625
INFO:root:Train (Epoch 30): Loss/seq after 03800 batchs: 1239.3345947265625
INFO:root:Train (Epoch 30): Loss/seq after 03850 batchs: 1234.587158203125
INFO:root:Train (Epoch 30): Loss/seq after 03900 batchs: 1240.641845703125
INFO:root:Train (Epoch 30): Loss/seq after 03950 batchs: 1245.6810302734375
INFO:root:Train (Epoch 30): Loss/seq after 04000 batchs: 1236.4183349609375
INFO:root:Train (Epoch 30): Loss/seq after 04050 batchs: 1228.193603515625
INFO:root:Train (Epoch 30): Loss/seq after 04100 batchs: 1222.7523193359375
INFO:root:Train (Epoch 30): Loss/seq after 04150 batchs: 1216.9168701171875
INFO:root:Train (Epoch 30): Loss/seq after 04200 batchs: 1211.7764892578125
INFO:root:Train (Epoch 30): Loss/seq after 04250 batchs: 1207.3448486328125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 30): Loss/seq after 00000 batches: 883.3260498046875
INFO:root:# Valid (Epoch 30): Loss/seq after 00050 batches: 1099.08740234375
INFO:root:# Valid (Epoch 30): Loss/seq after 00100 batches: 1412.4307861328125
INFO:root:# Valid (Epoch 30): Loss/seq after 00150 batches: 1141.253173828125
INFO:root:# Valid (Epoch 30): Loss/seq after 00200 batches: 1027.983154296875
INFO:root:Artifacts: Make stick videos for epoch 30
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_30_on_20220414_111349.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_30_index_1579_on_20220414_111349.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 31): Loss/seq after 00000 batchs: 2396.693603515625
INFO:root:Train (Epoch 31): Loss/seq after 00050 batchs: 1631.1077880859375
INFO:root:Train (Epoch 31): Loss/seq after 00100 batchs: 1650.5809326171875
INFO:root:Train (Epoch 31): Loss/seq after 00150 batchs: 1479.098388671875
INFO:root:Train (Epoch 31): Loss/seq after 00200 batchs: 1610.28369140625
INFO:root:Train (Epoch 31): Loss/seq after 00250 batchs: 1724.7115478515625
INFO:root:Train (Epoch 31): Loss/seq after 00300 batchs: 1621.4720458984375
INFO:root:Train (Epoch 31): Loss/seq after 00350 batchs: 1515.325439453125
INFO:root:Train (Epoch 31): Loss/seq after 00400 batchs: 1561.884521484375
INFO:root:Train (Epoch 31): Loss/seq after 00450 batchs: 1485.96240234375
INFO:root:Train (Epoch 31): Loss/seq after 00500 batchs: 1519.64892578125
INFO:root:Train (Epoch 31): Loss/seq after 00550 batchs: 1456.6060791015625
INFO:root:Train (Epoch 31): Loss/seq after 00600 batchs: 1421.514892578125
INFO:root:Train (Epoch 31): Loss/seq after 00650 batchs: 1429.3509521484375
INFO:root:Train (Epoch 31): Loss/seq after 00700 batchs: 1420.9041748046875
INFO:root:Train (Epoch 31): Loss/seq after 00750 batchs: 1457.7877197265625
INFO:root:Train (Epoch 31): Loss/seq after 00800 batchs: 1452.073486328125
INFO:root:Train (Epoch 31): Loss/seq after 00850 batchs: 1421.4688720703125
INFO:root:Train (Epoch 31): Loss/seq after 00900 batchs: 1428.3245849609375
INFO:root:Train (Epoch 31): Loss/seq after 00950 batchs: 1463.0186767578125
INFO:root:Train (Epoch 31): Loss/seq after 01000 batchs: 1458.3162841796875
INFO:root:Train (Epoch 31): Loss/seq after 01050 batchs: 1441.0445556640625
INFO:root:Train (Epoch 31): Loss/seq after 01100 batchs: 1434.0482177734375
INFO:root:Train (Epoch 31): Loss/seq after 01150 batchs: 1413.80908203125
INFO:root:Train (Epoch 31): Loss/seq after 01200 batchs: 1400.6641845703125
INFO:root:Train (Epoch 31): Loss/seq after 01250 batchs: 1393.1226806640625
INFO:root:Train (Epoch 31): Loss/seq after 01300 batchs: 1390.907958984375
INFO:root:Train (Epoch 31): Loss/seq after 01350 batchs: 1391.40673828125
INFO:root:Train (Epoch 31): Loss/seq after 01400 batchs: 1415.9346923828125
INFO:root:Train (Epoch 31): Loss/seq after 01450 batchs: 1404.4134521484375
INFO:root:Train (Epoch 31): Loss/seq after 01500 batchs: 1394.11279296875
INFO:root:Train (Epoch 31): Loss/seq after 01550 batchs: 1398.1121826171875
INFO:root:Train (Epoch 31): Loss/seq after 01600 batchs: 1379.4652099609375
INFO:root:Train (Epoch 31): Loss/seq after 01650 batchs: 1373.4764404296875
INFO:root:Train (Epoch 31): Loss/seq after 01700 batchs: 1363.3572998046875
INFO:root:Train (Epoch 31): Loss/seq after 01750 batchs: 1350.098388671875
INFO:root:Train (Epoch 31): Loss/seq after 01800 batchs: 1334.9173583984375
INFO:root:Train (Epoch 31): Loss/seq after 01850 batchs: 1320.35400390625
INFO:root:Train (Epoch 31): Loss/seq after 01900 batchs: 1318.33251953125
INFO:root:Train (Epoch 31): Loss/seq after 01950 batchs: 1312.7071533203125
INFO:root:Train (Epoch 31): Loss/seq after 02000 batchs: 1302.2135009765625
INFO:root:Train (Epoch 31): Loss/seq after 02050 batchs: 1293.456787109375
INFO:root:Train (Epoch 31): Loss/seq after 02100 batchs: 1281.4591064453125
INFO:root:Train (Epoch 31): Loss/seq after 02150 batchs: 1270.2933349609375
INFO:root:Train (Epoch 31): Loss/seq after 02200 batchs: 1258.46435546875
INFO:root:Train (Epoch 31): Loss/seq after 02250 batchs: 1262.7142333984375
INFO:root:Train (Epoch 31): Loss/seq after 02300 batchs: 1269.697509765625
INFO:root:Train (Epoch 31): Loss/seq after 02350 batchs: 1260.1639404296875
INFO:root:Train (Epoch 31): Loss/seq after 02400 batchs: 1256.061279296875
INFO:root:Train (Epoch 31): Loss/seq after 02450 batchs: 1243.143798828125
INFO:root:Train (Epoch 31): Loss/seq after 02500 batchs: 1225.5250244140625
INFO:root:Train (Epoch 31): Loss/seq after 02550 batchs: 1214.52001953125
INFO:root:Train (Epoch 31): Loss/seq after 02600 batchs: 1211.9315185546875
INFO:root:Train (Epoch 31): Loss/seq after 02650 batchs: 1207.3359375
INFO:root:Train (Epoch 31): Loss/seq after 02700 batchs: 1204.4881591796875
INFO:root:Train (Epoch 31): Loss/seq after 02750 batchs: 1236.209716796875
INFO:root:Train (Epoch 31): Loss/seq after 02800 batchs: 1243.1353759765625
INFO:root:Train (Epoch 31): Loss/seq after 02850 batchs: 1240.143798828125
INFO:root:Train (Epoch 31): Loss/seq after 02900 batchs: 1238.3460693359375
INFO:root:Train (Epoch 31): Loss/seq after 02950 batchs: 1230.055908203125
INFO:root:Train (Epoch 31): Loss/seq after 03000 batchs: 1227.673095703125
INFO:root:Train (Epoch 31): Loss/seq after 03050 batchs: 1229.9681396484375
INFO:root:Train (Epoch 31): Loss/seq after 03100 batchs: 1245.4805908203125
INFO:root:Train (Epoch 31): Loss/seq after 03150 batchs: 1255.8626708984375
INFO:root:Train (Epoch 31): Loss/seq after 03200 batchs: 1261.540771484375
INFO:root:Train (Epoch 31): Loss/seq after 03250 batchs: 1266.14208984375
INFO:root:Train (Epoch 31): Loss/seq after 03300 batchs: 1265.146728515625
INFO:root:Train (Epoch 31): Loss/seq after 03350 batchs: 1265.0006103515625
INFO:root:Train (Epoch 31): Loss/seq after 03400 batchs: 1255.9332275390625
INFO:root:Train (Epoch 31): Loss/seq after 03450 batchs: 1248.5743408203125
INFO:root:Train (Epoch 31): Loss/seq after 03500 batchs: 1248.7232666015625
INFO:root:Train (Epoch 31): Loss/seq after 03550 batchs: 1243.5479736328125
INFO:root:Train (Epoch 31): Loss/seq after 03600 batchs: 1249.2049560546875
INFO:root:Train (Epoch 31): Loss/seq after 03650 batchs: 1244.890380859375
INFO:root:Train (Epoch 31): Loss/seq after 03700 batchs: 1244.48486328125
INFO:root:Train (Epoch 31): Loss/seq after 03750 batchs: 1244.0654296875
INFO:root:Train (Epoch 31): Loss/seq after 03800 batchs: 1236.8533935546875
INFO:root:Train (Epoch 31): Loss/seq after 03850 batchs: 1232.14599609375
INFO:root:Train (Epoch 31): Loss/seq after 03900 batchs: 1237.911376953125
INFO:root:Train (Epoch 31): Loss/seq after 03950 batchs: 1242.51318359375
INFO:root:Train (Epoch 31): Loss/seq after 04000 batchs: 1233.281982421875
INFO:root:Train (Epoch 31): Loss/seq after 04050 batchs: 1225.0960693359375
INFO:root:Train (Epoch 31): Loss/seq after 04100 batchs: 1219.6348876953125
INFO:root:Train (Epoch 31): Loss/seq after 04150 batchs: 1213.77001953125
INFO:root:Train (Epoch 31): Loss/seq after 04200 batchs: 1208.725830078125
INFO:root:Train (Epoch 31): Loss/seq after 04250 batchs: 1204.3289794921875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 31): Loss/seq after 00000 batches: 896.473876953125
INFO:root:# Valid (Epoch 31): Loss/seq after 00050 batches: 1136.4805908203125
INFO:root:# Valid (Epoch 31): Loss/seq after 00100 batches: 1461.5343017578125
INFO:root:# Valid (Epoch 31): Loss/seq after 00150 batches: 1194.9046630859375
INFO:root:# Valid (Epoch 31): Loss/seq after 00200 batches: 1079.9039306640625
INFO:root:Artifacts: Make stick videos for epoch 31
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_31_on_20220414_111914.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_31_index_395_on_20220414_111914.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 32): Loss/seq after 00000 batchs: 2369.93359375
INFO:root:Train (Epoch 32): Loss/seq after 00050 batchs: 1681.197021484375
INFO:root:Train (Epoch 32): Loss/seq after 00100 batchs: 1680.063720703125
INFO:root:Train (Epoch 32): Loss/seq after 00150 batchs: 1502.1920166015625
INFO:root:Train (Epoch 32): Loss/seq after 00200 batchs: 1638.8270263671875
INFO:root:Train (Epoch 32): Loss/seq after 00250 batchs: 1746.471923828125
INFO:root:Train (Epoch 32): Loss/seq after 00300 batchs: 1639.90771484375
INFO:root:Train (Epoch 32): Loss/seq after 00350 batchs: 1531.4083251953125
INFO:root:Train (Epoch 32): Loss/seq after 00400 batchs: 1582.435791015625
INFO:root:Train (Epoch 32): Loss/seq after 00450 batchs: 1504.32177734375
INFO:root:Train (Epoch 32): Loss/seq after 00500 batchs: 1532.8712158203125
INFO:root:Train (Epoch 32): Loss/seq after 00550 batchs: 1470.2991943359375
INFO:root:Train (Epoch 32): Loss/seq after 00600 batchs: 1437.0838623046875
INFO:root:Train (Epoch 32): Loss/seq after 00650 batchs: 1439.51171875
INFO:root:Train (Epoch 32): Loss/seq after 00700 batchs: 1430.6134033203125
INFO:root:Train (Epoch 32): Loss/seq after 00750 batchs: 1463.228759765625
INFO:root:Train (Epoch 32): Loss/seq after 00800 batchs: 1457.6431884765625
INFO:root:Train (Epoch 32): Loss/seq after 00850 batchs: 1428.072265625
INFO:root:Train (Epoch 32): Loss/seq after 00900 batchs: 1434.969482421875
INFO:root:Train (Epoch 32): Loss/seq after 00950 batchs: 1478.214599609375
INFO:root:Train (Epoch 32): Loss/seq after 01000 batchs: 1475.8585205078125
INFO:root:Train (Epoch 32): Loss/seq after 01050 batchs: 1458.053955078125
INFO:root:Train (Epoch 32): Loss/seq after 01100 batchs: 1453.0048828125
INFO:root:Train (Epoch 32): Loss/seq after 01150 batchs: 1432.609130859375
INFO:root:Train (Epoch 32): Loss/seq after 01200 batchs: 1418.8302001953125
INFO:root:Train (Epoch 32): Loss/seq after 01250 batchs: 1410.4407958984375
INFO:root:Train (Epoch 32): Loss/seq after 01300 batchs: 1408.20947265625
INFO:root:Train (Epoch 32): Loss/seq after 01350 batchs: 1410.7882080078125
INFO:root:Train (Epoch 32): Loss/seq after 01400 batchs: 1432.184814453125
INFO:root:Train (Epoch 32): Loss/seq after 01450 batchs: 1419.169189453125
INFO:root:Train (Epoch 32): Loss/seq after 01500 batchs: 1407.01416015625
INFO:root:Train (Epoch 32): Loss/seq after 01550 batchs: 1411.796875
INFO:root:Train (Epoch 32): Loss/seq after 01600 batchs: 1392.6112060546875
INFO:root:Train (Epoch 32): Loss/seq after 01650 batchs: 1386.0897216796875
INFO:root:Train (Epoch 32): Loss/seq after 01700 batchs: 1375.4697265625
INFO:root:Train (Epoch 32): Loss/seq after 01750 batchs: 1361.866455078125
INFO:root:Train (Epoch 32): Loss/seq after 01800 batchs: 1346.5084228515625
INFO:root:Train (Epoch 32): Loss/seq after 01850 batchs: 1331.6710205078125
INFO:root:Train (Epoch 32): Loss/seq after 01900 batchs: 1329.453857421875
INFO:root:Train (Epoch 32): Loss/seq after 01950 batchs: 1323.744140625
INFO:root:Train (Epoch 32): Loss/seq after 02000 batchs: 1313.033935546875
INFO:root:Train (Epoch 32): Loss/seq after 02050 batchs: 1303.99853515625
INFO:root:Train (Epoch 32): Loss/seq after 02100 batchs: 1291.733154296875
INFO:root:Train (Epoch 32): Loss/seq after 02150 batchs: 1280.4132080078125
INFO:root:Train (Epoch 32): Loss/seq after 02200 batchs: 1268.3468017578125
INFO:root:Train (Epoch 32): Loss/seq after 02250 batchs: 1272.5560302734375
INFO:root:Train (Epoch 32): Loss/seq after 02300 batchs: 1281.1790771484375
INFO:root:Train (Epoch 32): Loss/seq after 02350 batchs: 1271.424072265625
INFO:root:Train (Epoch 32): Loss/seq after 02400 batchs: 1266.9840087890625
INFO:root:Train (Epoch 32): Loss/seq after 02450 batchs: 1253.748779296875
INFO:root:Train (Epoch 32): Loss/seq after 02500 batchs: 1235.937255859375
INFO:root:Train (Epoch 32): Loss/seq after 02550 batchs: 1224.618408203125
INFO:root:Train (Epoch 32): Loss/seq after 02600 batchs: 1221.673583984375
INFO:root:Train (Epoch 32): Loss/seq after 02650 batchs: 1216.6494140625
INFO:root:Train (Epoch 32): Loss/seq after 02700 batchs: 1213.3818359375
INFO:root:Train (Epoch 32): Loss/seq after 02750 batchs: 1244.5322265625
INFO:root:Train (Epoch 32): Loss/seq after 02800 batchs: 1250.7315673828125
INFO:root:Train (Epoch 32): Loss/seq after 02850 batchs: 1247.4691162109375
INFO:root:Train (Epoch 32): Loss/seq after 02900 batchs: 1245.43115234375
INFO:root:Train (Epoch 32): Loss/seq after 02950 batchs: 1236.9791259765625
INFO:root:Train (Epoch 32): Loss/seq after 03000 batchs: 1234.4520263671875
INFO:root:Train (Epoch 32): Loss/seq after 03050 batchs: 1236.641845703125
INFO:root:Train (Epoch 32): Loss/seq after 03100 batchs: 1251.1634521484375
INFO:root:Train (Epoch 32): Loss/seq after 03150 batchs: 1261.021484375
INFO:root:Train (Epoch 32): Loss/seq after 03200 batchs: 1265.807861328125
INFO:root:Train (Epoch 32): Loss/seq after 03250 batchs: 1269.0242919921875
INFO:root:Train (Epoch 32): Loss/seq after 03300 batchs: 1268.4346923828125
INFO:root:Train (Epoch 32): Loss/seq after 03350 batchs: 1268.4058837890625
INFO:root:Train (Epoch 32): Loss/seq after 03400 batchs: 1259.3221435546875
INFO:root:Train (Epoch 32): Loss/seq after 03450 batchs: 1252.0128173828125
INFO:root:Train (Epoch 32): Loss/seq after 03500 batchs: 1251.8863525390625
INFO:root:Train (Epoch 32): Loss/seq after 03550 batchs: 1246.7569580078125
INFO:root:Train (Epoch 32): Loss/seq after 03600 batchs: 1252.32763671875
INFO:root:Train (Epoch 32): Loss/seq after 03650 batchs: 1247.8489990234375
INFO:root:Train (Epoch 32): Loss/seq after 03700 batchs: 1247.3665771484375
INFO:root:Train (Epoch 32): Loss/seq after 03750 batchs: 1246.975830078125
INFO:root:Train (Epoch 32): Loss/seq after 03800 batchs: 1239.748291015625
INFO:root:Train (Epoch 32): Loss/seq after 03850 batchs: 1235.0020751953125
INFO:root:Train (Epoch 32): Loss/seq after 03900 batchs: 1241.2506103515625
INFO:root:Train (Epoch 32): Loss/seq after 03950 batchs: 1244.8421630859375
INFO:root:Train (Epoch 32): Loss/seq after 04000 batchs: 1235.582763671875
INFO:root:Train (Epoch 32): Loss/seq after 04050 batchs: 1227.3665771484375
INFO:root:Train (Epoch 32): Loss/seq after 04100 batchs: 1221.96728515625
INFO:root:Train (Epoch 32): Loss/seq after 04150 batchs: 1216.1361083984375
INFO:root:Train (Epoch 32): Loss/seq after 04200 batchs: 1211.054931640625
INFO:root:Train (Epoch 32): Loss/seq after 04250 batchs: 1206.650634765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 32): Loss/seq after 00000 batches: 890.1411743164062
INFO:root:# Valid (Epoch 32): Loss/seq after 00050 batches: 1120.641845703125
INFO:root:# Valid (Epoch 32): Loss/seq after 00100 batches: 1432.688232421875
INFO:root:# Valid (Epoch 32): Loss/seq after 00150 batches: 1162.4278564453125
INFO:root:# Valid (Epoch 32): Loss/seq after 00200 batches: 1048.4808349609375
INFO:root:Artifacts: Make stick videos for epoch 32
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_32_on_20220414_112439.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_32_index_852_on_20220414_112439.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 33): Loss/seq after 00000 batchs: 2180.98388671875
INFO:root:Train (Epoch 33): Loss/seq after 00050 batchs: 1705.9395751953125
INFO:root:Train (Epoch 33): Loss/seq after 00100 batchs: 1678.181396484375
INFO:root:Train (Epoch 33): Loss/seq after 00150 batchs: 1497.873779296875
INFO:root:Train (Epoch 33): Loss/seq after 00200 batchs: 1631.0684814453125
INFO:root:Train (Epoch 33): Loss/seq after 00250 batchs: 1742.551025390625
INFO:root:Train (Epoch 33): Loss/seq after 00300 batchs: 1636.3038330078125
INFO:root:Train (Epoch 33): Loss/seq after 00350 batchs: 1528.7239990234375
INFO:root:Train (Epoch 33): Loss/seq after 00400 batchs: 1581.68115234375
INFO:root:Train (Epoch 33): Loss/seq after 00450 batchs: 1503.731689453125
INFO:root:Train (Epoch 33): Loss/seq after 00500 batchs: 1538.7667236328125
INFO:root:Train (Epoch 33): Loss/seq after 00550 batchs: 1474.03857421875
INFO:root:Train (Epoch 33): Loss/seq after 00600 batchs: 1438.5377197265625
INFO:root:Train (Epoch 33): Loss/seq after 00650 batchs: 1446.2928466796875
INFO:root:Train (Epoch 33): Loss/seq after 00700 batchs: 1432.9884033203125
INFO:root:Train (Epoch 33): Loss/seq after 00750 batchs: 1468.9505615234375
INFO:root:Train (Epoch 33): Loss/seq after 00800 batchs: 1461.5089111328125
INFO:root:Train (Epoch 33): Loss/seq after 00850 batchs: 1430.3021240234375
INFO:root:Train (Epoch 33): Loss/seq after 00900 batchs: 1436.72021484375
INFO:root:Train (Epoch 33): Loss/seq after 00950 batchs: 1476.7476806640625
INFO:root:Train (Epoch 33): Loss/seq after 01000 batchs: 1473.1746826171875
INFO:root:Train (Epoch 33): Loss/seq after 01050 batchs: 1457.6419677734375
INFO:root:Train (Epoch 33): Loss/seq after 01100 batchs: 1453.3309326171875
INFO:root:Train (Epoch 33): Loss/seq after 01150 batchs: 1432.2215576171875
INFO:root:Train (Epoch 33): Loss/seq after 01200 batchs: 1418.0625
INFO:root:Train (Epoch 33): Loss/seq after 01250 batchs: 1409.6676025390625
INFO:root:Train (Epoch 33): Loss/seq after 01300 batchs: 1411.38427734375
INFO:root:Train (Epoch 33): Loss/seq after 01350 batchs: 1413.9443359375
INFO:root:Train (Epoch 33): Loss/seq after 01400 batchs: 1439.3187255859375
INFO:root:Train (Epoch 33): Loss/seq after 01450 batchs: 1425.9500732421875
INFO:root:Train (Epoch 33): Loss/seq after 01500 batchs: 1413.603271484375
INFO:root:Train (Epoch 33): Loss/seq after 01550 batchs: 1417.1959228515625
INFO:root:Train (Epoch 33): Loss/seq after 01600 batchs: 1397.9879150390625
INFO:root:Train (Epoch 33): Loss/seq after 01650 batchs: 1391.257080078125
INFO:root:Train (Epoch 33): Loss/seq after 01700 batchs: 1380.4122314453125
INFO:root:Train (Epoch 33): Loss/seq after 01750 batchs: 1366.6336669921875
INFO:root:Train (Epoch 33): Loss/seq after 01800 batchs: 1351.0313720703125
INFO:root:Train (Epoch 33): Loss/seq after 01850 batchs: 1336.0672607421875
INFO:root:Train (Epoch 33): Loss/seq after 01900 batchs: 1333.6273193359375
INFO:root:Train (Epoch 33): Loss/seq after 01950 batchs: 1327.6317138671875
INFO:root:Train (Epoch 33): Loss/seq after 02000 batchs: 1316.777099609375
INFO:root:Train (Epoch 33): Loss/seq after 02050 batchs: 1307.5772705078125
INFO:root:Train (Epoch 33): Loss/seq after 02100 batchs: 1295.177734375
INFO:root:Train (Epoch 33): Loss/seq after 02150 batchs: 1283.6868896484375
INFO:root:Train (Epoch 33): Loss/seq after 02200 batchs: 1271.5155029296875
INFO:root:Train (Epoch 33): Loss/seq after 02250 batchs: 1275.8448486328125
INFO:root:Train (Epoch 33): Loss/seq after 02300 batchs: 1282.3992919921875
INFO:root:Train (Epoch 33): Loss/seq after 02350 batchs: 1272.6317138671875
INFO:root:Train (Epoch 33): Loss/seq after 02400 batchs: 1268.2791748046875
INFO:root:Train (Epoch 33): Loss/seq after 02450 batchs: 1255.133056640625
INFO:root:Train (Epoch 33): Loss/seq after 02500 batchs: 1237.2784423828125
INFO:root:Train (Epoch 33): Loss/seq after 02550 batchs: 1226.029052734375
INFO:root:Train (Epoch 33): Loss/seq after 02600 batchs: 1223.1845703125
INFO:root:Train (Epoch 33): Loss/seq after 02650 batchs: 1218.380615234375
INFO:root:Train (Epoch 33): Loss/seq after 02700 batchs: 1216.1453857421875
INFO:root:Train (Epoch 33): Loss/seq after 02750 batchs: 1247.6063232421875
INFO:root:Train (Epoch 33): Loss/seq after 02800 batchs: 1255.762451171875
INFO:root:Train (Epoch 33): Loss/seq after 02850 batchs: 1252.4884033203125
INFO:root:Train (Epoch 33): Loss/seq after 02900 batchs: 1250.3016357421875
INFO:root:Train (Epoch 33): Loss/seq after 02950 batchs: 1241.8978271484375
INFO:root:Train (Epoch 33): Loss/seq after 03000 batchs: 1239.366943359375
INFO:root:Train (Epoch 33): Loss/seq after 03050 batchs: 1241.523193359375
INFO:root:Train (Epoch 33): Loss/seq after 03100 batchs: 1256.6695556640625
INFO:root:Train (Epoch 33): Loss/seq after 03150 batchs: 1265.05712890625
INFO:root:Train (Epoch 33): Loss/seq after 03200 batchs: 1269.103759765625
INFO:root:Train (Epoch 33): Loss/seq after 03250 batchs: 1272.2120361328125
INFO:root:Train (Epoch 33): Loss/seq after 03300 batchs: 1271.2991943359375
INFO:root:Train (Epoch 33): Loss/seq after 03350 batchs: 1271.509765625
INFO:root:Train (Epoch 33): Loss/seq after 03400 batchs: 1262.33984375
INFO:root:Train (Epoch 33): Loss/seq after 03450 batchs: 1254.9677734375
INFO:root:Train (Epoch 33): Loss/seq after 03500 batchs: 1254.76806640625
INFO:root:Train (Epoch 33): Loss/seq after 03550 batchs: 1249.4771728515625
INFO:root:Train (Epoch 33): Loss/seq after 03600 batchs: 1255.0035400390625
INFO:root:Train (Epoch 33): Loss/seq after 03650 batchs: 1250.463623046875
INFO:root:Train (Epoch 33): Loss/seq after 03700 batchs: 1249.8514404296875
INFO:root:Train (Epoch 33): Loss/seq after 03750 batchs: 1249.3826904296875
INFO:root:Train (Epoch 33): Loss/seq after 03800 batchs: 1242.112548828125
INFO:root:Train (Epoch 33): Loss/seq after 03850 batchs: 1237.3590087890625
INFO:root:Train (Epoch 33): Loss/seq after 03900 batchs: 1242.6500244140625
INFO:root:Train (Epoch 33): Loss/seq after 03950 batchs: 1247.0340576171875
INFO:root:Train (Epoch 33): Loss/seq after 04000 batchs: 1237.74267578125
INFO:root:Train (Epoch 33): Loss/seq after 04050 batchs: 1229.5025634765625
INFO:root:Train (Epoch 33): Loss/seq after 04100 batchs: 1223.6981201171875
INFO:root:Train (Epoch 33): Loss/seq after 04150 batchs: 1217.7109375
INFO:root:Train (Epoch 33): Loss/seq after 04200 batchs: 1212.5621337890625
INFO:root:Train (Epoch 33): Loss/seq after 04250 batchs: 1208.060546875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 33): Loss/seq after 00000 batches: 884.2720947265625
INFO:root:# Valid (Epoch 33): Loss/seq after 00050 batches: 1111.121337890625
INFO:root:# Valid (Epoch 33): Loss/seq after 00100 batches: 1416.2384033203125
INFO:root:# Valid (Epoch 33): Loss/seq after 00150 batches: 1139.9656982421875
INFO:root:# Valid (Epoch 33): Loss/seq after 00200 batches: 1024.94287109375
INFO:root:Artifacts: Make stick videos for epoch 33
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_33_on_20220414_113004.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_33_index_1570_on_20220414_113004.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 34): Loss/seq after 00000 batchs: 1699.697998046875
INFO:root:Train (Epoch 34): Loss/seq after 00050 batchs: 1683.973876953125
INFO:root:Train (Epoch 34): Loss/seq after 00100 batchs: 1685.3809814453125
INFO:root:Train (Epoch 34): Loss/seq after 00150 batchs: 1495.101318359375
INFO:root:Train (Epoch 34): Loss/seq after 00200 batchs: 1615.6717529296875
INFO:root:Train (Epoch 34): Loss/seq after 00250 batchs: 1726.0592041015625
INFO:root:Train (Epoch 34): Loss/seq after 00300 batchs: 1622.33251953125
INFO:root:Train (Epoch 34): Loss/seq after 00350 batchs: 1514.8653564453125
INFO:root:Train (Epoch 34): Loss/seq after 00400 batchs: 1562.887939453125
INFO:root:Train (Epoch 34): Loss/seq after 00450 batchs: 1486.7489013671875
INFO:root:Train (Epoch 34): Loss/seq after 00500 batchs: 1519.23193359375
INFO:root:Train (Epoch 34): Loss/seq after 00550 batchs: 1455.4881591796875
INFO:root:Train (Epoch 34): Loss/seq after 00600 batchs: 1421.9185791015625
INFO:root:Train (Epoch 34): Loss/seq after 00650 batchs: 1426.2181396484375
INFO:root:Train (Epoch 34): Loss/seq after 00700 batchs: 1409.3238525390625
INFO:root:Train (Epoch 34): Loss/seq after 00750 batchs: 1446.14794921875
INFO:root:Train (Epoch 34): Loss/seq after 00800 batchs: 1440.5035400390625
INFO:root:Train (Epoch 34): Loss/seq after 00850 batchs: 1409.2445068359375
INFO:root:Train (Epoch 34): Loss/seq after 00900 batchs: 1416.2635498046875
INFO:root:Train (Epoch 34): Loss/seq after 00950 batchs: 1459.633056640625
INFO:root:Train (Epoch 34): Loss/seq after 01000 batchs: 1456.8358154296875
INFO:root:Train (Epoch 34): Loss/seq after 01050 batchs: 1439.39990234375
INFO:root:Train (Epoch 34): Loss/seq after 01100 batchs: 1431.070556640625
INFO:root:Train (Epoch 34): Loss/seq after 01150 batchs: 1410.6729736328125
INFO:root:Train (Epoch 34): Loss/seq after 01200 batchs: 1397.5531005859375
INFO:root:Train (Epoch 34): Loss/seq after 01250 batchs: 1393.4925537109375
INFO:root:Train (Epoch 34): Loss/seq after 01300 batchs: 1399.8927001953125
INFO:root:Train (Epoch 34): Loss/seq after 01350 batchs: 1403.4183349609375
INFO:root:Train (Epoch 34): Loss/seq after 01400 batchs: 1429.120361328125
INFO:root:Train (Epoch 34): Loss/seq after 01450 batchs: 1416.400146484375
INFO:root:Train (Epoch 34): Loss/seq after 01500 batchs: 1404.3558349609375
INFO:root:Train (Epoch 34): Loss/seq after 01550 batchs: 1408.4520263671875
INFO:root:Train (Epoch 34): Loss/seq after 01600 batchs: 1389.4462890625
INFO:root:Train (Epoch 34): Loss/seq after 01650 batchs: 1383.1622314453125
INFO:root:Train (Epoch 34): Loss/seq after 01700 batchs: 1372.6435546875
INFO:root:Train (Epoch 34): Loss/seq after 01750 batchs: 1359.1485595703125
INFO:root:Train (Epoch 34): Loss/seq after 01800 batchs: 1343.702880859375
INFO:root:Train (Epoch 34): Loss/seq after 01850 batchs: 1328.848388671875
INFO:root:Train (Epoch 34): Loss/seq after 01900 batchs: 1326.5811767578125
INFO:root:Train (Epoch 34): Loss/seq after 01950 batchs: 1320.7210693359375
INFO:root:Train (Epoch 34): Loss/seq after 02000 batchs: 1310.037353515625
INFO:root:Train (Epoch 34): Loss/seq after 02050 batchs: 1300.9573974609375
INFO:root:Train (Epoch 34): Loss/seq after 02100 batchs: 1288.7138671875
INFO:root:Train (Epoch 34): Loss/seq after 02150 batchs: 1277.3603515625
INFO:root:Train (Epoch 34): Loss/seq after 02200 batchs: 1265.3118896484375
INFO:root:Train (Epoch 34): Loss/seq after 02250 batchs: 1269.732421875
INFO:root:Train (Epoch 34): Loss/seq after 02300 batchs: 1276.8438720703125
INFO:root:Train (Epoch 34): Loss/seq after 02350 batchs: 1267.0799560546875
INFO:root:Train (Epoch 34): Loss/seq after 02400 batchs: 1262.6820068359375
INFO:root:Train (Epoch 34): Loss/seq after 02450 batchs: 1249.5135498046875
INFO:root:Train (Epoch 34): Loss/seq after 02500 batchs: 1231.7508544921875
INFO:root:Train (Epoch 34): Loss/seq after 02550 batchs: 1220.559326171875
INFO:root:Train (Epoch 34): Loss/seq after 02600 batchs: 1217.531982421875
INFO:root:Train (Epoch 34): Loss/seq after 02650 batchs: 1212.6212158203125
INFO:root:Train (Epoch 34): Loss/seq after 02700 batchs: 1209.7510986328125
INFO:root:Train (Epoch 34): Loss/seq after 02750 batchs: 1241.389404296875
INFO:root:Train (Epoch 34): Loss/seq after 02800 batchs: 1248.6251220703125
INFO:root:Train (Epoch 34): Loss/seq after 02850 batchs: 1245.50048828125
INFO:root:Train (Epoch 34): Loss/seq after 02900 batchs: 1243.539794921875
INFO:root:Train (Epoch 34): Loss/seq after 02950 batchs: 1235.09130859375
INFO:root:Train (Epoch 34): Loss/seq after 03000 batchs: 1232.603759765625
INFO:root:Train (Epoch 34): Loss/seq after 03050 batchs: 1234.810791015625
INFO:root:Train (Epoch 34): Loss/seq after 03100 batchs: 1248.4273681640625
INFO:root:Train (Epoch 34): Loss/seq after 03150 batchs: 1257.4122314453125
INFO:root:Train (Epoch 34): Loss/seq after 03200 batchs: 1261.4576416015625
INFO:root:Train (Epoch 34): Loss/seq after 03250 batchs: 1263.6922607421875
INFO:root:Train (Epoch 34): Loss/seq after 03300 batchs: 1263.037353515625
INFO:root:Train (Epoch 34): Loss/seq after 03350 batchs: 1264.269287109375
INFO:root:Train (Epoch 34): Loss/seq after 03400 batchs: 1255.1915283203125
INFO:root:Train (Epoch 34): Loss/seq after 03450 batchs: 1248.11962890625
INFO:root:Train (Epoch 34): Loss/seq after 03500 batchs: 1248.8985595703125
INFO:root:Train (Epoch 34): Loss/seq after 03550 batchs: 1243.6881103515625
INFO:root:Train (Epoch 34): Loss/seq after 03600 batchs: 1249.2955322265625
INFO:root:Train (Epoch 34): Loss/seq after 03650 batchs: 1244.9525146484375
INFO:root:Train (Epoch 34): Loss/seq after 03700 batchs: 1244.4429931640625
INFO:root:Train (Epoch 34): Loss/seq after 03750 batchs: 1244.0623779296875
INFO:root:Train (Epoch 34): Loss/seq after 03800 batchs: 1236.8731689453125
INFO:root:Train (Epoch 34): Loss/seq after 03850 batchs: 1232.1724853515625
INFO:root:Train (Epoch 34): Loss/seq after 03900 batchs: 1239.28466796875
INFO:root:Train (Epoch 34): Loss/seq after 03950 batchs: 1243.2510986328125
INFO:root:Train (Epoch 34): Loss/seq after 04000 batchs: 1234.0091552734375
INFO:root:Train (Epoch 34): Loss/seq after 04050 batchs: 1225.8087158203125
INFO:root:Train (Epoch 34): Loss/seq after 04100 batchs: 1220.1478271484375
INFO:root:Train (Epoch 34): Loss/seq after 04150 batchs: 1214.176513671875
INFO:root:Train (Epoch 34): Loss/seq after 04200 batchs: 1209.110595703125
INFO:root:Train (Epoch 34): Loss/seq after 04250 batchs: 1204.629150390625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 34): Loss/seq after 00000 batches: 888.10693359375
INFO:root:# Valid (Epoch 34): Loss/seq after 00050 batches: 1123.253662109375
INFO:root:# Valid (Epoch 34): Loss/seq after 00100 batches: 1426.0660400390625
INFO:root:# Valid (Epoch 34): Loss/seq after 00150 batches: 1144.5164794921875
INFO:root:# Valid (Epoch 34): Loss/seq after 00200 batches: 1030.3172607421875
INFO:root:Artifacts: Make stick videos for epoch 34
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_34_on_20220414_113530.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_34_index_247_on_20220414_113530.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 35): Loss/seq after 00000 batchs: 1847.8563232421875
INFO:root:Train (Epoch 35): Loss/seq after 00050 batchs: 1636.3790283203125
INFO:root:Train (Epoch 35): Loss/seq after 00100 batchs: 1654.6961669921875
INFO:root:Train (Epoch 35): Loss/seq after 00150 batchs: 1477.254638671875
INFO:root:Train (Epoch 35): Loss/seq after 00200 batchs: 1592.8983154296875
INFO:root:Train (Epoch 35): Loss/seq after 00250 batchs: 1710.4151611328125
INFO:root:Train (Epoch 35): Loss/seq after 00300 batchs: 1609.5987548828125
INFO:root:Train (Epoch 35): Loss/seq after 00350 batchs: 1504.384765625
INFO:root:Train (Epoch 35): Loss/seq after 00400 batchs: 1546.9453125
INFO:root:Train (Epoch 35): Loss/seq after 00450 batchs: 1472.480712890625
INFO:root:Train (Epoch 35): Loss/seq after 00500 batchs: 1502.1072998046875
INFO:root:Train (Epoch 35): Loss/seq after 00550 batchs: 1440.0057373046875
INFO:root:Train (Epoch 35): Loss/seq after 00600 batchs: 1407.365966796875
INFO:root:Train (Epoch 35): Loss/seq after 00650 batchs: 1408.300537109375
INFO:root:Train (Epoch 35): Loss/seq after 00700 batchs: 1395.0458984375
INFO:root:Train (Epoch 35): Loss/seq after 00750 batchs: 1430.096435546875
INFO:root:Train (Epoch 35): Loss/seq after 00800 batchs: 1425.41455078125
INFO:root:Train (Epoch 35): Loss/seq after 00850 batchs: 1394.9849853515625
INFO:root:Train (Epoch 35): Loss/seq after 00900 batchs: 1402.9439697265625
INFO:root:Train (Epoch 35): Loss/seq after 00950 batchs: 1434.912353515625
INFO:root:Train (Epoch 35): Loss/seq after 01000 batchs: 1433.054443359375
INFO:root:Train (Epoch 35): Loss/seq after 01050 batchs: 1415.913330078125
INFO:root:Train (Epoch 35): Loss/seq after 01100 batchs: 1410.9359130859375
INFO:root:Train (Epoch 35): Loss/seq after 01150 batchs: 1391.4193115234375
INFO:root:Train (Epoch 35): Loss/seq after 01200 batchs: 1378.7576904296875
INFO:root:Train (Epoch 35): Loss/seq after 01250 batchs: 1371.408447265625
INFO:root:Train (Epoch 35): Loss/seq after 01300 batchs: 1371.9473876953125
INFO:root:Train (Epoch 35): Loss/seq after 01350 batchs: 1371.6031494140625
INFO:root:Train (Epoch 35): Loss/seq after 01400 batchs: 1393.69140625
INFO:root:Train (Epoch 35): Loss/seq after 01450 batchs: 1381.729736328125
INFO:root:Train (Epoch 35): Loss/seq after 01500 batchs: 1370.80908203125
INFO:root:Train (Epoch 35): Loss/seq after 01550 batchs: 1375.51513671875
INFO:root:Train (Epoch 35): Loss/seq after 01600 batchs: 1357.5189208984375
INFO:root:Train (Epoch 35): Loss/seq after 01650 batchs: 1352.2281494140625
INFO:root:Train (Epoch 35): Loss/seq after 01700 batchs: 1342.7783203125
INFO:root:Train (Epoch 35): Loss/seq after 01750 batchs: 1330.08349609375
INFO:root:Train (Epoch 35): Loss/seq after 01800 batchs: 1315.5054931640625
INFO:root:Train (Epoch 35): Loss/seq after 01850 batchs: 1301.462158203125
INFO:root:Train (Epoch 35): Loss/seq after 01900 batchs: 1299.8975830078125
INFO:root:Train (Epoch 35): Loss/seq after 01950 batchs: 1294.6915283203125
INFO:root:Train (Epoch 35): Loss/seq after 02000 batchs: 1284.669189453125
INFO:root:Train (Epoch 35): Loss/seq after 02050 batchs: 1276.2822265625
INFO:root:Train (Epoch 35): Loss/seq after 02100 batchs: 1264.6480712890625
INFO:root:Train (Epoch 35): Loss/seq after 02150 batchs: 1253.864013671875
INFO:root:Train (Epoch 35): Loss/seq after 02200 batchs: 1242.3544921875
INFO:root:Train (Epoch 35): Loss/seq after 02250 batchs: 1247.544189453125
INFO:root:Train (Epoch 35): Loss/seq after 02300 batchs: 1256.31201171875
INFO:root:Train (Epoch 35): Loss/seq after 02350 batchs: 1247.088623046875
INFO:root:Train (Epoch 35): Loss/seq after 02400 batchs: 1243.3609619140625
INFO:root:Train (Epoch 35): Loss/seq after 02450 batchs: 1230.8167724609375
INFO:root:Train (Epoch 35): Loss/seq after 02500 batchs: 1213.4439697265625
INFO:root:Train (Epoch 35): Loss/seq after 02550 batchs: 1202.5423583984375
INFO:root:Train (Epoch 35): Loss/seq after 02600 batchs: 1200.395751953125
INFO:root:Train (Epoch 35): Loss/seq after 02650 batchs: 1195.750244140625
INFO:root:Train (Epoch 35): Loss/seq after 02700 batchs: 1192.0804443359375
INFO:root:Train (Epoch 35): Loss/seq after 02750 batchs: 1223.197021484375
INFO:root:Train (Epoch 35): Loss/seq after 02800 batchs: 1229.0413818359375
INFO:root:Train (Epoch 35): Loss/seq after 02850 batchs: 1226.1654052734375
INFO:root:Train (Epoch 35): Loss/seq after 02900 batchs: 1224.4765625
INFO:root:Train (Epoch 35): Loss/seq after 02950 batchs: 1216.3677978515625
INFO:root:Train (Epoch 35): Loss/seq after 03000 batchs: 1214.296142578125
INFO:root:Train (Epoch 35): Loss/seq after 03050 batchs: 1216.851318359375
INFO:root:Train (Epoch 35): Loss/seq after 03100 batchs: 1230.6668701171875
INFO:root:Train (Epoch 35): Loss/seq after 03150 batchs: 1241.810791015625
INFO:root:Train (Epoch 35): Loss/seq after 03200 batchs: 1245.17626953125
INFO:root:Train (Epoch 35): Loss/seq after 03250 batchs: 1246.1033935546875
INFO:root:Train (Epoch 35): Loss/seq after 03300 batchs: 1246.0570068359375
INFO:root:Train (Epoch 35): Loss/seq after 03350 batchs: 1245.9598388671875
INFO:root:Train (Epoch 35): Loss/seq after 03400 batchs: 1237.109619140625
INFO:root:Train (Epoch 35): Loss/seq after 03450 batchs: 1229.97412109375
INFO:root:Train (Epoch 35): Loss/seq after 03500 batchs: 1230.17724609375
INFO:root:Train (Epoch 35): Loss/seq after 03550 batchs: 1225.26220703125
INFO:root:Train (Epoch 35): Loss/seq after 03600 batchs: 1231.1038818359375
INFO:root:Train (Epoch 35): Loss/seq after 03650 batchs: 1226.9425048828125
INFO:root:Train (Epoch 35): Loss/seq after 03700 batchs: 1226.6666259765625
INFO:root:Train (Epoch 35): Loss/seq after 03750 batchs: 1226.481689453125
INFO:root:Train (Epoch 35): Loss/seq after 03800 batchs: 1219.5103759765625
INFO:root:Train (Epoch 35): Loss/seq after 03850 batchs: 1215.0750732421875
INFO:root:Train (Epoch 35): Loss/seq after 03900 batchs: 1221.1614990234375
INFO:root:Train (Epoch 35): Loss/seq after 03950 batchs: 1225.0211181640625
INFO:root:Train (Epoch 35): Loss/seq after 04000 batchs: 1216.0084228515625
INFO:root:Train (Epoch 35): Loss/seq after 04050 batchs: 1208.0355224609375
INFO:root:Train (Epoch 35): Loss/seq after 04100 batchs: 1202.515380859375
INFO:root:Train (Epoch 35): Loss/seq after 04150 batchs: 1196.843017578125
INFO:root:Train (Epoch 35): Loss/seq after 04200 batchs: 1191.995361328125
INFO:root:Train (Epoch 35): Loss/seq after 04250 batchs: 1187.7559814453125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 35): Loss/seq after 00000 batches: 883.3399658203125
INFO:root:# Valid (Epoch 35): Loss/seq after 00050 batches: 1100.6708984375
INFO:root:# Valid (Epoch 35): Loss/seq after 00100 batches: 1415.6611328125
INFO:root:# Valid (Epoch 35): Loss/seq after 00150 batches: 1138.3426513671875
INFO:root:# Valid (Epoch 35): Loss/seq after 00200 batches: 1024.16162109375
INFO:root:Artifacts: Make stick videos for epoch 35
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_35_on_20220414_114055.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_35_index_1111_on_20220414_114055.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 36): Loss/seq after 00000 batchs: 1529.0059814453125
INFO:root:Train (Epoch 36): Loss/seq after 00050 batchs: 1577.4625244140625
INFO:root:Train (Epoch 36): Loss/seq after 00100 batchs: 1612.1800537109375
INFO:root:Train (Epoch 36): Loss/seq after 00150 batchs: 1447.6533203125
INFO:root:Train (Epoch 36): Loss/seq after 00200 batchs: 1555.765625
INFO:root:Train (Epoch 36): Loss/seq after 00250 batchs: 1683.7237548828125
INFO:root:Train (Epoch 36): Loss/seq after 00300 batchs: 1587.404541015625
INFO:root:Train (Epoch 36): Loss/seq after 00350 batchs: 1485.16748046875
INFO:root:Train (Epoch 36): Loss/seq after 00400 batchs: 1532.3138427734375
INFO:root:Train (Epoch 36): Loss/seq after 00450 batchs: 1459.556640625
INFO:root:Train (Epoch 36): Loss/seq after 00500 batchs: 1489.9637451171875
INFO:root:Train (Epoch 36): Loss/seq after 00550 batchs: 1429.2989501953125
INFO:root:Train (Epoch 36): Loss/seq after 00600 batchs: 1397.167236328125
INFO:root:Train (Epoch 36): Loss/seq after 00650 batchs: 1396.3804931640625
INFO:root:Train (Epoch 36): Loss/seq after 00700 batchs: 1389.8046875
INFO:root:Train (Epoch 36): Loss/seq after 00750 batchs: 1421.7935791015625
INFO:root:Train (Epoch 36): Loss/seq after 00800 batchs: 1417.676025390625
INFO:root:Train (Epoch 36): Loss/seq after 00850 batchs: 1389.1871337890625
INFO:root:Train (Epoch 36): Loss/seq after 00900 batchs: 1397.7894287109375
INFO:root:Train (Epoch 36): Loss/seq after 00950 batchs: 1430.57568359375
INFO:root:Train (Epoch 36): Loss/seq after 01000 batchs: 1428.91259765625
INFO:root:Train (Epoch 36): Loss/seq after 01050 batchs: 1412.609375
INFO:root:Train (Epoch 36): Loss/seq after 01100 batchs: 1407.3232421875
INFO:root:Train (Epoch 36): Loss/seq after 01150 batchs: 1388.2076416015625
INFO:root:Train (Epoch 36): Loss/seq after 01200 batchs: 1375.726318359375
INFO:root:Train (Epoch 36): Loss/seq after 01250 batchs: 1368.3531494140625
INFO:root:Train (Epoch 36): Loss/seq after 01300 batchs: 1369.558837890625
INFO:root:Train (Epoch 36): Loss/seq after 01350 batchs: 1372.6119384765625
INFO:root:Train (Epoch 36): Loss/seq after 01400 batchs: 1394.2275390625
INFO:root:Train (Epoch 36): Loss/seq after 01450 batchs: 1382.2906494140625
INFO:root:Train (Epoch 36): Loss/seq after 01500 batchs: 1371.339599609375
INFO:root:Train (Epoch 36): Loss/seq after 01550 batchs: 1376.08203125
INFO:root:Train (Epoch 36): Loss/seq after 01600 batchs: 1359.4573974609375
INFO:root:Train (Epoch 36): Loss/seq after 01650 batchs: 1354.1915283203125
INFO:root:Train (Epoch 36): Loss/seq after 01700 batchs: 1344.539794921875
INFO:root:Train (Epoch 36): Loss/seq after 01750 batchs: 1331.8228759765625
INFO:root:Train (Epoch 36): Loss/seq after 01800 batchs: 1317.228271484375
INFO:root:Train (Epoch 36): Loss/seq after 01850 batchs: 1303.0120849609375
INFO:root:Train (Epoch 36): Loss/seq after 01900 batchs: 1301.4130859375
INFO:root:Train (Epoch 36): Loss/seq after 01950 batchs: 1296.1729736328125
INFO:root:Train (Epoch 36): Loss/seq after 02000 batchs: 1286.0870361328125
INFO:root:Train (Epoch 36): Loss/seq after 02050 batchs: 1277.6063232421875
INFO:root:Train (Epoch 36): Loss/seq after 02100 batchs: 1265.906982421875
INFO:root:Train (Epoch 36): Loss/seq after 02150 batchs: 1255.061767578125
INFO:root:Train (Epoch 36): Loss/seq after 02200 batchs: 1243.48681640625
INFO:root:Train (Epoch 36): Loss/seq after 02250 batchs: 1248.2799072265625
INFO:root:Train (Epoch 36): Loss/seq after 02300 batchs: 1256.615478515625
INFO:root:Train (Epoch 36): Loss/seq after 02350 batchs: 1247.44873046875
INFO:root:Train (Epoch 36): Loss/seq after 02400 batchs: 1243.5245361328125
INFO:root:Train (Epoch 36): Loss/seq after 02450 batchs: 1230.954833984375
INFO:root:Train (Epoch 36): Loss/seq after 02500 batchs: 1213.571044921875
INFO:root:Train (Epoch 36): Loss/seq after 02550 batchs: 1204.2086181640625
INFO:root:Train (Epoch 36): Loss/seq after 02600 batchs: 1203.9156494140625
INFO:root:Train (Epoch 36): Loss/seq after 02650 batchs: 1199.9005126953125
INFO:root:Train (Epoch 36): Loss/seq after 02700 batchs: 1198.4610595703125
INFO:root:Train (Epoch 36): Loss/seq after 02750 batchs: 1230.0345458984375
INFO:root:Train (Epoch 36): Loss/seq after 02800 batchs: 1237.6397705078125
INFO:root:Train (Epoch 36): Loss/seq after 02850 batchs: 1235.0474853515625
INFO:root:Train (Epoch 36): Loss/seq after 02900 batchs: 1233.2081298828125
INFO:root:Train (Epoch 36): Loss/seq after 02950 batchs: 1225.215576171875
INFO:root:Train (Epoch 36): Loss/seq after 03000 batchs: 1222.9351806640625
INFO:root:Train (Epoch 36): Loss/seq after 03050 batchs: 1225.2789306640625
INFO:root:Train (Epoch 36): Loss/seq after 03100 batchs: 1239.63671875
INFO:root:Train (Epoch 36): Loss/seq after 03150 batchs: 1248.5408935546875
INFO:root:Train (Epoch 36): Loss/seq after 03200 batchs: 1252.35400390625
INFO:root:Train (Epoch 36): Loss/seq after 03250 batchs: 1253.1165771484375
INFO:root:Train (Epoch 36): Loss/seq after 03300 batchs: 1252.58447265625
INFO:root:Train (Epoch 36): Loss/seq after 03350 batchs: 1253.3359375
INFO:root:Train (Epoch 36): Loss/seq after 03400 batchs: 1244.4132080078125
INFO:root:Train (Epoch 36): Loss/seq after 03450 batchs: 1237.3306884765625
INFO:root:Train (Epoch 36): Loss/seq after 03500 batchs: 1237.278076171875
INFO:root:Train (Epoch 36): Loss/seq after 03550 batchs: 1232.213623046875
INFO:root:Train (Epoch 36): Loss/seq after 03600 batchs: 1237.9534912109375
INFO:root:Train (Epoch 36): Loss/seq after 03650 batchs: 1233.6048583984375
INFO:root:Train (Epoch 36): Loss/seq after 03700 batchs: 1233.219482421875
INFO:root:Train (Epoch 36): Loss/seq after 03750 batchs: 1232.962890625
INFO:root:Train (Epoch 36): Loss/seq after 03800 batchs: 1225.880615234375
INFO:root:Train (Epoch 36): Loss/seq after 03850 batchs: 1221.30419921875
INFO:root:Train (Epoch 36): Loss/seq after 03900 batchs: 1227.70458984375
INFO:root:Train (Epoch 36): Loss/seq after 03950 batchs: 1231.54345703125
INFO:root:Train (Epoch 36): Loss/seq after 04000 batchs: 1222.446533203125
INFO:root:Train (Epoch 36): Loss/seq after 04050 batchs: 1214.3948974609375
INFO:root:Train (Epoch 36): Loss/seq after 04100 batchs: 1209.06591796875
INFO:root:Train (Epoch 36): Loss/seq after 04150 batchs: 1203.23974609375
INFO:root:Train (Epoch 36): Loss/seq after 04200 batchs: 1198.3326416015625
INFO:root:Train (Epoch 36): Loss/seq after 04250 batchs: 1194.0047607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 36): Loss/seq after 00000 batches: 887.3367309570312
INFO:root:# Valid (Epoch 36): Loss/seq after 00050 batches: 1105.03173828125
INFO:root:# Valid (Epoch 36): Loss/seq after 00100 batches: 1413.6806640625
INFO:root:# Valid (Epoch 36): Loss/seq after 00150 batches: 1138.1639404296875
INFO:root:# Valid (Epoch 36): Loss/seq after 00200 batches: 1023.7822875976562
INFO:root:Artifacts: Make stick videos for epoch 36
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_36_on_20220414_114620.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_36_index_441_on_20220414_114620.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 37): Loss/seq after 00000 batchs: 1685.1026611328125
INFO:root:Train (Epoch 37): Loss/seq after 00050 batchs: 1594.0263671875
INFO:root:Train (Epoch 37): Loss/seq after 00100 batchs: 1616.116943359375
INFO:root:Train (Epoch 37): Loss/seq after 00150 batchs: 1449.9320068359375
INFO:root:Train (Epoch 37): Loss/seq after 00200 batchs: 1546.90185546875
INFO:root:Train (Epoch 37): Loss/seq after 00250 batchs: 1672.53857421875
INFO:root:Train (Epoch 37): Loss/seq after 00300 batchs: 1577.884765625
INFO:root:Train (Epoch 37): Loss/seq after 00350 batchs: 1476.9442138671875
INFO:root:Train (Epoch 37): Loss/seq after 00400 batchs: 1522.1668701171875
INFO:root:Train (Epoch 37): Loss/seq after 00450 batchs: 1450.62548828125
INFO:root:Train (Epoch 37): Loss/seq after 00500 batchs: 1483.0238037109375
INFO:root:Train (Epoch 37): Loss/seq after 00550 batchs: 1422.5614013671875
INFO:root:Train (Epoch 37): Loss/seq after 00600 batchs: 1388.6370849609375
INFO:root:Train (Epoch 37): Loss/seq after 00650 batchs: 1387.271484375
INFO:root:Train (Epoch 37): Loss/seq after 00700 batchs: 1368.7056884765625
INFO:root:Train (Epoch 37): Loss/seq after 00750 batchs: 1402.3824462890625
INFO:root:Train (Epoch 37): Loss/seq after 00800 batchs: 1399.0755615234375
INFO:root:Train (Epoch 37): Loss/seq after 00850 batchs: 1371.2724609375
INFO:root:Train (Epoch 37): Loss/seq after 00900 batchs: 1382.1649169921875
INFO:root:Train (Epoch 37): Loss/seq after 00950 batchs: 1417.2991943359375
INFO:root:Train (Epoch 37): Loss/seq after 01000 batchs: 1415.3074951171875
INFO:root:Train (Epoch 37): Loss/seq after 01050 batchs: 1399.522705078125
INFO:root:Train (Epoch 37): Loss/seq after 01100 batchs: 1398.502685546875
INFO:root:Train (Epoch 37): Loss/seq after 01150 batchs: 1379.55224609375
INFO:root:Train (Epoch 37): Loss/seq after 01200 batchs: 1367.36181640625
INFO:root:Train (Epoch 37): Loss/seq after 01250 batchs: 1360.7001953125
INFO:root:Train (Epoch 37): Loss/seq after 01300 batchs: 1360.8076171875
INFO:root:Train (Epoch 37): Loss/seq after 01350 batchs: 1359.9293212890625
INFO:root:Train (Epoch 37): Loss/seq after 01400 batchs: 1380.274658203125
INFO:root:Train (Epoch 37): Loss/seq after 01450 batchs: 1368.9918212890625
INFO:root:Train (Epoch 37): Loss/seq after 01500 batchs: 1358.5196533203125
INFO:root:Train (Epoch 37): Loss/seq after 01550 batchs: 1363.009765625
INFO:root:Train (Epoch 37): Loss/seq after 01600 batchs: 1345.341064453125
INFO:root:Train (Epoch 37): Loss/seq after 01650 batchs: 1340.3304443359375
INFO:root:Train (Epoch 37): Loss/seq after 01700 batchs: 1331.1087646484375
INFO:root:Train (Epoch 37): Loss/seq after 01750 batchs: 1318.714111328125
INFO:root:Train (Epoch 37): Loss/seq after 01800 batchs: 1304.3258056640625
INFO:root:Train (Epoch 37): Loss/seq after 01850 batchs: 1290.494384765625
INFO:root:Train (Epoch 37): Loss/seq after 01900 batchs: 1289.2421875
INFO:root:Train (Epoch 37): Loss/seq after 01950 batchs: 1284.332763671875
INFO:root:Train (Epoch 37): Loss/seq after 02000 batchs: 1274.5894775390625
INFO:root:Train (Epoch 37): Loss/seq after 02050 batchs: 1266.4390869140625
INFO:root:Train (Epoch 37): Loss/seq after 02100 batchs: 1255.0230712890625
INFO:root:Train (Epoch 37): Loss/seq after 02150 batchs: 1244.43359375
INFO:root:Train (Epoch 37): Loss/seq after 02200 batchs: 1233.135498046875
INFO:root:Train (Epoch 37): Loss/seq after 02250 batchs: 1238.3978271484375
INFO:root:Train (Epoch 37): Loss/seq after 02300 batchs: 1247.90185546875
INFO:root:Train (Epoch 37): Loss/seq after 02350 batchs: 1239.03857421875
INFO:root:Train (Epoch 37): Loss/seq after 02400 batchs: 1235.7454833984375
INFO:root:Train (Epoch 37): Loss/seq after 02450 batchs: 1223.7955322265625
INFO:root:Train (Epoch 37): Loss/seq after 02500 batchs: 1206.590576171875
INFO:root:Train (Epoch 37): Loss/seq after 02550 batchs: 1195.8570556640625
INFO:root:Train (Epoch 37): Loss/seq after 02600 batchs: 1193.6068115234375
INFO:root:Train (Epoch 37): Loss/seq after 02650 batchs: 1189.0291748046875
INFO:root:Train (Epoch 37): Loss/seq after 02700 batchs: 1185.39208984375
INFO:root:Train (Epoch 37): Loss/seq after 02750 batchs: 1218.17724609375
INFO:root:Train (Epoch 37): Loss/seq after 02800 batchs: 1223.371337890625
INFO:root:Train (Epoch 37): Loss/seq after 02850 batchs: 1220.495361328125
INFO:root:Train (Epoch 37): Loss/seq after 02900 batchs: 1218.785888671875
INFO:root:Train (Epoch 37): Loss/seq after 02950 batchs: 1210.75048828125
INFO:root:Train (Epoch 37): Loss/seq after 03000 batchs: 1208.68701171875
INFO:root:Train (Epoch 37): Loss/seq after 03050 batchs: 1211.361572265625
INFO:root:Train (Epoch 37): Loss/seq after 03100 batchs: 1226.583984375
INFO:root:Train (Epoch 37): Loss/seq after 03150 batchs: 1237.1986083984375
INFO:root:Train (Epoch 37): Loss/seq after 03200 batchs: 1241.6187744140625
INFO:root:Train (Epoch 37): Loss/seq after 03250 batchs: 1243.5892333984375
INFO:root:Train (Epoch 37): Loss/seq after 03300 batchs: 1243.060546875
INFO:root:Train (Epoch 37): Loss/seq after 03350 batchs: 1243.4173583984375
INFO:root:Train (Epoch 37): Loss/seq after 03400 batchs: 1234.631591796875
INFO:root:Train (Epoch 37): Loss/seq after 03450 batchs: 1227.651611328125
INFO:root:Train (Epoch 37): Loss/seq after 03500 batchs: 1227.7254638671875
INFO:root:Train (Epoch 37): Loss/seq after 03550 batchs: 1222.8148193359375
INFO:root:Train (Epoch 37): Loss/seq after 03600 batchs: 1228.705322265625
INFO:root:Train (Epoch 37): Loss/seq after 03650 batchs: 1224.534423828125
INFO:root:Train (Epoch 37): Loss/seq after 03700 batchs: 1224.28857421875
INFO:root:Train (Epoch 37): Loss/seq after 03750 batchs: 1224.1278076171875
INFO:root:Train (Epoch 37): Loss/seq after 03800 batchs: 1217.1722412109375
INFO:root:Train (Epoch 37): Loss/seq after 03850 batchs: 1212.7381591796875
INFO:root:Train (Epoch 37): Loss/seq after 03900 batchs: 1219.114501953125
INFO:root:Train (Epoch 37): Loss/seq after 03950 batchs: 1222.995849609375
INFO:root:Train (Epoch 37): Loss/seq after 04000 batchs: 1214.0125732421875
INFO:root:Train (Epoch 37): Loss/seq after 04050 batchs: 1206.06298828125
INFO:root:Train (Epoch 37): Loss/seq after 04100 batchs: 1201.102783203125
INFO:root:Train (Epoch 37): Loss/seq after 04150 batchs: 1195.5372314453125
INFO:root:Train (Epoch 37): Loss/seq after 04200 batchs: 1190.6796875
INFO:root:Train (Epoch 37): Loss/seq after 04250 batchs: 1186.4547119140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 37): Loss/seq after 00000 batches: 885.9465942382812
INFO:root:# Valid (Epoch 37): Loss/seq after 00050 batches: 1107.3028564453125
INFO:root:# Valid (Epoch 37): Loss/seq after 00100 batches: 1422.442626953125
INFO:root:# Valid (Epoch 37): Loss/seq after 00150 batches: 1151.88330078125
INFO:root:# Valid (Epoch 37): Loss/seq after 00200 batches: 1038.9022216796875
INFO:root:Artifacts: Make stick videos for epoch 37
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_37_on_20220414_115146.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_37_index_1389_on_20220414_115146.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 38): Loss/seq after 00000 batchs: 2119.346923828125
INFO:root:Train (Epoch 38): Loss/seq after 00050 batchs: 1613.258056640625
INFO:root:Train (Epoch 38): Loss/seq after 00100 batchs: 1614.66455078125
INFO:root:Train (Epoch 38): Loss/seq after 00150 batchs: 1450.4822998046875
INFO:root:Train (Epoch 38): Loss/seq after 00200 batchs: 1574.382080078125
INFO:root:Train (Epoch 38): Loss/seq after 00250 batchs: 1690.822998046875
INFO:root:Train (Epoch 38): Loss/seq after 00300 batchs: 1593.2137451171875
INFO:root:Train (Epoch 38): Loss/seq after 00350 batchs: 1490.4390869140625
INFO:root:Train (Epoch 38): Loss/seq after 00400 batchs: 1534.8787841796875
INFO:root:Train (Epoch 38): Loss/seq after 00450 batchs: 1461.9405517578125
INFO:root:Train (Epoch 38): Loss/seq after 00500 batchs: 1496.714111328125
INFO:root:Train (Epoch 38): Loss/seq after 00550 batchs: 1435.1060791015625
INFO:root:Train (Epoch 38): Loss/seq after 00600 batchs: 1402.081787109375
INFO:root:Train (Epoch 38): Loss/seq after 00650 batchs: 1407.1094970703125
INFO:root:Train (Epoch 38): Loss/seq after 00700 batchs: 1392.57666015625
INFO:root:Train (Epoch 38): Loss/seq after 00750 batchs: 1422.978759765625
INFO:root:Train (Epoch 38): Loss/seq after 00800 batchs: 1418.710693359375
INFO:root:Train (Epoch 38): Loss/seq after 00850 batchs: 1389.705322265625
INFO:root:Train (Epoch 38): Loss/seq after 00900 batchs: 1397.505126953125
INFO:root:Train (Epoch 38): Loss/seq after 00950 batchs: 1432.742919921875
INFO:root:Train (Epoch 38): Loss/seq after 01000 batchs: 1426.6170654296875
INFO:root:Train (Epoch 38): Loss/seq after 01050 batchs: 1410.56494140625
INFO:root:Train (Epoch 38): Loss/seq after 01100 batchs: 1404.4266357421875
INFO:root:Train (Epoch 38): Loss/seq after 01150 batchs: 1385.70166015625
INFO:root:Train (Epoch 38): Loss/seq after 01200 batchs: 1373.5224609375
INFO:root:Train (Epoch 38): Loss/seq after 01250 batchs: 1366.169677734375
INFO:root:Train (Epoch 38): Loss/seq after 01300 batchs: 1364.3343505859375
INFO:root:Train (Epoch 38): Loss/seq after 01350 batchs: 1366.0638427734375
INFO:root:Train (Epoch 38): Loss/seq after 01400 batchs: 1386.7052001953125
INFO:root:Train (Epoch 38): Loss/seq after 01450 batchs: 1375.262451171875
INFO:root:Train (Epoch 38): Loss/seq after 01500 batchs: 1364.6259765625
INFO:root:Train (Epoch 38): Loss/seq after 01550 batchs: 1369.1917724609375
INFO:root:Train (Epoch 38): Loss/seq after 01600 batchs: 1351.6485595703125
INFO:root:Train (Epoch 38): Loss/seq after 01650 batchs: 1346.02587890625
INFO:root:Train (Epoch 38): Loss/seq after 01700 batchs: 1336.496826171875
INFO:root:Train (Epoch 38): Loss/seq after 01750 batchs: 1323.9354248046875
INFO:root:Train (Epoch 38): Loss/seq after 01800 batchs: 1309.379638671875
INFO:root:Train (Epoch 38): Loss/seq after 01850 batchs: 1295.3729248046875
INFO:root:Train (Epoch 38): Loss/seq after 01900 batchs: 1293.9302978515625
INFO:root:Train (Epoch 38): Loss/seq after 01950 batchs: 1288.8564453125
INFO:root:Train (Epoch 38): Loss/seq after 02000 batchs: 1278.9522705078125
INFO:root:Train (Epoch 38): Loss/seq after 02050 batchs: 1270.659423828125
INFO:root:Train (Epoch 38): Loss/seq after 02100 batchs: 1259.1268310546875
INFO:root:Train (Epoch 38): Loss/seq after 02150 batchs: 1248.4757080078125
INFO:root:Train (Epoch 38): Loss/seq after 02200 batchs: 1237.107177734375
INFO:root:Train (Epoch 38): Loss/seq after 02250 batchs: 1242.05712890625
INFO:root:Train (Epoch 38): Loss/seq after 02300 batchs: 1249.9921875
INFO:root:Train (Epoch 38): Loss/seq after 02350 batchs: 1240.9085693359375
INFO:root:Train (Epoch 38): Loss/seq after 02400 batchs: 1237.292236328125
INFO:root:Train (Epoch 38): Loss/seq after 02450 batchs: 1224.763916015625
INFO:root:Train (Epoch 38): Loss/seq after 02500 batchs: 1207.5201416015625
INFO:root:Train (Epoch 38): Loss/seq after 02550 batchs: 1196.6522216796875
INFO:root:Train (Epoch 38): Loss/seq after 02600 batchs: 1193.9278564453125
INFO:root:Train (Epoch 38): Loss/seq after 02650 batchs: 1189.394775390625
INFO:root:Train (Epoch 38): Loss/seq after 02700 batchs: 1186.444091796875
INFO:root:Train (Epoch 38): Loss/seq after 02750 batchs: 1217.7969970703125
INFO:root:Train (Epoch 38): Loss/seq after 02800 batchs: 1224.8402099609375
INFO:root:Train (Epoch 38): Loss/seq after 02850 batchs: 1222.0924072265625
INFO:root:Train (Epoch 38): Loss/seq after 02900 batchs: 1220.4698486328125
INFO:root:Train (Epoch 38): Loss/seq after 02950 batchs: 1212.410400390625
INFO:root:Train (Epoch 38): Loss/seq after 03000 batchs: 1210.295654296875
INFO:root:Train (Epoch 38): Loss/seq after 03050 batchs: 1212.8365478515625
INFO:root:Train (Epoch 38): Loss/seq after 03100 batchs: 1227.720703125
INFO:root:Train (Epoch 38): Loss/seq after 03150 batchs: 1235.4658203125
INFO:root:Train (Epoch 38): Loss/seq after 03200 batchs: 1238.948974609375
INFO:root:Train (Epoch 38): Loss/seq after 03250 batchs: 1239.9478759765625
INFO:root:Train (Epoch 38): Loss/seq after 03300 batchs: 1239.955078125
INFO:root:Train (Epoch 38): Loss/seq after 03350 batchs: 1240.2999267578125
INFO:root:Train (Epoch 38): Loss/seq after 03400 batchs: 1231.5257568359375
INFO:root:Train (Epoch 38): Loss/seq after 03450 batchs: 1224.5013427734375
INFO:root:Train (Epoch 38): Loss/seq after 03500 batchs: 1224.635498046875
INFO:root:Train (Epoch 38): Loss/seq after 03550 batchs: 1219.8616943359375
INFO:root:Train (Epoch 38): Loss/seq after 03600 batchs: 1225.867919921875
INFO:root:Train (Epoch 38): Loss/seq after 03650 batchs: 1221.7694091796875
INFO:root:Train (Epoch 38): Loss/seq after 03700 batchs: 1221.59326171875
INFO:root:Train (Epoch 38): Loss/seq after 03750 batchs: 1221.4969482421875
INFO:root:Train (Epoch 38): Loss/seq after 03800 batchs: 1214.58740234375
INFO:root:Train (Epoch 38): Loss/seq after 03850 batchs: 1210.185791015625
INFO:root:Train (Epoch 38): Loss/seq after 03900 batchs: 1215.2337646484375
INFO:root:Train (Epoch 38): Loss/seq after 03950 batchs: 1218.8555908203125
INFO:root:Train (Epoch 38): Loss/seq after 04000 batchs: 1209.906005859375
INFO:root:Train (Epoch 38): Loss/seq after 04050 batchs: 1202.00830078125
INFO:root:Train (Epoch 38): Loss/seq after 04100 batchs: 1196.7274169921875
INFO:root:Train (Epoch 38): Loss/seq after 04150 batchs: 1191.1083984375
INFO:root:Train (Epoch 38): Loss/seq after 04200 batchs: 1186.51220703125
INFO:root:Train (Epoch 38): Loss/seq after 04250 batchs: 1182.319580078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 38): Loss/seq after 00000 batches: 886.4456176757812
INFO:root:# Valid (Epoch 38): Loss/seq after 00050 batches: 1100.8760986328125
INFO:root:# Valid (Epoch 38): Loss/seq after 00100 batches: 1412.01318359375
INFO:root:# Valid (Epoch 38): Loss/seq after 00150 batches: 1137.5838623046875
INFO:root:# Valid (Epoch 38): Loss/seq after 00200 batches: 1024.3697509765625
INFO:root:Artifacts: Make stick videos for epoch 38
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_38_on_20220414_115711.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_38_index_1602_on_20220414_115711.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 39): Loss/seq after 00000 batchs: 1635.82568359375
INFO:root:Train (Epoch 39): Loss/seq after 00050 batchs: 1651.125244140625
INFO:root:Train (Epoch 39): Loss/seq after 00100 batchs: 1638.17431640625
INFO:root:Train (Epoch 39): Loss/seq after 00150 batchs: 1467.0125732421875
INFO:root:Train (Epoch 39): Loss/seq after 00200 batchs: 1579.607421875
INFO:root:Train (Epoch 39): Loss/seq after 00250 batchs: 1694.4385986328125
INFO:root:Train (Epoch 39): Loss/seq after 00300 batchs: 1596.394287109375
INFO:root:Train (Epoch 39): Loss/seq after 00350 batchs: 1493.2906494140625
INFO:root:Train (Epoch 39): Loss/seq after 00400 batchs: 1544.2904052734375
INFO:root:Train (Epoch 39): Loss/seq after 00450 batchs: 1470.2657470703125
INFO:root:Train (Epoch 39): Loss/seq after 00500 batchs: 1499.4066162109375
INFO:root:Train (Epoch 39): Loss/seq after 00550 batchs: 1437.88427734375
INFO:root:Train (Epoch 39): Loss/seq after 00600 batchs: 1405.4930419921875
INFO:root:Train (Epoch 39): Loss/seq after 00650 batchs: 1400.837646484375
INFO:root:Train (Epoch 39): Loss/seq after 00700 batchs: 1385.72509765625
INFO:root:Train (Epoch 39): Loss/seq after 00750 batchs: 1416.6199951171875
INFO:root:Train (Epoch 39): Loss/seq after 00800 batchs: 1412.5791015625
INFO:root:Train (Epoch 39): Loss/seq after 00850 batchs: 1384.075439453125
INFO:root:Train (Epoch 39): Loss/seq after 00900 batchs: 1393.1798095703125
INFO:root:Train (Epoch 39): Loss/seq after 00950 batchs: 1426.546875
INFO:root:Train (Epoch 39): Loss/seq after 01000 batchs: 1418.1363525390625
INFO:root:Train (Epoch 39): Loss/seq after 01050 batchs: 1402.5743408203125
INFO:root:Train (Epoch 39): Loss/seq after 01100 batchs: 1395.818115234375
INFO:root:Train (Epoch 39): Loss/seq after 01150 batchs: 1377.1314697265625
INFO:root:Train (Epoch 39): Loss/seq after 01200 batchs: 1365.1873779296875
INFO:root:Train (Epoch 39): Loss/seq after 01250 batchs: 1357.3505859375
INFO:root:Train (Epoch 39): Loss/seq after 01300 batchs: 1361.4837646484375
INFO:root:Train (Epoch 39): Loss/seq after 01350 batchs: 1362.3358154296875
INFO:root:Train (Epoch 39): Loss/seq after 01400 batchs: 1381.873046875
INFO:root:Train (Epoch 39): Loss/seq after 01450 batchs: 1370.383544921875
INFO:root:Train (Epoch 39): Loss/seq after 01500 batchs: 1359.754150390625
INFO:root:Train (Epoch 39): Loss/seq after 01550 batchs: 1364.53076171875
INFO:root:Train (Epoch 39): Loss/seq after 01600 batchs: 1346.941162109375
INFO:root:Train (Epoch 39): Loss/seq after 01650 batchs: 1341.577880859375
INFO:root:Train (Epoch 39): Loss/seq after 01700 batchs: 1332.3580322265625
INFO:root:Train (Epoch 39): Loss/seq after 01750 batchs: 1319.9068603515625
INFO:root:Train (Epoch 39): Loss/seq after 01800 batchs: 1305.4951171875
INFO:root:Train (Epoch 39): Loss/seq after 01850 batchs: 1291.5299072265625
INFO:root:Train (Epoch 39): Loss/seq after 01900 batchs: 1290.2103271484375
INFO:root:Train (Epoch 39): Loss/seq after 01950 batchs: 1285.1944580078125
INFO:root:Train (Epoch 39): Loss/seq after 02000 batchs: 1275.378173828125
INFO:root:Train (Epoch 39): Loss/seq after 02050 batchs: 1267.2452392578125
INFO:root:Train (Epoch 39): Loss/seq after 02100 batchs: 1255.806640625
INFO:root:Train (Epoch 39): Loss/seq after 02150 batchs: 1245.1734619140625
INFO:root:Train (Epoch 39): Loss/seq after 02200 batchs: 1233.8424072265625
INFO:root:Train (Epoch 39): Loss/seq after 02250 batchs: 1238.7607421875
INFO:root:Train (Epoch 39): Loss/seq after 02300 batchs: 1246.929931640625
INFO:root:Train (Epoch 39): Loss/seq after 02350 batchs: 1237.8006591796875
INFO:root:Train (Epoch 39): Loss/seq after 02400 batchs: 1233.9677734375
INFO:root:Train (Epoch 39): Loss/seq after 02450 batchs: 1221.3831787109375
INFO:root:Train (Epoch 39): Loss/seq after 02500 batchs: 1204.1761474609375
INFO:root:Train (Epoch 39): Loss/seq after 02550 batchs: 1193.614501953125
INFO:root:Train (Epoch 39): Loss/seq after 02600 batchs: 1191.5733642578125
INFO:root:Train (Epoch 39): Loss/seq after 02650 batchs: 1187.1878662109375
INFO:root:Train (Epoch 39): Loss/seq after 02700 batchs: 1184.8255615234375
INFO:root:Train (Epoch 39): Loss/seq after 02750 batchs: 1216.83935546875
INFO:root:Train (Epoch 39): Loss/seq after 02800 batchs: 1223.171875
INFO:root:Train (Epoch 39): Loss/seq after 02850 batchs: 1220.78076171875
INFO:root:Train (Epoch 39): Loss/seq after 02900 batchs: 1219.0335693359375
INFO:root:Train (Epoch 39): Loss/seq after 02950 batchs: 1211.15869140625
INFO:root:Train (Epoch 39): Loss/seq after 03000 batchs: 1209.056396484375
INFO:root:Train (Epoch 39): Loss/seq after 03050 batchs: 1211.6822509765625
INFO:root:Train (Epoch 39): Loss/seq after 03100 batchs: 1226.432861328125
INFO:root:Train (Epoch 39): Loss/seq after 03150 batchs: 1234.0029296875
INFO:root:Train (Epoch 39): Loss/seq after 03200 batchs: 1238.200927734375
INFO:root:Train (Epoch 39): Loss/seq after 03250 batchs: 1239.593994140625
INFO:root:Train (Epoch 39): Loss/seq after 03300 batchs: 1239.785888671875
INFO:root:Train (Epoch 39): Loss/seq after 03350 batchs: 1239.4757080078125
INFO:root:Train (Epoch 39): Loss/seq after 03400 batchs: 1230.701171875
INFO:root:Train (Epoch 39): Loss/seq after 03450 batchs: 1223.6424560546875
INFO:root:Train (Epoch 39): Loss/seq after 03500 batchs: 1223.6923828125
INFO:root:Train (Epoch 39): Loss/seq after 03550 batchs: 1218.884033203125
INFO:root:Train (Epoch 39): Loss/seq after 03600 batchs: 1224.914794921875
INFO:root:Train (Epoch 39): Loss/seq after 03650 batchs: 1220.837890625
INFO:root:Train (Epoch 39): Loss/seq after 03700 batchs: 1220.6517333984375
INFO:root:Train (Epoch 39): Loss/seq after 03750 batchs: 1220.5888671875
INFO:root:Train (Epoch 39): Loss/seq after 03800 batchs: 1213.7298583984375
INFO:root:Train (Epoch 39): Loss/seq after 03850 batchs: 1209.374755859375
INFO:root:Train (Epoch 39): Loss/seq after 03900 batchs: 1215.197998046875
INFO:root:Train (Epoch 39): Loss/seq after 03950 batchs: 1218.9842529296875
INFO:root:Train (Epoch 39): Loss/seq after 04000 batchs: 1210.0538330078125
INFO:root:Train (Epoch 39): Loss/seq after 04050 batchs: 1202.1524658203125
INFO:root:Train (Epoch 39): Loss/seq after 04100 batchs: 1196.6802978515625
INFO:root:Train (Epoch 39): Loss/seq after 04150 batchs: 1191.0010986328125
INFO:root:Train (Epoch 39): Loss/seq after 04200 batchs: 1186.22314453125
INFO:root:Train (Epoch 39): Loss/seq after 04250 batchs: 1182.006591796875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 39): Loss/seq after 00000 batches: 887.3877563476562
INFO:root:# Valid (Epoch 39): Loss/seq after 00050 batches: 1114.357666015625
INFO:root:# Valid (Epoch 39): Loss/seq after 00100 batches: 1422.5164794921875
INFO:root:# Valid (Epoch 39): Loss/seq after 00150 batches: 1140.465576171875
INFO:root:# Valid (Epoch 39): Loss/seq after 00200 batches: 1024.7630615234375
INFO:root:Artifacts: Make stick videos for epoch 39
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_39_on_20220414_120240.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_39_index_147_on_20220414_120240.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 40): Loss/seq after 00000 batchs: 1482.0672607421875
INFO:root:Train (Epoch 40): Loss/seq after 00050 batchs: 1567.324951171875
INFO:root:Train (Epoch 40): Loss/seq after 00100 batchs: 1588.513427734375
INFO:root:Train (Epoch 40): Loss/seq after 00150 batchs: 1432.2724609375
INFO:root:Train (Epoch 40): Loss/seq after 00200 batchs: 1544.386474609375
INFO:root:Train (Epoch 40): Loss/seq after 00250 batchs: 1667.1170654296875
INFO:root:Train (Epoch 40): Loss/seq after 00300 batchs: 1573.4693603515625
INFO:root:Train (Epoch 40): Loss/seq after 00350 batchs: 1473.5145263671875
INFO:root:Train (Epoch 40): Loss/seq after 00400 batchs: 1520.1689453125
INFO:root:Train (Epoch 40): Loss/seq after 00450 batchs: 1448.7427978515625
INFO:root:Train (Epoch 40): Loss/seq after 00500 batchs: 1485.6534423828125
INFO:root:Train (Epoch 40): Loss/seq after 00550 batchs: 1425.4320068359375
INFO:root:Train (Epoch 40): Loss/seq after 00600 batchs: 1393.74853515625
INFO:root:Train (Epoch 40): Loss/seq after 00650 batchs: 1394.6522216796875
INFO:root:Train (Epoch 40): Loss/seq after 00700 batchs: 1378.9893798828125
INFO:root:Train (Epoch 40): Loss/seq after 00750 batchs: 1408.196533203125
INFO:root:Train (Epoch 40): Loss/seq after 00800 batchs: 1405.1973876953125
INFO:root:Train (Epoch 40): Loss/seq after 00850 batchs: 1376.4691162109375
INFO:root:Train (Epoch 40): Loss/seq after 00900 batchs: 1384.9122314453125
INFO:root:Train (Epoch 40): Loss/seq after 00950 batchs: 1420.3604736328125
INFO:root:Train (Epoch 40): Loss/seq after 01000 batchs: 1415.43359375
INFO:root:Train (Epoch 40): Loss/seq after 01050 batchs: 1399.1435546875
INFO:root:Train (Epoch 40): Loss/seq after 01100 batchs: 1394.346923828125
INFO:root:Train (Epoch 40): Loss/seq after 01150 batchs: 1375.631103515625
INFO:root:Train (Epoch 40): Loss/seq after 01200 batchs: 1363.56787109375
INFO:root:Train (Epoch 40): Loss/seq after 01250 batchs: 1355.512939453125
INFO:root:Train (Epoch 40): Loss/seq after 01300 batchs: 1353.326171875
INFO:root:Train (Epoch 40): Loss/seq after 01350 batchs: 1351.722412109375
INFO:root:Train (Epoch 40): Loss/seq after 01400 batchs: 1371.7412109375
INFO:root:Train (Epoch 40): Loss/seq after 01450 batchs: 1360.614013671875
INFO:root:Train (Epoch 40): Loss/seq after 01500 batchs: 1350.3338623046875
INFO:root:Train (Epoch 40): Loss/seq after 01550 batchs: 1354.68310546875
INFO:root:Train (Epoch 40): Loss/seq after 01600 batchs: 1337.2620849609375
INFO:root:Train (Epoch 40): Loss/seq after 01650 batchs: 1332.3353271484375
INFO:root:Train (Epoch 40): Loss/seq after 01700 batchs: 1323.3797607421875
INFO:root:Train (Epoch 40): Loss/seq after 01750 batchs: 1311.2244873046875
INFO:root:Train (Epoch 40): Loss/seq after 01800 batchs: 1297.1585693359375
INFO:root:Train (Epoch 40): Loss/seq after 01850 batchs: 1283.577880859375
INFO:root:Train (Epoch 40): Loss/seq after 01900 batchs: 1282.5238037109375
INFO:root:Train (Epoch 40): Loss/seq after 01950 batchs: 1277.812255859375
INFO:root:Train (Epoch 40): Loss/seq after 02000 batchs: 1268.2027587890625
INFO:root:Train (Epoch 40): Loss/seq after 02050 batchs: 1260.2235107421875
INFO:root:Train (Epoch 40): Loss/seq after 02100 batchs: 1248.98193359375
INFO:root:Train (Epoch 40): Loss/seq after 02150 batchs: 1238.532958984375
INFO:root:Train (Epoch 40): Loss/seq after 02200 batchs: 1227.3663330078125
INFO:root:Train (Epoch 40): Loss/seq after 02250 batchs: 1232.642578125
INFO:root:Train (Epoch 40): Loss/seq after 02300 batchs: 1241.951904296875
INFO:root:Train (Epoch 40): Loss/seq after 02350 batchs: 1233.1455078125
INFO:root:Train (Epoch 40): Loss/seq after 02400 batchs: 1229.6328125
INFO:root:Train (Epoch 40): Loss/seq after 02450 batchs: 1217.2313232421875
INFO:root:Train (Epoch 40): Loss/seq after 02500 batchs: 1200.1324462890625
INFO:root:Train (Epoch 40): Loss/seq after 02550 batchs: 1189.403564453125
INFO:root:Train (Epoch 40): Loss/seq after 02600 batchs: 1187.0137939453125
INFO:root:Train (Epoch 40): Loss/seq after 02650 batchs: 1182.5396728515625
INFO:root:Train (Epoch 40): Loss/seq after 02700 batchs: 1179.057373046875
INFO:root:Train (Epoch 40): Loss/seq after 02750 batchs: 1210.239990234375
INFO:root:Train (Epoch 40): Loss/seq after 02800 batchs: 1215.1478271484375
INFO:root:Train (Epoch 40): Loss/seq after 02850 batchs: 1212.51708984375
INFO:root:Train (Epoch 40): Loss/seq after 02900 batchs: 1210.7420654296875
INFO:root:Train (Epoch 40): Loss/seq after 02950 batchs: 1202.81298828125
INFO:root:Train (Epoch 40): Loss/seq after 03000 batchs: 1200.850341796875
INFO:root:Train (Epoch 40): Loss/seq after 03050 batchs: 1203.608154296875
INFO:root:Train (Epoch 40): Loss/seq after 03100 batchs: 1217.5191650390625
INFO:root:Train (Epoch 40): Loss/seq after 03150 batchs: 1226.170654296875
INFO:root:Train (Epoch 40): Loss/seq after 03200 batchs: 1230.42431640625
INFO:root:Train (Epoch 40): Loss/seq after 03250 batchs: 1231.7005615234375
INFO:root:Train (Epoch 40): Loss/seq after 03300 batchs: 1230.9854736328125
INFO:root:Train (Epoch 40): Loss/seq after 03350 batchs: 1230.7603759765625
INFO:root:Train (Epoch 40): Loss/seq after 03400 batchs: 1222.1673583984375
INFO:root:Train (Epoch 40): Loss/seq after 03450 batchs: 1215.2259521484375
INFO:root:Train (Epoch 40): Loss/seq after 03500 batchs: 1215.1468505859375
INFO:root:Train (Epoch 40): Loss/seq after 03550 batchs: 1210.404296875
INFO:root:Train (Epoch 40): Loss/seq after 03600 batchs: 1216.453369140625
INFO:root:Train (Epoch 40): Loss/seq after 03650 batchs: 1212.449951171875
INFO:root:Train (Epoch 40): Loss/seq after 03700 batchs: 1212.3939208984375
INFO:root:Train (Epoch 40): Loss/seq after 03750 batchs: 1212.4163818359375
INFO:root:Train (Epoch 40): Loss/seq after 03800 batchs: 1205.625244140625
INFO:root:Train (Epoch 40): Loss/seq after 03850 batchs: 1201.3326416015625
INFO:root:Train (Epoch 40): Loss/seq after 03900 batchs: 1207.030517578125
INFO:root:Train (Epoch 40): Loss/seq after 03950 batchs: 1210.7332763671875
INFO:root:Train (Epoch 40): Loss/seq after 04000 batchs: 1201.8836669921875
INFO:root:Train (Epoch 40): Loss/seq after 04050 batchs: 1194.0777587890625
INFO:root:Train (Epoch 40): Loss/seq after 04100 batchs: 1188.9364013671875
INFO:root:Train (Epoch 40): Loss/seq after 04150 batchs: 1183.382080078125
INFO:root:Train (Epoch 40): Loss/seq after 04200 batchs: 1178.6920166015625
INFO:root:Train (Epoch 40): Loss/seq after 04250 batchs: 1174.5999755859375
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 40): Loss/seq after 00000 batches: 884.9437866210938
INFO:root:# Valid (Epoch 40): Loss/seq after 00050 batches: 1099.4879150390625
INFO:root:# Valid (Epoch 40): Loss/seq after 00100 batches: 1416.5821533203125
INFO:root:# Valid (Epoch 40): Loss/seq after 00150 batches: 1137.0987548828125
INFO:root:# Valid (Epoch 40): Loss/seq after 00200 batches: 1022.6089477539062
INFO:root:Artifacts: Make stick videos for epoch 40
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_40_on_20220414_120805.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_40_index_1405_on_20220414_120805.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 41): Loss/seq after 00000 batchs: 1571.5567626953125
INFO:root:Train (Epoch 41): Loss/seq after 00050 batchs: 1593.2169189453125
INFO:root:Train (Epoch 41): Loss/seq after 00100 batchs: 1618.1964111328125
INFO:root:Train (Epoch 41): Loss/seq after 00150 batchs: 1452.8284912109375
INFO:root:Train (Epoch 41): Loss/seq after 00200 batchs: 1553.7354736328125
INFO:root:Train (Epoch 41): Loss/seq after 00250 batchs: 1674.554443359375
INFO:root:Train (Epoch 41): Loss/seq after 00300 batchs: 1579.9149169921875
INFO:root:Train (Epoch 41): Loss/seq after 00350 batchs: 1480.0445556640625
INFO:root:Train (Epoch 41): Loss/seq after 00400 batchs: 1526.7811279296875
INFO:root:Train (Epoch 41): Loss/seq after 00450 batchs: 1454.715576171875
INFO:root:Train (Epoch 41): Loss/seq after 00500 batchs: 1491.464111328125
INFO:root:Train (Epoch 41): Loss/seq after 00550 batchs: 1430.5047607421875
INFO:root:Train (Epoch 41): Loss/seq after 00600 batchs: 1398.4256591796875
INFO:root:Train (Epoch 41): Loss/seq after 00650 batchs: 1396.138671875
INFO:root:Train (Epoch 41): Loss/seq after 00700 batchs: 1379.455322265625
INFO:root:Train (Epoch 41): Loss/seq after 00750 batchs: 1408.1529541015625
INFO:root:Train (Epoch 41): Loss/seq after 00800 batchs: 1404.89697265625
INFO:root:Train (Epoch 41): Loss/seq after 00850 batchs: 1377.3433837890625
INFO:root:Train (Epoch 41): Loss/seq after 00900 batchs: 1387.9744873046875
INFO:root:Train (Epoch 41): Loss/seq after 00950 batchs: 1421.1280517578125
INFO:root:Train (Epoch 41): Loss/seq after 01000 batchs: 1415.473388671875
INFO:root:Train (Epoch 41): Loss/seq after 01050 batchs: 1398.77197265625
INFO:root:Train (Epoch 41): Loss/seq after 01100 batchs: 1392.2520751953125
INFO:root:Train (Epoch 41): Loss/seq after 01150 batchs: 1373.9718017578125
INFO:root:Train (Epoch 41): Loss/seq after 01200 batchs: 1362.1129150390625
INFO:root:Train (Epoch 41): Loss/seq after 01250 batchs: 1353.4844970703125
INFO:root:Train (Epoch 41): Loss/seq after 01300 batchs: 1350.587646484375
INFO:root:Train (Epoch 41): Loss/seq after 01350 batchs: 1352.369873046875
INFO:root:Train (Epoch 41): Loss/seq after 01400 batchs: 1370.8662109375
INFO:root:Train (Epoch 41): Loss/seq after 01450 batchs: 1359.8651123046875
INFO:root:Train (Epoch 41): Loss/seq after 01500 batchs: 1349.6923828125
INFO:root:Train (Epoch 41): Loss/seq after 01550 batchs: 1354.716796875
INFO:root:Train (Epoch 41): Loss/seq after 01600 batchs: 1337.3651123046875
INFO:root:Train (Epoch 41): Loss/seq after 01650 batchs: 1332.6854248046875
INFO:root:Train (Epoch 41): Loss/seq after 01700 batchs: 1323.8338623046875
INFO:root:Train (Epoch 41): Loss/seq after 01750 batchs: 1311.658203125
INFO:root:Train (Epoch 41): Loss/seq after 01800 batchs: 1297.4658203125
INFO:root:Train (Epoch 41): Loss/seq after 01850 batchs: 1283.8134765625
INFO:root:Train (Epoch 41): Loss/seq after 01900 batchs: 1282.7156982421875
INFO:root:Train (Epoch 41): Loss/seq after 01950 batchs: 1277.9056396484375
INFO:root:Train (Epoch 41): Loss/seq after 02000 batchs: 1268.2742919921875
INFO:root:Train (Epoch 41): Loss/seq after 02050 batchs: 1260.2652587890625
INFO:root:Train (Epoch 41): Loss/seq after 02100 batchs: 1248.9942626953125
INFO:root:Train (Epoch 41): Loss/seq after 02150 batchs: 1238.5648193359375
INFO:root:Train (Epoch 41): Loss/seq after 02200 batchs: 1227.466552734375
INFO:root:Train (Epoch 41): Loss/seq after 02250 batchs: 1232.677001953125
INFO:root:Train (Epoch 41): Loss/seq after 02300 batchs: 1240.7257080078125
INFO:root:Train (Epoch 41): Loss/seq after 02350 batchs: 1231.745361328125
INFO:root:Train (Epoch 41): Loss/seq after 02400 batchs: 1228.1480712890625
INFO:root:Train (Epoch 41): Loss/seq after 02450 batchs: 1215.6749267578125
INFO:root:Train (Epoch 41): Loss/seq after 02500 batchs: 1198.5914306640625
INFO:root:Train (Epoch 41): Loss/seq after 02550 batchs: 1187.9010009765625
INFO:root:Train (Epoch 41): Loss/seq after 02600 batchs: 1185.534423828125
INFO:root:Train (Epoch 41): Loss/seq after 02650 batchs: 1181.15576171875
INFO:root:Train (Epoch 41): Loss/seq after 02700 batchs: 1178.47119140625
INFO:root:Train (Epoch 41): Loss/seq after 02750 batchs: 1209.4066162109375
INFO:root:Train (Epoch 41): Loss/seq after 02800 batchs: 1215.3460693359375
INFO:root:Train (Epoch 41): Loss/seq after 02850 batchs: 1212.7799072265625
INFO:root:Train (Epoch 41): Loss/seq after 02900 batchs: 1211.2745361328125
INFO:root:Train (Epoch 41): Loss/seq after 02950 batchs: 1203.412353515625
INFO:root:Train (Epoch 41): Loss/seq after 03000 batchs: 1201.4378662109375
INFO:root:Train (Epoch 41): Loss/seq after 03050 batchs: 1204.168212890625
INFO:root:Train (Epoch 41): Loss/seq after 03100 batchs: 1218.77587890625
INFO:root:Train (Epoch 41): Loss/seq after 03150 batchs: 1226.432861328125
INFO:root:Train (Epoch 41): Loss/seq after 03200 batchs: 1229.6353759765625
INFO:root:Train (Epoch 41): Loss/seq after 03250 batchs: 1230.5712890625
INFO:root:Train (Epoch 41): Loss/seq after 03300 batchs: 1229.3681640625
INFO:root:Train (Epoch 41): Loss/seq after 03350 batchs: 1229.095458984375
INFO:root:Train (Epoch 41): Loss/seq after 03400 batchs: 1220.5028076171875
INFO:root:Train (Epoch 41): Loss/seq after 03450 batchs: 1213.62158203125
INFO:root:Train (Epoch 41): Loss/seq after 03500 batchs: 1213.80810546875
INFO:root:Train (Epoch 41): Loss/seq after 03550 batchs: 1209.0447998046875
INFO:root:Train (Epoch 41): Loss/seq after 03600 batchs: 1215.1248779296875
INFO:root:Train (Epoch 41): Loss/seq after 03650 batchs: 1211.1461181640625
INFO:root:Train (Epoch 41): Loss/seq after 03700 batchs: 1211.0445556640625
INFO:root:Train (Epoch 41): Loss/seq after 03750 batchs: 1211.0858154296875
INFO:root:Train (Epoch 41): Loss/seq after 03800 batchs: 1204.3128662109375
INFO:root:Train (Epoch 41): Loss/seq after 03850 batchs: 1200.03173828125
INFO:root:Train (Epoch 41): Loss/seq after 03900 batchs: 1205.4356689453125
INFO:root:Train (Epoch 41): Loss/seq after 03950 batchs: 1208.9864501953125
INFO:root:Train (Epoch 41): Loss/seq after 04000 batchs: 1200.1600341796875
INFO:root:Train (Epoch 41): Loss/seq after 04050 batchs: 1192.377685546875
INFO:root:Train (Epoch 41): Loss/seq after 04100 batchs: 1187.0836181640625
INFO:root:Train (Epoch 41): Loss/seq after 04150 batchs: 1181.5318603515625
INFO:root:Train (Epoch 41): Loss/seq after 04200 batchs: 1176.846435546875
INFO:root:Train (Epoch 41): Loss/seq after 04250 batchs: 1172.7799072265625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 41): Loss/seq after 00000 batches: 884.6266479492188
INFO:root:# Valid (Epoch 41): Loss/seq after 00050 batches: 1118.86572265625
INFO:root:# Valid (Epoch 41): Loss/seq after 00100 batches: 1428.677001953125
INFO:root:# Valid (Epoch 41): Loss/seq after 00150 batches: 1160.9276123046875
INFO:root:# Valid (Epoch 41): Loss/seq after 00200 batches: 1051.93603515625
INFO:root:Artifacts: Make stick videos for epoch 41
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_41_on_20220414_121329.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_41_index_874_on_20220414_121329.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 42): Loss/seq after 00000 batchs: 1520.0367431640625
INFO:root:Train (Epoch 42): Loss/seq after 00050 batchs: 1590.9769287109375
INFO:root:Train (Epoch 42): Loss/seq after 00100 batchs: 1600.8426513671875
INFO:root:Train (Epoch 42): Loss/seq after 00150 batchs: 1439.0078125
INFO:root:Train (Epoch 42): Loss/seq after 00200 batchs: 1540.5968017578125
INFO:root:Train (Epoch 42): Loss/seq after 00250 batchs: 1658.7728271484375
INFO:root:Train (Epoch 42): Loss/seq after 00300 batchs: 1566.40771484375
INFO:root:Train (Epoch 42): Loss/seq after 00350 batchs: 1467.4014892578125
INFO:root:Train (Epoch 42): Loss/seq after 00400 batchs: 1518.3780517578125
INFO:root:Train (Epoch 42): Loss/seq after 00450 batchs: 1447.125244140625
INFO:root:Train (Epoch 42): Loss/seq after 00500 batchs: 1481.4725341796875
INFO:root:Train (Epoch 42): Loss/seq after 00550 batchs: 1421.318359375
INFO:root:Train (Epoch 42): Loss/seq after 00600 batchs: 1388.408935546875
INFO:root:Train (Epoch 42): Loss/seq after 00650 batchs: 1387.2052001953125
INFO:root:Train (Epoch 42): Loss/seq after 00700 batchs: 1368.0169677734375
INFO:root:Train (Epoch 42): Loss/seq after 00750 batchs: 1398.7548828125
INFO:root:Train (Epoch 42): Loss/seq after 00800 batchs: 1395.742919921875
INFO:root:Train (Epoch 42): Loss/seq after 00850 batchs: 1368.19287109375
INFO:root:Train (Epoch 42): Loss/seq after 00900 batchs: 1377.81689453125
INFO:root:Train (Epoch 42): Loss/seq after 00950 batchs: 1411.153564453125
INFO:root:Train (Epoch 42): Loss/seq after 01000 batchs: 1403.5989990234375
INFO:root:Train (Epoch 42): Loss/seq after 01050 batchs: 1388.4443359375
INFO:root:Train (Epoch 42): Loss/seq after 01100 batchs: 1381.3065185546875
INFO:root:Train (Epoch 42): Loss/seq after 01150 batchs: 1363.623291015625
INFO:root:Train (Epoch 42): Loss/seq after 01200 batchs: 1352.09521484375
INFO:root:Train (Epoch 42): Loss/seq after 01250 batchs: 1344.5521240234375
INFO:root:Train (Epoch 42): Loss/seq after 01300 batchs: 1341.631591796875
INFO:root:Train (Epoch 42): Loss/seq after 01350 batchs: 1341.0697021484375
INFO:root:Train (Epoch 42): Loss/seq after 01400 batchs: 1359.4195556640625
INFO:root:Train (Epoch 42): Loss/seq after 01450 batchs: 1349.64794921875
INFO:root:Train (Epoch 42): Loss/seq after 01500 batchs: 1339.69189453125
INFO:root:Train (Epoch 42): Loss/seq after 01550 batchs: 1343.788330078125
INFO:root:Train (Epoch 42): Loss/seq after 01600 batchs: 1326.8974609375
INFO:root:Train (Epoch 42): Loss/seq after 01650 batchs: 1321.9210205078125
INFO:root:Train (Epoch 42): Loss/seq after 01700 batchs: 1313.285400390625
INFO:root:Train (Epoch 42): Loss/seq after 01750 batchs: 1301.3701171875
INFO:root:Train (Epoch 42): Loss/seq after 01800 batchs: 1287.482177734375
INFO:root:Train (Epoch 42): Loss/seq after 01850 batchs: 1274.122314453125
INFO:root:Train (Epoch 42): Loss/seq after 01900 batchs: 1273.288330078125
INFO:root:Train (Epoch 42): Loss/seq after 01950 batchs: 1268.829833984375
INFO:root:Train (Epoch 42): Loss/seq after 02000 batchs: 1259.439453125
INFO:root:Train (Epoch 42): Loss/seq after 02050 batchs: 1251.6705322265625
INFO:root:Train (Epoch 42): Loss/seq after 02100 batchs: 1240.60009765625
INFO:root:Train (Epoch 42): Loss/seq after 02150 batchs: 1230.3656005859375
INFO:root:Train (Epoch 42): Loss/seq after 02200 batchs: 1219.3994140625
INFO:root:Train (Epoch 42): Loss/seq after 02250 batchs: 1224.558349609375
INFO:root:Train (Epoch 42): Loss/seq after 02300 batchs: 1233.81298828125
INFO:root:Train (Epoch 42): Loss/seq after 02350 batchs: 1225.114990234375
INFO:root:Train (Epoch 42): Loss/seq after 02400 batchs: 1221.702880859375
INFO:root:Train (Epoch 42): Loss/seq after 02450 batchs: 1209.4093017578125
INFO:root:Train (Epoch 42): Loss/seq after 02500 batchs: 1192.45166015625
INFO:root:Train (Epoch 42): Loss/seq after 02550 batchs: 1182.0269775390625
INFO:root:Train (Epoch 42): Loss/seq after 02600 batchs: 1179.86376953125
INFO:root:Train (Epoch 42): Loss/seq after 02650 batchs: 1175.705810546875
INFO:root:Train (Epoch 42): Loss/seq after 02700 batchs: 1172.940185546875
INFO:root:Train (Epoch 42): Loss/seq after 02750 batchs: 1205.503662109375
INFO:root:Train (Epoch 42): Loss/seq after 02800 batchs: 1210.874755859375
INFO:root:Train (Epoch 42): Loss/seq after 02850 batchs: 1208.4996337890625
INFO:root:Train (Epoch 42): Loss/seq after 02900 batchs: 1206.947509765625
INFO:root:Train (Epoch 42): Loss/seq after 02950 batchs: 1199.1058349609375
INFO:root:Train (Epoch 42): Loss/seq after 03000 batchs: 1197.3331298828125
INFO:root:Train (Epoch 42): Loss/seq after 03050 batchs: 1200.1954345703125
INFO:root:Train (Epoch 42): Loss/seq after 03100 batchs: 1214.0804443359375
INFO:root:Train (Epoch 42): Loss/seq after 03150 batchs: 1221.769287109375
INFO:root:Train (Epoch 42): Loss/seq after 03200 batchs: 1225.638671875
INFO:root:Train (Epoch 42): Loss/seq after 03250 batchs: 1225.8892822265625
INFO:root:Train (Epoch 42): Loss/seq after 03300 batchs: 1225.5377197265625
INFO:root:Train (Epoch 42): Loss/seq after 03350 batchs: 1225.158447265625
INFO:root:Train (Epoch 42): Loss/seq after 03400 batchs: 1216.6019287109375
INFO:root:Train (Epoch 42): Loss/seq after 03450 batchs: 1209.728515625
INFO:root:Train (Epoch 42): Loss/seq after 03500 batchs: 1209.8924560546875
INFO:root:Train (Epoch 42): Loss/seq after 03550 batchs: 1205.257080078125
INFO:root:Train (Epoch 42): Loss/seq after 03600 batchs: 1211.4302978515625
INFO:root:Train (Epoch 42): Loss/seq after 03650 batchs: 1207.46142578125
INFO:root:Train (Epoch 42): Loss/seq after 03700 batchs: 1207.430908203125
INFO:root:Train (Epoch 42): Loss/seq after 03750 batchs: 1207.50732421875
INFO:root:Train (Epoch 42): Loss/seq after 03800 batchs: 1200.768798828125
INFO:root:Train (Epoch 42): Loss/seq after 03850 batchs: 1196.5352783203125
INFO:root:Train (Epoch 42): Loss/seq after 03900 batchs: 1201.8321533203125
INFO:root:Train (Epoch 42): Loss/seq after 03950 batchs: 1205.392822265625
INFO:root:Train (Epoch 42): Loss/seq after 04000 batchs: 1196.6123046875
INFO:root:Train (Epoch 42): Loss/seq after 04050 batchs: 1188.869384765625
INFO:root:Train (Epoch 42): Loss/seq after 04100 batchs: 1183.5419921875
INFO:root:Train (Epoch 42): Loss/seq after 04150 batchs: 1178.0335693359375
INFO:root:Train (Epoch 42): Loss/seq after 04200 batchs: 1173.4488525390625
INFO:root:Train (Epoch 42): Loss/seq after 04250 batchs: 1169.3797607421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 42): Loss/seq after 00000 batches: 903.7864990234375
INFO:root:# Valid (Epoch 42): Loss/seq after 00050 batches: 1110.0623779296875
INFO:root:# Valid (Epoch 42): Loss/seq after 00100 batches: 1424.3465576171875
INFO:root:# Valid (Epoch 42): Loss/seq after 00150 batches: 1144.922119140625
INFO:root:# Valid (Epoch 42): Loss/seq after 00200 batches: 1028.3182373046875
INFO:root:Artifacts: Make stick videos for epoch 42
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_42_on_20220414_121852.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_42_index_112_on_20220414_121852.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 43): Loss/seq after 00000 batchs: 1503.111328125
INFO:root:Train (Epoch 43): Loss/seq after 00050 batchs: 1553.1195068359375
INFO:root:Train (Epoch 43): Loss/seq after 00100 batchs: 1566.613037109375
INFO:root:Train (Epoch 43): Loss/seq after 00150 batchs: 1417.29833984375
INFO:root:Train (Epoch 43): Loss/seq after 00200 batchs: 1523.04541015625
INFO:root:Train (Epoch 43): Loss/seq after 00250 batchs: 1643.5419921875
INFO:root:Train (Epoch 43): Loss/seq after 00300 batchs: 1553.729248046875
INFO:root:Train (Epoch 43): Loss/seq after 00350 batchs: 1456.5374755859375
INFO:root:Train (Epoch 43): Loss/seq after 00400 batchs: 1507.33544921875
INFO:root:Train (Epoch 43): Loss/seq after 00450 batchs: 1437.338134765625
INFO:root:Train (Epoch 43): Loss/seq after 00500 batchs: 1471.022216796875
INFO:root:Train (Epoch 43): Loss/seq after 00550 batchs: 1411.8311767578125
INFO:root:Train (Epoch 43): Loss/seq after 00600 batchs: 1379.0594482421875
INFO:root:Train (Epoch 43): Loss/seq after 00650 batchs: 1372.7830810546875
INFO:root:Train (Epoch 43): Loss/seq after 00700 batchs: 1351.4957275390625
INFO:root:Train (Epoch 43): Loss/seq after 00750 batchs: 1381.846435546875
INFO:root:Train (Epoch 43): Loss/seq after 00800 batchs: 1379.9356689453125
INFO:root:Train (Epoch 43): Loss/seq after 00850 batchs: 1351.9654541015625
INFO:root:Train (Epoch 43): Loss/seq after 00900 batchs: 1361.1514892578125
INFO:root:Train (Epoch 43): Loss/seq after 00950 batchs: 1391.6043701171875
INFO:root:Train (Epoch 43): Loss/seq after 01000 batchs: 1384.2552490234375
INFO:root:Train (Epoch 43): Loss/seq after 01050 batchs: 1368.9676513671875
INFO:root:Train (Epoch 43): Loss/seq after 01100 batchs: 1361.5355224609375
INFO:root:Train (Epoch 43): Loss/seq after 01150 batchs: 1344.17236328125
INFO:root:Train (Epoch 43): Loss/seq after 01200 batchs: 1333.35107421875
INFO:root:Train (Epoch 43): Loss/seq after 01250 batchs: 1326.545166015625
INFO:root:Train (Epoch 43): Loss/seq after 01300 batchs: 1323.5272216796875
INFO:root:Train (Epoch 43): Loss/seq after 01350 batchs: 1322.3682861328125
INFO:root:Train (Epoch 43): Loss/seq after 01400 batchs: 1337.8380126953125
INFO:root:Train (Epoch 43): Loss/seq after 01450 batchs: 1328.246826171875
INFO:root:Train (Epoch 43): Loss/seq after 01500 batchs: 1319.094970703125
INFO:root:Train (Epoch 43): Loss/seq after 01550 batchs: 1324.498046875
INFO:root:Train (Epoch 43): Loss/seq after 01600 batchs: 1308.103759765625
INFO:root:Train (Epoch 43): Loss/seq after 01650 batchs: 1304.202392578125
INFO:root:Train (Epoch 43): Loss/seq after 01700 batchs: 1296.0609130859375
INFO:root:Train (Epoch 43): Loss/seq after 01750 batchs: 1284.731689453125
INFO:root:Train (Epoch 43): Loss/seq after 01800 batchs: 1271.447509765625
INFO:root:Train (Epoch 43): Loss/seq after 01850 batchs: 1258.4764404296875
INFO:root:Train (Epoch 43): Loss/seq after 01900 batchs: 1258.07666015625
INFO:root:Train (Epoch 43): Loss/seq after 01950 batchs: 1253.94921875
INFO:root:Train (Epoch 43): Loss/seq after 02000 batchs: 1244.946044921875
INFO:root:Train (Epoch 43): Loss/seq after 02050 batchs: 1237.48828125
INFO:root:Train (Epoch 43): Loss/seq after 02100 batchs: 1226.7542724609375
INFO:root:Train (Epoch 43): Loss/seq after 02150 batchs: 1216.803955078125
INFO:root:Train (Epoch 43): Loss/seq after 02200 batchs: 1206.1058349609375
INFO:root:Train (Epoch 43): Loss/seq after 02250 batchs: 1211.618896484375
INFO:root:Train (Epoch 43): Loss/seq after 02300 batchs: 1221.218505859375
INFO:root:Train (Epoch 43): Loss/seq after 02350 batchs: 1212.6787109375
INFO:root:Train (Epoch 43): Loss/seq after 02400 batchs: 1209.6165771484375
INFO:root:Train (Epoch 43): Loss/seq after 02450 batchs: 1197.6739501953125
INFO:root:Train (Epoch 43): Loss/seq after 02500 batchs: 1180.9625244140625
INFO:root:Train (Epoch 43): Loss/seq after 02550 batchs: 1170.501708984375
INFO:root:Train (Epoch 43): Loss/seq after 02600 batchs: 1168.7315673828125
INFO:root:Train (Epoch 43): Loss/seq after 02650 batchs: 1164.664306640625
INFO:root:Train (Epoch 43): Loss/seq after 02700 batchs: 1161.48486328125
INFO:root:Train (Epoch 43): Loss/seq after 02750 batchs: 1192.0416259765625
INFO:root:Train (Epoch 43): Loss/seq after 02800 batchs: 1197.8807373046875
INFO:root:Train (Epoch 43): Loss/seq after 02850 batchs: 1195.5269775390625
INFO:root:Train (Epoch 43): Loss/seq after 02900 batchs: 1193.9410400390625
INFO:root:Train (Epoch 43): Loss/seq after 02950 batchs: 1186.3475341796875
INFO:root:Train (Epoch 43): Loss/seq after 03000 batchs: 1184.77001953125
INFO:root:Train (Epoch 43): Loss/seq after 03050 batchs: 1187.8109130859375
INFO:root:Train (Epoch 43): Loss/seq after 03100 batchs: 1201.300537109375
INFO:root:Train (Epoch 43): Loss/seq after 03150 batchs: 1208.5693359375
INFO:root:Train (Epoch 43): Loss/seq after 03200 batchs: 1212.92236328125
INFO:root:Train (Epoch 43): Loss/seq after 03250 batchs: 1213.5020751953125
INFO:root:Train (Epoch 43): Loss/seq after 03300 batchs: 1212.727783203125
INFO:root:Train (Epoch 43): Loss/seq after 03350 batchs: 1211.977294921875
INFO:root:Train (Epoch 43): Loss/seq after 03400 batchs: 1203.7479248046875
INFO:root:Train (Epoch 43): Loss/seq after 03450 batchs: 1197.70654296875
INFO:root:Train (Epoch 43): Loss/seq after 03500 batchs: 1198.0411376953125
INFO:root:Train (Epoch 43): Loss/seq after 03550 batchs: 1193.6378173828125
INFO:root:Train (Epoch 43): Loss/seq after 03600 batchs: 1199.9747314453125
INFO:root:Train (Epoch 43): Loss/seq after 03650 batchs: 1196.196533203125
INFO:root:Train (Epoch 43): Loss/seq after 03700 batchs: 1196.32861328125
INFO:root:Train (Epoch 43): Loss/seq after 03750 batchs: 1196.5992431640625
INFO:root:Train (Epoch 43): Loss/seq after 03800 batchs: 1190.0118408203125
INFO:root:Train (Epoch 43): Loss/seq after 03850 batchs: 1185.9052734375
INFO:root:Train (Epoch 43): Loss/seq after 03900 batchs: 1191.117431640625
INFO:root:Train (Epoch 43): Loss/seq after 03950 batchs: 1194.703369140625
INFO:root:Train (Epoch 43): Loss/seq after 04000 batchs: 1186.0535888671875
INFO:root:Train (Epoch 43): Loss/seq after 04050 batchs: 1178.44091796875
INFO:root:Train (Epoch 43): Loss/seq after 04100 batchs: 1173.2657470703125
INFO:root:Train (Epoch 43): Loss/seq after 04150 batchs: 1167.8953857421875
INFO:root:Train (Epoch 43): Loss/seq after 04200 batchs: 1163.38818359375
INFO:root:Train (Epoch 43): Loss/seq after 04250 batchs: 1159.4654541015625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 43): Loss/seq after 00000 batches: 884.1102294921875
INFO:root:# Valid (Epoch 43): Loss/seq after 00050 batches: 1100.3642578125
INFO:root:# Valid (Epoch 43): Loss/seq after 00100 batches: 1409.6248779296875
INFO:root:# Valid (Epoch 43): Loss/seq after 00150 batches: 1134.616455078125
INFO:root:# Valid (Epoch 43): Loss/seq after 00200 batches: 1021.3356323242188
INFO:root:Artifacts: Make stick videos for epoch 43
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_43_on_20220414_122416.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_43_index_1540_on_20220414_122416.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 44): Loss/seq after 00000 batchs: 1622.4400634765625
INFO:root:Train (Epoch 44): Loss/seq after 00050 batchs: 1540.11865234375
INFO:root:Train (Epoch 44): Loss/seq after 00100 batchs: 1553.0914306640625
INFO:root:Train (Epoch 44): Loss/seq after 00150 batchs: 1406.139892578125
INFO:root:Train (Epoch 44): Loss/seq after 00200 batchs: 1517.64111328125
INFO:root:Train (Epoch 44): Loss/seq after 00250 batchs: 1625.5941162109375
INFO:root:Train (Epoch 44): Loss/seq after 00300 batchs: 1538.90966796875
INFO:root:Train (Epoch 44): Loss/seq after 00350 batchs: 1443.687255859375
INFO:root:Train (Epoch 44): Loss/seq after 00400 batchs: 1496.342529296875
INFO:root:Train (Epoch 44): Loss/seq after 00450 batchs: 1427.5325927734375
INFO:root:Train (Epoch 44): Loss/seq after 00500 batchs: 1459.7471923828125
INFO:root:Train (Epoch 44): Loss/seq after 00550 batchs: 1402.339599609375
INFO:root:Train (Epoch 44): Loss/seq after 00600 batchs: 1370.8756103515625
INFO:root:Train (Epoch 44): Loss/seq after 00650 batchs: 1365.117431640625
INFO:root:Train (Epoch 44): Loss/seq after 00700 batchs: 1339.8319091796875
INFO:root:Train (Epoch 44): Loss/seq after 00750 batchs: 1369.48974609375
INFO:root:Train (Epoch 44): Loss/seq after 00800 batchs: 1368.07177734375
INFO:root:Train (Epoch 44): Loss/seq after 00850 batchs: 1342.7840576171875
INFO:root:Train (Epoch 44): Loss/seq after 00900 batchs: 1353.1844482421875
INFO:root:Train (Epoch 44): Loss/seq after 00950 batchs: 1377.7503662109375
INFO:root:Train (Epoch 44): Loss/seq after 01000 batchs: 1370.986083984375
INFO:root:Train (Epoch 44): Loss/seq after 01050 batchs: 1356.767578125
INFO:root:Train (Epoch 44): Loss/seq after 01100 batchs: 1351.4544677734375
INFO:root:Train (Epoch 44): Loss/seq after 01150 batchs: 1334.5640869140625
INFO:root:Train (Epoch 44): Loss/seq after 01200 batchs: 1324.3023681640625
INFO:root:Train (Epoch 44): Loss/seq after 01250 batchs: 1317.0628662109375
INFO:root:Train (Epoch 44): Loss/seq after 01300 batchs: 1312.7054443359375
INFO:root:Train (Epoch 44): Loss/seq after 01350 batchs: 1311.764404296875
INFO:root:Train (Epoch 44): Loss/seq after 01400 batchs: 1326.7825927734375
INFO:root:Train (Epoch 44): Loss/seq after 01450 batchs: 1317.2490234375
INFO:root:Train (Epoch 44): Loss/seq after 01500 batchs: 1308.4366455078125
INFO:root:Train (Epoch 44): Loss/seq after 01550 batchs: 1313.78759765625
INFO:root:Train (Epoch 44): Loss/seq after 01600 batchs: 1297.7576904296875
INFO:root:Train (Epoch 44): Loss/seq after 01650 batchs: 1293.582763671875
INFO:root:Train (Epoch 44): Loss/seq after 01700 batchs: 1285.620361328125
INFO:root:Train (Epoch 44): Loss/seq after 01750 batchs: 1274.50634765625
INFO:root:Train (Epoch 44): Loss/seq after 01800 batchs: 1261.3309326171875
INFO:root:Train (Epoch 44): Loss/seq after 01850 batchs: 1248.61181640625
INFO:root:Train (Epoch 44): Loss/seq after 01900 batchs: 1248.408203125
INFO:root:Train (Epoch 44): Loss/seq after 01950 batchs: 1244.431640625
INFO:root:Train (Epoch 44): Loss/seq after 02000 batchs: 1235.6561279296875
INFO:root:Train (Epoch 44): Loss/seq after 02050 batchs: 1228.4375
INFO:root:Train (Epoch 44): Loss/seq after 02100 batchs: 1217.8887939453125
INFO:root:Train (Epoch 44): Loss/seq after 02150 batchs: 1208.13330078125
INFO:root:Train (Epoch 44): Loss/seq after 02200 batchs: 1197.6217041015625
INFO:root:Train (Epoch 44): Loss/seq after 02250 batchs: 1202.83544921875
INFO:root:Train (Epoch 44): Loss/seq after 02300 batchs: 1210.3621826171875
INFO:root:Train (Epoch 44): Loss/seq after 02350 batchs: 1202.101806640625
INFO:root:Train (Epoch 44): Loss/seq after 02400 batchs: 1199.0997314453125
INFO:root:Train (Epoch 44): Loss/seq after 02450 batchs: 1187.2008056640625
INFO:root:Train (Epoch 44): Loss/seq after 02500 batchs: 1170.6612548828125
INFO:root:Train (Epoch 44): Loss/seq after 02550 batchs: 1160.34912109375
INFO:root:Train (Epoch 44): Loss/seq after 02600 batchs: 1158.389404296875
INFO:root:Train (Epoch 44): Loss/seq after 02650 batchs: 1154.50048828125
INFO:root:Train (Epoch 44): Loss/seq after 02700 batchs: 1151.46826171875
INFO:root:Train (Epoch 44): Loss/seq after 02750 batchs: 1181.9398193359375
INFO:root:Train (Epoch 44): Loss/seq after 02800 batchs: 1187.5787353515625
INFO:root:Train (Epoch 44): Loss/seq after 02850 batchs: 1185.395751953125
INFO:root:Train (Epoch 44): Loss/seq after 02900 batchs: 1184.0072021484375
INFO:root:Train (Epoch 44): Loss/seq after 02950 batchs: 1176.5850830078125
INFO:root:Train (Epoch 44): Loss/seq after 03000 batchs: 1175.095703125
INFO:root:Train (Epoch 44): Loss/seq after 03050 batchs: 1178.24853515625
INFO:root:Train (Epoch 44): Loss/seq after 03100 batchs: 1191.5078125
INFO:root:Train (Epoch 44): Loss/seq after 03150 batchs: 1198.95166015625
INFO:root:Train (Epoch 44): Loss/seq after 03200 batchs: 1202.46630859375
INFO:root:Train (Epoch 44): Loss/seq after 03250 batchs: 1203.2802734375
INFO:root:Train (Epoch 44): Loss/seq after 03300 batchs: 1202.2471923828125
INFO:root:Train (Epoch 44): Loss/seq after 03350 batchs: 1201.6522216796875
INFO:root:Train (Epoch 44): Loss/seq after 03400 batchs: 1193.572265625
INFO:root:Train (Epoch 44): Loss/seq after 03450 batchs: 1187.24560546875
INFO:root:Train (Epoch 44): Loss/seq after 03500 batchs: 1187.2528076171875
INFO:root:Train (Epoch 44): Loss/seq after 03550 batchs: 1182.9403076171875
INFO:root:Train (Epoch 44): Loss/seq after 03600 batchs: 1189.43798828125
INFO:root:Train (Epoch 44): Loss/seq after 03650 batchs: 1185.8404541015625
INFO:root:Train (Epoch 44): Loss/seq after 03700 batchs: 1186.108642578125
INFO:root:Train (Epoch 44): Loss/seq after 03750 batchs: 1186.510009765625
INFO:root:Train (Epoch 44): Loss/seq after 03800 batchs: 1180.0704345703125
INFO:root:Train (Epoch 44): Loss/seq after 03850 batchs: 1176.0880126953125
INFO:root:Train (Epoch 44): Loss/seq after 03900 batchs: 1181.1849365234375
INFO:root:Train (Epoch 44): Loss/seq after 03950 batchs: 1184.7401123046875
INFO:root:Train (Epoch 44): Loss/seq after 04000 batchs: 1176.2008056640625
INFO:root:Train (Epoch 44): Loss/seq after 04050 batchs: 1168.7095947265625
INFO:root:Train (Epoch 44): Loss/seq after 04100 batchs: 1163.774658203125
INFO:root:Train (Epoch 44): Loss/seq after 04150 batchs: 1158.5594482421875
INFO:root:Train (Epoch 44): Loss/seq after 04200 batchs: 1154.1845703125
INFO:root:Train (Epoch 44): Loss/seq after 04250 batchs: 1150.3660888671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 44): Loss/seq after 00000 batches: 885.8388671875
INFO:root:# Valid (Epoch 44): Loss/seq after 00050 batches: 1123.4510498046875
INFO:root:# Valid (Epoch 44): Loss/seq after 00100 batches: 1427.0904541015625
INFO:root:# Valid (Epoch 44): Loss/seq after 00150 batches: 1156.02001953125
INFO:root:# Valid (Epoch 44): Loss/seq after 00200 batches: 1043.3343505859375
INFO:root:Artifacts: Make stick videos for epoch 44
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_44_on_20220414_122941.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_44_index_1173_on_20220414_122941.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 45): Loss/seq after 00000 batchs: 1600.226806640625
INFO:root:Train (Epoch 45): Loss/seq after 00050 batchs: 1517.3807373046875
INFO:root:Train (Epoch 45): Loss/seq after 00100 batchs: 1528.1622314453125
INFO:root:Train (Epoch 45): Loss/seq after 00150 batchs: 1391.746826171875
INFO:root:Train (Epoch 45): Loss/seq after 00200 batchs: 1494.3394775390625
INFO:root:Train (Epoch 45): Loss/seq after 00250 batchs: 1605.3304443359375
INFO:root:Train (Epoch 45): Loss/seq after 00300 batchs: 1522.122314453125
INFO:root:Train (Epoch 45): Loss/seq after 00350 batchs: 1429.7452392578125
INFO:root:Train (Epoch 45): Loss/seq after 00400 batchs: 1476.7313232421875
INFO:root:Train (Epoch 45): Loss/seq after 00450 batchs: 1410.1783447265625
INFO:root:Train (Epoch 45): Loss/seq after 00500 batchs: 1445.3016357421875
INFO:root:Train (Epoch 45): Loss/seq after 00550 batchs: 1388.738037109375
INFO:root:Train (Epoch 45): Loss/seq after 00600 batchs: 1357.5704345703125
INFO:root:Train (Epoch 45): Loss/seq after 00650 batchs: 1352.95703125
INFO:root:Train (Epoch 45): Loss/seq after 00700 batchs: 1327.43017578125
INFO:root:Train (Epoch 45): Loss/seq after 00750 batchs: 1356.493896484375
INFO:root:Train (Epoch 45): Loss/seq after 00800 batchs: 1355.4932861328125
INFO:root:Train (Epoch 45): Loss/seq after 00850 batchs: 1333.477294921875
INFO:root:Train (Epoch 45): Loss/seq after 00900 batchs: 1345.9124755859375
INFO:root:Train (Epoch 45): Loss/seq after 00950 batchs: 1376.934814453125
INFO:root:Train (Epoch 45): Loss/seq after 01000 batchs: 1368.4417724609375
INFO:root:Train (Epoch 45): Loss/seq after 01050 batchs: 1355.83935546875
INFO:root:Train (Epoch 45): Loss/seq after 01100 batchs: 1348.5599365234375
INFO:root:Train (Epoch 45): Loss/seq after 01150 batchs: 1332.1246337890625
INFO:root:Train (Epoch 45): Loss/seq after 01200 batchs: 1321.7535400390625
INFO:root:Train (Epoch 45): Loss/seq after 01250 batchs: 1314.6806640625
INFO:root:Train (Epoch 45): Loss/seq after 01300 batchs: 1309.8013916015625
INFO:root:Train (Epoch 45): Loss/seq after 01350 batchs: 1307.48779296875
INFO:root:Train (Epoch 45): Loss/seq after 01400 batchs: 1323.89794921875
INFO:root:Train (Epoch 45): Loss/seq after 01450 batchs: 1314.500732421875
INFO:root:Train (Epoch 45): Loss/seq after 01500 batchs: 1305.7437744140625
INFO:root:Train (Epoch 45): Loss/seq after 01550 batchs: 1310.5426025390625
INFO:root:Train (Epoch 45): Loss/seq after 01600 batchs: 1294.61376953125
INFO:root:Train (Epoch 45): Loss/seq after 01650 batchs: 1290.4620361328125
INFO:root:Train (Epoch 45): Loss/seq after 01700 batchs: 1282.569580078125
INFO:root:Train (Epoch 45): Loss/seq after 01750 batchs: 1271.5616455078125
INFO:root:Train (Epoch 45): Loss/seq after 01800 batchs: 1258.4908447265625
INFO:root:Train (Epoch 45): Loss/seq after 01850 batchs: 1245.83935546875
INFO:root:Train (Epoch 45): Loss/seq after 01900 batchs: 1245.756591796875
INFO:root:Train (Epoch 45): Loss/seq after 01950 batchs: 1241.894287109375
INFO:root:Train (Epoch 45): Loss/seq after 02000 batchs: 1233.1639404296875
INFO:root:Train (Epoch 45): Loss/seq after 02050 batchs: 1225.9825439453125
INFO:root:Train (Epoch 45): Loss/seq after 02100 batchs: 1215.4962158203125
INFO:root:Train (Epoch 45): Loss/seq after 02150 batchs: 1205.8172607421875
INFO:root:Train (Epoch 45): Loss/seq after 02200 batchs: 1195.38671875
INFO:root:Train (Epoch 45): Loss/seq after 02250 batchs: 1201.081298828125
INFO:root:Train (Epoch 45): Loss/seq after 02300 batchs: 1210.8212890625
INFO:root:Train (Epoch 45): Loss/seq after 02350 batchs: 1203.5693359375
INFO:root:Train (Epoch 45): Loss/seq after 02400 batchs: 1200.6053466796875
INFO:root:Train (Epoch 45): Loss/seq after 02450 batchs: 1188.8330078125
INFO:root:Train (Epoch 45): Loss/seq after 02500 batchs: 1172.3192138671875
INFO:root:Train (Epoch 45): Loss/seq after 02550 batchs: 1162.152099609375
INFO:root:Train (Epoch 45): Loss/seq after 02600 batchs: 1160.213623046875
INFO:root:Train (Epoch 45): Loss/seq after 02650 batchs: 1156.2452392578125
INFO:root:Train (Epoch 45): Loss/seq after 02700 batchs: 1152.7354736328125
INFO:root:Train (Epoch 45): Loss/seq after 02750 batchs: 1182.352783203125
INFO:root:Train (Epoch 45): Loss/seq after 02800 batchs: 1187.063720703125
INFO:root:Train (Epoch 45): Loss/seq after 02850 batchs: 1184.9853515625
INFO:root:Train (Epoch 45): Loss/seq after 02900 batchs: 1183.44287109375
INFO:root:Train (Epoch 45): Loss/seq after 02950 batchs: 1175.9959716796875
INFO:root:Train (Epoch 45): Loss/seq after 03000 batchs: 1174.4779052734375
INFO:root:Train (Epoch 45): Loss/seq after 03050 batchs: 1177.623291015625
INFO:root:Train (Epoch 45): Loss/seq after 03100 batchs: 1190.2818603515625
INFO:root:Train (Epoch 45): Loss/seq after 03150 batchs: 1197.7584228515625
INFO:root:Train (Epoch 45): Loss/seq after 03200 batchs: 1201.31884765625
INFO:root:Train (Epoch 45): Loss/seq after 03250 batchs: 1201.5955810546875
INFO:root:Train (Epoch 45): Loss/seq after 03300 batchs: 1200.096923828125
INFO:root:Train (Epoch 45): Loss/seq after 03350 batchs: 1199.990966796875
INFO:root:Train (Epoch 45): Loss/seq after 03400 batchs: 1191.9329833984375
INFO:root:Train (Epoch 45): Loss/seq after 03450 batchs: 1185.890380859375
INFO:root:Train (Epoch 45): Loss/seq after 03500 batchs: 1186.0396728515625
INFO:root:Train (Epoch 45): Loss/seq after 03550 batchs: 1181.76953125
INFO:root:Train (Epoch 45): Loss/seq after 03600 batchs: 1188.2642822265625
INFO:root:Train (Epoch 45): Loss/seq after 03650 batchs: 1184.5826416015625
INFO:root:Train (Epoch 45): Loss/seq after 03700 batchs: 1184.889892578125
INFO:root:Train (Epoch 45): Loss/seq after 03750 batchs: 1185.31787109375
INFO:root:Train (Epoch 45): Loss/seq after 03800 batchs: 1178.86767578125
INFO:root:Train (Epoch 45): Loss/seq after 03850 batchs: 1174.9149169921875
INFO:root:Train (Epoch 45): Loss/seq after 03900 batchs: 1179.9429931640625
INFO:root:Train (Epoch 45): Loss/seq after 03950 batchs: 1183.571533203125
INFO:root:Train (Epoch 45): Loss/seq after 04000 batchs: 1175.048583984375
INFO:root:Train (Epoch 45): Loss/seq after 04050 batchs: 1167.571044921875
INFO:root:Train (Epoch 45): Loss/seq after 04100 batchs: 1162.5953369140625
INFO:root:Train (Epoch 45): Loss/seq after 04150 batchs: 1157.3743896484375
INFO:root:Train (Epoch 45): Loss/seq after 04200 batchs: 1153.0540771484375
INFO:root:Train (Epoch 45): Loss/seq after 04250 batchs: 1149.250244140625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 45): Loss/seq after 00000 batches: 881.8314208984375
INFO:root:# Valid (Epoch 45): Loss/seq after 00050 batches: 1128.6708984375
INFO:root:# Valid (Epoch 45): Loss/seq after 00100 batches: 1431.205078125
INFO:root:# Valid (Epoch 45): Loss/seq after 00150 batches: 1172.8123779296875
INFO:root:# Valid (Epoch 45): Loss/seq after 00200 batches: 1065.80322265625
INFO:root:Artifacts: Make stick videos for epoch 45
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_45_on_20220414_123506.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_45_index_1114_on_20220414_123506.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 46): Loss/seq after 00000 batchs: 1657.0321044921875
INFO:root:Train (Epoch 46): Loss/seq after 00050 batchs: 1506.9696044921875
INFO:root:Train (Epoch 46): Loss/seq after 00100 batchs: 1522.936279296875
INFO:root:Train (Epoch 46): Loss/seq after 00150 batchs: 1387.40185546875
INFO:root:Train (Epoch 46): Loss/seq after 00200 batchs: 1497.4483642578125
INFO:root:Train (Epoch 46): Loss/seq after 00250 batchs: 1607.241455078125
INFO:root:Train (Epoch 46): Loss/seq after 00300 batchs: 1523.5174560546875
INFO:root:Train (Epoch 46): Loss/seq after 00350 batchs: 1429.9091796875
INFO:root:Train (Epoch 46): Loss/seq after 00400 batchs: 1479.7276611328125
INFO:root:Train (Epoch 46): Loss/seq after 00450 batchs: 1413.00390625
INFO:root:Train (Epoch 46): Loss/seq after 00500 batchs: 1444.3021240234375
INFO:root:Train (Epoch 46): Loss/seq after 00550 batchs: 1387.0054931640625
INFO:root:Train (Epoch 46): Loss/seq after 00600 batchs: 1354.364013671875
INFO:root:Train (Epoch 46): Loss/seq after 00650 batchs: 1345.8931884765625
INFO:root:Train (Epoch 46): Loss/seq after 00700 batchs: 1316.6331787109375
INFO:root:Train (Epoch 46): Loss/seq after 00750 batchs: 1344.88037109375
INFO:root:Train (Epoch 46): Loss/seq after 00800 batchs: 1343.712646484375
INFO:root:Train (Epoch 46): Loss/seq after 00850 batchs: 1320.6591796875
INFO:root:Train (Epoch 46): Loss/seq after 00900 batchs: 1332.5806884765625
INFO:root:Train (Epoch 46): Loss/seq after 00950 batchs: 1361.52587890625
INFO:root:Train (Epoch 46): Loss/seq after 01000 batchs: 1352.7117919921875
INFO:root:Train (Epoch 46): Loss/seq after 01050 batchs: 1340.3304443359375
INFO:root:Train (Epoch 46): Loss/seq after 01100 batchs: 1332.0321044921875
INFO:root:Train (Epoch 46): Loss/seq after 01150 batchs: 1316.141357421875
INFO:root:Train (Epoch 46): Loss/seq after 01200 batchs: 1306.5435791015625
INFO:root:Train (Epoch 46): Loss/seq after 01250 batchs: 1299.784912109375
INFO:root:Train (Epoch 46): Loss/seq after 01300 batchs: 1294.103515625
INFO:root:Train (Epoch 46): Loss/seq after 01350 batchs: 1291.873046875
INFO:root:Train (Epoch 46): Loss/seq after 01400 batchs: 1305.618408203125
INFO:root:Train (Epoch 46): Loss/seq after 01450 batchs: 1296.7459716796875
INFO:root:Train (Epoch 46): Loss/seq after 01500 batchs: 1288.56591796875
INFO:root:Train (Epoch 46): Loss/seq after 01550 batchs: 1293.449951171875
INFO:root:Train (Epoch 46): Loss/seq after 01600 batchs: 1278.0595703125
INFO:root:Train (Epoch 46): Loss/seq after 01650 batchs: 1274.1785888671875
INFO:root:Train (Epoch 46): Loss/seq after 01700 batchs: 1266.6177978515625
INFO:root:Train (Epoch 46): Loss/seq after 01750 batchs: 1256.0587158203125
INFO:root:Train (Epoch 46): Loss/seq after 01800 batchs: 1243.3885498046875
INFO:root:Train (Epoch 46): Loss/seq after 01850 batchs: 1231.1055908203125
INFO:root:Train (Epoch 46): Loss/seq after 01900 batchs: 1231.329833984375
INFO:root:Train (Epoch 46): Loss/seq after 01950 batchs: 1227.7066650390625
INFO:root:Train (Epoch 46): Loss/seq after 02000 batchs: 1219.310302734375
INFO:root:Train (Epoch 46): Loss/seq after 02050 batchs: 1212.462646484375
INFO:root:Train (Epoch 46): Loss/seq after 02100 batchs: 1202.2816162109375
INFO:root:Train (Epoch 46): Loss/seq after 02150 batchs: 1192.9488525390625
INFO:root:Train (Epoch 46): Loss/seq after 02200 batchs: 1182.8028564453125
INFO:root:Train (Epoch 46): Loss/seq after 02250 batchs: 1187.8114013671875
INFO:root:Train (Epoch 46): Loss/seq after 02300 batchs: 1196.7552490234375
INFO:root:Train (Epoch 46): Loss/seq after 02350 batchs: 1189.00439453125
INFO:root:Train (Epoch 46): Loss/seq after 02400 batchs: 1186.5435791015625
INFO:root:Train (Epoch 46): Loss/seq after 02450 batchs: 1175.0540771484375
INFO:root:Train (Epoch 46): Loss/seq after 02500 batchs: 1158.8079833984375
INFO:root:Train (Epoch 46): Loss/seq after 02550 batchs: 1148.8402099609375
INFO:root:Train (Epoch 46): Loss/seq after 02600 batchs: 1147.6549072265625
INFO:root:Train (Epoch 46): Loss/seq after 02650 batchs: 1143.9798583984375
INFO:root:Train (Epoch 46): Loss/seq after 02700 batchs: 1140.528076171875
INFO:root:Train (Epoch 46): Loss/seq after 02750 batchs: 1169.920654296875
INFO:root:Train (Epoch 46): Loss/seq after 02800 batchs: 1174.63525390625
INFO:root:Train (Epoch 46): Loss/seq after 02850 batchs: 1172.705810546875
INFO:root:Train (Epoch 46): Loss/seq after 02900 batchs: 1171.797119140625
INFO:root:Train (Epoch 46): Loss/seq after 02950 batchs: 1164.556884765625
INFO:root:Train (Epoch 46): Loss/seq after 03000 batchs: 1163.2454833984375
INFO:root:Train (Epoch 46): Loss/seq after 03050 batchs: 1166.5770263671875
INFO:root:Train (Epoch 46): Loss/seq after 03100 batchs: 1180.5849609375
INFO:root:Train (Epoch 46): Loss/seq after 03150 batchs: 1186.868896484375
INFO:root:Train (Epoch 46): Loss/seq after 03200 batchs: 1191.1185302734375
INFO:root:Train (Epoch 46): Loss/seq after 03250 batchs: 1191.389404296875
INFO:root:Train (Epoch 46): Loss/seq after 03300 batchs: 1189.84423828125
INFO:root:Train (Epoch 46): Loss/seq after 03350 batchs: 1189.0465087890625
INFO:root:Train (Epoch 46): Loss/seq after 03400 batchs: 1181.061279296875
INFO:root:Train (Epoch 46): Loss/seq after 03450 batchs: 1174.681640625
INFO:root:Train (Epoch 46): Loss/seq after 03500 batchs: 1175.065185546875
INFO:root:Train (Epoch 46): Loss/seq after 03550 batchs: 1170.807373046875
INFO:root:Train (Epoch 46): Loss/seq after 03600 batchs: 1177.388916015625
INFO:root:Train (Epoch 46): Loss/seq after 03650 batchs: 1173.7760009765625
INFO:root:Train (Epoch 46): Loss/seq after 03700 batchs: 1174.1695556640625
INFO:root:Train (Epoch 46): Loss/seq after 03750 batchs: 1174.73388671875
INFO:root:Train (Epoch 46): Loss/seq after 03800 batchs: 1168.411376953125
INFO:root:Train (Epoch 46): Loss/seq after 03850 batchs: 1164.5955810546875
INFO:root:Train (Epoch 46): Loss/seq after 03900 batchs: 1169.9024658203125
INFO:root:Train (Epoch 46): Loss/seq after 03950 batchs: 1173.4322509765625
INFO:root:Train (Epoch 46): Loss/seq after 04000 batchs: 1165.0382080078125
INFO:root:Train (Epoch 46): Loss/seq after 04050 batchs: 1157.683349609375
INFO:root:Train (Epoch 46): Loss/seq after 04100 batchs: 1152.7947998046875
INFO:root:Train (Epoch 46): Loss/seq after 04150 batchs: 1147.658935546875
INFO:root:Train (Epoch 46): Loss/seq after 04200 batchs: 1143.422119140625
INFO:root:Train (Epoch 46): Loss/seq after 04250 batchs: 1139.7158203125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 46): Loss/seq after 00000 batches: 876.2007446289062
INFO:root:# Valid (Epoch 46): Loss/seq after 00050 batches: 1124.7626953125
INFO:root:# Valid (Epoch 46): Loss/seq after 00100 batches: 1425.0194091796875
INFO:root:# Valid (Epoch 46): Loss/seq after 00150 batches: 1160.3402099609375
INFO:root:# Valid (Epoch 46): Loss/seq after 00200 batches: 1050.3262939453125
INFO:root:Artifacts: Make stick videos for epoch 46
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_46_on_20220414_124030.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_46_index_1448_on_20220414_124030.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 47): Loss/seq after 00000 batchs: 1467.355224609375
INFO:root:Train (Epoch 47): Loss/seq after 00050 batchs: 1500.9713134765625
INFO:root:Train (Epoch 47): Loss/seq after 00100 batchs: 1508.04736328125
INFO:root:Train (Epoch 47): Loss/seq after 00150 batchs: 1373.6649169921875
INFO:root:Train (Epoch 47): Loss/seq after 00200 batchs: 1479.903564453125
INFO:root:Train (Epoch 47): Loss/seq after 00250 batchs: 1581.46875
INFO:root:Train (Epoch 47): Loss/seq after 00300 batchs: 1502.206298828125
INFO:root:Train (Epoch 47): Loss/seq after 00350 batchs: 1412.0899658203125
INFO:root:Train (Epoch 47): Loss/seq after 00400 batchs: 1458.759765625
INFO:root:Train (Epoch 47): Loss/seq after 00450 batchs: 1394.2337646484375
INFO:root:Train (Epoch 47): Loss/seq after 00500 batchs: 1422.888916015625
INFO:root:Train (Epoch 47): Loss/seq after 00550 batchs: 1367.489990234375
INFO:root:Train (Epoch 47): Loss/seq after 00600 batchs: 1335.15966796875
INFO:root:Train (Epoch 47): Loss/seq after 00650 batchs: 1327.169677734375
INFO:root:Train (Epoch 47): Loss/seq after 00700 batchs: 1297.440185546875
INFO:root:Train (Epoch 47): Loss/seq after 00750 batchs: 1325.501220703125
INFO:root:Train (Epoch 47): Loss/seq after 00800 batchs: 1326.0545654296875
INFO:root:Train (Epoch 47): Loss/seq after 00850 batchs: 1303.606201171875
INFO:root:Train (Epoch 47): Loss/seq after 00900 batchs: 1315.2750244140625
INFO:root:Train (Epoch 47): Loss/seq after 00950 batchs: 1337.9725341796875
INFO:root:Train (Epoch 47): Loss/seq after 01000 batchs: 1330.2437744140625
INFO:root:Train (Epoch 47): Loss/seq after 01050 batchs: 1317.6142578125
INFO:root:Train (Epoch 47): Loss/seq after 01100 batchs: 1310.501220703125
INFO:root:Train (Epoch 47): Loss/seq after 01150 batchs: 1295.4576416015625
INFO:root:Train (Epoch 47): Loss/seq after 01200 batchs: 1286.6385498046875
INFO:root:Train (Epoch 47): Loss/seq after 01250 batchs: 1280.256591796875
INFO:root:Train (Epoch 47): Loss/seq after 01300 batchs: 1275.6055908203125
INFO:root:Train (Epoch 47): Loss/seq after 01350 batchs: 1274.255615234375
INFO:root:Train (Epoch 47): Loss/seq after 01400 batchs: 1288.1314697265625
INFO:root:Train (Epoch 47): Loss/seq after 01450 batchs: 1279.96533203125
INFO:root:Train (Epoch 47): Loss/seq after 01500 batchs: 1272.368408203125
INFO:root:Train (Epoch 47): Loss/seq after 01550 batchs: 1277.79443359375
INFO:root:Train (Epoch 47): Loss/seq after 01600 batchs: 1262.7801513671875
INFO:root:Train (Epoch 47): Loss/seq after 01650 batchs: 1259.337646484375
INFO:root:Train (Epoch 47): Loss/seq after 01700 batchs: 1252.23486328125
INFO:root:Train (Epoch 47): Loss/seq after 01750 batchs: 1242.05810546875
INFO:root:Train (Epoch 47): Loss/seq after 01800 batchs: 1229.9229736328125
INFO:root:Train (Epoch 47): Loss/seq after 01850 batchs: 1218.101318359375
INFO:root:Train (Epoch 47): Loss/seq after 01900 batchs: 1218.6258544921875
INFO:root:Train (Epoch 47): Loss/seq after 01950 batchs: 1215.324462890625
INFO:root:Train (Epoch 47): Loss/seq after 02000 batchs: 1207.2403564453125
INFO:root:Train (Epoch 47): Loss/seq after 02050 batchs: 1200.6617431640625
INFO:root:Train (Epoch 47): Loss/seq after 02100 batchs: 1190.7589111328125
INFO:root:Train (Epoch 47): Loss/seq after 02150 batchs: 1181.6412353515625
INFO:root:Train (Epoch 47): Loss/seq after 02200 batchs: 1171.726806640625
INFO:root:Train (Epoch 47): Loss/seq after 02250 batchs: 1176.41455078125
INFO:root:Train (Epoch 47): Loss/seq after 02300 batchs: 1184.9652099609375
INFO:root:Train (Epoch 47): Loss/seq after 02350 batchs: 1177.4459228515625
INFO:root:Train (Epoch 47): Loss/seq after 02400 batchs: 1174.79150390625
INFO:root:Train (Epoch 47): Loss/seq after 02450 batchs: 1163.38525390625
INFO:root:Train (Epoch 47): Loss/seq after 02500 batchs: 1147.3314208984375
INFO:root:Train (Epoch 47): Loss/seq after 02550 batchs: 1137.298828125
INFO:root:Train (Epoch 47): Loss/seq after 02600 batchs: 1135.2666015625
INFO:root:Train (Epoch 47): Loss/seq after 02650 batchs: 1131.5472412109375
INFO:root:Train (Epoch 47): Loss/seq after 02700 batchs: 1128.3800048828125
INFO:root:Train (Epoch 47): Loss/seq after 02750 batchs: 1157.22998046875
INFO:root:Train (Epoch 47): Loss/seq after 02800 batchs: 1162.14306640625
INFO:root:Train (Epoch 47): Loss/seq after 02850 batchs: 1160.3526611328125
INFO:root:Train (Epoch 47): Loss/seq after 02900 batchs: 1159.0767822265625
INFO:root:Train (Epoch 47): Loss/seq after 02950 batchs: 1152.0865478515625
INFO:root:Train (Epoch 47): Loss/seq after 03000 batchs: 1150.962646484375
INFO:root:Train (Epoch 47): Loss/seq after 03050 batchs: 1154.439208984375
INFO:root:Train (Epoch 47): Loss/seq after 03100 batchs: 1167.1597900390625
INFO:root:Train (Epoch 47): Loss/seq after 03150 batchs: 1173.10009765625
INFO:root:Train (Epoch 47): Loss/seq after 03200 batchs: 1176.248779296875
INFO:root:Train (Epoch 47): Loss/seq after 03250 batchs: 1176.309326171875
INFO:root:Train (Epoch 47): Loss/seq after 03300 batchs: 1174.5963134765625
INFO:root:Train (Epoch 47): Loss/seq after 03350 batchs: 1173.7015380859375
INFO:root:Train (Epoch 47): Loss/seq after 03400 batchs: 1165.8577880859375
INFO:root:Train (Epoch 47): Loss/seq after 03450 batchs: 1159.570556640625
INFO:root:Train (Epoch 47): Loss/seq after 03500 batchs: 1159.769287109375
INFO:root:Train (Epoch 47): Loss/seq after 03550 batchs: 1155.6055908203125
INFO:root:Train (Epoch 47): Loss/seq after 03600 batchs: 1162.3370361328125
INFO:root:Train (Epoch 47): Loss/seq after 03650 batchs: 1158.77734375
INFO:root:Train (Epoch 47): Loss/seq after 03700 batchs: 1159.1680908203125
INFO:root:Train (Epoch 47): Loss/seq after 03750 batchs: 1159.8988037109375
INFO:root:Train (Epoch 47): Loss/seq after 03800 batchs: 1153.7178955078125
INFO:root:Train (Epoch 47): Loss/seq after 03850 batchs: 1150.0863037109375
INFO:root:Train (Epoch 47): Loss/seq after 03900 batchs: 1154.76318359375
INFO:root:Train (Epoch 47): Loss/seq after 03950 batchs: 1158.59130859375
INFO:root:Train (Epoch 47): Loss/seq after 04000 batchs: 1150.3409423828125
INFO:root:Train (Epoch 47): Loss/seq after 04050 batchs: 1143.1763916015625
INFO:root:Train (Epoch 47): Loss/seq after 04100 batchs: 1138.302978515625
INFO:root:Train (Epoch 47): Loss/seq after 04150 batchs: 1133.3109130859375
INFO:root:Train (Epoch 47): Loss/seq after 04200 batchs: 1129.1103515625
INFO:root:Train (Epoch 47): Loss/seq after 04250 batchs: 1125.4266357421875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 47): Loss/seq after 00000 batches: 885.6403198242188
INFO:root:# Valid (Epoch 47): Loss/seq after 00050 batches: 1160.310302734375
INFO:root:# Valid (Epoch 47): Loss/seq after 00100 batches: 1465.3414306640625
INFO:root:# Valid (Epoch 47): Loss/seq after 00150 batches: 1224.557373046875
INFO:root:# Valid (Epoch 47): Loss/seq after 00200 batches: 1123.6668701171875
INFO:root:Artifacts: Make stick videos for epoch 47
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_47_on_20220414_124558.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_47_index_471_on_20220414_124558.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 48): Loss/seq after 00000 batchs: 1463.3192138671875
INFO:root:Train (Epoch 48): Loss/seq after 00050 batchs: 1480.5675048828125
INFO:root:Train (Epoch 48): Loss/seq after 00100 batchs: 1510.8583984375
INFO:root:Train (Epoch 48): Loss/seq after 00150 batchs: 1381.5755615234375
INFO:root:Train (Epoch 48): Loss/seq after 00200 batchs: 1482.1705322265625
INFO:root:Train (Epoch 48): Loss/seq after 00250 batchs: 1578.606689453125
INFO:root:Train (Epoch 48): Loss/seq after 00300 batchs: 1499.60302734375
INFO:root:Train (Epoch 48): Loss/seq after 00350 batchs: 1409.0152587890625
INFO:root:Train (Epoch 48): Loss/seq after 00400 batchs: 1461.742431640625
INFO:root:Train (Epoch 48): Loss/seq after 00450 batchs: 1396.8583984375
INFO:root:Train (Epoch 48): Loss/seq after 00500 batchs: 1427.87890625
INFO:root:Train (Epoch 48): Loss/seq after 00550 batchs: 1371.270751953125
INFO:root:Train (Epoch 48): Loss/seq after 00600 batchs: 1337.371337890625
INFO:root:Train (Epoch 48): Loss/seq after 00650 batchs: 1326.84423828125
INFO:root:Train (Epoch 48): Loss/seq after 00700 batchs: 1295.389404296875
INFO:root:Train (Epoch 48): Loss/seq after 00750 batchs: 1320.5941162109375
INFO:root:Train (Epoch 48): Loss/seq after 00800 batchs: 1321.23388671875
INFO:root:Train (Epoch 48): Loss/seq after 00850 batchs: 1297.4366455078125
INFO:root:Train (Epoch 48): Loss/seq after 00900 batchs: 1307.8299560546875
INFO:root:Train (Epoch 48): Loss/seq after 00950 batchs: 1329.6436767578125
INFO:root:Train (Epoch 48): Loss/seq after 01000 batchs: 1322.226806640625
INFO:root:Train (Epoch 48): Loss/seq after 01050 batchs: 1309.61083984375
INFO:root:Train (Epoch 48): Loss/seq after 01100 batchs: 1302.512939453125
INFO:root:Train (Epoch 48): Loss/seq after 01150 batchs: 1287.317138671875
INFO:root:Train (Epoch 48): Loss/seq after 01200 batchs: 1278.826904296875
INFO:root:Train (Epoch 48): Loss/seq after 01250 batchs: 1271.7994384765625
INFO:root:Train (Epoch 48): Loss/seq after 01300 batchs: 1266.0418701171875
INFO:root:Train (Epoch 48): Loss/seq after 01350 batchs: 1263.7293701171875
INFO:root:Train (Epoch 48): Loss/seq after 01400 batchs: 1276.5758056640625
INFO:root:Train (Epoch 48): Loss/seq after 01450 batchs: 1268.5390625
INFO:root:Train (Epoch 48): Loss/seq after 01500 batchs: 1261.3394775390625
INFO:root:Train (Epoch 48): Loss/seq after 01550 batchs: 1266.1458740234375
INFO:root:Train (Epoch 48): Loss/seq after 01600 batchs: 1251.5980224609375
INFO:root:Train (Epoch 48): Loss/seq after 01650 batchs: 1248.0560302734375
INFO:root:Train (Epoch 48): Loss/seq after 01700 batchs: 1240.83740234375
INFO:root:Train (Epoch 48): Loss/seq after 01750 batchs: 1230.9388427734375
INFO:root:Train (Epoch 48): Loss/seq after 01800 batchs: 1218.823974609375
INFO:root:Train (Epoch 48): Loss/seq after 01850 batchs: 1206.970703125
INFO:root:Train (Epoch 48): Loss/seq after 01900 batchs: 1207.4351806640625
INFO:root:Train (Epoch 48): Loss/seq after 01950 batchs: 1203.57421875
INFO:root:Train (Epoch 48): Loss/seq after 02000 batchs: 1195.492431640625
INFO:root:Train (Epoch 48): Loss/seq after 02050 batchs: 1188.9207763671875
INFO:root:Train (Epoch 48): Loss/seq after 02100 batchs: 1179.02783203125
INFO:root:Train (Epoch 48): Loss/seq after 02150 batchs: 1169.9791259765625
INFO:root:Train (Epoch 48): Loss/seq after 02200 batchs: 1160.091796875
INFO:root:Train (Epoch 48): Loss/seq after 02250 batchs: 1164.116943359375
INFO:root:Train (Epoch 48): Loss/seq after 02300 batchs: 1172.20361328125
INFO:root:Train (Epoch 48): Loss/seq after 02350 batchs: 1164.2552490234375
INFO:root:Train (Epoch 48): Loss/seq after 02400 batchs: 1161.7491455078125
INFO:root:Train (Epoch 48): Loss/seq after 02450 batchs: 1150.697265625
INFO:root:Train (Epoch 48): Loss/seq after 02500 batchs: 1134.822998046875
INFO:root:Train (Epoch 48): Loss/seq after 02550 batchs: 1124.599609375
INFO:root:Train (Epoch 48): Loss/seq after 02600 batchs: 1123.049560546875
INFO:root:Train (Epoch 48): Loss/seq after 02650 batchs: 1119.04833984375
INFO:root:Train (Epoch 48): Loss/seq after 02700 batchs: 1115.410888671875
INFO:root:Train (Epoch 48): Loss/seq after 02750 batchs: 1143.8221435546875
INFO:root:Train (Epoch 48): Loss/seq after 02800 batchs: 1147.45361328125
INFO:root:Train (Epoch 48): Loss/seq after 02850 batchs: 1145.6793212890625
INFO:root:Train (Epoch 48): Loss/seq after 02900 batchs: 1144.2427978515625
INFO:root:Train (Epoch 48): Loss/seq after 02950 batchs: 1137.448974609375
INFO:root:Train (Epoch 48): Loss/seq after 03000 batchs: 1136.564208984375
INFO:root:Train (Epoch 48): Loss/seq after 03050 batchs: 1140.0753173828125
INFO:root:Train (Epoch 48): Loss/seq after 03100 batchs: 1153.795654296875
INFO:root:Train (Epoch 48): Loss/seq after 03150 batchs: 1158.663330078125
INFO:root:Train (Epoch 48): Loss/seq after 03200 batchs: 1162.612060546875
INFO:root:Train (Epoch 48): Loss/seq after 03250 batchs: 1162.8975830078125
INFO:root:Train (Epoch 48): Loss/seq after 03300 batchs: 1161.1312255859375
INFO:root:Train (Epoch 48): Loss/seq after 03350 batchs: 1160.0819091796875
INFO:root:Train (Epoch 48): Loss/seq after 03400 batchs: 1152.4058837890625
INFO:root:Train (Epoch 48): Loss/seq after 03450 batchs: 1146.1929931640625
INFO:root:Train (Epoch 48): Loss/seq after 03500 batchs: 1145.9259033203125
INFO:root:Train (Epoch 48): Loss/seq after 03550 batchs: 1141.443603515625
INFO:root:Train (Epoch 48): Loss/seq after 03600 batchs: 1148.179931640625
INFO:root:Train (Epoch 48): Loss/seq after 03650 batchs: 1144.15185546875
INFO:root:Train (Epoch 48): Loss/seq after 03700 batchs: 1144.4033203125
INFO:root:Train (Epoch 48): Loss/seq after 03750 batchs: 1145.339111328125
INFO:root:Train (Epoch 48): Loss/seq after 03800 batchs: 1139.3116455078125
INFO:root:Train (Epoch 48): Loss/seq after 03850 batchs: 1135.7806396484375
INFO:root:Train (Epoch 48): Loss/seq after 03900 batchs: 1140.981689453125
INFO:root:Train (Epoch 48): Loss/seq after 03950 batchs: 1145.19287109375
INFO:root:Train (Epoch 48): Loss/seq after 04000 batchs: 1137.1893310546875
INFO:root:Train (Epoch 48): Loss/seq after 04050 batchs: 1130.20166015625
INFO:root:Train (Epoch 48): Loss/seq after 04100 batchs: 1125.1719970703125
INFO:root:Train (Epoch 48): Loss/seq after 04150 batchs: 1120.4647216796875
INFO:root:Train (Epoch 48): Loss/seq after 04200 batchs: 1116.1756591796875
INFO:root:Train (Epoch 48): Loss/seq after 04250 batchs: 1112.40625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 48): Loss/seq after 00000 batches: 899.61767578125
INFO:root:# Valid (Epoch 48): Loss/seq after 00050 batches: 1137.5421142578125
INFO:root:# Valid (Epoch 48): Loss/seq after 00100 batches: 1427.6661376953125
INFO:root:# Valid (Epoch 48): Loss/seq after 00150 batches: 1147.2279052734375
INFO:root:# Valid (Epoch 48): Loss/seq after 00200 batches: 1039.1851806640625
INFO:root:Artifacts: Make stick videos for epoch 48
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_48_on_20220414_125124.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_48_index_342_on_20220414_125124.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 49): Loss/seq after 00000 batchs: 1549.6019287109375
INFO:root:Train (Epoch 49): Loss/seq after 00050 batchs: 1429.160888671875
INFO:root:Train (Epoch 49): Loss/seq after 00100 batchs: 1416.7960205078125
INFO:root:Train (Epoch 49): Loss/seq after 00150 batchs: 1292.6507568359375
INFO:root:Train (Epoch 49): Loss/seq after 00200 batchs: 1414.5960693359375
INFO:root:Train (Epoch 49): Loss/seq after 00250 batchs: 1521.099609375
INFO:root:Train (Epoch 49): Loss/seq after 00300 batchs: 1451.3883056640625
INFO:root:Train (Epoch 49): Loss/seq after 00350 batchs: 1364.9931640625
INFO:root:Train (Epoch 49): Loss/seq after 00400 batchs: 1408.0877685546875
INFO:root:Train (Epoch 49): Loss/seq after 00450 batchs: 1349.4332275390625
INFO:root:Train (Epoch 49): Loss/seq after 00500 batchs: 1376.728515625
INFO:root:Train (Epoch 49): Loss/seq after 00550 batchs: 1321.011474609375
INFO:root:Train (Epoch 49): Loss/seq after 00600 batchs: 1287.385986328125
INFO:root:Train (Epoch 49): Loss/seq after 00650 batchs: 1281.1258544921875
INFO:root:Train (Epoch 49): Loss/seq after 00700 batchs: 1254.758544921875
INFO:root:Train (Epoch 49): Loss/seq after 00750 batchs: 1282.276611328125
INFO:root:Train (Epoch 49): Loss/seq after 00800 batchs: 1278.2860107421875
INFO:root:Train (Epoch 49): Loss/seq after 00850 batchs: 1255.133544921875
INFO:root:Train (Epoch 49): Loss/seq after 00900 batchs: 1262.94873046875
INFO:root:Train (Epoch 49): Loss/seq after 00950 batchs: 1286.2786865234375
INFO:root:Train (Epoch 49): Loss/seq after 01000 batchs: 1277.2431640625
INFO:root:Train (Epoch 49): Loss/seq after 01050 batchs: 1264.7861328125
INFO:root:Train (Epoch 49): Loss/seq after 01100 batchs: 1257.833251953125
INFO:root:Train (Epoch 49): Loss/seq after 01150 batchs: 1243.926513671875
INFO:root:Train (Epoch 49): Loss/seq after 01200 batchs: 1237.07373046875
INFO:root:Train (Epoch 49): Loss/seq after 01250 batchs: 1229.3603515625
INFO:root:Train (Epoch 49): Loss/seq after 01300 batchs: 1223.493896484375
INFO:root:Train (Epoch 49): Loss/seq after 01350 batchs: 1221.053955078125
INFO:root:Train (Epoch 49): Loss/seq after 01400 batchs: 1234.7945556640625
INFO:root:Train (Epoch 49): Loss/seq after 01450 batchs: 1229.2569580078125
INFO:root:Train (Epoch 49): Loss/seq after 01500 batchs: 1223.4794921875
INFO:root:Train (Epoch 49): Loss/seq after 01550 batchs: 1227.8358154296875
INFO:root:Train (Epoch 49): Loss/seq after 01600 batchs: 1214.381591796875
INFO:root:Train (Epoch 49): Loss/seq after 01650 batchs: 1210.070068359375
INFO:root:Train (Epoch 49): Loss/seq after 01700 batchs: 1203.1044921875
INFO:root:Train (Epoch 49): Loss/seq after 01750 batchs: 1194.189453125
INFO:root:Train (Epoch 49): Loss/seq after 01800 batchs: 1182.9361572265625
INFO:root:Train (Epoch 49): Loss/seq after 01850 batchs: 1171.8231201171875
INFO:root:Train (Epoch 49): Loss/seq after 01900 batchs: 1172.906982421875
INFO:root:Train (Epoch 49): Loss/seq after 01950 batchs: 1168.77734375
INFO:root:Train (Epoch 49): Loss/seq after 02000 batchs: 1161.3753662109375
INFO:root:Train (Epoch 49): Loss/seq after 02050 batchs: 1155.1630859375
INFO:root:Train (Epoch 49): Loss/seq after 02100 batchs: 1145.8616943359375
INFO:root:Train (Epoch 49): Loss/seq after 02150 batchs: 1137.45068359375
INFO:root:Train (Epoch 49): Loss/seq after 02200 batchs: 1128.2197265625
INFO:root:Train (Epoch 49): Loss/seq after 02250 batchs: 1130.8770751953125
INFO:root:Train (Epoch 49): Loss/seq after 02300 batchs: 1139.4908447265625
INFO:root:Train (Epoch 49): Loss/seq after 02350 batchs: 1131.662841796875
INFO:root:Train (Epoch 49): Loss/seq after 02400 batchs: 1129.631103515625
INFO:root:Train (Epoch 49): Loss/seq after 02450 batchs: 1118.542724609375
INFO:root:Train (Epoch 49): Loss/seq after 02500 batchs: 1103.4012451171875
INFO:root:Train (Epoch 49): Loss/seq after 02550 batchs: 1093.3328857421875
INFO:root:Train (Epoch 49): Loss/seq after 02600 batchs: 1092.4129638671875
INFO:root:Train (Epoch 49): Loss/seq after 02650 batchs: 1088.8583984375
INFO:root:Train (Epoch 49): Loss/seq after 02700 batchs: 1085.95703125
INFO:root:Train (Epoch 49): Loss/seq after 02750 batchs: 1115.1553955078125
INFO:root:Train (Epoch 49): Loss/seq after 02800 batchs: 1118.691162109375
INFO:root:Train (Epoch 49): Loss/seq after 02850 batchs: 1116.5648193359375
INFO:root:Train (Epoch 49): Loss/seq after 02900 batchs: 1115.4569091796875
INFO:root:Train (Epoch 49): Loss/seq after 02950 batchs: 1109.0235595703125
INFO:root:Train (Epoch 49): Loss/seq after 03000 batchs: 1108.6502685546875
INFO:root:Train (Epoch 49): Loss/seq after 03050 batchs: 1112.4957275390625
INFO:root:Train (Epoch 49): Loss/seq after 03100 batchs: 1124.7249755859375
INFO:root:Train (Epoch 49): Loss/seq after 03150 batchs: 1128.8319091796875
INFO:root:Train (Epoch 49): Loss/seq after 03200 batchs: 1132.662841796875
INFO:root:Train (Epoch 49): Loss/seq after 03250 batchs: 1133.4239501953125
INFO:root:Train (Epoch 49): Loss/seq after 03300 batchs: 1133.83642578125
INFO:root:Train (Epoch 49): Loss/seq after 03350 batchs: 1133.5250244140625
INFO:root:Train (Epoch 49): Loss/seq after 03400 batchs: 1126.4049072265625
INFO:root:Train (Epoch 49): Loss/seq after 03450 batchs: 1121.193603515625
INFO:root:Train (Epoch 49): Loss/seq after 03500 batchs: 1121.7943115234375
INFO:root:Train (Epoch 49): Loss/seq after 03550 batchs: 1117.742919921875
INFO:root:Train (Epoch 49): Loss/seq after 03600 batchs: 1124.7545166015625
INFO:root:Train (Epoch 49): Loss/seq after 03650 batchs: 1120.8758544921875
INFO:root:Train (Epoch 49): Loss/seq after 03700 batchs: 1121.427490234375
INFO:root:Train (Epoch 49): Loss/seq after 03750 batchs: 1122.4940185546875
INFO:root:Train (Epoch 49): Loss/seq after 03800 batchs: 1116.58203125
INFO:root:Train (Epoch 49): Loss/seq after 03850 batchs: 1113.330078125
INFO:root:Train (Epoch 49): Loss/seq after 03900 batchs: 1118.224365234375
INFO:root:Train (Epoch 49): Loss/seq after 03950 batchs: 1122.1016845703125
INFO:root:Train (Epoch 49): Loss/seq after 04000 batchs: 1114.388671875
INFO:root:Train (Epoch 49): Loss/seq after 04050 batchs: 1107.5501708984375
INFO:root:Train (Epoch 49): Loss/seq after 04100 batchs: 1102.54248046875
INFO:root:Train (Epoch 49): Loss/seq after 04150 batchs: 1097.6932373046875
INFO:root:Train (Epoch 49): Loss/seq after 04200 batchs: 1093.52490234375
INFO:root:Train (Epoch 49): Loss/seq after 04250 batchs: 1090.0301513671875
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 49): Loss/seq after 00000 batches: 889.18994140625
INFO:root:# Valid (Epoch 49): Loss/seq after 00050 batches: 1091.779052734375
INFO:root:# Valid (Epoch 49): Loss/seq after 00100 batches: 1385.74658203125
INFO:root:# Valid (Epoch 49): Loss/seq after 00150 batches: 1112.1632080078125
INFO:root:# Valid (Epoch 49): Loss/seq after 00200 batches: 1007.2483520507812
INFO:root:Artifacts: Make stick videos for epoch 49
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_49_on_20220414_125647.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_49_index_612_on_20220414_125647.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 50): Loss/seq after 00000 batchs: 1581.7703857421875
INFO:root:Train (Epoch 50): Loss/seq after 00050 batchs: 1352.65380859375
INFO:root:Train (Epoch 50): Loss/seq after 00100 batchs: 1364.8822021484375
INFO:root:Train (Epoch 50): Loss/seq after 00150 batchs: 1248.251953125
INFO:root:Train (Epoch 50): Loss/seq after 00200 batchs: 1359.607666015625
INFO:root:Train (Epoch 50): Loss/seq after 00250 batchs: 1478.009765625
INFO:root:Train (Epoch 50): Loss/seq after 00300 batchs: 1414.51171875
INFO:root:Train (Epoch 50): Loss/seq after 00350 batchs: 1327.1346435546875
INFO:root:Train (Epoch 50): Loss/seq after 00400 batchs: 1372.4598388671875
INFO:root:Train (Epoch 50): Loss/seq after 00450 batchs: 1317.55517578125
INFO:root:Train (Epoch 50): Loss/seq after 00500 batchs: 1338.709228515625
INFO:root:Train (Epoch 50): Loss/seq after 00550 batchs: 1286.58642578125
INFO:root:Train (Epoch 50): Loss/seq after 00600 batchs: 1248.5257568359375
INFO:root:Train (Epoch 50): Loss/seq after 00650 batchs: 1245.2620849609375
INFO:root:Train (Epoch 50): Loss/seq after 00700 batchs: 1217.6480712890625
INFO:root:Train (Epoch 50): Loss/seq after 00750 batchs: 1244.48583984375
INFO:root:Train (Epoch 50): Loss/seq after 00800 batchs: 1242.0733642578125
INFO:root:Train (Epoch 50): Loss/seq after 00850 batchs: 1219.3089599609375
INFO:root:Train (Epoch 50): Loss/seq after 00900 batchs: 1226.9736328125
INFO:root:Train (Epoch 50): Loss/seq after 00950 batchs: 1251.378173828125
INFO:root:Train (Epoch 50): Loss/seq after 01000 batchs: 1242.6319580078125
INFO:root:Train (Epoch 50): Loss/seq after 01050 batchs: 1228.1949462890625
INFO:root:Train (Epoch 50): Loss/seq after 01100 batchs: 1222.5797119140625
INFO:root:Train (Epoch 50): Loss/seq after 01150 batchs: 1208.5244140625
INFO:root:Train (Epoch 50): Loss/seq after 01200 batchs: 1202.49267578125
INFO:root:Train (Epoch 50): Loss/seq after 01250 batchs: 1196.3087158203125
INFO:root:Train (Epoch 50): Loss/seq after 01300 batchs: 1191.25244140625
INFO:root:Train (Epoch 50): Loss/seq after 01350 batchs: 1190.261474609375
INFO:root:Train (Epoch 50): Loss/seq after 01400 batchs: 1203.1185302734375
INFO:root:Train (Epoch 50): Loss/seq after 01450 batchs: 1196.8858642578125
INFO:root:Train (Epoch 50): Loss/seq after 01500 batchs: 1191.5684814453125
INFO:root:Train (Epoch 50): Loss/seq after 01550 batchs: 1194.3863525390625
INFO:root:Train (Epoch 50): Loss/seq after 01600 batchs: 1181.2220458984375
INFO:root:Train (Epoch 50): Loss/seq after 01650 batchs: 1175.36279296875
INFO:root:Train (Epoch 50): Loss/seq after 01700 batchs: 1170.1746826171875
INFO:root:Train (Epoch 50): Loss/seq after 01750 batchs: 1162.1927490234375
INFO:root:Train (Epoch 50): Loss/seq after 01800 batchs: 1151.5206298828125
INFO:root:Train (Epoch 50): Loss/seq after 01850 batchs: 1140.72802734375
INFO:root:Train (Epoch 50): Loss/seq after 01900 batchs: 1141.9375
INFO:root:Train (Epoch 50): Loss/seq after 01950 batchs: 1137.8050537109375
INFO:root:Train (Epoch 50): Loss/seq after 02000 batchs: 1130.8529052734375
INFO:root:Train (Epoch 50): Loss/seq after 02050 batchs: 1125.134765625
INFO:root:Train (Epoch 50): Loss/seq after 02100 batchs: 1116.07373046875
INFO:root:Train (Epoch 50): Loss/seq after 02150 batchs: 1107.963623046875
INFO:root:Train (Epoch 50): Loss/seq after 02200 batchs: 1099.037841796875
INFO:root:Train (Epoch 50): Loss/seq after 02250 batchs: 1102.3358154296875
INFO:root:Train (Epoch 50): Loss/seq after 02300 batchs: 1109.4781494140625
INFO:root:Train (Epoch 50): Loss/seq after 02350 batchs: 1102.052001953125
INFO:root:Train (Epoch 50): Loss/seq after 02400 batchs: 1099.6744384765625
INFO:root:Train (Epoch 50): Loss/seq after 02450 batchs: 1089.5372314453125
INFO:root:Train (Epoch 50): Loss/seq after 02500 batchs: 1074.8094482421875
INFO:root:Train (Epoch 50): Loss/seq after 02550 batchs: 1064.6103515625
INFO:root:Train (Epoch 50): Loss/seq after 02600 batchs: 1062.880126953125
INFO:root:Train (Epoch 50): Loss/seq after 02650 batchs: 1059.1983642578125
INFO:root:Train (Epoch 50): Loss/seq after 02700 batchs: 1055.691650390625
INFO:root:Train (Epoch 50): Loss/seq after 02750 batchs: 1084.114501953125
INFO:root:Train (Epoch 50): Loss/seq after 02800 batchs: 1087.81982421875
INFO:root:Train (Epoch 50): Loss/seq after 02850 batchs: 1085.9202880859375
INFO:root:Train (Epoch 50): Loss/seq after 02900 batchs: 1084.46142578125
INFO:root:Train (Epoch 50): Loss/seq after 02950 batchs: 1078.971435546875
INFO:root:Train (Epoch 50): Loss/seq after 03000 batchs: 1078.8892822265625
INFO:root:Train (Epoch 50): Loss/seq after 03050 batchs: 1083.1309814453125
INFO:root:Train (Epoch 50): Loss/seq after 03100 batchs: 1094.7437744140625
INFO:root:Train (Epoch 50): Loss/seq after 03150 batchs: 1099.26318359375
INFO:root:Train (Epoch 50): Loss/seq after 03200 batchs: 1103.333251953125
INFO:root:Train (Epoch 50): Loss/seq after 03250 batchs: 1104.236572265625
INFO:root:Train (Epoch 50): Loss/seq after 03300 batchs: 1106.418701171875
INFO:root:Train (Epoch 50): Loss/seq after 03350 batchs: 1107.2264404296875
INFO:root:Train (Epoch 50): Loss/seq after 03400 batchs: 1100.2987060546875
INFO:root:Train (Epoch 50): Loss/seq after 03450 batchs: 1095.787841796875
INFO:root:Train (Epoch 50): Loss/seq after 03500 batchs: 1096.7825927734375
INFO:root:Train (Epoch 50): Loss/seq after 03550 batchs: 1092.93115234375
INFO:root:Train (Epoch 50): Loss/seq after 03600 batchs: 1100.21142578125
INFO:root:Train (Epoch 50): Loss/seq after 03650 batchs: 1096.4202880859375
INFO:root:Train (Epoch 50): Loss/seq after 03700 batchs: 1096.6448974609375
INFO:root:Train (Epoch 50): Loss/seq after 03750 batchs: 1098.012451171875
INFO:root:Train (Epoch 50): Loss/seq after 03800 batchs: 1092.07177734375
INFO:root:Train (Epoch 50): Loss/seq after 03850 batchs: 1088.8837890625
INFO:root:Train (Epoch 50): Loss/seq after 03900 batchs: 1093.35791015625
INFO:root:Train (Epoch 50): Loss/seq after 03950 batchs: 1097.68017578125
INFO:root:Train (Epoch 50): Loss/seq after 04000 batchs: 1090.2452392578125
INFO:root:Train (Epoch 50): Loss/seq after 04050 batchs: 1083.556396484375
INFO:root:Train (Epoch 50): Loss/seq after 04100 batchs: 1079.0382080078125
INFO:root:Train (Epoch 50): Loss/seq after 04150 batchs: 1074.5604248046875
INFO:root:Train (Epoch 50): Loss/seq after 04200 batchs: 1070.623046875
INFO:root:Train (Epoch 50): Loss/seq after 04250 batchs: 1067.2525634765625
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 50): Loss/seq after 00000 batches: 812.2412719726562
INFO:root:# Valid (Epoch 50): Loss/seq after 00050 batches: 1078.651611328125
INFO:root:# Valid (Epoch 50): Loss/seq after 00100 batches: 1374.4669189453125
INFO:root:# Valid (Epoch 50): Loss/seq after 00150 batches: 1092.515380859375
INFO:root:# Valid (Epoch 50): Loss/seq after 00200 batches: 994.3844604492188
INFO:root:Artifacts: Make stick videos for epoch 50
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_50_on_20220414_130210.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_50_index_1335_on_20220414_130210.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 51): Loss/seq after 00000 batchs: 1523.7982177734375
INFO:root:Train (Epoch 51): Loss/seq after 00050 batchs: 1375.3109130859375
INFO:root:Train (Epoch 51): Loss/seq after 00100 batchs: 1366.6341552734375
INFO:root:Train (Epoch 51): Loss/seq after 00150 batchs: 1248.2894287109375
INFO:root:Train (Epoch 51): Loss/seq after 00200 batchs: 1352.649169921875
INFO:root:Train (Epoch 51): Loss/seq after 00250 batchs: 1471.8662109375
INFO:root:Train (Epoch 51): Loss/seq after 00300 batchs: 1408.6239013671875
INFO:root:Train (Epoch 51): Loss/seq after 00350 batchs: 1318.5086669921875
INFO:root:Train (Epoch 51): Loss/seq after 00400 batchs: 1355.0667724609375
INFO:root:Train (Epoch 51): Loss/seq after 00450 batchs: 1302.3719482421875
INFO:root:Train (Epoch 51): Loss/seq after 00500 batchs: 1321.8004150390625
INFO:root:Train (Epoch 51): Loss/seq after 00550 batchs: 1269.142578125
INFO:root:Train (Epoch 51): Loss/seq after 00600 batchs: 1230.9945068359375
INFO:root:Train (Epoch 51): Loss/seq after 00650 batchs: 1229.419677734375
INFO:root:Train (Epoch 51): Loss/seq after 00700 batchs: 1201.27001953125
INFO:root:Train (Epoch 51): Loss/seq after 00750 batchs: 1229.2774658203125
INFO:root:Train (Epoch 51): Loss/seq after 00800 batchs: 1228.5845947265625
INFO:root:Train (Epoch 51): Loss/seq after 00850 batchs: 1204.4771728515625
INFO:root:Train (Epoch 51): Loss/seq after 00900 batchs: 1213.171875
INFO:root:Train (Epoch 51): Loss/seq after 00950 batchs: 1233.1041259765625
INFO:root:Train (Epoch 51): Loss/seq after 01000 batchs: 1226.2109375
INFO:root:Train (Epoch 51): Loss/seq after 01050 batchs: 1209.28369140625
INFO:root:Train (Epoch 51): Loss/seq after 01100 batchs: 1204.492919921875
INFO:root:Train (Epoch 51): Loss/seq after 01150 batchs: 1189.0137939453125
INFO:root:Train (Epoch 51): Loss/seq after 01200 batchs: 1184.1197509765625
INFO:root:Train (Epoch 51): Loss/seq after 01250 batchs: 1176.070068359375
INFO:root:Train (Epoch 51): Loss/seq after 01300 batchs: 1171.2901611328125
INFO:root:Train (Epoch 51): Loss/seq after 01350 batchs: 1172.048583984375
INFO:root:Train (Epoch 51): Loss/seq after 01400 batchs: 1186.0904541015625
INFO:root:Train (Epoch 51): Loss/seq after 01450 batchs: 1185.2882080078125
INFO:root:Train (Epoch 51): Loss/seq after 01500 batchs: 1181.0015869140625
INFO:root:Train (Epoch 51): Loss/seq after 01550 batchs: 1186.7479248046875
INFO:root:Train (Epoch 51): Loss/seq after 01600 batchs: 1174.827392578125
INFO:root:Train (Epoch 51): Loss/seq after 01650 batchs: 1171.77490234375
INFO:root:Train (Epoch 51): Loss/seq after 01700 batchs: 1165.99072265625
INFO:root:Train (Epoch 51): Loss/seq after 01750 batchs: 1157.33837890625
INFO:root:Train (Epoch 51): Loss/seq after 01800 batchs: 1146.599365234375
INFO:root:Train (Epoch 51): Loss/seq after 01850 batchs: 1135.9169921875
INFO:root:Train (Epoch 51): Loss/seq after 01900 batchs: 1137.5052490234375
INFO:root:Train (Epoch 51): Loss/seq after 01950 batchs: 1133.3397216796875
INFO:root:Train (Epoch 51): Loss/seq after 02000 batchs: 1126.4383544921875
INFO:root:Train (Epoch 51): Loss/seq after 02050 batchs: 1120.550537109375
INFO:root:Train (Epoch 51): Loss/seq after 02100 batchs: 1111.5389404296875
INFO:root:Train (Epoch 51): Loss/seq after 02150 batchs: 1103.5701904296875
INFO:root:Train (Epoch 51): Loss/seq after 02200 batchs: 1094.5677490234375
INFO:root:Train (Epoch 51): Loss/seq after 02250 batchs: 1095.4337158203125
INFO:root:Train (Epoch 51): Loss/seq after 02300 batchs: 1102.2459716796875
INFO:root:Train (Epoch 51): Loss/seq after 02350 batchs: 1094.0911865234375
INFO:root:Train (Epoch 51): Loss/seq after 02400 batchs: 1090.9473876953125
INFO:root:Train (Epoch 51): Loss/seq after 02450 batchs: 1080.296142578125
INFO:root:Train (Epoch 51): Loss/seq after 02500 batchs: 1065.4813232421875
INFO:root:Train (Epoch 51): Loss/seq after 02550 batchs: 1055.11572265625
INFO:root:Train (Epoch 51): Loss/seq after 02600 batchs: 1053.2808837890625
INFO:root:Train (Epoch 51): Loss/seq after 02650 batchs: 1048.579345703125
INFO:root:Train (Epoch 51): Loss/seq after 02700 batchs: 1044.6593017578125
INFO:root:Train (Epoch 51): Loss/seq after 02750 batchs: 1071.710693359375
INFO:root:Train (Epoch 51): Loss/seq after 02800 batchs: 1074.8919677734375
INFO:root:Train (Epoch 51): Loss/seq after 02850 batchs: 1072.5179443359375
INFO:root:Train (Epoch 51): Loss/seq after 02900 batchs: 1071.0711669921875
INFO:root:Train (Epoch 51): Loss/seq after 02950 batchs: 1064.88427734375
INFO:root:Train (Epoch 51): Loss/seq after 03000 batchs: 1064.765380859375
INFO:root:Train (Epoch 51): Loss/seq after 03050 batchs: 1068.7255859375
INFO:root:Train (Epoch 51): Loss/seq after 03100 batchs: 1078.861572265625
INFO:root:Train (Epoch 51): Loss/seq after 03150 batchs: 1083.0255126953125
INFO:root:Train (Epoch 51): Loss/seq after 03200 batchs: 1087.9642333984375
INFO:root:Train (Epoch 51): Loss/seq after 03250 batchs: 1089.3502197265625
INFO:root:Train (Epoch 51): Loss/seq after 03300 batchs: 1087.9351806640625
INFO:root:Train (Epoch 51): Loss/seq after 03350 batchs: 1086.814208984375
INFO:root:Train (Epoch 51): Loss/seq after 03400 batchs: 1079.3326416015625
INFO:root:Train (Epoch 51): Loss/seq after 03450 batchs: 1073.7257080078125
INFO:root:Train (Epoch 51): Loss/seq after 03500 batchs: 1073.454833984375
INFO:root:Train (Epoch 51): Loss/seq after 03550 batchs: 1068.9481201171875
INFO:root:Train (Epoch 51): Loss/seq after 03600 batchs: 1076.0008544921875
INFO:root:Train (Epoch 51): Loss/seq after 03650 batchs: 1071.55419921875
INFO:root:Train (Epoch 51): Loss/seq after 03700 batchs: 1071.5970458984375
INFO:root:Train (Epoch 51): Loss/seq after 03750 batchs: 1073.1334228515625
INFO:root:Train (Epoch 51): Loss/seq after 03800 batchs: 1067.552734375
INFO:root:Train (Epoch 51): Loss/seq after 03850 batchs: 1064.7293701171875
INFO:root:Train (Epoch 51): Loss/seq after 03900 batchs: 1068.88232421875
INFO:root:Train (Epoch 51): Loss/seq after 03950 batchs: 1072.880859375
INFO:root:Train (Epoch 51): Loss/seq after 04000 batchs: 1065.7440185546875
INFO:root:Train (Epoch 51): Loss/seq after 04050 batchs: 1059.251708984375
INFO:root:Train (Epoch 51): Loss/seq after 04100 batchs: 1054.8751220703125
INFO:root:Train (Epoch 51): Loss/seq after 04150 batchs: 1050.6002197265625
INFO:root:Train (Epoch 51): Loss/seq after 04200 batchs: 1046.6319580078125
INFO:root:Train (Epoch 51): Loss/seq after 04250 batchs: 1043.25830078125
INFO:root:Valid minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:# Valid (Epoch 51): Loss/seq after 00000 batches: 788.7536010742188
INFO:root:# Valid (Epoch 51): Loss/seq after 00050 batches: 1031.718994140625
INFO:root:# Valid (Epoch 51): Loss/seq after 00100 batches: 1319.2869873046875
INFO:root:# Valid (Epoch 51): Loss/seq after 00150 batches: 1045.7991943359375
INFO:root:# Valid (Epoch 51): Loss/seq after 00200 batches: 946.5014038085938
INFO:root:Artifacts: Make stick videos for epoch 51
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/train_artifact_epoch_51_on_20220414_130736.gif.
INFO:root:Logged train artifact to wandb.
INFO:matplotlib.animation:Animation.save using <class 'matplotlib.animation.PillowWriter'>
INFO:root:Artifact saved at /home/papillon/move/move/animations/test_artifact_epoch_51_index_672_on_20220414_130736.gif.
INFO:root:Logged test artifact to wandb.
INFO:root:Train minibatch x of shape: torch.Size([8, 128, 159])
INFO:root:Train (Epoch 52): Loss/seq after 00000 batchs: 1502.1900634765625
INFO:root:Train (Epoch 52): Loss/seq after 00050 batchs: 1304.3861083984375
INFO:root:Train (Epoch 52): Loss/seq after 00100 batchs: 1296.8515625
INFO:root:Train (Epoch 52): Loss/seq after 00150 batchs: 1186.303955078125
INFO:root:Train (Epoch 52): Loss/seq after 00200 batchs: 1289.0909423828125
INFO:root:Train (Epoch 52): Loss/seq after 00250 batchs: 1410.8189697265625
INFO:root:Train (Epoch 52): Loss/seq after 00300 batchs: 1356.7899169921875
INFO:root:Train (Epoch 52): Loss/seq after 00350 batchs: 1274.9322509765625
INFO:root:Train (Epoch 52): Loss/seq after 00400 batchs: 1320.5341796875
INFO:root:Train (Epoch 52): Loss/seq after 00450 batchs: 1271.2891845703125
INFO:root:Train (Epoch 52): Loss/seq after 00500 batchs: 1287.2418212890625
INFO:root:Train (Epoch 52): Loss/seq after 00550 batchs: 1237.5831298828125
INFO:root:Train (Epoch 52): Loss/seq after 00600 batchs: 1200.267578125
INFO:root:Train (Epoch 52): Loss/seq after 00650 batchs: 1202.7047119140625
INFO:root:Train (Epoch 52): Loss/seq after 00700 batchs: 1177.9339599609375
INFO:root:Train (Epoch 52): Loss/seq after 00750 batchs: 1204.7701416015625
INFO:root:Train (Epoch 52): Loss/seq after 00800 batchs: 1201.1654052734375
INFO:root:Train (Epoch 52): Loss/seq after 00850 batchs: 1174.610595703125
INFO:root:Train (Epoch 52): Loss/seq after 00900 batchs: 1179.0699462890625
INFO:root:Train (Epoch 52): Loss/seq after 00950 batchs: 1200.8758544921875
INFO:root:Train (Epoch 52): Loss/seq after 01000 batchs: 1194.4404296875
INFO:root:Train (Epoch 52): Loss/seq after 01050 batchs: 1179.888916015625
INFO:root:Train (Epoch 52): Loss/seq after 01100 batchs: 1175.1925048828125
INFO:root:Train (Epoch 52): Loss/seq after 01150 batchs: 1160.9139404296875
INFO:root:Train (Epoch 52): Loss/seq after 01200 batchs: 1156.929931640625
INFO:root:Train (Epoch 52): Loss/seq after 01250 batchs: 1152.1612548828125
INFO:root:Train (Epoch 52): Loss/seq after 01300 batchs: 1149.0345458984375
INFO:root:Train (Epoch 52): Loss/seq after 01350 batchs: 1150.07421875
INFO:root:Train (Epoch 52): Loss/seq after 01400 batchs: 1165.3323974609375
INFO:root:Train (Epoch 52): Loss/seq after 01450 batchs: 1159.675048828125
INFO:root:Train (Epoch 52): Loss/seq after 01500 batchs: 1155.34375
INFO:root:Train (Epoch 52): Loss/seq after 01550 batchs: 1159.8123779296875
INFO:root:Train (Epoch 52): Loss/seq after 01600 batchs: 1147.6778564453125
INFO:root:Train (Epoch 52): Loss/seq after 01650 batchs: 1142.9210205078125
INFO:root:Train (Epoch 52): Loss/seq after 01700 batchs: 1137.811767578125
INFO:root:Train (Epoch 52): Loss/seq after 01750 batchs: 1129.7108154296875
INFO:root:Train (Epoch 52): Loss/seq after 01800 batchs: 1119.859130859375
